<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>DP-NMT: Scalable Differentially-Private Machine Translation</title>
<!--Generated on Tue Apr 30 19:50:06 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2311.14465v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S1" title="In DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S2" title="In DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>DP-SGD and subsampling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S3" title="In DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Related work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S3.SS1" title="In 3 Related work ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Applications of DP-SGD to NLP</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S3.SS2" title="In 3 Related work ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Private neural machine translation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S4" title="In DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Description of software</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S4.SS0.SSS0.Px1" title="In 4 Description of software ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title">Accelerated DP-SGD with JAX and Flax</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S4.SS0.SSS0.Px2" title="In 4 Description of software ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title">Model training and inference</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S4.SS0.SSS0.Px3" title="In 4 Description of software ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title">Integrating <span class="ltx_text ltx_font_typewriter">DPDataloader</span> from Opacus</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S4.SS0.SSS0.Px4" title="In 4 Description of software ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title">Engineering challenges for LLMs</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S5" title="In DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S5.SS1" title="In 5 Experiments ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S5.SS2" title="In 5 Experiments ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Experimental setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S5.SS3" title="In 5 Experiments ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Results and Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S5.SS3.SSS0.Px1" title="In 5.3 Results and Discussion ‣ 5 Experiments ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title">Privacy/utility trade-off</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S5.SS3.SSS0.Px2" title="In 5.3 Results and Discussion ‣ 5 Experiments ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title">Method of dataset iteration</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S6" title="In DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#A1" title="In DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Background on Differential Privacy and DP-SGD</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#A1.SS0.SSS0.Px1" title="In Appendix A Background on Differential Privacy and DP-SGD ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title">Differential Privacy</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#A1.SS0.SSS0.Px2" title="In Appendix A Background on Differential Privacy and DP-SGD ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title">DP-SGD</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#A2" title="In DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Hyperparameters</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#A3" title="In DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Detailed Results</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para ltx_noindent" id="p1">
<p class="ltx_p" id="p1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1">DP-NMT: Scalable Differentially-Private Machine Translation</span></p>
</div>
<div class="ltx_para ltx_noindent" id="p2">
<p class="ltx_p" id="p2.1">Timour Igamberdiev, Doan Nam Long Vu, Felix Künnecke, Zhuo Yu, Jannik Holmer and Ivan Habernal</p>
</div>
<div class="ltx_para" id="p3">
<br class="ltx_break"/>
<p class="ltx_p" id="p3.1">This is a <span class="ltx_text ltx_font_bold" id="p3.1.1">camera-ready version</span> of the article accepted for publication at the <em class="ltx_emph ltx_font_italic" id="p3.1.2">18th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2024)</em>. The final official version is published on the ACL Anthology website: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/" title="">https://aclanthology.org/</a></p>
</div>
<div class="ltx_para" id="p4">
<p class="ltx_p" id="p4.1">Please cite this pre-print version as follows.</p>
</div>
<div class="ltx_para" id="p5">
<pre class="ltx_verbatim ltx_font_typewriter" id="p5.1">
@InProceedings{Igamberdiev.2024.EACL,
    title = {DP-NMT: Scalable Differentially-Private
             Machine Translation},
    author = {Igamberdiev, Timour and
              Vu, Doan Nam Long and
              Kuennecke, Felix and
              Yu, Zhuo and
              Holmer, Jannik and
              Habernal, Ivan},
    publisher = {Association for Computational Linguistics},
    booktitle = {Proceedings of the 18th Conference
                 of the European Chapter of the
                 Association for Computational Linguistics:
                 System Demonstrations},
    pages = {94--105},
    year = {2024},
    address = {St. Julians, Malta}
}
</pre>
</div>
<h1 class="ltx_title ltx_title_document">DP-NMT: Scalable Differentially-Private Machine Translation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Timour Igamberdiev<sup class="ltx_sup" id="id1.1.1"><math alttext="1" class="ltx_Math" display="inline" id="id1.1.1.m1.1"><semantics id="id1.1.1.m1.1a"><mn id="id1.1.1.m1.1.1" xref="id1.1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="id1.1.1.m1.1b"><cn id="id1.1.1.m1.1.1.cmml" type="integer" xref="id1.1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="id1.1.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="id1.1.1.m1.1d">1</annotation></semantics></math></sup>  
Doan Nam Long Vu<sup class="ltx_sup" id="id2.2.2"><math alttext="1" class="ltx_Math" display="inline" id="id2.2.2.m1.1"><semantics id="id2.2.2.m1.1a"><mn id="id2.2.2.m1.1.1" xref="id2.2.2.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="id2.2.2.m1.1b"><cn id="id2.2.2.m1.1.1.cmml" type="integer" xref="id2.2.2.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="id2.2.2.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="id2.2.2.m1.1d">1</annotation></semantics></math></sup>  
Felix Künnecke<sup class="ltx_sup" id="id3.3.3"><math alttext="1" class="ltx_Math" display="inline" id="id3.3.3.m1.1"><semantics id="id3.3.3.m1.1a"><mn id="id3.3.3.m1.1.1" xref="id3.3.3.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="id3.3.3.m1.1b"><cn id="id3.3.3.m1.1.1.cmml" type="integer" xref="id3.3.3.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="id3.3.3.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="id3.3.3.m1.1d">1</annotation></semantics></math></sup>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id4.4.4">Zhuo Yu<sup class="ltx_sup" id="id4.4.4.1"><math alttext="1" class="ltx_Math" display="inline" id="id4.4.4.1.m1.1"><semantics id="id4.4.4.1.m1.1a"><mn id="id4.4.4.1.m1.1.1" xref="id4.4.4.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="id4.4.4.1.m1.1b"><cn id="id4.4.4.1.m1.1.1.cmml" type="integer" xref="id4.4.4.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="id4.4.4.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="id4.4.4.1.m1.1d">1</annotation></semantics></math></sup></span>  
<span class="ltx_text ltx_font_bold" id="id5.5.5">Jannik Holmer<sup class="ltx_sup" id="id5.5.5.1"><math alttext="1" class="ltx_Math" display="inline" id="id5.5.5.1.m1.1"><semantics id="id5.5.5.1.m1.1a"><mn id="id5.5.5.1.m1.1.1" xref="id5.5.5.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="id5.5.5.1.m1.1b"><cn id="id5.5.5.1.m1.1.1.cmml" type="integer" xref="id5.5.5.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="id5.5.5.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="id5.5.5.1.m1.1d">1</annotation></semantics></math></sup></span>  
<span class="ltx_text ltx_font_bold" id="id6.6.6">Ivan Habernal<sup class="ltx_sup" id="id6.6.6.1"><math alttext="2" class="ltx_Math" display="inline" id="id6.6.6.1.m1.1"><semantics id="id6.6.6.1.m1.1a"><mn id="id6.6.6.1.m1.1.1" xref="id6.6.6.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="id6.6.6.1.m1.1b"><cn id="id6.6.6.1.m1.1.1.cmml" type="integer" xref="id6.6.6.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="id6.6.6.1.m1.1c">2</annotation><annotation encoding="application/x-llamapun" id="id6.6.6.1.m1.1d">2</annotation></semantics></math></sup></span>
<br class="ltx_break"/>Trustworthy Human Language Technologies 
<br class="ltx_break"/><sup class="ltx_sup" id="id7.7.7"><math alttext="1" class="ltx_Math" display="inline" id="id7.7.7.m1.1"><semantics id="id7.7.7.m1.1a"><mn id="id7.7.7.m1.1.1" xref="id7.7.7.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="id7.7.7.m1.1b"><cn id="id7.7.7.m1.1.1.cmml" type="integer" xref="id7.7.7.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="id7.7.7.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="id7.7.7.m1.1d">1</annotation></semantics></math></sup> Department of Computer Science, Technical University of Darmstadt 
<br class="ltx_break"/><sup class="ltx_sup" id="id8.8.8"><math alttext="2" class="ltx_Math" display="inline" id="id8.8.8.m1.1"><semantics id="id8.8.8.m1.1a"><mn id="id8.8.8.m1.1.1" xref="id8.8.8.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="id8.8.8.m1.1b"><cn id="id8.8.8.m1.1.1.cmml" type="integer" xref="id8.8.8.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="id8.8.8.m1.1c">2</annotation><annotation encoding="application/x-llamapun" id="id8.8.8.m1.1d">2</annotation></semantics></math></sup> Department of Computer Science, Paderborn University 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id9.9.id1">timour.igamberdiev@tu-darmstadt.de</span>
<br class="ltx_break"/><a class="ltx_ref ltx_url ltx_font_typewriter" href="www.trusthlt.org" title="">www.trusthlt.org</a>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id10.id1">Neural machine translation (NMT) is a widely popular text generation task, yet there is a considerable research gap in the development of privacy-preserving NMT models, despite significant data privacy concerns for NMT systems.
Differentially private stochastic gradient descent (DP-SGD) is a popular method for training machine learning models with concrete privacy guarantees; however, the implementation specifics of training a model with DP-SGD are not always clarified in existing models,
with differing software libraries used and code bases not always being public, leading to reproducibility issues.
To tackle this, we introduce <span class="ltx_text ltx_font_typewriter" id="id10.id1.1">DP-NMT</span>, an open-source framework for carrying out research on privacy-preserving NMT with DP-SGD, bringing together numerous models, datasets, and evaluation metrics in one systematic software package.
Our goal is to provide a platform for researchers to advance the development of privacy-preserving NMT systems, keeping the specific details of the DP-SGD algorithm transparent and intuitive to implement.
We run a set of experiments on datasets from both general and privacy-related domains to demonstrate our framework in use.
We make our framework publicly available and welcome feedback from the community.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/trusthlt/dp-nmt" title="">https://github.com/trusthlt/dp-nmt</a></span></span></span></p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Privacy-preserving natural language processing (NLP) has been a recently growing field, in large part due to an increasing amount of concern regarding data privacy. This is especially a concern in the context of modern neural networks memorizing training data that may contain sensitive information <cite class="ltx_cite ltx_citemacro_citep">(Carlini et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib10" title="">2021</a>)</cite>.
While there has been a body of research investigating privacy for text classification tasks <cite class="ltx_cite ltx_citemacro_citep">(Senge et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib43" title="">2022</a>)</cite> and language models <cite class="ltx_cite ltx_citemacro_citep">(Hoory et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib21" title="">2021</a>; Anil et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib3" title="">2022</a>)</cite>, there has not been as much focus on text generation tasks, in particular neural machine translation (NMT).
However, NMT is particularly worrying from a privacy perspective, due to a variety of machine translation services available online that users send their personal data to.
This includes built-in NMT services to existing websites, e-mail clients, and search engines.
After data has been sent to these systems, it may be further processed and used in the development of the NMT system <cite class="ltx_cite ltx_citemacro_citep">(Kamocki and O’Regan, <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib26" title="">2016</a>)</cite>, which has a significant risk of being memorized if trained in a non-private manner.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">One of the most popular methods for tackling this privacy issue is differential privacy (DP), being a formal framework which provides probabilistic guarantees that the contribution of any single data point to some analysis is bounded.
In the case of NLP and machine learning (ML), this means that a data point associated with some individual which is included in the model’s training data cannot stand out ‘too much’ in the learning process of the model.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The DP-SGD algorithm <cite class="ltx_cite ltx_citemacro_citep">(Abadi et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib2" title="">2016b</a>)</cite> is one of the most standard methods to achieve this for ML systems, yet implementations of DP-SGD often lack some technical details on the specifics of the algorithm.
In particular, this includes the privacy amplification method assumed for calculating the privacy budget <math alttext="\varepsilon" class="ltx_Math" display="inline" id="S1.p3.1.m1.1"><semantics id="S1.p3.1.m1.1a"><mi id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><ci id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">\varepsilon</annotation><annotation encoding="application/x-llamapun" id="S1.p3.1.m1.1d">italic_ε</annotation></semantics></math> when composed over all training iterations of the model.
This means that the exact <span class="ltx_text ltx_font_italic" id="S1.p3.1.1">strength of the privacy protection</span> that the resulting systems provide is not clear, with the ‘standard’ <span class="ltx_text ltx_font_bold" id="S1.p3.1.2">random shuffling</span> method for iterating over batches providing a weaker privacy guarantee for the training data than <span class="ltx_text ltx_font_bold" id="S1.p3.1.3">Poisson sampling</span>.
With different implementations using different software libraries, the community currently does not have a consistent platform for conducting experiments for scalable differentially private systems, such as NMT.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">To tackle this problem, we develop a modular framework for conducting research on private NMT in a transparent and reproducible manner.
Our primary goal is to allow for a deeper investigation into the applications of DP for NMT, all while ensuring that important theoretical details of the DP-SGD methodology are properly reflected in the implementation.
Following previous work on DP-SGD <cite class="ltx_cite ltx_citemacro_citep">(Subramani et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib46" title="">2021</a>; Anil et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib3" title="">2022</a>)</cite>, we implement our framework in the JAX library <cite class="ltx_cite ltx_citemacro_citep">(Bradbury et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib8" title="">2018</a>)</cite>, which provides powerful tools that help to reduce the significant computational overhead of DP-SGD, allowing for scalability in implementing larger systems and more extended training regimes.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Our primary contributions are as follows.
First, we present <span class="ltx_text ltx_font_typewriter" id="S1.p5.1.1">DP-NMT</span>, a framework developed in JAX for leading research on NMT with DP-SGD. It includes a growing list of available NMT models, different evaluation schemes, as well as numerous datasets available out of the box, including standard datasets used for NMT research and more specific privacy-related domains.
Second, we demonstrate our framework by running experiments on these NMT datasets, providing one of the first investigations into privacy-preserving NMT.
Importantly, we compare the random shuffling and Poisson sampling methods for iterating over training data when using DP-SGD.
We demonstrate that, in addition to the theoretical privacy guarantee, there may indeed be differences in the model performance when utilizing each of the two settings.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>DP-SGD and subsampling</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">We describe the main ideas of differential privacy (DP) and DP-SGD in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#A1" title="Appendix A Background on Differential Privacy and DP-SGD ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_tag">A</span></a>.
We refer to <cite class="ltx_cite ltx_citemacro_citet">Abadi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib2" title="">2016b</a>); Igamberdiev and Habernal (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib24" title="">2022</a>); Habernal (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib16" title="">2021</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib17" title="">2022</a>); Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib23" title="">2024</a>)</cite> for a more comprehensive explanation.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.3">A key aspect of the DP-SGD algorithm (see Alg. <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#alg1" title="Algorithm 1 ‣ DP-SGD ‣ Appendix A Background on Differential Privacy and DP-SGD ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a> in the Appendix) is <span class="ltx_text ltx_font_bold" id="S2.p2.3.1">privacy amplification by subsampling</span>, in which a stronger privacy guarantee can be obtained for a given dataset <math alttext="x" class="ltx_Math" display="inline" id="S2.p2.1.m1.1"><semantics id="S2.p2.1.m1.1a"><mi id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><ci id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.p2.1.m1.1d">italic_x</annotation></semantics></math> when a subset of this dataset is first randomly sampled <cite class="ltx_cite ltx_citemacro_citep">(Kasiviswanathan et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib27" title="">2011</a>; Beimel et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib6" title="">2014</a>)</cite>.
If the sampling probability is <math alttext="q" class="ltx_Math" display="inline" id="S2.p2.2.m2.1"><semantics id="S2.p2.2.m2.1a"><mi id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><ci id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="S2.p2.2.m2.1d">italic_q</annotation></semantics></math>, then the overall privacy guarantee can be analyzed as being approximately <math alttext="q\varepsilon" class="ltx_Math" display="inline" id="S2.p2.3.m3.1"><semantics id="S2.p2.3.m3.1a"><mrow id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml"><mi id="S2.p2.3.m3.1.1.2" xref="S2.p2.3.m3.1.1.2.cmml">q</mi><mo id="S2.p2.3.m3.1.1.1" xref="S2.p2.3.m3.1.1.1.cmml">⁢</mo><mi id="S2.p2.3.m3.1.1.3" xref="S2.p2.3.m3.1.1.3.cmml">ε</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.1b"><apply id="S2.p2.3.m3.1.1.cmml" xref="S2.p2.3.m3.1.1"><times id="S2.p2.3.m3.1.1.1.cmml" xref="S2.p2.3.m3.1.1.1"></times><ci id="S2.p2.3.m3.1.1.2.cmml" xref="S2.p2.3.m3.1.1.2">𝑞</ci><ci id="S2.p2.3.m3.1.1.3.cmml" xref="S2.p2.3.m3.1.1.3">𝜀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.1c">q\varepsilon</annotation><annotation encoding="application/x-llamapun" id="S2.p2.3.m3.1d">italic_q italic_ε</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.3">A key point here is the nature of this sampling procedure and the resulting privacy guarantee.
The moments accountant of <cite class="ltx_cite ltx_citemacro_citet">Abadi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib2" title="">2016b</a>)</cite>, which is an improvement on the strong composition theorem <cite class="ltx_cite ltx_citemacro_citep">(Dwork et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib13" title="">2010</a>)</cite> for composing multiple DP mechanisms, assumes Poisson sampling.
Under this procedure, <span class="ltx_text ltx_font_italic" id="S2.p3.3.1">each data point</span> is included in a mini-batch with probability <math alttext="q=L/N" class="ltx_Math" display="inline" id="S2.p3.1.m1.1"><semantics id="S2.p3.1.m1.1a"><mrow id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml"><mi id="S2.p3.1.m1.1.1.2" xref="S2.p3.1.m1.1.1.2.cmml">q</mi><mo id="S2.p3.1.m1.1.1.1" xref="S2.p3.1.m1.1.1.1.cmml">=</mo><mrow id="S2.p3.1.m1.1.1.3" xref="S2.p3.1.m1.1.1.3.cmml"><mi id="S2.p3.1.m1.1.1.3.2" xref="S2.p3.1.m1.1.1.3.2.cmml">L</mi><mo id="S2.p3.1.m1.1.1.3.1" xref="S2.p3.1.m1.1.1.3.1.cmml">/</mo><mi id="S2.p3.1.m1.1.1.3.3" xref="S2.p3.1.m1.1.1.3.3.cmml">N</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><apply id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1"><eq id="S2.p3.1.m1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1"></eq><ci id="S2.p3.1.m1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.2">𝑞</ci><apply id="S2.p3.1.m1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.3"><divide id="S2.p3.1.m1.1.1.3.1.cmml" xref="S2.p3.1.m1.1.1.3.1"></divide><ci id="S2.p3.1.m1.1.1.3.2.cmml" xref="S2.p3.1.m1.1.1.3.2">𝐿</ci><ci id="S2.p3.1.m1.1.1.3.3.cmml" xref="S2.p3.1.m1.1.1.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">q=L/N</annotation><annotation encoding="application/x-llamapun" id="S2.p3.1.m1.1d">italic_q = italic_L / italic_N</annotation></semantics></math>, with <math alttext="L" class="ltx_Math" display="inline" id="S2.p3.2.m2.1"><semantics id="S2.p3.2.m2.1a"><mi id="S2.p3.2.m2.1.1" xref="S2.p3.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.p3.2.m2.1b"><ci id="S2.p3.2.m2.1.1.cmml" xref="S2.p3.2.m2.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.2.m2.1c">L</annotation><annotation encoding="application/x-llamapun" id="S2.p3.2.m2.1d">italic_L</annotation></semantics></math> being the <span class="ltx_text ltx_font_italic" id="S2.p3.3.2">lot size</span> and <math alttext="N" class="ltx_Math" display="inline" id="S2.p3.3.m3.1"><semantics id="S2.p3.3.m3.1a"><mi id="S2.p3.3.m3.1.1" xref="S2.p3.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.p3.3.m3.1b"><ci id="S2.p3.3.m3.1.1.cmml" xref="S2.p3.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S2.p3.3.m3.1d">italic_N</annotation></semantics></math> the size of the dataset.
An alternative method to Poisson sampling is uniform sampling, in which mini-batches of a fixed size are independently drawn at each training iteration <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib49" title="">2019</a>; Balle et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib4" title="">2018</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.2">In practice, however, many modern implementations of DP-SGD utilize <span class="ltx_text ltx_font_bold" id="S2.p4.2.1">random shuffling</span>, with the dataset split into fixed-size mini-batches.
Several training iterations thus form an epoch, in which each training data point appears exactly once, in contrast to Poisson sampling for which the original notion of ‘epoch’ is not quite suitable, since each data point can appear in any training iteration and there is no “single passing of the training data through the model”.
In <cite class="ltx_cite ltx_citemacro_citet">Abadi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib2" title="">2016b</a>)</cite>, the term <span class="ltx_text ltx_font_italic" id="S2.p4.2.2">epoch</span> is redefined as <math alttext="\frac{N}{L}" class="ltx_Math" display="inline" id="S2.p4.1.m1.1"><semantics id="S2.p4.1.m1.1a"><mfrac id="S2.p4.1.m1.1.1" xref="S2.p4.1.m1.1.1.cmml"><mi id="S2.p4.1.m1.1.1.2" xref="S2.p4.1.m1.1.1.2.cmml">N</mi><mi id="S2.p4.1.m1.1.1.3" xref="S2.p4.1.m1.1.1.3.cmml">L</mi></mfrac><annotation-xml encoding="MathML-Content" id="S2.p4.1.m1.1b"><apply id="S2.p4.1.m1.1.1.cmml" xref="S2.p4.1.m1.1.1"><divide id="S2.p4.1.m1.1.1.1.cmml" xref="S2.p4.1.m1.1.1"></divide><ci id="S2.p4.1.m1.1.1.2.cmml" xref="S2.p4.1.m1.1.1.2">𝑁</ci><ci id="S2.p4.1.m1.1.1.3.cmml" xref="S2.p4.1.m1.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.1.m1.1c">\frac{N}{L}</annotation><annotation encoding="application/x-llamapun" id="S2.p4.1.m1.1d">divide start_ARG italic_N end_ARG start_ARG italic_L end_ARG</annotation></semantics></math> lots, being essentially an expectation of the number of batches when utilizing <math alttext="N" class="ltx_Math" display="inline" id="S2.p4.2.m2.1"><semantics id="S2.p4.2.m2.1a"><mi id="S2.p4.2.m2.1.1" xref="S2.p4.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.p4.2.m2.1b"><ci id="S2.p4.2.m2.1.1.cmml" xref="S2.p4.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S2.p4.2.m2.1d">italic_N</annotation></semantics></math> data points for training the model.
While simply shuffling the dataset can indeed result in privacy amplification <cite class="ltx_cite ltx_citemacro_citep">(Erlingsson et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib14" title="">2019</a>; Feldman et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib15" title="">2022</a>)</cite>, the nature of the corresponding privacy guarantee is <span class="ltx_text ltx_font_bold" id="S2.p4.2.3">not the same</span> as the guarantee achieved by Poisson sampling, generally being weaker. We refer to <cite class="ltx_cite ltx_citemacro_citet">Ponomareva et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib39" title="">2023</a>, Section 4.3)</cite> for further details.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Related work</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Applications of DP-SGD to NLP</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The application of DP-SGD to the field of NLP has seen an increasing amount of attention in recent years.
A large part of these studies focus on differentially private pre-training or fine-tuning of language models <cite class="ltx_cite ltx_citemacro_citep">(Hoory et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib21" title="">2021</a>; Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib57" title="">2021</a>; Basu et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib5" title="">2021</a>; Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib53" title="">2021</a>; Anil et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib3" title="">2022</a>; Ponomareva et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib38" title="">2022</a>; Shi et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib44" title="">2022</a>; Wu et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib52" title="">2022</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib31" title="">2022</a>; Yin and Habernal, <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib55" title="">2022</a>; Mattern et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib33" title="">2022</a>; Hansen et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib18" title="">2022</a>; Senge et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib43" title="">2022</a>)</cite>. A primary goal is to reach the best possible privacy/utility trade-off for the trained models, in which the highest performance is achieved with the strictest privacy guarantees.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">In the general machine learning setting, the exact sampling method that is used for selecting batches at each training iteration is often omitted, since this is generally not a core detail of the training methodology.
Possibly for this reason, in the case of privately training a model with DP-SGD, the sampling method is also often not mentioned.
However, in contrast to the non-private setting, here <span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">sampling is actually a core detail of the algorithm</span>, which has an <span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.2">impact on the privacy accounting procedure</span>.
In the case that experimental descriptions with DP-SGD include mentions of <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.3">epochs</span> without further clarification, this in fact suggests the use of the random shuffling scheme, as opposed to Poisson sampling, as described in Section <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S2" title="2 DP-SGD and subsampling ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>.
In addition, sometimes the code base is not publicly available, in which case it is not possible to validate the sampling scheme used.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">Finally, standard implementations of DP-SGD in the Opacus <cite class="ltx_cite ltx_citemacro_citep">(Yousefpour et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib56" title="">2021</a>)</cite> and TensorFlow Privacy <cite class="ltx_cite ltx_citemacro_citep">(Abadi et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib1" title="">2016a</a>)</cite> libraries often include descriptions of DP-SGD implementations with randomly shuffled fixed-size batches.
For instance, while Opacus currently has a <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p3.1.1">DPDataLoader</span> class which by default uses their <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p3.1.2">UniformWithReplacementSampler</span> class for facilitating the use of Poisson sampling, some of the tutorials currently offered appear to also use static batches instead.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://opacus.ai/tutorials/building_image_classifier" title="">https://opacus.ai/tutorials/building_image_classifier</a>.</span></span></span>
A similar situation is true for TensorFlow Privacy.<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.tensorflow.org/responsible_ai/privacy/tutorials/classification_privacy" title="">https://www.tensorflow.org/responsible_ai/privacy/tutorials/classification_privacy</a>.</span></span></span>
While these libraries support per-example gradients as well, several core features of JAX make it the fastest and most scalable option for implementing DP-SGD <cite class="ltx_cite ltx_citemacro_citep">(Subramani et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib46" title="">2021</a>)</cite>, described in more detail below in Section <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S4" title="4 Description of software ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">We therefore stress the importance of clarifying implementation details that may not be as vital in the general machine learning setting, but are very relevant in the private setting. As described by <cite class="ltx_cite ltx_citemacro_citet">Ponomareva et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib39" title="">2023</a>)</cite>, it is an open theoretical question as to how random shuffling and Poisson sampling differ with respect to privacy amplification gains, with known privacy guarantees being weaker for the former.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Private neural machine translation</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The task of private neural machine translation remains largely unexplored, with currently no studies we could find that incorporate DP-SGD to an NMT system.
<cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib48" title="">2021</a>)</cite> investigate NMT in a federated learning setup <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib34" title="">2017</a>)</cite>, with differential privacy included in the aggregation of parameters from each local model, adding Laplace noise to these parameters.
Several other studies explore NMT with federated learning, but do not incorporate differential privacy in the methodology <cite class="ltx_cite ltx_citemacro_citep">(Roosta et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib42" title="">2021</a>; Passban et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib37" title="">2022</a>; Du et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib11" title="">2022</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Hisamoto et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib20" title="">2020</a>)</cite>, applied a membership inference attack <cite class="ltx_cite ltx_citemacro_citep">(Shokri et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib45" title="">2017</a>)</cite> on a 6-layer Transformer <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib47" title="">2017</a>)</cite> model in the scenario of NMT as a service, with the goal of clients being able to verify whether their data was used to train an NMT model.
Finally, <cite class="ltx_cite ltx_citemacro_citet">Kamocki and O’Regan (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib26" title="">2016</a>)</cite> address the general topic of privacy issues for machine translation as a service.
The authors examine how these MT services fit European data protection laws, noting the legal nature of various types of data processing that can occur by both the provider of such a service, as well as by the users themselves.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Description of software</h2>
<figure class="ltx_figure" id="S4.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S4.F1.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Framework Pipeline. Similar components are represented with different colors. Green: Dataset selection. Blue: Experimental configurations (including privacy settings). Grey: Dataset preparation. Orange: Model-specific elements. Red: Model training. Purple: Model inference. Yellow: Output of experiments.</figcaption>
</figure>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">The aim of our system is to offer a reliable and scalable approach to achieve differentially private machine translation. Figure <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S4.F1" title="Figure 1 ‣ 4 Description of software ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates the central structure of our system.
The user can upload a translation dataset that is either accessible on the HuggingFace Datasets Hub<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets" title="">https://huggingface.co/datasets</a></span></span></span> or is provided by us out of the box, and integrate it seamlessly for both training and efficient privacy accounting, utilizing HuggingFace’s Datasets library <cite class="ltx_cite ltx_citemacro_cite">Lhoest et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib30" title="">2021</a>)</cite>.</p>
</div>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Accelerated DP-SGD with JAX and Flax</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p1.1">Our goal is to accelerate DP-SGD training through the use of a Transformer model implemented with JAX and Flax <cite class="ltx_cite ltx_citemacro_cite">Bradbury et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib8" title="">2018</a>); Heek et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib19" title="">2023</a>)</cite>. The speed of training DP-SGD in the framework can be considerably enhanced through vectorization, just-in-time (JIT) compilation, and static graph optimization <cite class="ltx_cite ltx_citemacro_cite">Subramani et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib46" title="">2021</a>)</cite>. JIT compilation and automatic differentiation are defined and established on the XLA compiler. JAX’s main transformation methods of interest for fast DP-SGD are <span class="ltx_text ltx_font_typewriter" id="S4.SS0.SSS0.Px1.p1.1.1">grad</span>, <span class="ltx_text ltx_font_typewriter" id="S4.SS0.SSS0.Px1.p1.1.2">vmap</span>, and <span class="ltx_text ltx_font_typewriter" id="S4.SS0.SSS0.Px1.p1.1.3">pmap</span>, offering the ability to mix these operations as needed <cite class="ltx_cite ltx_citemacro_cite">Yin and Habernal (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib55" title="">2022</a>)</cite>. In the DP-SGD scenario, combining <span class="ltx_text ltx_font_typewriter" id="S4.SS0.SSS0.Px1.p1.1.4">grad</span> and <span class="ltx_text ltx_font_typewriter" id="S4.SS0.SSS0.Px1.p1.1.5">vmap</span> facilitates efficient computation of per-example gradients by vectorizing the gradient calculation along the batch dimension <cite class="ltx_cite ltx_citemacro_cite">Anil et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib3" title="">2022</a>)</cite>. Additionally, our training step is decorated by <span class="ltx_text ltx_font_typewriter" id="S4.SS0.SSS0.Px1.p1.1.6">pmap</span> to leverage the XLA compiler on multiple GPUs, significantly accelerating training speed. The framework offers to conduct experiments with multiple encoder-decoder models and integrate new seq2seq models, in addition to existing ones, such as mBART <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib32" title="">2020</a>)</cite>, T5 <cite class="ltx_cite ltx_citemacro_cite">Raffel et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib40" title="">2020</a>)</cite>, and mT5 <cite class="ltx_cite ltx_citemacro_cite">Xue et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib54" title="">2021</a>)</cite>. When selecting a model, the corresponding preprocessor will prepare the dataset accordingly. This allows the software to be flexible and modular, enabling researchers to exchange models and datasets to perform a range of private NMT experiments.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Model training and inference</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.1">The experimental workflow of our framework works in two phases, namely model training and model inference. For both phases, the process begins with a data loader that can be either a framework-provided dataset or a user-specified dataset.
Subsequently, the loaded dataset is prepared based on user-defined parameters, including standard options (e.g. sequence length), as well as parameters relating to DP-SGD (e.g. data loader type, sampling method, and batch size).
After selecting the model, the user separates it into different procedures according to the model type. Subsequently, the model is initiated, optionally from a checkpoint that has already been trained. Then, the primary experiment is carried out based on the specified mode, which includes (1) fine-tuning on an existing dataset, (2) using an existing fine-tuned checkpoint to continue fine-tuning on the dataset, or (3) inference without teacher forcing.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Integrating <span class="ltx_text ltx_font_typewriter" id="S4.SS0.SSS0.Px3.1.1">DPDataloader</span> from Opacus</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px3.p1.1">One notable improvement in our software is the incorporation of the <span class="ltx_text ltx_font_typewriter" id="S4.SS0.SSS0.Px3.p1.1.1">DPDataloader</span> from Opacus <cite class="ltx_cite ltx_citemacro_cite">Yousefpour et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib56" title="">2021</a>)</cite> for out-of-the-box Poisson sampling.
This is different from the existing approaches in JAX used by <cite class="ltx_cite ltx_citemacro_citet">Yin and Habernal (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib55" title="">2022</a>); Subramani et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib46" title="">2021</a>); Ponomareva et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib38" title="">2022</a>)</cite>, who employ iteration over a randomly shuffled dataset, which theoretically provides weaker DP bounds. Evaluation metrics such as BLEU <cite class="ltx_cite ltx_citemacro_cite">Papineni et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib36" title="">2002</a>)</cite> and BERTScore <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib58" title="">2020</a>)</cite> are available for each mode.
We incorporate the differential privacy component during the training phase of the systems.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Engineering challenges for LLMs</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px4.p1.1">Throughout development, we encountered multiple engineering challenges. Initially, our academic budget limitations made it difficult to train a larger model due to the significant memory consumption during per-example gradient calculations. Consequently, we anticipated a relatively small physical batch size on each GPU. We attempted to freeze parts of the model for faster training and improved memory efficiency, as <cite class="ltx_cite ltx_citemacro_citet">Senge et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib43" title="">2022</a>)</cite> noted. However, in Flax, the freezing mechanism only occurs during the optimization step and does not affect per-example gradient computation. Therefore, it does not solve the issue of limited physical batch sizes. Multiple reports suggest that increasing the lot size leads to better DP-SGD performance due to an improved gradient signal-to-noise ratio and an increased likelihood of non-duplicated example sampling across the entire dataset <cite class="ltx_cite ltx_citemacro_cite">Hoory et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib21" title="">2021</a>); Yin and Habernal (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib55" title="">2022</a>); Anil et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib3" title="">2022</a>)</cite>.
However, compared to previous work on large models that mostly relied on dataset iteration <cite class="ltx_cite ltx_citemacro_citep">(Yin and Habernal, <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib55" title="">2022</a>; Ponomareva et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib38" title="">2022</a>)</cite>, implementing the original DP-SGD with large lots using Poisson sampling, a large language model (LLM) with millions of parameters, and on multiple GPUs presents a challenge that makes comparison difficult.
To address this issue, we first conduct a sampling process on a large dataset, then divide it into smaller subsets that the GPU can handle.
We then build up the large lot using gradient accumulation.
It is crucial that we refrain from implementing any additional normalization operations that might change the gradient sensitivity <cite class="ltx_cite ltx_citemacro_cite">Ponomareva et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib39" title="">2023</a>); Hoory et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib21" title="">2021</a>)</cite>, prior to the noise addition step.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">To demonstrate our framework in use, fill the gaps on current knowledge of the privacy/utility trade-off for the task of NMT, as well as examine the effects of using random shuffling vs. Poisson sampling, we run a series of experiments with DP-SGD on several NMT datasets, using a variety of privacy budgets.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Datasets</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">We utilize datasets comprising two main types of settings.
The first is the general NMT setting for comparing our models with previous work and investigating the effectiveness of DP-SGD on a common NMT dataset.
For this we utilize WMT-16 <cite class="ltx_cite ltx_citemacro_citep">(Bojar et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib7" title="">2016</a>)</cite>, using the German-English (DE-EN) language pair as the focus of our experiments.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.3">The second setting is the more specific target domain of private texts that we are aiming to protect with differentially private NMT.
For the sake of reproducibility and ethical considerations, we utilize datasets that <span class="ltx_text ltx_font_italic" id="S5.SS1.p2.3.1">imitate</span> the actual private setting of processing sensitive information, namely business communications and medical notes, but are themselves publicly available.
The first dataset is the Business Scene Dialogue corpus (BSD) <cite class="ltx_cite ltx_citemacro_citep">(Rikters et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib41" title="">2019</a>)</cite>, which is a collection of fictional business conversations in various scenarios (e.g. “face-to-face”, “phone call”, “meeting”), with parallel data for Japanese and English.
While the original corpus consists of half English <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.p2.1.m1.1"><semantics id="S5.SS1.p2.1.m1.1a"><mo id="S5.SS1.p2.1.m1.1.1" stretchy="false" xref="S5.SS1.p2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><ci id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.1.m1.1d">→</annotation></semantics></math> Japanese and half Japanese <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.p2.2.m2.1"><semantics id="S5.SS1.p2.2.m2.1a"><mo id="S5.SS1.p2.2.m2.1.1" stretchy="false" xref="S5.SS1.p2.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.1b"><ci id="S5.SS1.p2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.2.m2.1d">→</annotation></semantics></math> English scenarios, we combine both into a single Japanese <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.p2.3.m3.1"><semantics id="S5.SS1.p2.3.m3.1a"><mo id="S5.SS1.p2.3.m3.1.1" stretchy="false" xref="S5.SS1.p2.3.m3.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.3.m3.1b"><ci id="S5.SS1.p2.3.m3.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.3.m3.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.3.m3.1d">→</annotation></semantics></math> English (JA-EN) language pair for our experiments.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">The second dataset is ClinSPEn-CC <cite class="ltx_cite ltx_citemacro_citep">(Neves et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib35" title="">2022</a>)</cite>, which is a collection of parallel COVID-19 clinical cases in English and Spanish, originally part of the biomedical translation task of WMT-22. We utilize this corpus in the Spanish <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.p3.1.m1.1"><semantics id="S5.SS1.p3.1.m1.1a"><mo id="S5.SS1.p3.1.m1.1.1" stretchy="false" xref="S5.SS1.p3.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.m1.1b"><ci id="S5.SS1.p3.1.m1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p3.1.m1.1d">→</annotation></semantics></math> English (ES-EN) direction.
These latter two datasets simulate a realistic scenario where a company or public authority may train an NMT model on private data, for later public use.
We present overall statistics for each dataset in Table <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S5.T1" title="Table 1 ‣ 5.1 Datasets ‣ 5 Experiments ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T1.1" style="width:216.8pt;height:62.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-15.9pt,4.6pt) scale(0.871888822249393,0.871888822249393) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T1.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T1.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S5.T1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.1.1.1">Dataset</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S5.T1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.1.2.1">Lang. Pair</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S5.T1.1.1.1.1.3"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S5.T1.1.1.1.1.3.1">#<span class="ltx_text ltx_font_serif" id="S5.T1.1.1.1.1.3.1.1"> Trn.+Vld.</span></span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S5.T1.1.1.1.1.4"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S5.T1.1.1.1.1.4.1">#<span class="ltx_text ltx_font_serif" id="S5.T1.1.1.1.1.4.1.1"> Test</span></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T1.1.1.2.1.1">WMT-16</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T1.1.1.2.1.2">DE-EN</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T1.1.1.2.1.3">4,551,054</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T1.1.1.2.1.4">2,999</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T1.1.1.3.2.1">BSD</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T1.1.1.3.2.2">JA-EN</th>
<td class="ltx_td ltx_align_right" id="S5.T1.1.1.3.2.3">22,051</td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.1.3.2.4">2,120</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T1.1.1.4.3.1">ClinSPEn-CC</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T1.1.1.4.3.2">ES-EN</th>
<td class="ltx_td ltx_align_right" id="S5.T1.1.1.4.3.3">1,065</td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.1.4.3.4">2,870</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Dataset statistics. Trn.: Train, Vld.: Validation.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Experimental setup</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.7">For each of the above three datasets, we fine-tune a pre-trained mT5 model <cite class="ltx_cite ltx_citemacro_citep">(Xue et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib54" title="">2021</a>)</cite>, opting for the <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.7.1">mT5-small<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote5.1.1.1">5</span></span><a class="ltx_ref ltx_url" href="https://huggingface.co/google/mt5-small" title="">https://huggingface.co/google/mt5-small</a></span></span></span></span> version due to computational capacity limitations described in Section <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S4" title="4 Description of software ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>.
We compare <math alttext="\varepsilon" class="ltx_Math" display="inline" id="S5.SS2.p1.1.m1.1"><semantics id="S5.SS2.p1.1.m1.1a"><mi id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><ci id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">\varepsilon</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.1.m1.1d">italic_ε</annotation></semantics></math> values of <math alttext="\infty,1000,5," class="ltx_Math" display="inline" id="S5.SS2.p1.2.m2.4"><semantics id="S5.SS2.p1.2.m2.4a"><mrow id="S5.SS2.p1.2.m2.4.4.1"><mrow id="S5.SS2.p1.2.m2.4.4.1.1.2" xref="S5.SS2.p1.2.m2.4.4.1.1.1.cmml"><mi id="S5.SS2.p1.2.m2.1.1" mathvariant="normal" xref="S5.SS2.p1.2.m2.1.1.cmml">∞</mi><mo id="S5.SS2.p1.2.m2.4.4.1.1.2.1" xref="S5.SS2.p1.2.m2.4.4.1.1.1.cmml">,</mo><mn id="S5.SS2.p1.2.m2.2.2" xref="S5.SS2.p1.2.m2.2.2.cmml">1000</mn><mo id="S5.SS2.p1.2.m2.4.4.1.1.2.2" xref="S5.SS2.p1.2.m2.4.4.1.1.1.cmml">,</mo><mn id="S5.SS2.p1.2.m2.3.3" xref="S5.SS2.p1.2.m2.3.3.cmml">5</mn></mrow><mo id="S5.SS2.p1.2.m2.4.4.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.4b"><list id="S5.SS2.p1.2.m2.4.4.1.1.1.cmml" xref="S5.SS2.p1.2.m2.4.4.1.1.2"><infinity id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1"></infinity><cn id="S5.SS2.p1.2.m2.2.2.cmml" type="integer" xref="S5.SS2.p1.2.m2.2.2">1000</cn><cn id="S5.SS2.p1.2.m2.3.3.cmml" type="integer" xref="S5.SS2.p1.2.m2.3.3">5</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.4c">\infty,1000,5,</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.2.m2.4d">∞ , 1000 , 5 ,</annotation></semantics></math> and <math alttext="1" class="ltx_Math" display="inline" id="S5.SS2.p1.3.m3.1"><semantics id="S5.SS2.p1.3.m3.1a"><mn id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><cn id="S5.SS2.p1.3.m3.1.1.cmml" type="integer" xref="S5.SS2.p1.3.m3.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">1</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.3.m3.1d">1</annotation></semantics></math>, representing the non-private, weakly private, moderately private, and very private scenarios, respectively (see <cite class="ltx_cite ltx_citemacro_citet">Lee and Clifton (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib29" title="">2011</a>); Hsu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib22" title="">2014</a>); Weiss et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib51" title="">2023</a>)</cite> for a more detailed discussion on selecting the ‘right’ <math alttext="\varepsilon" class="ltx_Math" display="inline" id="S5.SS2.p1.4.m4.1"><semantics id="S5.SS2.p1.4.m4.1a"><mi id="S5.SS2.p1.4.m4.1.1" xref="S5.SS2.p1.4.m4.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.4.m4.1b"><ci id="S5.SS2.p1.4.m4.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.4.m4.1c">\varepsilon</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.4.m4.1d">italic_ε</annotation></semantics></math> value).
We fix the value of <math alttext="\delta" class="ltx_Math" display="inline" id="S5.SS2.p1.5.m5.1"><semantics id="S5.SS2.p1.5.m5.1a"><mi id="S5.SS2.p1.5.m5.1.1" xref="S5.SS2.p1.5.m5.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.5.m5.1b"><ci id="S5.SS2.p1.5.m5.1.1.cmml" xref="S5.SS2.p1.5.m5.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.5.m5.1c">\delta</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.5.m5.1d">italic_δ</annotation></semantics></math> to <math alttext="10^{-8}" class="ltx_Math" display="inline" id="S5.SS2.p1.6.m6.1"><semantics id="S5.SS2.p1.6.m6.1a"><msup id="S5.SS2.p1.6.m6.1.1" xref="S5.SS2.p1.6.m6.1.1.cmml"><mn id="S5.SS2.p1.6.m6.1.1.2" xref="S5.SS2.p1.6.m6.1.1.2.cmml">10</mn><mrow id="S5.SS2.p1.6.m6.1.1.3" xref="S5.SS2.p1.6.m6.1.1.3.cmml"><mo id="S5.SS2.p1.6.m6.1.1.3a" xref="S5.SS2.p1.6.m6.1.1.3.cmml">−</mo><mn id="S5.SS2.p1.6.m6.1.1.3.2" xref="S5.SS2.p1.6.m6.1.1.3.2.cmml">8</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.6.m6.1b"><apply id="S5.SS2.p1.6.m6.1.1.cmml" xref="S5.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.6.m6.1.1.1.cmml" xref="S5.SS2.p1.6.m6.1.1">superscript</csymbol><cn id="S5.SS2.p1.6.m6.1.1.2.cmml" type="integer" xref="S5.SS2.p1.6.m6.1.1.2">10</cn><apply id="S5.SS2.p1.6.m6.1.1.3.cmml" xref="S5.SS2.p1.6.m6.1.1.3"><minus id="S5.SS2.p1.6.m6.1.1.3.1.cmml" xref="S5.SS2.p1.6.m6.1.1.3"></minus><cn id="S5.SS2.p1.6.m6.1.1.3.2.cmml" type="integer" xref="S5.SS2.p1.6.m6.1.1.3.2">8</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.6.m6.1c">10^{-8}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.6.m6.1d">10 start_POSTSUPERSCRIPT - 8 end_POSTSUPERSCRIPT</annotation></semantics></math> for all experiments, staying well below the recommended <math alttext="\delta\ll\frac{1}{N}" class="ltx_Math" display="inline" id="S5.SS2.p1.7.m7.1"><semantics id="S5.SS2.p1.7.m7.1a"><mrow id="S5.SS2.p1.7.m7.1.1" xref="S5.SS2.p1.7.m7.1.1.cmml"><mi id="S5.SS2.p1.7.m7.1.1.2" xref="S5.SS2.p1.7.m7.1.1.2.cmml">δ</mi><mo id="S5.SS2.p1.7.m7.1.1.1" xref="S5.SS2.p1.7.m7.1.1.1.cmml">≪</mo><mfrac id="S5.SS2.p1.7.m7.1.1.3" xref="S5.SS2.p1.7.m7.1.1.3.cmml"><mn id="S5.SS2.p1.7.m7.1.1.3.2" xref="S5.SS2.p1.7.m7.1.1.3.2.cmml">1</mn><mi id="S5.SS2.p1.7.m7.1.1.3.3" xref="S5.SS2.p1.7.m7.1.1.3.3.cmml">N</mi></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.7.m7.1b"><apply id="S5.SS2.p1.7.m7.1.1.cmml" xref="S5.SS2.p1.7.m7.1.1"><csymbol cd="latexml" id="S5.SS2.p1.7.m7.1.1.1.cmml" xref="S5.SS2.p1.7.m7.1.1.1">much-less-than</csymbol><ci id="S5.SS2.p1.7.m7.1.1.2.cmml" xref="S5.SS2.p1.7.m7.1.1.2">𝛿</ci><apply id="S5.SS2.p1.7.m7.1.1.3.cmml" xref="S5.SS2.p1.7.m7.1.1.3"><divide id="S5.SS2.p1.7.m7.1.1.3.1.cmml" xref="S5.SS2.p1.7.m7.1.1.3"></divide><cn id="S5.SS2.p1.7.m7.1.1.3.2.cmml" type="integer" xref="S5.SS2.p1.7.m7.1.1.3.2">1</cn><ci id="S5.SS2.p1.7.m7.1.1.3.3.cmml" xref="S5.SS2.p1.7.m7.1.1.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.7.m7.1c">\delta\ll\frac{1}{N}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.7.m7.1d">italic_δ ≪ divide start_ARG 1 end_ARG start_ARG italic_N end_ARG</annotation></semantics></math> condition <cite class="ltx_cite ltx_citemacro_citep">(Abadi et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib2" title="">2016b</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">For all of the above configurations, we compare two methods of selecting batches of data points from the dataset for our DP-SGD configurations, namely <span class="ltx_text ltx_font_bold" id="S5.SS2.p2.1.1">random shuffling</span> and <span class="ltx_text ltx_font_bold" id="S5.SS2.p2.1.2">Poisson sampling</span>.
Following previous work <cite class="ltx_cite ltx_citemacro_citep">(Hoory et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib21" title="">2021</a>; Anil et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib3" title="">2022</a>; Yin and Habernal, <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib55" title="">2022</a>)</cite>, we utilize very large batch sizes for both of these methods, setting <math alttext="L" class="ltx_Math" display="inline" id="S5.SS2.p2.1.m1.1"><semantics id="S5.SS2.p2.1.m1.1a"><mi id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><ci id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">L</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.1.m1.1d">italic_L</annotation></semantics></math> to a large value and building up the resulting drawn batches with gradient accumulation for the latter method, as described in Section <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S4" title="4 Description of software ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>.
We refer to Appendix <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#A2" title="Appendix B Hyperparameters ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_tag">B</span></a> for a more detailed description of our hyperparameter search.
We evaluate our model outputs using BLEU <cite class="ltx_cite ltx_citemacro_citep">(Papineni et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib36" title="">2002</a>)</cite>, and BERTScore <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib58" title="">2020</a>)</cite> metrics.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Results and Discussion</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S5.F2" title="Figure 2 ‣ 5.3 Results and Discussion ‣ 5 Experiments ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a> shows the results of our experiments, reporting BLEU scores on the test partition of each dataset.</p>
</div>
<figure class="ltx_figure" id="S5.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S5.F2.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Test BLEU scores for each of the three datasets using varying privacy budgets, comparing the random shuffling and Poisson sampling methods to iterate over the dataset. Non-private results are additionally shown for each dataset (<math alttext="\varepsilon=\infty" class="ltx_Math" display="inline" id="S5.F2.3.m1.1"><semantics id="S5.F2.3.m1.1b"><mrow id="S5.F2.3.m1.1.1" xref="S5.F2.3.m1.1.1.cmml"><mi id="S5.F2.3.m1.1.1.2" xref="S5.F2.3.m1.1.1.2.cmml">ε</mi><mo id="S5.F2.3.m1.1.1.1" xref="S5.F2.3.m1.1.1.1.cmml">=</mo><mi id="S5.F2.3.m1.1.1.3" mathvariant="normal" xref="S5.F2.3.m1.1.1.3.cmml">∞</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.F2.3.m1.1c"><apply id="S5.F2.3.m1.1.1.cmml" xref="S5.F2.3.m1.1.1"><eq id="S5.F2.3.m1.1.1.1.cmml" xref="S5.F2.3.m1.1.1.1"></eq><ci id="S5.F2.3.m1.1.1.2.cmml" xref="S5.F2.3.m1.1.1.2">𝜀</ci><infinity id="S5.F2.3.m1.1.1.3.cmml" xref="S5.F2.3.m1.1.1.3"></infinity></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F2.3.m1.1d">\varepsilon=\infty</annotation><annotation encoding="application/x-llamapun" id="S5.F2.3.m1.1e">italic_ε = ∞</annotation></semantics></math>) with random shuffling. Lower <math alttext="\varepsilon" class="ltx_Math" display="inline" id="S5.F2.4.m2.1"><semantics id="S5.F2.4.m2.1b"><mi id="S5.F2.4.m2.1.1" xref="S5.F2.4.m2.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S5.F2.4.m2.1c"><ci id="S5.F2.4.m2.1.1.cmml" xref="S5.F2.4.m2.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F2.4.m2.1d">\varepsilon</annotation><annotation encoding="application/x-llamapun" id="S5.F2.4.m2.1e">italic_ε</annotation></semantics></math> corresponds to a stronger privacy guarantee.</figcaption>
</figure>
<section class="ltx_paragraph" id="S5.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Privacy/utility trade-off</h4>
<div class="ltx_para" id="S5.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS3.SSS0.Px1.p1.1">We verify the soundness of our models in the non-private setting (<math alttext="\varepsilon=\infty" class="ltx_Math" display="inline" id="S5.SS3.SSS0.Px1.p1.1.m1.1"><semantics id="S5.SS3.SSS0.Px1.p1.1.m1.1a"><mrow id="S5.SS3.SSS0.Px1.p1.1.m1.1.1" xref="S5.SS3.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S5.SS3.SSS0.Px1.p1.1.m1.1.1.2" xref="S5.SS3.SSS0.Px1.p1.1.m1.1.1.2.cmml">ε</mi><mo id="S5.SS3.SSS0.Px1.p1.1.m1.1.1.1" xref="S5.SS3.SSS0.Px1.p1.1.m1.1.1.1.cmml">=</mo><mi id="S5.SS3.SSS0.Px1.p1.1.m1.1.1.3" mathvariant="normal" xref="S5.SS3.SSS0.Px1.p1.1.m1.1.1.3.cmml">∞</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS0.Px1.p1.1.m1.1b"><apply id="S5.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS3.SSS0.Px1.p1.1.m1.1.1"><eq id="S5.SS3.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S5.SS3.SSS0.Px1.p1.1.m1.1.1.1"></eq><ci id="S5.SS3.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S5.SS3.SSS0.Px1.p1.1.m1.1.1.2">𝜀</ci><infinity id="S5.SS3.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S5.SS3.SSS0.Px1.p1.1.m1.1.1.3"></infinity></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS0.Px1.p1.1.m1.1c">\varepsilon=\infty</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS0.Px1.p1.1.m1.1d">italic_ε = ∞</annotation></semantics></math>) by comparing with past non-private results, particularly for the commonly used WMT-16 dataset.
For WMT-16 DE-EN, we reach a BLEU score of 36.2, being similar to past models (e.g. <cite class="ltx_cite ltx_citemacro_citet">Wei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib50" title="">2021</a>)</cite> obtain a BLEU score of 38.6 using their 137B parameter FLAN model).
In the case of BSD and ClinSPEn-CC, these datasets are not as ‘standard’ within the NMT community, and therefore have a more limited chance for comparison.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS0.Px1.p2">
<p class="ltx_p" id="S5.SS3.SSS0.Px1.p2.1">For private results, we can see a clear difference between the drop in WMT-16 performance vs. that of BSD and ClinSPEn-CC.
This is not at all surprising, given that the latter two datasets are vastly smaller in comparison to WMT-16, making it far more difficult to train an NMT model, particularly in the noisy setting of DP-SGD.
In addition, ClinSPEn-CC contains a large amount of complicated medical terminology that adds an extra layer of difficulty for a model.
We therefore need to conduct further investigations into applications of DP-SGD to very small datasets in order to reach more meaningful <math alttext="\varepsilon" class="ltx_Math" display="inline" id="S5.SS3.SSS0.Px1.p2.1.m1.1"><semantics id="S5.SS3.SSS0.Px1.p2.1.m1.1a"><mi id="S5.SS3.SSS0.Px1.p2.1.m1.1.1" xref="S5.SS3.SSS0.Px1.p2.1.m1.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS0.Px1.p2.1.m1.1b"><ci id="S5.SS3.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S5.SS3.SSS0.Px1.p2.1.m1.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS0.Px1.p2.1.m1.1c">\varepsilon</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS0.Px1.p2.1.m1.1d">italic_ε</annotation></semantics></math> values.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Method of dataset iteration</h4>
<div class="ltx_para" id="S5.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS3.SSS0.Px2.p1.2">When comparing random shuffling with Poisson sampling, we can see practically no difference for BSD and ClinSPEn-CC, most likely due to the low DP-SGD results for these two datasets.
The differences are more notable for WMT-16, where there is a clear gap between the two sets of configurations.
For instance, at <math alttext="\varepsilon=1" class="ltx_Math" display="inline" id="S5.SS3.SSS0.Px2.p1.1.m1.1"><semantics id="S5.SS3.SSS0.Px2.p1.1.m1.1a"><mrow id="S5.SS3.SSS0.Px2.p1.1.m1.1.1" xref="S5.SS3.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S5.SS3.SSS0.Px2.p1.1.m1.1.1.2" xref="S5.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml">ε</mi><mo id="S5.SS3.SSS0.Px2.p1.1.m1.1.1.1" xref="S5.SS3.SSS0.Px2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS3.SSS0.Px2.p1.1.m1.1.1.3" xref="S5.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS0.Px2.p1.1.m1.1b"><apply id="S5.SS3.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S5.SS3.SSS0.Px2.p1.1.m1.1.1"><eq id="S5.SS3.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S5.SS3.SSS0.Px2.p1.1.m1.1.1.1"></eq><ci id="S5.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S5.SS3.SSS0.Px2.p1.1.m1.1.1.2">𝜀</ci><cn id="S5.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.SS3.SSS0.Px2.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS0.Px2.p1.1.m1.1c">\varepsilon=1</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS0.Px2.p1.1.m1.1d">italic_ε = 1</annotation></semantics></math>, WMT-16 shows a BLEU score of 19.83 when using random shuffling, in contrast to 2.35 with Poisson sampling.
The latter method therefore shows a far greater drop from the non-private setting, improving more gradually as <math alttext="\varepsilon" class="ltx_Math" display="inline" id="S5.SS3.SSS0.Px2.p1.2.m2.1"><semantics id="S5.SS3.SSS0.Px2.p1.2.m2.1a"><mi id="S5.SS3.SSS0.Px2.p1.2.m2.1.1" xref="S5.SS3.SSS0.Px2.p1.2.m2.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS0.Px2.p1.2.m2.1b"><ci id="S5.SS3.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S5.SS3.SSS0.Px2.p1.2.m2.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS0.Px2.p1.2.m2.1c">\varepsilon</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS0.Px2.p1.2.m2.1d">italic_ε</annotation></semantics></math> is increased.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS0.Px2.p2">
<p class="ltx_p" id="S5.SS3.SSS0.Px2.p2.1">There are several possible explanations for this.
With Poisson sampling, while each data point has an equal probability of being drawn to make up a particular batch, it is possible that some data points end up being drawn more frequently than others for several training iterations.
This may have an impact on the model learning process, possibly missing out on the signal from certain useful data points at various stages of training.
Another reason may be that we simply require additional hyperparameter optimization with Poisson sampling, expanding the search space further.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">We have introduced <span class="ltx_text ltx_font_typewriter" id="S6.p1.1.1">DP-NMT</span>, a modular framework developed using the JAX library, with the goal of leading research on neural machine translation with DP-SGD.
To demonstrate our framework in use, we have presented several experiments on both general and privacy-related NMT datasets, comparing two separate approaches for iterating over training data with DP-SGD, and facilitating in filling the research gap on the privacy/utility trade-off in this task.
We are continuing to actively expand the framework, including the integration of new models and NMT datasets.
We hope that our framework will help to expand research into privacy-preserving NMT and welcome feedback from the community.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Ethics and Limitations</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">An important ethical consideration with regards to our framework is its intended use.
We strive to further the field of private NMT and improve the current knowledge on how to effectively apply differential privacy to data used in NMT systems.
However, applications of differential privacy to textual data are still at an early research stage, and <span class="ltx_text ltx_font_bold" id="Sx1.p1.1.1">should not currently be used in actual services that handle real sensitive data of individuals.</span></p>
</div>
<div class="ltx_para" id="Sx1.p2">
<p class="ltx_p" id="Sx1.p2.1">The primary reason for this is that our understanding of what is <span class="ltx_text ltx_font_italic" id="Sx1.p2.1.1">private information</span> in textual data is still very limited.
Applications of differential privacy in the machine learning setting provide a privacy guarantee to each individual <span class="ltx_text ltx_font_italic" id="Sx1.p2.1.2">data point</span>.
In the context of DP-SGD, this means that if any single data point is removed from the dataset, the impact on the resulting model parameter update is bounded by the provided multiplicative guarantee in Eqn. <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#A1.E1" title="In Differential Privacy ‣ Appendix A Background on Differential Privacy and DP-SGD ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>.
In other words, it does not stand out ‘too much’ in its contribution to training the model.</p>
</div>
<div class="ltx_para" id="Sx1.p3">
<p class="ltx_p" id="Sx1.p3.1">For textual data, a single data point will often be a sentence or document.
However, this does not mean that there is a one-to-one mapping from <span class="ltx_text ltx_font_italic" id="Sx1.p3.1.1">individuals</span> to sentences and documents.
For instance, multiple documents could potentially refer to the same individual, or contain the same piece of sensitive information that would break the assumption of each data point being independent and identically distributed (i.i.d.) in the DP setting.
Thus, we require further research on how to properly apply a privacy guarantee to individuals represented within a textual dataset.
We refer to <cite class="ltx_cite ltx_citemacro_citet">Klymenko et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib28" title="">2022</a>); Brown et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib9" title="">2022</a>); Igamberdiev and Habernal (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib25" title="">2023</a>)</cite> for a more comprehensive discussion on this.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">This project was supported by the PrivaLingo research grant (Hessisches Ministerium des Innern und für Sport).
The independent research group TrustHLT is supported by the Hessian Ministry of Higher Education, Research, Science and the Arts.
Thanks to Luke Bates for helpful feedback on a preliminary draft.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abadi et al. (2016a)</span>
<span class="ltx_bibblock">
Martin Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, Manjunath Kudlur, Josh Levenberg, Rajat Monga, Sherry Moore, Derek G. Murray, Benoit Steiner, Paul Tucker, Vijay Vasudevan, Pete Warden, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. 2016a.

</span>
<span class="ltx_bibblock">Tensorflow: A system for large-scale machine learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation</em>, OSDI’16, page 265–283, USA. USENIX Association.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abadi et al. (2016b)</span>
<span class="ltx_bibblock">
Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. 2016b.

</span>
<span class="ltx_bibblock">Deep learning with differential privacy.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 2016 ACM SIGSAC conference on computer and communications security</em>, pages 308–318.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anil et al. (2022)</span>
<span class="ltx_bibblock">
Rohan Anil, Badih Ghazi, Vineet Gupta, Ravi Kumar, and Pasin Manurangsi. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.findings-emnlp.484" title="">Large-scale differentially private BERT</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Findings of the Association for Computational Linguistics: EMNLP 2022</em>, pages 6481–6491, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Balle et al. (2018)</span>
<span class="ltx_bibblock">
Borja Balle, Gilles Barthe, and Marco Gaboardi. 2018.

</span>
<span class="ltx_bibblock">Privacy amplification by subsampling: Tight analyses via couplings and divergences.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Advances in neural information processing systems</em>, 31.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Basu et al. (2021)</span>
<span class="ltx_bibblock">
Priyam Basu, Tiasa Singha Roy, Rakshit Naidu, and Zumrut Muftuoglu. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.econlp-1.7" title="">Privacy enabled financial text classification using differential privacy and federated learning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the Third Workshop on Economics and Natural Language Processing</em>, pages 50–55, Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beimel et al. (2014)</span>
<span class="ltx_bibblock">
Amos Beimel, Hai Brenner, Shiva Prasad Kasiviswanathan, and Kobbi Nissim. 2014.

</span>
<span class="ltx_bibblock">Bounds on the sample complexity for private learning and private data release.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Machine learning</em>, 94:401–437.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bojar et al. (2016)</span>
<span class="ltx_bibblock">
Ondrej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, Antonio Jimeno Yepes, Philipp Koehn, Varvara Logacheva, Christof Monz, et al. 2016.

</span>
<span class="ltx_bibblock">Findings of the 2016 conference on machine translation (wmt16).

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">First conference on machine translation</em>, pages 131–198. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bradbury et al. (2018)</span>
<span class="ltx_bibblock">
James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin, George Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao Zhang. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://github.com/google/jax" title="">JAX: composable transformations of Python+NumPy programs</a>.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_typewriter" id="bib.bib8.1.1">http://github.com/google/jax</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2022)</span>
<span class="ltx_bibblock">
Hannah Brown, Katherine Lee, Fatemehsadat Mireshghallah, Reza Shokri, and Florian Tramèr. 2022.

</span>
<span class="ltx_bibblock">What does it mean for a language model to preserve privacy?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency</em>, pages 2280–2292.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini et al. (2021)</span>
<span class="ltx_bibblock">
Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar Erlingsson, et al. 2021.

</span>
<span class="ltx_bibblock">Extracting training data from large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">30th USENIX Security Symposium (USENIX Security 21)</em>, pages 2633–2650.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et al. (2022)</span>
<span class="ltx_bibblock">
Yichao Du, Zhirui Zhang, Bingzhe Wu, Lemao Liu, Tong Xu, and Enhong Chen. 2022.

</span>
<span class="ltx_bibblock">Federated nearest neighbor machine translation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">The Eleventh International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork and Roth (2013)</span>
<span class="ltx_bibblock">
Cynthia Dwork and Aaron Roth. 2013.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1561/0400000042" title="">The Algorithmic Foundations of Differential Privacy</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Foundations and Trends® in Theoretical Computer Science</em>, 9(3-4):211–407.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork et al. (2010)</span>
<span class="ltx_bibblock">
Cynthia Dwork, Guy N Rothblum, and Salil Vadhan. 2010.

</span>
<span class="ltx_bibblock">Boosting and differential privacy.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">2010 IEEE 51st Annual Symposium on Foundations of Computer Science</em>, pages 51–60. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Erlingsson et al. (2019)</span>
<span class="ltx_bibblock">
Úlfar Erlingsson, Vitaly Feldman, Ilya Mironov, Ananth Raghunathan, Kunal Talwar, and Abhradeep Thakurta. 2019.

</span>
<span class="ltx_bibblock">Amplification by shuffling: From local to central differential privacy via anonymity.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms</em>, pages 2468–2479. SIAM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feldman et al. (2022)</span>
<span class="ltx_bibblock">
Vitaly Feldman, Audra McMillan, and Kunal Talwar. 2022.

</span>
<span class="ltx_bibblock">Hiding among the clones: A simple and nearly optimal analysis of privacy amplification by shuffling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">2021 IEEE 62nd Annual Symposium on Foundations of Computer Science (FOCS)</em>, pages 954–964. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Habernal (2021)</span>
<span class="ltx_bibblock">
Ivan Habernal. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.emnlp-main.114" title="">When differential privacy meets NLP: The devil is in the detail</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pages 1522–1528, Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Habernal (2022)</span>
<span class="ltx_bibblock">
Ivan Habernal. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-short.87" title="">How reparametrization trick broke differentially-private text representation learning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, pages 771–777, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hansen et al. (2022)</span>
<span class="ltx_bibblock">
Victor Petrén Bach Hansen, Atula Tejaswi Neerkaje, Ramit Sawhney, Lucie Flek, and Anders Søgaard. 2022.

</span>
<span class="ltx_bibblock">The impact of differential privacy on group disparity mitigation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the Fourth Workshop on Privacy in Natural Language Processing</em>, pages 12–12.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heek et al. (2023)</span>
<span class="ltx_bibblock">
Jonathan Heek, Anselm Levskaya, Avital Oliver, Marvin Ritter, Bertrand Rondepierre, Andreas Steiner, and Marc van Zee. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://github.com/google/flax" title="">Flax: A neural network library and ecosystem for JAX</a>.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_typewriter" id="bib.bib19.1.1">http://github.com/google/flax</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hisamoto et al. (2020)</span>
<span class="ltx_bibblock">
Sorami Hisamoto, Matt Post, and Kevin Duh. 2020.

</span>
<span class="ltx_bibblock">Membership inference attacks on sequence-to-sequence models: Is my data in your machine translation system?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Transactions of the Association for Computational Linguistics</em>, 8:49–63.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoory et al. (2021)</span>
<span class="ltx_bibblock">
Shlomo Hoory, Amir Feder, Avichai Tendler, Sofia Erell, Alon Peled-Cohen, Itay Laish, Hootan Nakhost, Uri Stemmer, Ayelet Benjamini, Avinatan Hassidim, and Yossi Matias. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2021.findings-emnlp.102" title="">Learning and Evaluating a Differentially Private Pre-trained Language Model</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Findings of the Association for Computational Linguistics: EMNLP 2021</em>, pages 1178–1189, Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsu et al. (2014)</span>
<span class="ltx_bibblock">
Justin Hsu, Marco Gaboardi, Andreas Haeberlen, Sanjeev Khanna, Arjun Narayan, Benjamin C Pierce, and Aaron Roth. 2014.

</span>
<span class="ltx_bibblock">Differential privacy: An economic method for choosing epsilon.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">2014 IEEE 27th Computer Security Foundations Symposium</em>, pages 398–410. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2024)</span>
<span class="ltx_bibblock">
Lijie Hu, Ivan Habernal, Lei Shen, and Di Wang. 2024.

</span>
<span class="ltx_bibblock">Differentially Private Natural Language Models: Recent Advances and Future Directions.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics</em>, page (to appear), Malta. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Igamberdiev and Habernal (2022)</span>
<span class="ltx_bibblock">
Timour Igamberdiev and Ivan Habernal. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.lrec-1.36" title="">Privacy-Preserving Graph Convolutional Networks for Text Classification</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the Language Resources and Evaluation Conference</em>, pages 338–350, Marseille, France. European Language Resources Association.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Igamberdiev and Habernal (2023)</span>
<span class="ltx_bibblock">
Timour Igamberdiev and Ivan Habernal. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.findings-acl.874" title="">DP-BART for privatized text rewriting under local differential privacy</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Findings of the Association for Computational Linguistics: ACL 2023</em>, pages 13914–13934, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kamocki and O’Regan (2016)</span>
<span class="ltx_bibblock">
Paweł Kamocki and Jim O’Regan. 2016.

</span>
<span class="ltx_bibblock">Privacy issues in online machine translation services-european perspective.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC’16)</em>, pages 4458–4462.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kasiviswanathan et al. (2011)</span>
<span class="ltx_bibblock">
Shiva Prasad Kasiviswanathan, Homin K Lee, Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. 2011.

</span>
<span class="ltx_bibblock">What can we learn privately?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">SIAM Journal on Computing</em>, 40(3):793–826.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Klymenko et al. (2022)</span>
<span class="ltx_bibblock">
Oleksandra Klymenko, Stephen Meisenbacher, and Florian Matthes. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.privatenlp-1.1" title="">Differential privacy in natural language processing the story so far</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the Fourth Workshop on Privacy in Natural Language Processing</em>, pages 1–11, Seattle, United States. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee and Clifton (2011)</span>
<span class="ltx_bibblock">
Jaewoo Lee and Chris Clifton. 2011.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1007/978-3-642-24861-0_22" title="">How Much Is Enough? Choosing <math alttext="\epsilon" class="ltx_Math" display="inline" id="bib.bib29.1.1.m1.1"><semantics id="bib.bib29.1.1.m1.1a"><mi id="bib.bib29.1.1.m1.1.1" xref="bib.bib29.1.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="bib.bib29.1.1.m1.1b"><ci id="bib.bib29.1.1.m1.1.1.cmml" xref="bib.bib29.1.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib29.1.1.m1.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="bib.bib29.1.1.m1.1d">italic_ϵ</annotation></semantics></math> for Differential Privacy</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.2.1">Proceedings of the 14th Information Security Conference (ISC 2011)</em>, pages 325–340, Xi’an, China. Springer Berlin / Heidelberg.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lhoest et al. (2021)</span>
<span class="ltx_bibblock">
Quentin Lhoest, Albert Villanova del Moral, Yacine Jernite, Abhishek Thakur, Patrick von Platen, Suraj Patil, Julien Chaumond, Mariama Drame, Julien Plu, Lewis Tunstall, Joe Davison, Mario Šaško, Gunjan Chhablani, Bhavitvya Malik, Simon Brandeis, Teven Le Scao, Victor Sanh, Canwen Xu, Nicolas Patry, Angelina McMillan-Major, Philipp Schmid, Sylvain Gugger, Clément Delangue, Théo Matussière, Lysandre Debut, Stas Bekman, Pierric Cistac, Thibault Goehringer, Victor Mustar, François Lagunas, Alexander Rush, and Thomas Wolf. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2109.02846" title="">Datasets: A community library for natural language processing</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</em>, pages 175–184, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2022)</span>
<span class="ltx_bibblock">
Xuechen Li, Florian Tramer, Percy Liang, and Tatsunori Hashimoto. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=bVuP3ltATMz" title="">Large language models can be strong differentially private learners</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2020)</span>
<span class="ltx_bibblock">
Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, and Luke Zettlemoyer. 2020.

</span>
<span class="ltx_bibblock">Multilingual denoising pre-training for neural machine translation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Transactions of the Association for Computational Linguistics</em>, 8:726–742.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mattern et al. (2022)</span>
<span class="ltx_bibblock">
Justus Mattern, Zhijing Jin, Benjamin Weggenmann, Bernhard Schoelkopf, and Mrinmaya Sachan. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.emnlp-main.323" title="">Differentially private language models for secure data sharing</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</em>, pages 4860–4873, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. (2017)</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. 2017.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized data.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Artificial intelligence and statistics</em>, pages 1273–1282. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neves et al. (2022)</span>
<span class="ltx_bibblock">
Mariana Neves, Antonio Jimeno Yepes, Amy Siu, Roland Roller, Philippe Thomas, Maika Vicente Navarro, Lana Yeganova, Dina Wiemann, Giorgio Maria Di Nunzio, Federica Vezzani, et al. 2022.

</span>
<span class="ltx_bibblock">Findings of the wmt 2022 biomedical translation shared task: Monolingual clinical case reports.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">WMT22-Seventh Conference on Machine Translation</em>, pages 694–723.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al. (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3115/1073083.1073135" title="">Bleu: a method for automatic evaluation of machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</em>, pages 311–318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Passban et al. (2022)</span>
<span class="ltx_bibblock">
Peyman Passban, Tanya Roosta, Rahul Gupta, Ankit Chadha, and Clement Chung. 2022.

</span>
<span class="ltx_bibblock">Training mixed-domain translation models via federated learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 2576–2586.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ponomareva et al. (2022)</span>
<span class="ltx_bibblock">
Natalia Ponomareva, Jasmijn Bastings, and Sergei Vassilvitskii. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.findings-acl.171" title="">Training text-to-text transformers with privacy guarantees</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Findings of the Association for Computational Linguistics: ACL 2022</em>, pages 2182–2193, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ponomareva et al. (2023)</span>
<span class="ltx_bibblock">
Natalia Ponomareva, Hussein Hazimeh, Alex Kurakin, Zheng Xu, Carson Denison, H Brendan McMahan, Sergei Vassilvitskii, Steve Chien, and Abhradeep Guha Thakurta. 2023.

</span>
<span class="ltx_bibblock">How to dp-fy ml: A practical guide to machine learning with differential privacy.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Journal of Artificial Intelligence Research</em>, 77:1113–1201.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://jmlr.org/papers/v21/20-074.html" title="">Exploring the limits of transfer learning with a unified text-to-text transformer</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Journal of Machine Learning Research</em>, 21(140):1–67.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rikters et al. (2019)</span>
<span class="ltx_bibblock">
Matīss Rikters, Ryokan Ri, Tong Li, and Toshiaki Nakazawa. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D19-5204" title="">Designing the business conversation corpus</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Proceedings of the 6th Workshop on Asian Translation</em>, pages 54–61, Hong Kong, China. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roosta et al. (2021)</span>
<span class="ltx_bibblock">
Tanya Roosta, Peyman Passban, and Ankit Chadha. 2021.

</span>
<span class="ltx_bibblock">Communication-efficient federated learning for neural machine translation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">arXiv preprint arXiv:2112.06135</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Senge et al. (2022)</span>
<span class="ltx_bibblock">
Manuel Senge, Timour Igamberdiev, and Ivan Habernal. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.emnlp-main.496" title="">One size does not fit all: Investigating strategies for differentially-private learning across NLP tasks</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</em>, pages 7340–7353, Abu Dhabi, UAE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al. (2022)</span>
<span class="ltx_bibblock">
Weiyan Shi, Aiqi Cui, Evan Li, Ruoxi Jia, and Zhou Yu. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.naacl-main.205" title="">Selective differential privacy for language modeling</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 2848–2859, Seattle, United States. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shokri et al. (2017)</span>
<span class="ltx_bibblock">
Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. 2017.

</span>
<span class="ltx_bibblock">Membership inference attacks against machine learning models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">2017 IEEE symposium on security and privacy (SP)</em>, pages 3–18. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Subramani et al. (2021)</span>
<span class="ltx_bibblock">
Pranav Subramani, Nicholas Vadivelu, and Gautam Kamath. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2021/file/ddf9029977a61241841edeae15e9b53f-Paper.pdf" title="">Enabling Fast Differentially Private SGD via Just-in-Time Compilation and Vectorization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Advances in Neural Information Processing Systems</em>, volume 34, pages 26409–26421. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention Is All You Need.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Advances in Neural Information Processing Systems 30</em>, pages 5998–6008, Long Beach, CA, USA. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2021)</span>
<span class="ltx_bibblock">
Jianzong Wang, Zhangcheng Huang, Lingwei Kong, Denghao Li, and Jing Xiao. 2021.

</span>
<span class="ltx_bibblock">Modeling without sharing privacy: Federated neural machine translation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Web Information Systems Engineering–WISE 2021: 22nd International Conference on Web Information Systems Engineering, WISE 2021, Melbourne, VIC, Australia, October 26–29, 2021, Proceedings, Part I 22</em>, pages 216–223. Springer.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2019)</span>
<span class="ltx_bibblock">
Yu-Xiang Wang, Borja Balle, and Shiva Prasad Kasiviswanathan. 2019.

</span>
<span class="ltx_bibblock">Subsampled rényi differential privacy and analytical moments accountant.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">The 22nd International Conference on Artificial Intelligence and Statistics</em>, pages 1226–1235. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2021)</span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 2021.

</span>
<span class="ltx_bibblock">Finetuned language models are zero-shot learners.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weiss et al. (2023)</span>
<span class="ltx_bibblock">
Christopher Weiss, Frauke Kreuter, and Ivan Habernal. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2307.06708" title="">To share or not to share: What risks would laypeople accept to give sensitive data to differentially-private NLP systems?</a>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">arXiv preprint</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2022)</span>
<span class="ltx_bibblock">
Xinwei Wu, Li Gong, and Deyi Xiong. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.fl4nlp-1.3" title="">Adaptive differential privacy for language model training</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Proceedings of the First Workshop on Federated Learning for Natural Language Processing (FL4NLP 2022)</em>, pages 21–26, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2021)</span>
<span class="ltx_bibblock">
Chang Xu, Jun Wang, Francisco Guzmán, Benjamin Rubinstein, and Trevor Cohn. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.findings-emnlp.369" title="">Mitigating data poisoning in text classification with differential privacy</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">Findings of the Association for Computational Linguistics: EMNLP 2021</em>, pages 4348–4356, Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xue et al. (2021)</span>
<span class="ltx_bibblock">
Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.naacl-main.41" title="">mT5: A massively multilingual pre-trained text-to-text transformer</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 483–498, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin and Habernal (2022)</span>
<span class="ltx_bibblock">
Ying Yin and Ivan Habernal. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.nllp-1.14" title="">Privacy-preserving models for legal natural language processing</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">Proceedings of the Natural Legal Language Processing Workshop 2022</em>, pages 172–183, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yousefpour et al. (2021)</span>
<span class="ltx_bibblock">
Ashkan Yousefpour, Igor Shilov, Alexandre Sablayrolles, Davide Testuggine, Karthik Prasad, Mani Malek, John Nguyen, Sayan Ghosh, Akash Bharadwaj, Jessica Zhao, Graham Cormode, and Ilya Mironov. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2109.12298" title="">Opacus: User-Friendly Differential Privacy Library in PyTorch</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">arXiv preprint</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2021)</span>
<span class="ltx_bibblock">
Da Yu, Saurabh Naik, Arturs Backurs, Sivakanth Gopi, Huseyin A Inan, Gautam Kamath, Janardhan Kulkarni, Yin Tat Lee, Andre Manoel, Lukas Wutschitz, et al. 2021.

</span>
<span class="ltx_bibblock">Differentially private fine-tuning of language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2020)</span>
<span class="ltx_bibblock">
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=SkeHuCVFDr" title="">BERTScore: Evaluating Text Generation with BERT</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">International Conference on Learning Representations</em>.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Background on Differential Privacy and DP-SGD</h2>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Differential Privacy</h4>
<div class="ltx_para" id="A1.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px1.p1.2">Differential privacy (DP) is a mathematical framework which formally guarantees that the output of a randomized algorithm <math alttext="\mathcal{M}:\mathcal{X}\rightarrow\mathcal{Y}" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px1.p1.1.m1.1"><semantics id="A1.SS0.SSS0.Px1.p1.1.m1.1a"><mrow id="A1.SS0.SSS0.Px1.p1.1.m1.1.1" xref="A1.SS0.SSS0.Px1.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.SS0.SSS0.Px1.p1.1.m1.1.1.2" xref="A1.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml">ℳ</mi><mo id="A1.SS0.SSS0.Px1.p1.1.m1.1.1.1" lspace="0.278em" rspace="0.278em" xref="A1.SS0.SSS0.Px1.p1.1.m1.1.1.1.cmml">:</mo><mrow id="A1.SS0.SSS0.Px1.p1.1.m1.1.1.3" xref="A1.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.SS0.SSS0.Px1.p1.1.m1.1.1.3.2" xref="A1.SS0.SSS0.Px1.p1.1.m1.1.1.3.2.cmml">𝒳</mi><mo id="A1.SS0.SSS0.Px1.p1.1.m1.1.1.3.1" stretchy="false" xref="A1.SS0.SSS0.Px1.p1.1.m1.1.1.3.1.cmml">→</mo><mi class="ltx_font_mathcaligraphic" id="A1.SS0.SSS0.Px1.p1.1.m1.1.1.3.3" xref="A1.SS0.SSS0.Px1.p1.1.m1.1.1.3.3.cmml">𝒴</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p1.1.m1.1b"><apply id="A1.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="A1.SS0.SSS0.Px1.p1.1.m1.1.1"><ci id="A1.SS0.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="A1.SS0.SSS0.Px1.p1.1.m1.1.1.1">:</ci><ci id="A1.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="A1.SS0.SSS0.Px1.p1.1.m1.1.1.2">ℳ</ci><apply id="A1.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="A1.SS0.SSS0.Px1.p1.1.m1.1.1.3"><ci id="A1.SS0.SSS0.Px1.p1.1.m1.1.1.3.1.cmml" xref="A1.SS0.SSS0.Px1.p1.1.m1.1.1.3.1">→</ci><ci id="A1.SS0.SSS0.Px1.p1.1.m1.1.1.3.2.cmml" xref="A1.SS0.SSS0.Px1.p1.1.m1.1.1.3.2">𝒳</ci><ci id="A1.SS0.SSS0.Px1.p1.1.m1.1.1.3.3.cmml" xref="A1.SS0.SSS0.Px1.p1.1.m1.1.1.3.3">𝒴</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p1.1.m1.1c">\mathcal{M}:\mathcal{X}\rightarrow\mathcal{Y}</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p1.1.m1.1d">caligraphic_M : caligraphic_X → caligraphic_Y</annotation></semantics></math> abides by the following inequality in Eqn. <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#A1.E1" title="In Differential Privacy ‣ Appendix A Background on Differential Privacy and DP-SGD ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>, for all <span class="ltx_text ltx_font_italic" id="A1.SS0.SSS0.Px1.p1.2.1">neighboring</span> datasets <math alttext="x,x^{\prime}\in\mathcal{X}" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px1.p1.2.m2.2"><semantics id="A1.SS0.SSS0.Px1.p1.2.m2.2a"><mrow id="A1.SS0.SSS0.Px1.p1.2.m2.2.2" xref="A1.SS0.SSS0.Px1.p1.2.m2.2.2.cmml"><mrow id="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.1" xref="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.2.cmml"><mi id="A1.SS0.SSS0.Px1.p1.2.m2.1.1" xref="A1.SS0.SSS0.Px1.p1.2.m2.1.1.cmml">x</mi><mo id="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.1.2" xref="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.2.cmml">,</mo><msup id="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.1.1" xref="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.1.1.cmml"><mi id="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.1.1.2" xref="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.1.1.2.cmml">x</mi><mo id="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.1.1.3" xref="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.1.1.3.cmml">′</mo></msup></mrow><mo id="A1.SS0.SSS0.Px1.p1.2.m2.2.2.2" xref="A1.SS0.SSS0.Px1.p1.2.m2.2.2.2.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="A1.SS0.SSS0.Px1.p1.2.m2.2.2.3" xref="A1.SS0.SSS0.Px1.p1.2.m2.2.2.3.cmml">𝒳</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p1.2.m2.2b"><apply id="A1.SS0.SSS0.Px1.p1.2.m2.2.2.cmml" xref="A1.SS0.SSS0.Px1.p1.2.m2.2.2"><in id="A1.SS0.SSS0.Px1.p1.2.m2.2.2.2.cmml" xref="A1.SS0.SSS0.Px1.p1.2.m2.2.2.2"></in><list id="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.2.cmml" xref="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.1"><ci id="A1.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="A1.SS0.SSS0.Px1.p1.2.m2.1.1">𝑥</ci><apply id="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.1.1.cmml" xref="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.1.1.1.cmml" xref="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.1.1">superscript</csymbol><ci id="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.1.1.2.cmml" xref="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.1.1.2">𝑥</ci><ci id="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.1.1.3.cmml" xref="A1.SS0.SSS0.Px1.p1.2.m2.2.2.1.1.1.3">′</ci></apply></list><ci id="A1.SS0.SSS0.Px1.p1.2.m2.2.2.3.cmml" xref="A1.SS0.SSS0.Px1.p1.2.m2.2.2.3">𝒳</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p1.2.m2.2c">x,x^{\prime}\in\mathcal{X}</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p1.2.m2.2d">italic_x , italic_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∈ caligraphic_X</annotation></semantics></math>, i.e. datasets which are identical to one another, with the exception of one data point <cite class="ltx_cite ltx_citemacro_citep">(Dwork and Roth, <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib12" title="">2013</a>)</cite></p>
<table class="ltx_equation ltx_eqn_table" id="A1.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\Pr[\mathcal{M}(x)\in S]\leq e^{\varepsilon}\Pr[\mathcal{M}(x^{\prime})\in S]+\delta," class="ltx_Math" display="block" id="A1.E1.m1.4"><semantics id="A1.E1.m1.4a"><mrow id="A1.E1.m1.4.4.1" xref="A1.E1.m1.4.4.1.1.cmml"><mrow id="A1.E1.m1.4.4.1.1" xref="A1.E1.m1.4.4.1.1.cmml"><mrow id="A1.E1.m1.4.4.1.1.1.1" xref="A1.E1.m1.4.4.1.1.1.2.cmml"><mi id="A1.E1.m1.2.2" xref="A1.E1.m1.2.2.cmml">Pr</mi><mo id="A1.E1.m1.4.4.1.1.1.1a" xref="A1.E1.m1.4.4.1.1.1.2.cmml">⁡</mo><mrow id="A1.E1.m1.4.4.1.1.1.1.1" xref="A1.E1.m1.4.4.1.1.1.2.cmml"><mo id="A1.E1.m1.4.4.1.1.1.1.1.2" stretchy="false" xref="A1.E1.m1.4.4.1.1.1.2.cmml">[</mo><mrow id="A1.E1.m1.4.4.1.1.1.1.1.1" xref="A1.E1.m1.4.4.1.1.1.1.1.1.cmml"><mrow id="A1.E1.m1.4.4.1.1.1.1.1.1.2" xref="A1.E1.m1.4.4.1.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.E1.m1.4.4.1.1.1.1.1.1.2.2" xref="A1.E1.m1.4.4.1.1.1.1.1.1.2.2.cmml">ℳ</mi><mo id="A1.E1.m1.4.4.1.1.1.1.1.1.2.1" xref="A1.E1.m1.4.4.1.1.1.1.1.1.2.1.cmml">⁢</mo><mrow id="A1.E1.m1.4.4.1.1.1.1.1.1.2.3.2" xref="A1.E1.m1.4.4.1.1.1.1.1.1.2.cmml"><mo id="A1.E1.m1.4.4.1.1.1.1.1.1.2.3.2.1" stretchy="false" xref="A1.E1.m1.4.4.1.1.1.1.1.1.2.cmml">(</mo><mi id="A1.E1.m1.1.1" xref="A1.E1.m1.1.1.cmml">x</mi><mo id="A1.E1.m1.4.4.1.1.1.1.1.1.2.3.2.2" stretchy="false" xref="A1.E1.m1.4.4.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="A1.E1.m1.4.4.1.1.1.1.1.1.1" xref="A1.E1.m1.4.4.1.1.1.1.1.1.1.cmml">∈</mo><mi id="A1.E1.m1.4.4.1.1.1.1.1.1.3" xref="A1.E1.m1.4.4.1.1.1.1.1.1.3.cmml">S</mi></mrow><mo id="A1.E1.m1.4.4.1.1.1.1.1.3" stretchy="false" xref="A1.E1.m1.4.4.1.1.1.2.cmml">]</mo></mrow></mrow><mo id="A1.E1.m1.4.4.1.1.3" xref="A1.E1.m1.4.4.1.1.3.cmml">≤</mo><mrow id="A1.E1.m1.4.4.1.1.2" xref="A1.E1.m1.4.4.1.1.2.cmml"><mrow id="A1.E1.m1.4.4.1.1.2.1" xref="A1.E1.m1.4.4.1.1.2.1.cmml"><msup id="A1.E1.m1.4.4.1.1.2.1.3" xref="A1.E1.m1.4.4.1.1.2.1.3.cmml"><mi id="A1.E1.m1.4.4.1.1.2.1.3.2" xref="A1.E1.m1.4.4.1.1.2.1.3.2.cmml">e</mi><mi id="A1.E1.m1.4.4.1.1.2.1.3.3" xref="A1.E1.m1.4.4.1.1.2.1.3.3.cmml">ε</mi></msup><mo id="A1.E1.m1.4.4.1.1.2.1.2" lspace="0.167em" xref="A1.E1.m1.4.4.1.1.2.1.2.cmml">⁢</mo><mrow id="A1.E1.m1.4.4.1.1.2.1.1.1" xref="A1.E1.m1.4.4.1.1.2.1.1.2.cmml"><mi id="A1.E1.m1.3.3" xref="A1.E1.m1.3.3.cmml">Pr</mi><mo id="A1.E1.m1.4.4.1.1.2.1.1.1a" xref="A1.E1.m1.4.4.1.1.2.1.1.2.cmml">⁡</mo><mrow id="A1.E1.m1.4.4.1.1.2.1.1.1.1" xref="A1.E1.m1.4.4.1.1.2.1.1.2.cmml"><mo id="A1.E1.m1.4.4.1.1.2.1.1.1.1.2" stretchy="false" xref="A1.E1.m1.4.4.1.1.2.1.1.2.cmml">[</mo><mrow id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.cmml"><mrow id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.3" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.3.cmml">ℳ</mi><mo id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.2" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.1.cmml"><mo id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.1" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.1.2" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mo id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.1.3" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.1.3.cmml">′</mo></msup><mo id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.2" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.2.cmml">∈</mo><mi id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.3" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.3.cmml">S</mi></mrow><mo id="A1.E1.m1.4.4.1.1.2.1.1.1.1.3" stretchy="false" xref="A1.E1.m1.4.4.1.1.2.1.1.2.cmml">]</mo></mrow></mrow></mrow><mo id="A1.E1.m1.4.4.1.1.2.2" xref="A1.E1.m1.4.4.1.1.2.2.cmml">+</mo><mi id="A1.E1.m1.4.4.1.1.2.3" xref="A1.E1.m1.4.4.1.1.2.3.cmml">δ</mi></mrow></mrow><mo id="A1.E1.m1.4.4.1.2" xref="A1.E1.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.E1.m1.4b"><apply id="A1.E1.m1.4.4.1.1.cmml" xref="A1.E1.m1.4.4.1"><leq id="A1.E1.m1.4.4.1.1.3.cmml" xref="A1.E1.m1.4.4.1.1.3"></leq><apply id="A1.E1.m1.4.4.1.1.1.2.cmml" xref="A1.E1.m1.4.4.1.1.1.1"><ci id="A1.E1.m1.2.2.cmml" xref="A1.E1.m1.2.2">Pr</ci><apply id="A1.E1.m1.4.4.1.1.1.1.1.1.cmml" xref="A1.E1.m1.4.4.1.1.1.1.1.1"><in id="A1.E1.m1.4.4.1.1.1.1.1.1.1.cmml" xref="A1.E1.m1.4.4.1.1.1.1.1.1.1"></in><apply id="A1.E1.m1.4.4.1.1.1.1.1.1.2.cmml" xref="A1.E1.m1.4.4.1.1.1.1.1.1.2"><times id="A1.E1.m1.4.4.1.1.1.1.1.1.2.1.cmml" xref="A1.E1.m1.4.4.1.1.1.1.1.1.2.1"></times><ci id="A1.E1.m1.4.4.1.1.1.1.1.1.2.2.cmml" xref="A1.E1.m1.4.4.1.1.1.1.1.1.2.2">ℳ</ci><ci id="A1.E1.m1.1.1.cmml" xref="A1.E1.m1.1.1">𝑥</ci></apply><ci id="A1.E1.m1.4.4.1.1.1.1.1.1.3.cmml" xref="A1.E1.m1.4.4.1.1.1.1.1.1.3">𝑆</ci></apply></apply><apply id="A1.E1.m1.4.4.1.1.2.cmml" xref="A1.E1.m1.4.4.1.1.2"><plus id="A1.E1.m1.4.4.1.1.2.2.cmml" xref="A1.E1.m1.4.4.1.1.2.2"></plus><apply id="A1.E1.m1.4.4.1.1.2.1.cmml" xref="A1.E1.m1.4.4.1.1.2.1"><times id="A1.E1.m1.4.4.1.1.2.1.2.cmml" xref="A1.E1.m1.4.4.1.1.2.1.2"></times><apply id="A1.E1.m1.4.4.1.1.2.1.3.cmml" xref="A1.E1.m1.4.4.1.1.2.1.3"><csymbol cd="ambiguous" id="A1.E1.m1.4.4.1.1.2.1.3.1.cmml" xref="A1.E1.m1.4.4.1.1.2.1.3">superscript</csymbol><ci id="A1.E1.m1.4.4.1.1.2.1.3.2.cmml" xref="A1.E1.m1.4.4.1.1.2.1.3.2">𝑒</ci><ci id="A1.E1.m1.4.4.1.1.2.1.3.3.cmml" xref="A1.E1.m1.4.4.1.1.2.1.3.3">𝜀</ci></apply><apply id="A1.E1.m1.4.4.1.1.2.1.1.2.cmml" xref="A1.E1.m1.4.4.1.1.2.1.1.1"><ci id="A1.E1.m1.3.3.cmml" xref="A1.E1.m1.3.3">Pr</ci><apply id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.cmml" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1"><in id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.2.cmml" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.2"></in><apply id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.cmml" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1"><times id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.2.cmml" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.2"></times><ci id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.3.cmml" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.3">ℳ</ci><apply id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.1.cmml" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.1.3">′</ci></apply></apply><ci id="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.3.cmml" xref="A1.E1.m1.4.4.1.1.2.1.1.1.1.1.3">𝑆</ci></apply></apply></apply><ci id="A1.E1.m1.4.4.1.1.2.3.cmml" xref="A1.E1.m1.4.4.1.1.2.3">𝛿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.E1.m1.4c">\Pr[\mathcal{M}(x)\in S]\leq e^{\varepsilon}\Pr[\mathcal{M}(x^{\prime})\in S]+\delta,</annotation><annotation encoding="application/x-llamapun" id="A1.E1.m1.4d">roman_Pr [ caligraphic_M ( italic_x ) ∈ italic_S ] ≤ italic_e start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT roman_Pr [ caligraphic_M ( italic_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) ∈ italic_S ] + italic_δ ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="A1.SS0.SSS0.Px1.p1.3">for all <math alttext="S\subseteq\mathcal{Y}" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px1.p1.3.m1.1"><semantics id="A1.SS0.SSS0.Px1.p1.3.m1.1a"><mrow id="A1.SS0.SSS0.Px1.p1.3.m1.1.1" xref="A1.SS0.SSS0.Px1.p1.3.m1.1.1.cmml"><mi id="A1.SS0.SSS0.Px1.p1.3.m1.1.1.2" xref="A1.SS0.SSS0.Px1.p1.3.m1.1.1.2.cmml">S</mi><mo id="A1.SS0.SSS0.Px1.p1.3.m1.1.1.1" xref="A1.SS0.SSS0.Px1.p1.3.m1.1.1.1.cmml">⊆</mo><mi class="ltx_font_mathcaligraphic" id="A1.SS0.SSS0.Px1.p1.3.m1.1.1.3" xref="A1.SS0.SSS0.Px1.p1.3.m1.1.1.3.cmml">𝒴</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p1.3.m1.1b"><apply id="A1.SS0.SSS0.Px1.p1.3.m1.1.1.cmml" xref="A1.SS0.SSS0.Px1.p1.3.m1.1.1"><subset id="A1.SS0.SSS0.Px1.p1.3.m1.1.1.1.cmml" xref="A1.SS0.SSS0.Px1.p1.3.m1.1.1.1"></subset><ci id="A1.SS0.SSS0.Px1.p1.3.m1.1.1.2.cmml" xref="A1.SS0.SSS0.Px1.p1.3.m1.1.1.2">𝑆</ci><ci id="A1.SS0.SSS0.Px1.p1.3.m1.1.1.3.cmml" xref="A1.SS0.SSS0.Px1.p1.3.m1.1.1.3">𝒴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p1.3.m1.1c">S\subseteq\mathcal{Y}</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p1.3.m1.1d">italic_S ⊆ caligraphic_Y</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="A1.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="A1.SS0.SSS0.Px1.p2.6">We refer to the algorithm <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px1.p2.1.m1.1"><semantics id="A1.SS0.SSS0.Px1.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="A1.SS0.SSS0.Px1.p2.1.m1.1.1" xref="A1.SS0.SSS0.Px1.p2.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p2.1.m1.1b"><ci id="A1.SS0.SSS0.Px1.p2.1.m1.1.1.cmml" xref="A1.SS0.SSS0.Px1.p2.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p2.1.m1.1c">\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p2.1.m1.1d">caligraphic_M</annotation></semantics></math> as being (<math alttext="\varepsilon,\delta" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px1.p2.2.m2.2"><semantics id="A1.SS0.SSS0.Px1.p2.2.m2.2a"><mrow id="A1.SS0.SSS0.Px1.p2.2.m2.2.3.2" xref="A1.SS0.SSS0.Px1.p2.2.m2.2.3.1.cmml"><mi id="A1.SS0.SSS0.Px1.p2.2.m2.1.1" xref="A1.SS0.SSS0.Px1.p2.2.m2.1.1.cmml">ε</mi><mo id="A1.SS0.SSS0.Px1.p2.2.m2.2.3.2.1" xref="A1.SS0.SSS0.Px1.p2.2.m2.2.3.1.cmml">,</mo><mi id="A1.SS0.SSS0.Px1.p2.2.m2.2.2" xref="A1.SS0.SSS0.Px1.p2.2.m2.2.2.cmml">δ</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p2.2.m2.2b"><list id="A1.SS0.SSS0.Px1.p2.2.m2.2.3.1.cmml" xref="A1.SS0.SSS0.Px1.p2.2.m2.2.3.2"><ci id="A1.SS0.SSS0.Px1.p2.2.m2.1.1.cmml" xref="A1.SS0.SSS0.Px1.p2.2.m2.1.1">𝜀</ci><ci id="A1.SS0.SSS0.Px1.p2.2.m2.2.2.cmml" xref="A1.SS0.SSS0.Px1.p2.2.m2.2.2">𝛿</ci></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p2.2.m2.2c">\varepsilon,\delta</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p2.2.m2.2d">italic_ε , italic_δ</annotation></semantics></math>)-differentially private, where <math alttext="\varepsilon\in[0,\infty)" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px1.p2.3.m3.2"><semantics id="A1.SS0.SSS0.Px1.p2.3.m3.2a"><mrow id="A1.SS0.SSS0.Px1.p2.3.m3.2.3" xref="A1.SS0.SSS0.Px1.p2.3.m3.2.3.cmml"><mi id="A1.SS0.SSS0.Px1.p2.3.m3.2.3.2" xref="A1.SS0.SSS0.Px1.p2.3.m3.2.3.2.cmml">ε</mi><mo id="A1.SS0.SSS0.Px1.p2.3.m3.2.3.1" xref="A1.SS0.SSS0.Px1.p2.3.m3.2.3.1.cmml">∈</mo><mrow id="A1.SS0.SSS0.Px1.p2.3.m3.2.3.3.2" xref="A1.SS0.SSS0.Px1.p2.3.m3.2.3.3.1.cmml"><mo id="A1.SS0.SSS0.Px1.p2.3.m3.2.3.3.2.1" stretchy="false" xref="A1.SS0.SSS0.Px1.p2.3.m3.2.3.3.1.cmml">[</mo><mn id="A1.SS0.SSS0.Px1.p2.3.m3.1.1" xref="A1.SS0.SSS0.Px1.p2.3.m3.1.1.cmml">0</mn><mo id="A1.SS0.SSS0.Px1.p2.3.m3.2.3.3.2.2" xref="A1.SS0.SSS0.Px1.p2.3.m3.2.3.3.1.cmml">,</mo><mi id="A1.SS0.SSS0.Px1.p2.3.m3.2.2" mathvariant="normal" xref="A1.SS0.SSS0.Px1.p2.3.m3.2.2.cmml">∞</mi><mo id="A1.SS0.SSS0.Px1.p2.3.m3.2.3.3.2.3" stretchy="false" xref="A1.SS0.SSS0.Px1.p2.3.m3.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p2.3.m3.2b"><apply id="A1.SS0.SSS0.Px1.p2.3.m3.2.3.cmml" xref="A1.SS0.SSS0.Px1.p2.3.m3.2.3"><in id="A1.SS0.SSS0.Px1.p2.3.m3.2.3.1.cmml" xref="A1.SS0.SSS0.Px1.p2.3.m3.2.3.1"></in><ci id="A1.SS0.SSS0.Px1.p2.3.m3.2.3.2.cmml" xref="A1.SS0.SSS0.Px1.p2.3.m3.2.3.2">𝜀</ci><interval closure="closed-open" id="A1.SS0.SSS0.Px1.p2.3.m3.2.3.3.1.cmml" xref="A1.SS0.SSS0.Px1.p2.3.m3.2.3.3.2"><cn id="A1.SS0.SSS0.Px1.p2.3.m3.1.1.cmml" type="integer" xref="A1.SS0.SSS0.Px1.p2.3.m3.1.1">0</cn><infinity id="A1.SS0.SSS0.Px1.p2.3.m3.2.2.cmml" xref="A1.SS0.SSS0.Px1.p2.3.m3.2.2"></infinity></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p2.3.m3.2c">\varepsilon\in[0,\infty)</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p2.3.m3.2d">italic_ε ∈ [ 0 , ∞ )</annotation></semantics></math>, also known as the <span class="ltx_text ltx_font_italic" id="A1.SS0.SSS0.Px1.p2.6.1">privacy budget</span>, represents the strength of the privacy guarantee. A lower <math alttext="\varepsilon" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px1.p2.4.m4.1"><semantics id="A1.SS0.SSS0.Px1.p2.4.m4.1a"><mi id="A1.SS0.SSS0.Px1.p2.4.m4.1.1" xref="A1.SS0.SSS0.Px1.p2.4.m4.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p2.4.m4.1b"><ci id="A1.SS0.SSS0.Px1.p2.4.m4.1.1.cmml" xref="A1.SS0.SSS0.Px1.p2.4.m4.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p2.4.m4.1c">\varepsilon</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p2.4.m4.1d">italic_ε</annotation></semantics></math> value represents an exponentially stronger privacy protection. <math alttext="\delta\in[0,1]" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px1.p2.5.m5.2"><semantics id="A1.SS0.SSS0.Px1.p2.5.m5.2a"><mrow id="A1.SS0.SSS0.Px1.p2.5.m5.2.3" xref="A1.SS0.SSS0.Px1.p2.5.m5.2.3.cmml"><mi id="A1.SS0.SSS0.Px1.p2.5.m5.2.3.2" xref="A1.SS0.SSS0.Px1.p2.5.m5.2.3.2.cmml">δ</mi><mo id="A1.SS0.SSS0.Px1.p2.5.m5.2.3.1" xref="A1.SS0.SSS0.Px1.p2.5.m5.2.3.1.cmml">∈</mo><mrow id="A1.SS0.SSS0.Px1.p2.5.m5.2.3.3.2" xref="A1.SS0.SSS0.Px1.p2.5.m5.2.3.3.1.cmml"><mo id="A1.SS0.SSS0.Px1.p2.5.m5.2.3.3.2.1" stretchy="false" xref="A1.SS0.SSS0.Px1.p2.5.m5.2.3.3.1.cmml">[</mo><mn id="A1.SS0.SSS0.Px1.p2.5.m5.1.1" xref="A1.SS0.SSS0.Px1.p2.5.m5.1.1.cmml">0</mn><mo id="A1.SS0.SSS0.Px1.p2.5.m5.2.3.3.2.2" xref="A1.SS0.SSS0.Px1.p2.5.m5.2.3.3.1.cmml">,</mo><mn id="A1.SS0.SSS0.Px1.p2.5.m5.2.2" xref="A1.SS0.SSS0.Px1.p2.5.m5.2.2.cmml">1</mn><mo id="A1.SS0.SSS0.Px1.p2.5.m5.2.3.3.2.3" stretchy="false" xref="A1.SS0.SSS0.Px1.p2.5.m5.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p2.5.m5.2b"><apply id="A1.SS0.SSS0.Px1.p2.5.m5.2.3.cmml" xref="A1.SS0.SSS0.Px1.p2.5.m5.2.3"><in id="A1.SS0.SSS0.Px1.p2.5.m5.2.3.1.cmml" xref="A1.SS0.SSS0.Px1.p2.5.m5.2.3.1"></in><ci id="A1.SS0.SSS0.Px1.p2.5.m5.2.3.2.cmml" xref="A1.SS0.SSS0.Px1.p2.5.m5.2.3.2">𝛿</ci><interval closure="closed" id="A1.SS0.SSS0.Px1.p2.5.m5.2.3.3.1.cmml" xref="A1.SS0.SSS0.Px1.p2.5.m5.2.3.3.2"><cn id="A1.SS0.SSS0.Px1.p2.5.m5.1.1.cmml" type="integer" xref="A1.SS0.SSS0.Px1.p2.5.m5.1.1">0</cn><cn id="A1.SS0.SSS0.Px1.p2.5.m5.2.2.cmml" type="integer" xref="A1.SS0.SSS0.Px1.p2.5.m5.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p2.5.m5.2c">\delta\in[0,1]</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p2.5.m5.2d">italic_δ ∈ [ 0 , 1 ]</annotation></semantics></math> is a very small constant which relaxes the pure differential privacy of (<math alttext="\varepsilon,0" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px1.p2.6.m6.2"><semantics id="A1.SS0.SSS0.Px1.p2.6.m6.2a"><mrow id="A1.SS0.SSS0.Px1.p2.6.m6.2.3.2" xref="A1.SS0.SSS0.Px1.p2.6.m6.2.3.1.cmml"><mi id="A1.SS0.SSS0.Px1.p2.6.m6.1.1" xref="A1.SS0.SSS0.Px1.p2.6.m6.1.1.cmml">ε</mi><mo id="A1.SS0.SSS0.Px1.p2.6.m6.2.3.2.1" xref="A1.SS0.SSS0.Px1.p2.6.m6.2.3.1.cmml">,</mo><mn id="A1.SS0.SSS0.Px1.p2.6.m6.2.2" xref="A1.SS0.SSS0.Px1.p2.6.m6.2.2.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p2.6.m6.2b"><list id="A1.SS0.SSS0.Px1.p2.6.m6.2.3.1.cmml" xref="A1.SS0.SSS0.Px1.p2.6.m6.2.3.2"><ci id="A1.SS0.SSS0.Px1.p2.6.m6.1.1.cmml" xref="A1.SS0.SSS0.Px1.p2.6.m6.1.1">𝜀</ci><cn id="A1.SS0.SSS0.Px1.p2.6.m6.2.2.cmml" type="integer" xref="A1.SS0.SSS0.Px1.p2.6.m6.2.2">0</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p2.6.m6.2c">\varepsilon,0</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p2.6.m6.2d">italic_ε , 0</annotation></semantics></math>)-DP, providing better composition when iteratively applying multiple DP mechanisms to a given dataset.</p>
</div>
<div class="ltx_para" id="A1.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="A1.SS0.SSS0.Px1.p3.4">In order to transform a non-private algorithm <math alttext="f:\mathcal{X}\rightarrow\mathcal{Y}" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px1.p3.1.m1.1"><semantics id="A1.SS0.SSS0.Px1.p3.1.m1.1a"><mrow id="A1.SS0.SSS0.Px1.p3.1.m1.1.1" xref="A1.SS0.SSS0.Px1.p3.1.m1.1.1.cmml"><mi id="A1.SS0.SSS0.Px1.p3.1.m1.1.1.2" xref="A1.SS0.SSS0.Px1.p3.1.m1.1.1.2.cmml">f</mi><mo id="A1.SS0.SSS0.Px1.p3.1.m1.1.1.1" lspace="0.278em" rspace="0.278em" xref="A1.SS0.SSS0.Px1.p3.1.m1.1.1.1.cmml">:</mo><mrow id="A1.SS0.SSS0.Px1.p3.1.m1.1.1.3" xref="A1.SS0.SSS0.Px1.p3.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.SS0.SSS0.Px1.p3.1.m1.1.1.3.2" xref="A1.SS0.SSS0.Px1.p3.1.m1.1.1.3.2.cmml">𝒳</mi><mo id="A1.SS0.SSS0.Px1.p3.1.m1.1.1.3.1" stretchy="false" xref="A1.SS0.SSS0.Px1.p3.1.m1.1.1.3.1.cmml">→</mo><mi class="ltx_font_mathcaligraphic" id="A1.SS0.SSS0.Px1.p3.1.m1.1.1.3.3" xref="A1.SS0.SSS0.Px1.p3.1.m1.1.1.3.3.cmml">𝒴</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p3.1.m1.1b"><apply id="A1.SS0.SSS0.Px1.p3.1.m1.1.1.cmml" xref="A1.SS0.SSS0.Px1.p3.1.m1.1.1"><ci id="A1.SS0.SSS0.Px1.p3.1.m1.1.1.1.cmml" xref="A1.SS0.SSS0.Px1.p3.1.m1.1.1.1">:</ci><ci id="A1.SS0.SSS0.Px1.p3.1.m1.1.1.2.cmml" xref="A1.SS0.SSS0.Px1.p3.1.m1.1.1.2">𝑓</ci><apply id="A1.SS0.SSS0.Px1.p3.1.m1.1.1.3.cmml" xref="A1.SS0.SSS0.Px1.p3.1.m1.1.1.3"><ci id="A1.SS0.SSS0.Px1.p3.1.m1.1.1.3.1.cmml" xref="A1.SS0.SSS0.Px1.p3.1.m1.1.1.3.1">→</ci><ci id="A1.SS0.SSS0.Px1.p3.1.m1.1.1.3.2.cmml" xref="A1.SS0.SSS0.Px1.p3.1.m1.1.1.3.2">𝒳</ci><ci id="A1.SS0.SSS0.Px1.p3.1.m1.1.1.3.3.cmml" xref="A1.SS0.SSS0.Px1.p3.1.m1.1.1.3.3">𝒴</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p3.1.m1.1c">f:\mathcal{X}\rightarrow\mathcal{Y}</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p3.1.m1.1d">italic_f : caligraphic_X → caligraphic_Y</annotation></semantics></math> into one satisfying an (<math alttext="\varepsilon,\delta" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px1.p3.2.m2.2"><semantics id="A1.SS0.SSS0.Px1.p3.2.m2.2a"><mrow id="A1.SS0.SSS0.Px1.p3.2.m2.2.3.2" xref="A1.SS0.SSS0.Px1.p3.2.m2.2.3.1.cmml"><mi id="A1.SS0.SSS0.Px1.p3.2.m2.1.1" xref="A1.SS0.SSS0.Px1.p3.2.m2.1.1.cmml">ε</mi><mo id="A1.SS0.SSS0.Px1.p3.2.m2.2.3.2.1" xref="A1.SS0.SSS0.Px1.p3.2.m2.2.3.1.cmml">,</mo><mi id="A1.SS0.SSS0.Px1.p3.2.m2.2.2" xref="A1.SS0.SSS0.Px1.p3.2.m2.2.2.cmml">δ</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p3.2.m2.2b"><list id="A1.SS0.SSS0.Px1.p3.2.m2.2.3.1.cmml" xref="A1.SS0.SSS0.Px1.p3.2.m2.2.3.2"><ci id="A1.SS0.SSS0.Px1.p3.2.m2.1.1.cmml" xref="A1.SS0.SSS0.Px1.p3.2.m2.1.1">𝜀</ci><ci id="A1.SS0.SSS0.Px1.p3.2.m2.2.2.cmml" xref="A1.SS0.SSS0.Px1.p3.2.m2.2.2">𝛿</ci></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p3.2.m2.2c">\varepsilon,\delta</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p3.2.m2.2d">italic_ε , italic_δ</annotation></semantics></math>)-DP guarantee, we generally add Gaussian noise to the output of <math alttext="f" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px1.p3.3.m3.1"><semantics id="A1.SS0.SSS0.Px1.p3.3.m3.1a"><mi id="A1.SS0.SSS0.Px1.p3.3.m3.1.1" xref="A1.SS0.SSS0.Px1.p3.3.m3.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p3.3.m3.1b"><ci id="A1.SS0.SSS0.Px1.p3.3.m3.1.1.cmml" xref="A1.SS0.SSS0.Px1.p3.3.m3.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p3.3.m3.1c">f</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p3.3.m3.1d">italic_f</annotation></semantics></math>. Overall, the whole process restricts the degree to which any single data point can stand out when applying algorithm <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px1.p3.4.m4.1"><semantics id="A1.SS0.SSS0.Px1.p3.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="A1.SS0.SSS0.Px1.p3.4.m4.1.1" xref="A1.SS0.SSS0.Px1.p3.4.m4.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p3.4.m4.1b"><ci id="A1.SS0.SSS0.Px1.p3.4.m4.1.1.cmml" xref="A1.SS0.SSS0.Px1.p3.4.m4.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p3.4.m4.1c">\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p3.4.m4.1d">caligraphic_M</annotation></semantics></math> on a dataset.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">DP-SGD</h4>
<div class="ltx_para" id="A1.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px2.p1.5">A popular method for applying DP to the domain of machine learning is through differentially private stochastic gradient descent (DP-SGD) <cite class="ltx_cite ltx_citemacro_citep">(Abadi et al., <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib2" title="">2016b</a>)</cite>.
The core of the methodology relies on adding two extra steps to the original stochastic gradient descent algorithm. For any input data point <math alttext="x_{i}" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="A1.SS0.SSS0.Px2.p1.1.m1.1a"><msub id="A1.SS0.SSS0.Px2.p1.1.m1.1.1" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">x</mi><mi id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.2">𝑥</ci><ci id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px2.p1.1.m1.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px2.p1.1.m1.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, we first calculate the gradient of the loss function for a model with parameters <math alttext="\theta" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px2.p1.2.m2.1"><semantics id="A1.SS0.SSS0.Px2.p1.2.m2.1a"><mi id="A1.SS0.SSS0.Px2.p1.2.m2.1.1" xref="A1.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px2.p1.2.m2.1b"><ci id="A1.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.2.m2.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px2.p1.2.m2.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px2.p1.2.m2.1d">italic_θ</annotation></semantics></math>, <math alttext="\mathcal{L}(\theta)" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px2.p1.3.m3.1"><semantics id="A1.SS0.SSS0.Px2.p1.3.m3.1a"><mrow id="A1.SS0.SSS0.Px2.p1.3.m3.1.2" xref="A1.SS0.SSS0.Px2.p1.3.m3.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.SS0.SSS0.Px2.p1.3.m3.1.2.2" xref="A1.SS0.SSS0.Px2.p1.3.m3.1.2.2.cmml">ℒ</mi><mo id="A1.SS0.SSS0.Px2.p1.3.m3.1.2.1" xref="A1.SS0.SSS0.Px2.p1.3.m3.1.2.1.cmml">⁢</mo><mrow id="A1.SS0.SSS0.Px2.p1.3.m3.1.2.3.2" xref="A1.SS0.SSS0.Px2.p1.3.m3.1.2.cmml"><mo id="A1.SS0.SSS0.Px2.p1.3.m3.1.2.3.2.1" stretchy="false" xref="A1.SS0.SSS0.Px2.p1.3.m3.1.2.cmml">(</mo><mi id="A1.SS0.SSS0.Px2.p1.3.m3.1.1" xref="A1.SS0.SSS0.Px2.p1.3.m3.1.1.cmml">θ</mi><mo id="A1.SS0.SSS0.Px2.p1.3.m3.1.2.3.2.2" stretchy="false" xref="A1.SS0.SSS0.Px2.p1.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px2.p1.3.m3.1b"><apply id="A1.SS0.SSS0.Px2.p1.3.m3.1.2.cmml" xref="A1.SS0.SSS0.Px2.p1.3.m3.1.2"><times id="A1.SS0.SSS0.Px2.p1.3.m3.1.2.1.cmml" xref="A1.SS0.SSS0.Px2.p1.3.m3.1.2.1"></times><ci id="A1.SS0.SSS0.Px2.p1.3.m3.1.2.2.cmml" xref="A1.SS0.SSS0.Px2.p1.3.m3.1.2.2">ℒ</ci><ci id="A1.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.3.m3.1.1">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px2.p1.3.m3.1c">\mathcal{L}(\theta)</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px2.p1.3.m3.1d">caligraphic_L ( italic_θ )</annotation></semantics></math>, at training iteration <math alttext="t" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px2.p1.4.m4.1"><semantics id="A1.SS0.SSS0.Px2.p1.4.m4.1a"><mi id="A1.SS0.SSS0.Px2.p1.4.m4.1.1" xref="A1.SS0.SSS0.Px2.p1.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px2.p1.4.m4.1b"><ci id="A1.SS0.SSS0.Px2.p1.4.m4.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px2.p1.4.m4.1c">t</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px2.p1.4.m4.1d">italic_t</annotation></semantics></math>. Hence, <math alttext="g_{t}(x_{i})=\nabla_{\theta_{t}}\mathcal{L}(\theta_{t},x_{i})" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px2.p1.5.m5.3"><semantics id="A1.SS0.SSS0.Px2.p1.5.m5.3a"><mrow id="A1.SS0.SSS0.Px2.p1.5.m5.3.3" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.cmml"><mrow id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.cmml"><msub id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.3" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.3.cmml"><mi id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.3.2" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.3.2.cmml">g</mi><mi id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.3.3" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.3.3.cmml">t</mi></msub><mo id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.2" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.2.cmml">⁢</mo><mrow id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1.1.cmml"><mo id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1.2" stretchy="false" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1.1.cmml">(</mo><msub id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1.1" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1.1.cmml"><mi id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1.1.2" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1.1.2.cmml">x</mi><mi id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1.1.3" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1.3" stretchy="false" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.4" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.4.cmml">=</mo><mrow id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.cmml"><mrow id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.cmml"><msub id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.cmml"><mo id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.2" rspace="0.167em" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.2.cmml">∇</mo><msub id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.3" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.3.cmml"><mi id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.3.2" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.3.2.cmml">θ</mi><mi id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.3.3" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.3.3.cmml">t</mi></msub></msub><mi class="ltx_font_mathcaligraphic" id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.2" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.2.cmml">ℒ</mi></mrow><mo id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.3" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.3.cmml">⁢</mo><mrow id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.3.cmml"><mo id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2.3" stretchy="false" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.3.cmml">(</mo><msub id="A1.SS0.SSS0.Px2.p1.5.m5.2.2.2.1.1.1" xref="A1.SS0.SSS0.Px2.p1.5.m5.2.2.2.1.1.1.cmml"><mi id="A1.SS0.SSS0.Px2.p1.5.m5.2.2.2.1.1.1.2" xref="A1.SS0.SSS0.Px2.p1.5.m5.2.2.2.1.1.1.2.cmml">θ</mi><mi id="A1.SS0.SSS0.Px2.p1.5.m5.2.2.2.1.1.1.3" xref="A1.SS0.SSS0.Px2.p1.5.m5.2.2.2.1.1.1.3.cmml">t</mi></msub><mo id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2.4" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.3.cmml">,</mo><msub id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2.2" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2.2.cmml"><mi id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2.2.2" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2.2.2.cmml">x</mi><mi id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2.2.3" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2.2.3.cmml">i</mi></msub><mo id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2.5" stretchy="false" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px2.p1.5.m5.3b"><apply id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3"><eq id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.4.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.4"></eq><apply id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1"><times id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.2.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.2"></times><apply id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.3.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.3"><csymbol cd="ambiguous" id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.3.1.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.3">subscript</csymbol><ci id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.3.2.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.3.2">𝑔</ci><ci id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.3.3.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.3.3">𝑡</ci></apply><apply id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1">subscript</csymbol><ci id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1.1.2.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1.1.2">𝑥</ci><ci id="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1.1.3.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3"><times id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.3.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.3"></times><apply id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4"><apply id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1"><csymbol cd="ambiguous" id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1">subscript</csymbol><ci id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.2.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.2">∇</ci><apply id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.3.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.3"><csymbol cd="ambiguous" id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.3.1.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.3">subscript</csymbol><ci id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.3.2.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.3.2">𝜃</ci><ci id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.3.3.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.1.3.3">𝑡</ci></apply></apply><ci id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.2.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.4.2">ℒ</ci></apply><interval closure="open" id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.3.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2"><apply id="A1.SS0.SSS0.Px2.p1.5.m5.2.2.2.1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.2.2.2.1.1.1"><csymbol cd="ambiguous" id="A1.SS0.SSS0.Px2.p1.5.m5.2.2.2.1.1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.2.2.2.1.1.1">subscript</csymbol><ci id="A1.SS0.SSS0.Px2.p1.5.m5.2.2.2.1.1.1.2.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.2.2.2.1.1.1.2">𝜃</ci><ci id="A1.SS0.SSS0.Px2.p1.5.m5.2.2.2.1.1.1.3.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.2.2.2.1.1.1.3">𝑡</ci></apply><apply id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2.2.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2.2"><csymbol cd="ambiguous" id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2.2.1.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2.2">subscript</csymbol><ci id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2.2.2.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2.2.2">𝑥</ci><ci id="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2.2.3.cmml" xref="A1.SS0.SSS0.Px2.p1.5.m5.3.3.3.2.2.2.3">𝑖</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px2.p1.5.m5.3c">g_{t}(x_{i})=\nabla_{\theta_{t}}\mathcal{L}(\theta_{t},x_{i})</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px2.p1.5.m5.3d">italic_g start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = ∇ start_POSTSUBSCRIPT italic_θ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_L ( italic_θ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="A1.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="A1.SS0.SSS0.Px2.p2.3">We then incorporate a <span class="ltx_text ltx_font_italic" id="A1.SS0.SSS0.Px2.p2.3.1">clipping</span> step, in which the <math alttext="\ell_{2}" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px2.p2.1.m1.1"><semantics id="A1.SS0.SSS0.Px2.p2.1.m1.1a"><msub id="A1.SS0.SSS0.Px2.p2.1.m1.1.1" xref="A1.SS0.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="A1.SS0.SSS0.Px2.p2.1.m1.1.1.2" mathvariant="normal" xref="A1.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml">ℓ</mi><mn id="A1.SS0.SSS0.Px2.p2.1.m1.1.1.3" xref="A1.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px2.p2.1.m1.1b"><apply id="A1.SS0.SSS0.Px2.p2.1.m1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS0.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p2.1.m1.1.1">subscript</csymbol><ci id="A1.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="A1.SS0.SSS0.Px2.p2.1.m1.1.1.2">ℓ</ci><cn id="A1.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml" type="integer" xref="A1.SS0.SSS0.Px2.p2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px2.p2.1.m1.1c">\ell_{2}</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px2.p2.1.m1.1d">roman_ℓ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>-norm of <math alttext="g_{t}(x_{i})" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px2.p2.2.m2.1"><semantics id="A1.SS0.SSS0.Px2.p2.2.m2.1a"><mrow id="A1.SS0.SSS0.Px2.p2.2.m2.1.1" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.cmml"><msub id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.3" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.3.cmml"><mi id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.3.2" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.3.2.cmml">g</mi><mi id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.3.3" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.3.3.cmml">t</mi></msub><mo id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.2" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml">⁢</mo><mrow id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.cmml"><mo id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.2" stretchy="false" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.cmml">(</mo><msub id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.cmml"><mi id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.cmml">x</mi><mi id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.3" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.3" stretchy="false" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px2.p2.2.m2.1b"><apply id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.cmml" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1"><times id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.2"></times><apply id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.3.cmml" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.3.1.cmml" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.3">subscript</csymbol><ci id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.3.2.cmml" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.3.2">𝑔</ci><ci id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.3.3.cmml" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.3.3">𝑡</ci></apply><apply id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1">subscript</csymbol><ci id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.cmml" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2">𝑥</ci><ci id="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.3.cmml" xref="A1.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px2.p2.2.m2.1c">g_{t}(x_{i})</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px2.p2.2.m2.1d">italic_g start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> is clipped with clipping constant <math alttext="C" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px2.p2.3.m3.1"><semantics id="A1.SS0.SSS0.Px2.p2.3.m3.1a"><mi id="A1.SS0.SSS0.Px2.p2.3.m3.1.1" xref="A1.SS0.SSS0.Px2.p2.3.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px2.p2.3.m3.1b"><ci id="A1.SS0.SSS0.Px2.p2.3.m3.1.1.cmml" xref="A1.SS0.SSS0.Px2.p2.3.m3.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px2.p2.3.m3.1c">C</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px2.p2.3.m3.1d">italic_C</annotation></semantics></math>, as in Eqn. <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#A1.E2" title="In DP-SGD ‣ Appendix A Background on Differential Privacy and DP-SGD ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>, in order to constrain the range of possible values.
This is followed by a <span class="ltx_text ltx_font_italic" id="A1.SS0.SSS0.Px2.p2.3.2">perturbation</span> step, adding Gaussian noise to the clipped gradients, as in Eqn. <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#A1.E3" title="In DP-SGD ‣ Appendix A Background on Differential Privacy and DP-SGD ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div class="ltx_para" id="A1.SS0.SSS0.Px2.p3">
<table class="ltx_equation ltx_eqn_table" id="A1.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\bar{g}_{t}(x_{i})=\frac{g_{t}(x_{i})}{\max\left(1,\frac{||g_{t}(x_{i})||_{2}}%
{C}\right)}" class="ltx_Math" display="block" id="A1.E2.m1.5"><semantics id="A1.E2.m1.5a"><mrow id="A1.E2.m1.5.5" xref="A1.E2.m1.5.5.cmml"><mrow id="A1.E2.m1.5.5.1" xref="A1.E2.m1.5.5.1.cmml"><msub id="A1.E2.m1.5.5.1.3" xref="A1.E2.m1.5.5.1.3.cmml"><mover accent="true" id="A1.E2.m1.5.5.1.3.2" xref="A1.E2.m1.5.5.1.3.2.cmml"><mi id="A1.E2.m1.5.5.1.3.2.2" xref="A1.E2.m1.5.5.1.3.2.2.cmml">g</mi><mo id="A1.E2.m1.5.5.1.3.2.1" xref="A1.E2.m1.5.5.1.3.2.1.cmml">¯</mo></mover><mi id="A1.E2.m1.5.5.1.3.3" xref="A1.E2.m1.5.5.1.3.3.cmml">t</mi></msub><mo id="A1.E2.m1.5.5.1.2" xref="A1.E2.m1.5.5.1.2.cmml">⁢</mo><mrow id="A1.E2.m1.5.5.1.1.1" xref="A1.E2.m1.5.5.1.1.1.1.cmml"><mo id="A1.E2.m1.5.5.1.1.1.2" stretchy="false" xref="A1.E2.m1.5.5.1.1.1.1.cmml">(</mo><msub id="A1.E2.m1.5.5.1.1.1.1" xref="A1.E2.m1.5.5.1.1.1.1.cmml"><mi id="A1.E2.m1.5.5.1.1.1.1.2" xref="A1.E2.m1.5.5.1.1.1.1.2.cmml">x</mi><mi id="A1.E2.m1.5.5.1.1.1.1.3" xref="A1.E2.m1.5.5.1.1.1.1.3.cmml">i</mi></msub><mo id="A1.E2.m1.5.5.1.1.1.3" stretchy="false" xref="A1.E2.m1.5.5.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.E2.m1.5.5.2" xref="A1.E2.m1.5.5.2.cmml">=</mo><mfrac id="A1.E2.m1.4.4" xref="A1.E2.m1.4.4.cmml"><mrow id="A1.E2.m1.1.1.1" xref="A1.E2.m1.1.1.1.cmml"><msub id="A1.E2.m1.1.1.1.3" xref="A1.E2.m1.1.1.1.3.cmml"><mi id="A1.E2.m1.1.1.1.3.2" xref="A1.E2.m1.1.1.1.3.2.cmml">g</mi><mi id="A1.E2.m1.1.1.1.3.3" xref="A1.E2.m1.1.1.1.3.3.cmml">t</mi></msub><mo id="A1.E2.m1.1.1.1.2" xref="A1.E2.m1.1.1.1.2.cmml">⁢</mo><mrow id="A1.E2.m1.1.1.1.1.1" xref="A1.E2.m1.1.1.1.1.1.1.cmml"><mo id="A1.E2.m1.1.1.1.1.1.2" stretchy="false" xref="A1.E2.m1.1.1.1.1.1.1.cmml">(</mo><msub id="A1.E2.m1.1.1.1.1.1.1" xref="A1.E2.m1.1.1.1.1.1.1.cmml"><mi id="A1.E2.m1.1.1.1.1.1.1.2" xref="A1.E2.m1.1.1.1.1.1.1.2.cmml">x</mi><mi id="A1.E2.m1.1.1.1.1.1.1.3" xref="A1.E2.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A1.E2.m1.1.1.1.1.1.3" stretchy="false" xref="A1.E2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="A1.E2.m1.4.4.4.5" xref="A1.E2.m1.4.4.4.4.cmml"><mi id="A1.E2.m1.3.3.3.2" xref="A1.E2.m1.3.3.3.2.cmml">max</mi><mo id="A1.E2.m1.4.4.4.5a" xref="A1.E2.m1.4.4.4.4.cmml">⁡</mo><mrow id="A1.E2.m1.4.4.4.5.1" xref="A1.E2.m1.4.4.4.4.cmml"><mo id="A1.E2.m1.4.4.4.5.1.1" xref="A1.E2.m1.4.4.4.4.cmml">(</mo><mn id="A1.E2.m1.4.4.4.3" xref="A1.E2.m1.4.4.4.3.cmml">1</mn><mo id="A1.E2.m1.4.4.4.5.1.2" xref="A1.E2.m1.4.4.4.4.cmml">,</mo><mfrac id="A1.E2.m1.2.2.2.1" xref="A1.E2.m1.2.2.2.1.cmml"><msub id="A1.E2.m1.2.2.2.1.1" xref="A1.E2.m1.2.2.2.1.1.cmml"><mrow id="A1.E2.m1.2.2.2.1.1.1.1" xref="A1.E2.m1.2.2.2.1.1.1.2.cmml"><mo id="A1.E2.m1.2.2.2.1.1.1.1.2" maxsize="142%" minsize="142%" xref="A1.E2.m1.2.2.2.1.1.1.2.1.cmml">‖</mo><mrow id="A1.E2.m1.2.2.2.1.1.1.1.1" xref="A1.E2.m1.2.2.2.1.1.1.1.1.cmml"><msub id="A1.E2.m1.2.2.2.1.1.1.1.1.3" xref="A1.E2.m1.2.2.2.1.1.1.1.1.3.cmml"><mi id="A1.E2.m1.2.2.2.1.1.1.1.1.3.2" xref="A1.E2.m1.2.2.2.1.1.1.1.1.3.2.cmml">g</mi><mi id="A1.E2.m1.2.2.2.1.1.1.1.1.3.3" xref="A1.E2.m1.2.2.2.1.1.1.1.1.3.3.cmml">t</mi></msub><mo id="A1.E2.m1.2.2.2.1.1.1.1.1.2" xref="A1.E2.m1.2.2.2.1.1.1.1.1.2.cmml">⁢</mo><mrow id="A1.E2.m1.2.2.2.1.1.1.1.1.1.1" xref="A1.E2.m1.2.2.2.1.1.1.1.1.1.1.1.cmml"><mo id="A1.E2.m1.2.2.2.1.1.1.1.1.1.1.2" stretchy="false" xref="A1.E2.m1.2.2.2.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="A1.E2.m1.2.2.2.1.1.1.1.1.1.1.1" xref="A1.E2.m1.2.2.2.1.1.1.1.1.1.1.1.cmml"><mi id="A1.E2.m1.2.2.2.1.1.1.1.1.1.1.1.2" xref="A1.E2.m1.2.2.2.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="A1.E2.m1.2.2.2.1.1.1.1.1.1.1.1.3" xref="A1.E2.m1.2.2.2.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A1.E2.m1.2.2.2.1.1.1.1.1.1.1.3" stretchy="false" xref="A1.E2.m1.2.2.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.E2.m1.2.2.2.1.1.1.1.3" maxsize="142%" minsize="142%" xref="A1.E2.m1.2.2.2.1.1.1.2.1.cmml">‖</mo></mrow><mn id="A1.E2.m1.2.2.2.1.1.3" xref="A1.E2.m1.2.2.2.1.1.3.cmml">2</mn></msub><mi id="A1.E2.m1.2.2.2.1.3" xref="A1.E2.m1.2.2.2.1.3.cmml">C</mi></mfrac><mo id="A1.E2.m1.4.4.4.5.1.3" xref="A1.E2.m1.4.4.4.4.cmml">)</mo></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="A1.E2.m1.5b"><apply id="A1.E2.m1.5.5.cmml" xref="A1.E2.m1.5.5"><eq id="A1.E2.m1.5.5.2.cmml" xref="A1.E2.m1.5.5.2"></eq><apply id="A1.E2.m1.5.5.1.cmml" xref="A1.E2.m1.5.5.1"><times id="A1.E2.m1.5.5.1.2.cmml" xref="A1.E2.m1.5.5.1.2"></times><apply id="A1.E2.m1.5.5.1.3.cmml" xref="A1.E2.m1.5.5.1.3"><csymbol cd="ambiguous" id="A1.E2.m1.5.5.1.3.1.cmml" xref="A1.E2.m1.5.5.1.3">subscript</csymbol><apply id="A1.E2.m1.5.5.1.3.2.cmml" xref="A1.E2.m1.5.5.1.3.2"><ci id="A1.E2.m1.5.5.1.3.2.1.cmml" xref="A1.E2.m1.5.5.1.3.2.1">¯</ci><ci id="A1.E2.m1.5.5.1.3.2.2.cmml" xref="A1.E2.m1.5.5.1.3.2.2">𝑔</ci></apply><ci id="A1.E2.m1.5.5.1.3.3.cmml" xref="A1.E2.m1.5.5.1.3.3">𝑡</ci></apply><apply id="A1.E2.m1.5.5.1.1.1.1.cmml" xref="A1.E2.m1.5.5.1.1.1"><csymbol cd="ambiguous" id="A1.E2.m1.5.5.1.1.1.1.1.cmml" xref="A1.E2.m1.5.5.1.1.1">subscript</csymbol><ci id="A1.E2.m1.5.5.1.1.1.1.2.cmml" xref="A1.E2.m1.5.5.1.1.1.1.2">𝑥</ci><ci id="A1.E2.m1.5.5.1.1.1.1.3.cmml" xref="A1.E2.m1.5.5.1.1.1.1.3">𝑖</ci></apply></apply><apply id="A1.E2.m1.4.4.cmml" xref="A1.E2.m1.4.4"><divide id="A1.E2.m1.4.4.5.cmml" xref="A1.E2.m1.4.4"></divide><apply id="A1.E2.m1.1.1.1.cmml" xref="A1.E2.m1.1.1.1"><times id="A1.E2.m1.1.1.1.2.cmml" xref="A1.E2.m1.1.1.1.2"></times><apply id="A1.E2.m1.1.1.1.3.cmml" xref="A1.E2.m1.1.1.1.3"><csymbol cd="ambiguous" id="A1.E2.m1.1.1.1.3.1.cmml" xref="A1.E2.m1.1.1.1.3">subscript</csymbol><ci id="A1.E2.m1.1.1.1.3.2.cmml" xref="A1.E2.m1.1.1.1.3.2">𝑔</ci><ci id="A1.E2.m1.1.1.1.3.3.cmml" xref="A1.E2.m1.1.1.1.3.3">𝑡</ci></apply><apply id="A1.E2.m1.1.1.1.1.1.1.cmml" xref="A1.E2.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.E2.m1.1.1.1.1.1.1.1.cmml" xref="A1.E2.m1.1.1.1.1.1">subscript</csymbol><ci id="A1.E2.m1.1.1.1.1.1.1.2.cmml" xref="A1.E2.m1.1.1.1.1.1.1.2">𝑥</ci><ci id="A1.E2.m1.1.1.1.1.1.1.3.cmml" xref="A1.E2.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="A1.E2.m1.4.4.4.4.cmml" xref="A1.E2.m1.4.4.4.5"><max id="A1.E2.m1.3.3.3.2.cmml" xref="A1.E2.m1.3.3.3.2"></max><cn id="A1.E2.m1.4.4.4.3.cmml" type="integer" xref="A1.E2.m1.4.4.4.3">1</cn><apply id="A1.E2.m1.2.2.2.1.cmml" xref="A1.E2.m1.2.2.2.1"><divide id="A1.E2.m1.2.2.2.1.2.cmml" xref="A1.E2.m1.2.2.2.1"></divide><apply id="A1.E2.m1.2.2.2.1.1.cmml" xref="A1.E2.m1.2.2.2.1.1"><csymbol cd="ambiguous" id="A1.E2.m1.2.2.2.1.1.2.cmml" xref="A1.E2.m1.2.2.2.1.1">subscript</csymbol><apply id="A1.E2.m1.2.2.2.1.1.1.2.cmml" xref="A1.E2.m1.2.2.2.1.1.1.1"><csymbol cd="latexml" id="A1.E2.m1.2.2.2.1.1.1.2.1.cmml" xref="A1.E2.m1.2.2.2.1.1.1.1.2">norm</csymbol><apply id="A1.E2.m1.2.2.2.1.1.1.1.1.cmml" xref="A1.E2.m1.2.2.2.1.1.1.1.1"><times id="A1.E2.m1.2.2.2.1.1.1.1.1.2.cmml" xref="A1.E2.m1.2.2.2.1.1.1.1.1.2"></times><apply id="A1.E2.m1.2.2.2.1.1.1.1.1.3.cmml" xref="A1.E2.m1.2.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A1.E2.m1.2.2.2.1.1.1.1.1.3.1.cmml" xref="A1.E2.m1.2.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="A1.E2.m1.2.2.2.1.1.1.1.1.3.2.cmml" xref="A1.E2.m1.2.2.2.1.1.1.1.1.3.2">𝑔</ci><ci id="A1.E2.m1.2.2.2.1.1.1.1.1.3.3.cmml" xref="A1.E2.m1.2.2.2.1.1.1.1.1.3.3">𝑡</ci></apply><apply id="A1.E2.m1.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="A1.E2.m1.2.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.E2.m1.2.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="A1.E2.m1.2.2.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="A1.E2.m1.2.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="A1.E2.m1.2.2.2.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="A1.E2.m1.2.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="A1.E2.m1.2.2.2.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply><cn id="A1.E2.m1.2.2.2.1.1.3.cmml" type="integer" xref="A1.E2.m1.2.2.2.1.1.3">2</cn></apply><ci id="A1.E2.m1.2.2.2.1.3.cmml" xref="A1.E2.m1.2.2.2.1.3">𝐶</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.E2.m1.5c">\bar{g}_{t}(x_{i})=\frac{g_{t}(x_{i})}{\max\left(1,\frac{||g_{t}(x_{i})||_{2}}%
{C}\right)}</annotation><annotation encoding="application/x-llamapun" id="A1.E2.m1.5d">over¯ start_ARG italic_g end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = divide start_ARG italic_g start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG roman_max ( 1 , divide start_ARG | | italic_g start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) | | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG start_ARG italic_C end_ARG ) end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="A1.SS0.SSS0.Px2.p4">
<table class="ltx_equation ltx_eqn_table" id="A1.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\hat{g}_{t}=\frac{1}{L}\sum_{i\in L}\left(\bar{g}_{t}(x_{i})+\mathcal{N}(0,%
\sigma^{2}C^{2}\mathbf{I})\right)" class="ltx_Math" display="block" id="A1.E3.m1.2"><semantics id="A1.E3.m1.2a"><mrow id="A1.E3.m1.2.2" xref="A1.E3.m1.2.2.cmml"><msub id="A1.E3.m1.2.2.3" xref="A1.E3.m1.2.2.3.cmml"><mover accent="true" id="A1.E3.m1.2.2.3.2" xref="A1.E3.m1.2.2.3.2.cmml"><mi id="A1.E3.m1.2.2.3.2.2" xref="A1.E3.m1.2.2.3.2.2.cmml">g</mi><mo id="A1.E3.m1.2.2.3.2.1" xref="A1.E3.m1.2.2.3.2.1.cmml">^</mo></mover><mi id="A1.E3.m1.2.2.3.3" xref="A1.E3.m1.2.2.3.3.cmml">t</mi></msub><mo id="A1.E3.m1.2.2.2" xref="A1.E3.m1.2.2.2.cmml">=</mo><mrow id="A1.E3.m1.2.2.1" xref="A1.E3.m1.2.2.1.cmml"><mfrac id="A1.E3.m1.2.2.1.3" xref="A1.E3.m1.2.2.1.3.cmml"><mn id="A1.E3.m1.2.2.1.3.2" xref="A1.E3.m1.2.2.1.3.2.cmml">1</mn><mi id="A1.E3.m1.2.2.1.3.3" xref="A1.E3.m1.2.2.1.3.3.cmml">L</mi></mfrac><mo id="A1.E3.m1.2.2.1.2" xref="A1.E3.m1.2.2.1.2.cmml">⁢</mo><mrow id="A1.E3.m1.2.2.1.1" xref="A1.E3.m1.2.2.1.1.cmml"><munder id="A1.E3.m1.2.2.1.1.2" xref="A1.E3.m1.2.2.1.1.2.cmml"><mo id="A1.E3.m1.2.2.1.1.2.2" movablelimits="false" rspace="0em" xref="A1.E3.m1.2.2.1.1.2.2.cmml">∑</mo><mrow id="A1.E3.m1.2.2.1.1.2.3" xref="A1.E3.m1.2.2.1.1.2.3.cmml"><mi id="A1.E3.m1.2.2.1.1.2.3.2" xref="A1.E3.m1.2.2.1.1.2.3.2.cmml">i</mi><mo id="A1.E3.m1.2.2.1.1.2.3.1" xref="A1.E3.m1.2.2.1.1.2.3.1.cmml">∈</mo><mi id="A1.E3.m1.2.2.1.1.2.3.3" xref="A1.E3.m1.2.2.1.1.2.3.3.cmml">L</mi></mrow></munder><mrow id="A1.E3.m1.2.2.1.1.1.1" xref="A1.E3.m1.2.2.1.1.1.1.1.cmml"><mo id="A1.E3.m1.2.2.1.1.1.1.2" xref="A1.E3.m1.2.2.1.1.1.1.1.cmml">(</mo><mrow id="A1.E3.m1.2.2.1.1.1.1.1" xref="A1.E3.m1.2.2.1.1.1.1.1.cmml"><mrow id="A1.E3.m1.2.2.1.1.1.1.1.1" xref="A1.E3.m1.2.2.1.1.1.1.1.1.cmml"><msub id="A1.E3.m1.2.2.1.1.1.1.1.1.3" xref="A1.E3.m1.2.2.1.1.1.1.1.1.3.cmml"><mover accent="true" id="A1.E3.m1.2.2.1.1.1.1.1.1.3.2" xref="A1.E3.m1.2.2.1.1.1.1.1.1.3.2.cmml"><mi id="A1.E3.m1.2.2.1.1.1.1.1.1.3.2.2" xref="A1.E3.m1.2.2.1.1.1.1.1.1.3.2.2.cmml">g</mi><mo id="A1.E3.m1.2.2.1.1.1.1.1.1.3.2.1" xref="A1.E3.m1.2.2.1.1.1.1.1.1.3.2.1.cmml">¯</mo></mover><mi id="A1.E3.m1.2.2.1.1.1.1.1.1.3.3" xref="A1.E3.m1.2.2.1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo id="A1.E3.m1.2.2.1.1.1.1.1.1.2" xref="A1.E3.m1.2.2.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="A1.E3.m1.2.2.1.1.1.1.1.1.1.1" xref="A1.E3.m1.2.2.1.1.1.1.1.1.1.1.1.cmml"><mo id="A1.E3.m1.2.2.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A1.E3.m1.2.2.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="A1.E3.m1.2.2.1.1.1.1.1.1.1.1.1" xref="A1.E3.m1.2.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="A1.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="A1.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="A1.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="A1.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A1.E3.m1.2.2.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A1.E3.m1.2.2.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.E3.m1.2.2.1.1.1.1.1.3" xref="A1.E3.m1.2.2.1.1.1.1.1.3.cmml">+</mo><mrow id="A1.E3.m1.2.2.1.1.1.1.1.2" xref="A1.E3.m1.2.2.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.E3.m1.2.2.1.1.1.1.1.2.3" xref="A1.E3.m1.2.2.1.1.1.1.1.2.3.cmml">𝒩</mi><mo id="A1.E3.m1.2.2.1.1.1.1.1.2.2" xref="A1.E3.m1.2.2.1.1.1.1.1.2.2.cmml">⁢</mo><mrow id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.2.cmml"><mo id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.2" stretchy="false" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.2.cmml">(</mo><mn id="A1.E3.m1.1.1" xref="A1.E3.m1.1.1.cmml">0</mn><mo id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.3" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.2.cmml">,</mo><mrow id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.cmml"><msup id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.2" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.2.cmml"><mi id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.2.2" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.2.2.cmml">σ</mi><mn id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.2.3" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.2.3.cmml">2</mn></msup><mo id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.1" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.1.cmml">⁢</mo><msup id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.3" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.3.cmml"><mi id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.3.2" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.3.2.cmml">C</mi><mn id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.3.3" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.3.3.cmml">2</mn></msup><mo id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.1a" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.1.cmml">⁢</mo><mi id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.4" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.4.cmml">𝐈</mi></mrow><mo id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.4" stretchy="false" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="A1.E3.m1.2.2.1.1.1.1.3" xref="A1.E3.m1.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.E3.m1.2b"><apply id="A1.E3.m1.2.2.cmml" xref="A1.E3.m1.2.2"><eq id="A1.E3.m1.2.2.2.cmml" xref="A1.E3.m1.2.2.2"></eq><apply id="A1.E3.m1.2.2.3.cmml" xref="A1.E3.m1.2.2.3"><csymbol cd="ambiguous" id="A1.E3.m1.2.2.3.1.cmml" xref="A1.E3.m1.2.2.3">subscript</csymbol><apply id="A1.E3.m1.2.2.3.2.cmml" xref="A1.E3.m1.2.2.3.2"><ci id="A1.E3.m1.2.2.3.2.1.cmml" xref="A1.E3.m1.2.2.3.2.1">^</ci><ci id="A1.E3.m1.2.2.3.2.2.cmml" xref="A1.E3.m1.2.2.3.2.2">𝑔</ci></apply><ci id="A1.E3.m1.2.2.3.3.cmml" xref="A1.E3.m1.2.2.3.3">𝑡</ci></apply><apply id="A1.E3.m1.2.2.1.cmml" xref="A1.E3.m1.2.2.1"><times id="A1.E3.m1.2.2.1.2.cmml" xref="A1.E3.m1.2.2.1.2"></times><apply id="A1.E3.m1.2.2.1.3.cmml" xref="A1.E3.m1.2.2.1.3"><divide id="A1.E3.m1.2.2.1.3.1.cmml" xref="A1.E3.m1.2.2.1.3"></divide><cn id="A1.E3.m1.2.2.1.3.2.cmml" type="integer" xref="A1.E3.m1.2.2.1.3.2">1</cn><ci id="A1.E3.m1.2.2.1.3.3.cmml" xref="A1.E3.m1.2.2.1.3.3">𝐿</ci></apply><apply id="A1.E3.m1.2.2.1.1.cmml" xref="A1.E3.m1.2.2.1.1"><apply id="A1.E3.m1.2.2.1.1.2.cmml" xref="A1.E3.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="A1.E3.m1.2.2.1.1.2.1.cmml" xref="A1.E3.m1.2.2.1.1.2">subscript</csymbol><sum id="A1.E3.m1.2.2.1.1.2.2.cmml" xref="A1.E3.m1.2.2.1.1.2.2"></sum><apply id="A1.E3.m1.2.2.1.1.2.3.cmml" xref="A1.E3.m1.2.2.1.1.2.3"><in id="A1.E3.m1.2.2.1.1.2.3.1.cmml" xref="A1.E3.m1.2.2.1.1.2.3.1"></in><ci id="A1.E3.m1.2.2.1.1.2.3.2.cmml" xref="A1.E3.m1.2.2.1.1.2.3.2">𝑖</ci><ci id="A1.E3.m1.2.2.1.1.2.3.3.cmml" xref="A1.E3.m1.2.2.1.1.2.3.3">𝐿</ci></apply></apply><apply id="A1.E3.m1.2.2.1.1.1.1.1.cmml" xref="A1.E3.m1.2.2.1.1.1.1"><plus id="A1.E3.m1.2.2.1.1.1.1.1.3.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.3"></plus><apply id="A1.E3.m1.2.2.1.1.1.1.1.1.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.1"><times id="A1.E3.m1.2.2.1.1.1.1.1.1.2.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.1.2"></times><apply id="A1.E3.m1.2.2.1.1.1.1.1.1.3.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A1.E3.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.1.3">subscript</csymbol><apply id="A1.E3.m1.2.2.1.1.1.1.1.1.3.2.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.1.3.2"><ci id="A1.E3.m1.2.2.1.1.1.1.1.1.3.2.1.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.1.3.2.1">¯</ci><ci id="A1.E3.m1.2.2.1.1.1.1.1.1.3.2.2.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.1.3.2.2">𝑔</ci></apply><ci id="A1.E3.m1.2.2.1.1.1.1.1.1.3.3.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.1.3.3">𝑡</ci></apply><apply id="A1.E3.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="A1.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="A1.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="A1.E3.m1.2.2.1.1.1.1.1.2.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.2"><times id="A1.E3.m1.2.2.1.1.1.1.1.2.2.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.2.2"></times><ci id="A1.E3.m1.2.2.1.1.1.1.1.2.3.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.2.3">𝒩</ci><interval closure="open" id="A1.E3.m1.2.2.1.1.1.1.1.2.1.2.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1"><cn id="A1.E3.m1.1.1.cmml" type="integer" xref="A1.E3.m1.1.1">0</cn><apply id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1"><times id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.1.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.1"></times><apply id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.2.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.2"><csymbol cd="ambiguous" id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.2.1.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.2">superscript</csymbol><ci id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.2.2.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.2.2">𝜎</ci><cn id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.2.3.cmml" type="integer" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.2.3">2</cn></apply><apply id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.3.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.3"><csymbol cd="ambiguous" id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.3.1.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.3">superscript</csymbol><ci id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.3.2.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.3.2">𝐶</ci><cn id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.3.3.cmml" type="integer" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.3.3">2</cn></apply><ci id="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.4.cmml" xref="A1.E3.m1.2.2.1.1.1.1.1.2.1.1.1.4">𝐈</ci></apply></interval></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.E3.m1.2c">\hat{g}_{t}=\frac{1}{L}\sum_{i\in L}\left(\bar{g}_{t}(x_{i})+\mathcal{N}(0,%
\sigma^{2}C^{2}\mathbf{I})\right)</annotation><annotation encoding="application/x-llamapun" id="A1.E3.m1.2d">over^ start_ARG italic_g end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_L end_ARG ∑ start_POSTSUBSCRIPT italic_i ∈ italic_L end_POSTSUBSCRIPT ( over¯ start_ARG italic_g end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) + caligraphic_N ( 0 , italic_σ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT bold_I ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="A1.SS0.SSS0.Px2.p4.2">Importantly, <math alttext="L" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px2.p4.1.m1.1"><semantics id="A1.SS0.SSS0.Px2.p4.1.m1.1a"><mi id="A1.SS0.SSS0.Px2.p4.1.m1.1.1" xref="A1.SS0.SSS0.Px2.p4.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px2.p4.1.m1.1b"><ci id="A1.SS0.SSS0.Px2.p4.1.m1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p4.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px2.p4.1.m1.1c">L</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px2.p4.1.m1.1d">italic_L</annotation></semantics></math> represents the <span class="ltx_text ltx_font_italic" id="A1.SS0.SSS0.Px2.p4.2.1">lot size</span>, being a group of data points that are randomly drawn from the full training dataset at each iteration.
The final gradient descent step is then taken with respect to this noisy gradient <math alttext="\hat{g}_{t}" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px2.p4.2.m2.1"><semantics id="A1.SS0.SSS0.Px2.p4.2.m2.1a"><msub id="A1.SS0.SSS0.Px2.p4.2.m2.1.1" xref="A1.SS0.SSS0.Px2.p4.2.m2.1.1.cmml"><mover accent="true" id="A1.SS0.SSS0.Px2.p4.2.m2.1.1.2" xref="A1.SS0.SSS0.Px2.p4.2.m2.1.1.2.cmml"><mi id="A1.SS0.SSS0.Px2.p4.2.m2.1.1.2.2" xref="A1.SS0.SSS0.Px2.p4.2.m2.1.1.2.2.cmml">g</mi><mo id="A1.SS0.SSS0.Px2.p4.2.m2.1.1.2.1" xref="A1.SS0.SSS0.Px2.p4.2.m2.1.1.2.1.cmml">^</mo></mover><mi id="A1.SS0.SSS0.Px2.p4.2.m2.1.1.3" xref="A1.SS0.SSS0.Px2.p4.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px2.p4.2.m2.1b"><apply id="A1.SS0.SSS0.Px2.p4.2.m2.1.1.cmml" xref="A1.SS0.SSS0.Px2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="A1.SS0.SSS0.Px2.p4.2.m2.1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p4.2.m2.1.1">subscript</csymbol><apply id="A1.SS0.SSS0.Px2.p4.2.m2.1.1.2.cmml" xref="A1.SS0.SSS0.Px2.p4.2.m2.1.1.2"><ci id="A1.SS0.SSS0.Px2.p4.2.m2.1.1.2.1.cmml" xref="A1.SS0.SSS0.Px2.p4.2.m2.1.1.2.1">^</ci><ci id="A1.SS0.SSS0.Px2.p4.2.m2.1.1.2.2.cmml" xref="A1.SS0.SSS0.Px2.p4.2.m2.1.1.2.2">𝑔</ci></apply><ci id="A1.SS0.SSS0.Px2.p4.2.m2.1.1.3.cmml" xref="A1.SS0.SSS0.Px2.p4.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px2.p4.2.m2.1c">\hat{g}_{t}</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px2.p4.2.m2.1d">over^ start_ARG italic_g end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>.
We outline the DP-SGD algorithm in more detail in Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#alg1" title="Algorithm 1 ‣ DP-SGD ‣ Appendix A Background on Differential Privacy and DP-SGD ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.2.1.1">Algorithm 1</span> </span> DP-SGD</figcaption>
<div class="ltx_listing ltx_listing" id="alg1.3">
<div class="ltx_listingline" id="alg1.l1">
<span class="ltx_tag ltx_tag_listingline">1:</span><span class="ltx_text ltx_font_bold" id="alg1.l1.1">function</span> <span class="ltx_text ltx_font_smallcaps" id="alg1.l1.2">DP-SGD</span>(<math alttext="f(\bm{x};\Theta)" class="ltx_Math" display="inline" id="alg1.l1.m1.2"><semantics id="alg1.l1.m1.2a"><mrow id="alg1.l1.m1.2.3" xref="alg1.l1.m1.2.3.cmml"><mi id="alg1.l1.m1.2.3.2" xref="alg1.l1.m1.2.3.2.cmml">f</mi><mo id="alg1.l1.m1.2.3.1" xref="alg1.l1.m1.2.3.1.cmml">⁢</mo><mrow id="alg1.l1.m1.2.3.3.2" xref="alg1.l1.m1.2.3.3.1.cmml"><mo id="alg1.l1.m1.2.3.3.2.1" stretchy="false" xref="alg1.l1.m1.2.3.3.1.cmml">(</mo><mi id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml">𝒙</mi><mo id="alg1.l1.m1.2.3.3.2.2" xref="alg1.l1.m1.2.3.3.1.cmml">;</mo><mi id="alg1.l1.m1.2.2" mathvariant="normal" xref="alg1.l1.m1.2.2.cmml">Θ</mi><mo id="alg1.l1.m1.2.3.3.2.3" stretchy="false" xref="alg1.l1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.2b"><apply id="alg1.l1.m1.2.3.cmml" xref="alg1.l1.m1.2.3"><times id="alg1.l1.m1.2.3.1.cmml" xref="alg1.l1.m1.2.3.1"></times><ci id="alg1.l1.m1.2.3.2.cmml" xref="alg1.l1.m1.2.3.2">𝑓</ci><list id="alg1.l1.m1.2.3.3.1.cmml" xref="alg1.l1.m1.2.3.3.2"><ci id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1">𝒙</ci><ci id="alg1.l1.m1.2.2.cmml" xref="alg1.l1.m1.2.2">Θ</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.2c">f(\bm{x};\Theta)</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m1.2d">italic_f ( bold_italic_x ; roman_Θ )</annotation></semantics></math>, <math alttext="(\bm{x}_{1},\ldots,\bm{x}_{n})" class="ltx_Math" display="inline" id="alg1.l1.m2.3"><semantics id="alg1.l1.m2.3a"><mrow id="alg1.l1.m2.3.3.2" xref="alg1.l1.m2.3.3.3.cmml"><mo id="alg1.l1.m2.3.3.2.3" stretchy="false" xref="alg1.l1.m2.3.3.3.cmml">(</mo><msub id="alg1.l1.m2.2.2.1.1" xref="alg1.l1.m2.2.2.1.1.cmml"><mi id="alg1.l1.m2.2.2.1.1.2" xref="alg1.l1.m2.2.2.1.1.2.cmml">𝒙</mi><mn id="alg1.l1.m2.2.2.1.1.3" xref="alg1.l1.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="alg1.l1.m2.3.3.2.4" xref="alg1.l1.m2.3.3.3.cmml">,</mo><mi id="alg1.l1.m2.1.1" mathvariant="normal" xref="alg1.l1.m2.1.1.cmml">…</mi><mo id="alg1.l1.m2.3.3.2.5" xref="alg1.l1.m2.3.3.3.cmml">,</mo><msub id="alg1.l1.m2.3.3.2.2" xref="alg1.l1.m2.3.3.2.2.cmml"><mi id="alg1.l1.m2.3.3.2.2.2" xref="alg1.l1.m2.3.3.2.2.2.cmml">𝒙</mi><mi id="alg1.l1.m2.3.3.2.2.3" xref="alg1.l1.m2.3.3.2.2.3.cmml">n</mi></msub><mo id="alg1.l1.m2.3.3.2.6" stretchy="false" xref="alg1.l1.m2.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m2.3b"><vector id="alg1.l1.m2.3.3.3.cmml" xref="alg1.l1.m2.3.3.2"><apply id="alg1.l1.m2.2.2.1.1.cmml" xref="alg1.l1.m2.2.2.1.1"><csymbol cd="ambiguous" id="alg1.l1.m2.2.2.1.1.1.cmml" xref="alg1.l1.m2.2.2.1.1">subscript</csymbol><ci id="alg1.l1.m2.2.2.1.1.2.cmml" xref="alg1.l1.m2.2.2.1.1.2">𝒙</ci><cn id="alg1.l1.m2.2.2.1.1.3.cmml" type="integer" xref="alg1.l1.m2.2.2.1.1.3">1</cn></apply><ci id="alg1.l1.m2.1.1.cmml" xref="alg1.l1.m2.1.1">…</ci><apply id="alg1.l1.m2.3.3.2.2.cmml" xref="alg1.l1.m2.3.3.2.2"><csymbol cd="ambiguous" id="alg1.l1.m2.3.3.2.2.1.cmml" xref="alg1.l1.m2.3.3.2.2">subscript</csymbol><ci id="alg1.l1.m2.3.3.2.2.2.cmml" xref="alg1.l1.m2.3.3.2.2.2">𝒙</ci><ci id="alg1.l1.m2.3.3.2.2.3.cmml" xref="alg1.l1.m2.3.3.2.2.3">𝑛</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m2.3c">(\bm{x}_{1},\ldots,\bm{x}_{n})</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m2.3d">( bold_italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , bold_italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT )</annotation></semantics></math>, <math alttext="|L|" class="ltx_Math" display="inline" id="alg1.l1.m3.1"><semantics id="alg1.l1.m3.1a"><mrow id="alg1.l1.m3.1.2.2" xref="alg1.l1.m3.1.2.1.cmml"><mo id="alg1.l1.m3.1.2.2.1" stretchy="false" xref="alg1.l1.m3.1.2.1.1.cmml">|</mo><mi id="alg1.l1.m3.1.1" xref="alg1.l1.m3.1.1.cmml">L</mi><mo id="alg1.l1.m3.1.2.2.2" stretchy="false" xref="alg1.l1.m3.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m3.1b"><apply id="alg1.l1.m3.1.2.1.cmml" xref="alg1.l1.m3.1.2.2"><abs id="alg1.l1.m3.1.2.1.1.cmml" xref="alg1.l1.m3.1.2.2.1"></abs><ci id="alg1.l1.m3.1.1.cmml" xref="alg1.l1.m3.1.1">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m3.1c">|L|</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m3.1d">| italic_L |</annotation></semantics></math> — ‘lot’ size, <math alttext="T" class="ltx_Math" display="inline" id="alg1.l1.m4.1"><semantics id="alg1.l1.m4.1a"><mi id="alg1.l1.m4.1.1" xref="alg1.l1.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m4.1b"><ci id="alg1.l1.m4.1.1.cmml" xref="alg1.l1.m4.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m4.1c">T</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m4.1d">italic_T</annotation></semantics></math> — # of steps)

</div>
<div class="ltx_listingline" id="alg1.l2">
<span class="ltx_tag ltx_tag_listingline">2:</span>   <span class="ltx_text ltx_font_bold" id="alg1.l2.1">for</span> <math alttext="t\in(1,2,\ldots,T)" class="ltx_Math" display="inline" id="alg1.l2.m1.4"><semantics id="alg1.l2.m1.4a"><mrow id="alg1.l2.m1.4.5" xref="alg1.l2.m1.4.5.cmml"><mi id="alg1.l2.m1.4.5.2" xref="alg1.l2.m1.4.5.2.cmml">t</mi><mo id="alg1.l2.m1.4.5.1" xref="alg1.l2.m1.4.5.1.cmml">∈</mo><mrow id="alg1.l2.m1.4.5.3.2" xref="alg1.l2.m1.4.5.3.1.cmml"><mo id="alg1.l2.m1.4.5.3.2.1" stretchy="false" xref="alg1.l2.m1.4.5.3.1.cmml">(</mo><mn id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml">1</mn><mo id="alg1.l2.m1.4.5.3.2.2" xref="alg1.l2.m1.4.5.3.1.cmml">,</mo><mn id="alg1.l2.m1.2.2" xref="alg1.l2.m1.2.2.cmml">2</mn><mo id="alg1.l2.m1.4.5.3.2.3" xref="alg1.l2.m1.4.5.3.1.cmml">,</mo><mi id="alg1.l2.m1.3.3" mathvariant="normal" xref="alg1.l2.m1.3.3.cmml">…</mi><mo id="alg1.l2.m1.4.5.3.2.4" xref="alg1.l2.m1.4.5.3.1.cmml">,</mo><mi id="alg1.l2.m1.4.4" xref="alg1.l2.m1.4.4.cmml">T</mi><mo id="alg1.l2.m1.4.5.3.2.5" stretchy="false" xref="alg1.l2.m1.4.5.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.4b"><apply id="alg1.l2.m1.4.5.cmml" xref="alg1.l2.m1.4.5"><in id="alg1.l2.m1.4.5.1.cmml" xref="alg1.l2.m1.4.5.1"></in><ci id="alg1.l2.m1.4.5.2.cmml" xref="alg1.l2.m1.4.5.2">𝑡</ci><vector id="alg1.l2.m1.4.5.3.1.cmml" xref="alg1.l2.m1.4.5.3.2"><cn id="alg1.l2.m1.1.1.cmml" type="integer" xref="alg1.l2.m1.1.1">1</cn><cn id="alg1.l2.m1.2.2.cmml" type="integer" xref="alg1.l2.m1.2.2">2</cn><ci id="alg1.l2.m1.3.3.cmml" xref="alg1.l2.m1.3.3">…</ci><ci id="alg1.l2.m1.4.4.cmml" xref="alg1.l2.m1.4.4">𝑇</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.4c">t\in(1,2,\ldots,T)</annotation><annotation encoding="application/x-llamapun" id="alg1.l2.m1.4d">italic_t ∈ ( 1 , 2 , … , italic_T )</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l2.2">do</span>
</div>
<div class="ltx_listingline" id="alg1.l3">
<span class="ltx_tag ltx_tag_listingline">3:</span>      Add each training example to a ‘lot’ <math alttext="L_{t}" class="ltx_Math" display="inline" id="alg1.l3.m1.1"><semantics id="alg1.l3.m1.1a"><msub id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml"><mi id="alg1.l3.m1.1.1.2" xref="alg1.l3.m1.1.1.2.cmml">L</mi><mi id="alg1.l3.m1.1.1.3" xref="alg1.l3.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><apply id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1"><csymbol cd="ambiguous" id="alg1.l3.m1.1.1.1.cmml" xref="alg1.l3.m1.1.1">subscript</csymbol><ci id="alg1.l3.m1.1.1.2.cmml" xref="alg1.l3.m1.1.1.2">𝐿</ci><ci id="alg1.l3.m1.1.1.3.cmml" xref="alg1.l3.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">L_{t}</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m1.1d">italic_L start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> with probability <math alttext="|L|/N" class="ltx_Math" display="inline" id="alg1.l3.m2.1"><semantics id="alg1.l3.m2.1a"><mrow id="alg1.l3.m2.1.2" xref="alg1.l3.m2.1.2.cmml"><mrow id="alg1.l3.m2.1.2.2.2" xref="alg1.l3.m2.1.2.2.1.cmml"><mo id="alg1.l3.m2.1.2.2.2.1" stretchy="false" xref="alg1.l3.m2.1.2.2.1.1.cmml">|</mo><mi id="alg1.l3.m2.1.1" xref="alg1.l3.m2.1.1.cmml">L</mi><mo id="alg1.l3.m2.1.2.2.2.2" stretchy="false" xref="alg1.l3.m2.1.2.2.1.1.cmml">|</mo></mrow><mo id="alg1.l3.m2.1.2.1" xref="alg1.l3.m2.1.2.1.cmml">/</mo><mi id="alg1.l3.m2.1.2.3" xref="alg1.l3.m2.1.2.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m2.1b"><apply id="alg1.l3.m2.1.2.cmml" xref="alg1.l3.m2.1.2"><divide id="alg1.l3.m2.1.2.1.cmml" xref="alg1.l3.m2.1.2.1"></divide><apply id="alg1.l3.m2.1.2.2.1.cmml" xref="alg1.l3.m2.1.2.2.2"><abs id="alg1.l3.m2.1.2.2.1.1.cmml" xref="alg1.l3.m2.1.2.2.2.1"></abs><ci id="alg1.l3.m2.1.1.cmml" xref="alg1.l3.m2.1.1">𝐿</ci></apply><ci id="alg1.l3.m2.1.2.3.cmml" xref="alg1.l3.m2.1.2.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m2.1c">|L|/N</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m2.1d">| italic_L | / italic_N</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l4">
<span class="ltx_tag ltx_tag_listingline">4:</span>      <span class="ltx_text ltx_font_bold" id="alg1.l4.1">for</span> each example in the ‘lot’ <math alttext="\bm{x}_{i}\in L_{t}" class="ltx_Math" display="inline" id="alg1.l4.m1.1"><semantics id="alg1.l4.m1.1a"><mrow id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml"><msub id="alg1.l4.m1.1.1.2" xref="alg1.l4.m1.1.1.2.cmml"><mi id="alg1.l4.m1.1.1.2.2" xref="alg1.l4.m1.1.1.2.2.cmml">𝒙</mi><mi id="alg1.l4.m1.1.1.2.3" xref="alg1.l4.m1.1.1.2.3.cmml">i</mi></msub><mo id="alg1.l4.m1.1.1.1" xref="alg1.l4.m1.1.1.1.cmml">∈</mo><msub id="alg1.l4.m1.1.1.3" xref="alg1.l4.m1.1.1.3.cmml"><mi id="alg1.l4.m1.1.1.3.2" xref="alg1.l4.m1.1.1.3.2.cmml">L</mi><mi id="alg1.l4.m1.1.1.3.3" xref="alg1.l4.m1.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b"><apply id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1"><in id="alg1.l4.m1.1.1.1.cmml" xref="alg1.l4.m1.1.1.1"></in><apply id="alg1.l4.m1.1.1.2.cmml" xref="alg1.l4.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l4.m1.1.1.2.1.cmml" xref="alg1.l4.m1.1.1.2">subscript</csymbol><ci id="alg1.l4.m1.1.1.2.2.cmml" xref="alg1.l4.m1.1.1.2.2">𝒙</ci><ci id="alg1.l4.m1.1.1.2.3.cmml" xref="alg1.l4.m1.1.1.2.3">𝑖</ci></apply><apply id="alg1.l4.m1.1.1.3.cmml" xref="alg1.l4.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l4.m1.1.1.3.1.cmml" xref="alg1.l4.m1.1.1.3">subscript</csymbol><ci id="alg1.l4.m1.1.1.3.2.cmml" xref="alg1.l4.m1.1.1.3.2">𝐿</ci><ci id="alg1.l4.m1.1.1.3.3.cmml" xref="alg1.l4.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">\bm{x}_{i}\in L_{t}</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m1.1d">bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ italic_L start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l4.2">do</span>
</div>
<div class="ltx_listingline" id="alg1.l5">
<span class="ltx_tag ltx_tag_listingline">5:</span>         <math alttext="\bm{g}(\bm{x}_{i})\leftarrow\nabla\mathcal{L}(\theta_{t},\bm{x}_{i})" class="ltx_Math" display="inline" id="alg1.l5.m1.3"><semantics id="alg1.l5.m1.3a"><mrow id="alg1.l5.m1.3.3" xref="alg1.l5.m1.3.3.cmml"><mrow id="alg1.l5.m1.1.1.1" xref="alg1.l5.m1.1.1.1.cmml"><mi id="alg1.l5.m1.1.1.1.3" xref="alg1.l5.m1.1.1.1.3.cmml">𝒈</mi><mo id="alg1.l5.m1.1.1.1.2" xref="alg1.l5.m1.1.1.1.2.cmml">⁢</mo><mrow id="alg1.l5.m1.1.1.1.1.1" xref="alg1.l5.m1.1.1.1.1.1.1.cmml"><mo id="alg1.l5.m1.1.1.1.1.1.2" stretchy="false" xref="alg1.l5.m1.1.1.1.1.1.1.cmml">(</mo><msub id="alg1.l5.m1.1.1.1.1.1.1" xref="alg1.l5.m1.1.1.1.1.1.1.cmml"><mi id="alg1.l5.m1.1.1.1.1.1.1.2" xref="alg1.l5.m1.1.1.1.1.1.1.2.cmml">𝒙</mi><mi id="alg1.l5.m1.1.1.1.1.1.1.3" xref="alg1.l5.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="alg1.l5.m1.1.1.1.1.1.3" stretchy="false" xref="alg1.l5.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l5.m1.3.3.4" stretchy="false" xref="alg1.l5.m1.3.3.4.cmml">←</mo><mrow id="alg1.l5.m1.3.3.3" xref="alg1.l5.m1.3.3.3.cmml"><mrow id="alg1.l5.m1.3.3.3.4" xref="alg1.l5.m1.3.3.3.4.cmml"><mo id="alg1.l5.m1.3.3.3.4.1" rspace="0.167em" xref="alg1.l5.m1.3.3.3.4.1.cmml">∇</mo><mi class="ltx_font_mathcaligraphic" id="alg1.l5.m1.3.3.3.4.2" xref="alg1.l5.m1.3.3.3.4.2.cmml">ℒ</mi></mrow><mo id="alg1.l5.m1.3.3.3.3" xref="alg1.l5.m1.3.3.3.3.cmml">⁢</mo><mrow id="alg1.l5.m1.3.3.3.2.2" xref="alg1.l5.m1.3.3.3.2.3.cmml"><mo id="alg1.l5.m1.3.3.3.2.2.3" stretchy="false" xref="alg1.l5.m1.3.3.3.2.3.cmml">(</mo><msub id="alg1.l5.m1.2.2.2.1.1.1" xref="alg1.l5.m1.2.2.2.1.1.1.cmml"><mi id="alg1.l5.m1.2.2.2.1.1.1.2" xref="alg1.l5.m1.2.2.2.1.1.1.2.cmml">θ</mi><mi id="alg1.l5.m1.2.2.2.1.1.1.3" xref="alg1.l5.m1.2.2.2.1.1.1.3.cmml">t</mi></msub><mo id="alg1.l5.m1.3.3.3.2.2.4" xref="alg1.l5.m1.3.3.3.2.3.cmml">,</mo><msub id="alg1.l5.m1.3.3.3.2.2.2" xref="alg1.l5.m1.3.3.3.2.2.2.cmml"><mi id="alg1.l5.m1.3.3.3.2.2.2.2" xref="alg1.l5.m1.3.3.3.2.2.2.2.cmml">𝒙</mi><mi id="alg1.l5.m1.3.3.3.2.2.2.3" xref="alg1.l5.m1.3.3.3.2.2.2.3.cmml">i</mi></msub><mo id="alg1.l5.m1.3.3.3.2.2.5" stretchy="false" xref="alg1.l5.m1.3.3.3.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.3b"><apply id="alg1.l5.m1.3.3.cmml" xref="alg1.l5.m1.3.3"><ci id="alg1.l5.m1.3.3.4.cmml" xref="alg1.l5.m1.3.3.4">←</ci><apply id="alg1.l5.m1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1"><times id="alg1.l5.m1.1.1.1.2.cmml" xref="alg1.l5.m1.1.1.1.2"></times><ci id="alg1.l5.m1.1.1.1.3.cmml" xref="alg1.l5.m1.1.1.1.3">𝒈</ci><apply id="alg1.l5.m1.1.1.1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l5.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l5.m1.1.1.1.1.1.1.2">𝒙</ci><ci id="alg1.l5.m1.1.1.1.1.1.1.3.cmml" xref="alg1.l5.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="alg1.l5.m1.3.3.3.cmml" xref="alg1.l5.m1.3.3.3"><times id="alg1.l5.m1.3.3.3.3.cmml" xref="alg1.l5.m1.3.3.3.3"></times><apply id="alg1.l5.m1.3.3.3.4.cmml" xref="alg1.l5.m1.3.3.3.4"><ci id="alg1.l5.m1.3.3.3.4.1.cmml" xref="alg1.l5.m1.3.3.3.4.1">∇</ci><ci id="alg1.l5.m1.3.3.3.4.2.cmml" xref="alg1.l5.m1.3.3.3.4.2">ℒ</ci></apply><interval closure="open" id="alg1.l5.m1.3.3.3.2.3.cmml" xref="alg1.l5.m1.3.3.3.2.2"><apply id="alg1.l5.m1.2.2.2.1.1.1.cmml" xref="alg1.l5.m1.2.2.2.1.1.1"><csymbol cd="ambiguous" id="alg1.l5.m1.2.2.2.1.1.1.1.cmml" xref="alg1.l5.m1.2.2.2.1.1.1">subscript</csymbol><ci id="alg1.l5.m1.2.2.2.1.1.1.2.cmml" xref="alg1.l5.m1.2.2.2.1.1.1.2">𝜃</ci><ci id="alg1.l5.m1.2.2.2.1.1.1.3.cmml" xref="alg1.l5.m1.2.2.2.1.1.1.3">𝑡</ci></apply><apply id="alg1.l5.m1.3.3.3.2.2.2.cmml" xref="alg1.l5.m1.3.3.3.2.2.2"><csymbol cd="ambiguous" id="alg1.l5.m1.3.3.3.2.2.2.1.cmml" xref="alg1.l5.m1.3.3.3.2.2.2">subscript</csymbol><ci id="alg1.l5.m1.3.3.3.2.2.2.2.cmml" xref="alg1.l5.m1.3.3.3.2.2.2.2">𝒙</ci><ci id="alg1.l5.m1.3.3.3.2.2.2.3.cmml" xref="alg1.l5.m1.3.3.3.2.2.2.3">𝑖</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.3c">\bm{g}(\bm{x}_{i})\leftarrow\nabla\mathcal{L}(\theta_{t},\bm{x}_{i})</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.m1.3d">bold_italic_g ( bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ← ∇ caligraphic_L ( italic_θ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>
<span class="ltx_text" id="alg1.l5.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l5.1.m1.1"><semantics id="alg1.l5.1.m1.1a"><mo id="alg1.l5.1.m1.1.1" xref="alg1.l5.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l5.1.m1.1b"><ci id="alg1.l5.1.m1.1.1.cmml" xref="alg1.l5.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.1.m1.1d">▷</annotation></semantics></math> Compute gradient
</span>
</div>
<div class="ltx_listingline" id="alg1.l6">
<span class="ltx_tag ltx_tag_listingline">6:</span>         <math alttext="\bar{\bm{g}}(\bm{x}_{i})\leftarrow\bm{g}(\bm{x}_{i})/\max\left(1,\|\bm{g}(\bm{%
x}_{i})\|/C\right)" class="ltx_Math" display="inline" id="alg1.l6.m1.5"><semantics id="alg1.l6.m1.5a"><mrow id="alg1.l6.m1.5.5" xref="alg1.l6.m1.5.5.cmml"><mrow id="alg1.l6.m1.3.3.1" xref="alg1.l6.m1.3.3.1.cmml"><mover accent="true" id="alg1.l6.m1.3.3.1.3" xref="alg1.l6.m1.3.3.1.3.cmml"><mi id="alg1.l6.m1.3.3.1.3.2" xref="alg1.l6.m1.3.3.1.3.2.cmml">𝒈</mi><mo id="alg1.l6.m1.3.3.1.3.1" xref="alg1.l6.m1.3.3.1.3.1.cmml">¯</mo></mover><mo id="alg1.l6.m1.3.3.1.2" xref="alg1.l6.m1.3.3.1.2.cmml">⁢</mo><mrow id="alg1.l6.m1.3.3.1.1.1" xref="alg1.l6.m1.3.3.1.1.1.1.cmml"><mo id="alg1.l6.m1.3.3.1.1.1.2" stretchy="false" xref="alg1.l6.m1.3.3.1.1.1.1.cmml">(</mo><msub id="alg1.l6.m1.3.3.1.1.1.1" xref="alg1.l6.m1.3.3.1.1.1.1.cmml"><mi id="alg1.l6.m1.3.3.1.1.1.1.2" xref="alg1.l6.m1.3.3.1.1.1.1.2.cmml">𝒙</mi><mi id="alg1.l6.m1.3.3.1.1.1.1.3" xref="alg1.l6.m1.3.3.1.1.1.1.3.cmml">i</mi></msub><mo id="alg1.l6.m1.3.3.1.1.1.3" stretchy="false" xref="alg1.l6.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l6.m1.5.5.4" stretchy="false" xref="alg1.l6.m1.5.5.4.cmml">←</mo><mrow id="alg1.l6.m1.5.5.3" xref="alg1.l6.m1.5.5.3.cmml"><mrow id="alg1.l6.m1.4.4.2.1" xref="alg1.l6.m1.4.4.2.1.cmml"><mi id="alg1.l6.m1.4.4.2.1.3" xref="alg1.l6.m1.4.4.2.1.3.cmml">𝒈</mi><mo id="alg1.l6.m1.4.4.2.1.2" xref="alg1.l6.m1.4.4.2.1.2.cmml">⁢</mo><mrow id="alg1.l6.m1.4.4.2.1.1.1" xref="alg1.l6.m1.4.4.2.1.1.1.1.cmml"><mo id="alg1.l6.m1.4.4.2.1.1.1.2" stretchy="false" xref="alg1.l6.m1.4.4.2.1.1.1.1.cmml">(</mo><msub id="alg1.l6.m1.4.4.2.1.1.1.1" xref="alg1.l6.m1.4.4.2.1.1.1.1.cmml"><mi id="alg1.l6.m1.4.4.2.1.1.1.1.2" xref="alg1.l6.m1.4.4.2.1.1.1.1.2.cmml">𝒙</mi><mi id="alg1.l6.m1.4.4.2.1.1.1.1.3" xref="alg1.l6.m1.4.4.2.1.1.1.1.3.cmml">i</mi></msub><mo id="alg1.l6.m1.4.4.2.1.1.1.3" stretchy="false" xref="alg1.l6.m1.4.4.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l6.m1.5.5.3.3" xref="alg1.l6.m1.5.5.3.3.cmml">/</mo><mrow id="alg1.l6.m1.5.5.3.2.1" xref="alg1.l6.m1.5.5.3.2.2.cmml"><mi id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml">max</mi><mo id="alg1.l6.m1.5.5.3.2.1a" xref="alg1.l6.m1.5.5.3.2.2.cmml">⁡</mo><mrow id="alg1.l6.m1.5.5.3.2.1.1" xref="alg1.l6.m1.5.5.3.2.2.cmml"><mo id="alg1.l6.m1.5.5.3.2.1.1.2" xref="alg1.l6.m1.5.5.3.2.2.cmml">(</mo><mn id="alg1.l6.m1.2.2" xref="alg1.l6.m1.2.2.cmml">1</mn><mo id="alg1.l6.m1.5.5.3.2.1.1.3" xref="alg1.l6.m1.5.5.3.2.2.cmml">,</mo><mrow id="alg1.l6.m1.5.5.3.2.1.1.1" xref="alg1.l6.m1.5.5.3.2.1.1.1.cmml"><mrow id="alg1.l6.m1.5.5.3.2.1.1.1.1.1" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.2.cmml"><mo id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.2" stretchy="false" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.2.1.cmml">‖</mo><mrow id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.cmml"><mi id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.3" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.3.cmml">𝒈</mi><mo id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.2" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1.1.cmml"><mo id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1.2" stretchy="false" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1.1" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1.1.2" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1.1.2.cmml">𝒙</mi><mi id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1.1.3" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1.3" stretchy="false" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.3" stretchy="false" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.2.1.cmml">‖</mo></mrow><mo id="alg1.l6.m1.5.5.3.2.1.1.1.2" xref="alg1.l6.m1.5.5.3.2.1.1.1.2.cmml">/</mo><mi id="alg1.l6.m1.5.5.3.2.1.1.1.3" xref="alg1.l6.m1.5.5.3.2.1.1.1.3.cmml">C</mi></mrow><mo id="alg1.l6.m1.5.5.3.2.1.1.4" xref="alg1.l6.m1.5.5.3.2.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.5b"><apply id="alg1.l6.m1.5.5.cmml" xref="alg1.l6.m1.5.5"><ci id="alg1.l6.m1.5.5.4.cmml" xref="alg1.l6.m1.5.5.4">←</ci><apply id="alg1.l6.m1.3.3.1.cmml" xref="alg1.l6.m1.3.3.1"><times id="alg1.l6.m1.3.3.1.2.cmml" xref="alg1.l6.m1.3.3.1.2"></times><apply id="alg1.l6.m1.3.3.1.3.cmml" xref="alg1.l6.m1.3.3.1.3"><ci id="alg1.l6.m1.3.3.1.3.1.cmml" xref="alg1.l6.m1.3.3.1.3.1">¯</ci><ci id="alg1.l6.m1.3.3.1.3.2.cmml" xref="alg1.l6.m1.3.3.1.3.2">𝒈</ci></apply><apply id="alg1.l6.m1.3.3.1.1.1.1.cmml" xref="alg1.l6.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="alg1.l6.m1.3.3.1.1.1.1.1.cmml" xref="alg1.l6.m1.3.3.1.1.1">subscript</csymbol><ci id="alg1.l6.m1.3.3.1.1.1.1.2.cmml" xref="alg1.l6.m1.3.3.1.1.1.1.2">𝒙</ci><ci id="alg1.l6.m1.3.3.1.1.1.1.3.cmml" xref="alg1.l6.m1.3.3.1.1.1.1.3">𝑖</ci></apply></apply><apply id="alg1.l6.m1.5.5.3.cmml" xref="alg1.l6.m1.5.5.3"><divide id="alg1.l6.m1.5.5.3.3.cmml" xref="alg1.l6.m1.5.5.3.3"></divide><apply id="alg1.l6.m1.4.4.2.1.cmml" xref="alg1.l6.m1.4.4.2.1"><times id="alg1.l6.m1.4.4.2.1.2.cmml" xref="alg1.l6.m1.4.4.2.1.2"></times><ci id="alg1.l6.m1.4.4.2.1.3.cmml" xref="alg1.l6.m1.4.4.2.1.3">𝒈</ci><apply id="alg1.l6.m1.4.4.2.1.1.1.1.cmml" xref="alg1.l6.m1.4.4.2.1.1.1"><csymbol cd="ambiguous" id="alg1.l6.m1.4.4.2.1.1.1.1.1.cmml" xref="alg1.l6.m1.4.4.2.1.1.1">subscript</csymbol><ci id="alg1.l6.m1.4.4.2.1.1.1.1.2.cmml" xref="alg1.l6.m1.4.4.2.1.1.1.1.2">𝒙</ci><ci id="alg1.l6.m1.4.4.2.1.1.1.1.3.cmml" xref="alg1.l6.m1.4.4.2.1.1.1.1.3">𝑖</ci></apply></apply><apply id="alg1.l6.m1.5.5.3.2.2.cmml" xref="alg1.l6.m1.5.5.3.2.1"><max id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"></max><cn id="alg1.l6.m1.2.2.cmml" type="integer" xref="alg1.l6.m1.2.2">1</cn><apply id="alg1.l6.m1.5.5.3.2.1.1.1.cmml" xref="alg1.l6.m1.5.5.3.2.1.1.1"><divide id="alg1.l6.m1.5.5.3.2.1.1.1.2.cmml" xref="alg1.l6.m1.5.5.3.2.1.1.1.2"></divide><apply id="alg1.l6.m1.5.5.3.2.1.1.1.1.2.cmml" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1"><csymbol cd="latexml" id="alg1.l6.m1.5.5.3.2.1.1.1.1.2.1.cmml" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1.2">norm</csymbol><apply id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.cmml" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1"><times id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.2.cmml" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.2"></times><ci id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.3.cmml" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.3">𝒈</ci><apply id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1.1.cmml" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1.1.2">𝒙</ci><ci id="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="alg1.l6.m1.5.5.3.2.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply><ci id="alg1.l6.m1.5.5.3.2.1.1.1.3.cmml" xref="alg1.l6.m1.5.5.3.2.1.1.1.3">𝐶</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.5c">\bar{\bm{g}}(\bm{x}_{i})\leftarrow\bm{g}(\bm{x}_{i})/\max\left(1,\|\bm{g}(\bm{%
x}_{i})\|/C\right)</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m1.5d">over¯ start_ARG bold_italic_g end_ARG ( bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ← bold_italic_g ( bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) / roman_max ( 1 , ∥ bold_italic_g ( bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ∥ / italic_C )</annotation></semantics></math>
<span class="ltx_text" id="alg1.l6.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l6.1.m1.1"><semantics id="alg1.l6.1.m1.1a"><mo id="alg1.l6.1.m1.1.1" xref="alg1.l6.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l6.1.m1.1b"><ci id="alg1.l6.1.m1.1.1.cmml" xref="alg1.l6.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.1.m1.1d">▷</annotation></semantics></math> Clip gradient
</span>
</div>
<div class="ltx_listingline" id="alg1.l7">
<span class="ltx_tag ltx_tag_listingline">7:</span>         <math alttext="\tilde{\bm{g}}(\bm{x}_{i})\leftarrow\bar{\bm{g}}(\bm{x}_{i})+\mathcal{N}(0,%
\sigma^{2}C^{2}\bm{I})" class="ltx_Math" display="inline" id="alg1.l7.m1.4"><semantics id="alg1.l7.m1.4a"><mrow id="alg1.l7.m1.4.4" xref="alg1.l7.m1.4.4.cmml"><mrow id="alg1.l7.m1.2.2.1" xref="alg1.l7.m1.2.2.1.cmml"><mover accent="true" id="alg1.l7.m1.2.2.1.3" xref="alg1.l7.m1.2.2.1.3.cmml"><mi id="alg1.l7.m1.2.2.1.3.2" xref="alg1.l7.m1.2.2.1.3.2.cmml">𝒈</mi><mo id="alg1.l7.m1.2.2.1.3.1" xref="alg1.l7.m1.2.2.1.3.1.cmml">~</mo></mover><mo id="alg1.l7.m1.2.2.1.2" xref="alg1.l7.m1.2.2.1.2.cmml">⁢</mo><mrow id="alg1.l7.m1.2.2.1.1.1" xref="alg1.l7.m1.2.2.1.1.1.1.cmml"><mo id="alg1.l7.m1.2.2.1.1.1.2" stretchy="false" xref="alg1.l7.m1.2.2.1.1.1.1.cmml">(</mo><msub id="alg1.l7.m1.2.2.1.1.1.1" xref="alg1.l7.m1.2.2.1.1.1.1.cmml"><mi id="alg1.l7.m1.2.2.1.1.1.1.2" xref="alg1.l7.m1.2.2.1.1.1.1.2.cmml">𝒙</mi><mi id="alg1.l7.m1.2.2.1.1.1.1.3" xref="alg1.l7.m1.2.2.1.1.1.1.3.cmml">i</mi></msub><mo id="alg1.l7.m1.2.2.1.1.1.3" stretchy="false" xref="alg1.l7.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l7.m1.4.4.4" stretchy="false" xref="alg1.l7.m1.4.4.4.cmml">←</mo><mrow id="alg1.l7.m1.4.4.3" xref="alg1.l7.m1.4.4.3.cmml"><mrow id="alg1.l7.m1.3.3.2.1" xref="alg1.l7.m1.3.3.2.1.cmml"><mover accent="true" id="alg1.l7.m1.3.3.2.1.3" xref="alg1.l7.m1.3.3.2.1.3.cmml"><mi id="alg1.l7.m1.3.3.2.1.3.2" xref="alg1.l7.m1.3.3.2.1.3.2.cmml">𝒈</mi><mo id="alg1.l7.m1.3.3.2.1.3.1" xref="alg1.l7.m1.3.3.2.1.3.1.cmml">¯</mo></mover><mo id="alg1.l7.m1.3.3.2.1.2" xref="alg1.l7.m1.3.3.2.1.2.cmml">⁢</mo><mrow id="alg1.l7.m1.3.3.2.1.1.1" xref="alg1.l7.m1.3.3.2.1.1.1.1.cmml"><mo id="alg1.l7.m1.3.3.2.1.1.1.2" stretchy="false" xref="alg1.l7.m1.3.3.2.1.1.1.1.cmml">(</mo><msub id="alg1.l7.m1.3.3.2.1.1.1.1" xref="alg1.l7.m1.3.3.2.1.1.1.1.cmml"><mi id="alg1.l7.m1.3.3.2.1.1.1.1.2" xref="alg1.l7.m1.3.3.2.1.1.1.1.2.cmml">𝒙</mi><mi id="alg1.l7.m1.3.3.2.1.1.1.1.3" xref="alg1.l7.m1.3.3.2.1.1.1.1.3.cmml">i</mi></msub><mo id="alg1.l7.m1.3.3.2.1.1.1.3" stretchy="false" xref="alg1.l7.m1.3.3.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l7.m1.4.4.3.3" xref="alg1.l7.m1.4.4.3.3.cmml">+</mo><mrow id="alg1.l7.m1.4.4.3.2" xref="alg1.l7.m1.4.4.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l7.m1.4.4.3.2.3" xref="alg1.l7.m1.4.4.3.2.3.cmml">𝒩</mi><mo id="alg1.l7.m1.4.4.3.2.2" xref="alg1.l7.m1.4.4.3.2.2.cmml">⁢</mo><mrow id="alg1.l7.m1.4.4.3.2.1.1" xref="alg1.l7.m1.4.4.3.2.1.2.cmml"><mo id="alg1.l7.m1.4.4.3.2.1.1.2" stretchy="false" xref="alg1.l7.m1.4.4.3.2.1.2.cmml">(</mo><mn id="alg1.l7.m1.1.1" xref="alg1.l7.m1.1.1.cmml">0</mn><mo id="alg1.l7.m1.4.4.3.2.1.1.3" xref="alg1.l7.m1.4.4.3.2.1.2.cmml">,</mo><mrow id="alg1.l7.m1.4.4.3.2.1.1.1" xref="alg1.l7.m1.4.4.3.2.1.1.1.cmml"><msup id="alg1.l7.m1.4.4.3.2.1.1.1.2" xref="alg1.l7.m1.4.4.3.2.1.1.1.2.cmml"><mi id="alg1.l7.m1.4.4.3.2.1.1.1.2.2" xref="alg1.l7.m1.4.4.3.2.1.1.1.2.2.cmml">σ</mi><mn id="alg1.l7.m1.4.4.3.2.1.1.1.2.3" xref="alg1.l7.m1.4.4.3.2.1.1.1.2.3.cmml">2</mn></msup><mo id="alg1.l7.m1.4.4.3.2.1.1.1.1" xref="alg1.l7.m1.4.4.3.2.1.1.1.1.cmml">⁢</mo><msup id="alg1.l7.m1.4.4.3.2.1.1.1.3" xref="alg1.l7.m1.4.4.3.2.1.1.1.3.cmml"><mi id="alg1.l7.m1.4.4.3.2.1.1.1.3.2" xref="alg1.l7.m1.4.4.3.2.1.1.1.3.2.cmml">C</mi><mn id="alg1.l7.m1.4.4.3.2.1.1.1.3.3" xref="alg1.l7.m1.4.4.3.2.1.1.1.3.3.cmml">2</mn></msup><mo id="alg1.l7.m1.4.4.3.2.1.1.1.1a" xref="alg1.l7.m1.4.4.3.2.1.1.1.1.cmml">⁢</mo><mi id="alg1.l7.m1.4.4.3.2.1.1.1.4" xref="alg1.l7.m1.4.4.3.2.1.1.1.4.cmml">𝑰</mi></mrow><mo id="alg1.l7.m1.4.4.3.2.1.1.4" stretchy="false" xref="alg1.l7.m1.4.4.3.2.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.4b"><apply id="alg1.l7.m1.4.4.cmml" xref="alg1.l7.m1.4.4"><ci id="alg1.l7.m1.4.4.4.cmml" xref="alg1.l7.m1.4.4.4">←</ci><apply id="alg1.l7.m1.2.2.1.cmml" xref="alg1.l7.m1.2.2.1"><times id="alg1.l7.m1.2.2.1.2.cmml" xref="alg1.l7.m1.2.2.1.2"></times><apply id="alg1.l7.m1.2.2.1.3.cmml" xref="alg1.l7.m1.2.2.1.3"><ci id="alg1.l7.m1.2.2.1.3.1.cmml" xref="alg1.l7.m1.2.2.1.3.1">~</ci><ci id="alg1.l7.m1.2.2.1.3.2.cmml" xref="alg1.l7.m1.2.2.1.3.2">𝒈</ci></apply><apply id="alg1.l7.m1.2.2.1.1.1.1.cmml" xref="alg1.l7.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="alg1.l7.m1.2.2.1.1.1.1.1.cmml" xref="alg1.l7.m1.2.2.1.1.1">subscript</csymbol><ci id="alg1.l7.m1.2.2.1.1.1.1.2.cmml" xref="alg1.l7.m1.2.2.1.1.1.1.2">𝒙</ci><ci id="alg1.l7.m1.2.2.1.1.1.1.3.cmml" xref="alg1.l7.m1.2.2.1.1.1.1.3">𝑖</ci></apply></apply><apply id="alg1.l7.m1.4.4.3.cmml" xref="alg1.l7.m1.4.4.3"><plus id="alg1.l7.m1.4.4.3.3.cmml" xref="alg1.l7.m1.4.4.3.3"></plus><apply id="alg1.l7.m1.3.3.2.1.cmml" xref="alg1.l7.m1.3.3.2.1"><times id="alg1.l7.m1.3.3.2.1.2.cmml" xref="alg1.l7.m1.3.3.2.1.2"></times><apply id="alg1.l7.m1.3.3.2.1.3.cmml" xref="alg1.l7.m1.3.3.2.1.3"><ci id="alg1.l7.m1.3.3.2.1.3.1.cmml" xref="alg1.l7.m1.3.3.2.1.3.1">¯</ci><ci id="alg1.l7.m1.3.3.2.1.3.2.cmml" xref="alg1.l7.m1.3.3.2.1.3.2">𝒈</ci></apply><apply id="alg1.l7.m1.3.3.2.1.1.1.1.cmml" xref="alg1.l7.m1.3.3.2.1.1.1"><csymbol cd="ambiguous" id="alg1.l7.m1.3.3.2.1.1.1.1.1.cmml" xref="alg1.l7.m1.3.3.2.1.1.1">subscript</csymbol><ci id="alg1.l7.m1.3.3.2.1.1.1.1.2.cmml" xref="alg1.l7.m1.3.3.2.1.1.1.1.2">𝒙</ci><ci id="alg1.l7.m1.3.3.2.1.1.1.1.3.cmml" xref="alg1.l7.m1.3.3.2.1.1.1.1.3">𝑖</ci></apply></apply><apply id="alg1.l7.m1.4.4.3.2.cmml" xref="alg1.l7.m1.4.4.3.2"><times id="alg1.l7.m1.4.4.3.2.2.cmml" xref="alg1.l7.m1.4.4.3.2.2"></times><ci id="alg1.l7.m1.4.4.3.2.3.cmml" xref="alg1.l7.m1.4.4.3.2.3">𝒩</ci><interval closure="open" id="alg1.l7.m1.4.4.3.2.1.2.cmml" xref="alg1.l7.m1.4.4.3.2.1.1"><cn id="alg1.l7.m1.1.1.cmml" type="integer" xref="alg1.l7.m1.1.1">0</cn><apply id="alg1.l7.m1.4.4.3.2.1.1.1.cmml" xref="alg1.l7.m1.4.4.3.2.1.1.1"><times id="alg1.l7.m1.4.4.3.2.1.1.1.1.cmml" xref="alg1.l7.m1.4.4.3.2.1.1.1.1"></times><apply id="alg1.l7.m1.4.4.3.2.1.1.1.2.cmml" xref="alg1.l7.m1.4.4.3.2.1.1.1.2"><csymbol cd="ambiguous" id="alg1.l7.m1.4.4.3.2.1.1.1.2.1.cmml" xref="alg1.l7.m1.4.4.3.2.1.1.1.2">superscript</csymbol><ci id="alg1.l7.m1.4.4.3.2.1.1.1.2.2.cmml" xref="alg1.l7.m1.4.4.3.2.1.1.1.2.2">𝜎</ci><cn id="alg1.l7.m1.4.4.3.2.1.1.1.2.3.cmml" type="integer" xref="alg1.l7.m1.4.4.3.2.1.1.1.2.3">2</cn></apply><apply id="alg1.l7.m1.4.4.3.2.1.1.1.3.cmml" xref="alg1.l7.m1.4.4.3.2.1.1.1.3"><csymbol cd="ambiguous" id="alg1.l7.m1.4.4.3.2.1.1.1.3.1.cmml" xref="alg1.l7.m1.4.4.3.2.1.1.1.3">superscript</csymbol><ci id="alg1.l7.m1.4.4.3.2.1.1.1.3.2.cmml" xref="alg1.l7.m1.4.4.3.2.1.1.1.3.2">𝐶</ci><cn id="alg1.l7.m1.4.4.3.2.1.1.1.3.3.cmml" type="integer" xref="alg1.l7.m1.4.4.3.2.1.1.1.3.3">2</cn></apply><ci id="alg1.l7.m1.4.4.3.2.1.1.1.4.cmml" xref="alg1.l7.m1.4.4.3.2.1.1.1.4">𝑰</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.4c">\tilde{\bm{g}}(\bm{x}_{i})\leftarrow\bar{\bm{g}}(\bm{x}_{i})+\mathcal{N}(0,%
\sigma^{2}C^{2}\bm{I})</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m1.4d">over~ start_ARG bold_italic_g end_ARG ( bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ← over¯ start_ARG bold_italic_g end_ARG ( bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) + caligraphic_N ( 0 , italic_σ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT bold_italic_I )</annotation></semantics></math>
<span class="ltx_text" id="alg1.l7.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l7.1.m1.1"><semantics id="alg1.l7.1.m1.1a"><mo id="alg1.l7.1.m1.1.1" xref="alg1.l7.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l7.1.m1.1b"><ci id="alg1.l7.1.m1.1.1.cmml" xref="alg1.l7.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.1.m1.1d">▷</annotation></semantics></math> Add noise
      </span>
</div>
<div class="ltx_listingline" id="alg1.l8">
<span class="ltx_tag ltx_tag_listingline">8:</span>      <math alttext="\hat{\bm{g}}\leftarrow\frac{1}{|L|}\sum_{k=1}^{|L|}\tilde{\bm{g}}(\bm{x}_{k})" class="ltx_Math" display="inline" id="alg1.l8.m1.3"><semantics id="alg1.l8.m1.3a"><mrow id="alg1.l8.m1.3.3" xref="alg1.l8.m1.3.3.cmml"><mover accent="true" id="alg1.l8.m1.3.3.3" xref="alg1.l8.m1.3.3.3.cmml"><mi id="alg1.l8.m1.3.3.3.2" xref="alg1.l8.m1.3.3.3.2.cmml">𝒈</mi><mo id="alg1.l8.m1.3.3.3.1" xref="alg1.l8.m1.3.3.3.1.cmml">^</mo></mover><mo id="alg1.l8.m1.3.3.2" stretchy="false" xref="alg1.l8.m1.3.3.2.cmml">←</mo><mrow id="alg1.l8.m1.3.3.1" xref="alg1.l8.m1.3.3.1.cmml"><mfrac id="alg1.l8.m1.1.1" xref="alg1.l8.m1.1.1.cmml"><mn id="alg1.l8.m1.1.1.3" xref="alg1.l8.m1.1.1.3.cmml">1</mn><mrow id="alg1.l8.m1.1.1.1.3" xref="alg1.l8.m1.1.1.1.2.cmml"><mo id="alg1.l8.m1.1.1.1.3.1" stretchy="false" xref="alg1.l8.m1.1.1.1.2.1.cmml">|</mo><mi id="alg1.l8.m1.1.1.1.1" xref="alg1.l8.m1.1.1.1.1.cmml">L</mi><mo id="alg1.l8.m1.1.1.1.3.2" stretchy="false" xref="alg1.l8.m1.1.1.1.2.1.cmml">|</mo></mrow></mfrac><mo id="alg1.l8.m1.3.3.1.2" xref="alg1.l8.m1.3.3.1.2.cmml">⁢</mo><mrow id="alg1.l8.m1.3.3.1.1" xref="alg1.l8.m1.3.3.1.1.cmml"><msubsup id="alg1.l8.m1.3.3.1.1.2" xref="alg1.l8.m1.3.3.1.1.2.cmml"><mo id="alg1.l8.m1.3.3.1.1.2.2.2" xref="alg1.l8.m1.3.3.1.1.2.2.2.cmml">∑</mo><mrow id="alg1.l8.m1.3.3.1.1.2.2.3" xref="alg1.l8.m1.3.3.1.1.2.2.3.cmml"><mi id="alg1.l8.m1.3.3.1.1.2.2.3.2" xref="alg1.l8.m1.3.3.1.1.2.2.3.2.cmml">k</mi><mo id="alg1.l8.m1.3.3.1.1.2.2.3.1" xref="alg1.l8.m1.3.3.1.1.2.2.3.1.cmml">=</mo><mn id="alg1.l8.m1.3.3.1.1.2.2.3.3" xref="alg1.l8.m1.3.3.1.1.2.2.3.3.cmml">1</mn></mrow><mrow id="alg1.l8.m1.2.2.1.3" xref="alg1.l8.m1.2.2.1.2.cmml"><mo id="alg1.l8.m1.2.2.1.3.1" stretchy="false" xref="alg1.l8.m1.2.2.1.2.1.cmml">|</mo><mi id="alg1.l8.m1.2.2.1.1" xref="alg1.l8.m1.2.2.1.1.cmml">L</mi><mo id="alg1.l8.m1.2.2.1.3.2" stretchy="false" xref="alg1.l8.m1.2.2.1.2.1.cmml">|</mo></mrow></msubsup><mrow id="alg1.l8.m1.3.3.1.1.1" xref="alg1.l8.m1.3.3.1.1.1.cmml"><mover accent="true" id="alg1.l8.m1.3.3.1.1.1.3" xref="alg1.l8.m1.3.3.1.1.1.3.cmml"><mi id="alg1.l8.m1.3.3.1.1.1.3.2" xref="alg1.l8.m1.3.3.1.1.1.3.2.cmml">𝒈</mi><mo id="alg1.l8.m1.3.3.1.1.1.3.1" xref="alg1.l8.m1.3.3.1.1.1.3.1.cmml">~</mo></mover><mo id="alg1.l8.m1.3.3.1.1.1.2" xref="alg1.l8.m1.3.3.1.1.1.2.cmml">⁢</mo><mrow id="alg1.l8.m1.3.3.1.1.1.1.1" xref="alg1.l8.m1.3.3.1.1.1.1.1.1.cmml"><mo id="alg1.l8.m1.3.3.1.1.1.1.1.2" stretchy="false" xref="alg1.l8.m1.3.3.1.1.1.1.1.1.cmml">(</mo><msub id="alg1.l8.m1.3.3.1.1.1.1.1.1" xref="alg1.l8.m1.3.3.1.1.1.1.1.1.cmml"><mi id="alg1.l8.m1.3.3.1.1.1.1.1.1.2" xref="alg1.l8.m1.3.3.1.1.1.1.1.1.2.cmml">𝒙</mi><mi id="alg1.l8.m1.3.3.1.1.1.1.1.1.3" xref="alg1.l8.m1.3.3.1.1.1.1.1.1.3.cmml">k</mi></msub><mo id="alg1.l8.m1.3.3.1.1.1.1.1.3" stretchy="false" xref="alg1.l8.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l8.m1.3b"><apply id="alg1.l8.m1.3.3.cmml" xref="alg1.l8.m1.3.3"><ci id="alg1.l8.m1.3.3.2.cmml" xref="alg1.l8.m1.3.3.2">←</ci><apply id="alg1.l8.m1.3.3.3.cmml" xref="alg1.l8.m1.3.3.3"><ci id="alg1.l8.m1.3.3.3.1.cmml" xref="alg1.l8.m1.3.3.3.1">^</ci><ci id="alg1.l8.m1.3.3.3.2.cmml" xref="alg1.l8.m1.3.3.3.2">𝒈</ci></apply><apply id="alg1.l8.m1.3.3.1.cmml" xref="alg1.l8.m1.3.3.1"><times id="alg1.l8.m1.3.3.1.2.cmml" xref="alg1.l8.m1.3.3.1.2"></times><apply id="alg1.l8.m1.1.1.cmml" xref="alg1.l8.m1.1.1"><divide id="alg1.l8.m1.1.1.2.cmml" xref="alg1.l8.m1.1.1"></divide><cn id="alg1.l8.m1.1.1.3.cmml" type="integer" xref="alg1.l8.m1.1.1.3">1</cn><apply id="alg1.l8.m1.1.1.1.2.cmml" xref="alg1.l8.m1.1.1.1.3"><abs id="alg1.l8.m1.1.1.1.2.1.cmml" xref="alg1.l8.m1.1.1.1.3.1"></abs><ci id="alg1.l8.m1.1.1.1.1.cmml" xref="alg1.l8.m1.1.1.1.1">𝐿</ci></apply></apply><apply id="alg1.l8.m1.3.3.1.1.cmml" xref="alg1.l8.m1.3.3.1.1"><apply id="alg1.l8.m1.3.3.1.1.2.cmml" xref="alg1.l8.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="alg1.l8.m1.3.3.1.1.2.1.cmml" xref="alg1.l8.m1.3.3.1.1.2">superscript</csymbol><apply id="alg1.l8.m1.3.3.1.1.2.2.cmml" xref="alg1.l8.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="alg1.l8.m1.3.3.1.1.2.2.1.cmml" xref="alg1.l8.m1.3.3.1.1.2">subscript</csymbol><sum id="alg1.l8.m1.3.3.1.1.2.2.2.cmml" xref="alg1.l8.m1.3.3.1.1.2.2.2"></sum><apply id="alg1.l8.m1.3.3.1.1.2.2.3.cmml" xref="alg1.l8.m1.3.3.1.1.2.2.3"><eq id="alg1.l8.m1.3.3.1.1.2.2.3.1.cmml" xref="alg1.l8.m1.3.3.1.1.2.2.3.1"></eq><ci id="alg1.l8.m1.3.3.1.1.2.2.3.2.cmml" xref="alg1.l8.m1.3.3.1.1.2.2.3.2">𝑘</ci><cn id="alg1.l8.m1.3.3.1.1.2.2.3.3.cmml" type="integer" xref="alg1.l8.m1.3.3.1.1.2.2.3.3">1</cn></apply></apply><apply id="alg1.l8.m1.2.2.1.2.cmml" xref="alg1.l8.m1.2.2.1.3"><abs id="alg1.l8.m1.2.2.1.2.1.cmml" xref="alg1.l8.m1.2.2.1.3.1"></abs><ci id="alg1.l8.m1.2.2.1.1.cmml" xref="alg1.l8.m1.2.2.1.1">𝐿</ci></apply></apply><apply id="alg1.l8.m1.3.3.1.1.1.cmml" xref="alg1.l8.m1.3.3.1.1.1"><times id="alg1.l8.m1.3.3.1.1.1.2.cmml" xref="alg1.l8.m1.3.3.1.1.1.2"></times><apply id="alg1.l8.m1.3.3.1.1.1.3.cmml" xref="alg1.l8.m1.3.3.1.1.1.3"><ci id="alg1.l8.m1.3.3.1.1.1.3.1.cmml" xref="alg1.l8.m1.3.3.1.1.1.3.1">~</ci><ci id="alg1.l8.m1.3.3.1.1.1.3.2.cmml" xref="alg1.l8.m1.3.3.1.1.1.3.2">𝒈</ci></apply><apply id="alg1.l8.m1.3.3.1.1.1.1.1.1.cmml" xref="alg1.l8.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l8.m1.3.3.1.1.1.1.1.1.1.cmml" xref="alg1.l8.m1.3.3.1.1.1.1.1">subscript</csymbol><ci id="alg1.l8.m1.3.3.1.1.1.1.1.1.2.cmml" xref="alg1.l8.m1.3.3.1.1.1.1.1.1.2">𝒙</ci><ci id="alg1.l8.m1.3.3.1.1.1.1.1.1.3.cmml" xref="alg1.l8.m1.3.3.1.1.1.1.1.1.3">𝑘</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m1.3c">\hat{\bm{g}}\leftarrow\frac{1}{|L|}\sum_{k=1}^{|L|}\tilde{\bm{g}}(\bm{x}_{k})</annotation><annotation encoding="application/x-llamapun" id="alg1.l8.m1.3d">over^ start_ARG bold_italic_g end_ARG ← divide start_ARG 1 end_ARG start_ARG | italic_L | end_ARG ∑ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT | italic_L | end_POSTSUPERSCRIPT over~ start_ARG bold_italic_g end_ARG ( bold_italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT )</annotation></semantics></math>
<span class="ltx_text" id="alg1.l8.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l8.1.m1.1"><semantics id="alg1.l8.1.m1.1a"><mo id="alg1.l8.1.m1.1.1" xref="alg1.l8.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l8.1.m1.1b"><ci id="alg1.l8.1.m1.1.1.cmml" xref="alg1.l8.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg1.l8.1.m1.1d">▷</annotation></semantics></math> Gradient estimate of ‘lot’ by averaging
</span>
</div>
<div class="ltx_listingline" id="alg1.l9">
<span class="ltx_tag ltx_tag_listingline">9:</span>      <math alttext="\Theta_{t+1}\leftarrow\Theta_{t}-\eta_{t}\hat{\bm{g}}" class="ltx_Math" display="inline" id="alg1.l9.m1.1"><semantics id="alg1.l9.m1.1a"><mrow id="alg1.l9.m1.1.1" xref="alg1.l9.m1.1.1.cmml"><msub id="alg1.l9.m1.1.1.2" xref="alg1.l9.m1.1.1.2.cmml"><mi id="alg1.l9.m1.1.1.2.2" mathvariant="normal" xref="alg1.l9.m1.1.1.2.2.cmml">Θ</mi><mrow id="alg1.l9.m1.1.1.2.3" xref="alg1.l9.m1.1.1.2.3.cmml"><mi id="alg1.l9.m1.1.1.2.3.2" xref="alg1.l9.m1.1.1.2.3.2.cmml">t</mi><mo id="alg1.l9.m1.1.1.2.3.1" xref="alg1.l9.m1.1.1.2.3.1.cmml">+</mo><mn id="alg1.l9.m1.1.1.2.3.3" xref="alg1.l9.m1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo id="alg1.l9.m1.1.1.1" stretchy="false" xref="alg1.l9.m1.1.1.1.cmml">←</mo><mrow id="alg1.l9.m1.1.1.3" xref="alg1.l9.m1.1.1.3.cmml"><msub id="alg1.l9.m1.1.1.3.2" xref="alg1.l9.m1.1.1.3.2.cmml"><mi id="alg1.l9.m1.1.1.3.2.2" mathvariant="normal" xref="alg1.l9.m1.1.1.3.2.2.cmml">Θ</mi><mi id="alg1.l9.m1.1.1.3.2.3" xref="alg1.l9.m1.1.1.3.2.3.cmml">t</mi></msub><mo id="alg1.l9.m1.1.1.3.1" xref="alg1.l9.m1.1.1.3.1.cmml">−</mo><mrow id="alg1.l9.m1.1.1.3.3" xref="alg1.l9.m1.1.1.3.3.cmml"><msub id="alg1.l9.m1.1.1.3.3.2" xref="alg1.l9.m1.1.1.3.3.2.cmml"><mi id="alg1.l9.m1.1.1.3.3.2.2" xref="alg1.l9.m1.1.1.3.3.2.2.cmml">η</mi><mi id="alg1.l9.m1.1.1.3.3.2.3" xref="alg1.l9.m1.1.1.3.3.2.3.cmml">t</mi></msub><mo id="alg1.l9.m1.1.1.3.3.1" xref="alg1.l9.m1.1.1.3.3.1.cmml">⁢</mo><mover accent="true" id="alg1.l9.m1.1.1.3.3.3" xref="alg1.l9.m1.1.1.3.3.3.cmml"><mi id="alg1.l9.m1.1.1.3.3.3.2" xref="alg1.l9.m1.1.1.3.3.3.2.cmml">𝒈</mi><mo id="alg1.l9.m1.1.1.3.3.3.1" xref="alg1.l9.m1.1.1.3.3.3.1.cmml">^</mo></mover></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.1b"><apply id="alg1.l9.m1.1.1.cmml" xref="alg1.l9.m1.1.1"><ci id="alg1.l9.m1.1.1.1.cmml" xref="alg1.l9.m1.1.1.1">←</ci><apply id="alg1.l9.m1.1.1.2.cmml" xref="alg1.l9.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.2.1.cmml" xref="alg1.l9.m1.1.1.2">subscript</csymbol><ci id="alg1.l9.m1.1.1.2.2.cmml" xref="alg1.l9.m1.1.1.2.2">Θ</ci><apply id="alg1.l9.m1.1.1.2.3.cmml" xref="alg1.l9.m1.1.1.2.3"><plus id="alg1.l9.m1.1.1.2.3.1.cmml" xref="alg1.l9.m1.1.1.2.3.1"></plus><ci id="alg1.l9.m1.1.1.2.3.2.cmml" xref="alg1.l9.m1.1.1.2.3.2">𝑡</ci><cn id="alg1.l9.m1.1.1.2.3.3.cmml" type="integer" xref="alg1.l9.m1.1.1.2.3.3">1</cn></apply></apply><apply id="alg1.l9.m1.1.1.3.cmml" xref="alg1.l9.m1.1.1.3"><minus id="alg1.l9.m1.1.1.3.1.cmml" xref="alg1.l9.m1.1.1.3.1"></minus><apply id="alg1.l9.m1.1.1.3.2.cmml" xref="alg1.l9.m1.1.1.3.2"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.2.1.cmml" xref="alg1.l9.m1.1.1.3.2">subscript</csymbol><ci id="alg1.l9.m1.1.1.3.2.2.cmml" xref="alg1.l9.m1.1.1.3.2.2">Θ</ci><ci id="alg1.l9.m1.1.1.3.2.3.cmml" xref="alg1.l9.m1.1.1.3.2.3">𝑡</ci></apply><apply id="alg1.l9.m1.1.1.3.3.cmml" xref="alg1.l9.m1.1.1.3.3"><times id="alg1.l9.m1.1.1.3.3.1.cmml" xref="alg1.l9.m1.1.1.3.3.1"></times><apply id="alg1.l9.m1.1.1.3.3.2.cmml" xref="alg1.l9.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.3.2.1.cmml" xref="alg1.l9.m1.1.1.3.3.2">subscript</csymbol><ci id="alg1.l9.m1.1.1.3.3.2.2.cmml" xref="alg1.l9.m1.1.1.3.3.2.2">𝜂</ci><ci id="alg1.l9.m1.1.1.3.3.2.3.cmml" xref="alg1.l9.m1.1.1.3.3.2.3">𝑡</ci></apply><apply id="alg1.l9.m1.1.1.3.3.3.cmml" xref="alg1.l9.m1.1.1.3.3.3"><ci id="alg1.l9.m1.1.1.3.3.3.1.cmml" xref="alg1.l9.m1.1.1.3.3.3.1">^</ci><ci id="alg1.l9.m1.1.1.3.3.3.2.cmml" xref="alg1.l9.m1.1.1.3.3.3.2">𝒈</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.1c">\Theta_{t+1}\leftarrow\Theta_{t}-\eta_{t}\hat{\bm{g}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l9.m1.1d">roman_Θ start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT ← roman_Θ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - italic_η start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT over^ start_ARG bold_italic_g end_ARG</annotation></semantics></math>
<span class="ltx_text" id="alg1.l9.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l9.1.m1.1"><semantics id="alg1.l9.1.m1.1a"><mo id="alg1.l9.1.m1.1.1" xref="alg1.l9.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l9.1.m1.1b"><ci id="alg1.l9.1.m1.1.1.cmml" xref="alg1.l9.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg1.l9.1.m1.1d">▷</annotation></semantics></math> Update parameters by gradient descent
   </span>
</div>
<div class="ltx_listingline" id="alg1.l10">
<span class="ltx_tag ltx_tag_listingline">10:</span>   <span class="ltx_text ltx_font_bold" id="alg1.l10.1">return</span> <math alttext="\Theta" class="ltx_Math" display="inline" id="alg1.l10.m1.1"><semantics id="alg1.l10.m1.1a"><mi id="alg1.l10.m1.1.1" mathvariant="normal" xref="alg1.l10.m1.1.1.cmml">Θ</mi><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.1b"><ci id="alg1.l10.m1.1.1.cmml" xref="alg1.l10.m1.1.1">Θ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.1c">\Theta</annotation><annotation encoding="application/x-llamapun" id="alg1.l10.m1.1d">roman_Θ</annotation></semantics></math>
</div>
</div>
</figure>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Hyperparameters</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.10">We present our hyperparameter search space as follows.
We experiment with learning rates in the range <math alttext="[10^{-5},0.01]" class="ltx_Math" display="inline" id="A2.p1.1.m1.2"><semantics id="A2.p1.1.m1.2a"><mrow id="A2.p1.1.m1.2.2.1" xref="A2.p1.1.m1.2.2.2.cmml"><mo id="A2.p1.1.m1.2.2.1.2" stretchy="false" xref="A2.p1.1.m1.2.2.2.cmml">[</mo><msup id="A2.p1.1.m1.2.2.1.1" xref="A2.p1.1.m1.2.2.1.1.cmml"><mn id="A2.p1.1.m1.2.2.1.1.2" xref="A2.p1.1.m1.2.2.1.1.2.cmml">10</mn><mrow id="A2.p1.1.m1.2.2.1.1.3" xref="A2.p1.1.m1.2.2.1.1.3.cmml"><mo id="A2.p1.1.m1.2.2.1.1.3a" xref="A2.p1.1.m1.2.2.1.1.3.cmml">−</mo><mn id="A2.p1.1.m1.2.2.1.1.3.2" xref="A2.p1.1.m1.2.2.1.1.3.2.cmml">5</mn></mrow></msup><mo id="A2.p1.1.m1.2.2.1.3" xref="A2.p1.1.m1.2.2.2.cmml">,</mo><mn id="A2.p1.1.m1.1.1" xref="A2.p1.1.m1.1.1.cmml">0.01</mn><mo id="A2.p1.1.m1.2.2.1.4" stretchy="false" xref="A2.p1.1.m1.2.2.2.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.1.m1.2b"><interval closure="closed" id="A2.p1.1.m1.2.2.2.cmml" xref="A2.p1.1.m1.2.2.1"><apply id="A2.p1.1.m1.2.2.1.1.cmml" xref="A2.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="A2.p1.1.m1.2.2.1.1.1.cmml" xref="A2.p1.1.m1.2.2.1.1">superscript</csymbol><cn id="A2.p1.1.m1.2.2.1.1.2.cmml" type="integer" xref="A2.p1.1.m1.2.2.1.1.2">10</cn><apply id="A2.p1.1.m1.2.2.1.1.3.cmml" xref="A2.p1.1.m1.2.2.1.1.3"><minus id="A2.p1.1.m1.2.2.1.1.3.1.cmml" xref="A2.p1.1.m1.2.2.1.1.3"></minus><cn id="A2.p1.1.m1.2.2.1.1.3.2.cmml" type="integer" xref="A2.p1.1.m1.2.2.1.1.3.2">5</cn></apply></apply><cn id="A2.p1.1.m1.1.1.cmml" type="float" xref="A2.p1.1.m1.1.1">0.01</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.1.m1.2c">[10^{-5},0.01]</annotation><annotation encoding="application/x-llamapun" id="A2.p1.1.m1.2d">[ 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT , 0.01 ]</annotation></semantics></math> and maximum sequence lengths in <math alttext="[8,64]" class="ltx_Math" display="inline" id="A2.p1.2.m2.2"><semantics id="A2.p1.2.m2.2a"><mrow id="A2.p1.2.m2.2.3.2" xref="A2.p1.2.m2.2.3.1.cmml"><mo id="A2.p1.2.m2.2.3.2.1" stretchy="false" xref="A2.p1.2.m2.2.3.1.cmml">[</mo><mn id="A2.p1.2.m2.1.1" xref="A2.p1.2.m2.1.1.cmml">8</mn><mo id="A2.p1.2.m2.2.3.2.2" xref="A2.p1.2.m2.2.3.1.cmml">,</mo><mn id="A2.p1.2.m2.2.2" xref="A2.p1.2.m2.2.2.cmml">64</mn><mo id="A2.p1.2.m2.2.3.2.3" stretchy="false" xref="A2.p1.2.m2.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.2.m2.2b"><interval closure="closed" id="A2.p1.2.m2.2.3.1.cmml" xref="A2.p1.2.m2.2.3.2"><cn id="A2.p1.2.m2.1.1.cmml" type="integer" xref="A2.p1.2.m2.1.1">8</cn><cn id="A2.p1.2.m2.2.2.cmml" type="integer" xref="A2.p1.2.m2.2.2">64</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.2.m2.2c">[8,64]</annotation><annotation encoding="application/x-llamapun" id="A2.p1.2.m2.2d">[ 8 , 64 ]</annotation></semantics></math>.
Following previous work, we utilize large batch and lot sizes for our experiments, finding <math alttext="1,048,576" class="ltx_Math" display="inline" id="A2.p1.3.m3.3"><semantics id="A2.p1.3.m3.3a"><mrow id="A2.p1.3.m3.3.4.2" xref="A2.p1.3.m3.3.4.1.cmml"><mn id="A2.p1.3.m3.1.1" xref="A2.p1.3.m3.1.1.cmml">1</mn><mo id="A2.p1.3.m3.3.4.2.1" xref="A2.p1.3.m3.3.4.1.cmml">,</mo><mn id="A2.p1.3.m3.2.2" xref="A2.p1.3.m3.2.2.cmml">048</mn><mo id="A2.p1.3.m3.3.4.2.2" xref="A2.p1.3.m3.3.4.1.cmml">,</mo><mn id="A2.p1.3.m3.3.3" xref="A2.p1.3.m3.3.3.cmml">576</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.3.m3.3b"><list id="A2.p1.3.m3.3.4.1.cmml" xref="A2.p1.3.m3.3.4.2"><cn id="A2.p1.3.m3.1.1.cmml" type="integer" xref="A2.p1.3.m3.1.1">1</cn><cn id="A2.p1.3.m3.2.2.cmml" type="integer" xref="A2.p1.3.m3.2.2">048</cn><cn id="A2.p1.3.m3.3.3.cmml" type="integer" xref="A2.p1.3.m3.3.3">576</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.3.m3.3c">1,048,576</annotation><annotation encoding="application/x-llamapun" id="A2.p1.3.m3.3d">1 , 048 , 576</annotation></semantics></math> to be the best for WMT-16, <math alttext="2,048" class="ltx_Math" display="inline" id="A2.p1.4.m4.2"><semantics id="A2.p1.4.m4.2a"><mrow id="A2.p1.4.m4.2.3.2" xref="A2.p1.4.m4.2.3.1.cmml"><mn id="A2.p1.4.m4.1.1" xref="A2.p1.4.m4.1.1.cmml">2</mn><mo id="A2.p1.4.m4.2.3.2.1" xref="A2.p1.4.m4.2.3.1.cmml">,</mo><mn id="A2.p1.4.m4.2.2" xref="A2.p1.4.m4.2.2.cmml">048</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.4.m4.2b"><list id="A2.p1.4.m4.2.3.1.cmml" xref="A2.p1.4.m4.2.3.2"><cn id="A2.p1.4.m4.1.1.cmml" type="integer" xref="A2.p1.4.m4.1.1">2</cn><cn id="A2.p1.4.m4.2.2.cmml" type="integer" xref="A2.p1.4.m4.2.2">048</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.4.m4.2c">2,048</annotation><annotation encoding="application/x-llamapun" id="A2.p1.4.m4.2d">2 , 048</annotation></semantics></math> for BSD, and <math alttext="256" class="ltx_Math" display="inline" id="A2.p1.5.m5.1"><semantics id="A2.p1.5.m5.1a"><mn id="A2.p1.5.m5.1.1" xref="A2.p1.5.m5.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="A2.p1.5.m5.1b"><cn id="A2.p1.5.m5.1.1.cmml" type="integer" xref="A2.p1.5.m5.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.5.m5.1c">256</annotation><annotation encoding="application/x-llamapun" id="A2.p1.5.m5.1d">256</annotation></semantics></math> for ClinSPEn-CC.
We build up these batch sizes using gradient accumulation with a physical batch size of <math alttext="16" class="ltx_Math" display="inline" id="A2.p1.6.m6.1"><semantics id="A2.p1.6.m6.1a"><mn id="A2.p1.6.m6.1.1" xref="A2.p1.6.m6.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A2.p1.6.m6.1b"><cn id="A2.p1.6.m6.1.1.cmml" type="integer" xref="A2.p1.6.m6.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.6.m6.1c">16</annotation><annotation encoding="application/x-llamapun" id="A2.p1.6.m6.1d">16</annotation></semantics></math>.
In the case of Poisson sampling, we first sample using large lot sizes and build the resulting drawn batch using gradient accumulation, as described in Section <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#S4" title="4 Description of software ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>.
We train models for up to <math alttext="25" class="ltx_Math" display="inline" id="A2.p1.7.m7.1"><semantics id="A2.p1.7.m7.1a"><mn id="A2.p1.7.m7.1.1" xref="A2.p1.7.m7.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="A2.p1.7.m7.1b"><cn id="A2.p1.7.m7.1.1.cmml" type="integer" xref="A2.p1.7.m7.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.7.m7.1c">25</annotation><annotation encoding="application/x-llamapun" id="A2.p1.7.m7.1d">25</annotation></semantics></math> epochs, using the same definition for <span class="ltx_text ltx_font_italic" id="A2.p1.10.1">epochs</span> as in <cite class="ltx_cite ltx_citemacro_citet">Abadi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#bib.bib2" title="">2016b</a>)</cite> in the Poisson sampling setting, being <math alttext="\frac{N}{L}" class="ltx_Math" display="inline" id="A2.p1.8.m8.1"><semantics id="A2.p1.8.m8.1a"><mfrac id="A2.p1.8.m8.1.1" xref="A2.p1.8.m8.1.1.cmml"><mi id="A2.p1.8.m8.1.1.2" xref="A2.p1.8.m8.1.1.2.cmml">N</mi><mi id="A2.p1.8.m8.1.1.3" xref="A2.p1.8.m8.1.1.3.cmml">L</mi></mfrac><annotation-xml encoding="MathML-Content" id="A2.p1.8.m8.1b"><apply id="A2.p1.8.m8.1.1.cmml" xref="A2.p1.8.m8.1.1"><divide id="A2.p1.8.m8.1.1.1.cmml" xref="A2.p1.8.m8.1.1"></divide><ci id="A2.p1.8.m8.1.1.2.cmml" xref="A2.p1.8.m8.1.1.2">𝑁</ci><ci id="A2.p1.8.m8.1.1.3.cmml" xref="A2.p1.8.m8.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.8.m8.1c">\frac{N}{L}</annotation><annotation encoding="application/x-llamapun" id="A2.p1.8.m8.1d">divide start_ARG italic_N end_ARG start_ARG italic_L end_ARG</annotation></semantics></math>. We take the ceiling in case of <math alttext="L" class="ltx_Math" display="inline" id="A2.p1.9.m9.1"><semantics id="A2.p1.9.m9.1a"><mi id="A2.p1.9.m9.1.1" xref="A2.p1.9.m9.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="A2.p1.9.m9.1b"><ci id="A2.p1.9.m9.1.1.cmml" xref="A2.p1.9.m9.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.9.m9.1c">L</annotation><annotation encoding="application/x-llamapun" id="A2.p1.9.m9.1d">italic_L</annotation></semantics></math> not cleanly dividing into <math alttext="N" class="ltx_Math" display="inline" id="A2.p1.10.m10.1"><semantics id="A2.p1.10.m10.1a"><mi id="A2.p1.10.m10.1.1" xref="A2.p1.10.m10.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="A2.p1.10.m10.1b"><ci id="A2.p1.10.m10.1.1.cmml" xref="A2.p1.10.m10.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.10.m10.1c">N</annotation><annotation encoding="application/x-llamapun" id="A2.p1.10.m10.1d">italic_N</annotation></semantics></math>.
Each configuration is run using 5 seeds for the BSD and ClinSPEn-CC datasets and 3 seeds for WMT-16, reporting the mean and standard deviation of results.</p>
</div>
<div class="ltx_para" id="A2.p2">
<p class="ltx_p" id="A2.p2.1">We additionally present our computational runtimes in Table <a class="ltx_ref" href="https://arxiv.org/html/2311.14465v2#A2.T2" title="Table 2 ‣ Appendix B Hyperparameters ‣ DP-NMT: Scalable Differentially-Private Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>.
All experiments are run on up to two 80GB NVIDIA A100 Tensor Core GPUs.</p>
</div>
<figure class="ltx_table" id="A2.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A2.T2.22" style="width:216.8pt;height:315.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-27.7pt,40.3pt) scale(0.796687443131241,0.796687443131241) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.T2.22.22">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="A2.T2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A2.T2.1.1.1.2.1">Dataset</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row" id="A2.T2.1.1.1.1"><math alttext="\varepsilon" class="ltx_Math" display="inline" id="A2.T2.1.1.1.1.m1.1"><semantics id="A2.T2.1.1.1.1.m1.1a"><mi id="A2.T2.1.1.1.1.m1.1.1" xref="A2.T2.1.1.1.1.m1.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="A2.T2.1.1.1.1.m1.1b"><ci id="A2.T2.1.1.1.1.m1.1.1.cmml" xref="A2.T2.1.1.1.1.m1.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.1.1.1.1.m1.1c">\varepsilon</annotation><annotation encoding="application/x-llamapun" id="A2.T2.1.1.1.1.m1.1d">italic_ε</annotation></semantics></math></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r" id="A2.T2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A2.T2.1.1.1.3.1">Iteration Method</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="A2.T2.1.1.1.4"><span class="ltx_text ltx_font_bold" id="A2.T2.1.1.1.4.1">Epoch Time</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T2.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A2.T2.2.2.2.2">WMT-16</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t" id="A2.T2.2.2.2.1"><math alttext="\infty" class="ltx_Math" display="inline" id="A2.T2.2.2.2.1.m1.1"><semantics id="A2.T2.2.2.2.1.m1.1a"><mi id="A2.T2.2.2.2.1.m1.1.1" mathvariant="normal" xref="A2.T2.2.2.2.1.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="A2.T2.2.2.2.1.m1.1b"><infinity id="A2.T2.2.2.2.1.m1.1.1.cmml" xref="A2.T2.2.2.2.1.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.2.2.2.1.m1.1c">\infty</annotation><annotation encoding="application/x-llamapun" id="A2.T2.2.2.2.1.m1.1d">∞</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="A2.T2.2.2.2.3">Random shuffling</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A2.T2.2.2.2.4">2 h 45 m 08 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.3.3.3.2">WMT-16</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.3.3.3.1"><math alttext="1000" class="ltx_Math" display="inline" id="A2.T2.3.3.3.1.m1.1"><semantics id="A2.T2.3.3.3.1.m1.1a"><mn id="A2.T2.3.3.3.1.m1.1.1" xref="A2.T2.3.3.3.1.m1.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A2.T2.3.3.3.1.m1.1b"><cn id="A2.T2.3.3.3.1.m1.1.1.cmml" type="integer" xref="A2.T2.3.3.3.1.m1.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.3.3.3.1.m1.1c">1000</annotation><annotation encoding="application/x-llamapun" id="A2.T2.3.3.3.1.m1.1d">1000</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.3.3.3.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.3.3.3.4">2 h 59 m 15 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.4.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.4.4.4.2">WMT-16</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.4.4.4.1"><math alttext="1000" class="ltx_Math" display="inline" id="A2.T2.4.4.4.1.m1.1"><semantics id="A2.T2.4.4.4.1.m1.1a"><mn id="A2.T2.4.4.4.1.m1.1.1" xref="A2.T2.4.4.4.1.m1.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A2.T2.4.4.4.1.m1.1b"><cn id="A2.T2.4.4.4.1.m1.1.1.cmml" type="integer" xref="A2.T2.4.4.4.1.m1.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.4.4.4.1.m1.1c">1000</annotation><annotation encoding="application/x-llamapun" id="A2.T2.4.4.4.1.m1.1d">1000</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.4.4.4.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.4.4.4.4">4 h 08 m 01 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.5.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.5.5.5.2">WMT-16</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.5.5.5.1"><math alttext="5" class="ltx_Math" display="inline" id="A2.T2.5.5.5.1.m1.1"><semantics id="A2.T2.5.5.5.1.m1.1a"><mn id="A2.T2.5.5.5.1.m1.1.1" xref="A2.T2.5.5.5.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A2.T2.5.5.5.1.m1.1b"><cn id="A2.T2.5.5.5.1.m1.1.1.cmml" type="integer" xref="A2.T2.5.5.5.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.5.5.5.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="A2.T2.5.5.5.1.m1.1d">5</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.5.5.5.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.5.5.5.4">1 h 30 m 03 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.6.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.6.6.6.2">WMT-16</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.6.6.6.1"><math alttext="5" class="ltx_Math" display="inline" id="A2.T2.6.6.6.1.m1.1"><semantics id="A2.T2.6.6.6.1.m1.1a"><mn id="A2.T2.6.6.6.1.m1.1.1" xref="A2.T2.6.6.6.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A2.T2.6.6.6.1.m1.1b"><cn id="A2.T2.6.6.6.1.m1.1.1.cmml" type="integer" xref="A2.T2.6.6.6.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.6.6.6.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="A2.T2.6.6.6.1.m1.1d">5</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.6.6.6.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.6.6.6.4">4 h 02 m 35 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.7.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.7.7.7.2">WMT-16</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.7.7.7.1"><math alttext="1" class="ltx_Math" display="inline" id="A2.T2.7.7.7.1.m1.1"><semantics id="A2.T2.7.7.7.1.m1.1a"><mn id="A2.T2.7.7.7.1.m1.1.1" xref="A2.T2.7.7.7.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A2.T2.7.7.7.1.m1.1b"><cn id="A2.T2.7.7.7.1.m1.1.1.cmml" type="integer" xref="A2.T2.7.7.7.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.7.7.7.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="A2.T2.7.7.7.1.m1.1d">1</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.7.7.7.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.7.7.7.4">1 h 29 m 49 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.8.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.8.8.8.2">WMT-16</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.8.8.8.1"><math alttext="1" class="ltx_Math" display="inline" id="A2.T2.8.8.8.1.m1.1"><semantics id="A2.T2.8.8.8.1.m1.1a"><mn id="A2.T2.8.8.8.1.m1.1.1" xref="A2.T2.8.8.8.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A2.T2.8.8.8.1.m1.1b"><cn id="A2.T2.8.8.8.1.m1.1.1.cmml" type="integer" xref="A2.T2.8.8.8.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.8.8.8.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="A2.T2.8.8.8.1.m1.1d">1</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.8.8.8.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.8.8.8.4">4 h 09 m 02 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.9.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.9.9.9.2">BSD</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.9.9.9.1"><math alttext="\infty" class="ltx_Math" display="inline" id="A2.T2.9.9.9.1.m1.1"><semantics id="A2.T2.9.9.9.1.m1.1a"><mi id="A2.T2.9.9.9.1.m1.1.1" mathvariant="normal" xref="A2.T2.9.9.9.1.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="A2.T2.9.9.9.1.m1.1b"><infinity id="A2.T2.9.9.9.1.m1.1.1.cmml" xref="A2.T2.9.9.9.1.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.9.9.9.1.m1.1c">\infty</annotation><annotation encoding="application/x-llamapun" id="A2.T2.9.9.9.1.m1.1d">∞</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.9.9.9.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.9.9.9.4">0 h 01 m 17 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.10.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.10.10.10.2">BSD</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.10.10.10.1"><math alttext="1000" class="ltx_Math" display="inline" id="A2.T2.10.10.10.1.m1.1"><semantics id="A2.T2.10.10.10.1.m1.1a"><mn id="A2.T2.10.10.10.1.m1.1.1" xref="A2.T2.10.10.10.1.m1.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A2.T2.10.10.10.1.m1.1b"><cn id="A2.T2.10.10.10.1.m1.1.1.cmml" type="integer" xref="A2.T2.10.10.10.1.m1.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.10.10.10.1.m1.1c">1000</annotation><annotation encoding="application/x-llamapun" id="A2.T2.10.10.10.1.m1.1d">1000</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.10.10.10.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.10.10.10.4">0 h 01 m 59 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.11.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.11.11.11.2">BSD</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.11.11.11.1"><math alttext="1000" class="ltx_Math" display="inline" id="A2.T2.11.11.11.1.m1.1"><semantics id="A2.T2.11.11.11.1.m1.1a"><mn id="A2.T2.11.11.11.1.m1.1.1" xref="A2.T2.11.11.11.1.m1.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A2.T2.11.11.11.1.m1.1b"><cn id="A2.T2.11.11.11.1.m1.1.1.cmml" type="integer" xref="A2.T2.11.11.11.1.m1.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.11.11.11.1.m1.1c">1000</annotation><annotation encoding="application/x-llamapun" id="A2.T2.11.11.11.1.m1.1d">1000</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.11.11.11.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.11.11.11.4">0 h 01 m 49 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.12.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.12.12.12.2">BSD</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.12.12.12.1"><math alttext="5" class="ltx_Math" display="inline" id="A2.T2.12.12.12.1.m1.1"><semantics id="A2.T2.12.12.12.1.m1.1a"><mn id="A2.T2.12.12.12.1.m1.1.1" xref="A2.T2.12.12.12.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A2.T2.12.12.12.1.m1.1b"><cn id="A2.T2.12.12.12.1.m1.1.1.cmml" type="integer" xref="A2.T2.12.12.12.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.12.12.12.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="A2.T2.12.12.12.1.m1.1d">5</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.12.12.12.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.12.12.12.4">0 h 00 m 52 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.13.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.13.13.13.2">BSD</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.13.13.13.1"><math alttext="5" class="ltx_Math" display="inline" id="A2.T2.13.13.13.1.m1.1"><semantics id="A2.T2.13.13.13.1.m1.1a"><mn id="A2.T2.13.13.13.1.m1.1.1" xref="A2.T2.13.13.13.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A2.T2.13.13.13.1.m1.1b"><cn id="A2.T2.13.13.13.1.m1.1.1.cmml" type="integer" xref="A2.T2.13.13.13.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.13.13.13.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="A2.T2.13.13.13.1.m1.1d">5</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.13.13.13.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.13.13.13.4">0 h 01 m 49 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.14.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.14.14.14.2">BSD</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.14.14.14.1"><math alttext="1" class="ltx_Math" display="inline" id="A2.T2.14.14.14.1.m1.1"><semantics id="A2.T2.14.14.14.1.m1.1a"><mn id="A2.T2.14.14.14.1.m1.1.1" xref="A2.T2.14.14.14.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A2.T2.14.14.14.1.m1.1b"><cn id="A2.T2.14.14.14.1.m1.1.1.cmml" type="integer" xref="A2.T2.14.14.14.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.14.14.14.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="A2.T2.14.14.14.1.m1.1d">1</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.14.14.14.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.14.14.14.4">0 h 01 m 09 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.15.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.15.15.15.2">BSD</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.15.15.15.1"><math alttext="1" class="ltx_Math" display="inline" id="A2.T2.15.15.15.1.m1.1"><semantics id="A2.T2.15.15.15.1.m1.1a"><mn id="A2.T2.15.15.15.1.m1.1.1" xref="A2.T2.15.15.15.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A2.T2.15.15.15.1.m1.1b"><cn id="A2.T2.15.15.15.1.m1.1.1.cmml" type="integer" xref="A2.T2.15.15.15.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.15.15.15.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="A2.T2.15.15.15.1.m1.1d">1</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.15.15.15.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.15.15.15.4">0 h 02 m 15 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.16.16.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.16.16.16.2">ClinSPEn-CC</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.16.16.16.1"><math alttext="\infty" class="ltx_Math" display="inline" id="A2.T2.16.16.16.1.m1.1"><semantics id="A2.T2.16.16.16.1.m1.1a"><mi id="A2.T2.16.16.16.1.m1.1.1" mathvariant="normal" xref="A2.T2.16.16.16.1.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="A2.T2.16.16.16.1.m1.1b"><infinity id="A2.T2.16.16.16.1.m1.1.1.cmml" xref="A2.T2.16.16.16.1.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.16.16.16.1.m1.1c">\infty</annotation><annotation encoding="application/x-llamapun" id="A2.T2.16.16.16.1.m1.1d">∞</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.16.16.16.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.16.16.16.4">0 h 00 m 09 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.17.17.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.17.17.17.2">ClinSPEn-CC</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.17.17.17.1"><math alttext="1000" class="ltx_Math" display="inline" id="A2.T2.17.17.17.1.m1.1"><semantics id="A2.T2.17.17.17.1.m1.1a"><mn id="A2.T2.17.17.17.1.m1.1.1" xref="A2.T2.17.17.17.1.m1.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A2.T2.17.17.17.1.m1.1b"><cn id="A2.T2.17.17.17.1.m1.1.1.cmml" type="integer" xref="A2.T2.17.17.17.1.m1.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.17.17.17.1.m1.1c">1000</annotation><annotation encoding="application/x-llamapun" id="A2.T2.17.17.17.1.m1.1d">1000</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.17.17.17.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.17.17.17.4">0 h 00 m 05 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.18.18.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.18.18.18.2">ClinSPEn-CC</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.18.18.18.1"><math alttext="1000" class="ltx_Math" display="inline" id="A2.T2.18.18.18.1.m1.1"><semantics id="A2.T2.18.18.18.1.m1.1a"><mn id="A2.T2.18.18.18.1.m1.1.1" xref="A2.T2.18.18.18.1.m1.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A2.T2.18.18.18.1.m1.1b"><cn id="A2.T2.18.18.18.1.m1.1.1.cmml" type="integer" xref="A2.T2.18.18.18.1.m1.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.18.18.18.1.m1.1c">1000</annotation><annotation encoding="application/x-llamapun" id="A2.T2.18.18.18.1.m1.1d">1000</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.18.18.18.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.18.18.18.4">0 h 00 m 28 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.19.19.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.19.19.19.2">ClinSPEn-CC</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.19.19.19.1"><math alttext="5" class="ltx_Math" display="inline" id="A2.T2.19.19.19.1.m1.1"><semantics id="A2.T2.19.19.19.1.m1.1a"><mn id="A2.T2.19.19.19.1.m1.1.1" xref="A2.T2.19.19.19.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A2.T2.19.19.19.1.m1.1b"><cn id="A2.T2.19.19.19.1.m1.1.1.cmml" type="integer" xref="A2.T2.19.19.19.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.19.19.19.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="A2.T2.19.19.19.1.m1.1d">5</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.19.19.19.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.19.19.19.4">0 h 00 m 10 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.20.20.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.20.20.20.2">ClinSPEn-CC</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.20.20.20.1"><math alttext="5" class="ltx_Math" display="inline" id="A2.T2.20.20.20.1.m1.1"><semantics id="A2.T2.20.20.20.1.m1.1a"><mn id="A2.T2.20.20.20.1.m1.1.1" xref="A2.T2.20.20.20.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A2.T2.20.20.20.1.m1.1b"><cn id="A2.T2.20.20.20.1.m1.1.1.cmml" type="integer" xref="A2.T2.20.20.20.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.20.20.20.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="A2.T2.20.20.20.1.m1.1d">5</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.20.20.20.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.20.20.20.4">0 h 00 m 27 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.21.21.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.21.21.21.2">ClinSPEn-CC</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.21.21.21.1"><math alttext="1" class="ltx_Math" display="inline" id="A2.T2.21.21.21.1.m1.1"><semantics id="A2.T2.21.21.21.1.m1.1a"><mn id="A2.T2.21.21.21.1.m1.1.1" xref="A2.T2.21.21.21.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A2.T2.21.21.21.1.m1.1b"><cn id="A2.T2.21.21.21.1.m1.1.1.cmml" type="integer" xref="A2.T2.21.21.21.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.21.21.21.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="A2.T2.21.21.21.1.m1.1d">1</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.21.21.21.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.21.21.21.4">0 h 00 m 15 s</td>
</tr>
<tr class="ltx_tr" id="A2.T2.22.22.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.22.22.22.2">ClinSPEn-CC</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T2.22.22.22.1"><math alttext="1" class="ltx_Math" display="inline" id="A2.T2.22.22.22.1.m1.1"><semantics id="A2.T2.22.22.22.1.m1.1a"><mn id="A2.T2.22.22.22.1.m1.1.1" xref="A2.T2.22.22.22.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A2.T2.22.22.22.1.m1.1b"><cn id="A2.T2.22.22.22.1.m1.1.1.cmml" type="integer" xref="A2.T2.22.22.22.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.22.22.22.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="A2.T2.22.22.22.1.m1.1d">1</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T2.22.22.22.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A2.T2.22.22.22.4">0 h 00 m 27 s</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Sample epoch runtimes for each configuration. Some differences between configurations arise due to different optimal hyperparameters, with larger sequence lengths leading to longer epoch times.</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Detailed Results</h2>
<figure class="ltx_table" id="A3.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A3.T3.22" style="width:303.5pt;height:344.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-22.9pt,25.9pt) scale(0.868958840348962,0.868958840348962) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A3.T3.22.22">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A3.T3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="A3.T3.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.2.1">Dataset</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="A3.T3.1.1.1.1"><math alttext="\varepsilon" class="ltx_Math" display="inline" id="A3.T3.1.1.1.1.m1.1"><semantics id="A3.T3.1.1.1.1.m1.1a"><mi id="A3.T3.1.1.1.1.m1.1.1" xref="A3.T3.1.1.1.1.m1.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="A3.T3.1.1.1.1.m1.1b"><ci id="A3.T3.1.1.1.1.m1.1.1.cmml" xref="A3.T3.1.1.1.1.m1.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.1.1.1.1.m1.1c">\varepsilon</annotation><annotation encoding="application/x-llamapun" id="A3.T3.1.1.1.1.m1.1d">italic_ε</annotation></semantics></math></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r" id="A3.T3.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.3.1">Iteration Method</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="A3.T3.1.1.1.4"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.4.1">Test BLEU</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="A3.T3.1.1.1.5"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.5.1">Test BERTScore</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T3.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="A3.T3.2.2.2.2">WMT-16</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A3.T3.2.2.2.1"><math alttext="\infty" class="ltx_Math" display="inline" id="A3.T3.2.2.2.1.m1.1"><semantics id="A3.T3.2.2.2.1.m1.1a"><mi id="A3.T3.2.2.2.1.m1.1.1" mathvariant="normal" xref="A3.T3.2.2.2.1.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="A3.T3.2.2.2.1.m1.1b"><infinity id="A3.T3.2.2.2.1.m1.1.1.cmml" xref="A3.T3.2.2.2.1.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.2.2.2.1.m1.1c">\infty</annotation><annotation encoding="application/x-llamapun" id="A3.T3.2.2.2.1.m1.1d">∞</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="A3.T3.2.2.2.3">Random shuffling</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A3.T3.2.2.2.4">36.19 (0.13)</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A3.T3.2.2.2.5">0.95 (0.00)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.3.3">
<td class="ltx_td ltx_align_left" id="A3.T3.3.3.3.2">WMT-16</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.3.3.1"><math alttext="1000" class="ltx_Math" display="inline" id="A3.T3.3.3.3.1.m1.1"><semantics id="A3.T3.3.3.3.1.m1.1a"><mn id="A3.T3.3.3.3.1.m1.1.1" xref="A3.T3.3.3.3.1.m1.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A3.T3.3.3.3.1.m1.1b"><cn id="A3.T3.3.3.3.1.m1.1.1.cmml" type="integer" xref="A3.T3.3.3.3.1.m1.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.3.3.3.1.m1.1c">1000</annotation><annotation encoding="application/x-llamapun" id="A3.T3.3.3.3.1.m1.1d">1000</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.3.3.3.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.3.3.4">20.86 (0.56)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.3.3.5">0.92 (0.00)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.4.4.4">
<td class="ltx_td ltx_align_left" id="A3.T3.4.4.4.2">WMT-16</td>
<td class="ltx_td ltx_align_right" id="A3.T3.4.4.4.1"><math alttext="1000" class="ltx_Math" display="inline" id="A3.T3.4.4.4.1.m1.1"><semantics id="A3.T3.4.4.4.1.m1.1a"><mn id="A3.T3.4.4.4.1.m1.1.1" xref="A3.T3.4.4.4.1.m1.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A3.T3.4.4.4.1.m1.1b"><cn id="A3.T3.4.4.4.1.m1.1.1.cmml" type="integer" xref="A3.T3.4.4.4.1.m1.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.4.4.4.1.m1.1c">1000</annotation><annotation encoding="application/x-llamapun" id="A3.T3.4.4.4.1.m1.1d">1000</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.4.4.4.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.4.4.4.4">15.12 (0.08)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.4.4.4.5">0.91 (0.00)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.5.5.5">
<td class="ltx_td ltx_align_left" id="A3.T3.5.5.5.2">WMT-16</td>
<td class="ltx_td ltx_align_right" id="A3.T3.5.5.5.1"><math alttext="5" class="ltx_Math" display="inline" id="A3.T3.5.5.5.1.m1.1"><semantics id="A3.T3.5.5.5.1.m1.1a"><mn id="A3.T3.5.5.5.1.m1.1.1" xref="A3.T3.5.5.5.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A3.T3.5.5.5.1.m1.1b"><cn id="A3.T3.5.5.5.1.m1.1.1.cmml" type="integer" xref="A3.T3.5.5.5.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.5.5.5.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="A3.T3.5.5.5.1.m1.1d">5</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.5.5.5.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.5.5.5.4">19.24 (0.52)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.5.5.5.5">0.92 (0.00)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.6.6.6">
<td class="ltx_td ltx_align_left" id="A3.T3.6.6.6.2">WMT-16</td>
<td class="ltx_td ltx_align_right" id="A3.T3.6.6.6.1"><math alttext="5" class="ltx_Math" display="inline" id="A3.T3.6.6.6.1.m1.1"><semantics id="A3.T3.6.6.6.1.m1.1a"><mn id="A3.T3.6.6.6.1.m1.1.1" xref="A3.T3.6.6.6.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A3.T3.6.6.6.1.m1.1b"><cn id="A3.T3.6.6.6.1.m1.1.1.cmml" type="integer" xref="A3.T3.6.6.6.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.6.6.6.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="A3.T3.6.6.6.1.m1.1d">5</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.6.6.6.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.6.6.6.4">7.23 (0.21)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.6.6.6.5">0.89 (0.00)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.7.7.7">
<td class="ltx_td ltx_align_left" id="A3.T3.7.7.7.2">WMT-16</td>
<td class="ltx_td ltx_align_right" id="A3.T3.7.7.7.1"><math alttext="1" class="ltx_Math" display="inline" id="A3.T3.7.7.7.1.m1.1"><semantics id="A3.T3.7.7.7.1.m1.1a"><mn id="A3.T3.7.7.7.1.m1.1.1" xref="A3.T3.7.7.7.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A3.T3.7.7.7.1.m1.1b"><cn id="A3.T3.7.7.7.1.m1.1.1.cmml" type="integer" xref="A3.T3.7.7.7.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.7.7.7.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="A3.T3.7.7.7.1.m1.1d">1</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.7.7.7.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.7.7.7.4">19.83 (0.64)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.7.7.7.5">0.92 (0.00)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.8.8.8">
<td class="ltx_td ltx_align_left" id="A3.T3.8.8.8.2">WMT-16</td>
<td class="ltx_td ltx_align_right" id="A3.T3.8.8.8.1"><math alttext="1" class="ltx_Math" display="inline" id="A3.T3.8.8.8.1.m1.1"><semantics id="A3.T3.8.8.8.1.m1.1a"><mn id="A3.T3.8.8.8.1.m1.1.1" xref="A3.T3.8.8.8.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A3.T3.8.8.8.1.m1.1b"><cn id="A3.T3.8.8.8.1.m1.1.1.cmml" type="integer" xref="A3.T3.8.8.8.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.8.8.8.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="A3.T3.8.8.8.1.m1.1d">1</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.8.8.8.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.8.8.8.4">2.35 (0.07)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.8.8.8.5">0.84 (0.00)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.9.9.9">
<td class="ltx_td ltx_align_left" id="A3.T3.9.9.9.2">BSD</td>
<td class="ltx_td ltx_align_right" id="A3.T3.9.9.9.1"><math alttext="\infty" class="ltx_Math" display="inline" id="A3.T3.9.9.9.1.m1.1"><semantics id="A3.T3.9.9.9.1.m1.1a"><mi id="A3.T3.9.9.9.1.m1.1.1" mathvariant="normal" xref="A3.T3.9.9.9.1.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="A3.T3.9.9.9.1.m1.1b"><infinity id="A3.T3.9.9.9.1.m1.1.1.cmml" xref="A3.T3.9.9.9.1.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.9.9.9.1.m1.1c">\infty</annotation><annotation encoding="application/x-llamapun" id="A3.T3.9.9.9.1.m1.1d">∞</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.9.9.9.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.9.9.9.4">10.09 (2.75)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.9.9.9.5">0.90 (0.01)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.10.10.10">
<td class="ltx_td ltx_align_left" id="A3.T3.10.10.10.2">BSD</td>
<td class="ltx_td ltx_align_right" id="A3.T3.10.10.10.1"><math alttext="1000" class="ltx_Math" display="inline" id="A3.T3.10.10.10.1.m1.1"><semantics id="A3.T3.10.10.10.1.m1.1a"><mn id="A3.T3.10.10.10.1.m1.1.1" xref="A3.T3.10.10.10.1.m1.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A3.T3.10.10.10.1.m1.1b"><cn id="A3.T3.10.10.10.1.m1.1.1.cmml" type="integer" xref="A3.T3.10.10.10.1.m1.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.10.10.10.1.m1.1c">1000</annotation><annotation encoding="application/x-llamapun" id="A3.T3.10.10.10.1.m1.1d">1000</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.10.10.10.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.10.10.10.4">1.36 (0.67)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.10.10.10.5">0.87 (0.01)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.11.11.11">
<td class="ltx_td ltx_align_left" id="A3.T3.11.11.11.2">BSD</td>
<td class="ltx_td ltx_align_right" id="A3.T3.11.11.11.1"><math alttext="1000" class="ltx_Math" display="inline" id="A3.T3.11.11.11.1.m1.1"><semantics id="A3.T3.11.11.11.1.m1.1a"><mn id="A3.T3.11.11.11.1.m1.1.1" xref="A3.T3.11.11.11.1.m1.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A3.T3.11.11.11.1.m1.1b"><cn id="A3.T3.11.11.11.1.m1.1.1.cmml" type="integer" xref="A3.T3.11.11.11.1.m1.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.11.11.11.1.m1.1c">1000</annotation><annotation encoding="application/x-llamapun" id="A3.T3.11.11.11.1.m1.1d">1000</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.11.11.11.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.11.11.11.4">1.01 (0.07)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.11.11.11.5">0.87 (0.00)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.12.12.12">
<td class="ltx_td ltx_align_left" id="A3.T3.12.12.12.2">BSD</td>
<td class="ltx_td ltx_align_right" id="A3.T3.12.12.12.1"><math alttext="5" class="ltx_Math" display="inline" id="A3.T3.12.12.12.1.m1.1"><semantics id="A3.T3.12.12.12.1.m1.1a"><mn id="A3.T3.12.12.12.1.m1.1.1" xref="A3.T3.12.12.12.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A3.T3.12.12.12.1.m1.1b"><cn id="A3.T3.12.12.12.1.m1.1.1.cmml" type="integer" xref="A3.T3.12.12.12.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.12.12.12.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="A3.T3.12.12.12.1.m1.1d">5</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.12.12.12.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.12.12.12.4">0.06 (0.05)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.12.12.12.5">0.85 (0.01)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.13.13.13">
<td class="ltx_td ltx_align_left" id="A3.T3.13.13.13.2">BSD</td>
<td class="ltx_td ltx_align_right" id="A3.T3.13.13.13.1"><math alttext="5" class="ltx_Math" display="inline" id="A3.T3.13.13.13.1.m1.1"><semantics id="A3.T3.13.13.13.1.m1.1a"><mn id="A3.T3.13.13.13.1.m1.1.1" xref="A3.T3.13.13.13.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A3.T3.13.13.13.1.m1.1b"><cn id="A3.T3.13.13.13.1.m1.1.1.cmml" type="integer" xref="A3.T3.13.13.13.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.13.13.13.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="A3.T3.13.13.13.1.m1.1d">5</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.13.13.13.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.13.13.13.4">0.06 (0.06)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.13.13.13.5">0.84 (0.02)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.14.14.14">
<td class="ltx_td ltx_align_left" id="A3.T3.14.14.14.2">BSD</td>
<td class="ltx_td ltx_align_right" id="A3.T3.14.14.14.1"><math alttext="1" class="ltx_Math" display="inline" id="A3.T3.14.14.14.1.m1.1"><semantics id="A3.T3.14.14.14.1.m1.1a"><mn id="A3.T3.14.14.14.1.m1.1.1" xref="A3.T3.14.14.14.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A3.T3.14.14.14.1.m1.1b"><cn id="A3.T3.14.14.14.1.m1.1.1.cmml" type="integer" xref="A3.T3.14.14.14.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.14.14.14.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="A3.T3.14.14.14.1.m1.1d">1</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.14.14.14.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.14.14.14.4">0.00 (0.01)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.14.14.14.5">0.45 (0.22)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.15.15.15">
<td class="ltx_td ltx_align_left" id="A3.T3.15.15.15.2">BSD</td>
<td class="ltx_td ltx_align_right" id="A3.T3.15.15.15.1"><math alttext="1" class="ltx_Math" display="inline" id="A3.T3.15.15.15.1.m1.1"><semantics id="A3.T3.15.15.15.1.m1.1a"><mn id="A3.T3.15.15.15.1.m1.1.1" xref="A3.T3.15.15.15.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A3.T3.15.15.15.1.m1.1b"><cn id="A3.T3.15.15.15.1.m1.1.1.cmml" type="integer" xref="A3.T3.15.15.15.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.15.15.15.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="A3.T3.15.15.15.1.m1.1d">1</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.15.15.15.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.15.15.15.4">0.00 (0.00)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.15.15.15.5">0.65 (0.15)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.16.16.16">
<td class="ltx_td ltx_align_left" id="A3.T3.16.16.16.2">ClinSPEn-CC</td>
<td class="ltx_td ltx_align_right" id="A3.T3.16.16.16.1"><math alttext="\infty" class="ltx_Math" display="inline" id="A3.T3.16.16.16.1.m1.1"><semantics id="A3.T3.16.16.16.1.m1.1a"><mi id="A3.T3.16.16.16.1.m1.1.1" mathvariant="normal" xref="A3.T3.16.16.16.1.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="A3.T3.16.16.16.1.m1.1b"><infinity id="A3.T3.16.16.16.1.m1.1.1.cmml" xref="A3.T3.16.16.16.1.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.16.16.16.1.m1.1c">\infty</annotation><annotation encoding="application/x-llamapun" id="A3.T3.16.16.16.1.m1.1d">∞</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.16.16.16.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.16.16.16.4">5.42 (2.41)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.16.16.16.5">0.86 (0.02)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.17.17.17">
<td class="ltx_td ltx_align_left" id="A3.T3.17.17.17.2">ClinSPEn-CC</td>
<td class="ltx_td ltx_align_right" id="A3.T3.17.17.17.1"><math alttext="1000" class="ltx_Math" display="inline" id="A3.T3.17.17.17.1.m1.1"><semantics id="A3.T3.17.17.17.1.m1.1a"><mn id="A3.T3.17.17.17.1.m1.1.1" xref="A3.T3.17.17.17.1.m1.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A3.T3.17.17.17.1.m1.1b"><cn id="A3.T3.17.17.17.1.m1.1.1.cmml" type="integer" xref="A3.T3.17.17.17.1.m1.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.17.17.17.1.m1.1c">1000</annotation><annotation encoding="application/x-llamapun" id="A3.T3.17.17.17.1.m1.1d">1000</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.17.17.17.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.17.17.17.4">0.03 (0.02)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.17.17.17.5">0.75 (0.01)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.18.18.18">
<td class="ltx_td ltx_align_left" id="A3.T3.18.18.18.2">ClinSPEn-CC</td>
<td class="ltx_td ltx_align_right" id="A3.T3.18.18.18.1"><math alttext="1000" class="ltx_Math" display="inline" id="A3.T3.18.18.18.1.m1.1"><semantics id="A3.T3.18.18.18.1.m1.1a"><mn id="A3.T3.18.18.18.1.m1.1.1" xref="A3.T3.18.18.18.1.m1.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A3.T3.18.18.18.1.m1.1b"><cn id="A3.T3.18.18.18.1.m1.1.1.cmml" type="integer" xref="A3.T3.18.18.18.1.m1.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.18.18.18.1.m1.1c">1000</annotation><annotation encoding="application/x-llamapun" id="A3.T3.18.18.18.1.m1.1d">1000</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.18.18.18.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.18.18.18.4">0.70 (0.19)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.18.18.18.5">0.78 (0.00)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.19.19.19">
<td class="ltx_td ltx_align_left" id="A3.T3.19.19.19.2">ClinSPEn-CC</td>
<td class="ltx_td ltx_align_right" id="A3.T3.19.19.19.1"><math alttext="5" class="ltx_Math" display="inline" id="A3.T3.19.19.19.1.m1.1"><semantics id="A3.T3.19.19.19.1.m1.1a"><mn id="A3.T3.19.19.19.1.m1.1.1" xref="A3.T3.19.19.19.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A3.T3.19.19.19.1.m1.1b"><cn id="A3.T3.19.19.19.1.m1.1.1.cmml" type="integer" xref="A3.T3.19.19.19.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.19.19.19.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="A3.T3.19.19.19.1.m1.1d">5</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.19.19.19.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.19.19.19.4">0.80 (0.56)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.19.19.19.5">0.79 (0.00)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.20.20.20">
<td class="ltx_td ltx_align_left" id="A3.T3.20.20.20.2">ClinSPEn-CC</td>
<td class="ltx_td ltx_align_right" id="A3.T3.20.20.20.1"><math alttext="5" class="ltx_Math" display="inline" id="A3.T3.20.20.20.1.m1.1"><semantics id="A3.T3.20.20.20.1.m1.1a"><mn id="A3.T3.20.20.20.1.m1.1.1" xref="A3.T3.20.20.20.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A3.T3.20.20.20.1.m1.1b"><cn id="A3.T3.20.20.20.1.m1.1.1.cmml" type="integer" xref="A3.T3.20.20.20.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.20.20.20.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="A3.T3.20.20.20.1.m1.1d">5</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.20.20.20.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.20.20.20.4">0.83 (0.27)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.20.20.20.5">0.79 (0.00)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.21.21.21">
<td class="ltx_td ltx_align_left" id="A3.T3.21.21.21.2">ClinSPEn-CC</td>
<td class="ltx_td ltx_align_right" id="A3.T3.21.21.21.1"><math alttext="1" class="ltx_Math" display="inline" id="A3.T3.21.21.21.1.m1.1"><semantics id="A3.T3.21.21.21.1.m1.1a"><mn id="A3.T3.21.21.21.1.m1.1.1" xref="A3.T3.21.21.21.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A3.T3.21.21.21.1.m1.1b"><cn id="A3.T3.21.21.21.1.m1.1.1.cmml" type="integer" xref="A3.T3.21.21.21.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.21.21.21.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="A3.T3.21.21.21.1.m1.1d">1</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.21.21.21.3">Random shuffling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.21.21.21.4">0.50 (0.20)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.21.21.21.5">0.78 (0.00)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.22.22.22">
<td class="ltx_td ltx_align_left" id="A3.T3.22.22.22.2">ClinSPEn-CC</td>
<td class="ltx_td ltx_align_right" id="A3.T3.22.22.22.1"><math alttext="1" class="ltx_Math" display="inline" id="A3.T3.22.22.22.1.m1.1"><semantics id="A3.T3.22.22.22.1.m1.1a"><mn id="A3.T3.22.22.22.1.m1.1.1" xref="A3.T3.22.22.22.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A3.T3.22.22.22.1.m1.1b"><cn id="A3.T3.22.22.22.1.m1.1.1.cmml" type="integer" xref="A3.T3.22.22.22.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.22.22.22.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="A3.T3.22.22.22.1.m1.1d">1</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A3.T3.22.22.22.3">Poisson sampling</td>
<td class="ltx_td ltx_align_right" id="A3.T3.22.22.22.4">0.54 (0.22)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.22.22.22.5">0.78 (0.00)</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Detailed results of each experimental configuration. Scores shown as “mean (standard deviation)”. Results show the average over 3 seeds for the WMT-16 dataset, and 5 seeds for BSD and ClinSPEn-CC.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Apr 30 19:50:06 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
