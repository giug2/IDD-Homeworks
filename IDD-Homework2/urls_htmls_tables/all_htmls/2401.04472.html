<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2401.04472] A Survey on Efficient Federated Learning Methods for Foundation Model Training</title><meta property="og:description" content="Federated Learning (FL) has become an established technique to facilitate privacy-preserving collaborative training across a multitude of clients.
However, new approaches to FL often discuss their contributions involviâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Survey on Efficient Federated Learning Methods for Foundation Model Training">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Survey on Efficient Federated Learning Methods for Foundation Model Training">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2401.04472">

<!--Generated on Tue Feb 27 10:21:12 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A Survey on Efficient Federated Learning Methods for Foundation Model Training</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Herbert WoisetschlÃ¤ger<sup id="id10.2.id1" class="ltx_sup">1</sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Alexander Isenko<sup id="id11.2.id1" class="ltx_sup">1</sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shiqiang Wang<sup id="id12.2.id1" class="ltx_sup">2</sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<br class="ltx_break">Ruben Mayer<sup id="id13.7.id1" class="ltx_sup">3</sup> &amp;Hans-Arno Jacobsen<sup id="id14.8.id2" class="ltx_sup">4</sup>
<sup id="id15.9.id3" class="ltx_sup">1</sup>Technical University of Munich
<sup id="id16.10.id4" class="ltx_sup">2</sup>IBM Research
<sup id="id17.11.id5" class="ltx_sup">3</sup>University of Bayreuth
<sup id="id18.12.id6" class="ltx_sup">4</sup>University of Toronto
{herbert.woisetschlaeger, alex.isenko}@tum.de,
wangshiq@us.ibm.com,
ruben.mayer@uni-bayreuth.de,
jacobsen@eecg.toronto.edu
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id19.id1" class="ltx_p">Federated Learning (FL) has become an established technique to facilitate privacy-preserving collaborative training across a multitude of clients.
However, new approaches to FL often discuss their contributions involving small deep-learning models only and focus on training full models on clients.
In the wake of Foundation Models (FM), the reality is different for many deep learning applications.
Typically, FMs have already been pre-trained across a wide variety of tasks and can be fine-tuned to specific downstream tasks over significantly smaller datasets than required for full model training.
However, access to such datasets is often challenging.
By its design, FL can help to open data silos.
With this survey, we introduce a novel taxonomy focused on computational and communication efficiency, the vital elements to make use of FMs in FL systems.
We discuss the benefits and drawbacks of parameter-efficient fine-tuning (PEFT) for FL applications, elaborate on the readiness of FL frameworks to work with FMs and provide future research opportunities on how to evaluate generative models in FL as well as the interplay of privacy and PEFT.</p>
</div>
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">{textblock*}</span>
<p id="p1.2" class="ltx_p">5cm(1.52cm,26cm)
Preprint. Under Review.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Foundation Models (FMs) have conquered the deep learning world with unprecedented speed, enabling generative artificial intelligence for a broad audience.
As FMs have been pre-trained on an extensive data basis and can be used in multi-modal applications, they perform well over a wide range of tasks <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Bommasani </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>.
To specialize these models on a downstream task, we use fine-tuning that can either be done over the full model or with parameter-efficient fine-tuning techniques (PEFT) <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Hu </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>); <span class="ltx_text" style="font-size:90%;">Lester </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>); <span class="ltx_text" style="font-size:90%;">Zaken </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>.
A major advantage is that fine-tuning requires orders of magnitude smaller datasets than pre-training but benefits from access to a variety of samples pertaining to a task.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Access to a breadth of data has always been challenging in deep learning, as data owners are typically reluctant to share their data with service providers.
To tackle the data access challenge, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">McMahan </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2017</span></a></cite>] introduced <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">Federated Learning</em> (FL).
FL enables privacy-preserving machine learning over decentralized data without the necessity of sharing input data and not requiring high bandwidth client connections.
Rather, a set of clients collectively train a model and send their local model updates to a server that subsequently aggregates the updates to a global model.
In FL applications that involve small models with less than 1M parameters, we may spend as much time on communication as we spend on computation <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Yousefpour </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>.
However, it is desirable to design systems in such a way that computation takes up the majority of time.
Luckily, the larger models become, the more time we spend on training rather than on communication <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Ryabinin </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>); <span class="ltx_text" style="font-size:90%;">WoisetschlÃ¤ger </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>); <span class="ltx_text" style="font-size:90%;">Beutel </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>.
As such, scaling the model size in FL systems can be desirable, and this introduces beneficial properties that can aid us in training large models with several 100M parameters and beyond.
These properties render FL the perfect choice for fine-tuning FMs for downstream tasks.
FL can provide access to a significantly larger and more diverse data basis while benefiting from the increased computational intensity of FMs over small models.
As the model updates increase in size with FMs, we also require communication efficient FL methods to further reduce the communication times.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Our survey is the first to study advances in computational and communication-efficient methods for <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">FM training</em> in FL applications.
Our work contains three distinct contributions:</p>
</div>
<div id="S1.p4" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">A novel taxonomy on FL methods for FM training focused on the core challenges in computation and communication</span>.
We discover a gap between FL methods to increase computational efficiency for FM training and fine-tuning and communication efficiency techniques, which primarily focus on full models.
Our taxonomy aims to identify synergies between FL methods for FMs and efficient communication methods.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Thorough evaluation of existing FL computational efficiency methods for FMs and communication efficiency techniques</span>.
We study how existing techniques can help drive the adoption of FMs in FL applications and what needs to be done to render FL frameworks ready for large models.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">We thoroughly discuss future research directions</span>.
We highlight future directions for research on computational and communication efficiency as these domains grow closer together.
Also, we show what is necessary to render FMs in FL applications a reality, especially with regard to generative tasks and privacy considerations.</p>
</div>
</li>
</ul>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2401.04472/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="251" height="145" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Our Taxonomy. Foundation Models, in conjunction with Federated Learning, require efficient computational and communication methods.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Taxonomy</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Our taxonomy introduces a novel perspective focused on the current developments in the field of efficient computational and communication methods for FL applications intended for training and fine-tuning FMs. While communication efficiency has been studied extensively in FL, computational advancements in conjunction with large models are currently emerging. Our taxonomy is visualized in <a href="#S1.F1" title="In 1 Introduction â€£ A Survey on Efficient Federated Learning Methods for Foundation Model Training" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Basics of Federated Learning</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">To understand the relevancy of our taxonomy, it is key to briefly introduce the fundamentals of FL and the notations of this paper.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.3" class="ltx_p">Coordinated by a server, the overall goal of FL is to collaboratively and iteratively train a DL model across a set of clients <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mi id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><ci id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">N</annotation></semantics></math> and minimize the global loss, where <math id="S2.SS1.p2.2.m2.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S2.SS1.p2.2.m2.1a"><mi id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">f</annotation></semantics></math> denotes an objective function with parameters <math id="S2.SS1.p2.3.m3.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S2.SS1.p2.3.m3.1a"><mi id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.1b"><ci id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.1c">w</annotation></semantics></math>,</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.3" class="ltx_math_unparsed" alttext="\min_{w}\,f(w)\mathrel{\mathop{\mathchar 58\relax}}=\frac{1}{|N|}\sum_{n=1}^{|N|}f_{n}(w)\mathrm{.}" display="block"><semantics id="S2.E1.m1.3a"><mrow id="S2.E1.m1.3b"><munder id="S2.E1.m1.3.4"><mi id="S2.E1.m1.3.4.2">min</mi><mi id="S2.E1.m1.3.4.3">w</mi></munder><mi id="S2.E1.m1.3.5">f</mi><mrow id="S2.E1.m1.3.6"><mo stretchy="false" id="S2.E1.m1.3.6.1">(</mo><mi id="S2.E1.m1.3.3">w</mi><mo rspace="0.278em" stretchy="false" id="S2.E1.m1.3.6.2">)</mo></mrow><mo rspace="0em" id="S2.E1.m1.3.7">:</mo><mo lspace="0em" id="S2.E1.m1.3.8">=</mo><mfrac id="S2.E1.m1.1.1"><mn id="S2.E1.m1.1.1.3">1</mn><mrow id="S2.E1.m1.1.1.1.3"><mo stretchy="false" id="S2.E1.m1.1.1.1.3.1">|</mo><mi id="S2.E1.m1.1.1.1.1">N</mi><mo stretchy="false" id="S2.E1.m1.1.1.1.3.2">|</mo></mrow></mfrac><munderover id="S2.E1.m1.3.9"><mo movablelimits="false" id="S2.E1.m1.3.9.2.2">âˆ‘</mo><mrow id="S2.E1.m1.3.9.2.3"><mi id="S2.E1.m1.3.9.2.3.2">n</mi><mo id="S2.E1.m1.3.9.2.3.1">=</mo><mn id="S2.E1.m1.3.9.2.3.3">1</mn></mrow><mrow id="S2.E1.m1.2.2.1.3"><mo stretchy="false" id="S2.E1.m1.2.2.1.3.1">|</mo><mi id="S2.E1.m1.2.2.1.1">N</mi><mo stretchy="false" id="S2.E1.m1.2.2.1.3.2">|</mo></mrow></munderover><msub id="S2.E1.m1.3.10"><mi id="S2.E1.m1.3.10.2">f</mi><mi id="S2.E1.m1.3.10.3">n</mi></msub><mrow id="S2.E1.m1.3.11"><mo stretchy="false" id="S2.E1.m1.3.11.1">(</mo><mi id="S2.E1.m1.3.11.2">w</mi><mo stretchy="false" id="S2.E1.m1.3.11.3">)</mo></mrow><mo lspace="0em" id="S2.E1.m1.3.12">.</mo></mrow><annotation encoding="application/x-tex" id="S2.E1.m1.3c">\min_{w}\,f(w)\mathrel{\mathop{\mathchar 58\relax}}=\frac{1}{|N|}\sum_{n=1}^{|N|}f_{n}(w)\mathrm{.}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.3" class="ltx_p">With this, we create a model that generalizes across all clients <math id="S2.SS1.p3.1.m1.1" class="ltx_Math" alttext="n\in N" display="inline"><semantics id="S2.SS1.p3.1.m1.1a"><mrow id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml"><mi id="S2.SS1.p3.1.m1.1.1.2" xref="S2.SS1.p3.1.m1.1.1.2.cmml">n</mi><mo id="S2.SS1.p3.1.m1.1.1.1" xref="S2.SS1.p3.1.m1.1.1.1.cmml">âˆˆ</mo><mi id="S2.SS1.p3.1.m1.1.1.3" xref="S2.SS1.p3.1.m1.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><apply id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1"><in id="S2.SS1.p3.1.m1.1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1.1"></in><ci id="S2.SS1.p3.1.m1.1.1.2.cmml" xref="S2.SS1.p3.1.m1.1.1.2">ğ‘›</ci><ci id="S2.SS1.p3.1.m1.1.1.3.cmml" xref="S2.SS1.p3.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">n\in N</annotation></semantics></math>.
Specifically, at the beginning, we commonly initialize the model weights across clients. Then, clients train the model on their local data and return the updated model parameters to the server.
At the same time, each client updates its local parameters with fixed minibatch size <math id="S2.SS1.p3.2.m2.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S2.SS1.p3.2.m2.1a"><mi id="S2.SS1.p3.2.m2.1.1" xref="S2.SS1.p3.2.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m2.1b"><ci id="S2.SS1.p3.2.m2.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m2.1c">m</annotation></semantics></math> over one or more epochs by applying gradient descent steps <math id="S2.SS1.p3.3.m3.2" class="ltx_Math" alttext="\nabla l(w^{n}_{t};m)" display="inline"><semantics id="S2.SS1.p3.3.m3.2a"><mrow id="S2.SS1.p3.3.m3.2.2" xref="S2.SS1.p3.3.m3.2.2.cmml"><mrow id="S2.SS1.p3.3.m3.2.2.3" xref="S2.SS1.p3.3.m3.2.2.3.cmml"><mo rspace="0.167em" id="S2.SS1.p3.3.m3.2.2.3.1" xref="S2.SS1.p3.3.m3.2.2.3.1.cmml">âˆ‡</mo><mi id="S2.SS1.p3.3.m3.2.2.3.2" xref="S2.SS1.p3.3.m3.2.2.3.2.cmml">l</mi></mrow><mo lspace="0em" rspace="0em" id="S2.SS1.p3.3.m3.2.2.2" xref="S2.SS1.p3.3.m3.2.2.2.cmml">â€‹</mo><mrow id="S2.SS1.p3.3.m3.2.2.1.1" xref="S2.SS1.p3.3.m3.2.2.1.2.cmml"><mo stretchy="false" id="S2.SS1.p3.3.m3.2.2.1.1.2" xref="S2.SS1.p3.3.m3.2.2.1.2.cmml">(</mo><msubsup id="S2.SS1.p3.3.m3.2.2.1.1.1" xref="S2.SS1.p3.3.m3.2.2.1.1.1.cmml"><mi id="S2.SS1.p3.3.m3.2.2.1.1.1.2.2" xref="S2.SS1.p3.3.m3.2.2.1.1.1.2.2.cmml">w</mi><mi id="S2.SS1.p3.3.m3.2.2.1.1.1.3" xref="S2.SS1.p3.3.m3.2.2.1.1.1.3.cmml">t</mi><mi id="S2.SS1.p3.3.m3.2.2.1.1.1.2.3" xref="S2.SS1.p3.3.m3.2.2.1.1.1.2.3.cmml">n</mi></msubsup><mo id="S2.SS1.p3.3.m3.2.2.1.1.3" xref="S2.SS1.p3.3.m3.2.2.1.2.cmml">;</mo><mi id="S2.SS1.p3.3.m3.1.1" xref="S2.SS1.p3.3.m3.1.1.cmml">m</mi><mo stretchy="false" id="S2.SS1.p3.3.m3.2.2.1.1.4" xref="S2.SS1.p3.3.m3.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.3.m3.2b"><apply id="S2.SS1.p3.3.m3.2.2.cmml" xref="S2.SS1.p3.3.m3.2.2"><times id="S2.SS1.p3.3.m3.2.2.2.cmml" xref="S2.SS1.p3.3.m3.2.2.2"></times><apply id="S2.SS1.p3.3.m3.2.2.3.cmml" xref="S2.SS1.p3.3.m3.2.2.3"><ci id="S2.SS1.p3.3.m3.2.2.3.1.cmml" xref="S2.SS1.p3.3.m3.2.2.3.1">âˆ‡</ci><ci id="S2.SS1.p3.3.m3.2.2.3.2.cmml" xref="S2.SS1.p3.3.m3.2.2.3.2">ğ‘™</ci></apply><list id="S2.SS1.p3.3.m3.2.2.1.2.cmml" xref="S2.SS1.p3.3.m3.2.2.1.1"><apply id="S2.SS1.p3.3.m3.2.2.1.1.1.cmml" xref="S2.SS1.p3.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.3.m3.2.2.1.1.1.1.cmml" xref="S2.SS1.p3.3.m3.2.2.1.1.1">subscript</csymbol><apply id="S2.SS1.p3.3.m3.2.2.1.1.1.2.cmml" xref="S2.SS1.p3.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.3.m3.2.2.1.1.1.2.1.cmml" xref="S2.SS1.p3.3.m3.2.2.1.1.1">superscript</csymbol><ci id="S2.SS1.p3.3.m3.2.2.1.1.1.2.2.cmml" xref="S2.SS1.p3.3.m3.2.2.1.1.1.2.2">ğ‘¤</ci><ci id="S2.SS1.p3.3.m3.2.2.1.1.1.2.3.cmml" xref="S2.SS1.p3.3.m3.2.2.1.1.1.2.3">ğ‘›</ci></apply><ci id="S2.SS1.p3.3.m3.2.2.1.1.1.3.cmml" xref="S2.SS1.p3.3.m3.2.2.1.1.1.3">ğ‘¡</ci></apply><ci id="S2.SS1.p3.3.m3.1.1.cmml" xref="S2.SS1.p3.3.m3.1.1">ğ‘š</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.3.m3.2c">\nabla l(w^{n}_{t};m)</annotation></semantics></math> to the model,</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.2" class="ltx_Math" alttext="w_{t+1}^{n}=w_{t}-\eta\nabla l(w^{n}_{t};m),\,\forall n\in N\mathrm{.}" display="block"><semantics id="S2.E2.m1.2a"><mrow id="S2.E2.m1.2.2.1"><mrow id="S2.E2.m1.2.2.1.1.2" xref="S2.E2.m1.2.2.1.1.3.cmml"><mrow id="S2.E2.m1.2.2.1.1.1.1" xref="S2.E2.m1.2.2.1.1.1.1.cmml"><msubsup id="S2.E2.m1.2.2.1.1.1.1.3" xref="S2.E2.m1.2.2.1.1.1.1.3.cmml"><mi id="S2.E2.m1.2.2.1.1.1.1.3.2.2" xref="S2.E2.m1.2.2.1.1.1.1.3.2.2.cmml">w</mi><mrow id="S2.E2.m1.2.2.1.1.1.1.3.2.3" xref="S2.E2.m1.2.2.1.1.1.1.3.2.3.cmml"><mi id="S2.E2.m1.2.2.1.1.1.1.3.2.3.2" xref="S2.E2.m1.2.2.1.1.1.1.3.2.3.2.cmml">t</mi><mo id="S2.E2.m1.2.2.1.1.1.1.3.2.3.1" xref="S2.E2.m1.2.2.1.1.1.1.3.2.3.1.cmml">+</mo><mn id="S2.E2.m1.2.2.1.1.1.1.3.2.3.3" xref="S2.E2.m1.2.2.1.1.1.1.3.2.3.3.cmml">1</mn></mrow><mi id="S2.E2.m1.2.2.1.1.1.1.3.3" xref="S2.E2.m1.2.2.1.1.1.1.3.3.cmml">n</mi></msubsup><mo id="S2.E2.m1.2.2.1.1.1.1.2" xref="S2.E2.m1.2.2.1.1.1.1.2.cmml">=</mo><mrow id="S2.E2.m1.2.2.1.1.1.1.1" xref="S2.E2.m1.2.2.1.1.1.1.1.cmml"><msub id="S2.E2.m1.2.2.1.1.1.1.1.3" xref="S2.E2.m1.2.2.1.1.1.1.1.3.cmml"><mi id="S2.E2.m1.2.2.1.1.1.1.1.3.2" xref="S2.E2.m1.2.2.1.1.1.1.1.3.2.cmml">w</mi><mi id="S2.E2.m1.2.2.1.1.1.1.1.3.3" xref="S2.E2.m1.2.2.1.1.1.1.1.3.3.cmml">t</mi></msub><mo id="S2.E2.m1.2.2.1.1.1.1.1.2" xref="S2.E2.m1.2.2.1.1.1.1.1.2.cmml">âˆ’</mo><mrow id="S2.E2.m1.2.2.1.1.1.1.1.1" xref="S2.E2.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S2.E2.m1.2.2.1.1.1.1.1.1.3" xref="S2.E2.m1.2.2.1.1.1.1.1.1.3.cmml">Î·</mi><mo lspace="0.167em" rspace="0em" id="S2.E2.m1.2.2.1.1.1.1.1.1.2" xref="S2.E2.m1.2.2.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E2.m1.2.2.1.1.1.1.1.1.4" xref="S2.E2.m1.2.2.1.1.1.1.1.1.4.cmml"><mo rspace="0.167em" id="S2.E2.m1.2.2.1.1.1.1.1.1.4.1" xref="S2.E2.m1.2.2.1.1.1.1.1.1.4.1.cmml">âˆ‡</mo><mi id="S2.E2.m1.2.2.1.1.1.1.1.1.4.2" xref="S2.E2.m1.2.2.1.1.1.1.1.1.4.2.cmml">l</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.1.1.1.1.1.1.2a" xref="S2.E2.m1.2.2.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml">(</mo><msubsup id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.cmml">w</mi><mi id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">t</mi><mi id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.3" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.cmml">n</mi></msubsup><mo id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml">;</mo><mi id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml">m</mi><mo stretchy="false" id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.4" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo rspace="0.337em" id="S2.E2.m1.2.2.1.1.2.3" xref="S2.E2.m1.2.2.1.1.3a.cmml">,</mo><mrow id="S2.E2.m1.2.2.1.1.2.2" xref="S2.E2.m1.2.2.1.1.2.2.cmml"><mrow id="S2.E2.m1.2.2.1.1.2.2.2" xref="S2.E2.m1.2.2.1.1.2.2.2.cmml"><mo rspace="0.167em" id="S2.E2.m1.2.2.1.1.2.2.2.1" xref="S2.E2.m1.2.2.1.1.2.2.2.1.cmml">âˆ€</mo><mi id="S2.E2.m1.2.2.1.1.2.2.2.2" xref="S2.E2.m1.2.2.1.1.2.2.2.2.cmml">n</mi></mrow><mo id="S2.E2.m1.2.2.1.1.2.2.1" xref="S2.E2.m1.2.2.1.1.2.2.1.cmml">âˆˆ</mo><mi id="S2.E2.m1.2.2.1.1.2.2.3" xref="S2.E2.m1.2.2.1.1.2.2.3.cmml">N</mi></mrow></mrow><mo lspace="0em" id="S2.E2.m1.2.2.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.2b"><apply id="S2.E2.m1.2.2.1.1.3.cmml" xref="S2.E2.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.3a.cmml" xref="S2.E2.m1.2.2.1.1.2.3">formulae-sequence</csymbol><apply id="S2.E2.m1.2.2.1.1.1.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1"><eq id="S2.E2.m1.2.2.1.1.1.1.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.2"></eq><apply id="S2.E2.m1.2.2.1.1.1.1.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.1.1.3.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.3">superscript</csymbol><apply id="S2.E2.m1.2.2.1.1.1.1.3.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.1.1.3.2.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.3">subscript</csymbol><ci id="S2.E2.m1.2.2.1.1.1.1.3.2.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.3.2.2">ğ‘¤</ci><apply id="S2.E2.m1.2.2.1.1.1.1.3.2.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.3.2.3"><plus id="S2.E2.m1.2.2.1.1.1.1.3.2.3.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.3.2.3.1"></plus><ci id="S2.E2.m1.2.2.1.1.1.1.3.2.3.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.3.2.3.2">ğ‘¡</ci><cn type="integer" id="S2.E2.m1.2.2.1.1.1.1.3.2.3.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.3.2.3.3">1</cn></apply></apply><ci id="S2.E2.m1.2.2.1.1.1.1.3.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.3.3">ğ‘›</ci></apply><apply id="S2.E2.m1.2.2.1.1.1.1.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1"><minus id="S2.E2.m1.2.2.1.1.1.1.1.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.2"></minus><apply id="S2.E2.m1.2.2.1.1.1.1.1.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E2.m1.2.2.1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3.2">ğ‘¤</ci><ci id="S2.E2.m1.2.2.1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S2.E2.m1.2.2.1.1.1.1.1.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1"><times id="S2.E2.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.2"></times><ci id="S2.E2.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.3">ğœ‚</ci><apply id="S2.E2.m1.2.2.1.1.1.1.1.1.4.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.4"><ci id="S2.E2.m1.2.2.1.1.1.1.1.1.4.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.4.1">âˆ‡</ci><ci id="S2.E2.m1.2.2.1.1.1.1.1.1.4.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.4.2">ğ‘™</ci></apply><list id="S2.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1"><apply id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2">ğ‘¤</ci><ci id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.3">ğ‘›</ci></apply><ci id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><ci id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1">ğ‘š</ci></list></apply></apply></apply><apply id="S2.E2.m1.2.2.1.1.2.2.cmml" xref="S2.E2.m1.2.2.1.1.2.2"><in id="S2.E2.m1.2.2.1.1.2.2.1.cmml" xref="S2.E2.m1.2.2.1.1.2.2.1"></in><apply id="S2.E2.m1.2.2.1.1.2.2.2.cmml" xref="S2.E2.m1.2.2.1.1.2.2.2"><csymbol cd="latexml" id="S2.E2.m1.2.2.1.1.2.2.2.1.cmml" xref="S2.E2.m1.2.2.1.1.2.2.2.1">for-all</csymbol><ci id="S2.E2.m1.2.2.1.1.2.2.2.2.cmml" xref="S2.E2.m1.2.2.1.1.2.2.2.2">ğ‘›</ci></apply><ci id="S2.E2.m1.2.2.1.1.2.2.3.cmml" xref="S2.E2.m1.2.2.1.1.2.2.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.2c">w_{t+1}^{n}=w_{t}-\eta\nabla l(w^{n}_{t};m),\,\forall n\in N\mathrm{.}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">Subsequently, only the model parameters <math id="S2.SS1.p4.1.m1.1" class="ltx_Math" alttext="w_{t+1}^{n}" display="inline"><semantics id="S2.SS1.p4.1.m1.1a"><msubsup id="S2.SS1.p4.1.m1.1.1" xref="S2.SS1.p4.1.m1.1.1.cmml"><mi id="S2.SS1.p4.1.m1.1.1.2.2" xref="S2.SS1.p4.1.m1.1.1.2.2.cmml">w</mi><mrow id="S2.SS1.p4.1.m1.1.1.2.3" xref="S2.SS1.p4.1.m1.1.1.2.3.cmml"><mi id="S2.SS1.p4.1.m1.1.1.2.3.2" xref="S2.SS1.p4.1.m1.1.1.2.3.2.cmml">t</mi><mo id="S2.SS1.p4.1.m1.1.1.2.3.1" xref="S2.SS1.p4.1.m1.1.1.2.3.1.cmml">+</mo><mn id="S2.SS1.p4.1.m1.1.1.2.3.3" xref="S2.SS1.p4.1.m1.1.1.2.3.3.cmml">1</mn></mrow><mi id="S2.SS1.p4.1.m1.1.1.3" xref="S2.SS1.p4.1.m1.1.1.3.cmml">n</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.1.m1.1b"><apply id="S2.SS1.p4.1.m1.1.1.cmml" xref="S2.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p4.1.m1.1.1.1.cmml" xref="S2.SS1.p4.1.m1.1.1">superscript</csymbol><apply id="S2.SS1.p4.1.m1.1.1.2.cmml" xref="S2.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p4.1.m1.1.1.2.1.cmml" xref="S2.SS1.p4.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p4.1.m1.1.1.2.2.cmml" xref="S2.SS1.p4.1.m1.1.1.2.2">ğ‘¤</ci><apply id="S2.SS1.p4.1.m1.1.1.2.3.cmml" xref="S2.SS1.p4.1.m1.1.1.2.3"><plus id="S2.SS1.p4.1.m1.1.1.2.3.1.cmml" xref="S2.SS1.p4.1.m1.1.1.2.3.1"></plus><ci id="S2.SS1.p4.1.m1.1.1.2.3.2.cmml" xref="S2.SS1.p4.1.m1.1.1.2.3.2">ğ‘¡</ci><cn type="integer" id="S2.SS1.p4.1.m1.1.1.2.3.3.cmml" xref="S2.SS1.p4.1.m1.1.1.2.3.3">1</cn></apply></apply><ci id="S2.SS1.p4.1.m1.1.1.3.cmml" xref="S2.SS1.p4.1.m1.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.1.m1.1c">w_{t+1}^{n}</annotation></semantics></math> are communicated back to the server.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Taxonomy Explanation</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.3" class="ltx_p">Our taxonomy is centered on two major challenges in FL: the computational and communication efficiency levers.
While these challenges have been studied in FL extensively in the past <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib64" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>, existing approaches predominantly focus on small models with <math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="&lt;10\mathrm{M}" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><mrow id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml"><mi id="S2.SS2.p1.1.m1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.2.cmml"></mi><mo id="S2.SS2.p1.1.m1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.1.cmml">&lt;</mo><mrow id="S2.SS2.p1.1.m1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.3.cmml"><mn id="S2.SS2.p1.1.m1.1.1.3.2" xref="S2.SS2.p1.1.m1.1.1.3.2.cmml">10</mn><mo lspace="0em" rspace="0em" id="S2.SS2.p1.1.m1.1.1.3.1" xref="S2.SS2.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathvariant="normal" id="S2.SS2.p1.1.m1.1.1.3.3" xref="S2.SS2.p1.1.m1.1.1.3.3.cmml">M</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><apply id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1"><lt id="S2.SS2.p1.1.m1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S2.SS2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.2">absent</csymbol><apply id="S2.SS2.p1.1.m1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.3"><times id="S2.SS2.p1.1.m1.1.1.3.1.cmml" xref="S2.SS2.p1.1.m1.1.1.3.1"></times><cn type="integer" id="S2.SS2.p1.1.m1.1.1.3.2.cmml" xref="S2.SS2.p1.1.m1.1.1.3.2">10</cn><ci id="S2.SS2.p1.1.m1.1.1.3.3.cmml" xref="S2.SS2.p1.1.m1.1.1.3.3">M</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">&lt;10\mathrm{M}</annotation></semantics></math> parameters.
With the emergence of FMs as the backbone for multi-modal applications, we need to combine computational and communication efficiency in FL as these FMs typically come with <math id="S2.SS2.p1.2.m2.1" class="ltx_Math" alttext="&gt;1\mathrm{B}" display="inline"><semantics id="S2.SS2.p1.2.m2.1a"><mrow id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml"><mi id="S2.SS2.p1.2.m2.1.1.2" xref="S2.SS2.p1.2.m2.1.1.2.cmml"></mi><mo id="S2.SS2.p1.2.m2.1.1.1" xref="S2.SS2.p1.2.m2.1.1.1.cmml">&gt;</mo><mrow id="S2.SS2.p1.2.m2.1.1.3" xref="S2.SS2.p1.2.m2.1.1.3.cmml"><mn id="S2.SS2.p1.2.m2.1.1.3.2" xref="S2.SS2.p1.2.m2.1.1.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S2.SS2.p1.2.m2.1.1.3.1" xref="S2.SS2.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi mathvariant="normal" id="S2.SS2.p1.2.m2.1.1.3.3" xref="S2.SS2.p1.2.m2.1.1.3.3.cmml">B</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><apply id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1"><gt id="S2.SS2.p1.2.m2.1.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1.1"></gt><csymbol cd="latexml" id="S2.SS2.p1.2.m2.1.1.2.cmml" xref="S2.SS2.p1.2.m2.1.1.2">absent</csymbol><apply id="S2.SS2.p1.2.m2.1.1.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3"><times id="S2.SS2.p1.2.m2.1.1.3.1.cmml" xref="S2.SS2.p1.2.m2.1.1.3.1"></times><cn type="integer" id="S2.SS2.p1.2.m2.1.1.3.2.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2">1</cn><ci id="S2.SS2.p1.2.m2.1.1.3.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3">B</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">&gt;1\mathrm{B}</annotation></semantics></math> parameters <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib65" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023a</span></a>)</cite>; a growth factor of <math id="S2.SS2.p1.3.m3.1" class="ltx_math_unparsed" alttext="100\times" display="inline"><semantics id="S2.SS2.p1.3.m3.1a"><mrow id="S2.SS2.p1.3.m3.1b"><mn id="S2.SS2.p1.3.m3.1.1">100</mn><mo lspace="0.222em" id="S2.SS2.p1.3.m3.1.2">Ã—</mo></mrow><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">100\times</annotation></semantics></math>
This introduces additional computational load for FL clients, while their resources are often scarce already <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Beutel </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>.
At the same time, communication efforts are also growing since many parameters need to be transmitted.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold">Computational Efficiency</span>.
We discuss computational efficiency levers along four major categories.
Full model training is used to train large transformer models from the very beginning (<a href="#S3.SS1" title="3.1 Full Model Training â€£ 3 Computational Efficiency â€£ A Survey on Efficient Federated Learning Methods for Foundation Model Training" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>Â <span class="ltx_text ltx_ref_tag">3.1</span></a>).
Parameter-efficient fine-tuning techniques can be utilized to improve a pre-trained FM for a specific downstream task (<a href="#S3.SS2" title="3.2 Parameter Efficient Fine-Tuning â€£ 3 Computational Efficiency â€£ A Survey on Efficient Federated Learning Methods for Foundation Model Training" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>Â <span class="ltx_text ltx_ref_tag">3.2</span></a>). Prompt tuning enables performance improvements of an FM without training the model itself but by designing textual prompts that we prepend to an input (<a href="#S3.SS3" title="3.3 Prompt Tuning â€£ 3 Computational Efficiency â€£ A Survey on Efficient Federated Learning Methods for Foundation Model Training" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>Â <span class="ltx_text ltx_ref_tag">3.3</span></a>).
Instruction tuning enables fine-grained control over the model training process and allows for a high degree of model specialization for certain downstream tasks (<a href="#S3.SS4" title="3.4 Instruction Tuning â€£ 3 Computational Efficiency â€£ A Survey on Efficient Federated Learning Methods for Foundation Model Training" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>Â <span class="ltx_text ltx_ref_tag">3.4</span></a>).</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p"><span id="S2.SS2.p3.1.1" class="ltx_text ltx_font_bold">Communication Efficiency</span>. While computationally efficient methods for FM training in FL applications can already reduce the number of parameters to communicate, there is still a significant amount of data to be communicated between clients and servers. For instance, parameter-efficient fine-tuning methods only require 1â€“2% of parameters to be trainable. This still amounts to up to 14M parameters when working with Alpaca-7B <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib65" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023a</span></a>)</cite>, larger than the majority of models (with <math id="S2.SS2.p3.1.m1.1" class="ltx_Math" alttext="&lt;1\mathrm{M}" display="inline"><semantics id="S2.SS2.p3.1.m1.1a"><mrow id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml"><mi id="S2.SS2.p3.1.m1.1.1.2" xref="S2.SS2.p3.1.m1.1.1.2.cmml"></mi><mo id="S2.SS2.p3.1.m1.1.1.1" xref="S2.SS2.p3.1.m1.1.1.1.cmml">&lt;</mo><mrow id="S2.SS2.p3.1.m1.1.1.3" xref="S2.SS2.p3.1.m1.1.1.3.cmml"><mn id="S2.SS2.p3.1.m1.1.1.3.2" xref="S2.SS2.p3.1.m1.1.1.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S2.SS2.p3.1.m1.1.1.3.1" xref="S2.SS2.p3.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathvariant="normal" id="S2.SS2.p3.1.m1.1.1.3.3" xref="S2.SS2.p3.1.m1.1.1.3.3.cmml">M</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><apply id="S2.SS2.p3.1.m1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1"><lt id="S2.SS2.p3.1.m1.1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S2.SS2.p3.1.m1.1.1.2.cmml" xref="S2.SS2.p3.1.m1.1.1.2">absent</csymbol><apply id="S2.SS2.p3.1.m1.1.1.3.cmml" xref="S2.SS2.p3.1.m1.1.1.3"><times id="S2.SS2.p3.1.m1.1.1.3.1.cmml" xref="S2.SS2.p3.1.m1.1.1.3.1"></times><cn type="integer" id="S2.SS2.p3.1.m1.1.1.3.2.cmml" xref="S2.SS2.p3.1.m1.1.1.3.2">1</cn><ci id="S2.SS2.p3.1.m1.1.1.3.3.cmml" xref="S2.SS2.p3.1.m1.1.1.3.3">M</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">&lt;1\mathrm{M}</annotation></semantics></math> trainable parameters) currently being discussed in FL research <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">He </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>); <span class="ltx_text" style="font-size:90%;">Beutel </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p">We discuss communication efficiency methods along two major categories. (I) <em id="S2.SS2.p4.1.1" class="ltx_emph ltx_font_italic">Model pruning</em> is a method to communicate parts of a model between clients and the server, which resemble the most important parameters for a client (<a href="#S4.SS1" title="4.1 Model Pruning â€£ 4 Communication Efficiency â€£ A Survey on Efficient Federated Learning Methods for Foundation Model Training" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>Â <span class="ltx_text ltx_ref_tag">4.1</span></a>). (II) <em id="S2.SS2.p4.1.2" class="ltx_emph ltx_font_italic">Full model compression</em> is divided into three sub-categories: First, quantization is a method to decrease the numeric precision of model parameters. Second, sparsification is used as a way to zero out less important model parameters. Third, low-rank compression transforms high dimensional parameter matrices in client updates into significantly lower dimensional representations (<a href="#S4.SS2" title="4.2 Full Model Compression â€£ 4 Communication Efficiency â€£ A Survey on Efficient Federated Learning Methods for Foundation Model Training" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>Â <span class="ltx_text ltx_ref_tag">4.2</span></a>).</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>
Computational Efficiency Methods for FL Systems and FM.
FMs are generally multi-modal and provide a strong performance across a variety of domains that are well explored in centralized learning but not in FL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Dosovitskiy </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>); <span class="ltx_text" style="font-size:90%;">OpenAI</span> (<a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>); <span class="ltx_text" style="font-size:90%;">Yang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>); <span class="ltx_text" style="font-size:90%;">Liu </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>.
</figcaption>
<div id="S2.T1.18" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:90.4pt;vertical-align:-0.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-217.3pt,45.1pt) scale(0.499441519124222,0.499441519124222) ;">
<table id="S2.T1.18.18" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.18.18.19.1" class="ltx_tr">
<th id="S2.T1.18.18.19.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="S2.T1.18.18.19.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Training</th>
<th id="S2.T1.18.18.19.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Underlying FL</th>
<th id="S2.T1.18.18.19.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Max. Model</th>
<th id="S2.T1.18.18.19.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Trainable</th>
<th id="S2.T1.18.18.19.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Comms Savings</th>
<th id="S2.T1.18.18.19.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">Domain</th>
</tr>
<tr id="S2.T1.18.18.20.2" class="ltx_tr">
<th id="S2.T1.18.18.20.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column">Paper</th>
<th id="S2.T1.18.18.20.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Regime</th>
<th id="S2.T1.18.18.20.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">Aggregation Strategy</th>
<th id="S2.T1.18.18.20.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">Params</th>
<th id="S2.T1.18.18.20.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">Parameters</th>
<th id="S2.T1.18.18.20.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">compared to FMT</th>
<th id="S2.T1.18.18.20.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">CV</th>
<th id="S2.T1.18.18.20.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column">NLP</th>
<th id="S2.T1.18.18.20.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column">Audio</th>
<th id="S2.T1.18.18.20.2.10" class="ltx_td ltx_align_center ltx_th ltx_th_column">Graph</th>
</tr>
<tr id="S2.T1.5.5.5" class="ltx_tr">
<th id="S2.T1.5.5.5.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S2.T1.5.5.5.6.1" class="ltx_text ltx_font_italic">Centralized Learning</span></th>
<th id="S2.T1.5.5.5.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">FMT, PEFT, PT, IT</th>
<th id="S2.T1.5.5.5.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">â€“</th>
<th id="S2.T1.1.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t"><math id="S2.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="&gt;100\mathrm{B}" display="inline"><semantics id="S2.T1.1.1.1.1.m1.1a"><mrow id="S2.T1.1.1.1.1.m1.1.1" xref="S2.T1.1.1.1.1.m1.1.1.cmml"><mi id="S2.T1.1.1.1.1.m1.1.1.2" xref="S2.T1.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="S2.T1.1.1.1.1.m1.1.1.1" xref="S2.T1.1.1.1.1.m1.1.1.1.cmml">&gt;</mo><mrow id="S2.T1.1.1.1.1.m1.1.1.3" xref="S2.T1.1.1.1.1.m1.1.1.3.cmml"><mn id="S2.T1.1.1.1.1.m1.1.1.3.2" xref="S2.T1.1.1.1.1.m1.1.1.3.2.cmml">100</mn><mo lspace="0em" rspace="0em" id="S2.T1.1.1.1.1.m1.1.1.3.1" xref="S2.T1.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathvariant="normal" id="S2.T1.1.1.1.1.m1.1.1.3.3" xref="S2.T1.1.1.1.1.m1.1.1.3.3.cmml">B</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.1.m1.1b"><apply id="S2.T1.1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.1.m1.1.1"><gt id="S2.T1.1.1.1.1.m1.1.1.1.cmml" xref="S2.T1.1.1.1.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S2.T1.1.1.1.1.m1.1.1.2.cmml" xref="S2.T1.1.1.1.1.m1.1.1.2">absent</csymbol><apply id="S2.T1.1.1.1.1.m1.1.1.3.cmml" xref="S2.T1.1.1.1.1.m1.1.1.3"><times id="S2.T1.1.1.1.1.m1.1.1.3.1.cmml" xref="S2.T1.1.1.1.1.m1.1.1.3.1"></times><cn type="integer" id="S2.T1.1.1.1.1.m1.1.1.3.2.cmml" xref="S2.T1.1.1.1.1.m1.1.1.3.2">100</cn><ci id="S2.T1.1.1.1.1.m1.1.1.3.3.cmml" xref="S2.T1.1.1.1.1.m1.1.1.3.3">B</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.1.m1.1c">&gt;100\mathrm{B}</annotation></semantics></math></th>
<th id="S2.T1.5.5.5.9" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t">â€“</th>
<th id="S2.T1.5.5.5.10" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">â€“</th>
<th id="S2.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><svg id="S2.T1.2.2.2.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</th>
<th id="S2.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><svg id="S2.T1.3.3.3.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</th>
<th id="S2.T1.4.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><svg id="S2.T1.4.4.4.4.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</th>
<th id="S2.T1.5.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><svg id="S2.T1.5.5.5.5.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.6.6.6" class="ltx_tr">
<td id="S2.T1.6.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FedBERT <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Tian </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>
</td>
<td id="S2.T1.6.6.6.3" class="ltx_td ltx_align_left ltx_border_t">FMT</td>
<td id="S2.T1.6.6.6.4" class="ltx_td ltx_align_left ltx_border_t">Weighted Average</td>
<td id="S2.T1.6.6.6.5" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">117M</td>
<td id="S2.T1.6.6.6.6" class="ltx_td ltx_align_right ltx_border_t">110M</td>
<td id="S2.T1.6.6.6.7" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">0%</td>
<td id="S2.T1.6.6.6.8" class="ltx_td ltx_border_t"></td>
<td id="S2.T1.6.6.6.1" class="ltx_td ltx_align_center ltx_border_t"><svg id="S2.T1.6.6.6.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S2.T1.6.6.6.9" class="ltx_td ltx_border_t"></td>
<td id="S2.T1.6.6.6.10" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S2.T1.8.8.8" class="ltx_tr">
<td id="S2.T1.8.8.8.3" class="ltx_td ltx_align_left ltx_border_r">FedCLIP <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Lu </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>
</td>
<td id="S2.T1.8.8.8.4" class="ltx_td ltx_align_left">PEFT</td>
<td id="S2.T1.8.8.8.5" class="ltx_td ltx_align_left">Weighted Average</td>
<td id="S2.T1.8.8.8.6" class="ltx_td ltx_align_right ltx_border_r">85M</td>
<td id="S2.T1.8.8.8.7" class="ltx_td ltx_align_right">530K</td>
<td id="S2.T1.7.7.7.1" class="ltx_td ltx_align_right ltx_border_r"><math id="S2.T1.7.7.7.1.m1.1" class="ltx_Math" alttext="&gt;99\%" display="inline"><semantics id="S2.T1.7.7.7.1.m1.1a"><mrow id="S2.T1.7.7.7.1.m1.1.1" xref="S2.T1.7.7.7.1.m1.1.1.cmml"><mi id="S2.T1.7.7.7.1.m1.1.1.2" xref="S2.T1.7.7.7.1.m1.1.1.2.cmml"></mi><mo id="S2.T1.7.7.7.1.m1.1.1.1" xref="S2.T1.7.7.7.1.m1.1.1.1.cmml">&gt;</mo><mrow id="S2.T1.7.7.7.1.m1.1.1.3" xref="S2.T1.7.7.7.1.m1.1.1.3.cmml"><mn id="S2.T1.7.7.7.1.m1.1.1.3.2" xref="S2.T1.7.7.7.1.m1.1.1.3.2.cmml">99</mn><mo id="S2.T1.7.7.7.1.m1.1.1.3.1" xref="S2.T1.7.7.7.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.7.7.7.1.m1.1b"><apply id="S2.T1.7.7.7.1.m1.1.1.cmml" xref="S2.T1.7.7.7.1.m1.1.1"><gt id="S2.T1.7.7.7.1.m1.1.1.1.cmml" xref="S2.T1.7.7.7.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S2.T1.7.7.7.1.m1.1.1.2.cmml" xref="S2.T1.7.7.7.1.m1.1.1.2">absent</csymbol><apply id="S2.T1.7.7.7.1.m1.1.1.3.cmml" xref="S2.T1.7.7.7.1.m1.1.1.3"><csymbol cd="latexml" id="S2.T1.7.7.7.1.m1.1.1.3.1.cmml" xref="S2.T1.7.7.7.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S2.T1.7.7.7.1.m1.1.1.3.2.cmml" xref="S2.T1.7.7.7.1.m1.1.1.3.2">99</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.7.7.7.1.m1.1c">&gt;99\%</annotation></semantics></math></td>
<td id="S2.T1.8.8.8.2" class="ltx_td ltx_align_center"><svg id="S2.T1.8.8.8.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S2.T1.8.8.8.8" class="ltx_td"></td>
<td id="S2.T1.8.8.8.9" class="ltx_td"></td>
<td id="S2.T1.8.8.8.10" class="ltx_td"></td>
</tr>
<tr id="S2.T1.10.10.10" class="ltx_tr">
<td id="S2.T1.10.10.10.3" class="ltx_td ltx_align_left ltx_border_r">FedPEFT <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Sun </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>
</td>
<td id="S2.T1.10.10.10.4" class="ltx_td ltx_align_left">PEFT</td>
<td id="S2.T1.10.10.10.5" class="ltx_td ltx_align_left">Weighted Average</td>
<td id="S2.T1.10.10.10.6" class="ltx_td ltx_align_right ltx_border_r">85M</td>
<td id="S2.T1.10.10.10.7" class="ltx_td ltx_align_right">230K</td>
<td id="S2.T1.9.9.9.1" class="ltx_td ltx_align_right ltx_border_r"><math id="S2.T1.9.9.9.1.m1.1" class="ltx_Math" alttext="&gt;99\%" display="inline"><semantics id="S2.T1.9.9.9.1.m1.1a"><mrow id="S2.T1.9.9.9.1.m1.1.1" xref="S2.T1.9.9.9.1.m1.1.1.cmml"><mi id="S2.T1.9.9.9.1.m1.1.1.2" xref="S2.T1.9.9.9.1.m1.1.1.2.cmml"></mi><mo id="S2.T1.9.9.9.1.m1.1.1.1" xref="S2.T1.9.9.9.1.m1.1.1.1.cmml">&gt;</mo><mrow id="S2.T1.9.9.9.1.m1.1.1.3" xref="S2.T1.9.9.9.1.m1.1.1.3.cmml"><mn id="S2.T1.9.9.9.1.m1.1.1.3.2" xref="S2.T1.9.9.9.1.m1.1.1.3.2.cmml">99</mn><mo id="S2.T1.9.9.9.1.m1.1.1.3.1" xref="S2.T1.9.9.9.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.9.9.9.1.m1.1b"><apply id="S2.T1.9.9.9.1.m1.1.1.cmml" xref="S2.T1.9.9.9.1.m1.1.1"><gt id="S2.T1.9.9.9.1.m1.1.1.1.cmml" xref="S2.T1.9.9.9.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S2.T1.9.9.9.1.m1.1.1.2.cmml" xref="S2.T1.9.9.9.1.m1.1.1.2">absent</csymbol><apply id="S2.T1.9.9.9.1.m1.1.1.3.cmml" xref="S2.T1.9.9.9.1.m1.1.1.3"><csymbol cd="latexml" id="S2.T1.9.9.9.1.m1.1.1.3.1.cmml" xref="S2.T1.9.9.9.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S2.T1.9.9.9.1.m1.1.1.3.2.cmml" xref="S2.T1.9.9.9.1.m1.1.1.3.2">99</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.9.9.9.1.m1.1c">&gt;99\%</annotation></semantics></math></td>
<td id="S2.T1.10.10.10.2" class="ltx_td ltx_align_center"><svg id="S2.T1.10.10.10.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S2.T1.10.10.10.8" class="ltx_td"></td>
<td id="S2.T1.10.10.10.9" class="ltx_td"></td>
<td id="S2.T1.10.10.10.10" class="ltx_td"></td>
</tr>
<tr id="S2.T1.12.12.12" class="ltx_tr">
<td id="S2.T1.12.12.12.3" class="ltx_td ltx_align_left ltx_border_r">FedPETuning <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib66" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023b</span></a>)</cite>
</td>
<td id="S2.T1.12.12.12.4" class="ltx_td ltx_align_left">PEFT</td>
<td id="S2.T1.12.12.12.5" class="ltx_td ltx_align_left">Weighted Average</td>
<td id="S2.T1.12.12.12.6" class="ltx_td ltx_align_right ltx_border_r">125M</td>
<td id="S2.T1.12.12.12.7" class="ltx_td ltx_align_right">1.25M</td>
<td id="S2.T1.11.11.11.1" class="ltx_td ltx_align_right ltx_border_r"><math id="S2.T1.11.11.11.1.m1.1" class="ltx_Math" alttext="99\%" display="inline"><semantics id="S2.T1.11.11.11.1.m1.1a"><mrow id="S2.T1.11.11.11.1.m1.1.1" xref="S2.T1.11.11.11.1.m1.1.1.cmml"><mn id="S2.T1.11.11.11.1.m1.1.1.2" xref="S2.T1.11.11.11.1.m1.1.1.2.cmml">99</mn><mo id="S2.T1.11.11.11.1.m1.1.1.1" xref="S2.T1.11.11.11.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.11.11.11.1.m1.1b"><apply id="S2.T1.11.11.11.1.m1.1.1.cmml" xref="S2.T1.11.11.11.1.m1.1.1"><csymbol cd="latexml" id="S2.T1.11.11.11.1.m1.1.1.1.cmml" xref="S2.T1.11.11.11.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S2.T1.11.11.11.1.m1.1.1.2.cmml" xref="S2.T1.11.11.11.1.m1.1.1.2">99</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.11.11.11.1.m1.1c">99\%</annotation></semantics></math></td>
<td id="S2.T1.12.12.12.8" class="ltx_td"></td>
<td id="S2.T1.12.12.12.2" class="ltx_td ltx_align_center"><svg id="S2.T1.12.12.12.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S2.T1.12.12.12.9" class="ltx_td"></td>
<td id="S2.T1.12.12.12.10" class="ltx_td"></td>
</tr>
<tr id="S2.T1.14.14.14" class="ltx_tr">
<td id="S2.T1.14.14.14.3" class="ltx_td ltx_align_left ltx_border_r">SLoRA <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Babakniya </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>
</td>
<td id="S2.T1.14.14.14.4" class="ltx_td ltx_align_left">PEFT</td>
<td id="S2.T1.14.14.14.5" class="ltx_td ltx_align_left">Weighted Average</td>
<td id="S2.T1.14.14.14.6" class="ltx_td ltx_align_right ltx_border_r">67M</td>
<td id="S2.T1.14.14.14.7" class="ltx_td ltx_align_right">140K</td>
<td id="S2.T1.13.13.13.1" class="ltx_td ltx_align_right ltx_border_r"><math id="S2.T1.13.13.13.1.m1.1" class="ltx_Math" alttext="&gt;99\%" display="inline"><semantics id="S2.T1.13.13.13.1.m1.1a"><mrow id="S2.T1.13.13.13.1.m1.1.1" xref="S2.T1.13.13.13.1.m1.1.1.cmml"><mi id="S2.T1.13.13.13.1.m1.1.1.2" xref="S2.T1.13.13.13.1.m1.1.1.2.cmml"></mi><mo id="S2.T1.13.13.13.1.m1.1.1.1" xref="S2.T1.13.13.13.1.m1.1.1.1.cmml">&gt;</mo><mrow id="S2.T1.13.13.13.1.m1.1.1.3" xref="S2.T1.13.13.13.1.m1.1.1.3.cmml"><mn id="S2.T1.13.13.13.1.m1.1.1.3.2" xref="S2.T1.13.13.13.1.m1.1.1.3.2.cmml">99</mn><mo id="S2.T1.13.13.13.1.m1.1.1.3.1" xref="S2.T1.13.13.13.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.13.13.13.1.m1.1b"><apply id="S2.T1.13.13.13.1.m1.1.1.cmml" xref="S2.T1.13.13.13.1.m1.1.1"><gt id="S2.T1.13.13.13.1.m1.1.1.1.cmml" xref="S2.T1.13.13.13.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S2.T1.13.13.13.1.m1.1.1.2.cmml" xref="S2.T1.13.13.13.1.m1.1.1.2">absent</csymbol><apply id="S2.T1.13.13.13.1.m1.1.1.3.cmml" xref="S2.T1.13.13.13.1.m1.1.1.3"><csymbol cd="latexml" id="S2.T1.13.13.13.1.m1.1.1.3.1.cmml" xref="S2.T1.13.13.13.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S2.T1.13.13.13.1.m1.1.1.3.2.cmml" xref="S2.T1.13.13.13.1.m1.1.1.3.2">99</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.13.13.13.1.m1.1c">&gt;99\%</annotation></semantics></math></td>
<td id="S2.T1.14.14.14.8" class="ltx_td"></td>
<td id="S2.T1.14.14.14.2" class="ltx_td ltx_align_center"><svg id="S2.T1.14.14.14.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S2.T1.14.14.14.9" class="ltx_td"></td>
<td id="S2.T1.14.14.14.10" class="ltx_td"></td>
</tr>
<tr id="S2.T1.16.16.16" class="ltx_tr">
<td id="S2.T1.16.16.16.3" class="ltx_td ltx_align_left ltx_border_r">FedPrompt <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>
</td>
<td id="S2.T1.16.16.16.4" class="ltx_td ltx_align_left">PT</td>
<td id="S2.T1.16.16.16.5" class="ltx_td ltx_align_left">Weighted Average</td>
<td id="S2.T1.16.16.16.6" class="ltx_td ltx_align_right ltx_border_r">223M</td>
<td id="S2.T1.16.16.16.7" class="ltx_td ltx_align_right">â€“</td>
<td id="S2.T1.15.15.15.1" class="ltx_td ltx_align_right ltx_border_r"><math id="S2.T1.15.15.15.1.m1.1" class="ltx_Math" alttext="&gt;99\%" display="inline"><semantics id="S2.T1.15.15.15.1.m1.1a"><mrow id="S2.T1.15.15.15.1.m1.1.1" xref="S2.T1.15.15.15.1.m1.1.1.cmml"><mi id="S2.T1.15.15.15.1.m1.1.1.2" xref="S2.T1.15.15.15.1.m1.1.1.2.cmml"></mi><mo id="S2.T1.15.15.15.1.m1.1.1.1" xref="S2.T1.15.15.15.1.m1.1.1.1.cmml">&gt;</mo><mrow id="S2.T1.15.15.15.1.m1.1.1.3" xref="S2.T1.15.15.15.1.m1.1.1.3.cmml"><mn id="S2.T1.15.15.15.1.m1.1.1.3.2" xref="S2.T1.15.15.15.1.m1.1.1.3.2.cmml">99</mn><mo id="S2.T1.15.15.15.1.m1.1.1.3.1" xref="S2.T1.15.15.15.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.15.15.15.1.m1.1b"><apply id="S2.T1.15.15.15.1.m1.1.1.cmml" xref="S2.T1.15.15.15.1.m1.1.1"><gt id="S2.T1.15.15.15.1.m1.1.1.1.cmml" xref="S2.T1.15.15.15.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S2.T1.15.15.15.1.m1.1.1.2.cmml" xref="S2.T1.15.15.15.1.m1.1.1.2">absent</csymbol><apply id="S2.T1.15.15.15.1.m1.1.1.3.cmml" xref="S2.T1.15.15.15.1.m1.1.1.3"><csymbol cd="latexml" id="S2.T1.15.15.15.1.m1.1.1.3.1.cmml" xref="S2.T1.15.15.15.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S2.T1.15.15.15.1.m1.1.1.3.2.cmml" xref="S2.T1.15.15.15.1.m1.1.1.3.2">99</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.15.15.15.1.m1.1c">&gt;99\%</annotation></semantics></math></td>
<td id="S2.T1.16.16.16.8" class="ltx_td"></td>
<td id="S2.T1.16.16.16.2" class="ltx_td ltx_align_center"><svg id="S2.T1.16.16.16.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S2.T1.16.16.16.9" class="ltx_td"></td>
<td id="S2.T1.16.16.16.10" class="ltx_td"></td>
</tr>
<tr id="S2.T1.18.18.18" class="ltx_tr">
<td id="S2.T1.18.18.18.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_bb ltx_border_r">FedIT <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib65" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023a</span></a>)</cite>
</td>
<td id="S2.T1.18.18.18.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_bb">IT</td>
<td id="S2.T1.18.18.18.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_bb">Weighted Average</td>
<td id="S2.T1.18.18.18.6" class="ltx_td ltx_align_right ltx_border_bb ltx_border_bb ltx_border_r">7B</td>
<td id="S2.T1.18.18.18.7" class="ltx_td ltx_align_right ltx_border_bb ltx_border_bb">â€“</td>
<td id="S2.T1.17.17.17.1" class="ltx_td ltx_align_right ltx_border_bb ltx_border_bb ltx_border_r"><math id="S2.T1.17.17.17.1.m1.1" class="ltx_Math" alttext="&gt;99\%" display="inline"><semantics id="S2.T1.17.17.17.1.m1.1a"><mrow id="S2.T1.17.17.17.1.m1.1.1" xref="S2.T1.17.17.17.1.m1.1.1.cmml"><mi id="S2.T1.17.17.17.1.m1.1.1.2" xref="S2.T1.17.17.17.1.m1.1.1.2.cmml"></mi><mo id="S2.T1.17.17.17.1.m1.1.1.1" xref="S2.T1.17.17.17.1.m1.1.1.1.cmml">&gt;</mo><mrow id="S2.T1.17.17.17.1.m1.1.1.3" xref="S2.T1.17.17.17.1.m1.1.1.3.cmml"><mn id="S2.T1.17.17.17.1.m1.1.1.3.2" xref="S2.T1.17.17.17.1.m1.1.1.3.2.cmml">99</mn><mo id="S2.T1.17.17.17.1.m1.1.1.3.1" xref="S2.T1.17.17.17.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.17.17.17.1.m1.1b"><apply id="S2.T1.17.17.17.1.m1.1.1.cmml" xref="S2.T1.17.17.17.1.m1.1.1"><gt id="S2.T1.17.17.17.1.m1.1.1.1.cmml" xref="S2.T1.17.17.17.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S2.T1.17.17.17.1.m1.1.1.2.cmml" xref="S2.T1.17.17.17.1.m1.1.1.2">absent</csymbol><apply id="S2.T1.17.17.17.1.m1.1.1.3.cmml" xref="S2.T1.17.17.17.1.m1.1.1.3"><csymbol cd="latexml" id="S2.T1.17.17.17.1.m1.1.1.3.1.cmml" xref="S2.T1.17.17.17.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S2.T1.17.17.17.1.m1.1.1.3.2.cmml" xref="S2.T1.17.17.17.1.m1.1.1.3.2">99</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.17.17.17.1.m1.1c">&gt;99\%</annotation></semantics></math></td>
<td id="S2.T1.18.18.18.8" class="ltx_td ltx_border_bb ltx_border_bb"></td>
<td id="S2.T1.18.18.18.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_bb"><svg id="S2.T1.18.18.18.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S2.T1.18.18.18.9" class="ltx_td ltx_border_bb ltx_border_bb"></td>
<td id="S2.T1.18.18.18.10" class="ltx_td ltx_border_bb ltx_border_bb"></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Computational Efficiency</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">This section discusses recent methods to train FMs with FL methods.
We distinguish between full model training (FMT), as it has been studied frequently in the FL domain, PEFT, prompt tuning (PT), and instruction tuning (IT). <a href="#S2.T1" title="In 2.2 Taxonomy Explanation â€£ 2 Taxonomy â€£ A Survey on Efficient Federated Learning Methods for Foundation Model Training" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">1</span></a> summarizes existing computational efficiency methods for FM training.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Full Model Training</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Generally, full model training is referred to when training all parameters of a neural network. This is particularly useful when permanently fitting a model to a specific use case. In this approach, we locally train a model on all clients with the objective of minimizing the loss <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">l</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.3" class="ltx_p">The BERT transformer is one of the first transformer architectures - the building blocks of FMs. <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Tian </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a></cite>] discuss federated pre-training of BERT-family models with up to 117M parameters for masked language modeling (MLM). In MLM, the loss is defined over the sum of probabilities <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">ğ‘ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">P</annotation></semantics></math> of predicted tokens <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="\hat{x}" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mover accent="true" id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">x</mi><mo id="S3.SS1.p2.2.m2.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><ci id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1">^</ci><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">ğ‘¥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\hat{x}</annotation></semantics></math> over the representation function of a masked sentence <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="g\big{(}\frac{x}{M(x)}\big{)}" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mrow id="S3.SS1.p2.3.m3.1.2" xref="S3.SS1.p2.3.m3.1.2.cmml"><mi id="S3.SS1.p2.3.m3.1.2.2" xref="S3.SS1.p2.3.m3.1.2.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.3.m3.1.2.1" xref="S3.SS1.p2.3.m3.1.2.1.cmml">â€‹</mo><mrow id="S3.SS1.p2.3.m3.1.2.3.2" xref="S3.SS1.p2.3.m3.1.1.cmml"><mo maxsize="120%" minsize="120%" id="S3.SS1.p2.3.m3.1.2.3.2.1" xref="S3.SS1.p2.3.m3.1.1.cmml">(</mo><mfrac id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">x</mi><mrow id="S3.SS1.p2.3.m3.1.1.1" xref="S3.SS1.p2.3.m3.1.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.1.3" xref="S3.SS1.p2.3.m3.1.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.3.m3.1.1.1.2" xref="S3.SS1.p2.3.m3.1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS1.p2.3.m3.1.1.1.4.2" xref="S3.SS1.p2.3.m3.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p2.3.m3.1.1.1.4.2.1" xref="S3.SS1.p2.3.m3.1.1.1.cmml">(</mo><mi id="S3.SS1.p2.3.m3.1.1.1.1" xref="S3.SS1.p2.3.m3.1.1.1.1.cmml">x</mi><mo stretchy="false" id="S3.SS1.p2.3.m3.1.1.1.4.2.2" xref="S3.SS1.p2.3.m3.1.1.1.cmml">)</mo></mrow></mrow></mfrac><mo maxsize="120%" minsize="120%" id="S3.SS1.p2.3.m3.1.2.3.2.2" xref="S3.SS1.p2.3.m3.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.2.cmml" xref="S3.SS1.p2.3.m3.1.2"><times id="S3.SS1.p2.3.m3.1.2.1.cmml" xref="S3.SS1.p2.3.m3.1.2.1"></times><ci id="S3.SS1.p2.3.m3.1.2.2.cmml" xref="S3.SS1.p2.3.m3.1.2.2">ğ‘”</ci><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.2.3.2"><divide id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.2.3.2"></divide><ci id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3">ğ‘¥</ci><apply id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1.1"><times id="S3.SS1.p2.3.m3.1.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.1.2"></times><ci id="S3.SS1.p2.3.m3.1.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.1.3">ğ‘€</ci><ci id="S3.SS1.p2.3.m3.1.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1.1.1">ğ‘¥</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">g\big{(}\frac{x}{M(x)}\big{)}</annotation></semantics></math>,</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.4" class="ltx_Math" alttext="l(w^{t}_{n},m)=-\sum_{\hat{x}\in\mathcal{M(\mathrm{x})}}\mathrm{log}P\left(\hat{x}\left|g\left(\frac{x}{M(x)}\right)\right.\right),\,\forall n\in N\mathrm{.}" display="block"><semantics id="S3.E3.m1.4a"><mrow id="S3.E3.m1.4.4.1"><mrow id="S3.E3.m1.4.4.1.1.2" xref="S3.E3.m1.4.4.1.1.3.cmml"><mrow id="S3.E3.m1.4.4.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.cmml"><mrow id="S3.E3.m1.4.4.1.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.1.cmml"><mi id="S3.E3.m1.4.4.1.1.1.1.1.3" xref="S3.E3.m1.4.4.1.1.1.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.1.1.1.1.1.2" xref="S3.E3.m1.4.4.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.4.4.1.1.1.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.4.4.1.1.1.1.1.1.1.2" xref="S3.E3.m1.4.4.1.1.1.1.1.1.2.cmml">(</mo><msubsup id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.2.2" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.2.2.cmml">w</mi><mi id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.3.cmml">n</mi><mi id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.2.3" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.2.3.cmml">t</mi></msubsup><mo id="S3.E3.m1.4.4.1.1.1.1.1.1.1.3" xref="S3.E3.m1.4.4.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml">m</mi><mo stretchy="false" id="S3.E3.m1.4.4.1.1.1.1.1.1.1.4" xref="S3.E3.m1.4.4.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.4.4.1.1.1.1.3" xref="S3.E3.m1.4.4.1.1.1.1.3.cmml">=</mo><mrow id="S3.E3.m1.4.4.1.1.1.1.2" xref="S3.E3.m1.4.4.1.1.1.1.2.cmml"><mo id="S3.E3.m1.4.4.1.1.1.1.2a" xref="S3.E3.m1.4.4.1.1.1.1.2.cmml">âˆ’</mo><mrow id="S3.E3.m1.4.4.1.1.1.1.2.1" xref="S3.E3.m1.4.4.1.1.1.1.2.1.cmml"><munder id="S3.E3.m1.4.4.1.1.1.1.2.1.2" xref="S3.E3.m1.4.4.1.1.1.1.2.1.2.cmml"><mo movablelimits="false" id="S3.E3.m1.4.4.1.1.1.1.2.1.2.2" xref="S3.E3.m1.4.4.1.1.1.1.2.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.cmml"><mover accent="true" id="S3.E3.m1.1.1.1.3" xref="S3.E3.m1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.3.2.cmml">x</mi><mo id="S3.E3.m1.1.1.1.3.1" xref="S3.E3.m1.1.1.1.3.1.cmml">^</mo></mover><mo id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.2.cmml">âˆˆ</mo><mrow id="S3.E3.m1.1.1.1.4" xref="S3.E3.m1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.4.2" xref="S3.E3.m1.1.1.1.4.2.cmml">â„³</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.4.1" xref="S3.E3.m1.1.1.1.4.1.cmml">â€‹</mo><mrow id="S3.E3.m1.1.1.1.4.3.2" xref="S3.E3.m1.1.1.1.4.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.4.3.2.1" xref="S3.E3.m1.1.1.1.4.cmml">(</mo><mi mathvariant="normal" id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml">x</mi><mo stretchy="false" id="S3.E3.m1.1.1.1.4.3.2.2" xref="S3.E3.m1.1.1.1.4.cmml">)</mo></mrow></mrow></mrow></munder><mrow id="S3.E3.m1.4.4.1.1.1.1.2.1.1" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.cmml"><mi id="S3.E3.m1.4.4.1.1.1.1.2.1.1.3" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.3.cmml">log</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.1.1.1.1.2.1.1.2" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.4.4.1.1.1.1.2.1.1.4" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.1.1.1.1.2.1.1.2a" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.cmml"><mo id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.2" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.cmml"><mover accent="true" id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.2" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.2.2" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.2.2.cmml">x</mi><mo id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.2.1" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.2.1.cmml">^</mo></mover><mo fence="false" stretchy="true" id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.1.cmml">|</mo><mrow id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.3" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.3.2" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.3.1" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.3.1.cmml">â€‹</mo><mrow id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.3.3.2" xref="S3.E3.m1.2.2.cmml"><mo id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.3.3.2.1" xref="S3.E3.m1.2.2.cmml">(</mo><mfrac id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml"><mi id="S3.E3.m1.2.2.3" xref="S3.E3.m1.2.2.3.cmml">x</mi><mrow id="S3.E3.m1.2.2.1" xref="S3.E3.m1.2.2.1.cmml"><mi id="S3.E3.m1.2.2.1.3" xref="S3.E3.m1.2.2.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.2" xref="S3.E3.m1.2.2.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.2.2.1.4.2" xref="S3.E3.m1.2.2.1.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.4.2.1" xref="S3.E3.m1.2.2.1.cmml">(</mo><mi id="S3.E3.m1.2.2.1.1" xref="S3.E3.m1.2.2.1.1.cmml">x</mi><mo stretchy="false" id="S3.E3.m1.2.2.1.4.2.2" xref="S3.E3.m1.2.2.1.cmml">)</mo></mrow></mrow></mfrac><mo id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.3.3.2.2" xref="S3.E3.m1.2.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.3" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo rspace="0.337em" id="S3.E3.m1.4.4.1.1.2.3" xref="S3.E3.m1.4.4.1.1.3a.cmml">,</mo><mrow id="S3.E3.m1.4.4.1.1.2.2" xref="S3.E3.m1.4.4.1.1.2.2.cmml"><mrow id="S3.E3.m1.4.4.1.1.2.2.2" xref="S3.E3.m1.4.4.1.1.2.2.2.cmml"><mo rspace="0.167em" id="S3.E3.m1.4.4.1.1.2.2.2.1" xref="S3.E3.m1.4.4.1.1.2.2.2.1.cmml">âˆ€</mo><mi id="S3.E3.m1.4.4.1.1.2.2.2.2" xref="S3.E3.m1.4.4.1.1.2.2.2.2.cmml">n</mi></mrow><mo id="S3.E3.m1.4.4.1.1.2.2.1" xref="S3.E3.m1.4.4.1.1.2.2.1.cmml">âˆˆ</mo><mi id="S3.E3.m1.4.4.1.1.2.2.3" xref="S3.E3.m1.4.4.1.1.2.2.3.cmml">N</mi></mrow></mrow><mo lspace="0em" id="S3.E3.m1.4.4.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.4b"><apply id="S3.E3.m1.4.4.1.1.3.cmml" xref="S3.E3.m1.4.4.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.3a.cmml" xref="S3.E3.m1.4.4.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E3.m1.4.4.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1"><eq id="S3.E3.m1.4.4.1.1.1.1.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.3"></eq><apply id="S3.E3.m1.4.4.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1"><times id="S3.E3.m1.4.4.1.1.1.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.2"></times><ci id="S3.E3.m1.4.4.1.1.1.1.1.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.3">ğ‘™</ci><interval closure="open" id="S3.E3.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1"><apply id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.2.2">ğ‘¤</ci><ci id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.3">ğ‘›</ci></apply><ci id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3">ğ‘š</ci></interval></apply><apply id="S3.E3.m1.4.4.1.1.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2"><minus id="S3.E3.m1.4.4.1.1.1.1.2.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2"></minus><apply id="S3.E3.m1.4.4.1.1.1.1.2.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1"><apply id="S3.E3.m1.4.4.1.1.1.1.2.1.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.1.1.2.1.2.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1.2">subscript</csymbol><sum id="S3.E3.m1.4.4.1.1.1.1.2.1.2.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1.2.2"></sum><apply id="S3.E3.m1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><in id="S3.E3.m1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.2"></in><apply id="S3.E3.m1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.3"><ci id="S3.E3.m1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.3.1">^</ci><ci id="S3.E3.m1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.3.2">ğ‘¥</ci></apply><apply id="S3.E3.m1.1.1.1.4.cmml" xref="S3.E3.m1.1.1.1.4"><times id="S3.E3.m1.1.1.1.4.1.cmml" xref="S3.E3.m1.1.1.1.4.1"></times><ci id="S3.E3.m1.1.1.1.4.2.cmml" xref="S3.E3.m1.1.1.1.4.2">â„³</ci><ci id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1">x</ci></apply></apply></apply><apply id="S3.E3.m1.4.4.1.1.1.1.2.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1"><times id="S3.E3.m1.4.4.1.1.1.1.2.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.2"></times><ci id="S3.E3.m1.4.4.1.1.1.1.2.1.1.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.3">log</ci><ci id="S3.E3.m1.4.4.1.1.1.1.2.1.1.4.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.4">ğ‘ƒ</ci><apply id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.1">conditional</csymbol><apply id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.2"><ci id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.2.1">^</ci><ci id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.2.2">ğ‘¥</ci></apply><apply id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.3"><times id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.3.1"></times><ci id="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.3.2">ğ‘”</ci><apply id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.3.3.2"><divide id="S3.E3.m1.2.2.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1.1.1.1.1.3.3.2"></divide><ci id="S3.E3.m1.2.2.3.cmml" xref="S3.E3.m1.2.2.3">ğ‘¥</ci><apply id="S3.E3.m1.2.2.1.cmml" xref="S3.E3.m1.2.2.1"><times id="S3.E3.m1.2.2.1.2.cmml" xref="S3.E3.m1.2.2.1.2"></times><ci id="S3.E3.m1.2.2.1.3.cmml" xref="S3.E3.m1.2.2.1.3">ğ‘€</ci><ci id="S3.E3.m1.2.2.1.1.cmml" xref="S3.E3.m1.2.2.1.1">ğ‘¥</ci></apply></apply></apply></apply></apply></apply></apply></apply><apply id="S3.E3.m1.4.4.1.1.2.2.cmml" xref="S3.E3.m1.4.4.1.1.2.2"><in id="S3.E3.m1.4.4.1.1.2.2.1.cmml" xref="S3.E3.m1.4.4.1.1.2.2.1"></in><apply id="S3.E3.m1.4.4.1.1.2.2.2.cmml" xref="S3.E3.m1.4.4.1.1.2.2.2"><csymbol cd="latexml" id="S3.E3.m1.4.4.1.1.2.2.2.1.cmml" xref="S3.E3.m1.4.4.1.1.2.2.2.1">for-all</csymbol><ci id="S3.E3.m1.4.4.1.1.2.2.2.2.cmml" xref="S3.E3.m1.4.4.1.1.2.2.2.2">ğ‘›</ci></apply><ci id="S3.E3.m1.4.4.1.1.2.2.3.cmml" xref="S3.E3.m1.4.4.1.1.2.2.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.4c">l(w^{t}_{n},m)=-\sum_{\hat{x}\in\mathcal{M(\mathrm{x})}}\mathrm{log}P\left(\hat{x}\left|g\left(\frac{x}{M(x)}\right)\right.\right),\,\forall n\in N\mathrm{.}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">In FL applications, supervised learning can be challenging as we cannot ensure a proper data labeling process for supervised learning.
Here, MLM can be beneficial since it is a self-supervised learning technique that masks parts of a sentence. Those masked parts will be used as the prediction target.
Federated pre-training provides a net benefit over training on local datasets <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Ding </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>); <span class="ltx_text" style="font-size:90%;">Babakniya </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>); <span class="ltx_text" style="font-size:90%;">He </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>. However, the perplexity for large models (e.g., GPT-2) trained in a federated fashion is four orders of magnitude worse than centralized training, which is a stark indicator of low model quality <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Tian </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>); <span class="ltx_text" style="font-size:90%;">Radford </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>. Nonetheless, for use cases involving sensitive data and strict privacy regulation, full model pre-training allows the creation of foundation models based on federated data.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">While FL pre-training has shown some promise, it is brittle and has shown to be worse at model sizes above <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="100\mathrm{M}" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><mrow id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><mn id="S3.SS1.p4.1.m1.1.1.2" xref="S3.SS1.p4.1.m1.1.1.2.cmml">100</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p4.1.m1.1.1.1" xref="S3.SS1.p4.1.m1.1.1.1.cmml">â€‹</mo><mi mathvariant="normal" id="S3.SS1.p4.1.m1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><times id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1.1"></times><cn type="integer" id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2">100</cn><ci id="S3.SS1.p4.1.m1.1.1.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3">M</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">100\mathrm{M}</annotation></semantics></math> parameters. Due to the increased computation and communication demands, the practical applicability of FL is currently limited.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Parameter Efficient Fine-Tuning</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Generally, PEFT is used to further improve the performance of large models that were already trained on a large data basis and provide good performance across a variety of tasks.
This is especially effective since the data required for fine-tuning is orders of magnitude smaller than for pre-training. Also, since we use a pre-trained model, freeze most of the model parameters and insert model adapters between the transformer blocks. Typically, the adapter size in PEFT is only 1 - 2% of the pre-trained model <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Babakniya </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>.
This renders PEFT techniques well-suited for FL applications since they address computation and communication alike.
However, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Babakniya </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a></cite>] show in their study that PEFT is more sensitive towards non-IID data than FMT, but this sensitivity can be mitigated.
PEFT can be applied in FL applications as follows.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.8" class="ltx_p"><span id="S3.SS2.p2.8.1" class="ltx_text ltx_font_bold">Sparse fine-tuning of pre-trained model parameters</span>. As communication is a key concern in FL, reducing the number of parameters to communicate between client and server has become a priority.
One of the most used approaches to achieve this is BitFit <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zaken </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>.
The technique freezes almost all model parameters <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="w_{t}" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><msub id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">w</mi><mi id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">ğ‘¤</ci><ci id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">w_{t}</annotation></semantics></math> and only trains the bias term <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="b" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">b</annotation></semantics></math> and the final classification layer <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="w^{\mathrm{final}}_{t}" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><msubsup id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.2.2" xref="S3.SS2.p2.3.m3.1.1.2.2.cmml">w</mi><mi id="S3.SS2.p2.3.m3.1.1.3" xref="S3.SS2.p2.3.m3.1.1.3.cmml">t</mi><mi id="S3.SS2.p2.3.m3.1.1.2.3" xref="S3.SS2.p2.3.m3.1.1.2.3.cmml">final</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">subscript</csymbol><apply id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.2.1.cmml" xref="S3.SS2.p2.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.p2.3.m3.1.1.2.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2.2">ğ‘¤</ci><ci id="S3.SS2.p2.3.m3.1.1.2.3.cmml" xref="S3.SS2.p2.3.m3.1.1.2.3">final</ci></apply><ci id="S3.SS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">w^{\mathrm{final}}_{t}</annotation></semantics></math> over the input features <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="a_{t}" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><msub id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml">a</mi><mi id="S3.SS2.p2.4.m4.1.1.3" xref="S3.SS2.p2.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2">ğ‘</ci><ci id="S3.SS2.p2.4.m4.1.1.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">a_{t}</annotation></semantics></math>, where the next-layer input features <math id="S3.SS2.p2.5.m5.1" class="ltx_Math" alttext="a_{t+1}=a_{t}\cdot w_{t}+b" display="inline"><semantics id="S3.SS2.p2.5.m5.1a"><mrow id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml"><msub id="S3.SS2.p2.5.m5.1.1.2" xref="S3.SS2.p2.5.m5.1.1.2.cmml"><mi id="S3.SS2.p2.5.m5.1.1.2.2" xref="S3.SS2.p2.5.m5.1.1.2.2.cmml">a</mi><mrow id="S3.SS2.p2.5.m5.1.1.2.3" xref="S3.SS2.p2.5.m5.1.1.2.3.cmml"><mi id="S3.SS2.p2.5.m5.1.1.2.3.2" xref="S3.SS2.p2.5.m5.1.1.2.3.2.cmml">t</mi><mo id="S3.SS2.p2.5.m5.1.1.2.3.1" xref="S3.SS2.p2.5.m5.1.1.2.3.1.cmml">+</mo><mn id="S3.SS2.p2.5.m5.1.1.2.3.3" xref="S3.SS2.p2.5.m5.1.1.2.3.3.cmml">1</mn></mrow></msub><mo id="S3.SS2.p2.5.m5.1.1.1" xref="S3.SS2.p2.5.m5.1.1.1.cmml">=</mo><mrow id="S3.SS2.p2.5.m5.1.1.3" xref="S3.SS2.p2.5.m5.1.1.3.cmml"><mrow id="S3.SS2.p2.5.m5.1.1.3.2" xref="S3.SS2.p2.5.m5.1.1.3.2.cmml"><msub id="S3.SS2.p2.5.m5.1.1.3.2.2" xref="S3.SS2.p2.5.m5.1.1.3.2.2.cmml"><mi id="S3.SS2.p2.5.m5.1.1.3.2.2.2" xref="S3.SS2.p2.5.m5.1.1.3.2.2.2.cmml">a</mi><mi id="S3.SS2.p2.5.m5.1.1.3.2.2.3" xref="S3.SS2.p2.5.m5.1.1.3.2.2.3.cmml">t</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.5.m5.1.1.3.2.1" xref="S3.SS2.p2.5.m5.1.1.3.2.1.cmml">â‹…</mo><msub id="S3.SS2.p2.5.m5.1.1.3.2.3" xref="S3.SS2.p2.5.m5.1.1.3.2.3.cmml"><mi id="S3.SS2.p2.5.m5.1.1.3.2.3.2" xref="S3.SS2.p2.5.m5.1.1.3.2.3.2.cmml">w</mi><mi id="S3.SS2.p2.5.m5.1.1.3.2.3.3" xref="S3.SS2.p2.5.m5.1.1.3.2.3.3.cmml">t</mi></msub></mrow><mo id="S3.SS2.p2.5.m5.1.1.3.1" xref="S3.SS2.p2.5.m5.1.1.3.1.cmml">+</mo><mi id="S3.SS2.p2.5.m5.1.1.3.3" xref="S3.SS2.p2.5.m5.1.1.3.3.cmml">b</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><apply id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1"><eq id="S3.SS2.p2.5.m5.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1.1"></eq><apply id="S3.SS2.p2.5.m5.1.1.2.cmml" xref="S3.SS2.p2.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.1.1.2.1.cmml" xref="S3.SS2.p2.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS2.p2.5.m5.1.1.2.2.cmml" xref="S3.SS2.p2.5.m5.1.1.2.2">ğ‘</ci><apply id="S3.SS2.p2.5.m5.1.1.2.3.cmml" xref="S3.SS2.p2.5.m5.1.1.2.3"><plus id="S3.SS2.p2.5.m5.1.1.2.3.1.cmml" xref="S3.SS2.p2.5.m5.1.1.2.3.1"></plus><ci id="S3.SS2.p2.5.m5.1.1.2.3.2.cmml" xref="S3.SS2.p2.5.m5.1.1.2.3.2">ğ‘¡</ci><cn type="integer" id="S3.SS2.p2.5.m5.1.1.2.3.3.cmml" xref="S3.SS2.p2.5.m5.1.1.2.3.3">1</cn></apply></apply><apply id="S3.SS2.p2.5.m5.1.1.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3"><plus id="S3.SS2.p2.5.m5.1.1.3.1.cmml" xref="S3.SS2.p2.5.m5.1.1.3.1"></plus><apply id="S3.SS2.p2.5.m5.1.1.3.2.cmml" xref="S3.SS2.p2.5.m5.1.1.3.2"><ci id="S3.SS2.p2.5.m5.1.1.3.2.1.cmml" xref="S3.SS2.p2.5.m5.1.1.3.2.1">â‹…</ci><apply id="S3.SS2.p2.5.m5.1.1.3.2.2.cmml" xref="S3.SS2.p2.5.m5.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.1.1.3.2.2.1.cmml" xref="S3.SS2.p2.5.m5.1.1.3.2.2">subscript</csymbol><ci id="S3.SS2.p2.5.m5.1.1.3.2.2.2.cmml" xref="S3.SS2.p2.5.m5.1.1.3.2.2.2">ğ‘</ci><ci id="S3.SS2.p2.5.m5.1.1.3.2.2.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3.2.2.3">ğ‘¡</ci></apply><apply id="S3.SS2.p2.5.m5.1.1.3.2.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.1.1.3.2.3.1.cmml" xref="S3.SS2.p2.5.m5.1.1.3.2.3">subscript</csymbol><ci id="S3.SS2.p2.5.m5.1.1.3.2.3.2.cmml" xref="S3.SS2.p2.5.m5.1.1.3.2.3.2">ğ‘¤</ci><ci id="S3.SS2.p2.5.m5.1.1.3.2.3.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3.2.3.3">ğ‘¡</ci></apply></apply><ci id="S3.SS2.p2.5.m5.1.1.3.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">a_{t+1}=a_{t}\cdot w_{t}+b</annotation></semantics></math>.
With this technique, it is only required to communicate <math id="S3.SS2.p2.6.m6.1" class="ltx_Math" alttext="b" display="inline"><semantics id="S3.SS2.p2.6.m6.1a"><mi id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><ci id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">b</annotation></semantics></math> and <math id="S3.SS2.p2.7.m7.1" class="ltx_Math" alttext="w^{\mathrm{final}}_{t}" display="inline"><semantics id="S3.SS2.p2.7.m7.1a"><msubsup id="S3.SS2.p2.7.m7.1.1" xref="S3.SS2.p2.7.m7.1.1.cmml"><mi id="S3.SS2.p2.7.m7.1.1.2.2" xref="S3.SS2.p2.7.m7.1.1.2.2.cmml">w</mi><mi id="S3.SS2.p2.7.m7.1.1.3" xref="S3.SS2.p2.7.m7.1.1.3.cmml">t</mi><mi id="S3.SS2.p2.7.m7.1.1.2.3" xref="S3.SS2.p2.7.m7.1.1.2.3.cmml">final</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m7.1b"><apply id="S3.SS2.p2.7.m7.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1">subscript</csymbol><apply id="S3.SS2.p2.7.m7.1.1.2.cmml" xref="S3.SS2.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.2.1.cmml" xref="S3.SS2.p2.7.m7.1.1">superscript</csymbol><ci id="S3.SS2.p2.7.m7.1.1.2.2.cmml" xref="S3.SS2.p2.7.m7.1.1.2.2">ğ‘¤</ci><ci id="S3.SS2.p2.7.m7.1.1.2.3.cmml" xref="S3.SS2.p2.7.m7.1.1.2.3">final</ci></apply><ci id="S3.SS2.p2.7.m7.1.1.3.cmml" xref="S3.SS2.p2.7.m7.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m7.1c">w^{\mathrm{final}}_{t}</annotation></semantics></math>. The communication load is reduced by <math id="S3.SS2.p2.8.m8.1" class="ltx_Math" alttext="\geq 99\%" display="inline"><semantics id="S3.SS2.p2.8.m8.1a"><mrow id="S3.SS2.p2.8.m8.1.1" xref="S3.SS2.p2.8.m8.1.1.cmml"><mi id="S3.SS2.p2.8.m8.1.1.2" xref="S3.SS2.p2.8.m8.1.1.2.cmml"></mi><mo id="S3.SS2.p2.8.m8.1.1.1" xref="S3.SS2.p2.8.m8.1.1.1.cmml">â‰¥</mo><mrow id="S3.SS2.p2.8.m8.1.1.3" xref="S3.SS2.p2.8.m8.1.1.3.cmml"><mn id="S3.SS2.p2.8.m8.1.1.3.2" xref="S3.SS2.p2.8.m8.1.1.3.2.cmml">99</mn><mo id="S3.SS2.p2.8.m8.1.1.3.1" xref="S3.SS2.p2.8.m8.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m8.1b"><apply id="S3.SS2.p2.8.m8.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1"><geq id="S3.SS2.p2.8.m8.1.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1.1"></geq><csymbol cd="latexml" id="S3.SS2.p2.8.m8.1.1.2.cmml" xref="S3.SS2.p2.8.m8.1.1.2">absent</csymbol><apply id="S3.SS2.p2.8.m8.1.1.3.cmml" xref="S3.SS2.p2.8.m8.1.1.3"><csymbol cd="latexml" id="S3.SS2.p2.8.m8.1.1.3.1.cmml" xref="S3.SS2.p2.8.m8.1.1.3.1">percent</csymbol><cn type="integer" id="S3.SS2.p2.8.m8.1.1.3.2.cmml" xref="S3.SS2.p2.8.m8.1.1.3.2">99</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m8.1c">\geq 99\%</annotation></semantics></math>, i.e., instead of communicating several 100M parameters, only a few 100K parameters are sent over the network.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Sun </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a></cite>] propose FedPEFT, a framework for federated transformer fine-tuning that freezes the model weights to retain upstream knowledge within the model and adjust the systematic error for the downstream task. Their experimental results on vision transformers (ViT-B with 85M parameters) show on-par performance compared to full model fine-tuning on non-IID data, all the while reducing communication byÂ 99.8%.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.5" class="ltx_p"><span id="S3.SS2.p4.5.1" class="ltx_text ltx_font_bold">Adapter-based fine-tuning of additionally added parameters</span>. When aiming to maintain a pre-trained model while introducing task-specific knowledge, adapter-based fine-tuning techniques provide strong performance and on-par efficiency compared to sparse fine-tuning techniques <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Houlsby </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>. Here, we introduce two adapter layers in each transformer block of a foundation model. The adapter layer <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="a^{a}_{t+1}" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><msubsup id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml"><mi id="S3.SS2.p4.1.m1.1.1.2.2" xref="S3.SS2.p4.1.m1.1.1.2.2.cmml">a</mi><mrow id="S3.SS2.p4.1.m1.1.1.3" xref="S3.SS2.p4.1.m1.1.1.3.cmml"><mi id="S3.SS2.p4.1.m1.1.1.3.2" xref="S3.SS2.p4.1.m1.1.1.3.2.cmml">t</mi><mo id="S3.SS2.p4.1.m1.1.1.3.1" xref="S3.SS2.p4.1.m1.1.1.3.1.cmml">+</mo><mn id="S3.SS2.p4.1.m1.1.1.3.3" xref="S3.SS2.p4.1.m1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.SS2.p4.1.m1.1.1.2.3" xref="S3.SS2.p4.1.m1.1.1.2.3.cmml">a</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><apply id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">subscript</csymbol><apply id="S3.SS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.1.1.2.1.cmml" xref="S3.SS2.p4.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p4.1.m1.1.1.2.2.cmml" xref="S3.SS2.p4.1.m1.1.1.2.2">ğ‘</ci><ci id="S3.SS2.p4.1.m1.1.1.2.3.cmml" xref="S3.SS2.p4.1.m1.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3"><plus id="S3.SS2.p4.1.m1.1.1.3.1.cmml" xref="S3.SS2.p4.1.m1.1.1.3.1"></plus><ci id="S3.SS2.p4.1.m1.1.1.3.2.cmml" xref="S3.SS2.p4.1.m1.1.1.3.2">ğ‘¡</ci><cn type="integer" id="S3.SS2.p4.1.m1.1.1.3.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">a^{a}_{t+1}</annotation></semantics></math> is calculated based on a downstream projection <math id="S3.SS2.p4.2.m2.1" class="ltx_Math" alttext="w_{t}^{\mathrm{down}}" display="inline"><semantics id="S3.SS2.p4.2.m2.1a"><msubsup id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.p4.2.m2.1.1.2.2" xref="S3.SS2.p4.2.m2.1.1.2.2.cmml">w</mi><mi id="S3.SS2.p4.2.m2.1.1.2.3" xref="S3.SS2.p4.2.m2.1.1.2.3.cmml">t</mi><mi id="S3.SS2.p4.2.m2.1.1.3" xref="S3.SS2.p4.2.m2.1.1.3.cmml">down</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><apply id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">superscript</csymbol><apply id="S3.SS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.2.1.cmml" xref="S3.SS2.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p4.2.m2.1.1.2.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2.2">ğ‘¤</ci><ci id="S3.SS2.p4.2.m2.1.1.2.3.cmml" xref="S3.SS2.p4.2.m2.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.SS2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3">down</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">w_{t}^{\mathrm{down}}</annotation></semantics></math> of input feature <math id="S3.SS2.p4.3.m3.1" class="ltx_Math" alttext="a^{a}_{t}" display="inline"><semantics id="S3.SS2.p4.3.m3.1a"><msubsup id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml"><mi id="S3.SS2.p4.3.m3.1.1.2.2" xref="S3.SS2.p4.3.m3.1.1.2.2.cmml">a</mi><mi id="S3.SS2.p4.3.m3.1.1.3" xref="S3.SS2.p4.3.m3.1.1.3.cmml">t</mi><mi id="S3.SS2.p4.3.m3.1.1.2.3" xref="S3.SS2.p4.3.m3.1.1.2.3.cmml">a</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><apply id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.3.m3.1.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1">subscript</csymbol><apply id="S3.SS2.p4.3.m3.1.1.2.cmml" xref="S3.SS2.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.3.m3.1.1.2.1.cmml" xref="S3.SS2.p4.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.p4.3.m3.1.1.2.2.cmml" xref="S3.SS2.p4.3.m3.1.1.2.2">ğ‘</ci><ci id="S3.SS2.p4.3.m3.1.1.2.3.cmml" xref="S3.SS2.p4.3.m3.1.1.2.3">ğ‘</ci></apply><ci id="S3.SS2.p4.3.m3.1.1.3.cmml" xref="S3.SS2.p4.3.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">a^{a}_{t}</annotation></semantics></math> into a lower-dimensional space <math id="S3.SS2.p4.4.m4.1" class="ltx_Math" alttext="w_{t}^{\mathrm{down}}\in\mathcal{R}^{d\times r}" display="inline"><semantics id="S3.SS2.p4.4.m4.1a"><mrow id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml"><msubsup id="S3.SS2.p4.4.m4.1.1.2" xref="S3.SS2.p4.4.m4.1.1.2.cmml"><mi id="S3.SS2.p4.4.m4.1.1.2.2.2" xref="S3.SS2.p4.4.m4.1.1.2.2.2.cmml">w</mi><mi id="S3.SS2.p4.4.m4.1.1.2.2.3" xref="S3.SS2.p4.4.m4.1.1.2.2.3.cmml">t</mi><mi id="S3.SS2.p4.4.m4.1.1.2.3" xref="S3.SS2.p4.4.m4.1.1.2.3.cmml">down</mi></msubsup><mo id="S3.SS2.p4.4.m4.1.1.1" xref="S3.SS2.p4.4.m4.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p4.4.m4.1.1.3" xref="S3.SS2.p4.4.m4.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.4.m4.1.1.3.2" xref="S3.SS2.p4.4.m4.1.1.3.2.cmml">â„›</mi><mrow id="S3.SS2.p4.4.m4.1.1.3.3" xref="S3.SS2.p4.4.m4.1.1.3.3.cmml"><mi id="S3.SS2.p4.4.m4.1.1.3.3.2" xref="S3.SS2.p4.4.m4.1.1.3.3.2.cmml">d</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p4.4.m4.1.1.3.3.1" xref="S3.SS2.p4.4.m4.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS2.p4.4.m4.1.1.3.3.3" xref="S3.SS2.p4.4.m4.1.1.3.3.3.cmml">r</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.1b"><apply id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1"><in id="S3.SS2.p4.4.m4.1.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1.1"></in><apply id="S3.SS2.p4.4.m4.1.1.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m4.1.1.2.1.cmml" xref="S3.SS2.p4.4.m4.1.1.2">superscript</csymbol><apply id="S3.SS2.p4.4.m4.1.1.2.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m4.1.1.2.2.1.cmml" xref="S3.SS2.p4.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS2.p4.4.m4.1.1.2.2.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2.2.2">ğ‘¤</ci><ci id="S3.SS2.p4.4.m4.1.1.2.2.3.cmml" xref="S3.SS2.p4.4.m4.1.1.2.2.3">ğ‘¡</ci></apply><ci id="S3.SS2.p4.4.m4.1.1.2.3.cmml" xref="S3.SS2.p4.4.m4.1.1.2.3">down</ci></apply><apply id="S3.SS2.p4.4.m4.1.1.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m4.1.1.3.1.cmml" xref="S3.SS2.p4.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS2.p4.4.m4.1.1.3.2.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2">â„›</ci><apply id="S3.SS2.p4.4.m4.1.1.3.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3.3"><times id="S3.SS2.p4.4.m4.1.1.3.3.1.cmml" xref="S3.SS2.p4.4.m4.1.1.3.3.1"></times><ci id="S3.SS2.p4.4.m4.1.1.3.3.2.cmml" xref="S3.SS2.p4.4.m4.1.1.3.3.2">ğ‘‘</ci><ci id="S3.SS2.p4.4.m4.1.1.3.3.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3.3.3">ğ‘Ÿ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.1c">w_{t}^{\mathrm{down}}\in\mathcal{R}^{d\times r}</annotation></semantics></math> followed by an upstream projection <math id="S3.SS2.p4.5.m5.1" class="ltx_Math" alttext="w_{t}^{\mathrm{up}}\in\mathcal{R}^{r\times u}" display="inline"><semantics id="S3.SS2.p4.5.m5.1a"><mrow id="S3.SS2.p4.5.m5.1.1" xref="S3.SS2.p4.5.m5.1.1.cmml"><msubsup id="S3.SS2.p4.5.m5.1.1.2" xref="S3.SS2.p4.5.m5.1.1.2.cmml"><mi id="S3.SS2.p4.5.m5.1.1.2.2.2" xref="S3.SS2.p4.5.m5.1.1.2.2.2.cmml">w</mi><mi id="S3.SS2.p4.5.m5.1.1.2.2.3" xref="S3.SS2.p4.5.m5.1.1.2.2.3.cmml">t</mi><mi id="S3.SS2.p4.5.m5.1.1.2.3" xref="S3.SS2.p4.5.m5.1.1.2.3.cmml">up</mi></msubsup><mo id="S3.SS2.p4.5.m5.1.1.1" xref="S3.SS2.p4.5.m5.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p4.5.m5.1.1.3" xref="S3.SS2.p4.5.m5.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.5.m5.1.1.3.2" xref="S3.SS2.p4.5.m5.1.1.3.2.cmml">â„›</mi><mrow id="S3.SS2.p4.5.m5.1.1.3.3" xref="S3.SS2.p4.5.m5.1.1.3.3.cmml"><mi id="S3.SS2.p4.5.m5.1.1.3.3.2" xref="S3.SS2.p4.5.m5.1.1.3.3.2.cmml">r</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p4.5.m5.1.1.3.3.1" xref="S3.SS2.p4.5.m5.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS2.p4.5.m5.1.1.3.3.3" xref="S3.SS2.p4.5.m5.1.1.3.3.3.cmml">u</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.5.m5.1b"><apply id="S3.SS2.p4.5.m5.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1"><in id="S3.SS2.p4.5.m5.1.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1.1"></in><apply id="S3.SS2.p4.5.m5.1.1.2.cmml" xref="S3.SS2.p4.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p4.5.m5.1.1.2.1.cmml" xref="S3.SS2.p4.5.m5.1.1.2">superscript</csymbol><apply id="S3.SS2.p4.5.m5.1.1.2.2.cmml" xref="S3.SS2.p4.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p4.5.m5.1.1.2.2.1.cmml" xref="S3.SS2.p4.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS2.p4.5.m5.1.1.2.2.2.cmml" xref="S3.SS2.p4.5.m5.1.1.2.2.2">ğ‘¤</ci><ci id="S3.SS2.p4.5.m5.1.1.2.2.3.cmml" xref="S3.SS2.p4.5.m5.1.1.2.2.3">ğ‘¡</ci></apply><ci id="S3.SS2.p4.5.m5.1.1.2.3.cmml" xref="S3.SS2.p4.5.m5.1.1.2.3">up</ci></apply><apply id="S3.SS2.p4.5.m5.1.1.3.cmml" xref="S3.SS2.p4.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p4.5.m5.1.1.3.1.cmml" xref="S3.SS2.p4.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS2.p4.5.m5.1.1.3.2.cmml" xref="S3.SS2.p4.5.m5.1.1.3.2">â„›</ci><apply id="S3.SS2.p4.5.m5.1.1.3.3.cmml" xref="S3.SS2.p4.5.m5.1.1.3.3"><times id="S3.SS2.p4.5.m5.1.1.3.3.1.cmml" xref="S3.SS2.p4.5.m5.1.1.3.3.1"></times><ci id="S3.SS2.p4.5.m5.1.1.3.3.2.cmml" xref="S3.SS2.p4.5.m5.1.1.3.3.2">ğ‘Ÿ</ci><ci id="S3.SS2.p4.5.m5.1.1.3.3.3.cmml" xref="S3.SS2.p4.5.m5.1.1.3.3.3">ğ‘¢</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.5.m5.1c">w_{t}^{\mathrm{up}}\in\mathcal{R}^{r\times u}</annotation></semantics></math>, resulting in</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.1" class="ltx_Math" alttext="a^{a}_{t+1}=w_{t}^{\mathrm{up}}\cdot h(w_{t}^{\mathrm{down}}\cdot a^{a}_{t})\mathrm{.}" display="block"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><msubsup id="S3.E4.m1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.3.2.2" xref="S3.E4.m1.1.1.1.1.3.2.2.cmml">a</mi><mrow id="S3.E4.m1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.3.3.cmml"><mi id="S3.E4.m1.1.1.1.1.3.3.2" xref="S3.E4.m1.1.1.1.1.3.3.2.cmml">t</mi><mo id="S3.E4.m1.1.1.1.1.3.3.1" xref="S3.E4.m1.1.1.1.1.3.3.1.cmml">+</mo><mn id="S3.E4.m1.1.1.1.1.3.3.3" xref="S3.E4.m1.1.1.1.1.3.3.3.cmml">1</mn></mrow><mi id="S3.E4.m1.1.1.1.1.3.2.3" xref="S3.E4.m1.1.1.1.1.3.2.3.cmml">a</mi></msubsup><mo id="S3.E4.m1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.3.cmml"><msubsup id="S3.E4.m1.1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.1.3.2.cmml"><mi id="S3.E4.m1.1.1.1.1.1.3.2.2.2" xref="S3.E4.m1.1.1.1.1.1.3.2.2.2.cmml">w</mi><mi id="S3.E4.m1.1.1.1.1.1.3.2.2.3" xref="S3.E4.m1.1.1.1.1.1.3.2.2.3.cmml">t</mi><mi id="S3.E4.m1.1.1.1.1.1.3.2.3" xref="S3.E4.m1.1.1.1.1.1.3.2.3.cmml">up</mi></msubsup><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.1.1.1.1.1.3.1" xref="S3.E4.m1.1.1.1.1.1.3.1.cmml">â‹…</mo><mi id="S3.E4.m1.1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.1.3.3.cmml">h</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml"><msubsup id="S3.E4.m1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.2.2.cmml">w</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.2.2.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.2.3.cmml">t</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.3.cmml">down</mi></msubsup><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml">â‹…</mo><msubsup id="S3.E4.m1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.2.2.cmml">a</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.3.cmml">t</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.2.3.cmml">a</mi></msubsup></mrow><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><eq id="S3.E4.m1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2"></eq><apply id="S3.E4.m1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3">subscript</csymbol><apply id="S3.E4.m1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.2.1.cmml" xref="S3.E4.m1.1.1.1.1.3">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.2.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2.2">ğ‘</ci><ci id="S3.E4.m1.1.1.1.1.3.2.3.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3">ğ‘</ci></apply><apply id="S3.E4.m1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3"><plus id="S3.E4.m1.1.1.1.1.3.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1"></plus><ci id="S3.E4.m1.1.1.1.1.3.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2">ğ‘¡</ci><cn type="integer" id="S3.E4.m1.1.1.1.1.3.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.3">1</cn></apply></apply><apply id="S3.E4.m1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1"><times id="S3.E4.m1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.2"></times><apply id="S3.E4.m1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.3"><ci id="S3.E4.m1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.3.1">â‹…</ci><apply id="S3.E4.m1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.3.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.3.2">superscript</csymbol><apply id="S3.E4.m1.1.1.1.1.1.3.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.3.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.3.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.3.2.2.2">ğ‘¤</ci><ci id="S3.E4.m1.1.1.1.1.1.3.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.3.2.2.3">ğ‘¡</ci></apply><ci id="S3.E4.m1.1.1.1.1.1.3.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.3.2.3">up</ci></apply><ci id="S3.E4.m1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.1.3.3">â„</ci></apply><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1"><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1">â‹…</ci><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.2.2">ğ‘¤</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.2.3">ğ‘¡</ci></apply><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.3">down</ci></apply><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.2.2">ğ‘</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.2.3">ğ‘</ci></apply><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">a^{a}_{t+1}=w_{t}^{\mathrm{up}}\cdot h(w_{t}^{\mathrm{down}}\cdot a^{a}_{t})\mathrm{.}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.1" class="ltx_p">With this, we can fine-tune an FM over much fewer dimensions than when fully fine-tuning a model. This saves both computational resources and communication costs in the same range as FedPEFT.</p>
</div>
<div id="S3.SS2.p6" class="ltx_para">
<p id="S3.SS2.p6.8" class="ltx_p">An improvement with regard to computational and communication efficiency over additional adapters is low-rank adapters (LoRA) <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Hu </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>.
The technique uses a lower dimensional representation <math id="S3.SS2.p6.1.m1.1" class="ltx_Math" alttext="\mathbf{A}\in\mathcal{R}^{r\times u}" display="inline"><semantics id="S3.SS2.p6.1.m1.1a"><mrow id="S3.SS2.p6.1.m1.1.1" xref="S3.SS2.p6.1.m1.1.1.cmml"><mi id="S3.SS2.p6.1.m1.1.1.2" xref="S3.SS2.p6.1.m1.1.1.2.cmml">ğ€</mi><mo id="S3.SS2.p6.1.m1.1.1.1" xref="S3.SS2.p6.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p6.1.m1.1.1.3" xref="S3.SS2.p6.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p6.1.m1.1.1.3.2" xref="S3.SS2.p6.1.m1.1.1.3.2.cmml">â„›</mi><mrow id="S3.SS2.p6.1.m1.1.1.3.3" xref="S3.SS2.p6.1.m1.1.1.3.3.cmml"><mi id="S3.SS2.p6.1.m1.1.1.3.3.2" xref="S3.SS2.p6.1.m1.1.1.3.3.2.cmml">r</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p6.1.m1.1.1.3.3.1" xref="S3.SS2.p6.1.m1.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS2.p6.1.m1.1.1.3.3.3" xref="S3.SS2.p6.1.m1.1.1.3.3.3.cmml">u</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.1.m1.1b"><apply id="S3.SS2.p6.1.m1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1"><in id="S3.SS2.p6.1.m1.1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1.1"></in><ci id="S3.SS2.p6.1.m1.1.1.2.cmml" xref="S3.SS2.p6.1.m1.1.1.2">ğ€</ci><apply id="S3.SS2.p6.1.m1.1.1.3.cmml" xref="S3.SS2.p6.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p6.1.m1.1.1.3.1.cmml" xref="S3.SS2.p6.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.p6.1.m1.1.1.3.2.cmml" xref="S3.SS2.p6.1.m1.1.1.3.2">â„›</ci><apply id="S3.SS2.p6.1.m1.1.1.3.3.cmml" xref="S3.SS2.p6.1.m1.1.1.3.3"><times id="S3.SS2.p6.1.m1.1.1.3.3.1.cmml" xref="S3.SS2.p6.1.m1.1.1.3.3.1"></times><ci id="S3.SS2.p6.1.m1.1.1.3.3.2.cmml" xref="S3.SS2.p6.1.m1.1.1.3.3.2">ğ‘Ÿ</ci><ci id="S3.SS2.p6.1.m1.1.1.3.3.3.cmml" xref="S3.SS2.p6.1.m1.1.1.3.3.3">ğ‘¢</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.1.m1.1c">\mathbf{A}\in\mathcal{R}^{r\times u}</annotation></semantics></math>, where <math id="S3.SS2.p6.2.m2.1" class="ltx_Math" alttext="u" display="inline"><semantics id="S3.SS2.p6.2.m2.1a"><mi id="S3.SS2.p6.2.m2.1.1" xref="S3.SS2.p6.2.m2.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.2.m2.1b"><ci id="S3.SS2.p6.2.m2.1.1.cmml" xref="S3.SS2.p6.2.m2.1.1">ğ‘¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.2.m2.1c">u</annotation></semantics></math> is the dimension of the next layer after the LoRA adapter and <math id="S3.SS2.p6.3.m3.1" class="ltx_Math" alttext="\mathbf{B}\in\mathcal{R}^{d\times r}" display="inline"><semantics id="S3.SS2.p6.3.m3.1a"><mrow id="S3.SS2.p6.3.m3.1.1" xref="S3.SS2.p6.3.m3.1.1.cmml"><mi id="S3.SS2.p6.3.m3.1.1.2" xref="S3.SS2.p6.3.m3.1.1.2.cmml">ğ</mi><mo id="S3.SS2.p6.3.m3.1.1.1" xref="S3.SS2.p6.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p6.3.m3.1.1.3" xref="S3.SS2.p6.3.m3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p6.3.m3.1.1.3.2" xref="S3.SS2.p6.3.m3.1.1.3.2.cmml">â„›</mi><mrow id="S3.SS2.p6.3.m3.1.1.3.3" xref="S3.SS2.p6.3.m3.1.1.3.3.cmml"><mi id="S3.SS2.p6.3.m3.1.1.3.3.2" xref="S3.SS2.p6.3.m3.1.1.3.3.2.cmml">d</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p6.3.m3.1.1.3.3.1" xref="S3.SS2.p6.3.m3.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS2.p6.3.m3.1.1.3.3.3" xref="S3.SS2.p6.3.m3.1.1.3.3.3.cmml">r</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.3.m3.1b"><apply id="S3.SS2.p6.3.m3.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1"><in id="S3.SS2.p6.3.m3.1.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1.1"></in><ci id="S3.SS2.p6.3.m3.1.1.2.cmml" xref="S3.SS2.p6.3.m3.1.1.2">ğ</ci><apply id="S3.SS2.p6.3.m3.1.1.3.cmml" xref="S3.SS2.p6.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p6.3.m3.1.1.3.1.cmml" xref="S3.SS2.p6.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS2.p6.3.m3.1.1.3.2.cmml" xref="S3.SS2.p6.3.m3.1.1.3.2">â„›</ci><apply id="S3.SS2.p6.3.m3.1.1.3.3.cmml" xref="S3.SS2.p6.3.m3.1.1.3.3"><times id="S3.SS2.p6.3.m3.1.1.3.3.1.cmml" xref="S3.SS2.p6.3.m3.1.1.3.3.1"></times><ci id="S3.SS2.p6.3.m3.1.1.3.3.2.cmml" xref="S3.SS2.p6.3.m3.1.1.3.3.2">ğ‘‘</ci><ci id="S3.SS2.p6.3.m3.1.1.3.3.3.cmml" xref="S3.SS2.p6.3.m3.1.1.3.3.3">ğ‘Ÿ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.3.m3.1c">\mathbf{B}\in\mathcal{R}^{d\times r}</annotation></semantics></math>, where <math id="S3.SS2.p6.4.m4.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS2.p6.4.m4.1a"><mi id="S3.SS2.p6.4.m4.1.1" xref="S3.SS2.p6.4.m4.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.4.m4.1b"><ci id="S3.SS2.p6.4.m4.1.1.cmml" xref="S3.SS2.p6.4.m4.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.4.m4.1c">d</annotation></semantics></math> is the dimension of the previous LoRA adapter. The weight updates are calculated with <math id="S3.SS2.p6.5.m5.1" class="ltx_Math" alttext="w_{t+1}=w_{t}+\Delta w=w_{t}+\mathbf{B}\mathbf{A}" display="inline"><semantics id="S3.SS2.p6.5.m5.1a"><mrow id="S3.SS2.p6.5.m5.1.1" xref="S3.SS2.p6.5.m5.1.1.cmml"><msub id="S3.SS2.p6.5.m5.1.1.2" xref="S3.SS2.p6.5.m5.1.1.2.cmml"><mi id="S3.SS2.p6.5.m5.1.1.2.2" xref="S3.SS2.p6.5.m5.1.1.2.2.cmml">w</mi><mrow id="S3.SS2.p6.5.m5.1.1.2.3" xref="S3.SS2.p6.5.m5.1.1.2.3.cmml"><mi id="S3.SS2.p6.5.m5.1.1.2.3.2" xref="S3.SS2.p6.5.m5.1.1.2.3.2.cmml">t</mi><mo id="S3.SS2.p6.5.m5.1.1.2.3.1" xref="S3.SS2.p6.5.m5.1.1.2.3.1.cmml">+</mo><mn id="S3.SS2.p6.5.m5.1.1.2.3.3" xref="S3.SS2.p6.5.m5.1.1.2.3.3.cmml">1</mn></mrow></msub><mo id="S3.SS2.p6.5.m5.1.1.3" xref="S3.SS2.p6.5.m5.1.1.3.cmml">=</mo><mrow id="S3.SS2.p6.5.m5.1.1.4" xref="S3.SS2.p6.5.m5.1.1.4.cmml"><msub id="S3.SS2.p6.5.m5.1.1.4.2" xref="S3.SS2.p6.5.m5.1.1.4.2.cmml"><mi id="S3.SS2.p6.5.m5.1.1.4.2.2" xref="S3.SS2.p6.5.m5.1.1.4.2.2.cmml">w</mi><mi id="S3.SS2.p6.5.m5.1.1.4.2.3" xref="S3.SS2.p6.5.m5.1.1.4.2.3.cmml">t</mi></msub><mo id="S3.SS2.p6.5.m5.1.1.4.1" xref="S3.SS2.p6.5.m5.1.1.4.1.cmml">+</mo><mrow id="S3.SS2.p6.5.m5.1.1.4.3" xref="S3.SS2.p6.5.m5.1.1.4.3.cmml"><mi mathvariant="normal" id="S3.SS2.p6.5.m5.1.1.4.3.2" xref="S3.SS2.p6.5.m5.1.1.4.3.2.cmml">Î”</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p6.5.m5.1.1.4.3.1" xref="S3.SS2.p6.5.m5.1.1.4.3.1.cmml">â€‹</mo><mi id="S3.SS2.p6.5.m5.1.1.4.3.3" xref="S3.SS2.p6.5.m5.1.1.4.3.3.cmml">w</mi></mrow></mrow><mo id="S3.SS2.p6.5.m5.1.1.5" xref="S3.SS2.p6.5.m5.1.1.5.cmml">=</mo><mrow id="S3.SS2.p6.5.m5.1.1.6" xref="S3.SS2.p6.5.m5.1.1.6.cmml"><msub id="S3.SS2.p6.5.m5.1.1.6.2" xref="S3.SS2.p6.5.m5.1.1.6.2.cmml"><mi id="S3.SS2.p6.5.m5.1.1.6.2.2" xref="S3.SS2.p6.5.m5.1.1.6.2.2.cmml">w</mi><mi id="S3.SS2.p6.5.m5.1.1.6.2.3" xref="S3.SS2.p6.5.m5.1.1.6.2.3.cmml">t</mi></msub><mo id="S3.SS2.p6.5.m5.1.1.6.1" xref="S3.SS2.p6.5.m5.1.1.6.1.cmml">+</mo><mi id="S3.SS2.p6.5.m5.1.1.6.3" xref="S3.SS2.p6.5.m5.1.1.6.3.cmml">ğğ€</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.5.m5.1b"><apply id="S3.SS2.p6.5.m5.1.1.cmml" xref="S3.SS2.p6.5.m5.1.1"><and id="S3.SS2.p6.5.m5.1.1a.cmml" xref="S3.SS2.p6.5.m5.1.1"></and><apply id="S3.SS2.p6.5.m5.1.1b.cmml" xref="S3.SS2.p6.5.m5.1.1"><eq id="S3.SS2.p6.5.m5.1.1.3.cmml" xref="S3.SS2.p6.5.m5.1.1.3"></eq><apply id="S3.SS2.p6.5.m5.1.1.2.cmml" xref="S3.SS2.p6.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p6.5.m5.1.1.2.1.cmml" xref="S3.SS2.p6.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS2.p6.5.m5.1.1.2.2.cmml" xref="S3.SS2.p6.5.m5.1.1.2.2">ğ‘¤</ci><apply id="S3.SS2.p6.5.m5.1.1.2.3.cmml" xref="S3.SS2.p6.5.m5.1.1.2.3"><plus id="S3.SS2.p6.5.m5.1.1.2.3.1.cmml" xref="S3.SS2.p6.5.m5.1.1.2.3.1"></plus><ci id="S3.SS2.p6.5.m5.1.1.2.3.2.cmml" xref="S3.SS2.p6.5.m5.1.1.2.3.2">ğ‘¡</ci><cn type="integer" id="S3.SS2.p6.5.m5.1.1.2.3.3.cmml" xref="S3.SS2.p6.5.m5.1.1.2.3.3">1</cn></apply></apply><apply id="S3.SS2.p6.5.m5.1.1.4.cmml" xref="S3.SS2.p6.5.m5.1.1.4"><plus id="S3.SS2.p6.5.m5.1.1.4.1.cmml" xref="S3.SS2.p6.5.m5.1.1.4.1"></plus><apply id="S3.SS2.p6.5.m5.1.1.4.2.cmml" xref="S3.SS2.p6.5.m5.1.1.4.2"><csymbol cd="ambiguous" id="S3.SS2.p6.5.m5.1.1.4.2.1.cmml" xref="S3.SS2.p6.5.m5.1.1.4.2">subscript</csymbol><ci id="S3.SS2.p6.5.m5.1.1.4.2.2.cmml" xref="S3.SS2.p6.5.m5.1.1.4.2.2">ğ‘¤</ci><ci id="S3.SS2.p6.5.m5.1.1.4.2.3.cmml" xref="S3.SS2.p6.5.m5.1.1.4.2.3">ğ‘¡</ci></apply><apply id="S3.SS2.p6.5.m5.1.1.4.3.cmml" xref="S3.SS2.p6.5.m5.1.1.4.3"><times id="S3.SS2.p6.5.m5.1.1.4.3.1.cmml" xref="S3.SS2.p6.5.m5.1.1.4.3.1"></times><ci id="S3.SS2.p6.5.m5.1.1.4.3.2.cmml" xref="S3.SS2.p6.5.m5.1.1.4.3.2">Î”</ci><ci id="S3.SS2.p6.5.m5.1.1.4.3.3.cmml" xref="S3.SS2.p6.5.m5.1.1.4.3.3">ğ‘¤</ci></apply></apply></apply><apply id="S3.SS2.p6.5.m5.1.1c.cmml" xref="S3.SS2.p6.5.m5.1.1"><eq id="S3.SS2.p6.5.m5.1.1.5.cmml" xref="S3.SS2.p6.5.m5.1.1.5"></eq><share href="#S3.SS2.p6.5.m5.1.1.4.cmml" id="S3.SS2.p6.5.m5.1.1d.cmml" xref="S3.SS2.p6.5.m5.1.1"></share><apply id="S3.SS2.p6.5.m5.1.1.6.cmml" xref="S3.SS2.p6.5.m5.1.1.6"><plus id="S3.SS2.p6.5.m5.1.1.6.1.cmml" xref="S3.SS2.p6.5.m5.1.1.6.1"></plus><apply id="S3.SS2.p6.5.m5.1.1.6.2.cmml" xref="S3.SS2.p6.5.m5.1.1.6.2"><csymbol cd="ambiguous" id="S3.SS2.p6.5.m5.1.1.6.2.1.cmml" xref="S3.SS2.p6.5.m5.1.1.6.2">subscript</csymbol><ci id="S3.SS2.p6.5.m5.1.1.6.2.2.cmml" xref="S3.SS2.p6.5.m5.1.1.6.2.2">ğ‘¤</ci><ci id="S3.SS2.p6.5.m5.1.1.6.2.3.cmml" xref="S3.SS2.p6.5.m5.1.1.6.2.3">ğ‘¡</ci></apply><ci id="S3.SS2.p6.5.m5.1.1.6.3.cmml" xref="S3.SS2.p6.5.m5.1.1.6.3">ğğ€</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.5.m5.1c">w_{t+1}=w_{t}+\Delta w=w_{t}+\mathbf{B}\mathbf{A}</annotation></semantics></math>.
<math id="S3.SS2.p6.6.m6.3" class="ltx_Math" alttext="r\ll\min(d,u)" display="inline"><semantics id="S3.SS2.p6.6.m6.3a"><mrow id="S3.SS2.p6.6.m6.3.4" xref="S3.SS2.p6.6.m6.3.4.cmml"><mi id="S3.SS2.p6.6.m6.3.4.2" xref="S3.SS2.p6.6.m6.3.4.2.cmml">r</mi><mo id="S3.SS2.p6.6.m6.3.4.1" xref="S3.SS2.p6.6.m6.3.4.1.cmml">â‰ª</mo><mrow id="S3.SS2.p6.6.m6.3.4.3.2" xref="S3.SS2.p6.6.m6.3.4.3.1.cmml"><mi id="S3.SS2.p6.6.m6.1.1" xref="S3.SS2.p6.6.m6.1.1.cmml">min</mi><mo id="S3.SS2.p6.6.m6.3.4.3.2a" xref="S3.SS2.p6.6.m6.3.4.3.1.cmml">â¡</mo><mrow id="S3.SS2.p6.6.m6.3.4.3.2.1" xref="S3.SS2.p6.6.m6.3.4.3.1.cmml"><mo stretchy="false" id="S3.SS2.p6.6.m6.3.4.3.2.1.1" xref="S3.SS2.p6.6.m6.3.4.3.1.cmml">(</mo><mi id="S3.SS2.p6.6.m6.2.2" xref="S3.SS2.p6.6.m6.2.2.cmml">d</mi><mo id="S3.SS2.p6.6.m6.3.4.3.2.1.2" xref="S3.SS2.p6.6.m6.3.4.3.1.cmml">,</mo><mi id="S3.SS2.p6.6.m6.3.3" xref="S3.SS2.p6.6.m6.3.3.cmml">u</mi><mo stretchy="false" id="S3.SS2.p6.6.m6.3.4.3.2.1.3" xref="S3.SS2.p6.6.m6.3.4.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.6.m6.3b"><apply id="S3.SS2.p6.6.m6.3.4.cmml" xref="S3.SS2.p6.6.m6.3.4"><csymbol cd="latexml" id="S3.SS2.p6.6.m6.3.4.1.cmml" xref="S3.SS2.p6.6.m6.3.4.1">much-less-than</csymbol><ci id="S3.SS2.p6.6.m6.3.4.2.cmml" xref="S3.SS2.p6.6.m6.3.4.2">ğ‘Ÿ</ci><apply id="S3.SS2.p6.6.m6.3.4.3.1.cmml" xref="S3.SS2.p6.6.m6.3.4.3.2"><min id="S3.SS2.p6.6.m6.1.1.cmml" xref="S3.SS2.p6.6.m6.1.1"></min><ci id="S3.SS2.p6.6.m6.2.2.cmml" xref="S3.SS2.p6.6.m6.2.2">ğ‘‘</ci><ci id="S3.SS2.p6.6.m6.3.3.cmml" xref="S3.SS2.p6.6.m6.3.3">ğ‘¢</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.6.m6.3c">r\ll\min(d,u)</annotation></semantics></math> casts the weight update matrices into a much lower dimensionality than in the original transformer module without the necessity of adding additional adapters, i.e., LoRA builds an adapter for existing parameters.
However, as <math id="S3.SS2.p6.7.m7.1" class="ltx_Math" alttext="\mathbf{A}" display="inline"><semantics id="S3.SS2.p6.7.m7.1a"><mi id="S3.SS2.p6.7.m7.1.1" xref="S3.SS2.p6.7.m7.1.1.cmml">ğ€</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.7.m7.1b"><ci id="S3.SS2.p6.7.m7.1.1.cmml" xref="S3.SS2.p6.7.m7.1.1">ğ€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.7.m7.1c">\mathbf{A}</annotation></semantics></math> is initialized randomly to a Gaussian distribution and <math id="S3.SS2.p6.8.m8.1" class="ltx_Math" alttext="\mathbf{B}" display="inline"><semantics id="S3.SS2.p6.8.m8.1a"><mi id="S3.SS2.p6.8.m8.1.1" xref="S3.SS2.p6.8.m8.1.1.cmml">ğ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.8.m8.1b"><ci id="S3.SS2.p6.8.m8.1.1.cmml" xref="S3.SS2.p6.8.m8.1.1">ğ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.8.m8.1c">\mathbf{B}</annotation></semantics></math> as a zero matrix, this works well for centralized settings with IID data <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Hu </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>.
For FL settings, this initialization method bears the risk of slowing down the fine-tuning process over non-IID data.</p>
</div>
<div id="S3.SS2.p7" class="ltx_para">
<p id="S3.SS2.p7.1" class="ltx_p">FedCLIP <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Lu </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite> introduces a PEFT method with an adjusted FedAvg-based adapter aggregation technique. Their approach yields significant performance improvements over vanilla FedAvg and FedProx.</p>
</div>
<div id="S3.SS2.p8" class="ltx_para">
<p id="S3.SS2.p8.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib66" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib66" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023b</span></a></cite>] provide a systematic benchmark study on adapter-based fine-tuning methods in privacy-preserving FL systems. Their results show that fine-tuning with additional adapters and LoRA both yield the same benchmark results regarding model accuracy. However, LoRA requires <math id="S3.SS2.p8.1.m1.1" class="ltx_math_unparsed" alttext="3\times" display="inline"><semantics id="S3.SS2.p8.1.m1.1a"><mrow id="S3.SS2.p8.1.m1.1b"><mn id="S3.SS2.p8.1.m1.1.1">3</mn><mo lspace="0.222em" id="S3.SS2.p8.1.m1.1.2">Ã—</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.p8.1.m1.1c">3\times</annotation></semantics></math> less communication than additional adapters.</p>
</div>
<div id="S3.SS2.p9" class="ltx_para">
<p id="S3.SS2.p9.1" class="ltx_p">However, both FedCLIP and FedPETuning yield a worse accuracy than full fine-tuning. With SLoRA, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Babakniya </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a></cite>] propose a method to optimize LoRA for non-IID FL settings. Their approach parameterizes the weight update based on <math id="S3.SS2.p9.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS2.p9.1.m1.1a"><mi id="S3.SS2.p9.1.m1.1.1" xref="S3.SS2.p9.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.1.m1.1b"><ci id="S3.SS2.p9.1.m1.1.1.cmml" xref="S3.SS2.p9.1.m1.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.1.m1.1c">r</annotation></semantics></math>,</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.1" class="ltx_Math" alttext="w_{t+1}=w_{t}+\frac{\beta}{r}\mathbf{B}\mathbf{A}\mathrm{.}" display="block"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><msub id="S3.E5.m1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.2.cmml"><mi id="S3.E5.m1.1.1.1.1.2.2" xref="S3.E5.m1.1.1.1.1.2.2.cmml">w</mi><mrow id="S3.E5.m1.1.1.1.1.2.3" xref="S3.E5.m1.1.1.1.1.2.3.cmml"><mi id="S3.E5.m1.1.1.1.1.2.3.2" xref="S3.E5.m1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S3.E5.m1.1.1.1.1.2.3.1" xref="S3.E5.m1.1.1.1.1.2.3.1.cmml">+</mo><mn id="S3.E5.m1.1.1.1.1.2.3.3" xref="S3.E5.m1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo id="S3.E5.m1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E5.m1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.3.cmml"><msub id="S3.E5.m1.1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.1.3.2.cmml"><mi id="S3.E5.m1.1.1.1.1.3.2.2" xref="S3.E5.m1.1.1.1.1.3.2.2.cmml">w</mi><mi id="S3.E5.m1.1.1.1.1.3.2.3" xref="S3.E5.m1.1.1.1.1.3.2.3.cmml">t</mi></msub><mo id="S3.E5.m1.1.1.1.1.3.1" xref="S3.E5.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E5.m1.1.1.1.1.3.3" xref="S3.E5.m1.1.1.1.1.3.3.cmml"><mfrac id="S3.E5.m1.1.1.1.1.3.3.2" xref="S3.E5.m1.1.1.1.1.3.3.2.cmml"><mi id="S3.E5.m1.1.1.1.1.3.3.2.2" xref="S3.E5.m1.1.1.1.1.3.3.2.2.cmml">Î²</mi><mi id="S3.E5.m1.1.1.1.1.3.3.2.3" xref="S3.E5.m1.1.1.1.1.3.3.2.3.cmml">r</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.1.1.3.3.1" xref="S3.E5.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.1.1.1.1.3.3.3" xref="S3.E5.m1.1.1.1.1.3.3.3.cmml">ğğ€</mi></mrow></mrow></mrow><mo lspace="0em" id="S3.E5.m1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"><eq id="S3.E5.m1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1"></eq><apply id="S3.E5.m1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.2.2">ğ‘¤</ci><apply id="S3.E5.m1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.2.3"><plus id="S3.E5.m1.1.1.1.1.2.3.1.cmml" xref="S3.E5.m1.1.1.1.1.2.3.1"></plus><ci id="S3.E5.m1.1.1.1.1.2.3.2.cmml" xref="S3.E5.m1.1.1.1.1.2.3.2">ğ‘¡</ci><cn type="integer" id="S3.E5.m1.1.1.1.1.2.3.3.cmml" xref="S3.E5.m1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S3.E5.m1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.3"><plus id="S3.E5.m1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3.1"></plus><apply id="S3.E5.m1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.2.1.cmml" xref="S3.E5.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.3.2.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2">ğ‘¤</ci><ci id="S3.E5.m1.1.1.1.1.3.2.3.cmml" xref="S3.E5.m1.1.1.1.1.3.2.3">ğ‘¡</ci></apply><apply id="S3.E5.m1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3"><times id="S3.E5.m1.1.1.1.1.3.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3.3.1"></times><apply id="S3.E5.m1.1.1.1.1.3.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2"><divide id="S3.E5.m1.1.1.1.1.3.3.2.1.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2"></divide><ci id="S3.E5.m1.1.1.1.1.3.3.2.2.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2.2">ğ›½</ci><ci id="S3.E5.m1.1.1.1.1.3.3.2.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2.3">ğ‘Ÿ</ci></apply><ci id="S3.E5.m1.1.1.1.1.3.3.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3">ğğ€</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">w_{t+1}=w_{t}+\frac{\beta}{r}\mathbf{B}\mathbf{A}\mathrm{.}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p10" class="ltx_para">
<p id="S3.SS2.p10.4" class="ltx_p">As <math id="S3.SS2.p10.1.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S3.SS2.p10.1.m1.1a"><mi id="S3.SS2.p10.1.m1.1.1" xref="S3.SS2.p10.1.m1.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p10.1.m1.1b"><ci id="S3.SS2.p10.1.m1.1.1.cmml" xref="S3.SS2.p10.1.m1.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p10.1.m1.1c">\beta</annotation></semantics></math> depends on <math id="S3.SS2.p10.2.m2.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS2.p10.2.m2.1a"><mi id="S3.SS2.p10.2.m2.1.1" xref="S3.SS2.p10.2.m2.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p10.2.m2.1b"><ci id="S3.SS2.p10.2.m2.1.1.cmml" xref="S3.SS2.p10.2.m2.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p10.2.m2.1c">r</annotation></semantics></math>, scaling the ratio helps control the weight update impact of a single client. Subsequently, this can be used to control inconsistent training updates caused by non-IID data. To practically achieve this, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Babakniya </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a></cite>] make use of a two-stage process: First, they used singular vector decomposition on <math id="S3.SS2.p10.3.m3.1" class="ltx_Math" alttext="\mathbf{A}" display="inline"><semantics id="S3.SS2.p10.3.m3.1a"><mi id="S3.SS2.p10.3.m3.1.1" xref="S3.SS2.p10.3.m3.1.1.cmml">ğ€</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p10.3.m3.1b"><ci id="S3.SS2.p10.3.m3.1.1.cmml" xref="S3.SS2.p10.3.m3.1.1">ğ€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p10.3.m3.1c">\mathbf{A}</annotation></semantics></math> and <math id="S3.SS2.p10.4.m4.1" class="ltx_Math" alttext="\mathbf{B}" display="inline"><semantics id="S3.SS2.p10.4.m4.1a"><mi id="S3.SS2.p10.4.m4.1.1" xref="S3.SS2.p10.4.m4.1.1.cmml">ğ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p10.4.m4.1b"><ci id="S3.SS2.p10.4.m4.1.1.cmml" xref="S3.SS2.p10.4.m4.1.1">ğ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p10.4.m4.1c">\mathbf{B}</annotation></semantics></math> to obtain a common initialization point for LoRA across all clients in an FL system. Second, the training is facilitated with the commonly initialized low-rank representations. Their approach achieves on-par performance with full model fine-tuning. However, they require a warmup time of approximately 100 FL rounds for stage 1, which can be very expensive in FL settings as clients are often unavailable consecutively for such a long time <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">McMahan </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2017</span></a>)</cite>.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Prompt Tuning</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Prompt tuning is another efficient method for tuning pre-trained models to a downstream task. Here, we use binary sentiments subsequent to masked-language-modeling to achieve high-quality results <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Lester </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>. As such, the model remains entirely frozen, and we only tweak the prompts (a very small number of tokens) that are being prepended to each embedded input query to improve the output quality. In contrast to fine-tuning, this method does not interfere with the model architecture or parameters. <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Lester </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a></cite>] show that the effects of prompt tuning on model performance in centralized settings become better with larger models, i.e., for large FMs, prompt tuning bears significant potential.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.5" class="ltx_p">Specifically, in FL settings, for each client <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mi id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><ci id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">n</annotation></semantics></math> the likelihood <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><mi id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><ci id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">ğ‘ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">P</annotation></semantics></math> for a desired output <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="\hat{x}" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><mover accent="true" id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml"><mi id="S3.SS3.p2.3.m3.1.1.2" xref="S3.SS3.p2.3.m3.1.1.2.cmml">x</mi><mo id="S3.SS3.p2.3.m3.1.1.1" xref="S3.SS3.p2.3.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><apply id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1"><ci id="S3.SS3.p2.3.m3.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1.1">^</ci><ci id="S3.SS3.p2.3.m3.1.1.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2">ğ‘¥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">\hat{x}</annotation></semantics></math> is calculated over prepending trainable embedded prompts <math id="S3.SS3.p2.4.m4.1" class="ltx_Math" alttext="x_{p}" display="inline"><semantics id="S3.SS3.p2.4.m4.1a"><msub id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml"><mi id="S3.SS3.p2.4.m4.1.1.2" xref="S3.SS3.p2.4.m4.1.1.2.cmml">x</mi><mi id="S3.SS3.p2.4.m4.1.1.3" xref="S3.SS3.p2.4.m4.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><apply id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.4.m4.1.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p2.4.m4.1.1.2.cmml" xref="S3.SS3.p2.4.m4.1.1.2">ğ‘¥</ci><ci id="S3.SS3.p2.4.m4.1.1.3.cmml" xref="S3.SS3.p2.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">x_{p}</annotation></semantics></math> to each embedded input <math id="S3.SS3.p2.5.m5.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS3.p2.5.m5.1a"><mi id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><ci id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">x</annotation></semantics></math>. In the interactive training process, the prompt is optimized in such a way that it optimally resembles the local objective of a client,</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.3" class="ltx_Math" alttext="\max(P_{n}(\hat{x}|[x_{p};x])),\,\forall n\in N\mathrm{.}" display="block"><semantics id="S3.E6.m1.3a"><mrow id="S3.E6.m1.3.3.1" xref="S3.E6.m1.3.3.1.1.cmml"><mrow id="S3.E6.m1.3.3.1.1" xref="S3.E6.m1.3.3.1.1.cmml"><mrow id="S3.E6.m1.3.3.1.1.2.2" xref="S3.E6.m1.3.3.1.1.2.3.cmml"><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.2.cmml"><mi id="S3.E6.m1.2.2" xref="S3.E6.m1.2.2.cmml">max</mi><mo id="S3.E6.m1.3.3.1.1.1.1.1.1a" xref="S3.E6.m1.3.3.1.1.1.1.1.2.cmml">â¡</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.2.cmml">(</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.3.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.3.2.cmml">P</mi><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.3.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.3.3.cmml">n</mi></msub><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">x</mi><mo id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">^</mo></mover><mo fence="false" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.cmml">|</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">[</mo><msub id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">p</mi></msub><mo id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">;</mo><mi id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml">x</mi><mo stretchy="false" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">]</mo></mrow></mrow><mo stretchy="false" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo rspace="0.337em" id="S3.E6.m1.3.3.1.1.2.2.3" xref="S3.E6.m1.3.3.1.1.2.3.cmml">,</mo><mrow id="S3.E6.m1.3.3.1.1.2.2.2" xref="S3.E6.m1.3.3.1.1.2.2.2.cmml"><mo rspace="0.167em" id="S3.E6.m1.3.3.1.1.2.2.2.1" xref="S3.E6.m1.3.3.1.1.2.2.2.1.cmml">âˆ€</mo><mi id="S3.E6.m1.3.3.1.1.2.2.2.2" xref="S3.E6.m1.3.3.1.1.2.2.2.2.cmml">n</mi></mrow></mrow><mo id="S3.E6.m1.3.3.1.1.3" xref="S3.E6.m1.3.3.1.1.3.cmml">âˆˆ</mo><mi id="S3.E6.m1.3.3.1.1.4" xref="S3.E6.m1.3.3.1.1.4.cmml">N</mi></mrow><mo lspace="0em" id="S3.E6.m1.3.3.1.2" xref="S3.E6.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.3b"><apply id="S3.E6.m1.3.3.1.1.cmml" xref="S3.E6.m1.3.3.1"><in id="S3.E6.m1.3.3.1.1.3.cmml" xref="S3.E6.m1.3.3.1.1.3"></in><list id="S3.E6.m1.3.3.1.1.2.3.cmml" xref="S3.E6.m1.3.3.1.1.2.2"><apply id="S3.E6.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1"><max id="S3.E6.m1.2.2.cmml" xref="S3.E6.m1.2.2"></max><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1"><times id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.3.2">ğ‘ƒ</ci><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.3.3">ğ‘›</ci></apply><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2">conditional</csymbol><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3"><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.1">^</ci><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.2">ğ‘¥</ci></apply><list id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1"><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘</ci></apply><ci id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1">ğ‘¥</ci></list></apply></apply></apply><apply id="S3.E6.m1.3.3.1.1.2.2.2.cmml" xref="S3.E6.m1.3.3.1.1.2.2.2"><csymbol cd="latexml" id="S3.E6.m1.3.3.1.1.2.2.2.1.cmml" xref="S3.E6.m1.3.3.1.1.2.2.2.1">for-all</csymbol><ci id="S3.E6.m1.3.3.1.1.2.2.2.2.cmml" xref="S3.E6.m1.3.3.1.1.2.2.2.2">ğ‘›</ci></apply></list><ci id="S3.E6.m1.3.3.1.1.4.cmml" xref="S3.E6.m1.3.3.1.1.4">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.3c">\max(P_{n}(\hat{x}|[x_{p};x])),\,\forall n\in N\mathrm{.}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Zhao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a></cite>] introduce FedPrompt, a method to efficiently communicate federally generated prompts only and aggregate them such that the global model performance of a pre-trained model improves for a downstream task.
Their experimental evaluation shows a general sensitivity of prompt tuning towards data heterogeneity as the model performance degrades by 5 â€“ 10% for the 100M parameter BERT model compared to a centrally trained baseline.
However, with RoBERTa Base (124M parameters), the sensitivity diminishes, and the FL results are on par with centralized training.
The larger T5 Base model (223M parameters) follows this trend, showing that prompt tuning becomes more effective with larger model sizes <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Lester </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Instruction Tuning</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Some applications work with highly sensitive and protected data or require a very high model performance.
The previously mentioned fine-tuning techniques may not yield sufficient results in these cases.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">This is where instruction tuning comes into play as a technique that uses high-quality data. For instance, GPT-4 <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">OpenAI</span> (<a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite> uses Reinforcement Learning with Human Feedback (RLHF). RLHF is a multi-stage process where an FM is initially trained on supervised data. In the second step - reward model training - the FM generates outputs over a given prompt, which a user then ranks based on their preference. With this, the model learns human preferences. In the third step - proximal policy optimization - the model trains self-supervised for a maximum reward <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zheng </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib68" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p">With FedIT, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib65" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib65" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023a</span></a></cite>] study instruction tuning on LLaMA-7B in an FL application over heterogeneous client tasks, e.g., learning brainstorming and text summarization on different clients in a single system at the same time. Their results show that the additional context on a downstream task generated with federated instruction tuning provides net benefits over central training only, even in heterogeneous settings. However, it is important to note that these results were produced over a single dataset only, Dollybricks-15k.</p>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Discussion</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">As more open-source FMs become available for unrestricted use (e.g., Alpaca <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Taori </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>, Falcon <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Penedo </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>), it is unlikely that full model training will be a common use case since training an FM from scratch is very challenging, even in a centralized setting.</p>
</div>
<div id="S3.SS5.p2" class="ltx_para">
<p id="S3.SS5.p2.1" class="ltx_p">Therefore, we see a priority in improving upon PEFT for downstream tasks, for instance, by introducing new and enhancing existing algorithms to remove the currently required warm-up times to improve the performance of LoRA in non-IID data environments. Computer Vision (CV) applications may benefit from exploring prompt tuning for vision transformers <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Jia </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>.
Also, we find significant challenges for instruction tuning as data quality is a general issue in FL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Longpre </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>, and access to human preferences, as it is required for RLHF, is hardly available in a real-world federated setting without incentive schemes.</p>
</div>
<div id="S3.SS5.p3" class="ltx_para">
<p id="S3.SS5.p3.1" class="ltx_p">Furthermore, PEFT also positively affects communication efficiency as it significantly reduces the number of trainable (and thus communicable) parameters. As such, we now see the computational and communication efficiency grow closer together for FL and FMs.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Communication-efficient FL methods. Their centralized learning pendants are often tied to specific domains: CV <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Habib </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>, NLP <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">He </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>, Audio <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Perez </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>, and Graph data <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Yang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>.</figcaption>
<div id="S3.T2.26" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:624.5pt;height:188pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-78.1pt,23.4pt) scale(0.8,0.8) ;">
<table id="S3.T2.26.26" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.26.26.27.1" class="ltx_tr">
<th id="S3.T2.26.26.27.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="S3.T2.26.26.27.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Enhancement</th>
<th id="S3.T2.26.26.27.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Underlying FL</th>
<th id="S3.T2.26.26.27.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Max. Model</th>
<th id="S3.T2.26.26.27.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Communication</th>
<th id="S3.T2.26.26.27.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">Domain</th>
</tr>
<tr id="S3.T2.26.26.28.2" class="ltx_tr">
<th id="S3.T2.26.26.28.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column">Algorithm</th>
<th id="S3.T2.26.26.28.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Method(s)</th>
<th id="S3.T2.26.26.28.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">Aggregation Strategy</th>
<th id="S3.T2.26.26.28.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">Parameters</th>
<th id="S3.T2.26.26.28.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">Savings vs. FedAvg</th>
<th id="S3.T2.26.26.28.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">CV</th>
<th id="S3.T2.26.26.28.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">NLP</th>
<th id="S3.T2.26.26.28.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column">Audio</th>
<th id="S3.T2.26.26.28.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column">Graph</th>
</tr>
<tr id="S3.T2.5.5.5" class="ltx_tr">
<th id="S3.T2.5.5.5.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T2.5.5.5.6.1" class="ltx_text ltx_font_italic">Centralized Learning</span></th>
<th id="S3.T2.5.5.5.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">MP, Q, S, LRC</th>
<th id="S3.T2.5.5.5.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">â€“</th>
<th id="S3.T2.1.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><math id="S3.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="&gt;100\mathrm{B}" display="inline"><semantics id="S3.T2.1.1.1.1.m1.1a"><mrow id="S3.T2.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.m1.1.1.cmml"><mi id="S3.T2.1.1.1.1.m1.1.1.2" xref="S3.T2.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="S3.T2.1.1.1.1.m1.1.1.1" xref="S3.T2.1.1.1.1.m1.1.1.1.cmml">&gt;</mo><mrow id="S3.T2.1.1.1.1.m1.1.1.3" xref="S3.T2.1.1.1.1.m1.1.1.3.cmml"><mn id="S3.T2.1.1.1.1.m1.1.1.3.2" xref="S3.T2.1.1.1.1.m1.1.1.3.2.cmml">100</mn><mo lspace="0em" rspace="0em" id="S3.T2.1.1.1.1.m1.1.1.3.1" xref="S3.T2.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathvariant="normal" id="S3.T2.1.1.1.1.m1.1.1.3.3" xref="S3.T2.1.1.1.1.m1.1.1.3.3.cmml">B</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.m1.1b"><apply id="S3.T2.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1"><gt id="S3.T2.1.1.1.1.m1.1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S3.T2.1.1.1.1.m1.1.1.2.cmml" xref="S3.T2.1.1.1.1.m1.1.1.2">absent</csymbol><apply id="S3.T2.1.1.1.1.m1.1.1.3.cmml" xref="S3.T2.1.1.1.1.m1.1.1.3"><times id="S3.T2.1.1.1.1.m1.1.1.3.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1.3.1"></times><cn type="integer" id="S3.T2.1.1.1.1.m1.1.1.3.2.cmml" xref="S3.T2.1.1.1.1.m1.1.1.3.2">100</cn><ci id="S3.T2.1.1.1.1.m1.1.1.3.3.cmml" xref="S3.T2.1.1.1.1.m1.1.1.3.3">B</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.m1.1c">&gt;100\mathrm{B}</annotation></semantics></math></th>
<th id="S3.T2.5.5.5.9" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">â€“</th>
<th id="S3.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><svg id="S3.T2.2.2.2.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</th>
<th id="S3.T2.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><svg id="S3.T2.3.3.3.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</th>
<th id="S3.T2.4.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><svg id="S3.T2.4.4.4.4.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</th>
<th id="S3.T2.5.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><svg id="S3.T2.5.5.5.5.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.8.8.8" class="ltx_tr">
<td id="S3.T2.8.8.8.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FedOBD <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Chen </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>
</td>
<td id="S3.T2.8.8.8.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Q</td>
<td id="S3.T2.8.8.8.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Weighted Average</td>
<td id="S3.T2.8.8.8.7" class="ltx_td ltx_align_right ltx_border_t">17M</td>
<td id="S3.T2.6.6.6.1" class="ltx_td ltx_align_right ltx_border_r ltx_border_t"><math id="S3.T2.6.6.6.1.m1.1" class="ltx_Math" alttext="89\%" display="inline"><semantics id="S3.T2.6.6.6.1.m1.1a"><mrow id="S3.T2.6.6.6.1.m1.1.1" xref="S3.T2.6.6.6.1.m1.1.1.cmml"><mn id="S3.T2.6.6.6.1.m1.1.1.2" xref="S3.T2.6.6.6.1.m1.1.1.2.cmml">89</mn><mo id="S3.T2.6.6.6.1.m1.1.1.1" xref="S3.T2.6.6.6.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.6.6.6.1.m1.1b"><apply id="S3.T2.6.6.6.1.m1.1.1.cmml" xref="S3.T2.6.6.6.1.m1.1.1"><csymbol cd="latexml" id="S3.T2.6.6.6.1.m1.1.1.1.cmml" xref="S3.T2.6.6.6.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.T2.6.6.6.1.m1.1.1.2.cmml" xref="S3.T2.6.6.6.1.m1.1.1.2">89</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.6.6.6.1.m1.1c">89\%</annotation></semantics></math></td>
<td id="S3.T2.7.7.7.2" class="ltx_td ltx_align_center ltx_border_t"><svg id="S3.T2.7.7.7.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S3.T2.8.8.8.3" class="ltx_td ltx_align_center ltx_border_t"><svg id="S3.T2.8.8.8.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S3.T2.8.8.8.8" class="ltx_td ltx_border_t"></td>
<td id="S3.T2.8.8.8.9" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S3.T2.10.10.10" class="ltx_tr">
<td id="S3.T2.10.10.10.3" class="ltx_td ltx_align_left ltx_border_r">PruneFL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Jiang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>
</td>
<td id="S3.T2.10.10.10.4" class="ltx_td ltx_align_left ltx_border_r">MP</td>
<td id="S3.T2.10.10.10.5" class="ltx_td ltx_align_left ltx_border_r">Weighted Average</td>
<td id="S3.T2.10.10.10.6" class="ltx_td ltx_align_right">132M</td>
<td id="S3.T2.9.9.9.1" class="ltx_td ltx_align_right ltx_border_r"><math id="S3.T2.9.9.9.1.m1.1" class="ltx_Math" alttext="80\%" display="inline"><semantics id="S3.T2.9.9.9.1.m1.1a"><mrow id="S3.T2.9.9.9.1.m1.1.1" xref="S3.T2.9.9.9.1.m1.1.1.cmml"><mn id="S3.T2.9.9.9.1.m1.1.1.2" xref="S3.T2.9.9.9.1.m1.1.1.2.cmml">80</mn><mo id="S3.T2.9.9.9.1.m1.1.1.1" xref="S3.T2.9.9.9.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.9.9.9.1.m1.1b"><apply id="S3.T2.9.9.9.1.m1.1.1.cmml" xref="S3.T2.9.9.9.1.m1.1.1"><csymbol cd="latexml" id="S3.T2.9.9.9.1.m1.1.1.1.cmml" xref="S3.T2.9.9.9.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.T2.9.9.9.1.m1.1.1.2.cmml" xref="S3.T2.9.9.9.1.m1.1.1.2">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.9.9.9.1.m1.1c">80\%</annotation></semantics></math></td>
<td id="S3.T2.10.10.10.2" class="ltx_td ltx_align_center"><svg id="S3.T2.10.10.10.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S3.T2.10.10.10.7" class="ltx_td"></td>
<td id="S3.T2.10.10.10.8" class="ltx_td"></td>
<td id="S3.T2.10.10.10.9" class="ltx_td"></td>
</tr>
<tr id="S3.T2.12.12.12" class="ltx_tr">
<td id="S3.T2.12.12.12.3" class="ltx_td ltx_align_left ltx_border_r">FedPM <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Isik </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>
</td>
<td id="S3.T2.12.12.12.4" class="ltx_td ltx_align_left ltx_border_r">MP</td>
<td id="S3.T2.12.12.12.5" class="ltx_td ltx_align_left ltx_border_r">Weighted Average</td>
<td id="S3.T2.12.12.12.6" class="ltx_td ltx_align_right">12M</td>
<td id="S3.T2.11.11.11.1" class="ltx_td ltx_align_right ltx_border_r"><math id="S3.T2.11.11.11.1.m1.1" class="ltx_Math" alttext="98\%" display="inline"><semantics id="S3.T2.11.11.11.1.m1.1a"><mrow id="S3.T2.11.11.11.1.m1.1.1" xref="S3.T2.11.11.11.1.m1.1.1.cmml"><mn id="S3.T2.11.11.11.1.m1.1.1.2" xref="S3.T2.11.11.11.1.m1.1.1.2.cmml">98</mn><mo id="S3.T2.11.11.11.1.m1.1.1.1" xref="S3.T2.11.11.11.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.11.11.11.1.m1.1b"><apply id="S3.T2.11.11.11.1.m1.1.1.cmml" xref="S3.T2.11.11.11.1.m1.1.1"><csymbol cd="latexml" id="S3.T2.11.11.11.1.m1.1.1.1.cmml" xref="S3.T2.11.11.11.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.T2.11.11.11.1.m1.1.1.2.cmml" xref="S3.T2.11.11.11.1.m1.1.1.2">98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.11.11.11.1.m1.1c">98\%</annotation></semantics></math></td>
<td id="S3.T2.12.12.12.2" class="ltx_td ltx_align_center"><svg id="S3.T2.12.12.12.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S3.T2.12.12.12.7" class="ltx_td"></td>
<td id="S3.T2.12.12.12.8" class="ltx_td"></td>
<td id="S3.T2.12.12.12.9" class="ltx_td"></td>
</tr>
<tr id="S3.T2.14.14.14" class="ltx_tr">
<td id="S3.T2.14.14.14.3" class="ltx_td ltx_align_left ltx_border_r">FedTiny <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Huang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>
</td>
<td id="S3.T2.14.14.14.4" class="ltx_td ltx_align_left ltx_border_r">MP</td>
<td id="S3.T2.14.14.14.5" class="ltx_td ltx_align_left ltx_border_r">Weighted Average</td>
<td id="S3.T2.14.14.14.6" class="ltx_td ltx_align_right">132M</td>
<td id="S3.T2.13.13.13.1" class="ltx_td ltx_align_right ltx_border_r"><math id="S3.T2.13.13.13.1.m1.1" class="ltx_Math" alttext="97\%" display="inline"><semantics id="S3.T2.13.13.13.1.m1.1a"><mrow id="S3.T2.13.13.13.1.m1.1.1" xref="S3.T2.13.13.13.1.m1.1.1.cmml"><mn id="S3.T2.13.13.13.1.m1.1.1.2" xref="S3.T2.13.13.13.1.m1.1.1.2.cmml">97</mn><mo id="S3.T2.13.13.13.1.m1.1.1.1" xref="S3.T2.13.13.13.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.13.13.13.1.m1.1b"><apply id="S3.T2.13.13.13.1.m1.1.1.cmml" xref="S3.T2.13.13.13.1.m1.1.1"><csymbol cd="latexml" id="S3.T2.13.13.13.1.m1.1.1.1.cmml" xref="S3.T2.13.13.13.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.T2.13.13.13.1.m1.1.1.2.cmml" xref="S3.T2.13.13.13.1.m1.1.1.2">97</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.13.13.13.1.m1.1c">97\%</annotation></semantics></math></td>
<td id="S3.T2.14.14.14.2" class="ltx_td ltx_align_center"><svg id="S3.T2.14.14.14.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S3.T2.14.14.14.7" class="ltx_td"></td>
<td id="S3.T2.14.14.14.8" class="ltx_td"></td>
<td id="S3.T2.14.14.14.9" class="ltx_td"></td>
</tr>
<tr id="S3.T2.15.15.15" class="ltx_tr">
<td id="S3.T2.15.15.15.2" class="ltx_td ltx_align_left ltx_border_r">SoteriaFL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Li </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>
</td>
<td id="S3.T2.15.15.15.3" class="ltx_td ltx_align_left ltx_border_r">S</td>
<td id="S3.T2.15.15.15.4" class="ltx_td ltx_align_left ltx_border_r">FedSGD</td>
<td id="S3.T2.15.15.15.5" class="ltx_td ltx_align_right">0.05M</td>
<td id="S3.T2.15.15.15.6" class="ltx_td ltx_align_right ltx_border_r">N/A</td>
<td id="S3.T2.15.15.15.1" class="ltx_td ltx_align_center"><svg id="S3.T2.15.15.15.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S3.T2.15.15.15.7" class="ltx_td"></td>
<td id="S3.T2.15.15.15.8" class="ltx_td"></td>
<td id="S3.T2.15.15.15.9" class="ltx_td"></td>
</tr>
<tr id="S3.T2.18.18.18" class="ltx_tr">
<td id="S3.T2.18.18.18.4" class="ltx_td ltx_align_left ltx_border_r">FjORD <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">HorvÃ¡th </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>
</td>
<td id="S3.T2.18.18.18.5" class="ltx_td ltx_align_left ltx_border_r">MP</td>
<td id="S3.T2.18.18.18.6" class="ltx_td ltx_align_left ltx_border_r">Weighted Average</td>
<td id="S3.T2.18.18.18.7" class="ltx_td ltx_align_right">11M</td>
<td id="S3.T2.16.16.16.1" class="ltx_td ltx_align_right ltx_border_r"><math id="S3.T2.16.16.16.1.m1.1" class="ltx_Math" alttext="98\%" display="inline"><semantics id="S3.T2.16.16.16.1.m1.1a"><mrow id="S3.T2.16.16.16.1.m1.1.1" xref="S3.T2.16.16.16.1.m1.1.1.cmml"><mn id="S3.T2.16.16.16.1.m1.1.1.2" xref="S3.T2.16.16.16.1.m1.1.1.2.cmml">98</mn><mo id="S3.T2.16.16.16.1.m1.1.1.1" xref="S3.T2.16.16.16.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.16.16.16.1.m1.1b"><apply id="S3.T2.16.16.16.1.m1.1.1.cmml" xref="S3.T2.16.16.16.1.m1.1.1"><csymbol cd="latexml" id="S3.T2.16.16.16.1.m1.1.1.1.cmml" xref="S3.T2.16.16.16.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.T2.16.16.16.1.m1.1.1.2.cmml" xref="S3.T2.16.16.16.1.m1.1.1.2">98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.16.16.16.1.m1.1c">98\%</annotation></semantics></math></td>
<td id="S3.T2.17.17.17.2" class="ltx_td ltx_align_center"><svg id="S3.T2.17.17.17.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S3.T2.18.18.18.3" class="ltx_td ltx_align_center"><svg id="S3.T2.18.18.18.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S3.T2.18.18.18.8" class="ltx_td"></td>
<td id="S3.T2.18.18.18.9" class="ltx_td"></td>
</tr>
<tr id="S3.T2.20.20.20" class="ltx_tr">
<td id="S3.T2.20.20.20.3" class="ltx_td ltx_align_left ltx_border_r">H-FL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Yang</span> (<a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>
</td>
<td id="S3.T2.20.20.20.4" class="ltx_td ltx_align_left ltx_border_r">LRC</td>
<td id="S3.T2.20.20.20.5" class="ltx_td ltx_align_left ltx_border_r">Weighted Average</td>
<td id="S3.T2.20.20.20.6" class="ltx_td ltx_align_right">138M</td>
<td id="S3.T2.19.19.19.1" class="ltx_td ltx_align_right ltx_border_r"><math id="S3.T2.19.19.19.1.m1.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="S3.T2.19.19.19.1.m1.1a"><mrow id="S3.T2.19.19.19.1.m1.1.1" xref="S3.T2.19.19.19.1.m1.1.1.cmml"><mn id="S3.T2.19.19.19.1.m1.1.1.2" xref="S3.T2.19.19.19.1.m1.1.1.2.cmml">90</mn><mo id="S3.T2.19.19.19.1.m1.1.1.1" xref="S3.T2.19.19.19.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.19.19.19.1.m1.1b"><apply id="S3.T2.19.19.19.1.m1.1.1.cmml" xref="S3.T2.19.19.19.1.m1.1.1"><csymbol cd="latexml" id="S3.T2.19.19.19.1.m1.1.1.1.cmml" xref="S3.T2.19.19.19.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.T2.19.19.19.1.m1.1.1.2.cmml" xref="S3.T2.19.19.19.1.m1.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.19.19.19.1.m1.1c">90\%</annotation></semantics></math></td>
<td id="S3.T2.20.20.20.2" class="ltx_td ltx_align_center"><svg id="S3.T2.20.20.20.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S3.T2.20.20.20.7" class="ltx_td"></td>
<td id="S3.T2.20.20.20.8" class="ltx_td"></td>
<td id="S3.T2.20.20.20.9" class="ltx_td"></td>
</tr>
<tr id="S3.T2.22.22.22" class="ltx_tr">
<td id="S3.T2.22.22.22.3" class="ltx_td ltx_align_left ltx_border_r">FedPAQ <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Reisizadeh </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>
</td>
<td id="S3.T2.22.22.22.4" class="ltx_td ltx_align_left ltx_border_r">Q</td>
<td id="S3.T2.22.22.22.5" class="ltx_td ltx_align_left ltx_border_r">FedSGD</td>
<td id="S3.T2.22.22.22.6" class="ltx_td ltx_align_right">0.2 M</td>
<td id="S3.T2.21.21.21.1" class="ltx_td ltx_align_right ltx_border_r"><math id="S3.T2.21.21.21.1.m1.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="S3.T2.21.21.21.1.m1.1a"><mrow id="S3.T2.21.21.21.1.m1.1.1" xref="S3.T2.21.21.21.1.m1.1.1.cmml"><mn id="S3.T2.21.21.21.1.m1.1.1.2" xref="S3.T2.21.21.21.1.m1.1.1.2.cmml">90</mn><mo id="S3.T2.21.21.21.1.m1.1.1.1" xref="S3.T2.21.21.21.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.21.21.21.1.m1.1b"><apply id="S3.T2.21.21.21.1.m1.1.1.cmml" xref="S3.T2.21.21.21.1.m1.1.1"><csymbol cd="latexml" id="S3.T2.21.21.21.1.m1.1.1.1.cmml" xref="S3.T2.21.21.21.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.T2.21.21.21.1.m1.1.1.2.cmml" xref="S3.T2.21.21.21.1.m1.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.21.21.21.1.m1.1c">90\%</annotation></semantics></math></td>
<td id="S3.T2.22.22.22.2" class="ltx_td ltx_align_center"><svg id="S3.T2.22.22.22.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S3.T2.22.22.22.7" class="ltx_td"></td>
<td id="S3.T2.22.22.22.8" class="ltx_td"></td>
<td id="S3.T2.22.22.22.9" class="ltx_td"></td>
</tr>
<tr id="S3.T2.24.24.24" class="ltx_tr">
<td id="S3.T2.24.24.24.3" class="ltx_td ltx_align_left ltx_border_r">HeteroFL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Diao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>
</td>
<td id="S3.T2.24.24.24.4" class="ltx_td ltx_align_left ltx_border_r">MP</td>
<td id="S3.T2.24.24.24.5" class="ltx_td ltx_align_left ltx_border_r">Weighted Average</td>
<td id="S3.T2.24.24.24.6" class="ltx_td ltx_align_right">11M</td>
<td id="S3.T2.23.23.23.1" class="ltx_td ltx_align_right ltx_border_r"><math id="S3.T2.23.23.23.1.m1.1" class="ltx_Math" alttext="98\%" display="inline"><semantics id="S3.T2.23.23.23.1.m1.1a"><mrow id="S3.T2.23.23.23.1.m1.1.1" xref="S3.T2.23.23.23.1.m1.1.1.cmml"><mn id="S3.T2.23.23.23.1.m1.1.1.2" xref="S3.T2.23.23.23.1.m1.1.1.2.cmml">98</mn><mo id="S3.T2.23.23.23.1.m1.1.1.1" xref="S3.T2.23.23.23.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.23.23.23.1.m1.1b"><apply id="S3.T2.23.23.23.1.m1.1.1.cmml" xref="S3.T2.23.23.23.1.m1.1.1"><csymbol cd="latexml" id="S3.T2.23.23.23.1.m1.1.1.1.cmml" xref="S3.T2.23.23.23.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.T2.23.23.23.1.m1.1.1.2.cmml" xref="S3.T2.23.23.23.1.m1.1.1.2">98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.23.23.23.1.m1.1c">98\%</annotation></semantics></math></td>
<td id="S3.T2.24.24.24.2" class="ltx_td ltx_align_center"><svg id="S3.T2.24.24.24.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S3.T2.24.24.24.7" class="ltx_td"></td>
<td id="S3.T2.24.24.24.8" class="ltx_td"></td>
<td id="S3.T2.24.24.24.9" class="ltx_td"></td>
</tr>
<tr id="S3.T2.26.26.26" class="ltx_tr">
<td id="S3.T2.26.26.26.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_bb ltx_border_r">LotteryFL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Li </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>
</td>
<td id="S3.T2.26.26.26.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_bb ltx_border_r">MP</td>
<td id="S3.T2.26.26.26.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_bb ltx_border_r">Weighted Average</td>
<td id="S3.T2.26.26.26.6" class="ltx_td ltx_align_right ltx_border_bb ltx_border_bb">138M</td>
<td id="S3.T2.25.25.25.1" class="ltx_td ltx_align_right ltx_border_bb ltx_border_bb ltx_border_r"><math id="S3.T2.25.25.25.1.m1.1" class="ltx_Math" alttext="50\%" display="inline"><semantics id="S3.T2.25.25.25.1.m1.1a"><mrow id="S3.T2.25.25.25.1.m1.1.1" xref="S3.T2.25.25.25.1.m1.1.1.cmml"><mn id="S3.T2.25.25.25.1.m1.1.1.2" xref="S3.T2.25.25.25.1.m1.1.1.2.cmml">50</mn><mo id="S3.T2.25.25.25.1.m1.1.1.1" xref="S3.T2.25.25.25.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.25.25.25.1.m1.1b"><apply id="S3.T2.25.25.25.1.m1.1.1.cmml" xref="S3.T2.25.25.25.1.m1.1.1"><csymbol cd="latexml" id="S3.T2.25.25.25.1.m1.1.1.1.cmml" xref="S3.T2.25.25.25.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.T2.25.25.25.1.m1.1.1.2.cmml" xref="S3.T2.25.25.25.1.m1.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.25.25.25.1.m1.1c">50\%</annotation></semantics></math></td>
<td id="S3.T2.26.26.26.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_bb"><svg id="S3.T2.26.26.26.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S3.T2.26.26.26.7" class="ltx_td ltx_border_bb ltx_border_bb"></td>
<td id="S3.T2.26.26.26.8" class="ltx_td ltx_border_bb ltx_border_bb"></td>
<td id="S3.T2.26.26.26.9" class="ltx_td ltx_border_bb ltx_border_bb"></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Communication Efficiency</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">With FMs, models have exponentially grown from a few million to several billion parameters to be able to multi-modal tasks.
For FL, this specifically means that the communication load between clients and servers has grown significantly, even though with PEFT, there is not necessarily the need to communicate an entire model.
However, when fine-tuning a billion-parameter FM with adapter-based methods, we still need to facilitate communication for a million parameters.
For cross-device scenarios involving more than 1,000 clients per training round, the data traffic can quickly overstrain a serverâ€™s network capacity and potentially incur significant communication costs for data transfer from the edge to a cloud <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Xu </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>); <span class="ltx_text" style="font-size:90%;">Isenko </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>.
Therefore, efficient communication and training design is vital for future FL systems. We distinguish two major efficiency methods: model pruning and full model compression. A detailed overview of studies on efficient communication in FL is provided in <a href="#S3.T2" title="In 3.5 Discussion â€£ 3 Computational Efficiency â€£ A Survey on Efficient Federated Learning Methods for Foundation Model Training" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Model Pruning</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The objective of model pruning (MP) is to retain and communicate only parts of a DL model that are relevant to a certain task.
The reduction of parameters with this technique reduces the communication effort <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhu and Gupta</span> (<a href="#bib.bib70" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2017</span></a>)</cite>. However, the success of pruning highly depends on the underlying data.
Pruning client models without coordination may deny convergence with heterogeneous non-IID data in FL systems.
<cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Jiang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a></cite>] introduce PruneFL, a two-stage procedure to realize model pruning in FL systems.
The first stage is carried out on a powerful client to find a common initialization for the model and generate the importance-based pruning mask.
This mask is then iteratively refined over multiple FL training rounds under the consideration of all clients.
The experimental results with PruneFL show two remarkable results: (I) The models have a shorter time to accuracy over the same task with PruneFL than with FedAvg, which is attributable to the higher degree of model specialization.
(II) Since the model size is reduced, one would expect additional effects on faster computation, but there is limited hardware support for sparse matrix multiplications in training.
Therefore, there are no computational benefits of PruneFL to this point. However, this may change with new hardware, such as sparse Tensor cores <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhu </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib71" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>.
With FedTiny, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Huang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a></cite>] present an approach that works identically to PruneFL, except for them swapping the common initialization procedure with using batch normalization values of clients to choose a common initialization.
Furthermore, FjORD <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">HorvÃ¡th </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> and HeteroFL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Diao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite> provide similar approaches to pruning.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Isik </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a></cite>] choose a similar approach for pruning models based on the lottery ticket hypothesis, first introduced to FL by <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Li </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a></cite>]. Instead of commonly initializing a pruned model for an FL system, they initialize a random binary mask based on a shared seed on each client. This reduces computational efforts in the ramp-up phase. After an FL training round, each client communicates their binary mask to the server, which creates a global model based on the weighted average of those binary masks. With this, an approximate weight estimate replaces the parameters on the global model. From client to server, FedPM achieves significant communication efficiencies. However, the full model still has to be communicated from the server to the clients, lowering the net benefit.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">Model pruning has also been discussed extensively for FM fine-tuning outside of FL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Lagunas </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>); <span class="ltx_text" style="font-size:90%;">Sanh </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>.
As existing pruning approaches have shown strong benefits to delivering on-par model performance compared to fine-tuning the full model, this is a promising direction to combine federated PEFT with highly efficient pruning techniques to further enhance communication. Along with pruning, sparse tensor computation hardware can also lower computational loads.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Full Model Compression</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Model pruning is prone to omit segments of a DL model that may become relevant at a later stage. This originates from domain shifts <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Peng </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite> and might require preserving the full model with all its parameters. For this, three frequently discussed techniques for full model compression in FL systems are Quantization, Sparsification, and Low-rank Compression.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">Quantization (Q)</span>. The first work towards dynamic quantization is FedPAQ <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Reisizadeh </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>, which combines FedAvg with strong quantization guarantees, where <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mi id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><ci id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">Q</annotation></semantics></math> represents the quantization term for a local model update,</p>
<table id="S4.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E7.m1.3" class="ltx_Math" alttext="w_{t+1}=w_{t}+\frac{1}{|N|}\sum^{|N|}_{n=1}Q(w^{n}_{t+1}-w_{t})\mathrm{.}" display="block"><semantics id="S4.E7.m1.3a"><mrow id="S4.E7.m1.3.3.1" xref="S4.E7.m1.3.3.1.1.cmml"><mrow id="S4.E7.m1.3.3.1.1" xref="S4.E7.m1.3.3.1.1.cmml"><msub id="S4.E7.m1.3.3.1.1.3" xref="S4.E7.m1.3.3.1.1.3.cmml"><mi id="S4.E7.m1.3.3.1.1.3.2" xref="S4.E7.m1.3.3.1.1.3.2.cmml">w</mi><mrow id="S4.E7.m1.3.3.1.1.3.3" xref="S4.E7.m1.3.3.1.1.3.3.cmml"><mi id="S4.E7.m1.3.3.1.1.3.3.2" xref="S4.E7.m1.3.3.1.1.3.3.2.cmml">t</mi><mo id="S4.E7.m1.3.3.1.1.3.3.1" xref="S4.E7.m1.3.3.1.1.3.3.1.cmml">+</mo><mn id="S4.E7.m1.3.3.1.1.3.3.3" xref="S4.E7.m1.3.3.1.1.3.3.3.cmml">1</mn></mrow></msub><mo id="S4.E7.m1.3.3.1.1.2" xref="S4.E7.m1.3.3.1.1.2.cmml">=</mo><mrow id="S4.E7.m1.3.3.1.1.1" xref="S4.E7.m1.3.3.1.1.1.cmml"><msub id="S4.E7.m1.3.3.1.1.1.3" xref="S4.E7.m1.3.3.1.1.1.3.cmml"><mi id="S4.E7.m1.3.3.1.1.1.3.2" xref="S4.E7.m1.3.3.1.1.1.3.2.cmml">w</mi><mi id="S4.E7.m1.3.3.1.1.1.3.3" xref="S4.E7.m1.3.3.1.1.1.3.3.cmml">t</mi></msub><mo id="S4.E7.m1.3.3.1.1.1.2" xref="S4.E7.m1.3.3.1.1.1.2.cmml">+</mo><mrow id="S4.E7.m1.3.3.1.1.1.1" xref="S4.E7.m1.3.3.1.1.1.1.cmml"><mfrac id="S4.E7.m1.1.1" xref="S4.E7.m1.1.1.cmml"><mn id="S4.E7.m1.1.1.3" xref="S4.E7.m1.1.1.3.cmml">1</mn><mrow id="S4.E7.m1.1.1.1.3" xref="S4.E7.m1.1.1.1.2.cmml"><mo stretchy="false" id="S4.E7.m1.1.1.1.3.1" xref="S4.E7.m1.1.1.1.2.1.cmml">|</mo><mi id="S4.E7.m1.1.1.1.1" xref="S4.E7.m1.1.1.1.1.cmml">N</mi><mo stretchy="false" id="S4.E7.m1.1.1.1.3.2" xref="S4.E7.m1.1.1.1.2.1.cmml">|</mo></mrow></mfrac><mo lspace="0em" rspace="0em" id="S4.E7.m1.3.3.1.1.1.1.2" xref="S4.E7.m1.3.3.1.1.1.1.2.cmml">â€‹</mo><mrow id="S4.E7.m1.3.3.1.1.1.1.1" xref="S4.E7.m1.3.3.1.1.1.1.1.cmml"><munderover id="S4.E7.m1.3.3.1.1.1.1.1.2" xref="S4.E7.m1.3.3.1.1.1.1.1.2.cmml"><mo movablelimits="false" id="S4.E7.m1.3.3.1.1.1.1.1.2.2.2" xref="S4.E7.m1.3.3.1.1.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S4.E7.m1.3.3.1.1.1.1.1.2.3" xref="S4.E7.m1.3.3.1.1.1.1.1.2.3.cmml"><mi id="S4.E7.m1.3.3.1.1.1.1.1.2.3.2" xref="S4.E7.m1.3.3.1.1.1.1.1.2.3.2.cmml">n</mi><mo id="S4.E7.m1.3.3.1.1.1.1.1.2.3.1" xref="S4.E7.m1.3.3.1.1.1.1.1.2.3.1.cmml">=</mo><mn id="S4.E7.m1.3.3.1.1.1.1.1.2.3.3" xref="S4.E7.m1.3.3.1.1.1.1.1.2.3.3.cmml">1</mn></mrow><mrow id="S4.E7.m1.2.2.1.3" xref="S4.E7.m1.2.2.1.2.cmml"><mo stretchy="false" id="S4.E7.m1.2.2.1.3.1" xref="S4.E7.m1.2.2.1.2.1.cmml">|</mo><mi id="S4.E7.m1.2.2.1.1" xref="S4.E7.m1.2.2.1.1.cmml">N</mi><mo stretchy="false" id="S4.E7.m1.2.2.1.3.2" xref="S4.E7.m1.2.2.1.2.1.cmml">|</mo></mrow></munderover><mrow id="S4.E7.m1.3.3.1.1.1.1.1.1" xref="S4.E7.m1.3.3.1.1.1.1.1.1.cmml"><mi id="S4.E7.m1.3.3.1.1.1.1.1.1.3" xref="S4.E7.m1.3.3.1.1.1.1.1.1.3.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S4.E7.m1.3.3.1.1.1.1.1.1.2" xref="S4.E7.m1.3.3.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><msubsup id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.cmml">w</mi><mrow id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.3" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.2" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.1" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.1.cmml">+</mo><mn id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.3" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.3.cmml">1</mn></mrow><mi id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.3" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.3.cmml">n</mi></msubsup><mo id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.3" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.3.2" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.3.2.cmml">w</mi><mi id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.3.3" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo lspace="0em" id="S4.E7.m1.3.3.1.2" xref="S4.E7.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E7.m1.3b"><apply id="S4.E7.m1.3.3.1.1.cmml" xref="S4.E7.m1.3.3.1"><eq id="S4.E7.m1.3.3.1.1.2.cmml" xref="S4.E7.m1.3.3.1.1.2"></eq><apply id="S4.E7.m1.3.3.1.1.3.cmml" xref="S4.E7.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S4.E7.m1.3.3.1.1.3.1.cmml" xref="S4.E7.m1.3.3.1.1.3">subscript</csymbol><ci id="S4.E7.m1.3.3.1.1.3.2.cmml" xref="S4.E7.m1.3.3.1.1.3.2">ğ‘¤</ci><apply id="S4.E7.m1.3.3.1.1.3.3.cmml" xref="S4.E7.m1.3.3.1.1.3.3"><plus id="S4.E7.m1.3.3.1.1.3.3.1.cmml" xref="S4.E7.m1.3.3.1.1.3.3.1"></plus><ci id="S4.E7.m1.3.3.1.1.3.3.2.cmml" xref="S4.E7.m1.3.3.1.1.3.3.2">ğ‘¡</ci><cn type="integer" id="S4.E7.m1.3.3.1.1.3.3.3.cmml" xref="S4.E7.m1.3.3.1.1.3.3.3">1</cn></apply></apply><apply id="S4.E7.m1.3.3.1.1.1.cmml" xref="S4.E7.m1.3.3.1.1.1"><plus id="S4.E7.m1.3.3.1.1.1.2.cmml" xref="S4.E7.m1.3.3.1.1.1.2"></plus><apply id="S4.E7.m1.3.3.1.1.1.3.cmml" xref="S4.E7.m1.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S4.E7.m1.3.3.1.1.1.3.1.cmml" xref="S4.E7.m1.3.3.1.1.1.3">subscript</csymbol><ci id="S4.E7.m1.3.3.1.1.1.3.2.cmml" xref="S4.E7.m1.3.3.1.1.1.3.2">ğ‘¤</ci><ci id="S4.E7.m1.3.3.1.1.1.3.3.cmml" xref="S4.E7.m1.3.3.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S4.E7.m1.3.3.1.1.1.1.cmml" xref="S4.E7.m1.3.3.1.1.1.1"><times id="S4.E7.m1.3.3.1.1.1.1.2.cmml" xref="S4.E7.m1.3.3.1.1.1.1.2"></times><apply id="S4.E7.m1.1.1.cmml" xref="S4.E7.m1.1.1"><divide id="S4.E7.m1.1.1.2.cmml" xref="S4.E7.m1.1.1"></divide><cn type="integer" id="S4.E7.m1.1.1.3.cmml" xref="S4.E7.m1.1.1.3">1</cn><apply id="S4.E7.m1.1.1.1.2.cmml" xref="S4.E7.m1.1.1.1.3"><abs id="S4.E7.m1.1.1.1.2.1.cmml" xref="S4.E7.m1.1.1.1.3.1"></abs><ci id="S4.E7.m1.1.1.1.1.cmml" xref="S4.E7.m1.1.1.1.1">ğ‘</ci></apply></apply><apply id="S4.E7.m1.3.3.1.1.1.1.1.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1"><apply id="S4.E7.m1.3.3.1.1.1.1.1.2.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E7.m1.3.3.1.1.1.1.1.2.1.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.2">subscript</csymbol><apply id="S4.E7.m1.3.3.1.1.1.1.1.2.2.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E7.m1.3.3.1.1.1.1.1.2.2.1.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.2">superscript</csymbol><sum id="S4.E7.m1.3.3.1.1.1.1.1.2.2.2.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.2.2.2"></sum><apply id="S4.E7.m1.2.2.1.2.cmml" xref="S4.E7.m1.2.2.1.3"><abs id="S4.E7.m1.2.2.1.2.1.cmml" xref="S4.E7.m1.2.2.1.3.1"></abs><ci id="S4.E7.m1.2.2.1.1.cmml" xref="S4.E7.m1.2.2.1.1">ğ‘</ci></apply></apply><apply id="S4.E7.m1.3.3.1.1.1.1.1.2.3.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.2.3"><eq id="S4.E7.m1.3.3.1.1.1.1.1.2.3.1.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.2.3.1"></eq><ci id="S4.E7.m1.3.3.1.1.1.1.1.2.3.2.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.2.3.2">ğ‘›</ci><cn type="integer" id="S4.E7.m1.3.3.1.1.1.1.1.2.3.3.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S4.E7.m1.3.3.1.1.1.1.1.1.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1"><times id="S4.E7.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.2"></times><ci id="S4.E7.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.3">ğ‘„</ci><apply id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1"><minus id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1"></minus><apply id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><apply id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2">ğ‘¤</ci><ci id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.3">ğ‘›</ci></apply><apply id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.3"><plus id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.1"></plus><ci id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.2">ğ‘¡</ci><cn type="integer" id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.3.2">ğ‘¤</ci><ci id="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E7.m1.3.3.1.1.1.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E7.m1.3c">w_{t+1}=w_{t}+\frac{1}{|N|}\sum^{|N|}_{n=1}Q(w^{n}_{t+1}-w_{t})\mathrm{.}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.6" class="ltx_p">While DL models often operate on full precision (32-bit), this high degree of detail is not necessarily required <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhou </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib69" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2018</span></a>)</cite>.
FedPAQ leverages this to reduce the communication intensity of FL applications.
<math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mi id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><ci id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">Q</annotation></semantics></math> calculates the optimal float precision of a model update to preserve all required information: <math id="S4.SS2.p3.2.m2.5" class="ltx_Math" alttext="Q(w)=\mathinner{\!\left\lVert w\right\rVert}\cdot\mathrm{sign}(w)\cdot\xi(w,s)" display="inline"><semantics id="S4.SS2.p3.2.m2.5a"><mrow id="S4.SS2.p3.2.m2.5.6" xref="S4.SS2.p3.2.m2.5.6.cmml"><mrow id="S4.SS2.p3.2.m2.5.6.2" xref="S4.SS2.p3.2.m2.5.6.2.cmml"><mi id="S4.SS2.p3.2.m2.5.6.2.2" xref="S4.SS2.p3.2.m2.5.6.2.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.2.m2.5.6.2.1" xref="S4.SS2.p3.2.m2.5.6.2.1.cmml">â€‹</mo><mrow id="S4.SS2.p3.2.m2.5.6.2.3.2" xref="S4.SS2.p3.2.m2.5.6.2.cmml"><mo stretchy="false" id="S4.SS2.p3.2.m2.5.6.2.3.2.1" xref="S4.SS2.p3.2.m2.5.6.2.cmml">(</mo><mi id="S4.SS2.p3.2.m2.2.2" xref="S4.SS2.p3.2.m2.2.2.cmml">w</mi><mo stretchy="false" id="S4.SS2.p3.2.m2.5.6.2.3.2.2" xref="S4.SS2.p3.2.m2.5.6.2.cmml">)</mo></mrow></mrow><mo rspace="0.0539em" id="S4.SS2.p3.2.m2.5.6.1" xref="S4.SS2.p3.2.m2.5.6.1.cmml">=</mo><mrow id="S4.SS2.p3.2.m2.5.6.3" xref="S4.SS2.p3.2.m2.5.6.3.cmml"><mrow id="S4.SS2.p3.2.m2.5.6.3.2" xref="S4.SS2.p3.2.m2.5.6.3.2.cmml"><mrow id="S4.SS2.p3.2.m2.5.6.3.2.2" xref="S4.SS2.p3.2.m2.5.6.3.2.2.cmml"><mrow id="S4.SS2.p3.2.m2.5.6.3.2.2.2" xref="S4.SS2.p3.2.m2.5.6.3.2.2.2.cmml"><mrow id="S4.SS2.p3.2.m2.1.1.3" xref="S4.SS2.p3.2.m2.1.1.2.cmml"><mo fence="true" lspace="0.0539em" rspace="0em" stretchy="true" id="S4.SS2.p3.2.m2.1.1.3.1" xref="S4.SS2.p3.2.m2.1.1.2.1.cmml">âˆ¥</mo><mi id="S4.SS2.p3.2.m2.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.cmml">w</mi><mo fence="true" lspace="0em" rspace="0.055em" stretchy="true" id="S4.SS2.p3.2.m2.1.1.3.2" xref="S4.SS2.p3.2.m2.1.1.2.1.cmml">âˆ¥</mo></mrow><mo rspace="0.222em" id="S4.SS2.p3.2.m2.5.6.3.2.2.2.1" xref="S4.SS2.p3.2.m2.5.6.3.2.2.2.1.cmml">â‹…</mo><mi id="S4.SS2.p3.2.m2.5.6.3.2.2.2.2" xref="S4.SS2.p3.2.m2.5.6.3.2.2.2.2.cmml">sign</mi></mrow><mo lspace="0em" rspace="0em" id="S4.SS2.p3.2.m2.5.6.3.2.2.1" xref="S4.SS2.p3.2.m2.5.6.3.2.2.1.cmml">â€‹</mo><mrow id="S4.SS2.p3.2.m2.5.6.3.2.2.3.2" xref="S4.SS2.p3.2.m2.5.6.3.2.2.cmml"><mo stretchy="false" id="S4.SS2.p3.2.m2.5.6.3.2.2.3.2.1" xref="S4.SS2.p3.2.m2.5.6.3.2.2.cmml">(</mo><mi id="S4.SS2.p3.2.m2.3.3" xref="S4.SS2.p3.2.m2.3.3.cmml">w</mi><mo rspace="0.055em" stretchy="false" id="S4.SS2.p3.2.m2.5.6.3.2.2.3.2.2" xref="S4.SS2.p3.2.m2.5.6.3.2.2.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S4.SS2.p3.2.m2.5.6.3.2.1" xref="S4.SS2.p3.2.m2.5.6.3.2.1.cmml">â‹…</mo><mi id="S4.SS2.p3.2.m2.5.6.3.2.3" xref="S4.SS2.p3.2.m2.5.6.3.2.3.cmml">Î¾</mi></mrow><mo lspace="0em" rspace="0em" id="S4.SS2.p3.2.m2.5.6.3.1" xref="S4.SS2.p3.2.m2.5.6.3.1.cmml">â€‹</mo><mrow id="S4.SS2.p3.2.m2.5.6.3.3.2" xref="S4.SS2.p3.2.m2.5.6.3.3.1.cmml"><mo stretchy="false" id="S4.SS2.p3.2.m2.5.6.3.3.2.1" xref="S4.SS2.p3.2.m2.5.6.3.3.1.cmml">(</mo><mi id="S4.SS2.p3.2.m2.4.4" xref="S4.SS2.p3.2.m2.4.4.cmml">w</mi><mo id="S4.SS2.p3.2.m2.5.6.3.3.2.2" xref="S4.SS2.p3.2.m2.5.6.3.3.1.cmml">,</mo><mi id="S4.SS2.p3.2.m2.5.5" xref="S4.SS2.p3.2.m2.5.5.cmml">s</mi><mo stretchy="false" id="S4.SS2.p3.2.m2.5.6.3.3.2.3" xref="S4.SS2.p3.2.m2.5.6.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.5b"><apply id="S4.SS2.p3.2.m2.5.6.cmml" xref="S4.SS2.p3.2.m2.5.6"><eq id="S4.SS2.p3.2.m2.5.6.1.cmml" xref="S4.SS2.p3.2.m2.5.6.1"></eq><apply id="S4.SS2.p3.2.m2.5.6.2.cmml" xref="S4.SS2.p3.2.m2.5.6.2"><times id="S4.SS2.p3.2.m2.5.6.2.1.cmml" xref="S4.SS2.p3.2.m2.5.6.2.1"></times><ci id="S4.SS2.p3.2.m2.5.6.2.2.cmml" xref="S4.SS2.p3.2.m2.5.6.2.2">ğ‘„</ci><ci id="S4.SS2.p3.2.m2.2.2.cmml" xref="S4.SS2.p3.2.m2.2.2">ğ‘¤</ci></apply><apply id="S4.SS2.p3.2.m2.5.6.3.cmml" xref="S4.SS2.p3.2.m2.5.6.3"><times id="S4.SS2.p3.2.m2.5.6.3.1.cmml" xref="S4.SS2.p3.2.m2.5.6.3.1"></times><apply id="S4.SS2.p3.2.m2.5.6.3.2.cmml" xref="S4.SS2.p3.2.m2.5.6.3.2"><ci id="S4.SS2.p3.2.m2.5.6.3.2.1.cmml" xref="S4.SS2.p3.2.m2.5.6.3.2.1">â‹…</ci><apply id="S4.SS2.p3.2.m2.5.6.3.2.2.cmml" xref="S4.SS2.p3.2.m2.5.6.3.2.2"><times id="S4.SS2.p3.2.m2.5.6.3.2.2.1.cmml" xref="S4.SS2.p3.2.m2.5.6.3.2.2.1"></times><apply id="S4.SS2.p3.2.m2.5.6.3.2.2.2.cmml" xref="S4.SS2.p3.2.m2.5.6.3.2.2.2"><ci id="S4.SS2.p3.2.m2.5.6.3.2.2.2.1.cmml" xref="S4.SS2.p3.2.m2.5.6.3.2.2.2.1">â‹…</ci><apply id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.3"><csymbol cd="latexml" id="S4.SS2.p3.2.m2.1.1.2.1.cmml" xref="S4.SS2.p3.2.m2.1.1.3.1">delimited-âˆ¥âˆ¥</csymbol><ci id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1">ğ‘¤</ci></apply><ci id="S4.SS2.p3.2.m2.5.6.3.2.2.2.2.cmml" xref="S4.SS2.p3.2.m2.5.6.3.2.2.2.2">sign</ci></apply><ci id="S4.SS2.p3.2.m2.3.3.cmml" xref="S4.SS2.p3.2.m2.3.3">ğ‘¤</ci></apply><ci id="S4.SS2.p3.2.m2.5.6.3.2.3.cmml" xref="S4.SS2.p3.2.m2.5.6.3.2.3">ğœ‰</ci></apply><interval closure="open" id="S4.SS2.p3.2.m2.5.6.3.3.1.cmml" xref="S4.SS2.p3.2.m2.5.6.3.3.2"><ci id="S4.SS2.p3.2.m2.4.4.cmml" xref="S4.SS2.p3.2.m2.4.4">ğ‘¤</ci><ci id="S4.SS2.p3.2.m2.5.5.cmml" xref="S4.SS2.p3.2.m2.5.5">ğ‘ </ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.5c">Q(w)=\mathinner{\!\left\lVert w\right\rVert}\cdot\mathrm{sign}(w)\cdot\xi(w,s)</annotation></semantics></math>, as proposed in QSGD by <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Alistarh </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2017</span></a></cite>].
<math id="S4.SS2.p3.3.m3.1" class="ltx_Math" alttext="\xi" display="inline"><semantics id="S4.SS2.p3.3.m3.1a"><mi id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml">Î¾</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><ci id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">ğœ‰</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">\xi</annotation></semantics></math> formulates a stochastic process to dynamically tune <math id="S4.SS2.p3.4.m4.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS2.p3.4.m4.1a"><mi id="S4.SS2.p3.4.m4.1.1" xref="S4.SS2.p3.4.m4.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.4.m4.1b"><ci id="S4.SS2.p3.4.m4.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.4.m4.1c">s</annotation></semantics></math>, the level of precision. FedPAQ has a significantly lower time to accuracy than QSGD, which is attributable to dynamizing <math id="S4.SS2.p3.5.m5.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS2.p3.5.m5.1a"><mi id="S4.SS2.p3.5.m5.1.1" xref="S4.SS2.p3.5.m5.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.5.m5.1b"><ci id="S4.SS2.p3.5.m5.1.1.cmml" xref="S4.SS2.p3.5.m5.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.5.m5.1c">s</annotation></semantics></math>. However, it must be noted that dynamic quantization only yields benefits for communication. Depending on the infrastructure, the model updates have to be cast back to full precision, creating additional computational overhead on the client and server. Also, the method has been only tested with small models (<math id="S4.SS2.p3.6.m6.1" class="ltx_Math" alttext="&lt;100\mathrm{K}" display="inline"><semantics id="S4.SS2.p3.6.m6.1a"><mrow id="S4.SS2.p3.6.m6.1.1" xref="S4.SS2.p3.6.m6.1.1.cmml"><mi id="S4.SS2.p3.6.m6.1.1.2" xref="S4.SS2.p3.6.m6.1.1.2.cmml"></mi><mo id="S4.SS2.p3.6.m6.1.1.1" xref="S4.SS2.p3.6.m6.1.1.1.cmml">&lt;</mo><mrow id="S4.SS2.p3.6.m6.1.1.3" xref="S4.SS2.p3.6.m6.1.1.3.cmml"><mn id="S4.SS2.p3.6.m6.1.1.3.2" xref="S4.SS2.p3.6.m6.1.1.3.2.cmml">100</mn><mo lspace="0em" rspace="0em" id="S4.SS2.p3.6.m6.1.1.3.1" xref="S4.SS2.p3.6.m6.1.1.3.1.cmml">â€‹</mo><mi mathvariant="normal" id="S4.SS2.p3.6.m6.1.1.3.3" xref="S4.SS2.p3.6.m6.1.1.3.3.cmml">K</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.6.m6.1b"><apply id="S4.SS2.p3.6.m6.1.1.cmml" xref="S4.SS2.p3.6.m6.1.1"><lt id="S4.SS2.p3.6.m6.1.1.1.cmml" xref="S4.SS2.p3.6.m6.1.1.1"></lt><csymbol cd="latexml" id="S4.SS2.p3.6.m6.1.1.2.cmml" xref="S4.SS2.p3.6.m6.1.1.2">absent</csymbol><apply id="S4.SS2.p3.6.m6.1.1.3.cmml" xref="S4.SS2.p3.6.m6.1.1.3"><times id="S4.SS2.p3.6.m6.1.1.3.1.cmml" xref="S4.SS2.p3.6.m6.1.1.3.1"></times><cn type="integer" id="S4.SS2.p3.6.m6.1.1.3.2.cmml" xref="S4.SS2.p3.6.m6.1.1.3.2">100</cn><ci id="S4.SS2.p3.6.m6.1.1.3.3.cmml" xref="S4.SS2.p3.6.m6.1.1.3.3">K</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.6.m6.1c">&lt;100\mathrm{K}</annotation></semantics></math> parameters).</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.2" class="ltx_p">FedOBD <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Chen </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite> quantizes models with transformer block dropout, i.e., the random removal of entire model blocks. The dropout mechanism is carried out during training by each client and returns only the top-k most important model blocks to communicate. Additionally, FedOBD includes the ideas discussed in <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Alistarh </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2017</span></a></cite>] and <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Reisizadeh </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a></cite>] but proposes an optimization problem out of the stochastic quantization where the trade-off originates from entropy and update size. The communication required for FL with a 17M parameter transformer model shows FedOBD to cut communication cost by <math id="S4.SS2.p4.1.m1.1" class="ltx_math_unparsed" alttext="2\times" display="inline"><semantics id="S4.SS2.p4.1.m1.1a"><mrow id="S4.SS2.p4.1.m1.1b"><mn id="S4.SS2.p4.1.m1.1.1">2</mn><mo lspace="0.222em" id="S4.SS2.p4.1.m1.1.2">Ã—</mo></mrow><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">2\times</annotation></semantics></math> vs. FedPAQ and by <math id="S4.SS2.p4.2.m2.1" class="ltx_math_unparsed" alttext="8\times" display="inline"><semantics id="S4.SS2.p4.2.m2.1a"><mrow id="S4.SS2.p4.2.m2.1b"><mn id="S4.SS2.p4.2.m2.1.1">8</mn><mo lspace="0.222em" id="S4.SS2.p4.2.m2.1.2">Ã—</mo></mrow><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.1c">8\times</annotation></semantics></math> compared to vanilla FedAvg <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Chen </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.4" class="ltx_p"><span id="S4.SS2.p5.4.1" class="ltx_text ltx_font_bold">Sparsification (S)</span>. While model pruning and sparsification technically have the same objective, pruned models do not necessarily resemble sparse models. A model is sparse once more than 50% of weights are set to <math id="S4.SS2.p5.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.SS2.p5.1.m1.1a"><mn id="S4.SS2.p5.1.m1.1.1" xref="S4.SS2.p5.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.1.m1.1b"><cn type="integer" id="S4.SS2.p5.1.m1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1">0</cn></annotation-xml></semantics></math> <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Frankle and Carbin</span> (<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>. However, pruning can also change the model architecture, i.e., not return the full model. Since it lends its idea from <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Frankle and Carbin</span> (<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>, FedPM <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Isik </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite> (see <a href="#S4.SS1" title="4.1 Model Pruning â€£ 4 Communication Efficiency â€£ A Survey on Efficient Federated Learning Methods for Foundation Model Training" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>Â <span class="ltx_text ltx_ref_tag">4.1</span></a>) can be considered as a model sparsification technique but does not necessarily lead to sparse networks and may return partial networks.
SoteriaFL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Li </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite> guarantees sparse networks while maintaining differential privacy. <a href="#S4.E7" title="In 4.2 Full Model Compression â€£ 4 Communication Efficiency â€£ A Survey on Efficient Federated Learning Methods for Foundation Model Training" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Equation</span>Â <span class="ltx_text ltx_ref_tag">7</span></a> is amended in such a way that <math id="S4.SS2.p5.2.m2.1" class="ltx_Math" alttext="Q(w^{n}_{t+1}-w_{t})" display="inline"><semantics id="S4.SS2.p5.2.m2.1a"><mrow id="S4.SS2.p5.2.m2.1.1" xref="S4.SS2.p5.2.m2.1.1.cmml"><mi id="S4.SS2.p5.2.m2.1.1.3" xref="S4.SS2.p5.2.m2.1.1.3.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p5.2.m2.1.1.2" xref="S4.SS2.p5.2.m2.1.1.2.cmml">â€‹</mo><mrow id="S4.SS2.p5.2.m2.1.1.1.1" xref="S4.SS2.p5.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.p5.2.m2.1.1.1.1.2" xref="S4.SS2.p5.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.p5.2.m2.1.1.1.1.1" xref="S4.SS2.p5.2.m2.1.1.1.1.1.cmml"><msubsup id="S4.SS2.p5.2.m2.1.1.1.1.1.2" xref="S4.SS2.p5.2.m2.1.1.1.1.1.2.cmml"><mi id="S4.SS2.p5.2.m2.1.1.1.1.1.2.2.2" xref="S4.SS2.p5.2.m2.1.1.1.1.1.2.2.2.cmml">w</mi><mrow id="S4.SS2.p5.2.m2.1.1.1.1.1.2.3" xref="S4.SS2.p5.2.m2.1.1.1.1.1.2.3.cmml"><mi id="S4.SS2.p5.2.m2.1.1.1.1.1.2.3.2" xref="S4.SS2.p5.2.m2.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S4.SS2.p5.2.m2.1.1.1.1.1.2.3.1" xref="S4.SS2.p5.2.m2.1.1.1.1.1.2.3.1.cmml">+</mo><mn id="S4.SS2.p5.2.m2.1.1.1.1.1.2.3.3" xref="S4.SS2.p5.2.m2.1.1.1.1.1.2.3.3.cmml">1</mn></mrow><mi id="S4.SS2.p5.2.m2.1.1.1.1.1.2.2.3" xref="S4.SS2.p5.2.m2.1.1.1.1.1.2.2.3.cmml">n</mi></msubsup><mo id="S4.SS2.p5.2.m2.1.1.1.1.1.1" xref="S4.SS2.p5.2.m2.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S4.SS2.p5.2.m2.1.1.1.1.1.3" xref="S4.SS2.p5.2.m2.1.1.1.1.1.3.cmml"><mi id="S4.SS2.p5.2.m2.1.1.1.1.1.3.2" xref="S4.SS2.p5.2.m2.1.1.1.1.1.3.2.cmml">w</mi><mi id="S4.SS2.p5.2.m2.1.1.1.1.1.3.3" xref="S4.SS2.p5.2.m2.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S4.SS2.p5.2.m2.1.1.1.1.3" xref="S4.SS2.p5.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.2.m2.1b"><apply id="S4.SS2.p5.2.m2.1.1.cmml" xref="S4.SS2.p5.2.m2.1.1"><times id="S4.SS2.p5.2.m2.1.1.2.cmml" xref="S4.SS2.p5.2.m2.1.1.2"></times><ci id="S4.SS2.p5.2.m2.1.1.3.cmml" xref="S4.SS2.p5.2.m2.1.1.3">ğ‘„</ci><apply id="S4.SS2.p5.2.m2.1.1.1.1.1.cmml" xref="S4.SS2.p5.2.m2.1.1.1.1"><minus id="S4.SS2.p5.2.m2.1.1.1.1.1.1.cmml" xref="S4.SS2.p5.2.m2.1.1.1.1.1.1"></minus><apply id="S4.SS2.p5.2.m2.1.1.1.1.1.2.cmml" xref="S4.SS2.p5.2.m2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p5.2.m2.1.1.1.1.1.2.1.cmml" xref="S4.SS2.p5.2.m2.1.1.1.1.1.2">subscript</csymbol><apply id="S4.SS2.p5.2.m2.1.1.1.1.1.2.2.cmml" xref="S4.SS2.p5.2.m2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p5.2.m2.1.1.1.1.1.2.2.1.cmml" xref="S4.SS2.p5.2.m2.1.1.1.1.1.2">superscript</csymbol><ci id="S4.SS2.p5.2.m2.1.1.1.1.1.2.2.2.cmml" xref="S4.SS2.p5.2.m2.1.1.1.1.1.2.2.2">ğ‘¤</ci><ci id="S4.SS2.p5.2.m2.1.1.1.1.1.2.2.3.cmml" xref="S4.SS2.p5.2.m2.1.1.1.1.1.2.2.3">ğ‘›</ci></apply><apply id="S4.SS2.p5.2.m2.1.1.1.1.1.2.3.cmml" xref="S4.SS2.p5.2.m2.1.1.1.1.1.2.3"><plus id="S4.SS2.p5.2.m2.1.1.1.1.1.2.3.1.cmml" xref="S4.SS2.p5.2.m2.1.1.1.1.1.2.3.1"></plus><ci id="S4.SS2.p5.2.m2.1.1.1.1.1.2.3.2.cmml" xref="S4.SS2.p5.2.m2.1.1.1.1.1.2.3.2">ğ‘¡</ci><cn type="integer" id="S4.SS2.p5.2.m2.1.1.1.1.1.2.3.3.cmml" xref="S4.SS2.p5.2.m2.1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S4.SS2.p5.2.m2.1.1.1.1.1.3.cmml" xref="S4.SS2.p5.2.m2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p5.2.m2.1.1.1.1.1.3.1.cmml" xref="S4.SS2.p5.2.m2.1.1.1.1.1.3">subscript</csymbol><ci id="S4.SS2.p5.2.m2.1.1.1.1.1.3.2.cmml" xref="S4.SS2.p5.2.m2.1.1.1.1.1.3.2">ğ‘¤</ci><ci id="S4.SS2.p5.2.m2.1.1.1.1.1.3.3.cmml" xref="S4.SS2.p5.2.m2.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.2.m2.1c">Q(w^{n}_{t+1}-w_{t})</annotation></semantics></math> is replaced by <math id="S4.SS2.p5.3.m3.2" class="ltx_Math" alttext="C(w^{n}_{t+1}+\mathcal{N}(0,\sigma^{2}\mathcal{I}))" display="inline"><semantics id="S4.SS2.p5.3.m3.2a"><mrow id="S4.SS2.p5.3.m3.2.2" xref="S4.SS2.p5.3.m3.2.2.cmml"><mi id="S4.SS2.p5.3.m3.2.2.3" xref="S4.SS2.p5.3.m3.2.2.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p5.3.m3.2.2.2" xref="S4.SS2.p5.3.m3.2.2.2.cmml">â€‹</mo><mrow id="S4.SS2.p5.3.m3.2.2.1.1" xref="S4.SS2.p5.3.m3.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.p5.3.m3.2.2.1.1.2" xref="S4.SS2.p5.3.m3.2.2.1.1.1.cmml">(</mo><mrow id="S4.SS2.p5.3.m3.2.2.1.1.1" xref="S4.SS2.p5.3.m3.2.2.1.1.1.cmml"><msubsup id="S4.SS2.p5.3.m3.2.2.1.1.1.3" xref="S4.SS2.p5.3.m3.2.2.1.1.1.3.cmml"><mi id="S4.SS2.p5.3.m3.2.2.1.1.1.3.2.2" xref="S4.SS2.p5.3.m3.2.2.1.1.1.3.2.2.cmml">w</mi><mrow id="S4.SS2.p5.3.m3.2.2.1.1.1.3.3" xref="S4.SS2.p5.3.m3.2.2.1.1.1.3.3.cmml"><mi id="S4.SS2.p5.3.m3.2.2.1.1.1.3.3.2" xref="S4.SS2.p5.3.m3.2.2.1.1.1.3.3.2.cmml">t</mi><mo id="S4.SS2.p5.3.m3.2.2.1.1.1.3.3.1" xref="S4.SS2.p5.3.m3.2.2.1.1.1.3.3.1.cmml">+</mo><mn id="S4.SS2.p5.3.m3.2.2.1.1.1.3.3.3" xref="S4.SS2.p5.3.m3.2.2.1.1.1.3.3.3.cmml">1</mn></mrow><mi id="S4.SS2.p5.3.m3.2.2.1.1.1.3.2.3" xref="S4.SS2.p5.3.m3.2.2.1.1.1.3.2.3.cmml">n</mi></msubsup><mo id="S4.SS2.p5.3.m3.2.2.1.1.1.2" xref="S4.SS2.p5.3.m3.2.2.1.1.1.2.cmml">+</mo><mrow id="S4.SS2.p5.3.m3.2.2.1.1.1.1" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p5.3.m3.2.2.1.1.1.1.3" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.3.cmml">ğ’©</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p5.3.m3.2.2.1.1.1.1.2" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.2.cmml">â€‹</mo><mrow id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.2" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.2.cmml">(</mo><mn id="S4.SS2.p5.3.m3.1.1" xref="S4.SS2.p5.3.m3.1.1.cmml">0</mn><mo id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.3" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.2.cmml">,</mo><mrow id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.cmml"><msup id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.2" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.2.cmml"><mi id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.2.2" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.2.2.cmml">Ïƒ</mi><mn id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.2.3" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.2.3.cmml">2</mn></msup><mo lspace="0em" rspace="0em" id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.1" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.3" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.3.cmml">â„</mi></mrow><mo stretchy="false" id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.4" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S4.SS2.p5.3.m3.2.2.1.1.3" xref="S4.SS2.p5.3.m3.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.3.m3.2b"><apply id="S4.SS2.p5.3.m3.2.2.cmml" xref="S4.SS2.p5.3.m3.2.2"><times id="S4.SS2.p5.3.m3.2.2.2.cmml" xref="S4.SS2.p5.3.m3.2.2.2"></times><ci id="S4.SS2.p5.3.m3.2.2.3.cmml" xref="S4.SS2.p5.3.m3.2.2.3">ğ¶</ci><apply id="S4.SS2.p5.3.m3.2.2.1.1.1.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1"><plus id="S4.SS2.p5.3.m3.2.2.1.1.1.2.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.2"></plus><apply id="S4.SS2.p5.3.m3.2.2.1.1.1.3.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p5.3.m3.2.2.1.1.1.3.1.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.3">subscript</csymbol><apply id="S4.SS2.p5.3.m3.2.2.1.1.1.3.2.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p5.3.m3.2.2.1.1.1.3.2.1.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.3">superscript</csymbol><ci id="S4.SS2.p5.3.m3.2.2.1.1.1.3.2.2.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.3.2.2">ğ‘¤</ci><ci id="S4.SS2.p5.3.m3.2.2.1.1.1.3.2.3.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.3.2.3">ğ‘›</ci></apply><apply id="S4.SS2.p5.3.m3.2.2.1.1.1.3.3.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.3.3"><plus id="S4.SS2.p5.3.m3.2.2.1.1.1.3.3.1.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.3.3.1"></plus><ci id="S4.SS2.p5.3.m3.2.2.1.1.1.3.3.2.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.3.3.2">ğ‘¡</ci><cn type="integer" id="S4.SS2.p5.3.m3.2.2.1.1.1.3.3.3.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.3.3.3">1</cn></apply></apply><apply id="S4.SS2.p5.3.m3.2.2.1.1.1.1.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1"><times id="S4.SS2.p5.3.m3.2.2.1.1.1.1.2.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.2"></times><ci id="S4.SS2.p5.3.m3.2.2.1.1.1.1.3.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.3">ğ’©</ci><interval closure="open" id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.2.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1"><cn type="integer" id="S4.SS2.p5.3.m3.1.1.cmml" xref="S4.SS2.p5.3.m3.1.1">0</cn><apply id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1"><times id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.1.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.1"></times><apply id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.2.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.2.2">ğœ</ci><cn type="integer" id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.2.3">2</cn></apply><ci id="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.3.cmml" xref="S4.SS2.p5.3.m3.2.2.1.1.1.1.1.1.1.3">â„</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.3.m3.2c">C(w^{n}_{t+1}+\mathcal{N}(0,\sigma^{2}\mathcal{I}))</annotation></semantics></math> with <math id="S4.SS2.p5.4.m4.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S4.SS2.p5.4.m4.1a"><mi id="S4.SS2.p5.4.m4.1.1" xref="S4.SS2.p5.4.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.4.m4.1b"><ci id="S4.SS2.p5.4.m4.1.1.cmml" xref="S4.SS2.p5.4.m4.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.4.m4.1c">C</annotation></semantics></math> resembling a sparse client update through shifted compression that has proven to improve convergence of DL models in FL settings compared to direct compression <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Mitra </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>); <span class="ltx_text" style="font-size:90%;">Mishchenko </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>. Overall, SoteriaFL mitigates the trade-off between model utility and compression, i.e., the differentially private models converge faster in stricter compression regimes than previously existing non-compressed differentially private approaches.</p>
</div>
<div id="S4.SS2.p6" class="ltx_para">
<p id="S4.SS2.p6.1" class="ltx_p"><span id="S4.SS2.p6.1.1" class="ltx_text ltx_font_bold">Low-rank Compression (LRC)</span>. H-FL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Yang</span> (<a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> introduces a multi-level FL system with low-rank compression for full models by applying singular value decomposition to the feature matrix. This comes at the cost of model accuracy. To mitigate these effects, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Yang</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a></cite>] includes a bias correction mechanism before each FL training round. However, it is to be noted that H-FL is a hierarchical learning framework that trains shallow models on the clients and employs mediating servers to connect the shallow client models with additional layers to form deep neural networks. The server is responsible for aggregating two models: the client models and the deep mediator network. Depending on the model architecture and nature of the task, maintaining two models could be cumbersome and incur additional communication overhead.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Discussion</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">To date, advancements in communication efficient methods for FL systems predominantly focus on training small full models.
The communication paradigm shifts with the emergence of FMs in FL applications.
With fine-tuning tasks, we only need to train a small fraction of model parameters, and thus, only trainable parameters have to be communicated.
However, each trainable parameter usually contains a high degree of information for a downstream task. As such, the effectiveness of model pruning techniques is unclear as they would cut away fine-tuned parameters.
At the same time, full-model compression techniques do not alter the model structure but rather reduce the parameter precision.
Thus, these techniques can be used with FL applications with FMs in order to further reduce the size of the communicated updates. However, since fine-tuning is used for learning specific details in a downstream task, it is open to what degree we can compress PEFT model updates without removing essential information. Since PEFT is already sensitive to non-IID, efficient communication techniques can cause compounding effects as they remove information from trainable parameters.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Are FL frameworks ready for FMs?</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">The backbones for making FL applications available to a broad audience are FL frameworks that implement recent advancements in FL research.
We investigate widely used frameworks for their FM readiness and progress in integrating computational and communication efficiency (<a href="#S5.T3" title="In 5 Are FL frameworks ready for FMs? â€£ A Survey on Efficient Federated Learning Methods for Foundation Model Training" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Current capabilities of state-of-the-art FL framework with respect to our taxonomy and their ability to run in resource-limited environments. The table is sorted by the frameworksâ€™ ability to train FMs. Key: DP = Differential Privacy, HEC = Homomorphic Encryption, SMPC = Secure Multi-Party Computation.</figcaption>
<div id="S5.T3.10" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:212.5pt;height:101pt;vertical-align:-0.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-122.2pt,57.8pt) scale(0.465134110162542,0.465134110162542) ;">
<table id="S5.T3.10.10" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T3.10.10.11.1" class="ltx_tr">
<td id="S5.T3.10.10.11.1.1" class="ltx_td ltx_border_tt"></td>
<th id="S5.T3.10.10.11.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T3.10.10.11.1.2.1" class="ltx_text ltx_font_bold">Secure</span></th>
<th id="S5.T3.10.10.11.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T3.10.10.11.1.3.1" class="ltx_text ltx_font_bold">Training</span></th>
<th id="S5.T3.10.10.11.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T3.10.10.11.1.4.1" class="ltx_text ltx_font_bold">Communication</span></th>
<th id="S5.T3.10.10.11.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T3.10.10.11.1.5.1" class="ltx_text ltx_font_bold">FM Training /</span></th>
<th id="S5.T3.10.10.11.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T3.10.10.11.1.6.1" class="ltx_text ltx_font_bold">Edge</span></th>
</tr>
<tr id="S5.T3.10.10.12.2" class="ltx_tr">
<th id="S5.T3.10.10.12.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column"><span id="S5.T3.10.10.12.2.1.1" class="ltx_text ltx_font_bold">Framework</span></th>
<th id="S5.T3.10.10.12.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T3.10.10.12.2.2.1" class="ltx_text ltx_font_bold">Aggregation</span></th>
<th id="S5.T3.10.10.12.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T3.10.10.12.2.3.1" class="ltx_text ltx_font_bold">Efficiency</span></th>
<th id="S5.T3.10.10.12.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T3.10.10.12.2.4.1" class="ltx_text ltx_font_bold">Efficiency</span></th>
<th id="S5.T3.10.10.12.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T3.10.10.12.2.5.1" class="ltx_text ltx_font_bold">Fine-Tuning</span></th>
<th id="S5.T3.10.10.12.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T3.10.10.12.2.6.1" class="ltx_text ltx_font_bold">Ready</span></th>
</tr>
<tr id="S5.T3.1.1.1" class="ltx_tr">
<td id="S5.T3.1.1.1.2" class="ltx_td ltx_align_left ltx_border_t">Clara</td>
<td id="S5.T3.1.1.1.3" class="ltx_td ltx_align_left ltx_border_t">DP, HEC</td>
<td id="S5.T3.1.1.1.4" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.1.1.1.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_bb ltx_border_t" rowspan="10"><span id="S5.T3.1.1.1.5.1" class="ltx_text">
<span id="S5.T3.1.1.1.5.1.1" class="ltx_inline-block ltx_align_left">
<span id="S5.T3.1.1.1.5.1.1.1" class="ltx_p">Currently, none of the</span>
<span id="S5.T3.1.1.1.5.1.1.2" class="ltx_p">Frameworks implements</span>
<span id="S5.T3.1.1.1.5.1.1.3" class="ltx_p">communication efficient</span>
<span id="S5.T3.1.1.1.5.1.1.4" class="ltx_p">FL methods.</span>
</span></span></td>
<td id="S5.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><svg id="S5.T3.1.1.1.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S5.T3.1.1.1.6" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S5.T3.3.3.3" class="ltx_tr">
<td id="S5.T3.3.3.3.3" class="ltx_td ltx_align_left">FedML</td>
<td id="S5.T3.3.3.3.4" class="ltx_td ltx_align_left">DP, HEC</td>
<td id="S5.T3.3.3.3.5" class="ltx_td ltx_align_left">PEFT</td>
<td id="S5.T3.2.2.2.1" class="ltx_td ltx_align_center"><svg id="S5.T3.2.2.2.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S5.T3.3.3.3.2" class="ltx_td ltx_align_center"><svg id="S5.T3.3.3.3.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S5.T3.5.5.5" class="ltx_tr">
<td id="S5.T3.5.5.5.3" class="ltx_td ltx_align_left">FederatedScope</td>
<td id="S5.T3.5.5.5.4" class="ltx_td"></td>
<td id="S5.T3.5.5.5.5" class="ltx_td ltx_align_left">PEFT</td>
<td id="S5.T3.4.4.4.1" class="ltx_td ltx_align_center"><svg id="S5.T3.4.4.4.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S5.T3.5.5.5.2" class="ltx_td ltx_align_center"><svg id="S5.T3.5.5.5.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S5.T3.7.7.7" class="ltx_tr">
<td id="S5.T3.7.7.7.3" class="ltx_td ltx_align_left">Flower</td>
<td id="S5.T3.7.7.7.4" class="ltx_td ltx_align_left">DP, SMPC</td>
<td id="S5.T3.7.7.7.5" class="ltx_td ltx_align_left">PEFT</td>
<td id="S5.T3.6.6.6.1" class="ltx_td ltx_align_center"><svg id="S5.T3.6.6.6.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S5.T3.7.7.7.2" class="ltx_td ltx_align_center"><svg id="S5.T3.7.7.7.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S5.T3.9.9.9" class="ltx_tr">
<td id="S5.T3.9.9.9.3" class="ltx_td ltx_align_left">FATE</td>
<td id="S5.T3.9.9.9.4" class="ltx_td ltx_align_left">HEC, SMPC</td>
<td id="S5.T3.9.9.9.5" class="ltx_td ltx_align_left">PEFT</td>
<td id="S5.T3.8.8.8.1" class="ltx_td ltx_align_center"><svg id="S5.T3.8.8.8.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S5.T3.9.9.9.2" class="ltx_td ltx_align_center"><svg id="S5.T3.9.9.9.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S5.T3.10.10.13.3" class="ltx_tr">
<td id="S5.T3.10.10.13.3.1" class="ltx_td ltx_align_left ltx_border_t">Substra</td>
<td id="S5.T3.10.10.13.3.2" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.10.10.13.3.3" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.10.10.13.3.4" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.10.10.13.3.5" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S5.T3.10.10.14.4" class="ltx_tr">
<td id="S5.T3.10.10.14.4.1" class="ltx_td ltx_align_left">PySyft</td>
<td id="S5.T3.10.10.14.4.2" class="ltx_td ltx_align_left">DP</td>
<td id="S5.T3.10.10.14.4.3" class="ltx_td"></td>
<td id="S5.T3.10.10.14.4.4" class="ltx_td"></td>
<td id="S5.T3.10.10.14.4.5" class="ltx_td"></td>
</tr>
<tr id="S5.T3.10.10.15.5" class="ltx_tr">
<td id="S5.T3.10.10.15.5.1" class="ltx_td ltx_align_left">OpenFL</td>
<td id="S5.T3.10.10.15.5.2" class="ltx_td"></td>
<td id="S5.T3.10.10.15.5.3" class="ltx_td"></td>
<td id="S5.T3.10.10.15.5.4" class="ltx_td"></td>
<td id="S5.T3.10.10.15.5.5" class="ltx_td"></td>
</tr>
<tr id="S5.T3.10.10.10" class="ltx_tr">
<td id="S5.T3.10.10.10.2" class="ltx_td ltx_align_left">TFF</td>
<td id="S5.T3.10.10.10.3" class="ltx_td ltx_align_left">DP</td>
<td id="S5.T3.10.10.10.4" class="ltx_td"></td>
<td id="S5.T3.10.10.10.5" class="ltx_td"></td>
<td id="S5.T3.10.10.10.1" class="ltx_td ltx_align_center"><svg id="S5.T3.10.10.10.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S5.T3.10.10.16.6" class="ltx_tr">
<td id="S5.T3.10.10.16.6.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_bb">IBM FL</td>
<td id="S5.T3.10.10.16.6.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_bb">HEC</td>
<td id="S5.T3.10.10.16.6.3" class="ltx_td ltx_border_bb ltx_border_bb"></td>
<td id="S5.T3.10.10.16.6.4" class="ltx_td ltx_border_bb ltx_border_bb"></td>
<td id="S5.T3.10.10.16.6.5" class="ltx_td ltx_border_bb ltx_border_bb"></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Generally, all FL frameworks could handle FMs.
Yet, only half implement efficient training methods.
To further drive the adoption of FL in times of FMs, the frameworks need to improve both computationally and communication-efficient methods for training.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">Clara is a proprietary FL framework designed specifically for medical applications and to work with NVIDIA GPUs <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">NVIDIA</span> (<a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>. The focus on powerful infrastructure makes training FMs in an FL setting possible. However, the Clara SDK does not include FL-specific optimizations to reduce computational or communication efforts specific to FMs.
The final set of FL frameworks, characterized by their active open-source community, FATE <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Fan </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>); <span class="ltx_text" style="font-size:90%;">Liu </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>, FedML <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">He </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>, TensorFlow Federated (TFF) <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Google</span> (<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>, FederatedScope <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Kuang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>); <span class="ltx_text" style="font-size:90%;">Xie </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite> and Flower <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Beutel </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>, have adopted recent advancements in FL research. The frameworks especially allow for PEFT of FMs with LoRA.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">Substra <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Galtier and Marini</span> (<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>, PySyft <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Ziller </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib73" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>, OpenFL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Foley </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>, and IBM FL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Ludwig </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>, in their versions as of 2023, focus on training smaller FL tasks with several hundred thousand up to a few million parameters and, therefore, do not provide adapters for FM workloads with more than 100M parameters.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p">Yet, a consistent observation across all frameworks is their lack of efficient communication techniques.
Workloads with FMs will significantly increase communication costs, and the growing use cases involving resource-constrained edge and IoT devices require high efficiency for computation and communication.
As a result and due to their PEFT capabilities, FATE, FederatedScope, FedML, and Flower are currently the best choices when working with FMs in FL systems.

</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Related Work</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">While there are ample surveys that provide a broad perspective on FL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Li </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>); <span class="ltx_text" style="font-size:90%;">Banabilah </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>); <span class="ltx_text" style="font-size:90%;">Liu </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>); <span class="ltx_text" style="font-size:90%;">Nguyen </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>); <span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib64" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>); <span class="ltx_text" style="font-size:90%;">Aledhari </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>, there are two closely related surveys to our work as they also focus on FMs.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">In their survey, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Zhuang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a></cite>] introduce a broad and general perspective on FMs and FL.
They extensively discuss data modalities. This includes access to data across a large number of highly distributed clients and the quality of data that lives on these clients.
Currently, FM training or fine-tuning requires datasets with high data quality, i.e., the instructions or texts used for MLM must be curated very carefully.
Thus, their survey identifies a stark need for methods to train or fine-tune FMs on a scattered data basis with (highly) varying data quality.
Further, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Zhuang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a></cite>] discuss approaches to integrate FL applications into the lifecycle of FMs, i.e., how FMs can benefit from a continuously evolving system.
While their survey briefly touches upon computational efficiency, our study provides an in-depth overview of state-of-the-art training and fine-tuning techniques to render FMs in FL applications a reality.
Furthermore, our study includes a comprehensive overview of communication techniques that can enhance the adoption of FMs in communication resource-constrained environments.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Yu </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span></a></cite>Â [<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a></cite>] provide an overview of FMs and FL with a special focus on privacy, an integral component of FL.
Their survey includes a comprehensive overview of different fields of application for FMs, which they divide into once-off training and continual learning.
The authors elaborate on technical challenges that may arise for specific use cases, such as robustness towards unreliable clients, varying data quality, the degree of non-IID data, and scalability.
In contrast, our survey provides an application-agnostic, in-depth study of existing methods suitable for FM training. Our focus is to outline the technical challenges that currently hinder the operationalization of FM for use cases in federated applications.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusions &amp; Future Directions</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this paper, we survey the current landscape of computational and communication efficiency methods in FL systems and introduce a novel taxonomy based on the key techniques.
While efficient FL methods have been separate topics on their own in the past, they become closely intertwined as we start using FL systems to train FMs.
Adjacent to our analysis of efficiency methods in FL, we find the following three open questions that require attention from the FL community.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p"><span id="S7.p2.1.1" class="ltx_text ltx_font_bold">What are good and realistic evaluation strategies for generative downstream tasks in FL settings where we do not have control of data?</span>
Fine-tuning generative FM requires high-quality data.
However, we do not have access to data on the clients to monitor data quality before or during training.
It is interesting to understand the notion of data heterogeneity in the context of generative tasks and the definition of heterogeneous data splits.</p>
</div>
<div id="S7.p3" class="ltx_para">
<p id="S7.p3.1" class="ltx_p"><span id="S7.p3.1.1" class="ltx_text ltx_font_bold">How does hyperparameter optimization work for FMs in continuously evolving FL systems?</span>
While hyperparameter optimization in FL has been a key challenge, PEFT adds additional complexity. By the example of LoRA, we can systematically search for the optimal parameterization of <math id="S7.p3.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S7.p3.1.m1.1a"><mi id="S7.p3.1.m1.1.1" xref="S7.p3.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S7.p3.1.m1.1b"><ci id="S7.p3.1.m1.1.1.cmml" xref="S7.p3.1.m1.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.p3.1.m1.1c">r</annotation></semantics></math> while training in a centralized setting.
In continuously evolving FL systems, parameterization needs to evolve over time.
Furthermore, PEFT has been shown to be particularly sensitive to non-IID data, which further increases the complexity of hyperparameter optimization.
However, PEFT and FL can create good quality models, but to date, at significant costs in the form of long warm-up times.</p>
</div>
<div id="S7.p4" class="ltx_para">
<p id="S7.p4.1" class="ltx_p"><span id="S7.p4.1.1" class="ltx_text ltx_font_bold">How do PEFT and privacy in FL work together?</span>
Communication-efficient FL techniques have been studied for their effect on privacy, but this is still an open topic for PEFT, PT, and IT. While it is proven that PEFT is more sensitive to data heterogeneity, the effects of perturbation through differential privacy are still subject to further studies. The same is true for PT and IT, as both techniques require precise prompts and instructions, respectively. As such, noise may have significantly negative effects here, as well.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="Ax1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">Acknowledgments</h2>

<div id="Ax1.p1" class="ltx_para">
<p id="Ax1.p1.1" class="ltx_p">This work is partially supported by the Bavarian Ministry of Economic Affairs, Regional Development and Energy (Grant: DIK0446/01).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.5.5.1" class="ltx_text" style="font-size:90%;">Aledhari </span><span id="bib.bib1.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib1.7.7.3" class="ltx_text" style="font-size:90%;"> [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.9.1" class="ltx_text" style="font-size:90%;">
Mohammed Aledhari, Rehma Razzak, RezaÂ M. Parizi, and Fahad Saeed.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.10.1" class="ltx_text" style="font-size:90%;">Federated learning: A survey on enabling technologies, protocols, and applications.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Access</span><span id="bib.bib1.12.2" class="ltx_text" style="font-size:90%;">, 8:140699â€“140725, 2020.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.5.5.1" class="ltx_text" style="font-size:90%;">Alistarh </span><span id="bib.bib2.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib2.7.7.3" class="ltx_text" style="font-size:90%;"> [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.9.1" class="ltx_text" style="font-size:90%;">
Dan Alistarh, Demjan Grubic, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.10.1" class="ltx_text" style="font-size:90%;">Qsgd: Communication-efficient sgd via gradient quantization and encoding.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib2.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib2.13.3" class="ltx_text" style="font-size:90%;">, volumeÂ 30, 2017.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.5.5.1" class="ltx_text" style="font-size:90%;">Babakniya </span><span id="bib.bib3.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib3.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.9.1" class="ltx_text" style="font-size:90%;">
Sara Babakniya, AhmedÂ R. Elkordy, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.10.1" class="ltx_text" style="font-size:90%;">Slora: Federated parameter efficient fine-tuning of language models, 2023.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.5.5.1" class="ltx_text" style="font-size:90%;">Banabilah </span><span id="bib.bib4.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib4.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.9.1" class="ltx_text" style="font-size:90%;">
Syreen Banabilah, Moayad Aloqaily, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.10.1" class="ltx_text" style="font-size:90%;">Federated learning review: Fundamentals, enabling technologies, and future applications.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Information Processing &amp; Management</span><span id="bib.bib4.12.2" class="ltx_text" style="font-size:90%;">, 59(6), 2022.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.5.5.1" class="ltx_text" style="font-size:90%;">Beutel </span><span id="bib.bib5.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib5.7.7.3" class="ltx_text" style="font-size:90%;"> [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.9.1" class="ltx_text" style="font-size:90%;">
DanielÂ J. Beutel, Taner Topal, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.10.1" class="ltx_text" style="font-size:90%;">Flower: A friendly federated learning research framework, 2020.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.5.5.1" class="ltx_text" style="font-size:90%;">Bommasani </span><span id="bib.bib6.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib6.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.9.1" class="ltx_text" style="font-size:90%;">
Rishi Bommasani, DrewÂ A. Hudson, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.10.1" class="ltx_text" style="font-size:90%;">On the opportunities and risks of foundation models, 2021.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.5.5.1" class="ltx_text" style="font-size:90%;">Chen </span><span id="bib.bib7.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib7.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.9.1" class="ltx_text" style="font-size:90%;">
Yuanyuan Chen, Zichen Chen, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.10.1" class="ltx_text" style="font-size:90%;">Fedobd: Opportunistic block dropout for efficiently training large-scale neural networks through federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, IJCAI-23</span><span id="bib.bib7.13.3" class="ltx_text" style="font-size:90%;">. IJCAI Org., 2023.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.5.5.1" class="ltx_text" style="font-size:90%;">Diao </span><span id="bib.bib8.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib8.7.7.3" class="ltx_text" style="font-size:90%;"> [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.9.1" class="ltx_text" style="font-size:90%;">
Enmao Diao, Jie Ding, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.10.1" class="ltx_text" style="font-size:90%;">Heterofl: Computation and communication efficient federated learning for heterogeneous clients, 2020.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.5.5.1" class="ltx_text" style="font-size:90%;">Ding </span><span id="bib.bib9.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib9.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.9.1" class="ltx_text" style="font-size:90%;">
Ning Ding, Yujia Qin, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.10.1" class="ltx_text" style="font-size:90%;">Parameter-efficient fine-tuning of large-scale pre-trained language models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Nature Machine Intelligence</span><span id="bib.bib9.12.2" class="ltx_text" style="font-size:90%;">, 5(3):220â€“235, March 2023.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.5.5.1" class="ltx_text" style="font-size:90%;">Dosovitskiy </span><span id="bib.bib10.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib10.7.7.3" class="ltx_text" style="font-size:90%;"> [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.9.1" class="ltx_text" style="font-size:90%;">
Alexey Dosovitskiy, Lucas Beyer, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.10.1" class="ltx_text" style="font-size:90%;">An image is worth 16x16 words: Transformers for image recognition at scale, 2020.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.5.5.1" class="ltx_text" style="font-size:90%;">Fan </span><span id="bib.bib11.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib11.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.9.1" class="ltx_text" style="font-size:90%;">
Tao Fan, Yan Kang, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.10.1" class="ltx_text" style="font-size:90%;">Fate-llm: A industrial grade federated learning framework for large language models, 2023.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.5.5.1" class="ltx_text" style="font-size:90%;">Foley </span><span id="bib.bib12.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib12.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.9.1" class="ltx_text" style="font-size:90%;">
Patrick Foley, MicahÂ J Sheller, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.10.1" class="ltx_text" style="font-size:90%;">Openfl: the open federated learning library.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Physics in Medicine &amp; Biology</span><span id="bib.bib12.12.2" class="ltx_text" style="font-size:90%;">, 67(21), 2022.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.4.4.1" class="ltx_text" style="font-size:90%;">Frankle and Carbin [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.6.1" class="ltx_text" style="font-size:90%;">
Jonathan Frankle and Michael Carbin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.7.1" class="ltx_text" style="font-size:90%;">The lottery ticket hypothesis: Finding sparse, trainable neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.8.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.9.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICLR</span><span id="bib.bib13.10.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.4.4.1" class="ltx_text" style="font-size:90%;">Galtier and Marini [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.6.1" class="ltx_text" style="font-size:90%;">
MathieuÂ N Galtier and Camille Marini.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.7.1" class="ltx_text" style="font-size:90%;">Substra: a framework for privacy-preserving, traceable and collaborative machine learning, 2019.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.4.4.1" class="ltx_text" style="font-size:90%;">Google [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.6.1" class="ltx_text" style="font-size:90%;">
Google.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.7.1" class="ltx_text" style="font-size:90%;">Tensorflow federated.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.8.1" class="ltx_text ltx_font_italic" style="font-size:90%;">.</span><span id="bib.bib15.9.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.5.5.1" class="ltx_text" style="font-size:90%;">Habib </span><span id="bib.bib16.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib16.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.9.1" class="ltx_text" style="font-size:90%;">
Gousia Habib, TausifaÂ Jan Saleem, and Brejesh Lall.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.10.1" class="ltx_text" style="font-size:90%;">Knowledge distillation in vision transformers: A critical review, 2023.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.5.5.1" class="ltx_text" style="font-size:90%;">He </span><span id="bib.bib17.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib17.7.7.3" class="ltx_text" style="font-size:90%;"> [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.9.1" class="ltx_text" style="font-size:90%;">
Chaoyang He, Songze Li, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.10.1" class="ltx_text" style="font-size:90%;">Fedml: A research library and benchmark for federated machine learning, 2020.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.5.5.1" class="ltx_text" style="font-size:90%;">He </span><span id="bib.bib18.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib18.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.9.1" class="ltx_text" style="font-size:90%;">
Haoyu He, Xingjian Shi, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.10.1" class="ltx_text" style="font-size:90%;">Distiller: A systematic study of model distillation methods in natural language processing, 2021.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.5.5.1" class="ltx_text" style="font-size:90%;">HorvÃ¡th </span><span id="bib.bib19.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib19.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.9.1" class="ltx_text" style="font-size:90%;">
Samuel HorvÃ¡th, Stefanos Laskaridis, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.10.1" class="ltx_text" style="font-size:90%;">FjORD: Fair and accurate federated learning under heterogeneous targets with ordered dropout.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib19.13.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.5.5.1" class="ltx_text" style="font-size:90%;">Houlsby </span><span id="bib.bib20.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib20.7.7.3" class="ltx_text" style="font-size:90%;"> [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.9.1" class="ltx_text" style="font-size:90%;">
Neil Houlsby, Andrei Giurgiu, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.10.1" class="ltx_text" style="font-size:90%;">Parameter-efficient transfer learning for nlp, 2019.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.5.5.1" class="ltx_text" style="font-size:90%;">Hu </span><span id="bib.bib21.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib21.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.9.1" class="ltx_text" style="font-size:90%;">
EdwardÂ J. Hu, Yelong Shen, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.10.1" class="ltx_text" style="font-size:90%;">Lora: Low-rank adaptation of large language models, 2021.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.5.5.1" class="ltx_text" style="font-size:90%;">Huang </span><span id="bib.bib22.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib22.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.9.1" class="ltx_text" style="font-size:90%;">
Hong Huang, Lan Zhang, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.10.1" class="ltx_text" style="font-size:90%;">Distributed pruning towards tiny neural networks in federated learning, 2022.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.5.5.1" class="ltx_text" style="font-size:90%;">Isenko </span><span id="bib.bib23.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib23.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.9.1" class="ltx_text" style="font-size:90%;">
Alexander Isenko, Ruben Mayer, and Hans-Arno Jacobsen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.10.1" class="ltx_text" style="font-size:90%;">How can we train deep learning models across clouds and continents? an experimental study, 2023.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.5.5.1" class="ltx_text" style="font-size:90%;">Isik </span><span id="bib.bib24.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib24.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.9.1" class="ltx_text" style="font-size:90%;">
Berivan Isik, Francesco Pase, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.10.1" class="ltx_text" style="font-size:90%;">Sparse random networks for communication-efficient federated learning, 2022.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.5.5.1" class="ltx_text" style="font-size:90%;">Jia </span><span id="bib.bib25.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib25.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.9.1" class="ltx_text" style="font-size:90%;">
Menglin Jia, Luming Tang, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.10.1" class="ltx_text" style="font-size:90%;">Visual prompt tuning, 2022.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.5.5.1" class="ltx_text" style="font-size:90%;">Jiang </span><span id="bib.bib26.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib26.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.9.1" class="ltx_text" style="font-size:90%;">
Yuang Jiang, Shiqiang Wang, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.10.1" class="ltx_text" style="font-size:90%;">Model pruning enables efficient federated learning on edge devices.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Neural Networks and Learning Systems</span><span id="bib.bib26.12.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.5.5.1" class="ltx_text" style="font-size:90%;">Kuang </span><span id="bib.bib27.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib27.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.9.1" class="ltx_text" style="font-size:90%;">
Weirui Kuang, Bingchen Qian, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.10.1" class="ltx_text" style="font-size:90%;">Federatedscope-llm: A comprehensive package for fine-tuning large language models in federated learning, 2023.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.5.5.1" class="ltx_text" style="font-size:90%;">Lagunas </span><span id="bib.bib28.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib28.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.9.1" class="ltx_text" style="font-size:90%;">
Francois Lagunas, Ella Charlaix, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.10.1" class="ltx_text" style="font-size:90%;">Block pruning for faster transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib28.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 2021 Conference on EMNLP</span><span id="bib.bib28.13.3" class="ltx_text" style="font-size:90%;">, Online and Punta Cana, Dominican Republic, November 2021. ACL.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.5.5.1" class="ltx_text" style="font-size:90%;">Lester </span><span id="bib.bib29.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib29.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.9.1" class="ltx_text" style="font-size:90%;">
Brian Lester, Rami Al-Rfou, and Noah Constant.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.10.1" class="ltx_text" style="font-size:90%;">The power of scale for parameter-efficient prompt tuning, 2021.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.5.5.1" class="ltx_text" style="font-size:90%;">Li </span><span id="bib.bib30.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib30.7.7.3" class="ltx_text" style="font-size:90%;"> [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.9.1" class="ltx_text" style="font-size:90%;">
Ang Li, Jingwei Sun, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.10.1" class="ltx_text" style="font-size:90%;">Lotteryfl: Personalized and communication-efficient federated learning with lottery ticket hypothesis on non-iid datasets, 2020.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.5.5.1" class="ltx_text" style="font-size:90%;">Li </span><span id="bib.bib31.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib31.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.9.1" class="ltx_text" style="font-size:90%;">
Zhize Li, Haoyu Zhao, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.10.1" class="ltx_text" style="font-size:90%;">Soteriafl: A unified framework for private federated learning with communication compression.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib31.13.3" class="ltx_text" style="font-size:90%;">, volumeÂ 35, 2022.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.5.5.1" class="ltx_text" style="font-size:90%;">Li </span><span id="bib.bib32.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib32.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.9.1" class="ltx_text" style="font-size:90%;">
Qinbin Li, Zeyi Wen, Zhaomin Wu, Sixu Hu, Naibo Wang, Yuan Li, XuÂ Liu, and Bingsheng He.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.10.1" class="ltx_text" style="font-size:90%;">A survey on federated learning systems: Vision, hype and reality for data privacy and protection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Knowledge and Data Engineering</span><span id="bib.bib32.12.2" class="ltx_text" style="font-size:90%;">, 35(4):3347â€“3366, April 2023.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.5.5.1" class="ltx_text" style="font-size:90%;">Liu </span><span id="bib.bib33.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib33.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.9.1" class="ltx_text" style="font-size:90%;">
Yang Liu, Tao Fan, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.10.1" class="ltx_text" style="font-size:90%;">Fate: An industrial grade platform for collaborative learning with data protection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">JMLR</span><span id="bib.bib33.12.2" class="ltx_text" style="font-size:90%;">, 22(1), 2021.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.5.5.1" class="ltx_text" style="font-size:90%;">Liu </span><span id="bib.bib34.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib34.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.9.1" class="ltx_text" style="font-size:90%;">
JiÂ Liu, Jizhou Huang, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.10.1" class="ltx_text" style="font-size:90%;">From distributed machine learning to federated learning: a survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Knowledge and Information Systems</span><span id="bib.bib34.12.2" class="ltx_text" style="font-size:90%;">, 64(4), 2022.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.5.5.1" class="ltx_text" style="font-size:90%;">Liu </span><span id="bib.bib35.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib35.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.9.1" class="ltx_text" style="font-size:90%;">
Jiawei Liu, Cheng Yang, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.10.1" class="ltx_text" style="font-size:90%;">Towards graph foundation models: A survey and beyond, 2023.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.5.5.1" class="ltx_text" style="font-size:90%;">Longpre </span><span id="bib.bib36.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib36.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.9.1" class="ltx_text" style="font-size:90%;">
Shayne Longpre, LeÂ Hou, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.10.1" class="ltx_text" style="font-size:90%;">The flan collection: Designing data and methods for effective instruction tuning, 2023.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.5.5.1" class="ltx_text" style="font-size:90%;">Lu </span><span id="bib.bib37.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib37.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.9.1" class="ltx_text" style="font-size:90%;">
Wang Lu, Xixu Hu, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.10.1" class="ltx_text" style="font-size:90%;">Fedclip: Fast generalization and personalization for clip in federated learning, 2023.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.5.5.1" class="ltx_text" style="font-size:90%;">Ludwig </span><span id="bib.bib38.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib38.7.7.3" class="ltx_text" style="font-size:90%;"> [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.9.1" class="ltx_text" style="font-size:90%;">
Heiko Ludwig, Nathalie Baracaldo, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.10.1" class="ltx_text" style="font-size:90%;">Ibm federated learning: an enterprise framework white paper v0.1, 2020.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.5.5.1" class="ltx_text" style="font-size:90%;">McMahan </span><span id="bib.bib39.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib39.7.7.3" class="ltx_text" style="font-size:90%;"> [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.9.1" class="ltx_text" style="font-size:90%;">
Brendan McMahan, Eider Moore, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.10.1" class="ltx_text" style="font-size:90%;">Communication-Efficient Learning of Deep Networks from Decentralized Data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib39.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 20th International Conference on Artificial Intelligence and Statistics</span><span id="bib.bib39.13.3" class="ltx_text" style="font-size:90%;">, volumeÂ 54 of </span><span id="bib.bib39.14.4" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of Machine Learning Research</span><span id="bib.bib39.15.5" class="ltx_text" style="font-size:90%;">. PMLR, 2017.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.5.5.1" class="ltx_text" style="font-size:90%;">Mishchenko </span><span id="bib.bib40.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib40.7.7.3" class="ltx_text" style="font-size:90%;"> [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.9.1" class="ltx_text" style="font-size:90%;">
Konstantin Mishchenko, Eduard Gorbunov, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.10.1" class="ltx_text" style="font-size:90%;">Distributed learning with compressed gradient differences, 2019.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.5.5.1" class="ltx_text" style="font-size:90%;">Mitra </span><span id="bib.bib41.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib41.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.9.1" class="ltx_text" style="font-size:90%;">
Aritra Mitra, Rayana Jaafar, GeorgeÂ J. Pappas, and Hamed Hassani.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.10.1" class="ltx_text" style="font-size:90%;">Linear convergence in federated learning: Tackling client heterogeneity and sparse gradients.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib41.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib41.13.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.5.5.1" class="ltx_text" style="font-size:90%;">Nguyen </span><span id="bib.bib42.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib42.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.9.1" class="ltx_text" style="font-size:90%;">
DinhÂ C. Nguyen, Ming Ding, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.10.1" class="ltx_text" style="font-size:90%;">Federated learning for internet of things: A comprehensive survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Communications Surveys &amp; Tutorials</span><span id="bib.bib42.12.2" class="ltx_text" style="font-size:90%;">, 23(3), 2021.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.4.4.1" class="ltx_text" style="font-size:90%;">NVIDIA [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.6.1" class="ltx_text" style="font-size:90%;">
NVIDIA.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.7.1" class="ltx_text" style="font-size:90%;">Federated learning for healthcare using nvidia clara.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.8.1" class="ltx_text ltx_font_italic" style="font-size:90%;">.</span><span id="bib.bib43.9.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.4.4.1" class="ltx_text" style="font-size:90%;">OpenAI [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.6.1" class="ltx_text" style="font-size:90%;">
OpenAI.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.7.1" class="ltx_text" style="font-size:90%;">Gpt-4 technical report, 2023.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.5.5.1" class="ltx_text" style="font-size:90%;">Penedo </span><span id="bib.bib45.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib45.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.9.1" class="ltx_text" style="font-size:90%;">
Guilherme Penedo, Quentin Malartic, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.10.1" class="ltx_text" style="font-size:90%;">The refinedweb dataset for falcon llm: Outperforming curated corpora with web data, and web data only, 2023.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.5.5.1" class="ltx_text" style="font-size:90%;">Peng </span><span id="bib.bib46.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib46.7.7.3" class="ltx_text" style="font-size:90%;"> [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.9.1" class="ltx_text" style="font-size:90%;">
Xingchao Peng, Zijun Huang, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.10.1" class="ltx_text" style="font-size:90%;">Federated adversarial domain adaptation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib46.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICLR</span><span id="bib.bib46.13.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.5.5.1" class="ltx_text" style="font-size:90%;">Perez </span><span id="bib.bib47.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib47.7.7.3" class="ltx_text" style="font-size:90%;"> [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.9.1" class="ltx_text" style="font-size:90%;">
Andres Perez, Valentina Sanguineti, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.10.1" class="ltx_text" style="font-size:90%;">Audio-visual model distillation using acoustic images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib47.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</span><span id="bib.bib47.13.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.5.5.1" class="ltx_text" style="font-size:90%;">Radford </span><span id="bib.bib48.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib48.7.7.3" class="ltx_text" style="font-size:90%;"> [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.9.1" class="ltx_text" style="font-size:90%;">
Alec Radford, Jeff Wu, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.10.1" class="ltx_text" style="font-size:90%;">Language models are unsupervised multitask learners.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.11.1" class="ltx_text" style="font-size:90%;">2019.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.5.5.1" class="ltx_text" style="font-size:90%;">Reisizadeh </span><span id="bib.bib49.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib49.7.7.3" class="ltx_text" style="font-size:90%;"> [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.9.1" class="ltx_text" style="font-size:90%;">
Amirhossein Reisizadeh, Aryan Mokhtari, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.10.1" class="ltx_text" style="font-size:90%;">Fedpaq: A communication-efficient federated learning method with periodic averaging and quantization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib49.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics</span><span id="bib.bib49.13.3" class="ltx_text" style="font-size:90%;">, volume 108. PMLR, 2020.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib50.5.5.1" class="ltx_text" style="font-size:90%;">Ryabinin </span><span id="bib.bib50.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib50.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib50.9.1" class="ltx_text" style="font-size:90%;">
Max Ryabinin, Tim Dettmers, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.10.1" class="ltx_text" style="font-size:90%;">Swarm parallelism: Training large models can be surprisingly communication-efficient, 2023.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib51.5.5.1" class="ltx_text" style="font-size:90%;">Sanh </span><span id="bib.bib51.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib51.7.7.3" class="ltx_text" style="font-size:90%;"> [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib51.9.1" class="ltx_text" style="font-size:90%;">
Victor Sanh, Thomas Wolf, and Alexander Rush.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.10.1" class="ltx_text" style="font-size:90%;">Movement pruning: Adaptive sparsity by fine-tuning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib51.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib51.13.3" class="ltx_text" style="font-size:90%;">, volumeÂ 33. Curran Associates, Inc., 2020.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib52.5.5.1" class="ltx_text" style="font-size:90%;">Sun </span><span id="bib.bib52.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib52.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib52.9.1" class="ltx_text" style="font-size:90%;">
Guangyu Sun, Matias Mendieta, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.10.1" class="ltx_text" style="font-size:90%;">Exploring parameter-efficient fine-tuning for improving communication efficiency in federated learning, 2023.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib53.5.5.1" class="ltx_text" style="font-size:90%;">Taori </span><span id="bib.bib53.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib53.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib53.9.1" class="ltx_text" style="font-size:90%;">
Rohan Taori, Ishaan Gulrajani, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.10.1" class="ltx_text" style="font-size:90%;">Stanford alpaca: An instruction-following llama model.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://github.com/tatsu-lab/stanford_alpaca</a><span id="bib.bib53.11.1" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib54.5.5.1" class="ltx_text" style="font-size:90%;">Tian </span><span id="bib.bib54.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib54.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib54.9.1" class="ltx_text" style="font-size:90%;">
Yuanyishu Tian, Yao Wan, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.10.1" class="ltx_text" style="font-size:90%;">Fedbert: When federated learning meets pre-training.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Transactions on Intelligent Systems and Technology</span><span id="bib.bib54.12.2" class="ltx_text" style="font-size:90%;">, 13(4), 2022.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib55.5.5.1" class="ltx_text" style="font-size:90%;">WoisetschlÃ¤ger </span><span id="bib.bib55.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib55.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib55.9.1" class="ltx_text" style="font-size:90%;">
Herbert WoisetschlÃ¤ger, Alexander Isenko, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.10.1" class="ltx_text" style="font-size:90%;">Federated fine-tuning of llms on the very edge: The good, the bad, the ugly, 2023.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib56.5.5.1" class="ltx_text" style="font-size:90%;">Xie </span><span id="bib.bib56.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib56.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib56.9.1" class="ltx_text" style="font-size:90%;">
Yuexiang Xie, Zhen Wang, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.10.1" class="ltx_text" style="font-size:90%;">Federatedscope: A flexible federated learning platform for heterogeneity.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the VLDB Endowment</span><span id="bib.bib56.12.2" class="ltx_text" style="font-size:90%;">, 16(5), 2023.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib57.5.5.1" class="ltx_text" style="font-size:90%;">Xu </span><span id="bib.bib57.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib57.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib57.9.1" class="ltx_text" style="font-size:90%;">
Zheng Xu, Yanxiang Zhang, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.10.1" class="ltx_text" style="font-size:90%;">Federated learning of gboard language models with differential privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.11.1" class="ltx_text" style="font-size:90%;">2023.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib58.5.5.1" class="ltx_text" style="font-size:90%;">Yang </span><span id="bib.bib58.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib58.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib58.9.1" class="ltx_text" style="font-size:90%;">
Cheng Yang, Jiawei Liu, and Chuan Shi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.10.1" class="ltx_text" style="font-size:90%;">Extract the knowledge of graph neural networks and go beyond it: An effective knowledge distillation framework.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib58.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the Web Conference 2021</span><span id="bib.bib58.13.3" class="ltx_text" style="font-size:90%;">, WWW â€™21. ACM, 2021.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib59.5.5.1" class="ltx_text" style="font-size:90%;">Yang </span><span id="bib.bib59.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib59.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib59.9.1" class="ltx_text" style="font-size:90%;">
Dongchao Yang, Jinchuan Tian, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.10.1" class="ltx_text" style="font-size:90%;">Uniaudio: An audio foundation model toward universal audio generation, 2023.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib60.4.4.1" class="ltx_text" style="font-size:90%;">Yang [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib60.6.1" class="ltx_text" style="font-size:90%;">
HeÂ Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.7.1" class="ltx_text" style="font-size:90%;">H-FL: A hierarchical communication-efficient and privacy-protected architecture for federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.8.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib60.9.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence</span><span id="bib.bib60.10.3" class="ltx_text" style="font-size:90%;">. IJCAI Org., 2021.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib61.5.5.1" class="ltx_text" style="font-size:90%;">Yousefpour </span><span id="bib.bib61.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib61.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib61.9.1" class="ltx_text" style="font-size:90%;">
Ashkan Yousefpour, Shen Guo, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.10.1" class="ltx_text" style="font-size:90%;">Green federated learning, 2023.
</span>
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib62.5.5.1" class="ltx_text" style="font-size:90%;">Yu </span><span id="bib.bib62.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib62.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib62.9.1" class="ltx_text" style="font-size:90%;">
Sixing Yu, J.Â Pablo MuÃ±oz, and Ali Jannesari.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.10.1" class="ltx_text" style="font-size:90%;">Federated foundation models: Privacy-preserving and collaborative learning for large models, 2023.
</span>
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib63.5.5.1" class="ltx_text" style="font-size:90%;">Zaken </span><span id="bib.bib63.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib63.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib63.9.1" class="ltx_text" style="font-size:90%;">
EladÂ Ben Zaken, Shauli Ravfogel, and Yoav Goldberg.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.10.1" class="ltx_text" style="font-size:90%;">Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models, 2021.
</span>
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib64.5.5.1" class="ltx_text" style="font-size:90%;">Zhang </span><span id="bib.bib64.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib64.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib64.9.1" class="ltx_text" style="font-size:90%;">
Chen Zhang, YuÂ Xie, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.10.1" class="ltx_text" style="font-size:90%;">A survey on federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Knowledge-Based Systems</span><span id="bib.bib64.12.2" class="ltx_text" style="font-size:90%;">, 216, 2021.
</span>
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib65.5.5.1" class="ltx_text" style="font-size:90%;">Zhang </span><span id="bib.bib65.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib65.7.7.3" class="ltx_text" style="font-size:90%;"> [2023a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib65.9.1" class="ltx_text" style="font-size:90%;">
Jianyi Zhang, Saeed Vahidian, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.10.1" class="ltx_text" style="font-size:90%;">Towards building the federated gpt: Federated instruction tuning, 2023.
</span>
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib66.5.5.1" class="ltx_text" style="font-size:90%;">Zhang </span><span id="bib.bib66.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib66.7.7.3" class="ltx_text" style="font-size:90%;"> [2023b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib66.9.1" class="ltx_text" style="font-size:90%;">
Zhuo Zhang, Yuanhang Yang, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.10.1" class="ltx_text" style="font-size:90%;">FedPETuning: When federated learning meets the parameter-efficient tuning methods of pre-trained language models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib66.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Findings of the Association for Computational Linguistics: ACL 2023</span><span id="bib.bib66.13.3" class="ltx_text" style="font-size:90%;">. ACL, 2023.
</span>
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib67.5.5.1" class="ltx_text" style="font-size:90%;">Zhao </span><span id="bib.bib67.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib67.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib67.9.1" class="ltx_text" style="font-size:90%;">
Haodong Zhao, Wei Du, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib67.10.1" class="ltx_text" style="font-size:90%;">Fedprompt: Communication-efficient and privacy preserving prompt tuning in federated learning, 2022.
</span>
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib68.5.5.1" class="ltx_text" style="font-size:90%;">Zheng </span><span id="bib.bib68.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib68.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib68.9.1" class="ltx_text" style="font-size:90%;">
Rui Zheng, Shihan Dou, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib68.10.1" class="ltx_text" style="font-size:90%;">Secrets of rlhf in large language models part i: Ppo, 2023.
</span>
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib69.5.5.1" class="ltx_text" style="font-size:90%;">Zhou </span><span id="bib.bib69.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib69.7.7.3" class="ltx_text" style="font-size:90%;"> [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib69.9.1" class="ltx_text" style="font-size:90%;">
Yiren Zhou, Seyed Moosavi-Dezfooli, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib69.10.1" class="ltx_text" style="font-size:90%;">Adaptive quantization for deep neural network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib69.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the AAAI Conference on Artificial Intelligence</span><span id="bib.bib69.12.2" class="ltx_text" style="font-size:90%;">, 32(1), 2018.
</span>
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib70.4.4.1" class="ltx_text" style="font-size:90%;">Zhu and Gupta [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib70.6.1" class="ltx_text" style="font-size:90%;">
Michael Zhu and Suyog Gupta.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib70.7.1" class="ltx_text" style="font-size:90%;">To prune, or not to prune: exploring the efficacy of pruning for model compression, 2017.
</span>
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib71.5.5.1" class="ltx_text" style="font-size:90%;">Zhu </span><span id="bib.bib71.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib71.7.7.3" class="ltx_text" style="font-size:90%;"> [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib71.9.1" class="ltx_text" style="font-size:90%;">
Maohua Zhu, Tao Zhang, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib71.10.1" class="ltx_text" style="font-size:90%;">Sparse tensor core: Algorithm and hardware co-design for vector-wise sparse neural networks on modern gpus.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib71.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib71.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture</span><span id="bib.bib71.13.3" class="ltx_text" style="font-size:90%;">, MICRO â€™52. ACM, 2019.
</span>
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib72.5.5.1" class="ltx_text" style="font-size:90%;">Zhuang </span><span id="bib.bib72.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib72.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib72.9.1" class="ltx_text" style="font-size:90%;">
Weiming Zhuang, Chen Chen, and Lingjuan Lyu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib72.10.1" class="ltx_text" style="font-size:90%;">When foundation model meets federated learning: Motivations, challenges, and future directions, 2023.
</span>
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib73.5.5.1" class="ltx_text" style="font-size:90%;">Ziller </span><span id="bib.bib73.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib73.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib73.9.1" class="ltx_text" style="font-size:90%;">
Alexander Ziller, Andrew Trask, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib73.10.1" class="ltx_text ltx_font_italic" style="font-size:90%;">PySyft: A Library for Easy Federated Learning</span><span id="bib.bib73.11.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib73.12.1" class="ltx_text" style="font-size:90%;">Springer International Publishing, 2021.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2401.04471" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2401.04472" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2401.04472">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2401.04472" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2401.04473" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 10:21:12 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
