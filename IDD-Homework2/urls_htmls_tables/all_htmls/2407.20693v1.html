<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2407.20693] Boosting Audio Visual Question Answering via Key Semantic-Aware Cues</title><meta property="og:description" content="The Audio Visual Question Answering (AVQA) task aims to answer questions related to various visual objects, sounds, and their interactions in videos.
Such naturally multimodal videos contain rich and complex dynamic au…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Boosting Audio Visual Question Answering via Key Semantic-Aware Cues">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Boosting Audio Visual Question Answering via Key Semantic-Aware Cues">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2407.20693">

<!--Generated on Mon Aug  5 18:04:33 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Multi-modal scene understanding,  Audio visual question answering">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Boosting Audio Visual Question Answering via Key Semantic-Aware Cues</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Guangyao Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">GSAI, Renmin University of China</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">Beijing</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_country">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:guangyaoli@ruc.edu.cn">guangyaoli@ruc.edu.cn</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Henghui Du
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">GSAI, Renmin University of China</span><span id="id5.2.id2" class="ltx_text ltx_affiliation_city">Beijing</span><span id="id6.3.id3" class="ltx_text ltx_affiliation_country">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:cserdu@ruc.edu.cn">cserdu@ruc.edu.cn</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Di Hu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_affiliation_institution">GSAI, Renmin University of China</span><span id="id8.2.id2" class="ltx_text ltx_affiliation_city">Beijing</span><span id="id9.3.id3" class="ltx_text ltx_affiliation_country">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:dihu@ruc.edu.cn">dihu@ruc.edu.cn</a>
</span></span></span>
</div>
<div class="ltx_dates">(2024)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id10.id1" class="ltx_p">The Audio Visual Question Answering (AVQA) task aims to answer questions related to various visual objects, sounds, and their interactions in videos.
Such naturally multimodal videos contain rich and complex dynamic audio-visual components, with only a portion of them closely related to the given questions.
Hence, effectively perceiving audio-visual cues relevant to the given questions is crucial for correctly answering them.
In this paper, we propose a <span id="id10.id1.1" class="ltx_text ltx_font_bold">T</span>emporal-<span id="id10.id1.2" class="ltx_text ltx_font_bold">S</span>patial <span id="id10.id1.3" class="ltx_text ltx_font_bold">P</span>erception <span id="id10.id1.4" class="ltx_text ltx_font_bold">M</span>odel (<span id="id10.id1.5" class="ltx_text ltx_font_bold">TSPM</span>), which aims to empower the model to perceive key visual and auditory cues related to the questions.
Specifically, considering the challenge of aligning non-declarative questions and visual representations into the same semantic space using visual-language pretrained models, we construct declarative sentence prompts derived from the question template, to assist the <span id="id10.id1.6" class="ltx_text ltx_font_italic">temporal perception module</span> in better identifying critical segments relevant to the questions.
Subsequently, a <span id="id10.id1.7" class="ltx_text ltx_font_italic">spatial perception module</span> is designed to merge visual tokens from selected segments to highlight key latent targets, followed by cross-modal interaction with audio to perceive potential sound-aware areas.
Finally, the significant temporal-spatial cues from these modules are integrated to answer the question.
Extensive experiments on multiple AVQA benchmarks demonstrate that our framework excels not only in understanding audio-visual scenes but also in answering complex questions effectively.
Code is available at <a target="_blank" href="https://github.com/GeWu-Lab/TSPM" title="" class="ltx_ref ltx_href">https://github.com/GeWu-Lab/TSPM</a>.
<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup>

<span id="S0.I1" class="ltx_itemize">
<span id="S0.I1.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S0.I1.i1.p1" class="ltx_para">
<span id="S0.I1.i1.p1.1" class="ltx_p">Di Hu is the corresponding author.</span>
</span></span>
</span>
</span></span></span></p>
</div>
<div class="ltx_keywords">Multi-modal scene understanding, Audio visual question answering
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>Proceedings of the 32nd ACM International Conference on Multimedia; October 28-November 1, 2024; Melbourne, VIC, Australia</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_booktitle"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>Proceedings of the 32nd ACM International Conference on Multimedia (MM ’24), October 28-November 1, 2024, Melbourne, VIC, Australia</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/3664647.3680803</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_isbn"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>979-8-4007-0686-8/24/10</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Scene understanding</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<figure id="S1.F1" class="ltx_figure"><img src="/html/2407.20693/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="219" height="228" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>
Identifying key temporal segments and spatial sound-aware areas is critical for fine-grained audio-visual scene understanding through human-like cognitive processes.
For instance, in a scenario of violin and flute ensemble, regarding a given complex question:
<span id="S1.F1.4.1" class="ltx_text ltx_font_bold">a)</span> directly utilizing the question makes it difficult to effectively select key temporal segments;
<span id="S1.F1.5.2" class="ltx_text ltx_font_bold">b)</span> the lack of spatial supervision signals leads to challenges in capturing audio-visual association;
<span id="S1.F1.6.3" class="ltx_text ltx_font_bold">c)</span> our method, employing constructed declarative prompts, can accurately locate critical temporal segments and spatial cues.
</figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Audio and visual cues abundantly contribute to conveying information in our daily lives, and both modalities jointly improve our ability in scene perception and understanding <cite class="ltx_cite ltx_citemacro_citep">(Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2022</a>)</cite>.
For instance, imagining that we are driving along a winding mountain road, honking the horn ahead of time is often safer than relying solely on observing the road ahead with our eyes.
In recent years, we have seen significant progress in sound source localization <cite class="ltx_cite ltx_citemacro_citep">(Senocak et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2018</a>; Hu et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>, <a href="#bib.bib13" title="" class="ltx_ref">2022</a>)</cite> and separation <cite class="ltx_cite ltx_citemacro_citep">(Gan et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>; Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2022b</a>)</cite>, event localization <cite class="ltx_cite ltx_citemacro_citep">(Tian et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2018</a>; Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2023</a>)</cite>, video parsing <cite class="ltx_cite ltx_citemacro_citep">(Tian et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2020</a>; Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2024</a>)</cite>,
segmentation <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib43" title="" class="ltx_ref">2022a</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2024b</a>)</cite>,
question answering <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2022</a>; Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2022</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2024</a>)</cite>, <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">etc</span>., towards audio-visual scene understanding.
Particularly, the Audio-Visual Question Answering (AVQA) task, involving the fine-grained spatio-temporal perception and reasoning of complex audio-visual scenes, has emerged as valuable and challenging focus of research interest.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To solve the above AVQA task, Li <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">et al</span>. <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite> build a large-scale MUSIC-AVQA dataset as a strong benchmark and propose a spatiotemporal grounding model to achieve scene understanding and reasoning over audio and visual modalities.
Yun <span id="S1.p2.1.2" class="ltx_text ltx_font_italic">et al</span>. <cite class="ltx_cite ltx_citemacro_citep">(Yun et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2021</a>)</cite> and Yang <span id="S1.p2.1.3" class="ltx_text ltx_font_italic">et al</span>. <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite> also introduce the Pano-AVQA and AVQA dataset to explore the panoramic and real-life scene, respectively.
Recently, LAVISH <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2023</a>)</cite> introduced a novel parameter-efficient framework for encoding audio-visual scenes using off-the-shelf pre-trained vision transformers, achieving notable progress.
Moreover, researchers <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2023b</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite> have considered the significance of the given question, attempting to achieve precise perception of relevant temporal segments and spatial sound sources using the question as a guiding factor, leading to promising results.
Clearly, these endeavors have markedly propelled the progress of research in audio-visual question answering.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Despite the significant progress made in AVQA, there are still several challenges that need to be addressed.
<span id="S1.p3.1.1" class="ltx_text ltx_font_bold">For temporal perception</span>,
this task involves understanding long audio-visual videos, which suffer from heavy information redundancy. Existing works <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2022</a>; Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2023</a>; Nadeem et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2023</a>)</cite> typically employ a uniform sampling strategy to reduce redundancy and computational costs, but may lead to the loss of crucial information.
Others <cite class="ltx_cite ltx_citemacro_citep">(Jiang and Yin, <a href="#bib.bib16" title="" class="ltx_ref">2023</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2023b</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite> attempt to use the CLIP pre-trained model as a feature extractor by measuring the similarity between given questions and video frames to select temporally relevant segments. However, the given question’s expression format is not declarative, inconsistent with the textual format used in the CLIP model, making it difficult to effectively align with the semantic content of video frames, and thus challenging the search for temporally relevant segments related to the input question.
<span id="S1.p3.1.2" class="ltx_text ltx_font_bold">Regarding spatial perception</span>,
the lack of supervised information for spatial visual objects and sound makes it challenging for models to associate visual targets with sounds in the video, thereby making it difficult to identify potential sound-aware areas.
While existing pre-trained object detection models used in visual question answering tasks can excel in key object localization, the absence of certain specific categories (<span id="S1.p3.1.3" class="ltx_text ltx_font_italic">eg</span>., suona, guzheng, <span id="S1.p3.1.4" class="ltx_text ltx_font_italic">etc</span>.) in the AVQA-related datasets, adding difficulty to locate relevant areas.
Some explorations <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite> have employed ViT to convert video frames into token sequences, utilizing semantic similarity calculations between questions and tokens to perceive the most relevant tokens as key targets. Nevertheless, the absence of objects’ semantics in visual tokens makes establishing an effective correlation with questions challenging, thus rendering accurate localization difficult.
This imprecise spatial perception makes it difficult to establish effective associations with sounds in the video, thereby complicating the localization of potential sound-aware areas.
Hence, as shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, it is crucial to enable machines to perceive complex audio-visual scenes in a manner akin to human cognition and accurately infer answers to questions.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To address these challenges, we propose an effective Temporal-Spatial Perception Model (TSPM) for perceiving crucial visual and auditory cues related to the questions in complex audio-visual scenes.
<span id="S1.p4.1.1" class="ltx_text ltx_font_bold">Firstly</span>, the content related to the question is usually scattered in partial segments of the video instead of the whole sequence. Hence, we design a Text Prompt Constructor (TPC), which constructs a declarative sentence text prompt derived from the question template, effectively aligning it with the semantic content of the visual frames. Following this, we introduce a Temporal Perception Module (TPM) that utilizes cross-modal attention mechanisms to identify the key temporal segments relevant to the given question.
<span id="S1.p4.1.2" class="ltx_text ltx_font_bold">Secondly</span>, identifying key visual areas and their corresponding sound source positions within critical segments, can help to learn audio-visual associations in complex scenarios.
To achieve this, the Spatial Perception Module (SPM) is designed to merge visual tokens on selected temporal segments to multiple joint tokens, thus preserving the semantic information of potential targets. Then, these joint tokens interact cross-modal interaction with audio to perceive potential sound-aware areas.
<span id="S1.p4.1.3" class="ltx_text ltx_font_bold">Finally</span>, the above critical temporal segments and sound-aware regions’ features are fused to obtain a joint representation for question answering.
Extensive experiments on multiple benchmarks demonstrate that our proposed approach achieves precise temporal-spatial perception, highlighting its immense potential in tackling audio visual question-answering tasks.
Our contributions can be summarized as follows:</p>
</div>
<div id="S1.p5" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">The temporal perception module designed in TSPM transforms questions into declarative prompts using a constructed declarative sentence generator, facilitating better alignment with the semantics of visual frames and effectively identifying key temporal segments relevant to the given question.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">The spatial perception module introduced in TSPM merges visual tokens on selected temporal segments to preserve key potential targets, then engages in cross-modal interaction with audio, effectively perceiving potential sound-aware areas.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Extensive experiments on multiple benchmarks demonstrate that the proposed TSPM achieves precise spatiotemporal perception, showcasing its significant potential in addressing audio visual question answering task.</p>
</div>
</li>
</ul>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2407.20693/assets/x2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="454" height="211" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>
Our proposed Temporal-Spatio Perception Model (TSPM) framework.
Firstly, the video is divided into <math id="S1.F2.3.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S1.F2.3.m1.1b"><mi id="S1.F2.3.m1.1.1" xref="S1.F2.3.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S1.F2.3.m1.1c"><ci id="S1.F2.3.m1.1.1.cmml" xref="S1.F2.3.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.3.m1.1d">T</annotation></semantics></math> segments, and we use a pre-trained model to extract audio, visual, and question features.
Then, a temporal perception module incorporating a constructed prompt aiming to effectively capture <math id="S1.F2.4.m2.1" class="ltx_Math" alttext="Top_{k}" display="inline"><semantics id="S1.F2.4.m2.1b"><mrow id="S1.F2.4.m2.1.1" xref="S1.F2.4.m2.1.1.cmml"><mi id="S1.F2.4.m2.1.1.2" xref="S1.F2.4.m2.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S1.F2.4.m2.1.1.1" xref="S1.F2.4.m2.1.1.1.cmml">​</mo><mi id="S1.F2.4.m2.1.1.3" xref="S1.F2.4.m2.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S1.F2.4.m2.1.1.1b" xref="S1.F2.4.m2.1.1.1.cmml">​</mo><msub id="S1.F2.4.m2.1.1.4" xref="S1.F2.4.m2.1.1.4.cmml"><mi id="S1.F2.4.m2.1.1.4.2" xref="S1.F2.4.m2.1.1.4.2.cmml">p</mi><mi id="S1.F2.4.m2.1.1.4.3" xref="S1.F2.4.m2.1.1.4.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S1.F2.4.m2.1c"><apply id="S1.F2.4.m2.1.1.cmml" xref="S1.F2.4.m2.1.1"><times id="S1.F2.4.m2.1.1.1.cmml" xref="S1.F2.4.m2.1.1.1"></times><ci id="S1.F2.4.m2.1.1.2.cmml" xref="S1.F2.4.m2.1.1.2">𝑇</ci><ci id="S1.F2.4.m2.1.1.3.cmml" xref="S1.F2.4.m2.1.1.3">𝑜</ci><apply id="S1.F2.4.m2.1.1.4.cmml" xref="S1.F2.4.m2.1.1.4"><csymbol cd="ambiguous" id="S1.F2.4.m2.1.1.4.1.cmml" xref="S1.F2.4.m2.1.1.4">subscript</csymbol><ci id="S1.F2.4.m2.1.1.4.2.cmml" xref="S1.F2.4.m2.1.1.4.2">𝑝</ci><ci id="S1.F2.4.m2.1.1.4.3.cmml" xref="S1.F2.4.m2.1.1.4.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.4.m2.1d">Top_{k}</annotation></semantics></math> key relevant temporal segments.
Subsequently, the spatial perception module is designed to enhance spatial awareness through the interaction of audio-visual tokens.
</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related works</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Audio Visual Scene Understanding</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Inspired by the multisensory perception of humans, the community has paid more and more attention to audio-visual scene understanding in recent years <cite class="ltx_cite ltx_citemacro_citep">(Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2022</a>)</cite>.
Compared to other modalities, visual and auditory modalities possess unique characteristics such as cognitive foundation, semantic consistency, spatial consistency, temporal consistency, and rich support from real-world data.
It includes various interesting tasks such as sound source localization <cite class="ltx_cite ltx_citemacro_citep">(Senocak et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2018</a>; Hu et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>, <a href="#bib.bib13" title="" class="ltx_ref">2022</a>)</cite>, action recognition <cite class="ltx_cite ltx_citemacro_citep">(Gao et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite>, event localization <cite class="ltx_cite ltx_citemacro_citep">(Tian et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2018</a>; Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2023</a>)</cite>, video parsing <cite class="ltx_cite ltx_citemacro_citep">(Tian et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2020</a>; Hou et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2023</a>; Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2024</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2024</a>)</cite>,
segmentation <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib43" title="" class="ltx_ref">2022a</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2023b</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2024a</a>)</cite>,
<span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_italic">etc</span>.
These studies integrate rich audiovisual information within multimodal scenes to overcome limitations in perception inherent to single modalities, thereby utilizing both auditory and visual modalities to explore finer-grained scene comprehension.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Apart from the above methods that facilitate scene understanding by excavating and analyzing different modalities, a unified multimodal model should also be able to reason their spatiotemporal correlation.
Therefore, we focus on the audio-visual question answering task <cite class="ltx_cite ltx_citemacro_citep">(Yun et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2021</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2022</a>; Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2022</a>; Duan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2023</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2024</a>)</cite> and explore spatiotemporal perception and reasoning in the audio-visual context.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Audio Visual Question Answering</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Audio-visual question answering, which exploits the natural multimodal medium of video, is attracting increasing attention from researchers <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2023</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2023a</a>)</cite>. It requires a comprehensive understanding and integration of diverse modalities,
leading to precise responses to distinct questions. To explore the above AVQA task, Yun <em id="S2.SS2.p1.1.1" class="ltx_emph ltx_font_italic">et al</em>. <cite class="ltx_cite ltx_citemacro_citep">(Yun et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2021</a>)</cite> proposed the Pano-AVQA, which includes 360-degree videos and their corresponding question-answer pairs, aimed at exploring understanding of panoramic scenes. Li <em id="S2.SS2.p1.1.2" class="ltx_emph ltx_font_italic">et al</em>. <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite> presented that the MUSIC-AVQA has become a strong benchmark for promoting spatiotemporal reasoning research in dynamic and long-term audio-visual scenes. Considering that real-life scenarios contain a greater variety of audio-visual daily activities, AVQA benchmark is proposed in  <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite>, which further expands the audio visual scene coverage of AVQA task.
Recently, LAVISH <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2023</a>)</cite> has dedicated to exploring improvements in audio-visual association and enhancing training efficiency, resulting in satisfactory outcomes.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Above research extract audio and visual features globally, without considering the importance of local feature representation.
Chen <span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_italic">et al</span>. <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2023b</a>)</cite> consider the importance of the given question, which guides the feature extraction of both audio and visual signals. And then the PSTP-Net <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite> is proposed to explore critical temporal segments and sound-aware regions among the complex audiovisual scenarios progressively.
However, aligning questions with video semantics is challenging due to its non-declarative nature, making it hard to identify key relevant segments. Our work
focuses on empowering
the model to gradually perceive essential visual and auditory cues for audio-visual scene understanding.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Method</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">To solve the AVQA challenges, we propose an effective <span id="S3.p1.1.1" class="ltx_text ltx_font_bold">T</span>emporal-<span id="S3.p1.1.2" class="ltx_text ltx_font_bold">S</span>patial <span id="S3.p1.1.3" class="ltx_text ltx_font_bold">P</span>erception <span id="S3.p1.1.4" class="ltx_text ltx_font_bold">M</span>odel (<span id="S3.p1.1.5" class="ltx_text ltx_font_bold">TSPM</span>) to achieve fine-grained audio-visual scene understanding, thus answering questions accurately. An overview of the proposed framework is illustrated in Fig. <a href="#S1.F2" title="Figure 2 ‣ 1. Introduction ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Input Representation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.8" class="ltx_p">Given an input audio-visual video sequence, we first divide it into <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">T</annotation></semantics></math> non-overlapping audio and visual segment pairs <math id="S3.SS1.p1.2.m2.2" class="ltx_Math" alttext="\{a_{t},v_{t}\}_{t=1}^{T}" display="inline"><semantics id="S3.SS1.p1.2.m2.2a"><msubsup id="S3.SS1.p1.2.m2.2.2" xref="S3.SS1.p1.2.m2.2.2.cmml"><mrow id="S3.SS1.p1.2.m2.2.2.2.2.2" xref="S3.SS1.p1.2.m2.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.p1.2.m2.2.2.2.2.2.3" xref="S3.SS1.p1.2.m2.2.2.2.2.3.cmml">{</mo><msub id="S3.SS1.p1.2.m2.1.1.1.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.1.1.1.1.2" xref="S3.SS1.p1.2.m2.1.1.1.1.1.1.2.cmml">a</mi><mi id="S3.SS1.p1.2.m2.1.1.1.1.1.1.3" xref="S3.SS1.p1.2.m2.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.SS1.p1.2.m2.2.2.2.2.2.4" xref="S3.SS1.p1.2.m2.2.2.2.2.3.cmml">,</mo><msub id="S3.SS1.p1.2.m2.2.2.2.2.2.2" xref="S3.SS1.p1.2.m2.2.2.2.2.2.2.cmml"><mi id="S3.SS1.p1.2.m2.2.2.2.2.2.2.2" xref="S3.SS1.p1.2.m2.2.2.2.2.2.2.2.cmml">v</mi><mi id="S3.SS1.p1.2.m2.2.2.2.2.2.2.3" xref="S3.SS1.p1.2.m2.2.2.2.2.2.2.3.cmml">t</mi></msub><mo stretchy="false" id="S3.SS1.p1.2.m2.2.2.2.2.2.5" xref="S3.SS1.p1.2.m2.2.2.2.2.3.cmml">}</mo></mrow><mrow id="S3.SS1.p1.2.m2.2.2.2.4" xref="S3.SS1.p1.2.m2.2.2.2.4.cmml"><mi id="S3.SS1.p1.2.m2.2.2.2.4.2" xref="S3.SS1.p1.2.m2.2.2.2.4.2.cmml">t</mi><mo id="S3.SS1.p1.2.m2.2.2.2.4.1" xref="S3.SS1.p1.2.m2.2.2.2.4.1.cmml">=</mo><mn id="S3.SS1.p1.2.m2.2.2.2.4.3" xref="S3.SS1.p1.2.m2.2.2.2.4.3.cmml">1</mn></mrow><mi id="S3.SS1.p1.2.m2.2.2.4" xref="S3.SS1.p1.2.m2.2.2.4.cmml">T</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.2b"><apply id="S3.SS1.p1.2.m2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.2.2.3.cmml" xref="S3.SS1.p1.2.m2.2.2">superscript</csymbol><apply id="S3.SS1.p1.2.m2.2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.2.2.2.3.cmml" xref="S3.SS1.p1.2.m2.2.2">subscript</csymbol><set id="S3.SS1.p1.2.m2.2.2.2.2.3.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2"><apply id="S3.SS1.p1.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1.1.2">𝑎</ci><ci id="S3.SS1.p1.2.m2.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S3.SS1.p1.2.m2.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.2.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.2.m2.2.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2.2.2">𝑣</ci><ci id="S3.SS1.p1.2.m2.2.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2.2.3">𝑡</ci></apply></set><apply id="S3.SS1.p1.2.m2.2.2.2.4.cmml" xref="S3.SS1.p1.2.m2.2.2.2.4"><eq id="S3.SS1.p1.2.m2.2.2.2.4.1.cmml" xref="S3.SS1.p1.2.m2.2.2.2.4.1"></eq><ci id="S3.SS1.p1.2.m2.2.2.2.4.2.cmml" xref="S3.SS1.p1.2.m2.2.2.2.4.2">𝑡</ci><cn type="integer" id="S3.SS1.p1.2.m2.2.2.2.4.3.cmml" xref="S3.SS1.p1.2.m2.2.2.2.4.3">1</cn></apply></apply><ci id="S3.SS1.p1.2.m2.2.2.4.cmml" xref="S3.SS1.p1.2.m2.2.2.4">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.2c">\{a_{t},v_{t}\}_{t=1}^{T}</annotation></semantics></math>, where each segment is <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="1s" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mrow id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mn id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p1.3.m3.1.1.1" xref="S3.SS1.p1.3.m3.1.1.1.cmml">​</mo><mi id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><times id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1"></times><cn type="integer" id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">1</cn><ci id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">1s</annotation></semantics></math> long.
Subsequently, we partition each visual frame into <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">M</annotation></semantics></math> patches and append a special <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="\mathtt{[CLS]}" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mrow id="S3.SS1.p1.5.m5.1.2.2" xref="S3.SS1.p1.5.m5.1.2.1.cmml"><mo stretchy="false" id="S3.SS1.p1.5.m5.1.2.2.1" xref="S3.SS1.p1.5.m5.1.2.1.1.cmml">[</mo><mi id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">𝙲𝙻𝚂</mi><mo stretchy="false" id="S3.SS1.p1.5.m5.1.2.2.2" xref="S3.SS1.p1.5.m5.1.2.1.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.2.1.cmml" xref="S3.SS1.p1.5.m5.1.2.2"><csymbol cd="latexml" id="S3.SS1.p1.5.m5.1.2.1.1.cmml" xref="S3.SS1.p1.5.m5.1.2.2.1">delimited-[]</csymbol><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">𝙲𝙻𝚂</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">\mathtt{[CLS]}</annotation></semantics></math> token to the beginning of the first patch.
The question sentence <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><mi id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">Q</annotation></semantics></math> is tokenized into <math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><mi id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">N</annotation></semantics></math> individual words <math id="S3.SS1.p1.8.m8.1" class="ltx_Math" alttext="\{q_{n}\}_{n=1}^{N}" display="inline"><semantics id="S3.SS1.p1.8.m8.1a"><msubsup id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml"><mrow id="S3.SS1.p1.8.m8.1.1.1.1.1" xref="S3.SS1.p1.8.m8.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p1.8.m8.1.1.1.1.1.2" xref="S3.SS1.p1.8.m8.1.1.1.1.2.cmml">{</mo><msub id="S3.SS1.p1.8.m8.1.1.1.1.1.1" xref="S3.SS1.p1.8.m8.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.8.m8.1.1.1.1.1.1.2" xref="S3.SS1.p1.8.m8.1.1.1.1.1.1.2.cmml">q</mi><mi id="S3.SS1.p1.8.m8.1.1.1.1.1.1.3" xref="S3.SS1.p1.8.m8.1.1.1.1.1.1.3.cmml">n</mi></msub><mo stretchy="false" id="S3.SS1.p1.8.m8.1.1.1.1.1.3" xref="S3.SS1.p1.8.m8.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS1.p1.8.m8.1.1.1.3" xref="S3.SS1.p1.8.m8.1.1.1.3.cmml"><mi id="S3.SS1.p1.8.m8.1.1.1.3.2" xref="S3.SS1.p1.8.m8.1.1.1.3.2.cmml">n</mi><mo id="S3.SS1.p1.8.m8.1.1.1.3.1" xref="S3.SS1.p1.8.m8.1.1.1.3.1.cmml">=</mo><mn id="S3.SS1.p1.8.m8.1.1.1.3.3" xref="S3.SS1.p1.8.m8.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.SS1.p1.8.m8.1.1.3" xref="S3.SS1.p1.8.m8.1.1.3.cmml">N</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><apply id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.1.2.cmml" xref="S3.SS1.p1.8.m8.1.1">superscript</csymbol><apply id="S3.SS1.p1.8.m8.1.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.1.1.2.cmml" xref="S3.SS1.p1.8.m8.1.1">subscript</csymbol><set id="S3.SS1.p1.8.m8.1.1.1.1.2.cmml" xref="S3.SS1.p1.8.m8.1.1.1.1.1"><apply id="S3.SS1.p1.8.m8.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.8.m8.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.8.m8.1.1.1.1.1.1.2">𝑞</ci><ci id="S3.SS1.p1.8.m8.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.8.m8.1.1.1.1.1.1.3">𝑛</ci></apply></set><apply id="S3.SS1.p1.8.m8.1.1.1.3.cmml" xref="S3.SS1.p1.8.m8.1.1.1.3"><eq id="S3.SS1.p1.8.m8.1.1.1.3.1.cmml" xref="S3.SS1.p1.8.m8.1.1.1.3.1"></eq><ci id="S3.SS1.p1.8.m8.1.1.1.3.2.cmml" xref="S3.SS1.p1.8.m8.1.1.1.3.2">𝑛</ci><cn type="integer" id="S3.SS1.p1.8.m8.1.1.1.3.3.cmml" xref="S3.SS1.p1.8.m8.1.1.1.3.3">1</cn></apply></apply><ci id="S3.SS1.p1.8.m8.1.1.3.cmml" xref="S3.SS1.p1.8.m8.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">\{q_{n}\}_{n=1}^{N}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.4" class="ltx_p"><span id="S3.SS1.p2.4.1" class="ltx_text ltx_font_bold">Audio Representation</span>.
For each audio segment <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="a_{t}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">a</mi><mi id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">𝑎</ci><ci id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">a_{t}</annotation></semantics></math>, we use the pre-trained VGGish <cite class="ltx_cite ltx_citemacro_citep">(Gemmeke et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2017</a>)</cite> model to extract the audio feature as <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="f_{a}^{t}\in\mathbb{R}^{D}" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mrow id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><msubsup id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2.2.2" xref="S3.SS1.p2.2.m2.1.1.2.2.2.cmml">f</mi><mi id="S3.SS1.p2.2.m2.1.1.2.2.3" xref="S3.SS1.p2.2.m2.1.1.2.2.3.cmml">a</mi><mi id="S3.SS1.p2.2.m2.1.1.2.3" xref="S3.SS1.p2.2.m2.1.1.2.3.cmml">t</mi></msubsup><mo id="S3.SS1.p2.2.m2.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.cmml">∈</mo><msup id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml"><mi id="S3.SS1.p2.2.m2.1.1.3.2" xref="S3.SS1.p2.2.m2.1.1.3.2.cmml">ℝ</mi><mi id="S3.SS1.p2.2.m2.1.1.3.3" xref="S3.SS1.p2.2.m2.1.1.3.3.cmml">D</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><in id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1"></in><apply id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.2.1.cmml" xref="S3.SS1.p2.2.m2.1.1.2">superscript</csymbol><apply id="S3.SS1.p2.2.m2.1.1.2.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.2.2.1.cmml" xref="S3.SS1.p2.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.2.2.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2.2.2">𝑓</ci><ci id="S3.SS1.p2.2.m2.1.1.2.2.3.cmml" xref="S3.SS1.p2.2.m2.1.1.2.2.3">𝑎</ci></apply><ci id="S3.SS1.p2.2.m2.1.1.2.3.cmml" xref="S3.SS1.p2.2.m2.1.1.2.3">𝑡</ci></apply><apply id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.3.1.cmml" xref="S3.SS1.p2.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.3.2.cmml" xref="S3.SS1.p2.2.m2.1.1.3.2">ℝ</ci><ci id="S3.SS1.p2.2.m2.1.1.3.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">f_{a}^{t}\in\mathbb{R}^{D}</annotation></semantics></math>, where <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">D</annotation></semantics></math> is the feature dimension. The pretrained VGGish model is a VGG-like 2-D CNN network that trained on the large-scale AudioSet <cite class="ltx_cite ltx_citemacro_citep">(Gemmeke et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2017</a>)</cite> dataset, employing over transformed audio spectrograms.
Then the features at the audio spectrogram second-level can be interpreted as <math id="S3.SS1.p2.4.m4.4" class="ltx_Math" alttext="F_{a}=\{f_{a}^{1},f_{a}^{2},...,f_{a}^{T}\}" display="inline"><semantics id="S3.SS1.p2.4.m4.4a"><mrow id="S3.SS1.p2.4.m4.4.4" xref="S3.SS1.p2.4.m4.4.4.cmml"><msub id="S3.SS1.p2.4.m4.4.4.5" xref="S3.SS1.p2.4.m4.4.4.5.cmml"><mi id="S3.SS1.p2.4.m4.4.4.5.2" xref="S3.SS1.p2.4.m4.4.4.5.2.cmml">F</mi><mi id="S3.SS1.p2.4.m4.4.4.5.3" xref="S3.SS1.p2.4.m4.4.4.5.3.cmml">a</mi></msub><mo id="S3.SS1.p2.4.m4.4.4.4" xref="S3.SS1.p2.4.m4.4.4.4.cmml">=</mo><mrow id="S3.SS1.p2.4.m4.4.4.3.3" xref="S3.SS1.p2.4.m4.4.4.3.4.cmml"><mo stretchy="false" id="S3.SS1.p2.4.m4.4.4.3.3.4" xref="S3.SS1.p2.4.m4.4.4.3.4.cmml">{</mo><msubsup id="S3.SS1.p2.4.m4.2.2.1.1.1" xref="S3.SS1.p2.4.m4.2.2.1.1.1.cmml"><mi id="S3.SS1.p2.4.m4.2.2.1.1.1.2.2" xref="S3.SS1.p2.4.m4.2.2.1.1.1.2.2.cmml">f</mi><mi id="S3.SS1.p2.4.m4.2.2.1.1.1.2.3" xref="S3.SS1.p2.4.m4.2.2.1.1.1.2.3.cmml">a</mi><mn id="S3.SS1.p2.4.m4.2.2.1.1.1.3" xref="S3.SS1.p2.4.m4.2.2.1.1.1.3.cmml">1</mn></msubsup><mo id="S3.SS1.p2.4.m4.4.4.3.3.5" xref="S3.SS1.p2.4.m4.4.4.3.4.cmml">,</mo><msubsup id="S3.SS1.p2.4.m4.3.3.2.2.2" xref="S3.SS1.p2.4.m4.3.3.2.2.2.cmml"><mi id="S3.SS1.p2.4.m4.3.3.2.2.2.2.2" xref="S3.SS1.p2.4.m4.3.3.2.2.2.2.2.cmml">f</mi><mi id="S3.SS1.p2.4.m4.3.3.2.2.2.2.3" xref="S3.SS1.p2.4.m4.3.3.2.2.2.2.3.cmml">a</mi><mn id="S3.SS1.p2.4.m4.3.3.2.2.2.3" xref="S3.SS1.p2.4.m4.3.3.2.2.2.3.cmml">2</mn></msubsup><mo id="S3.SS1.p2.4.m4.4.4.3.3.6" xref="S3.SS1.p2.4.m4.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">…</mi><mo id="S3.SS1.p2.4.m4.4.4.3.3.7" xref="S3.SS1.p2.4.m4.4.4.3.4.cmml">,</mo><msubsup id="S3.SS1.p2.4.m4.4.4.3.3.3" xref="S3.SS1.p2.4.m4.4.4.3.3.3.cmml"><mi id="S3.SS1.p2.4.m4.4.4.3.3.3.2.2" xref="S3.SS1.p2.4.m4.4.4.3.3.3.2.2.cmml">f</mi><mi id="S3.SS1.p2.4.m4.4.4.3.3.3.2.3" xref="S3.SS1.p2.4.m4.4.4.3.3.3.2.3.cmml">a</mi><mi id="S3.SS1.p2.4.m4.4.4.3.3.3.3" xref="S3.SS1.p2.4.m4.4.4.3.3.3.3.cmml">T</mi></msubsup><mo stretchy="false" id="S3.SS1.p2.4.m4.4.4.3.3.8" xref="S3.SS1.p2.4.m4.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.4b"><apply id="S3.SS1.p2.4.m4.4.4.cmml" xref="S3.SS1.p2.4.m4.4.4"><eq id="S3.SS1.p2.4.m4.4.4.4.cmml" xref="S3.SS1.p2.4.m4.4.4.4"></eq><apply id="S3.SS1.p2.4.m4.4.4.5.cmml" xref="S3.SS1.p2.4.m4.4.4.5"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.4.4.5.1.cmml" xref="S3.SS1.p2.4.m4.4.4.5">subscript</csymbol><ci id="S3.SS1.p2.4.m4.4.4.5.2.cmml" xref="S3.SS1.p2.4.m4.4.4.5.2">𝐹</ci><ci id="S3.SS1.p2.4.m4.4.4.5.3.cmml" xref="S3.SS1.p2.4.m4.4.4.5.3">𝑎</ci></apply><set id="S3.SS1.p2.4.m4.4.4.3.4.cmml" xref="S3.SS1.p2.4.m4.4.4.3.3"><apply id="S3.SS1.p2.4.m4.2.2.1.1.1.cmml" xref="S3.SS1.p2.4.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.2.2.1.1.1.1.cmml" xref="S3.SS1.p2.4.m4.2.2.1.1.1">superscript</csymbol><apply id="S3.SS1.p2.4.m4.2.2.1.1.1.2.cmml" xref="S3.SS1.p2.4.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.2.2.1.1.1.2.1.cmml" xref="S3.SS1.p2.4.m4.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.4.m4.2.2.1.1.1.2.2.cmml" xref="S3.SS1.p2.4.m4.2.2.1.1.1.2.2">𝑓</ci><ci id="S3.SS1.p2.4.m4.2.2.1.1.1.2.3.cmml" xref="S3.SS1.p2.4.m4.2.2.1.1.1.2.3">𝑎</ci></apply><cn type="integer" id="S3.SS1.p2.4.m4.2.2.1.1.1.3.cmml" xref="S3.SS1.p2.4.m4.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS1.p2.4.m4.3.3.2.2.2.cmml" xref="S3.SS1.p2.4.m4.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.3.3.2.2.2.1.cmml" xref="S3.SS1.p2.4.m4.3.3.2.2.2">superscript</csymbol><apply id="S3.SS1.p2.4.m4.3.3.2.2.2.2.cmml" xref="S3.SS1.p2.4.m4.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.3.3.2.2.2.2.1.cmml" xref="S3.SS1.p2.4.m4.3.3.2.2.2">subscript</csymbol><ci id="S3.SS1.p2.4.m4.3.3.2.2.2.2.2.cmml" xref="S3.SS1.p2.4.m4.3.3.2.2.2.2.2">𝑓</ci><ci id="S3.SS1.p2.4.m4.3.3.2.2.2.2.3.cmml" xref="S3.SS1.p2.4.m4.3.3.2.2.2.2.3">𝑎</ci></apply><cn type="integer" id="S3.SS1.p2.4.m4.3.3.2.2.2.3.cmml" xref="S3.SS1.p2.4.m4.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">…</ci><apply id="S3.SS1.p2.4.m4.4.4.3.3.3.cmml" xref="S3.SS1.p2.4.m4.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.4.4.3.3.3.1.cmml" xref="S3.SS1.p2.4.m4.4.4.3.3.3">superscript</csymbol><apply id="S3.SS1.p2.4.m4.4.4.3.3.3.2.cmml" xref="S3.SS1.p2.4.m4.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.4.4.3.3.3.2.1.cmml" xref="S3.SS1.p2.4.m4.4.4.3.3.3">subscript</csymbol><ci id="S3.SS1.p2.4.m4.4.4.3.3.3.2.2.cmml" xref="S3.SS1.p2.4.m4.4.4.3.3.3.2.2">𝑓</ci><ci id="S3.SS1.p2.4.m4.4.4.3.3.3.2.3.cmml" xref="S3.SS1.p2.4.m4.4.4.3.3.3.2.3">𝑎</ci></apply><ci id="S3.SS1.p2.4.m4.4.4.3.3.3.3.cmml" xref="S3.SS1.p2.4.m4.4.4.3.3.3.3">𝑇</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.4c">F_{a}=\{f_{a}^{1},f_{a}^{2},...,f_{a}^{T}\}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.8" class="ltx_p"><span id="S3.SS1.p3.8.1" class="ltx_text ltx_font_bold">Visual Representation</span>.
A fixed number of frames are sampled from each visual segment <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="v_{t}" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><msub id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">v</mi><mi id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">𝑣</ci><ci id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">v_{t}</annotation></semantics></math>.
Then we apply pre-trained CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2021</a>)</cite>, with frozen parameters, extract both frame-level and token-level features as <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="f_{v}^{t}" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><msubsup id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2.2" xref="S3.SS1.p3.2.m2.1.1.2.2.cmml">f</mi><mi id="S3.SS1.p3.2.m2.1.1.2.3" xref="S3.SS1.p3.2.m2.1.1.2.3.cmml">v</mi><mi id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">superscript</csymbol><apply id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.2.1.cmml" xref="S3.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2.2">𝑓</ci><ci id="S3.SS1.p3.2.m2.1.1.2.3.cmml" xref="S3.SS1.p3.2.m2.1.1.2.3">𝑣</ci></apply><ci id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">f_{v}^{t}</annotation></semantics></math> and <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="f_{p}^{t}" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><msubsup id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><mi id="S3.SS1.p3.3.m3.1.1.2.2" xref="S3.SS1.p3.3.m3.1.1.2.2.cmml">f</mi><mi id="S3.SS1.p3.3.m3.1.1.2.3" xref="S3.SS1.p3.3.m3.1.1.2.3.cmml">p</mi><mi id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">superscript</csymbol><apply id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.2.1.cmml" xref="S3.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.2.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2.2">𝑓</ci><ci id="S3.SS1.p3.3.m3.1.1.2.3.cmml" xref="S3.SS1.p3.3.m3.1.1.2.3">𝑝</ci></apply><ci id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">f_{p}^{t}</annotation></semantics></math> on video frames, respectively, where <math id="S3.SS1.p3.4.m4.1" class="ltx_Math" alttext="f_{v}^{t}\in\mathbb{R}^{D}" display="inline"><semantics id="S3.SS1.p3.4.m4.1a"><mrow id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml"><msubsup id="S3.SS1.p3.4.m4.1.1.2" xref="S3.SS1.p3.4.m4.1.1.2.cmml"><mi id="S3.SS1.p3.4.m4.1.1.2.2.2" xref="S3.SS1.p3.4.m4.1.1.2.2.2.cmml">f</mi><mi id="S3.SS1.p3.4.m4.1.1.2.2.3" xref="S3.SS1.p3.4.m4.1.1.2.2.3.cmml">v</mi><mi id="S3.SS1.p3.4.m4.1.1.2.3" xref="S3.SS1.p3.4.m4.1.1.2.3.cmml">t</mi></msubsup><mo id="S3.SS1.p3.4.m4.1.1.1" xref="S3.SS1.p3.4.m4.1.1.1.cmml">∈</mo><msup id="S3.SS1.p3.4.m4.1.1.3" xref="S3.SS1.p3.4.m4.1.1.3.cmml"><mi id="S3.SS1.p3.4.m4.1.1.3.2" xref="S3.SS1.p3.4.m4.1.1.3.2.cmml">ℝ</mi><mi id="S3.SS1.p3.4.m4.1.1.3.3" xref="S3.SS1.p3.4.m4.1.1.3.3.cmml">D</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><apply id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1"><in id="S3.SS1.p3.4.m4.1.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1.1"></in><apply id="S3.SS1.p3.4.m4.1.1.2.cmml" xref="S3.SS1.p3.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.4.m4.1.1.2.1.cmml" xref="S3.SS1.p3.4.m4.1.1.2">superscript</csymbol><apply id="S3.SS1.p3.4.m4.1.1.2.2.cmml" xref="S3.SS1.p3.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.4.m4.1.1.2.2.1.cmml" xref="S3.SS1.p3.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS1.p3.4.m4.1.1.2.2.2.cmml" xref="S3.SS1.p3.4.m4.1.1.2.2.2">𝑓</ci><ci id="S3.SS1.p3.4.m4.1.1.2.2.3.cmml" xref="S3.SS1.p3.4.m4.1.1.2.2.3">𝑣</ci></apply><ci id="S3.SS1.p3.4.m4.1.1.2.3.cmml" xref="S3.SS1.p3.4.m4.1.1.2.3">𝑡</ci></apply><apply id="S3.SS1.p3.4.m4.1.1.3.cmml" xref="S3.SS1.p3.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p3.4.m4.1.1.3.1.cmml" xref="S3.SS1.p3.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS1.p3.4.m4.1.1.3.2.cmml" xref="S3.SS1.p3.4.m4.1.1.3.2">ℝ</ci><ci id="S3.SS1.p3.4.m4.1.1.3.3.cmml" xref="S3.SS1.p3.4.m4.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">f_{v}^{t}\in\mathbb{R}^{D}</annotation></semantics></math>, <math id="S3.SS1.p3.5.m5.1" class="ltx_Math" alttext="f_{p}^{t}\in\mathbb{R}^{M\times D}" display="inline"><semantics id="S3.SS1.p3.5.m5.1a"><mrow id="S3.SS1.p3.5.m5.1.1" xref="S3.SS1.p3.5.m5.1.1.cmml"><msubsup id="S3.SS1.p3.5.m5.1.1.2" xref="S3.SS1.p3.5.m5.1.1.2.cmml"><mi id="S3.SS1.p3.5.m5.1.1.2.2.2" xref="S3.SS1.p3.5.m5.1.1.2.2.2.cmml">f</mi><mi id="S3.SS1.p3.5.m5.1.1.2.2.3" xref="S3.SS1.p3.5.m5.1.1.2.2.3.cmml">p</mi><mi id="S3.SS1.p3.5.m5.1.1.2.3" xref="S3.SS1.p3.5.m5.1.1.2.3.cmml">t</mi></msubsup><mo id="S3.SS1.p3.5.m5.1.1.1" xref="S3.SS1.p3.5.m5.1.1.1.cmml">∈</mo><msup id="S3.SS1.p3.5.m5.1.1.3" xref="S3.SS1.p3.5.m5.1.1.3.cmml"><mi id="S3.SS1.p3.5.m5.1.1.3.2" xref="S3.SS1.p3.5.m5.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p3.5.m5.1.1.3.3" xref="S3.SS1.p3.5.m5.1.1.3.3.cmml"><mi id="S3.SS1.p3.5.m5.1.1.3.3.2" xref="S3.SS1.p3.5.m5.1.1.3.3.2.cmml">M</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p3.5.m5.1.1.3.3.1" xref="S3.SS1.p3.5.m5.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p3.5.m5.1.1.3.3.3" xref="S3.SS1.p3.5.m5.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.1b"><apply id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1"><in id="S3.SS1.p3.5.m5.1.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1.1"></in><apply id="S3.SS1.p3.5.m5.1.1.2.cmml" xref="S3.SS1.p3.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.1.1.2.1.cmml" xref="S3.SS1.p3.5.m5.1.1.2">superscript</csymbol><apply id="S3.SS1.p3.5.m5.1.1.2.2.cmml" xref="S3.SS1.p3.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.1.1.2.2.1.cmml" xref="S3.SS1.p3.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS1.p3.5.m5.1.1.2.2.2.cmml" xref="S3.SS1.p3.5.m5.1.1.2.2.2">𝑓</ci><ci id="S3.SS1.p3.5.m5.1.1.2.2.3.cmml" xref="S3.SS1.p3.5.m5.1.1.2.2.3">𝑝</ci></apply><ci id="S3.SS1.p3.5.m5.1.1.2.3.cmml" xref="S3.SS1.p3.5.m5.1.1.2.3">𝑡</ci></apply><apply id="S3.SS1.p3.5.m5.1.1.3.cmml" xref="S3.SS1.p3.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.1.1.3.1.cmml" xref="S3.SS1.p3.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS1.p3.5.m5.1.1.3.2.cmml" xref="S3.SS1.p3.5.m5.1.1.3.2">ℝ</ci><apply id="S3.SS1.p3.5.m5.1.1.3.3.cmml" xref="S3.SS1.p3.5.m5.1.1.3.3"><times id="S3.SS1.p3.5.m5.1.1.3.3.1.cmml" xref="S3.SS1.p3.5.m5.1.1.3.3.1"></times><ci id="S3.SS1.p3.5.m5.1.1.3.3.2.cmml" xref="S3.SS1.p3.5.m5.1.1.3.3.2">𝑀</ci><ci id="S3.SS1.p3.5.m5.1.1.3.3.3.cmml" xref="S3.SS1.p3.5.m5.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.1c">f_{p}^{t}\in\mathbb{R}^{M\times D}</annotation></semantics></math> and <math id="S3.SS1.p3.6.m6.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS1.p3.6.m6.1a"><mi id="S3.SS1.p3.6.m6.1.1" xref="S3.SS1.p3.6.m6.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.6.m6.1b"><ci id="S3.SS1.p3.6.m6.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.6.m6.1c">M</annotation></semantics></math> are token numbers of one frame.
Finally, the visual frame-level and token-level features can be denoted as <math id="S3.SS1.p3.7.m7.4" class="ltx_Math" alttext="F_{v}=\{f_{v}^{1},f_{v}^{2},...,f_{v}^{T}\}" display="inline"><semantics id="S3.SS1.p3.7.m7.4a"><mrow id="S3.SS1.p3.7.m7.4.4" xref="S3.SS1.p3.7.m7.4.4.cmml"><msub id="S3.SS1.p3.7.m7.4.4.5" xref="S3.SS1.p3.7.m7.4.4.5.cmml"><mi id="S3.SS1.p3.7.m7.4.4.5.2" xref="S3.SS1.p3.7.m7.4.4.5.2.cmml">F</mi><mi id="S3.SS1.p3.7.m7.4.4.5.3" xref="S3.SS1.p3.7.m7.4.4.5.3.cmml">v</mi></msub><mo id="S3.SS1.p3.7.m7.4.4.4" xref="S3.SS1.p3.7.m7.4.4.4.cmml">=</mo><mrow id="S3.SS1.p3.7.m7.4.4.3.3" xref="S3.SS1.p3.7.m7.4.4.3.4.cmml"><mo stretchy="false" id="S3.SS1.p3.7.m7.4.4.3.3.4" xref="S3.SS1.p3.7.m7.4.4.3.4.cmml">{</mo><msubsup id="S3.SS1.p3.7.m7.2.2.1.1.1" xref="S3.SS1.p3.7.m7.2.2.1.1.1.cmml"><mi id="S3.SS1.p3.7.m7.2.2.1.1.1.2.2" xref="S3.SS1.p3.7.m7.2.2.1.1.1.2.2.cmml">f</mi><mi id="S3.SS1.p3.7.m7.2.2.1.1.1.2.3" xref="S3.SS1.p3.7.m7.2.2.1.1.1.2.3.cmml">v</mi><mn id="S3.SS1.p3.7.m7.2.2.1.1.1.3" xref="S3.SS1.p3.7.m7.2.2.1.1.1.3.cmml">1</mn></msubsup><mo id="S3.SS1.p3.7.m7.4.4.3.3.5" xref="S3.SS1.p3.7.m7.4.4.3.4.cmml">,</mo><msubsup id="S3.SS1.p3.7.m7.3.3.2.2.2" xref="S3.SS1.p3.7.m7.3.3.2.2.2.cmml"><mi id="S3.SS1.p3.7.m7.3.3.2.2.2.2.2" xref="S3.SS1.p3.7.m7.3.3.2.2.2.2.2.cmml">f</mi><mi id="S3.SS1.p3.7.m7.3.3.2.2.2.2.3" xref="S3.SS1.p3.7.m7.3.3.2.2.2.2.3.cmml">v</mi><mn id="S3.SS1.p3.7.m7.3.3.2.2.2.3" xref="S3.SS1.p3.7.m7.3.3.2.2.2.3.cmml">2</mn></msubsup><mo id="S3.SS1.p3.7.m7.4.4.3.3.6" xref="S3.SS1.p3.7.m7.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p3.7.m7.1.1" xref="S3.SS1.p3.7.m7.1.1.cmml">…</mi><mo id="S3.SS1.p3.7.m7.4.4.3.3.7" xref="S3.SS1.p3.7.m7.4.4.3.4.cmml">,</mo><msubsup id="S3.SS1.p3.7.m7.4.4.3.3.3" xref="S3.SS1.p3.7.m7.4.4.3.3.3.cmml"><mi id="S3.SS1.p3.7.m7.4.4.3.3.3.2.2" xref="S3.SS1.p3.7.m7.4.4.3.3.3.2.2.cmml">f</mi><mi id="S3.SS1.p3.7.m7.4.4.3.3.3.2.3" xref="S3.SS1.p3.7.m7.4.4.3.3.3.2.3.cmml">v</mi><mi id="S3.SS1.p3.7.m7.4.4.3.3.3.3" xref="S3.SS1.p3.7.m7.4.4.3.3.3.3.cmml">T</mi></msubsup><mo stretchy="false" id="S3.SS1.p3.7.m7.4.4.3.3.8" xref="S3.SS1.p3.7.m7.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.7.m7.4b"><apply id="S3.SS1.p3.7.m7.4.4.cmml" xref="S3.SS1.p3.7.m7.4.4"><eq id="S3.SS1.p3.7.m7.4.4.4.cmml" xref="S3.SS1.p3.7.m7.4.4.4"></eq><apply id="S3.SS1.p3.7.m7.4.4.5.cmml" xref="S3.SS1.p3.7.m7.4.4.5"><csymbol cd="ambiguous" id="S3.SS1.p3.7.m7.4.4.5.1.cmml" xref="S3.SS1.p3.7.m7.4.4.5">subscript</csymbol><ci id="S3.SS1.p3.7.m7.4.4.5.2.cmml" xref="S3.SS1.p3.7.m7.4.4.5.2">𝐹</ci><ci id="S3.SS1.p3.7.m7.4.4.5.3.cmml" xref="S3.SS1.p3.7.m7.4.4.5.3">𝑣</ci></apply><set id="S3.SS1.p3.7.m7.4.4.3.4.cmml" xref="S3.SS1.p3.7.m7.4.4.3.3"><apply id="S3.SS1.p3.7.m7.2.2.1.1.1.cmml" xref="S3.SS1.p3.7.m7.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.7.m7.2.2.1.1.1.1.cmml" xref="S3.SS1.p3.7.m7.2.2.1.1.1">superscript</csymbol><apply id="S3.SS1.p3.7.m7.2.2.1.1.1.2.cmml" xref="S3.SS1.p3.7.m7.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.7.m7.2.2.1.1.1.2.1.cmml" xref="S3.SS1.p3.7.m7.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p3.7.m7.2.2.1.1.1.2.2.cmml" xref="S3.SS1.p3.7.m7.2.2.1.1.1.2.2">𝑓</ci><ci id="S3.SS1.p3.7.m7.2.2.1.1.1.2.3.cmml" xref="S3.SS1.p3.7.m7.2.2.1.1.1.2.3">𝑣</ci></apply><cn type="integer" id="S3.SS1.p3.7.m7.2.2.1.1.1.3.cmml" xref="S3.SS1.p3.7.m7.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS1.p3.7.m7.3.3.2.2.2.cmml" xref="S3.SS1.p3.7.m7.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.7.m7.3.3.2.2.2.1.cmml" xref="S3.SS1.p3.7.m7.3.3.2.2.2">superscript</csymbol><apply id="S3.SS1.p3.7.m7.3.3.2.2.2.2.cmml" xref="S3.SS1.p3.7.m7.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.7.m7.3.3.2.2.2.2.1.cmml" xref="S3.SS1.p3.7.m7.3.3.2.2.2">subscript</csymbol><ci id="S3.SS1.p3.7.m7.3.3.2.2.2.2.2.cmml" xref="S3.SS1.p3.7.m7.3.3.2.2.2.2.2">𝑓</ci><ci id="S3.SS1.p3.7.m7.3.3.2.2.2.2.3.cmml" xref="S3.SS1.p3.7.m7.3.3.2.2.2.2.3">𝑣</ci></apply><cn type="integer" id="S3.SS1.p3.7.m7.3.3.2.2.2.3.cmml" xref="S3.SS1.p3.7.m7.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS1.p3.7.m7.1.1.cmml" xref="S3.SS1.p3.7.m7.1.1">…</ci><apply id="S3.SS1.p3.7.m7.4.4.3.3.3.cmml" xref="S3.SS1.p3.7.m7.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p3.7.m7.4.4.3.3.3.1.cmml" xref="S3.SS1.p3.7.m7.4.4.3.3.3">superscript</csymbol><apply id="S3.SS1.p3.7.m7.4.4.3.3.3.2.cmml" xref="S3.SS1.p3.7.m7.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p3.7.m7.4.4.3.3.3.2.1.cmml" xref="S3.SS1.p3.7.m7.4.4.3.3.3">subscript</csymbol><ci id="S3.SS1.p3.7.m7.4.4.3.3.3.2.2.cmml" xref="S3.SS1.p3.7.m7.4.4.3.3.3.2.2">𝑓</ci><ci id="S3.SS1.p3.7.m7.4.4.3.3.3.2.3.cmml" xref="S3.SS1.p3.7.m7.4.4.3.3.3.2.3">𝑣</ci></apply><ci id="S3.SS1.p3.7.m7.4.4.3.3.3.3.cmml" xref="S3.SS1.p3.7.m7.4.4.3.3.3.3">𝑇</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.7.m7.4c">F_{v}=\{f_{v}^{1},f_{v}^{2},...,f_{v}^{T}\}</annotation></semantics></math>, <math id="S3.SS1.p3.8.m8.4" class="ltx_Math" alttext="F_{p}=\{f_{p}^{1},f_{p}^{2},...,f_{p}^{T}\}" display="inline"><semantics id="S3.SS1.p3.8.m8.4a"><mrow id="S3.SS1.p3.8.m8.4.4" xref="S3.SS1.p3.8.m8.4.4.cmml"><msub id="S3.SS1.p3.8.m8.4.4.5" xref="S3.SS1.p3.8.m8.4.4.5.cmml"><mi id="S3.SS1.p3.8.m8.4.4.5.2" xref="S3.SS1.p3.8.m8.4.4.5.2.cmml">F</mi><mi id="S3.SS1.p3.8.m8.4.4.5.3" xref="S3.SS1.p3.8.m8.4.4.5.3.cmml">p</mi></msub><mo id="S3.SS1.p3.8.m8.4.4.4" xref="S3.SS1.p3.8.m8.4.4.4.cmml">=</mo><mrow id="S3.SS1.p3.8.m8.4.4.3.3" xref="S3.SS1.p3.8.m8.4.4.3.4.cmml"><mo stretchy="false" id="S3.SS1.p3.8.m8.4.4.3.3.4" xref="S3.SS1.p3.8.m8.4.4.3.4.cmml">{</mo><msubsup id="S3.SS1.p3.8.m8.2.2.1.1.1" xref="S3.SS1.p3.8.m8.2.2.1.1.1.cmml"><mi id="S3.SS1.p3.8.m8.2.2.1.1.1.2.2" xref="S3.SS1.p3.8.m8.2.2.1.1.1.2.2.cmml">f</mi><mi id="S3.SS1.p3.8.m8.2.2.1.1.1.2.3" xref="S3.SS1.p3.8.m8.2.2.1.1.1.2.3.cmml">p</mi><mn id="S3.SS1.p3.8.m8.2.2.1.1.1.3" xref="S3.SS1.p3.8.m8.2.2.1.1.1.3.cmml">1</mn></msubsup><mo id="S3.SS1.p3.8.m8.4.4.3.3.5" xref="S3.SS1.p3.8.m8.4.4.3.4.cmml">,</mo><msubsup id="S3.SS1.p3.8.m8.3.3.2.2.2" xref="S3.SS1.p3.8.m8.3.3.2.2.2.cmml"><mi id="S3.SS1.p3.8.m8.3.3.2.2.2.2.2" xref="S3.SS1.p3.8.m8.3.3.2.2.2.2.2.cmml">f</mi><mi id="S3.SS1.p3.8.m8.3.3.2.2.2.2.3" xref="S3.SS1.p3.8.m8.3.3.2.2.2.2.3.cmml">p</mi><mn id="S3.SS1.p3.8.m8.3.3.2.2.2.3" xref="S3.SS1.p3.8.m8.3.3.2.2.2.3.cmml">2</mn></msubsup><mo id="S3.SS1.p3.8.m8.4.4.3.3.6" xref="S3.SS1.p3.8.m8.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p3.8.m8.1.1" xref="S3.SS1.p3.8.m8.1.1.cmml">…</mi><mo id="S3.SS1.p3.8.m8.4.4.3.3.7" xref="S3.SS1.p3.8.m8.4.4.3.4.cmml">,</mo><msubsup id="S3.SS1.p3.8.m8.4.4.3.3.3" xref="S3.SS1.p3.8.m8.4.4.3.3.3.cmml"><mi id="S3.SS1.p3.8.m8.4.4.3.3.3.2.2" xref="S3.SS1.p3.8.m8.4.4.3.3.3.2.2.cmml">f</mi><mi id="S3.SS1.p3.8.m8.4.4.3.3.3.2.3" xref="S3.SS1.p3.8.m8.4.4.3.3.3.2.3.cmml">p</mi><mi id="S3.SS1.p3.8.m8.4.4.3.3.3.3" xref="S3.SS1.p3.8.m8.4.4.3.3.3.3.cmml">T</mi></msubsup><mo stretchy="false" id="S3.SS1.p3.8.m8.4.4.3.3.8" xref="S3.SS1.p3.8.m8.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.8.m8.4b"><apply id="S3.SS1.p3.8.m8.4.4.cmml" xref="S3.SS1.p3.8.m8.4.4"><eq id="S3.SS1.p3.8.m8.4.4.4.cmml" xref="S3.SS1.p3.8.m8.4.4.4"></eq><apply id="S3.SS1.p3.8.m8.4.4.5.cmml" xref="S3.SS1.p3.8.m8.4.4.5"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.4.4.5.1.cmml" xref="S3.SS1.p3.8.m8.4.4.5">subscript</csymbol><ci id="S3.SS1.p3.8.m8.4.4.5.2.cmml" xref="S3.SS1.p3.8.m8.4.4.5.2">𝐹</ci><ci id="S3.SS1.p3.8.m8.4.4.5.3.cmml" xref="S3.SS1.p3.8.m8.4.4.5.3">𝑝</ci></apply><set id="S3.SS1.p3.8.m8.4.4.3.4.cmml" xref="S3.SS1.p3.8.m8.4.4.3.3"><apply id="S3.SS1.p3.8.m8.2.2.1.1.1.cmml" xref="S3.SS1.p3.8.m8.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.2.2.1.1.1.1.cmml" xref="S3.SS1.p3.8.m8.2.2.1.1.1">superscript</csymbol><apply id="S3.SS1.p3.8.m8.2.2.1.1.1.2.cmml" xref="S3.SS1.p3.8.m8.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.2.2.1.1.1.2.1.cmml" xref="S3.SS1.p3.8.m8.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p3.8.m8.2.2.1.1.1.2.2.cmml" xref="S3.SS1.p3.8.m8.2.2.1.1.1.2.2">𝑓</ci><ci id="S3.SS1.p3.8.m8.2.2.1.1.1.2.3.cmml" xref="S3.SS1.p3.8.m8.2.2.1.1.1.2.3">𝑝</ci></apply><cn type="integer" id="S3.SS1.p3.8.m8.2.2.1.1.1.3.cmml" xref="S3.SS1.p3.8.m8.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS1.p3.8.m8.3.3.2.2.2.cmml" xref="S3.SS1.p3.8.m8.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.3.3.2.2.2.1.cmml" xref="S3.SS1.p3.8.m8.3.3.2.2.2">superscript</csymbol><apply id="S3.SS1.p3.8.m8.3.3.2.2.2.2.cmml" xref="S3.SS1.p3.8.m8.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.3.3.2.2.2.2.1.cmml" xref="S3.SS1.p3.8.m8.3.3.2.2.2">subscript</csymbol><ci id="S3.SS1.p3.8.m8.3.3.2.2.2.2.2.cmml" xref="S3.SS1.p3.8.m8.3.3.2.2.2.2.2">𝑓</ci><ci id="S3.SS1.p3.8.m8.3.3.2.2.2.2.3.cmml" xref="S3.SS1.p3.8.m8.3.3.2.2.2.2.3">𝑝</ci></apply><cn type="integer" id="S3.SS1.p3.8.m8.3.3.2.2.2.3.cmml" xref="S3.SS1.p3.8.m8.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS1.p3.8.m8.1.1.cmml" xref="S3.SS1.p3.8.m8.1.1">…</ci><apply id="S3.SS1.p3.8.m8.4.4.3.3.3.cmml" xref="S3.SS1.p3.8.m8.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.4.4.3.3.3.1.cmml" xref="S3.SS1.p3.8.m8.4.4.3.3.3">superscript</csymbol><apply id="S3.SS1.p3.8.m8.4.4.3.3.3.2.cmml" xref="S3.SS1.p3.8.m8.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.4.4.3.3.3.2.1.cmml" xref="S3.SS1.p3.8.m8.4.4.3.3.3">subscript</csymbol><ci id="S3.SS1.p3.8.m8.4.4.3.3.3.2.2.cmml" xref="S3.SS1.p3.8.m8.4.4.3.3.3.2.2">𝑓</ci><ci id="S3.SS1.p3.8.m8.4.4.3.3.3.2.3.cmml" xref="S3.SS1.p3.8.m8.4.4.3.3.3.2.3">𝑝</ci></apply><ci id="S3.SS1.p3.8.m8.4.4.3.3.3.3.cmml" xref="S3.SS1.p3.8.m8.4.4.3.3.3.3">𝑇</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.8.m8.4c">F_{p}=\{f_{p}^{1},f_{p}^{2},...,f_{p}^{T}\}</annotation></semantics></math>, respectively.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.4" class="ltx_p"><span id="S3.SS1.p4.4.1" class="ltx_text ltx_font_bold">Text Representation</span>.
Given an asked question <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><mi id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><ci id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">Q</annotation></semantics></math>, we represent each word <math id="S3.SS1.p4.2.m2.1" class="ltx_Math" alttext="q_{n}" display="inline"><semantics id="S3.SS1.p4.2.m2.1a"><msub id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml"><mi id="S3.SS1.p4.2.m2.1.1.2" xref="S3.SS1.p4.2.m2.1.1.2.cmml">q</mi><mi id="S3.SS1.p4.2.m2.1.1.3" xref="S3.SS1.p4.2.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><apply id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p4.2.m2.1.1.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2">𝑞</ci><ci id="S3.SS1.p4.2.m2.1.1.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">q_{n}</annotation></semantics></math> in a fixed length vector with word embeddings, and then feed it into the pre-trained CLIP<cite class="ltx_cite ltx_citemacro_citep">(Radford et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2021</a>)</cite> model to get the question feature <math id="S3.SS1.p4.3.m3.1" class="ltx_Math" alttext="F_{Q}" display="inline"><semantics id="S3.SS1.p4.3.m3.1a"><msub id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml"><mi id="S3.SS1.p4.3.m3.1.1.2" xref="S3.SS1.p4.3.m3.1.1.2.cmml">F</mi><mi id="S3.SS1.p4.3.m3.1.1.3" xref="S3.SS1.p4.3.m3.1.1.3.cmml">Q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><apply id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.3.m3.1.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p4.3.m3.1.1.2.cmml" xref="S3.SS1.p4.3.m3.1.1.2">𝐹</ci><ci id="S3.SS1.p4.3.m3.1.1.3.cmml" xref="S3.SS1.p4.3.m3.1.1.3">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">F_{Q}</annotation></semantics></math>, where <math id="S3.SS1.p4.4.m4.1" class="ltx_Math" alttext="F_{Q}\in\mathbb{R}^{D}" display="inline"><semantics id="S3.SS1.p4.4.m4.1a"><mrow id="S3.SS1.p4.4.m4.1.1" xref="S3.SS1.p4.4.m4.1.1.cmml"><msub id="S3.SS1.p4.4.m4.1.1.2" xref="S3.SS1.p4.4.m4.1.1.2.cmml"><mi id="S3.SS1.p4.4.m4.1.1.2.2" xref="S3.SS1.p4.4.m4.1.1.2.2.cmml">F</mi><mi id="S3.SS1.p4.4.m4.1.1.2.3" xref="S3.SS1.p4.4.m4.1.1.2.3.cmml">Q</mi></msub><mo id="S3.SS1.p4.4.m4.1.1.1" xref="S3.SS1.p4.4.m4.1.1.1.cmml">∈</mo><msup id="S3.SS1.p4.4.m4.1.1.3" xref="S3.SS1.p4.4.m4.1.1.3.cmml"><mi id="S3.SS1.p4.4.m4.1.1.3.2" xref="S3.SS1.p4.4.m4.1.1.3.2.cmml">ℝ</mi><mi id="S3.SS1.p4.4.m4.1.1.3.3" xref="S3.SS1.p4.4.m4.1.1.3.3.cmml">D</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.1b"><apply id="S3.SS1.p4.4.m4.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1"><in id="S3.SS1.p4.4.m4.1.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1.1"></in><apply id="S3.SS1.p4.4.m4.1.1.2.cmml" xref="S3.SS1.p4.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p4.4.m4.1.1.2.1.cmml" xref="S3.SS1.p4.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS1.p4.4.m4.1.1.2.2.cmml" xref="S3.SS1.p4.4.m4.1.1.2.2">𝐹</ci><ci id="S3.SS1.p4.4.m4.1.1.2.3.cmml" xref="S3.SS1.p4.4.m4.1.1.2.3">𝑄</ci></apply><apply id="S3.SS1.p4.4.m4.1.1.3.cmml" xref="S3.SS1.p4.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p4.4.m4.1.1.3.1.cmml" xref="S3.SS1.p4.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS1.p4.4.m4.1.1.3.2.cmml" xref="S3.SS1.p4.4.m4.1.1.3.2">ℝ</ci><ci id="S3.SS1.p4.4.m4.1.1.3.3.cmml" xref="S3.SS1.p4.4.m4.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.1c">F_{Q}\in\mathbb{R}^{D}</annotation></semantics></math>.
Note that the first token pooling is used for extracting question features.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Temporal Perception Module</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">To highlight the <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="Top_{k}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.1.m1.1.1.1a" xref="S3.SS2.p1.1.m1.1.1.1.cmml">​</mo><msub id="S3.SS2.p1.1.m1.1.1.4" xref="S3.SS2.p1.1.m1.1.1.4.cmml"><mi id="S3.SS2.p1.1.m1.1.1.4.2" xref="S3.SS2.p1.1.m1.1.1.4.2.cmml">p</mi><mi id="S3.SS2.p1.1.m1.1.1.4.3" xref="S3.SS2.p1.1.m1.1.1.4.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><times id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></times><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">𝑇</ci><ci id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">𝑜</ci><apply id="S3.SS2.p1.1.m1.1.1.4.cmml" xref="S3.SS2.p1.1.m1.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.4.1.cmml" xref="S3.SS2.p1.1.m1.1.1.4">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.4.2.cmml" xref="S3.SS2.p1.1.m1.1.1.4.2">𝑝</ci><ci id="S3.SS2.p1.1.m1.1.1.4.3.cmml" xref="S3.SS2.p1.1.m1.1.1.4.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">Top_{k}</annotation></semantics></math> crucial temporal segments that are relevant to the question, we propose a <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_bold">T</span>emporal <span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_bold">P</span>erception <span id="S3.SS2.p1.1.3" class="ltx_text ltx_font_bold">M</span>odule (<span id="S3.SS2.p1.1.4" class="ltx_text ltx_font_bold">TPM</span>) with a carefully designed text prompt.
While previous works <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2023b</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite> have considered identifying key segments through the semantic similarity between question and temporal visual segments, aligning questions with visual frame semantics poses a significant challenge due to the non-declarative sentence of the questions.
Therefore, the key of TPM lies in constructing a declarative sentence, aligning it effectively with the semantic content of the video, and facilitating the identification of critical segments.
</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.3" class="ltx_p">To achieve this, we devised a <span id="S3.SS2.p2.3.2" class="ltx_text ltx_font_bold">T</span>ext <span id="S3.SS2.p2.3.3" class="ltx_text ltx_font_bold">P</span>rompt <span id="S3.SS2.p2.3.4" class="ltx_text ltx_font_bold">C</span>onstructor (<span id="S3.SS2.p2.3.5" class="ltx_text ltx_font_bold">TPC</span>) with the goal of generating declarative statements based on input questions.
This helps semantic alignment between the generated statements and the visual frame, facilitating the identify key temporal segments to enhance the model’s temporal perception ability.
Specifically, the TPC process is as follows:
<span id="S3.SS2.p2.3.6" class="ltx_text ltx_font_bold">1) Construction Guidelines:</span>
Since the input question does not contain answers, directly transforming them into declarative statements poses difficulties.
Hence, considering the design of statements that exclude irrelevant segments, guiding the model’s attention toward temporal content relevant to the questions.
<span id="S3.SS2.p2.3.7" class="ltx_text ltx_font_bold">2) Construction Process:</span>
Based on the question templates, we manually constructed corresponding declarative sentence templates following the guidelines. These templates were refined and optimized through multiple discussions with several contributors to ensure their validity.
<span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">3) Construction Results<sup id="S3.SS2.p2.1.1.1" class="ltx_sup"><span id="S3.SS2.p2.1.1.1.1" class="ltx_text ltx_font_medium">1</span></sup><span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><sup id="footnote2.3" class="ltx_sup"><span id="footnote2.3.1" class="ltx_text ltx_font_medium">1</span></sup><span id="footnote2.4" class="ltx_text ltx_font_medium"> More results are described in the code files (‘</span><span id="footnote2.5" class="ltx_text ltx_font_italic">./dataset/TextPrompt.xlsx</span><span id="footnote2.6" class="ltx_text ltx_font_medium">”).</span></span></span></span>:</span>
Illustrated by the example in Fig. <a href="#S1.F2" title="Figure 2 ‣ 1. Introduction ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>,
for input question “<span id="S3.SS2.p2.3.8" class="ltx_text ltx_font_italic">Where is the first sounding instrument?</span>”, the objective is to identify the moment when the <span id="S3.SS2.p2.3.9" class="ltx_text ltx_font_italic">first</span> instrument starts playing. Considering that instruments in the video do not play simultaneously but follow a sequential order, we direct the model’s attention to segments in the video where instruments do not play simultaneously.
This directs the model to focus on segments where there are changes in the order of instrument sounds, identifying crucial segments.
Leveraging the <span id="S3.SS2.p2.3.10" class="ltx_text ltx_font_bold">TPC</span>, we manually transform the question into a declarative sentence “<span id="S3.SS2.p2.3.11" class="ltx_text ltx_font_italic">The instruments in the video do not sound at the same time.</span>”, denoted as <math id="S3.SS2.p2.2.m1.1" class="ltx_Math" alttext="\mathtt{TPrompt}" display="inline"><semantics id="S3.SS2.p2.2.m1.1a"><mi id="S3.SS2.p2.2.m1.1.1" xref="S3.SS2.p2.2.m1.1.1.cmml">𝚃𝙿𝚛𝚘𝚖𝚙𝚝</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m1.1b"><ci id="S3.SS2.p2.2.m1.1.1.cmml" xref="S3.SS2.p2.2.m1.1.1">𝚃𝙿𝚛𝚘𝚖𝚙𝚝</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m1.1c">\mathtt{TPrompt}</annotation></semantics></math>, aligning its feature representation well with the semantic content of the video.
This allows us to locate segments related to <math id="S3.SS2.p2.3.m2.1" class="ltx_Math" alttext="\mathtt{TPrompt}" display="inline"><semantics id="S3.SS2.p2.3.m2.1a"><mi id="S3.SS2.p2.3.m2.1.1" xref="S3.SS2.p2.3.m2.1.1.cmml">𝚃𝙿𝚛𝚘𝚖𝚙𝚝</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m2.1b"><ci id="S3.SS2.p2.3.m2.1.1.cmml" xref="S3.SS2.p2.3.m2.1.1">𝚃𝙿𝚛𝚘𝚖𝚙𝚝</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m2.1c">\mathtt{TPrompt}</annotation></semantics></math> and subsequently locate temporal segments relevant to the question.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.7" class="ltx_p">For a given declarative sentence <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="\mathtt{TPrompt}" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">𝚃𝙿𝚛𝚘𝚖𝚙𝚝</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝚃𝙿𝚛𝚘𝚖𝚙𝚝</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\mathtt{TPrompt}</annotation></semantics></math>, its feature embedding <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="F_{TPrompt}" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><msub id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">F</mi><mrow id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml"><mi id="S3.SS2.p3.2.m2.1.1.3.2" xref="S3.SS2.p3.2.m2.1.1.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.2.m2.1.1.3.1" xref="S3.SS2.p3.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.2.m2.1.1.3.3" xref="S3.SS2.p3.2.m2.1.1.3.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.2.m2.1.1.3.1a" xref="S3.SS2.p3.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.2.m2.1.1.3.4" xref="S3.SS2.p3.2.m2.1.1.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.2.m2.1.1.3.1b" xref="S3.SS2.p3.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.2.m2.1.1.3.5" xref="S3.SS2.p3.2.m2.1.1.3.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.2.m2.1.1.3.1c" xref="S3.SS2.p3.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.2.m2.1.1.3.6" xref="S3.SS2.p3.2.m2.1.1.3.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.2.m2.1.1.3.1d" xref="S3.SS2.p3.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.2.m2.1.1.3.7" xref="S3.SS2.p3.2.m2.1.1.3.7.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.2.m2.1.1.3.1e" xref="S3.SS2.p3.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.2.m2.1.1.3.8" xref="S3.SS2.p3.2.m2.1.1.3.8.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2">𝐹</ci><apply id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3"><times id="S3.SS2.p3.2.m2.1.1.3.1.cmml" xref="S3.SS2.p3.2.m2.1.1.3.1"></times><ci id="S3.SS2.p3.2.m2.1.1.3.2.cmml" xref="S3.SS2.p3.2.m2.1.1.3.2">𝑇</ci><ci id="S3.SS2.p3.2.m2.1.1.3.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3.3">𝑃</ci><ci id="S3.SS2.p3.2.m2.1.1.3.4.cmml" xref="S3.SS2.p3.2.m2.1.1.3.4">𝑟</ci><ci id="S3.SS2.p3.2.m2.1.1.3.5.cmml" xref="S3.SS2.p3.2.m2.1.1.3.5">𝑜</ci><ci id="S3.SS2.p3.2.m2.1.1.3.6.cmml" xref="S3.SS2.p3.2.m2.1.1.3.6">𝑚</ci><ci id="S3.SS2.p3.2.m2.1.1.3.7.cmml" xref="S3.SS2.p3.2.m2.1.1.3.7">𝑝</ci><ci id="S3.SS2.p3.2.m2.1.1.3.8.cmml" xref="S3.SS2.p3.2.m2.1.1.3.8">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">F_{TPrompt}</annotation></semantics></math> using the same encoder as the given question.
Concretely, we first use one linear projection layer <math id="S3.SS2.p3.3.m3.1" class="ltx_Math" alttext="\mathtt{Key(\cdot)}" display="inline"><semantics id="S3.SS2.p3.3.m3.1a"><mrow id="S3.SS2.p3.3.m3.1.2" xref="S3.SS2.p3.3.m3.1.2.cmml"><mi id="S3.SS2.p3.3.m3.1.2.2" xref="S3.SS2.p3.3.m3.1.2.2.cmml">𝙺𝚎𝚢</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.3.m3.1.2.1" xref="S3.SS2.p3.3.m3.1.2.1.cmml">​</mo><mrow id="S3.SS2.p3.3.m3.1.2.3.2" xref="S3.SS2.p3.3.m3.1.2.cmml"><mo stretchy="false" id="S3.SS2.p3.3.m3.1.2.3.2.1" xref="S3.SS2.p3.3.m3.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">⋅</mo><mo stretchy="false" id="S3.SS2.p3.3.m3.1.2.3.2.2" xref="S3.SS2.p3.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.2.cmml" xref="S3.SS2.p3.3.m3.1.2"><times id="S3.SS2.p3.3.m3.1.2.1.cmml" xref="S3.SS2.p3.3.m3.1.2.1"></times><ci id="S3.SS2.p3.3.m3.1.2.2.cmml" xref="S3.SS2.p3.3.m3.1.2.2">𝙺𝚎𝚢</ci><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">\mathtt{Key(\cdot)}</annotation></semantics></math> to transform indexing visual features <math id="S3.SS2.p3.4.m4.1" class="ltx_Math" alttext="F_{v}" display="inline"><semantics id="S3.SS2.p3.4.m4.1a"><msub id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml"><mi id="S3.SS2.p3.4.m4.1.1.2" xref="S3.SS2.p3.4.m4.1.1.2.cmml">F</mi><mi id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2">𝐹</ci><ci id="S3.SS2.p3.4.m4.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">F_{v}</annotation></semantics></math> to indexing keys <math id="S3.SS2.p3.5.m5.1" class="ltx_Math" alttext="\mathbf{k}" display="inline"><semantics id="S3.SS2.p3.5.m5.1a"><mi id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">𝐤</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><ci id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">𝐤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">\mathbf{k}</annotation></semantics></math>.
Then we get an attention score for each indexing key in the video temporal sequence.
A <math id="S3.SS2.p3.6.m6.1" class="ltx_Math" alttext="\mathtt{Softmax}" display="inline"><semantics id="S3.SS2.p3.6.m6.1a"><mi id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml">𝚂𝚘𝚏𝚝𝚖𝚊𝚡</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><ci id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">𝚂𝚘𝚏𝚝𝚖𝚊𝚡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">\mathtt{Softmax}</annotation></semantics></math> layer normalizes the attention scores and generates an attention weight vector <math id="S3.SS2.p3.7.m7.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS2.p3.7.m7.1a"><mi id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><ci id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">W</annotation></semantics></math> by:</p>
<table id="S5.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1.m1.5" class="ltx_Math" alttext="\displaystyle W=\mathtt{Softmax}(\frac{F_{TPrompt}\centerdot[\mathbf{k}_{1},\mathbf{k}_{2},...,\mathbf{k}_{T}]^{\intercal}}{\sqrt{d}})," display="inline"><semantics id="S3.E1.m1.5a"><mrow id="S3.E1.m1.5.5.1" xref="S3.E1.m1.5.5.1.1.cmml"><mrow id="S3.E1.m1.5.5.1.1" xref="S3.E1.m1.5.5.1.1.cmml"><mi id="S3.E1.m1.5.5.1.1.2" xref="S3.E1.m1.5.5.1.1.2.cmml">W</mi><mo id="S3.E1.m1.5.5.1.1.1" xref="S3.E1.m1.5.5.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.5.5.1.1.3" xref="S3.E1.m1.5.5.1.1.3.cmml"><mi id="S3.E1.m1.5.5.1.1.3.2" xref="S3.E1.m1.5.5.1.1.3.2.cmml">𝚂𝚘𝚏𝚝𝚖𝚊𝚡</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.5.5.1.1.3.1" xref="S3.E1.m1.5.5.1.1.3.1.cmml">​</mo><mrow id="S3.E1.m1.5.5.1.1.3.3.2" xref="S3.E1.m1.4.4.cmml"><mo stretchy="false" id="S3.E1.m1.5.5.1.1.3.3.2.1" xref="S3.E1.m1.4.4.cmml">(</mo><mstyle displaystyle="true" id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml"><mfrac id="S3.E1.m1.4.4a" xref="S3.E1.m1.4.4.cmml"><mrow id="S3.E1.m1.4.4.4" xref="S3.E1.m1.4.4.4.cmml"><msub id="S3.E1.m1.4.4.4.6" xref="S3.E1.m1.4.4.4.6.cmml"><mi id="S3.E1.m1.4.4.4.6.2" xref="S3.E1.m1.4.4.4.6.2.cmml">F</mi><mrow id="S3.E1.m1.4.4.4.6.3" xref="S3.E1.m1.4.4.4.6.3.cmml"><mi id="S3.E1.m1.4.4.4.6.3.2" xref="S3.E1.m1.4.4.4.6.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.4.6.3.1" xref="S3.E1.m1.4.4.4.6.3.1.cmml">​</mo><mi id="S3.E1.m1.4.4.4.6.3.3" xref="S3.E1.m1.4.4.4.6.3.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.4.6.3.1a" xref="S3.E1.m1.4.4.4.6.3.1.cmml">​</mo><mi id="S3.E1.m1.4.4.4.6.3.4" xref="S3.E1.m1.4.4.4.6.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.4.6.3.1b" xref="S3.E1.m1.4.4.4.6.3.1.cmml">​</mo><mi id="S3.E1.m1.4.4.4.6.3.5" xref="S3.E1.m1.4.4.4.6.3.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.4.6.3.1c" xref="S3.E1.m1.4.4.4.6.3.1.cmml">​</mo><mi id="S3.E1.m1.4.4.4.6.3.6" xref="S3.E1.m1.4.4.4.6.3.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.4.6.3.1d" xref="S3.E1.m1.4.4.4.6.3.1.cmml">​</mo><mi id="S3.E1.m1.4.4.4.6.3.7" xref="S3.E1.m1.4.4.4.6.3.7.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.4.6.3.1e" xref="S3.E1.m1.4.4.4.6.3.1.cmml">​</mo><mi id="S3.E1.m1.4.4.4.6.3.8" xref="S3.E1.m1.4.4.4.6.3.8.cmml">t</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.4.4.4.5" xref="S3.E1.m1.4.4.4.5.cmml">∙</mo><msup id="S3.E1.m1.4.4.4.4" xref="S3.E1.m1.4.4.4.4.cmml"><mrow id="S3.E1.m1.4.4.4.4.3.3" xref="S3.E1.m1.4.4.4.4.3.4.cmml"><mo stretchy="false" id="S3.E1.m1.4.4.4.4.3.3.4" xref="S3.E1.m1.4.4.4.4.3.4.cmml">[</mo><msub id="S3.E1.m1.2.2.2.2.1.1.1" xref="S3.E1.m1.2.2.2.2.1.1.1.cmml"><mi id="S3.E1.m1.2.2.2.2.1.1.1.2" xref="S3.E1.m1.2.2.2.2.1.1.1.2.cmml">𝐤</mi><mn id="S3.E1.m1.2.2.2.2.1.1.1.3" xref="S3.E1.m1.2.2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.E1.m1.4.4.4.4.3.3.5" xref="S3.E1.m1.4.4.4.4.3.4.cmml">,</mo><msub id="S3.E1.m1.3.3.3.3.2.2.2" xref="S3.E1.m1.3.3.3.3.2.2.2.cmml"><mi id="S3.E1.m1.3.3.3.3.2.2.2.2" xref="S3.E1.m1.3.3.3.3.2.2.2.2.cmml">𝐤</mi><mn id="S3.E1.m1.3.3.3.3.2.2.2.3" xref="S3.E1.m1.3.3.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S3.E1.m1.4.4.4.4.3.3.6" xref="S3.E1.m1.4.4.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">…</mi><mo id="S3.E1.m1.4.4.4.4.3.3.7" xref="S3.E1.m1.4.4.4.4.3.4.cmml">,</mo><msub id="S3.E1.m1.4.4.4.4.3.3.3" xref="S3.E1.m1.4.4.4.4.3.3.3.cmml"><mi id="S3.E1.m1.4.4.4.4.3.3.3.2" xref="S3.E1.m1.4.4.4.4.3.3.3.2.cmml">𝐤</mi><mi id="S3.E1.m1.4.4.4.4.3.3.3.3" xref="S3.E1.m1.4.4.4.4.3.3.3.3.cmml">T</mi></msub><mo stretchy="false" id="S3.E1.m1.4.4.4.4.3.3.8" xref="S3.E1.m1.4.4.4.4.3.4.cmml">]</mo></mrow><mo id="S3.E1.m1.4.4.4.4.5" xref="S3.E1.m1.4.4.4.4.5.cmml">⊺</mo></msup></mrow><msqrt id="S3.E1.m1.4.4.6" xref="S3.E1.m1.4.4.6.cmml"><mi id="S3.E1.m1.4.4.6.2" xref="S3.E1.m1.4.4.6.2.cmml">d</mi></msqrt></mfrac></mstyle><mo stretchy="false" id="S3.E1.m1.5.5.1.1.3.3.2.2" xref="S3.E1.m1.4.4.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E1.m1.5.5.1.2" xref="S3.E1.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.5b"><apply id="S3.E1.m1.5.5.1.1.cmml" xref="S3.E1.m1.5.5.1"><eq id="S3.E1.m1.5.5.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1"></eq><ci id="S3.E1.m1.5.5.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.2">𝑊</ci><apply id="S3.E1.m1.5.5.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.3"><times id="S3.E1.m1.5.5.1.1.3.1.cmml" xref="S3.E1.m1.5.5.1.1.3.1"></times><ci id="S3.E1.m1.5.5.1.1.3.2.cmml" xref="S3.E1.m1.5.5.1.1.3.2">𝚂𝚘𝚏𝚝𝚖𝚊𝚡</ci><apply id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.5.5.1.1.3.3.2"><divide id="S3.E1.m1.4.4.5.cmml" xref="S3.E1.m1.5.5.1.1.3.3.2"></divide><apply id="S3.E1.m1.4.4.4.cmml" xref="S3.E1.m1.4.4.4"><ci id="S3.E1.m1.4.4.4.5.cmml" xref="S3.E1.m1.4.4.4.5">∙</ci><apply id="S3.E1.m1.4.4.4.6.cmml" xref="S3.E1.m1.4.4.4.6"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.6.1.cmml" xref="S3.E1.m1.4.4.4.6">subscript</csymbol><ci id="S3.E1.m1.4.4.4.6.2.cmml" xref="S3.E1.m1.4.4.4.6.2">𝐹</ci><apply id="S3.E1.m1.4.4.4.6.3.cmml" xref="S3.E1.m1.4.4.4.6.3"><times id="S3.E1.m1.4.4.4.6.3.1.cmml" xref="S3.E1.m1.4.4.4.6.3.1"></times><ci id="S3.E1.m1.4.4.4.6.3.2.cmml" xref="S3.E1.m1.4.4.4.6.3.2">𝑇</ci><ci id="S3.E1.m1.4.4.4.6.3.3.cmml" xref="S3.E1.m1.4.4.4.6.3.3">𝑃</ci><ci id="S3.E1.m1.4.4.4.6.3.4.cmml" xref="S3.E1.m1.4.4.4.6.3.4">𝑟</ci><ci id="S3.E1.m1.4.4.4.6.3.5.cmml" xref="S3.E1.m1.4.4.4.6.3.5">𝑜</ci><ci id="S3.E1.m1.4.4.4.6.3.6.cmml" xref="S3.E1.m1.4.4.4.6.3.6">𝑚</ci><ci id="S3.E1.m1.4.4.4.6.3.7.cmml" xref="S3.E1.m1.4.4.4.6.3.7">𝑝</ci><ci id="S3.E1.m1.4.4.4.6.3.8.cmml" xref="S3.E1.m1.4.4.4.6.3.8">𝑡</ci></apply></apply><apply id="S3.E1.m1.4.4.4.4.cmml" xref="S3.E1.m1.4.4.4.4"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.4.4.cmml" xref="S3.E1.m1.4.4.4.4">superscript</csymbol><list id="S3.E1.m1.4.4.4.4.3.4.cmml" xref="S3.E1.m1.4.4.4.4.3.3"><apply id="S3.E1.m1.2.2.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.1.1.1.2.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1.2">𝐤</ci><cn type="integer" id="S3.E1.m1.2.2.2.2.1.1.1.3.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1.3">1</cn></apply><apply id="S3.E1.m1.3.3.3.3.2.2.2.cmml" xref="S3.E1.m1.3.3.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.3.2.2.2.1.cmml" xref="S3.E1.m1.3.3.3.3.2.2.2">subscript</csymbol><ci id="S3.E1.m1.3.3.3.3.2.2.2.2.cmml" xref="S3.E1.m1.3.3.3.3.2.2.2.2">𝐤</ci><cn type="integer" id="S3.E1.m1.3.3.3.3.2.2.2.3.cmml" xref="S3.E1.m1.3.3.3.3.2.2.2.3">2</cn></apply><ci id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">…</ci><apply id="S3.E1.m1.4.4.4.4.3.3.3.cmml" xref="S3.E1.m1.4.4.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.4.3.3.3.1.cmml" xref="S3.E1.m1.4.4.4.4.3.3.3">subscript</csymbol><ci id="S3.E1.m1.4.4.4.4.3.3.3.2.cmml" xref="S3.E1.m1.4.4.4.4.3.3.3.2">𝐤</ci><ci id="S3.E1.m1.4.4.4.4.3.3.3.3.cmml" xref="S3.E1.m1.4.4.4.4.3.3.3.3">𝑇</ci></apply></list><ci id="S3.E1.m1.4.4.4.4.5.cmml" xref="S3.E1.m1.4.4.4.4.5">⊺</ci></apply></apply><apply id="S3.E1.m1.4.4.6.cmml" xref="S3.E1.m1.4.4.6"><root id="S3.E1.m1.4.4.6a.cmml" xref="S3.E1.m1.4.4.6"></root><ci id="S3.E1.m1.4.4.6.2.cmml" xref="S3.E1.m1.4.4.6.2">𝑑</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.5c">\displaystyle W=\mathtt{Softmax}(\frac{F_{TPrompt}\centerdot[\mathbf{k}_{1},\mathbf{k}_{2},...,\mathbf{k}_{T}]^{\intercal}}{\sqrt{d}}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS2.p3.14" class="ltx_p">where <math id="S3.SS2.p3.8.m1.1" class="ltx_Math" alttext="\mathbf{k}_{j}=\mathtt{Key}(F_{v}^{j})" display="inline"><semantics id="S3.SS2.p3.8.m1.1a"><mrow id="S3.SS2.p3.8.m1.1.1" xref="S3.SS2.p3.8.m1.1.1.cmml"><msub id="S3.SS2.p3.8.m1.1.1.3" xref="S3.SS2.p3.8.m1.1.1.3.cmml"><mi id="S3.SS2.p3.8.m1.1.1.3.2" xref="S3.SS2.p3.8.m1.1.1.3.2.cmml">𝐤</mi><mi id="S3.SS2.p3.8.m1.1.1.3.3" xref="S3.SS2.p3.8.m1.1.1.3.3.cmml">j</mi></msub><mo id="S3.SS2.p3.8.m1.1.1.2" xref="S3.SS2.p3.8.m1.1.1.2.cmml">=</mo><mrow id="S3.SS2.p3.8.m1.1.1.1" xref="S3.SS2.p3.8.m1.1.1.1.cmml"><mi id="S3.SS2.p3.8.m1.1.1.1.3" xref="S3.SS2.p3.8.m1.1.1.1.3.cmml">𝙺𝚎𝚢</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.8.m1.1.1.1.2" xref="S3.SS2.p3.8.m1.1.1.1.2.cmml">​</mo><mrow id="S3.SS2.p3.8.m1.1.1.1.1.1" xref="S3.SS2.p3.8.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p3.8.m1.1.1.1.1.1.2" xref="S3.SS2.p3.8.m1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S3.SS2.p3.8.m1.1.1.1.1.1.1" xref="S3.SS2.p3.8.m1.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.8.m1.1.1.1.1.1.1.2.2" xref="S3.SS2.p3.8.m1.1.1.1.1.1.1.2.2.cmml">F</mi><mi id="S3.SS2.p3.8.m1.1.1.1.1.1.1.2.3" xref="S3.SS2.p3.8.m1.1.1.1.1.1.1.2.3.cmml">v</mi><mi id="S3.SS2.p3.8.m1.1.1.1.1.1.1.3" xref="S3.SS2.p3.8.m1.1.1.1.1.1.1.3.cmml">j</mi></msubsup><mo stretchy="false" id="S3.SS2.p3.8.m1.1.1.1.1.1.3" xref="S3.SS2.p3.8.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m1.1b"><apply id="S3.SS2.p3.8.m1.1.1.cmml" xref="S3.SS2.p3.8.m1.1.1"><eq id="S3.SS2.p3.8.m1.1.1.2.cmml" xref="S3.SS2.p3.8.m1.1.1.2"></eq><apply id="S3.SS2.p3.8.m1.1.1.3.cmml" xref="S3.SS2.p3.8.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.8.m1.1.1.3.1.cmml" xref="S3.SS2.p3.8.m1.1.1.3">subscript</csymbol><ci id="S3.SS2.p3.8.m1.1.1.3.2.cmml" xref="S3.SS2.p3.8.m1.1.1.3.2">𝐤</ci><ci id="S3.SS2.p3.8.m1.1.1.3.3.cmml" xref="S3.SS2.p3.8.m1.1.1.3.3">𝑗</ci></apply><apply id="S3.SS2.p3.8.m1.1.1.1.cmml" xref="S3.SS2.p3.8.m1.1.1.1"><times id="S3.SS2.p3.8.m1.1.1.1.2.cmml" xref="S3.SS2.p3.8.m1.1.1.1.2"></times><ci id="S3.SS2.p3.8.m1.1.1.1.3.cmml" xref="S3.SS2.p3.8.m1.1.1.1.3">𝙺𝚎𝚢</ci><apply id="S3.SS2.p3.8.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.8.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.8.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.8.m1.1.1.1.1.1">superscript</csymbol><apply id="S3.SS2.p3.8.m1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.8.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.8.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p3.8.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.8.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p3.8.m1.1.1.1.1.1.1.2.2">𝐹</ci><ci id="S3.SS2.p3.8.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p3.8.m1.1.1.1.1.1.1.2.3">𝑣</ci></apply><ci id="S3.SS2.p3.8.m1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.8.m1.1.1.1.1.1.1.3">𝑗</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m1.1c">\mathbf{k}_{j}=\mathtt{Key}(F_{v}^{j})</annotation></semantics></math>, <math id="S3.SS2.p3.9.m2.4" class="ltx_Math" alttext="j\in\{1,2,...,T\}" display="inline"><semantics id="S3.SS2.p3.9.m2.4a"><mrow id="S3.SS2.p3.9.m2.4.5" xref="S3.SS2.p3.9.m2.4.5.cmml"><mi id="S3.SS2.p3.9.m2.4.5.2" xref="S3.SS2.p3.9.m2.4.5.2.cmml">j</mi><mo id="S3.SS2.p3.9.m2.4.5.1" xref="S3.SS2.p3.9.m2.4.5.1.cmml">∈</mo><mrow id="S3.SS2.p3.9.m2.4.5.3.2" xref="S3.SS2.p3.9.m2.4.5.3.1.cmml"><mo stretchy="false" id="S3.SS2.p3.9.m2.4.5.3.2.1" xref="S3.SS2.p3.9.m2.4.5.3.1.cmml">{</mo><mn id="S3.SS2.p3.9.m2.1.1" xref="S3.SS2.p3.9.m2.1.1.cmml">1</mn><mo id="S3.SS2.p3.9.m2.4.5.3.2.2" xref="S3.SS2.p3.9.m2.4.5.3.1.cmml">,</mo><mn id="S3.SS2.p3.9.m2.2.2" xref="S3.SS2.p3.9.m2.2.2.cmml">2</mn><mo id="S3.SS2.p3.9.m2.4.5.3.2.3" xref="S3.SS2.p3.9.m2.4.5.3.1.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.p3.9.m2.3.3" xref="S3.SS2.p3.9.m2.3.3.cmml">…</mi><mo id="S3.SS2.p3.9.m2.4.5.3.2.4" xref="S3.SS2.p3.9.m2.4.5.3.1.cmml">,</mo><mi id="S3.SS2.p3.9.m2.4.4" xref="S3.SS2.p3.9.m2.4.4.cmml">T</mi><mo stretchy="false" id="S3.SS2.p3.9.m2.4.5.3.2.5" xref="S3.SS2.p3.9.m2.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.9.m2.4b"><apply id="S3.SS2.p3.9.m2.4.5.cmml" xref="S3.SS2.p3.9.m2.4.5"><in id="S3.SS2.p3.9.m2.4.5.1.cmml" xref="S3.SS2.p3.9.m2.4.5.1"></in><ci id="S3.SS2.p3.9.m2.4.5.2.cmml" xref="S3.SS2.p3.9.m2.4.5.2">𝑗</ci><set id="S3.SS2.p3.9.m2.4.5.3.1.cmml" xref="S3.SS2.p3.9.m2.4.5.3.2"><cn type="integer" id="S3.SS2.p3.9.m2.1.1.cmml" xref="S3.SS2.p3.9.m2.1.1">1</cn><cn type="integer" id="S3.SS2.p3.9.m2.2.2.cmml" xref="S3.SS2.p3.9.m2.2.2">2</cn><ci id="S3.SS2.p3.9.m2.3.3.cmml" xref="S3.SS2.p3.9.m2.3.3">…</ci><ci id="S3.SS2.p3.9.m2.4.4.cmml" xref="S3.SS2.p3.9.m2.4.4">𝑇</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.9.m2.4c">j\in\{1,2,...,T\}</annotation></semantics></math>,
and <math id="S3.SS2.p3.10.m3.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS2.p3.10.m3.1a"><mi id="S3.SS2.p3.10.m3.1.1" xref="S3.SS2.p3.10.m3.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.10.m3.1b"><ci id="S3.SS2.p3.10.m3.1.1.cmml" xref="S3.SS2.p3.10.m3.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.10.m3.1c">d</annotation></semantics></math> is the dimensionality of the key vector.
Considering that the higher weight indicates a stronger correlation between the video content and <math id="S3.SS2.p3.11.m4.1" class="ltx_Math" alttext="\mathtt{TPrompt}" display="inline"><semantics id="S3.SS2.p3.11.m4.1a"><mi id="S3.SS2.p3.11.m4.1.1" xref="S3.SS2.p3.11.m4.1.1.cmml">𝚃𝙿𝚛𝚘𝚖𝚙𝚝</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.11.m4.1b"><ci id="S3.SS2.p3.11.m4.1.1.cmml" xref="S3.SS2.p3.11.m4.1.1">𝚃𝙿𝚛𝚘𝚖𝚙𝚝</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.11.m4.1c">\mathtt{TPrompt}</annotation></semantics></math>, we conduct <math id="S3.SS2.p3.12.m5.1" class="ltx_Math" alttext="Top_{k}" display="inline"><semantics id="S3.SS2.p3.12.m5.1a"><mrow id="S3.SS2.p3.12.m5.1.1" xref="S3.SS2.p3.12.m5.1.1.cmml"><mi id="S3.SS2.p3.12.m5.1.1.2" xref="S3.SS2.p3.12.m5.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.12.m5.1.1.1" xref="S3.SS2.p3.12.m5.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.12.m5.1.1.3" xref="S3.SS2.p3.12.m5.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.12.m5.1.1.1a" xref="S3.SS2.p3.12.m5.1.1.1.cmml">​</mo><msub id="S3.SS2.p3.12.m5.1.1.4" xref="S3.SS2.p3.12.m5.1.1.4.cmml"><mi id="S3.SS2.p3.12.m5.1.1.4.2" xref="S3.SS2.p3.12.m5.1.1.4.2.cmml">p</mi><mi id="S3.SS2.p3.12.m5.1.1.4.3" xref="S3.SS2.p3.12.m5.1.1.4.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.12.m5.1b"><apply id="S3.SS2.p3.12.m5.1.1.cmml" xref="S3.SS2.p3.12.m5.1.1"><times id="S3.SS2.p3.12.m5.1.1.1.cmml" xref="S3.SS2.p3.12.m5.1.1.1"></times><ci id="S3.SS2.p3.12.m5.1.1.2.cmml" xref="S3.SS2.p3.12.m5.1.1.2">𝑇</ci><ci id="S3.SS2.p3.12.m5.1.1.3.cmml" xref="S3.SS2.p3.12.m5.1.1.3">𝑜</ci><apply id="S3.SS2.p3.12.m5.1.1.4.cmml" xref="S3.SS2.p3.12.m5.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.p3.12.m5.1.1.4.1.cmml" xref="S3.SS2.p3.12.m5.1.1.4">subscript</csymbol><ci id="S3.SS2.p3.12.m5.1.1.4.2.cmml" xref="S3.SS2.p3.12.m5.1.1.4.2">𝑝</ci><ci id="S3.SS2.p3.12.m5.1.1.4.3.cmml" xref="S3.SS2.p3.12.m5.1.1.4.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.12.m5.1c">Top_{k}</annotation></semantics></math> feature selection over <math id="S3.SS2.p3.13.m6.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS2.p3.13.m6.1a"><mi id="S3.SS2.p3.13.m6.1.1" xref="S3.SS2.p3.13.m6.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.13.m6.1b"><ci id="S3.SS2.p3.13.m6.1.1.cmml" xref="S3.SS2.p3.13.m6.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.13.m6.1c">T</annotation></semantics></math> segments.
To be specific, we employ a temporal selection operation algorithm, denoted as <math id="S3.SS2.p3.14.m7.1" class="ltx_Math" alttext="\Psi" display="inline"><semantics id="S3.SS2.p3.14.m7.1a"><mi mathvariant="normal" id="S3.SS2.p3.14.m7.1.1" xref="S3.SS2.p3.14.m7.1.1.cmml">Ψ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.14.m7.1b"><ci id="S3.SS2.p3.14.m7.1.1.cmml" xref="S3.SS2.p3.14.m7.1.1">Ψ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.14.m7.1c">\Psi</annotation></semantics></math>, which is implemented by the sorted algorithm for ranking and sorting to pick out the crucial relevant segments with the highest attention weights and their corresponding indices:</p>
<table id="S5.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E2.m1.2" class="ltx_Math" alttext="\displaystyle F_{a}^{\prime},F_{v}^{\prime},\Omega_{TPM}=\Psi(F_{a},F_{v},W,Top_{k})," display="inline"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.3.3" xref="S3.E2.m1.2.2.1.1.3.4.cmml"><msubsup id="S3.E2.m1.2.2.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.2.2.cmml">F</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.2.3" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3.cmml">a</mi><mo id="S3.E2.m1.2.2.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.3.cmml">′</mo></msubsup><mo id="S3.E2.m1.2.2.1.1.3.3.4" xref="S3.E2.m1.2.2.1.1.3.4.cmml">,</mo><msubsup id="S3.E2.m1.2.2.1.1.2.2.2" xref="S3.E2.m1.2.2.1.1.2.2.2.cmml"><mi id="S3.E2.m1.2.2.1.1.2.2.2.2.2" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.cmml">F</mi><mi id="S3.E2.m1.2.2.1.1.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.2.2.2.2.3.cmml">v</mi><mo id="S3.E2.m1.2.2.1.1.2.2.2.3" xref="S3.E2.m1.2.2.1.1.2.2.2.3.cmml">′</mo></msubsup><mo id="S3.E2.m1.2.2.1.1.3.3.5" xref="S3.E2.m1.2.2.1.1.3.4.cmml">,</mo><msub id="S3.E2.m1.2.2.1.1.3.3.3" xref="S3.E2.m1.2.2.1.1.3.3.3.cmml"><mi mathvariant="normal" id="S3.E2.m1.2.2.1.1.3.3.3.2" xref="S3.E2.m1.2.2.1.1.3.3.3.2.cmml">Ω</mi><mrow id="S3.E2.m1.2.2.1.1.3.3.3.3" xref="S3.E2.m1.2.2.1.1.3.3.3.3.cmml"><mi id="S3.E2.m1.2.2.1.1.3.3.3.3.2" xref="S3.E2.m1.2.2.1.1.3.3.3.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.3.3.3.3.1" xref="S3.E2.m1.2.2.1.1.3.3.3.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.3.3.3.3.3" xref="S3.E2.m1.2.2.1.1.3.3.3.3.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.3.3.3.3.1a" xref="S3.E2.m1.2.2.1.1.3.3.3.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.3.3.3.3.4" xref="S3.E2.m1.2.2.1.1.3.3.3.3.4.cmml">M</mi></mrow></msub></mrow><mo id="S3.E2.m1.2.2.1.1.7" xref="S3.E2.m1.2.2.1.1.7.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1.6" xref="S3.E2.m1.2.2.1.1.6.cmml"><mi mathvariant="normal" id="S3.E2.m1.2.2.1.1.6.5" xref="S3.E2.m1.2.2.1.1.6.5.cmml">Ψ</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.6.4" xref="S3.E2.m1.2.2.1.1.6.4.cmml">​</mo><mrow id="S3.E2.m1.2.2.1.1.6.3.3" xref="S3.E2.m1.2.2.1.1.6.3.4.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.1.1.6.3.3.4" xref="S3.E2.m1.2.2.1.1.6.3.4.cmml">(</mo><msub id="S3.E2.m1.2.2.1.1.4.1.1.1" xref="S3.E2.m1.2.2.1.1.4.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.4.1.1.1.2" xref="S3.E2.m1.2.2.1.1.4.1.1.1.2.cmml">F</mi><mi id="S3.E2.m1.2.2.1.1.4.1.1.1.3" xref="S3.E2.m1.2.2.1.1.4.1.1.1.3.cmml">a</mi></msub><mo id="S3.E2.m1.2.2.1.1.6.3.3.5" xref="S3.E2.m1.2.2.1.1.6.3.4.cmml">,</mo><msub id="S3.E2.m1.2.2.1.1.5.2.2.2" xref="S3.E2.m1.2.2.1.1.5.2.2.2.cmml"><mi id="S3.E2.m1.2.2.1.1.5.2.2.2.2" xref="S3.E2.m1.2.2.1.1.5.2.2.2.2.cmml">F</mi><mi id="S3.E2.m1.2.2.1.1.5.2.2.2.3" xref="S3.E2.m1.2.2.1.1.5.2.2.2.3.cmml">v</mi></msub><mo id="S3.E2.m1.2.2.1.1.6.3.3.6" xref="S3.E2.m1.2.2.1.1.6.3.4.cmml">,</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">W</mi><mo id="S3.E2.m1.2.2.1.1.6.3.3.7" xref="S3.E2.m1.2.2.1.1.6.3.4.cmml">,</mo><mrow id="S3.E2.m1.2.2.1.1.6.3.3.3" xref="S3.E2.m1.2.2.1.1.6.3.3.3.cmml"><mi id="S3.E2.m1.2.2.1.1.6.3.3.3.2" xref="S3.E2.m1.2.2.1.1.6.3.3.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.6.3.3.3.1" xref="S3.E2.m1.2.2.1.1.6.3.3.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.6.3.3.3.3" xref="S3.E2.m1.2.2.1.1.6.3.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.6.3.3.3.1a" xref="S3.E2.m1.2.2.1.1.6.3.3.3.1.cmml">​</mo><msub id="S3.E2.m1.2.2.1.1.6.3.3.3.4" xref="S3.E2.m1.2.2.1.1.6.3.3.3.4.cmml"><mi id="S3.E2.m1.2.2.1.1.6.3.3.3.4.2" xref="S3.E2.m1.2.2.1.1.6.3.3.3.4.2.cmml">p</mi><mi id="S3.E2.m1.2.2.1.1.6.3.3.3.4.3" xref="S3.E2.m1.2.2.1.1.6.3.3.3.4.3.cmml">k</mi></msub></mrow><mo stretchy="false" id="S3.E2.m1.2.2.1.1.6.3.3.8" xref="S3.E2.m1.2.2.1.1.6.3.4.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.2.2.1.2" xref="S3.E2.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1"><eq id="S3.E2.m1.2.2.1.1.7.cmml" xref="S3.E2.m1.2.2.1.1.7"></eq><list id="S3.E2.m1.2.2.1.1.3.4.cmml" xref="S3.E2.m1.2.2.1.1.3.3"><apply id="S3.E2.m1.2.2.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1">superscript</csymbol><apply id="S3.E2.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.2">𝐹</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3">𝑎</ci></apply><ci id="S3.E2.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.3">′</ci></apply><apply id="S3.E2.m1.2.2.1.1.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2">superscript</csymbol><apply id="S3.E2.m1.2.2.1.1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2">𝐹</ci><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.3">𝑣</ci></apply><ci id="S3.E2.m1.2.2.1.1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3">′</ci></apply><apply id="S3.E2.m1.2.2.1.1.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3.3.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.3.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.3.3.3.2">Ω</ci><apply id="S3.E2.m1.2.2.1.1.3.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3.3.3"><times id="S3.E2.m1.2.2.1.1.3.3.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3.3.3.3.1"></times><ci id="S3.E2.m1.2.2.1.1.3.3.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.3.3.3.3.2">𝑇</ci><ci id="S3.E2.m1.2.2.1.1.3.3.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3.3.3.3">𝑃</ci><ci id="S3.E2.m1.2.2.1.1.3.3.3.3.4.cmml" xref="S3.E2.m1.2.2.1.1.3.3.3.3.4">𝑀</ci></apply></apply></list><apply id="S3.E2.m1.2.2.1.1.6.cmml" xref="S3.E2.m1.2.2.1.1.6"><times id="S3.E2.m1.2.2.1.1.6.4.cmml" xref="S3.E2.m1.2.2.1.1.6.4"></times><ci id="S3.E2.m1.2.2.1.1.6.5.cmml" xref="S3.E2.m1.2.2.1.1.6.5">Ψ</ci><vector id="S3.E2.m1.2.2.1.1.6.3.4.cmml" xref="S3.E2.m1.2.2.1.1.6.3.3"><apply id="S3.E2.m1.2.2.1.1.4.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.4.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.4.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.4.1.1.1">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.4.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.4.1.1.1.2">𝐹</ci><ci id="S3.E2.m1.2.2.1.1.4.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.4.1.1.1.3">𝑎</ci></apply><apply id="S3.E2.m1.2.2.1.1.5.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.5.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.5.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.5.2.2.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.5.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.5.2.2.2.2">𝐹</ci><ci id="S3.E2.m1.2.2.1.1.5.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.5.2.2.2.3">𝑣</ci></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">𝑊</ci><apply id="S3.E2.m1.2.2.1.1.6.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.6.3.3.3"><times id="S3.E2.m1.2.2.1.1.6.3.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.6.3.3.3.1"></times><ci id="S3.E2.m1.2.2.1.1.6.3.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.6.3.3.3.2">𝑇</ci><ci id="S3.E2.m1.2.2.1.1.6.3.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.6.3.3.3.3">𝑜</ci><apply id="S3.E2.m1.2.2.1.1.6.3.3.3.4.cmml" xref="S3.E2.m1.2.2.1.1.6.3.3.3.4"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.6.3.3.3.4.1.cmml" xref="S3.E2.m1.2.2.1.1.6.3.3.3.4">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.6.3.3.3.4.2.cmml" xref="S3.E2.m1.2.2.1.1.6.3.3.3.4.2">𝑝</ci><ci id="S3.E2.m1.2.2.1.1.6.3.3.3.4.3.cmml" xref="S3.E2.m1.2.2.1.1.6.3.3.3.4.3">𝑘</ci></apply></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">\displaystyle F_{a}^{\prime},F_{v}^{\prime},\Omega_{TPM}=\Psi(F_{a},F_{v},W,Top_{k}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS2.p3.22" class="ltx_p">where <math id="S3.SS2.p3.15.m1.1" class="ltx_Math" alttext="\Psi" display="inline"><semantics id="S3.SS2.p3.15.m1.1a"><mi mathvariant="normal" id="S3.SS2.p3.15.m1.1.1" xref="S3.SS2.p3.15.m1.1.1.cmml">Ψ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.15.m1.1b"><ci id="S3.SS2.p3.15.m1.1.1.cmml" xref="S3.SS2.p3.15.m1.1.1">Ψ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.15.m1.1c">\Psi</annotation></semantics></math> is a selection operation,
<math id="S3.SS2.p3.16.m2.1" class="ltx_Math" alttext="\Omega_{TPM}" display="inline"><semantics id="S3.SS2.p3.16.m2.1a"><msub id="S3.SS2.p3.16.m2.1.1" xref="S3.SS2.p3.16.m2.1.1.cmml"><mi mathvariant="normal" id="S3.SS2.p3.16.m2.1.1.2" xref="S3.SS2.p3.16.m2.1.1.2.cmml">Ω</mi><mrow id="S3.SS2.p3.16.m2.1.1.3" xref="S3.SS2.p3.16.m2.1.1.3.cmml"><mi id="S3.SS2.p3.16.m2.1.1.3.2" xref="S3.SS2.p3.16.m2.1.1.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.16.m2.1.1.3.1" xref="S3.SS2.p3.16.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.16.m2.1.1.3.3" xref="S3.SS2.p3.16.m2.1.1.3.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.16.m2.1.1.3.1a" xref="S3.SS2.p3.16.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.16.m2.1.1.3.4" xref="S3.SS2.p3.16.m2.1.1.3.4.cmml">M</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.16.m2.1b"><apply id="S3.SS2.p3.16.m2.1.1.cmml" xref="S3.SS2.p3.16.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.16.m2.1.1.1.cmml" xref="S3.SS2.p3.16.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.16.m2.1.1.2.cmml" xref="S3.SS2.p3.16.m2.1.1.2">Ω</ci><apply id="S3.SS2.p3.16.m2.1.1.3.cmml" xref="S3.SS2.p3.16.m2.1.1.3"><times id="S3.SS2.p3.16.m2.1.1.3.1.cmml" xref="S3.SS2.p3.16.m2.1.1.3.1"></times><ci id="S3.SS2.p3.16.m2.1.1.3.2.cmml" xref="S3.SS2.p3.16.m2.1.1.3.2">𝑇</ci><ci id="S3.SS2.p3.16.m2.1.1.3.3.cmml" xref="S3.SS2.p3.16.m2.1.1.3.3">𝑃</ci><ci id="S3.SS2.p3.16.m2.1.1.3.4.cmml" xref="S3.SS2.p3.16.m2.1.1.3.4">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.16.m2.1c">\Omega_{TPM}</annotation></semantics></math> is the index position corresponding to the <math id="S3.SS2.p3.17.m3.1" class="ltx_Math" alttext="Top_{k}" display="inline"><semantics id="S3.SS2.p3.17.m3.1a"><mrow id="S3.SS2.p3.17.m3.1.1" xref="S3.SS2.p3.17.m3.1.1.cmml"><mi id="S3.SS2.p3.17.m3.1.1.2" xref="S3.SS2.p3.17.m3.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.17.m3.1.1.1" xref="S3.SS2.p3.17.m3.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.17.m3.1.1.3" xref="S3.SS2.p3.17.m3.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.17.m3.1.1.1a" xref="S3.SS2.p3.17.m3.1.1.1.cmml">​</mo><msub id="S3.SS2.p3.17.m3.1.1.4" xref="S3.SS2.p3.17.m3.1.1.4.cmml"><mi id="S3.SS2.p3.17.m3.1.1.4.2" xref="S3.SS2.p3.17.m3.1.1.4.2.cmml">p</mi><mi id="S3.SS2.p3.17.m3.1.1.4.3" xref="S3.SS2.p3.17.m3.1.1.4.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.17.m3.1b"><apply id="S3.SS2.p3.17.m3.1.1.cmml" xref="S3.SS2.p3.17.m3.1.1"><times id="S3.SS2.p3.17.m3.1.1.1.cmml" xref="S3.SS2.p3.17.m3.1.1.1"></times><ci id="S3.SS2.p3.17.m3.1.1.2.cmml" xref="S3.SS2.p3.17.m3.1.1.2">𝑇</ci><ci id="S3.SS2.p3.17.m3.1.1.3.cmml" xref="S3.SS2.p3.17.m3.1.1.3">𝑜</ci><apply id="S3.SS2.p3.17.m3.1.1.4.cmml" xref="S3.SS2.p3.17.m3.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.p3.17.m3.1.1.4.1.cmml" xref="S3.SS2.p3.17.m3.1.1.4">subscript</csymbol><ci id="S3.SS2.p3.17.m3.1.1.4.2.cmml" xref="S3.SS2.p3.17.m3.1.1.4.2">𝑝</ci><ci id="S3.SS2.p3.17.m3.1.1.4.3.cmml" xref="S3.SS2.p3.17.m3.1.1.4.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.17.m3.1c">Top_{k}</annotation></semantics></math> highest weights, <math id="S3.SS2.p3.18.m4.4" class="ltx_Math" alttext="\Omega_{TPM}\in\{0,1,...,k-1\}^{Top_{k}}" display="inline"><semantics id="S3.SS2.p3.18.m4.4a"><mrow id="S3.SS2.p3.18.m4.4.4" xref="S3.SS2.p3.18.m4.4.4.cmml"><msub id="S3.SS2.p3.18.m4.4.4.3" xref="S3.SS2.p3.18.m4.4.4.3.cmml"><mi mathvariant="normal" id="S3.SS2.p3.18.m4.4.4.3.2" xref="S3.SS2.p3.18.m4.4.4.3.2.cmml">Ω</mi><mrow id="S3.SS2.p3.18.m4.4.4.3.3" xref="S3.SS2.p3.18.m4.4.4.3.3.cmml"><mi id="S3.SS2.p3.18.m4.4.4.3.3.2" xref="S3.SS2.p3.18.m4.4.4.3.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.18.m4.4.4.3.3.1" xref="S3.SS2.p3.18.m4.4.4.3.3.1.cmml">​</mo><mi id="S3.SS2.p3.18.m4.4.4.3.3.3" xref="S3.SS2.p3.18.m4.4.4.3.3.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.18.m4.4.4.3.3.1a" xref="S3.SS2.p3.18.m4.4.4.3.3.1.cmml">​</mo><mi id="S3.SS2.p3.18.m4.4.4.3.3.4" xref="S3.SS2.p3.18.m4.4.4.3.3.4.cmml">M</mi></mrow></msub><mo id="S3.SS2.p3.18.m4.4.4.2" xref="S3.SS2.p3.18.m4.4.4.2.cmml">∈</mo><msup id="S3.SS2.p3.18.m4.4.4.1" xref="S3.SS2.p3.18.m4.4.4.1.cmml"><mrow id="S3.SS2.p3.18.m4.4.4.1.1.1" xref="S3.SS2.p3.18.m4.4.4.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p3.18.m4.4.4.1.1.1.2" xref="S3.SS2.p3.18.m4.4.4.1.1.2.cmml">{</mo><mn id="S3.SS2.p3.18.m4.1.1" xref="S3.SS2.p3.18.m4.1.1.cmml">0</mn><mo id="S3.SS2.p3.18.m4.4.4.1.1.1.3" xref="S3.SS2.p3.18.m4.4.4.1.1.2.cmml">,</mo><mn id="S3.SS2.p3.18.m4.2.2" xref="S3.SS2.p3.18.m4.2.2.cmml">1</mn><mo id="S3.SS2.p3.18.m4.4.4.1.1.1.4" xref="S3.SS2.p3.18.m4.4.4.1.1.2.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.p3.18.m4.3.3" xref="S3.SS2.p3.18.m4.3.3.cmml">…</mi><mo id="S3.SS2.p3.18.m4.4.4.1.1.1.5" xref="S3.SS2.p3.18.m4.4.4.1.1.2.cmml">,</mo><mrow id="S3.SS2.p3.18.m4.4.4.1.1.1.1" xref="S3.SS2.p3.18.m4.4.4.1.1.1.1.cmml"><mi id="S3.SS2.p3.18.m4.4.4.1.1.1.1.2" xref="S3.SS2.p3.18.m4.4.4.1.1.1.1.2.cmml">k</mi><mo id="S3.SS2.p3.18.m4.4.4.1.1.1.1.1" xref="S3.SS2.p3.18.m4.4.4.1.1.1.1.1.cmml">−</mo><mn id="S3.SS2.p3.18.m4.4.4.1.1.1.1.3" xref="S3.SS2.p3.18.m4.4.4.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S3.SS2.p3.18.m4.4.4.1.1.1.6" xref="S3.SS2.p3.18.m4.4.4.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS2.p3.18.m4.4.4.1.3" xref="S3.SS2.p3.18.m4.4.4.1.3.cmml"><mi id="S3.SS2.p3.18.m4.4.4.1.3.2" xref="S3.SS2.p3.18.m4.4.4.1.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.18.m4.4.4.1.3.1" xref="S3.SS2.p3.18.m4.4.4.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.18.m4.4.4.1.3.3" xref="S3.SS2.p3.18.m4.4.4.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.18.m4.4.4.1.3.1a" xref="S3.SS2.p3.18.m4.4.4.1.3.1.cmml">​</mo><msub id="S3.SS2.p3.18.m4.4.4.1.3.4" xref="S3.SS2.p3.18.m4.4.4.1.3.4.cmml"><mi id="S3.SS2.p3.18.m4.4.4.1.3.4.2" xref="S3.SS2.p3.18.m4.4.4.1.3.4.2.cmml">p</mi><mi id="S3.SS2.p3.18.m4.4.4.1.3.4.3" xref="S3.SS2.p3.18.m4.4.4.1.3.4.3.cmml">k</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.18.m4.4b"><apply id="S3.SS2.p3.18.m4.4.4.cmml" xref="S3.SS2.p3.18.m4.4.4"><in id="S3.SS2.p3.18.m4.4.4.2.cmml" xref="S3.SS2.p3.18.m4.4.4.2"></in><apply id="S3.SS2.p3.18.m4.4.4.3.cmml" xref="S3.SS2.p3.18.m4.4.4.3"><csymbol cd="ambiguous" id="S3.SS2.p3.18.m4.4.4.3.1.cmml" xref="S3.SS2.p3.18.m4.4.4.3">subscript</csymbol><ci id="S3.SS2.p3.18.m4.4.4.3.2.cmml" xref="S3.SS2.p3.18.m4.4.4.3.2">Ω</ci><apply id="S3.SS2.p3.18.m4.4.4.3.3.cmml" xref="S3.SS2.p3.18.m4.4.4.3.3"><times id="S3.SS2.p3.18.m4.4.4.3.3.1.cmml" xref="S3.SS2.p3.18.m4.4.4.3.3.1"></times><ci id="S3.SS2.p3.18.m4.4.4.3.3.2.cmml" xref="S3.SS2.p3.18.m4.4.4.3.3.2">𝑇</ci><ci id="S3.SS2.p3.18.m4.4.4.3.3.3.cmml" xref="S3.SS2.p3.18.m4.4.4.3.3.3">𝑃</ci><ci id="S3.SS2.p3.18.m4.4.4.3.3.4.cmml" xref="S3.SS2.p3.18.m4.4.4.3.3.4">𝑀</ci></apply></apply><apply id="S3.SS2.p3.18.m4.4.4.1.cmml" xref="S3.SS2.p3.18.m4.4.4.1"><csymbol cd="ambiguous" id="S3.SS2.p3.18.m4.4.4.1.2.cmml" xref="S3.SS2.p3.18.m4.4.4.1">superscript</csymbol><set id="S3.SS2.p3.18.m4.4.4.1.1.2.cmml" xref="S3.SS2.p3.18.m4.4.4.1.1.1"><cn type="integer" id="S3.SS2.p3.18.m4.1.1.cmml" xref="S3.SS2.p3.18.m4.1.1">0</cn><cn type="integer" id="S3.SS2.p3.18.m4.2.2.cmml" xref="S3.SS2.p3.18.m4.2.2">1</cn><ci id="S3.SS2.p3.18.m4.3.3.cmml" xref="S3.SS2.p3.18.m4.3.3">…</ci><apply id="S3.SS2.p3.18.m4.4.4.1.1.1.1.cmml" xref="S3.SS2.p3.18.m4.4.4.1.1.1.1"><minus id="S3.SS2.p3.18.m4.4.4.1.1.1.1.1.cmml" xref="S3.SS2.p3.18.m4.4.4.1.1.1.1.1"></minus><ci id="S3.SS2.p3.18.m4.4.4.1.1.1.1.2.cmml" xref="S3.SS2.p3.18.m4.4.4.1.1.1.1.2">𝑘</ci><cn type="integer" id="S3.SS2.p3.18.m4.4.4.1.1.1.1.3.cmml" xref="S3.SS2.p3.18.m4.4.4.1.1.1.1.3">1</cn></apply></set><apply id="S3.SS2.p3.18.m4.4.4.1.3.cmml" xref="S3.SS2.p3.18.m4.4.4.1.3"><times id="S3.SS2.p3.18.m4.4.4.1.3.1.cmml" xref="S3.SS2.p3.18.m4.4.4.1.3.1"></times><ci id="S3.SS2.p3.18.m4.4.4.1.3.2.cmml" xref="S3.SS2.p3.18.m4.4.4.1.3.2">𝑇</ci><ci id="S3.SS2.p3.18.m4.4.4.1.3.3.cmml" xref="S3.SS2.p3.18.m4.4.4.1.3.3">𝑜</ci><apply id="S3.SS2.p3.18.m4.4.4.1.3.4.cmml" xref="S3.SS2.p3.18.m4.4.4.1.3.4"><csymbol cd="ambiguous" id="S3.SS2.p3.18.m4.4.4.1.3.4.1.cmml" xref="S3.SS2.p3.18.m4.4.4.1.3.4">subscript</csymbol><ci id="S3.SS2.p3.18.m4.4.4.1.3.4.2.cmml" xref="S3.SS2.p3.18.m4.4.4.1.3.4.2">𝑝</ci><ci id="S3.SS2.p3.18.m4.4.4.1.3.4.3.cmml" xref="S3.SS2.p3.18.m4.4.4.1.3.4.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.18.m4.4c">\Omega_{TPM}\in\{0,1,...,k-1\}^{Top_{k}}</annotation></semantics></math>, <math id="S3.SS2.p3.19.m5.2" class="ltx_Math" alttext="F_{a}^{\prime},F_{v}^{\prime}" display="inline"><semantics id="S3.SS2.p3.19.m5.2a"><mrow id="S3.SS2.p3.19.m5.2.2.2" xref="S3.SS2.p3.19.m5.2.2.3.cmml"><msubsup id="S3.SS2.p3.19.m5.1.1.1.1" xref="S3.SS2.p3.19.m5.1.1.1.1.cmml"><mi id="S3.SS2.p3.19.m5.1.1.1.1.2.2" xref="S3.SS2.p3.19.m5.1.1.1.1.2.2.cmml">F</mi><mi id="S3.SS2.p3.19.m5.1.1.1.1.2.3" xref="S3.SS2.p3.19.m5.1.1.1.1.2.3.cmml">a</mi><mo id="S3.SS2.p3.19.m5.1.1.1.1.3" xref="S3.SS2.p3.19.m5.1.1.1.1.3.cmml">′</mo></msubsup><mo id="S3.SS2.p3.19.m5.2.2.2.3" xref="S3.SS2.p3.19.m5.2.2.3.cmml">,</mo><msubsup id="S3.SS2.p3.19.m5.2.2.2.2" xref="S3.SS2.p3.19.m5.2.2.2.2.cmml"><mi id="S3.SS2.p3.19.m5.2.2.2.2.2.2" xref="S3.SS2.p3.19.m5.2.2.2.2.2.2.cmml">F</mi><mi id="S3.SS2.p3.19.m5.2.2.2.2.2.3" xref="S3.SS2.p3.19.m5.2.2.2.2.2.3.cmml">v</mi><mo id="S3.SS2.p3.19.m5.2.2.2.2.3" xref="S3.SS2.p3.19.m5.2.2.2.2.3.cmml">′</mo></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.19.m5.2b"><list id="S3.SS2.p3.19.m5.2.2.3.cmml" xref="S3.SS2.p3.19.m5.2.2.2"><apply id="S3.SS2.p3.19.m5.1.1.1.1.cmml" xref="S3.SS2.p3.19.m5.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.19.m5.1.1.1.1.1.cmml" xref="S3.SS2.p3.19.m5.1.1.1.1">superscript</csymbol><apply id="S3.SS2.p3.19.m5.1.1.1.1.2.cmml" xref="S3.SS2.p3.19.m5.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.19.m5.1.1.1.1.2.1.cmml" xref="S3.SS2.p3.19.m5.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.19.m5.1.1.1.1.2.2.cmml" xref="S3.SS2.p3.19.m5.1.1.1.1.2.2">𝐹</ci><ci id="S3.SS2.p3.19.m5.1.1.1.1.2.3.cmml" xref="S3.SS2.p3.19.m5.1.1.1.1.2.3">𝑎</ci></apply><ci id="S3.SS2.p3.19.m5.1.1.1.1.3.cmml" xref="S3.SS2.p3.19.m5.1.1.1.1.3">′</ci></apply><apply id="S3.SS2.p3.19.m5.2.2.2.2.cmml" xref="S3.SS2.p3.19.m5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.19.m5.2.2.2.2.1.cmml" xref="S3.SS2.p3.19.m5.2.2.2.2">superscript</csymbol><apply id="S3.SS2.p3.19.m5.2.2.2.2.2.cmml" xref="S3.SS2.p3.19.m5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.19.m5.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.19.m5.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.19.m5.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.19.m5.2.2.2.2.2.2">𝐹</ci><ci id="S3.SS2.p3.19.m5.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.19.m5.2.2.2.2.2.3">𝑣</ci></apply><ci id="S3.SS2.p3.19.m5.2.2.2.2.3.cmml" xref="S3.SS2.p3.19.m5.2.2.2.2.3">′</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.19.m5.2c">F_{a}^{\prime},F_{v}^{\prime}</annotation></semantics></math> is selected temporal feature, <math id="S3.SS2.p3.20.m6.2" class="ltx_Math" alttext="F_{a}^{\prime}\in\mathbb{R}^{Top_{k}\times D},F_{v}^{\prime}\in\mathbb{R}^{Top_{k}\times D}" display="inline"><semantics id="S3.SS2.p3.20.m6.2a"><mrow id="S3.SS2.p3.20.m6.2.2.2" xref="S3.SS2.p3.20.m6.2.2.3.cmml"><mrow id="S3.SS2.p3.20.m6.1.1.1.1" xref="S3.SS2.p3.20.m6.1.1.1.1.cmml"><msubsup id="S3.SS2.p3.20.m6.1.1.1.1.2" xref="S3.SS2.p3.20.m6.1.1.1.1.2.cmml"><mi id="S3.SS2.p3.20.m6.1.1.1.1.2.2.2" xref="S3.SS2.p3.20.m6.1.1.1.1.2.2.2.cmml">F</mi><mi id="S3.SS2.p3.20.m6.1.1.1.1.2.2.3" xref="S3.SS2.p3.20.m6.1.1.1.1.2.2.3.cmml">a</mi><mo id="S3.SS2.p3.20.m6.1.1.1.1.2.3" xref="S3.SS2.p3.20.m6.1.1.1.1.2.3.cmml">′</mo></msubsup><mo id="S3.SS2.p3.20.m6.1.1.1.1.1" xref="S3.SS2.p3.20.m6.1.1.1.1.1.cmml">∈</mo><msup id="S3.SS2.p3.20.m6.1.1.1.1.3" xref="S3.SS2.p3.20.m6.1.1.1.1.3.cmml"><mi id="S3.SS2.p3.20.m6.1.1.1.1.3.2" xref="S3.SS2.p3.20.m6.1.1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS2.p3.20.m6.1.1.1.1.3.3" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.cmml"><mrow id="S3.SS2.p3.20.m6.1.1.1.1.3.3.2" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.cmml"><mi id="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.2" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.1" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.1.cmml">​</mo><mi id="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.3" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.1a" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.1.cmml">​</mo><msub id="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.4" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.4.cmml"><mi id="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.4.2" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.4.2.cmml">p</mi><mi id="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.4.3" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.4.3.cmml">k</mi></msub></mrow><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.20.m6.1.1.1.1.3.3.1" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS2.p3.20.m6.1.1.1.1.3.3.3" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><mo id="S3.SS2.p3.20.m6.2.2.2.3" xref="S3.SS2.p3.20.m6.2.2.3a.cmml">,</mo><mrow id="S3.SS2.p3.20.m6.2.2.2.2" xref="S3.SS2.p3.20.m6.2.2.2.2.cmml"><msubsup id="S3.SS2.p3.20.m6.2.2.2.2.2" xref="S3.SS2.p3.20.m6.2.2.2.2.2.cmml"><mi id="S3.SS2.p3.20.m6.2.2.2.2.2.2.2" xref="S3.SS2.p3.20.m6.2.2.2.2.2.2.2.cmml">F</mi><mi id="S3.SS2.p3.20.m6.2.2.2.2.2.2.3" xref="S3.SS2.p3.20.m6.2.2.2.2.2.2.3.cmml">v</mi><mo id="S3.SS2.p3.20.m6.2.2.2.2.2.3" xref="S3.SS2.p3.20.m6.2.2.2.2.2.3.cmml">′</mo></msubsup><mo id="S3.SS2.p3.20.m6.2.2.2.2.1" xref="S3.SS2.p3.20.m6.2.2.2.2.1.cmml">∈</mo><msup id="S3.SS2.p3.20.m6.2.2.2.2.3" xref="S3.SS2.p3.20.m6.2.2.2.2.3.cmml"><mi id="S3.SS2.p3.20.m6.2.2.2.2.3.2" xref="S3.SS2.p3.20.m6.2.2.2.2.3.2.cmml">ℝ</mi><mrow id="S3.SS2.p3.20.m6.2.2.2.2.3.3" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.cmml"><mrow id="S3.SS2.p3.20.m6.2.2.2.2.3.3.2" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.cmml"><mi id="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.2" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.1" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.1.cmml">​</mo><mi id="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.3" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.1a" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.1.cmml">​</mo><msub id="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.4" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.4.cmml"><mi id="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.4.2" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.4.2.cmml">p</mi><mi id="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.4.3" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.4.3.cmml">k</mi></msub></mrow><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.20.m6.2.2.2.2.3.3.1" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.1.cmml">×</mo><mi id="S3.SS2.p3.20.m6.2.2.2.2.3.3.3" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.3.cmml">D</mi></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.20.m6.2b"><apply id="S3.SS2.p3.20.m6.2.2.3.cmml" xref="S3.SS2.p3.20.m6.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.20.m6.2.2.3a.cmml" xref="S3.SS2.p3.20.m6.2.2.2.3">formulae-sequence</csymbol><apply id="S3.SS2.p3.20.m6.1.1.1.1.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1"><in id="S3.SS2.p3.20.m6.1.1.1.1.1.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.1"></in><apply id="S3.SS2.p3.20.m6.1.1.1.1.2.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.20.m6.1.1.1.1.2.1.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.2">superscript</csymbol><apply id="S3.SS2.p3.20.m6.1.1.1.1.2.2.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.20.m6.1.1.1.1.2.2.1.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.2">subscript</csymbol><ci id="S3.SS2.p3.20.m6.1.1.1.1.2.2.2.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.2.2.2">𝐹</ci><ci id="S3.SS2.p3.20.m6.1.1.1.1.2.2.3.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.2.2.3">𝑎</ci></apply><ci id="S3.SS2.p3.20.m6.1.1.1.1.2.3.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.2.3">′</ci></apply><apply id="S3.SS2.p3.20.m6.1.1.1.1.3.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.20.m6.1.1.1.1.3.1.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.3">superscript</csymbol><ci id="S3.SS2.p3.20.m6.1.1.1.1.3.2.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.3.2">ℝ</ci><apply id="S3.SS2.p3.20.m6.1.1.1.1.3.3.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3"><times id="S3.SS2.p3.20.m6.1.1.1.1.3.3.1.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.1"></times><apply id="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.2"><times id="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.1.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.1"></times><ci id="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.2.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.2">𝑇</ci><ci id="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.3.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.3">𝑜</ci><apply id="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.4.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.4"><csymbol cd="ambiguous" id="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.4.1.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.4">subscript</csymbol><ci id="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.4.2.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.4.2">𝑝</ci><ci id="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.4.3.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.2.4.3">𝑘</ci></apply></apply><ci id="S3.SS2.p3.20.m6.1.1.1.1.3.3.3.cmml" xref="S3.SS2.p3.20.m6.1.1.1.1.3.3.3">𝐷</ci></apply></apply></apply><apply id="S3.SS2.p3.20.m6.2.2.2.2.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2"><in id="S3.SS2.p3.20.m6.2.2.2.2.1.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.1"></in><apply id="S3.SS2.p3.20.m6.2.2.2.2.2.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.20.m6.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.2">superscript</csymbol><apply id="S3.SS2.p3.20.m6.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.20.m6.2.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.20.m6.2.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.2.2.2">𝐹</ci><ci id="S3.SS2.p3.20.m6.2.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.2.2.3">𝑣</ci></apply><ci id="S3.SS2.p3.20.m6.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.2.3">′</ci></apply><apply id="S3.SS2.p3.20.m6.2.2.2.2.3.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS2.p3.20.m6.2.2.2.2.3.1.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.3">superscript</csymbol><ci id="S3.SS2.p3.20.m6.2.2.2.2.3.2.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.3.2">ℝ</ci><apply id="S3.SS2.p3.20.m6.2.2.2.2.3.3.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3"><times id="S3.SS2.p3.20.m6.2.2.2.2.3.3.1.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.1"></times><apply id="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.2"><times id="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.1.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.1"></times><ci id="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.2.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.2">𝑇</ci><ci id="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.3.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.3">𝑜</ci><apply id="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.4.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.4"><csymbol cd="ambiguous" id="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.4.1.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.4">subscript</csymbol><ci id="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.4.2.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.4.2">𝑝</ci><ci id="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.4.3.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.2.4.3">𝑘</ci></apply></apply><ci id="S3.SS2.p3.20.m6.2.2.2.2.3.3.3.cmml" xref="S3.SS2.p3.20.m6.2.2.2.2.3.3.3">𝐷</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.20.m6.2c">F_{a}^{\prime}\in\mathbb{R}^{Top_{k}\times D},F_{v}^{\prime}\in\mathbb{R}^{Top_{k}\times D}</annotation></semantics></math>.
Note that the <math id="S3.SS2.p3.21.m7.1" class="ltx_Math" alttext="Top_{k}" display="inline"><semantics id="S3.SS2.p3.21.m7.1a"><mrow id="S3.SS2.p3.21.m7.1.1" xref="S3.SS2.p3.21.m7.1.1.cmml"><mi id="S3.SS2.p3.21.m7.1.1.2" xref="S3.SS2.p3.21.m7.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.21.m7.1.1.1" xref="S3.SS2.p3.21.m7.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.21.m7.1.1.3" xref="S3.SS2.p3.21.m7.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.21.m7.1.1.1a" xref="S3.SS2.p3.21.m7.1.1.1.cmml">​</mo><msub id="S3.SS2.p3.21.m7.1.1.4" xref="S3.SS2.p3.21.m7.1.1.4.cmml"><mi id="S3.SS2.p3.21.m7.1.1.4.2" xref="S3.SS2.p3.21.m7.1.1.4.2.cmml">p</mi><mi id="S3.SS2.p3.21.m7.1.1.4.3" xref="S3.SS2.p3.21.m7.1.1.4.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.21.m7.1b"><apply id="S3.SS2.p3.21.m7.1.1.cmml" xref="S3.SS2.p3.21.m7.1.1"><times id="S3.SS2.p3.21.m7.1.1.1.cmml" xref="S3.SS2.p3.21.m7.1.1.1"></times><ci id="S3.SS2.p3.21.m7.1.1.2.cmml" xref="S3.SS2.p3.21.m7.1.1.2">𝑇</ci><ci id="S3.SS2.p3.21.m7.1.1.3.cmml" xref="S3.SS2.p3.21.m7.1.1.3">𝑜</ci><apply id="S3.SS2.p3.21.m7.1.1.4.cmml" xref="S3.SS2.p3.21.m7.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.p3.21.m7.1.1.4.1.cmml" xref="S3.SS2.p3.21.m7.1.1.4">subscript</csymbol><ci id="S3.SS2.p3.21.m7.1.1.4.2.cmml" xref="S3.SS2.p3.21.m7.1.1.4.2">𝑝</ci><ci id="S3.SS2.p3.21.m7.1.1.4.3.cmml" xref="S3.SS2.p3.21.m7.1.1.4.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.21.m7.1c">Top_{k}</annotation></semantics></math> temporal audio segments are corresponding to positions on the <math id="S3.SS2.p3.22.m8.1" class="ltx_Math" alttext="Top_{k}" display="inline"><semantics id="S3.SS2.p3.22.m8.1a"><mrow id="S3.SS2.p3.22.m8.1.1" xref="S3.SS2.p3.22.m8.1.1.cmml"><mi id="S3.SS2.p3.22.m8.1.1.2" xref="S3.SS2.p3.22.m8.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.22.m8.1.1.1" xref="S3.SS2.p3.22.m8.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.22.m8.1.1.3" xref="S3.SS2.p3.22.m8.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.22.m8.1.1.1a" xref="S3.SS2.p3.22.m8.1.1.1.cmml">​</mo><msub id="S3.SS2.p3.22.m8.1.1.4" xref="S3.SS2.p3.22.m8.1.1.4.cmml"><mi id="S3.SS2.p3.22.m8.1.1.4.2" xref="S3.SS2.p3.22.m8.1.1.4.2.cmml">p</mi><mi id="S3.SS2.p3.22.m8.1.1.4.3" xref="S3.SS2.p3.22.m8.1.1.4.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.22.m8.1b"><apply id="S3.SS2.p3.22.m8.1.1.cmml" xref="S3.SS2.p3.22.m8.1.1"><times id="S3.SS2.p3.22.m8.1.1.1.cmml" xref="S3.SS2.p3.22.m8.1.1.1"></times><ci id="S3.SS2.p3.22.m8.1.1.2.cmml" xref="S3.SS2.p3.22.m8.1.1.2">𝑇</ci><ci id="S3.SS2.p3.22.m8.1.1.3.cmml" xref="S3.SS2.p3.22.m8.1.1.3">𝑜</ci><apply id="S3.SS2.p3.22.m8.1.1.4.cmml" xref="S3.SS2.p3.22.m8.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.p3.22.m8.1.1.4.1.cmml" xref="S3.SS2.p3.22.m8.1.1.4">subscript</csymbol><ci id="S3.SS2.p3.22.m8.1.1.4.2.cmml" xref="S3.SS2.p3.22.m8.1.1.4.2">𝑝</ci><ci id="S3.SS2.p3.22.m8.1.1.4.3.cmml" xref="S3.SS2.p3.22.m8.1.1.4.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.22.m8.1c">Top_{k}</annotation></semantics></math> visual segments relevant to the question.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2407.20693/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="218" height="147" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Spatial Perception Module.
Similar tokens are merged.
For example, for a given complex scene, the man is playing flute if merged into a single token, and the woman is playing violin is merged into a single token.
Following this, the proposed model identifies the <span id="S3.F3.2.1" class="ltx_text ltx_font_italic">sounding</span> instrument, thus inferring the correct answer to the input question.
</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Spatial Perception Module</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">To identify visual regions that are pertinent to the key instrument, the <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_bold">S</span>patial <span id="S3.SS3.p1.1.2" class="ltx_text ltx_font_bold">P</span>erception <span id="S3.SS3.p1.1.3" class="ltx_text ltx_font_bold">M</span>odule (<span id="S3.SS3.p1.1.4" class="ltx_text ltx_font_bold">SPM</span>) is designed to merge visual tokens in selected temporal segments based on similarity, preserving their semantics, and subsequently engages in cross-modal interaction with audio to enhance audio-visual association.
Given previous works <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite> attempt to identify crucial regions by leveraging the semantics similarity between questions and visual tokens, the lack of semantic about objects within these tokens presents a challenge in establishing effective correlations with sound.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.2" class="ltx_p">To address this, we enhanced the preservation of semantic information in visual tokens along selected key temporal sequences. We achieve this by merging similar tokens within each visual frame, resulting in merged tokens that carry richer semantic information about objects.
Especially, given the visual token-level embedding <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="F_{p}" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><msub id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">F</mi><mi id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">𝐹</ci><ci id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">F_{p}</annotation></semantics></math> and <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="Top_{k}" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><mrow id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.2.m2.1.1.1" xref="S3.SS3.p2.2.m2.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.2.m2.1.1.1a" xref="S3.SS3.p2.2.m2.1.1.1.cmml">​</mo><msub id="S3.SS3.p2.2.m2.1.1.4" xref="S3.SS3.p2.2.m2.1.1.4.cmml"><mi id="S3.SS3.p2.2.m2.1.1.4.2" xref="S3.SS3.p2.2.m2.1.1.4.2.cmml">p</mi><mi id="S3.SS3.p2.2.m2.1.1.4.3" xref="S3.SS3.p2.2.m2.1.1.4.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><times id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1.1"></times><ci id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">𝑇</ci><ci id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3">𝑜</ci><apply id="S3.SS3.p2.2.m2.1.1.4.cmml" xref="S3.SS3.p2.2.m2.1.1.4"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.4.1.cmml" xref="S3.SS3.p2.2.m2.1.1.4">subscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.4.2.cmml" xref="S3.SS3.p2.2.m2.1.1.4.2">𝑝</ci><ci id="S3.SS3.p2.2.m2.1.1.4.3.cmml" xref="S3.SS3.p2.2.m2.1.1.4.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">Top_{k}</annotation></semantics></math> curious temporal segment index, we obtain the temporal visual token-level features as follows:</p>
<table id="S5.EGx3" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E3.m1.1" class="ltx_Math" alttext="\displaystyle F_{p}^{\prime}=\Phi(F_{p},\Omega_{TPM})," display="inline"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><msubsup id="S3.E3.m1.1.1.1.1.4" xref="S3.E3.m1.1.1.1.1.4.cmml"><mi id="S3.E3.m1.1.1.1.1.4.2.2" xref="S3.E3.m1.1.1.1.1.4.2.2.cmml">F</mi><mi id="S3.E3.m1.1.1.1.1.4.2.3" xref="S3.E3.m1.1.1.1.1.4.2.3.cmml">p</mi><mo id="S3.E3.m1.1.1.1.1.4.3" xref="S3.E3.m1.1.1.1.1.4.3.cmml">′</mo></msubsup><mo id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.cmml">=</mo><mrow id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.cmml"><mi mathvariant="normal" id="S3.E3.m1.1.1.1.1.2.4" xref="S3.E3.m1.1.1.1.1.2.4.cmml">Φ</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.2.3.cmml">​</mo><mrow id="S3.E3.m1.1.1.1.1.2.2.2" xref="S3.E3.m1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.2.2.2.3" xref="S3.E3.m1.1.1.1.1.2.2.3.cmml">(</mo><msub id="S3.E3.m1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml">F</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.cmml">p</mi></msub><mo id="S3.E3.m1.1.1.1.1.2.2.2.4" xref="S3.E3.m1.1.1.1.1.2.2.3.cmml">,</mo><msub id="S3.E3.m1.1.1.1.1.2.2.2.2" xref="S3.E3.m1.1.1.1.1.2.2.2.2.cmml"><mi mathvariant="normal" id="S3.E3.m1.1.1.1.1.2.2.2.2.2" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.cmml">Ω</mi><mrow id="S3.E3.m1.1.1.1.1.2.2.2.2.3" xref="S3.E3.m1.1.1.1.1.2.2.2.2.3.cmml"><mi id="S3.E3.m1.1.1.1.1.2.2.2.2.3.2" xref="S3.E3.m1.1.1.1.1.2.2.2.2.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.2.2.2.2.3.1" xref="S3.E3.m1.1.1.1.1.2.2.2.2.3.1.cmml">​</mo><mi id="S3.E3.m1.1.1.1.1.2.2.2.2.3.3" xref="S3.E3.m1.1.1.1.1.2.2.2.2.3.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.2.2.2.2.3.1a" xref="S3.E3.m1.1.1.1.1.2.2.2.2.3.1.cmml">​</mo><mi id="S3.E3.m1.1.1.1.1.2.2.2.2.3.4" xref="S3.E3.m1.1.1.1.1.2.2.2.2.3.4.cmml">M</mi></mrow></msub><mo stretchy="false" id="S3.E3.m1.1.1.1.1.2.2.2.5" xref="S3.E3.m1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><eq id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3"></eq><apply id="S3.E3.m1.1.1.1.1.4.cmml" xref="S3.E3.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.4.1.cmml" xref="S3.E3.m1.1.1.1.1.4">superscript</csymbol><apply id="S3.E3.m1.1.1.1.1.4.2.cmml" xref="S3.E3.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.4.2.1.cmml" xref="S3.E3.m1.1.1.1.1.4">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.4.2.2.cmml" xref="S3.E3.m1.1.1.1.1.4.2.2">𝐹</ci><ci id="S3.E3.m1.1.1.1.1.4.2.3.cmml" xref="S3.E3.m1.1.1.1.1.4.2.3">𝑝</ci></apply><ci id="S3.E3.m1.1.1.1.1.4.3.cmml" xref="S3.E3.m1.1.1.1.1.4.3">′</ci></apply><apply id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2"><times id="S3.E3.m1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.3"></times><ci id="S3.E3.m1.1.1.1.1.2.4.cmml" xref="S3.E3.m1.1.1.1.1.2.4">Φ</ci><interval closure="open" id="S3.E3.m1.1.1.1.1.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2"><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2">𝐹</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3">𝑝</ci></apply><apply id="S3.E3.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2">Ω</ci><apply id="S3.E3.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.3"><times id="S3.E3.m1.1.1.1.1.2.2.2.2.3.1.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.3.1"></times><ci id="S3.E3.m1.1.1.1.1.2.2.2.2.3.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.3.2">𝑇</ci><ci id="S3.E3.m1.1.1.1.1.2.2.2.2.3.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.3.3">𝑃</ci><ci id="S3.E3.m1.1.1.1.1.2.2.2.2.3.4.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.3.4">𝑀</ci></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\displaystyle F_{p}^{\prime}=\Phi(F_{p},\Omega_{TPM}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.9" class="ltx_p">where <math id="S3.SS3.p2.3.m1.1" class="ltx_Math" alttext="F_{p}^{\prime}\in\mathbb{R}^{Top_{k}\times M\times D}" display="inline"><semantics id="S3.SS3.p2.3.m1.1a"><mrow id="S3.SS3.p2.3.m1.1.1" xref="S3.SS3.p2.3.m1.1.1.cmml"><msubsup id="S3.SS3.p2.3.m1.1.1.2" xref="S3.SS3.p2.3.m1.1.1.2.cmml"><mi id="S3.SS3.p2.3.m1.1.1.2.2.2" xref="S3.SS3.p2.3.m1.1.1.2.2.2.cmml">F</mi><mi id="S3.SS3.p2.3.m1.1.1.2.2.3" xref="S3.SS3.p2.3.m1.1.1.2.2.3.cmml">p</mi><mo id="S3.SS3.p2.3.m1.1.1.2.3" xref="S3.SS3.p2.3.m1.1.1.2.3.cmml">′</mo></msubsup><mo id="S3.SS3.p2.3.m1.1.1.1" xref="S3.SS3.p2.3.m1.1.1.1.cmml">∈</mo><msup id="S3.SS3.p2.3.m1.1.1.3" xref="S3.SS3.p2.3.m1.1.1.3.cmml"><mi id="S3.SS3.p2.3.m1.1.1.3.2" xref="S3.SS3.p2.3.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.p2.3.m1.1.1.3.3" xref="S3.SS3.p2.3.m1.1.1.3.3.cmml"><mrow id="S3.SS3.p2.3.m1.1.1.3.3.2" xref="S3.SS3.p2.3.m1.1.1.3.3.2.cmml"><mi id="S3.SS3.p2.3.m1.1.1.3.3.2.2" xref="S3.SS3.p2.3.m1.1.1.3.3.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.3.m1.1.1.3.3.2.1" xref="S3.SS3.p2.3.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S3.SS3.p2.3.m1.1.1.3.3.2.3" xref="S3.SS3.p2.3.m1.1.1.3.3.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.3.m1.1.1.3.3.2.1a" xref="S3.SS3.p2.3.m1.1.1.3.3.2.1.cmml">​</mo><msub id="S3.SS3.p2.3.m1.1.1.3.3.2.4" xref="S3.SS3.p2.3.m1.1.1.3.3.2.4.cmml"><mi id="S3.SS3.p2.3.m1.1.1.3.3.2.4.2" xref="S3.SS3.p2.3.m1.1.1.3.3.2.4.2.cmml">p</mi><mi id="S3.SS3.p2.3.m1.1.1.3.3.2.4.3" xref="S3.SS3.p2.3.m1.1.1.3.3.2.4.3.cmml">k</mi></msub></mrow><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.3.m1.1.1.3.3.1" xref="S3.SS3.p2.3.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.p2.3.m1.1.1.3.3.3" xref="S3.SS3.p2.3.m1.1.1.3.3.3.cmml">M</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.3.m1.1.1.3.3.1a" xref="S3.SS3.p2.3.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.p2.3.m1.1.1.3.3.4" xref="S3.SS3.p2.3.m1.1.1.3.3.4.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m1.1b"><apply id="S3.SS3.p2.3.m1.1.1.cmml" xref="S3.SS3.p2.3.m1.1.1"><in id="S3.SS3.p2.3.m1.1.1.1.cmml" xref="S3.SS3.p2.3.m1.1.1.1"></in><apply id="S3.SS3.p2.3.m1.1.1.2.cmml" xref="S3.SS3.p2.3.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m1.1.1.2.1.cmml" xref="S3.SS3.p2.3.m1.1.1.2">superscript</csymbol><apply id="S3.SS3.p2.3.m1.1.1.2.2.cmml" xref="S3.SS3.p2.3.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m1.1.1.2.2.1.cmml" xref="S3.SS3.p2.3.m1.1.1.2">subscript</csymbol><ci id="S3.SS3.p2.3.m1.1.1.2.2.2.cmml" xref="S3.SS3.p2.3.m1.1.1.2.2.2">𝐹</ci><ci id="S3.SS3.p2.3.m1.1.1.2.2.3.cmml" xref="S3.SS3.p2.3.m1.1.1.2.2.3">𝑝</ci></apply><ci id="S3.SS3.p2.3.m1.1.1.2.3.cmml" xref="S3.SS3.p2.3.m1.1.1.2.3">′</ci></apply><apply id="S3.SS3.p2.3.m1.1.1.3.cmml" xref="S3.SS3.p2.3.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m1.1.1.3.1.cmml" xref="S3.SS3.p2.3.m1.1.1.3">superscript</csymbol><ci id="S3.SS3.p2.3.m1.1.1.3.2.cmml" xref="S3.SS3.p2.3.m1.1.1.3.2">ℝ</ci><apply id="S3.SS3.p2.3.m1.1.1.3.3.cmml" xref="S3.SS3.p2.3.m1.1.1.3.3"><times id="S3.SS3.p2.3.m1.1.1.3.3.1.cmml" xref="S3.SS3.p2.3.m1.1.1.3.3.1"></times><apply id="S3.SS3.p2.3.m1.1.1.3.3.2.cmml" xref="S3.SS3.p2.3.m1.1.1.3.3.2"><times id="S3.SS3.p2.3.m1.1.1.3.3.2.1.cmml" xref="S3.SS3.p2.3.m1.1.1.3.3.2.1"></times><ci id="S3.SS3.p2.3.m1.1.1.3.3.2.2.cmml" xref="S3.SS3.p2.3.m1.1.1.3.3.2.2">𝑇</ci><ci id="S3.SS3.p2.3.m1.1.1.3.3.2.3.cmml" xref="S3.SS3.p2.3.m1.1.1.3.3.2.3">𝑜</ci><apply id="S3.SS3.p2.3.m1.1.1.3.3.2.4.cmml" xref="S3.SS3.p2.3.m1.1.1.3.3.2.4"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m1.1.1.3.3.2.4.1.cmml" xref="S3.SS3.p2.3.m1.1.1.3.3.2.4">subscript</csymbol><ci id="S3.SS3.p2.3.m1.1.1.3.3.2.4.2.cmml" xref="S3.SS3.p2.3.m1.1.1.3.3.2.4.2">𝑝</ci><ci id="S3.SS3.p2.3.m1.1.1.3.3.2.4.3.cmml" xref="S3.SS3.p2.3.m1.1.1.3.3.2.4.3">𝑘</ci></apply></apply><ci id="S3.SS3.p2.3.m1.1.1.3.3.3.cmml" xref="S3.SS3.p2.3.m1.1.1.3.3.3">𝑀</ci><ci id="S3.SS3.p2.3.m1.1.1.3.3.4.cmml" xref="S3.SS3.p2.3.m1.1.1.3.3.4">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m1.1c">F_{p}^{\prime}\in\mathbb{R}^{Top_{k}\times M\times D}</annotation></semantics></math>, and
<math id="S3.SS3.p2.4.m2.1" class="ltx_Math" alttext="\Phi" display="inline"><semantics id="S3.SS3.p2.4.m2.1a"><mi mathvariant="normal" id="S3.SS3.p2.4.m2.1.1" xref="S3.SS3.p2.4.m2.1.1.cmml">Φ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m2.1b"><ci id="S3.SS3.p2.4.m2.1.1.cmml" xref="S3.SS3.p2.4.m2.1.1">Φ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m2.1c">\Phi</annotation></semantics></math> represents an operation aimed at selecting relevant visual token-level features <math id="S3.SS3.p2.5.m3.1" class="ltx_Math" alttext="F_{p}" display="inline"><semantics id="S3.SS3.p2.5.m3.1a"><msub id="S3.SS3.p2.5.m3.1.1" xref="S3.SS3.p2.5.m3.1.1.cmml"><mi id="S3.SS3.p2.5.m3.1.1.2" xref="S3.SS3.p2.5.m3.1.1.2.cmml">F</mi><mi id="S3.SS3.p2.5.m3.1.1.3" xref="S3.SS3.p2.5.m3.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m3.1b"><apply id="S3.SS3.p2.5.m3.1.1.cmml" xref="S3.SS3.p2.5.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.5.m3.1.1.1.cmml" xref="S3.SS3.p2.5.m3.1.1">subscript</csymbol><ci id="S3.SS3.p2.5.m3.1.1.2.cmml" xref="S3.SS3.p2.5.m3.1.1.2">𝐹</ci><ci id="S3.SS3.p2.5.m3.1.1.3.cmml" xref="S3.SS3.p2.5.m3.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m3.1c">F_{p}</annotation></semantics></math> based on the <math id="S3.SS3.p2.6.m4.1" class="ltx_Math" alttext="Top_{k}" display="inline"><semantics id="S3.SS3.p2.6.m4.1a"><mrow id="S3.SS3.p2.6.m4.1.1" xref="S3.SS3.p2.6.m4.1.1.cmml"><mi id="S3.SS3.p2.6.m4.1.1.2" xref="S3.SS3.p2.6.m4.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.6.m4.1.1.1" xref="S3.SS3.p2.6.m4.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.6.m4.1.1.3" xref="S3.SS3.p2.6.m4.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.6.m4.1.1.1a" xref="S3.SS3.p2.6.m4.1.1.1.cmml">​</mo><msub id="S3.SS3.p2.6.m4.1.1.4" xref="S3.SS3.p2.6.m4.1.1.4.cmml"><mi id="S3.SS3.p2.6.m4.1.1.4.2" xref="S3.SS3.p2.6.m4.1.1.4.2.cmml">p</mi><mi id="S3.SS3.p2.6.m4.1.1.4.3" xref="S3.SS3.p2.6.m4.1.1.4.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m4.1b"><apply id="S3.SS3.p2.6.m4.1.1.cmml" xref="S3.SS3.p2.6.m4.1.1"><times id="S3.SS3.p2.6.m4.1.1.1.cmml" xref="S3.SS3.p2.6.m4.1.1.1"></times><ci id="S3.SS3.p2.6.m4.1.1.2.cmml" xref="S3.SS3.p2.6.m4.1.1.2">𝑇</ci><ci id="S3.SS3.p2.6.m4.1.1.3.cmml" xref="S3.SS3.p2.6.m4.1.1.3">𝑜</ci><apply id="S3.SS3.p2.6.m4.1.1.4.cmml" xref="S3.SS3.p2.6.m4.1.1.4"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m4.1.1.4.1.cmml" xref="S3.SS3.p2.6.m4.1.1.4">subscript</csymbol><ci id="S3.SS3.p2.6.m4.1.1.4.2.cmml" xref="S3.SS3.p2.6.m4.1.1.4.2">𝑝</ci><ci id="S3.SS3.p2.6.m4.1.1.4.3.cmml" xref="S3.SS3.p2.6.m4.1.1.4.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m4.1c">Top_{k}</annotation></semantics></math> indices <math id="S3.SS3.p2.7.m5.1" class="ltx_Math" alttext="\Omega_{TPM}" display="inline"><semantics id="S3.SS3.p2.7.m5.1a"><msub id="S3.SS3.p2.7.m5.1.1" xref="S3.SS3.p2.7.m5.1.1.cmml"><mi mathvariant="normal" id="S3.SS3.p2.7.m5.1.1.2" xref="S3.SS3.p2.7.m5.1.1.2.cmml">Ω</mi><mrow id="S3.SS3.p2.7.m5.1.1.3" xref="S3.SS3.p2.7.m5.1.1.3.cmml"><mi id="S3.SS3.p2.7.m5.1.1.3.2" xref="S3.SS3.p2.7.m5.1.1.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.7.m5.1.1.3.1" xref="S3.SS3.p2.7.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.7.m5.1.1.3.3" xref="S3.SS3.p2.7.m5.1.1.3.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.7.m5.1.1.3.1a" xref="S3.SS3.p2.7.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.7.m5.1.1.3.4" xref="S3.SS3.p2.7.m5.1.1.3.4.cmml">M</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m5.1b"><apply id="S3.SS3.p2.7.m5.1.1.cmml" xref="S3.SS3.p2.7.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.7.m5.1.1.1.cmml" xref="S3.SS3.p2.7.m5.1.1">subscript</csymbol><ci id="S3.SS3.p2.7.m5.1.1.2.cmml" xref="S3.SS3.p2.7.m5.1.1.2">Ω</ci><apply id="S3.SS3.p2.7.m5.1.1.3.cmml" xref="S3.SS3.p2.7.m5.1.1.3"><times id="S3.SS3.p2.7.m5.1.1.3.1.cmml" xref="S3.SS3.p2.7.m5.1.1.3.1"></times><ci id="S3.SS3.p2.7.m5.1.1.3.2.cmml" xref="S3.SS3.p2.7.m5.1.1.3.2">𝑇</ci><ci id="S3.SS3.p2.7.m5.1.1.3.3.cmml" xref="S3.SS3.p2.7.m5.1.1.3.3">𝑃</ci><ci id="S3.SS3.p2.7.m5.1.1.3.4.cmml" xref="S3.SS3.p2.7.m5.1.1.3.4">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m5.1c">\Omega_{TPM}</annotation></semantics></math>, to serve as the visual input for the SPM.
Inspired by ToMe <cite class="ltx_cite ltx_citemacro_citep">(Bolya et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2022</a>)</cite>,
for the given selected visual token-level feature <math id="S3.SS3.p2.8.m6.1" class="ltx_Math" alttext="F_{p}^{\prime}" display="inline"><semantics id="S3.SS3.p2.8.m6.1a"><msubsup id="S3.SS3.p2.8.m6.1.1" xref="S3.SS3.p2.8.m6.1.1.cmml"><mi id="S3.SS3.p2.8.m6.1.1.2.2" xref="S3.SS3.p2.8.m6.1.1.2.2.cmml">F</mi><mi id="S3.SS3.p2.8.m6.1.1.2.3" xref="S3.SS3.p2.8.m6.1.1.2.3.cmml">p</mi><mo id="S3.SS3.p2.8.m6.1.1.3" xref="S3.SS3.p2.8.m6.1.1.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m6.1b"><apply id="S3.SS3.p2.8.m6.1.1.cmml" xref="S3.SS3.p2.8.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.8.m6.1.1.1.cmml" xref="S3.SS3.p2.8.m6.1.1">superscript</csymbol><apply id="S3.SS3.p2.8.m6.1.1.2.cmml" xref="S3.SS3.p2.8.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.8.m6.1.1.2.1.cmml" xref="S3.SS3.p2.8.m6.1.1">subscript</csymbol><ci id="S3.SS3.p2.8.m6.1.1.2.2.cmml" xref="S3.SS3.p2.8.m6.1.1.2.2">𝐹</ci><ci id="S3.SS3.p2.8.m6.1.1.2.3.cmml" xref="S3.SS3.p2.8.m6.1.1.2.3">𝑝</ci></apply><ci id="S3.SS3.p2.8.m6.1.1.3.cmml" xref="S3.SS3.p2.8.m6.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m6.1c">F_{p}^{\prime}</annotation></semantics></math>, we employ a token-merging strategy to enhance the semantic features between the attention and MLP branches of each transformer block.
Then, similar tokens are merged in each transformer block per layer, and the merged visual token-level feature <math id="S3.SS3.p2.9.m7.1" class="ltx_Math" alttext="\hat{F_{p}}" display="inline"><semantics id="S3.SS3.p2.9.m7.1a"><mover accent="true" id="S3.SS3.p2.9.m7.1.1" xref="S3.SS3.p2.9.m7.1.1.cmml"><msub id="S3.SS3.p2.9.m7.1.1.2" xref="S3.SS3.p2.9.m7.1.1.2.cmml"><mi id="S3.SS3.p2.9.m7.1.1.2.2" xref="S3.SS3.p2.9.m7.1.1.2.2.cmml">F</mi><mi id="S3.SS3.p2.9.m7.1.1.2.3" xref="S3.SS3.p2.9.m7.1.1.2.3.cmml">p</mi></msub><mo id="S3.SS3.p2.9.m7.1.1.1" xref="S3.SS3.p2.9.m7.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.9.m7.1b"><apply id="S3.SS3.p2.9.m7.1.1.cmml" xref="S3.SS3.p2.9.m7.1.1"><ci id="S3.SS3.p2.9.m7.1.1.1.cmml" xref="S3.SS3.p2.9.m7.1.1.1">^</ci><apply id="S3.SS3.p2.9.m7.1.1.2.cmml" xref="S3.SS3.p2.9.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.9.m7.1.1.2.1.cmml" xref="S3.SS3.p2.9.m7.1.1.2">subscript</csymbol><ci id="S3.SS3.p2.9.m7.1.1.2.2.cmml" xref="S3.SS3.p2.9.m7.1.1.2.2">𝐹</ci><ci id="S3.SS3.p2.9.m7.1.1.2.3.cmml" xref="S3.SS3.p2.9.m7.1.1.2.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.9.m7.1c">\hat{F_{p}}</annotation></semantics></math> as:</p>
<table id="S5.EGx4" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(4)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E4.m1.1" class="ltx_Math" alttext="\displaystyle\hat{F_{p}}=\mathbf{Merge}(F_{p}^{\prime})," display="inline"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mover accent="true" id="S3.E4.m1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.3.cmml"><msub id="S3.E4.m1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.3.2.cmml"><mi id="S3.E4.m1.1.1.1.1.3.2.2" xref="S3.E4.m1.1.1.1.1.3.2.2.cmml">F</mi><mi id="S3.E4.m1.1.1.1.1.3.2.3" xref="S3.E4.m1.1.1.1.1.3.2.3.cmml">p</mi></msub><mo id="S3.E4.m1.1.1.1.1.3.1" xref="S3.E4.m1.1.1.1.1.3.1.cmml">^</mo></mover><mo id="S3.E4.m1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.3.cmml">𝐌𝐞𝐫𝐠𝐞</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S3.E4.m1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.2.cmml">F</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.3.cmml">p</mi><mo id="S3.E4.m1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml">′</mo></msubsup><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><eq id="S3.E4.m1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2"></eq><apply id="S3.E4.m1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.3"><ci id="S3.E4.m1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.1">^</ci><apply id="S3.E4.m1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.2.1.cmml" xref="S3.E4.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.2.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2.2">𝐹</ci><ci id="S3.E4.m1.1.1.1.1.3.2.3.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3">𝑝</ci></apply></apply><apply id="S3.E4.m1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1"><times id="S3.E4.m1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.2"></times><ci id="S3.E4.m1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.3">𝐌𝐞𝐫𝐠𝐞</ci><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.2">𝐹</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.3">𝑝</ci></apply><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3">′</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">\displaystyle\hat{F_{p}}=\mathbf{Merge}(F_{p}^{\prime}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.22" class="ltx_p">where <math id="S3.SS3.p2.10.m1.4" class="ltx_Math" alttext="\hat{F}_{p}=\{\hat{f_{p}^{1}},\hat{f_{p}^{2}},...,\hat{f_{p}^{\lambda}}\}" display="inline"><semantics id="S3.SS3.p2.10.m1.4a"><mrow id="S3.SS3.p2.10.m1.4.5" xref="S3.SS3.p2.10.m1.4.5.cmml"><msub id="S3.SS3.p2.10.m1.4.5.2" xref="S3.SS3.p2.10.m1.4.5.2.cmml"><mover accent="true" id="S3.SS3.p2.10.m1.4.5.2.2" xref="S3.SS3.p2.10.m1.4.5.2.2.cmml"><mi id="S3.SS3.p2.10.m1.4.5.2.2.2" xref="S3.SS3.p2.10.m1.4.5.2.2.2.cmml">F</mi><mo id="S3.SS3.p2.10.m1.4.5.2.2.1" xref="S3.SS3.p2.10.m1.4.5.2.2.1.cmml">^</mo></mover><mi id="S3.SS3.p2.10.m1.4.5.2.3" xref="S3.SS3.p2.10.m1.4.5.2.3.cmml">p</mi></msub><mo id="S3.SS3.p2.10.m1.4.5.1" xref="S3.SS3.p2.10.m1.4.5.1.cmml">=</mo><mrow id="S3.SS3.p2.10.m1.4.5.3.2" xref="S3.SS3.p2.10.m1.4.5.3.1.cmml"><mo stretchy="false" id="S3.SS3.p2.10.m1.4.5.3.2.1" xref="S3.SS3.p2.10.m1.4.5.3.1.cmml">{</mo><mover accent="true" id="S3.SS3.p2.10.m1.1.1" xref="S3.SS3.p2.10.m1.1.1.cmml"><msubsup id="S3.SS3.p2.10.m1.1.1.2" xref="S3.SS3.p2.10.m1.1.1.2.cmml"><mi id="S3.SS3.p2.10.m1.1.1.2.2.2" xref="S3.SS3.p2.10.m1.1.1.2.2.2.cmml">f</mi><mi id="S3.SS3.p2.10.m1.1.1.2.2.3" xref="S3.SS3.p2.10.m1.1.1.2.2.3.cmml">p</mi><mn id="S3.SS3.p2.10.m1.1.1.2.3" xref="S3.SS3.p2.10.m1.1.1.2.3.cmml">1</mn></msubsup><mo id="S3.SS3.p2.10.m1.1.1.1" xref="S3.SS3.p2.10.m1.1.1.1.cmml">^</mo></mover><mo id="S3.SS3.p2.10.m1.4.5.3.2.2" xref="S3.SS3.p2.10.m1.4.5.3.1.cmml">,</mo><mover accent="true" id="S3.SS3.p2.10.m1.2.2" xref="S3.SS3.p2.10.m1.2.2.cmml"><msubsup id="S3.SS3.p2.10.m1.2.2.2" xref="S3.SS3.p2.10.m1.2.2.2.cmml"><mi id="S3.SS3.p2.10.m1.2.2.2.2.2" xref="S3.SS3.p2.10.m1.2.2.2.2.2.cmml">f</mi><mi id="S3.SS3.p2.10.m1.2.2.2.2.3" xref="S3.SS3.p2.10.m1.2.2.2.2.3.cmml">p</mi><mn id="S3.SS3.p2.10.m1.2.2.2.3" xref="S3.SS3.p2.10.m1.2.2.2.3.cmml">2</mn></msubsup><mo id="S3.SS3.p2.10.m1.2.2.1" xref="S3.SS3.p2.10.m1.2.2.1.cmml">^</mo></mover><mo id="S3.SS3.p2.10.m1.4.5.3.2.3" xref="S3.SS3.p2.10.m1.4.5.3.1.cmml">,</mo><mi mathvariant="normal" id="S3.SS3.p2.10.m1.3.3" xref="S3.SS3.p2.10.m1.3.3.cmml">…</mi><mo id="S3.SS3.p2.10.m1.4.5.3.2.4" xref="S3.SS3.p2.10.m1.4.5.3.1.cmml">,</mo><mover accent="true" id="S3.SS3.p2.10.m1.4.4" xref="S3.SS3.p2.10.m1.4.4.cmml"><msubsup id="S3.SS3.p2.10.m1.4.4.2" xref="S3.SS3.p2.10.m1.4.4.2.cmml"><mi id="S3.SS3.p2.10.m1.4.4.2.2.2" xref="S3.SS3.p2.10.m1.4.4.2.2.2.cmml">f</mi><mi id="S3.SS3.p2.10.m1.4.4.2.2.3" xref="S3.SS3.p2.10.m1.4.4.2.2.3.cmml">p</mi><mi id="S3.SS3.p2.10.m1.4.4.2.3" xref="S3.SS3.p2.10.m1.4.4.2.3.cmml">λ</mi></msubsup><mo id="S3.SS3.p2.10.m1.4.4.1" xref="S3.SS3.p2.10.m1.4.4.1.cmml">^</mo></mover><mo stretchy="false" id="S3.SS3.p2.10.m1.4.5.3.2.5" xref="S3.SS3.p2.10.m1.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.10.m1.4b"><apply id="S3.SS3.p2.10.m1.4.5.cmml" xref="S3.SS3.p2.10.m1.4.5"><eq id="S3.SS3.p2.10.m1.4.5.1.cmml" xref="S3.SS3.p2.10.m1.4.5.1"></eq><apply id="S3.SS3.p2.10.m1.4.5.2.cmml" xref="S3.SS3.p2.10.m1.4.5.2"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m1.4.5.2.1.cmml" xref="S3.SS3.p2.10.m1.4.5.2">subscript</csymbol><apply id="S3.SS3.p2.10.m1.4.5.2.2.cmml" xref="S3.SS3.p2.10.m1.4.5.2.2"><ci id="S3.SS3.p2.10.m1.4.5.2.2.1.cmml" xref="S3.SS3.p2.10.m1.4.5.2.2.1">^</ci><ci id="S3.SS3.p2.10.m1.4.5.2.2.2.cmml" xref="S3.SS3.p2.10.m1.4.5.2.2.2">𝐹</ci></apply><ci id="S3.SS3.p2.10.m1.4.5.2.3.cmml" xref="S3.SS3.p2.10.m1.4.5.2.3">𝑝</ci></apply><set id="S3.SS3.p2.10.m1.4.5.3.1.cmml" xref="S3.SS3.p2.10.m1.4.5.3.2"><apply id="S3.SS3.p2.10.m1.1.1.cmml" xref="S3.SS3.p2.10.m1.1.1"><ci id="S3.SS3.p2.10.m1.1.1.1.cmml" xref="S3.SS3.p2.10.m1.1.1.1">^</ci><apply id="S3.SS3.p2.10.m1.1.1.2.cmml" xref="S3.SS3.p2.10.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m1.1.1.2.1.cmml" xref="S3.SS3.p2.10.m1.1.1.2">superscript</csymbol><apply id="S3.SS3.p2.10.m1.1.1.2.2.cmml" xref="S3.SS3.p2.10.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m1.1.1.2.2.1.cmml" xref="S3.SS3.p2.10.m1.1.1.2">subscript</csymbol><ci id="S3.SS3.p2.10.m1.1.1.2.2.2.cmml" xref="S3.SS3.p2.10.m1.1.1.2.2.2">𝑓</ci><ci id="S3.SS3.p2.10.m1.1.1.2.2.3.cmml" xref="S3.SS3.p2.10.m1.1.1.2.2.3">𝑝</ci></apply><cn type="integer" id="S3.SS3.p2.10.m1.1.1.2.3.cmml" xref="S3.SS3.p2.10.m1.1.1.2.3">1</cn></apply></apply><apply id="S3.SS3.p2.10.m1.2.2.cmml" xref="S3.SS3.p2.10.m1.2.2"><ci id="S3.SS3.p2.10.m1.2.2.1.cmml" xref="S3.SS3.p2.10.m1.2.2.1">^</ci><apply id="S3.SS3.p2.10.m1.2.2.2.cmml" xref="S3.SS3.p2.10.m1.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m1.2.2.2.1.cmml" xref="S3.SS3.p2.10.m1.2.2.2">superscript</csymbol><apply id="S3.SS3.p2.10.m1.2.2.2.2.cmml" xref="S3.SS3.p2.10.m1.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m1.2.2.2.2.1.cmml" xref="S3.SS3.p2.10.m1.2.2.2">subscript</csymbol><ci id="S3.SS3.p2.10.m1.2.2.2.2.2.cmml" xref="S3.SS3.p2.10.m1.2.2.2.2.2">𝑓</ci><ci id="S3.SS3.p2.10.m1.2.2.2.2.3.cmml" xref="S3.SS3.p2.10.m1.2.2.2.2.3">𝑝</ci></apply><cn type="integer" id="S3.SS3.p2.10.m1.2.2.2.3.cmml" xref="S3.SS3.p2.10.m1.2.2.2.3">2</cn></apply></apply><ci id="S3.SS3.p2.10.m1.3.3.cmml" xref="S3.SS3.p2.10.m1.3.3">…</ci><apply id="S3.SS3.p2.10.m1.4.4.cmml" xref="S3.SS3.p2.10.m1.4.4"><ci id="S3.SS3.p2.10.m1.4.4.1.cmml" xref="S3.SS3.p2.10.m1.4.4.1">^</ci><apply id="S3.SS3.p2.10.m1.4.4.2.cmml" xref="S3.SS3.p2.10.m1.4.4.2"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m1.4.4.2.1.cmml" xref="S3.SS3.p2.10.m1.4.4.2">superscript</csymbol><apply id="S3.SS3.p2.10.m1.4.4.2.2.cmml" xref="S3.SS3.p2.10.m1.4.4.2"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m1.4.4.2.2.1.cmml" xref="S3.SS3.p2.10.m1.4.4.2">subscript</csymbol><ci id="S3.SS3.p2.10.m1.4.4.2.2.2.cmml" xref="S3.SS3.p2.10.m1.4.4.2.2.2">𝑓</ci><ci id="S3.SS3.p2.10.m1.4.4.2.2.3.cmml" xref="S3.SS3.p2.10.m1.4.4.2.2.3">𝑝</ci></apply><ci id="S3.SS3.p2.10.m1.4.4.2.3.cmml" xref="S3.SS3.p2.10.m1.4.4.2.3">𝜆</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.10.m1.4c">\hat{F}_{p}=\{\hat{f_{p}^{1}},\hat{f_{p}^{2}},...,\hat{f_{p}^{\lambda}}\}</annotation></semantics></math>, <math id="S3.SS3.p2.11.m2.1" class="ltx_Math" alttext="\hat{F_{p}}\in\mathbb{R}^{\lambda\times S\times D}" display="inline"><semantics id="S3.SS3.p2.11.m2.1a"><mrow id="S3.SS3.p2.11.m2.1.1" xref="S3.SS3.p2.11.m2.1.1.cmml"><mover accent="true" id="S3.SS3.p2.11.m2.1.1.2" xref="S3.SS3.p2.11.m2.1.1.2.cmml"><msub id="S3.SS3.p2.11.m2.1.1.2.2" xref="S3.SS3.p2.11.m2.1.1.2.2.cmml"><mi id="S3.SS3.p2.11.m2.1.1.2.2.2" xref="S3.SS3.p2.11.m2.1.1.2.2.2.cmml">F</mi><mi id="S3.SS3.p2.11.m2.1.1.2.2.3" xref="S3.SS3.p2.11.m2.1.1.2.2.3.cmml">p</mi></msub><mo id="S3.SS3.p2.11.m2.1.1.2.1" xref="S3.SS3.p2.11.m2.1.1.2.1.cmml">^</mo></mover><mo id="S3.SS3.p2.11.m2.1.1.1" xref="S3.SS3.p2.11.m2.1.1.1.cmml">∈</mo><msup id="S3.SS3.p2.11.m2.1.1.3" xref="S3.SS3.p2.11.m2.1.1.3.cmml"><mi id="S3.SS3.p2.11.m2.1.1.3.2" xref="S3.SS3.p2.11.m2.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.p2.11.m2.1.1.3.3" xref="S3.SS3.p2.11.m2.1.1.3.3.cmml"><mi id="S3.SS3.p2.11.m2.1.1.3.3.2" xref="S3.SS3.p2.11.m2.1.1.3.3.2.cmml">λ</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.11.m2.1.1.3.3.1" xref="S3.SS3.p2.11.m2.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.p2.11.m2.1.1.3.3.3" xref="S3.SS3.p2.11.m2.1.1.3.3.3.cmml">S</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.11.m2.1.1.3.3.1a" xref="S3.SS3.p2.11.m2.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.p2.11.m2.1.1.3.3.4" xref="S3.SS3.p2.11.m2.1.1.3.3.4.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.11.m2.1b"><apply id="S3.SS3.p2.11.m2.1.1.cmml" xref="S3.SS3.p2.11.m2.1.1"><in id="S3.SS3.p2.11.m2.1.1.1.cmml" xref="S3.SS3.p2.11.m2.1.1.1"></in><apply id="S3.SS3.p2.11.m2.1.1.2.cmml" xref="S3.SS3.p2.11.m2.1.1.2"><ci id="S3.SS3.p2.11.m2.1.1.2.1.cmml" xref="S3.SS3.p2.11.m2.1.1.2.1">^</ci><apply id="S3.SS3.p2.11.m2.1.1.2.2.cmml" xref="S3.SS3.p2.11.m2.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS3.p2.11.m2.1.1.2.2.1.cmml" xref="S3.SS3.p2.11.m2.1.1.2.2">subscript</csymbol><ci id="S3.SS3.p2.11.m2.1.1.2.2.2.cmml" xref="S3.SS3.p2.11.m2.1.1.2.2.2">𝐹</ci><ci id="S3.SS3.p2.11.m2.1.1.2.2.3.cmml" xref="S3.SS3.p2.11.m2.1.1.2.2.3">𝑝</ci></apply></apply><apply id="S3.SS3.p2.11.m2.1.1.3.cmml" xref="S3.SS3.p2.11.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p2.11.m2.1.1.3.1.cmml" xref="S3.SS3.p2.11.m2.1.1.3">superscript</csymbol><ci id="S3.SS3.p2.11.m2.1.1.3.2.cmml" xref="S3.SS3.p2.11.m2.1.1.3.2">ℝ</ci><apply id="S3.SS3.p2.11.m2.1.1.3.3.cmml" xref="S3.SS3.p2.11.m2.1.1.3.3"><times id="S3.SS3.p2.11.m2.1.1.3.3.1.cmml" xref="S3.SS3.p2.11.m2.1.1.3.3.1"></times><ci id="S3.SS3.p2.11.m2.1.1.3.3.2.cmml" xref="S3.SS3.p2.11.m2.1.1.3.3.2">𝜆</ci><ci id="S3.SS3.p2.11.m2.1.1.3.3.3.cmml" xref="S3.SS3.p2.11.m2.1.1.3.3.3">𝑆</ci><ci id="S3.SS3.p2.11.m2.1.1.3.3.4.cmml" xref="S3.SS3.p2.11.m2.1.1.3.3.4">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.11.m2.1c">\hat{F_{p}}\in\mathbb{R}^{\lambda\times S\times D}</annotation></semantics></math> and <math id="S3.SS3.p2.12.m3.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS3.p2.12.m3.1a"><mi id="S3.SS3.p2.12.m3.1.1" xref="S3.SS3.p2.12.m3.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.12.m3.1b"><ci id="S3.SS3.p2.12.m3.1.1.cmml" xref="S3.SS3.p2.12.m3.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.12.m3.1c">\lambda</annotation></semantics></math> is selected temporal segments’ moment, <math id="S3.SS3.p2.13.m4.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS3.p2.13.m4.1a"><mi id="S3.SS3.p2.13.m4.1.1" xref="S3.SS3.p2.13.m4.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.13.m4.1b"><ci id="S3.SS3.p2.13.m4.1.1.cmml" xref="S3.SS3.p2.13.m4.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.13.m4.1c">S</annotation></semantics></math> is merged tokens number.
Specifically, as shown in Fig. <a href="#S3.F3" title="Figure 3 ‣ 3.2. Temporal Perception Module ‣ 3. Method ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, evenly divide the <math id="S3.SS3.p2.14.m5.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS3.p2.14.m5.1a"><mi id="S3.SS3.p2.14.m5.1.1" xref="S3.SS3.p2.14.m5.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.14.m5.1b"><ci id="S3.SS3.p2.14.m5.1.1.cmml" xref="S3.SS3.p2.14.m5.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.14.m5.1c">M</annotation></semantics></math> tokens in <math id="S3.SS3.p2.15.m6.1" class="ltx_Math" alttext="F_{p}^{\prime}" display="inline"><semantics id="S3.SS3.p2.15.m6.1a"><msubsup id="S3.SS3.p2.15.m6.1.1" xref="S3.SS3.p2.15.m6.1.1.cmml"><mi id="S3.SS3.p2.15.m6.1.1.2.2" xref="S3.SS3.p2.15.m6.1.1.2.2.cmml">F</mi><mi id="S3.SS3.p2.15.m6.1.1.2.3" xref="S3.SS3.p2.15.m6.1.1.2.3.cmml">p</mi><mo id="S3.SS3.p2.15.m6.1.1.3" xref="S3.SS3.p2.15.m6.1.1.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.15.m6.1b"><apply id="S3.SS3.p2.15.m6.1.1.cmml" xref="S3.SS3.p2.15.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.15.m6.1.1.1.cmml" xref="S3.SS3.p2.15.m6.1.1">superscript</csymbol><apply id="S3.SS3.p2.15.m6.1.1.2.cmml" xref="S3.SS3.p2.15.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.15.m6.1.1.2.1.cmml" xref="S3.SS3.p2.15.m6.1.1">subscript</csymbol><ci id="S3.SS3.p2.15.m6.1.1.2.2.cmml" xref="S3.SS3.p2.15.m6.1.1.2.2">𝐹</ci><ci id="S3.SS3.p2.15.m6.1.1.2.3.cmml" xref="S3.SS3.p2.15.m6.1.1.2.3">𝑝</ci></apply><ci id="S3.SS3.p2.15.m6.1.1.3.cmml" xref="S3.SS3.p2.15.m6.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.15.m6.1c">F_{p}^{\prime}</annotation></semantics></math> into two subsets <math id="S3.SS3.p2.16.m7.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS3.p2.16.m7.1a"><mi id="S3.SS3.p2.16.m7.1.1" xref="S3.SS3.p2.16.m7.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.16.m7.1b"><ci id="S3.SS3.p2.16.m7.1.1.cmml" xref="S3.SS3.p2.16.m7.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.16.m7.1c">A</annotation></semantics></math> and <math id="S3.SS3.p2.17.m8.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S3.SS3.p2.17.m8.1a"><mi id="S3.SS3.p2.17.m8.1.1" xref="S3.SS3.p2.17.m8.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.17.m8.1b"><ci id="S3.SS3.p2.17.m8.1.1.cmml" xref="S3.SS3.p2.17.m8.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.17.m8.1c">B</annotation></semantics></math> of roughly equal size in <span id="S3.SS3.p2.22.1" class="ltx_text ltx_font_italic">Step 1</span>.
Then, for one subset <math id="S3.SS3.p2.18.m9.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS3.p2.18.m9.1a"><mi id="S3.SS3.p2.18.m9.1.1" xref="S3.SS3.p2.18.m9.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.18.m9.1b"><ci id="S3.SS3.p2.18.m9.1.1.cmml" xref="S3.SS3.p2.18.m9.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.18.m9.1c">A</annotation></semantics></math>, calculate the similarity between each token and every token in the other subset <math id="S3.SS3.p2.19.m10.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S3.SS3.p2.19.m10.1a"><mi id="S3.SS3.p2.19.m10.1.1" xref="S3.SS3.p2.19.m10.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.19.m10.1b"><ci id="S3.SS3.p2.19.m10.1.1.cmml" xref="S3.SS3.p2.19.m10.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.19.m10.1c">B</annotation></semantics></math>, drawing an edge for each calculated similarity.
Subsequently, apply mean fusion to the tokens connected by the similar edges.
And in <span id="S3.SS3.p2.22.2" class="ltx_text ltx_font_italic">Step 2</span>, concatenating the two subsets to generate a merged visual token-level feature <math id="S3.SS3.p2.20.m11.1" class="ltx_Math" alttext="\hat{F_{p}}" display="inline"><semantics id="S3.SS3.p2.20.m11.1a"><mover accent="true" id="S3.SS3.p2.20.m11.1.1" xref="S3.SS3.p2.20.m11.1.1.cmml"><msub id="S3.SS3.p2.20.m11.1.1.2" xref="S3.SS3.p2.20.m11.1.1.2.cmml"><mi id="S3.SS3.p2.20.m11.1.1.2.2" xref="S3.SS3.p2.20.m11.1.1.2.2.cmml">F</mi><mi id="S3.SS3.p2.20.m11.1.1.2.3" xref="S3.SS3.p2.20.m11.1.1.2.3.cmml">p</mi></msub><mo id="S3.SS3.p2.20.m11.1.1.1" xref="S3.SS3.p2.20.m11.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.20.m11.1b"><apply id="S3.SS3.p2.20.m11.1.1.cmml" xref="S3.SS3.p2.20.m11.1.1"><ci id="S3.SS3.p2.20.m11.1.1.1.cmml" xref="S3.SS3.p2.20.m11.1.1.1">^</ci><apply id="S3.SS3.p2.20.m11.1.1.2.cmml" xref="S3.SS3.p2.20.m11.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.20.m11.1.1.2.1.cmml" xref="S3.SS3.p2.20.m11.1.1.2">subscript</csymbol><ci id="S3.SS3.p2.20.m11.1.1.2.2.cmml" xref="S3.SS3.p2.20.m11.1.1.2.2">𝐹</ci><ci id="S3.SS3.p2.20.m11.1.1.2.3.cmml" xref="S3.SS3.p2.20.m11.1.1.2.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.20.m11.1c">\hat{F_{p}}</annotation></semantics></math>.
It’s worth noting that between each transformer block’s attention branch and MLP branch, <span id="S3.SS3.p2.22.3" class="ltx_text ltx_font_italic">Step 1</span> through <span id="S3.SS3.p2.22.4" class="ltx_text ltx_font_italic">Step 3</span> of the visual token merging process is executed, resulting in the creation of multiple merged tokens sequences with semantic representations.
During the merge process, all tokens are divided into two sets <math id="S3.SS3.p2.21.m12.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS3.p2.21.m12.1a"><mi id="S3.SS3.p2.21.m12.1.1" xref="S3.SS3.p2.21.m12.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.21.m12.1b"><ci id="S3.SS3.p2.21.m12.1.1.cmml" xref="S3.SS3.p2.21.m12.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.21.m12.1c">A</annotation></semantics></math> and <math id="S3.SS3.p2.22.m13.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S3.SS3.p2.22.m13.1a"><mi id="S3.SS3.p2.22.m13.1.1" xref="S3.SS3.p2.22.m13.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.22.m13.1b"><ci id="S3.SS3.p2.22.m13.1.1.cmml" xref="S3.SS3.p2.22.m13.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.22.m13.1c">B</annotation></semantics></math> based on their odd and even positions. Given this way, the position embedding merely serves as an odd-even indicator, having a negligible impact on the final merging outcome.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.2" class="ltx_p">Then, considering that the sound and the location of its visual source usually reflect the spatial association between audio and visual modality,
we leverage the powerful cross-modal perception ability to interact between selected visual merged token-level features and audio embeddings <math id="S3.SS3.p3.1.m1.2" class="ltx_Math" alttext="\hat{F_{p}},F_{a}^{\prime}" display="inline"><semantics id="S3.SS3.p3.1.m1.2a"><mrow id="S3.SS3.p3.1.m1.2.2.1" xref="S3.SS3.p3.1.m1.2.2.2.cmml"><mover accent="true" id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><msub id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2.2" xref="S3.SS3.p3.1.m1.1.1.2.2.cmml">F</mi><mi id="S3.SS3.p3.1.m1.1.1.2.3" xref="S3.SS3.p3.1.m1.1.1.2.3.cmml">p</mi></msub><mo id="S3.SS3.p3.1.m1.1.1.1" xref="S3.SS3.p3.1.m1.1.1.1.cmml">^</mo></mover><mo id="S3.SS3.p3.1.m1.2.2.1.2" xref="S3.SS3.p3.1.m1.2.2.2.cmml">,</mo><msubsup id="S3.SS3.p3.1.m1.2.2.1.1" xref="S3.SS3.p3.1.m1.2.2.1.1.cmml"><mi id="S3.SS3.p3.1.m1.2.2.1.1.2.2" xref="S3.SS3.p3.1.m1.2.2.1.1.2.2.cmml">F</mi><mi id="S3.SS3.p3.1.m1.2.2.1.1.2.3" xref="S3.SS3.p3.1.m1.2.2.1.1.2.3.cmml">a</mi><mo id="S3.SS3.p3.1.m1.2.2.1.1.3" xref="S3.SS3.p3.1.m1.2.2.1.1.3.cmml">′</mo></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.2b"><list id="S3.SS3.p3.1.m1.2.2.2.cmml" xref="S3.SS3.p3.1.m1.2.2.1"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><ci id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1">^</ci><apply id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.2.1.cmml" xref="S3.SS3.p3.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2.2">𝐹</ci><ci id="S3.SS3.p3.1.m1.1.1.2.3.cmml" xref="S3.SS3.p3.1.m1.1.1.2.3">𝑝</ci></apply></apply><apply id="S3.SS3.p3.1.m1.2.2.1.1.cmml" xref="S3.SS3.p3.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.2.2.1.1.1.cmml" xref="S3.SS3.p3.1.m1.2.2.1.1">superscript</csymbol><apply id="S3.SS3.p3.1.m1.2.2.1.1.2.cmml" xref="S3.SS3.p3.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.2.2.1.1.2.1.cmml" xref="S3.SS3.p3.1.m1.2.2.1.1">subscript</csymbol><ci id="S3.SS3.p3.1.m1.2.2.1.1.2.2.cmml" xref="S3.SS3.p3.1.m1.2.2.1.1.2.2">𝐹</ci><ci id="S3.SS3.p3.1.m1.2.2.1.1.2.3.cmml" xref="S3.SS3.p3.1.m1.2.2.1.1.2.3">𝑎</ci></apply><ci id="S3.SS3.p3.1.m1.2.2.1.1.3.cmml" xref="S3.SS3.p3.1.m1.2.2.1.1.3">′</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.2c">\hat{F_{p}},F_{a}^{\prime}</annotation></semantics></math>.
This enables concrete audio-visual correlation which performs attention-based patch-level merged tokens sound source perception.
Denote <math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="\mathtt{Attn}(\cdot)" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><mrow id="S3.SS3.p3.2.m2.1.2" xref="S3.SS3.p3.2.m2.1.2.cmml"><mi id="S3.SS3.p3.2.m2.1.2.2" xref="S3.SS3.p3.2.m2.1.2.2.cmml">𝙰𝚝𝚝𝚗</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.2.m2.1.2.1" xref="S3.SS3.p3.2.m2.1.2.1.cmml">​</mo><mrow id="S3.SS3.p3.2.m2.1.2.3.2" xref="S3.SS3.p3.2.m2.1.2.cmml"><mo stretchy="false" id="S3.SS3.p3.2.m2.1.2.3.2.1" xref="S3.SS3.p3.2.m2.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml">⋅</mo><mo stretchy="false" id="S3.SS3.p3.2.m2.1.2.3.2.2" xref="S3.SS3.p3.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.2.cmml" xref="S3.SS3.p3.2.m2.1.2"><times id="S3.SS3.p3.2.m2.1.2.1.cmml" xref="S3.SS3.p3.2.m2.1.2.1"></times><ci id="S3.SS3.p3.2.m2.1.2.2.cmml" xref="S3.SS3.p3.2.m2.1.2.2">𝙰𝚝𝚝𝚗</ci><ci id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">\mathtt{Attn}(\cdot)</annotation></semantics></math> to be the scaled dot-product conducted on the query, keys, and values, the aggregated feature can be obtained by:</p>
<table id="S5.EGx5" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(5)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E5.m1.2" class="ltx_Math" alttext="\displaystyle\overline{F}_{v}=\hat{f_{p}^{\lambda}}+\mathtt{Attn}(\hat{f_{p}^{\lambda}},\hat{F}_{p},\hat{F}_{p})+\mathtt{Attn}(f_{a}^{\lambda},\hat{F}_{p},\hat{F}_{p})," display="inline"><semantics id="S3.E5.m1.2a"><mrow id="S3.E5.m1.2.2.1" xref="S3.E5.m1.2.2.1.1.cmml"><mrow id="S3.E5.m1.2.2.1.1" xref="S3.E5.m1.2.2.1.1.cmml"><msub id="S3.E5.m1.2.2.1.1.7" xref="S3.E5.m1.2.2.1.1.7.cmml"><mover accent="true" id="S3.E5.m1.2.2.1.1.7.2" xref="S3.E5.m1.2.2.1.1.7.2.cmml"><mi id="S3.E5.m1.2.2.1.1.7.2.2" xref="S3.E5.m1.2.2.1.1.7.2.2.cmml">F</mi><mo id="S3.E5.m1.2.2.1.1.7.2.1" xref="S3.E5.m1.2.2.1.1.7.2.1.cmml">¯</mo></mover><mi id="S3.E5.m1.2.2.1.1.7.3" xref="S3.E5.m1.2.2.1.1.7.3.cmml">v</mi></msub><mo id="S3.E5.m1.2.2.1.1.6" xref="S3.E5.m1.2.2.1.1.6.cmml">=</mo><mrow id="S3.E5.m1.2.2.1.1.5" xref="S3.E5.m1.2.2.1.1.5.cmml"><mover accent="true" id="S3.E5.m1.2.2.1.1.5.7" xref="S3.E5.m1.2.2.1.1.5.7.cmml"><msubsup id="S3.E5.m1.2.2.1.1.5.7.2" xref="S3.E5.m1.2.2.1.1.5.7.2.cmml"><mi id="S3.E5.m1.2.2.1.1.5.7.2.2.2" xref="S3.E5.m1.2.2.1.1.5.7.2.2.2.cmml">f</mi><mi id="S3.E5.m1.2.2.1.1.5.7.2.2.3" xref="S3.E5.m1.2.2.1.1.5.7.2.2.3.cmml">p</mi><mi id="S3.E5.m1.2.2.1.1.5.7.2.3" xref="S3.E5.m1.2.2.1.1.5.7.2.3.cmml">λ</mi></msubsup><mo id="S3.E5.m1.2.2.1.1.5.7.1" xref="S3.E5.m1.2.2.1.1.5.7.1.cmml">^</mo></mover><mo id="S3.E5.m1.2.2.1.1.5.6" xref="S3.E5.m1.2.2.1.1.5.6.cmml">+</mo><mrow id="S3.E5.m1.2.2.1.1.2.2" xref="S3.E5.m1.2.2.1.1.2.2.cmml"><mi id="S3.E5.m1.2.2.1.1.2.2.4" xref="S3.E5.m1.2.2.1.1.2.2.4.cmml">𝙰𝚝𝚝𝚗</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.1.2.2.3" xref="S3.E5.m1.2.2.1.1.2.2.3.cmml">​</mo><mrow id="S3.E5.m1.2.2.1.1.2.2.2.2" xref="S3.E5.m1.2.2.1.1.2.2.2.3.cmml"><mo stretchy="false" id="S3.E5.m1.2.2.1.1.2.2.2.2.3" xref="S3.E5.m1.2.2.1.1.2.2.2.3.cmml">(</mo><mover accent="true" id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml"><msubsup id="S3.E5.m1.1.1.2" xref="S3.E5.m1.1.1.2.cmml"><mi id="S3.E5.m1.1.1.2.2.2" xref="S3.E5.m1.1.1.2.2.2.cmml">f</mi><mi id="S3.E5.m1.1.1.2.2.3" xref="S3.E5.m1.1.1.2.2.3.cmml">p</mi><mi id="S3.E5.m1.1.1.2.3" xref="S3.E5.m1.1.1.2.3.cmml">λ</mi></msubsup><mo id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.cmml">^</mo></mover><mo id="S3.E5.m1.2.2.1.1.2.2.2.2.4" xref="S3.E5.m1.2.2.1.1.2.2.2.3.cmml">,</mo><msub id="S3.E5.m1.2.2.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.cmml">F</mi><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.1.cmml">^</mo></mover><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.cmml">p</mi></msub><mo id="S3.E5.m1.2.2.1.1.2.2.2.2.5" xref="S3.E5.m1.2.2.1.1.2.2.2.3.cmml">,</mo><msub id="S3.E5.m1.2.2.1.1.2.2.2.2.2" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2.cmml"><mover accent="true" id="S3.E5.m1.2.2.1.1.2.2.2.2.2.2" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2.2.cmml"><mi id="S3.E5.m1.2.2.1.1.2.2.2.2.2.2.2" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2.2.2.cmml">F</mi><mo id="S3.E5.m1.2.2.1.1.2.2.2.2.2.2.1" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2.2.1.cmml">^</mo></mover><mi id="S3.E5.m1.2.2.1.1.2.2.2.2.2.3" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2.3.cmml">p</mi></msub><mo stretchy="false" id="S3.E5.m1.2.2.1.1.2.2.2.2.6" xref="S3.E5.m1.2.2.1.1.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.2.2.1.1.5.6a" xref="S3.E5.m1.2.2.1.1.5.6.cmml">+</mo><mrow id="S3.E5.m1.2.2.1.1.5.5" xref="S3.E5.m1.2.2.1.1.5.5.cmml"><mi id="S3.E5.m1.2.2.1.1.5.5.5" xref="S3.E5.m1.2.2.1.1.5.5.5.cmml">𝙰𝚝𝚝𝚗</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.1.5.5.4" xref="S3.E5.m1.2.2.1.1.5.5.4.cmml">​</mo><mrow id="S3.E5.m1.2.2.1.1.5.5.3.3" xref="S3.E5.m1.2.2.1.1.5.5.3.4.cmml"><mo stretchy="false" id="S3.E5.m1.2.2.1.1.5.5.3.3.4" xref="S3.E5.m1.2.2.1.1.5.5.3.4.cmml">(</mo><msubsup id="S3.E5.m1.2.2.1.1.3.3.1.1.1" xref="S3.E5.m1.2.2.1.1.3.3.1.1.1.cmml"><mi id="S3.E5.m1.2.2.1.1.3.3.1.1.1.2.2" xref="S3.E5.m1.2.2.1.1.3.3.1.1.1.2.2.cmml">f</mi><mi id="S3.E5.m1.2.2.1.1.3.3.1.1.1.2.3" xref="S3.E5.m1.2.2.1.1.3.3.1.1.1.2.3.cmml">a</mi><mi id="S3.E5.m1.2.2.1.1.3.3.1.1.1.3" xref="S3.E5.m1.2.2.1.1.3.3.1.1.1.3.cmml">λ</mi></msubsup><mo id="S3.E5.m1.2.2.1.1.5.5.3.3.5" xref="S3.E5.m1.2.2.1.1.5.5.3.4.cmml">,</mo><msub id="S3.E5.m1.2.2.1.1.4.4.2.2.2" xref="S3.E5.m1.2.2.1.1.4.4.2.2.2.cmml"><mover accent="true" id="S3.E5.m1.2.2.1.1.4.4.2.2.2.2" xref="S3.E5.m1.2.2.1.1.4.4.2.2.2.2.cmml"><mi id="S3.E5.m1.2.2.1.1.4.4.2.2.2.2.2" xref="S3.E5.m1.2.2.1.1.4.4.2.2.2.2.2.cmml">F</mi><mo id="S3.E5.m1.2.2.1.1.4.4.2.2.2.2.1" xref="S3.E5.m1.2.2.1.1.4.4.2.2.2.2.1.cmml">^</mo></mover><mi id="S3.E5.m1.2.2.1.1.4.4.2.2.2.3" xref="S3.E5.m1.2.2.1.1.4.4.2.2.2.3.cmml">p</mi></msub><mo id="S3.E5.m1.2.2.1.1.5.5.3.3.6" xref="S3.E5.m1.2.2.1.1.5.5.3.4.cmml">,</mo><msub id="S3.E5.m1.2.2.1.1.5.5.3.3.3" xref="S3.E5.m1.2.2.1.1.5.5.3.3.3.cmml"><mover accent="true" id="S3.E5.m1.2.2.1.1.5.5.3.3.3.2" xref="S3.E5.m1.2.2.1.1.5.5.3.3.3.2.cmml"><mi id="S3.E5.m1.2.2.1.1.5.5.3.3.3.2.2" xref="S3.E5.m1.2.2.1.1.5.5.3.3.3.2.2.cmml">F</mi><mo id="S3.E5.m1.2.2.1.1.5.5.3.3.3.2.1" xref="S3.E5.m1.2.2.1.1.5.5.3.3.3.2.1.cmml">^</mo></mover><mi id="S3.E5.m1.2.2.1.1.5.5.3.3.3.3" xref="S3.E5.m1.2.2.1.1.5.5.3.3.3.3.cmml">p</mi></msub><mo stretchy="false" id="S3.E5.m1.2.2.1.1.5.5.3.3.7" xref="S3.E5.m1.2.2.1.1.5.5.3.4.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E5.m1.2.2.1.2" xref="S3.E5.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.2b"><apply id="S3.E5.m1.2.2.1.1.cmml" xref="S3.E5.m1.2.2.1"><eq id="S3.E5.m1.2.2.1.1.6.cmml" xref="S3.E5.m1.2.2.1.1.6"></eq><apply id="S3.E5.m1.2.2.1.1.7.cmml" xref="S3.E5.m1.2.2.1.1.7"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.7.1.cmml" xref="S3.E5.m1.2.2.1.1.7">subscript</csymbol><apply id="S3.E5.m1.2.2.1.1.7.2.cmml" xref="S3.E5.m1.2.2.1.1.7.2"><ci id="S3.E5.m1.2.2.1.1.7.2.1.cmml" xref="S3.E5.m1.2.2.1.1.7.2.1">¯</ci><ci id="S3.E5.m1.2.2.1.1.7.2.2.cmml" xref="S3.E5.m1.2.2.1.1.7.2.2">𝐹</ci></apply><ci id="S3.E5.m1.2.2.1.1.7.3.cmml" xref="S3.E5.m1.2.2.1.1.7.3">𝑣</ci></apply><apply id="S3.E5.m1.2.2.1.1.5.cmml" xref="S3.E5.m1.2.2.1.1.5"><plus id="S3.E5.m1.2.2.1.1.5.6.cmml" xref="S3.E5.m1.2.2.1.1.5.6"></plus><apply id="S3.E5.m1.2.2.1.1.5.7.cmml" xref="S3.E5.m1.2.2.1.1.5.7"><ci id="S3.E5.m1.2.2.1.1.5.7.1.cmml" xref="S3.E5.m1.2.2.1.1.5.7.1">^</ci><apply id="S3.E5.m1.2.2.1.1.5.7.2.cmml" xref="S3.E5.m1.2.2.1.1.5.7.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.5.7.2.1.cmml" xref="S3.E5.m1.2.2.1.1.5.7.2">superscript</csymbol><apply id="S3.E5.m1.2.2.1.1.5.7.2.2.cmml" xref="S3.E5.m1.2.2.1.1.5.7.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.5.7.2.2.1.cmml" xref="S3.E5.m1.2.2.1.1.5.7.2">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.5.7.2.2.2.cmml" xref="S3.E5.m1.2.2.1.1.5.7.2.2.2">𝑓</ci><ci id="S3.E5.m1.2.2.1.1.5.7.2.2.3.cmml" xref="S3.E5.m1.2.2.1.1.5.7.2.2.3">𝑝</ci></apply><ci id="S3.E5.m1.2.2.1.1.5.7.2.3.cmml" xref="S3.E5.m1.2.2.1.1.5.7.2.3">𝜆</ci></apply></apply><apply id="S3.E5.m1.2.2.1.1.2.2.cmml" xref="S3.E5.m1.2.2.1.1.2.2"><times id="S3.E5.m1.2.2.1.1.2.2.3.cmml" xref="S3.E5.m1.2.2.1.1.2.2.3"></times><ci id="S3.E5.m1.2.2.1.1.2.2.4.cmml" xref="S3.E5.m1.2.2.1.1.2.2.4">𝙰𝚝𝚝𝚗</ci><vector id="S3.E5.m1.2.2.1.1.2.2.2.3.cmml" xref="S3.E5.m1.2.2.1.1.2.2.2.2"><apply id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1"><ci id="S3.E5.m1.1.1.1.cmml" xref="S3.E5.m1.1.1.1">^</ci><apply id="S3.E5.m1.1.1.2.cmml" xref="S3.E5.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.2">superscript</csymbol><apply id="S3.E5.m1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.2.2.1.cmml" xref="S3.E5.m1.1.1.2">subscript</csymbol><ci id="S3.E5.m1.1.1.2.2.2.cmml" xref="S3.E5.m1.1.1.2.2.2">𝑓</ci><ci id="S3.E5.m1.1.1.2.2.3.cmml" xref="S3.E5.m1.1.1.2.2.3">𝑝</ci></apply><ci id="S3.E5.m1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.2.3">𝜆</ci></apply></apply><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2"><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.1">^</ci><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2">𝐹</ci></apply><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3">𝑝</ci></apply><apply id="S3.E5.m1.2.2.1.1.2.2.2.2.2.cmml" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.2.2.2.2.2.1.cmml" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2">subscript</csymbol><apply id="S3.E5.m1.2.2.1.1.2.2.2.2.2.2.cmml" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2.2"><ci id="S3.E5.m1.2.2.1.1.2.2.2.2.2.2.1.cmml" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2.2.1">^</ci><ci id="S3.E5.m1.2.2.1.1.2.2.2.2.2.2.2.cmml" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2.2.2">𝐹</ci></apply><ci id="S3.E5.m1.2.2.1.1.2.2.2.2.2.3.cmml" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2.3">𝑝</ci></apply></vector></apply><apply id="S3.E5.m1.2.2.1.1.5.5.cmml" xref="S3.E5.m1.2.2.1.1.5.5"><times id="S3.E5.m1.2.2.1.1.5.5.4.cmml" xref="S3.E5.m1.2.2.1.1.5.5.4"></times><ci id="S3.E5.m1.2.2.1.1.5.5.5.cmml" xref="S3.E5.m1.2.2.1.1.5.5.5">𝙰𝚝𝚝𝚗</ci><vector id="S3.E5.m1.2.2.1.1.5.5.3.4.cmml" xref="S3.E5.m1.2.2.1.1.5.5.3.3"><apply id="S3.E5.m1.2.2.1.1.3.3.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.3.3.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.3.3.1.1.1">superscript</csymbol><apply id="S3.E5.m1.2.2.1.1.3.3.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.3.3.1.1.1.2.1.cmml" xref="S3.E5.m1.2.2.1.1.3.3.1.1.1">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.3.3.1.1.1.2.2.cmml" xref="S3.E5.m1.2.2.1.1.3.3.1.1.1.2.2">𝑓</ci><ci id="S3.E5.m1.2.2.1.1.3.3.1.1.1.2.3.cmml" xref="S3.E5.m1.2.2.1.1.3.3.1.1.1.2.3">𝑎</ci></apply><ci id="S3.E5.m1.2.2.1.1.3.3.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.3.3.1.1.1.3">𝜆</ci></apply><apply id="S3.E5.m1.2.2.1.1.4.4.2.2.2.cmml" xref="S3.E5.m1.2.2.1.1.4.4.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.4.4.2.2.2.1.cmml" xref="S3.E5.m1.2.2.1.1.4.4.2.2.2">subscript</csymbol><apply id="S3.E5.m1.2.2.1.1.4.4.2.2.2.2.cmml" xref="S3.E5.m1.2.2.1.1.4.4.2.2.2.2"><ci id="S3.E5.m1.2.2.1.1.4.4.2.2.2.2.1.cmml" xref="S3.E5.m1.2.2.1.1.4.4.2.2.2.2.1">^</ci><ci id="S3.E5.m1.2.2.1.1.4.4.2.2.2.2.2.cmml" xref="S3.E5.m1.2.2.1.1.4.4.2.2.2.2.2">𝐹</ci></apply><ci id="S3.E5.m1.2.2.1.1.4.4.2.2.2.3.cmml" xref="S3.E5.m1.2.2.1.1.4.4.2.2.2.3">𝑝</ci></apply><apply id="S3.E5.m1.2.2.1.1.5.5.3.3.3.cmml" xref="S3.E5.m1.2.2.1.1.5.5.3.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.5.5.3.3.3.1.cmml" xref="S3.E5.m1.2.2.1.1.5.5.3.3.3">subscript</csymbol><apply id="S3.E5.m1.2.2.1.1.5.5.3.3.3.2.cmml" xref="S3.E5.m1.2.2.1.1.5.5.3.3.3.2"><ci id="S3.E5.m1.2.2.1.1.5.5.3.3.3.2.1.cmml" xref="S3.E5.m1.2.2.1.1.5.5.3.3.3.2.1">^</ci><ci id="S3.E5.m1.2.2.1.1.5.5.3.3.3.2.2.cmml" xref="S3.E5.m1.2.2.1.1.5.5.3.3.3.2.2">𝐹</ci></apply><ci id="S3.E5.m1.2.2.1.1.5.5.3.3.3.3.cmml" xref="S3.E5.m1.2.2.1.1.5.5.3.3.3.3">𝑝</ci></apply></vector></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.2c">\displaystyle\overline{F}_{v}=\hat{f_{p}^{\lambda}}+\mathtt{Attn}(\hat{f_{p}^{\lambda}},\hat{F}_{p},\hat{F}_{p})+\mathtt{Attn}(f_{a}^{\lambda},\hat{F}_{p},\hat{F}_{p}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS3.p3.3" class="ltx_p">where <math id="S3.SS3.p3.3.m1.1" class="ltx_Math" alttext="\overline{F}_{p}\in\mathbb{R}^{Top_{k}\times S\times D}." display="inline"><semantics id="S3.SS3.p3.3.m1.1a"><mrow id="S3.SS3.p3.3.m1.1.1.1" xref="S3.SS3.p3.3.m1.1.1.1.1.cmml"><mrow id="S3.SS3.p3.3.m1.1.1.1.1" xref="S3.SS3.p3.3.m1.1.1.1.1.cmml"><msub id="S3.SS3.p3.3.m1.1.1.1.1.2" xref="S3.SS3.p3.3.m1.1.1.1.1.2.cmml"><mover accent="true" id="S3.SS3.p3.3.m1.1.1.1.1.2.2" xref="S3.SS3.p3.3.m1.1.1.1.1.2.2.cmml"><mi id="S3.SS3.p3.3.m1.1.1.1.1.2.2.2" xref="S3.SS3.p3.3.m1.1.1.1.1.2.2.2.cmml">F</mi><mo id="S3.SS3.p3.3.m1.1.1.1.1.2.2.1" xref="S3.SS3.p3.3.m1.1.1.1.1.2.2.1.cmml">¯</mo></mover><mi id="S3.SS3.p3.3.m1.1.1.1.1.2.3" xref="S3.SS3.p3.3.m1.1.1.1.1.2.3.cmml">p</mi></msub><mo id="S3.SS3.p3.3.m1.1.1.1.1.1" xref="S3.SS3.p3.3.m1.1.1.1.1.1.cmml">∈</mo><msup id="S3.SS3.p3.3.m1.1.1.1.1.3" xref="S3.SS3.p3.3.m1.1.1.1.1.3.cmml"><mi id="S3.SS3.p3.3.m1.1.1.1.1.3.2" xref="S3.SS3.p3.3.m1.1.1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.p3.3.m1.1.1.1.1.3.3" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.cmml"><mrow id="S3.SS3.p3.3.m1.1.1.1.1.3.3.2" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.cmml"><mi id="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.2" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.1" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.1.cmml">​</mo><mi id="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.3" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.1a" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.1.cmml">​</mo><msub id="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.4" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.4.cmml"><mi id="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.4.2" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.4.2.cmml">p</mi><mi id="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.4.3" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.4.3.cmml">k</mi></msub></mrow><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p3.3.m1.1.1.1.1.3.3.1" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.p3.3.m1.1.1.1.1.3.3.3" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.3.cmml">S</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p3.3.m1.1.1.1.1.3.3.1a" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.p3.3.m1.1.1.1.1.3.3.4" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.4.cmml">D</mi></mrow></msup></mrow><mo lspace="0em" id="S3.SS3.p3.3.m1.1.1.1.2" xref="S3.SS3.p3.3.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m1.1b"><apply id="S3.SS3.p3.3.m1.1.1.1.1.cmml" xref="S3.SS3.p3.3.m1.1.1.1"><in id="S3.SS3.p3.3.m1.1.1.1.1.1.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.1"></in><apply id="S3.SS3.p3.3.m1.1.1.1.1.2.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m1.1.1.1.1.2.1.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.2">subscript</csymbol><apply id="S3.SS3.p3.3.m1.1.1.1.1.2.2.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.2.2"><ci id="S3.SS3.p3.3.m1.1.1.1.1.2.2.1.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.2.2.1">¯</ci><ci id="S3.SS3.p3.3.m1.1.1.1.1.2.2.2.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.2.2.2">𝐹</ci></apply><ci id="S3.SS3.p3.3.m1.1.1.1.1.2.3.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.2.3">𝑝</ci></apply><apply id="S3.SS3.p3.3.m1.1.1.1.1.3.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m1.1.1.1.1.3.1.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.3">superscript</csymbol><ci id="S3.SS3.p3.3.m1.1.1.1.1.3.2.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.3.2">ℝ</ci><apply id="S3.SS3.p3.3.m1.1.1.1.1.3.3.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3"><times id="S3.SS3.p3.3.m1.1.1.1.1.3.3.1.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.1"></times><apply id="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.2"><times id="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.1.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.1"></times><ci id="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.2.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.2">𝑇</ci><ci id="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.3.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.3">𝑜</ci><apply id="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.4.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.4"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.4.1.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.4">subscript</csymbol><ci id="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.4.2.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.4.2">𝑝</ci><ci id="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.4.3.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.2.4.3">𝑘</ci></apply></apply><ci id="S3.SS3.p3.3.m1.1.1.1.1.3.3.3.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.3">𝑆</ci><ci id="S3.SS3.p3.3.m1.1.1.1.1.3.3.4.cmml" xref="S3.SS3.p3.3.m1.1.1.1.1.3.3.4">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m1.1c">\overline{F}_{p}\in\mathbb{R}^{Top_{k}\times S\times D}.</annotation></semantics></math>
Thus far, we have progressively identified the key temporal
segments that are most relevant to the input question, and its potential sound-aware areas.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>Multimodal Fusion and Answer Prediction</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.5" class="ltx_p">To achieve the AVQA task, we concatenate the updated visual features <math id="S3.SS4.p1.1.m1.2" class="ltx_Math" alttext="F_{v}^{\prime},\overline{F}_{v}" display="inline"><semantics id="S3.SS4.p1.1.m1.2a"><mrow id="S3.SS4.p1.1.m1.2.2.2" xref="S3.SS4.p1.1.m1.2.2.3.cmml"><msubsup id="S3.SS4.p1.1.m1.1.1.1.1" xref="S3.SS4.p1.1.m1.1.1.1.1.cmml"><mi id="S3.SS4.p1.1.m1.1.1.1.1.2.2" xref="S3.SS4.p1.1.m1.1.1.1.1.2.2.cmml">F</mi><mi id="S3.SS4.p1.1.m1.1.1.1.1.2.3" xref="S3.SS4.p1.1.m1.1.1.1.1.2.3.cmml">v</mi><mo id="S3.SS4.p1.1.m1.1.1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.1.1.3.cmml">′</mo></msubsup><mo id="S3.SS4.p1.1.m1.2.2.2.3" xref="S3.SS4.p1.1.m1.2.2.3.cmml">,</mo><msub id="S3.SS4.p1.1.m1.2.2.2.2" xref="S3.SS4.p1.1.m1.2.2.2.2.cmml"><mover accent="true" id="S3.SS4.p1.1.m1.2.2.2.2.2" xref="S3.SS4.p1.1.m1.2.2.2.2.2.cmml"><mi id="S3.SS4.p1.1.m1.2.2.2.2.2.2" xref="S3.SS4.p1.1.m1.2.2.2.2.2.2.cmml">F</mi><mo id="S3.SS4.p1.1.m1.2.2.2.2.2.1" xref="S3.SS4.p1.1.m1.2.2.2.2.2.1.cmml">¯</mo></mover><mi id="S3.SS4.p1.1.m1.2.2.2.2.3" xref="S3.SS4.p1.1.m1.2.2.2.2.3.cmml">v</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.2b"><list id="S3.SS4.p1.1.m1.2.2.3.cmml" xref="S3.SS4.p1.1.m1.2.2.2"><apply id="S3.SS4.p1.1.m1.1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1.1.1">superscript</csymbol><apply id="S3.SS4.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.1.1.1.1.2.1.cmml" xref="S3.SS4.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p1.1.m1.1.1.1.1.2.2.cmml" xref="S3.SS4.p1.1.m1.1.1.1.1.2.2">𝐹</ci><ci id="S3.SS4.p1.1.m1.1.1.1.1.2.3.cmml" xref="S3.SS4.p1.1.m1.1.1.1.1.2.3">𝑣</ci></apply><ci id="S3.SS4.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.1.1.3">′</ci></apply><apply id="S3.SS4.p1.1.m1.2.2.2.2.cmml" xref="S3.SS4.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.2.2.2.2.1.cmml" xref="S3.SS4.p1.1.m1.2.2.2.2">subscript</csymbol><apply id="S3.SS4.p1.1.m1.2.2.2.2.2.cmml" xref="S3.SS4.p1.1.m1.2.2.2.2.2"><ci id="S3.SS4.p1.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS4.p1.1.m1.2.2.2.2.2.1">¯</ci><ci id="S3.SS4.p1.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS4.p1.1.m1.2.2.2.2.2.2">𝐹</ci></apply><ci id="S3.SS4.p1.1.m1.2.2.2.2.3.cmml" xref="S3.SS4.p1.1.m1.2.2.2.2.3">𝑣</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.2c">F_{v}^{\prime},\overline{F}_{v}</annotation></semantics></math>, and the audio features <math id="S3.SS4.p1.2.m2.1" class="ltx_Math" alttext="F_{a}^{\prime}" display="inline"><semantics id="S3.SS4.p1.2.m2.1a"><msubsup id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml"><mi id="S3.SS4.p1.2.m2.1.1.2.2" xref="S3.SS4.p1.2.m2.1.1.2.2.cmml">F</mi><mi id="S3.SS4.p1.2.m2.1.1.2.3" xref="S3.SS4.p1.2.m2.1.1.2.3.cmml">a</mi><mo id="S3.SS4.p1.2.m2.1.1.3" xref="S3.SS4.p1.2.m2.1.1.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><apply id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">superscript</csymbol><apply id="S3.SS4.p1.2.m2.1.1.2.cmml" xref="S3.SS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.1.1.2.1.cmml" xref="S3.SS4.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.p1.2.m2.1.1.2.2.cmml" xref="S3.SS4.p1.2.m2.1.1.2.2">𝐹</ci><ci id="S3.SS4.p1.2.m2.1.1.2.3.cmml" xref="S3.SS4.p1.2.m2.1.1.2.3">𝑎</ci></apply><ci id="S3.SS4.p1.2.m2.1.1.3.cmml" xref="S3.SS4.p1.2.m2.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">F_{a}^{\prime}</annotation></semantics></math> obtained from TPM and SPM, respectively.
Then the visual fusion feature <math id="S3.SS4.p1.3.m3.1" class="ltx_Math" alttext="F_{av}" display="inline"><semantics id="S3.SS4.p1.3.m3.1a"><msub id="S3.SS4.p1.3.m3.1.1" xref="S3.SS4.p1.3.m3.1.1.cmml"><mi id="S3.SS4.p1.3.m3.1.1.2" xref="S3.SS4.p1.3.m3.1.1.2.cmml">F</mi><mrow id="S3.SS4.p1.3.m3.1.1.3" xref="S3.SS4.p1.3.m3.1.1.3.cmml"><mi id="S3.SS4.p1.3.m3.1.1.3.2" xref="S3.SS4.p1.3.m3.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.3.m3.1.1.3.1" xref="S3.SS4.p1.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS4.p1.3.m3.1.1.3.3" xref="S3.SS4.p1.3.m3.1.1.3.3.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.1b"><apply id="S3.SS4.p1.3.m3.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.3.m3.1.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS4.p1.3.m3.1.1.2.cmml" xref="S3.SS4.p1.3.m3.1.1.2">𝐹</ci><apply id="S3.SS4.p1.3.m3.1.1.3.cmml" xref="S3.SS4.p1.3.m3.1.1.3"><times id="S3.SS4.p1.3.m3.1.1.3.1.cmml" xref="S3.SS4.p1.3.m3.1.1.3.1"></times><ci id="S3.SS4.p1.3.m3.1.1.3.2.cmml" xref="S3.SS4.p1.3.m3.1.1.3.2">𝑎</ci><ci id="S3.SS4.p1.3.m3.1.1.3.3.cmml" xref="S3.SS4.p1.3.m3.1.1.3.3">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.1c">F_{av}</annotation></semantics></math> is obtained by a linear layer.
To verify the audio-visual fusion of our proposed effective Temporal-Spatial Perception Model, we employ a simple element-wise multiplication operation to integrate the question feature <math id="S3.SS4.p1.4.m4.1" class="ltx_Math" alttext="F_{q}" display="inline"><semantics id="S3.SS4.p1.4.m4.1a"><msub id="S3.SS4.p1.4.m4.1.1" xref="S3.SS4.p1.4.m4.1.1.cmml"><mi id="S3.SS4.p1.4.m4.1.1.2" xref="S3.SS4.p1.4.m4.1.1.2.cmml">F</mi><mi id="S3.SS4.p1.4.m4.1.1.3" xref="S3.SS4.p1.4.m4.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.4.m4.1b"><apply id="S3.SS4.p1.4.m4.1.1.cmml" xref="S3.SS4.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.4.m4.1.1.1.cmml" xref="S3.SS4.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS4.p1.4.m4.1.1.2.cmml" xref="S3.SS4.p1.4.m4.1.1.2">𝐹</ci><ci id="S3.SS4.p1.4.m4.1.1.3.cmml" xref="S3.SS4.p1.4.m4.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.4.m4.1c">F_{q}</annotation></semantics></math> and the previously obtained audio-visual fusion embedding <math id="S3.SS4.p1.5.m5.1" class="ltx_Math" alttext="F_{av}" display="inline"><semantics id="S3.SS4.p1.5.m5.1a"><msub id="S3.SS4.p1.5.m5.1.1" xref="S3.SS4.p1.5.m5.1.1.cmml"><mi id="S3.SS4.p1.5.m5.1.1.2" xref="S3.SS4.p1.5.m5.1.1.2.cmml">F</mi><mrow id="S3.SS4.p1.5.m5.1.1.3" xref="S3.SS4.p1.5.m5.1.1.3.cmml"><mi id="S3.SS4.p1.5.m5.1.1.3.2" xref="S3.SS4.p1.5.m5.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.5.m5.1.1.3.1" xref="S3.SS4.p1.5.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS4.p1.5.m5.1.1.3.3" xref="S3.SS4.p1.5.m5.1.1.3.3.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.5.m5.1b"><apply id="S3.SS4.p1.5.m5.1.1.cmml" xref="S3.SS4.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.5.m5.1.1.1.cmml" xref="S3.SS4.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS4.p1.5.m5.1.1.2.cmml" xref="S3.SS4.p1.5.m5.1.1.2">𝐹</ci><apply id="S3.SS4.p1.5.m5.1.1.3.cmml" xref="S3.SS4.p1.5.m5.1.1.3"><times id="S3.SS4.p1.5.m5.1.1.3.1.cmml" xref="S3.SS4.p1.5.m5.1.1.3.1"></times><ci id="S3.SS4.p1.5.m5.1.1.3.2.cmml" xref="S3.SS4.p1.5.m5.1.1.3.2">𝑎</ci><ci id="S3.SS4.p1.5.m5.1.1.3.3.cmml" xref="S3.SS4.p1.5.m5.1.1.3.3">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.5.m5.1c">F_{av}</annotation></semantics></math>.
And it can be formulated as:</p>
<table id="S5.EGx6" class="ltx_equationgroup ltx_eqn_gather ltx_eqn_table">

<tbody id="S3.E6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(6)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.1" class="ltx_Math" alttext="\displaystyle F_{av}=FC(Concat[F_{a}^{\prime},F_{v}^{\prime},\overline{F}_{v}])," display="block"><semantics id="S3.E6.m1.1a"><mrow id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><mrow id="S3.E6.m1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.1.3.2.cmml">F</mi><mrow id="S3.E6.m1.1.1.1.1.3.3" xref="S3.E6.m1.1.1.1.1.3.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.3.2" xref="S3.E6.m1.1.1.1.1.3.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.3.1" xref="S3.E6.m1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S3.E6.m1.1.1.1.1.3.3.3" xref="S3.E6.m1.1.1.1.1.3.3.3.cmml">v</mi></mrow></msub><mo id="S3.E6.m1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E6.m1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.3.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.2.cmml">​</mo><mi id="S3.E6.m1.1.1.1.1.1.4" xref="S3.E6.m1.1.1.1.1.1.4.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.1.2a" xref="S3.E6.m1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E6.m1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.5" xref="S3.E6.m1.1.1.1.1.1.1.1.1.5.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.1.1.1.1.4" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.cmml">​</mo><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.6" xref="S3.E6.m1.1.1.1.1.1.1.1.1.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.1.1.1.1.4a" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.cmml">​</mo><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.7" xref="S3.E6.m1.1.1.1.1.1.1.1.1.7.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.1.1.1.1.4b" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.cmml">​</mo><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.8" xref="S3.E6.m1.1.1.1.1.1.1.1.1.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.1.1.1.1.4c" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.cmml">​</mo><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.9" xref="S3.E6.m1.1.1.1.1.1.1.1.1.9.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.1.1.1.1.4d" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.cmml">​</mo><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.10" xref="S3.E6.m1.1.1.1.1.1.1.1.1.10.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.1.1.1.1.4e" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.cmml">​</mo><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.4.cmml"><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.4" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.4.cmml">[</mo><msubsup id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">F</mi><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">a</mi><mo id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">′</mo></msubsup><mo id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.5" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msubsup id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.2.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml">F</mi><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.2.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml">v</mi><mo id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.3.cmml">′</mo></msubsup><mo id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.6" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.cmml"><mover accent="true" id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.2.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.2.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.2.2.cmml">F</mi><mo id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.2.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.2.1.cmml">¯</mo></mover><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.3.cmml">v</mi></msub><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.7" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.4.cmml">]</mo></mrow></mrow><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E6.m1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"><eq id="S3.E6.m1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.2"></eq><apply id="S3.E6.m1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2">𝐹</ci><apply id="S3.E6.m1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3"><times id="S3.E6.m1.1.1.1.1.3.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.1"></times><ci id="S3.E6.m1.1.1.1.1.3.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2">𝑎</ci><ci id="S3.E6.m1.1.1.1.1.3.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3">𝑣</ci></apply></apply><apply id="S3.E6.m1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1"><times id="S3.E6.m1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.2"></times><ci id="S3.E6.m1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.3">𝐹</ci><ci id="S3.E6.m1.1.1.1.1.1.4.cmml" xref="S3.E6.m1.1.1.1.1.1.4">𝐶</ci><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1"><times id="S3.E6.m1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4"></times><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.5.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.5">𝐶</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.6.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.6">𝑜</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.7.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.7">𝑛</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.8.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.8">𝑐</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.9.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.9">𝑎</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.10.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.10">𝑡</ci><list id="S3.E6.m1.1.1.1.1.1.1.1.1.3.4.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.3"><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.2">𝐹</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3">𝑎</ci></apply><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.3">′</ci></apply><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2">superscript</csymbol><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.2.2">𝐹</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.2.3">𝑣</ci></apply><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.3">′</ci></apply><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3">subscript</csymbol><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.2"><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.2.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.2.1">¯</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.2.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.2.2">𝐹</ci></apply><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.3.3">𝑣</ci></apply></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">\displaystyle F_{av}=FC(Concat[F_{a}^{\prime},F_{v}^{\prime},\overline{F}_{v}]),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S3.E7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(7)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.1" class="ltx_Math" alttext="\displaystyle e=F_{q}\odot F_{av}," display="block"><semantics id="S3.E7.m1.1a"><mrow id="S3.E7.m1.1.1.1" xref="S3.E7.m1.1.1.1.1.cmml"><mrow id="S3.E7.m1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.cmml"><mi id="S3.E7.m1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.2.cmml">e</mi><mo id="S3.E7.m1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E7.m1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.3.cmml"><msub id="S3.E7.m1.1.1.1.1.3.2" xref="S3.E7.m1.1.1.1.1.3.2.cmml"><mi id="S3.E7.m1.1.1.1.1.3.2.2" xref="S3.E7.m1.1.1.1.1.3.2.2.cmml">F</mi><mi id="S3.E7.m1.1.1.1.1.3.2.3" xref="S3.E7.m1.1.1.1.1.3.2.3.cmml">q</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E7.m1.1.1.1.1.3.1" xref="S3.E7.m1.1.1.1.1.3.1.cmml">⊙</mo><msub id="S3.E7.m1.1.1.1.1.3.3" xref="S3.E7.m1.1.1.1.1.3.3.cmml"><mi id="S3.E7.m1.1.1.1.1.3.3.2" xref="S3.E7.m1.1.1.1.1.3.3.2.cmml">F</mi><mrow id="S3.E7.m1.1.1.1.1.3.3.3" xref="S3.E7.m1.1.1.1.1.3.3.3.cmml"><mi id="S3.E7.m1.1.1.1.1.3.3.3.2" xref="S3.E7.m1.1.1.1.1.3.3.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.3.3.1" xref="S3.E7.m1.1.1.1.1.3.3.3.1.cmml">​</mo><mi id="S3.E7.m1.1.1.1.1.3.3.3.3" xref="S3.E7.m1.1.1.1.1.3.3.3.3.cmml">v</mi></mrow></msub></mrow></mrow><mo id="S3.E7.m1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.1b"><apply id="S3.E7.m1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1"><eq id="S3.E7.m1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1"></eq><ci id="S3.E7.m1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.2">𝑒</ci><apply id="S3.E7.m1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.3"><csymbol cd="latexml" id="S3.E7.m1.1.1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3.1">direct-product</csymbol><apply id="S3.E7.m1.1.1.1.1.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.2.1.cmml" xref="S3.E7.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.3.2.2.cmml" xref="S3.E7.m1.1.1.1.1.3.2.2">𝐹</ci><ci id="S3.E7.m1.1.1.1.1.3.2.3.cmml" xref="S3.E7.m1.1.1.1.1.3.2.3">𝑞</ci></apply><apply id="S3.E7.m1.1.1.1.1.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.3.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.3.2">𝐹</ci><apply id="S3.E7.m1.1.1.1.1.3.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3"><times id="S3.E7.m1.1.1.1.1.3.3.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.1"></times><ci id="S3.E7.m1.1.1.1.1.3.3.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.2">𝑎</ci><ci id="S3.E7.m1.1.1.1.1.3.3.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.3">𝑣</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.1c">\displaystyle e=F_{q}\odot F_{av},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS4.p1.15" class="ltx_p">where <math id="S3.SS4.p1.6.m1.1" class="ltx_Math" alttext="\odot" display="inline"><semantics id="S3.SS4.p1.6.m1.1a"><mo id="S3.SS4.p1.6.m1.1.1" xref="S3.SS4.p1.6.m1.1.1.cmml">⊙</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.6.m1.1b"><csymbol cd="latexml" id="S3.SS4.p1.6.m1.1.1.cmml" xref="S3.SS4.p1.6.m1.1.1">direct-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.6.m1.1c">\odot</annotation></semantics></math> is element-wise multiplication operation,
<math id="S3.SS4.p1.7.m2.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S3.SS4.p1.7.m2.1a"><mi id="S3.SS4.p1.7.m2.1.1" xref="S3.SS4.p1.7.m2.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.7.m2.1b"><ci id="S3.SS4.p1.7.m2.1.1.cmml" xref="S3.SS4.p1.7.m2.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.7.m2.1c">\delta</annotation></semantics></math> and <math id="S3.SS4.p1.8.m3.1" class="ltx_Math" alttext="FC" display="inline"><semantics id="S3.SS4.p1.8.m3.1a"><mrow id="S3.SS4.p1.8.m3.1.1" xref="S3.SS4.p1.8.m3.1.1.cmml"><mi id="S3.SS4.p1.8.m3.1.1.2" xref="S3.SS4.p1.8.m3.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.8.m3.1.1.1" xref="S3.SS4.p1.8.m3.1.1.1.cmml">​</mo><mi id="S3.SS4.p1.8.m3.1.1.3" xref="S3.SS4.p1.8.m3.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.8.m3.1b"><apply id="S3.SS4.p1.8.m3.1.1.cmml" xref="S3.SS4.p1.8.m3.1.1"><times id="S3.SS4.p1.8.m3.1.1.1.cmml" xref="S3.SS4.p1.8.m3.1.1.1"></times><ci id="S3.SS4.p1.8.m3.1.1.2.cmml" xref="S3.SS4.p1.8.m3.1.1.2">𝐹</ci><ci id="S3.SS4.p1.8.m3.1.1.3.cmml" xref="S3.SS4.p1.8.m3.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.8.m3.1c">FC</annotation></semantics></math> represent <math id="S3.SS4.p1.9.m4.1" class="ltx_Math" alttext="Tanh" display="inline"><semantics id="S3.SS4.p1.9.m4.1a"><mrow id="S3.SS4.p1.9.m4.1.1" xref="S3.SS4.p1.9.m4.1.1.cmml"><mi id="S3.SS4.p1.9.m4.1.1.2" xref="S3.SS4.p1.9.m4.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.9.m4.1.1.1" xref="S3.SS4.p1.9.m4.1.1.1.cmml">​</mo><mi id="S3.SS4.p1.9.m4.1.1.3" xref="S3.SS4.p1.9.m4.1.1.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.9.m4.1.1.1a" xref="S3.SS4.p1.9.m4.1.1.1.cmml">​</mo><mi id="S3.SS4.p1.9.m4.1.1.4" xref="S3.SS4.p1.9.m4.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.9.m4.1.1.1b" xref="S3.SS4.p1.9.m4.1.1.1.cmml">​</mo><mi id="S3.SS4.p1.9.m4.1.1.5" xref="S3.SS4.p1.9.m4.1.1.5.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.9.m4.1b"><apply id="S3.SS4.p1.9.m4.1.1.cmml" xref="S3.SS4.p1.9.m4.1.1"><times id="S3.SS4.p1.9.m4.1.1.1.cmml" xref="S3.SS4.p1.9.m4.1.1.1"></times><ci id="S3.SS4.p1.9.m4.1.1.2.cmml" xref="S3.SS4.p1.9.m4.1.1.2">𝑇</ci><ci id="S3.SS4.p1.9.m4.1.1.3.cmml" xref="S3.SS4.p1.9.m4.1.1.3">𝑎</ci><ci id="S3.SS4.p1.9.m4.1.1.4.cmml" xref="S3.SS4.p1.9.m4.1.1.4">𝑛</ci><ci id="S3.SS4.p1.9.m4.1.1.5.cmml" xref="S3.SS4.p1.9.m4.1.1.5">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.9.m4.1c">Tanh</annotation></semantics></math> activation function and linear layer, respectively.
Then a <math id="S3.SS4.p1.10.m5.1" class="ltx_Math" alttext="\mathtt{Softmax}" display="inline"><semantics id="S3.SS4.p1.10.m5.1a"><mi id="S3.SS4.p1.10.m5.1.1" xref="S3.SS4.p1.10.m5.1.1.cmml">𝚂𝚘𝚏𝚝𝚖𝚊𝚡</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.10.m5.1b"><ci id="S3.SS4.p1.10.m5.1.1.cmml" xref="S3.SS4.p1.10.m5.1.1">𝚂𝚘𝚏𝚝𝚖𝚊𝚡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.10.m5.1c">\mathtt{Softmax}</annotation></semantics></math> function is used to output probabilities <math id="S3.SS4.p1.11.m6.1" class="ltx_Math" alttext="p\in\mathbb{R}^{C}" display="inline"><semantics id="S3.SS4.p1.11.m6.1a"><mrow id="S3.SS4.p1.11.m6.1.1" xref="S3.SS4.p1.11.m6.1.1.cmml"><mi id="S3.SS4.p1.11.m6.1.1.2" xref="S3.SS4.p1.11.m6.1.1.2.cmml">p</mi><mo id="S3.SS4.p1.11.m6.1.1.1" xref="S3.SS4.p1.11.m6.1.1.1.cmml">∈</mo><msup id="S3.SS4.p1.11.m6.1.1.3" xref="S3.SS4.p1.11.m6.1.1.3.cmml"><mi id="S3.SS4.p1.11.m6.1.1.3.2" xref="S3.SS4.p1.11.m6.1.1.3.2.cmml">ℝ</mi><mi id="S3.SS4.p1.11.m6.1.1.3.3" xref="S3.SS4.p1.11.m6.1.1.3.3.cmml">C</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.11.m6.1b"><apply id="S3.SS4.p1.11.m6.1.1.cmml" xref="S3.SS4.p1.11.m6.1.1"><in id="S3.SS4.p1.11.m6.1.1.1.cmml" xref="S3.SS4.p1.11.m6.1.1.1"></in><ci id="S3.SS4.p1.11.m6.1.1.2.cmml" xref="S3.SS4.p1.11.m6.1.1.2">𝑝</ci><apply id="S3.SS4.p1.11.m6.1.1.3.cmml" xref="S3.SS4.p1.11.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p1.11.m6.1.1.3.1.cmml" xref="S3.SS4.p1.11.m6.1.1.3">superscript</csymbol><ci id="S3.SS4.p1.11.m6.1.1.3.2.cmml" xref="S3.SS4.p1.11.m6.1.1.3.2">ℝ</ci><ci id="S3.SS4.p1.11.m6.1.1.3.3.cmml" xref="S3.SS4.p1.11.m6.1.1.3.3">𝐶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.11.m6.1c">p\in\mathbb{R}^{C}</annotation></semantics></math> for candidate answers, where <math id="S3.SS4.p1.12.m7.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS4.p1.12.m7.1a"><mi id="S3.SS4.p1.12.m7.1.1" xref="S3.SS4.p1.12.m7.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.12.m7.1b"><ci id="S3.SS4.p1.12.m7.1.1.cmml" xref="S3.SS4.p1.12.m7.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.12.m7.1c">C</annotation></semantics></math> is the size of the pre-defined candidate answer vocabulary pool.
With the predicted probability vector and the corresponding groundtruth label <math id="S3.SS4.p1.13.m8.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS4.p1.13.m8.1a"><mi id="S3.SS4.p1.13.m8.1.1" xref="S3.SS4.p1.13.m8.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.13.m8.1b"><ci id="S3.SS4.p1.13.m8.1.1.cmml" xref="S3.SS4.p1.13.m8.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.13.m8.1c">y</annotation></semantics></math>, we use a cross-entropy loss: <math id="S3.SS4.p1.14.m9.1" class="ltx_Math" alttext="\mathcal{L}_{qa}=-\sum_{c=1}^{C}y_{c}log(p_{c})" display="inline"><semantics id="S3.SS4.p1.14.m9.1a"><mrow id="S3.SS4.p1.14.m9.1.1" xref="S3.SS4.p1.14.m9.1.1.cmml"><msub id="S3.SS4.p1.14.m9.1.1.3" xref="S3.SS4.p1.14.m9.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p1.14.m9.1.1.3.2" xref="S3.SS4.p1.14.m9.1.1.3.2.cmml">ℒ</mi><mrow id="S3.SS4.p1.14.m9.1.1.3.3" xref="S3.SS4.p1.14.m9.1.1.3.3.cmml"><mi id="S3.SS4.p1.14.m9.1.1.3.3.2" xref="S3.SS4.p1.14.m9.1.1.3.3.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.14.m9.1.1.3.3.1" xref="S3.SS4.p1.14.m9.1.1.3.3.1.cmml">​</mo><mi id="S3.SS4.p1.14.m9.1.1.3.3.3" xref="S3.SS4.p1.14.m9.1.1.3.3.3.cmml">a</mi></mrow></msub><mo id="S3.SS4.p1.14.m9.1.1.2" xref="S3.SS4.p1.14.m9.1.1.2.cmml">=</mo><mrow id="S3.SS4.p1.14.m9.1.1.1" xref="S3.SS4.p1.14.m9.1.1.1.cmml"><mo id="S3.SS4.p1.14.m9.1.1.1a" xref="S3.SS4.p1.14.m9.1.1.1.cmml">−</mo><mrow id="S3.SS4.p1.14.m9.1.1.1.1" xref="S3.SS4.p1.14.m9.1.1.1.1.cmml"><msubsup id="S3.SS4.p1.14.m9.1.1.1.1.2" xref="S3.SS4.p1.14.m9.1.1.1.1.2.cmml"><mo id="S3.SS4.p1.14.m9.1.1.1.1.2.2.2" xref="S3.SS4.p1.14.m9.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S3.SS4.p1.14.m9.1.1.1.1.2.2.3" xref="S3.SS4.p1.14.m9.1.1.1.1.2.2.3.cmml"><mi id="S3.SS4.p1.14.m9.1.1.1.1.2.2.3.2" xref="S3.SS4.p1.14.m9.1.1.1.1.2.2.3.2.cmml">c</mi><mo id="S3.SS4.p1.14.m9.1.1.1.1.2.2.3.1" xref="S3.SS4.p1.14.m9.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.SS4.p1.14.m9.1.1.1.1.2.2.3.3" xref="S3.SS4.p1.14.m9.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.SS4.p1.14.m9.1.1.1.1.2.3" xref="S3.SS4.p1.14.m9.1.1.1.1.2.3.cmml">C</mi></msubsup><mrow id="S3.SS4.p1.14.m9.1.1.1.1.1" xref="S3.SS4.p1.14.m9.1.1.1.1.1.cmml"><msub id="S3.SS4.p1.14.m9.1.1.1.1.1.3" xref="S3.SS4.p1.14.m9.1.1.1.1.1.3.cmml"><mi id="S3.SS4.p1.14.m9.1.1.1.1.1.3.2" xref="S3.SS4.p1.14.m9.1.1.1.1.1.3.2.cmml">y</mi><mi id="S3.SS4.p1.14.m9.1.1.1.1.1.3.3" xref="S3.SS4.p1.14.m9.1.1.1.1.1.3.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS4.p1.14.m9.1.1.1.1.1.2" xref="S3.SS4.p1.14.m9.1.1.1.1.1.2.cmml">​</mo><mi id="S3.SS4.p1.14.m9.1.1.1.1.1.4" xref="S3.SS4.p1.14.m9.1.1.1.1.1.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.14.m9.1.1.1.1.1.2a" xref="S3.SS4.p1.14.m9.1.1.1.1.1.2.cmml">​</mo><mi id="S3.SS4.p1.14.m9.1.1.1.1.1.5" xref="S3.SS4.p1.14.m9.1.1.1.1.1.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.14.m9.1.1.1.1.1.2b" xref="S3.SS4.p1.14.m9.1.1.1.1.1.2.cmml">​</mo><mi id="S3.SS4.p1.14.m9.1.1.1.1.1.6" xref="S3.SS4.p1.14.m9.1.1.1.1.1.6.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.14.m9.1.1.1.1.1.2c" xref="S3.SS4.p1.14.m9.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.SS4.p1.14.m9.1.1.1.1.1.1.1" xref="S3.SS4.p1.14.m9.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS4.p1.14.m9.1.1.1.1.1.1.1.2" xref="S3.SS4.p1.14.m9.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS4.p1.14.m9.1.1.1.1.1.1.1.1" xref="S3.SS4.p1.14.m9.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS4.p1.14.m9.1.1.1.1.1.1.1.1.2" xref="S3.SS4.p1.14.m9.1.1.1.1.1.1.1.1.2.cmml">p</mi><mi id="S3.SS4.p1.14.m9.1.1.1.1.1.1.1.1.3" xref="S3.SS4.p1.14.m9.1.1.1.1.1.1.1.1.3.cmml">c</mi></msub><mo stretchy="false" id="S3.SS4.p1.14.m9.1.1.1.1.1.1.1.3" xref="S3.SS4.p1.14.m9.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.14.m9.1b"><apply id="S3.SS4.p1.14.m9.1.1.cmml" xref="S3.SS4.p1.14.m9.1.1"><eq id="S3.SS4.p1.14.m9.1.1.2.cmml" xref="S3.SS4.p1.14.m9.1.1.2"></eq><apply id="S3.SS4.p1.14.m9.1.1.3.cmml" xref="S3.SS4.p1.14.m9.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p1.14.m9.1.1.3.1.cmml" xref="S3.SS4.p1.14.m9.1.1.3">subscript</csymbol><ci id="S3.SS4.p1.14.m9.1.1.3.2.cmml" xref="S3.SS4.p1.14.m9.1.1.3.2">ℒ</ci><apply id="S3.SS4.p1.14.m9.1.1.3.3.cmml" xref="S3.SS4.p1.14.m9.1.1.3.3"><times id="S3.SS4.p1.14.m9.1.1.3.3.1.cmml" xref="S3.SS4.p1.14.m9.1.1.3.3.1"></times><ci id="S3.SS4.p1.14.m9.1.1.3.3.2.cmml" xref="S3.SS4.p1.14.m9.1.1.3.3.2">𝑞</ci><ci id="S3.SS4.p1.14.m9.1.1.3.3.3.cmml" xref="S3.SS4.p1.14.m9.1.1.3.3.3">𝑎</ci></apply></apply><apply id="S3.SS4.p1.14.m9.1.1.1.cmml" xref="S3.SS4.p1.14.m9.1.1.1"><minus id="S3.SS4.p1.14.m9.1.1.1.2.cmml" xref="S3.SS4.p1.14.m9.1.1.1"></minus><apply id="S3.SS4.p1.14.m9.1.1.1.1.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1"><apply id="S3.SS4.p1.14.m9.1.1.1.1.2.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p1.14.m9.1.1.1.1.2.1.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.2">superscript</csymbol><apply id="S3.SS4.p1.14.m9.1.1.1.1.2.2.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p1.14.m9.1.1.1.1.2.2.1.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.2">subscript</csymbol><sum id="S3.SS4.p1.14.m9.1.1.1.1.2.2.2.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.2.2.2"></sum><apply id="S3.SS4.p1.14.m9.1.1.1.1.2.2.3.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.2.2.3"><eq id="S3.SS4.p1.14.m9.1.1.1.1.2.2.3.1.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.2.2.3.1"></eq><ci id="S3.SS4.p1.14.m9.1.1.1.1.2.2.3.2.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.2.2.3.2">𝑐</ci><cn type="integer" id="S3.SS4.p1.14.m9.1.1.1.1.2.2.3.3.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.SS4.p1.14.m9.1.1.1.1.2.3.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.2.3">𝐶</ci></apply><apply id="S3.SS4.p1.14.m9.1.1.1.1.1.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.1"><times id="S3.SS4.p1.14.m9.1.1.1.1.1.2.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.1.2"></times><apply id="S3.SS4.p1.14.m9.1.1.1.1.1.3.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p1.14.m9.1.1.1.1.1.3.1.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS4.p1.14.m9.1.1.1.1.1.3.2.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.1.3.2">𝑦</ci><ci id="S3.SS4.p1.14.m9.1.1.1.1.1.3.3.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.1.3.3">𝑐</ci></apply><ci id="S3.SS4.p1.14.m9.1.1.1.1.1.4.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.1.4">𝑙</ci><ci id="S3.SS4.p1.14.m9.1.1.1.1.1.5.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.1.5">𝑜</ci><ci id="S3.SS4.p1.14.m9.1.1.1.1.1.6.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.1.6">𝑔</ci><apply id="S3.SS4.p1.14.m9.1.1.1.1.1.1.1.1.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.14.m9.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p1.14.m9.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.1.1.1.1.2">𝑝</ci><ci id="S3.SS4.p1.14.m9.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS4.p1.14.m9.1.1.1.1.1.1.1.1.3">𝑐</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.14.m9.1c">\mathcal{L}_{qa}=-\sum_{c=1}^{C}y_{c}log(p_{c})</annotation></semantics></math>. During testing, we can select the predicted answer by <math id="S3.SS4.p1.15.m10.1" class="ltx_Math" alttext="\hat{c}=\arg\text{max}_{c}(p)" display="inline"><semantics id="S3.SS4.p1.15.m10.1a"><mrow id="S3.SS4.p1.15.m10.1.2" xref="S3.SS4.p1.15.m10.1.2.cmml"><mover accent="true" id="S3.SS4.p1.15.m10.1.2.2" xref="S3.SS4.p1.15.m10.1.2.2.cmml"><mi id="S3.SS4.p1.15.m10.1.2.2.2" xref="S3.SS4.p1.15.m10.1.2.2.2.cmml">c</mi><mo id="S3.SS4.p1.15.m10.1.2.2.1" xref="S3.SS4.p1.15.m10.1.2.2.1.cmml">^</mo></mover><mo id="S3.SS4.p1.15.m10.1.2.1" xref="S3.SS4.p1.15.m10.1.2.1.cmml">=</mo><mrow id="S3.SS4.p1.15.m10.1.2.3" xref="S3.SS4.p1.15.m10.1.2.3.cmml"><mrow id="S3.SS4.p1.15.m10.1.2.3.2" xref="S3.SS4.p1.15.m10.1.2.3.2.cmml"><mi id="S3.SS4.p1.15.m10.1.2.3.2.1" xref="S3.SS4.p1.15.m10.1.2.3.2.1.cmml">arg</mi><mo lspace="0.167em" id="S3.SS4.p1.15.m10.1.2.3.2a" xref="S3.SS4.p1.15.m10.1.2.3.2.cmml">⁡</mo><msub id="S3.SS4.p1.15.m10.1.2.3.2.2" xref="S3.SS4.p1.15.m10.1.2.3.2.2.cmml"><mtext id="S3.SS4.p1.15.m10.1.2.3.2.2.2" xref="S3.SS4.p1.15.m10.1.2.3.2.2.2a.cmml">max</mtext><mi id="S3.SS4.p1.15.m10.1.2.3.2.2.3" xref="S3.SS4.p1.15.m10.1.2.3.2.2.3.cmml">c</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S3.SS4.p1.15.m10.1.2.3.1" xref="S3.SS4.p1.15.m10.1.2.3.1.cmml">​</mo><mrow id="S3.SS4.p1.15.m10.1.2.3.3.2" xref="S3.SS4.p1.15.m10.1.2.3.cmml"><mo stretchy="false" id="S3.SS4.p1.15.m10.1.2.3.3.2.1" xref="S3.SS4.p1.15.m10.1.2.3.cmml">(</mo><mi id="S3.SS4.p1.15.m10.1.1" xref="S3.SS4.p1.15.m10.1.1.cmml">p</mi><mo stretchy="false" id="S3.SS4.p1.15.m10.1.2.3.3.2.2" xref="S3.SS4.p1.15.m10.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.15.m10.1b"><apply id="S3.SS4.p1.15.m10.1.2.cmml" xref="S3.SS4.p1.15.m10.1.2"><eq id="S3.SS4.p1.15.m10.1.2.1.cmml" xref="S3.SS4.p1.15.m10.1.2.1"></eq><apply id="S3.SS4.p1.15.m10.1.2.2.cmml" xref="S3.SS4.p1.15.m10.1.2.2"><ci id="S3.SS4.p1.15.m10.1.2.2.1.cmml" xref="S3.SS4.p1.15.m10.1.2.2.1">^</ci><ci id="S3.SS4.p1.15.m10.1.2.2.2.cmml" xref="S3.SS4.p1.15.m10.1.2.2.2">𝑐</ci></apply><apply id="S3.SS4.p1.15.m10.1.2.3.cmml" xref="S3.SS4.p1.15.m10.1.2.3"><times id="S3.SS4.p1.15.m10.1.2.3.1.cmml" xref="S3.SS4.p1.15.m10.1.2.3.1"></times><apply id="S3.SS4.p1.15.m10.1.2.3.2.cmml" xref="S3.SS4.p1.15.m10.1.2.3.2"><arg id="S3.SS4.p1.15.m10.1.2.3.2.1.cmml" xref="S3.SS4.p1.15.m10.1.2.3.2.1"></arg><apply id="S3.SS4.p1.15.m10.1.2.3.2.2.cmml" xref="S3.SS4.p1.15.m10.1.2.3.2.2"><csymbol cd="ambiguous" id="S3.SS4.p1.15.m10.1.2.3.2.2.1.cmml" xref="S3.SS4.p1.15.m10.1.2.3.2.2">subscript</csymbol><ci id="S3.SS4.p1.15.m10.1.2.3.2.2.2a.cmml" xref="S3.SS4.p1.15.m10.1.2.3.2.2.2"><mtext id="S3.SS4.p1.15.m10.1.2.3.2.2.2.cmml" xref="S3.SS4.p1.15.m10.1.2.3.2.2.2">max</mtext></ci><ci id="S3.SS4.p1.15.m10.1.2.3.2.2.3.cmml" xref="S3.SS4.p1.15.m10.1.2.3.2.2.3">𝑐</ci></apply></apply><ci id="S3.SS4.p1.15.m10.1.1.cmml" xref="S3.SS4.p1.15.m10.1.1">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.15.m10.1c">\hat{c}=\arg\text{max}_{c}(p)</annotation></semantics></math>.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<div id="S3.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:797.0pt;height:281.8pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-10.2pt,3.6pt) scale(0.975,0.975) ;">
<table id="S3.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_t"></th>
<th id="S3.T1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="3"><span id="S3.T1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Audio</span></th>
<th id="S3.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="3"><span id="S3.T1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Visual</span></th>
<th id="S3.T1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="6"><span id="S3.T1.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Audio-Visual</span></th>
<th id="S3.T1.1.1.1.1.5" class="ltx_td ltx_th ltx_th_column ltx_border_t"></th>
</tr>
<tr id="S3.T1.1.1.2.2" class="ltx_tr">
<th id="S3.T1.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S3.T1.1.1.2.2.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<th id="S3.T1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T1.1.1.2.2.2.1" class="ltx_text ltx_font_bold">Count</span></th>
<th id="S3.T1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T1.1.1.2.2.3.1" class="ltx_text ltx_font_bold">Comp</span></th>
<th id="S3.T1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S3.T1.1.1.2.2.4.1" class="ltx_text ltx_font_bold">Avg</span></th>
<th id="S3.T1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T1.1.1.2.2.5.1" class="ltx_text ltx_font_bold">Count</span></th>
<th id="S3.T1.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T1.1.1.2.2.6.1" class="ltx_text ltx_font_bold">Local</span></th>
<th id="S3.T1.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S3.T1.1.1.2.2.7.1" class="ltx_text ltx_font_bold">Avg</span></th>
<th id="S3.T1.1.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T1.1.1.2.2.8.1" class="ltx_text ltx_font_bold">Exist</span></th>
<th id="S3.T1.1.1.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T1.1.1.2.2.9.1" class="ltx_text ltx_font_bold">Count</span></th>
<th id="S3.T1.1.1.2.2.10" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T1.1.1.2.2.10.1" class="ltx_text ltx_font_bold">Local</span></th>
<th id="S3.T1.1.1.2.2.11" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T1.1.1.2.2.11.1" class="ltx_text ltx_font_bold">Comp</span></th>
<th id="S3.T1.1.1.2.2.12" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T1.1.1.2.2.12.1" class="ltx_text ltx_font_bold">Temp</span></th>
<th id="S3.T1.1.1.2.2.13" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S3.T1.1.1.2.2.13.1" class="ltx_text ltx_font_bold">Avg</span></th>
<th id="S3.T1.1.1.2.2.14" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T1.1.1.2.2.14.1" class="ltx_text ltx_font_bold">Avg</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.1.1.3.1" class="ltx_tr">
<td id="S3.T1.1.1.3.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">FCNLSTM <cite class="ltx_cite ltx_citemacro_citep">(Fayek and Johnson, <a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="S3.T1.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t">70.80</td>
<td id="S3.T1.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">65.66</td>
<td id="S3.T1.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">68.90</td>
<td id="S3.T1.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">64.58</td>
<td id="S3.T1.1.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">48.08</td>
<td id="S3.T1.1.1.3.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56.23</td>
<td id="S3.T1.1.1.3.1.8" class="ltx_td ltx_align_center ltx_border_t">82.29</td>
<td id="S3.T1.1.1.3.1.9" class="ltx_td ltx_align_center ltx_border_t">59.92</td>
<td id="S3.T1.1.1.3.1.10" class="ltx_td ltx_align_center ltx_border_t">46.20</td>
<td id="S3.T1.1.1.3.1.11" class="ltx_td ltx_align_center ltx_border_t">62.94</td>
<td id="S3.T1.1.1.3.1.12" class="ltx_td ltx_align_center ltx_border_t">47.45</td>
<td id="S3.T1.1.1.3.1.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">60.42</td>
<td id="S3.T1.1.1.3.1.14" class="ltx_td ltx_align_center ltx_border_t">60.81</td>
</tr>
<tr id="S3.T1.1.1.4.2" class="ltx_tr">
<td id="S3.T1.1.1.4.2.1" class="ltx_td ltx_align_center ltx_border_r">BiLSTM <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2016</a>)</cite>
</td>
<td id="S3.T1.1.1.4.2.2" class="ltx_td ltx_align_center">67.75</td>
<td id="S3.T1.1.1.4.2.3" class="ltx_td ltx_align_center">63.64</td>
<td id="S3.T1.1.1.4.2.4" class="ltx_td ltx_align_center ltx_border_r">66.23</td>
<td id="S3.T1.1.1.4.2.5" class="ltx_td ltx_align_center">59.65</td>
<td id="S3.T1.1.1.4.2.6" class="ltx_td ltx_align_center">29.80</td>
<td id="S3.T1.1.1.4.2.7" class="ltx_td ltx_align_center ltx_border_r">44.55</td>
<td id="S3.T1.1.1.4.2.8" class="ltx_td ltx_align_center">80.97</td>
<td id="S3.T1.1.1.4.2.9" class="ltx_td ltx_align_center">56.05</td>
<td id="S3.T1.1.1.4.2.10" class="ltx_td ltx_align_center">36.09</td>
<td id="S3.T1.1.1.4.2.11" class="ltx_td ltx_align_center">62.67</td>
<td id="S3.T1.1.1.4.2.12" class="ltx_td ltx_align_center">32.60</td>
<td id="S3.T1.1.1.4.2.13" class="ltx_td ltx_align_center ltx_border_r">54.93</td>
<td id="S3.T1.1.1.4.2.14" class="ltx_td ltx_align_center">54.17</td>
</tr>
<tr id="S3.T1.1.1.5.3" class="ltx_tr">
<td id="S3.T1.1.1.5.3.1" class="ltx_td ltx_align_center ltx_border_r">Hco_Att <cite class="ltx_cite ltx_citemacro_citep">(Lu et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2016</a>)</cite>
</td>
<td id="S3.T1.1.1.5.3.2" class="ltx_td ltx_align_center">70.80</td>
<td id="S3.T1.1.1.5.3.3" class="ltx_td ltx_align_center">54.71</td>
<td id="S3.T1.1.1.5.3.4" class="ltx_td ltx_align_center ltx_border_r">64.87</td>
<td id="S3.T1.1.1.5.3.5" class="ltx_td ltx_align_center">63.49</td>
<td id="S3.T1.1.1.5.3.6" class="ltx_td ltx_align_center">67.10</td>
<td id="S3.T1.1.1.5.3.7" class="ltx_td ltx_align_center ltx_border_r">65.32</td>
<td id="S3.T1.1.1.5.3.8" class="ltx_td ltx_align_center">79.48</td>
<td id="S3.T1.1.1.5.3.9" class="ltx_td ltx_align_center">59.84</td>
<td id="S3.T1.1.1.5.3.10" class="ltx_td ltx_align_center">48.80</td>
<td id="S3.T1.1.1.5.3.11" class="ltx_td ltx_align_center">56.31</td>
<td id="S3.T1.1.1.5.3.12" class="ltx_td ltx_align_center">56.33</td>
<td id="S3.T1.1.1.5.3.13" class="ltx_td ltx_align_center ltx_border_r">60.32</td>
<td id="S3.T1.1.1.5.3.14" class="ltx_td ltx_align_center">62.45</td>
</tr>
<tr id="S3.T1.1.1.6.4" class="ltx_tr">
<td id="S3.T1.1.1.6.4.1" class="ltx_td ltx_align_center ltx_border_r">MCAN <cite class="ltx_cite ltx_citemacro_citep">(Yu et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2019</a>)</cite>
</td>
<td id="S3.T1.1.1.6.4.2" class="ltx_td ltx_align_center">78.07</td>
<td id="S3.T1.1.1.6.4.3" class="ltx_td ltx_align_center">57.74</td>
<td id="S3.T1.1.1.6.4.4" class="ltx_td ltx_align_center ltx_border_r">70.58</td>
<td id="S3.T1.1.1.6.4.5" class="ltx_td ltx_align_center">71.76</td>
<td id="S3.T1.1.1.6.4.6" class="ltx_td ltx_align_center">71.76</td>
<td id="S3.T1.1.1.6.4.7" class="ltx_td ltx_align_center ltx_border_r">71.76</td>
<td id="S3.T1.1.1.6.4.8" class="ltx_td ltx_align_center">80.77</td>
<td id="S3.T1.1.1.6.4.9" class="ltx_td ltx_align_center">65.22</td>
<td id="S3.T1.1.1.6.4.10" class="ltx_td ltx_align_center">54.57</td>
<td id="S3.T1.1.1.6.4.11" class="ltx_td ltx_align_center">56.77</td>
<td id="S3.T1.1.1.6.4.12" class="ltx_td ltx_align_center">46.84</td>
<td id="S3.T1.1.1.6.4.13" class="ltx_td ltx_align_center ltx_border_r">61.52</td>
<td id="S3.T1.1.1.6.4.14" class="ltx_td ltx_align_center">65.83</td>
</tr>
<tr id="S3.T1.1.1.7.5" class="ltx_tr">
<td id="S3.T1.1.1.7.5.1" class="ltx_td ltx_align_center ltx_border_r">PSAC <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2019b</a>)</cite>
</td>
<td id="S3.T1.1.1.7.5.2" class="ltx_td ltx_align_center">75.02</td>
<td id="S3.T1.1.1.7.5.3" class="ltx_td ltx_align_center">66.84</td>
<td id="S3.T1.1.1.7.5.4" class="ltx_td ltx_align_center ltx_border_r">72.00</td>
<td id="S3.T1.1.1.7.5.5" class="ltx_td ltx_align_center">68.00</td>
<td id="S3.T1.1.1.7.5.6" class="ltx_td ltx_align_center">70.78</td>
<td id="S3.T1.1.1.7.5.7" class="ltx_td ltx_align_center ltx_border_r">69.41</td>
<td id="S3.T1.1.1.7.5.8" class="ltx_td ltx_align_center">79.76</td>
<td id="S3.T1.1.1.7.5.9" class="ltx_td ltx_align_center">61.66</td>
<td id="S3.T1.1.1.7.5.10" class="ltx_td ltx_align_center">55.22</td>
<td id="S3.T1.1.1.7.5.11" class="ltx_td ltx_align_center">61.13</td>
<td id="S3.T1.1.1.7.5.12" class="ltx_td ltx_align_center">59.85</td>
<td id="S3.T1.1.1.7.5.13" class="ltx_td ltx_align_center ltx_border_r">63.60</td>
<td id="S3.T1.1.1.7.5.14" class="ltx_td ltx_align_center">66.62</td>
</tr>
<tr id="S3.T1.1.1.8.6" class="ltx_tr">
<td id="S3.T1.1.1.8.6.1" class="ltx_td ltx_align_center ltx_border_r">HME <cite class="ltx_cite ltx_citemacro_citep">(Fan et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2019</a>)</cite>
</td>
<td id="S3.T1.1.1.8.6.2" class="ltx_td ltx_align_center">73.65</td>
<td id="S3.T1.1.1.8.6.3" class="ltx_td ltx_align_center">63.74</td>
<td id="S3.T1.1.1.8.6.4" class="ltx_td ltx_align_center ltx_border_r">69.89</td>
<td id="S3.T1.1.1.8.6.5" class="ltx_td ltx_align_center">67.42</td>
<td id="S3.T1.1.1.8.6.6" class="ltx_td ltx_align_center">70.20</td>
<td id="S3.T1.1.1.8.6.7" class="ltx_td ltx_align_center ltx_border_r">68.83</td>
<td id="S3.T1.1.1.8.6.8" class="ltx_td ltx_align_center">80.87</td>
<td id="S3.T1.1.1.8.6.9" class="ltx_td ltx_align_center">63.64</td>
<td id="S3.T1.1.1.8.6.10" class="ltx_td ltx_align_center">54.89</td>
<td id="S3.T1.1.1.8.6.11" class="ltx_td ltx_align_center">63.03</td>
<td id="S3.T1.1.1.8.6.12" class="ltx_td ltx_align_center">60.58</td>
<td id="S3.T1.1.1.8.6.13" class="ltx_td ltx_align_center ltx_border_r">64.78</td>
<td id="S3.T1.1.1.8.6.14" class="ltx_td ltx_align_center">66.75</td>
</tr>
<tr id="S3.T1.1.1.9.7" class="ltx_tr">
<td id="S3.T1.1.1.9.7.1" class="ltx_td ltx_align_center ltx_border_r">HCRN <cite class="ltx_cite ltx_citemacro_citep">(Le et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="S3.T1.1.1.9.7.2" class="ltx_td ltx_align_center">71.29</td>
<td id="S3.T1.1.1.9.7.3" class="ltx_td ltx_align_center">50.67</td>
<td id="S3.T1.1.1.9.7.4" class="ltx_td ltx_align_center ltx_border_r">63.69</td>
<td id="S3.T1.1.1.9.7.5" class="ltx_td ltx_align_center">65.33</td>
<td id="S3.T1.1.1.9.7.6" class="ltx_td ltx_align_center">64.98</td>
<td id="S3.T1.1.1.9.7.7" class="ltx_td ltx_align_center ltx_border_r">65.15</td>
<td id="S3.T1.1.1.9.7.8" class="ltx_td ltx_align_center">54.15</td>
<td id="S3.T1.1.1.9.7.9" class="ltx_td ltx_align_center">53.28</td>
<td id="S3.T1.1.1.9.7.10" class="ltx_td ltx_align_center">41.74</td>
<td id="S3.T1.1.1.9.7.11" class="ltx_td ltx_align_center">51.04</td>
<td id="S3.T1.1.1.9.7.12" class="ltx_td ltx_align_center">46.72</td>
<td id="S3.T1.1.1.9.7.13" class="ltx_td ltx_align_center ltx_border_r">49.82</td>
<td id="S3.T1.1.1.9.7.14" class="ltx_td ltx_align_center">56.34</td>
</tr>
<tr id="S3.T1.1.1.10.8" class="ltx_tr">
<td id="S3.T1.1.1.10.8.1" class="ltx_td ltx_align_center ltx_border_r">AVSD <cite class="ltx_cite ltx_citemacro_citep">(Schwartz et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2019</a>)</cite>
</td>
<td id="S3.T1.1.1.10.8.2" class="ltx_td ltx_align_center">72.47</td>
<td id="S3.T1.1.1.10.8.3" class="ltx_td ltx_align_center">62.46</td>
<td id="S3.T1.1.1.10.8.4" class="ltx_td ltx_align_center ltx_border_r">68.78</td>
<td id="S3.T1.1.1.10.8.5" class="ltx_td ltx_align_center">66.00</td>
<td id="S3.T1.1.1.10.8.6" class="ltx_td ltx_align_center">74.53</td>
<td id="S3.T1.1.1.10.8.7" class="ltx_td ltx_align_center ltx_border_r">70.31</td>
<td id="S3.T1.1.1.10.8.8" class="ltx_td ltx_align_center">80.77</td>
<td id="S3.T1.1.1.10.8.9" class="ltx_td ltx_align_center">64.03</td>
<td id="S3.T1.1.1.10.8.10" class="ltx_td ltx_align_center">57.93</td>
<td id="S3.T1.1.1.10.8.11" class="ltx_td ltx_align_center">62.85</td>
<td id="S3.T1.1.1.10.8.12" class="ltx_td ltx_align_center">61.07</td>
<td id="S3.T1.1.1.10.8.13" class="ltx_td ltx_align_center ltx_border_r">65.44</td>
<td id="S3.T1.1.1.10.8.14" class="ltx_td ltx_align_center">67.32</td>
</tr>
<tr id="S3.T1.1.1.11.9" class="ltx_tr">
<td id="S3.T1.1.1.11.9.1" class="ltx_td ltx_align_center ltx_border_r">PanoAVQA <cite class="ltx_cite ltx_citemacro_citep">(Yun et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S3.T1.1.1.11.9.2" class="ltx_td ltx_align_center">75.71</td>
<td id="S3.T1.1.1.11.9.3" class="ltx_td ltx_align_center">65.99</td>
<td id="S3.T1.1.1.11.9.4" class="ltx_td ltx_align_center ltx_border_r">72.13</td>
<td id="S3.T1.1.1.11.9.5" class="ltx_td ltx_align_center">70.51</td>
<td id="S3.T1.1.1.11.9.6" class="ltx_td ltx_align_center">75.76</td>
<td id="S3.T1.1.1.11.9.7" class="ltx_td ltx_align_center ltx_border_r">73.16</td>
<td id="S3.T1.1.1.11.9.8" class="ltx_td ltx_align_center">82.09</td>
<td id="S3.T1.1.1.11.9.9" class="ltx_td ltx_align_center">65.38</td>
<td id="S3.T1.1.1.11.9.10" class="ltx_td ltx_align_center">61.30</td>
<td id="S3.T1.1.1.11.9.11" class="ltx_td ltx_align_center">63.67</td>
<td id="S3.T1.1.1.11.9.12" class="ltx_td ltx_align_center">62.04</td>
<td id="S3.T1.1.1.11.9.13" class="ltx_td ltx_align_center ltx_border_r">66.97</td>
<td id="S3.T1.1.1.11.9.14" class="ltx_td ltx_align_center">69.53</td>
</tr>
<tr id="S3.T1.1.1.12.10" class="ltx_tr">
<td id="S3.T1.1.1.12.10.1" class="ltx_td ltx_align_center ltx_border_r">ST-AVQA <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S3.T1.1.1.12.10.2" class="ltx_td ltx_align_center">77.78</td>
<td id="S3.T1.1.1.12.10.3" class="ltx_td ltx_align_center"><span id="S3.T1.1.1.12.10.3.1" class="ltx_text ltx_framed ltx_framed_underline">67.17</span></td>
<td id="S3.T1.1.1.12.10.4" class="ltx_td ltx_align_center ltx_border_r">73.87</td>
<td id="S3.T1.1.1.12.10.5" class="ltx_td ltx_align_center">73.52</td>
<td id="S3.T1.1.1.12.10.6" class="ltx_td ltx_align_center">75.27</td>
<td id="S3.T1.1.1.12.10.7" class="ltx_td ltx_align_center ltx_border_r">74.40</td>
<td id="S3.T1.1.1.12.10.8" class="ltx_td ltx_align_center"><span id="S3.T1.1.1.12.10.8.1" class="ltx_text ltx_framed ltx_framed_underline">82.49</span></td>
<td id="S3.T1.1.1.12.10.9" class="ltx_td ltx_align_center">69.88</td>
<td id="S3.T1.1.1.12.10.10" class="ltx_td ltx_align_center">64.24</td>
<td id="S3.T1.1.1.12.10.11" class="ltx_td ltx_align_center">64.67</td>
<td id="S3.T1.1.1.12.10.12" class="ltx_td ltx_align_center">65.82</td>
<td id="S3.T1.1.1.12.10.13" class="ltx_td ltx_align_center ltx_border_r">69.53</td>
<td id="S3.T1.1.1.12.10.14" class="ltx_td ltx_align_center">71.59</td>
</tr>
<tr id="S3.T1.1.1.13.11" class="ltx_tr">
<td id="S3.T1.1.1.13.11.1" class="ltx_td ltx_align_center ltx_border_r">COCA <cite class="ltx_cite ltx_citemacro_citep">(Lao et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2023</a>)</cite>
</td>
<td id="S3.T1.1.1.13.11.2" class="ltx_td ltx_align_center">79.35</td>
<td id="S3.T1.1.1.13.11.3" class="ltx_td ltx_align_center"><span id="S3.T1.1.1.13.11.3.1" class="ltx_text ltx_font_bold">67.68</span></td>
<td id="S3.T1.1.1.13.11.4" class="ltx_td ltx_align_center ltx_border_r">75.42</td>
<td id="S3.T1.1.1.13.11.5" class="ltx_td ltx_align_center">75.10</td>
<td id="S3.T1.1.1.13.11.6" class="ltx_td ltx_align_center">75.43</td>
<td id="S3.T1.1.1.13.11.7" class="ltx_td ltx_align_center ltx_border_r">75.23</td>
<td id="S3.T1.1.1.13.11.8" class="ltx_td ltx_align_center"><span id="S3.T1.1.1.13.11.8.1" class="ltx_text ltx_font_bold">83.50</span></td>
<td id="S3.T1.1.1.13.11.9" class="ltx_td ltx_align_center">66.63</td>
<td id="S3.T1.1.1.13.11.10" class="ltx_td ltx_align_center">69.72</td>
<td id="S3.T1.1.1.13.11.11" class="ltx_td ltx_align_center">64.12</td>
<td id="S3.T1.1.1.13.11.12" class="ltx_td ltx_align_center">65.57</td>
<td id="S3.T1.1.1.13.11.13" class="ltx_td ltx_align_center ltx_border_r">69.96</td>
<td id="S3.T1.1.1.13.11.14" class="ltx_td ltx_align_center">72.33</td>
</tr>
<tr id="S3.T1.1.1.14.12" class="ltx_tr">
<td id="S3.T1.1.1.14.12.1" class="ltx_td ltx_align_center ltx_border_r">PSTP-Net <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite>
</td>
<td id="S3.T1.1.1.14.12.2" class="ltx_td ltx_align_center">73.97</td>
<td id="S3.T1.1.1.14.12.3" class="ltx_td ltx_align_center">65.59</td>
<td id="S3.T1.1.1.14.12.4" class="ltx_td ltx_align_center ltx_border_r">70.91</td>
<td id="S3.T1.1.1.14.12.5" class="ltx_td ltx_align_center">77.15</td>
<td id="S3.T1.1.1.14.12.6" class="ltx_td ltx_align_center">77.36</td>
<td id="S3.T1.1.1.14.12.7" class="ltx_td ltx_align_center ltx_border_r">77.26</td>
<td id="S3.T1.1.1.14.12.8" class="ltx_td ltx_align_center">76.18</td>
<td id="S3.T1.1.1.14.12.9" class="ltx_td ltx_align_center">72.23</td>
<td id="S3.T1.1.1.14.12.10" class="ltx_td ltx_align_center"><span id="S3.T1.1.1.14.12.10.1" class="ltx_text ltx_framed ltx_framed_underline">71.80</span></td>
<td id="S3.T1.1.1.14.12.11" class="ltx_td ltx_align_center"><span id="S3.T1.1.1.14.12.11.1" class="ltx_text ltx_font_bold">71.79</span></td>
<td id="S3.T1.1.1.14.12.12" class="ltx_td ltx_align_center"><span id="S3.T1.1.1.14.12.12.1" class="ltx_text ltx_framed ltx_framed_underline">69.00</span></td>
<td id="S3.T1.1.1.14.12.13" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T1.1.1.14.12.13.1" class="ltx_text ltx_framed ltx_framed_underline">72.57</span></td>
<td id="S3.T1.1.1.14.12.14" class="ltx_td ltx_align_center">73.52</td>
</tr>
<tr id="S3.T1.1.1.15.13" class="ltx_tr">
<td id="S3.T1.1.1.15.13.1" class="ltx_td ltx_align_center ltx_border_r">LAVISH <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2023</a>)</cite>
</td>
<td id="S3.T1.1.1.15.13.2" class="ltx_td ltx_align_center"><span id="S3.T1.1.1.15.13.2.1" class="ltx_text ltx_framed ltx_framed_underline">82.09</span></td>
<td id="S3.T1.1.1.15.13.3" class="ltx_td ltx_align_center">65.56</td>
<td id="S3.T1.1.1.15.13.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T1.1.1.15.13.4.1" class="ltx_text ltx_framed ltx_framed_underline">75.97</span></td>
<td id="S3.T1.1.1.15.13.5" class="ltx_td ltx_align_center"><span id="S3.T1.1.1.15.13.5.1" class="ltx_text ltx_framed ltx_framed_underline">78.98</span></td>
<td id="S3.T1.1.1.15.13.6" class="ltx_td ltx_align_center"><span id="S3.T1.1.1.15.13.6.1" class="ltx_text ltx_framed ltx_framed_underline">81.43</span></td>
<td id="S3.T1.1.1.15.13.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T1.1.1.15.13.7.1" class="ltx_text ltx_framed ltx_framed_underline">80.22</span></td>
<td id="S3.T1.1.1.15.13.8" class="ltx_td ltx_align_center">81.71</td>
<td id="S3.T1.1.1.15.13.9" class="ltx_td ltx_align_center"><span id="S3.T1.1.1.15.13.9.1" class="ltx_text ltx_framed ltx_framed_underline">75.51</span></td>
<td id="S3.T1.1.1.15.13.10" class="ltx_td ltx_align_center">66.13</td>
<td id="S3.T1.1.1.15.13.11" class="ltx_td ltx_align_center">63.77</td>
<td id="S3.T1.1.1.15.13.12" class="ltx_td ltx_align_center">67.96</td>
<td id="S3.T1.1.1.15.13.13" class="ltx_td ltx_align_center ltx_border_r">71.26</td>
<td id="S3.T1.1.1.15.13.14" class="ltx_td ltx_align_center"><span id="S3.T1.1.1.15.13.14.1" class="ltx_text ltx_framed ltx_framed_underline">74.46</span></td>
</tr>
<tr id="S3.T1.1.1.16.14" class="ltx_tr">
<td id="S3.T1.1.1.16.14.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T1.1.1.16.14.1.1" class="ltx_text ltx_font_bold">TSPM</span> (Ours)</td>
<td id="S3.T1.1.1.16.14.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S3.T1.1.1.16.14.2.1" class="ltx_text ltx_font_bold">84.07</span></td>
<td id="S3.T1.1.1.16.14.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">64.65</td>
<td id="S3.T1.1.1.16.14.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T1.1.1.16.14.4.1" class="ltx_text ltx_font_bold">76.91</span></td>
<td id="S3.T1.1.1.16.14.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S3.T1.1.1.16.14.5.1" class="ltx_text ltx_font_bold">82.29</span></td>
<td id="S3.T1.1.1.16.14.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S3.T1.1.1.16.14.6.1" class="ltx_text ltx_font_bold">84.90</span></td>
<td id="S3.T1.1.1.16.14.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T1.1.1.16.14.7.1" class="ltx_text ltx_font_bold">83.61</span></td>
<td id="S3.T1.1.1.16.14.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">82.19</td>
<td id="S3.T1.1.1.16.14.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S3.T1.1.1.16.14.9.1" class="ltx_text ltx_font_bold">76.21</span></td>
<td id="S3.T1.1.1.16.14.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S3.T1.1.1.16.14.10.1" class="ltx_text ltx_font_bold">71.85</span></td>
<td id="S3.T1.1.1.16.14.11" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S3.T1.1.1.16.14.11.1" class="ltx_text ltx_framed ltx_framed_underline">65.76</span></td>
<td id="S3.T1.1.1.16.14.12" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S3.T1.1.1.16.14.12.1" class="ltx_text ltx_font_bold">71.17</span></td>
<td id="S3.T1.1.1.16.14.13" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T1.1.1.16.14.13.1" class="ltx_text ltx_font_bold">73.51</span></td>
<td id="S3.T1.1.1.16.14.14" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S3.T1.1.1.16.14.14.1" class="ltx_text ltx_font_bold">76.79</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Temporal-Spatial Perception Model results on the test set of MUSIC-AVQA. The top-2 results are highlighted.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Experiments</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Datasets</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">MUSIC-AVQA</span> <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite>, it contains 9,288 videos covering 22 different musical instruments, with a total duration of over 150 hours and 45,867 question-answering pairs.
The questions are designed under multi-modal scenes containing 33 question templates covering nine types,
i.e., the audio-visual, separate visual, and separate audio, depending on which modalities are used to discover question-related clues for answer prediction.
The diversity question-answering pairs which occupy a large portion of the entire dataset, and there are five audio-visual question types referring to
<span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_italic">existential</span>, <span id="S4.SS1.p1.1.3" class="ltx_text ltx_font_italic">counting</span>, <span id="S4.SS1.p1.1.4" class="ltx_text ltx_font_italic">location</span>, <span id="S4.SS1.p1.1.5" class="ltx_text ltx_font_italic">comparative</span>, and <span id="S4.SS1.p1.1.6" class="ltx_text ltx_font_italic">temporal</span>.
The large-scale MUSIC-AVQA dataset is well suited for studying temporal-spatial perception for dynamic and long-term audio-visual scenes.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">AVQA</span> <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite>, is designed for audio-visual question answering in general real-life scenario videos. It contains 57,015 videos from daily audio-visual activities, along with 57,335 question-answering pairs designed relying on clues from both modalities, where information from a single modality is insufficient or ambiguous.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">For both datasets, we adopt the official split of the two benchmarks into
training, evaluation, and test sets.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Implementation Details</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.8" class="ltx_p">For the visual stream, we divide the video into <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mn id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><cn type="integer" id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">1</annotation></semantics></math>-second segments and sample frames at a rate of <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="1fps" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mn id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.1a" xref="S4.SS2.p1.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.4" xref="S4.SS2.p1.2.m2.1.1.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.1b" xref="S4.SS2.p1.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.5" xref="S4.SS2.p1.2.m2.1.1.5.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><times id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1"></times><cn type="integer" id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">1</cn><ci id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3">𝑓</ci><ci id="S4.SS2.p1.2.m2.1.1.4.cmml" xref="S4.SS2.p1.2.m2.1.1.4">𝑝</ci><ci id="S4.SS2.p1.2.m2.1.1.5.cmml" xref="S4.SS2.p1.2.m2.1.1.5">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">1fps</annotation></semantics></math>.
We utilize the CLIP-ViT-L/14 <cite class="ltx_cite ltx_citemacro_citep">(Radford et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2021</a>)</cite> model pre-trained on ImageNet to extract 512-<math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mi id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><ci id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">D</annotation></semantics></math> feature representations for each visual segment, where <math id="S4.SS2.p1.4.m4.1" class="ltx_Math" alttext="[CLS]" display="inline"><semantics id="S4.SS2.p1.4.m4.1a"><mrow id="S4.SS2.p1.4.m4.1.1.1" xref="S4.SS2.p1.4.m4.1.1.2.cmml"><mo stretchy="false" id="S4.SS2.p1.4.m4.1.1.1.2" xref="S4.SS2.p1.4.m4.1.1.2.1.cmml">[</mo><mrow id="S4.SS2.p1.4.m4.1.1.1.1" xref="S4.SS2.p1.4.m4.1.1.1.1.cmml"><mi id="S4.SS2.p1.4.m4.1.1.1.1.2" xref="S4.SS2.p1.4.m4.1.1.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.4.m4.1.1.1.1.1" xref="S4.SS2.p1.4.m4.1.1.1.1.1.cmml">​</mo><mi id="S4.SS2.p1.4.m4.1.1.1.1.3" xref="S4.SS2.p1.4.m4.1.1.1.1.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.4.m4.1.1.1.1.1a" xref="S4.SS2.p1.4.m4.1.1.1.1.1.cmml">​</mo><mi id="S4.SS2.p1.4.m4.1.1.1.1.4" xref="S4.SS2.p1.4.m4.1.1.1.1.4.cmml">S</mi></mrow><mo stretchy="false" id="S4.SS2.p1.4.m4.1.1.1.3" xref="S4.SS2.p1.4.m4.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><apply id="S4.SS2.p1.4.m4.1.1.2.cmml" xref="S4.SS2.p1.4.m4.1.1.1"><csymbol cd="latexml" id="S4.SS2.p1.4.m4.1.1.2.1.cmml" xref="S4.SS2.p1.4.m4.1.1.1.2">delimited-[]</csymbol><apply id="S4.SS2.p1.4.m4.1.1.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1.1.1"><times id="S4.SS2.p1.4.m4.1.1.1.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1.1.1.1"></times><ci id="S4.SS2.p1.4.m4.1.1.1.1.2.cmml" xref="S4.SS2.p1.4.m4.1.1.1.1.2">𝐶</ci><ci id="S4.SS2.p1.4.m4.1.1.1.1.3.cmml" xref="S4.SS2.p1.4.m4.1.1.1.1.3">𝐿</ci><ci id="S4.SS2.p1.4.m4.1.1.1.1.4.cmml" xref="S4.SS2.p1.4.m4.1.1.1.1.4">𝑆</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">[CLS]</annotation></semantics></math> token denotes visual frame-level features.
For the audio signal, it is sampled at 16kHz, which is a standard sampling rate for audio.
we use the VGGish network pre-trained on AudioSet to extract 128-<math id="S4.SS2.p1.5.m5.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS2.p1.5.m5.1a"><mi id="S4.SS2.p1.5.m5.1.1" xref="S4.SS2.p1.5.m5.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m5.1b"><ci id="S4.SS2.p1.5.m5.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m5.1c">D</annotation></semantics></math> features.
For each input question sentence, we extract its feature same as visual frame-level encoder to obtain 512-<math id="S4.SS2.p1.6.m6.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS2.p1.6.m6.1a"><mi id="S4.SS2.p1.6.m6.1.1" xref="S4.SS2.p1.6.m6.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.6.m6.1b"><ci id="S4.SS2.p1.6.m6.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.6.m6.1c">D</annotation></semantics></math> feature vector.
In all experiments, we use Adam optimizer with an initial learning rate of <math id="S4.SS2.p1.7.m7.1" class="ltx_Math" alttext="1e" display="inline"><semantics id="S4.SS2.p1.7.m7.1a"><mrow id="S4.SS2.p1.7.m7.1.1" xref="S4.SS2.p1.7.m7.1.1.cmml"><mn id="S4.SS2.p1.7.m7.1.1.2" xref="S4.SS2.p1.7.m7.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS2.p1.7.m7.1.1.1" xref="S4.SS2.p1.7.m7.1.1.1.cmml">​</mo><mi id="S4.SS2.p1.7.m7.1.1.3" xref="S4.SS2.p1.7.m7.1.1.3.cmml">e</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.7.m7.1b"><apply id="S4.SS2.p1.7.m7.1.1.cmml" xref="S4.SS2.p1.7.m7.1.1"><times id="S4.SS2.p1.7.m7.1.1.1.cmml" xref="S4.SS2.p1.7.m7.1.1.1"></times><cn type="integer" id="S4.SS2.p1.7.m7.1.1.2.cmml" xref="S4.SS2.p1.7.m7.1.1.2">1</cn><ci id="S4.SS2.p1.7.m7.1.1.3.cmml" xref="S4.SS2.p1.7.m7.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.7.m7.1c">1e</annotation></semantics></math>-4, and will drop by multiplying 0.1 every 10 epochs. The batch size and number of epochs are set to 64 and 30, respectively.
We use the <math id="S4.SS2.p1.8.m8.1" class="ltx_Math" alttext="thop" display="inline"><semantics id="S4.SS2.p1.8.m8.1a"><mrow id="S4.SS2.p1.8.m8.1.1" xref="S4.SS2.p1.8.m8.1.1.cmml"><mi id="S4.SS2.p1.8.m8.1.1.2" xref="S4.SS2.p1.8.m8.1.1.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.8.m8.1.1.1" xref="S4.SS2.p1.8.m8.1.1.1.cmml">​</mo><mi id="S4.SS2.p1.8.m8.1.1.3" xref="S4.SS2.p1.8.m8.1.1.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.8.m8.1.1.1a" xref="S4.SS2.p1.8.m8.1.1.1.cmml">​</mo><mi id="S4.SS2.p1.8.m8.1.1.4" xref="S4.SS2.p1.8.m8.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.8.m8.1.1.1b" xref="S4.SS2.p1.8.m8.1.1.1.cmml">​</mo><mi id="S4.SS2.p1.8.m8.1.1.5" xref="S4.SS2.p1.8.m8.1.1.5.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.8.m8.1b"><apply id="S4.SS2.p1.8.m8.1.1.cmml" xref="S4.SS2.p1.8.m8.1.1"><times id="S4.SS2.p1.8.m8.1.1.1.cmml" xref="S4.SS2.p1.8.m8.1.1.1"></times><ci id="S4.SS2.p1.8.m8.1.1.2.cmml" xref="S4.SS2.p1.8.m8.1.1.2">𝑡</ci><ci id="S4.SS2.p1.8.m8.1.1.3.cmml" xref="S4.SS2.p1.8.m8.1.1.3">ℎ</ci><ci id="S4.SS2.p1.8.m8.1.1.4.cmml" xref="S4.SS2.p1.8.m8.1.1.4">𝑜</ci><ci id="S4.SS2.p1.8.m8.1.1.5.cmml" xref="S4.SS2.p1.8.m8.1.1.5">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.8.m8.1c">thop</annotation></semantics></math> library in PyTorch to calculate the model’s parameters and FLOPs. Our proposed model is trained on NVIDIA GeForce RTX 3090 and implemented in PyTorch.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Quantitative Results and Analysis</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">To verify the effectiveness of the proposed TSPM, we compare it with multiple existing methods:
AVSD <cite class="ltx_cite ltx_citemacro_citep">(Schwartz et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2019</a>)</cite>, Pano-AVQA <cite class="ltx_cite ltx_citemacro_citep">(Yun et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2021</a>)</cite>, AVST <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite>, LAVISH <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2023</a>)</cite>, COCA <cite class="ltx_cite ltx_citemacro_citep">(Lao et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2023</a>)</cite>, PSTP-Net <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite>, <em id="S4.SS3.p1.1.1" class="ltx_emph ltx_font_italic">etc.</em>
Tab. <a href="#S3.T1" title="Table 1 ‣ 3.4. Multimodal Fusion and Answer Prediction ‣ 3. Method ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> indicates that the TSPM outperforms all comparison methods.
Specially, the TSPM method shows significant improvements in the subtask types of <span id="S4.SS3.p1.1.2" class="ltx_text ltx_font_italic">Audio-visual</span>, including <span id="S4.SS3.p1.1.3" class="ltx_text ltx_font_italic">Localization</span>, and <span id="S4.SS3.p1.1.4" class="ltx_text ltx_font_italic">Temporal</span>.
Specifically, compared to the recent PSTP-Net <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite>, the model achieves remarkable improvements of 0.92% (73.51% and 71.26%) in the above-mentioned complex audio-visual question types.
It is worth noting that the model shows a performance boost of 5.14% (82.29% and 77.15%) and 7.54% (84.90% and 77.36%) in the <span id="S4.SS3.p1.1.5" class="ltx_text ltx_font_italic">Counting</span> and <span id="S4.SS3.p1.1.6" class="ltx_text ltx_font_italic">Localization</span> subtasks of the visual modality, respectively, when compared to PSTP-Net <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite>.
The significant performance improvements indicate that our TSPM effectively identifies crucial temporal segments and spatial tokens in videos.
Moreover, in comparison to LAVISH <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2023</a>)</cite>, which fine-tunes large pretrained models, our model demonstrates superior efficiency without the need for fine-tuning.
We conducted tests with an equal number of epochs under the same hardware configuration, and it was observed that LAVISH incurred a cost of 14<math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="\mathit{\times}" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mo id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><times id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\mathit{\times}</annotation></semantics></math> higher than our model.
Additionally, we observed limitations in the performance of <span id="S4.SS3.p1.1.7" class="ltx_text ltx_font_italic">Comparative</span> type questions, and we consider this may be attributed to the challenges of separating multiple sounds in complex audio-visual scenes. This motivates us to explore strategies (such as dynamic fusion) in future work that can achieve better performance on both single-modality and multi-modality aspects.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<div id="S4.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:441.0pt;height:109pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table id="S4.T2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<th id="S4.T2.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Audio</span></th>
<th id="S4.T2.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Visual</span></th>
<th id="S4.T2.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Audio-Visual</span></th>
<th id="S4.T2.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.1.1.5.1" class="ltx_text ltx_font_bold">Avg</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.1.2.1" class="ltx_tr">
<th id="S4.T2.1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">AVSD <cite class="ltx_cite ltx_citemacro_citep">(Schwartz et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2019</a>)</cite>
</th>
<td id="S4.T2.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">71.74</td>
<td id="S4.T2.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">69.21</td>
<td id="S4.T2.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.41</td>
<td id="S4.T2.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">67.53</td>
</tr>
<tr id="S4.T2.1.1.3.2" class="ltx_tr">
<th id="S4.T2.1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">ST-AVQA <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite>
</th>
<td id="S4.T2.1.1.3.2.2" class="ltx_td ltx_align_center">71.74</td>
<td id="S4.T2.1.1.3.2.3" class="ltx_td ltx_align_center">70.71</td>
<td id="S4.T2.1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r">66.53</td>
<td id="S4.T2.1.1.3.2.5" class="ltx_td ltx_align_center">68.56</td>
</tr>
<tr id="S4.T2.1.1.4.3" class="ltx_tr">
<th id="S4.T2.1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">LAVISH <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2023</a>)</cite>
</th>
<td id="S4.T2.1.1.4.3.2" class="ltx_td ltx_align_center">73.00</td>
<td id="S4.T2.1.1.4.3.3" class="ltx_td ltx_align_center"><span id="S4.T2.1.1.4.3.3.1" class="ltx_text ltx_framed ltx_framed_underline">77.62</span></td>
<td id="S4.T2.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.1.1.4.3.4.1" class="ltx_text ltx_framed ltx_framed_underline">70.09</span></td>
<td id="S4.T2.1.1.4.3.5" class="ltx_td ltx_align_center"><span id="S4.T2.1.1.4.3.5.1" class="ltx_text ltx_framed ltx_framed_underline">72.60</span></td>
</tr>
<tr id="S4.T2.1.1.5.4" class="ltx_tr">
<th id="S4.T2.1.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">PSTP-Net <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite>
</th>
<td id="S4.T2.1.1.5.4.2" class="ltx_td ltx_align_center"><span id="S4.T2.1.1.5.4.2.1" class="ltx_text ltx_framed ltx_framed_underline">73.58</span></td>
<td id="S4.T2.1.1.5.4.3" class="ltx_td ltx_align_center">76.44</td>
<td id="S4.T2.1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r">67.66</td>
<td id="S4.T2.1.1.5.4.5" class="ltx_td ltx_align_center">71.06</td>
</tr>
<tr id="S4.T2.1.1.6.5" class="ltx_tr">
<th id="S4.T2.1.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T2.1.1.6.5.1.1" class="ltx_text ltx_font_bold">TSPM</span> (Ours)</th>
<td id="S4.T2.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.1.1.6.5.2.1" class="ltx_text ltx_font_bold">76.93</span></td>
<td id="S4.T2.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.1.1.6.5.3.1" class="ltx_text ltx_font_bold">81.07</span></td>
<td id="S4.T2.1.1.6.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.1.1.6.5.4.1" class="ltx_text ltx_font_bold">71.93</span></td>
<td id="S4.T2.1.1.6.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.1.1.6.5.5.1" class="ltx_text ltx_font_bold">75.27</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2. </span>TSPM results on the test set of MUSIC-AVQA (split by video id). The top-2 results are highlighted.</figcaption>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">To further validate the capabilities of the proposed TSPM, in contrast to splitting by <span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_italic">Question ID</span>, we also partitioned the MUSIC-AVQA dataset based on <span id="S4.SS3.p2.1.2" class="ltx_text ltx_font_italic">Video ID</span>, apportioning it into training, validation, and test sets in a ratio of <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="7:1:2" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mrow id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mn id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml">7</mn><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.p2.1.m1.1.1.3" xref="S4.SS3.p2.1.m1.1.1.3.cmml">:</mo><mn id="S4.SS3.p2.1.m1.1.1.4" xref="S4.SS3.p2.1.m1.1.1.4.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.p2.1.m1.1.1.5" xref="S4.SS3.p2.1.m1.1.1.5.cmml">:</mo><mn id="S4.SS3.p2.1.m1.1.1.6" xref="S4.SS3.p2.1.m1.1.1.6.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><and id="S4.SS3.p2.1.m1.1.1a.cmml" xref="S4.SS3.p2.1.m1.1.1"></and><apply id="S4.SS3.p2.1.m1.1.1b.cmml" xref="S4.SS3.p2.1.m1.1.1"><ci id="S4.SS3.p2.1.m1.1.1.3.cmml" xref="S4.SS3.p2.1.m1.1.1.3">:</ci><cn type="integer" id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2">7</cn><cn type="integer" id="S4.SS3.p2.1.m1.1.1.4.cmml" xref="S4.SS3.p2.1.m1.1.1.4">1</cn></apply><apply id="S4.SS3.p2.1.m1.1.1c.cmml" xref="S4.SS3.p2.1.m1.1.1"><ci id="S4.SS3.p2.1.m1.1.1.5.cmml" xref="S4.SS3.p2.1.m1.1.1.5">:</ci><share href="#S4.SS3.p2.1.m1.1.1.4.cmml" id="S4.SS3.p2.1.m1.1.1d.cmml" xref="S4.SS3.p2.1.m1.1.1"></share><cn type="integer" id="S4.SS3.p2.1.m1.1.1.6.cmml" xref="S4.SS3.p2.1.m1.1.1.6">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">7:1:2</annotation></semantics></math>.
As shown in Tab. <a href="#S4.T2" title="Table 2 ‣ 4.3. Quantitative Results and Analysis ‣ 4. Experiments ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, it can be seen that our proposed TSPM achieves the best overall performance compared to the latest AVQA methods. Particularly, in the three subtask types of audio, visual, and audio-visual, our TSPM outperforms others significantly, showcasing the excellent generalization capability and performance of the proposed TSPM.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">In summary, the TSPM offers significant improvements over existing approaches and provides a novel insight into question-oriented audio-visual scene understanding.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Ablation Studies</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">In this subsection, we delve into examining the impact of various modules within the TSPM on the performance of the MUSIC-AVQA.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">To verify the effectiveness of the proposed components,
<em id="S4.SS4.p2.1.1" class="ltx_emph ltx_font_italic">i.e.</em>, TPM, SPM, TPC, Tokens merge, <em id="S4.SS4.p2.1.2" class="ltx_emph ltx_font_italic">etc.</em>, we remove them from the primary model and re-evaluate the new model’s performance.
Tab. <a href="#S4.T3" title="Table 3 ‣ 1st item ‣ 4.4. Ablation Studies ‣ 4. Experiments ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows that after removing a single component, the overall model’s performance decreases, and different modules have different performance
effects. The specific analysis is as follows:</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">TSPM <span id="S4.I1.i1.p1.1.1.1" class="ltx_text ltx_font_italic">w/o.</span> all</span>.
When we remove all designed modules or components within the framework, retaining only the simple fusion operation of input audio, video, and question features, a significant decline (76.79% and 73.35%) in model performance can be clearly observed from Tab. <a href="#S4.T3" title="Table 3 ‣ 1st item ‣ 4.4. Ablation Studies ‣ 4. Experiments ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
This pronounced deterioration serves as compelling evidence that the multiple components intricately designed within the proposed TSPM play a pivotal role in bolstering the model’s overall effectiveness.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<div id="S4.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:254.7pt;height:144pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table id="S4.T3.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;"><span id="S4.T3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<td id="S4.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;"><span id="S4.T3.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Audio</span></td>
<td id="S4.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;"><span id="S4.T3.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Visual</span></td>
<td id="S4.T3.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;"><span id="S4.T3.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Audio-Visual</span></td>
<td id="S4.T3.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;"><span id="S4.T3.1.1.1.1.5.1" class="ltx_text ltx_font_bold">Avg</span></td>
</tr>
<tr id="S4.T3.1.1.2.2" class="ltx_tr">
<th id="S4.T3.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;">
<span id="S4.T3.1.1.2.2.1.1" class="ltx_text ltx_font_italic">w/o.</span> all</th>
<td id="S4.T3.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;">73.93</td>
<td id="S4.T3.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;">79.23</td>
<td id="S4.T3.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;">70.37</td>
<td id="S4.T3.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;">73.35</td>
</tr>
<tr id="S4.T3.1.1.3.3" class="ltx_tr">
<th id="S4.T3.1.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:5.3pt;padding-right:5.3pt;">
<span id="S4.T3.1.1.3.3.1.1" class="ltx_text ltx_font_italic">w/o.</span> TPM</th>
<td id="S4.T3.1.1.3.3.2" class="ltx_td ltx_align_center" style="padding-left:5.3pt;padding-right:5.3pt;">75.85</td>
<td id="S4.T3.1.1.3.3.3" class="ltx_td ltx_align_center" style="padding-left:5.3pt;padding-right:5.3pt;">82.74</td>
<td id="S4.T3.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.3pt;padding-right:5.3pt;">72.53</td>
<td id="S4.T3.1.1.3.3.5" class="ltx_td ltx_align_center" style="padding-left:5.3pt;padding-right:5.3pt;">75.82</td>
</tr>
<tr id="S4.T3.1.1.4.4" class="ltx_tr">
<th id="S4.T3.1.1.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:5.3pt;padding-right:5.3pt;">
<span id="S4.T3.1.1.4.4.1.1" class="ltx_text ltx_font_italic">w/o.</span> SPM</th>
<td id="S4.T3.1.1.4.4.2" class="ltx_td ltx_align_center" style="padding-left:5.3pt;padding-right:5.3pt;">77.16</td>
<td id="S4.T3.1.1.4.4.3" class="ltx_td ltx_align_center" style="padding-left:5.3pt;padding-right:5.3pt;">81.92</td>
<td id="S4.T3.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.3pt;padding-right:5.3pt;">72.25</td>
<td id="S4.T3.1.1.4.4.5" class="ltx_td ltx_align_center" style="padding-left:5.3pt;padding-right:5.3pt;">75.68</td>
</tr>
<tr id="S4.T3.1.1.5.5" class="ltx_tr">
<th id="S4.T3.1.1.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;">
<span id="S4.T3.1.1.5.5.1.1" class="ltx_text ltx_font_italic">w/o.</span> TPC</th>
<td id="S4.T3.1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;">75.54</td>
<td id="S4.T3.1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;">82.20</td>
<td id="S4.T3.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;">72.96</td>
<td id="S4.T3.1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;">75.87</td>
</tr>
<tr id="S4.T3.1.1.6.6" class="ltx_tr">
<th id="S4.T3.1.1.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:5.3pt;padding-right:5.3pt;">
<span id="S4.T3.1.1.6.6.1.1" class="ltx_text ltx_font_italic">w/.</span> QPrompt</th>
<td id="S4.T3.1.1.6.6.2" class="ltx_td ltx_align_center" style="padding-left:5.3pt;padding-right:5.3pt;">76.47</td>
<td id="S4.T3.1.1.6.6.3" class="ltx_td ltx_align_center" style="padding-left:5.3pt;padding-right:5.3pt;">81.30</td>
<td id="S4.T3.1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.3pt;padding-right:5.3pt;">71.82</td>
<td id="S4.T3.1.1.6.6.5" class="ltx_td ltx_align_center" style="padding-left:5.3pt;padding-right:5.3pt;">75.16</td>
</tr>
<tr id="S4.T3.1.1.7.7" class="ltx_tr">
<th id="S4.T3.1.1.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:5.3pt;padding-right:5.3pt;">
<span id="S4.T3.1.1.7.7.1.1" class="ltx_text ltx_font_italic">w/o.</span> Merge</th>
<td id="S4.T3.1.1.7.7.2" class="ltx_td ltx_align_center" style="padding-left:5.3pt;padding-right:5.3pt;">75.79</td>
<td id="S4.T3.1.1.7.7.3" class="ltx_td ltx_align_center" style="padding-left:5.3pt;padding-right:5.3pt;">82.91</td>
<td id="S4.T3.1.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.3pt;padding-right:5.3pt;">72.84</td>
<td id="S4.T3.1.1.7.7.5" class="ltx_td ltx_align_center" style="padding-left:5.3pt;padding-right:5.3pt;">76.03</td>
</tr>
<tr id="S4.T3.1.1.8.8" class="ltx_tr">
<th id="S4.T3.1.1.8.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;">
<span id="S4.T3.1.1.8.8.1.1" class="ltx_text ltx_font_bold">TSPM</span> (Ours)</th>
<td id="S4.T3.1.1.8.8.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;">76.91</td>
<td id="S4.T3.1.1.8.8.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;">83.61</td>
<td id="S4.T3.1.1.8.8.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;">73.51</td>
<td id="S4.T3.1.1.8.8.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:5.3pt;padding-right:5.3pt;">76.79</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3. </span>TSPM’s module configuration results.</figcaption>
</figure>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">TSPM <span id="S4.I1.i2.p1.1.1.1" class="ltx_text ltx_font_italic">w/o.</span> TPM</span>.
The motivation behind designing the TPM is to enable the model to select temporal segments most relevant to the given question. To validate the necessity of the TPM, we removed the TPM from the TSPM and assessed the performance of the new model.
As shown in Tab. <a href="#S4.T3" title="Table 3 ‣ 1st item ‣ 4.4. Ablation Studies ‣ 4. Experiments ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>,
when the TPM was removed, the new model’s performance decreased to 75.82%, representing a 0.97% decrease compared to when TPM was utilized.
Furthermore, noticeable performance declines were observed across the audio, visual, and audio-visual subtask types.
These experimental results underscore the importance of TPM, which effectively enables the model to perceive crucial temporal segments, thereby enhancing temporal perception performance.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">TSPM <span id="S4.I1.i3.p1.1.1.1" class="ltx_text ltx_font_italic">w/o.</span> SPM</span>.
The purpose of the SPM is to identify key objects and potential sound-aware areas within the selected visual frame. To demonstrate the significance of the SPM, we conducted an experiment where it is removed.
As shown in Tab. <a href="#S4.T3" title="Table 3 ‣ 1st item ‣ 4.4. Ablation Studies ‣ 4. Experiments ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, compared with TSPM, the result decreased to by 1.11% (from
76.79% to 75.68%), indicating the importance of spatial perception in improving performance.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<div id="S4.T4.4.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:264.5pt;height:162pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table id="S4.T4.4.4.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.4.4.4.5.1" class="ltx_tr">
<th id="S4.T4.4.4.4.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;"><span id="S4.T4.4.4.4.5.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<td id="S4.T4.4.4.4.5.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;"><span id="S4.T4.4.4.4.5.1.2.1" class="ltx_text ltx_font_bold">Audio</span></td>
<td id="S4.T4.4.4.4.5.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;"><span id="S4.T4.4.4.4.5.1.3.1" class="ltx_text ltx_font_bold">Visual</span></td>
<td id="S4.T4.4.4.4.5.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;"><span id="S4.T4.4.4.4.5.1.4.1" class="ltx_text ltx_font_bold">Audio-visual</span></td>
<td id="S4.T4.4.4.4.5.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;"><span id="S4.T4.4.4.4.5.1.5.1" class="ltx_text ltx_font_bold">Avg</span></td>
</tr>
<tr id="S4.T4.1.1.1.1" class="ltx_tr">
<th id="S4.T4.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;">Top-<math id="S4.T4.1.1.1.1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.T4.1.1.1.1.1.m1.1a"><mi id="S4.T4.1.1.1.1.1.m1.1.1" xref="S4.T4.1.1.1.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.1.m1.1b"><ci id="S4.T4.1.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.1.m1.1c">k</annotation></semantics></math>=10</th>
<td id="S4.T4.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;">76.91</td>
<td id="S4.T4.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;">83.61</td>
<td id="S4.T4.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;">73.51</td>
<td id="S4.T4.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;">76.79</td>
</tr>
<tr id="S4.T4.2.2.2.2" class="ltx_tr">
<th id="S4.T4.2.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:6.5pt;padding-right:6.5pt;">Top-<math id="S4.T4.2.2.2.2.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.T4.2.2.2.2.1.m1.1a"><mi id="S4.T4.2.2.2.2.1.m1.1.1" xref="S4.T4.2.2.2.2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.2.1.m1.1b"><ci id="S4.T4.2.2.2.2.1.m1.1.1.cmml" xref="S4.T4.2.2.2.2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.2.1.m1.1c">k</annotation></semantics></math>=20</th>
<td id="S4.T4.2.2.2.2.2" class="ltx_td ltx_align_center" style="padding-left:6.5pt;padding-right:6.5pt;">76.60</td>
<td id="S4.T4.2.2.2.2.3" class="ltx_td ltx_align_center" style="padding-left:6.5pt;padding-right:6.5pt;">82.58</td>
<td id="S4.T4.2.2.2.2.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:6.5pt;padding-right:6.5pt;">73.41</td>
<td id="S4.T4.2.2.2.2.5" class="ltx_td ltx_align_center" style="padding-left:6.5pt;padding-right:6.5pt;">76.40</td>
</tr>
<tr id="S4.T4.3.3.3.3" class="ltx_tr">
<th id="S4.T4.3.3.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:6.5pt;padding-right:6.5pt;">Top-<math id="S4.T4.3.3.3.3.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.T4.3.3.3.3.1.m1.1a"><mi id="S4.T4.3.3.3.3.1.m1.1.1" xref="S4.T4.3.3.3.3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.3.1.m1.1b"><ci id="S4.T4.3.3.3.3.1.m1.1.1.cmml" xref="S4.T4.3.3.3.3.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.3.3.1.m1.1c">k</annotation></semantics></math>=30</th>
<td id="S4.T4.3.3.3.3.2" class="ltx_td ltx_align_center" style="padding-left:6.5pt;padding-right:6.5pt;">77.41</td>
<td id="S4.T4.3.3.3.3.3" class="ltx_td ltx_align_center" style="padding-left:6.5pt;padding-right:6.5pt;">82.70</td>
<td id="S4.T4.3.3.3.3.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:6.5pt;padding-right:6.5pt;">73.55</td>
<td id="S4.T4.3.3.3.3.5" class="ltx_td ltx_align_center" style="padding-left:6.5pt;padding-right:6.5pt;">76.66</td>
</tr>
<tr id="S4.T4.4.4.4.4" class="ltx_tr">
<th id="S4.T4.4.4.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:6.5pt;padding-right:6.5pt;">Top-<math id="S4.T4.4.4.4.4.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.T4.4.4.4.4.1.m1.1a"><mi id="S4.T4.4.4.4.4.1.m1.1.1" xref="S4.T4.4.4.4.4.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.4.4.1.m1.1b"><ci id="S4.T4.4.4.4.4.1.m1.1.1.cmml" xref="S4.T4.4.4.4.4.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.4.4.1.m1.1c">k</annotation></semantics></math>=40</th>
<td id="S4.T4.4.4.4.4.2" class="ltx_td ltx_align_center" style="padding-left:6.5pt;padding-right:6.5pt;">76.41</td>
<td id="S4.T4.4.4.4.4.3" class="ltx_td ltx_align_center" style="padding-left:6.5pt;padding-right:6.5pt;">82.78</td>
<td id="S4.T4.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:6.5pt;padding-right:6.5pt;">72.94</td>
<td id="S4.T4.4.4.4.4.5" class="ltx_td ltx_align_center" style="padding-left:6.5pt;padding-right:6.5pt;">76.16</td>
</tr>
<tr id="S4.T4.4.4.4.6.2" class="ltx_tr">
<th id="S4.T4.4.4.4.6.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;">tokens=8</th>
<td id="S4.T4.4.4.4.6.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;">75.54</td>
<td id="S4.T4.4.4.4.6.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;">82.00</td>
<td id="S4.T4.4.4.4.6.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;">73.08</td>
<td id="S4.T4.4.4.4.6.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;">75.88</td>
</tr>
<tr id="S4.T4.4.4.4.7.3" class="ltx_tr">
<th id="S4.T4.4.4.4.7.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:6.5pt;padding-right:6.5pt;">tokens=14</th>
<td id="S4.T4.4.4.4.7.3.2" class="ltx_td ltx_align_center" style="padding-left:6.5pt;padding-right:6.5pt;">76.91</td>
<td id="S4.T4.4.4.4.7.3.3" class="ltx_td ltx_align_center" style="padding-left:6.5pt;padding-right:6.5pt;">83.61</td>
<td id="S4.T4.4.4.4.7.3.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:6.5pt;padding-right:6.5pt;">73.51</td>
<td id="S4.T4.4.4.4.7.3.5" class="ltx_td ltx_align_center" style="padding-left:6.5pt;padding-right:6.5pt;">76.79</td>
</tr>
<tr id="S4.T4.4.4.4.8.4" class="ltx_tr">
<th id="S4.T4.4.4.4.8.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:6.5pt;padding-right:6.5pt;">tokens=27</th>
<td id="S4.T4.4.4.4.8.4.2" class="ltx_td ltx_align_center" style="padding-left:6.5pt;padding-right:6.5pt;">76.16</td>
<td id="S4.T4.4.4.4.8.4.3" class="ltx_td ltx_align_center" style="padding-left:6.5pt;padding-right:6.5pt;">82.20</td>
<td id="S4.T4.4.4.4.8.4.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:6.5pt;padding-right:6.5pt;">73.00</td>
<td id="S4.T4.4.4.4.8.4.5" class="ltx_td ltx_align_center" style="padding-left:6.5pt;padding-right:6.5pt;">76.00</td>
</tr>
<tr id="S4.T4.4.4.4.9.5" class="ltx_tr">
<th id="S4.T4.4.4.4.9.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;">
<span id="S4.T4.4.4.4.9.5.1.1" class="ltx_text ltx_font_bold">TSPM</span> (Ours)</th>
<td id="S4.T4.4.4.4.9.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;">76.91</td>
<td id="S4.T4.4.4.4.9.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;">83.61</td>
<td id="S4.T4.4.4.4.9.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;">73.51</td>
<td id="S4.T4.4.4.4.9.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:6.5pt;padding-right:6.5pt;">76.79</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4. </span>Effects of TSPM’s parameter configuration.</figcaption>
</figure>
<figure id="S4.T5" class="ltx_table">
<div id="S4.T5.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:427.7pt;height:97.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-37.7pt,8.5pt) scale(0.85,0.85) ;">
<table id="S4.T5.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.1.1.1.1" class="ltx_tr">
<th id="S4.T5.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T5.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<th id="S4.T5.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T5.1.1.1.1.2.1" class="ltx_text">
<span id="S4.T5.1.1.1.1.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T5.1.1.1.1.2.1.1.1" class="ltx_tr">
<span id="S4.T5.1.1.1.1.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.1.1.1.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">Visual</span></span></span>
<span id="S4.T5.1.1.1.1.2.1.1.2" class="ltx_tr">
<span id="S4.T5.1.1.1.1.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.1.1.1.1.2.1.1.2.1.1" class="ltx_text ltx_font_bold">Encoder</span></span></span>
</span></span></th>
<th id="S4.T5.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T5.1.1.1.1.3.1" class="ltx_text">
<span id="S4.T5.1.1.1.1.3.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T5.1.1.1.1.3.1.1.1" class="ltx_tr">
<span id="S4.T5.1.1.1.1.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.1.1.1.1.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Text</span></span></span>
<span id="S4.T5.1.1.1.1.3.1.1.2" class="ltx_tr">
<span id="S4.T5.1.1.1.1.3.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.1.1.1.1.3.1.1.2.1.1" class="ltx_text ltx_font_bold">Encoder</span></span></span>
</span></span></th>
<th id="S4.T5.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T5.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Audio</span></th>
<th id="S4.T5.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T5.1.1.1.1.5.1" class="ltx_text ltx_font_bold">Visual</span></th>
<th id="S4.T5.1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T5.1.1.1.1.6.1" class="ltx_text ltx_font_bold">A-V</span></th>
<th id="S4.T5.1.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T5.1.1.1.1.7.1" class="ltx_text ltx_font_bold">All</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.1.1.2.1" class="ltx_tr">
<td id="S4.T5.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T5.1.1.2.1.1.1" class="ltx_text">PSTP-Net <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite></span></td>
<td id="S4.T5.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">B/32</td>
<td id="S4.T5.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">B/32</td>
<td id="S4.T5.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">70.91</td>
<td id="S4.T5.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">77.26</td>
<td id="S4.T5.1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">72.57</td>
<td id="S4.T5.1.1.2.1.7" class="ltx_td ltx_align_center ltx_border_t">73.52</td>
</tr>
<tr id="S4.T5.1.1.3.2" class="ltx_tr">
<td id="S4.T5.1.1.3.2.1" class="ltx_td ltx_align_center">L/14</td>
<td id="S4.T5.1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r">L/14</td>
<td id="S4.T5.1.1.3.2.3" class="ltx_td ltx_align_center">73.87</td>
<td id="S4.T5.1.1.3.2.4" class="ltx_td ltx_align_center">79.19</td>
<td id="S4.T5.1.1.3.2.5" class="ltx_td ltx_align_center ltx_border_r">71.76</td>
<td id="S4.T5.1.1.3.2.6" class="ltx_td ltx_align_center">74.10</td>
</tr>
<tr id="S4.T5.1.1.4.3" class="ltx_tr">
<td id="S4.T5.1.1.4.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T5.1.1.4.3.1.1" class="ltx_text"><span id="S4.T5.1.1.4.3.1.1.1" class="ltx_text ltx_font_bold">TSPM</span> (Ours)</span></td>
<td id="S4.T5.1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_t">B/32</td>
<td id="S4.T5.1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">B/32</td>
<td id="S4.T5.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t">76.91</td>
<td id="S4.T5.1.1.4.3.5" class="ltx_td ltx_align_center ltx_border_t">81.92</td>
<td id="S4.T5.1.1.4.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">72.57</td>
<td id="S4.T5.1.1.4.3.7" class="ltx_td ltx_align_center ltx_border_t">75.81</td>
</tr>
<tr id="S4.T5.1.1.5.4" class="ltx_tr">
<td id="S4.T5.1.1.5.4.1" class="ltx_td ltx_align_center ltx_border_b">L/14</td>
<td id="S4.T5.1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">L/14</td>
<td id="S4.T5.1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_b">76.91</td>
<td id="S4.T5.1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_b">83.61</td>
<td id="S4.T5.1.1.5.4.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">73.51</td>
<td id="S4.T5.1.1.5.4.6" class="ltx_td ltx_align_center ltx_border_b">76.79</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5. </span>Different visual and textual feature extractors.</figcaption>
</figure>
<figure id="S4.T6" class="ltx_table">
<div id="S4.T6.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:451.6pt;height:87.4pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-9.4pt,1.8pt) scale(0.96,0.96) ;">
<table id="S4.T6.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.1.1.1.1" class="ltx_tr">
<th id="S4.T6.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T6.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<th id="S4.T6.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T6.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Training Param (M)</span></th>
<th id="S4.T6.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T6.1.1.1.1.3.1" class="ltx_text ltx_font_bold">FLOPs (G)</span></th>
<th id="S4.T6.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T6.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Acc (%)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.1.1.2.1" class="ltx_tr">
<th id="S4.T6.1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">ST-AVQA <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite>
</th>
<td id="S4.T6.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">18.48</td>
<td id="S4.T6.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.19</td>
<td id="S4.T6.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">71.59</td>
</tr>
<tr id="S4.T6.1.1.3.2" class="ltx_tr">
<th id="S4.T6.1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">PSTP-Net <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite>
</th>
<td id="S4.T6.1.1.3.2.2" class="ltx_td ltx_align_center">4.30</td>
<td id="S4.T6.1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r">1.22</td>
<td id="S4.T6.1.1.3.2.4" class="ltx_td ltx_align_center">73.52</td>
</tr>
<tr id="S4.T6.1.1.4.3" class="ltx_tr">
<th id="S4.T6.1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">LAVISH <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2023</a>)</cite>
</th>
<td id="S4.T6.1.1.4.3.2" class="ltx_td ltx_align_center">21.09</td>
<td id="S4.T6.1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r">–</td>
<td id="S4.T6.1.1.4.3.4" class="ltx_td ltx_align_center">74.46</td>
</tr>
<tr id="S4.T6.1.1.5.4" class="ltx_tr">
<th id="S4.T6.1.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T6.1.1.5.4.1.1" class="ltx_text ltx_font_bold">TSPM</span> (Ours)</th>
<td id="S4.T6.1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">6.22</td>
<td id="S4.T6.1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">1.42</td>
<td id="S4.T6.1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">76.79</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6. </span>Parameters and FLOPs.</figcaption>
</figure>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p"><span id="S4.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">TSPM <span id="S4.I1.i4.p1.1.1.1" class="ltx_text ltx_font_italic">w/o.</span> TPC</span>.
The designed TPC primarily generates declarative sentence text based on the given question, aligning it with the semantics of video frames to better identify temporal segments relevant to the question.
Removing this module implies that all video frames (T=60) will be selected, potentially leading to temporal redundancy.
As observed in Tab. <a href="#S4.T3" title="Table 3 ‣ 1st item ‣ 4.4. Ablation Studies ‣ 4. Experiments ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the utilization of TPC effectively enhances model performance, resulting in a 1.12% improvement (from 75.87% to 76.79%), thereby strengthening temporal perception capability.</p>
</div>
</li>
<li id="S4.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i5.p1" class="ltx_para">
<p id="S4.I1.i5.p1.1" class="ltx_p"><span id="S4.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">TSPM <span id="S4.I1.i5.p1.1.1.1" class="ltx_text ltx_font_italic">w/o.</span> QPrompt</span>.
To validate whether transforming the given question into declarative statement indeed leads to better selection of key temporal segments, thereby effectively improving model performance, we replaced the constructed statements with input questions.
As shown in Tab. <a href="#S4.T3" title="Table 3 ‣ 1st item ‣ 4.4. Ablation Studies ‣ 4. Experiments ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, in this scenario, the model’s performance is significantly lower compared to when using declarative statements (76.79% and 75.16%).
The experimental results demonstrate the necessity of using declarative statements and indirectly highlight the importance of TPC.</p>
</div>
</li>
<li id="S4.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i6.p1" class="ltx_para">
<p id="S4.I1.i6.p1.1" class="ltx_p"><span id="S4.I1.i6.p1.1.1" class="ltx_text ltx_font_bold">TSPM <span id="S4.I1.i6.p1.1.1.1" class="ltx_text ltx_font_italic">w/o.</span> Tokens merge</span>.
Removing the Tokens merge operation from TSPM allows us to investigate whether it can preserve the semantic information of visual frame tokens. When this operation is removed, direct cross-modal interactions are conducted between all visual tokens and their corresponding temporal audio features. Tab. <a href="#S4.T3" title="Table 3 ‣ 1st item ‣ 4.4. Ablation Studies ‣ 4. Experiments ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows that when Tokens merge is removed, there is a decrease in model performance, highlighting the importance of the Tokens merge strategy.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.3" class="ltx_p">In general, each module contributes to better performance. When all modules are present, the TSPM achieves the best result on the MUSIC-AVQA dataset.
Similarly, we explored the impact of key parameter configurations on model performance.
As shown in Tab. <a href="#S4.T4" title="Table 4 ‣ 3rd item ‣ 4.4. Ablation Studies ‣ 4. Experiments ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, when the <math id="S4.SS4.p4.1.m1.1" class="ltx_Math" alttext="top_{k}" display="inline"><semantics id="S4.SS4.p4.1.m1.1a"><mrow id="S4.SS4.p4.1.m1.1.1" xref="S4.SS4.p4.1.m1.1.1.cmml"><mi id="S4.SS4.p4.1.m1.1.1.2" xref="S4.SS4.p4.1.m1.1.1.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p4.1.m1.1.1.1" xref="S4.SS4.p4.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS4.p4.1.m1.1.1.3" xref="S4.SS4.p4.1.m1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p4.1.m1.1.1.1a" xref="S4.SS4.p4.1.m1.1.1.1.cmml">​</mo><msub id="S4.SS4.p4.1.m1.1.1.4" xref="S4.SS4.p4.1.m1.1.1.4.cmml"><mi id="S4.SS4.p4.1.m1.1.1.4.2" xref="S4.SS4.p4.1.m1.1.1.4.2.cmml">p</mi><mi id="S4.SS4.p4.1.m1.1.1.4.3" xref="S4.SS4.p4.1.m1.1.1.4.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p4.1.m1.1b"><apply id="S4.SS4.p4.1.m1.1.1.cmml" xref="S4.SS4.p4.1.m1.1.1"><times id="S4.SS4.p4.1.m1.1.1.1.cmml" xref="S4.SS4.p4.1.m1.1.1.1"></times><ci id="S4.SS4.p4.1.m1.1.1.2.cmml" xref="S4.SS4.p4.1.m1.1.1.2">𝑡</ci><ci id="S4.SS4.p4.1.m1.1.1.3.cmml" xref="S4.SS4.p4.1.m1.1.1.3">𝑜</ci><apply id="S4.SS4.p4.1.m1.1.1.4.cmml" xref="S4.SS4.p4.1.m1.1.1.4"><csymbol cd="ambiguous" id="S4.SS4.p4.1.m1.1.1.4.1.cmml" xref="S4.SS4.p4.1.m1.1.1.4">subscript</csymbol><ci id="S4.SS4.p4.1.m1.1.1.4.2.cmml" xref="S4.SS4.p4.1.m1.1.1.4.2">𝑝</ci><ci id="S4.SS4.p4.1.m1.1.1.4.3.cmml" xref="S4.SS4.p4.1.m1.1.1.4.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p4.1.m1.1c">top_{k}</annotation></semantics></math> value is large, it may introduce temporal redundancy. When there are too many tokens, semantic merging on the token is not thorough enough; conversely, an excessive merging may result in semantic loss. The model achieves optimal performance when <math id="S4.SS4.p4.2.m2.1" class="ltx_Math" alttext="top_{k}=10" display="inline"><semantics id="S4.SS4.p4.2.m2.1a"><mrow id="S4.SS4.p4.2.m2.1.1" xref="S4.SS4.p4.2.m2.1.1.cmml"><mrow id="S4.SS4.p4.2.m2.1.1.2" xref="S4.SS4.p4.2.m2.1.1.2.cmml"><mi id="S4.SS4.p4.2.m2.1.1.2.2" xref="S4.SS4.p4.2.m2.1.1.2.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p4.2.m2.1.1.2.1" xref="S4.SS4.p4.2.m2.1.1.2.1.cmml">​</mo><mi id="S4.SS4.p4.2.m2.1.1.2.3" xref="S4.SS4.p4.2.m2.1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p4.2.m2.1.1.2.1a" xref="S4.SS4.p4.2.m2.1.1.2.1.cmml">​</mo><msub id="S4.SS4.p4.2.m2.1.1.2.4" xref="S4.SS4.p4.2.m2.1.1.2.4.cmml"><mi id="S4.SS4.p4.2.m2.1.1.2.4.2" xref="S4.SS4.p4.2.m2.1.1.2.4.2.cmml">p</mi><mi id="S4.SS4.p4.2.m2.1.1.2.4.3" xref="S4.SS4.p4.2.m2.1.1.2.4.3.cmml">k</mi></msub></mrow><mo id="S4.SS4.p4.2.m2.1.1.1" xref="S4.SS4.p4.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS4.p4.2.m2.1.1.3" xref="S4.SS4.p4.2.m2.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p4.2.m2.1b"><apply id="S4.SS4.p4.2.m2.1.1.cmml" xref="S4.SS4.p4.2.m2.1.1"><eq id="S4.SS4.p4.2.m2.1.1.1.cmml" xref="S4.SS4.p4.2.m2.1.1.1"></eq><apply id="S4.SS4.p4.2.m2.1.1.2.cmml" xref="S4.SS4.p4.2.m2.1.1.2"><times id="S4.SS4.p4.2.m2.1.1.2.1.cmml" xref="S4.SS4.p4.2.m2.1.1.2.1"></times><ci id="S4.SS4.p4.2.m2.1.1.2.2.cmml" xref="S4.SS4.p4.2.m2.1.1.2.2">𝑡</ci><ci id="S4.SS4.p4.2.m2.1.1.2.3.cmml" xref="S4.SS4.p4.2.m2.1.1.2.3">𝑜</ci><apply id="S4.SS4.p4.2.m2.1.1.2.4.cmml" xref="S4.SS4.p4.2.m2.1.1.2.4"><csymbol cd="ambiguous" id="S4.SS4.p4.2.m2.1.1.2.4.1.cmml" xref="S4.SS4.p4.2.m2.1.1.2.4">subscript</csymbol><ci id="S4.SS4.p4.2.m2.1.1.2.4.2.cmml" xref="S4.SS4.p4.2.m2.1.1.2.4.2">𝑝</ci><ci id="S4.SS4.p4.2.m2.1.1.2.4.3.cmml" xref="S4.SS4.p4.2.m2.1.1.2.4.3">𝑘</ci></apply></apply><cn type="integer" id="S4.SS4.p4.2.m2.1.1.3.cmml" xref="S4.SS4.p4.2.m2.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p4.2.m2.1c">top_{k}=10</annotation></semantics></math> and <math id="S4.SS4.p4.3.m3.1" class="ltx_Math" alttext="tokens=14" display="inline"><semantics id="S4.SS4.p4.3.m3.1a"><mrow id="S4.SS4.p4.3.m3.1.1" xref="S4.SS4.p4.3.m3.1.1.cmml"><mrow id="S4.SS4.p4.3.m3.1.1.2" xref="S4.SS4.p4.3.m3.1.1.2.cmml"><mi id="S4.SS4.p4.3.m3.1.1.2.2" xref="S4.SS4.p4.3.m3.1.1.2.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p4.3.m3.1.1.2.1" xref="S4.SS4.p4.3.m3.1.1.2.1.cmml">​</mo><mi id="S4.SS4.p4.3.m3.1.1.2.3" xref="S4.SS4.p4.3.m3.1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p4.3.m3.1.1.2.1a" xref="S4.SS4.p4.3.m3.1.1.2.1.cmml">​</mo><mi id="S4.SS4.p4.3.m3.1.1.2.4" xref="S4.SS4.p4.3.m3.1.1.2.4.cmml">k</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p4.3.m3.1.1.2.1b" xref="S4.SS4.p4.3.m3.1.1.2.1.cmml">​</mo><mi id="S4.SS4.p4.3.m3.1.1.2.5" xref="S4.SS4.p4.3.m3.1.1.2.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p4.3.m3.1.1.2.1c" xref="S4.SS4.p4.3.m3.1.1.2.1.cmml">​</mo><mi id="S4.SS4.p4.3.m3.1.1.2.6" xref="S4.SS4.p4.3.m3.1.1.2.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p4.3.m3.1.1.2.1d" xref="S4.SS4.p4.3.m3.1.1.2.1.cmml">​</mo><mi id="S4.SS4.p4.3.m3.1.1.2.7" xref="S4.SS4.p4.3.m3.1.1.2.7.cmml">s</mi></mrow><mo id="S4.SS4.p4.3.m3.1.1.1" xref="S4.SS4.p4.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS4.p4.3.m3.1.1.3" xref="S4.SS4.p4.3.m3.1.1.3.cmml">14</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p4.3.m3.1b"><apply id="S4.SS4.p4.3.m3.1.1.cmml" xref="S4.SS4.p4.3.m3.1.1"><eq id="S4.SS4.p4.3.m3.1.1.1.cmml" xref="S4.SS4.p4.3.m3.1.1.1"></eq><apply id="S4.SS4.p4.3.m3.1.1.2.cmml" xref="S4.SS4.p4.3.m3.1.1.2"><times id="S4.SS4.p4.3.m3.1.1.2.1.cmml" xref="S4.SS4.p4.3.m3.1.1.2.1"></times><ci id="S4.SS4.p4.3.m3.1.1.2.2.cmml" xref="S4.SS4.p4.3.m3.1.1.2.2">𝑡</ci><ci id="S4.SS4.p4.3.m3.1.1.2.3.cmml" xref="S4.SS4.p4.3.m3.1.1.2.3">𝑜</ci><ci id="S4.SS4.p4.3.m3.1.1.2.4.cmml" xref="S4.SS4.p4.3.m3.1.1.2.4">𝑘</ci><ci id="S4.SS4.p4.3.m3.1.1.2.5.cmml" xref="S4.SS4.p4.3.m3.1.1.2.5">𝑒</ci><ci id="S4.SS4.p4.3.m3.1.1.2.6.cmml" xref="S4.SS4.p4.3.m3.1.1.2.6">𝑛</ci><ci id="S4.SS4.p4.3.m3.1.1.2.7.cmml" xref="S4.SS4.p4.3.m3.1.1.2.7">𝑠</ci></apply><cn type="integer" id="S4.SS4.p4.3.m3.1.1.3.cmml" xref="S4.SS4.p4.3.m3.1.1.3">14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p4.3.m3.1c">tokens=14</annotation></semantics></math>, respectively.
Note that there are subtle differences between the TSPM and PSTP-Net <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite>, with the former employing CLIP-ViT-L/14 and the latter utilizing CLIP-ViT-B/32. As shown in Tab <a href="#S4.T5" title="Table 5 ‣ 3rd item ‣ 4.4. Ablation Studies ‣ 4. Experiments ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>: 1) The TSPM outperforms PSTP-Net regardless of the feature extractor used; 2) The model achieves better performance when equipped with a superior feature extractor. This underscores the effectiveness of the proposed TSPM.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5. </span>Computational costs</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">Tab. <a href="#S4.T6" title="Table 6 ‣ 3rd item ‣ 4.4. Ablation Studies ‣ 4. Experiments ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> illustrates the computational costs of TSPM compared with ST-AVQA <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite>, PSTP-Net <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite> and LAVISH <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2023</a>)</cite>.
It can be observed that TSPM has fewer training parameters, lower FLOPs, and higher accuracy compared to ST-AVQA.
Although PSTP-Net boasts lower computational costs, our TSPM achieves superior results at extremely low computational costs.
LAVISH achieves a well accuracy,
but its parameters are more than three times those of TSPM.
This is because LAVISH fine-tunes large pretrained models, whereas TSPM achieves comparable results without fine-tuning.
In summary, our proposed TSPM achieves high performance at a relatively low cost, fully demonstrating the effectiveness and efficiency of the model.
</p>
</div>
<figure id="S4.T7" class="ltx_table">
<div id="S4.T7.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:617.9pt;height:217pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table id="S4.T7.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T7.1.1.1.1" class="ltx_tr">
<th id="S4.T7.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T7.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<td id="S4.T7.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T7.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Ensemble</span></td>
<td id="S4.T7.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Total Accuracy (%)</span></td>
</tr>
<tr id="S4.T7.1.1.2.2" class="ltx_tr">
<th id="S4.T7.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">HME <cite class="ltx_cite ltx_citemacro_citep">(Fan et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2019</a>)</cite>
</th>
<td id="S4.T7.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">HAVF <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S4.T7.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">85.0</td>
</tr>
<tr id="S4.T7.1.1.3.3" class="ltx_tr">
<th id="S4.T7.1.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">PSAC <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2019b</a>)</cite>
</th>
<td id="S4.T7.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r">HAVF <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S4.T7.1.1.3.3.3" class="ltx_td ltx_align_center">87.4</td>
</tr>
<tr id="S4.T7.1.1.4.4" class="ltx_tr">
<th id="S4.T7.1.1.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">LADNet<cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2019a</a>)</cite>
</th>
<td id="S4.T7.1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r">HAVF <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S4.T7.1.1.4.4.3" class="ltx_td ltx_align_center">84.1</td>
</tr>
<tr id="S4.T7.1.1.5.5" class="ltx_tr">
<th id="S4.T7.1.1.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">ACRTransformer <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S4.T7.1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r">HAVF <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S4.T7.1.1.5.5.3" class="ltx_td ltx_align_center">87.8</td>
</tr>
<tr id="S4.T7.1.1.6.6" class="ltx_tr">
<th id="S4.T7.1.1.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">HGA <cite class="ltx_cite ltx_citemacro_citep">(Jiang and Han, <a href="#bib.bib15" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S4.T7.1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r">HAVF <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S4.T7.1.1.6.6.3" class="ltx_td ltx_align_center">87.7</td>
</tr>
<tr id="S4.T7.1.1.7.7" class="ltx_tr">
<th id="S4.T7.1.1.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">HCRN <cite class="ltx_cite ltx_citemacro_citep">(Le et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S4.T7.1.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r">HAVF <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S4.T7.1.1.7.7.3" class="ltx_td ltx_align_center">89.0</td>
</tr>
<tr id="S4.T7.1.1.8.8" class="ltx_tr">
<th id="S4.T7.1.1.8.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">PSTP-Net <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite>
</th>
<td id="S4.T7.1.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r">–</td>
<td id="S4.T7.1.1.8.8.3" class="ltx_td ltx_align_center">90.2</td>
</tr>
<tr id="S4.T7.1.1.9.9" class="ltx_tr">
<th id="S4.T7.1.1.9.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">TSPM <span id="S4.T7.1.1.9.9.1.1" class="ltx_text ltx_font_italic">w/o.</span> all</th>
<td id="S4.T7.1.1.9.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">–</td>
<td id="S4.T7.1.1.9.9.3" class="ltx_td ltx_align_center ltx_border_t">87.1</td>
</tr>
<tr id="S4.T7.1.1.10.10" class="ltx_tr">
<th id="S4.T7.1.1.10.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">TSPM <span id="S4.T7.1.1.10.10.1.1" class="ltx_text ltx_font_italic">w/o.</span> TPM</th>
<td id="S4.T7.1.1.10.10.2" class="ltx_td ltx_align_center ltx_border_r">–</td>
<td id="S4.T7.1.1.10.10.3" class="ltx_td ltx_align_center">89.4</td>
</tr>
<tr id="S4.T7.1.1.11.11" class="ltx_tr">
<th id="S4.T7.1.1.11.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">TSPM <span id="S4.T7.1.1.11.11.1.1" class="ltx_text ltx_font_italic">w/o.</span> SPM</th>
<td id="S4.T7.1.1.11.11.2" class="ltx_td ltx_align_center ltx_border_r">–</td>
<td id="S4.T7.1.1.11.11.3" class="ltx_td ltx_align_center">88.6</td>
</tr>
<tr id="S4.T7.1.1.12.12" class="ltx_tr">
<th id="S4.T7.1.1.12.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">
<span id="S4.T7.1.1.12.12.1.1" class="ltx_ERROR undefined">\cdashline</span>1-3[0.5pt/3pt]
<span id="S4.T7.1.1.12.12.1.2" class="ltx_text ltx_font_bold">TSPM</span> (Ours)</th>
<td id="S4.T7.1.1.12.12.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">–</td>
<td id="S4.T7.1.1.12.12.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T7.1.1.12.12.3.1" class="ltx_text ltx_font_bold">90.8</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7. </span>TSPM results on the test of AVQA.</figcaption>
</figure>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2407.20693/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="450" height="293" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>
Visualized TSPM results.
In the showcased examples, we compared our proposed TSPM with the recent AVQA-related method PSTP-Net <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite>.
It can be observed that TSPM can progressively select relevant temporal segments and locate potential sound-aware areas, thus accurately providing correct answers to the given questions.
This process vividly demonstrates TSPM’s effective spatiotemporal perception capabilities in complex audiovisual scenarios.
</figcaption>
</figure>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6. </span>Experiments on AVQA dataset</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">To verify the generalization capability of the proposed TSPM, we compared it with multiple existing AVQA-based methods, including ACRTransformer <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2020</a>)</cite>, HCRN <cite class="ltx_cite ltx_citemacro_citep">(Le et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2020</a>)</cite>, PSTP-Net <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite>, <em id="S4.SS6.p1.1.1" class="ltx_emph ltx_font_italic">etc.</em>, on the AVQA dataset.
As illustrated in Tab. <a href="#S4.T7" title="Table 7 ‣ 4.5. Computational costs ‣ 4. Experiments ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, the TSPM exhibits remarkable performance compared to recent methods. Specifically, our approach outperforms PSTP-Net <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite> by 0.6% (90.8% and 90.6%), demonstrating notable superiority over earlier methods such as ACRTransformer <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2020</a>)</cite>.
Furthermore, while the performance improvement of TSPM on the AVQA dataset seems limited compared to its performance on the MUSIC-AVQA dataset, we attribute this primarily to the AVQA dataset’s shorter duration (10<span id="S4.SS6.p1.1.2" class="ltx_text ltx_font_italic">s</span> <span id="S4.SS6.p1.1.3" class="ltx_text ltx_font_italic">vs.</span> 60<span id="S4.SS6.p1.1.4" class="ltx_text ltx_font_italic">s</span>) and simpler audio-visual components.</p>
</div>
<div id="S4.SS6.p2" class="ltx_para">
<p id="S4.SS6.p2.2" class="ltx_p">Despite these differences, our TSPM maintains its effectiveness even in this scenario.
Notably, in Tab. <a href="#S4.T7" title="Table 7 ‣ 4.5. Computational costs ‣ 4. Experiments ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, the PSTP-Net <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023a</a>)</cite> achieved a 1.2% improvement over the HCRN <cite class="ltx_cite ltx_citemacro_citep">(Le et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2020</a>)</cite>, while our TSPM exhibited a more substantial 1.8% enhancement, indicating the significant effectiveness of TSPM’s performance boost. Additionally, ablation studies further confirm the effectiveness of both TPM and SPM components.
Moreover, for the experimental settings on the AVQA dataset, we selected the Top-<math id="S4.SS6.p2.1.m1.1" class="ltx_Math" alttext="k=8" display="inline"><semantics id="S4.SS6.p2.1.m1.1a"><mrow id="S4.SS6.p2.1.m1.1.1" xref="S4.SS6.p2.1.m1.1.1.cmml"><mi id="S4.SS6.p2.1.m1.1.1.2" xref="S4.SS6.p2.1.m1.1.1.2.cmml">k</mi><mo id="S4.SS6.p2.1.m1.1.1.1" xref="S4.SS6.p2.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS6.p2.1.m1.1.1.3" xref="S4.SS6.p2.1.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.1.m1.1b"><apply id="S4.SS6.p2.1.m1.1.1.cmml" xref="S4.SS6.p2.1.m1.1.1"><eq id="S4.SS6.p2.1.m1.1.1.1.cmml" xref="S4.SS6.p2.1.m1.1.1.1"></eq><ci id="S4.SS6.p2.1.m1.1.1.2.cmml" xref="S4.SS6.p2.1.m1.1.1.2">𝑘</ci><cn type="integer" id="S4.SS6.p2.1.m1.1.1.3.cmml" xref="S4.SS6.p2.1.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.1.m1.1c">k=8</annotation></semantics></math> temporal segments relevant to the given question, with a merged token count of <math id="S4.SS6.p2.2.m2.1" class="ltx_Math" alttext="tokens=14" display="inline"><semantics id="S4.SS6.p2.2.m2.1a"><mrow id="S4.SS6.p2.2.m2.1.1" xref="S4.SS6.p2.2.m2.1.1.cmml"><mrow id="S4.SS6.p2.2.m2.1.1.2" xref="S4.SS6.p2.2.m2.1.1.2.cmml"><mi id="S4.SS6.p2.2.m2.1.1.2.2" xref="S4.SS6.p2.2.m2.1.1.2.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS6.p2.2.m2.1.1.2.1" xref="S4.SS6.p2.2.m2.1.1.2.1.cmml">​</mo><mi id="S4.SS6.p2.2.m2.1.1.2.3" xref="S4.SS6.p2.2.m2.1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS6.p2.2.m2.1.1.2.1a" xref="S4.SS6.p2.2.m2.1.1.2.1.cmml">​</mo><mi id="S4.SS6.p2.2.m2.1.1.2.4" xref="S4.SS6.p2.2.m2.1.1.2.4.cmml">k</mi><mo lspace="0em" rspace="0em" id="S4.SS6.p2.2.m2.1.1.2.1b" xref="S4.SS6.p2.2.m2.1.1.2.1.cmml">​</mo><mi id="S4.SS6.p2.2.m2.1.1.2.5" xref="S4.SS6.p2.2.m2.1.1.2.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS6.p2.2.m2.1.1.2.1c" xref="S4.SS6.p2.2.m2.1.1.2.1.cmml">​</mo><mi id="S4.SS6.p2.2.m2.1.1.2.6" xref="S4.SS6.p2.2.m2.1.1.2.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.SS6.p2.2.m2.1.1.2.1d" xref="S4.SS6.p2.2.m2.1.1.2.1.cmml">​</mo><mi id="S4.SS6.p2.2.m2.1.1.2.7" xref="S4.SS6.p2.2.m2.1.1.2.7.cmml">s</mi></mrow><mo id="S4.SS6.p2.2.m2.1.1.1" xref="S4.SS6.p2.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS6.p2.2.m2.1.1.3" xref="S4.SS6.p2.2.m2.1.1.3.cmml">14</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.2.m2.1b"><apply id="S4.SS6.p2.2.m2.1.1.cmml" xref="S4.SS6.p2.2.m2.1.1"><eq id="S4.SS6.p2.2.m2.1.1.1.cmml" xref="S4.SS6.p2.2.m2.1.1.1"></eq><apply id="S4.SS6.p2.2.m2.1.1.2.cmml" xref="S4.SS6.p2.2.m2.1.1.2"><times id="S4.SS6.p2.2.m2.1.1.2.1.cmml" xref="S4.SS6.p2.2.m2.1.1.2.1"></times><ci id="S4.SS6.p2.2.m2.1.1.2.2.cmml" xref="S4.SS6.p2.2.m2.1.1.2.2">𝑡</ci><ci id="S4.SS6.p2.2.m2.1.1.2.3.cmml" xref="S4.SS6.p2.2.m2.1.1.2.3">𝑜</ci><ci id="S4.SS6.p2.2.m2.1.1.2.4.cmml" xref="S4.SS6.p2.2.m2.1.1.2.4">𝑘</ci><ci id="S4.SS6.p2.2.m2.1.1.2.5.cmml" xref="S4.SS6.p2.2.m2.1.1.2.5">𝑒</ci><ci id="S4.SS6.p2.2.m2.1.1.2.6.cmml" xref="S4.SS6.p2.2.m2.1.1.2.6">𝑛</ci><ci id="S4.SS6.p2.2.m2.1.1.2.7.cmml" xref="S4.SS6.p2.2.m2.1.1.2.7">𝑠</ci></apply><cn type="integer" id="S4.SS6.p2.2.m2.1.1.3.cmml" xref="S4.SS6.p2.2.m2.1.1.3">14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.2.m2.1c">tokens=14</annotation></semantics></math>.
It’s worth noting that HAVF <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite> in Tab. <a href="#S4.T7" title="Table 7 ‣ 4.5. Computational costs ‣ 4. Experiments ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, serving as the baseline method for the AVQA dataset, includes three fusion modalities and integrates their outputs using an averaging strategy to generate answers.
In summary, the proposed TSPM effectively demonstrates both its effectiveness and generalization.</p>
</div>
</section>
<section id="S4.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.7. </span>Visualization Results</h3>

<div id="S4.SS7.p1" class="ltx_para">
<p id="S4.SS7.p1.1" class="ltx_p">To showcase the temporal and spatial perception capabilities of the proposed TSPM, we provide two examples contrasting with the recent AVQA-related method PSTP-Net in Fig. <a href="#S4.F4" title="Figure 4 ‣ 4.5. Computational costs ‣ 4. Experiments ‣ Boosting Audio Visual Question Answering via Key Semantic-Aware Cues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
In <span id="S4.SS7.p1.1.1" class="ltx_text ltx_font_italic">Example 01</span>, when presented with the question ”<span id="S4.SS7.p1.1.2" class="ltx_text ltx_font_italic">Where is the first sounding instrument?</span>”, the TPM first identifies the temporal indices relevant to the question. Subsequently, the SPM sequentially locates potential sound-aware areas, with the heatmap indicating these regions. In this example, it becomes apparent that initially, only the ”<span id="S4.SS7.p1.1.3" class="ltx_text ltx_font_italic">flute</span>” on the <span id="S4.SS7.p1.1.4" class="ltx_text ltx_font_italic">right</span> side is playing, but as time progresses, the violin on the left side also begins playing. The heatmap effectively illustrates the variation in multiple instruments playing within this dynamic and complex audio-visual scene.
Consequently, it can be inferred that the correct answer to the question is the instrument on the ”<span id="S4.SS7.p1.1.5" class="ltx_text ltx_font_italic">right</span>” side.
Similarly, in <span id="S4.SS7.p1.1.6" class="ltx_text ltx_font_italic">Example 02</span>, the progressive temporal-spatial perception process is aptly demonstrated, resulting in the correct answer.
These visualizations indicate that the proposed TSPM can effectively perceive the temporal segments relevant to the question and the spatial areas associated with sound, showcasing its efficacy in audio visual question answering task.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this work, we propose an effective Temporal-Spatial Perception Model framework for addressing complex question-answering tasks in dynamic audio-visual scenarios.
It includes a temporal perception module with a declarative sentence text prompt and a spatial perception module incorporating token merging. These modules are employed to locate temporal segments relevant to the question and enhance spatial audio-visual associations, thereby facilitating fine-grained audio-visual scene understanding.
Extensive experiments demonstrate that the proposed framework achieves precise temporal-spatial perception on multiple benchmarks, effectively showcasing the reasoning process involved in answering questions.
We believe that our work will serve as inspiration for researchers in the field of audio-visual scene understanding.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
This research was supported by National Natural Science Foundation of China (NO.62106272), and Public Computing Cloud, Renmin University of China.

</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bolya et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Daniel Bolya, Cheng-Yang Fu, Xiaoliang Dai, Peizhao Zhang, Christoph Feichtenhofer, and Judy Hoffman. 2022.

</span>
<span class="ltx_bibblock">Token merging: Your vit but faster.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.09461</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Sihan Chen, Xingjian He, Longteng Guo, Xinxin Zhu, Weining Wang, Jinhui Tang, and Jing Liu. 2023a.

</span>
<span class="ltx_bibblock">VALOR: Vision-Audio-Language Omni-Perception Pretraining Model and Dataset.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.08345</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Yaru Chen, Ruohao Guo, Xubo Liu, Peipei Wu, Guangyao Li, Zhenbo Li, and Wenwu Wang. 2024.

</span>
<span class="ltx_bibblock">CM-PIE: Cross-modal perception for interactive-enhanced audio-visual video parsing. In <em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>. IEEE, 8421–8425.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Zailong Chen, Lei Wang, Peng Wang, and Peng Gao. 2023b.

</span>
<span class="ltx_bibblock">Question-Aware Global-Local Video Understanding Network for Audio-Visual Question Answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Circuits and Systems for Video Technology</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duan et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Haoyi Duan, Yan Xia, Mingze Zhou, Li Tang, Jieming Zhu, and Zhou Zhao. 2023.

</span>
<span class="ltx_bibblock">Cross-modal Prompts: Adapting Large Pre-trained Models for Audio-Visual Downstream Tasks. In <em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">Thirty-seventh Conference on Neural Information Processing Systems</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Chenyou Fan, Xiaofan Zhang, Shu Zhang, Wensheng Wang, Chi Zhang, and Heng Huang. 2019.

</span>
<span class="ltx_bibblock">Heterogeneous memory enhanced multimodal attention model for video question answering. In <em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 1999–2007.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fayek and Johnson (2020)</span>
<span class="ltx_bibblock">
Haytham M Fayek and Justin Johnson. 2020.

</span>
<span class="ltx_bibblock">Temporal Reasoning via Audio Question Answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em> 28 (2020), 2283–2294.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gan et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Chuang Gan, Deng Huang, Hang Zhao, Joshua B Tenenbaum, and Antonio Torralba. 2020.

</span>
<span class="ltx_bibblock">Music gesture for visual sound separation. In <em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 10478–10487.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Ruohan Gao, Tae-Hyun Oh, Kristen Grauman, and Lorenzo Torresani. 2020.

</span>
<span class="ltx_bibblock">Listen to look: Action recognition by previewing audio. In <em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 10457–10467.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gemmeke et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Jort F Gemmeke, Daniel PW Ellis, Dylan Freedman, Aren Jansen, Wade Lawrence, R Channing Moore, Manoj Plakal, and Marvin Ritter. 2017.

</span>
<span class="ltx_bibblock">Audio set: An ontology and human-labeled dataset for audio events. In <em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)</em>. IEEE, 776–780.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hou et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Wenxuan Hou, Guangyao Li, Yapeng Tian, and Di Hu. 2023.

</span>
<span class="ltx_bibblock">Towards Long Form Audio-visual Video Understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Multimedia Computing, Communications and Applications</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Di Hu, Zheng Wang, Feiping Nie, Rong Wang, and Xuelong Li. 2022.

</span>
<span class="ltx_bibblock">Self-supervised Learning for Heterogeneous Audiovisual Scene Analysis.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Multimedia</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Di Hu, Yake Wei, Rui Qian, Weiyao Lin, Ruihua Song, and Ji-Rong Wen. 2021.

</span>
<span class="ltx_bibblock">Class-aware Sounding Objects Localization via Audiovisual Correspondence.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang and Han (2020)</span>
<span class="ltx_bibblock">
Pin Jiang and Yahong Han. 2020.

</span>
<span class="ltx_bibblock">Reasoning with heterogeneous graph alignment for video question answering. In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>, Vol. 34. 11109–11116.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang and Yin (2023)</span>
<span class="ltx_bibblock">
Yuanyuan Jiang and Jianqin Yin. 2023.

</span>
<span class="ltx_bibblock">Target-Aware Spatio-Temporal Reasoning via Answering Questions in Dynamics Audio-Visual Scenarios.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.12397</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lao et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Mingrui Lao, Nan Pu, Yu Liu, Kai He, Erwin M. Bakker, and Michael S. Lew. 2023.

</span>
<span class="ltx_bibblock">COCA: COllaborative CAusal Regularization for Audio-Visual Question Answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em> 37, 11 (Jun. 2023), 12995–13003.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1609/aaai.v37i11.26527" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1609/aaai.v37i11.26527</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Le et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Thao Minh Le, Vuong Le, Svetha Venkatesh, and Truyen Tran. 2020.

</span>
<span class="ltx_bibblock">Hierarchical conditional relation networks for video question answering. In <em id="bib.bib18.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 9972–9981.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Guangyao Li, Wenxuan Hou, and Di Hu. 2023a.

</span>
<span class="ltx_bibblock">Progressive Spatio-Temporal Perception for Audio-Visual Question Answering. In <em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 31st ACM International Conference on Multimedia</em> (Ottawa ON, Canada) <em id="bib.bib19.4.2" class="ltx_emph ltx_font_italic">(MM ’23)</em>. Association for Computing Machinery, New York, NY, USA, 7808–7816.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3581783.3612293" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3581783.3612293</a>

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Guangyao Li, Yake Wei, Yapeng Tian, Chenliang Xu, Ji-Rong Wen, and Di Hu. 2022.

</span>
<span class="ltx_bibblock">Learning to answer questions in dynamic audio-visual scenarios. In <em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 19108–19118.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Kexin Li, Zongxin Yang, Lei Chen, Yi Yang, and Jun Xiao. 2023b.

</span>
<span class="ltx_bibblock">Catr: Combinatorial-dependence audio-queried transformer for audio-visual video segmentation. In <em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 31st ACM International Conference on Multimedia</em>. 1485–1494.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Xiangpeng Li, Lianli Gao, Xuanhan Wang, Wu Liu, Xing Xu, Heng Tao Shen, and Jingkuan Song. 2019a.

</span>
<span class="ltx_bibblock">Learnable aggregating net with diversity learning for video question answering. In <em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th ACM international conference on multimedia</em>. 1166–1174.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Xiangpeng Li, Jingkuan Song, Lianli Gao, Xianglong Liu, Wenbing Huang, Xiangnan He, and Chuang Gan. 2019b.

</span>
<span class="ltx_bibblock">Beyond rnns: Positional self-attention with co-attention for video question answering. In <em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>, Vol. 33. 8658–8665.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Zhangbin Li, Dan Guo, Jinxing Zhou, Jing Zhang, and Meng Wang. 2024.

</span>
<span class="ltx_bibblock">Object-aware adaptive-positivity learning for audio-visual question answering. In <em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</em>. 3306–3314.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Yan-Bo Lin, Yi-Lin Sung, Jie Lei, Mohit Bansal, and Gedas Bertasius. 2023.

</span>
<span class="ltx_bibblock">Vision Transformers Are Parameter-Efficient Audio-Visual Learners. In <em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>. 2299–2309.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Jiasen Lu, Jianwei Yang, Dhruv Batra, and Devi Parikh. 2016.

</span>
<span class="ltx_bibblock">Hierarchical question-image co-attention for visual question answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1606.00061</em> (2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nadeem et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Asmar Nadeem, Adrian Hilton, Robert Dawes, Graham Thomas, and Armin Mustafa. 2023.

</span>
<span class="ltx_bibblock">CAD–Contextual Multi-modal Alignment for Dynamic AVQA.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.16754</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al<span id="bib.bib28.3.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language supervision. In <em id="bib.bib28.4.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>. PMLR, 8748–8763.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schwartz et al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Idan Schwartz, Alexander G Schwing, and Tamir Hazan. 2019.

</span>
<span class="ltx_bibblock">A simple baseline for audio-visual scene-aware dialog. In <em id="bib.bib29.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 12548–12558.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Senocak et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Arda Senocak, Tae-Hyun Oh, Junsik Kim, Ming-Hsuan Yang, and In So Kweon. 2018.

</span>
<span class="ltx_bibblock">Learning to localize sound source in visual scenes. In <em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>. 4358–4366.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yapeng Tian, Dingzeyu Li, and Chenliang Xu. 2020.

</span>
<span class="ltx_bibblock">Unified multisensory perception: Weakly-supervised audio-visual video parsing. In <em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">European Conference on Computer Vision</em>. Springer, 436–454.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian et al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Yapeng Tian, Jing Shi, Bochen Li, Zhiyao Duan, and Chenliang Xu. 2018.

</span>
<span class="ltx_bibblock">Audio-visual event localization in unconstrained videos. In <em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">Proceedings of the European Conference on Computer Vision</em>. 247–263.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2024a)</span>
<span class="ltx_bibblock">
Yaoting Wang, Weisong Liu, Guangyao Li, Jian Ding, Di Hu, and Xi Li. 2024a.

</span>
<span class="ltx_bibblock">Prompting segmentation with sound is generalizable audio-visual source localizer. In <em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>, Vol. 38. 5669–5677.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2024b)</span>
<span class="ltx_bibblock">
Yaoting Wang, Peiwen Sun, Dongzhan Zhou, Guangyao Li, Honggang Zhang, and Di Hu. 2024b.

</span>
<span class="ltx_bibblock">Ref-avs: Refer and segment objects in audio-visual scenes.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2407.10957</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yake Wei, Di Hu, Yapeng Tian, and Xuelong Li. 2022.

</span>
<span class="ltx_bibblock">Learning in audio-visual context: A review, analysis, and new perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2208.09579</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Pinci Yang, Xin Wang, Xuguang Duan, Hong Chen, Runze Hou, Cong Jin, and Wenwu Zhu. 2022.

</span>
<span class="ltx_bibblock">AVQA: A Dataset for Audio-Visual Question Answering on Videos. In <em id="bib.bib36.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 30th ACM International Conference on Multimedia</em>. 3480–3491.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Zhou Yu, Jun Yu, Yuhao Cui, Dacheng Tao, and Qi Tian. 2019.

</span>
<span class="ltx_bibblock">Deep modular co-attention networks for visual question answering. In <em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 6281–6290.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yun et al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Heeseung Yun, Youngjae Yu, Wonsuk Yang, Kangil Lee, and Gunhee Kim. 2021.

</span>
<span class="ltx_bibblock">Pano-AVQA: Grounded Audio-Visual Question Answering on 360deg Videos. In <em id="bib.bib38.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>. 2031–2041.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jipeng Zhang, Jie Shao, Rui Cao, Lianli Gao, Xing Xu, and Heng Tao Shen. 2020.

</span>
<span class="ltx_bibblock">Action-centric relation transformer network for video question answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Circuits and Systems for Video Technology</em> 32, 1 (2020), 63–74.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Dongzhan Zhou, Xinchi Zhou, Di Hu, Hang Zhou, Lei Bai, Ziwei Liu, and Wanli Ouyang. 2022b.

</span>
<span class="ltx_bibblock">SepFusion: Finding Optimal Fusion Structures for Visual Sound Separation. In <em id="bib.bib40.3.1" class="ltx_emph ltx_font_italic">AAAI</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span id="bib.bib41.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Jinxing Zhou, Dan Guo, Yuxin Mao, Yiran Zhong, Xiaojun Chang, and Meng Wang. 2024.

</span>
<span class="ltx_bibblock">Label-anticipated Event Disentanglement for Audio-Visual Video Parsing. In <em id="bib.bib41.3.1" class="ltx_emph ltx_font_italic">European Conference on Computer Vision (ECCV)</em>. 1–22.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Jinxing Zhou, Dan Guo, and Meng Wang. 2023.

</span>
<span class="ltx_bibblock">Contrastive positive sample propagation along the audio-visual event line.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em> (2023), 7239–7257.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span id="bib.bib43.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Jinxing Zhou, Jianyuan Wang, Jiayi Zhang, Weixuan Sun, Jing Zhang, Stan Birchfield, Dan Guo, Lingpeng Kong, Meng Wang, and Yiran Zhong. 2022a.

</span>
<span class="ltx_bibblock">Audio–Visual Segmentation. In <em id="bib.bib43.3.1" class="ltx_emph ltx_font_italic">Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part XXXVII</em>. Springer, 386–403.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span id="bib.bib44.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Peng Zhou, Wei Shi, Jun Tian, Zhenyu Qi, Bingchen Li, Hongwei Hao, and Bo Xu. 2016.

</span>
<span class="ltx_bibblock">Attention-based bidirectional long short-term memory networks for relation classification. In <em id="bib.bib44.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 54th annual meeting of the association for computational linguistics (volume 2: Short papers)</em>. 207–212.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2407.20692" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2407.20693" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2407.20693">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2407.20693" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2407.20694" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Aug  5 18:04:33 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
