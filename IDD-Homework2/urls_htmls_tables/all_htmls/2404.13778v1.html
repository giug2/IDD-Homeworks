<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems</title>
<!--Generated on Wed May  1 12:33:15 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
emotion recognition,  group movie recommendation; audio emotion,  color emotion,  text emotion,  recommender systems,  consensus.
" lang="en" name="keywords"/>
<base href="/html/2404.13778v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S1" title="In Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S2" title="In Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related Work</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S2.SS1" title="In II Related Work ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-A</span> </span><span class="ltx_text ltx_font_italic">Emotion Analysis</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S2.SS2" title="In II Related Work ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-B</span> </span><span class="ltx_text ltx_font_italic">Group Movie Recommendation</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3" title="In Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Methods</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.SS1" title="In III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Data Collection</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.SS1.SSS1" title="In III-A Data Collection ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span>1 </span>IMDB</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.SS1.SSS2" title="In III-A Data Collection ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span>2 </span>TMDB</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.SS2" title="In III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Emotion Detection</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.SS2.SSS1" title="In III-B Emotion Detection ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span>1 </span>Emotions in movie description</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.SS2.SSS2" title="In III-B Emotion Detection ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span>2 </span>Emotions in poster</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.SS2.SSS3" title="In III-B Emotion Detection ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span>3 </span>Emotions in movie soundtrack</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.SS2.SSS4" title="In III-B Emotion Detection ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span>4 </span>Multimodal Fusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.SS3" title="In III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-C</span> </span><span class="ltx_text ltx_font_italic">Recommendation using Jaccard Coefficient</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.SS4" title="In III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-D</span> </span><span class="ltx_text ltx_font_italic">Consensus Model using Fuzzy Logic</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4" title="In Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Experimental Results</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.SS1" title="In IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Performance Evaluation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.SS2" title="In IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Group Movie Recommendation Example</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.SS3" title="In IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-C</span> </span><span class="ltx_text ltx_font_italic">Experiment: Emotion Analysis of top 100 movies</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S5" title="In Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Discussion</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S6" title="In Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\useunder</span>
<p class="ltx_p" id="p1.2"><span class="ltx_text ltx_ulem_uline" id="p1.2.1"></span><span class="ltx_text ltx_framed ltx_framed_underline" id="p1.2.2"></span></p>
</div>
<h1 class="ltx_title ltx_title_document">Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Adilet Yerkin,
Elnara Kadyrgali,
Yerdauit Torekhan,
and  Pakizar Shamoi
</span><span class="ltx_author_notes">Manuscript received April 22, 2024. This paper is an expanded paper from the IEEE Digital Generation Student Conference held on April 4-5, 2024, in Astana, Kazakhstan.<span class="ltx_text ltx_font_italic" id="id5.1.id1">(Corresponding author: Pakizar Shamoi.)</span>A. Yerkin, E. Kadyrgali, Y. Torekhan, and P. Shamoi are with the School of Information Technology and Engineering, Kazakh-British Technical University, Almaty 050000, Kazakhstan (e-mail: p.shamoi@kbtu.kz).</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id6.id1">Watching movies is one of the social activities typically done in groups. Emotion is the most vital factor that affects movie viewers’ preferences. So, the emotional aspect of the movie needs to be determined and analyzed for further recommendations. It can be challenging to choose a movie that appeals to the emotions of a diverse group. Reaching an agreement for a group can be difficult due to the various genres and choices. This paper proposes a novel approach to group movie suggestions by examining emotions from three different channels: movie descriptions (text), soundtracks (audio), and posters (image). We employ the Jaccard similarity index to match each participant’s emotional preferences to prospective movie choices, followed by a fuzzy inference technique to determine group consensus. We use a weighted integration process for the fusion of emotion scores from diverse data types. Then, group movie recommendation is based on prevailing emotions and viewers’ best-loved movies. After determining the recommendations, the group’s consensus level is calculated using a fuzzy inference system, taking participants’ feedback as input. Participants (n=130) in the survey were provided with different emotion categories and asked to select the emotions best suited for particular movies (n=12). Comparison results between predicted and actual scores demonstrate the efficiency of using emotion detection for this problem (Jaccard similarity index = 0.76). We explored the relationship between induced emotions and movie popularity as an additional experiment, analyzing emotion distribution in 100 popular movies from the TMDB database. Such systems can potentially improve the accuracy of movie recommendation systems and achieve a high level of consensus among participants with diverse preferences.
</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
emotion recognition, group movie recommendation; audio emotion, color emotion, text emotion, recommender systems, consensus.

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">In today’s world, movies have a significant impact on cultural conversations and personal enjoyment. With plenty of options available, individuals choose what to watch, guided by their tastes and the influences around them. Their current context influences the user’s decision-making process, but using the internet helps to simplify this task.
At the same time, an increasing number of artificial intelligence (AI) systems are expected to depend on identifying emotions via speech, facial expressions, and conversation content <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib1" title="">1</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Emotions play a key role in successful information delivery, communication, and engagement and can critically affect the perception and attitudes of viewers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib2" title="">2</a>]</cite>. Researchers are increasingly interested in multimodal emotion identification because of its potential to overcome the limitations of monomodal systems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib3" title="">3</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib4" title="">4</a>]</cite>. Especially visual emotion analysis has recently received much attention, thanks to the growing trend of expressing and understanding emotions through photographs on social networks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib4" title="">4</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Emotional data is crucial in many multimedia applications <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib5" title="">5</a>]</cite>. Emotion is the most important element that links movies and humans. In today’s entertainment industry, watching a movie is not only about experiencing audio and visual sensations; it explores the complex domain of human emotions. Watching television shows or movies is an example of a social activity usually done in groups <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib6" title="">6</a>]</cite>. The process of selecting a movie that satisfies the emotional preferences of a diverse group can be challenging. Facilitating agreement among group members is a significant challenge in recommending movies. Emotions play a crucial role since we primarily watch movies to experience emotions.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Nowadays, recommendation systems are omnipresent due to the excessive volume of multimedia information. When selecting a movie, reaching a consensus among people with different preferences can be challenging. Previous studies revealed that the decision-making process becomes more difficult in the case of uncertain product features (e.g., delivered emotions). For this reason, when choosing which media content to interact with, users tend to rely on the insights provided by collaborative input <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib7" title="">7</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">This paper presents a novel methodology for group movie recommendations. We analyze emotions from three channels: movie descriptions, soundtracks, and posters. We use the Jaccard similarity index to match each participant’s emotional preferences with potential movie choices and then apply a fuzzy inference system to determine group consensus. In our previous works, we introduced the approach for movie emotion recognition <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib8" title="">8</a>]</cite>. The main contributions of this work are:</p>
</div>
<div class="ltx_para" id="S1.p6">
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Proposing a novel approach for achieving consensus in group movie selection using a multi-channel emotion recognition approach based on movie data like poster, text description, and soundtrack.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.1">Consensus Estimation</span>. After determining the most recommended movie for the group, the level of consensus is calculated considering participants’ feedback, namely, agreement and confidence levels. We propose a fuzzy inference system for this purpose.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I1.i3.p1.1.1">Emotion-Popularity analysis in movies.</span> We also investigate which emotions conveyed through poster colors (color image features), the soundtrack (music features), or the movie description (text features)—have the greatest impact on movie popularity.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">The paper is organized as follows. The present
section is an introduction that contains the research goals and main contributions. Section II involves a comprehensive literature review on emotion analysis, group movie recommendations, and consensus building. Section III describes the methods and details of the data collection. The experimental investigation, examples, and results are presented in Section IV. Section V comprises discussions on the topic, and Section VI includes a conclusion and ideas for future development.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related Work</span>
</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS1.4.1.1">II-A</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS1.5.2">Emotion Analysis</span>
</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Studies on emotion recognition can be categorized based on the approaches used in research. The first category of studies mainly focuses on analyzing a single component to detect the emotion. On the other hand, the second category employs multi-componential approaches in emotion analysis, integrating more human-like applications.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Several movie analysis-related works employed emotion recognition for various purposes. One study presents a multiclass emotion classifier emphasizing negative emotions, using a rich set of metadata and content from a tagged movie transcript <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib1" title="">1</a>]</cite>. Another study introduces a bimodal method that combines facial expression recognition (FER) with the actors’ ”semantic orientation” in their dialogue to recognize emotions in scenarios with challenging lighting, position changes, and occlusions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib9" title="">9</a>]</cite>. An emotion map for a movie based on aggregating and projecting reviewers’ movie scores and reviews onto the movie was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib10" title="">10</a>]</cite>. An approach for emotion tracking using supervised learning methods was introduced to model the continuous affective response using hidden Markov Models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib11" title="">11</a>]</cite>. Multichannel modeling approaches for predicting movie-induced and perceived emotions were presented in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib12" title="">12</a>]</cite>. Some works classify emotions present in movies using EEG signal analysis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib13" title="">13</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib14" title="">14</a>]</cite>. Another study introduces an EEG-based user-independent emotion recognition method to recover emotion tags for videos, pupillary response, and gaze distance. The study employed 20 movie video clips and 24 human subjects watching these emotional video clips. Ground truth was defined based on the median arousal and valence scores to define the ground truth from the survey. The other study proposes a multi-label positive emotion classification method based on the brain activities of viewers exposed to affective content from movies, TransEEG, a model for multi-label positive emotion classification from a viewer’s brain activities when watching emotional movies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib5" title="">5</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">Considering the influence of multimedia information on the audience’s emotions, the new methodology was proposed for movie preference prediction using low-level multimedia feature extraction and SVM-based classification and applied to a collection of 725 movie trailers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib15" title="">15</a>]</cite>. The following features were used: trailer colors, motion, and shot.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS2.4.1.1">II-B</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS2.5.2">Group Movie Recommendation</span>
</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Group Recommendation systems (RS) are RSs that incorporate group preferences, particularly in the context of movies. RSs are often divided into two types: collaborative filtering (CF) and content-based filtering (CBF). Some of the constraints of these traditional systems include the requirement for previous user information to complete the recommendation assignment <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib16" title="">16</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Several studies have examined the problem of group movie recommendation using various methods.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">The study <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib17" title="">17</a>]</cite> presents ”Happy movie,” a Facebook-integrated app that uses personality, social trust, and past preferences to enhance group movie recommendations. The goal is to improve consensus and overcome the limitations of existing systems. One study proposes using movie posters to improve movie recommender systems, addressing issues of information overload, sparsity, and cold-start problems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib18" title="">18</a>]</cite>. The study introduces a recommendation system for moviegoers in temporary groups, using the Slope One algorithm for individual predictions and the Multiplicative Utilitarian Strategy for group recommendations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib6" title="">6</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">Some studies propose the use of DL, ML, and NLP techniques for this task <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib19" title="">19</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib20" title="">20</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib21" title="">21</a>]</cite>. A novel method for suggesting movies involves using a knowledge graph that captures human emotions from movie reviews <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib19" title="">19</a>]</cite>. This is accomplished through machine learning techniques. A chatbot prototype can provide tailored movie recommendations by incorporating the emotional states of users, which are extracted from chat messages, with the knowledge graph. A study by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib20" title="">20</a>]</cite> presented a model that uses social networks, microblogging data, and sentiment analysis to improve program recommendations on media sites such as YouTube and Hulu. This model addresses the ”cold-start” problem by analyzing user preferences for similarity between movies and TV episodes.</p>
</div>
<div class="ltx_para" id="S2.SS2.p5">
<p class="ltx_p" id="S2.SS2.p5.1">Another study <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib22" title="">22</a>]</cite> introduced the Dynamic Interest Flow (DIF) system, a novel approach for adapting movie recommendations to users’ evolving preferences by leveraging the UMIS (User Movie Interest Space). It captures the intrinsic characteristics and relationships of interests that influence users’ movie-watching decisions. It facilitates tracking users’ interest evolution alongside their rating histories to more accurately forecast future rating events. An actor-based recommendation system was proposed using content-based filtering that considers the genres of 509 South Korean movies and the movieography information of the actor <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib23" title="">23</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p6">
<p class="ltx_p" id="S2.SS2.p6.1">Multiple studies focused on genre classification as a basis for proving movie recommendations for groups <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib25" title="">25</a>]</cite>. Studies related to emotions reveal that mood states notably influence movie ratings, with variations observed across genres <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib26" title="">26</a>]</cite>; for instance, positive moods tend to elevate ratings for romantic comedies, while tiredness may increase ratings for crime thrillers. Incorporating mood states suggested by the PANAS-X inventory into a mood-aware recommendation mechanism has been shown to enhance recommendation accuracy by accounting for these mood-related biases.</p>
</div>
<div class="ltx_para" id="S2.SS2.p7">
<p class="ltx_p" id="S2.SS2.p7.1">A hybrid approach to movie recommendations was proposed <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib27" title="">27</a>]</cite>, integrating tags and human ratings to address the limitations of current services that often overlook the depth of user annotations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib28" title="">28</a>]</cite>. There are several methods to improve recommendation systems. Some of these methods include combining k-means clustering and genetic algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib29" title="">29</a>]</cite>, user-based collaborative filtering using both ratings and social connections to calculate user similarity <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib30" title="">30</a>]</cite>, using graph attention network (GAT) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib31" title="">31</a>]</cite>, integrating basic movie attributes such as genre, cast, director, keywords, and descriptions along with ratings using a CNN-based deep learning model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib32" title="">32</a>]</cite>, and using an item-based collaborative filtering approach <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib33" title="">33</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p8">
<p class="ltx_p" id="S2.SS2.p8.1">Another representative of a hybrid recommendation system for movies integrates collaborative filtering, content-based filtering, and sentiment analysis of tweets from microblogging platforms <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib16" title="">16</a>]</cite>. The idea is to capture current trends, public sentiment, and audience reactions to movies.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="181" id="S2.F1.g1" src="extracted/2404.13778v1/fig/emodetect.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S2.F1.3.2" style="font-size:90%;">Multi-channel Emotion Recognition from movie data</span></figcaption>
</figure>
<div class="ltx_para" id="S2.SS2.p9">
<p class="ltx_p" id="S2.SS2.p9.1">Some studies focused on integrating consensus estimation in providing recommendations. Recent research presents a hybrid recommendation system that combines collaborative and content-based content, including top critic consensus and movie rating scores <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib34" title="">34</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p10">
<p class="ltx_p" id="S2.SS2.p10.1">It has been observed that there are only a few studies that concentrated on making collective suggestions for movies based on emotional features. To address this problem, our paper presents a new technique that uses emotional analysis to assist in the group movie selection process. By analyzing emotional data from multiple sources such as movie posters, main soundtrack, and descriptions, our methodology provides a comprehensive understanding of the emotional landscape associated with each movie.</p>
</div>
<div class="ltx_para" id="S2.SS2.p11">
<p class="ltx_p" id="S2.SS2.p11.1">Our approach is based on the understanding that movies are created to elicit specific emotional responses from the audience. movie posters capture the essence of the movie, soundtracks enhance the emotional tone, and descriptions provide the context. When combined, they create a complex emotional profile. Our methodology aims to integrate these elements, allowing us to match a movie’s emotional tone with a group’s collective mood and preferences. This simplifies the decision-making process regarding choosing a movie to watch.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Methods</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Our framework consists of three steps:</p>
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1">Multi-channel Emotion Detection. Three emotion channels are used to identify the emotions in the movie: the poster’s color features, the soundtrack’s audio features, and the movie description’s text features. As can be seen from the methodology presented in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S2.F1" title="Figure 1 ‣ II-B Group Movie Recommendation ‣ II Related Work ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">1</span></a>, all characteristics extracted from three tracks are aggregated using the weighted score.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">Recommendation using Jaccard coefficient based on detected emotions.
We also integrated genre as a normalizing factor in the decision step to make precise recommendations.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1">Consensus evaluation using Fuzzy Inference System.</p>
</div>
</li>
</ul>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.4.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.5.2">Data Collection</span>
</h3>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS1.SSS1.4.1.1">III-A</span>1 </span>IMDB</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">We collected data from the Internet Movie Database (IMDb) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib35" title="">35</a>]</cite>, an online repository of information about movies, television shows, and other information associated with them. We selected 12 movies of different genres and years to evaluate the model, including <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.p1.1.1">Comedy, Romance, Horror, Drama,</span> and <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.p1.1.2">Fantasy</span>. The database provided three main elements for each movie: the plot summary, posters, and a 30-second excerpt from one of the soundtracks.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p2">
<p class="ltx_p" id="S3.SS1.SSS1.p2.1">Analyzing a movie’s original soundtrack is not always possible, while the other two channels are always discoverable. So, for some movies, we chose music in trailers or during the movie itself instead of the original soundtrack. The following movies were selected for further analysis: Titanic (1997), Bride Wars (2009), Insidious: Chapter 3 (2015), Annabelle: Creation (2017), Just Go With It (2011), Me Before You (2016), Interstellar (2014), Edge of Tomorrow (2014), Passengers (2016), Don’t Breathe 2 (2021), The Proposal (2009), and The Holiday (2006). After considering various unofficial rate charts online, movies that garnered significant attention from global audiences between 1997 and 2021 were selected.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T1.2.1.1" style="font-size:90%;">TABLE I</span>: </span><span class="ltx_text" id="S3.T1.3.2" style="font-size:90%;">Example of records on top 100 popular movies from TMDB</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.4" style="width:433.6pt;height:331.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(47.8pt,-36.5pt) scale(1.28277268690125,1.28277268690125) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.4.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.4.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.1.1.1.1">
<span class="ltx_p" id="S3.T1.4.1.1.1.1.1.1" style="width:10.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.4.1.1.1.1.1.1.1">id</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.1.1.2.1">
<span class="ltx_p" id="S3.T1.4.1.1.1.2.1.1" style="width:48.4pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.4.1.1.1.2.1.1.1">Title</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.1.1.3.1">
<span class="ltx_p" id="S3.T1.4.1.1.1.3.1.1" style="width:48.4pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.4.1.1.1.3.1.1.1">Overview</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.1.1.4">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.1.1.4.1">
<span class="ltx_p" id="S3.T1.4.1.1.1.4.1.1" style="width:56.9pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.4.1.1.1.4.1.1.1">Genres</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.1.1.5">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.1.1.5.1">
<span class="ltx_p" id="S3.T1.4.1.1.1.5.1.1" style="width:37.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.4.1.1.1.5.1.1.1">track</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.1.1.6">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.1.1.6.1">
<span class="ltx_p" id="S3.T1.4.1.1.1.6.1.1" style="width:65.4pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.4.1.1.1.6.1.1.1">Performer</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.4.1.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.2.2.1.1">
<span class="ltx_p" id="S3.T1.4.1.2.2.1.1.1" style="width:10.0pt;">1</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.2.2.2.1">
<span class="ltx_p" id="S3.T1.4.1.2.2.2.1.1" style="width:48.4pt;">Kung Fu Panda 4</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.2.2.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.2.2.3.1">
<span class="ltx_p" id="S3.T1.4.1.2.2.3.1.1" style="width:48.4pt;">Po is gearing up to…</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.2.2.4">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.2.2.4.1">
<span class="ltx_p" id="S3.T1.4.1.2.2.4.1.1" style="width:56.9pt;">Action, Adventure, Animation, Comedy, Family</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.2.2.5">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.2.2.5.1">
<span class="ltx_p" id="S3.T1.4.1.2.2.5.1.1" style="width:37.0pt;">Journey</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.2.2.6">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.2.2.6.1">
<span class="ltx_p" id="S3.T1.4.1.2.2.6.1.1" style="width:65.4pt;">Hans Zimmer, Steve Mazzaro</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.4.1.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.3.3.1.1">
<span class="ltx_p" id="S3.T1.4.1.3.3.1.1.1" style="width:10.0pt;">2</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.3.3.2.1">
<span class="ltx_p" id="S3.T1.4.1.3.3.2.1.1" style="width:48.4pt;">Damsel</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.3.3.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.3.3.3.1">
<span class="ltx_p" id="S3.T1.4.1.3.3.3.1.1" style="width:48.4pt;">A young woman’s…</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.3.3.4">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.3.3.4.1">
<span class="ltx_p" id="S3.T1.4.1.3.3.4.1.1" style="width:56.9pt;">Fantasy, Adventure, Action</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.3.3.5">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.3.3.5.1">
<span class="ltx_p" id="S3.T1.4.1.3.3.5.1.1" style="width:37.0pt;">Elodie’s Maze</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.3.3.6">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.3.3.6.1">
<span class="ltx_p" id="S3.T1.4.1.3.3.6.1.1" style="width:65.4pt;">David Fleming</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.4.1.4.4.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.4.4.1.1">
<span class="ltx_p" id="S3.T1.4.1.4.4.1.1.1" style="width:10.0pt;">3</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.4.4.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.4.4.2.1">
<span class="ltx_p" id="S3.T1.4.1.4.4.2.1.1" style="width:48.4pt;">Sri Asih</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.4.4.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.4.4.3.1">
<span class="ltx_p" id="S3.T1.4.1.4.4.3.1.1" style="width:48.4pt;">Alana discover the…</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.4.4.4">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.4.4.4.1">
<span class="ltx_p" id="S3.T1.4.1.4.4.4.1.1" style="width:56.9pt;">Action, Adventure, Science Fiction, Fantasy, Drama</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.4.4.5">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.4.4.5.1">
<span class="ltx_p" id="S3.T1.4.1.4.4.5.1.1" style="width:37.0pt;">Yatim</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.4.4.6">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.4.4.6.1">
<span class="ltx_p" id="S3.T1.4.1.4.4.6.1.1" style="width:65.4pt;">Aghi Narottama, Bemby Gusti, Tony Merle</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.4.1.5.5.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.5.5.1.1">
<span class="ltx_p" id="S3.T1.4.1.5.5.1.1.1" style="width:10.0pt;">4</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.5.5.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.5.5.2.1">
<span class="ltx_p" id="S3.T1.4.1.5.5.2.1.1" style="width:48.4pt;">No Way Up</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.5.5.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.5.5.3.1">
<span class="ltx_p" id="S3.T1.4.1.5.5.3.1.1" style="width:48.4pt;">Characters from…</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.5.5.4">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.5.5.4.1">
<span class="ltx_p" id="S3.T1.4.1.5.5.4.1.1" style="width:56.9pt;">Action, Horror, Thriller</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.5.5.5">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.5.5.5.1">
<span class="ltx_p" id="S3.T1.4.1.5.5.5.1.1" style="width:37.0pt;">Opening Titles</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.5.5.6">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.5.5.6.1">
<span class="ltx_p" id="S3.T1.4.1.5.5.6.1.1" style="width:65.4pt;">Andy Gray</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.4.1.6.6.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.6.6.1.1">
<span class="ltx_p" id="S3.T1.4.1.6.6.1.1.1" style="width:10.0pt;">5</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.6.6.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.6.6.2.1">
<span class="ltx_p" id="S3.T1.4.1.6.6.2.1.1" style="width:48.4pt;">Argylle</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.6.6.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.6.6.3.1">
<span class="ltx_p" id="S3.T1.4.1.6.6.3.1.1" style="width:48.4pt;">When the plots of…</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.6.6.4">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.6.6.4.1">
<span class="ltx_p" id="S3.T1.4.1.6.6.4.1.1" style="width:56.9pt;">Action, Adventure, Comedy</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.6.6.5">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.6.6.5.1">
<span class="ltx_p" id="S3.T1.4.1.6.6.5.1.1" style="width:37.0pt;">Moke Mayhem</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.6.6.6">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.6.6.6.1">
<span class="ltx_p" id="S3.T1.4.1.6.6.6.1.1" style="width:65.4pt;">Lorne Balfe</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.7.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.4.1.7.7.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.7.7.1.1">
<span class="ltx_p" id="S3.T1.4.1.7.7.1.1.1" style="width:10.0pt;">…</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.7.7.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.7.7.2.1">
<span class="ltx_p" id="S3.T1.4.1.7.7.2.1.1" style="width:48.4pt;">…</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.7.7.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.7.7.3.1">
<span class="ltx_p" id="S3.T1.4.1.7.7.3.1.1" style="width:48.4pt;">…</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.7.7.4">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.7.7.4.1">
<span class="ltx_p" id="S3.T1.4.1.7.7.4.1.1" style="width:56.9pt;">…</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.7.7.5">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.7.7.5.1">
<span class="ltx_p" id="S3.T1.4.1.7.7.5.1.1" style="width:37.0pt;">…</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.7.7.6">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.7.7.6.1">
<span class="ltx_p" id="S3.T1.4.1.7.7.6.1.1" style="width:65.4pt;">…</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.8.8">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.4.1.8.8.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.8.8.1.1">
<span class="ltx_p" id="S3.T1.4.1.8.8.1.1.1" style="width:10.0pt;">100</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.4.1.8.8.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.8.8.2.1">
<span class="ltx_p" id="S3.T1.4.1.8.8.2.1.1" style="width:48.4pt;">My Fault</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.4.1.8.8.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.8.8.3.1">
<span class="ltx_p" id="S3.T1.4.1.8.8.3.1.1" style="width:48.4pt;">Noah must leave her…</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.4.1.8.8.4">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.8.8.4.1">
<span class="ltx_p" id="S3.T1.4.1.8.8.4.1.1" style="width:56.9pt;">Drama, Romance</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.4.1.8.8.5">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.8.8.5.1">
<span class="ltx_p" id="S3.T1.4.1.8.8.5.1.1" style="width:37.0pt;">Me quiero ir</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.4.1.8.8.6">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.8.8.6.1">
<span class="ltx_p" id="S3.T1.4.1.8.8.6.1.1" style="width:65.4pt;">lusillón</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS1.SSS2.4.1.1">III-A</span>2 </span>TMDB</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">For our experiment on exploring the relationship between induced emotions and movie popularity, we also collected the data using community-built The Movie Database (TMDB)<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://www.themoviedb.org</span></span></span> with 904,555 movie metadata except for adult content and Deezer<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://www.deezer.com</span></span></span> music database. TMDB has a voting score from the community, therefore we used this data to analyze the correlation between the popularity of the movie and its emotional range and to represent the emotion distribution in 100 popular movies. Table <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.T1" title="TABLE I ‣ III-A1 IMDB ‣ III-A Data Collection ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">I</span></a> shows a snippet of the database containing 100 popular movies’ details. The movie’s overview as text, poster images in ’.jpg’ format, and a list of genres are taken from TMDB via the database’s API. As TMDB does not provide the soundtrack data, a 30-second clip from the original soundtrack was taken from Deezer API in ’.mp3’ format, requested by the track’s name and its performer, and transferred to ’.wav’.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.4.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.5.2">Emotion Detection</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Human emotions are typically expressed and perceived through numerous modalities <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib2" title="">2</a>]</cite>. Algorithm I provides the general pseudocode for emotion detection from movies.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS2.SSS1.4.1.1">III-B</span>1 </span>Emotions in movie description</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">We utilized text2emotion version 0.0.5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib36" title="">36</a>]</cite> to identify the emotions in the movie description. Five emotion categories were used: <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.p1.1.1">Happy, Angry, Sad, Surprise,</span> and <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.p1.1.2">Fear</span>. Text2emotions provides a dictionary with emotion categories as keys and scores for each category as values. Only emotions with non-zero scores are considered.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p2">
<p class="ltx_p" id="S3.SS2.SSS1.p2.1">The movie overview’s text emotions were identified using text2emotion 0.0.5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib36" title="">36</a>]</cite>, a Python library that helps to extract the emotions from textual content. Taking as input data to process, it returns the dictionary with keys representing emotion categories and corresponding scores for each emotion category offered by text2emotion. The aggregation of the scores is always 1, so the percentage of each emotion in the input text can be observed. The five emotion categories were used: <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.p2.1.1">Happy, Angry, Sad, Surprised,</span> and <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.p2.1.2">Fearful</span> Not every one of the five emotions is covered in the text, so only scores that are not 0 are considered.</p>
</div>
<figure class="ltx_float ltx_algorithm" id="alg1">
<div class="ltx_listing ltx_lst_numbers_left ltx_listing" id="alg1.6">
<div class="ltx_listingline" id="alg1.6.7">
<span class="ltx_text" id="alg1.6.7.1"><span class="ltx_text ltx_font_bold" id="alg1.6.7.1.1">Input:</span> </span>Raw features for each movie (poster, audio, text) in dataset
</div>
<div class="ltx_listingline" id="alg1.6.8">
<span class="ltx_text" id="alg1.6.8.1"><span class="ltx_text ltx_font_bold" id="alg1.6.8.1.1">Output:</span> </span>Dictionary with weighted scores for each emotion for each movie
</div>
<div class="ltx_listingline" id="alg1.6.9">
</div>
<div class="ltx_listingline" id="alg1.6.10">
</div>
<div class="ltx_listingline" id="alg1.1.1">
<span class="ltx_text ltx_font_bold" id="alg1.1.1.1">Initialization:</span>
Dictionary <math alttext="emotionScores" class="ltx_Math" display="inline" id="alg1.1.1.m1.1"><semantics id="alg1.1.1.m1.1a"><mrow id="alg1.1.1.m1.1.1" xref="alg1.1.1.m1.1.1.cmml"><mi id="alg1.1.1.m1.1.1.2" xref="alg1.1.1.m1.1.1.2.cmml">e</mi><mo id="alg1.1.1.m1.1.1.1" xref="alg1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="alg1.1.1.m1.1.1.3" xref="alg1.1.1.m1.1.1.3.cmml">m</mi><mo id="alg1.1.1.m1.1.1.1a" xref="alg1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="alg1.1.1.m1.1.1.4" xref="alg1.1.1.m1.1.1.4.cmml">o</mi><mo id="alg1.1.1.m1.1.1.1b" xref="alg1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="alg1.1.1.m1.1.1.5" xref="alg1.1.1.m1.1.1.5.cmml">t</mi><mo id="alg1.1.1.m1.1.1.1c" xref="alg1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="alg1.1.1.m1.1.1.6" xref="alg1.1.1.m1.1.1.6.cmml">i</mi><mo id="alg1.1.1.m1.1.1.1d" xref="alg1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="alg1.1.1.m1.1.1.7" xref="alg1.1.1.m1.1.1.7.cmml">o</mi><mo id="alg1.1.1.m1.1.1.1e" xref="alg1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="alg1.1.1.m1.1.1.8" xref="alg1.1.1.m1.1.1.8.cmml">n</mi><mo id="alg1.1.1.m1.1.1.1f" xref="alg1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="alg1.1.1.m1.1.1.9" xref="alg1.1.1.m1.1.1.9.cmml">S</mi><mo id="alg1.1.1.m1.1.1.1g" xref="alg1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="alg1.1.1.m1.1.1.10" xref="alg1.1.1.m1.1.1.10.cmml">c</mi><mo id="alg1.1.1.m1.1.1.1h" xref="alg1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="alg1.1.1.m1.1.1.11" xref="alg1.1.1.m1.1.1.11.cmml">o</mi><mo id="alg1.1.1.m1.1.1.1i" xref="alg1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="alg1.1.1.m1.1.1.12" xref="alg1.1.1.m1.1.1.12.cmml">r</mi><mo id="alg1.1.1.m1.1.1.1j" xref="alg1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="alg1.1.1.m1.1.1.13" xref="alg1.1.1.m1.1.1.13.cmml">e</mi><mo id="alg1.1.1.m1.1.1.1k" xref="alg1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="alg1.1.1.m1.1.1.14" xref="alg1.1.1.m1.1.1.14.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.1.1.m1.1b"><apply id="alg1.1.1.m1.1.1.cmml" xref="alg1.1.1.m1.1.1"><times id="alg1.1.1.m1.1.1.1.cmml" xref="alg1.1.1.m1.1.1.1"></times><ci id="alg1.1.1.m1.1.1.2.cmml" xref="alg1.1.1.m1.1.1.2">𝑒</ci><ci id="alg1.1.1.m1.1.1.3.cmml" xref="alg1.1.1.m1.1.1.3">𝑚</ci><ci id="alg1.1.1.m1.1.1.4.cmml" xref="alg1.1.1.m1.1.1.4">𝑜</ci><ci id="alg1.1.1.m1.1.1.5.cmml" xref="alg1.1.1.m1.1.1.5">𝑡</ci><ci id="alg1.1.1.m1.1.1.6.cmml" xref="alg1.1.1.m1.1.1.6">𝑖</ci><ci id="alg1.1.1.m1.1.1.7.cmml" xref="alg1.1.1.m1.1.1.7">𝑜</ci><ci id="alg1.1.1.m1.1.1.8.cmml" xref="alg1.1.1.m1.1.1.8">𝑛</ci><ci id="alg1.1.1.m1.1.1.9.cmml" xref="alg1.1.1.m1.1.1.9">𝑆</ci><ci id="alg1.1.1.m1.1.1.10.cmml" xref="alg1.1.1.m1.1.1.10">𝑐</ci><ci id="alg1.1.1.m1.1.1.11.cmml" xref="alg1.1.1.m1.1.1.11">𝑜</ci><ci id="alg1.1.1.m1.1.1.12.cmml" xref="alg1.1.1.m1.1.1.12">𝑟</ci><ci id="alg1.1.1.m1.1.1.13.cmml" xref="alg1.1.1.m1.1.1.13">𝑒</ci><ci id="alg1.1.1.m1.1.1.14.cmml" xref="alg1.1.1.m1.1.1.14">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.1.1.m1.1c">emotionScores</annotation><annotation encoding="application/x-llamapun" id="alg1.1.1.m1.1d">italic_e italic_m italic_o italic_t italic_i italic_o italic_n italic_S italic_c italic_o italic_r italic_e italic_s</annotation></semantics></math> for storing emotion scores for each movie;
</div>
<div class="ltx_listingline" id="alg1.6.11">
</div>
<div class="ltx_listingline" id="alg1.6.12">
<span class="ltx_text ltx_font_bold" id="alg1.6.12.1">while</span> <em class="ltx_emph ltx_font_italic" id="alg1.6.12.2">there are more movies</em> <span class="ltx_text ltx_font_bold" id="alg1.6.12.3">do</span>
</div>
<div class="ltx_listingline" id="alg1.6.13">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
Get features for the current movie;
</div>
<div class="ltx_listingline" id="alg1.2.2">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
emotionAudio <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.2.2.m1.1"><semantics id="alg1.2.2.m1.1a"><mo id="alg1.2.2.m1.1.1" stretchy="false" xref="alg1.2.2.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.2.2.m1.1b"><ci id="alg1.2.2.m1.1.1.cmml" xref="alg1.2.2.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.2.2.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.2.2.m1.1d">←</annotation></semantics></math> <span class="ltx_text ltx_font_typewriter" id="alg1.2.2.1">FindAudioEmotion</span>;
</div>
<div class="ltx_listingline" id="alg1.3.3">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
emotionPoster <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.3.3.m1.1"><semantics id="alg1.3.3.m1.1a"><mo id="alg1.3.3.m1.1.1" stretchy="false" xref="alg1.3.3.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.3.3.m1.1b"><ci id="alg1.3.3.m1.1.1.cmml" xref="alg1.3.3.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.3.3.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.3.3.m1.1d">←</annotation></semantics></math> <span class="ltx_text ltx_font_typewriter" id="alg1.3.3.1">FindImgEmotion</span>;
</div>
<div class="ltx_listingline" id="alg1.4.4">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
emotionText <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.4.4.m1.1"><semantics id="alg1.4.4.m1.1a"><mo id="alg1.4.4.m1.1.1" stretchy="false" xref="alg1.4.4.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.4.4.m1.1b"><ci id="alg1.4.4.m1.1.1.cmml" xref="alg1.4.4.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.4.4.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.4.4.m1.1d">←</annotation></semantics></math> <span class="ltx_text ltx_font_typewriter" id="alg1.4.4.1">FindTextEmotion</span>
</div>
<div class="ltx_listingline" id="alg1.5.5">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   w <math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.5.5.m1.1"><semantics id="alg1.5.5.m1.1a"><mo id="alg1.5.5.m1.1.1" stretchy="false" xref="alg1.5.5.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.5.5.m1.1b"><ci id="alg1.5.5.m1.1.1.cmml" xref="alg1.5.5.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.5.5.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.5.5.m1.1d">←</annotation></semantics></math> weighted average; 
</div>
<div class="ltx_listingline" id="alg1.6.14">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span class="ltx_text ltx_font_typewriter" id="alg1.6.14.1">// </span><span class="ltx_text ltx_font_typewriter" id="alg1.6.14.2">Here we find a weighted average for each emotion from 3 channels </span>
</div>
<div class="ltx_listingline" id="alg1.6.15">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div class="ltx_listingline" id="alg1.6.16">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   Store emotion scores for the current movie in dictionary <em class="ltx_emph ltx_font_italic" id="alg1.6.16.1">emotionScores</em>;
</div>
<div class="ltx_listingline" id="alg1.6.17">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div class="ltx_listingline" id="alg1.6.18"> end while
</div>
<div class="ltx_listingline" id="alg1.6.6">
<span class="ltx_text ltx_font_bold" id="alg1.6.6.1">return</span> <math alttext="emotionScores" class="ltx_Math" display="inline" id="alg1.6.6.m1.1"><semantics id="alg1.6.6.m1.1a"><mrow id="alg1.6.6.m1.1.1" xref="alg1.6.6.m1.1.1.cmml"><mi id="alg1.6.6.m1.1.1.2" xref="alg1.6.6.m1.1.1.2.cmml">e</mi><mo id="alg1.6.6.m1.1.1.1" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.3" xref="alg1.6.6.m1.1.1.3.cmml">m</mi><mo id="alg1.6.6.m1.1.1.1a" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.4" xref="alg1.6.6.m1.1.1.4.cmml">o</mi><mo id="alg1.6.6.m1.1.1.1b" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.5" xref="alg1.6.6.m1.1.1.5.cmml">t</mi><mo id="alg1.6.6.m1.1.1.1c" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.6" xref="alg1.6.6.m1.1.1.6.cmml">i</mi><mo id="alg1.6.6.m1.1.1.1d" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.7" xref="alg1.6.6.m1.1.1.7.cmml">o</mi><mo id="alg1.6.6.m1.1.1.1e" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.8" xref="alg1.6.6.m1.1.1.8.cmml">n</mi><mo id="alg1.6.6.m1.1.1.1f" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.9" xref="alg1.6.6.m1.1.1.9.cmml">S</mi><mo id="alg1.6.6.m1.1.1.1g" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.10" xref="alg1.6.6.m1.1.1.10.cmml">c</mi><mo id="alg1.6.6.m1.1.1.1h" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.11" xref="alg1.6.6.m1.1.1.11.cmml">o</mi><mo id="alg1.6.6.m1.1.1.1i" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.12" xref="alg1.6.6.m1.1.1.12.cmml">r</mi><mo id="alg1.6.6.m1.1.1.1j" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.13" xref="alg1.6.6.m1.1.1.13.cmml">e</mi><mo id="alg1.6.6.m1.1.1.1k" xref="alg1.6.6.m1.1.1.1.cmml">⁢</mo><mi id="alg1.6.6.m1.1.1.14" xref="alg1.6.6.m1.1.1.14.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.6.6.m1.1b"><apply id="alg1.6.6.m1.1.1.cmml" xref="alg1.6.6.m1.1.1"><times id="alg1.6.6.m1.1.1.1.cmml" xref="alg1.6.6.m1.1.1.1"></times><ci id="alg1.6.6.m1.1.1.2.cmml" xref="alg1.6.6.m1.1.1.2">𝑒</ci><ci id="alg1.6.6.m1.1.1.3.cmml" xref="alg1.6.6.m1.1.1.3">𝑚</ci><ci id="alg1.6.6.m1.1.1.4.cmml" xref="alg1.6.6.m1.1.1.4">𝑜</ci><ci id="alg1.6.6.m1.1.1.5.cmml" xref="alg1.6.6.m1.1.1.5">𝑡</ci><ci id="alg1.6.6.m1.1.1.6.cmml" xref="alg1.6.6.m1.1.1.6">𝑖</ci><ci id="alg1.6.6.m1.1.1.7.cmml" xref="alg1.6.6.m1.1.1.7">𝑜</ci><ci id="alg1.6.6.m1.1.1.8.cmml" xref="alg1.6.6.m1.1.1.8">𝑛</ci><ci id="alg1.6.6.m1.1.1.9.cmml" xref="alg1.6.6.m1.1.1.9">𝑆</ci><ci id="alg1.6.6.m1.1.1.10.cmml" xref="alg1.6.6.m1.1.1.10">𝑐</ci><ci id="alg1.6.6.m1.1.1.11.cmml" xref="alg1.6.6.m1.1.1.11">𝑜</ci><ci id="alg1.6.6.m1.1.1.12.cmml" xref="alg1.6.6.m1.1.1.12">𝑟</ci><ci id="alg1.6.6.m1.1.1.13.cmml" xref="alg1.6.6.m1.1.1.13">𝑒</ci><ci id="alg1.6.6.m1.1.1.14.cmml" xref="alg1.6.6.m1.1.1.14">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.6.6.m1.1c">emotionScores</annotation><annotation encoding="application/x-llamapun" id="alg1.6.6.m1.1d">italic_e italic_m italic_o italic_t italic_i italic_o italic_n italic_S italic_c italic_o italic_r italic_e italic_s</annotation></semantics></math>;

</div>
<div class="ltx_listingline" id="alg1.6.19">
<span class="ltx_text ltx_font_bold" id="alg1.6.19.1">Function</span> <em class="ltx_emph ltx_font_typewriter" id="alg1.6.19.2">FindAudioEmotion</em><span class="ltx_text ltx_font_bold" id="alg1.6.19.3">:</span>
</div>
<div class="ltx_listingline" id="alg1.6.20">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span class="ltx_text ltx_font_typewriter" id="alg1.6.20.1">// </span><span class="ltx_text ltx_font_typewriter" id="alg1.6.20.2">Deep Neural network that takes audio from a movie, slices it, and processes it </span>
</div>
<div class="ltx_listingline" id="alg1.6.21">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div class="ltx_listingline" id="alg1.6.22">
</div>
<div class="ltx_listingline" id="alg1.6.23">
</div>
<div class="ltx_listingline" id="alg1.6.24">
<span class="ltx_text ltx_font_bold" id="alg1.6.24.1">Function</span> <em class="ltx_emph ltx_font_typewriter" id="alg1.6.24.2">FindImgEmotion</em><span class="ltx_text ltx_font_bold" id="alg1.6.24.3">:</span>
</div>
<div class="ltx_listingline" id="alg1.6.25">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span class="ltx_text ltx_font_typewriter" id="alg1.6.25.1">// </span><span class="ltx_text ltx_font_typewriter" id="alg1.6.25.2">Fuzzy Color Emotion Model that extracts a dominant color palette and correlates it with emotion </span>
</div>
<div class="ltx_listingline" id="alg1.6.26">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div class="ltx_listingline" id="alg1.6.27">
</div>
<div class="ltx_listingline" id="alg1.6.28">
</div>
<div class="ltx_listingline" id="alg1.6.29">
<span class="ltx_text ltx_font_bold" id="alg1.6.29.1">Function</span> <em class="ltx_emph ltx_font_typewriter" id="alg1.6.29.2">FindTextEmotion</em><span class="ltx_text ltx_font_bold" id="alg1.6.29.3">:</span>
</div>
<div class="ltx_listingline" id="alg1.6.30">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div class="ltx_listingline" id="alg1.6.31">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   <span class="ltx_text ltx_font_typewriter" id="alg1.6.31.1">// </span><span class="ltx_text ltx_font_typewriter" id="alg1.6.31.2">Here we use text2emotion to analyze the emotions present in the text </span>
</div>
<div class="ltx_listingline" id="alg1.6.32">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div class="ltx_listingline" id="alg1.6.33">
</div>
<div class="ltx_listingline" id="alg1.6.34">
</div>
<div class="ltx_listingline" id="alg1.6.35">
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.8.1.1">Algorithm 1</span> </span>Multi-channel emotion analysis of movies</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS2.SSS2.4.1.1">III-B</span>2 </span>Emotions in poster</h4>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="147" id="S3.F2.g1" src="extracted/2404.13778v1/images/movie.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S3.F2.3.2" style="font-size:90%;">Example of emotion extraction from the image. Method is adapted from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib37" title="">37</a>]</cite></span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">We used a novel fuzzy sets-based method to categorize emotions based on colors in a movie poster <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib37" title="">37</a>]</cite>, which fits well with human assessments’ imprecise and subjective nature. The proposed approach can be easily adapted to suit our specific needs. The research employed fuzzy colors <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib38" title="">38</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib39" title="">39</a>]</cite> (with n=120) and a range of emotions (with n=10) to determine fuzzy color distributions for ten distinct emotions, namely <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS2.p1.1.1">Anger, Shyness, Happiness, Sadness, Gratitude, Shame, Fear, Trust, Love,</span> and <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS2.p1.1.2">Surprise</span>. After processing, they are transformed into a crisp domain, and we gain a knowledge base of primary color-emotion correlations. The study revealed strong correlations between specific emotions and colors (2AFC score = 0.77).
We use these correlations and Jaccard’s similarity to identify emotions in poster images. To fit our context, we focus on a specific set of emotions listed in reference <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib30" title="">30</a>]</cite>: <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS2.p1.1.3">Anger, Happiness, Sadness, Fear, Love,</span> and <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS2.p1.1.4">Surprise</span>. Our process is illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.F2" title="Figure 2 ‣ III-B2 Emotions in poster ‣ III-B Emotion Detection ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS2.SSS3.4.1.1">III-B</span>3 </span>Emotions in movie soundtrack</h4>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="378" id="S3.F3.g1" src="extracted/2404.13778v1/fig/audio_emotion.jpg" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.2.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S3.F3.3.2" style="font-size:90%;">Audio Emotion Recognition using deep learning</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.SSS3.p1">
<p class="ltx_p" id="S3.SS2.SSS3.p1.1">Several methods and strategies are used in Music Emotion Recognition(MER).
In this research, we conduct single-component research simply applying audio analysis to our soundtrack excerpts, preliminarily dividing them into 2-second partitions. The procedure for detecting emotions from audio recordings is shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.F3" title="Figure 3 ‣ III-B3 Emotions in movie soundtrack ‣ III-B Emotion Detection ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p2">
<p class="ltx_p" id="S3.SS2.SSS3.p2.1">Music emotion recognition employs low-level features such as beat, pitch, rhythm, valence, and tempo <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib40" title="">40</a>]</cite>. Soundtrack analysis was performed using a pre-trained model based on a deep neural network algorithm, performed in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib41" title="">41</a>]</cite> that obtained an F1 score of 0.91 on the authors’ test set. The lowest performance was obtained in the sad emotional class with a score of 0.87, and the best results were seen in the angry class with a 0.95 score. The original paper <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib41" title="">41</a>]</cite> uses only the RAVDESS dataset. In contrast, the current paper’s model uses an updated one from GitHub, trained on two different datasets, with an F1 score of 0.80. So, the model is trained to recognize eight emotion categories (<span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p2.1.1">Neutral, Calm, Happy, Sad, Angry, Fearful, Disgust,</span> and <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p2.1.2">Surprise</span>) using the Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib42" title="">42</a>]</cite> and Toronto emotional speech set (TESS) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib43" title="">43</a>]</cite>. Important to mention that the model was initially intended for speech analysis, we noticed that it also works well for songs.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p3">
<p class="ltx_p" id="S3.SS2.SSS3.p3.1">We divided the initial 30-second duration audio files into 15 partitions for accurate analysis. As seen from Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.F3" title="Figure 3 ‣ III-B3 Emotions in movie soundtrack ‣ III-B Emotion Detection ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">3</span></a>, in a 30-second song, it is difficult to inspect features due to an enormous variation in the wave plot. This means that there can be several emotions in one partition of the whole soundtrack, so to hold as many emotions as possible, we analyze each 2 seconds of the song separately. Many emotions in a single input can result in emotions such as <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p3.1.1">Disgust</span>, and the other emotions will be lost in the output. The network may process vectors containing 40 audio features representing the audio frame’s numerical form for every audio file supplied as input. We use the main five emotions (<span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p3.1.2">Happy, Angry, Sad, Surprise,</span> and <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p3.1.3">Fear</span>) from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib41" title="">41</a>]</cite>, which is our main focus. The model generates an emotional class for input audio excerpts and encodes it as follows: <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p3.1.4">Happy</span>=2; <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p3.1.5">Sad</span>=3; <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p3.1.6">Angry</span>=4; <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p3.1.7">Fearful</span>=5; <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p3.1.8">Surprised</span>=7. We have observed ten emotional labels in each of the 15 parts of a single excerpt. Based on the prevalence of emotional categories, we have formulated a dictionary with scores for each category, represented as keys similar to the output of text emotion analysis.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS2.SSS4.4.1.1">III-B</span>4 </span>Multimodal Fusion</h4>
<div class="ltx_para" id="S3.SS2.SSS4.p1">
<p class="ltx_p" id="S3.SS2.SSS4.p1.1">We use a weighted integration process to achieve a cohesive result for the fusion of emotion scores from diverse data types.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS4.p2">
<p class="ltx_p" id="S3.SS2.SSS4.p2.4">The emotional scores from the movie poster, main soundtrack, and movie description are combined using a weighted average approach (<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.E1" title="In III-B4 Multimodal Fusion ‣ III-B Emotion Detection ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">1</span></a>). Let <math alttext="E_{p}" class="ltx_Math" display="inline" id="S3.SS2.SSS4.p2.1.m1.1"><semantics id="S3.SS2.SSS4.p2.1.m1.1a"><msub id="S3.SS2.SSS4.p2.1.m1.1.1" xref="S3.SS2.SSS4.p2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS4.p2.1.m1.1.1.2" xref="S3.SS2.SSS4.p2.1.m1.1.1.2.cmml">E</mi><mi id="S3.SS2.SSS4.p2.1.m1.1.1.3" xref="S3.SS2.SSS4.p2.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS4.p2.1.m1.1b"><apply id="S3.SS2.SSS4.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS4.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS4.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS4.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS4.p2.1.m1.1.1.2">𝐸</ci><ci id="S3.SS2.SSS4.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS4.p2.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS4.p2.1.m1.1c">E_{p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS4.p2.1.m1.1d">italic_E start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="E_{m}" class="ltx_Math" display="inline" id="S3.SS2.SSS4.p2.2.m2.1"><semantics id="S3.SS2.SSS4.p2.2.m2.1a"><msub id="S3.SS2.SSS4.p2.2.m2.1.1" xref="S3.SS2.SSS4.p2.2.m2.1.1.cmml"><mi id="S3.SS2.SSS4.p2.2.m2.1.1.2" xref="S3.SS2.SSS4.p2.2.m2.1.1.2.cmml">E</mi><mi id="S3.SS2.SSS4.p2.2.m2.1.1.3" xref="S3.SS2.SSS4.p2.2.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS4.p2.2.m2.1b"><apply id="S3.SS2.SSS4.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS4.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS4.p2.2.m2.1.1.1.cmml" xref="S3.SS2.SSS4.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS4.p2.2.m2.1.1.2.cmml" xref="S3.SS2.SSS4.p2.2.m2.1.1.2">𝐸</ci><ci id="S3.SS2.SSS4.p2.2.m2.1.1.3.cmml" xref="S3.SS2.SSS4.p2.2.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS4.p2.2.m2.1c">E_{m}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS4.p2.2.m2.1d">italic_E start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="E_{d}" class="ltx_Math" display="inline" id="S3.SS2.SSS4.p2.3.m3.1"><semantics id="S3.SS2.SSS4.p2.3.m3.1a"><msub id="S3.SS2.SSS4.p2.3.m3.1.1" xref="S3.SS2.SSS4.p2.3.m3.1.1.cmml"><mi id="S3.SS2.SSS4.p2.3.m3.1.1.2" xref="S3.SS2.SSS4.p2.3.m3.1.1.2.cmml">E</mi><mi id="S3.SS2.SSS4.p2.3.m3.1.1.3" xref="S3.SS2.SSS4.p2.3.m3.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS4.p2.3.m3.1b"><apply id="S3.SS2.SSS4.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS4.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS4.p2.3.m3.1.1.1.cmml" xref="S3.SS2.SSS4.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS4.p2.3.m3.1.1.2.cmml" xref="S3.SS2.SSS4.p2.3.m3.1.1.2">𝐸</ci><ci id="S3.SS2.SSS4.p2.3.m3.1.1.3.cmml" xref="S3.SS2.SSS4.p2.3.m3.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS4.p2.3.m3.1c">E_{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS4.p2.3.m3.1d">italic_E start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> denote the emotional scores from the poster, main soundtrack, and movie description. Each movie’s final emotional score (<math alttext="E_{agg}" class="ltx_Math" display="inline" id="S3.SS2.SSS4.p2.4.m4.1"><semantics id="S3.SS2.SSS4.p2.4.m4.1a"><msub id="S3.SS2.SSS4.p2.4.m4.1.1" xref="S3.SS2.SSS4.p2.4.m4.1.1.cmml"><mi id="S3.SS2.SSS4.p2.4.m4.1.1.2" xref="S3.SS2.SSS4.p2.4.m4.1.1.2.cmml">E</mi><mrow id="S3.SS2.SSS4.p2.4.m4.1.1.3" xref="S3.SS2.SSS4.p2.4.m4.1.1.3.cmml"><mi id="S3.SS2.SSS4.p2.4.m4.1.1.3.2" xref="S3.SS2.SSS4.p2.4.m4.1.1.3.2.cmml">a</mi><mo id="S3.SS2.SSS4.p2.4.m4.1.1.3.1" xref="S3.SS2.SSS4.p2.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS4.p2.4.m4.1.1.3.3" xref="S3.SS2.SSS4.p2.4.m4.1.1.3.3.cmml">g</mi><mo id="S3.SS2.SSS4.p2.4.m4.1.1.3.1a" xref="S3.SS2.SSS4.p2.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS4.p2.4.m4.1.1.3.4" xref="S3.SS2.SSS4.p2.4.m4.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS4.p2.4.m4.1b"><apply id="S3.SS2.SSS4.p2.4.m4.1.1.cmml" xref="S3.SS2.SSS4.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS4.p2.4.m4.1.1.1.cmml" xref="S3.SS2.SSS4.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS4.p2.4.m4.1.1.2.cmml" xref="S3.SS2.SSS4.p2.4.m4.1.1.2">𝐸</ci><apply id="S3.SS2.SSS4.p2.4.m4.1.1.3.cmml" xref="S3.SS2.SSS4.p2.4.m4.1.1.3"><times id="S3.SS2.SSS4.p2.4.m4.1.1.3.1.cmml" xref="S3.SS2.SSS4.p2.4.m4.1.1.3.1"></times><ci id="S3.SS2.SSS4.p2.4.m4.1.1.3.2.cmml" xref="S3.SS2.SSS4.p2.4.m4.1.1.3.2">𝑎</ci><ci id="S3.SS2.SSS4.p2.4.m4.1.1.3.3.cmml" xref="S3.SS2.SSS4.p2.4.m4.1.1.3.3">𝑔</ci><ci id="S3.SS2.SSS4.p2.4.m4.1.1.3.4.cmml" xref="S3.SS2.SSS4.p2.4.m4.1.1.3.4">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS4.p2.4.m4.1c">E_{agg}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS4.p2.4.m4.1d">italic_E start_POSTSUBSCRIPT italic_a italic_g italic_g end_POSTSUBSCRIPT</annotation></semantics></math>) is calculated by adding the individual emotional scores multiplied by a particular weight.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS4.p3">
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="E_{agg}=\frac{w_{p}*E_{p}+w_{m}*E_{m}+w_{d}*E_{d}}{w_{p}+w_{m}+w_{d}}" class="ltx_Math" display="block" id="S3.E1.m1.1"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><msub id="S3.E1.m1.1.1.2" xref="S3.E1.m1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.2.2" xref="S3.E1.m1.1.1.2.2.cmml">E</mi><mrow id="S3.E1.m1.1.1.2.3" xref="S3.E1.m1.1.1.2.3.cmml"><mi id="S3.E1.m1.1.1.2.3.2" xref="S3.E1.m1.1.1.2.3.2.cmml">a</mi><mo id="S3.E1.m1.1.1.2.3.1" xref="S3.E1.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.1.1.2.3.3" xref="S3.E1.m1.1.1.2.3.3.cmml">g</mi><mo id="S3.E1.m1.1.1.2.3.1a" xref="S3.E1.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.1.1.2.3.4" xref="S3.E1.m1.1.1.2.3.4.cmml">g</mi></mrow></msub><mo id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml">=</mo><mfrac id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml"><mrow id="S3.E1.m1.1.1.3.2" xref="S3.E1.m1.1.1.3.2.cmml"><mrow id="S3.E1.m1.1.1.3.2.2" xref="S3.E1.m1.1.1.3.2.2.cmml"><msub id="S3.E1.m1.1.1.3.2.2.2" xref="S3.E1.m1.1.1.3.2.2.2.cmml"><mi id="S3.E1.m1.1.1.3.2.2.2.2" xref="S3.E1.m1.1.1.3.2.2.2.2.cmml">w</mi><mi id="S3.E1.m1.1.1.3.2.2.2.3" xref="S3.E1.m1.1.1.3.2.2.2.3.cmml">p</mi></msub><mo id="S3.E1.m1.1.1.3.2.2.1" lspace="0.222em" rspace="0.222em" xref="S3.E1.m1.1.1.3.2.2.1.cmml">∗</mo><msub id="S3.E1.m1.1.1.3.2.2.3" xref="S3.E1.m1.1.1.3.2.2.3.cmml"><mi id="S3.E1.m1.1.1.3.2.2.3.2" xref="S3.E1.m1.1.1.3.2.2.3.2.cmml">E</mi><mi id="S3.E1.m1.1.1.3.2.2.3.3" xref="S3.E1.m1.1.1.3.2.2.3.3.cmml">p</mi></msub></mrow><mo id="S3.E1.m1.1.1.3.2.1" xref="S3.E1.m1.1.1.3.2.1.cmml">+</mo><mrow id="S3.E1.m1.1.1.3.2.3" xref="S3.E1.m1.1.1.3.2.3.cmml"><msub id="S3.E1.m1.1.1.3.2.3.2" xref="S3.E1.m1.1.1.3.2.3.2.cmml"><mi id="S3.E1.m1.1.1.3.2.3.2.2" xref="S3.E1.m1.1.1.3.2.3.2.2.cmml">w</mi><mi id="S3.E1.m1.1.1.3.2.3.2.3" xref="S3.E1.m1.1.1.3.2.3.2.3.cmml">m</mi></msub><mo id="S3.E1.m1.1.1.3.2.3.1" lspace="0.222em" rspace="0.222em" xref="S3.E1.m1.1.1.3.2.3.1.cmml">∗</mo><msub id="S3.E1.m1.1.1.3.2.3.3" xref="S3.E1.m1.1.1.3.2.3.3.cmml"><mi id="S3.E1.m1.1.1.3.2.3.3.2" xref="S3.E1.m1.1.1.3.2.3.3.2.cmml">E</mi><mi id="S3.E1.m1.1.1.3.2.3.3.3" xref="S3.E1.m1.1.1.3.2.3.3.3.cmml">m</mi></msub></mrow><mo id="S3.E1.m1.1.1.3.2.1a" xref="S3.E1.m1.1.1.3.2.1.cmml">+</mo><mrow id="S3.E1.m1.1.1.3.2.4" xref="S3.E1.m1.1.1.3.2.4.cmml"><msub id="S3.E1.m1.1.1.3.2.4.2" xref="S3.E1.m1.1.1.3.2.4.2.cmml"><mi id="S3.E1.m1.1.1.3.2.4.2.2" xref="S3.E1.m1.1.1.3.2.4.2.2.cmml">w</mi><mi id="S3.E1.m1.1.1.3.2.4.2.3" xref="S3.E1.m1.1.1.3.2.4.2.3.cmml">d</mi></msub><mo id="S3.E1.m1.1.1.3.2.4.1" lspace="0.222em" rspace="0.222em" xref="S3.E1.m1.1.1.3.2.4.1.cmml">∗</mo><msub id="S3.E1.m1.1.1.3.2.4.3" xref="S3.E1.m1.1.1.3.2.4.3.cmml"><mi id="S3.E1.m1.1.1.3.2.4.3.2" xref="S3.E1.m1.1.1.3.2.4.3.2.cmml">E</mi><mi id="S3.E1.m1.1.1.3.2.4.3.3" xref="S3.E1.m1.1.1.3.2.4.3.3.cmml">d</mi></msub></mrow></mrow><mrow id="S3.E1.m1.1.1.3.3" xref="S3.E1.m1.1.1.3.3.cmml"><msub id="S3.E1.m1.1.1.3.3.2" xref="S3.E1.m1.1.1.3.3.2.cmml"><mi id="S3.E1.m1.1.1.3.3.2.2" xref="S3.E1.m1.1.1.3.3.2.2.cmml">w</mi><mi id="S3.E1.m1.1.1.3.3.2.3" xref="S3.E1.m1.1.1.3.3.2.3.cmml">p</mi></msub><mo id="S3.E1.m1.1.1.3.3.1" xref="S3.E1.m1.1.1.3.3.1.cmml">+</mo><msub id="S3.E1.m1.1.1.3.3.3" xref="S3.E1.m1.1.1.3.3.3.cmml"><mi id="S3.E1.m1.1.1.3.3.3.2" xref="S3.E1.m1.1.1.3.3.3.2.cmml">w</mi><mi id="S3.E1.m1.1.1.3.3.3.3" xref="S3.E1.m1.1.1.3.3.3.3.cmml">m</mi></msub><mo id="S3.E1.m1.1.1.3.3.1a" xref="S3.E1.m1.1.1.3.3.1.cmml">+</mo><msub id="S3.E1.m1.1.1.3.3.4" xref="S3.E1.m1.1.1.3.3.4.cmml"><mi id="S3.E1.m1.1.1.3.3.4.2" xref="S3.E1.m1.1.1.3.3.4.2.cmml">w</mi><mi id="S3.E1.m1.1.1.3.3.4.3" xref="S3.E1.m1.1.1.3.3.4.3.cmml">d</mi></msub></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><eq id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"></eq><apply id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.2.2">𝐸</ci><apply id="S3.E1.m1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.2.3"><times id="S3.E1.m1.1.1.2.3.1.cmml" xref="S3.E1.m1.1.1.2.3.1"></times><ci id="S3.E1.m1.1.1.2.3.2.cmml" xref="S3.E1.m1.1.1.2.3.2">𝑎</ci><ci id="S3.E1.m1.1.1.2.3.3.cmml" xref="S3.E1.m1.1.1.2.3.3">𝑔</ci><ci id="S3.E1.m1.1.1.2.3.4.cmml" xref="S3.E1.m1.1.1.2.3.4">𝑔</ci></apply></apply><apply id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3"><divide id="S3.E1.m1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.3"></divide><apply id="S3.E1.m1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.3.2"><plus id="S3.E1.m1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.3.2.1"></plus><apply id="S3.E1.m1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.3.2.2"><times id="S3.E1.m1.1.1.3.2.2.1.cmml" xref="S3.E1.m1.1.1.3.2.2.1"></times><apply id="S3.E1.m1.1.1.3.2.2.2.cmml" xref="S3.E1.m1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.2.2.2.1.cmml" xref="S3.E1.m1.1.1.3.2.2.2">subscript</csymbol><ci id="S3.E1.m1.1.1.3.2.2.2.2.cmml" xref="S3.E1.m1.1.1.3.2.2.2.2">𝑤</ci><ci id="S3.E1.m1.1.1.3.2.2.2.3.cmml" xref="S3.E1.m1.1.1.3.2.2.2.3">𝑝</ci></apply><apply id="S3.E1.m1.1.1.3.2.2.3.cmml" xref="S3.E1.m1.1.1.3.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.2.2.3.1.cmml" xref="S3.E1.m1.1.1.3.2.2.3">subscript</csymbol><ci id="S3.E1.m1.1.1.3.2.2.3.2.cmml" xref="S3.E1.m1.1.1.3.2.2.3.2">𝐸</ci><ci id="S3.E1.m1.1.1.3.2.2.3.3.cmml" xref="S3.E1.m1.1.1.3.2.2.3.3">𝑝</ci></apply></apply><apply id="S3.E1.m1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.3.2.3"><times id="S3.E1.m1.1.1.3.2.3.1.cmml" xref="S3.E1.m1.1.1.3.2.3.1"></times><apply id="S3.E1.m1.1.1.3.2.3.2.cmml" xref="S3.E1.m1.1.1.3.2.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.2.3.2.1.cmml" xref="S3.E1.m1.1.1.3.2.3.2">subscript</csymbol><ci id="S3.E1.m1.1.1.3.2.3.2.2.cmml" xref="S3.E1.m1.1.1.3.2.3.2.2">𝑤</ci><ci id="S3.E1.m1.1.1.3.2.3.2.3.cmml" xref="S3.E1.m1.1.1.3.2.3.2.3">𝑚</ci></apply><apply id="S3.E1.m1.1.1.3.2.3.3.cmml" xref="S3.E1.m1.1.1.3.2.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.2.3.3.1.cmml" xref="S3.E1.m1.1.1.3.2.3.3">subscript</csymbol><ci id="S3.E1.m1.1.1.3.2.3.3.2.cmml" xref="S3.E1.m1.1.1.3.2.3.3.2">𝐸</ci><ci id="S3.E1.m1.1.1.3.2.3.3.3.cmml" xref="S3.E1.m1.1.1.3.2.3.3.3">𝑚</ci></apply></apply><apply id="S3.E1.m1.1.1.3.2.4.cmml" xref="S3.E1.m1.1.1.3.2.4"><times id="S3.E1.m1.1.1.3.2.4.1.cmml" xref="S3.E1.m1.1.1.3.2.4.1"></times><apply id="S3.E1.m1.1.1.3.2.4.2.cmml" xref="S3.E1.m1.1.1.3.2.4.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.2.4.2.1.cmml" xref="S3.E1.m1.1.1.3.2.4.2">subscript</csymbol><ci id="S3.E1.m1.1.1.3.2.4.2.2.cmml" xref="S3.E1.m1.1.1.3.2.4.2.2">𝑤</ci><ci id="S3.E1.m1.1.1.3.2.4.2.3.cmml" xref="S3.E1.m1.1.1.3.2.4.2.3">𝑑</ci></apply><apply id="S3.E1.m1.1.1.3.2.4.3.cmml" xref="S3.E1.m1.1.1.3.2.4.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.2.4.3.1.cmml" xref="S3.E1.m1.1.1.3.2.4.3">subscript</csymbol><ci id="S3.E1.m1.1.1.3.2.4.3.2.cmml" xref="S3.E1.m1.1.1.3.2.4.3.2">𝐸</ci><ci id="S3.E1.m1.1.1.3.2.4.3.3.cmml" xref="S3.E1.m1.1.1.3.2.4.3.3">𝑑</ci></apply></apply></apply><apply id="S3.E1.m1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.3.3"><plus id="S3.E1.m1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.3.3.1"></plus><apply id="S3.E1.m1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.3.2.1.cmml" xref="S3.E1.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.E1.m1.1.1.3.3.2.2.cmml" xref="S3.E1.m1.1.1.3.3.2.2">𝑤</ci><ci id="S3.E1.m1.1.1.3.3.2.3.cmml" xref="S3.E1.m1.1.1.3.3.2.3">𝑝</ci></apply><apply id="S3.E1.m1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.3.3.1.cmml" xref="S3.E1.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.E1.m1.1.1.3.3.3.2.cmml" xref="S3.E1.m1.1.1.3.3.3.2">𝑤</ci><ci id="S3.E1.m1.1.1.3.3.3.3.cmml" xref="S3.E1.m1.1.1.3.3.3.3">𝑚</ci></apply><apply id="S3.E1.m1.1.1.3.3.4.cmml" xref="S3.E1.m1.1.1.3.3.4"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.3.4.1.cmml" xref="S3.E1.m1.1.1.3.3.4">subscript</csymbol><ci id="S3.E1.m1.1.1.3.3.4.2.cmml" xref="S3.E1.m1.1.1.3.3.4.2">𝑤</ci><ci id="S3.E1.m1.1.1.3.3.4.3.cmml" xref="S3.E1.m1.1.1.3.3.4.3">𝑑</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">E_{agg}=\frac{w_{p}*E_{p}+w_{m}*E_{m}+w_{d}*E_{d}}{w_{p}+w_{m}+w_{d}}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.1d">italic_E start_POSTSUBSCRIPT italic_a italic_g italic_g end_POSTSUBSCRIPT = divide start_ARG italic_w start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ∗ italic_E start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT + italic_w start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ∗ italic_E start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT + italic_w start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ∗ italic_E start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT end_ARG start_ARG italic_w start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT + italic_w start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT + italic_w start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.SSS4.p4">
<p class="ltx_p" id="S3.SS2.SSS4.p4.6">where <math alttext="w_{p}" class="ltx_Math" display="inline" id="S3.SS2.SSS4.p4.1.m1.1"><semantics id="S3.SS2.SSS4.p4.1.m1.1a"><msub id="S3.SS2.SSS4.p4.1.m1.1.1" xref="S3.SS2.SSS4.p4.1.m1.1.1.cmml"><mi id="S3.SS2.SSS4.p4.1.m1.1.1.2" xref="S3.SS2.SSS4.p4.1.m1.1.1.2.cmml">w</mi><mi id="S3.SS2.SSS4.p4.1.m1.1.1.3" xref="S3.SS2.SSS4.p4.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS4.p4.1.m1.1b"><apply id="S3.SS2.SSS4.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS4.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS4.p4.1.m1.1.1.1.cmml" xref="S3.SS2.SSS4.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS4.p4.1.m1.1.1.2.cmml" xref="S3.SS2.SSS4.p4.1.m1.1.1.2">𝑤</ci><ci id="S3.SS2.SSS4.p4.1.m1.1.1.3.cmml" xref="S3.SS2.SSS4.p4.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS4.p4.1.m1.1c">w_{p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS4.p4.1.m1.1d">italic_w start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="w_{m}" class="ltx_Math" display="inline" id="S3.SS2.SSS4.p4.2.m2.1"><semantics id="S3.SS2.SSS4.p4.2.m2.1a"><msub id="S3.SS2.SSS4.p4.2.m2.1.1" xref="S3.SS2.SSS4.p4.2.m2.1.1.cmml"><mi id="S3.SS2.SSS4.p4.2.m2.1.1.2" xref="S3.SS2.SSS4.p4.2.m2.1.1.2.cmml">w</mi><mi id="S3.SS2.SSS4.p4.2.m2.1.1.3" xref="S3.SS2.SSS4.p4.2.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS4.p4.2.m2.1b"><apply id="S3.SS2.SSS4.p4.2.m2.1.1.cmml" xref="S3.SS2.SSS4.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS4.p4.2.m2.1.1.1.cmml" xref="S3.SS2.SSS4.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS4.p4.2.m2.1.1.2.cmml" xref="S3.SS2.SSS4.p4.2.m2.1.1.2">𝑤</ci><ci id="S3.SS2.SSS4.p4.2.m2.1.1.3.cmml" xref="S3.SS2.SSS4.p4.2.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS4.p4.2.m2.1c">w_{m}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS4.p4.2.m2.1d">italic_w start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="w_{d}" class="ltx_Math" display="inline" id="S3.SS2.SSS4.p4.3.m3.1"><semantics id="S3.SS2.SSS4.p4.3.m3.1a"><msub id="S3.SS2.SSS4.p4.3.m3.1.1" xref="S3.SS2.SSS4.p4.3.m3.1.1.cmml"><mi id="S3.SS2.SSS4.p4.3.m3.1.1.2" xref="S3.SS2.SSS4.p4.3.m3.1.1.2.cmml">w</mi><mi id="S3.SS2.SSS4.p4.3.m3.1.1.3" xref="S3.SS2.SSS4.p4.3.m3.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS4.p4.3.m3.1b"><apply id="S3.SS2.SSS4.p4.3.m3.1.1.cmml" xref="S3.SS2.SSS4.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS4.p4.3.m3.1.1.1.cmml" xref="S3.SS2.SSS4.p4.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS4.p4.3.m3.1.1.2.cmml" xref="S3.SS2.SSS4.p4.3.m3.1.1.2">𝑤</ci><ci id="S3.SS2.SSS4.p4.3.m3.1.1.3.cmml" xref="S3.SS2.SSS4.p4.3.m3.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS4.p4.3.m3.1c">w_{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS4.p4.3.m3.1d">italic_w start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> mean the weights assigned to the emotional scores from the poster, main soundtrack, and movie description, respectively. We selected the following weights based on subjective observations: <math alttext="w_{p}" class="ltx_Math" display="inline" id="S3.SS2.SSS4.p4.4.m4.1"><semantics id="S3.SS2.SSS4.p4.4.m4.1a"><msub id="S3.SS2.SSS4.p4.4.m4.1.1" xref="S3.SS2.SSS4.p4.4.m4.1.1.cmml"><mi id="S3.SS2.SSS4.p4.4.m4.1.1.2" xref="S3.SS2.SSS4.p4.4.m4.1.1.2.cmml">w</mi><mi id="S3.SS2.SSS4.p4.4.m4.1.1.3" xref="S3.SS2.SSS4.p4.4.m4.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS4.p4.4.m4.1b"><apply id="S3.SS2.SSS4.p4.4.m4.1.1.cmml" xref="S3.SS2.SSS4.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS4.p4.4.m4.1.1.1.cmml" xref="S3.SS2.SSS4.p4.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS4.p4.4.m4.1.1.2.cmml" xref="S3.SS2.SSS4.p4.4.m4.1.1.2">𝑤</ci><ci id="S3.SS2.SSS4.p4.4.m4.1.1.3.cmml" xref="S3.SS2.SSS4.p4.4.m4.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS4.p4.4.m4.1c">w_{p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS4.p4.4.m4.1d">italic_w start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math> = 1, <math alttext="w_{m}" class="ltx_Math" display="inline" id="S3.SS2.SSS4.p4.5.m5.1"><semantics id="S3.SS2.SSS4.p4.5.m5.1a"><msub id="S3.SS2.SSS4.p4.5.m5.1.1" xref="S3.SS2.SSS4.p4.5.m5.1.1.cmml"><mi id="S3.SS2.SSS4.p4.5.m5.1.1.2" xref="S3.SS2.SSS4.p4.5.m5.1.1.2.cmml">w</mi><mi id="S3.SS2.SSS4.p4.5.m5.1.1.3" xref="S3.SS2.SSS4.p4.5.m5.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS4.p4.5.m5.1b"><apply id="S3.SS2.SSS4.p4.5.m5.1.1.cmml" xref="S3.SS2.SSS4.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS4.p4.5.m5.1.1.1.cmml" xref="S3.SS2.SSS4.p4.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.SSS4.p4.5.m5.1.1.2.cmml" xref="S3.SS2.SSS4.p4.5.m5.1.1.2">𝑤</ci><ci id="S3.SS2.SSS4.p4.5.m5.1.1.3.cmml" xref="S3.SS2.SSS4.p4.5.m5.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS4.p4.5.m5.1c">w_{m}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS4.p4.5.m5.1d">italic_w start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> = 2, <math alttext="w_{d}" class="ltx_Math" display="inline" id="S3.SS2.SSS4.p4.6.m6.1"><semantics id="S3.SS2.SSS4.p4.6.m6.1a"><msub id="S3.SS2.SSS4.p4.6.m6.1.1" xref="S3.SS2.SSS4.p4.6.m6.1.1.cmml"><mi id="S3.SS2.SSS4.p4.6.m6.1.1.2" xref="S3.SS2.SSS4.p4.6.m6.1.1.2.cmml">w</mi><mi id="S3.SS2.SSS4.p4.6.m6.1.1.3" xref="S3.SS2.SSS4.p4.6.m6.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS4.p4.6.m6.1b"><apply id="S3.SS2.SSS4.p4.6.m6.1.1.cmml" xref="S3.SS2.SSS4.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS4.p4.6.m6.1.1.1.cmml" xref="S3.SS2.SSS4.p4.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.SSS4.p4.6.m6.1.1.2.cmml" xref="S3.SS2.SSS4.p4.6.m6.1.1.2">𝑤</ci><ci id="S3.SS2.SSS4.p4.6.m6.1.1.3.cmml" xref="S3.SS2.SSS4.p4.6.m6.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS4.p4.6.m6.1c">w_{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS4.p4.6.m6.1d">italic_w start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> = 3.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS3.4.1.1">III-C</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS3.5.2">Recommendation using Jaccard Coefficient</span>
</h3>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="699" id="S3.F4.g1" src="extracted/2404.13778v1/fig/recomendation_system_fiexed.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F4.2.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S3.F4.3.2" style="font-size:90%;">Recommendations are provided based on detected emotions and the Jaccard Similarity index, and then they are ordered by genre. Finally fuzzy inference system is used to evaluate consensus among group members regarding regarding recommended movies</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">We computed the Jaccard similarity coefficient between the emotional composition of movies in our database, and the participants’ most loved movies using equation (<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.E2" title="In III-C Recommendation using Jaccard Coefficient ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">2</span></a>). This process gives a Jaccard value indicating the similarity between the emotional composition of the <math alttext="n" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_n</annotation></semantics></math> movies and the participants’ preferred choices. Additionally, we can evaluate the effectiveness of our method by comparing the similarity between the actual and predicted ratings.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="J(A,B)=\frac{\left|A\cap B\right|}{\left|A\cup B\right|}" class="ltx_Math" display="block" id="S3.E2.m1.4"><semantics id="S3.E2.m1.4a"><mrow id="S3.E2.m1.4.5" xref="S3.E2.m1.4.5.cmml"><mrow id="S3.E2.m1.4.5.2" xref="S3.E2.m1.4.5.2.cmml"><mi id="S3.E2.m1.4.5.2.2" xref="S3.E2.m1.4.5.2.2.cmml">J</mi><mo id="S3.E2.m1.4.5.2.1" xref="S3.E2.m1.4.5.2.1.cmml">⁢</mo><mrow id="S3.E2.m1.4.5.2.3.2" xref="S3.E2.m1.4.5.2.3.1.cmml"><mo id="S3.E2.m1.4.5.2.3.2.1" stretchy="false" xref="S3.E2.m1.4.5.2.3.1.cmml">(</mo><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">A</mi><mo id="S3.E2.m1.4.5.2.3.2.2" xref="S3.E2.m1.4.5.2.3.1.cmml">,</mo><mi id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml">B</mi><mo id="S3.E2.m1.4.5.2.3.2.3" stretchy="false" xref="S3.E2.m1.4.5.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.4.5.1" xref="S3.E2.m1.4.5.1.cmml">=</mo><mfrac id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.2.cmml"><mo id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.2.1.cmml">|</mo><mrow id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.2.cmml">A</mi><mo id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml">∩</mo><mi id="S3.E2.m1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.3.cmml">B</mi></mrow><mo id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.2.1.cmml">|</mo></mrow><mrow id="S3.E2.m1.2.2.2.1" xref="S3.E2.m1.2.2.2.2.cmml"><mo id="S3.E2.m1.2.2.2.1.2" xref="S3.E2.m1.2.2.2.2.1.cmml">|</mo><mrow id="S3.E2.m1.2.2.2.1.1" xref="S3.E2.m1.2.2.2.1.1.cmml"><mi id="S3.E2.m1.2.2.2.1.1.2" xref="S3.E2.m1.2.2.2.1.1.2.cmml">A</mi><mo id="S3.E2.m1.2.2.2.1.1.1" xref="S3.E2.m1.2.2.2.1.1.1.cmml">∪</mo><mi id="S3.E2.m1.2.2.2.1.1.3" xref="S3.E2.m1.2.2.2.1.1.3.cmml">B</mi></mrow><mo id="S3.E2.m1.2.2.2.1.3" xref="S3.E2.m1.2.2.2.2.1.cmml">|</mo></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.4b"><apply id="S3.E2.m1.4.5.cmml" xref="S3.E2.m1.4.5"><eq id="S3.E2.m1.4.5.1.cmml" xref="S3.E2.m1.4.5.1"></eq><apply id="S3.E2.m1.4.5.2.cmml" xref="S3.E2.m1.4.5.2"><times id="S3.E2.m1.4.5.2.1.cmml" xref="S3.E2.m1.4.5.2.1"></times><ci id="S3.E2.m1.4.5.2.2.cmml" xref="S3.E2.m1.4.5.2.2">𝐽</ci><interval closure="open" id="S3.E2.m1.4.5.2.3.1.cmml" xref="S3.E2.m1.4.5.2.3.2"><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">𝐴</ci><ci id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.4">𝐵</ci></interval></apply><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2"><divide id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.2.2"></divide><apply id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1"><abs id="S3.E2.m1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2"></abs><apply id="S3.E2.m1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"><intersect id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1"></intersect><ci id="S3.E2.m1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.2">𝐴</ci><ci id="S3.E2.m1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.3">𝐵</ci></apply></apply><apply id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.1"><abs id="S3.E2.m1.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.1.2"></abs><apply id="S3.E2.m1.2.2.2.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1"><union id="S3.E2.m1.2.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1"></union><ci id="S3.E2.m1.2.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.2.1.1.2">𝐴</ci><ci id="S3.E2.m1.2.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.2.1.1.3">𝐵</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.4c">J(A,B)=\frac{\left|A\cap B\right|}{\left|A\cup B\right|}</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.4d">italic_J ( italic_A , italic_B ) = divide start_ARG | italic_A ∩ italic_B | end_ARG start_ARG | italic_A ∪ italic_B | end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.3">where <math alttext="J" class="ltx_Math" display="inline" id="S3.SS3.p3.1.m1.1"><semantics id="S3.SS3.p3.1.m1.1a"><mi id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml">J</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><ci id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">𝐽</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">J</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.1.m1.1d">italic_J</annotation></semantics></math> = Jaccard distance, <math alttext="A" class="ltx_Math" display="inline" id="S3.SS3.p3.2.m2.1"><semantics id="S3.SS3.p3.2.m2.1a"><mi id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><ci id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">A</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.2.m2.1d">italic_A</annotation></semantics></math> = set 1, <math alttext="B" class="ltx_Math" display="inline" id="S3.SS3.p3.3.m3.1"><semantics id="S3.SS3.p3.3.m3.1a"><mi id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><ci id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">B</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.3.m3.1d">italic_B</annotation></semantics></math> = set 2. Emotion was added with a threshold of 0.05 for the emotion score.</p>
</div>
<div class="ltx_para" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.5">For group recommendations, we aggregate the Jaccard values obtained from each participant’s favorite movie for each of the <math alttext="n" class="ltx_Math" display="inline" id="S3.SS3.p4.1.m1.1"><semantics id="S3.SS3.p4.1.m1.1a"><mi id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><ci id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.1.m1.1d">italic_n</annotation></semantics></math> movies. The Jaccard value <math alttext="J_{agg}^{i}" class="ltx_Math" display="inline" id="S3.SS3.p4.2.m2.1"><semantics id="S3.SS3.p4.2.m2.1a"><msubsup id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml"><mi id="S3.SS3.p4.2.m2.1.1.2.2" xref="S3.SS3.p4.2.m2.1.1.2.2.cmml">J</mi><mrow id="S3.SS3.p4.2.m2.1.1.2.3" xref="S3.SS3.p4.2.m2.1.1.2.3.cmml"><mi id="S3.SS3.p4.2.m2.1.1.2.3.2" xref="S3.SS3.p4.2.m2.1.1.2.3.2.cmml">a</mi><mo id="S3.SS3.p4.2.m2.1.1.2.3.1" xref="S3.SS3.p4.2.m2.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS3.p4.2.m2.1.1.2.3.3" xref="S3.SS3.p4.2.m2.1.1.2.3.3.cmml">g</mi><mo id="S3.SS3.p4.2.m2.1.1.2.3.1a" xref="S3.SS3.p4.2.m2.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS3.p4.2.m2.1.1.2.3.4" xref="S3.SS3.p4.2.m2.1.1.2.3.4.cmml">g</mi></mrow><mi id="S3.SS3.p4.2.m2.1.1.3" xref="S3.SS3.p4.2.m2.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><apply id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1">superscript</csymbol><apply id="S3.SS3.p4.2.m2.1.1.2.cmml" xref="S3.SS3.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.2.1.cmml" xref="S3.SS3.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p4.2.m2.1.1.2.2.cmml" xref="S3.SS3.p4.2.m2.1.1.2.2">𝐽</ci><apply id="S3.SS3.p4.2.m2.1.1.2.3.cmml" xref="S3.SS3.p4.2.m2.1.1.2.3"><times id="S3.SS3.p4.2.m2.1.1.2.3.1.cmml" xref="S3.SS3.p4.2.m2.1.1.2.3.1"></times><ci id="S3.SS3.p4.2.m2.1.1.2.3.2.cmml" xref="S3.SS3.p4.2.m2.1.1.2.3.2">𝑎</ci><ci id="S3.SS3.p4.2.m2.1.1.2.3.3.cmml" xref="S3.SS3.p4.2.m2.1.1.2.3.3">𝑔</ci><ci id="S3.SS3.p4.2.m2.1.1.2.3.4.cmml" xref="S3.SS3.p4.2.m2.1.1.2.3.4">𝑔</ci></apply></apply><ci id="S3.SS3.p4.2.m2.1.1.3.cmml" xref="S3.SS3.p4.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">J_{agg}^{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.2.m2.1d">italic_J start_POSTSUBSCRIPT italic_a italic_g italic_g end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math> for each movie is calculated as the average of Jaccard values across all participants. For movie <math alttext="i" class="ltx_Math" display="inline" id="S3.SS3.p4.3.m3.1"><semantics id="S3.SS3.p4.3.m3.1a"><mi id="S3.SS3.p4.3.m3.1.1" xref="S3.SS3.p4.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m3.1b"><ci id="S3.SS3.p4.3.m3.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.3.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.3.m3.1d">italic_i</annotation></semantics></math>, the aggregated Jaccard value <math alttext="J_{agg}^{i}" class="ltx_Math" display="inline" id="S3.SS3.p4.4.m4.1"><semantics id="S3.SS3.p4.4.m4.1a"><msubsup id="S3.SS3.p4.4.m4.1.1" xref="S3.SS3.p4.4.m4.1.1.cmml"><mi id="S3.SS3.p4.4.m4.1.1.2.2" xref="S3.SS3.p4.4.m4.1.1.2.2.cmml">J</mi><mrow id="S3.SS3.p4.4.m4.1.1.2.3" xref="S3.SS3.p4.4.m4.1.1.2.3.cmml"><mi id="S3.SS3.p4.4.m4.1.1.2.3.2" xref="S3.SS3.p4.4.m4.1.1.2.3.2.cmml">a</mi><mo id="S3.SS3.p4.4.m4.1.1.2.3.1" xref="S3.SS3.p4.4.m4.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS3.p4.4.m4.1.1.2.3.3" xref="S3.SS3.p4.4.m4.1.1.2.3.3.cmml">g</mi><mo id="S3.SS3.p4.4.m4.1.1.2.3.1a" xref="S3.SS3.p4.4.m4.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS3.p4.4.m4.1.1.2.3.4" xref="S3.SS3.p4.4.m4.1.1.2.3.4.cmml">g</mi></mrow><mi id="S3.SS3.p4.4.m4.1.1.3" xref="S3.SS3.p4.4.m4.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.4.m4.1b"><apply id="S3.SS3.p4.4.m4.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.4.m4.1.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1">superscript</csymbol><apply id="S3.SS3.p4.4.m4.1.1.2.cmml" xref="S3.SS3.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.4.m4.1.1.2.1.cmml" xref="S3.SS3.p4.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p4.4.m4.1.1.2.2.cmml" xref="S3.SS3.p4.4.m4.1.1.2.2">𝐽</ci><apply id="S3.SS3.p4.4.m4.1.1.2.3.cmml" xref="S3.SS3.p4.4.m4.1.1.2.3"><times id="S3.SS3.p4.4.m4.1.1.2.3.1.cmml" xref="S3.SS3.p4.4.m4.1.1.2.3.1"></times><ci id="S3.SS3.p4.4.m4.1.1.2.3.2.cmml" xref="S3.SS3.p4.4.m4.1.1.2.3.2">𝑎</ci><ci id="S3.SS3.p4.4.m4.1.1.2.3.3.cmml" xref="S3.SS3.p4.4.m4.1.1.2.3.3">𝑔</ci><ci id="S3.SS3.p4.4.m4.1.1.2.3.4.cmml" xref="S3.SS3.p4.4.m4.1.1.2.3.4">𝑔</ci></apply></apply><ci id="S3.SS3.p4.4.m4.1.1.3.cmml" xref="S3.SS3.p4.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.4.m4.1c">J_{agg}^{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.4.m4.1d">italic_J start_POSTSUBSCRIPT italic_a italic_g italic_g end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math> is calculated by taking the average of Jaccard values obtained from participant preferences, <math alttext="J_{j}^{i}" class="ltx_Math" display="inline" id="S3.SS3.p4.5.m5.1"><semantics id="S3.SS3.p4.5.m5.1a"><msubsup id="S3.SS3.p4.5.m5.1.1" xref="S3.SS3.p4.5.m5.1.1.cmml"><mi id="S3.SS3.p4.5.m5.1.1.2.2" xref="S3.SS3.p4.5.m5.1.1.2.2.cmml">J</mi><mi id="S3.SS3.p4.5.m5.1.1.2.3" xref="S3.SS3.p4.5.m5.1.1.2.3.cmml">j</mi><mi id="S3.SS3.p4.5.m5.1.1.3" xref="S3.SS3.p4.5.m5.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.5.m5.1b"><apply id="S3.SS3.p4.5.m5.1.1.cmml" xref="S3.SS3.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.5.m5.1.1.1.cmml" xref="S3.SS3.p4.5.m5.1.1">superscript</csymbol><apply id="S3.SS3.p4.5.m5.1.1.2.cmml" xref="S3.SS3.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.5.m5.1.1.2.1.cmml" xref="S3.SS3.p4.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.p4.5.m5.1.1.2.2.cmml" xref="S3.SS3.p4.5.m5.1.1.2.2">𝐽</ci><ci id="S3.SS3.p4.5.m5.1.1.2.3.cmml" xref="S3.SS3.p4.5.m5.1.1.2.3">𝑗</ci></apply><ci id="S3.SS3.p4.5.m5.1.1.3.cmml" xref="S3.SS3.p4.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.5.m5.1c">J_{j}^{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.5.m5.1d">italic_J start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS3.p5">
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="J_{agg}^{i}=\frac{\sum_{j=1}^{m}J_{j}^{i}}{m}" class="ltx_Math" display="block" id="S3.E3.m1.1"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml"><msubsup id="S3.E3.m1.1.1.2" xref="S3.E3.m1.1.1.2.cmml"><mi id="S3.E3.m1.1.1.2.2.2" xref="S3.E3.m1.1.1.2.2.2.cmml">J</mi><mrow id="S3.E3.m1.1.1.2.2.3" xref="S3.E3.m1.1.1.2.2.3.cmml"><mi id="S3.E3.m1.1.1.2.2.3.2" xref="S3.E3.m1.1.1.2.2.3.2.cmml">a</mi><mo id="S3.E3.m1.1.1.2.2.3.1" xref="S3.E3.m1.1.1.2.2.3.1.cmml">⁢</mo><mi id="S3.E3.m1.1.1.2.2.3.3" xref="S3.E3.m1.1.1.2.2.3.3.cmml">g</mi><mo id="S3.E3.m1.1.1.2.2.3.1a" xref="S3.E3.m1.1.1.2.2.3.1.cmml">⁢</mo><mi id="S3.E3.m1.1.1.2.2.3.4" xref="S3.E3.m1.1.1.2.2.3.4.cmml">g</mi></mrow><mi id="S3.E3.m1.1.1.2.3" xref="S3.E3.m1.1.1.2.3.cmml">i</mi></msubsup><mo id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.cmml">=</mo><mfrac id="S3.E3.m1.1.1.3" xref="S3.E3.m1.1.1.3.cmml"><mrow id="S3.E3.m1.1.1.3.2" xref="S3.E3.m1.1.1.3.2.cmml"><msubsup id="S3.E3.m1.1.1.3.2.1" xref="S3.E3.m1.1.1.3.2.1.cmml"><mo id="S3.E3.m1.1.1.3.2.1.2.2" xref="S3.E3.m1.1.1.3.2.1.2.2.cmml">∑</mo><mrow id="S3.E3.m1.1.1.3.2.1.2.3" xref="S3.E3.m1.1.1.3.2.1.2.3.cmml"><mi id="S3.E3.m1.1.1.3.2.1.2.3.2" xref="S3.E3.m1.1.1.3.2.1.2.3.2.cmml">j</mi><mo id="S3.E3.m1.1.1.3.2.1.2.3.1" xref="S3.E3.m1.1.1.3.2.1.2.3.1.cmml">=</mo><mn id="S3.E3.m1.1.1.3.2.1.2.3.3" xref="S3.E3.m1.1.1.3.2.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E3.m1.1.1.3.2.1.3" xref="S3.E3.m1.1.1.3.2.1.3.cmml">m</mi></msubsup><msubsup id="S3.E3.m1.1.1.3.2.2" xref="S3.E3.m1.1.1.3.2.2.cmml"><mi id="S3.E3.m1.1.1.3.2.2.2.2" xref="S3.E3.m1.1.1.3.2.2.2.2.cmml">J</mi><mi id="S3.E3.m1.1.1.3.2.2.2.3" xref="S3.E3.m1.1.1.3.2.2.2.3.cmml">j</mi><mi id="S3.E3.m1.1.1.3.2.2.3" xref="S3.E3.m1.1.1.3.2.2.3.cmml">i</mi></msubsup></mrow><mi id="S3.E3.m1.1.1.3.3" xref="S3.E3.m1.1.1.3.3.cmml">m</mi></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1"><eq id="S3.E3.m1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"></eq><apply id="S3.E3.m1.1.1.2.cmml" xref="S3.E3.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.2">superscript</csymbol><apply id="S3.E3.m1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.2.2.1.cmml" xref="S3.E3.m1.1.1.2">subscript</csymbol><ci id="S3.E3.m1.1.1.2.2.2.cmml" xref="S3.E3.m1.1.1.2.2.2">𝐽</ci><apply id="S3.E3.m1.1.1.2.2.3.cmml" xref="S3.E3.m1.1.1.2.2.3"><times id="S3.E3.m1.1.1.2.2.3.1.cmml" xref="S3.E3.m1.1.1.2.2.3.1"></times><ci id="S3.E3.m1.1.1.2.2.3.2.cmml" xref="S3.E3.m1.1.1.2.2.3.2">𝑎</ci><ci id="S3.E3.m1.1.1.2.2.3.3.cmml" xref="S3.E3.m1.1.1.2.2.3.3">𝑔</ci><ci id="S3.E3.m1.1.1.2.2.3.4.cmml" xref="S3.E3.m1.1.1.2.2.3.4">𝑔</ci></apply></apply><ci id="S3.E3.m1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.2.3">𝑖</ci></apply><apply id="S3.E3.m1.1.1.3.cmml" xref="S3.E3.m1.1.1.3"><divide id="S3.E3.m1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.3"></divide><apply id="S3.E3.m1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.3.2"><apply id="S3.E3.m1.1.1.3.2.1.cmml" xref="S3.E3.m1.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.2.1.1.cmml" xref="S3.E3.m1.1.1.3.2.1">superscript</csymbol><apply id="S3.E3.m1.1.1.3.2.1.2.cmml" xref="S3.E3.m1.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.2.1.2.1.cmml" xref="S3.E3.m1.1.1.3.2.1">subscript</csymbol><sum id="S3.E3.m1.1.1.3.2.1.2.2.cmml" xref="S3.E3.m1.1.1.3.2.1.2.2"></sum><apply id="S3.E3.m1.1.1.3.2.1.2.3.cmml" xref="S3.E3.m1.1.1.3.2.1.2.3"><eq id="S3.E3.m1.1.1.3.2.1.2.3.1.cmml" xref="S3.E3.m1.1.1.3.2.1.2.3.1"></eq><ci id="S3.E3.m1.1.1.3.2.1.2.3.2.cmml" xref="S3.E3.m1.1.1.3.2.1.2.3.2">𝑗</ci><cn id="S3.E3.m1.1.1.3.2.1.2.3.3.cmml" type="integer" xref="S3.E3.m1.1.1.3.2.1.2.3.3">1</cn></apply></apply><ci id="S3.E3.m1.1.1.3.2.1.3.cmml" xref="S3.E3.m1.1.1.3.2.1.3">𝑚</ci></apply><apply id="S3.E3.m1.1.1.3.2.2.cmml" xref="S3.E3.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.2.2.1.cmml" xref="S3.E3.m1.1.1.3.2.2">superscript</csymbol><apply id="S3.E3.m1.1.1.3.2.2.2.cmml" xref="S3.E3.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.2.2.2.1.cmml" xref="S3.E3.m1.1.1.3.2.2">subscript</csymbol><ci id="S3.E3.m1.1.1.3.2.2.2.2.cmml" xref="S3.E3.m1.1.1.3.2.2.2.2">𝐽</ci><ci id="S3.E3.m1.1.1.3.2.2.2.3.cmml" xref="S3.E3.m1.1.1.3.2.2.2.3">𝑗</ci></apply><ci id="S3.E3.m1.1.1.3.2.2.3.cmml" xref="S3.E3.m1.1.1.3.2.2.3">𝑖</ci></apply></apply><ci id="S3.E3.m1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.3.3">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">J_{agg}^{i}=\frac{\sum_{j=1}^{m}J_{j}^{i}}{m}</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.1d">italic_J start_POSTSUBSCRIPT italic_a italic_g italic_g end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = divide start_ARG ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_J start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_ARG start_ARG italic_m end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS3.p6">
<p class="ltx_p" id="S3.SS3.p6.5">where <math alttext="m" class="ltx_Math" display="inline" id="S3.SS3.p6.1.m1.1"><semantics id="S3.SS3.p6.1.m1.1a"><mi id="S3.SS3.p6.1.m1.1.1" xref="S3.SS3.p6.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.1.m1.1b"><ci id="S3.SS3.p6.1.m1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.1.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p6.1.m1.1d">italic_m</annotation></semantics></math> denotes the total number of participants, <math alttext="j" class="ltx_Math" display="inline" id="S3.SS3.p6.2.m2.1"><semantics id="S3.SS3.p6.2.m2.1a"><mi id="S3.SS3.p6.2.m2.1.1" xref="S3.SS3.p6.2.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.2.m2.1b"><ci id="S3.SS3.p6.2.m2.1.1.cmml" xref="S3.SS3.p6.2.m2.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.2.m2.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p6.2.m2.1d">italic_j</annotation></semantics></math> - from 1 to <math alttext="m" class="ltx_Math" display="inline" id="S3.SS3.p6.3.m3.1"><semantics id="S3.SS3.p6.3.m3.1a"><mi id="S3.SS3.p6.3.m3.1.1" xref="S3.SS3.p6.3.m3.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.3.m3.1b"><ci id="S3.SS3.p6.3.m3.1.1.cmml" xref="S3.SS3.p6.3.m3.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.3.m3.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p6.3.m3.1d">italic_m</annotation></semantics></math>, <math alttext="i" class="ltx_Math" display="inline" id="S3.SS3.p6.4.m4.1"><semantics id="S3.SS3.p6.4.m4.1a"><mi id="S3.SS3.p6.4.m4.1.1" xref="S3.SS3.p6.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.4.m4.1b"><ci id="S3.SS3.p6.4.m4.1.1.cmml" xref="S3.SS3.p6.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.4.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p6.4.m4.1d">italic_i</annotation></semantics></math> - from 1 to <math alttext="n" class="ltx_Math" display="inline" id="S3.SS3.p6.5.m5.1"><semantics id="S3.SS3.p6.5.m5.1a"><mi id="S3.SS3.p6.5.m5.1.1" xref="S3.SS3.p6.5.m5.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.5.m5.1b"><ci id="S3.SS3.p6.5.m5.1.1.cmml" xref="S3.SS3.p6.5.m5.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.5.m5.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p6.5.m5.1d">italic_n</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS3.p7">
<p class="ltx_p" id="S3.SS3.p7.1">The proposed recommendation system can be seen in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.F4" title="Figure 4 ‣ III-C Recommendation using Jaccard Coefficient ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">4</span></a>. As can be seen, the recommended alternatives are then ranked according to their genre.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS4.4.1.1">III-D</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS4.5.2">Consensus Model using Fuzzy Logic</span>
</h3>
<figure class="ltx_figure" id="S3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="194" id="S3.F5.g1" src="extracted/2404.13778v1/fig/consensus.png" width="299"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F5.2.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S3.F5.3.2" style="font-size:90%;">General process of consensus evaluation</span></figcaption>
</figure>
<figure class="ltx_figure" id="S3.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F6.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="170" id="S3.F6.sf1.g1" src="extracted/2404.13778v1/images/fuzzy_agreement_plot.png" width="305"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F6.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S3.F6.sf1.3.2" style="font-size:90%;">agreement measure</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F6.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="170" id="S3.F6.sf2.g1" src="extracted/2404.13778v1/images/fuzzy_confidence_plot.png" width="305"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F6.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S3.F6.sf2.3.2" style="font-size:90%;">confidence measure</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F6.2.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="S3.F6.3.2" style="font-size:90%;">Input Fuzzy Sets</span></figcaption>
</figure>
<figure class="ltx_figure" id="S3.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="157" id="S3.F7.g1" src="extracted/2404.13778v1/images/fuzzy_feedback_plot.png" width="240"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F7.2.1.1" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text" id="S3.F7.3.2" style="font-size:90%;">Output fuzzy set (feedback measure)</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">Group decision-making systems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib44" title="">44</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib45" title="">45</a>]</cite> often face challenges in achieving a high level of consensus among participants with diverse preferences <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib46" title="">46</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib47" title="">47</a>]</cite>. In the context of movie recommendations, this task becomes particularly complex due to the subjective nature of movie appreciation.

<br class="ltx_break"/>After determining the most recommended movie for the group, the level of consensus <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib48" title="">48</a>]</cite> with the proposed movie is calculated considering participants’ feedback. We propose a system that utilizes fuzzy logic to better accommodate and interpret the qualitative feedback of participants, thus aiming to enhance consensus and satisfaction with the recommended choice as illustrated in Fig <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.F5" title="Figure 5 ‣ III-D Consensus Model using Fuzzy Logic ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">Fuzzy logic <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib49" title="">49</a>]</cite> is a mathematical framework for dealing with uncertainty and imprecision, extending classical boolean logic by allowing truth values to range between 0 and 1. This approach facilitates the modeling of complex systems by enabling more nuanced decision-making and inference under conditions of ambiguity. By considering participants’ feedback and confidence levels in these agreements, we aim to calculate the level of consensus measure as shown in Fig <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.F5" title="Figure 5 ‣ III-D Consensus Model using Fuzzy Logic ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">5</span></a>, using a Fuzzy inference system.</p>
</div>
<div class="ltx_para" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1">Our fuzzy logic inference system consists of two input fuzzy variables — <span class="ltx_text ltx_font_italic" id="S3.SS4.p3.1.1">Participant’s Agreement</span> and <span class="ltx_text ltx_font_italic" id="S3.SS4.p3.1.2">Confidence Level</span>, and one fuzzy output variable - the <span class="ltx_text ltx_font_italic" id="S3.SS4.p3.1.3">Consensus Measure</span>:</p>
<ol class="ltx_enumerate" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1"><span class="ltx_text ltx_font_italic" id="S3.I2.i1.p1.1.1">Participant’s Agreement</span>: defined by linguistic terms such as ”Highly Agree”, ”Agree”, ”Neutral”, ”Disagree”, and ”Strongly Disagree”, converted into fuzzy values (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.F6.sf1" title="In Figure 6 ‣ III-D Consensus Model using Fuzzy Logic ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">6(a)</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1"><span class="ltx_text ltx_font_italic" id="S3.I2.i2.p1.1.1">Confidence Level</span>: defined by three fuzzy sets including ”Unsure”, ”Neutral”, and ”Sure” (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.F6.sf2" title="In Figure 6 ‣ III-D Consensus Model using Fuzzy Logic ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">6(b)</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I2.i3.p1">
<p class="ltx_p" id="S3.I2.i3.p1.1"><span class="ltx_text ltx_font_italic" id="S3.I2.i3.p1.1.1">Feedback Measure</span>: quantifies the group’s overall consensus, with fuzzy sets representing ”Weak”, ”Moderate”, and ”Strong” levels of feedback measure (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.F7" title="Figure 7 ‣ III-D Consensus Model using Fuzzy Logic ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">7</span></a>).</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS4.p4">
<p class="ltx_p" id="S3.SS4.p4.1">The inference system uses a set of fuzzy rules to determine the consensus measure from the combination of agreement and confidence levels, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.T2" title="TABLE II ‣ III-D Consensus Model using Fuzzy Logic ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">II</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS4.p5">
<p class="ltx_p" id="S3.SS4.p5.1">This process ensures that the recommended movies closely align with the group’s collective preferences and that participants are confident in these recommendations. Considering both the participants’ agreement and confidence levels, our system offers a more sophisticated and accurate means of achieving consensus.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T2.2.1.1" style="font-size:90%;">TABLE II</span>: </span><span class="ltx_text" id="S3.T2.3.2" style="font-size:90%;">Fuzzy rules for the fuzzy inference system</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S3.T2.4" style="width:433.6pt;height:359.9pt;vertical-align:-2.5pt;"><span class="ltx_transformed_inner" style="transform:translate(42.1pt,-34.7pt) scale(1.24088192999956,1.24088192999956) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T2.4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T2.4.1.1.1.1.1">Rule #</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T2.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T2.4.1.1.1.2.1">Agreement</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T2.4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T2.4.1.1.1.3.1">Confidence</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T2.4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T2.4.1.1.1.4.1">Feedback value</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.4.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.1.2.1.1">1</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.2.1.2">Strongly Agree</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.2.1.3">Unsure</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.2.1.4">Moderate</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.1.3.2.1">2</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.3.2.2">Strongly Agree</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.3.2.3">Neutral</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.3.2.4">Strong</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.1.4.3.1">3</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.4.3.2">Strongly Agree</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.4.3.3">Sure</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.4.3.4">Strong</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.1.5.4.1">4</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.5.4.2">Agree</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.5.4.3">Unsure</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.5.4.4">Moderate</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.1.6.5.1">5</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.6.5.2">Agree</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.6.5.3">Neutral</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.6.5.4">Moderate</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.1.7.6.1">6</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.7.6.2">Agree</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.7.6.3">Sure</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.7.6.4">Strong</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.1.8.7.1">7</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.8.7.2">Neutral</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.8.7.3">Unsure</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.8.7.4">Moderate</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.1.9.8.1">8</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.9.8.2">Neutral</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.9.8.3">Neutral</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.9.8.4">Moderate</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.1.10.9.1">9</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.10.9.2">Neutral</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.10.9.3">Sure</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.10.9.4">Strong</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.1.11.10.1">10</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.11.10.2">Disagree</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.11.10.3">Unsure</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.11.10.4">Moderate</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.1.12.11.1">11</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.12.11.2">Disagree</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.12.11.3">Neutral</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.12.11.4">Moderate</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.13.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.1.13.12.1">12</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.13.12.2">Disagree</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.13.12.3">Sure</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.13.12.4">Weak</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.14.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.1.14.13.1">13</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.14.13.2">Strongly Disagree</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.14.13.3">Unsure</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.14.13.4">Moderate</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.15.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.1.15.14.1">14</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.15.14.2">Strongly Disagree</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.15.14.3">Neutral</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.4.1.15.14.4">Weak</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.16.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.4.1.16.15.1">15</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.4.1.16.15.2">Strongly Disagree</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.4.1.16.15.3">Sure</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.4.1.16.15.4">Weak</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S3.SS4.p6">
<p class="ltx_p" id="S3.SS4.p6.5">In our fuzzy logic system, we use trapezoidal membership functions for defining the fuzzy sets for variables ”Participant’s Agreement,” ”Confidence Level,” described in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.F6" title="Figure 6 ‣ III-D Consensus Model using Fuzzy Logic ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">6</span></a> and ”Feedback Measure” presented in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.F7" title="Figure 7 ‣ III-D Consensus Model using Fuzzy Logic ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">7</span></a>. Fuzzy set <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib50" title="">50</a>]</cite> is defined as a set in which each element has a degree of membership that ranges between 0 and 1, indicating the degree to which the element belongs to the set.
The trapezoidal membership function is one of the standard shapes used in fuzzy logic systems due to its flexibility and simplicity. It is defined by four points, creating a shape that resembles a trapezoid. The parameters <math alttext="a" class="ltx_Math" display="inline" id="S3.SS4.p6.1.m1.1"><semantics id="S3.SS4.p6.1.m1.1a"><mi id="S3.SS4.p6.1.m1.1.1" xref="S3.SS4.p6.1.m1.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p6.1.m1.1b"><ci id="S3.SS4.p6.1.m1.1.1.cmml" xref="S3.SS4.p6.1.m1.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p6.1.m1.1c">a</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p6.1.m1.1d">italic_a</annotation></semantics></math> and <math alttext="d" class="ltx_Math" display="inline" id="S3.SS4.p6.2.m2.1"><semantics id="S3.SS4.p6.2.m2.1a"><mi id="S3.SS4.p6.2.m2.1.1" xref="S3.SS4.p6.2.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p6.2.m2.1b"><ci id="S3.SS4.p6.2.m2.1.1.cmml" xref="S3.SS4.p6.2.m2.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p6.2.m2.1c">d</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p6.2.m2.1d">italic_d</annotation></semantics></math> control the trapezoid’s left and right feet or base points, and the parameters <math alttext="b" class="ltx_Math" display="inline" id="S3.SS4.p6.3.m3.1"><semantics id="S3.SS4.p6.3.m3.1a"><mi id="S3.SS4.p6.3.m3.1.1" xref="S3.SS4.p6.3.m3.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p6.3.m3.1b"><ci id="S3.SS4.p6.3.m3.1.1.cmml" xref="S3.SS4.p6.3.m3.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p6.3.m3.1c">b</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p6.3.m3.1d">italic_b</annotation></semantics></math> and <math alttext="c" class="ltx_Math" display="inline" id="S3.SS4.p6.4.m4.1"><semantics id="S3.SS4.p6.4.m4.1a"><mi id="S3.SS4.p6.4.m4.1.1" xref="S3.SS4.p6.4.m4.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p6.4.m4.1b"><ci id="S3.SS4.p6.4.m4.1.1.cmml" xref="S3.SS4.p6.4.m4.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p6.4.m4.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p6.4.m4.1d">italic_c</annotation></semantics></math> control the trapezoid’s left and right shoulders or top points.
The general form of a trapezoidal membership function <math alttext="\mu(x)" class="ltx_Math" display="inline" id="S3.SS4.p6.5.m5.1"><semantics id="S3.SS4.p6.5.m5.1a"><mrow id="S3.SS4.p6.5.m5.1.2" xref="S3.SS4.p6.5.m5.1.2.cmml"><mi id="S3.SS4.p6.5.m5.1.2.2" xref="S3.SS4.p6.5.m5.1.2.2.cmml">μ</mi><mo id="S3.SS4.p6.5.m5.1.2.1" xref="S3.SS4.p6.5.m5.1.2.1.cmml">⁢</mo><mrow id="S3.SS4.p6.5.m5.1.2.3.2" xref="S3.SS4.p6.5.m5.1.2.cmml"><mo id="S3.SS4.p6.5.m5.1.2.3.2.1" stretchy="false" xref="S3.SS4.p6.5.m5.1.2.cmml">(</mo><mi id="S3.SS4.p6.5.m5.1.1" xref="S3.SS4.p6.5.m5.1.1.cmml">x</mi><mo id="S3.SS4.p6.5.m5.1.2.3.2.2" stretchy="false" xref="S3.SS4.p6.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p6.5.m5.1b"><apply id="S3.SS4.p6.5.m5.1.2.cmml" xref="S3.SS4.p6.5.m5.1.2"><times id="S3.SS4.p6.5.m5.1.2.1.cmml" xref="S3.SS4.p6.5.m5.1.2.1"></times><ci id="S3.SS4.p6.5.m5.1.2.2.cmml" xref="S3.SS4.p6.5.m5.1.2.2">𝜇</ci><ci id="S3.SS4.p6.5.m5.1.1.cmml" xref="S3.SS4.p6.5.m5.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p6.5.m5.1c">\mu(x)</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p6.5.m5.1d">italic_μ ( italic_x )</annotation></semantics></math> can be described mathematically as:</p>
</div>
<div class="ltx_para" id="S3.SS4.p7">
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mu(x)=\max\left(\min\left(\frac{x-a}{b-a},1,\frac{d-x}{d-c}\right),0\right)" class="ltx_Math" display="block" id="S3.E4.m1.8"><semantics id="S3.E4.m1.8a"><mrow id="S3.E4.m1.8.8" xref="S3.E4.m1.8.8.cmml"><mrow id="S3.E4.m1.8.8.3" xref="S3.E4.m1.8.8.3.cmml"><mi id="S3.E4.m1.8.8.3.2" xref="S3.E4.m1.8.8.3.2.cmml">μ</mi><mo id="S3.E4.m1.8.8.3.1" xref="S3.E4.m1.8.8.3.1.cmml">⁢</mo><mrow id="S3.E4.m1.8.8.3.3.2" xref="S3.E4.m1.8.8.3.cmml"><mo id="S3.E4.m1.8.8.3.3.2.1" stretchy="false" xref="S3.E4.m1.8.8.3.cmml">(</mo><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">x</mi><mo id="S3.E4.m1.8.8.3.3.2.2" stretchy="false" xref="S3.E4.m1.8.8.3.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.8.8.2" xref="S3.E4.m1.8.8.2.cmml">=</mo><mrow id="S3.E4.m1.8.8.1.1" xref="S3.E4.m1.8.8.1.2.cmml"><mi id="S3.E4.m1.6.6" xref="S3.E4.m1.6.6.cmml">max</mi><mo id="S3.E4.m1.8.8.1.1a" xref="S3.E4.m1.8.8.1.2.cmml">⁡</mo><mrow id="S3.E4.m1.8.8.1.1.1" xref="S3.E4.m1.8.8.1.2.cmml"><mo id="S3.E4.m1.8.8.1.1.1.2" xref="S3.E4.m1.8.8.1.2.cmml">(</mo><mrow id="S3.E4.m1.8.8.1.1.1.1.2" xref="S3.E4.m1.8.8.1.1.1.1.1.cmml"><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">min</mi><mo id="S3.E4.m1.8.8.1.1.1.1.2a" xref="S3.E4.m1.8.8.1.1.1.1.1.cmml">⁡</mo><mrow id="S3.E4.m1.8.8.1.1.1.1.2.1" xref="S3.E4.m1.8.8.1.1.1.1.1.cmml"><mo id="S3.E4.m1.8.8.1.1.1.1.2.1.1" xref="S3.E4.m1.8.8.1.1.1.1.1.cmml">(</mo><mfrac id="S3.E4.m1.3.3" xref="S3.E4.m1.3.3.cmml"><mrow id="S3.E4.m1.3.3.2" xref="S3.E4.m1.3.3.2.cmml"><mi id="S3.E4.m1.3.3.2.2" xref="S3.E4.m1.3.3.2.2.cmml">x</mi><mo id="S3.E4.m1.3.3.2.1" xref="S3.E4.m1.3.3.2.1.cmml">−</mo><mi id="S3.E4.m1.3.3.2.3" xref="S3.E4.m1.3.3.2.3.cmml">a</mi></mrow><mrow id="S3.E4.m1.3.3.3" xref="S3.E4.m1.3.3.3.cmml"><mi id="S3.E4.m1.3.3.3.2" xref="S3.E4.m1.3.3.3.2.cmml">b</mi><mo id="S3.E4.m1.3.3.3.1" xref="S3.E4.m1.3.3.3.1.cmml">−</mo><mi id="S3.E4.m1.3.3.3.3" xref="S3.E4.m1.3.3.3.3.cmml">a</mi></mrow></mfrac><mo id="S3.E4.m1.8.8.1.1.1.1.2.1.2" xref="S3.E4.m1.8.8.1.1.1.1.1.cmml">,</mo><mn id="S3.E4.m1.4.4" xref="S3.E4.m1.4.4.cmml">1</mn><mo id="S3.E4.m1.8.8.1.1.1.1.2.1.3" xref="S3.E4.m1.8.8.1.1.1.1.1.cmml">,</mo><mfrac id="S3.E4.m1.5.5" xref="S3.E4.m1.5.5.cmml"><mrow id="S3.E4.m1.5.5.2" xref="S3.E4.m1.5.5.2.cmml"><mi id="S3.E4.m1.5.5.2.2" xref="S3.E4.m1.5.5.2.2.cmml">d</mi><mo id="S3.E4.m1.5.5.2.1" xref="S3.E4.m1.5.5.2.1.cmml">−</mo><mi id="S3.E4.m1.5.5.2.3" xref="S3.E4.m1.5.5.2.3.cmml">x</mi></mrow><mrow id="S3.E4.m1.5.5.3" xref="S3.E4.m1.5.5.3.cmml"><mi id="S3.E4.m1.5.5.3.2" xref="S3.E4.m1.5.5.3.2.cmml">d</mi><mo id="S3.E4.m1.5.5.3.1" xref="S3.E4.m1.5.5.3.1.cmml">−</mo><mi id="S3.E4.m1.5.5.3.3" xref="S3.E4.m1.5.5.3.3.cmml">c</mi></mrow></mfrac><mo id="S3.E4.m1.8.8.1.1.1.1.2.1.4" xref="S3.E4.m1.8.8.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.8.8.1.1.1.3" xref="S3.E4.m1.8.8.1.2.cmml">,</mo><mn id="S3.E4.m1.7.7" xref="S3.E4.m1.7.7.cmml">0</mn><mo id="S3.E4.m1.8.8.1.1.1.4" xref="S3.E4.m1.8.8.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.8b"><apply id="S3.E4.m1.8.8.cmml" xref="S3.E4.m1.8.8"><eq id="S3.E4.m1.8.8.2.cmml" xref="S3.E4.m1.8.8.2"></eq><apply id="S3.E4.m1.8.8.3.cmml" xref="S3.E4.m1.8.8.3"><times id="S3.E4.m1.8.8.3.1.cmml" xref="S3.E4.m1.8.8.3.1"></times><ci id="S3.E4.m1.8.8.3.2.cmml" xref="S3.E4.m1.8.8.3.2">𝜇</ci><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">𝑥</ci></apply><apply id="S3.E4.m1.8.8.1.2.cmml" xref="S3.E4.m1.8.8.1.1"><max id="S3.E4.m1.6.6.cmml" xref="S3.E4.m1.6.6"></max><apply id="S3.E4.m1.8.8.1.1.1.1.1.cmml" xref="S3.E4.m1.8.8.1.1.1.1.2"><min id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2"></min><apply id="S3.E4.m1.3.3.cmml" xref="S3.E4.m1.3.3"><divide id="S3.E4.m1.3.3.1.cmml" xref="S3.E4.m1.3.3"></divide><apply id="S3.E4.m1.3.3.2.cmml" xref="S3.E4.m1.3.3.2"><minus id="S3.E4.m1.3.3.2.1.cmml" xref="S3.E4.m1.3.3.2.1"></minus><ci id="S3.E4.m1.3.3.2.2.cmml" xref="S3.E4.m1.3.3.2.2">𝑥</ci><ci id="S3.E4.m1.3.3.2.3.cmml" xref="S3.E4.m1.3.3.2.3">𝑎</ci></apply><apply id="S3.E4.m1.3.3.3.cmml" xref="S3.E4.m1.3.3.3"><minus id="S3.E4.m1.3.3.3.1.cmml" xref="S3.E4.m1.3.3.3.1"></minus><ci id="S3.E4.m1.3.3.3.2.cmml" xref="S3.E4.m1.3.3.3.2">𝑏</ci><ci id="S3.E4.m1.3.3.3.3.cmml" xref="S3.E4.m1.3.3.3.3">𝑎</ci></apply></apply><cn id="S3.E4.m1.4.4.cmml" type="integer" xref="S3.E4.m1.4.4">1</cn><apply id="S3.E4.m1.5.5.cmml" xref="S3.E4.m1.5.5"><divide id="S3.E4.m1.5.5.1.cmml" xref="S3.E4.m1.5.5"></divide><apply id="S3.E4.m1.5.5.2.cmml" xref="S3.E4.m1.5.5.2"><minus id="S3.E4.m1.5.5.2.1.cmml" xref="S3.E4.m1.5.5.2.1"></minus><ci id="S3.E4.m1.5.5.2.2.cmml" xref="S3.E4.m1.5.5.2.2">𝑑</ci><ci id="S3.E4.m1.5.5.2.3.cmml" xref="S3.E4.m1.5.5.2.3">𝑥</ci></apply><apply id="S3.E4.m1.5.5.3.cmml" xref="S3.E4.m1.5.5.3"><minus id="S3.E4.m1.5.5.3.1.cmml" xref="S3.E4.m1.5.5.3.1"></minus><ci id="S3.E4.m1.5.5.3.2.cmml" xref="S3.E4.m1.5.5.3.2">𝑑</ci><ci id="S3.E4.m1.5.5.3.3.cmml" xref="S3.E4.m1.5.5.3.3">𝑐</ci></apply></apply></apply><cn id="S3.E4.m1.7.7.cmml" type="integer" xref="S3.E4.m1.7.7">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.8c">\mu(x)=\max\left(\min\left(\frac{x-a}{b-a},1,\frac{d-x}{d-c}\right),0\right)</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.8d">italic_μ ( italic_x ) = roman_max ( roman_min ( divide start_ARG italic_x - italic_a end_ARG start_ARG italic_b - italic_a end_ARG , 1 , divide start_ARG italic_d - italic_x end_ARG start_ARG italic_d - italic_c end_ARG ) , 0 )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS4.p8">
<p class="ltx_p" id="S3.SS4.p8.1">The final consensus measure for the group was evaluated by using the measure of statistical dispersion - Interquartile Range (IQR) (<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.E5" title="In III-D Consensus Model using Fuzzy Logic ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">5</span></a>) and the measure of central tendency - Mean (<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.E6" title="In III-D Consensus Model using Fuzzy Logic ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">6</span></a>) inference across all participants to obtain a crisp value indicating the group’s overall consensus, in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.T3" title="TABLE III ‣ III-D Consensus Model using Fuzzy Logic ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">III</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS4.p9">
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="IQR=Q_{3}-Q_{1}" class="ltx_Math" display="block" id="S3.E5.m1.1"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml"><mrow id="S3.E5.m1.1.1.2" xref="S3.E5.m1.1.1.2.cmml"><mi id="S3.E5.m1.1.1.2.2" xref="S3.E5.m1.1.1.2.2.cmml">I</mi><mo id="S3.E5.m1.1.1.2.1" xref="S3.E5.m1.1.1.2.1.cmml">⁢</mo><mi id="S3.E5.m1.1.1.2.3" xref="S3.E5.m1.1.1.2.3.cmml">Q</mi><mo id="S3.E5.m1.1.1.2.1a" xref="S3.E5.m1.1.1.2.1.cmml">⁢</mo><mi id="S3.E5.m1.1.1.2.4" xref="S3.E5.m1.1.1.2.4.cmml">R</mi></mrow><mo id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.cmml">=</mo><mrow id="S3.E5.m1.1.1.3" xref="S3.E5.m1.1.1.3.cmml"><msub id="S3.E5.m1.1.1.3.2" xref="S3.E5.m1.1.1.3.2.cmml"><mi id="S3.E5.m1.1.1.3.2.2" xref="S3.E5.m1.1.1.3.2.2.cmml">Q</mi><mn id="S3.E5.m1.1.1.3.2.3" xref="S3.E5.m1.1.1.3.2.3.cmml">3</mn></msub><mo id="S3.E5.m1.1.1.3.1" xref="S3.E5.m1.1.1.3.1.cmml">−</mo><msub id="S3.E5.m1.1.1.3.3" xref="S3.E5.m1.1.1.3.3.cmml"><mi id="S3.E5.m1.1.1.3.3.2" xref="S3.E5.m1.1.1.3.3.2.cmml">Q</mi><mn id="S3.E5.m1.1.1.3.3.3" xref="S3.E5.m1.1.1.3.3.3.cmml">1</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1"><eq id="S3.E5.m1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"></eq><apply id="S3.E5.m1.1.1.2.cmml" xref="S3.E5.m1.1.1.2"><times id="S3.E5.m1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.2.1"></times><ci id="S3.E5.m1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.2.2">𝐼</ci><ci id="S3.E5.m1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.2.3">𝑄</ci><ci id="S3.E5.m1.1.1.2.4.cmml" xref="S3.E5.m1.1.1.2.4">𝑅</ci></apply><apply id="S3.E5.m1.1.1.3.cmml" xref="S3.E5.m1.1.1.3"><minus id="S3.E5.m1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.3.1"></minus><apply id="S3.E5.m1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.2.1.cmml" xref="S3.E5.m1.1.1.3.2">subscript</csymbol><ci id="S3.E5.m1.1.1.3.2.2.cmml" xref="S3.E5.m1.1.1.3.2.2">𝑄</ci><cn id="S3.E5.m1.1.1.3.2.3.cmml" type="integer" xref="S3.E5.m1.1.1.3.2.3">3</cn></apply><apply id="S3.E5.m1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.3.1.cmml" xref="S3.E5.m1.1.1.3.3">subscript</csymbol><ci id="S3.E5.m1.1.1.3.3.2.cmml" xref="S3.E5.m1.1.1.3.3.2">𝑄</ci><cn id="S3.E5.m1.1.1.3.3.3.cmml" type="integer" xref="S3.E5.m1.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">IQR=Q_{3}-Q_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.1d">italic_I italic_Q italic_R = italic_Q start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - italic_Q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS4.p9.2">where <math alttext="Q_{1}" class="ltx_Math" display="inline" id="S3.SS4.p9.1.m1.1"><semantics id="S3.SS4.p9.1.m1.1a"><msub id="S3.SS4.p9.1.m1.1.1" xref="S3.SS4.p9.1.m1.1.1.cmml"><mi id="S3.SS4.p9.1.m1.1.1.2" xref="S3.SS4.p9.1.m1.1.1.2.cmml">Q</mi><mn id="S3.SS4.p9.1.m1.1.1.3" xref="S3.SS4.p9.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p9.1.m1.1b"><apply id="S3.SS4.p9.1.m1.1.1.cmml" xref="S3.SS4.p9.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p9.1.m1.1.1.1.cmml" xref="S3.SS4.p9.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p9.1.m1.1.1.2.cmml" xref="S3.SS4.p9.1.m1.1.1.2">𝑄</ci><cn id="S3.SS4.p9.1.m1.1.1.3.cmml" type="integer" xref="S3.SS4.p9.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p9.1.m1.1c">Q_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p9.1.m1.1d">italic_Q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> is the first quartile, <math alttext="Q_{3}" class="ltx_Math" display="inline" id="S3.SS4.p9.2.m2.1"><semantics id="S3.SS4.p9.2.m2.1a"><msub id="S3.SS4.p9.2.m2.1.1" xref="S3.SS4.p9.2.m2.1.1.cmml"><mi id="S3.SS4.p9.2.m2.1.1.2" xref="S3.SS4.p9.2.m2.1.1.2.cmml">Q</mi><mn id="S3.SS4.p9.2.m2.1.1.3" xref="S3.SS4.p9.2.m2.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p9.2.m2.1b"><apply id="S3.SS4.p9.2.m2.1.1.cmml" xref="S3.SS4.p9.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p9.2.m2.1.1.1.cmml" xref="S3.SS4.p9.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.p9.2.m2.1.1.2.cmml" xref="S3.SS4.p9.2.m2.1.1.2">𝑄</ci><cn id="S3.SS4.p9.2.m2.1.1.3.cmml" type="integer" xref="S3.SS4.p9.2.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p9.2.m2.1c">Q_{3}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p9.2.m2.1d">italic_Q start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT</annotation></semantics></math> is the third quartile of distribution.</p>
</div>
<div class="ltx_para" id="S3.SS4.p10">
<table class="ltx_equation ltx_eqn_table" id="S3.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{Mean}=\frac{\sum_{i=1}^{n}x_{i}}{n}" class="ltx_Math" display="block" id="S3.E6.m1.1"><semantics id="S3.E6.m1.1a"><mrow id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml"><mtext id="S3.E6.m1.1.1.2" xref="S3.E6.m1.1.1.2a.cmml">Mean</mtext><mo id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.cmml">=</mo><mfrac id="S3.E6.m1.1.1.3" xref="S3.E6.m1.1.1.3.cmml"><mrow id="S3.E6.m1.1.1.3.2" xref="S3.E6.m1.1.1.3.2.cmml"><msubsup id="S3.E6.m1.1.1.3.2.1" xref="S3.E6.m1.1.1.3.2.1.cmml"><mo id="S3.E6.m1.1.1.3.2.1.2.2" xref="S3.E6.m1.1.1.3.2.1.2.2.cmml">∑</mo><mrow id="S3.E6.m1.1.1.3.2.1.2.3" xref="S3.E6.m1.1.1.3.2.1.2.3.cmml"><mi id="S3.E6.m1.1.1.3.2.1.2.3.2" xref="S3.E6.m1.1.1.3.2.1.2.3.2.cmml">i</mi><mo id="S3.E6.m1.1.1.3.2.1.2.3.1" xref="S3.E6.m1.1.1.3.2.1.2.3.1.cmml">=</mo><mn id="S3.E6.m1.1.1.3.2.1.2.3.3" xref="S3.E6.m1.1.1.3.2.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E6.m1.1.1.3.2.1.3" xref="S3.E6.m1.1.1.3.2.1.3.cmml">n</mi></msubsup><msub id="S3.E6.m1.1.1.3.2.2" xref="S3.E6.m1.1.1.3.2.2.cmml"><mi id="S3.E6.m1.1.1.3.2.2.2" xref="S3.E6.m1.1.1.3.2.2.2.cmml">x</mi><mi id="S3.E6.m1.1.1.3.2.2.3" xref="S3.E6.m1.1.1.3.2.2.3.cmml">i</mi></msub></mrow><mi id="S3.E6.m1.1.1.3.3" xref="S3.E6.m1.1.1.3.3.cmml">n</mi></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1"><eq id="S3.E6.m1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"></eq><ci id="S3.E6.m1.1.1.2a.cmml" xref="S3.E6.m1.1.1.2"><mtext id="S3.E6.m1.1.1.2.cmml" xref="S3.E6.m1.1.1.2">Mean</mtext></ci><apply id="S3.E6.m1.1.1.3.cmml" xref="S3.E6.m1.1.1.3"><divide id="S3.E6.m1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.3"></divide><apply id="S3.E6.m1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.3.2"><apply id="S3.E6.m1.1.1.3.2.1.cmml" xref="S3.E6.m1.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.2.1.1.cmml" xref="S3.E6.m1.1.1.3.2.1">superscript</csymbol><apply id="S3.E6.m1.1.1.3.2.1.2.cmml" xref="S3.E6.m1.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.2.1.2.1.cmml" xref="S3.E6.m1.1.1.3.2.1">subscript</csymbol><sum id="S3.E6.m1.1.1.3.2.1.2.2.cmml" xref="S3.E6.m1.1.1.3.2.1.2.2"></sum><apply id="S3.E6.m1.1.1.3.2.1.2.3.cmml" xref="S3.E6.m1.1.1.3.2.1.2.3"><eq id="S3.E6.m1.1.1.3.2.1.2.3.1.cmml" xref="S3.E6.m1.1.1.3.2.1.2.3.1"></eq><ci id="S3.E6.m1.1.1.3.2.1.2.3.2.cmml" xref="S3.E6.m1.1.1.3.2.1.2.3.2">𝑖</ci><cn id="S3.E6.m1.1.1.3.2.1.2.3.3.cmml" type="integer" xref="S3.E6.m1.1.1.3.2.1.2.3.3">1</cn></apply></apply><ci id="S3.E6.m1.1.1.3.2.1.3.cmml" xref="S3.E6.m1.1.1.3.2.1.3">𝑛</ci></apply><apply id="S3.E6.m1.1.1.3.2.2.cmml" xref="S3.E6.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.2.2.1.cmml" xref="S3.E6.m1.1.1.3.2.2">subscript</csymbol><ci id="S3.E6.m1.1.1.3.2.2.2.cmml" xref="S3.E6.m1.1.1.3.2.2.2">𝑥</ci><ci id="S3.E6.m1.1.1.3.2.2.3.cmml" xref="S3.E6.m1.1.1.3.2.2.3">𝑖</ci></apply></apply><ci id="S3.E6.m1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">\text{Mean}=\frac{\sum_{i=1}^{n}x_{i}}{n}</annotation><annotation encoding="application/x-llamapun" id="S3.E6.m1.1d">Mean = divide start_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_ARG italic_n end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS4.p10.5">where <math alttext="n" class="ltx_Math" display="inline" id="S3.SS4.p10.1.m1.1"><semantics id="S3.SS4.p10.1.m1.1a"><mi id="S3.SS4.p10.1.m1.1.1" xref="S3.SS4.p10.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p10.1.m1.1b"><ci id="S3.SS4.p10.1.m1.1.1.cmml" xref="S3.SS4.p10.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p10.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p10.1.m1.1d">italic_n</annotation></semantics></math> is the total number of participants, <math alttext="i" class="ltx_Math" display="inline" id="S3.SS4.p10.2.m2.1"><semantics id="S3.SS4.p10.2.m2.1a"><mi id="S3.SS4.p10.2.m2.1.1" xref="S3.SS4.p10.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p10.2.m2.1b"><ci id="S3.SS4.p10.2.m2.1.1.cmml" xref="S3.SS4.p10.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p10.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p10.2.m2.1d">italic_i</annotation></semantics></math> - from 1 to <math alttext="n" class="ltx_Math" display="inline" id="S3.SS4.p10.3.m3.1"><semantics id="S3.SS4.p10.3.m3.1a"><mi id="S3.SS4.p10.3.m3.1.1" xref="S3.SS4.p10.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p10.3.m3.1b"><ci id="S3.SS4.p10.3.m3.1.1.cmml" xref="S3.SS4.p10.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p10.3.m3.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p10.3.m3.1d">italic_n</annotation></semantics></math>, <math alttext="x_{i}" class="ltx_Math" display="inline" id="S3.SS4.p10.4.m4.1"><semantics id="S3.SS4.p10.4.m4.1a"><msub id="S3.SS4.p10.4.m4.1.1" xref="S3.SS4.p10.4.m4.1.1.cmml"><mi id="S3.SS4.p10.4.m4.1.1.2" xref="S3.SS4.p10.4.m4.1.1.2.cmml">x</mi><mi id="S3.SS4.p10.4.m4.1.1.3" xref="S3.SS4.p10.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p10.4.m4.1b"><apply id="S3.SS4.p10.4.m4.1.1.cmml" xref="S3.SS4.p10.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS4.p10.4.m4.1.1.1.cmml" xref="S3.SS4.p10.4.m4.1.1">subscript</csymbol><ci id="S3.SS4.p10.4.m4.1.1.2.cmml" xref="S3.SS4.p10.4.m4.1.1.2">𝑥</ci><ci id="S3.SS4.p10.4.m4.1.1.3.cmml" xref="S3.SS4.p10.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p10.4.m4.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p10.4.m4.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> - Feedback Measure of <math alttext="i" class="ltx_Math" display="inline" id="S3.SS4.p10.5.m5.1"><semantics id="S3.SS4.p10.5.m5.1a"><mi id="S3.SS4.p10.5.m5.1.1" xref="S3.SS4.p10.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p10.5.m5.1b"><ci id="S3.SS4.p10.5.m5.1.1.cmml" xref="S3.SS4.p10.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p10.5.m5.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p10.5.m5.1d">italic_i</annotation></semantics></math>-th participant.</p>
</div>
<figure class="ltx_table" id="S3.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T3.2.1.1" style="font-size:90%;">TABLE III</span>: </span><span class="ltx_text" id="S3.T3.3.2" style="font-size:90%;">Consensus level</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T3.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T3.4.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.4.1.1.1">
<table class="ltx_tabular ltx_align_middle" id="S3.T3.4.1.1.1.1">
<tr class="ltx_tr" id="S3.T3.4.1.1.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T3.4.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T3.4.1.1.1.1.1.1.1">Interquartile Range</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.1.1.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T3.4.1.1.1.1.2.1"><span class="ltx_text ltx_font_bold" id="S3.T3.4.1.1.1.1.2.1.1">(IQR)</span></td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T3.4.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T3.4.1.1.2.1">Consensus level</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T3.4.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.4.2.1.1">0.00 - 2.00</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.4.2.1.2">High</td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.4.3.2.1">2.01 - 4.00</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.4.3.2.2">Medium</td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.4.4.3.1">&gt;= 4.01</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T3.4.4.3.2">None</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S3.SS4.p11">
<p class="ltx_p" id="S3.SS4.p11.1">A satisfactory consensus measure is defined by a level of IQR and mean score. When the calculated IQR exceeds the set threshold, or the calculated mean does not reach the corresponding set threshold value, it signals the need to re-evaluate the movie options or the recommendation process. Conversely, otherwise indicates a successful recommendation, which confirms that most of the group is satisfied with the movie’s recommendation.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Experimental Results</span>
</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.4.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.5.2">Performance Evaluation</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We surveyed individuals to examine their emotional reactions to 12 movies shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.T4" title="TABLE IV ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">IV</span></a>, with responses categorized as <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.1">Happy, Anger, Surprise, Sad, and Fear</span>. Respondents were allowed to provide more than one emotional reaction for each question and were asked to list only the movies they had seen and their relevant feelings while watching them (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F8" title="Figure 8 ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">8</span></a>).</p>
</div>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T4.5.1.1" style="font-size:90%;">TABLE IV</span>: </span><span class="ltx_text" id="S4.T4.6.2" style="font-size:90%;">Movie alternatives for the experiments</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T4.3" style="width:433.6pt;height:418.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(32.4pt,-31.3pt) scale(1.17568700982133,1.17568700982133) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T4.3.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.3.3.4.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.3.3.4.1.1">id</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.3.3.4.1.2">Movie</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.3.3.4.1.3">Description text</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.3.3.4.1.4">Soundtrack</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T4.3.3.4.1.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.3.3.4.1.5.1">
<span class="ltx_p" id="S4.T4.3.3.4.1.5.1.1" style="width:56.9pt;">Poster</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.1.1.1.2">1</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.1.1.1.3">Insidious 3</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.1.1.1.4">
<table class="ltx_tabular ltx_align_middle" id="S4.T4.1.1.1.4.1">
<tr class="ltx_tr" id="S4.T4.1.1.1.4.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.1.1.1.4.1.1.1">After trying to connect</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.1.4.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.1.1.1.4.1.2.1">with her dead mother,</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.1.4.1.3">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.1.1.1.4.1.3.1">teenager Quinn Brenner,</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.1.4.1.4">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.1.1.1.4.1.4.1">asks psychic Elise …</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.1.1.1.5">
<table class="ltx_tabular ltx_align_middle" id="S4.T4.1.1.1.5.1">
<tr class="ltx_tr" id="S4.T4.1.1.1.5.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.1.1.1.5.1.1.1">The Insidious</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.1.5.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.1.1.1.5.1.2.1">Plane by</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.1.5.1.3">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.1.1.1.5.1.3.1">Joseph</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.1.5.1.4">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.1.1.1.5.1.4.1">Bishara</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T4.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.1.1.1.1">
<span class="ltx_p" id="S4.T4.1.1.1.1.1.1" style="width:56.9pt;">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" id="S4.T4.1.1.1.1.1.1.1" style="width:86.7pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="71" id="S4.T4.1.1.1.1.1.1.1.g1" src="extracted/2404.13778v1/images/3.jpg" width="240"/>
</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.2.2.2.2">2</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.2.2.2.3">
<table class="ltx_tabular ltx_align_middle" id="S4.T4.2.2.2.3.1">
<tr class="ltx_tr" id="S4.T4.2.2.2.3.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.2.2.2.3.1.1.1">Annabelle:</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.2.2.3.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.2.2.2.3.1.2.1">Creation</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.2.2.2.4">
<table class="ltx_tabular ltx_align_middle" id="S4.T4.2.2.2.4.1">
<tr class="ltx_tr" id="S4.T4.2.2.2.4.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.2.2.2.4.1.1.1">Doll manufacturer Samuel</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.2.2.4.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.2.2.2.4.1.2.1">Mullins is a happy</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.2.2.4.1.3">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.2.2.2.4.1.3.1">family man with his</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.2.2.4.1.4">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.2.2.2.4.1.4.1">wife Esther and</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.2.2.4.1.5">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.2.2.2.4.1.5.1">their daughter…</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.2.2.2.5">
<table class="ltx_tabular ltx_align_middle" id="S4.T4.2.2.2.5.1">
<tr class="ltx_tr" id="S4.T4.2.2.2.5.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.2.2.2.5.1.1.1">Somethin’</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.2.2.5.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.2.2.2.5.1.2.1">Special by</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.2.2.5.1.3">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.2.2.2.5.1.3.1">Colbie</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.2.2.5.1.4">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.2.2.2.5.1.4.1">Caillat</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T4.2.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.2.2.2.1.1">
<span class="ltx_p" id="S4.T4.2.2.2.1.1.1" style="width:56.9pt;">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" id="S4.T4.2.2.2.1.1.1.1" style="width:86.7pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="71" id="S4.T4.2.2.2.1.1.1.1.g1" src="extracted/2404.13778v1/images/4.png" width="240"/>
</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.3.5.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.3.3.5.2.1">…</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.3.3.5.2.2">…</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.3.3.5.2.3">…</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.3.3.5.2.4">…</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T4.3.3.5.2.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.3.3.5.2.5.1">
<span class="ltx_p" id="S4.T4.3.3.5.2.5.1.1" style="width:56.9pt;">…</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.3.3.3.2">12</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.3.3.3.3">
<table class="ltx_tabular ltx_align_middle" id="S4.T4.3.3.3.3.1">
<tr class="ltx_tr" id="S4.T4.3.3.3.3.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.3.3.3.3.1.1.1">Me before</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.3.3.3.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.3.3.3.3.1.2.1">you</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.3.3.3.4">
<table class="ltx_tabular ltx_align_middle" id="S4.T4.3.3.3.4.1">
<tr class="ltx_tr" id="S4.T4.3.3.3.4.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.3.3.3.4.1.1.1">Lou Clark knows</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.3.3.4.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.3.3.3.4.1.2.1">lots of things. She</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.3.3.4.1.3">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.3.3.3.4.1.3.1">knows how many</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.3.3.4.1.4">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.3.3.3.4.1.4.1">footsteps there are</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.3.3.4.1.5">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.3.3.3.4.1.5.1">between the …</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.3.3.3.5">
<table class="ltx_tabular ltx_align_middle" id="S4.T4.3.3.3.5.1">
<tr class="ltx_tr" id="S4.T4.3.3.3.5.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.3.3.3.5.1.1.1">Numb</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.3.3.5.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.3.3.3.5.1.2.1">by Max</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.3.3.5.1.3">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T4.3.3.3.5.1.3.1">Jury</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.3.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.3.3.3.1.1">
<span class="ltx_p" id="S4.T4.3.3.3.1.1.1" style="width:56.9pt;">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" id="S4.T4.3.3.3.1.1.1.1" style="width:86.7pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="71" id="S4.T4.3.3.3.1.1.1.1.g1" src="extracted/2404.13778v1/images/6.jpg" width="240"/>
</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">As a result, we obtained human ratings for emotion distribution for each of the 12 movies, illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F9" title="Figure 9 ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">9</span></a>. This bar chart shows the degree of agreement amongst participants. For instance, looking at the responses for the movie ”Just go with it” (number 5), we can see that most people selected <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.1">Happy</span> and <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.2">Surprise</span>, nobody selected <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.3">Fear</span>, and some selected <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.4">Sad</span> and <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.5">Angry</span>. It can be an example of the best consensus of the group. In contrast, answers for the movie ”Interstellar” (number 7) range widely, involving all five emotions, and four of them are chosen by a significant portion of respondents, making it the worst consensus example.</p>
</div>
<figure class="ltx_figure" id="S4.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="225" id="S4.F8.g1" src="extracted/2404.13778v1/fig/survey_fixed.png" width="180"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F8.2.1.1" style="font-size:90%;">Figure 8</span>: </span><span class="ltx_text" id="S4.F8.3.2" style="font-size:90%;">Survey on Movie Emotion Recognition</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="129" id="S4.F9.g1" src="extracted/2404.13778v1/fig/survey_emotion.jpg" width="299"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F9.2.1.1" style="font-size:90%;">Figure 9</span>: </span><span class="ltx_text" id="S4.F9.3.2" style="font-size:90%;">Survey results’ distribution</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F10" title="Figure 10 ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">10</span></a> represents survey results for two movies achieving the participants’ best and worst consent levels. The fifth movie’s replies are displayed in a histogram under <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F10.sf1" title="In Figure 10 ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">10(a)</span></a>, where the dominating emotions and obvious outliers are evident. The seventh movie’s answers are included under <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F10.sf2" title="In Figure 10 ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">10(b)</span></a>, highlighting the severe discrepancies in response patterns.</p>
</div>
<figure class="ltx_figure" id="S4.F10">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F10.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="130" id="S4.F10.sf1.g1" src="extracted/2404.13778v1/fig/Movie_5.png" width="346"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F10.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S4.F10.sf1.3.2" style="font-size:90%;">The best consent between participants (the movie ”Just go with it”)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F10.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="130" id="S4.F10.sf2.g1" src="extracted/2404.13778v1/fig/Movie_7.png" width="346"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F10.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S4.F10.sf2.3.2" style="font-size:90%;">The worst consent between participants for the movie ”Interstellar”</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F10.2.1.1" style="font-size:90%;">Figure 10</span>: </span><span class="ltx_text" id="S4.F10.3.2" style="font-size:90%;">Consensus between survey participants regarding the prevailing emotions in movies</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">The specific emotion score for a particular movie was calculated as the proportion of selection of this emotion among all choices made for this movie. The results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.T5" title="TABLE V ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">V</span></a>. Using data from three separate channels, the predicted scores for <span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.1">Happiness, Anger, Surprise, Sadness,</span> and <span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.2">Fear</span> are combined using (<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.E1" title="In III-B4 Multimodal Fusion ‣ III-B Emotion Detection ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">1</span></a>). The results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.T8" title="TABLE VIII ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">VIII</span></a>.</p>
</div>
<figure class="ltx_table" id="S4.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T5.2.1.1" style="font-size:90%;">TABLE V</span>: </span><span class="ltx_text" id="S4.T5.3.2" style="font-size:90%;">Emotion scores of survey participants</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T5.4" style="width:433.6pt;height:206.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(48.4pt,-23.0pt) scale(1.28712798190267,1.28712798190267) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T5.4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.4.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T5.4.1.1.1.1">id</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T5.4.1.1.1.2">Movie</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T5.4.1.1.1.3">Emotion scores of survey participants</td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.2.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T5.4.1.2.2.1">1</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T5.4.1.2.2.2">Insidious 3</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T5.4.1.2.2.3">
<table class="ltx_tabular ltx_align_middle" id="S4.T5.4.1.2.2.3.1">
<tr class="ltx_tr" id="S4.T5.4.1.2.2.3.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T5.4.1.2.2.3.1.1.1">{’Happy’: 0.05, ’Angry’: 0.09, ’Surprise’: 0.23,</td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.2.2.3.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T5.4.1.2.2.3.1.2.1">’Sad’: 0.05, ’Fear’: 0.59}</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.3.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T5.4.1.3.3.1">2</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T5.4.1.3.3.2">Annabele: Creation</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T5.4.1.3.3.3">
<table class="ltx_tabular ltx_align_middle" id="S4.T5.4.1.3.3.3.1">
<tr class="ltx_tr" id="S4.T5.4.1.3.3.3.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T5.4.1.3.3.3.1.1.1">{’Happy’: 0.0, ’Angry’: 0.03, ’Surprise’: 0.26,</td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.3.3.3.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T5.4.1.3.3.3.1.2.1">’Sad’: 0.06, ’Fear’: 0.65}</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.4.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T5.4.1.4.4.1">…</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T5.4.1.4.4.2">…</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T5.4.1.4.4.3">…</td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.5.5">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T5.4.1.5.5.1">12</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T5.4.1.5.5.2">Me before you</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T5.4.1.5.5.3">
<table class="ltx_tabular ltx_align_middle" id="S4.T5.4.1.5.5.3.1">
<tr class="ltx_tr" id="S4.T5.4.1.5.5.3.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T5.4.1.5.5.3.1.1.1">{’Happy’: 0.35, ’Angry’: 0.09, ’Surprise’: 0.17,</td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.5.5.3.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T5.4.1.5.5.3.1.2.1">’Sad’: 0.3, ’Fear’: 0.09}</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_figure" id="S4.F11">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F11.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="180" id="S4.F11.sf1.g1" src="extracted/2404.13778v1/fig/user_boxplot.png" width="252"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F11.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S4.F11.sf1.3.2" style="font-size:90%;">Human Ratings</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F11.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="180" id="S4.F11.sf2.g1" src="extracted/2404.13778v1/fig/predicted_boxplot.png" width="252"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F11.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S4.F11.sf2.3.2" style="font-size:90%;">Predicted Ratings</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F11.2.1.1" style="font-size:90%;">Figure 11</span>: </span><span class="ltx_text" id="S4.F11.3.2" style="font-size:90%;">Emotion score distribution: human versus predicted ratings </span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T6">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T6.6.1.1" style="font-size:90%;">TABLE VI</span>: </span><span class="ltx_text" id="S4.T6.7.2" style="font-size:90%;">Input parameters of participants’ favorite movies
</span></figcaption>
<p class="ltx_p ltx_align_center" id="S4.T6.4"><span class="ltx_text ltx_inline-block" id="S4.T6.4.4" style="width:433.6pt;">
<span class="ltx_inline-block ltx_transformed_outer" id="S4.T6.4.4.4.4" style="width:437.0pt;height:516.4pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="S4.T6.4.4.4.4.4"><span class="ltx_text" id="S4.T6.4.4.4.4.4.4">
<span class="ltx_inline-block ltx_transformed_outer" id="S4.T6.4.4.4.4.4.4.4" style="width:433.6pt;height:515.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(42.6pt,-50.6pt) scale(1.24418579960128,1.24418579960128) ;">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T6.4.4.4.4.4.4.4.4">
<span class="ltx_thead">
<span class="ltx_tr" id="S4.T6.4.4.4.4.4.4.4.4.5.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="S4.T6.4.4.4.4.4.4.4.4.5.1.1">id</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T6.4.4.4.4.4.4.4.4.5.1.2">Movie</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T6.4.4.4.4.4.4.4.4.5.1.3">Description text</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T6.4.4.4.4.4.4.4.4.5.1.4">
<span class="ltx_tabular ltx_align_middle" id="S4.T6.4.4.4.4.4.4.4.4.5.1.4.1">
<span class="ltx_tr" id="S4.T6.4.4.4.4.4.4.4.4.5.1.4.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.4.4.4.4.4.4.4.4.5.1.4.1.1.1">Soundtrack</span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T6.4.4.4.4.4.4.4.4.5.1.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T6.4.4.4.4.4.4.4.4.5.1.5.1">
<span class="ltx_p" id="S4.T6.4.4.4.4.4.4.4.4.5.1.5.1.1" style="width:56.9pt;">Poster</span>
</span></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="S4.T6.1.1.1.1.1.1.1.1.1">
<span class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T6.1.1.1.1.1.1.1.1.1.2">1</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T6.1.1.1.1.1.1.1.1.1.3">
<span class="ltx_tabular ltx_align_middle" id="S4.T6.1.1.1.1.1.1.1.1.1.3.1">
<span class="ltx_tr" id="S4.T6.1.1.1.1.1.1.1.1.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.1.1.1.1.1.1.1.1.1.3.1.1.1">The</span></span>
<span class="ltx_tr" id="S4.T6.1.1.1.1.1.1.1.1.1.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.1.1.1.1.1.1.1.1.1.3.1.2.1">Notebook</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T6.1.1.1.1.1.1.1.1.1.4">
<span class="ltx_tabular ltx_align_middle" id="S4.T6.1.1.1.1.1.1.1.1.1.4.1">
<span class="ltx_tr" id="S4.T6.1.1.1.1.1.1.1.1.1.4.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.1.1.1.1.1.1.1.1.1.4.1.1.1">With almost religious</span></span>
<span class="ltx_tr" id="S4.T6.1.1.1.1.1.1.1.1.1.4.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.1.1.1.1.1.1.1.1.1.4.1.2.1">devotion, Duke, a</span></span>
<span class="ltx_tr" id="S4.T6.1.1.1.1.1.1.1.1.1.4.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.1.1.1.1.1.1.1.1.1.4.1.3.1">kind octogenarian…</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T6.1.1.1.1.1.1.1.1.1.5">
<span class="ltx_tabular ltx_align_middle" id="S4.T6.1.1.1.1.1.1.1.1.1.5.1">
<span class="ltx_tr" id="S4.T6.1.1.1.1.1.1.1.1.1.5.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.1.1.1.1.1.1.1.1.1.5.1.1.1">I’ll Be</span></span>
<span class="ltx_tr" id="S4.T6.1.1.1.1.1.1.1.1.1.5.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.1.1.1.1.1.1.1.1.1.5.1.2.1">Seeing You</span></span>
<span class="ltx_tr" id="S4.T6.1.1.1.1.1.1.1.1.1.5.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.1.1.1.1.1.1.1.1.1.5.1.3.1">by Billie</span></span>
<span class="ltx_tr" id="S4.T6.1.1.1.1.1.1.1.1.1.5.1.4">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.1.1.1.1.1.1.1.1.1.5.1.4.1">Holiday</span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T6.1.1.1.1.1.1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T6.1.1.1.1.1.1.1.1.1.1.1">
<span class="ltx_p" id="S4.T6.1.1.1.1.1.1.1.1.1.1.1.1" style="width:56.9pt;">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" id="S4.T6.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:86.7pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="67" id="S4.T6.1.1.1.1.1.1.1.1.1.1.1.1.1.g1" src="extracted/2404.13778v1/images/parp1.png" width="240"/>
</span></span>
</span></span></span>
<span class="ltx_tr" id="S4.T6.2.2.2.2.2.2.2.2.2">
<span class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T6.2.2.2.2.2.2.2.2.2.2">2</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T6.2.2.2.2.2.2.2.2.2.3">Split</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T6.2.2.2.2.2.2.2.2.2.4">
<span class="ltx_tabular ltx_align_middle" id="S4.T6.2.2.2.2.2.2.2.2.2.4.1">
<span class="ltx_tr" id="S4.T6.2.2.2.2.2.2.2.2.2.4.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.2.2.2.2.2.2.2.2.2.4.1.1.1">Though Kevin</span></span>
<span class="ltx_tr" id="S4.T6.2.2.2.2.2.2.2.2.2.4.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.2.2.2.2.2.2.2.2.2.4.1.2.1">(James McAvoy) has</span></span>
<span class="ltx_tr" id="S4.T6.2.2.2.2.2.2.2.2.2.4.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.2.2.2.2.2.2.2.2.2.4.1.3.1">evidenced 23</span></span>
<span class="ltx_tr" id="S4.T6.2.2.2.2.2.2.2.2.2.4.1.4">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.2.2.2.2.2.2.2.2.2.4.1.4.1">personalities to his…</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T6.2.2.2.2.2.2.2.2.2.5">
<span class="ltx_tabular ltx_align_middle" id="S4.T6.2.2.2.2.2.2.2.2.2.5.1">
<span class="ltx_tr" id="S4.T6.2.2.2.2.2.2.2.2.2.5.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.2.2.2.2.2.2.2.2.2.5.1.1.1">In</span></span>
<span class="ltx_tr" id="S4.T6.2.2.2.2.2.2.2.2.2.5.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.2.2.2.2.2.2.2.2.2.5.1.2.1">September</span></span>
<span class="ltx_tr" id="S4.T6.2.2.2.2.2.2.2.2.2.5.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.2.2.2.2.2.2.2.2.2.5.1.3.1">by Slam</span></span>
<span class="ltx_tr" id="S4.T6.2.2.2.2.2.2.2.2.2.5.1.4">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.2.2.2.2.2.2.2.2.2.5.1.4.1">Allen</span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T6.2.2.2.2.2.2.2.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T6.2.2.2.2.2.2.2.2.2.1.1">
<span class="ltx_p" id="S4.T6.2.2.2.2.2.2.2.2.2.1.1.1" style="width:56.9pt;">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" id="S4.T6.2.2.2.2.2.2.2.2.2.1.1.1.1" style="width:86.7pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="67" id="S4.T6.2.2.2.2.2.2.2.2.2.1.1.1.1.g1" src="extracted/2404.13778v1/images/parp2.png" width="240"/>
</span></span>
</span></span></span>
<span class="ltx_tr" id="S4.T6.3.3.3.3.3.3.3.3.3">
<span class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T6.3.3.3.3.3.3.3.3.3.2">3</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T6.3.3.3.3.3.3.3.3.3.3">Oppenheimer</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T6.3.3.3.3.3.3.3.3.3.4">
<span class="ltx_tabular ltx_align_middle" id="S4.T6.3.3.3.3.3.3.3.3.3.4.1">
<span class="ltx_tr" id="S4.T6.3.3.3.3.3.3.3.3.3.4.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.3.3.3.3.3.3.3.3.3.4.1.1.1">A dramatization of</span></span>
<span class="ltx_tr" id="S4.T6.3.3.3.3.3.3.3.3.3.4.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.3.3.3.3.3.3.3.3.3.4.1.2.1">the life story of J.</span></span>
<span class="ltx_tr" id="S4.T6.3.3.3.3.3.3.3.3.3.4.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.3.3.3.3.3.3.3.3.3.4.1.3.1">Robert Oppenheimer,</span></span>
<span class="ltx_tr" id="S4.T6.3.3.3.3.3.3.3.3.3.4.1.4">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.3.3.3.3.3.3.3.3.3.4.1.4.1">the physicist who had…</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T6.3.3.3.3.3.3.3.3.3.5">
<span class="ltx_tabular ltx_align_middle" id="S4.T6.3.3.3.3.3.3.3.3.3.5.1">
<span class="ltx_tr" id="S4.T6.3.3.3.3.3.3.3.3.3.5.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.3.3.3.3.3.3.3.3.3.5.1.1.1">Can You</span></span>
<span class="ltx_tr" id="S4.T6.3.3.3.3.3.3.3.3.3.5.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.3.3.3.3.3.3.3.3.3.5.1.2.1">Hear The</span></span>
<span class="ltx_tr" id="S4.T6.3.3.3.3.3.3.3.3.3.5.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.3.3.3.3.3.3.3.3.3.5.1.3.1">Music by</span></span>
<span class="ltx_tr" id="S4.T6.3.3.3.3.3.3.3.3.3.5.1.4">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.3.3.3.3.3.3.3.3.3.5.1.4.1">Ludwig</span></span>
<span class="ltx_tr" id="S4.T6.3.3.3.3.3.3.3.3.3.5.1.5">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.3.3.3.3.3.3.3.3.3.5.1.5.1">Göransson</span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T6.3.3.3.3.3.3.3.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T6.3.3.3.3.3.3.3.3.3.1.1">
<span class="ltx_p" id="S4.T6.3.3.3.3.3.3.3.3.3.1.1.1" style="width:56.9pt;">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" id="S4.T6.3.3.3.3.3.3.3.3.3.1.1.1.1" style="width:86.7pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="67" id="S4.T6.3.3.3.3.3.3.3.3.3.1.1.1.1.g1" src="extracted/2404.13778v1/images/parp3.png" width="240"/>
</span></span>
</span></span></span>
<span class="ltx_tr" id="S4.T6.4.4.4.4.4.4.4.4.4">
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T6.4.4.4.4.4.4.4.4.4.2">4</span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T6.4.4.4.4.4.4.4.4.4.3">Barbie</span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T6.4.4.4.4.4.4.4.4.4.4">
<span class="ltx_tabular ltx_align_middle" id="S4.T6.4.4.4.4.4.4.4.4.4.4.1">
<span class="ltx_tr" id="S4.T6.4.4.4.4.4.4.4.4.4.4.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.4.4.4.4.4.4.4.4.4.4.1.1.1">Barbie the Doll lives</span></span>
<span class="ltx_tr" id="S4.T6.4.4.4.4.4.4.4.4.4.4.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.4.4.4.4.4.4.4.4.4.4.1.2.1">in bliss in the</span></span>
<span class="ltx_tr" id="S4.T6.4.4.4.4.4.4.4.4.4.4.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.4.4.4.4.4.4.4.4.4.4.1.3.1">matriarchal society of</span></span>
<span class="ltx_tr" id="S4.T6.4.4.4.4.4.4.4.4.4.4.1.4">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.4.4.4.4.4.4.4.4.4.4.1.4.1">Barbieland feeling…</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T6.4.4.4.4.4.4.4.4.4.5">
<span class="ltx_tabular ltx_align_middle" id="S4.T6.4.4.4.4.4.4.4.4.4.5.1">
<span class="ltx_tr" id="S4.T6.4.4.4.4.4.4.4.4.4.5.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.4.4.4.4.4.4.4.4.4.5.1.1.1">Dance the</span></span>
<span class="ltx_tr" id="S4.T6.4.4.4.4.4.4.4.4.4.5.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.4.4.4.4.4.4.4.4.4.5.1.2.1">Night by</span></span>
<span class="ltx_tr" id="S4.T6.4.4.4.4.4.4.4.4.4.5.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T6.4.4.4.4.4.4.4.4.4.5.1.3.1">Dua Lipa</span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S4.T6.4.4.4.4.4.4.4.4.4.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T6.4.4.4.4.4.4.4.4.4.1.1">
<span class="ltx_p" id="S4.T6.4.4.4.4.4.4.4.4.4.1.1.1" style="width:56.9pt;">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" id="S4.T6.4.4.4.4.4.4.4.4.4.1.1.1.1" style="width:86.7pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="67" id="S4.T6.4.4.4.4.4.4.4.4.4.1.1.1.1.g1" src="extracted/2404.13778v1/images/parp4.png" width="240"/>
</span></span>
</span></span></span>
</span>
</span>
</span></span></span></span>
</span></span></span></p>
</figure>
<div class="ltx_para" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.1">Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F11" title="Figure 11 ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">11</span></a> illustrates real (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F11.sf1" title="In Figure 11 ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">11(a)</span></a>) and predicted (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F11.sf1" title="In Figure 11 ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">11(a)</span></a>) emotion score distributions. Analyzing the distribution of the emotion scores for our predicted values (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F11.sf1" title="In Figure 11 ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">11(a)</span></a>), we observed that each emotion has a minimum significance of the first quartile(Q1) of almost 0.05. So, the threshold was selected as 0.05.</p>
</div>
<div class="ltx_para" id="S4.SS1.p6">
<p class="ltx_p" id="S4.SS1.p6.1">We calculated the Pearson correlation coefficient between each emotion channel (text, colors, audio) and real human ratings to evaluate which emotion channel has the most significant impact on human impression. With a correlation of 0.43, the text description emotion channel and human ratings had the highest relationship.</p>
</div>
<div class="ltx_para" id="S4.SS1.p7">
<p class="ltx_p" id="S4.SS1.p7.1">Now, we can compare the prediction power of our approach by finding the similarity index between predicted emotion scores and the scores given by survey participants. Using the aggregated results of predicted scores (see Table <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.T8" title="TABLE VIII ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">VIII</span></a>) and real human scores (Table <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.T5" title="TABLE V ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">V</span></a>), we calculated the Jaccard distance (<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.E2" title="In III-C Recommendation using Jaccard Coefficient ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">2</span></a>) between the real and the predicted values of emotions for each movie (see Table <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.T7" title="TABLE VII ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">VII</span></a>). Afterward, we estimated the average similarity coefficient to be 0.76.</p>
</div>
<figure class="ltx_table" id="S4.T7">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T7.2.1.1" style="font-size:90%;">TABLE VII</span>: </span><span class="ltx_text" id="S4.T7.3.2" style="font-size:90%;">Jaccard Similarity Index between predicted and real emotion distribution for each movie. The mean Jaccard Similarity Index is 0.76</span></figcaption>
<p class="ltx_p ltx_align_center" id="S4.T7.4"><span class="ltx_text ltx_inline-block" id="S4.T7.4.1" style="width:433.6pt;">
<span class="ltx_inline-block ltx_transformed_outer" id="S4.T7.4.1.1" style="width:433.6pt;height:50.5pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="S4.T7.4.1.1.1"><span class="ltx_text" id="S4.T7.4.1.1.1.1">
<span class="ltx_inline-block ltx_transformed_outer" id="S4.T7.4.1.1.1.1.1" style="width:433.6pt;height:49.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-145.8pt,16.6pt) scale(0.597958198190146,0.597958198190146) ;">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T7.4.1.1.1.1.1.1">
<span class="ltx_thead">
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.1.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.1.1.1">Movie</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.1.1.2">Titanic</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.1.1.3">
<span class="ltx_tabular ltx_align_middle" id="S4.T7.4.1.1.1.1.1.1.1.1.3.1">
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.1.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.1.1.3.1.1.1">Bride</span></span>
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.1.1.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.1.1.3.1.2.1">wars</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.1.1.4">Insidious 3</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.1.1.5">
<span class="ltx_tabular ltx_align_middle" id="S4.T7.4.1.1.1.1.1.1.1.1.5.1">
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.1.1.5.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.1.1.5.1.1.1">Annabelle:</span></span>
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.1.1.5.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.1.1.5.1.2.1">Creation</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.1.1.6">
<span class="ltx_tabular ltx_align_middle" id="S4.T7.4.1.1.1.1.1.1.1.1.6.1">
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.1.1.6.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.1.1.6.1.1.1">Just go</span></span>
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.1.1.6.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.1.1.6.1.2.1">with it</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.1.1.7">
<span class="ltx_tabular ltx_align_middle" id="S4.T7.4.1.1.1.1.1.1.1.1.7.1">
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.1.1.7.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.1.1.7.1.1.1">Me before</span></span>
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.1.1.7.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.1.1.7.1.2.1">you</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.1.1.8">Interstellar</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.1.1.9">
<span class="ltx_tabular ltx_align_middle" id="S4.T7.4.1.1.1.1.1.1.1.1.9.1">
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.1.1.9.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.1.1.9.1.1.1">Edge of</span></span>
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.1.1.9.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.1.1.9.1.2.1">tomorrow</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.1.1.10">Passengers</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.1.1.11">
<span class="ltx_tabular ltx_align_middle" id="S4.T7.4.1.1.1.1.1.1.1.1.11.1">
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.1.1.11.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.1.1.11.1.1.1">Don’t</span></span>
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.1.1.11.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.1.1.11.1.2.1">breathe 2</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.1.1.12">
<span class="ltx_tabular ltx_align_middle" id="S4.T7.4.1.1.1.1.1.1.1.1.12.1">
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.1.1.12.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.1.1.12.1.1.1">The</span></span>
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.1.1.12.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.1.1.12.1.2.1">Proposal</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.1.1.13">
<span class="ltx_tabular ltx_align_middle" id="S4.T7.4.1.1.1.1.1.1.1.1.13.1">
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.1.1.13.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.1.1.13.1.1.1">The</span></span>
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.1.1.13.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.1.1.13.1.2.1">holiday</span></span>
</span></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.2.1">
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.2.1.1">
<span class="ltx_tabular ltx_align_middle" id="S4.T7.4.1.1.1.1.1.1.2.1.1.1">
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.2.1.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.2.1.1.1.1.1">Jaccard</span></span>
<span class="ltx_tr" id="S4.T7.4.1.1.1.1.1.1.2.1.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T7.4.1.1.1.1.1.1.2.1.1.1.2.1">Similarity</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.2.1.2">1</span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.2.1.3">0.6</span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.2.1.4">0.4</span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.2.1.5">0.8</span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.2.1.6">0.5</span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.2.1.7">0.8</span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.2.1.8">0.8</span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.2.1.9">1.0</span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.2.1.10">1.0</span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.2.1.11">1.0</span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.2.1.12">0.6</span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.4.1.1.1.1.1.1.2.1.13">0.6</span></span>
</span>
</span>
</span></span></span></span>
</span></span></span></p>
</figure>
<figure class="ltx_table" id="S4.T8">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T8.2.1.1" style="font-size:90%;">TABLE VIII</span>: </span><span class="ltx_text" id="S4.T8.3.2" style="font-size:90%;">Predicted Emotion score of movies</span></figcaption>
<p class="ltx_p ltx_align_center" id="S4.T8.4"><span class="ltx_text ltx_inline-block" id="S4.T8.4.1" style="width:433.6pt;">
<span class="ltx_inline-block ltx_transformed_outer" id="S4.T8.4.1.1" style="width:433.6pt;height:154.9pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="S4.T8.4.1.1.1"><span class="ltx_text" id="S4.T8.4.1.1.1.1">
<span class="ltx_inline-block ltx_transformed_outer" id="S4.T8.4.1.1.1.1.1" style="width:433.6pt;height:153.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-118.0pt,41.9pt) scale(0.647649200310131,0.647649200310131) ;">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T8.4.1.1.1.1.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.1.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.1.1.1">id</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.1.1.2">Movie</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.1.1.3">
<span class="ltx_tabular ltx_align_middle" id="S4.T8.4.1.1.1.1.1.1.1.1.3.1">
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.1.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.1.1.3.1.1.1">Emotion score of movies</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.1.1.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.1.1.3.1.2.1">from description text</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.1.1.4">
<span class="ltx_tabular ltx_align_middle" id="S4.T8.4.1.1.1.1.1.1.1.1.4.1">
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.1.1.4.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.1.1.4.1.1.1">Emotion score of movies</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.1.1.4.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.1.1.4.1.2.1">from soundtrack</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.1.1.5">
<span class="ltx_tabular ltx_align_middle" id="S4.T8.4.1.1.1.1.1.1.1.1.5.1">
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.1.1.5.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.1.1.5.1.1.1">Emotion score of movies</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.1.1.5.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.1.1.5.1.2.1">from poster</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.1.1.6">
<span class="ltx_tabular ltx_align_middle" id="S4.T8.4.1.1.1.1.1.1.1.1.6.1">
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.1.1.6.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.1.1.6.1.1.1">Average emotion score</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.1.1.6.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.1.1.6.1.2.1">of movies</span></span>
</span></span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.2.2">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.2.2.1">1</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.2.2.2">Insidious 3</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.2.2.3">
<span class="ltx_tabular ltx_align_middle" id="S4.T8.4.1.1.1.1.1.1.2.2.3.1">
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.2.2.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.2.2.3.1.1.1">{’Happy’: 0, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.2.2.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.2.2.3.1.2.1">0.12, ’Surprise’: 0.0, ’Sad’:</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.2.2.3.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.2.2.3.1.3.1">0.38, ’Fear’: 0.5}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.2.2.4">
<span class="ltx_tabular ltx_align_middle" id="S4.T8.4.1.1.1.1.1.1.2.2.4.1">
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.2.2.4.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.2.2.4.1.1.1">{’Happy’: 0.0, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.2.2.4.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.2.2.4.1.2.1">0.5, ’Surprise’: 0.0, ’Sad’:</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.2.2.4.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.2.2.4.1.3.1">0.0, ’Fear’: 0.5}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.2.2.5">
<span class="ltx_tabular ltx_align_middle" id="S4.T8.4.1.1.1.1.1.1.2.2.5.1">
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.2.2.5.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.2.2.5.1.1.1">{’Happy’: 0.33, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.2.2.5.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.2.2.5.1.2.1">0.43, ’Surprise’: 0.25,</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.2.2.5.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.2.2.5.1.3.1">’Sad’: 0.38, ’Fear’: 0.33}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.2.2.6">
<span class="ltx_tabular ltx_align_middle" id="S4.T8.4.1.1.1.1.1.1.2.2.6.1">
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.2.2.6.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.2.2.6.1.1.1">{’Happy’: 0.06, ’Angry’: 0.3,</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.2.2.6.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.2.2.6.1.2.1">’Surprise’: 0.04, ’Sad’: 0.25,</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.2.2.6.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.2.2.6.1.3.1">’Fear’: 0.47}</span></span>
</span></span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.3.3">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.3.3.1">2</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.3.3.2">Annabele: Creation</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.3.3.3">
<span class="ltx_tabular ltx_align_middle" id="S4.T8.4.1.1.1.1.1.1.3.3.3.1">
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.3.3.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.3.3.3.1.1.1">{’Happy’: 0.16, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.3.3.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.3.3.3.1.2.1">0.05, ’Surprise’: 0.21, ’Sad’:</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.3.3.3.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.3.3.3.1.3.1">0.16, ’Fear’: 0.42}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.3.3.4">
<span class="ltx_tabular ltx_align_middle" id="S4.T8.4.1.1.1.1.1.1.3.3.4.1">
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.3.3.4.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.3.3.4.1.1.1">{’Happy’: 0, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.3.3.4.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.3.3.4.1.2.1">0.86, ’Surprise’: 0, ’Sad’:</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.3.3.4.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.3.3.4.1.3.1">0, ’Fear’: 0.14}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.3.3.5">
<span class="ltx_tabular ltx_align_middle" id="S4.T8.4.1.1.1.1.1.1.3.3.5.1">
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.3.3.5.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.3.3.5.1.1.1">{’Happy’: 0.5, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.3.3.5.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.3.3.5.1.2.1">0.3, ’Surprise’: 0.3,</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.3.3.5.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.3.3.5.1.3.1">’Sad’: 0.56, ’Fear’: 0.5}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.3.3.6">
<span class="ltx_tabular ltx_align_middle" id="S4.T8.4.1.1.1.1.1.1.3.3.6.1">
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.3.3.6.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.3.3.6.1.1.1">{’Happy’: 0.16, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.3.3.6.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.3.3.6.1.2.1">0.36, ’Surprise’: 0.16, ’Sad’:</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.3.3.6.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.3.3.6.1.3.1">0.17, ’Fear’: 0.34}</span></span>
</span></span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.4.4">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.4.4.1">…</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.4.4.2">…</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.4.4.3">…</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.4.4.4">…</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.4.4.5">…</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.4.4.6">…</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.5.5">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.5.5.1">12</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.5.5.2">Me before you</span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.5.5.3">
<span class="ltx_tabular ltx_align_middle" id="S4.T8.4.1.1.1.1.1.1.5.5.3.1">
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.5.5.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.5.5.3.1.1.1">{’Happy’: 0, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.5.5.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.5.5.3.1.2.1">0.06, ’Surprise’: 0.12,</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.5.5.3.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.5.5.3.1.3.1">’Sad’: 0.62, ’Fear’: 0.19}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.5.5.4">
<span class="ltx_tabular ltx_align_middle" id="S4.T8.4.1.1.1.1.1.1.5.5.4.1">
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.5.5.4.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.5.5.4.1.1.1">{’Happy’: 0.67, ’Angry’: 0.33,</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.5.5.4.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.5.5.4.1.2.1">’Surprise’: 0.0, ’Sad’: 0.0,</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.5.5.4.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.5.5.4.1.3.1">’Fear’: 0.0}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.5.5.5">
<span class="ltx_tabular ltx_align_middle" id="S4.T8.4.1.1.1.1.1.1.5.5.5.1">
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.5.5.5.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.5.5.5.1.1.1">{’Happy’: 0.67, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.5.5.5.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.5.5.5.1.2.1">0.63, ’Surprise’: 0.44,</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.5.5.5.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.5.5.5.1.3.1">’Sad’: 0.56, ’Fear’: 0.67}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T8.4.1.1.1.1.1.1.5.5.6">
<span class="ltx_tabular ltx_align_middle" id="S4.T8.4.1.1.1.1.1.1.5.5.6.1">
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.5.5.6.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.5.5.6.1.1.1">{’Happy’: 0.34, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.5.5.6.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.5.5.6.1.2.1">0.25, ’Surprise’: 0.13, ’Sad’:</span></span>
<span class="ltx_tr" id="S4.T8.4.1.1.1.1.1.1.5.5.6.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T8.4.1.1.1.1.1.1.5.5.6.1.3.1">0.4, ’Fear’: 0.21}</span></span>
</span></span></span>
</span>
</span>
</span></span></span></span>
</span></span></span></p>
</figure>
<figure class="ltx_table" id="S4.T9">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T9.2.1.1" style="font-size:90%;">TABLE IX</span>: </span><span class="ltx_text" id="S4.T9.3.2" style="font-size:90%;">Emotion score of participants’ favorite movies</span></figcaption>
<p class="ltx_p ltx_align_center" id="S4.T9.4"><span class="ltx_text ltx_inline-block" id="S4.T9.4.1" style="width:433.6pt;">
<span class="ltx_inline-block ltx_transformed_outer" id="S4.T9.4.1.1" style="width:433.6pt;height:189pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="S4.T9.4.1.1.1"><span class="ltx_text" id="S4.T9.4.1.1.1.1">
<span class="ltx_inline-block ltx_transformed_outer" id="S4.T9.4.1.1.1.1.1" style="width:433.6pt;height:188pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-104.9pt,45.5pt) scale(0.673844756143594,0.673844756143594) ;">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.1.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.1.1.1">id</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.1.1.2">Movie</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.1.1.3">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.1.1.3.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.1.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.1.1.3.1.1.1">Emotion score of movies</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.1.1.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.1.1.3.1.2.1">from description text</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.1.1.4">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.1.1.4.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.1.1.4.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.1.1.4.1.1.1">Emotion score of movies</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.1.1.4.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.1.1.4.1.2.1">from soundtrack</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.1.1.5">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.1.1.5.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.1.1.5.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.1.1.5.1.1.1">Emotion score of movies</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.1.1.5.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.1.1.5.1.2.1">from poster</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.1.1.6">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.1.1.6.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.1.1.6.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.1.1.6.1.1.1">Average emotion score</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.1.1.6.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.1.1.6.1.2.1">of movies</span></span>
</span></span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.2.2">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.2.2.1">1</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.2.2.2">The Notebook</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.2.2.3">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.2.2.3.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.2.2.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.2.2.3.1.1.1">{’Happy’: 0.45, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.2.2.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.2.2.3.1.2.1">0.05, ’Surprise’: 0.15,</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.2.2.3.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.2.2.3.1.3.1">’Sad’: 0.25, ’Fear’: 0.1}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.2.2.4">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.2.2.4.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.2.2.4.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.2.2.4.1.1.1">{’Happy’: 0.25, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.2.2.4.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.2.2.4.1.2.1">0.0, ’Surprise’: 0, ’Sad’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.2.2.4.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.2.2.4.1.3.1">0.5, ’Fear’: 0.25}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.2.2.5">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.2.2.5.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.2.2.5.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.2.2.5.1.1.1">{’Happy’: 0.56, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.2.2.5.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.2.2.5.1.2.1">0.33, ’Surprise’: 0.71,</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.2.2.5.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.2.2.5.1.3.1">’Sad’: 0.44, ’Fear’: 0.56}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.2.2.6">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.2.2.6.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.2.2.6.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.2.2.6.1.1.1">{’Happy’: 0.4, ’Angry’: 0.08,</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.2.2.6.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.2.2.6.1.2.1">’Surprise’: 0.19, ’Sad’: 0.37,</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.2.2.6.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.2.2.6.1.3.1">’Fear’: 0.23}</span></span>
</span></span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.3.3">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.3.3.1">2</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.3.3.2">Split</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.3.3.3">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.3.3.3.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.3.3.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.3.3.3.1.1.1">{’Happy’: 0.0, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.3.3.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.3.3.3.1.2.1">0.22, ’Surprise’: 0.11, ’Sad’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.3.3.3.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.3.3.3.1.3.1">0.22, ’Fear’: 0.44}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.3.3.4">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.3.3.4.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.3.3.4.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.3.3.4.1.1.1">{’Happy’: 0.5, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.3.3.4.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.3.3.4.1.2.1">0.25, ’Surprise’: 0, ’Sad’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.3.3.4.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.3.3.4.1.3.1">0.25, ’Fear’: 0.0}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.3.3.5">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.3.3.5.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.3.3.5.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.3.3.5.1.1.1">{’Happy’: 0.56, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.3.3.5.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.3.3.5.1.2.1">0.5, ’Surprise’: 0.33, ’Sad’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.3.3.5.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.3.3.5.1.3.1">0.44, ’Fear’: 0.56}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.3.3.6">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.3.3.6.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.3.3.6.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.3.3.6.1.1.1">{’Happy’: 0.26, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.3.3.6.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.3.3.6.1.2.1">0.28, ’Surprise’: 0.11, ’Sad’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.3.3.6.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.3.3.6.1.3.1">0.27, ’Fear’: 0.31}</span></span>
</span></span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.4.4">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.4.4.1">3</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.4.4.2">Oppenheimer</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.4.4.3">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.4.4.3.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.4.4.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.4.4.3.1.1.1">{’Happy’: 0.25, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.4.4.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.4.4.3.1.2.1">0.0, ’Surprise’: 0.25, ’Sad’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.4.4.3.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.4.4.3.1.3.1">0.0, ’Fear’: 0.5}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.4.4.4">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.4.4.4.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.4.4.4.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.4.4.4.1.1.1">{’Happy’: 0.0, ’Angry’: 1.0,</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.4.4.4.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.4.4.4.1.2.1">’Surprise’: 0, ’Sad’: 0.0,</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.4.4.4.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.4.4.4.1.3.1">’Fear’: 0.0}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.4.4.5">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.4.4.5.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.4.4.5.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.4.4.5.1.1.1">{’Happy’: 0.33, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.4.4.5.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.4.4.5.1.2.1">0.43, ’Surprise’: 0.25,</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.4.4.5.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.4.4.5.1.3.1">’Sad’: 0.38, ’Fear’: 0.33}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.4.4.6">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.4.4.6.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.4.4.6.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.4.4.6.1.1.1">{’Happy’: 0.18, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.4.4.6.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.4.4.6.1.2.1">0.41, ’Surprise’: 0.17, ’Sad’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.4.4.6.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.4.4.6.1.3.1">0.06, ’Fear’: 0.31}</span></span>
</span></span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.5.5">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.5.5.1">4</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.5.5.2">Barbie</span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.5.5.3">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.5.5.3.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.5.5.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.5.5.3.1.1.1">{’Happy’: 0.06, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.5.5.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.5.5.3.1.2.1">0.03, ’Surprise’: 0.09,</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.5.5.3.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.5.5.3.1.3.1">’Sad’: 0.41, ’Fear’: 0.41}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.5.5.4">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.5.5.4.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.5.5.4.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.5.5.4.1.1.1">{’Happy’: 0.0, ’Angry’: 0.0,</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.5.5.4.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.5.5.4.1.2.1">’Surprise’: 1, ’Sad’: 0.0,</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.5.5.4.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.5.5.4.1.3.1">’Fear’: 0.0}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.5.5.5">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.5.5.5.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.5.5.5.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.5.5.5.1.1.1">{’Happy’: 0.36, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.5.5.5.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.5.5.5.1.2.1">0.3, ’Surprise’: 0.3, ’Sad’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.5.5.5.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.5.5.5.1.3.1">0.27, ’Fear’: 0.36}</span></span>
</span></span>
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T9.4.1.1.1.1.1.1.5.5.6">
<span class="ltx_tabular ltx_align_middle" id="S4.T9.4.1.1.1.1.1.1.5.5.6.1">
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.5.5.6.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.5.5.6.1.1.1">{’Happy’: 0.09, ’Angry’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.5.5.6.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.5.5.6.1.2.1">0.07, ’Surprise’: 0.43, ’Sad’:</span></span>
<span class="ltx_tr" id="S4.T9.4.1.1.1.1.1.1.5.5.6.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T9.4.1.1.1.1.1.1.5.5.6.1.3.1">0.25, ’Fear’: 0.27}</span></span>
</span></span></span>
</span>
</span>
</span></span></span></span>
</span></span></span></p>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.4.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.5.2">Group Movie Recommendation Example</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Let us show the example of selecting a movie for a group of people using the proposed approach. Given four movie viewers and a pool of 12 movie options (shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.T4" title="TABLE IV ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">IV</span></a>), we aim to ensure satisfaction and provide the best movie recommendation for the participants.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Each participant provided information about their best-loved movie, a reference point for their preferences (see Table <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.T6" title="TABLE VI ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">VI</span></a>). Using the methods described in Section III, we conducted an emotional analysis of three primary sources associated with each movie: the movie poster (picture), the main soundtrack (music), and the movie description (text). Emotional data containing - <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.1">Happiness, Anger, Surprise, Sadness,</span> and <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.2">Fear</span> from the input are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.T8" title="TABLE VIII ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">VIII</span></a>, and emotional data of best-loved movies of each participant is provided in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.T9" title="TABLE IX ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">IX</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">Emotional scores from the three sources were aggregated using (<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.E1" title="In III-B4 Multimodal Fusion ‣ III-B Emotion Detection ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">1</span></a>) for each of the 12 offered movies and four favorite movies. After that, we calculated the Jaccard similarity coefficient between each movie’s emotional composition and each participant’s best-loved movie. This process gives a Jaccard value indicating the similarity between the emotional composition of the 12 movies and the participants’ preferred choices, shown in Tables <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.T8" title="TABLE VIII ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">VIII</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.T9" title="TABLE IX ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">IX</span></a>. The Box plot of predicted emotion scores is shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F11" title="Figure 11 ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">11</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1">The set of movies with the mean Jaccard value equal to the highest coefficient, having the greatest similarity to the participants’ best-loved movies, was identified as the best choice for the group. After that, we filtered them by genre. As a result, we obtained two movies with the highest recommendation scores of 0.8, namely “Titanic” and “Me Before You.” The least recommended movie for this group is “Passengers,” with a score of 0.34.</p>
</div>
<figure class="ltx_table" id="S4.T10">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T10.2.1.1" style="font-size:90%;">TABLE X</span>: </span><span class="ltx_text" id="S4.T10.3.2" style="font-size:90%;">Feedback from Participants on Movie Recommendation</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T10.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T10.4.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="S4.T10.4.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T10.4.1.1.1.1">Participant</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T10.4.1.1.2">
<table class="ltx_tabular ltx_align_middle" id="S4.T10.4.1.1.2.1">
<tr class="ltx_tr" id="S4.T10.4.1.1.2.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T10.4.1.1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T10.4.1.1.2.1.1.1.1">Agreement score</span></td>
</tr>
<tr class="ltx_tr" id="S4.T10.4.1.1.2.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T10.4.1.1.2.1.2.1"><span class="ltx_text ltx_font_bold" id="S4.T10.4.1.1.2.1.2.1.1">(0-10)</span></td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T10.4.1.1.3">
<table class="ltx_tabular ltx_align_middle" id="S4.T10.4.1.1.3.1">
<tr class="ltx_tr" id="S4.T10.4.1.1.3.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T10.4.1.1.3.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T10.4.1.1.3.1.1.1.1">Confidence Level</span></td>
</tr>
<tr class="ltx_tr" id="S4.T10.4.1.1.3.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T10.4.1.1.3.1.2.1"><span class="ltx_text ltx_font_bold" id="S4.T10.4.1.1.3.1.2.1.1">(0-10)</span></td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T10.4.1.1.4">
<table class="ltx_tabular ltx_align_middle" id="S4.T10.4.1.1.4.1">
<tr class="ltx_tr" id="S4.T10.4.1.1.4.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T10.4.1.1.4.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T10.4.1.1.4.1.1.1.1">Feedback</span></td>
</tr>
<tr class="ltx_tr" id="S4.T10.4.1.1.4.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T10.4.1.1.4.1.2.1"><span class="ltx_text ltx_font_bold" id="S4.T10.4.1.1.4.1.2.1.1">value</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T10.4.2.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T10.4.2.1.1">Participant 1</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T10.4.2.1.2">6</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T10.4.2.1.3">4</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T10.4.2.1.4">5.0</td>
</tr>
<tr class="ltx_tr" id="S4.T10.4.3.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T10.4.3.2.1">Participant 2</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T10.4.3.2.2">9</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T10.4.3.2.3">6</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T10.4.3.2.4">8.44</td>
</tr>
<tr class="ltx_tr" id="S4.T10.4.4.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T10.4.4.3.1">Participant 3</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T10.4.4.3.2">5</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T10.4.4.3.3">5</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T10.4.4.3.4">4.99</td>
</tr>
<tr class="ltx_tr" id="S4.T10.4.5.4">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T10.4.5.4.1">Participant 4</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T10.4.5.4.2">3</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T10.4.5.4.3">7</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T10.4.5.4.4">3.75</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_figure" id="S4.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="277" id="S4.F12.g1" src="extracted/2404.13778v1/images/Fuzzy_inference_rule.png" width="299"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F12.9.2.1" style="font-size:90%;">Figure 12</span>: </span><span class="ltx_text" id="S4.F12.2.1" style="font-size:90%;">Visual representation of the inference process. For example, the <span class="ltx_text ltx_font_italic" id="S4.F12.2.1.1">Agreement</span> <span class="ltx_text ltx_font_italic" id="S4.F12.2.1.2">value</span> is 8.8, and the<span class="ltx_text ltx_font_italic" id="S4.F12.2.1.3"> Confidence</span> <span class="ltx_text ltx_font_italic" id="S4.F12.2.1.4">value</span> is 3.4.
As a result, we get a <span class="ltx_text ltx_font_italic" id="S4.F12.2.1.5">Feedback value</span> <math alttext="\approx" class="ltx_Math" display="inline" id="S4.F12.2.1.m1.1"><semantics id="S4.F12.2.1.m1.1b"><mo id="S4.F12.2.1.m1.1.1" xref="S4.F12.2.1.m1.1.1.cmml">≈</mo><annotation-xml encoding="MathML-Content" id="S4.F12.2.1.m1.1c"><approx id="S4.F12.2.1.m1.1.1.cmml" xref="S4.F12.2.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S4.F12.2.1.m1.1d">\approx</annotation><annotation encoding="application/x-llamapun" id="S4.F12.2.1.m1.1e">≈</annotation></semantics></math> 6.94.</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p5">
<p class="ltx_p" id="S4.SS2.p5.1">After determining the most recommended movie for the group, the level of consensus with the proposed movie was calculated using fuzzy logic by using participants’ feedback. Each participant was asked to rate their agreement with the recommended movie and their confidence levels in these agreements on a scale of 0 to 10, shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.T10" title="TABLE X ‣ IV-B Group Movie Recommendation Example ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">X</span></a>.
The feedback value was calculated based on fuzzy logic rules that used both the agreement and confidence scores, providing a nuanced measure of each participant’s satisfaction with the movie recommendation.</p>
</div>
<div class="ltx_para" id="S4.SS2.p6">
<p class="ltx_p" id="S4.SS2.p6.1">For example, let us find the feedback value in the following scenario: the agreement value is 6, and the confidence value is 4. The next step is fuzzification, mapping the crisp numerical values into fuzzy linguistic terms. During fuzzification, each crisp input value is evaluated against these membership functions to determine its degrees of membership in the corresponding fuzzy sets. For instance, an agreement score of 6 has degrees of membership, such as 0.5 in ”Agree” and 0.5 in ”Neutral”. The next important step in a fuzzy inference system is the fuzzy rules. A fuzzy logic system comprises all the rules needed to cover the possible combinations of input linguistic terms. For instance, some rules in our system include:</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">Rule #5: IF Agreement is ’Agree’ AND Confidence is ’Neutral’, THEN Feedback is ’Moderate’</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">Rule #7: IF Agreement is ’Neutral’ AND Confidence is ’Unsure’ THEN Feedback value is ’Moderate’</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S4.SS2.p6.2">Following the defuzzification process, the centroid method obtained a clear answer. As a result of performing aggregation based on fuzzy rules, we get a feedback value equal to 5. The visual representation of the Rules as an example is shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F12" title="Figure 12 ‣ IV-B Group Movie Recommendation Example ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">12</span></a>.
The feedback measure of all Participants was calculated and was shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.T10" title="TABLE X ‣ IV-B Group Movie Recommendation Example ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">X</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS2.p7">
<p class="ltx_p" id="S4.SS2.p7.2">To evaluate the consensus among the group members regarding the recommended movie, we calculated the Interquartile Range (IQR) using Equation <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S3.E5" title="In III-D Consensus Model using Fuzzy Logic ‣ III Methods ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">5</span></a> and the mean of the feedback scores. The calculated IQR for the group’s feedback scores was <math alttext="\approx" class="ltx_Math" display="inline" id="S4.SS2.p7.1.m1.1"><semantics id="S4.SS2.p7.1.m1.1a"><mo id="S4.SS2.p7.1.m1.1.1" xref="S4.SS2.p7.1.m1.1.1.cmml">≈</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.1.m1.1b"><approx id="S4.SS2.p7.1.m1.1.1.cmml" xref="S4.SS2.p7.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.1.m1.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p7.1.m1.1d">≈</annotation></semantics></math>1.18, and the mean was equal to <math alttext="\approx" class="ltx_Math" display="inline" id="S4.SS2.p7.2.m2.1"><semantics id="S4.SS2.p7.2.m2.1a"><mo id="S4.SS2.p7.2.m2.1.1" xref="S4.SS2.p7.2.m2.1.1.cmml">≈</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.2.m2.1b"><approx id="S4.SS2.p7.2.m2.1.1.cmml" xref="S4.SS2.p7.2.m2.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.2.m2.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p7.2.m2.1d">≈</annotation></semantics></math>5.54. These values indicate that the participants’ satisfaction level dispersion is relatively low. At the same time, the mean value is relatively high, suggesting a generally positive consensus about the movie recommendation, shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.T11" title="TABLE XI ‣ IV-B Group Movie Recommendation Example ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">XI</span></a>. The low IQR value and high mean value demonstrated agreement among the group members and approved that the selected movie largely met the collective expectations and preferences of the participants.</p>
</div>
<figure class="ltx_table" id="S4.T11">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T11.2.1.1" style="font-size:90%;">TABLE XI</span>: </span><span class="ltx_text" id="S4.T11.3.2" style="font-size:90%;">Consensus scores of participants</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T11.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T11.4.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="S4.T11.4.1.1.1">
<table class="ltx_tabular ltx_align_middle" id="S4.T11.4.1.1.1.1">
<tr class="ltx_tr" id="S4.T11.4.1.1.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T11.4.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T11.4.1.1.1.1.1.1.1">Interquartile Range</span></td>
</tr>
<tr class="ltx_tr" id="S4.T11.4.1.1.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T11.4.1.1.1.1.2.1"><span class="ltx_text ltx_font_bold" id="S4.T11.4.1.1.1.1.2.1.1">(IQR)</span></td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T11.4.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T11.4.1.1.2.1">Mean</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T11.4.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T11.4.1.1.3.1">Consensus level</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T11.4.2.1">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T11.4.2.1.1">1.18</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T11.4.2.1.2">5.54</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T11.4.2.1.3">High</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS3.4.1.1">IV-C</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS3.5.2">Experiment: Emotion Analysis of top 100 movies</span>
</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">We also conduct experiments to explore the relationship between detected emotions and movie popularity. This research contributes socially by providing insights into the emotional aspects that influence the ratings of movies. Extracting emotions such as <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.1">Happy, Angry, Sad, Surprised,</span> and <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.2">Fear</span> from multiple channels, including posters, music, and movie descriptions, offers a comprehensive understanding of the emotional landscape of movies. Through correlation analysis between these emotional cues and movie ratings using dataset information, this study sheds light on the emotional factors contributing to a movie’s perceived quality.</p>
</div>
<figure class="ltx_figure" id="S4.F13"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="225" id="S4.F13.g1" src="extracted/2404.13778v1/fig/top100_with_t.jpg" width="269"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F13.2.1.1" style="font-size:90%;">Figure 13</span>: </span><span class="ltx_text" id="S4.F13.3.2" style="font-size:90%;">Emotion distribution in 100 most popular movies</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">For this purpose, we use the popular movies chart information from TMDB, which constantly refreshes. We chose and analyzed 100 popular movies. A noteworthy observation is that the data shows a continuous record of emotional variability through the places in rating, with some emotions being more intense than others.
The variations of the emotions depending on the place in the rating are shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F13" title="Figure 13 ‣ IV-C Experiment: Emotion Analysis of top 100 movies ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">13</span></a>. We can see the differences through ratings by monitoring each emotion line separately. We can observe that in the most popular movies, <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.1">Happiness</span> (approximately the first 30 movies) and <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.2">Surprise</span> (around the first ten movies), scores are much lower than the other partitions. At the same time, in the rest of the graph, they fluctuate intensely. Both of them have a mean value of less than 0.2. This implies that positive feelings are not very common in the emotional landscape of popular movies.
In contrast, <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.3">Anger</span> and <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.4">Sadness</span> exhibit hesitation across the entire graph, many peaks, and a mean value higher than positive emotions. This suggests that the emotional terrain of popular movies tends to be dominated by negative emotions.
But despite all of this variety, <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.5">Fear</span> emerges as the most noticeable feeling. The mean scores for <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.6">Fear</span> have been consistently higher throughout the line plot, indicating that <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.7">Horror</span> themes appear to touch deeply with movies.</p>
</div>
<figure class="ltx_figure" id="S4.F14"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="218" id="S4.F14.g1" src="extracted/2404.13778v1/fig/heatmap.jpg" width="269"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F14.2.1.1" style="font-size:90%;">Figure 14</span>: </span><span class="ltx_text" id="S4.F14.3.2" style="font-size:90%;">Genre/emotion correlation in 100 most popular movies</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">We also explore the coherence between the genre of the movie and its emotional aspect, as illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F14" title="Figure 14 ‣ IV-C Experiment: Emotion Analysis of top 100 movies ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">14</span></a>. In this graph, we can also see that positive emotions, such as <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.1">Happiness</span> and <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.2">Surprise</span>, are rarely found in most genres; moreover, in the case of existence, the emotional score is much lower. <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.3">Sadness</span> can be considered an emotion with a neutral score, having a middle point in about half of the genres, and taking high values only in <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.4">Drama, Fantasy, Romance, History,</span> and <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.5">Music</span>. <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.6">Anger</span> strongly meets in <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.7">War</span>, and slightly occurs in almost all genres except <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.8">Music</span> and <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.9">TV movies</span>. <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.10">Fear</span> has a strong correlation with <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.11">Western</span> movies and a weak connection with <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.12">Mystery</span> and <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.13">TV movies</span>. Interesting investigations can be observed in the correlation map, most positive genres like <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.14">Family, Fantasy,</span> and <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.15">Comedy</span> strongly correlate with negative feelings rather than positive ones. The overall Emotion distribution in 100 popular movies with a threshold of 0.2 is presented in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F15" title="Figure 15 ‣ IV-C Experiment: Emotion Analysis of top 100 movies ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">15</span></a></p>
</div>
<figure class="ltx_figure" id="S4.F15"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="165" id="S4.F15.g1" src="extracted/2404.13778v1/fig/piechart.png" width="180"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F15.2.1.1" style="font-size:90%;">Figure 15</span>: </span><span class="ltx_text" id="S4.F15.3.2" style="font-size:90%;">Emotion distribution in 100 most popular movies with threshold 0.2</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F16"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="205" id="S4.F16.g1" src="extracted/2404.13778v1/fig/user_heatmap.png" width="240"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F16.2.1.1" style="font-size:90%;">Figure 16</span>: </span><span class="ltx_text" id="S4.F16.3.2" style="font-size:90%;">Emotion correlation in survey responses</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.5">We also analyzed correlations between emotions selected by humans in our survey (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F16" title="Figure 16 ‣ IV-C Experiment: Emotion Analysis of top 100 movies ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">16</span></a>. As we can see, <span class="ltx_text ltx_font_italic" id="S4.SS3.p4.5.1">Happy</span> and <span class="ltx_text ltx_font_italic" id="S4.SS3.p4.5.2">Surprise</span> (<math alttext="r" class="ltx_Math" display="inline" id="S4.SS3.p4.1.m1.1"><semantics id="S4.SS3.p4.1.m1.1a"><mi id="S4.SS3.p4.1.m1.1.1" xref="S4.SS3.p4.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.m1.1b"><ci id="S4.SS3.p4.1.m1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">r</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p4.1.m1.1d">italic_r</annotation></semantics></math>=0.33),<span class="ltx_text ltx_font_italic" id="S4.SS3.p4.5.3"> Angry</span> and <span class="ltx_text ltx_font_italic" id="S4.SS3.p4.5.4">Fear</span> (<math alttext="r" class="ltx_Math" display="inline" id="S4.SS3.p4.2.m2.1"><semantics id="S4.SS3.p4.2.m2.1a"><mi id="S4.SS3.p4.2.m2.1.1" xref="S4.SS3.p4.2.m2.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.2.m2.1b"><ci id="S4.SS3.p4.2.m2.1.1.cmml" xref="S4.SS3.p4.2.m2.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.2.m2.1c">r</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p4.2.m2.1d">italic_r</annotation></semantics></math>=0.20) emotions are highly correlated. In contrast, there is a negative correlation identified between <span class="ltx_text ltx_font_italic" id="S4.SS3.p4.5.5">Happy</span> and <span class="ltx_text ltx_font_italic" id="S4.SS3.p4.5.6">Fear</span> (<math alttext="r" class="ltx_Math" display="inline" id="S4.SS3.p4.3.m3.1"><semantics id="S4.SS3.p4.3.m3.1a"><mi id="S4.SS3.p4.3.m3.1.1" xref="S4.SS3.p4.3.m3.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.3.m3.1b"><ci id="S4.SS3.p4.3.m3.1.1.cmml" xref="S4.SS3.p4.3.m3.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.3.m3.1c">r</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p4.3.m3.1d">italic_r</annotation></semantics></math>=-0.77), <span class="ltx_text ltx_font_italic" id="S4.SS3.p4.5.7">Happy</span> and <span class="ltx_text ltx_font_italic" id="S4.SS3.p4.5.8">Angry</span> (<math alttext="r" class="ltx_Math" display="inline" id="S4.SS3.p4.4.m4.1"><semantics id="S4.SS3.p4.4.m4.1a"><mi id="S4.SS3.p4.4.m4.1.1" xref="S4.SS3.p4.4.m4.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.4.m4.1b"><ci id="S4.SS3.p4.4.m4.1.1.cmml" xref="S4.SS3.p4.4.m4.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.4.m4.1c">r</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p4.4.m4.1d">italic_r</annotation></semantics></math>=-0.38), <span class="ltx_text ltx_font_italic" id="S4.SS3.p4.5.9">Surprise</span> and <span class="ltx_text ltx_font_italic" id="S4.SS3.p4.5.10">Fear</span> (<math alttext="r" class="ltx_Math" display="inline" id="S4.SS3.p4.5.m5.1"><semantics id="S4.SS3.p4.5.m5.1a"><mi id="S4.SS3.p4.5.m5.1.1" xref="S4.SS3.p4.5.m5.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.5.m5.1b"><ci id="S4.SS3.p4.5.m5.1.1.cmml" xref="S4.SS3.p4.5.m5.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.5.m5.1c">r</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p4.5.m5.1d">italic_r</annotation></semantics></math>=0.43) emotions.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Discussion</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Let us consider how the current study’s findings compare to previous studies. Several recent works investigated the influence of emotion in providing movie recommendations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib12" title="">12</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib19" title="">19</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib51" title="">51</a>]</cite>. Some studies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib52" title="">52</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib53" title="">53</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib54" title="">54</a>]</cite> proposed movie recommendation systems focusing on providing recommendations based on the emotions detected from user’s facial expressions.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Our research findings support previous studies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib55" title="">55</a>]</cite>, which have identified significant variations in emotions portrayed in movies, as illustrated by a boxplot. Similar results were obtained by us and are illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F11" title="Figure 11 ‣ IV-A Performance Evaluation ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">11</span></a>. In addition, our results agree on the prevalence of negative emotions in movies (<span class="ltx_text ltx_font_italic" id="S5.p2.1.1">Fear, Sad, Angry</span>) over positive ones. In contrast, our findings presented in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F15" title="Figure 15 ‣ IV-C Experiment: Emotion Analysis of top 100 movies ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">15</span></a> do not support the recent research focusing on analyzing emotion dynamics in movie dialogues <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib56" title="">56</a>]</cite>, according to which positive word usage in movies is much higher than negative ones.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">Recent research identified a high positive correlation between positive emotions collected through EEG present in movies, as opposed to negative emotions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib5" title="">5</a>]</cite>. Our research findings in Fig.<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#S4.F16" title="Figure 16 ‣ IV-C Experiment: Emotion Analysis of top 100 movies ‣ IV Experimental Results ‣ Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"><span class="ltx_text ltx_ref_tag">16</span></a> support this phenomenon, as the correlation scores among positive emotions are higher than negative ones.</p>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.1">Similar research has been conducted previously but focused on single-user emotion recognition. However, a limited number of works focused on emotion-based recommendations for groups. Most emotion detection methods are still limited to a single channel at the moment <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.13778v1#bib.bib57" title="">57</a>]</cite>. Another advantage of our approach lies in multi-channel emotion detection, with subsequent consensus estimation.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Conclusion</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This paper proposes a novel approach to group movie recommendations using multimodal emotion recognition. We examine emotions from multiple sources, including movie descriptions, soundtracks, and posters, providing a comprehensive understanding of the emotions associated with each movie. Then we employ the Jaccard similarity index to match each participant’s emotional preferences to prospective movie choices, followed by a fuzzy inference technique to evaluate the group consensus. Our findings suggest that emotion analysis is a promising approach to facilitating consensus in group movie recommendation systems.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">The proposed approach has certain limitations, like a relatively straightforward consensus-building process, which may not fully account for the complexities of human interaction and decision-making in group settings.
Another limitation is that emotions are inherently complex and may not always be accurately captured through the analysis of text, music, and images alone.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">In future work, we plan to collect bigger datasets and include additional types of media, such as movie trailers, actor expressions, and viewer reviews, which could provide a more rounded view of movies’ emotional impact. We also plan to integrate traditional recommendation factors like past viewing history with emotional analysis to enhance recommendation accuracy.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
J. Kim, Y. Ha, S. Kang, H. Lim, and M. Cha, “Detecting multiclass emotions from labeled movie scripts,” in <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">2018 IEEE International Conference on Big Data and Smart Computing (BigComp)</em>, 2018, pp. 590–594.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
H. Zeng, X. Wang, A. Wu, Y. Wang, Q. Li, A. Endert, and H. Qu, “Emoco: Visual analysis of emotion coherence in presentation videos,” <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, vol. 26, no. 1, pp. 927–937, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
S. Nemati, R. Rohani, M. E. Basiri, M. Abdar, N. Y. Yen, and V. Makarenkov, “A hybrid latent space data fusion method for multimodal emotion recognition,” <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">IEEE Access</em>, vol. 7, pp. 172 948–172 964, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
J. Yang, J. Li, X. Wang, Y. Ding, and X. Gao, “Stimuli-aware visual emotion analysis,” <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">IEEE Transactions on Image Processing</em>, vol. 30, pp. 7432–7445, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
X. Du, X. Deng, H. Qin, Y. Shu, F. Liu, G. Zhao, Y.-K. Lai, C. Ma, Y.-J. Liu, and H. Wang, “Mmpose: Movie-induced multi-label positive emotion classification through eeg signals,” <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">IEEE Transactions on Affective Computing</em>, vol. 14, no. 4, pp. 2925–2938, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
G. Fernández, W. Lopez, F. Olivera, B. Rienzi, and P. Rodríguez-Bocca, “Let’s go to the cinema! a movie recommender system for ephemeral groups of users,” vol. 18, 09 2014, pp. 1–12.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
M. J. Metzger, A. J. Flanagin, and R. B. Medders, “Social and heuristic approaches to credibility evaluation online,” <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Journal of communication</em>, vol. 60, no. 3, pp. 413–439, 2010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
E. Kadyrgali, A. Yerkin, Y. Torekhan, and P. Shamoi, “Group movie selection using multi-channel emotion recognition,” 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
R. Srivastava, S. Yan, T. Sim, and S. Roy, “Recognizing emotions of characters in movies,” in <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2012, pp. 993–996.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
K. Topal and G. Ozsoyoglu, “Movie review analysis: Emotion analysis of imdb movie reviews,” in <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)</em>, 2016, pp. 1170–1176.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
N. Malandrakis, A. Potamianos, G. Evangelopoulos, and A. Zlatintsi, “A supervised approach to movie emotion tracking,” in <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2011, pp. 2376–2379.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
M. Muszynski, L. Tian, C. Lai, J. D. Moore, T. Kostoulas, P. Lombardo, T. Pun, and G. Chanel, “Recognizing induced emotions of movie audiences from multimodal information,” <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">IEEE Transactions on Affective Computing</em>, vol. 12, no. 1, pp. 36–52, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
M. Kwon, J.-S. Kang, and M. Lee, “Emotion classification in movie clips based on 3d fuzzy gist and eeg signal analysis,” in <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">2013 International Winter Workshop on Brain-Computer Interface (BCI)</em>, 2013, pp. 67–68.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
D. Nie, X.-W. Wang, L.-C. Shi, and B.-L. Lu, “Eeg-based emotion recognition during watching movies,” in <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">2011 5th International IEEE/EMBS Conference on Neural Engineering</em>, 2011, pp. 667–670.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Y. Hou, T. Xiao, S. Zhang, X. Jiang, X. Li, X. Hu, J. Han, L. Guo, L. S. Miller, R. Neupert, and T. Liu, “Predicting movie trailer viewer’s “like/dislike” via learned shot editing patterns,” <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">IEEE Transactions on Affective Computing</em>, vol. 7, no. 1, pp. 29–44, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
S. Kumar, K. De, and P. P. Roy, “Movie recommendation system using sentiment analysis from microblogging data,” <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">IEEE Transactions on Computational Social Systems</em>, vol. 7, no. 4, pp. 915–923, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
L. Quijano-Sanchez, J. Recio-García, and B. Díaz-Agudo, “Happymovie: A facebook application for recommending movies to groups,” 11 2011, pp. 239–244.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
A. Fallahi, A. Bastanfard, A. Amini, and H. Saboohi, “Building movie recommender systems utilizing poster’s visual features: A survey study,” 11 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
A. Breitfuss, K. Errou, A. Kurteva, and A. Fensel, “Representing emotions with knowledge graphs for movie recommendations,” <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Future Generation Computer Systems</em>, vol. 125, 06 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
H. Li, J. Cui, B. Shen, and J. Ma, “An intelligent movie recommendation system through group-level sentiment analysis in microblogs,” <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Neurocomputing</em>, vol. 210, 06 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Y. Mu and Y. Wu, “Multimodal movie recommendation system using deep learning,” <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Mathematics</em>, vol. 11, no. 4, p. 895, Feb. 2023. [Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">http://dx.doi.org/10.3390/math11040895</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
M. Gan and H. Cui, “Exploring user movie interest space: A deep learning based dynamic recommendation model,” <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Expert Systems with Applications</em>, vol. 173, p. 114695, 2021. [Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://www.sciencedirect.com/science/article/pii/S0957417421001366</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
S. Hwang and E. Park, “Movie recommendation systems using actor-based matrix computations in south korea,” <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">IEEE Transactions on Computational Social Systems</em>, vol. 9, no. 5, pp. 1387–1393, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
W. Li, J. Xu, Q. Bao, R. Shen, H. Yuan, and M. Xu, “An adaptive aggregation method based on movie genre for group recommendation,” <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)</em>, pp. 73–78, 2020. [Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://api.semanticscholar.org/CorpusID:229703018</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
S. Choi, S. Ko, and Y. Han, “A movie recommendation algorithm based on genre correlations,” <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Expert Systems with Applications</em>, vol. 39, no. 9, pp. 8079–8085, July 2012, funding Information: This research was supported by the Basic Science Research Program through NRF funded by MEST (2010–0009168) and the IT R&amp; D program of MKE/IITA 2008-S-024–01.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
P. Winoto and T. Y. Tang, “The role of user mood in movie recommendations,” <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Expert Systems with Applications</em>, vol. 37, no. 8, pp. 6086–6092, 2010. [Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://www.sciencedirect.com/science/article/pii/S0957417410001569</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
S. Hwang, H. Ahn, and E. Park, “imovierec: a hybrid movie recommendation method based on a user-image-item model,” <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">International Journal of Machine Learning and Cybernetics</em>, vol. 14, no. 9, p. 3205–3216, Apr. 2023. [Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">http://dx.doi.org/10.1007/s13042-023-01828-3</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
S. Wei, X. Zheng, D. Chen, and C. Chen, “A hybrid approach for movie recommendation via tags and ratings,” <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Electronic Commerce Research and Applications</em>, vol. 18, 02 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Z. Wang, X. Yu, N. Feng, and Z. Wang, “An improved collaborative movie recommendation system using computational intelligence,” <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Journal of Visual Languages &amp; Computing</em>, vol. 25, 10 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
S. Brahim Belhaouari, A. Fareed, S. Hassan, and Z. Halim, “A collaborative filtering recommendation framework utilizing social networks,” <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Machine Learning with Applications</em>, p. 16, 09 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
W.-H. Liao, Y.-T. Lin, C.-Y. Lin, and S.-C. Kuai, “A group recommendation system for movies using deep learning,” in <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">2023 International Conference on Consumer Electronics-Taiwan (ICCE-Taiwan)</em>.   IEEE, 2023, pp. 61–62.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
S. Sahu, R. Kumar, M. M. S. Pathan, J. Shafi, Y. Kumar, and M. F. Ijaz, “Movie popularity and target audience prediction using the content-based recommender system,” <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">IEEE Access</em>, vol. 10, pp. 1–1, 04 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
P. Dwivedi and B. Islam, “An item-based collaborative filtering approach for movie recommendation system,” in <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">2023 10th International Conference on Computing for Sustainable Global Development (INDIACom)</em>, 2023, pp. 153–158.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
A. N. Varma and K. Petluri, “Movie recommender system using critic consensus,” in <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">2021 International Conference on Advances in Computing, Communication, and Control (ICAC3)</em>, 2021, pp. 1–4.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
“Imdb,” 2024-03-10. [Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">http://https://www.imdb.com/</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
M. LLC, “text2emotion 0.0.5 package,” 2020. [Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://pypi.org/project/text2emotion/</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
M. Muratbekova and P. Shamoi, “Color-emotion associations in art: Fuzzy approach,” <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">IEEE Access</em>, vol. 12, pp. 37 937–37 956, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
P. Shamoi, D. Sansyzbayev, and N. Abiley, “Comparative overview of color models for content-based image retrieval,” in <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">2022 International Conference on Smart Information Systems and Technologies (SIST)</em>, 2022, pp. 1–6.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
P. Shamoi, M. Muratbekova, A. Izbassar, A. Inoue, and H. Kawanaka, “Towards a universal understanding of color harmony: Fuzzy approach,” 12 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
A. Ualibekova and P. Shamoi, “Music emotion recognition using k-nearest neighbors algorithm,” 08 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
M. G. de Pinto, M. Polignano, P. Lops, and G. Semeraro, “Emotions understanding model from spoken language using deep neural networks and mel-frequency cepstral coefficients,” in <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">2020 IEEE Conference on Evolving and Adaptive Intelligent Systems (EAIS)</em>, 2020, pp. 1–5.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
S. Livingstone and F. Russo, “The ryerson audio-visual database of emotional speech and song (ravdess): A dynamic, multimodal set of facial and vocal expressions in north american english,” <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">PLOS ONE</em>, vol. 13, p. e0196391, 05 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
M. K. Pichora-Fuller and K. Dupuis, “Toronto emotional speech set (TESS),” 2020. [Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://doi.org/10.5683/SP2/E8H2MF</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
E. Herrera-Viedma, F. Herrera, and F. Chiclana, “A consensus model for multiperson decision making with different preference structures,” <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">IEEE Transactions on Systems, Man, and Cybernetics Part A:Systems and Humans.</em>, vol. 32, pp. 394–402, 5 2002.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
F. Herrera, E. Herrera-Viedma, and J. L. Verdegay, “A model of consensus in group decision making under linguistic assessments,” p. 87, 1996.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
G. D’Aniello, M. Gaeta, S. Tomasiello, and L. Rarità, “A fuzzy consensus approach for group decision making with variable importance of experts,” in <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">2016 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)</em>, 2016, pp. 1693–1700.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
H. Wu, P. Ren, and Z. Xu, “Hesitant fuzzy linguistic consensus model based on trust-recommendation mechanism for hospital expert consultation,” <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">IEEE Transactions on Fuzzy Systems</em>, vol. 27, no. 11, pp. 2227–2241, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
R. Rustum, Kurichiyanil, S. Forrest, C. Sommariva, A. Adeloye, M. Zounemat-Kermani, and Scholz, “Sustainability ranking of desalination plants using mamdani fuzzy logic inference systems,” <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Sustainability</em>, vol. 12, p. 631, 01 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
L.A. Zadeh, “Fuzzy logic,” <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Computer</em>, vol. 21, no. 4, pp. 83–93, 1988.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
L. A. Zadeh, “Fuzzy sets,” <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Information and Control</em>, vol. 8, no. 3, pp. 338–353, 1965.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
H. Cao and J. Kang, “Study on improvement of recommendation algorithm based on emotional polarity classification,” in <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">2020 5th International Conference on Computer and Communication Systems (ICCCS)</em>, 2020, pp. 182–186.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
M. Gupta, S. V. Amirishetty, B. Nithin, and H. Kurakula, “Mind frame music and movie recommendations to uplift the current mood using deep learning,” in <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">2021 International Conference on System, Computation, Automation and Networking (ICSCAN)</em>, 2021, pp. 1–6.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
S. Vidhani, F. Vora, J. Chhadwa, A. Karambelkar, and P. Mamania, “Mood indicator: Music and movie recommendation system using facial emotions,” in <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">2022 5th International Conference on Advances in Science and Technology (ICAST)</em>, 2022, pp. 329–333.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
M. Balfaqih, A. Altwaim, A. A. Almohammedi, and M. H. M. Yusof, “An intelligent movies recommendation system based facial attributes using machine learning,” in <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">2023 3rd International Conference on Emerging Smart Technologies and Applications (eSmarTA)</em>, 2023, pp. 1–6.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
O. Mokryn, D. Bodoff, N. Bader, Y. Albo, and J. Lanir, “Sharing emotions: determining films’ evoked emotional experience from their online reviews,” <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">Information Retrieval Journal</em>, vol. 23, no. 5, p. 475–501, May 2020. [Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">http://dx.doi.org/10.1007/s10791-020-09373-1</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
W. E. Hipson and S. M. Mohammad, “Emotion dynamics in movie dialogues,” <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">PLOS ONE</em>, vol. 16, no. 9, p. e0256153, Sept. 2021. [Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">http://dx.doi.org/10.1371/journal.pone.0256153</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
P. Kozlov, A. Akram, and P. Shamoi, “Fuzzy approach for audio-video emotion recognition in computer games for children,” <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">Procedia Computer Science</em>, vol. 231, pp. 771–778, 2024, 14th International Conference on Emerging Ubiquitous Systems and Pervasive Networks / 13th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (EUSPN/ICTH 2023). [Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://www.sciencedirect.com/science/article/pii/S1877050923021518</span>
</span>
</li>
</ul>
</section>
<figure class="ltx_float biography" id="id1">
<table class="ltx_tabular" id="id1.1">
<tr class="ltx_tr" id="id1.1.1">
<td class="ltx_td" id="id1.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="125" id="id1.1.1.1.g1" src="extracted/2404.13778v1/images/adilet.jpg" width="94"/></td>
<td class="ltx_td" id="id1.1.1.2">
<span class="ltx_inline-block" id="id1.1.1.2.1">
<span class="ltx_p" id="id1.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="id1.1.1.2.1.1.1">Adilet Yerkin</span>  received a B.S. degree in Information systems from the International University of Information Technologies, Almaty, Kazakhstan, in 2022. He is currently pursuing an M.S. degree in Data Science with the School of Information Technology and Engineering, at the Kazakh-British Technical University, Almaty. He participated in conferences, such as KBTU AGSRW 2023, IEEE AITU: Digital Generation 2024 and IITU YDF-2024, which received awards for the best paper. Also, he works as a senior data scientist in a leading state IT company in Kazakhstan. His research interests include machine learning, group decision making systems, fuzzy logic and sets.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure class="ltx_float biography" id="id2">
<table class="ltx_tabular" id="id2.1">
<tr class="ltx_tr" id="id2.1.1">
<td class="ltx_td" id="id2.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="199" id="id2.1.1.1.g1" src="x1.jpeg" width="199"/></td>
<td class="ltx_td" id="id2.1.1.2">
<span class="ltx_inline-block" id="id2.1.1.2.1">
<span class="ltx_p" id="id2.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="id2.1.1.2.1.1.1">Elnara Kadyrgali</span>  received a B.S. degree in Computer System and Software from
the Kazakh-British Technical University, Almaty, Kazakhstan, in 2022. She is currently pursuing an M.S. degree in IT management at the same university. She participated in a number of conferences, such as KBTU AGSRW 2023, IITU YDF-2024 and 2024 IEEE AITU: Digital Generation, which received the best paper award. Her research interests include music emotion recognition and recommendation systems.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure class="ltx_float biography" id="id3">
<table class="ltx_tabular" id="id3.1">
<tr class="ltx_tr" id="id3.1.1">
<td class="ltx_td" id="id3.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="117" id="id3.1.1.1.g1" src="extracted/2404.13778v1/images/yerdauit2.jpg" width="100"/></td>
<td class="ltx_td" id="id3.1.1.2">
<span class="ltx_inline-block" id="id3.1.1.2.1">
<span class="ltx_p" id="id3.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="id3.1.1.2.1.1.1">Yerdauit Torekhan</span>  is currently pursuing the bachelor’s degree in information systems with the School of Information Technology and Engineering at the Kazakh-British Technical University, Almaty, Kazakhstan and works as a data engineer in a leading IT company in Kazakhstan. He participated in a conference, 2024 IEEE AITU: Digital Generation, which received the best paper award. His research interests include machine learning, image processing, emotion detection, and human-friendly systems.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure class="ltx_float biography" id="id4">
<table class="ltx_tabular" id="id4.1">
<tr class="ltx_tr" id="id4.1.1">
<td class="ltx_td" id="id4.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="121" id="id4.1.1.1.g1" src="extracted/2404.13778v1/images/pakita2.png" width="100"/></td>
<td class="ltx_td" id="id4.1.1.2">
<span class="ltx_inline-block" id="id4.1.1.2.1">
<span class="ltx_p" id="id4.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="id4.1.1.2.1.1.1">Pakizar Shamoi</span>  received the B.S. and M.S. degrees in information systems from the Kazakh-British Technical University, Almaty, Kazakhstan in 2011 and 2013, and the Ph.D. degree in engineering from Mie University, Tsu, Japan, in 2019. In her academic journey, she has held various teaching and research positions at Kazakh-British Technical University, where she has been serving as a professor in the School of Information Technology and Engineering since August 2020. She is the author of 1 book and more than 33 scientific publications. Awards for the best paper at conferences were received five times. Her research interests include artificial intelligence and machine learning in general, focusing on fuzzy sets and logic, soft computing, representing and processing colors in computer systems, natural language processing, computational aesthetics, and human-friendly computing and systems. She took part in the organization and worked in the org. committee (as head of the session and responsible for special sessions) of several international conferences - IFSA-SCIS 2017, Otsu, Japan; SCIS-ISIS 2022, Mie, Japan; EUSPN 2023, Almaty, Kazakhstan. She served as a reviewer at several international conferences, including IEEE:
SIST 2023 and 2024, SMC 2022, SCIS-ISIS 2022, SMC 2020, ICIEV-IVPR 2019, ICIEV-IVPR 2018.</span>
</span>
</td>
</tr>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed May  1 12:33:15 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
