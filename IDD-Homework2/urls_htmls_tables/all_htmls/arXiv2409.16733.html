<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning</title>
<!--Generated on Wed Sep 25 08:26:51 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Lossy compression Medical imaging Deep Learning Image segmentation" lang="en" name="keywords"/>
<base href="/html/2409.16733v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S1" title="In The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S2" title="In The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S2.SS1" title="In 2 Methods ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>JPEG2000</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S2.SS2" title="In 2 Methods ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Data</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S2.SS2.SSS1" title="In 2.2 Data ‣ 2 Methods ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.1 </span>LiTS</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S2.SS2.SSS2" title="In 2.2 Data ‣ 2 Methods ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.2 </span>BraTS</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S2.SS2.SSS3" title="In 2.2 Data ‣ 2 Methods ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.3 </span>AMOS</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S2.SS2.SSS4" title="In 2.2 Data ‣ 2 Methods ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.4 </span>BGPD</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S2.SS3" title="In 2 Methods ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Experiments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S2.SS4" title="In 2 Methods ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Metrics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S3" title="In The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S3.SS1" title="In 3 Results ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Compressed images quality</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S3.SS2" title="In 3 Results ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Effect of training on lossy compressed images</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S3.SS3" title="In 3 Results ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Inference models trained on original data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S3.SS4" title="In 3 Results ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Few-shot vs lossy compressed full training</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S4" title="In The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Conclusion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S4.SS1" title="In 4 Conclusion ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Study limitations</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>
National Research Nuclear University MEPhI
</span></span></span><span class="ltx_note ltx_role_institutetext" id="id2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>Skolkovo Institute of Science and Technology, Moscow, Russia
</span></span></span><span class="ltx_note ltx_role_institutetext" id="id3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">institutetext: </span>Artificial Intelligence Research Institute (AIRI), Moscow, Russia
</span></span></span><span class="ltx_note ltx_role_institutetext" id="id4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">institutetext: </span>Independent researcher

<br class="ltx_break"/></span></span></span>
<h1 class="ltx_title ltx_title_document">The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Anvar Kurmukov
</span><span class="ltx_author_notes">44</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Bogdan Zavolovich
</span><span class="ltx_author_notes">11</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Aleksandra Dalechina
</span><span class="ltx_author_notes">11</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vladislav Proskurov
</span><span class="ltx_author_notes">44</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Boris Shirokikh
</span><span class="ltx_author_notes">22 3 3</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.1">Image compression is a critical tool in decreasing the cost of storage and improving the speed of transmission over the internet. While deep learning applications for natural images widely adopts the usage of lossy compression techniques, it is not widespread for 3D medical images. Using three CT datasets (17 tasks) and one MRI dataset (3 tasks) we demonstrate that lossy compression up to <math alttext="\times 20" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mi id="id1.1.m1.1.1.2" xref="id1.1.m1.1.1.2.cmml"></mi><mo id="id1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="id1.1.m1.1.1.1.cmml">×</mo><mn id="id1.1.m1.1.1.3" xref="id1.1.m1.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><times id="id1.1.m1.1.1.1.cmml" xref="id1.1.m1.1.1.1"></times><csymbol cd="latexml" id="id1.1.m1.1.1.2.cmml" xref="id1.1.m1.1.1.2">absent</csymbol><cn id="id1.1.m1.1.1.3.cmml" type="integer" xref="id1.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">\times 20</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">× 20</annotation></semantics></math> times have no negative impact on segmentation quality with deep neural networks (DNN). In addition, we demonstrate the ability of DNN models trained on compressed data to predict on uncompressed data and vice versa with no quality deterioration.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Lossy compression Medical imaging Deep Learning Image segmentation
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The advent of digital technology has revolutionized medical imaging, leading to an exponential increase in the volume of clinical data generated and stored globally. As the digital archives of medical images continue to expand, managing the storage requirements of this quantity of data has become a pressing challenge. Conventional approaches to addressing this problem have included the use of lossless compression techniques, such as JPEG and JPEG2000, which have been employed in an attempt to mitigate the issue of disk space scarcity <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#bib.bib4" title="">4</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">A more memory-efficient approach is to use lossy compression regimes; however, their application is not without consequences. Particularly in the context of deep learning (DL), where data management and loading efficiency are critical to model performance and GPU utilization, authors have demonstrated models’ performance deterioration when trained on heavily compressed images  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#bib.bib1" title="">1</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Recent studies, predominantly in non-medical domains, have investigated the impact of lossy image compression on the performance of neural networks, revealing a nuanced relationship between compression and model efficacy. Research by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#bib.bib11" title="">11</a>]</cite> on object detection with convolutional neural networks (CNNs) and subsequent inquiries into applications ranging from steel surface detection to agricultural image segmentation have illustrated both the potential advantages and drawbacks of incorporating lossy compression into data preprocessing workflows. These discoveries emphasize the importance of balancing data efficiency with the preservation of model accuracy and reliability.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Despite the growing body of research in various domains, the exploration of the impact of image compression on medical imaging applications, particularly in the realm of deep learning-based analysis, remains relatively uncharted. Previous studies have primarily focused on the direct effects of compression on image quality rather than its implications for algorithmic performance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#bib.bib13" title="">13</a>]</cite>. However, emerging evidence from the analysis of histopathological images for metastatic cancer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#bib.bib6" title="">6</a>]</cite> detection and mammogram classification <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#bib.bib10" title="">10</a>]</cite> suggests that, under certain conditions, models trained on compressed images may not only maintain but potentially enhance their performance on compressed data, challenging preconceived notions about the incompatibility of lossy compression and high-stakes medical image analysis.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In our work, we examine how lossy compression affects DL-based segmentation models on 20 segmentation tasks on 3D computed tomography (CT) and magnetic resonance imaging (MRI) data. Our key contributions are three-fold:</p>
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Through systematic experiments on four medical image datasets, we demonstrate that storage memory footprint could be reduced at training time up to 20 times via lossy compression with no negative effect on segmentation quality.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We illustrate that DNN models based on Unet architecture trained on uncompressed data do not deteriorate while inferenced on compressed data, and vice versa.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We show that while trained experts could accurately differentiate between lossy compressed images after a compression rate of 10 times, DL models still preserve their quality for images compressed 20 times.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methods</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>JPEG2000</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">The Joint Photographic Experts Group (JPEG) developed the JPEG 2000 image compression standard, which employs discrete wavelet transformation. This approach ensures the preservation of high image quality during the compression process. A key feature of JPEG 2000 is its support for progressive loading, enabling the stepwise display of image details as more data is received. Furthermore, JPEG 2000 provides the flexibility to either maintain all image details with lossless compression or manage the level of lossy compression according to specific needs. This functionality has been incorporated into the DICOM standard as Supplement 61, substantially enhancing the efficiency of medical image processing and storage. Despite high compression ratio, JPEG 2000 retains critical image details when required, demonstrating an optimal balance between storage efficiency and image quality <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#bib.bib4" title="">4</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Data</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">We used four publicly available datasets, covering two of the most popular 3D medical imaging modalities: computed tomography (CT) and magnetic resonance imaging (MRI), and two types of segmentation tasks: anatomical (15 organs and one anatomical structure) and pathological region segmentation (brain tumors and liver tumors).</p>
</div>
<section class="ltx_subsubsection" id="S2.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.1 </span>LiTS</h4>
<div class="ltx_para" id="S2.SS2.SSS1.p1">
<p class="ltx_p" id="S2.SS2.SSS1.p1.1">We utilized 131 training CT images with liver tumor segmentation masks from the LiTS dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#bib.bib3" title="">3</a>]</cite>. We cropped all images to a given liver mask; the rest of the preprocessing was done in nnunet.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.2 </span>BraTS</h4>
<div class="ltx_para" id="S2.SS2.SSS2.p1">
<p class="ltx_p" id="S2.SS2.SSS2.p1.1">We employed 1251 training skull-stripped MRI cases from the BraTS21 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#bib.bib14" title="">14</a>]</cite>. Each training case includes native (T1) and post-contrast T1-weighted (T1Gd) images, T2-weighted and T2 Fluid Attenuated Inversion Recovery (T2-FLAIR) volumes. The BraTS21 dataset contains annotations of the necrotic tumor core, the peritumoral invaded tissue, and GD-enhancing tumor.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.3 </span>AMOS</h4>
<div class="ltx_para" id="S2.SS2.SSS3.p1">
<p class="ltx_p" id="S2.SS2.SSS3.p1.1">We utilized 300 CT images from the training part of the AMOS dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#bib.bib9" title="">9</a>]</cite>. We performed a multi-class segmentation task, predicting 15 abdominal organ masks: spleen, right kidney, left kidney, gallbladder, esophagus, liver, stomach, aorta, inferior vena cava, pancreas, right adrenal gland, left adrenal gland, duodenum, bladder, and prostate/uterus.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS2.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.4 </span>BGPD</h4>
<div class="ltx_para" id="S2.SS2.SSS4.p1">
<p class="ltx_p" id="S2.SS2.SSS4.p1.1">We employed the Burdenko Glioblastoma Progression Dataset (BGPD) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#bib.bib15" title="">15</a>]</cite>, a systematically curated collection of patients diagnosed with primary glioblastoma. For our experiments, we used 176 CT topometric images, predicting segmentation masks of the brain stem.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Experiments</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">We selected nnU-Net <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#bib.bib8" title="">8</a>]</cite> for our experiments.
It is an open-source framework<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/MIC-DKFZ/nnUNet" title="">https://github.com/MIC-DKFZ/nnUNet</a></span></span></span>, widely adopted as a strong benchmark for medical image segmentation tasks. Low-resolution (lowres) architecture was used for primary results, fullres (default config) for ablation study. In addition, for ablation study on AMOS dataset, we used a Swin Unetr (base) <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/darragh/swinunetr-btcv-base" title="">https://huggingface.co/darragh/swinunetr-btcv-base</a></span></span></span> model pretrained on BTCV dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#bib.bib12" title="">12</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.3">Lowres architecture has been trained for 300 epochs with an initial learning rate of <math alttext="10^{-2}" class="ltx_Math" display="inline" id="S2.SS3.p2.1.m1.1"><semantics id="S2.SS3.p2.1.m1.1a"><msup id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml"><mn id="S2.SS3.p2.1.m1.1.1.2" xref="S2.SS3.p2.1.m1.1.1.2.cmml">10</mn><mrow id="S2.SS3.p2.1.m1.1.1.3" xref="S2.SS3.p2.1.m1.1.1.3.cmml"><mo id="S2.SS3.p2.1.m1.1.1.3a" xref="S2.SS3.p2.1.m1.1.1.3.cmml">−</mo><mn id="S2.SS3.p2.1.m1.1.1.3.2" xref="S2.SS3.p2.1.m1.1.1.3.2.cmml">2</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><apply id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.1.m1.1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1">superscript</csymbol><cn id="S2.SS3.p2.1.m1.1.1.2.cmml" type="integer" xref="S2.SS3.p2.1.m1.1.1.2">10</cn><apply id="S2.SS3.p2.1.m1.1.1.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3"><minus id="S2.SS3.p2.1.m1.1.1.3.1.cmml" xref="S2.SS3.p2.1.m1.1.1.3"></minus><cn id="S2.SS3.p2.1.m1.1.1.3.2.cmml" type="integer" xref="S2.SS3.p2.1.m1.1.1.3.2">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">10^{-2}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.1.m1.1d">10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT</annotation></semantics></math> reduced to <math alttext="10^{-4}" class="ltx_Math" display="inline" id="S2.SS3.p2.2.m2.1"><semantics id="S2.SS3.p2.2.m2.1a"><msup id="S2.SS3.p2.2.m2.1.1" xref="S2.SS3.p2.2.m2.1.1.cmml"><mn id="S2.SS3.p2.2.m2.1.1.2" xref="S2.SS3.p2.2.m2.1.1.2.cmml">10</mn><mrow id="S2.SS3.p2.2.m2.1.1.3" xref="S2.SS3.p2.2.m2.1.1.3.cmml"><mo id="S2.SS3.p2.2.m2.1.1.3a" xref="S2.SS3.p2.2.m2.1.1.3.cmml">−</mo><mn id="S2.SS3.p2.2.m2.1.1.3.2" xref="S2.SS3.p2.2.m2.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.2.m2.1b"><apply id="S2.SS3.p2.2.m2.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.2.m2.1.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1">superscript</csymbol><cn id="S2.SS3.p2.2.m2.1.1.2.cmml" type="integer" xref="S2.SS3.p2.2.m2.1.1.2">10</cn><apply id="S2.SS3.p2.2.m2.1.1.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3"><minus id="S2.SS3.p2.2.m2.1.1.3.1.cmml" xref="S2.SS3.p2.2.m2.1.1.3"></minus><cn id="S2.SS3.p2.2.m2.1.1.3.2.cmml" type="integer" xref="S2.SS3.p2.2.m2.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.2.m2.1c">10^{-4}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.2.m2.1d">10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math> at the last epoch. Each epoch consists of 250 iterations. Stochastic gradient descent with Nesterov momentum (0.99) is used for training. The loss function is a combination of Dice loss and cross-entropy. Poly learning rate scheduler changes the learning rate during training <math alttext="LR_{new}=LR_{initial}(1-epoch/epoch_{max})^{0.9}" class="ltx_Math" display="inline" id="S2.SS3.p2.3.m3.1"><semantics id="S2.SS3.p2.3.m3.1a"><mrow id="S2.SS3.p2.3.m3.1.1" xref="S2.SS3.p2.3.m3.1.1.cmml"><mrow id="S2.SS3.p2.3.m3.1.1.3" xref="S2.SS3.p2.3.m3.1.1.3.cmml"><mi id="S2.SS3.p2.3.m3.1.1.3.2" xref="S2.SS3.p2.3.m3.1.1.3.2.cmml">L</mi><mo id="S2.SS3.p2.3.m3.1.1.3.1" xref="S2.SS3.p2.3.m3.1.1.3.1.cmml">⁢</mo><msub id="S2.SS3.p2.3.m3.1.1.3.3" xref="S2.SS3.p2.3.m3.1.1.3.3.cmml"><mi id="S2.SS3.p2.3.m3.1.1.3.3.2" xref="S2.SS3.p2.3.m3.1.1.3.3.2.cmml">R</mi><mrow id="S2.SS3.p2.3.m3.1.1.3.3.3" xref="S2.SS3.p2.3.m3.1.1.3.3.3.cmml"><mi id="S2.SS3.p2.3.m3.1.1.3.3.3.2" xref="S2.SS3.p2.3.m3.1.1.3.3.3.2.cmml">n</mi><mo id="S2.SS3.p2.3.m3.1.1.3.3.3.1" xref="S2.SS3.p2.3.m3.1.1.3.3.3.1.cmml">⁢</mo><mi id="S2.SS3.p2.3.m3.1.1.3.3.3.3" xref="S2.SS3.p2.3.m3.1.1.3.3.3.3.cmml">e</mi><mo id="S2.SS3.p2.3.m3.1.1.3.3.3.1a" xref="S2.SS3.p2.3.m3.1.1.3.3.3.1.cmml">⁢</mo><mi id="S2.SS3.p2.3.m3.1.1.3.3.3.4" xref="S2.SS3.p2.3.m3.1.1.3.3.3.4.cmml">w</mi></mrow></msub></mrow><mo id="S2.SS3.p2.3.m3.1.1.2" xref="S2.SS3.p2.3.m3.1.1.2.cmml">=</mo><mrow id="S2.SS3.p2.3.m3.1.1.1" xref="S2.SS3.p2.3.m3.1.1.1.cmml"><mi id="S2.SS3.p2.3.m3.1.1.1.3" xref="S2.SS3.p2.3.m3.1.1.1.3.cmml">L</mi><mo id="S2.SS3.p2.3.m3.1.1.1.2" xref="S2.SS3.p2.3.m3.1.1.1.2.cmml">⁢</mo><msub id="S2.SS3.p2.3.m3.1.1.1.4" xref="S2.SS3.p2.3.m3.1.1.1.4.cmml"><mi id="S2.SS3.p2.3.m3.1.1.1.4.2" xref="S2.SS3.p2.3.m3.1.1.1.4.2.cmml">R</mi><mrow id="S2.SS3.p2.3.m3.1.1.1.4.3" xref="S2.SS3.p2.3.m3.1.1.1.4.3.cmml"><mi id="S2.SS3.p2.3.m3.1.1.1.4.3.2" xref="S2.SS3.p2.3.m3.1.1.1.4.3.2.cmml">i</mi><mo id="S2.SS3.p2.3.m3.1.1.1.4.3.1" xref="S2.SS3.p2.3.m3.1.1.1.4.3.1.cmml">⁢</mo><mi id="S2.SS3.p2.3.m3.1.1.1.4.3.3" xref="S2.SS3.p2.3.m3.1.1.1.4.3.3.cmml">n</mi><mo id="S2.SS3.p2.3.m3.1.1.1.4.3.1a" xref="S2.SS3.p2.3.m3.1.1.1.4.3.1.cmml">⁢</mo><mi id="S2.SS3.p2.3.m3.1.1.1.4.3.4" xref="S2.SS3.p2.3.m3.1.1.1.4.3.4.cmml">i</mi><mo id="S2.SS3.p2.3.m3.1.1.1.4.3.1b" xref="S2.SS3.p2.3.m3.1.1.1.4.3.1.cmml">⁢</mo><mi id="S2.SS3.p2.3.m3.1.1.1.4.3.5" xref="S2.SS3.p2.3.m3.1.1.1.4.3.5.cmml">t</mi><mo id="S2.SS3.p2.3.m3.1.1.1.4.3.1c" xref="S2.SS3.p2.3.m3.1.1.1.4.3.1.cmml">⁢</mo><mi id="S2.SS3.p2.3.m3.1.1.1.4.3.6" xref="S2.SS3.p2.3.m3.1.1.1.4.3.6.cmml">i</mi><mo id="S2.SS3.p2.3.m3.1.1.1.4.3.1d" xref="S2.SS3.p2.3.m3.1.1.1.4.3.1.cmml">⁢</mo><mi id="S2.SS3.p2.3.m3.1.1.1.4.3.7" xref="S2.SS3.p2.3.m3.1.1.1.4.3.7.cmml">a</mi><mo id="S2.SS3.p2.3.m3.1.1.1.4.3.1e" xref="S2.SS3.p2.3.m3.1.1.1.4.3.1.cmml">⁢</mo><mi id="S2.SS3.p2.3.m3.1.1.1.4.3.8" xref="S2.SS3.p2.3.m3.1.1.1.4.3.8.cmml">l</mi></mrow></msub><mo id="S2.SS3.p2.3.m3.1.1.1.2a" xref="S2.SS3.p2.3.m3.1.1.1.2.cmml">⁢</mo><msup id="S2.SS3.p2.3.m3.1.1.1.1" xref="S2.SS3.p2.3.m3.1.1.1.1.cmml"><mrow id="S2.SS3.p2.3.m3.1.1.1.1.1.1" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.cmml"><mo id="S2.SS3.p2.3.m3.1.1.1.1.1.1.2" stretchy="false" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.cmml"><mn id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.2" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.1" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.1.cmml">−</mo><mrow id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.cmml"><mrow id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.cmml"><mrow id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.cmml"><mi id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.2" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.2.cmml">e</mi><mo id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.1" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.1.cmml">⁢</mo><mi id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.3" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.3.cmml">p</mi><mo id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.1a" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.1.cmml">⁢</mo><mi id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.4" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.4.cmml">o</mi><mo id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.1b" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.1.cmml">⁢</mo><mi id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.5" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.5.cmml">c</mi><mo id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.1c" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.1.cmml">⁢</mo><mi id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.6" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.6.cmml">h</mi></mrow><mo id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.1" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.1.cmml">/</mo><mi id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.3" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.3.cmml">e</mi></mrow><mo id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.1" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.3" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.3.cmml">p</mi><mo id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.1a" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.4" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.4.cmml">o</mi><mo id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.1b" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.5" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.5.cmml">c</mi><mo id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.1c" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><msub id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.cmml"><mi id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.2" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.2.cmml">h</mi><mrow id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.cmml"><mi id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.2" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.2.cmml">m</mi><mo id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.1" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.1.cmml">⁢</mo><mi id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.3" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.3.cmml">a</mi><mo id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.1a" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.1.cmml">⁢</mo><mi id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.4" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.4.cmml">x</mi></mrow></msub></mrow></mrow><mo id="S2.SS3.p2.3.m3.1.1.1.1.1.1.3" stretchy="false" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.cmml">)</mo></mrow><mn id="S2.SS3.p2.3.m3.1.1.1.1.3" xref="S2.SS3.p2.3.m3.1.1.1.1.3.cmml">0.9</mn></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.3.m3.1b"><apply id="S2.SS3.p2.3.m3.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1"><eq id="S2.SS3.p2.3.m3.1.1.2.cmml" xref="S2.SS3.p2.3.m3.1.1.2"></eq><apply id="S2.SS3.p2.3.m3.1.1.3.cmml" xref="S2.SS3.p2.3.m3.1.1.3"><times id="S2.SS3.p2.3.m3.1.1.3.1.cmml" xref="S2.SS3.p2.3.m3.1.1.3.1"></times><ci id="S2.SS3.p2.3.m3.1.1.3.2.cmml" xref="S2.SS3.p2.3.m3.1.1.3.2">𝐿</ci><apply id="S2.SS3.p2.3.m3.1.1.3.3.cmml" xref="S2.SS3.p2.3.m3.1.1.3.3"><csymbol cd="ambiguous" id="S2.SS3.p2.3.m3.1.1.3.3.1.cmml" xref="S2.SS3.p2.3.m3.1.1.3.3">subscript</csymbol><ci id="S2.SS3.p2.3.m3.1.1.3.3.2.cmml" xref="S2.SS3.p2.3.m3.1.1.3.3.2">𝑅</ci><apply id="S2.SS3.p2.3.m3.1.1.3.3.3.cmml" xref="S2.SS3.p2.3.m3.1.1.3.3.3"><times id="S2.SS3.p2.3.m3.1.1.3.3.3.1.cmml" xref="S2.SS3.p2.3.m3.1.1.3.3.3.1"></times><ci id="S2.SS3.p2.3.m3.1.1.3.3.3.2.cmml" xref="S2.SS3.p2.3.m3.1.1.3.3.3.2">𝑛</ci><ci id="S2.SS3.p2.3.m3.1.1.3.3.3.3.cmml" xref="S2.SS3.p2.3.m3.1.1.3.3.3.3">𝑒</ci><ci id="S2.SS3.p2.3.m3.1.1.3.3.3.4.cmml" xref="S2.SS3.p2.3.m3.1.1.3.3.3.4">𝑤</ci></apply></apply></apply><apply id="S2.SS3.p2.3.m3.1.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1.1"><times id="S2.SS3.p2.3.m3.1.1.1.2.cmml" xref="S2.SS3.p2.3.m3.1.1.1.2"></times><ci id="S2.SS3.p2.3.m3.1.1.1.3.cmml" xref="S2.SS3.p2.3.m3.1.1.1.3">𝐿</ci><apply id="S2.SS3.p2.3.m3.1.1.1.4.cmml" xref="S2.SS3.p2.3.m3.1.1.1.4"><csymbol cd="ambiguous" id="S2.SS3.p2.3.m3.1.1.1.4.1.cmml" xref="S2.SS3.p2.3.m3.1.1.1.4">subscript</csymbol><ci id="S2.SS3.p2.3.m3.1.1.1.4.2.cmml" xref="S2.SS3.p2.3.m3.1.1.1.4.2">𝑅</ci><apply id="S2.SS3.p2.3.m3.1.1.1.4.3.cmml" xref="S2.SS3.p2.3.m3.1.1.1.4.3"><times id="S2.SS3.p2.3.m3.1.1.1.4.3.1.cmml" xref="S2.SS3.p2.3.m3.1.1.1.4.3.1"></times><ci id="S2.SS3.p2.3.m3.1.1.1.4.3.2.cmml" xref="S2.SS3.p2.3.m3.1.1.1.4.3.2">𝑖</ci><ci id="S2.SS3.p2.3.m3.1.1.1.4.3.3.cmml" xref="S2.SS3.p2.3.m3.1.1.1.4.3.3">𝑛</ci><ci id="S2.SS3.p2.3.m3.1.1.1.4.3.4.cmml" xref="S2.SS3.p2.3.m3.1.1.1.4.3.4">𝑖</ci><ci id="S2.SS3.p2.3.m3.1.1.1.4.3.5.cmml" xref="S2.SS3.p2.3.m3.1.1.1.4.3.5">𝑡</ci><ci id="S2.SS3.p2.3.m3.1.1.1.4.3.6.cmml" xref="S2.SS3.p2.3.m3.1.1.1.4.3.6">𝑖</ci><ci id="S2.SS3.p2.3.m3.1.1.1.4.3.7.cmml" xref="S2.SS3.p2.3.m3.1.1.1.4.3.7">𝑎</ci><ci id="S2.SS3.p2.3.m3.1.1.1.4.3.8.cmml" xref="S2.SS3.p2.3.m3.1.1.1.4.3.8">𝑙</ci></apply></apply><apply id="S2.SS3.p2.3.m3.1.1.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.3.m3.1.1.1.1.2.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1">superscript</csymbol><apply id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1"><minus id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.1"></minus><cn id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.2.cmml" type="integer" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.2">1</cn><apply id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3"><times id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.1.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.1"></times><apply id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2"><divide id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.1.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.1"></divide><apply id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2"><times id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.1.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.1"></times><ci id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.2.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.2">𝑒</ci><ci id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.3.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.3">𝑝</ci><ci id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.4.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.4">𝑜</ci><ci id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.5.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.5">𝑐</ci><ci id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.6.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.2.6">ℎ</ci></apply><ci id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.3.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.2.3">𝑒</ci></apply><ci id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.3.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.3">𝑝</ci><ci id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.4.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.4">𝑜</ci><ci id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.5.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.5">𝑐</ci><apply id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6"><csymbol cd="ambiguous" id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.1.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6">subscript</csymbol><ci id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.2.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.2">ℎ</ci><apply id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3"><times id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.1.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.1"></times><ci id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.2.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.2">𝑚</ci><ci id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.3.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.3">𝑎</ci><ci id="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.4.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1.1.1.3.6.3.4">𝑥</ci></apply></apply></apply></apply><cn id="S2.SS3.p2.3.m3.1.1.1.1.3.cmml" type="float" xref="S2.SS3.p2.3.m3.1.1.1.1.3">0.9</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.3.m3.1c">LR_{new}=LR_{initial}(1-epoch/epoch_{max})^{0.9}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.3.m3.1d">italic_L italic_R start_POSTSUBSCRIPT italic_n italic_e italic_w end_POSTSUBSCRIPT = italic_L italic_R start_POSTSUBSCRIPT italic_i italic_n italic_i italic_t italic_i italic_a italic_l end_POSTSUBSCRIPT ( 1 - italic_e italic_p italic_o italic_c italic_h / italic_e italic_p italic_o italic_c italic_h start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 0.9 end_POSTSUPERSCRIPT</annotation></semantics></math>. The training of 3 folds takes about 7.5 hours on a 32G NVIDIA Tesla V100.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Metrics</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">To assess the quality of the segmentation model, we used the Dice coefficient:</p>
</div>
<div class="ltx_para" id="S2.SS4.p2">
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{Dice}(X,Y)=\frac{2\times|X\cap Y|}{|X|+|Y|}" class="ltx_Math" display="block" id="S2.E1.m1.5"><semantics id="S2.E1.m1.5a"><mrow id="S2.E1.m1.5.6" xref="S2.E1.m1.5.6.cmml"><mrow id="S2.E1.m1.5.6.2" xref="S2.E1.m1.5.6.2.cmml"><mtext id="S2.E1.m1.5.6.2.2" xref="S2.E1.m1.5.6.2.2a.cmml">Dice</mtext><mo id="S2.E1.m1.5.6.2.1" xref="S2.E1.m1.5.6.2.1.cmml">⁢</mo><mrow id="S2.E1.m1.5.6.2.3.2" xref="S2.E1.m1.5.6.2.3.1.cmml"><mo id="S2.E1.m1.5.6.2.3.2.1" stretchy="false" xref="S2.E1.m1.5.6.2.3.1.cmml">(</mo><mi id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml">X</mi><mo id="S2.E1.m1.5.6.2.3.2.2" xref="S2.E1.m1.5.6.2.3.1.cmml">,</mo><mi id="S2.E1.m1.5.5" xref="S2.E1.m1.5.5.cmml">Y</mi><mo id="S2.E1.m1.5.6.2.3.2.3" stretchy="false" xref="S2.E1.m1.5.6.2.3.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.5.6.1" xref="S2.E1.m1.5.6.1.cmml">=</mo><mfrac id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml"><mrow id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.cmml"><mn id="S2.E1.m1.1.1.1.3" xref="S2.E1.m1.1.1.1.3.cmml">2</mn><mo id="S2.E1.m1.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="S2.E1.m1.1.1.1.2.cmml">×</mo><mrow id="S2.E1.m1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.2.cmml"><mo id="S2.E1.m1.1.1.1.1.1.2" stretchy="false" xref="S2.E1.m1.1.1.1.1.2.1.cmml">|</mo><mrow id="S2.E1.m1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.2.cmml">X</mi><mo id="S2.E1.m1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.cmml">∩</mo><mi id="S2.E1.m1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.3.cmml">Y</mi></mrow><mo id="S2.E1.m1.1.1.1.1.1.3" stretchy="false" xref="S2.E1.m1.1.1.1.1.2.1.cmml">|</mo></mrow></mrow><mrow id="S2.E1.m1.3.3.3" xref="S2.E1.m1.3.3.3.cmml"><mrow id="S2.E1.m1.3.3.3.4.2" xref="S2.E1.m1.3.3.3.4.1.cmml"><mo id="S2.E1.m1.3.3.3.4.2.1" stretchy="false" xref="S2.E1.m1.3.3.3.4.1.1.cmml">|</mo><mi id="S2.E1.m1.2.2.2.1" xref="S2.E1.m1.2.2.2.1.cmml">X</mi><mo id="S2.E1.m1.3.3.3.4.2.2" stretchy="false" xref="S2.E1.m1.3.3.3.4.1.1.cmml">|</mo></mrow><mo id="S2.E1.m1.3.3.3.3" xref="S2.E1.m1.3.3.3.3.cmml">+</mo><mrow id="S2.E1.m1.3.3.3.5.2" xref="S2.E1.m1.3.3.3.5.1.cmml"><mo id="S2.E1.m1.3.3.3.5.2.1" stretchy="false" xref="S2.E1.m1.3.3.3.5.1.1.cmml">|</mo><mi id="S2.E1.m1.3.3.3.2" xref="S2.E1.m1.3.3.3.2.cmml">Y</mi><mo id="S2.E1.m1.3.3.3.5.2.2" stretchy="false" xref="S2.E1.m1.3.3.3.5.1.1.cmml">|</mo></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.5b"><apply id="S2.E1.m1.5.6.cmml" xref="S2.E1.m1.5.6"><eq id="S2.E1.m1.5.6.1.cmml" xref="S2.E1.m1.5.6.1"></eq><apply id="S2.E1.m1.5.6.2.cmml" xref="S2.E1.m1.5.6.2"><times id="S2.E1.m1.5.6.2.1.cmml" xref="S2.E1.m1.5.6.2.1"></times><ci id="S2.E1.m1.5.6.2.2a.cmml" xref="S2.E1.m1.5.6.2.2"><mtext id="S2.E1.m1.5.6.2.2.cmml" xref="S2.E1.m1.5.6.2.2">Dice</mtext></ci><interval closure="open" id="S2.E1.m1.5.6.2.3.1.cmml" xref="S2.E1.m1.5.6.2.3.2"><ci id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4">𝑋</ci><ci id="S2.E1.m1.5.5.cmml" xref="S2.E1.m1.5.5">𝑌</ci></interval></apply><apply id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3"><divide id="S2.E1.m1.3.3.4.cmml" xref="S2.E1.m1.3.3"></divide><apply id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"><times id="S2.E1.m1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.2"></times><cn id="S2.E1.m1.1.1.1.3.cmml" type="integer" xref="S2.E1.m1.1.1.1.3">2</cn><apply id="S2.E1.m1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1"><abs id="S2.E1.m1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.2"></abs><apply id="S2.E1.m1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1"><intersect id="S2.E1.m1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1"></intersect><ci id="S2.E1.m1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2">𝑋</ci><ci id="S2.E1.m1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.3">𝑌</ci></apply></apply></apply><apply id="S2.E1.m1.3.3.3.cmml" xref="S2.E1.m1.3.3.3"><plus id="S2.E1.m1.3.3.3.3.cmml" xref="S2.E1.m1.3.3.3.3"></plus><apply id="S2.E1.m1.3.3.3.4.1.cmml" xref="S2.E1.m1.3.3.3.4.2"><abs id="S2.E1.m1.3.3.3.4.1.1.cmml" xref="S2.E1.m1.3.3.3.4.2.1"></abs><ci id="S2.E1.m1.2.2.2.1.cmml" xref="S2.E1.m1.2.2.2.1">𝑋</ci></apply><apply id="S2.E1.m1.3.3.3.5.1.cmml" xref="S2.E1.m1.3.3.3.5.2"><abs id="S2.E1.m1.3.3.3.5.1.1.cmml" xref="S2.E1.m1.3.3.3.5.2.1"></abs><ci id="S2.E1.m1.3.3.3.2.cmml" xref="S2.E1.m1.3.3.3.2">𝑌</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.5c">\text{Dice}(X,Y)=\frac{2\times|X\cap Y|}{|X|+|Y|}</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.5d">Dice ( italic_X , italic_Y ) = divide start_ARG 2 × | italic_X ∩ italic_Y | end_ARG start_ARG | italic_X | + | italic_Y | end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S2.SS4.p3">
<p class="ltx_p" id="S2.SS4.p3.2">where <math alttext="X" class="ltx_Math" display="inline" id="S2.SS4.p3.1.m1.1"><semantics id="S2.SS4.p3.1.m1.1a"><mi id="S2.SS4.p3.1.m1.1.1" xref="S2.SS4.p3.1.m1.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p3.1.m1.1b"><ci id="S2.SS4.p3.1.m1.1.1.cmml" xref="S2.SS4.p3.1.m1.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p3.1.m1.1c">X</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p3.1.m1.1d">italic_X</annotation></semantics></math> is the predicted binary segmentation, and <math alttext="Y" class="ltx_Math" display="inline" id="S2.SS4.p3.2.m2.1"><semantics id="S2.SS4.p3.2.m2.1a"><mi id="S2.SS4.p3.2.m2.1.1" xref="S2.SS4.p3.2.m2.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p3.2.m2.1b"><ci id="S2.SS4.p3.2.m2.1.1.cmml" xref="S2.SS4.p3.2.m2.1.1">𝑌</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p3.2.m2.1c">Y</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p3.2.m2.1d">italic_Y</annotation></semantics></math> is the ground truth. The Dice coefficient for multi-class segmentation is then obtained by averaging the Dice scores across all segmentation classes.</p>
</div>
<div class="ltx_para" id="S2.SS4.p4">
<p class="ltx_p" id="S2.SS4.p4.3">We used the Peak Signal-to-Noise Ratio (PSNR) to assess the quality of the compressed images. A higher value indicates a closer match between the original and compressed images. Given the original image <math alttext="I_{1}" class="ltx_Math" display="inline" id="S2.SS4.p4.1.m1.1"><semantics id="S2.SS4.p4.1.m1.1a"><msub id="S2.SS4.p4.1.m1.1.1" xref="S2.SS4.p4.1.m1.1.1.cmml"><mi id="S2.SS4.p4.1.m1.1.1.2" xref="S2.SS4.p4.1.m1.1.1.2.cmml">I</mi><mn id="S2.SS4.p4.1.m1.1.1.3" xref="S2.SS4.p4.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.1.m1.1b"><apply id="S2.SS4.p4.1.m1.1.1.cmml" xref="S2.SS4.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS4.p4.1.m1.1.1.1.cmml" xref="S2.SS4.p4.1.m1.1.1">subscript</csymbol><ci id="S2.SS4.p4.1.m1.1.1.2.cmml" xref="S2.SS4.p4.1.m1.1.1.2">𝐼</ci><cn id="S2.SS4.p4.1.m1.1.1.3.cmml" type="integer" xref="S2.SS4.p4.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.1.m1.1c">I_{1}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p4.1.m1.1d">italic_I start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> and the compressed image <math alttext="I_{2}" class="ltx_Math" display="inline" id="S2.SS4.p4.2.m2.1"><semantics id="S2.SS4.p4.2.m2.1a"><msub id="S2.SS4.p4.2.m2.1.1" xref="S2.SS4.p4.2.m2.1.1.cmml"><mi id="S2.SS4.p4.2.m2.1.1.2" xref="S2.SS4.p4.2.m2.1.1.2.cmml">I</mi><mn id="S2.SS4.p4.2.m2.1.1.3" xref="S2.SS4.p4.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.2.m2.1b"><apply id="S2.SS4.p4.2.m2.1.1.cmml" xref="S2.SS4.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS4.p4.2.m2.1.1.1.cmml" xref="S2.SS4.p4.2.m2.1.1">subscript</csymbol><ci id="S2.SS4.p4.2.m2.1.1.2.cmml" xref="S2.SS4.p4.2.m2.1.1.2">𝐼</ci><cn id="S2.SS4.p4.2.m2.1.1.3.cmml" type="integer" xref="S2.SS4.p4.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.2.m2.1c">I_{2}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p4.2.m2.1d">italic_I start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> of size <math alttext="M\times N" class="ltx_Math" display="inline" id="S2.SS4.p4.3.m3.1"><semantics id="S2.SS4.p4.3.m3.1a"><mrow id="S2.SS4.p4.3.m3.1.1" xref="S2.SS4.p4.3.m3.1.1.cmml"><mi id="S2.SS4.p4.3.m3.1.1.2" xref="S2.SS4.p4.3.m3.1.1.2.cmml">M</mi><mo id="S2.SS4.p4.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.SS4.p4.3.m3.1.1.1.cmml">×</mo><mi id="S2.SS4.p4.3.m3.1.1.3" xref="S2.SS4.p4.3.m3.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.3.m3.1b"><apply id="S2.SS4.p4.3.m3.1.1.cmml" xref="S2.SS4.p4.3.m3.1.1"><times id="S2.SS4.p4.3.m3.1.1.1.cmml" xref="S2.SS4.p4.3.m3.1.1.1"></times><ci id="S2.SS4.p4.3.m3.1.1.2.cmml" xref="S2.SS4.p4.3.m3.1.1.2">𝑀</ci><ci id="S2.SS4.p4.3.m3.1.1.3.cmml" xref="S2.SS4.p4.3.m3.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.3.m3.1c">M\times N</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p4.3.m3.1d">italic_M × italic_N</annotation></semantics></math>, PSNR is calculated based on the mean squared error (MSE):</p>
</div>
<div class="ltx_para" id="S2.SS4.p5">
<table class="ltx_equation ltx_eqn_table" id="S2.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{MSE}(I_{1},I_{2})=\frac{\sum_{M,N}(I_{1}(m,n)-I_{2}(m,n))^{2}}{M\times N}" class="ltx_Math" display="block" id="S2.E2.m1.9"><semantics id="S2.E2.m1.9a"><mrow id="S2.E2.m1.9.9" xref="S2.E2.m1.9.9.cmml"><mrow id="S2.E2.m1.9.9.2" xref="S2.E2.m1.9.9.2.cmml"><mtext id="S2.E2.m1.9.9.2.4" xref="S2.E2.m1.9.9.2.4a.cmml">MSE</mtext><mo id="S2.E2.m1.9.9.2.3" xref="S2.E2.m1.9.9.2.3.cmml">⁢</mo><mrow id="S2.E2.m1.9.9.2.2.2" xref="S2.E2.m1.9.9.2.2.3.cmml"><mo id="S2.E2.m1.9.9.2.2.2.3" stretchy="false" xref="S2.E2.m1.9.9.2.2.3.cmml">(</mo><msub id="S2.E2.m1.8.8.1.1.1.1" xref="S2.E2.m1.8.8.1.1.1.1.cmml"><mi id="S2.E2.m1.8.8.1.1.1.1.2" xref="S2.E2.m1.8.8.1.1.1.1.2.cmml">I</mi><mn id="S2.E2.m1.8.8.1.1.1.1.3" xref="S2.E2.m1.8.8.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.E2.m1.9.9.2.2.2.4" xref="S2.E2.m1.9.9.2.2.3.cmml">,</mo><msub id="S2.E2.m1.9.9.2.2.2.2" xref="S2.E2.m1.9.9.2.2.2.2.cmml"><mi id="S2.E2.m1.9.9.2.2.2.2.2" xref="S2.E2.m1.9.9.2.2.2.2.2.cmml">I</mi><mn id="S2.E2.m1.9.9.2.2.2.2.3" xref="S2.E2.m1.9.9.2.2.2.2.3.cmml">2</mn></msub><mo id="S2.E2.m1.9.9.2.2.2.5" stretchy="false" xref="S2.E2.m1.9.9.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.9.9.3" xref="S2.E2.m1.9.9.3.cmml">=</mo><mfrac id="S2.E2.m1.7.7" xref="S2.E2.m1.7.7.cmml"><mrow id="S2.E2.m1.7.7.7" xref="S2.E2.m1.7.7.7.cmml"><msub id="S2.E2.m1.7.7.7.8" xref="S2.E2.m1.7.7.7.8.cmml"><mo id="S2.E2.m1.7.7.7.8.2" xref="S2.E2.m1.7.7.7.8.2.cmml">∑</mo><mrow id="S2.E2.m1.2.2.2.2.2.4" xref="S2.E2.m1.2.2.2.2.2.3.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.cmml">M</mi><mo id="S2.E2.m1.2.2.2.2.2.4.1" xref="S2.E2.m1.2.2.2.2.2.3.cmml">,</mo><mi id="S2.E2.m1.2.2.2.2.2.2" xref="S2.E2.m1.2.2.2.2.2.2.cmml">N</mi></mrow></msub><msup id="S2.E2.m1.7.7.7.7" xref="S2.E2.m1.7.7.7.7.cmml"><mrow id="S2.E2.m1.7.7.7.7.1.1" xref="S2.E2.m1.7.7.7.7.1.1.1.cmml"><mo id="S2.E2.m1.7.7.7.7.1.1.2" lspace="0em" stretchy="false" xref="S2.E2.m1.7.7.7.7.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.7.7.7.7.1.1.1" xref="S2.E2.m1.7.7.7.7.1.1.1.cmml"><mrow id="S2.E2.m1.7.7.7.7.1.1.1.2" xref="S2.E2.m1.7.7.7.7.1.1.1.2.cmml"><msub id="S2.E2.m1.7.7.7.7.1.1.1.2.2" xref="S2.E2.m1.7.7.7.7.1.1.1.2.2.cmml"><mi id="S2.E2.m1.7.7.7.7.1.1.1.2.2.2" xref="S2.E2.m1.7.7.7.7.1.1.1.2.2.2.cmml">I</mi><mn id="S2.E2.m1.7.7.7.7.1.1.1.2.2.3" xref="S2.E2.m1.7.7.7.7.1.1.1.2.2.3.cmml">1</mn></msub><mo id="S2.E2.m1.7.7.7.7.1.1.1.2.1" xref="S2.E2.m1.7.7.7.7.1.1.1.2.1.cmml">⁢</mo><mrow id="S2.E2.m1.7.7.7.7.1.1.1.2.3.2" xref="S2.E2.m1.7.7.7.7.1.1.1.2.3.1.cmml"><mo id="S2.E2.m1.7.7.7.7.1.1.1.2.3.2.1" stretchy="false" xref="S2.E2.m1.7.7.7.7.1.1.1.2.3.1.cmml">(</mo><mi id="S2.E2.m1.3.3.3.3" xref="S2.E2.m1.3.3.3.3.cmml">m</mi><mo id="S2.E2.m1.7.7.7.7.1.1.1.2.3.2.2" xref="S2.E2.m1.7.7.7.7.1.1.1.2.3.1.cmml">,</mo><mi id="S2.E2.m1.4.4.4.4" xref="S2.E2.m1.4.4.4.4.cmml">n</mi><mo id="S2.E2.m1.7.7.7.7.1.1.1.2.3.2.3" stretchy="false" xref="S2.E2.m1.7.7.7.7.1.1.1.2.3.1.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.7.7.7.7.1.1.1.1" xref="S2.E2.m1.7.7.7.7.1.1.1.1.cmml">−</mo><mrow id="S2.E2.m1.7.7.7.7.1.1.1.3" xref="S2.E2.m1.7.7.7.7.1.1.1.3.cmml"><msub id="S2.E2.m1.7.7.7.7.1.1.1.3.2" xref="S2.E2.m1.7.7.7.7.1.1.1.3.2.cmml"><mi id="S2.E2.m1.7.7.7.7.1.1.1.3.2.2" xref="S2.E2.m1.7.7.7.7.1.1.1.3.2.2.cmml">I</mi><mn id="S2.E2.m1.7.7.7.7.1.1.1.3.2.3" xref="S2.E2.m1.7.7.7.7.1.1.1.3.2.3.cmml">2</mn></msub><mo id="S2.E2.m1.7.7.7.7.1.1.1.3.1" xref="S2.E2.m1.7.7.7.7.1.1.1.3.1.cmml">⁢</mo><mrow id="S2.E2.m1.7.7.7.7.1.1.1.3.3.2" xref="S2.E2.m1.7.7.7.7.1.1.1.3.3.1.cmml"><mo id="S2.E2.m1.7.7.7.7.1.1.1.3.3.2.1" stretchy="false" xref="S2.E2.m1.7.7.7.7.1.1.1.3.3.1.cmml">(</mo><mi id="S2.E2.m1.5.5.5.5" xref="S2.E2.m1.5.5.5.5.cmml">m</mi><mo id="S2.E2.m1.7.7.7.7.1.1.1.3.3.2.2" xref="S2.E2.m1.7.7.7.7.1.1.1.3.3.1.cmml">,</mo><mi id="S2.E2.m1.6.6.6.6" xref="S2.E2.m1.6.6.6.6.cmml">n</mi><mo id="S2.E2.m1.7.7.7.7.1.1.1.3.3.2.3" stretchy="false" xref="S2.E2.m1.7.7.7.7.1.1.1.3.3.1.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E2.m1.7.7.7.7.1.1.3" stretchy="false" xref="S2.E2.m1.7.7.7.7.1.1.1.cmml">)</mo></mrow><mn id="S2.E2.m1.7.7.7.7.3" xref="S2.E2.m1.7.7.7.7.3.cmml">2</mn></msup></mrow><mrow id="S2.E2.m1.7.7.9" xref="S2.E2.m1.7.7.9.cmml"><mi id="S2.E2.m1.7.7.9.2" xref="S2.E2.m1.7.7.9.2.cmml">M</mi><mo id="S2.E2.m1.7.7.9.1" lspace="0.222em" rspace="0.222em" xref="S2.E2.m1.7.7.9.1.cmml">×</mo><mi id="S2.E2.m1.7.7.9.3" xref="S2.E2.m1.7.7.9.3.cmml">N</mi></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.9b"><apply id="S2.E2.m1.9.9.cmml" xref="S2.E2.m1.9.9"><eq id="S2.E2.m1.9.9.3.cmml" xref="S2.E2.m1.9.9.3"></eq><apply id="S2.E2.m1.9.9.2.cmml" xref="S2.E2.m1.9.9.2"><times id="S2.E2.m1.9.9.2.3.cmml" xref="S2.E2.m1.9.9.2.3"></times><ci id="S2.E2.m1.9.9.2.4a.cmml" xref="S2.E2.m1.9.9.2.4"><mtext id="S2.E2.m1.9.9.2.4.cmml" xref="S2.E2.m1.9.9.2.4">MSE</mtext></ci><interval closure="open" id="S2.E2.m1.9.9.2.2.3.cmml" xref="S2.E2.m1.9.9.2.2.2"><apply id="S2.E2.m1.8.8.1.1.1.1.cmml" xref="S2.E2.m1.8.8.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.8.8.1.1.1.1.1.cmml" xref="S2.E2.m1.8.8.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.8.8.1.1.1.1.2.cmml" xref="S2.E2.m1.8.8.1.1.1.1.2">𝐼</ci><cn id="S2.E2.m1.8.8.1.1.1.1.3.cmml" type="integer" xref="S2.E2.m1.8.8.1.1.1.1.3">1</cn></apply><apply id="S2.E2.m1.9.9.2.2.2.2.cmml" xref="S2.E2.m1.9.9.2.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.9.9.2.2.2.2.1.cmml" xref="S2.E2.m1.9.9.2.2.2.2">subscript</csymbol><ci id="S2.E2.m1.9.9.2.2.2.2.2.cmml" xref="S2.E2.m1.9.9.2.2.2.2.2">𝐼</ci><cn id="S2.E2.m1.9.9.2.2.2.2.3.cmml" type="integer" xref="S2.E2.m1.9.9.2.2.2.2.3">2</cn></apply></interval></apply><apply id="S2.E2.m1.7.7.cmml" xref="S2.E2.m1.7.7"><divide id="S2.E2.m1.7.7.8.cmml" xref="S2.E2.m1.7.7"></divide><apply id="S2.E2.m1.7.7.7.cmml" xref="S2.E2.m1.7.7.7"><apply id="S2.E2.m1.7.7.7.8.cmml" xref="S2.E2.m1.7.7.7.8"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.7.8.1.cmml" xref="S2.E2.m1.7.7.7.8">subscript</csymbol><sum id="S2.E2.m1.7.7.7.8.2.cmml" xref="S2.E2.m1.7.7.7.8.2"></sum><list id="S2.E2.m1.2.2.2.2.2.3.cmml" xref="S2.E2.m1.2.2.2.2.2.4"><ci id="S2.E2.m1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1">𝑀</ci><ci id="S2.E2.m1.2.2.2.2.2.2.cmml" xref="S2.E2.m1.2.2.2.2.2.2">𝑁</ci></list></apply><apply id="S2.E2.m1.7.7.7.7.cmml" xref="S2.E2.m1.7.7.7.7"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.7.7.2.cmml" xref="S2.E2.m1.7.7.7.7">superscript</csymbol><apply id="S2.E2.m1.7.7.7.7.1.1.1.cmml" xref="S2.E2.m1.7.7.7.7.1.1"><minus id="S2.E2.m1.7.7.7.7.1.1.1.1.cmml" xref="S2.E2.m1.7.7.7.7.1.1.1.1"></minus><apply id="S2.E2.m1.7.7.7.7.1.1.1.2.cmml" xref="S2.E2.m1.7.7.7.7.1.1.1.2"><times id="S2.E2.m1.7.7.7.7.1.1.1.2.1.cmml" xref="S2.E2.m1.7.7.7.7.1.1.1.2.1"></times><apply id="S2.E2.m1.7.7.7.7.1.1.1.2.2.cmml" xref="S2.E2.m1.7.7.7.7.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.7.7.1.1.1.2.2.1.cmml" xref="S2.E2.m1.7.7.7.7.1.1.1.2.2">subscript</csymbol><ci id="S2.E2.m1.7.7.7.7.1.1.1.2.2.2.cmml" xref="S2.E2.m1.7.7.7.7.1.1.1.2.2.2">𝐼</ci><cn id="S2.E2.m1.7.7.7.7.1.1.1.2.2.3.cmml" type="integer" xref="S2.E2.m1.7.7.7.7.1.1.1.2.2.3">1</cn></apply><interval closure="open" id="S2.E2.m1.7.7.7.7.1.1.1.2.3.1.cmml" xref="S2.E2.m1.7.7.7.7.1.1.1.2.3.2"><ci id="S2.E2.m1.3.3.3.3.cmml" xref="S2.E2.m1.3.3.3.3">𝑚</ci><ci id="S2.E2.m1.4.4.4.4.cmml" xref="S2.E2.m1.4.4.4.4">𝑛</ci></interval></apply><apply id="S2.E2.m1.7.7.7.7.1.1.1.3.cmml" xref="S2.E2.m1.7.7.7.7.1.1.1.3"><times id="S2.E2.m1.7.7.7.7.1.1.1.3.1.cmml" xref="S2.E2.m1.7.7.7.7.1.1.1.3.1"></times><apply id="S2.E2.m1.7.7.7.7.1.1.1.3.2.cmml" xref="S2.E2.m1.7.7.7.7.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.7.7.1.1.1.3.2.1.cmml" xref="S2.E2.m1.7.7.7.7.1.1.1.3.2">subscript</csymbol><ci id="S2.E2.m1.7.7.7.7.1.1.1.3.2.2.cmml" xref="S2.E2.m1.7.7.7.7.1.1.1.3.2.2">𝐼</ci><cn id="S2.E2.m1.7.7.7.7.1.1.1.3.2.3.cmml" type="integer" xref="S2.E2.m1.7.7.7.7.1.1.1.3.2.3">2</cn></apply><interval closure="open" id="S2.E2.m1.7.7.7.7.1.1.1.3.3.1.cmml" xref="S2.E2.m1.7.7.7.7.1.1.1.3.3.2"><ci id="S2.E2.m1.5.5.5.5.cmml" xref="S2.E2.m1.5.5.5.5">𝑚</ci><ci id="S2.E2.m1.6.6.6.6.cmml" xref="S2.E2.m1.6.6.6.6">𝑛</ci></interval></apply></apply><cn id="S2.E2.m1.7.7.7.7.3.cmml" type="integer" xref="S2.E2.m1.7.7.7.7.3">2</cn></apply></apply><apply id="S2.E2.m1.7.7.9.cmml" xref="S2.E2.m1.7.7.9"><times id="S2.E2.m1.7.7.9.1.cmml" xref="S2.E2.m1.7.7.9.1"></times><ci id="S2.E2.m1.7.7.9.2.cmml" xref="S2.E2.m1.7.7.9.2">𝑀</ci><ci id="S2.E2.m1.7.7.9.3.cmml" xref="S2.E2.m1.7.7.9.3">𝑁</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.9c">\text{MSE}(I_{1},I_{2})=\frac{\sum_{M,N}(I_{1}(m,n)-I_{2}(m,n))^{2}}{M\times N}</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m1.9d">MSE ( italic_I start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) = divide start_ARG ∑ start_POSTSUBSCRIPT italic_M , italic_N end_POSTSUBSCRIPT ( italic_I start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_m , italic_n ) - italic_I start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_m , italic_n ) ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG italic_M × italic_N end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S2.SS4.p6">
<p class="ltx_p" id="S2.SS4.p6.1">The PSNR is then defined as:</p>
</div>
<div class="ltx_para" id="S2.SS4.p7">
<table class="ltx_equation ltx_eqn_table" id="S2.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{PSNR}(I_{1},I_{2})=10\cdot\log_{10}\left(\frac{r^{2}}{\text{MSE}(I_{1},I%
_{2})}\right)," class="ltx_Math" display="block" id="S2.E3.m1.3"><semantics id="S2.E3.m1.3a"><mrow id="S2.E3.m1.3.3.1" xref="S2.E3.m1.3.3.1.1.cmml"><mrow id="S2.E3.m1.3.3.1.1" xref="S2.E3.m1.3.3.1.1.cmml"><mrow id="S2.E3.m1.3.3.1.1.2" xref="S2.E3.m1.3.3.1.1.2.cmml"><mtext id="S2.E3.m1.3.3.1.1.2.4" xref="S2.E3.m1.3.3.1.1.2.4a.cmml">PSNR</mtext><mo id="S2.E3.m1.3.3.1.1.2.3" xref="S2.E3.m1.3.3.1.1.2.3.cmml">⁢</mo><mrow id="S2.E3.m1.3.3.1.1.2.2.2" xref="S2.E3.m1.3.3.1.1.2.2.3.cmml"><mo id="S2.E3.m1.3.3.1.1.2.2.2.3" stretchy="false" xref="S2.E3.m1.3.3.1.1.2.2.3.cmml">(</mo><msub id="S2.E3.m1.3.3.1.1.1.1.1.1" xref="S2.E3.m1.3.3.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.3.3.1.1.1.1.1.1.2" xref="S2.E3.m1.3.3.1.1.1.1.1.1.2.cmml">I</mi><mn id="S2.E3.m1.3.3.1.1.1.1.1.1.3" xref="S2.E3.m1.3.3.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.E3.m1.3.3.1.1.2.2.2.4" xref="S2.E3.m1.3.3.1.1.2.2.3.cmml">,</mo><msub id="S2.E3.m1.3.3.1.1.2.2.2.2" xref="S2.E3.m1.3.3.1.1.2.2.2.2.cmml"><mi id="S2.E3.m1.3.3.1.1.2.2.2.2.2" xref="S2.E3.m1.3.3.1.1.2.2.2.2.2.cmml">I</mi><mn id="S2.E3.m1.3.3.1.1.2.2.2.2.3" xref="S2.E3.m1.3.3.1.1.2.2.2.2.3.cmml">2</mn></msub><mo id="S2.E3.m1.3.3.1.1.2.2.2.5" stretchy="false" xref="S2.E3.m1.3.3.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.3.3.1.1.4" xref="S2.E3.m1.3.3.1.1.4.cmml">=</mo><mrow id="S2.E3.m1.3.3.1.1.3" xref="S2.E3.m1.3.3.1.1.3.cmml"><mn id="S2.E3.m1.3.3.1.1.3.3" xref="S2.E3.m1.3.3.1.1.3.3.cmml">10</mn><mo id="S2.E3.m1.3.3.1.1.3.2" lspace="0.222em" rspace="0.222em" xref="S2.E3.m1.3.3.1.1.3.2.cmml">⋅</mo><mrow id="S2.E3.m1.3.3.1.1.3.1.1" xref="S2.E3.m1.3.3.1.1.3.1.2.cmml"><msub id="S2.E3.m1.3.3.1.1.3.1.1.1" xref="S2.E3.m1.3.3.1.1.3.1.1.1.cmml"><mi id="S2.E3.m1.3.3.1.1.3.1.1.1.2" xref="S2.E3.m1.3.3.1.1.3.1.1.1.2.cmml">log</mi><mn id="S2.E3.m1.3.3.1.1.3.1.1.1.3" xref="S2.E3.m1.3.3.1.1.3.1.1.1.3.cmml">10</mn></msub><mo id="S2.E3.m1.3.3.1.1.3.1.1a" xref="S2.E3.m1.3.3.1.1.3.1.2.cmml">⁡</mo><mrow id="S2.E3.m1.3.3.1.1.3.1.1.2" xref="S2.E3.m1.3.3.1.1.3.1.2.cmml"><mo id="S2.E3.m1.3.3.1.1.3.1.1.2.1" xref="S2.E3.m1.3.3.1.1.3.1.2.cmml">(</mo><mfrac id="S2.E3.m1.2.2" xref="S2.E3.m1.2.2.cmml"><msup id="S2.E3.m1.2.2.4" xref="S2.E3.m1.2.2.4.cmml"><mi id="S2.E3.m1.2.2.4.2" xref="S2.E3.m1.2.2.4.2.cmml">r</mi><mn id="S2.E3.m1.2.2.4.3" xref="S2.E3.m1.2.2.4.3.cmml">2</mn></msup><mrow id="S2.E3.m1.2.2.2" xref="S2.E3.m1.2.2.2.cmml"><mtext id="S2.E3.m1.2.2.2.4" xref="S2.E3.m1.2.2.2.4a.cmml">MSE</mtext><mo id="S2.E3.m1.2.2.2.3" xref="S2.E3.m1.2.2.2.3.cmml">⁢</mo><mrow id="S2.E3.m1.2.2.2.2.2" xref="S2.E3.m1.2.2.2.2.3.cmml"><mo id="S2.E3.m1.2.2.2.2.2.3" stretchy="false" xref="S2.E3.m1.2.2.2.2.3.cmml">(</mo><msub id="S2.E3.m1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.2.cmml">I</mi><mn id="S2.E3.m1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.E3.m1.2.2.2.2.2.4" xref="S2.E3.m1.2.2.2.2.3.cmml">,</mo><msub id="S2.E3.m1.2.2.2.2.2.2" xref="S2.E3.m1.2.2.2.2.2.2.cmml"><mi id="S2.E3.m1.2.2.2.2.2.2.2" xref="S2.E3.m1.2.2.2.2.2.2.2.cmml">I</mi><mn id="S2.E3.m1.2.2.2.2.2.2.3" xref="S2.E3.m1.2.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S2.E3.m1.2.2.2.2.2.5" stretchy="false" xref="S2.E3.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mfrac><mo id="S2.E3.m1.3.3.1.1.3.1.1.2.2" xref="S2.E3.m1.3.3.1.1.3.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S2.E3.m1.3.3.1.2" xref="S2.E3.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.3b"><apply id="S2.E3.m1.3.3.1.1.cmml" xref="S2.E3.m1.3.3.1"><eq id="S2.E3.m1.3.3.1.1.4.cmml" xref="S2.E3.m1.3.3.1.1.4"></eq><apply id="S2.E3.m1.3.3.1.1.2.cmml" xref="S2.E3.m1.3.3.1.1.2"><times id="S2.E3.m1.3.3.1.1.2.3.cmml" xref="S2.E3.m1.3.3.1.1.2.3"></times><ci id="S2.E3.m1.3.3.1.1.2.4a.cmml" xref="S2.E3.m1.3.3.1.1.2.4"><mtext id="S2.E3.m1.3.3.1.1.2.4.cmml" xref="S2.E3.m1.3.3.1.1.2.4">PSNR</mtext></ci><interval closure="open" id="S2.E3.m1.3.3.1.1.2.2.3.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2"><apply id="S2.E3.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1.2">𝐼</ci><cn id="S2.E3.m1.3.3.1.1.1.1.1.1.3.cmml" type="integer" xref="S2.E3.m1.3.3.1.1.1.1.1.1.3">1</cn></apply><apply id="S2.E3.m1.3.3.1.1.2.2.2.2.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.1.1.2.2.2.2.1.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.2">subscript</csymbol><ci id="S2.E3.m1.3.3.1.1.2.2.2.2.2.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.2.2">𝐼</ci><cn id="S2.E3.m1.3.3.1.1.2.2.2.2.3.cmml" type="integer" xref="S2.E3.m1.3.3.1.1.2.2.2.2.3">2</cn></apply></interval></apply><apply id="S2.E3.m1.3.3.1.1.3.cmml" xref="S2.E3.m1.3.3.1.1.3"><ci id="S2.E3.m1.3.3.1.1.3.2.cmml" xref="S2.E3.m1.3.3.1.1.3.2">⋅</ci><cn id="S2.E3.m1.3.3.1.1.3.3.cmml" type="integer" xref="S2.E3.m1.3.3.1.1.3.3">10</cn><apply id="S2.E3.m1.3.3.1.1.3.1.2.cmml" xref="S2.E3.m1.3.3.1.1.3.1.1"><apply id="S2.E3.m1.3.3.1.1.3.1.1.1.cmml" xref="S2.E3.m1.3.3.1.1.3.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.1.1.3.1.1.1.1.cmml" xref="S2.E3.m1.3.3.1.1.3.1.1.1">subscript</csymbol><log id="S2.E3.m1.3.3.1.1.3.1.1.1.2.cmml" xref="S2.E3.m1.3.3.1.1.3.1.1.1.2"></log><cn id="S2.E3.m1.3.3.1.1.3.1.1.1.3.cmml" type="integer" xref="S2.E3.m1.3.3.1.1.3.1.1.1.3">10</cn></apply><apply id="S2.E3.m1.2.2.cmml" xref="S2.E3.m1.2.2"><divide id="S2.E3.m1.2.2.3.cmml" xref="S2.E3.m1.2.2"></divide><apply id="S2.E3.m1.2.2.4.cmml" xref="S2.E3.m1.2.2.4"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.4.1.cmml" xref="S2.E3.m1.2.2.4">superscript</csymbol><ci id="S2.E3.m1.2.2.4.2.cmml" xref="S2.E3.m1.2.2.4.2">𝑟</ci><cn id="S2.E3.m1.2.2.4.3.cmml" type="integer" xref="S2.E3.m1.2.2.4.3">2</cn></apply><apply id="S2.E3.m1.2.2.2.cmml" xref="S2.E3.m1.2.2.2"><times id="S2.E3.m1.2.2.2.3.cmml" xref="S2.E3.m1.2.2.2.3"></times><ci id="S2.E3.m1.2.2.2.4a.cmml" xref="S2.E3.m1.2.2.2.4"><mtext id="S2.E3.m1.2.2.2.4.cmml" xref="S2.E3.m1.2.2.2.4">MSE</mtext></ci><interval closure="open" id="S2.E3.m1.2.2.2.2.3.cmml" xref="S2.E3.m1.2.2.2.2.2"><apply id="S2.E3.m1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2">𝐼</ci><cn id="S2.E3.m1.1.1.1.1.1.1.3.cmml" type="integer" xref="S2.E3.m1.1.1.1.1.1.1.3">1</cn></apply><apply id="S2.E3.m1.2.2.2.2.2.2.cmml" xref="S2.E3.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.2.2.2.1.cmml" xref="S2.E3.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S2.E3.m1.2.2.2.2.2.2.2.cmml" xref="S2.E3.m1.2.2.2.2.2.2.2">𝐼</ci><cn id="S2.E3.m1.2.2.2.2.2.2.3.cmml" type="integer" xref="S2.E3.m1.2.2.2.2.2.2.3">2</cn></apply></interval></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.3c">\text{PSNR}(I_{1},I_{2})=10\cdot\log_{10}\left(\frac{r^{2}}{\text{MSE}(I_{1},I%
_{2})}\right),</annotation><annotation encoding="application/x-llamapun" id="S2.E3.m1.3d">PSNR ( italic_I start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) = 10 ⋅ roman_log start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT ( divide start_ARG italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG MSE ( italic_I start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) end_ARG ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S2.SS4.p8">
<p class="ltx_p" id="S2.SS4.p8.3">where <math alttext="r" class="ltx_Math" display="inline" id="S2.SS4.p8.1.m1.1"><semantics id="S2.SS4.p8.1.m1.1a"><mi id="S2.SS4.p8.1.m1.1.1" xref="S2.SS4.p8.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p8.1.m1.1b"><ci id="S2.SS4.p8.1.m1.1.1.cmml" xref="S2.SS4.p8.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p8.1.m1.1c">r</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p8.1.m1.1d">italic_r</annotation></semantics></math> is the maximum fluctuation in the input image data type. We set <math alttext="r" class="ltx_Math" display="inline" id="S2.SS4.p8.2.m2.1"><semantics id="S2.SS4.p8.2.m2.1a"><mi id="S2.SS4.p8.2.m2.1.1" xref="S2.SS4.p8.2.m2.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p8.2.m2.1b"><ci id="S2.SS4.p8.2.m2.1.1.cmml" xref="S2.SS4.p8.2.m2.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p8.2.m2.1c">r</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p8.2.m2.1d">italic_r</annotation></semantics></math> to 4096 for CT data and to <math alttext="\max(I)-\min(I)" class="ltx_Math" display="inline" id="S2.SS4.p8.3.m3.4"><semantics id="S2.SS4.p8.3.m3.4a"><mrow id="S2.SS4.p8.3.m3.4.5" xref="S2.SS4.p8.3.m3.4.5.cmml"><mrow id="S2.SS4.p8.3.m3.4.5.2.2" xref="S2.SS4.p8.3.m3.4.5.2.1.cmml"><mi id="S2.SS4.p8.3.m3.1.1" xref="S2.SS4.p8.3.m3.1.1.cmml">max</mi><mo id="S2.SS4.p8.3.m3.4.5.2.2a" xref="S2.SS4.p8.3.m3.4.5.2.1.cmml">⁡</mo><mrow id="S2.SS4.p8.3.m3.4.5.2.2.1" xref="S2.SS4.p8.3.m3.4.5.2.1.cmml"><mo id="S2.SS4.p8.3.m3.4.5.2.2.1.1" stretchy="false" xref="S2.SS4.p8.3.m3.4.5.2.1.cmml">(</mo><mi id="S2.SS4.p8.3.m3.2.2" xref="S2.SS4.p8.3.m3.2.2.cmml">I</mi><mo id="S2.SS4.p8.3.m3.4.5.2.2.1.2" stretchy="false" xref="S2.SS4.p8.3.m3.4.5.2.1.cmml">)</mo></mrow></mrow><mo id="S2.SS4.p8.3.m3.4.5.1" xref="S2.SS4.p8.3.m3.4.5.1.cmml">−</mo><mrow id="S2.SS4.p8.3.m3.4.5.3.2" xref="S2.SS4.p8.3.m3.4.5.3.1.cmml"><mi id="S2.SS4.p8.3.m3.3.3" xref="S2.SS4.p8.3.m3.3.3.cmml">min</mi><mo id="S2.SS4.p8.3.m3.4.5.3.2a" xref="S2.SS4.p8.3.m3.4.5.3.1.cmml">⁡</mo><mrow id="S2.SS4.p8.3.m3.4.5.3.2.1" xref="S2.SS4.p8.3.m3.4.5.3.1.cmml"><mo id="S2.SS4.p8.3.m3.4.5.3.2.1.1" stretchy="false" xref="S2.SS4.p8.3.m3.4.5.3.1.cmml">(</mo><mi id="S2.SS4.p8.3.m3.4.4" xref="S2.SS4.p8.3.m3.4.4.cmml">I</mi><mo id="S2.SS4.p8.3.m3.4.5.3.2.1.2" stretchy="false" xref="S2.SS4.p8.3.m3.4.5.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p8.3.m3.4b"><apply id="S2.SS4.p8.3.m3.4.5.cmml" xref="S2.SS4.p8.3.m3.4.5"><minus id="S2.SS4.p8.3.m3.4.5.1.cmml" xref="S2.SS4.p8.3.m3.4.5.1"></minus><apply id="S2.SS4.p8.3.m3.4.5.2.1.cmml" xref="S2.SS4.p8.3.m3.4.5.2.2"><max id="S2.SS4.p8.3.m3.1.1.cmml" xref="S2.SS4.p8.3.m3.1.1"></max><ci id="S2.SS4.p8.3.m3.2.2.cmml" xref="S2.SS4.p8.3.m3.2.2">𝐼</ci></apply><apply id="S2.SS4.p8.3.m3.4.5.3.1.cmml" xref="S2.SS4.p8.3.m3.4.5.3.2"><min id="S2.SS4.p8.3.m3.3.3.cmml" xref="S2.SS4.p8.3.m3.3.3"></min><ci id="S2.SS4.p8.3.m3.4.4.cmml" xref="S2.SS4.p8.3.m3.4.4">𝐼</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p8.3.m3.4c">\max(I)-\min(I)</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p8.3.m3.4d">roman_max ( italic_I ) - roman_min ( italic_I )</annotation></semantics></math> for MRI data (measuring the minimum and maximum values over the entire BraTS dataset).</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Results</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">First, we assess how lossy compression influences images quality using human evaluation and PSNR. Second, we test the effect on segmentation quality of training a Unet architecture on lossy compressed images. Third, we test how models trained on uncompressed images performs on lossy compressed images. Finally, we demonstrate that in a scenario were storage capacity is limited, compression is a better choice then data subsampling.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="225" id="S3.F1.g1" src="extracted/5878414/figures/Figure-3-human-evaluation-psnr.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Left: results of human assessment of image pairs with different compression ratios. Each line represents the average Spearman’s rank correlation (x-axis) between two compression rates (two ends of each line, y-axis). Right: peak signal-to-noise ratio of images compressed at different rates.</figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Compressed images quality</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">To assess how well radiologists differentiate between images of varying compression rates we generated pairs of images with different compression rates: 1 vs 2, 1 vs 5, …, 20 vs 50. For each pair of compression rates (15 in total), we generated 10 random images for each dataset (600 in total). 2D axial slices with lower compression rates were randomly placed on the left or right side of the image. Each axial slice in a pair was generated from the same uncompressed 2D slice. Two radiologists (5 and 8 years of experience) independently assessed image pairs and provided a decision on which image (left or right) was of better quality or if they could not decide which one was better. We next compare their results with the ground truth using Spearman’s Rank correlation (1 if radiologist chosen correct image of higher quality, 0 if she can not decide, -1 if image of lower quality is selected as image of higher quality). See example images in the Supplementary materials.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">First, we observe that both radiologists are unable to distinguish between uncompressed images and images with compression rates up to 5. Their performance steadily improves at compression rates 10 and 20, achieving almost perfect quality for compression rate 50 Figure  <a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S3.F1" title="Figure 1 ‣ 3 Results ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_tag">1</span></a> (left). Figure  <a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S3.F1" title="Figure 1 ‣ 3 Results ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_tag">1</span></a> (right) shows the PSNRs achieved via JPEG2000 lossy compression at different compression rates. We observe a significant drop in PSNR at rate 10, which then steadily declines. This result intuitively aligns with the outcomes from human evaluation.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Effect of training on lossy compressed images</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">To investigate the influence of image compression on the downstream segmentation task, we trained the Unet segmentation architecture on images compressed at different rates and on uncompressed original images (separate models) Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S3.F2" title="Figure 2 ‣ 3.2 Effect of training on lossy compressed images ‣ 3 Results ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_tag">2</span></a> (left). For all 4 datasets, we observe stable segmentation quality up to compression rates 20, with rapid deterioration of the quality at higher compression rates. This finding provides strong evidence that the Unet architecture with a standard training pipeline is robust to artifacts introduced by the JPEG2000 compression algorithm. Table <a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S3.T1" title="Table 1 ‣ 3.2 Effect of training on lossy compressed images ‣ 3 Results ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_tag">1</span></a> presents the by-class segmentation performance on the AMOS dataset. We observe no segmentation drop, even for smaller organs like adrenal glands and the gallbladder.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="200" id="S3.F2.g1" src="extracted/5878414/figures/Figure-1-compression-training-few-shot.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Left: segmentation performance of models trained on data compressed at different rates. Right: storage memory footprint tradeoff, few-shot (uncompressed) vs full-shot (compressed).</figcaption>
</figure>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Per-organ segmentation quality for different compression rates on AMOS. Numbers are mean Dice score averaged over 3-fold cross-validation.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T1.1.1.1.1">compression rate</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.2">1</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.3">2</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.4">5</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.5">10</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.6">20</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.7">50</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.8">70</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.9">100</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.1.2.1.1">SPL</th>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S3.T1.1.2.1.2">0.96</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S3.T1.1.2.1.3">0.96</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S3.T1.1.2.1.4">0.96</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S3.T1.1.2.1.5">0.96</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S3.T1.1.2.1.6">0.96</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S3.T1.1.2.1.7">0.94</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S3.T1.1.2.1.8">0.92</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S3.T1.1.2.1.9">0.90</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.3.2.1">RKI</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.3.2.2">0.84</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.3.2.3">0.84</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.3.2.4">0.84</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.3.2.5">0.84</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.3.2.6">0.83</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.3.2.7">0.76</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.3.2.8">0.72</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.3.2.9">0.67</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.4.3.1">LKI</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.4.3.2">0.76</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.4.3.3">0.76</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.4.3.4">0.76</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.4.3.5">0.76</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.4.3.6">0.73</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.4.3.7">0.63</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.4.3.8">0.59</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.4.3.9">0.54</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.5.4.1">GBL</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.5.4.2">0.76</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.5.4.3">0.76</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.5.4.4">0.76</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.5.4.5">0.76</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.5.4.6">0.75</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.5.4.7">0.62</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.5.4.8">0.57</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.5.4.9">0.51</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.6.5.1">ESO</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.6.5.2">0.80</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.6.5.3">0.80</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.6.5.4">0.80</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.6.5.5">0.80</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.6.5.6">0.78</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.6.5.7">0.70</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.6.5.8">0.67</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.6.5.9">0.62</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.7.6.1">LIV</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.7.6.2">0.87</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.7.6.3">0.87</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.7.6.4">0.88</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.7.6.5">0.87</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.7.6.6">0.85</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.7.6.7">0.79</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.7.6.8">0.76</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.7.6.9">0.73</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.8.7.1">STO</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.8.7.2">0.82</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.8.7.3">0.81</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.8.7.4">0.81</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.8.7.5">0.82</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.8.7.6">0.80</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.8.7.7">0.75</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.8.7.8">0.73</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.8.7.9">0.70</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.9.8.1">AOR</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.9.8.2">0.96</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.9.8.3">0.96</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.9.8.4">0.96</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.9.8.5">0.96</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.9.8.6">0.95</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.9.8.7">0.93</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.9.8.8">0.91</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.9.8.9">0.89</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.10.9.1">IVC</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.10.9.2">0.95</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.10.9.3">0.95</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.10.9.4">0.95</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.10.9.5">0.95</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.10.9.6">0.95</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.10.9.7">0.92</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.10.9.8">0.91</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.10.9.9">0.89</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.11.10.1">PAN</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.11.10.2">0.82</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.11.10.3">0.81</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.11.10.4">0.82</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.11.10.5">0.82</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.11.10.6">0.79</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.11.10.7">0.66</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.11.10.8">0.61</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.11.10.9">0.52</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.12.11.1">RAD</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.12.11.2">0.84</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.12.11.3">0.84</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.12.11.4">0.84</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.12.11.5">0.84</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.12.11.6">0.83</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.12.11.7">0.78</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.12.11.8">0.75</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.12.11.9">0.72</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.13.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.13.12.1">LAD</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.13.12.2">0.97</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.13.12.3">0.97</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.13.12.4">0.97</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.13.12.5">0.97</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.13.12.6">0.97</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.13.12.7">0.96</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.13.12.8">0.95</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.13.12.9">0.94</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.14.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.14.13.1">DUO</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.14.13.2">0.90</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.14.13.3">0.90</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.14.13.4">0.90</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.14.13.5">0.90</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.14.13.6">0.89</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.14.13.7">0.85</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.14.13.8">0.83</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.14.13.9">0.80</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.15.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.15.14.1">BLA</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.15.14.2">0.95</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.15.14.3">0.95</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.15.14.4">0.95</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.15.14.5">0.95</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.15.14.6">0.95</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.15.14.7">0.93</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.15.14.8">0.92</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.15.14.9">0.90</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.16.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.16.15.1">PRO/UTE</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.16.15.2">0.90</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.16.15.3">0.90</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.16.15.4">0.90</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.16.15.5">0.90</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.16.15.6">0.89</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.16.15.7">0.85</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.16.15.8">0.83</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.T1.1.16.15.9">0.80</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.17.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S3.T1.1.17.16.1">average</th>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.17.16.2">0.87</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.17.16.3">0.87</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.17.16.4">0.87</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.17.16.5">0.87</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.17.16.6">0.86</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.17.16.7">0.80</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.17.16.8">0.78</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.17.16.9">0.74</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Inference models trained on original data</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Next, we examine how models trained on images of higher compression rates perform on images of lower compression rates, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#Sx1.F5" title="Figure 5 ‣ Supplementary materials ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_tag">5</span></a>. On the AMOS and LiTS datasets, we observe no performance drop for compression rates up to 20. The selection of compression rate 20 is due to the fact that beyond this rate, models’ performance decreases compared to models trained on uncompressed data, as discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S3.SS2" title="3.2 Effect of training on lossy compressed images ‣ 3 Results ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_tag">3.2</span></a>. This scenario is important if one wants to use models already trained on compressed data on uncompressed data, potentially saving time on compression itself.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">Furthermore, we investigated how models trained on uncompressed data perform on data with various compression rates. For this experiment, we utilized the Unet (trained via the full resolution nn-Unet pipeline) and publicly available weights for the SWIN Unetr model (trained on the BTCV dataset
The results are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S3.T2" title="Table 2 ‣ 3.3 Inference models trained on original data ‣ 3 Results ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_tag">2</span></a>. Once again, we observe no deterioration in segmentation quality for either model. The significance of this result lies in the fact that researchers already have a plethora of trained models (both public and private), typically on uncompressed data. Our findings suggest that adopting an "inference on compressed data strategy" does not introduce any additional costs. Despite relatively modest (by an absolute value) segmentation performance of pretrained SWIN Unetr<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Likely due to the fact it was trained on a BTCV dataset, using only 24 training samples.</span></span></span>, the purpose of this experiment was to demonstrate that JPEG compression has almost no effect on the performance of publicly available network trained on an uncompressed data.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Models trained on uncompressed data tested on compressed data. Results on AMOS dataset. nn-Unet results are averaged over three cross validation folds. Swin Unetr results are averaged over all AMOS dataset.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.1">compression rate</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.2">2</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.3">5</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.4">10</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.5">20</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.6">50</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.1.2.1.1">nnUnet (high resolution)</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S3.T2.1.2.1.2">0.971</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S3.T2.1.2.1.3">0.971</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S3.T2.1.2.1.4">0.970</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S3.T2.1.2.1.5">0.969</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S3.T2.1.2.1.6">0.946</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.1.3.2.1">Swin Unetr <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#bib.bib7" title="">7</a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="S3.T2.1.3.2.2">0.614</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="S3.T2.1.3.2.3">0.614</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="S3.T2.1.3.2.4">0.614</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="S3.T2.1.3.2.5">0.614</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="S3.T2.1.3.2.6">0.603</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Few-shot vs lossy compressed full training</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">Finally, we examine the memory footprint tradeoff of training on compressed images. We trained nn-Unet in a few-shot regime, using 1%, 5%, 10%, 20%, 50%, and 100% of the data. We then compared the segmentation quality of the resulting algorithms using the same holdout set. Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.16733v1#S3.F2" title="Figure 2 ‣ 3.2 Effect of training on lossy compressed images ‣ 3 Results ‣ The Effect of Lossy Compression on 3D Medical Images Segmentation with Deep Learning"><span class="ltx_text ltx_ref_tag">2</span></a> (right) illustrates the Dice score of networks trained in a few-shot regime. Dashed lines visualize the segmentation quality of the networks trained on 100% of the data at different compression rates with the same memory footprint. For example, training a network on all training data compressed 20 times is equivalent (in terms of storage memory) to training on 5% of uncompressed data.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">The results on all 4 datasets suggest that at a compression rate of 20, training on 100% compressed data is superior compared to training the network on a fraction of uncompressed data with the same storage memory footprint.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="299" id="S3.F3.g1" src="extracted/5878414/figures/Figure-4-amos-lits-inference.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Testing model trained on images at different compression rates on images of other comression rates. Results for AMOS dataset (left), LiTS dataset (right). </figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this study, we conducted a comprehensive investigation into the impact of lossy image compression on the performance of deep learning-based segmentation models in the context of 3D medical imaging. Our findings demonstrate that significant reductions in storage memory footprint can be achieved through the use of lossy compression without compromising the segmentation quality of the DL models. We hope that our work will encourage medical imaging researchers, workig with 3D images to start integrating lossy compression in their pipelines, without the unreasonable fear of (segmentation) quality loss.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Study limitations</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">First, we solely tested the effect of lossy compression using JPEG2000. While we believe this choice is justified by the fact that this is the only lossy compression algorithm currently supported by DICOM, investigating the effect of other algorithms might be interesting. Second, we only focus our experiments on a single neural network architecture Unet, with a limited analysis of a publicly available pretrained Swin Unetr. Finally, human evaluation experiment only tested the ability of radiologists to differentiate between images of varying compression, but not their performance at segmenting images after compression.</p>
</div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Behme, L., Thirumuruganathan, S., Mahdiraji, A.R., Quiané-Ruiz, J.A., Markl, V.: The art of losing to win: Using lossy image compression to improve data loading in deep learning pipelines. In: 2023 IEEE 39th International Conference on Data Engineering (ICDE). pp. 936–949 (2023). https://doi.org/10.1109/ICDE55515.2023.00077

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Benbarrad, T., Eloutouate, L., Arioua, M., Elouaai, F., Laanaoui, M.D.: Impact of image compression on the performance of steel surface defect classification with a cnn. Journal of Sensor and Actuator Networks <span class="ltx_text ltx_font_bold" id="bib.bib2.1.1">10</span>(4),  73 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Bilic, P., Christ, P., Li, H.B., Vorontsov, E., Ben-Cohen, A., Kaissis, G., Szeskin, A., Jacobs, C., Mamani, G.E.H., Chartrand, G., et al.: The liver tumor segmentation benchmark (lits). Medical Image Analysis <span class="ltx_text ltx_font_bold" id="bib.bib3.1.1">84</span>, 102680 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Foos, D.H., Muka, E., Slone, R.M., Erickson, B.J., Flynn, M.J., Clunie, D.A., Hildebrand, L., Kohm, K.S., Young, S.S.: Jpeg 2000 compression of medical imagery. In: Medical Imaging 2000: PACS Design and Evaluation: Engineering and Clinical Issues. vol. 3980, pp. 85–96. SPIE (2000)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Gandor, T., Nalepa, J.: First gradually, then suddenly: understanding the impact of image compression on object detection using deep learning. Sensors <span class="ltx_text ltx_font_bold" id="bib.bib5.1.1">22</span>(3),  1104 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Ghazvinian Zanjani, F., Zinger, S., Piepers, B., Mahmoudpour, S., Schelkens, P., de With, P.H.: Impact of jpeg 2000 compression on deep convolutional neural networks for metastatic cancer detection in histopathological images. Journal of Medical Imaging <span class="ltx_text ltx_font_bold" id="bib.bib6.1.1">6</span>(2), 027501–027501 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Hatamizadeh, A., Nath, V., Tang, Y., Yang, D., Roth, H., Xu, D.: Swin unetr: Swin transformers for semantic segmentation of brain tumors in mri images. arXiv preprint arXiv:2201.01266 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Isensee, F., Jaeger, P.F., Kohl, S.A., Petersen, J., Maier-Hein, K.H.: nnu-net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods <span class="ltx_text ltx_font_bold" id="bib.bib8.1.1">18</span>(2), 203–211 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Ji, Y., Bai, H., Ge, C., Yang, J., Zhu, Y., Zhang, R., Li, Z., Zhanng, L., Ma, W., Wan, X., et al.: Amos: A large-scale abdominal multi-organ benchmark for versatile medical image segmentation. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib9.1.1">35</span>, 36722–36732 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Jo, Y.Y., Choi, Y.S., Park, H.W., Lee, J.H., Jung, H., Kim, H.E., Ko, K., Lee, C.W., Cha, H.S., Hwangbo, Y.: Impact of image compression on deep learning-based mammogram classification. Scientific Reports <span class="ltx_text ltx_font_bold" id="bib.bib10.1.1">11</span>(1),  7924 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Júnior, J.D.D., Ribeiro, J.B., Backes, A.R.: Assessing the impact of jpeg compression on the semantic segmentation of agricultural images. Signal, Image and Video Processing pp. 1–7 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Landman, B., Xu, Z., Igelsias, J., Styner, M., Langerak, T., Klein, A.: Miccai multi-atlas labeling beyond the cranial vault–workshop and challenge. In: Proc. MICCAI Multi-Atlas Labeling Beyond Cranial Vault—Workshop Challenge. vol. 5, p. 12 (2015)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Liu, F., Hernandez-Cabronero, M., Sanchez, V., Marcellin, M.W., Bilgin, A.: The current role of image compression standards in medical imaging. Information <span class="ltx_text ltx_font_bold" id="bib.bib13.1.1">8</span>(4),  131 (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Menze, B.H., Jakab, A., Bauer, S., Kalpathy-Cramer, J., Farahani, K., Kirby, J., Burren, Y., Porz, N., Slotboom, J., Wiest, R., et al.: The multimodal brain tumor image segmentation benchmark (brats). IEEE transactions on medical imaging <span class="ltx_text ltx_font_bold" id="bib.bib14.1.1">34</span>(10), 1993–2024 (2014)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Zolotova, S.V., Golanov, A.V., Pronin, I.N., Dalechina, A.V., Nikolaeva, A.A., Belyashova, A.S., Usachev, D.Y., Kondrateva, E.A., Druzhinina, P.V., Shirokikh, B.N., Saparov, T.N., Belyaev, M.G., Kurmukov, A.I.: Burdenko’s glioblastoma progression dataset (burdenko-gbm-progression) (2023). https://doi.org/10.7937/E1QP-D183, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.cancerimagingarchive.net/collection/burdenko-gbm-progression/" title="">https://www.cancerimagingarchive.net/collection/burdenko-gbm-progression/</a>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Supplementary materials</h2>
<figure class="ltx_figure" id="Sx1.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="299" id="Sx1.F4.g1" src="extracted/5878414/figures/Supp-amos_2744519_0223_156.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Example image used during human evaluation. Radiologists were asked to decide whether left or right image looks of higher quality (or both looks indistinguishable). CT images were clipped to abdominal, brain, or liver window respectively.</figcaption>
</figure>
<figure class="ltx_figure" id="Sx1.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="479" id="Sx1.F5.g1" src="extracted/5878414/figures/Supp-teaser.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Effect of JPEG2000 compression on images from different experimental datasets.</figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Sep 25 08:26:51 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
