<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2408.06903] Heterogeneity: An Open Challenge for Federated On-board Machine Learning</title><meta property="og:description" content="The design of satellite missions is currently undergoing a paradigm shift from the historical approach of individualised monolithic satellites towards distributed mission configurations, consisting of multiple small sa…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Heterogeneity: An Open Challenge for Federated On-board Machine Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Heterogeneity: An Open Challenge for Federated On-board Machine Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2408.06903">

<!--Generated on Thu Sep  5 15:59:58 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Heterogeneity: An Open Challenge for Federated On-board Machine Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Maria Hartmann
</span><span class="ltx_author_notes">Corresponding author. E-Mail: {firstname.lastname}@uni.lu
<span class="ltx_contact ltx_role_affiliation">SnT, University of Luxembourg, Luxembourg
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Grégoire Danoy
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">SnT, University of Luxembourg, Luxembourg
</span>
<span class="ltx_contact ltx_role_affiliation">FSTM, University of Luxembourg, Luxembourg
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Pascal Bouvry
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">FSTM, University of Luxembourg, Luxembourg
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">The design of satellite missions is currently undergoing a paradigm shift from the historical approach of individualised monolithic satellites towards distributed mission configurations, consisting of multiple small satellites. With a rapidly growing number of such satellites now deployed in orbit, each collecting large amounts of data, interest in on-board orbital edge computing is rising. Federated Learning is a promising distributed computing approach in this context, allowing multiple satellites to collaborate efficiently in training on-board machine learning models. Though recent works on the use of Federated Learning in orbital edge computing have focused largely on homogeneous satellite constellations, Federated Learning could also be employed to allow heterogeneous satellites to form ad-hoc collaborations, e.g.  in the case of communications satellites operated by different providers. Such an application presents additional challenges to the Federated Learning paradigm, arising largely from the heterogeneity of such a system. In this position paper, we offer a systematic review of these challenges in the context of the cross-provider use case, giving a brief overview of the state-of-the-art for each, and providing an entry point for deeper exploration of each issue.</p>
</div>
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\makeCustomtitle</span>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With advances in hardware and software capabilities, distributed satellite mission configurations are progressively replacing the classical paradigm of using a single monolithic spacecraft.
With nanosatellites able to generate and store increasingly large amounts of data through various on-board sensors, downlink capacity is becoming a major bottleneck in processing the gathered information.
To manage this problem, there is an ongoing drive towards shifting data processing onto satellites<cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">izzo2022selected</span>]</cite> – this strategy is referred to as Orbital Edge Computing (OEC)<cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Denby2020</span>]</cite>. The overarching idea of OEC is to leverage on-board computing capabilities of each satellite to process locally gathered data, reducing the size and amount of required transmissions and speeding up evaluation.
A promising variant of OEC proposes deploying Federated Learning <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">McMahan2017</span>]</cite> (FL) on satellites, allowing the joint training of on-board machine learning models across the data gathered by multiple satellites with a limited communication budget <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Jabbarpour2023</span>]</cite>. Under a FL scheme, each satellite performs on-board machine learning on the data it collects, training a local model – see Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Heterogeneity: An Open Challenge for Federated On-board Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. These models are shared periodically among participants, allowing them to be aggregated into a more accurate global model on which to continue training. Aggregation can take place with the aid of a parameter server on the ground or in orbit, or in a fully decentralised manner between satellites. Fundamental advantages of this approach include a vastly reduced communication cost compared to the transmission of raw data, and the inherent privacy advantages of compartmentalising data on satellites.
<br class="ltx_break">Current literature on the use of Federated Learning in Orbital Edge Computing is focused primarily on a single use case: using Federated Learning in a single, dedicated constellation of satellites. However, another frequently occurring scenario appears largely unstudied: the potential for satellites from different missions and providers to form (ad-hoc) cross-provider collaborations.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2408.06903/assets/figures/satellites-models-illustration-new-2.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="296" height="216" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>In Federated Learning, each satellite performs on-board machine learning to train a local model (1). Only these models are transmitted via satellite link to a server (2), here based on the ground, where multiple local models are aggregated into a single global model (3). This global model is transmitted back to the satellites (4) to continue the learning process. If necessary, satellites can act as relays for one another (5).
</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In this position paper, we offer an initial exploration of the conceptual challenges associated with this use case: we identify the characteristics of the problem, present a brief survey of the state of the art for each, connecting existing research from the application domain and the theoretical field, and discuss how existing approaches might fare in this scenario. We conclude with a gap analysis.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Survey results</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we analyse the current state of the art in research relating to our use case of cross-provider FL. As this use case has not yet been addressed explicitly, we divide our analysis into different thematic sections. We begin by considering the research closest to application, considering orbital edge computing (OEC) and Federated learning (FL) schemes tailored to use on satellites. Following this, we discuss cross-provider FL, an OEC use case that has, to the best of our knowledge, not been addressed to date. We explore related research from the field of FL that could be applicable for this use case, particularly works addressing the handling of different types of heterogeneity, and discuss their applicability.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Orbital edge computing and federated learning</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Federated Learning could offer a flexible framework for satellites to collaborate on on-board information processing<cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">izzo2022selected</span>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Chen2022</span>]</cite> while limiting communication cost and preserving data privacy.
Various works modify the FL paradigm for the use case of LEO constellations, mainly focusing on adapted communication schedules to handle the intermittent connectivity of satellites. These approaches can broadly be divided by their proposed placement of a parameter server.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Initial works focused on the use of a ground-based server, offering a relatively higher resource capacity of the server; the drawback is a communication bottleneck caused by the intermittent connectivity of satellites.
The FedSpace algorithm <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">So2022</span>]</cite> attempts to overcome this constraint by performing semi-asynchronous federated aggregation, exploiting knowledge about clients’ orbital periods to calculate an aggregation schedule that yields an optimal trade-off between satellite idleness and model staleness.The FedGSM algorithm<cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Wu2023</span>]</cite> similarly makes use of known connectivity intervals to extrapolate model updates.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">Conversely, FedISL<cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Razmi2022</span>]</cite>, a synchronous FL scheme for a dense LEO constellation, hinges on the strategic placement of a server in medium Earth orbit (MEO); with convergence speed further enhanced by the use of intra-plane inter-satellite links.
This concept is extended in <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Razmi2024</span>]</cite> with the grouping of satellites sharing the same orbit to speed up aggregation. Similarly, the synchronous FedHAP <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Elmahallawy2022</span>]</cite> algorithm is based on the deployment of multiple high-altitude aerial platforms to accelerate aggregation; AsyncFLEO <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Elmahallawy2022b</span>]</cite> rests on the same premise, but is capable of asynchronous aggregation.
The DSFL<cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Wu2022</span>]</cite> algorithm side-steps the challenge of server placement by performing fully decentralised aggregation. Finally, in their work on semi-supervised FL, Östman et al. <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Ostman2023</span>]</cite> compare a decentralised aggregation strategy with two scenarios where a relay satellite and a set of ground stations, respectively, act as the aggregation server. All three variants are shown to achieve comparable accuracy performances with similar total training time and power consumption.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">Note that the works presented in this section do not consider heterogeneity challenges in great depth; several works, e.g. <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">So2022</span>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Razmi2024</span>]</cite>, claim that any suitable FL algorithm could be utilised as a drop-in component. In the following section, we assess the additional characteristics that might be required of an algorithm to mitigate heterogeneity in the cross-provider use case.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Heterogeneity challenges of cross-provider FL</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">With the proliferation of private and commercial missions, an ever-increasing number of satellites with different capabilities and overlapping interests are active in Earth orbit. Enabling an ad-hoc collaboration between satellites of providers with compatible interests could serve to enhance the performance of all sides at a comparatively low communication cost.
A natural example is the application to satellite communication problems: machine learning has the potential to assist with various SatComm-related problems<cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Fourati2021</span>]</cite>, and collaboration between satellites could help solve these problems with greater accuracy and reliability. Many such satellites by different service providers are in operation today, with different hardware, different orbits and different underlying purposes, but nevertheless carrying out related functions. Compared to performing FL on single-mission satellite constellations, this application scenario presents unique challenges induced by the heterogeneity of satellites.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">This could involve many different types of heterogeneity, known to present a challenge to FL algorithms<cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Kairouz2021</span>]</cite>. These include <span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_italic">data heterogeneity</span>, <span id="S2.SS2.p2.1.2" class="ltx_text ltx_font_italic">feature heterogeneity</span>, <span id="S2.SS2.p2.1.3" class="ltx_text ltx_font_italic">device heterogeneity</span>, and <span id="S2.SS2.p2.1.4" class="ltx_text ltx_font_italic">preference heterogeneity</span>. In this section, we discuss the state-of-the-art approaches for each of these types, highlighting how each has been addressed for the OEC use case and, where missing, how existing solutions might transfer to this use case.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p"><span id="S2.SS2.p3.1.1" class="ltx_text ltx_font_bold">Data heterogeneity.</span> This type of heterogeneity, where data is imbalanced across participants, is discussed extensively in the literature<cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Kairouz2021</span>]</cite>, as it occurs naturally in most settings. In our use case, heterogeneous distributions of data across satellites are quite likely, with the extent dependent in part on the precise setting. For example, satellites gathering Earth observation images might collect significantly different samples based on their orbital planes, while for SatComm data might differ based on the role of the satellite or the associated service provider. The general issue of data heterogeneity is discussed in most FL variants proposed for the OEC use case, e.g. <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Wu2022</span>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Wu2023</span>]</cite>; however, their effectiveness is seldom demonstrated beyond preliminary benchmarking experiments.
Therefore, it appears worthwhile to also consider the state of the art in the general field of FL. A taxonomy of variants of data heterogeneity is presented in <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Ye2023</span>]</cite>, along with a comprehensive survey of current mitigation approaches. According to <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Ye2023</span>]</cite>, these can be broadly divided into data-level, model-level and server-level interventions. Data-level approaches involve modifying the underlying training data to balance heterogeneity, e.g. by preprocessing <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Li2021</span>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Xu2023</span>]</cite>, generating supplemental data using Generative Adversarial Networks <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Goodfellow2020</span>]</cite>, or transmitting information about data between clients <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Yoon2021FedMixAO</span>]</cite>. However, these strategies often place a significant additional computing or communication burden on the clients, rendering them unattractive use on satellites. Selected model- and server-level strategies appear more promising, as they either require little additional computation cost, or can be carried out on the server-side. Notably, these include model regularisation <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Kim2022MultiLevelBR</span>]</cite>, knowledge distillation <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Zhu2021</span>]</cite>, and personalised federated learning (PFL) approaches <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Tan2023</span>]</cite> such as client clustering<cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Ghosh2022</span>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Duan2021</span>]</cite>, parameter decoupling <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Arivazhagan2019</span>]</cite> and model interpolation <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Hanzely2020FederatedLO</span>]</cite>.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p">It is difficult to single out an optimal approach for the general version of our use case, where the data distribution pattern is unknown. The most promising approach would likely be an adaptive solution that modifies the aggregation approach during runtime based on observed metrics, e.g. clustering participants by similarity <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Ghosh2022</span>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Duan2021</span>]</cite> or assigning importance weights for aggregation <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Hanzely2020FederatedLO</span>]</cite>. For mission architectures involving a powerful ground-based parameter server, more complex knowledge distillation-based approaches may also be an option.</p>
</div>
<div id="S2.SS2.p5" class="ltx_para">
<p id="S2.SS2.p5.1" class="ltx_p">Finally, we note that if the nature of the data distribution is known, such as in EO imaging missions, this could be exploited to the advantage of the algorithm, e.g. by grouping participants known to collect similar data, or conversely by exchanging small sets of selected samples to balance highly different datasets.</p>
</div>
<div id="S2.SS2.p6" class="ltx_para">
<p id="S2.SS2.p6.1" class="ltx_p"><span id="S2.SS2.p6.1.1" class="ltx_text ltx_font_bold">Device heterogeneity.</span>
Aside from the communication challenges induced by orbital trajectories, satellites in the cross-provider setting would alsohave hardware differences, leading to different levels of noise and training datasets of varying quality, and impacting computational speeds and capabilities. This is a common problem in the general field of FL <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Ye2023</span>]</cite>; standard approaches include adaptively assigning different weight contributions <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Ma2022</span>]</cite> or model architectures <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Diao2020HeteroFLCA</span>]</cite> to participants; possibly also reducing the consideration of lower-quality participants in selecting clients for aggregation <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Li2021b</span>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Nishio2019</span>]</cite>. It appears likely that such strategies would transfer well to the present use case, without a need for major modifications.</p>
</div>
<div id="S2.SS2.p7" class="ltx_para">
<p id="S2.SS2.p7.1" class="ltx_p"><span id="S2.SS2.p7.1.1" class="ltx_text ltx_font_bold">Feature heterogeneity.</span> This setting corresponds to the collaboration of satellites with different types of sensors, collecting different types of data and potentially requiring different model architectures for on-board processing. Effectively integrating different features and models into a coherent federated model training process presents a difficult problem; to the best of our knowledge, it has not yet been tackled in research on OEC. Indeed, the general problem of performing FL in such a setting, known as Vertical Federated Learning (VFL) <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Yang2019</span>]</cite>, remains largely unsolved beyond highly constrained artificial scenarios or costly compensation approaches <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Liu2024</span>]</cite>. This present lack of solutions renders the application of FL to the real-world satellite use case infeasible. The only approach that appears viable at present would involve feature distillation on a ground-station parameter server – a computationally expensive solution that does not yield workable models for the federated participants, and so would benefit only the server-side <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Liu2024</span>]</cite>. Beyond this niche variant, the currently most feasible approach would likely be to separate participants by features, eliminating this type of heterogeneity.</p>
</div>
<div id="S2.SS2.p8" class="ltx_para">
<p id="S2.SS2.p8.1" class="ltx_p"><span id="S2.SS2.p8.1.1" class="ltx_text ltx_font_bold">Preference heterogeneity.</span> This is a novel type of heterogeneity that, as of now, has seen little recognition in the field of federated learning; yet it appears highly relevant to the present use case. Preference heterogeneity arises when participants are solving problems with multiple objectives, e.g. minimising communication cost while also minimising connection latency in a satellite communication network. In such multi-objective problems, different optimal solutions are generally possible, representing different trade-offs between the individual objectives. In practice, some trade-offs may be more desirable than others, e.g. conserving energy by limiting communication for severely resource-constrained satellites, or minimising connection latency to boost service to certain geographical areas. This can be controlled by assigning importance weights to each objective when solving the learning problem. We call participants with different importance weights preference-heterogeneous.</p>
</div>
<div id="S2.SS2.p9" class="ltx_para">
<p id="S2.SS2.p9.1" class="ltx_p">At present, little research has been devoted to performing Federated Learning under preference heterogeneity; the closest related works consider federated multi-task learning <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Smith2017</span>]</cite>, where participants have fully separate objectives, and federated multi-objective learning <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yang_federated_2023</span>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hartmann2023mofld</span>]</cite> without allowance for different preferences.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Other considerations</h3>

<section id="S2.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1 </span>Fairness</h4>

<div id="S2.SS3.SSS1.p1" class="ltx_para">
<p id="S2.SS3.SSS1.p1.1" class="ltx_p">In addition to the technical considerations of the previous section, this cross-provider use case also differs from the
single-provider variant in the assumptions made about participants’ intentions. Satellites designed to collaborate with each other as part of a single mission can generally be assumed to act altruistically in federation, i.e. towards the benefit of the larger system. In the cross-provider setting, however, no such assumption should be made, as has been noted e.g. in <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Razmi2024</span>]</cite>.
Instead, we assume that participants may act ‘selfishly’, valuing their own success over that of the federated system. This could occur e.g.  if satellites contribute low-quality updates, leading to an overall degradation of the global model and benefiting from the collaboration at the cost of others. Similarly, a participant could limit the frequency of its contributions to conserve communication budget or maintain privacy, to the detriment of others in the federation, while still receiving global model updates. A successful cross-provider collaboration scheme should guard against such exploitation. These fairness considerations have yet to be addressed in works targeting the OEC use case; a full survey on the state of the art of general FL approaches is provided in <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Shi2024</span>]</cite>. The same work gives a detailed account of the different definitions of fairness and underlying assumptions; the choice of an appropriate mitigation approach for the present depends on these characteristics.</p>
</div>
</section>
<section id="S2.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.2 </span>Guarding against malicious participants</h4>

<div id="S2.SS3.SSS2.p1" class="ltx_para">
<p id="S2.SS3.SSS2.p1.1" class="ltx_p">This is a more extreme case of the challenges discussed in the previous section – here participants intentionally attempt to sabotage the performance of the federated system through their participation, e.g. through submitting intentionally false model updates (known as model poisoning attacks). A thorough overview of possible attack vectors and approaches for guarding against such attacks is given in <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Kairouz2021</span>]</cite> and more recently <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">RodrguezBarroso2023</span>]</cite>, suggesting e.g. the assignment of confidence scores <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">MunozGonzlez2019ByzantineRobustFM</span>]</cite>, filtering outliers <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Yin2018</span>]</cite>, or normalising model updates before aggregation <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Sun2019</span>]</cite>. A number of these solutions appear to transfer well to the cross-provider OEC use case, given a trustworthy server, with the selection of approach dependent on the particular parameters of the system and the results of a risk analysis.</p>
</div>
</section>
<section id="S2.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.3 </span>The role of standardisation</h4>

<div id="S2.SS3.SSS3.p1" class="ltx_para">
<p id="S2.SS3.SSS3.p1.1" class="ltx_p">Along with the algorithmic approaches towards preventing misuse of the collaboration, standardisation likely has an important role to play in the deployment of FL to the present use case involving multiple providers. This could e.g.  include a requirement for certification of machine learning pipelines in accordance with certain quality standards to obtain access to such federated exchange schemes, to decrease the likelihood of interference by malicious or poorly engineered participants. A review of standards relating to the trustworthiness of machine learning for space applications suggests that such standards largely have yet to be defined <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ILNASWP1</span>]</cite>; a recently published handbook provides a first glimpse of such considerations <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">MLHandbookECSS</span>]</cite>.</p>
</div>
<div id="S2.SS3.SSS3.p2" class="ltx_para">
<p id="S2.SS3.SSS3.p2.1" class="ltx_p">Finally, we note another crucial challenge of this particular use case: the need for a unified communication protocol between participants, capable of negotiating the parameters of the FL scheme between participants and able to transmit machine learning models unambiguously, without interpretation errors caused e.g. by differences in hardware or software. For ad-hoc collaboration, standardised communication formats are of critical importance, both to negotiate the parameters of the FL protocol during the initialisation phase, and to transmit model updates without error. There appears to be no existing solution, as most works in the literature tend to assume a group of satellites collaborating as part of a single unified mission.</p>
</div>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Discussion</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In our analysis of the state of the art, we have seen that current works investigating the use of Federated Learning in satellite on-board edge computing have largely focused on a single scenario: a large constellation of homogeneous satellites deployed as part of a single mission. We have introduced a different use case, relevant to the present or near future, where heterogeneous satellites of multiple different providers could collaborate under a FL scheme to enhance on-board learning. We have elucidated the unique conceptual challenges of this use case, with a focus on the different types of heterogeneity and conflicts of interest that might arise. We have provided a broad perspective of the state of the art for each, discussing both the existing work close to the use case, and the general state of the art in the theoretical literature. Our brief survey shows that several aspects remain to be addressed to adequately solve this real-world use case. In particular, there is a need to further investigate (1) how state-of-the-art solutions can be combined in settings where multiple types of heterogeneity occur simultaneously; (2) which heterogeneity-mitigating algorithms could be selected to fit with the use case, and with existing OEC schemes; (3) how to perform Federated Learning under preference heterogeneity. Finally, we suggest that any engineering approach should be supported by additional measures reducing the complexity of the system by providing appropriate constraints, e.g. through the use of standardisation.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work is partially funded by the joint research programme UL/SnT–ILNAS on Technical Standardisation for Trustworthy ICT, Aerospace, and Construction.</p>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2408.06902" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2408.06903" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2408.06903">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2408.06903" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2408.06904" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Sep  5 15:59:58 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
