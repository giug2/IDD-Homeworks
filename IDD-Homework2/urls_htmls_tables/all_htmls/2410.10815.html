<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Depth Any Video with Scalable Synthetic Data</title>
<!--Generated on Sun Oct 13 16:47:28 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.10815v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S1" title="In Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S2" title="In Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Synthetic Data Workflow</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S3" title="In Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Generative Video Depth Model</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S3.SS1" title="In 3 Generative Video Depth Model â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Model Design</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S3.SS2" title="In 3 Generative Video Depth Model â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Mixed-duration Training Strategy</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S3.SS3" title="In 3 Generative Video Depth Model â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Long Video Inference</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4" title="In Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.SS1" title="In 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Datasets and Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.SS2" title="In 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Implementation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.SS3" title="In 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Zero-shot Depth Estimation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.SS4" title="In 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Ablation Studies</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S5" title="In Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S6" title="In Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">
Depth Any Video with Scalable Synthetic Data
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Honghui Yang<sup class="ltx_sup" id="id7.5.id1">âˆ—</sup>, Di Huang<sup class="ltx_sup" id="id8.6.id2">âˆ—</sup>, Wei Yin, Chunhua Shen, Haifeng Liu
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id4.4.2">Xiaofei He, Binbin Lin<sup class="ltx_sup" id="id4.4.2.1"><span class="ltx_text ltx_font_medium" id="id4.4.2.1.1">â€ </span></sup>, Wanli Ouyang, Tong He<sup class="ltx_sup" id="id4.4.2.2"><span class="ltx_text ltx_font_medium" id="id4.4.2.2.1">â€ </span></sup>
<br class="ltx_break"/></span>
Shanghai AI Laboratory â€ƒZhejiang University â€ƒThe University of Sydney
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id9.id1">Video depth estimation has long been hindered by the scarcity of consistent and scalable ground truth data, leading to inconsistent and unreliable results. In this paper, we introduce <span class="ltx_text ltx_font_bold" id="id9.id1.1">Depth Any Video</span>, a model that tackles the challenge through two key innovations. First, we develop a scalable synthetic data pipeline, capturing real-time video depth data from diverse synthetic environments, yielding 40,000 video clips of 5-second duration, each with precise depth annotations.
Second, we leverage the powerful priors of generative video diffusion models to handle real-world videos effectively, integrating advanced techniques such as rotary position encoding and flow matching to further enhance flexibility and efficiency.
Unlike previous models, which are limited to fixed-length video sequences, our approach introduces a novel mixed-duration training strategy that handles videos of varying lengths and performs robustly across different frame ratesâ€”even on single frames. At inference, we propose a depth interpolation method that enables our model to infer high-resolution video depth across sequences of up to 150 frames.
Our model outperforms all previous generative depth models in terms of spatial accuracy and temporal consistency.
<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><sup class="ltx_sup" id="footnote1.1">âˆ—</sup>Equal contribution.</span></span></span>
<span class="ltx_note ltx_role_footnote" id="footnote1a"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><sup class="ltx_sup" id="footnote1a.1"><span class="ltx_text ltx_font_italic" id="footnote1a.1.1">â€ </span></sup>Corresponding author.</span></span></span></p>
</div>
<div class="ltx_para" id="id6">
<p class="ltx_p ltx_align_center" id="id6.2"><a class="ltx_ref ltx_href" href="https://depthanyvideo.github.io" title=""><math alttext="\tt https" class="ltx_Math" display="inline" id="id5.1.1.m1.1"><semantics id="id5.1.1.m1.1a"><mi id="id5.1.1.m1.1.1" xref="id5.1.1.m1.1.1.cmml">ğš‘ğšğšğš™ğšœ</mi><annotation-xml encoding="MathML-Content" id="id5.1.1.m1.1b"><ci id="id5.1.1.m1.1.1.cmml" xref="id5.1.1.m1.1.1">ğš‘ğšğšğš™ğšœ</ci></annotation-xml><annotation encoding="application/x-tex" id="id5.1.1.m1.1c">\tt https</annotation><annotation encoding="application/x-llamapun" id="id5.1.1.m1.1d">typewriter_https</annotation></semantics></math>://<math alttext="\tt depthanyvideo.github.io" class="ltx_Math" display="inline" id="id6.2.2.m2.3"><semantics id="id6.2.2.m2.3a"><mrow id="id6.2.2.m2.3.4.2" xref="id6.2.2.m2.3.4.1.cmml"><mi id="id6.2.2.m2.1.1" xref="id6.2.2.m2.1.1.cmml">ğšğšğš™ğšğš‘ğšŠğš—ğš¢ğšŸğš’ğšğšğš˜</mi><mo id="id6.2.2.m2.3.4.2.1" lspace="0em" rspace="0.167em" xref="id6.2.2.m2.3.4.1a.cmml">.</mo><mi id="id6.2.2.m2.2.2" xref="id6.2.2.m2.2.2.cmml">ğšğš’ğšğš‘ğšğš‹</mi><mo id="id6.2.2.m2.3.4.2.2" lspace="0em" rspace="0.167em" xref="id6.2.2.m2.3.4.1a.cmml">.</mo><mi id="id6.2.2.m2.3.3" xref="id6.2.2.m2.3.3.cmml">ğš’ğš˜</mi></mrow><annotation-xml encoding="MathML-Content" id="id6.2.2.m2.3b"><apply id="id6.2.2.m2.3.4.1.cmml" xref="id6.2.2.m2.3.4.2"><csymbol cd="ambiguous" id="id6.2.2.m2.3.4.1a.cmml" xref="id6.2.2.m2.3.4.2.1">formulae-sequence</csymbol><ci id="id6.2.2.m2.1.1.cmml" xref="id6.2.2.m2.1.1">ğšğšğš™ğšğš‘ğšŠğš—ğš¢ğšŸğš’ğšğšğš˜</ci><ci id="id6.2.2.m2.2.2.cmml" xref="id6.2.2.m2.2.2">ğšğš’ğšğš‘ğšğš‹</ci><ci id="id6.2.2.m2.3.3.cmml" xref="id6.2.2.m2.3.3">ğš’ğš˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id6.2.2.m2.3c">\tt depthanyvideo.github.io</annotation><annotation encoding="application/x-llamapun" id="id6.2.2.m2.3d">typewriter_depthanyvideo . typewriter_github . typewriter_io</annotation></semantics></math></a></p>
</div>
<figure class="ltx_figure" id="S0.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="763" id="S0.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>We present <span class="ltx_text ltx_font_bold" id="S0.F1.2.1">Depth Any Video</span>, a versatile foundation model supporting both image (top half) and video (bottom half) depth estimation. Derived from Stable Video Diffusion and fine-tuned with diverse and high-quality synthetic data, our model achieves remarkably robust generalization across various real and synthetic unseen scenarios. Additionally, it faithfully captures intricate fine-grained details while ensuring temporal consistency throughout the video.</figcaption>
</figure>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Depth estimation is a foundational problem in understanding the 3D structure of the real world.
The ability to accurately perceive and represent depth in video sequences is crucial for a broad range of applications, including autonomous navigationÂ <cite class="ltx_cite ltx_citemacro_citep">(Borghi etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib5" title="">2017</a>)</cite>, augmented realityÂ <cite class="ltx_cite ltx_citemacro_citep">(Holynski &amp; Kopf, <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib20" title="">2018</a>)</cite>, and advanced video editingÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib60" title="">2024</a>; Peng etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib35" title="">2024</a>)</cite>.
Although recent advancements in single-image depth estimationÂ <cite class="ltx_cite ltx_citemacro_citep">(Ke etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib27" title="">2024</a>; Yang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib51" title="">2024a</a>; Fu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib13" title="">2024</a>; Ranftl etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib37" title="">2021</a>)</cite> have led to significant improvements in spatial accuracy, ensuring temporal consistency across video frames remains a substantial challenge.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">A major bottleneck in existing video depth estimationÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib49" title="">2023</a>; Shao etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib42" title="">2024</a>)</cite> is the lack of diverse and large-scale video depth data that capture the complexity of real-world environments.
Existing datasetsÂ <cite class="ltx_cite ltx_citemacro_citep">(Geiger etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib14" title="">2012</a>; Li etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib29" title="">2023</a>; Karaev etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib25" title="">2023</a>)</cite> are often limited in terms of scale, diversity, and scene variation, making it difficult for models to generalize effectively across different scenarios.
From a hardware perspective, depth sensors like LiDAR, structured light systems, and time-of-flight cameras can provide accurate depth measurements but are often costly, limited in range or resolution, and struggle under specific lighting conditions or when dealing with reflective surfaces.
Another common approachÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib49" title="">2023</a>; Hu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib22" title="">2024b</a>)</cite> is to rely on unlabeled stereo video datasetsÂ <cite class="ltx_cite ltx_citemacro_citep">(Alahari etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib1" title="">2013</a>)</cite> and state-of-the-art stereo-matching methodsÂ <cite class="ltx_cite ltx_citemacro_citep">(Jing etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib24" title="">2024</a>; Xu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib50" title="">2023</a>)</cite>; however, such methods are complex, computationally intensive, and often fail in areas with weak textures. These limitations hinder the development of robust models that can ensure both spatial precision and temporal consistency in dynamic scenes.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To tackle the challenge, in this paper, we propose a solution from two complementary perspectives: (1) constructing a large-scale synthetic video depth dataset and (2) designing a novel framework that leverages powerful visual priors of generative models to effectively handle various real-world videos.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1"><span class="ltx_text ltx_font_bold" id="S1.p4.1.1">Synthetic Data: </span>
Modern video games offer highly realistic graphics and simulate diverse real-world scenarios. For example, car racing games realistically replicate driving environments, while open-world games simulate various complex scenes.
Given that modern rendering pipelines often include depth buffers, it becomes possible to extract large-scale, highly accurate video depth data from synthetic environments, which is scalable and cost-effective.
In light of this, we construct DA-V, a synthetic dataset comprising 40,000 video clips.
DA-V captures a wide range of scenarios, covering various lighting conditions, dynamic camera movements, and intricate object interactions in both indoor and outdoor environments, providing the opportunity for models to generalize effectively to real-world environments.
</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1"><span class="ltx_text ltx_font_bold" id="S1.p5.1.1">Framework: </span>
To complement the dataset, we propose a novel framework for video depth estimation that leverages the rich prior knowledge embedded in video generation models.
Drawing from recent advancementsÂ <cite class="ltx_cite ltx_citemacro_citep">(Ke etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib27" title="">2024</a>)</cite>, we build upon SVDÂ <cite class="ltx_cite ltx_citemacro_citep">(Blattmann etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib3" title="">2023a</a>)</cite> and introduce two key innovations to enhance generalization and efficiency.
First, a mixed-duration training strategy is introduced to simulate videos with varying frame rates and lengths by randomly dropping frames.
To handle videos of different lengths, those with the same duration are grouped into the same batch, and batch sizes are adjusted accordingly, thus optimizing memory usage and improving training efficiency.
Second, a depth interpolation module is proposed, generating intermediate frames conditioned on globally consistent depth estimates from key frames, allowing for high-resolution and coherent inference of long videos under limited computational constraints.
Additionally, we refine the pipeline by introducing a flow-matching approachÂ <cite class="ltx_cite ltx_citemacro_citep">(Lipman etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib30" title="">2023</a>)</cite> and rotary position encodingÂ <cite class="ltx_cite ltx_citemacro_citep">(Su etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib46" title="">2021</a>)</cite> to further improve inference efficiency and flexibility.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">Our contributions can be summarized as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p7">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We introduce a large-scale synthetic dataset of 40,000 video depth clips collected from diverse rendering engines. This is the first dataset to leverage a variety of high-fidelity synthetic environments and to verify its generalization capability in real-world scenarios.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We propose a new training and inference framework that integrates a mixed-duration training strategy and a long-video inference module, enabling the model to handle varying video lengths while ensuring spatial accuracy and temporal consistency.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para ltx_noindent" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Our method achieves state-of-the-art performance among generative depth models, setting a new benchmark for accuracy and robustness in video depth estimation.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Synthetic Data Workflow</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Real-time Data Collection.</span>
To address the challenges of depth data, we collect a large-scale synthetic dataset comprising approximately 40,000 video clips.
A significant portion of this dataset is derived from state-of-the-art synthetic engines, leveraging their ability to generate photorealistic environments with accurate depth information.
We extract depth data from a diverse set of virtual environments, carefully selected to encompass a wide range of scene conditions.
In TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S2.T1" title="Table 1 â€£ 2 Synthetic Data Workflow â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">1</span></a>, we compare our dataset with previous public synthetic datasets. To the best of our knowledge, ours is the largest synthetic video dataset covering a wide range of realistic scenes.</p>
</div>
<figure class="ltx_table ltx_align_floatright" id="S2.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span><span class="ltx_text ltx_font_bold" id="S2.T1.2.1">Comparisons of synthetic datasets</span>.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S2.T1.3" style="width:216.8pt;height:59.2pt;vertical-align:-0.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-157.2pt,42.6pt) scale(0.408072042642556,0.408072042642556) ;">
<table class="ltx_tabular ltx_align_middle" id="S2.T1.3.1">
<tr class="ltx_tr" id="S2.T1.3.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S2.T1.3.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;">Dataset</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.3.1.1.2" style="padding-left:4.0pt;padding-right:4.0pt;">Outdoor</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.3.1.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">Indoor</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.3.1.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">Dynamic</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.3.1.1.5" style="padding-left:4.0pt;padding-right:4.0pt;">Video</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.3.1.1.6" style="padding-left:4.0pt;padding-right:4.0pt;"># Frame</td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.1.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T1.3.1.2.1" style="padding-left:4.0pt;padding-right:4.0pt;">HypersimÂ <cite class="ltx_cite ltx_citemacro_citep">(Roberts etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib38" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.1.2.2" style="padding-left:4.0pt;padding-right:4.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.1.2.3" style="padding-left:4.0pt;padding-right:4.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.1.2.4" style="padding-left:4.0pt;padding-right:4.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.1.2.5" style="padding-left:4.0pt;padding-right:4.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.3.1.2.6" style="padding-left:4.0pt;padding-right:4.0pt;">68K</td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.1.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.3.1.3.1" style="padding-left:4.0pt;padding-right:4.0pt;">MVS-SynthÂ <cite class="ltx_cite ltx_citemacro_citep">(Huang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib23" title="">2018</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.3.2" style="padding-left:4.0pt;padding-right:4.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.3.3" style="padding-left:4.0pt;padding-right:4.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.3.4" style="padding-left:4.0pt;padding-right:4.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.3.5" style="padding-left:4.0pt;padding-right:4.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.3.6" style="padding-left:4.0pt;padding-right:4.0pt;">12K</td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.3.1.4.1" style="padding-left:4.0pt;padding-right:4.0pt;">VKITTIÂ <cite class="ltx_cite ltx_citemacro_citep">(Cabon etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib7" title="">2020</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.4.2" style="padding-left:4.0pt;padding-right:4.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.4.3" style="padding-left:4.0pt;padding-right:4.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.4.4" style="padding-left:4.0pt;padding-right:4.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.4.5" style="padding-left:4.0pt;padding-right:4.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.4.6" style="padding-left:4.0pt;padding-right:4.0pt;">25K</td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.3.1.5.1" style="padding-left:4.0pt;padding-right:4.0pt;">MatrixCityÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib29" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.5.2" style="padding-left:4.0pt;padding-right:4.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.5.3" style="padding-left:4.0pt;padding-right:4.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.5.4" style="padding-left:4.0pt;padding-right:4.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.5.5" style="padding-left:4.0pt;padding-right:4.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.5.6" style="padding-left:4.0pt;padding-right:4.0pt;">519K</td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.1.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.3.1.6.1" style="padding-left:4.0pt;padding-right:4.0pt;">SintelÂ <cite class="ltx_cite ltx_citemacro_citep">(Butler etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib6" title="">2012</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.6.2" style="padding-left:4.0pt;padding-right:4.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.6.3" style="padding-left:4.0pt;padding-right:4.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.6.4" style="padding-left:4.0pt;padding-right:4.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.6.5" style="padding-left:4.0pt;padding-right:4.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.6.6" style="padding-left:4.0pt;padding-right:4.0pt;">1.6K</td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.1.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.3.1.7.1" style="padding-left:4.0pt;padding-right:4.0pt;">DynamicReplicaÂ <cite class="ltx_cite ltx_citemacro_citep">(Karaev etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib25" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.7.2" style="padding-left:4.0pt;padding-right:4.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.7.3" style="padding-left:4.0pt;padding-right:4.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.7.4" style="padding-left:4.0pt;padding-right:4.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.7.5" style="padding-left:4.0pt;padding-right:4.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center" id="S2.T1.3.1.7.6" style="padding-left:4.0pt;padding-right:4.0pt;">169K</td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.1.8">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S2.T1.3.1.8.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.3.1.8.1.1">DA-V (Ours)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.3.1.8.2" style="padding-left:4.0pt;padding-right:4.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.3.1.8.3" style="padding-left:4.0pt;padding-right:4.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.3.1.8.4" style="padding-left:4.0pt;padding-right:4.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.3.1.8.5" style="padding-left:4.0pt;padding-right:4.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.3.1.8.6" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.3.1.8.6.1">6M</span></td>
</tr>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.p2.1.1">Data Filtering.</span>
After collecting initial synthetic video data, occasional misalignments between the image and depth are observed.
To filter these frames, we first employ a scene cut method<span class="ltx_note ltx_role_footnote" id="footnote1b"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://github.com/Breakthrough/PySceneDetect</span></span></span> to detect scene transitions based on significant color changes.
Then, the depth model (detailed in Sec.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S3.SS1" title="3.1 Model Design â€£ 3 Generative Video Depth Model â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">3.1</span></a>), trained on a hand-picked subset of the data, is used to filter out splited video sequences with low depth metric scores.
However, this straightforward approach can lead to excessive filtering of unseen data.
Therefore, we further use a CLIPÂ <cite class="ltx_cite ltx_citemacro_citep">(Radford etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib36" title="">2021</a>)</cite> model to compute semantic similarity between the actual and predicted depth, both colorized from a single channel to three.
Finally, we uniformly sample 10 frames from each video segment.
If both the median semantic and depth metric scores fall below predefined thresholds, the segment is removed.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Generative Video Depth Model</h2>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we introduce Depth Any Video, a generative model designed for robust and consistent video depth estimation.
The model builds upon prior video foundation models, framing video depth estimation as a conditional denoising process (Sec.<a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S3.SS1" title="3.1 Model Design â€£ 3 Generative Video Depth Model â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">3.1</span></a>). A mixed-duration training strategy is then presented to improve model generalization and training efficiency (Sec.<a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S3.SS2" title="3.2 Mixed-duration Training Strategy â€£ 3 Generative Video Depth Model â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">3.2</span></a>).
Finally, we extend the model to estimate high-resolution depth in long videos (Sec.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S3.SS3" title="3.3 Long Video Inference â€£ 3 Generative Video Depth Model â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">3.3</span></a>).</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Model Design</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.6">Our approach builds upon the video foundation model, Stable Video Diffusion (SVD)Â <cite class="ltx_cite ltx_citemacro_citep">(Blattmann etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib3" title="">2023a</a>)</cite>, and reformulates monocular video depth estimation as a generative denoising process.
The overall framework is illustrated in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S3.F2" title="Figure 2 â€£ 3.1 Model Design â€£ 3 Generative Video Depth Model â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">2</span></a>.
The training flow consists of a forward process that gradually corrupts the ground truth video depth <math alttext="x_{d}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><msub id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">x</mi><mi id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">x_{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_x start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> by adding Gaussian noise <math alttext="\epsilon\sim\mathcal{N}(0,I)" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.2"><semantics id="S3.SS1.p1.2.m2.2a"><mrow id="S3.SS1.p1.2.m2.2.3" xref="S3.SS1.p1.2.m2.2.3.cmml"><mi id="S3.SS1.p1.2.m2.2.3.2" xref="S3.SS1.p1.2.m2.2.3.2.cmml">Ïµ</mi><mo id="S3.SS1.p1.2.m2.2.3.1" xref="S3.SS1.p1.2.m2.2.3.1.cmml">âˆ¼</mo><mrow id="S3.SS1.p1.2.m2.2.3.3" xref="S3.SS1.p1.2.m2.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.2.m2.2.3.3.2" xref="S3.SS1.p1.2.m2.2.3.3.2.cmml">ğ’©</mi><mo id="S3.SS1.p1.2.m2.2.3.3.1" xref="S3.SS1.p1.2.m2.2.3.3.1.cmml">â¢</mo><mrow id="S3.SS1.p1.2.m2.2.3.3.3.2" xref="S3.SS1.p1.2.m2.2.3.3.3.1.cmml"><mo id="S3.SS1.p1.2.m2.2.3.3.3.2.1" stretchy="false" xref="S3.SS1.p1.2.m2.2.3.3.3.1.cmml">(</mo><mn id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">0</mn><mo id="S3.SS1.p1.2.m2.2.3.3.3.2.2" xref="S3.SS1.p1.2.m2.2.3.3.3.1.cmml">,</mo><mi id="S3.SS1.p1.2.m2.2.2" xref="S3.SS1.p1.2.m2.2.2.cmml">I</mi><mo id="S3.SS1.p1.2.m2.2.3.3.3.2.3" stretchy="false" xref="S3.SS1.p1.2.m2.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.2b"><apply id="S3.SS1.p1.2.m2.2.3.cmml" xref="S3.SS1.p1.2.m2.2.3"><csymbol cd="latexml" id="S3.SS1.p1.2.m2.2.3.1.cmml" xref="S3.SS1.p1.2.m2.2.3.1">similar-to</csymbol><ci id="S3.SS1.p1.2.m2.2.3.2.cmml" xref="S3.SS1.p1.2.m2.2.3.2">italic-Ïµ</ci><apply id="S3.SS1.p1.2.m2.2.3.3.cmml" xref="S3.SS1.p1.2.m2.2.3.3"><times id="S3.SS1.p1.2.m2.2.3.3.1.cmml" xref="S3.SS1.p1.2.m2.2.3.3.1"></times><ci id="S3.SS1.p1.2.m2.2.3.3.2.cmml" xref="S3.SS1.p1.2.m2.2.3.3.2">ğ’©</ci><interval closure="open" id="S3.SS1.p1.2.m2.2.3.3.3.1.cmml" xref="S3.SS1.p1.2.m2.2.3.3.3.2"><cn id="S3.SS1.p1.2.m2.1.1.cmml" type="integer" xref="S3.SS1.p1.2.m2.1.1">0</cn><ci id="S3.SS1.p1.2.m2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2">ğ¼</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.2c">\epsilon\sim\mathcal{N}(0,I)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.2d">italic_Ïµ âˆ¼ caligraphic_N ( 0 , italic_I )</annotation></semantics></math> and a reverse process that uses a denoising model <math alttext="v_{\theta}" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><msub id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">v</mi><mi id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">ğ‘£</ci><ci id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">v_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_v start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math>, conditioned on the input video <math alttext="x_{c}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><msub id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">x</mi><mi id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">x_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">italic_x start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>, to remove the noise.
Once <math alttext="v_{\theta}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1"><semantics id="S3.SS1.p1.5.m5.1a"><msub id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml">v</mi><mi id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2">ğ‘£</ci><ci id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">v_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m5.1d">italic_v start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math> is trained, the inference flow begins with pure noise <math alttext="\epsilon" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1"><semantics id="S3.SS1.p1.6.m6.1a"><mi id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m6.1d">italic_Ïµ</annotation></semantics></math> and progressively denoises it, moving towards a cleaner result with each step.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.2"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.2.1">Latent Video Condition.</span>
Following prior latent diffusion modelsÂ <cite class="ltx_cite ltx_citemacro_citep">(Rombach etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib39" title="">2022</a>; Esser etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib12" title="">2024</a>)</cite>, the generation process operates within the latent space of a pre-trained variational autoencoder (VAE), allowing the model to handle high-resolution input without sacrificing computational efficiency.
Specifically, given a video depth <math alttext="x_{d}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">x</mi><mi id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">x_{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">italic_x start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, we first apply a normalization as in <cite class="ltx_cite ltx_citemacro_cite">Ke etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib27" title="">2024</a>)</cite> to ensure that depth values fall primarily within the VAEâ€™s input range of <math alttext="[-1,1]" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.2"><semantics id="S3.SS1.p2.2.m2.2a"><mrow id="S3.SS1.p2.2.m2.2.2.1" xref="S3.SS1.p2.2.m2.2.2.2.cmml"><mo id="S3.SS1.p2.2.m2.2.2.1.2" stretchy="false" xref="S3.SS1.p2.2.m2.2.2.2.cmml">[</mo><mrow id="S3.SS1.p2.2.m2.2.2.1.1" xref="S3.SS1.p2.2.m2.2.2.1.1.cmml"><mo id="S3.SS1.p2.2.m2.2.2.1.1a" xref="S3.SS1.p2.2.m2.2.2.1.1.cmml">âˆ’</mo><mn id="S3.SS1.p2.2.m2.2.2.1.1.2" xref="S3.SS1.p2.2.m2.2.2.1.1.2.cmml">1</mn></mrow><mo id="S3.SS1.p2.2.m2.2.2.1.3" xref="S3.SS1.p2.2.m2.2.2.2.cmml">,</mo><mn id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">1</mn><mo id="S3.SS1.p2.2.m2.2.2.1.4" stretchy="false" xref="S3.SS1.p2.2.m2.2.2.2.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.2b"><interval closure="closed" id="S3.SS1.p2.2.m2.2.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2.1"><apply id="S3.SS1.p2.2.m2.2.2.1.1.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1"><minus id="S3.SS1.p2.2.m2.2.2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1"></minus><cn id="S3.SS1.p2.2.m2.2.2.1.1.2.cmml" type="integer" xref="S3.SS1.p2.2.m2.2.2.1.1.2">1</cn></apply><cn id="S3.SS1.p2.2.m2.1.1.cmml" type="integer" xref="S3.SS1.p2.2.m2.1.1">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.2c">[-1,1]</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.2d">[ - 1 , 1 ]</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\tilde{x}_{d}=\left(\frac{x_{d}-d_{2}}{d_{98}-d_{2}}-0.5\right)\times 2," class="ltx_Math" display="block" id="S3.E1.m1.1"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml"><mover accent="true" id="S3.E1.m1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.3.2.2.cmml">x</mi><mo id="S3.E1.m1.1.1.1.1.3.2.1" xref="S3.E1.m1.1.1.1.1.3.2.1.cmml">~</mo></mover><mi id="S3.E1.m1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.3.3.cmml">d</mi></msub><mo id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><mfrac id="S3.E1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml"><msub id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.cmml">x</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2.3.cmml">d</mi></msub><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.1.cmml">âˆ’</mo><msub id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.3.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.3.2.cmml">d</mi><mn id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.3.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.3.3.cmml">2</mn></msub></mrow><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml"><msub id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.2.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.2.2.cmml">d</mi><mn id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.cmml">98</mn></msub><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.1.cmml">âˆ’</mo><msub id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.3.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.3.2.cmml">d</mi><mn id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.3.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.3.3.cmml">2</mn></msub></mrow></mfrac><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mn id="S3.E1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml">0.5</mn></mrow><mo id="S3.E1.m1.1.1.1.1.1.1.1.3" rspace="0.055em" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E1.m1.1.1.1.1.1.2" rspace="0.222em" xref="S3.E1.m1.1.1.1.1.1.2.cmml">Ã—</mo><mn id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.3.cmml">2</mn></mrow></mrow><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"></eq><apply id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3">subscript</csymbol><apply id="S3.E1.m1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2"><ci id="S3.E1.m1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.1">~</ci><ci id="S3.E1.m1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2">ğ‘¥</ci></apply><ci id="S3.E1.m1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3">ğ‘‘</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><times id="S3.E1.m1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.2"></times><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"><minus id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2"><divide id="S3.E1.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2"></divide><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2"><minus id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.1"></minus><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2">ğ‘¥</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2.3">ğ‘‘</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.3.2">ğ‘‘</ci><cn id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.3.3">2</cn></apply></apply><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3"><minus id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.1"></minus><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.2.2">ğ‘‘</ci><cn id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.cmml" type="integer" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3">98</cn></apply><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.3.2">ğ‘‘</ci><cn id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.3.3.cmml" type="integer" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.3.3">2</cn></apply></apply></apply><cn id="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml" type="float" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3">0.5</cn></apply><cn id="S3.E1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.E1.m1.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\tilde{x}_{d}=\left(\frac{x_{d}-d_{2}}{d_{98}-d_{2}}-0.5\right)\times 2,</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.1d">over~ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT = ( divide start_ARG italic_x start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT - italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG start_ARG italic_d start_POSTSUBSCRIPT 98 end_POSTSUBSCRIPT - italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG - 0.5 ) Ã— 2 ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p2.9">where <math alttext="d_{2}" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m1.1"><semantics id="S3.SS1.p2.3.m1.1a"><msub id="S3.SS1.p2.3.m1.1.1" xref="S3.SS1.p2.3.m1.1.1.cmml"><mi id="S3.SS1.p2.3.m1.1.1.2" xref="S3.SS1.p2.3.m1.1.1.2.cmml">d</mi><mn id="S3.SS1.p2.3.m1.1.1.3" xref="S3.SS1.p2.3.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m1.1b"><apply id="S3.SS1.p2.3.m1.1.1.cmml" xref="S3.SS1.p2.3.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m1.1.1.1.cmml" xref="S3.SS1.p2.3.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m1.1.1.2.cmml" xref="S3.SS1.p2.3.m1.1.1.2">ğ‘‘</ci><cn id="S3.SS1.p2.3.m1.1.1.3.cmml" type="integer" xref="S3.SS1.p2.3.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m1.1c">d_{2}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m1.1d">italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="d_{98}" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m2.1"><semantics id="S3.SS1.p2.4.m2.1a"><msub id="S3.SS1.p2.4.m2.1.1" xref="S3.SS1.p2.4.m2.1.1.cmml"><mi id="S3.SS1.p2.4.m2.1.1.2" xref="S3.SS1.p2.4.m2.1.1.2.cmml">d</mi><mn id="S3.SS1.p2.4.m2.1.1.3" xref="S3.SS1.p2.4.m2.1.1.3.cmml">98</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m2.1b"><apply id="S3.SS1.p2.4.m2.1.1.cmml" xref="S3.SS1.p2.4.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m2.1.1.1.cmml" xref="S3.SS1.p2.4.m2.1.1">subscript</csymbol><ci id="S3.SS1.p2.4.m2.1.1.2.cmml" xref="S3.SS1.p2.4.m2.1.1.2">ğ‘‘</ci><cn id="S3.SS1.p2.4.m2.1.1.3.cmml" type="integer" xref="S3.SS1.p2.4.m2.1.1.3">98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m2.1c">d_{98}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m2.1d">italic_d start_POSTSUBSCRIPT 98 end_POSTSUBSCRIPT</annotation></semantics></math> represent the 2% and 98% percentiles of <math alttext="x_{d}" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m3.1"><semantics id="S3.SS1.p2.5.m3.1a"><msub id="S3.SS1.p2.5.m3.1.1" xref="S3.SS1.p2.5.m3.1.1.cmml"><mi id="S3.SS1.p2.5.m3.1.1.2" xref="S3.SS1.p2.5.m3.1.1.2.cmml">x</mi><mi id="S3.SS1.p2.5.m3.1.1.3" xref="S3.SS1.p2.5.m3.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m3.1b"><apply id="S3.SS1.p2.5.m3.1.1.cmml" xref="S3.SS1.p2.5.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m3.1.1.1.cmml" xref="S3.SS1.p2.5.m3.1.1">subscript</csymbol><ci id="S3.SS1.p2.5.m3.1.1.2.cmml" xref="S3.SS1.p2.5.m3.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p2.5.m3.1.1.3.cmml" xref="S3.SS1.p2.5.m3.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m3.1c">x_{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.5.m3.1d">italic_x start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, respectively.
Then, the corresponding latent code is obtained using the encoder <math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="S3.SS1.p2.6.m4.1"><semantics id="S3.SS1.p2.6.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.6.m4.1.1" xref="S3.SS1.p2.6.m4.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m4.1b"><ci id="S3.SS1.p2.6.m4.1.1.cmml" xref="S3.SS1.p2.6.m4.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m4.1c">\mathcal{E}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.6.m4.1d">caligraphic_E</annotation></semantics></math>: <math alttext="z_{d}=\mathcal{E}(\tilde{x}_{d})" class="ltx_Math" display="inline" id="S3.SS1.p2.7.m5.1"><semantics id="S3.SS1.p2.7.m5.1a"><mrow id="S3.SS1.p2.7.m5.1.1" xref="S3.SS1.p2.7.m5.1.1.cmml"><msub id="S3.SS1.p2.7.m5.1.1.3" xref="S3.SS1.p2.7.m5.1.1.3.cmml"><mi id="S3.SS1.p2.7.m5.1.1.3.2" xref="S3.SS1.p2.7.m5.1.1.3.2.cmml">z</mi><mi id="S3.SS1.p2.7.m5.1.1.3.3" xref="S3.SS1.p2.7.m5.1.1.3.3.cmml">d</mi></msub><mo id="S3.SS1.p2.7.m5.1.1.2" xref="S3.SS1.p2.7.m5.1.1.2.cmml">=</mo><mrow id="S3.SS1.p2.7.m5.1.1.1" xref="S3.SS1.p2.7.m5.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.7.m5.1.1.1.3" xref="S3.SS1.p2.7.m5.1.1.1.3.cmml">â„°</mi><mo id="S3.SS1.p2.7.m5.1.1.1.2" xref="S3.SS1.p2.7.m5.1.1.1.2.cmml">â¢</mo><mrow id="S3.SS1.p2.7.m5.1.1.1.1.1" xref="S3.SS1.p2.7.m5.1.1.1.1.1.1.cmml"><mo id="S3.SS1.p2.7.m5.1.1.1.1.1.2" stretchy="false" xref="S3.SS1.p2.7.m5.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.p2.7.m5.1.1.1.1.1.1" xref="S3.SS1.p2.7.m5.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.SS1.p2.7.m5.1.1.1.1.1.1.2" xref="S3.SS1.p2.7.m5.1.1.1.1.1.1.2.cmml"><mi id="S3.SS1.p2.7.m5.1.1.1.1.1.1.2.2" xref="S3.SS1.p2.7.m5.1.1.1.1.1.1.2.2.cmml">x</mi><mo id="S3.SS1.p2.7.m5.1.1.1.1.1.1.2.1" xref="S3.SS1.p2.7.m5.1.1.1.1.1.1.2.1.cmml">~</mo></mover><mi id="S3.SS1.p2.7.m5.1.1.1.1.1.1.3" xref="S3.SS1.p2.7.m5.1.1.1.1.1.1.3.cmml">d</mi></msub><mo id="S3.SS1.p2.7.m5.1.1.1.1.1.3" stretchy="false" xref="S3.SS1.p2.7.m5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m5.1b"><apply id="S3.SS1.p2.7.m5.1.1.cmml" xref="S3.SS1.p2.7.m5.1.1"><eq id="S3.SS1.p2.7.m5.1.1.2.cmml" xref="S3.SS1.p2.7.m5.1.1.2"></eq><apply id="S3.SS1.p2.7.m5.1.1.3.cmml" xref="S3.SS1.p2.7.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m5.1.1.3.1.cmml" xref="S3.SS1.p2.7.m5.1.1.3">subscript</csymbol><ci id="S3.SS1.p2.7.m5.1.1.3.2.cmml" xref="S3.SS1.p2.7.m5.1.1.3.2">ğ‘§</ci><ci id="S3.SS1.p2.7.m5.1.1.3.3.cmml" xref="S3.SS1.p2.7.m5.1.1.3.3">ğ‘‘</ci></apply><apply id="S3.SS1.p2.7.m5.1.1.1.cmml" xref="S3.SS1.p2.7.m5.1.1.1"><times id="S3.SS1.p2.7.m5.1.1.1.2.cmml" xref="S3.SS1.p2.7.m5.1.1.1.2"></times><ci id="S3.SS1.p2.7.m5.1.1.1.3.cmml" xref="S3.SS1.p2.7.m5.1.1.1.3">â„°</ci><apply id="S3.SS1.p2.7.m5.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.7.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m5.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.7.m5.1.1.1.1.1">subscript</csymbol><apply id="S3.SS1.p2.7.m5.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p2.7.m5.1.1.1.1.1.1.2"><ci id="S3.SS1.p2.7.m5.1.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p2.7.m5.1.1.1.1.1.1.2.1">~</ci><ci id="S3.SS1.p2.7.m5.1.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p2.7.m5.1.1.1.1.1.1.2.2">ğ‘¥</ci></apply><ci id="S3.SS1.p2.7.m5.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p2.7.m5.1.1.1.1.1.1.3">ğ‘‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m5.1c">z_{d}=\mathcal{E}(\tilde{x}_{d})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.7.m5.1d">italic_z start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT = caligraphic_E ( over~ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT )</annotation></semantics></math>.
From this latent code, the normalized video depth can then be recovered by the decoder <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S3.SS1.p2.8.m6.1"><semantics id="S3.SS1.p2.8.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.8.m6.1.1" xref="S3.SS1.p2.8.m6.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m6.1b"><ci id="S3.SS1.p2.8.m6.1.1.cmml" xref="S3.SS1.p2.8.m6.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m6.1c">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.8.m6.1d">caligraphic_D</annotation></semantics></math>: <math alttext="\hat{x}_{d}=\mathcal{D}(z_{d})" class="ltx_Math" display="inline" id="S3.SS1.p2.9.m7.1"><semantics id="S3.SS1.p2.9.m7.1a"><mrow id="S3.SS1.p2.9.m7.1.1" xref="S3.SS1.p2.9.m7.1.1.cmml"><msub id="S3.SS1.p2.9.m7.1.1.3" xref="S3.SS1.p2.9.m7.1.1.3.cmml"><mover accent="true" id="S3.SS1.p2.9.m7.1.1.3.2" xref="S3.SS1.p2.9.m7.1.1.3.2.cmml"><mi id="S3.SS1.p2.9.m7.1.1.3.2.2" xref="S3.SS1.p2.9.m7.1.1.3.2.2.cmml">x</mi><mo id="S3.SS1.p2.9.m7.1.1.3.2.1" xref="S3.SS1.p2.9.m7.1.1.3.2.1.cmml">^</mo></mover><mi id="S3.SS1.p2.9.m7.1.1.3.3" xref="S3.SS1.p2.9.m7.1.1.3.3.cmml">d</mi></msub><mo id="S3.SS1.p2.9.m7.1.1.2" xref="S3.SS1.p2.9.m7.1.1.2.cmml">=</mo><mrow id="S3.SS1.p2.9.m7.1.1.1" xref="S3.SS1.p2.9.m7.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.9.m7.1.1.1.3" xref="S3.SS1.p2.9.m7.1.1.1.3.cmml">ğ’Ÿ</mi><mo id="S3.SS1.p2.9.m7.1.1.1.2" xref="S3.SS1.p2.9.m7.1.1.1.2.cmml">â¢</mo><mrow id="S3.SS1.p2.9.m7.1.1.1.1.1" xref="S3.SS1.p2.9.m7.1.1.1.1.1.1.cmml"><mo id="S3.SS1.p2.9.m7.1.1.1.1.1.2" stretchy="false" xref="S3.SS1.p2.9.m7.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.p2.9.m7.1.1.1.1.1.1" xref="S3.SS1.p2.9.m7.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p2.9.m7.1.1.1.1.1.1.2" xref="S3.SS1.p2.9.m7.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.SS1.p2.9.m7.1.1.1.1.1.1.3" xref="S3.SS1.p2.9.m7.1.1.1.1.1.1.3.cmml">d</mi></msub><mo id="S3.SS1.p2.9.m7.1.1.1.1.1.3" stretchy="false" xref="S3.SS1.p2.9.m7.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.9.m7.1b"><apply id="S3.SS1.p2.9.m7.1.1.cmml" xref="S3.SS1.p2.9.m7.1.1"><eq id="S3.SS1.p2.9.m7.1.1.2.cmml" xref="S3.SS1.p2.9.m7.1.1.2"></eq><apply id="S3.SS1.p2.9.m7.1.1.3.cmml" xref="S3.SS1.p2.9.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.9.m7.1.1.3.1.cmml" xref="S3.SS1.p2.9.m7.1.1.3">subscript</csymbol><apply id="S3.SS1.p2.9.m7.1.1.3.2.cmml" xref="S3.SS1.p2.9.m7.1.1.3.2"><ci id="S3.SS1.p2.9.m7.1.1.3.2.1.cmml" xref="S3.SS1.p2.9.m7.1.1.3.2.1">^</ci><ci id="S3.SS1.p2.9.m7.1.1.3.2.2.cmml" xref="S3.SS1.p2.9.m7.1.1.3.2.2">ğ‘¥</ci></apply><ci id="S3.SS1.p2.9.m7.1.1.3.3.cmml" xref="S3.SS1.p2.9.m7.1.1.3.3">ğ‘‘</ci></apply><apply id="S3.SS1.p2.9.m7.1.1.1.cmml" xref="S3.SS1.p2.9.m7.1.1.1"><times id="S3.SS1.p2.9.m7.1.1.1.2.cmml" xref="S3.SS1.p2.9.m7.1.1.1.2"></times><ci id="S3.SS1.p2.9.m7.1.1.1.3.cmml" xref="S3.SS1.p2.9.m7.1.1.1.3">ğ’Ÿ</ci><apply id="S3.SS1.p2.9.m7.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.9.m7.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.9.m7.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.9.m7.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.9.m7.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p2.9.m7.1.1.1.1.1.1.2">ğ‘§</ci><ci id="S3.SS1.p2.9.m7.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p2.9.m7.1.1.1.1.1.1.3">ğ‘‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.9.m7.1c">\hat{x}_{d}=\mathcal{D}(z_{d})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.9.m7.1d">over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT = caligraphic_D ( italic_z start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT )</annotation></semantics></math>.
Unlike the recent advanced 3D VAEÂ <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib53" title="">2024c</a>; OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib34" title="">2024</a>)</cite>, which compresses the input across both temporal and spatial dimensions into the latent code, we focus on compressing only the spatial dimension, as in <cite class="ltx_cite ltx_citemacro_citet">Blattmann etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib3" title="">2023a</a>)</cite>.
This is because temporal compression potentially causes motion blur artifacts when decoding latent depth codes, especially in videos with fast motion (detailed in Sec.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.SS4" title="4.4 Ablation Studies â€£ 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">4.4</span></a>).</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.5">To condition the denoiser <math alttext="v_{\theta}" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><msub id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">v</mi><mi id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">ğ‘£</ci><ci id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">v_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">italic_v start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math> on the input video, we first transform the video <math alttext="x_{c}" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m2.1"><semantics id="S3.SS1.p3.2.m2.1a"><msub id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2" xref="S3.SS1.p3.2.m2.1.1.2.cmml">x</mi><mi id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">x_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> into latent space as <math alttext="z_{c}=\mathcal{E}(x_{c})" class="ltx_Math" display="inline" id="S3.SS1.p3.3.m3.1"><semantics id="S3.SS1.p3.3.m3.1a"><mrow id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><msub id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml"><mi id="S3.SS1.p3.3.m3.1.1.3.2" xref="S3.SS1.p3.3.m3.1.1.3.2.cmml">z</mi><mi id="S3.SS1.p3.3.m3.1.1.3.3" xref="S3.SS1.p3.3.m3.1.1.3.3.cmml">c</mi></msub><mo id="S3.SS1.p3.3.m3.1.1.2" xref="S3.SS1.p3.3.m3.1.1.2.cmml">=</mo><mrow id="S3.SS1.p3.3.m3.1.1.1" xref="S3.SS1.p3.3.m3.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.3.m3.1.1.1.3" xref="S3.SS1.p3.3.m3.1.1.1.3.cmml">â„°</mi><mo id="S3.SS1.p3.3.m3.1.1.1.2" xref="S3.SS1.p3.3.m3.1.1.1.2.cmml">â¢</mo><mrow id="S3.SS1.p3.3.m3.1.1.1.1.1" xref="S3.SS1.p3.3.m3.1.1.1.1.1.1.cmml"><mo id="S3.SS1.p3.3.m3.1.1.1.1.1.2" stretchy="false" xref="S3.SS1.p3.3.m3.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.p3.3.m3.1.1.1.1.1.1" xref="S3.SS1.p3.3.m3.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p3.3.m3.1.1.1.1.1.1.2" xref="S3.SS1.p3.3.m3.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS1.p3.3.m3.1.1.1.1.1.1.3" xref="S3.SS1.p3.3.m3.1.1.1.1.1.1.3.cmml">c</mi></msub><mo id="S3.SS1.p3.3.m3.1.1.1.1.1.3" stretchy="false" xref="S3.SS1.p3.3.m3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><eq id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2"></eq><apply id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.3.1.cmml" xref="S3.SS1.p3.3.m3.1.1.3">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.3.2.cmml" xref="S3.SS1.p3.3.m3.1.1.3.2">ğ‘§</ci><ci id="S3.SS1.p3.3.m3.1.1.3.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3.3">ğ‘</ci></apply><apply id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1.1"><times id="S3.SS1.p3.3.m3.1.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.1.2"></times><ci id="S3.SS1.p3.3.m3.1.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.1.3">â„°</ci><apply id="S3.SS1.p3.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p3.3.m3.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.1.1.1.1.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">z_{c}=\mathcal{E}(x_{c})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.3.m3.1d">italic_z start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = caligraphic_E ( italic_x start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT )</annotation></semantics></math>.
Then, <math alttext="z_{c}" class="ltx_Math" display="inline" id="S3.SS1.p3.4.m4.1"><semantics id="S3.SS1.p3.4.m4.1a"><msub id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml"><mi id="S3.SS1.p3.4.m4.1.1.2" xref="S3.SS1.p3.4.m4.1.1.2.cmml">z</mi><mi id="S3.SS1.p3.4.m4.1.1.3" xref="S3.SS1.p3.4.m4.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><apply id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.4.m4.1.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p3.4.m4.1.1.2.cmml" xref="S3.SS1.p3.4.m4.1.1.2">ğ‘§</ci><ci id="S3.SS1.p3.4.m4.1.1.3.cmml" xref="S3.SS1.p3.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">z_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.4.m4.1d">italic_z start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> is concatenated with the latent depth code <math alttext="z_{d}" class="ltx_Math" display="inline" id="S3.SS1.p3.5.m5.1"><semantics id="S3.SS1.p3.5.m5.1a"><msub id="S3.SS1.p3.5.m5.1.1" xref="S3.SS1.p3.5.m5.1.1.cmml"><mi id="S3.SS1.p3.5.m5.1.1.2" xref="S3.SS1.p3.5.m5.1.1.2.cmml">z</mi><mi id="S3.SS1.p3.5.m5.1.1.3" xref="S3.SS1.p3.5.m5.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.1b"><apply id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.1.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p3.5.m5.1.1.2.cmml" xref="S3.SS1.p3.5.m5.1.1.2">ğ‘§</ci><ci id="S3.SS1.p3.5.m5.1.1.3.cmml" xref="S3.SS1.p3.5.m5.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.1c">z_{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.5.m5.1d">italic_z start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> frame by frame to form the input for the denoiser.
Unlike SVD, we remove the CLIP embedding condition and replace it with a zero embedding, as we find it has minimal impact on performance.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="204" id="S3.F2.g1" src="extracted/5923385/figure/struct.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span class="ltx_text ltx_font_bold" id="S3.F2.20.1">The overall architecture</span>. The input video <math alttext="x_{c}" class="ltx_Math" display="inline" id="S3.F2.9.m1.1"><semantics id="S3.F2.9.m1.1b"><msub id="S3.F2.9.m1.1.1" xref="S3.F2.9.m1.1.1.cmml"><mi id="S3.F2.9.m1.1.1.2" xref="S3.F2.9.m1.1.1.2.cmml">x</mi><mi id="S3.F2.9.m1.1.1.3" xref="S3.F2.9.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.9.m1.1c"><apply id="S3.F2.9.m1.1.1.cmml" xref="S3.F2.9.m1.1.1"><csymbol cd="ambiguous" id="S3.F2.9.m1.1.1.1.cmml" xref="S3.F2.9.m1.1.1">subscript</csymbol><ci id="S3.F2.9.m1.1.1.2.cmml" xref="S3.F2.9.m1.1.1.2">ğ‘¥</ci><ci id="S3.F2.9.m1.1.1.3.cmml" xref="S3.F2.9.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.9.m1.1d">x_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.F2.9.m1.1e">italic_x start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> and depth <math alttext="x_{d}" class="ltx_Math" display="inline" id="S3.F2.10.m2.1"><semantics id="S3.F2.10.m2.1b"><msub id="S3.F2.10.m2.1.1" xref="S3.F2.10.m2.1.1.cmml"><mi id="S3.F2.10.m2.1.1.2" xref="S3.F2.10.m2.1.1.2.cmml">x</mi><mi id="S3.F2.10.m2.1.1.3" xref="S3.F2.10.m2.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.10.m2.1c"><apply id="S3.F2.10.m2.1.1.cmml" xref="S3.F2.10.m2.1.1"><csymbol cd="ambiguous" id="S3.F2.10.m2.1.1.1.cmml" xref="S3.F2.10.m2.1.1">subscript</csymbol><ci id="S3.F2.10.m2.1.1.2.cmml" xref="S3.F2.10.m2.1.1.2">ğ‘¥</ci><ci id="S3.F2.10.m2.1.1.3.cmml" xref="S3.F2.10.m2.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.10.m2.1d">x_{d}</annotation><annotation encoding="application/x-llamapun" id="S3.F2.10.m2.1e">italic_x start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> are first encoded into latent space using a pretrained latent encoder <math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="S3.F2.11.m3.1"><semantics id="S3.F2.11.m3.1b"><mi class="ltx_font_mathcaligraphic" id="S3.F2.11.m3.1.1" xref="S3.F2.11.m3.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S3.F2.11.m3.1c"><ci id="S3.F2.11.m3.1.1.cmml" xref="S3.F2.11.m3.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.11.m3.1d">\mathcal{E}</annotation><annotation encoding="application/x-llamapun" id="S3.F2.11.m3.1e">caligraphic_E</annotation></semantics></math>. During training, Gaussian noise <math alttext="\epsilon" class="ltx_Math" display="inline" id="S3.F2.12.m4.1"><semantics id="S3.F2.12.m4.1b"><mi id="S3.F2.12.m4.1.1" xref="S3.F2.12.m4.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S3.F2.12.m4.1c"><ci id="S3.F2.12.m4.1.1.cmml" xref="S3.F2.12.m4.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.12.m4.1d">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S3.F2.12.m4.1e">italic_Ïµ</annotation></semantics></math> is added to the latent depth in a forward process, while a denoising model <math alttext="v_{\theta}" class="ltx_Math" display="inline" id="S3.F2.13.m5.1"><semantics id="S3.F2.13.m5.1b"><msub id="S3.F2.13.m5.1.1" xref="S3.F2.13.m5.1.1.cmml"><mi id="S3.F2.13.m5.1.1.2" xref="S3.F2.13.m5.1.1.2.cmml">v</mi><mi id="S3.F2.13.m5.1.1.3" xref="S3.F2.13.m5.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.13.m5.1c"><apply id="S3.F2.13.m5.1.1.cmml" xref="S3.F2.13.m5.1.1"><csymbol cd="ambiguous" id="S3.F2.13.m5.1.1.1.cmml" xref="S3.F2.13.m5.1.1">subscript</csymbol><ci id="S3.F2.13.m5.1.1.2.cmml" xref="S3.F2.13.m5.1.1.2">ğ‘£</ci><ci id="S3.F2.13.m5.1.1.3.cmml" xref="S3.F2.13.m5.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.13.m5.1d">v_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.F2.13.m5.1e">italic_v start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math>, conditioned on the latent video <math alttext="z_{c}" class="ltx_Math" display="inline" id="S3.F2.14.m6.1"><semantics id="S3.F2.14.m6.1b"><msub id="S3.F2.14.m6.1.1" xref="S3.F2.14.m6.1.1.cmml"><mi id="S3.F2.14.m6.1.1.2" xref="S3.F2.14.m6.1.1.2.cmml">z</mi><mi id="S3.F2.14.m6.1.1.3" xref="S3.F2.14.m6.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.14.m6.1c"><apply id="S3.F2.14.m6.1.1.cmml" xref="S3.F2.14.m6.1.1"><csymbol cd="ambiguous" id="S3.F2.14.m6.1.1.1.cmml" xref="S3.F2.14.m6.1.1">subscript</csymbol><ci id="S3.F2.14.m6.1.1.2.cmml" xref="S3.F2.14.m6.1.1.2">ğ‘§</ci><ci id="S3.F2.14.m6.1.1.3.cmml" xref="S3.F2.14.m6.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.14.m6.1d">z_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.F2.14.m6.1e">italic_z start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>, removes the noise in a reverse process. After training, the inference flow begins with pure noise, progressively denoises it, and then uses a latent decoder <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S3.F2.15.m7.1"><semantics id="S3.F2.15.m7.1b"><mi class="ltx_font_mathcaligraphic" id="S3.F2.15.m7.1.1" xref="S3.F2.15.m7.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S3.F2.15.m7.1c"><ci id="S3.F2.15.m7.1.1.cmml" xref="S3.F2.15.m7.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.15.m7.1d">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S3.F2.15.m7.1e">caligraphic_D</annotation></semantics></math> to transform it into the prediction depth <math alttext="\hat{x}_{d}" class="ltx_Math" display="inline" id="S3.F2.16.m8.1"><semantics id="S3.F2.16.m8.1b"><msub id="S3.F2.16.m8.1.1" xref="S3.F2.16.m8.1.1.cmml"><mover accent="true" id="S3.F2.16.m8.1.1.2" xref="S3.F2.16.m8.1.1.2.cmml"><mi id="S3.F2.16.m8.1.1.2.2" xref="S3.F2.16.m8.1.1.2.2.cmml">x</mi><mo id="S3.F2.16.m8.1.1.2.1" xref="S3.F2.16.m8.1.1.2.1.cmml">^</mo></mover><mi id="S3.F2.16.m8.1.1.3" xref="S3.F2.16.m8.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.16.m8.1c"><apply id="S3.F2.16.m8.1.1.cmml" xref="S3.F2.16.m8.1.1"><csymbol cd="ambiguous" id="S3.F2.16.m8.1.1.1.cmml" xref="S3.F2.16.m8.1.1">subscript</csymbol><apply id="S3.F2.16.m8.1.1.2.cmml" xref="S3.F2.16.m8.1.1.2"><ci id="S3.F2.16.m8.1.1.2.1.cmml" xref="S3.F2.16.m8.1.1.2.1">^</ci><ci id="S3.F2.16.m8.1.1.2.2.cmml" xref="S3.F2.16.m8.1.1.2.2">ğ‘¥</ci></apply><ci id="S3.F2.16.m8.1.1.3.cmml" xref="S3.F2.16.m8.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.16.m8.1d">\hat{x}_{d}</annotation><annotation encoding="application/x-llamapun" id="S3.F2.16.m8.1e">over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> with the original resolution.
Besides, the pipeline incorporates a mixed-duration training strategy: <span class="ltx_text ltx_font_bold" id="S3.F2.21.2">(a) frame dropout</span> and <span class="ltx_text ltx_font_bold" id="S3.F2.22.3">(b) video packing</span> to enhance model generalization and training efficiency.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.2"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.2.1">Conditional Flow Matching.</span>
To accelerate the denoising process, we replace the original EDM frameworkÂ <cite class="ltx_cite ltx_citemacro_citep">(Karras etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib26" title="">2022</a>)</cite> in SVD with conditional flow matchingÂ <cite class="ltx_cite ltx_citemacro_citep">(Lipman etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib30" title="">2023</a>)</cite>, which achieves satisfactory results in just 1 step, compared to the original 25 steps.
Concretely, the data corruption in our framework is formulated as a linear interpolation between Gaussian noise <math alttext="\epsilon\sim\mathcal{N}(0,I)" class="ltx_Math" display="inline" id="S3.SS1.p4.1.m1.2"><semantics id="S3.SS1.p4.1.m1.2a"><mrow id="S3.SS1.p4.1.m1.2.3" xref="S3.SS1.p4.1.m1.2.3.cmml"><mi id="S3.SS1.p4.1.m1.2.3.2" xref="S3.SS1.p4.1.m1.2.3.2.cmml">Ïµ</mi><mo id="S3.SS1.p4.1.m1.2.3.1" xref="S3.SS1.p4.1.m1.2.3.1.cmml">âˆ¼</mo><mrow id="S3.SS1.p4.1.m1.2.3.3" xref="S3.SS1.p4.1.m1.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.1.m1.2.3.3.2" xref="S3.SS1.p4.1.m1.2.3.3.2.cmml">ğ’©</mi><mo id="S3.SS1.p4.1.m1.2.3.3.1" xref="S3.SS1.p4.1.m1.2.3.3.1.cmml">â¢</mo><mrow id="S3.SS1.p4.1.m1.2.3.3.3.2" xref="S3.SS1.p4.1.m1.2.3.3.3.1.cmml"><mo id="S3.SS1.p4.1.m1.2.3.3.3.2.1" stretchy="false" xref="S3.SS1.p4.1.m1.2.3.3.3.1.cmml">(</mo><mn id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">0</mn><mo id="S3.SS1.p4.1.m1.2.3.3.3.2.2" xref="S3.SS1.p4.1.m1.2.3.3.3.1.cmml">,</mo><mi id="S3.SS1.p4.1.m1.2.2" xref="S3.SS1.p4.1.m1.2.2.cmml">I</mi><mo id="S3.SS1.p4.1.m1.2.3.3.3.2.3" stretchy="false" xref="S3.SS1.p4.1.m1.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.2b"><apply id="S3.SS1.p4.1.m1.2.3.cmml" xref="S3.SS1.p4.1.m1.2.3"><csymbol cd="latexml" id="S3.SS1.p4.1.m1.2.3.1.cmml" xref="S3.SS1.p4.1.m1.2.3.1">similar-to</csymbol><ci id="S3.SS1.p4.1.m1.2.3.2.cmml" xref="S3.SS1.p4.1.m1.2.3.2">italic-Ïµ</ci><apply id="S3.SS1.p4.1.m1.2.3.3.cmml" xref="S3.SS1.p4.1.m1.2.3.3"><times id="S3.SS1.p4.1.m1.2.3.3.1.cmml" xref="S3.SS1.p4.1.m1.2.3.3.1"></times><ci id="S3.SS1.p4.1.m1.2.3.3.2.cmml" xref="S3.SS1.p4.1.m1.2.3.3.2">ğ’©</ci><interval closure="open" id="S3.SS1.p4.1.m1.2.3.3.3.1.cmml" xref="S3.SS1.p4.1.m1.2.3.3.3.2"><cn id="S3.SS1.p4.1.m1.1.1.cmml" type="integer" xref="S3.SS1.p4.1.m1.1.1">0</cn><ci id="S3.SS1.p4.1.m1.2.2.cmml" xref="S3.SS1.p4.1.m1.2.2">ğ¼</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.2c">\epsilon\sim\mathcal{N}(0,I)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.1.m1.2d">italic_Ïµ âˆ¼ caligraphic_N ( 0 , italic_I )</annotation></semantics></math> and data <math alttext="x\sim p(x)" class="ltx_Math" display="inline" id="S3.SS1.p4.2.m2.1"><semantics id="S3.SS1.p4.2.m2.1a"><mrow id="S3.SS1.p4.2.m2.1.2" xref="S3.SS1.p4.2.m2.1.2.cmml"><mi id="S3.SS1.p4.2.m2.1.2.2" xref="S3.SS1.p4.2.m2.1.2.2.cmml">x</mi><mo id="S3.SS1.p4.2.m2.1.2.1" xref="S3.SS1.p4.2.m2.1.2.1.cmml">âˆ¼</mo><mrow id="S3.SS1.p4.2.m2.1.2.3" xref="S3.SS1.p4.2.m2.1.2.3.cmml"><mi id="S3.SS1.p4.2.m2.1.2.3.2" xref="S3.SS1.p4.2.m2.1.2.3.2.cmml">p</mi><mo id="S3.SS1.p4.2.m2.1.2.3.1" xref="S3.SS1.p4.2.m2.1.2.3.1.cmml">â¢</mo><mrow id="S3.SS1.p4.2.m2.1.2.3.3.2" xref="S3.SS1.p4.2.m2.1.2.3.cmml"><mo id="S3.SS1.p4.2.m2.1.2.3.3.2.1" stretchy="false" xref="S3.SS1.p4.2.m2.1.2.3.cmml">(</mo><mi id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml">x</mi><mo id="S3.SS1.p4.2.m2.1.2.3.3.2.2" stretchy="false" xref="S3.SS1.p4.2.m2.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><apply id="S3.SS1.p4.2.m2.1.2.cmml" xref="S3.SS1.p4.2.m2.1.2"><csymbol cd="latexml" id="S3.SS1.p4.2.m2.1.2.1.cmml" xref="S3.SS1.p4.2.m2.1.2.1">similar-to</csymbol><ci id="S3.SS1.p4.2.m2.1.2.2.cmml" xref="S3.SS1.p4.2.m2.1.2.2">ğ‘¥</ci><apply id="S3.SS1.p4.2.m2.1.2.3.cmml" xref="S3.SS1.p4.2.m2.1.2.3"><times id="S3.SS1.p4.2.m2.1.2.3.1.cmml" xref="S3.SS1.p4.2.m2.1.2.3.1"></times><ci id="S3.SS1.p4.2.m2.1.2.3.2.cmml" xref="S3.SS1.p4.2.m2.1.2.3.2">ğ‘</ci><ci id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">ğ‘¥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">x\sim p(x)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.2.m2.1d">italic_x âˆ¼ italic_p ( italic_x )</annotation></semantics></math> along a straight line:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\phi_{t}(x)=tx+\left(1-t\right)\epsilon," class="ltx_Math" display="block" id="S3.E2.m1.2"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.3" xref="S3.E2.m1.2.2.1.1.3.cmml"><msub id="S3.E2.m1.2.2.1.1.3.2" xref="S3.E2.m1.2.2.1.1.3.2.cmml"><mi id="S3.E2.m1.2.2.1.1.3.2.2" xref="S3.E2.m1.2.2.1.1.3.2.2.cmml">Ï•</mi><mi id="S3.E2.m1.2.2.1.1.3.2.3" xref="S3.E2.m1.2.2.1.1.3.2.3.cmml">t</mi></msub><mo id="S3.E2.m1.2.2.1.1.3.1" xref="S3.E2.m1.2.2.1.1.3.1.cmml">â¢</mo><mrow id="S3.E2.m1.2.2.1.1.3.3.2" xref="S3.E2.m1.2.2.1.1.3.cmml"><mo id="S3.E2.m1.2.2.1.1.3.3.2.1" stretchy="false" xref="S3.E2.m1.2.2.1.1.3.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">x</mi><mo id="S3.E2.m1.2.2.1.1.3.3.2.2" stretchy="false" xref="S3.E2.m1.2.2.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.2.2.1.1.2" xref="S3.E2.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1.1" xref="S3.E2.m1.2.2.1.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.3.cmml"><mi id="S3.E2.m1.2.2.1.1.1.3.2" xref="S3.E2.m1.2.2.1.1.1.3.2.cmml">t</mi><mo id="S3.E2.m1.2.2.1.1.1.3.1" xref="S3.E2.m1.2.2.1.1.1.3.1.cmml">â¢</mo><mi id="S3.E2.m1.2.2.1.1.1.3.3" xref="S3.E2.m1.2.2.1.1.1.3.3.cmml">x</mi></mrow><mo id="S3.E2.m1.2.2.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.2.cmml">+</mo><mrow id="S3.E2.m1.2.2.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml"><mn id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.cmml">t</mi></mrow><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E2.m1.2.2.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.2.cmml">â¢</mo><mi id="S3.E2.m1.2.2.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.3.cmml">Ïµ</mi></mrow></mrow></mrow><mo id="S3.E2.m1.2.2.1.2" xref="S3.E2.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1"><eq id="S3.E2.m1.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2"></eq><apply id="S3.E2.m1.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.3"><times id="S3.E2.m1.2.2.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3.1"></times><apply id="S3.E2.m1.2.2.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3.2.1.cmml" xref="S3.E2.m1.2.2.1.1.3.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.3.2.2.cmml" xref="S3.E2.m1.2.2.1.1.3.2.2">italic-Ï•</ci><ci id="S3.E2.m1.2.2.1.1.3.2.3.cmml" xref="S3.E2.m1.2.2.1.1.3.2.3">ğ‘¡</ci></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">ğ‘¥</ci></apply><apply id="S3.E2.m1.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1"><plus id="S3.E2.m1.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.2"></plus><apply id="S3.E2.m1.2.2.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.3"><times id="S3.E2.m1.2.2.1.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.3.1"></times><ci id="S3.E2.m1.2.2.1.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.3.2">ğ‘¡</ci><ci id="S3.E2.m1.2.2.1.1.1.3.3.cmml" xref="S3.E2.m1.2.2.1.1.1.3.3">ğ‘¥</ci></apply><apply id="S3.E2.m1.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1"><times id="S3.E2.m1.2.2.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.2"></times><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1"><minus id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1"></minus><cn id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml" type="integer" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2">1</cn><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><ci id="S3.E2.m1.2.2.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3">italic-Ïµ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">\phi_{t}(x)=tx+\left(1-t\right)\epsilon,</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.2d">italic_Ï• start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x ) = italic_t italic_x + ( 1 - italic_t ) italic_Ïµ ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p4.4">where <math alttext="\phi_{t}(x)" class="ltx_Math" display="inline" id="S3.SS1.p4.3.m1.1"><semantics id="S3.SS1.p4.3.m1.1a"><mrow id="S3.SS1.p4.3.m1.1.2" xref="S3.SS1.p4.3.m1.1.2.cmml"><msub id="S3.SS1.p4.3.m1.1.2.2" xref="S3.SS1.p4.3.m1.1.2.2.cmml"><mi id="S3.SS1.p4.3.m1.1.2.2.2" xref="S3.SS1.p4.3.m1.1.2.2.2.cmml">Ï•</mi><mi id="S3.SS1.p4.3.m1.1.2.2.3" xref="S3.SS1.p4.3.m1.1.2.2.3.cmml">t</mi></msub><mo id="S3.SS1.p4.3.m1.1.2.1" xref="S3.SS1.p4.3.m1.1.2.1.cmml">â¢</mo><mrow id="S3.SS1.p4.3.m1.1.2.3.2" xref="S3.SS1.p4.3.m1.1.2.cmml"><mo id="S3.SS1.p4.3.m1.1.2.3.2.1" stretchy="false" xref="S3.SS1.p4.3.m1.1.2.cmml">(</mo><mi id="S3.SS1.p4.3.m1.1.1" xref="S3.SS1.p4.3.m1.1.1.cmml">x</mi><mo id="S3.SS1.p4.3.m1.1.2.3.2.2" stretchy="false" xref="S3.SS1.p4.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m1.1b"><apply id="S3.SS1.p4.3.m1.1.2.cmml" xref="S3.SS1.p4.3.m1.1.2"><times id="S3.SS1.p4.3.m1.1.2.1.cmml" xref="S3.SS1.p4.3.m1.1.2.1"></times><apply id="S3.SS1.p4.3.m1.1.2.2.cmml" xref="S3.SS1.p4.3.m1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p4.3.m1.1.2.2.1.cmml" xref="S3.SS1.p4.3.m1.1.2.2">subscript</csymbol><ci id="S3.SS1.p4.3.m1.1.2.2.2.cmml" xref="S3.SS1.p4.3.m1.1.2.2.2">italic-Ï•</ci><ci id="S3.SS1.p4.3.m1.1.2.2.3.cmml" xref="S3.SS1.p4.3.m1.1.2.2.3">ğ‘¡</ci></apply><ci id="S3.SS1.p4.3.m1.1.1.cmml" xref="S3.SS1.p4.3.m1.1.1">ğ‘¥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m1.1c">\phi_{t}(x)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.3.m1.1d">italic_Ï• start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x )</annotation></semantics></math> represents the corrupted data, with <math alttext="t\in[0,1]" class="ltx_Math" display="inline" id="S3.SS1.p4.4.m2.2"><semantics id="S3.SS1.p4.4.m2.2a"><mrow id="S3.SS1.p4.4.m2.2.3" xref="S3.SS1.p4.4.m2.2.3.cmml"><mi id="S3.SS1.p4.4.m2.2.3.2" xref="S3.SS1.p4.4.m2.2.3.2.cmml">t</mi><mo id="S3.SS1.p4.4.m2.2.3.1" xref="S3.SS1.p4.4.m2.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS1.p4.4.m2.2.3.3.2" xref="S3.SS1.p4.4.m2.2.3.3.1.cmml"><mo id="S3.SS1.p4.4.m2.2.3.3.2.1" stretchy="false" xref="S3.SS1.p4.4.m2.2.3.3.1.cmml">[</mo><mn id="S3.SS1.p4.4.m2.1.1" xref="S3.SS1.p4.4.m2.1.1.cmml">0</mn><mo id="S3.SS1.p4.4.m2.2.3.3.2.2" xref="S3.SS1.p4.4.m2.2.3.3.1.cmml">,</mo><mn id="S3.SS1.p4.4.m2.2.2" xref="S3.SS1.p4.4.m2.2.2.cmml">1</mn><mo id="S3.SS1.p4.4.m2.2.3.3.2.3" stretchy="false" xref="S3.SS1.p4.4.m2.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m2.2b"><apply id="S3.SS1.p4.4.m2.2.3.cmml" xref="S3.SS1.p4.4.m2.2.3"><in id="S3.SS1.p4.4.m2.2.3.1.cmml" xref="S3.SS1.p4.4.m2.2.3.1"></in><ci id="S3.SS1.p4.4.m2.2.3.2.cmml" xref="S3.SS1.p4.4.m2.2.3.2">ğ‘¡</ci><interval closure="closed" id="S3.SS1.p4.4.m2.2.3.3.1.cmml" xref="S3.SS1.p4.4.m2.2.3.3.2"><cn id="S3.SS1.p4.4.m2.1.1.cmml" type="integer" xref="S3.SS1.p4.4.m2.1.1">0</cn><cn id="S3.SS1.p4.4.m2.2.2.cmml" type="integer" xref="S3.SS1.p4.4.m2.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m2.2c">t\in[0,1]</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.4.m2.2d">italic_t âˆˆ [ 0 , 1 ]</annotation></semantics></math> as the time-dependent interpolation factor.
This formulation implies a uniform transformation with constant velocity between data and noise.
The corresponding time-dependent velocity field, moving from noise to data, is given by:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="v_{t}(x)=x-\epsilon." class="ltx_Math" display="block" id="S3.E3.m1.2"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2.1" xref="S3.E3.m1.2.2.1.1.cmml"><mrow id="S3.E3.m1.2.2.1.1" xref="S3.E3.m1.2.2.1.1.cmml"><mrow id="S3.E3.m1.2.2.1.1.2" xref="S3.E3.m1.2.2.1.1.2.cmml"><msub id="S3.E3.m1.2.2.1.1.2.2" xref="S3.E3.m1.2.2.1.1.2.2.cmml"><mi id="S3.E3.m1.2.2.1.1.2.2.2" xref="S3.E3.m1.2.2.1.1.2.2.2.cmml">v</mi><mi id="S3.E3.m1.2.2.1.1.2.2.3" xref="S3.E3.m1.2.2.1.1.2.2.3.cmml">t</mi></msub><mo id="S3.E3.m1.2.2.1.1.2.1" xref="S3.E3.m1.2.2.1.1.2.1.cmml">â¢</mo><mrow id="S3.E3.m1.2.2.1.1.2.3.2" xref="S3.E3.m1.2.2.1.1.2.cmml"><mo id="S3.E3.m1.2.2.1.1.2.3.2.1" stretchy="false" xref="S3.E3.m1.2.2.1.1.2.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">x</mi><mo id="S3.E3.m1.2.2.1.1.2.3.2.2" stretchy="false" xref="S3.E3.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.2.2.1.1.1" xref="S3.E3.m1.2.2.1.1.1.cmml">=</mo><mrow id="S3.E3.m1.2.2.1.1.3" xref="S3.E3.m1.2.2.1.1.3.cmml"><mi id="S3.E3.m1.2.2.1.1.3.2" xref="S3.E3.m1.2.2.1.1.3.2.cmml">x</mi><mo id="S3.E3.m1.2.2.1.1.3.1" xref="S3.E3.m1.2.2.1.1.3.1.cmml">âˆ’</mo><mi id="S3.E3.m1.2.2.1.1.3.3" xref="S3.E3.m1.2.2.1.1.3.3.cmml">Ïµ</mi></mrow></mrow><mo id="S3.E3.m1.2.2.1.2" lspace="0em" xref="S3.E3.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.1.1.cmml" xref="S3.E3.m1.2.2.1"><eq id="S3.E3.m1.2.2.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1"></eq><apply id="S3.E3.m1.2.2.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.2"><times id="S3.E3.m1.2.2.1.1.2.1.cmml" xref="S3.E3.m1.2.2.1.1.2.1"></times><apply id="S3.E3.m1.2.2.1.1.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.2.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2">ğ‘£</ci><ci id="S3.E3.m1.2.2.1.1.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.3">ğ‘¡</ci></apply><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">ğ‘¥</ci></apply><apply id="S3.E3.m1.2.2.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.3"><minus id="S3.E3.m1.2.2.1.1.3.1.cmml" xref="S3.E3.m1.2.2.1.1.3.1"></minus><ci id="S3.E3.m1.2.2.1.1.3.2.cmml" xref="S3.E3.m1.2.2.1.1.3.2">ğ‘¥</ci><ci id="S3.E3.m1.2.2.1.1.3.3.cmml" xref="S3.E3.m1.2.2.1.1.3.3">italic-Ïµ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">v_{t}(x)=x-\epsilon.</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.2d">italic_v start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x ) = italic_x - italic_Ïµ .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p4.5">The velocity field <math alttext="v_{t}:[0,1]\times\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}" class="ltx_Math" display="inline" id="S3.SS1.p4.5.m1.2"><semantics id="S3.SS1.p4.5.m1.2a"><mrow id="S3.SS1.p4.5.m1.2.3" xref="S3.SS1.p4.5.m1.2.3.cmml"><msub id="S3.SS1.p4.5.m1.2.3.2" xref="S3.SS1.p4.5.m1.2.3.2.cmml"><mi id="S3.SS1.p4.5.m1.2.3.2.2" xref="S3.SS1.p4.5.m1.2.3.2.2.cmml">v</mi><mi id="S3.SS1.p4.5.m1.2.3.2.3" xref="S3.SS1.p4.5.m1.2.3.2.3.cmml">t</mi></msub><mo id="S3.SS1.p4.5.m1.2.3.1" lspace="0.278em" rspace="0.278em" xref="S3.SS1.p4.5.m1.2.3.1.cmml">:</mo><mrow id="S3.SS1.p4.5.m1.2.3.3" xref="S3.SS1.p4.5.m1.2.3.3.cmml"><mrow id="S3.SS1.p4.5.m1.2.3.3.2" xref="S3.SS1.p4.5.m1.2.3.3.2.cmml"><mrow id="S3.SS1.p4.5.m1.2.3.3.2.2.2" xref="S3.SS1.p4.5.m1.2.3.3.2.2.1.cmml"><mo id="S3.SS1.p4.5.m1.2.3.3.2.2.2.1" stretchy="false" xref="S3.SS1.p4.5.m1.2.3.3.2.2.1.cmml">[</mo><mn id="S3.SS1.p4.5.m1.1.1" xref="S3.SS1.p4.5.m1.1.1.cmml">0</mn><mo id="S3.SS1.p4.5.m1.2.3.3.2.2.2.2" xref="S3.SS1.p4.5.m1.2.3.3.2.2.1.cmml">,</mo><mn id="S3.SS1.p4.5.m1.2.2" xref="S3.SS1.p4.5.m1.2.2.cmml">1</mn><mo id="S3.SS1.p4.5.m1.2.3.3.2.2.2.3" rspace="0.055em" stretchy="false" xref="S3.SS1.p4.5.m1.2.3.3.2.2.1.cmml">]</mo></mrow><mo id="S3.SS1.p4.5.m1.2.3.3.2.1" rspace="0.222em" xref="S3.SS1.p4.5.m1.2.3.3.2.1.cmml">Ã—</mo><msup id="S3.SS1.p4.5.m1.2.3.3.2.3" xref="S3.SS1.p4.5.m1.2.3.3.2.3.cmml"><mi id="S3.SS1.p4.5.m1.2.3.3.2.3.2" xref="S3.SS1.p4.5.m1.2.3.3.2.3.2.cmml">â„</mi><mi id="S3.SS1.p4.5.m1.2.3.3.2.3.3" xref="S3.SS1.p4.5.m1.2.3.3.2.3.3.cmml">d</mi></msup></mrow><mo id="S3.SS1.p4.5.m1.2.3.3.1" stretchy="false" xref="S3.SS1.p4.5.m1.2.3.3.1.cmml">â†’</mo><msup id="S3.SS1.p4.5.m1.2.3.3.3" xref="S3.SS1.p4.5.m1.2.3.3.3.cmml"><mi id="S3.SS1.p4.5.m1.2.3.3.3.2" xref="S3.SS1.p4.5.m1.2.3.3.3.2.cmml">â„</mi><mi id="S3.SS1.p4.5.m1.2.3.3.3.3" xref="S3.SS1.p4.5.m1.2.3.3.3.3.cmml">d</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.5.m1.2b"><apply id="S3.SS1.p4.5.m1.2.3.cmml" xref="S3.SS1.p4.5.m1.2.3"><ci id="S3.SS1.p4.5.m1.2.3.1.cmml" xref="S3.SS1.p4.5.m1.2.3.1">:</ci><apply id="S3.SS1.p4.5.m1.2.3.2.cmml" xref="S3.SS1.p4.5.m1.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p4.5.m1.2.3.2.1.cmml" xref="S3.SS1.p4.5.m1.2.3.2">subscript</csymbol><ci id="S3.SS1.p4.5.m1.2.3.2.2.cmml" xref="S3.SS1.p4.5.m1.2.3.2.2">ğ‘£</ci><ci id="S3.SS1.p4.5.m1.2.3.2.3.cmml" xref="S3.SS1.p4.5.m1.2.3.2.3">ğ‘¡</ci></apply><apply id="S3.SS1.p4.5.m1.2.3.3.cmml" xref="S3.SS1.p4.5.m1.2.3.3"><ci id="S3.SS1.p4.5.m1.2.3.3.1.cmml" xref="S3.SS1.p4.5.m1.2.3.3.1">â†’</ci><apply id="S3.SS1.p4.5.m1.2.3.3.2.cmml" xref="S3.SS1.p4.5.m1.2.3.3.2"><times id="S3.SS1.p4.5.m1.2.3.3.2.1.cmml" xref="S3.SS1.p4.5.m1.2.3.3.2.1"></times><interval closure="closed" id="S3.SS1.p4.5.m1.2.3.3.2.2.1.cmml" xref="S3.SS1.p4.5.m1.2.3.3.2.2.2"><cn id="S3.SS1.p4.5.m1.1.1.cmml" type="integer" xref="S3.SS1.p4.5.m1.1.1">0</cn><cn id="S3.SS1.p4.5.m1.2.2.cmml" type="integer" xref="S3.SS1.p4.5.m1.2.2">1</cn></interval><apply id="S3.SS1.p4.5.m1.2.3.3.2.3.cmml" xref="S3.SS1.p4.5.m1.2.3.3.2.3"><csymbol cd="ambiguous" id="S3.SS1.p4.5.m1.2.3.3.2.3.1.cmml" xref="S3.SS1.p4.5.m1.2.3.3.2.3">superscript</csymbol><ci id="S3.SS1.p4.5.m1.2.3.3.2.3.2.cmml" xref="S3.SS1.p4.5.m1.2.3.3.2.3.2">â„</ci><ci id="S3.SS1.p4.5.m1.2.3.3.2.3.3.cmml" xref="S3.SS1.p4.5.m1.2.3.3.2.3.3">ğ‘‘</ci></apply></apply><apply id="S3.SS1.p4.5.m1.2.3.3.3.cmml" xref="S3.SS1.p4.5.m1.2.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p4.5.m1.2.3.3.3.1.cmml" xref="S3.SS1.p4.5.m1.2.3.3.3">superscript</csymbol><ci id="S3.SS1.p4.5.m1.2.3.3.3.2.cmml" xref="S3.SS1.p4.5.m1.2.3.3.3.2">â„</ci><ci id="S3.SS1.p4.5.m1.2.3.3.3.3.cmml" xref="S3.SS1.p4.5.m1.2.3.3.3.3">ğ‘‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.5.m1.2c">v_{t}:[0,1]\times\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.5.m1.2d">italic_v start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT : [ 0 , 1 ] Ã— blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT â†’ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> defines an ordinary differential equation (ODE):</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="d\phi_{t}(x)=v_{t}\left(\phi_{t}(x)\right)dt." class="ltx_Math" display="block" id="S3.E4.m1.3"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3.1" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1.3" xref="S3.E4.m1.3.3.1.1.3.cmml"><mi id="S3.E4.m1.3.3.1.1.3.2" xref="S3.E4.m1.3.3.1.1.3.2.cmml">d</mi><mo id="S3.E4.m1.3.3.1.1.3.1" xref="S3.E4.m1.3.3.1.1.3.1.cmml">â¢</mo><msub id="S3.E4.m1.3.3.1.1.3.3" xref="S3.E4.m1.3.3.1.1.3.3.cmml"><mi id="S3.E4.m1.3.3.1.1.3.3.2" xref="S3.E4.m1.3.3.1.1.3.3.2.cmml">Ï•</mi><mi id="S3.E4.m1.3.3.1.1.3.3.3" xref="S3.E4.m1.3.3.1.1.3.3.3.cmml">t</mi></msub><mo id="S3.E4.m1.3.3.1.1.3.1a" xref="S3.E4.m1.3.3.1.1.3.1.cmml">â¢</mo><mrow id="S3.E4.m1.3.3.1.1.3.4.2" xref="S3.E4.m1.3.3.1.1.3.cmml"><mo id="S3.E4.m1.3.3.1.1.3.4.2.1" stretchy="false" xref="S3.E4.m1.3.3.1.1.3.cmml">(</mo><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">x</mi><mo id="S3.E4.m1.3.3.1.1.3.4.2.2" stretchy="false" xref="S3.E4.m1.3.3.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.3.3.1.1.2" xref="S3.E4.m1.3.3.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.3.3.1.1.1" xref="S3.E4.m1.3.3.1.1.1.cmml"><msub id="S3.E4.m1.3.3.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.3.cmml"><mi id="S3.E4.m1.3.3.1.1.1.3.2" xref="S3.E4.m1.3.3.1.1.1.3.2.cmml">v</mi><mi id="S3.E4.m1.3.3.1.1.1.3.3" xref="S3.E4.m1.3.3.1.1.1.3.3.cmml">t</mi></msub><mo id="S3.E4.m1.3.3.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.2.cmml">â¢</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.3.3.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.cmml"><msub id="S3.E4.m1.3.3.1.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.2.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.2.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.2.2.cmml">Ï•</mi><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.2.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.cmml">â¢</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.1.1.3.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.3.2.1" stretchy="false" xref="S3.E4.m1.3.3.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">x</mi><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.3.2.2" stretchy="false" xref="S3.E4.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.3.3.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E4.m1.3.3.1.1.1.2a" xref="S3.E4.m1.3.3.1.1.1.2.cmml">â¢</mo><mi id="S3.E4.m1.3.3.1.1.1.4" xref="S3.E4.m1.3.3.1.1.1.4.cmml">d</mi><mo id="S3.E4.m1.3.3.1.1.1.2b" xref="S3.E4.m1.3.3.1.1.1.2.cmml">â¢</mo><mi id="S3.E4.m1.3.3.1.1.1.5" xref="S3.E4.m1.3.3.1.1.1.5.cmml">t</mi></mrow></mrow><mo id="S3.E4.m1.3.3.1.2" lspace="0em" xref="S3.E4.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.1.1.cmml" xref="S3.E4.m1.3.3.1"><eq id="S3.E4.m1.3.3.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.2"></eq><apply id="S3.E4.m1.3.3.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.3"><times id="S3.E4.m1.3.3.1.1.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3.1"></times><ci id="S3.E4.m1.3.3.1.1.3.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2">ğ‘‘</ci><apply id="S3.E4.m1.3.3.1.1.3.3.cmml" xref="S3.E4.m1.3.3.1.1.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.3.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3.3">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.3.3.2.cmml" xref="S3.E4.m1.3.3.1.1.3.3.2">italic-Ï•</ci><ci id="S3.E4.m1.3.3.1.1.3.3.3.cmml" xref="S3.E4.m1.3.3.1.1.3.3.3">ğ‘¡</ci></apply><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">ğ‘¥</ci></apply><apply id="S3.E4.m1.3.3.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1"><times id="S3.E4.m1.3.3.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.2"></times><apply id="S3.E4.m1.3.3.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.3.1.cmml" xref="S3.E4.m1.3.3.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.3.2.cmml" xref="S3.E4.m1.3.3.1.1.1.3.2">ğ‘£</ci><ci id="S3.E4.m1.3.3.1.1.1.3.3.cmml" xref="S3.E4.m1.3.3.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1"><times id="S3.E4.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1"></times><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.2.2">italic-Ï•</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2">ğ‘¥</ci></apply><ci id="S3.E4.m1.3.3.1.1.1.4.cmml" xref="S3.E4.m1.3.3.1.1.1.4">ğ‘‘</ci><ci id="S3.E4.m1.3.3.1.1.1.5.cmml" xref="S3.E4.m1.3.3.1.1.1.5">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">d\phi_{t}(x)=v_{t}\left(\phi_{t}(x)\right)dt.</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.3d">italic_d italic_Ï• start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x ) = italic_v start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_Ï• start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x ) ) italic_d italic_t .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p4.8">By solving this ODE from <math alttext="t=0" class="ltx_Math" display="inline" id="S3.SS1.p4.6.m1.1"><semantics id="S3.SS1.p4.6.m1.1a"><mrow id="S3.SS1.p4.6.m1.1.1" xref="S3.SS1.p4.6.m1.1.1.cmml"><mi id="S3.SS1.p4.6.m1.1.1.2" xref="S3.SS1.p4.6.m1.1.1.2.cmml">t</mi><mo id="S3.SS1.p4.6.m1.1.1.1" xref="S3.SS1.p4.6.m1.1.1.1.cmml">=</mo><mn id="S3.SS1.p4.6.m1.1.1.3" xref="S3.SS1.p4.6.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.6.m1.1b"><apply id="S3.SS1.p4.6.m1.1.1.cmml" xref="S3.SS1.p4.6.m1.1.1"><eq id="S3.SS1.p4.6.m1.1.1.1.cmml" xref="S3.SS1.p4.6.m1.1.1.1"></eq><ci id="S3.SS1.p4.6.m1.1.1.2.cmml" xref="S3.SS1.p4.6.m1.1.1.2">ğ‘¡</ci><cn id="S3.SS1.p4.6.m1.1.1.3.cmml" type="integer" xref="S3.SS1.p4.6.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.6.m1.1c">t=0</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.6.m1.1d">italic_t = 0</annotation></semantics></math> to <math alttext="t=1" class="ltx_Math" display="inline" id="S3.SS1.p4.7.m2.1"><semantics id="S3.SS1.p4.7.m2.1a"><mrow id="S3.SS1.p4.7.m2.1.1" xref="S3.SS1.p4.7.m2.1.1.cmml"><mi id="S3.SS1.p4.7.m2.1.1.2" xref="S3.SS1.p4.7.m2.1.1.2.cmml">t</mi><mo id="S3.SS1.p4.7.m2.1.1.1" xref="S3.SS1.p4.7.m2.1.1.1.cmml">=</mo><mn id="S3.SS1.p4.7.m2.1.1.3" xref="S3.SS1.p4.7.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.7.m2.1b"><apply id="S3.SS1.p4.7.m2.1.1.cmml" xref="S3.SS1.p4.7.m2.1.1"><eq id="S3.SS1.p4.7.m2.1.1.1.cmml" xref="S3.SS1.p4.7.m2.1.1.1"></eq><ci id="S3.SS1.p4.7.m2.1.1.2.cmml" xref="S3.SS1.p4.7.m2.1.1.2">ğ‘¡</ci><cn id="S3.SS1.p4.7.m2.1.1.3.cmml" type="integer" xref="S3.SS1.p4.7.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.7.m2.1c">t=1</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.7.m2.1d">italic_t = 1</annotation></semantics></math>, we can transform noise into a data sample using the approximated velocity field <math alttext="v_{\theta}" class="ltx_Math" display="inline" id="S3.SS1.p4.8.m3.1"><semantics id="S3.SS1.p4.8.m3.1a"><msub id="S3.SS1.p4.8.m3.1.1" xref="S3.SS1.p4.8.m3.1.1.cmml"><mi id="S3.SS1.p4.8.m3.1.1.2" xref="S3.SS1.p4.8.m3.1.1.2.cmml">v</mi><mi id="S3.SS1.p4.8.m3.1.1.3" xref="S3.SS1.p4.8.m3.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.8.m3.1b"><apply id="S3.SS1.p4.8.m3.1.1.cmml" xref="S3.SS1.p4.8.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.8.m3.1.1.1.cmml" xref="S3.SS1.p4.8.m3.1.1">subscript</csymbol><ci id="S3.SS1.p4.8.m3.1.1.2.cmml" xref="S3.SS1.p4.8.m3.1.1.2">ğ‘£</ci><ci id="S3.SS1.p4.8.m3.1.1.3.cmml" xref="S3.SS1.p4.8.m3.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.8.m3.1c">v_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.8.m3.1d">italic_v start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math>.
During training, the flow matching objective directly predicts the target velocity to generate the desired probability trajectory:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\theta}=\mathbb{E}_{t}\left\|v_{\theta}\left(\phi_{t}\left(z_{d}%
\right),z_{c},t\right)-v_{t}\left(z_{d}\right)\right\|^{2}," class="ltx_Math" display="block" id="S3.E5.m1.2"><semantics id="S3.E5.m1.2a"><mrow id="S3.E5.m1.2.2.1" xref="S3.E5.m1.2.2.1.1.cmml"><mrow id="S3.E5.m1.2.2.1.1" xref="S3.E5.m1.2.2.1.1.cmml"><msub id="S3.E5.m1.2.2.1.1.3" xref="S3.E5.m1.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.2.2.1.1.3.2" xref="S3.E5.m1.2.2.1.1.3.2.cmml">â„’</mi><mi id="S3.E5.m1.2.2.1.1.3.3" xref="S3.E5.m1.2.2.1.1.3.3.cmml">Î¸</mi></msub><mo id="S3.E5.m1.2.2.1.1.2" xref="S3.E5.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E5.m1.2.2.1.1.1" xref="S3.E5.m1.2.2.1.1.1.cmml"><msub id="S3.E5.m1.2.2.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.3.cmml"><mi id="S3.E5.m1.2.2.1.1.1.3.2" xref="S3.E5.m1.2.2.1.1.1.3.2.cmml">ğ”¼</mi><mi id="S3.E5.m1.2.2.1.1.1.3.3" xref="S3.E5.m1.2.2.1.1.1.3.3.cmml">t</mi></msub><mo id="S3.E5.m1.2.2.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.2.cmml">â¢</mo><msup id="S3.E5.m1.2.2.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.cmml"><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.2.cmml"><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.cmml"><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.cmml"><msub id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.4" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.4.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.4.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.4.2.cmml">v</mi><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.4.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.4.3.cmml">Î¸</mi></msub><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.3.cmml">â¢</mo><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.3.cmml"><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.3.cmml">(</mo><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">Ï•</mi><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">d</mi></msub><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.4" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.3.cmml">,</mo><msub id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.2.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.2.2.cmml">z</mi><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.2.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.2.3.cmml">c</mi></msub><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.5" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.3.cmml">,</mo><mi id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml">t</mi><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.6" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.4" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.4.cmml">âˆ’</mo><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.cmml"><msub id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3.2.cmml">v</mi><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3.3.cmml">t</mi></msub><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.2.cmml">â¢</mo><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1.1.cmml"><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1.1.cmml">(</mo><msub id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1.1.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1.1.2.cmml">z</mi><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1.1.3.cmml">d</mi></msub><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E5.m1.2.2.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.3.cmml">2</mn></msup></mrow></mrow><mo id="S3.E5.m1.2.2.1.2" xref="S3.E5.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.2b"><apply id="S3.E5.m1.2.2.1.1.cmml" xref="S3.E5.m1.2.2.1"><eq id="S3.E5.m1.2.2.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.2"></eq><apply id="S3.E5.m1.2.2.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.3.1.cmml" xref="S3.E5.m1.2.2.1.1.3">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.3.2.cmml" xref="S3.E5.m1.2.2.1.1.3.2">â„’</ci><ci id="S3.E5.m1.2.2.1.1.3.3.cmml" xref="S3.E5.m1.2.2.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E5.m1.2.2.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1"><times id="S3.E5.m1.2.2.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.2"></times><apply id="S3.E5.m1.2.2.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.3.1.cmml" xref="S3.E5.m1.2.2.1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.3.2.cmml" xref="S3.E5.m1.2.2.1.1.1.3.2">ğ”¼</ci><ci id="S3.E5.m1.2.2.1.1.1.3.3.cmml" xref="S3.E5.m1.2.2.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.E5.m1.2.2.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1">superscript</csymbol><apply id="S3.E5.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E5.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1"><minus id="S3.E5.m1.2.2.1.1.1.1.1.1.1.4.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.4"></minus><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2"><times id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.3"></times><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.4.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.4.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.4">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.4.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.4.2">ğ‘£</ci><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.4.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.4.3">ğœƒ</ci></apply><vector id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2"><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"><times id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2">italic-Ï•</ci><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘§</ci><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘‘</ci></apply></apply><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.2.2">ğ‘§</ci><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.2.2.3">ğ‘</ci></apply><ci id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1">ğ‘¡</ci></vector></apply><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3"><times id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.2"></times><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3.2">ğ‘£</ci><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.3.3">ğ‘¡</ci></apply><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1.1.2">ğ‘§</ci><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.1.1.1.3">ğ‘‘</ci></apply></apply></apply></apply><cn id="S3.E5.m1.2.2.1.1.1.1.3.cmml" type="integer" xref="S3.E5.m1.2.2.1.1.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.2c">\mathcal{L}_{\theta}=\mathbb{E}_{t}\left\|v_{\theta}\left(\phi_{t}\left(z_{d}%
\right),z_{c},t\right)-v_{t}\left(z_{d}\right)\right\|^{2},</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.2d">caligraphic_L start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT = blackboard_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT âˆ¥ italic_v start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_Ï• start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ) , italic_z start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , italic_t ) - italic_v start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ) âˆ¥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p4.10">where <math alttext="z_{d}" class="ltx_Math" display="inline" id="S3.SS1.p4.9.m1.1"><semantics id="S3.SS1.p4.9.m1.1a"><msub id="S3.SS1.p4.9.m1.1.1" xref="S3.SS1.p4.9.m1.1.1.cmml"><mi id="S3.SS1.p4.9.m1.1.1.2" xref="S3.SS1.p4.9.m1.1.1.2.cmml">z</mi><mi id="S3.SS1.p4.9.m1.1.1.3" xref="S3.SS1.p4.9.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.9.m1.1b"><apply id="S3.SS1.p4.9.m1.1.1.cmml" xref="S3.SS1.p4.9.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.9.m1.1.1.1.cmml" xref="S3.SS1.p4.9.m1.1.1">subscript</csymbol><ci id="S3.SS1.p4.9.m1.1.1.2.cmml" xref="S3.SS1.p4.9.m1.1.1.2">ğ‘§</ci><ci id="S3.SS1.p4.9.m1.1.1.3.cmml" xref="S3.SS1.p4.9.m1.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.9.m1.1c">z_{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.9.m1.1d">italic_z start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="z_{c}" class="ltx_Math" display="inline" id="S3.SS1.p4.10.m2.1"><semantics id="S3.SS1.p4.10.m2.1a"><msub id="S3.SS1.p4.10.m2.1.1" xref="S3.SS1.p4.10.m2.1.1.cmml"><mi id="S3.SS1.p4.10.m2.1.1.2" xref="S3.SS1.p4.10.m2.1.1.2.cmml">z</mi><mi id="S3.SS1.p4.10.m2.1.1.3" xref="S3.SS1.p4.10.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.10.m2.1b"><apply id="S3.SS1.p4.10.m2.1.1.cmml" xref="S3.SS1.p4.10.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.10.m2.1.1.1.cmml" xref="S3.SS1.p4.10.m2.1.1">subscript</csymbol><ci id="S3.SS1.p4.10.m2.1.1.2.cmml" xref="S3.SS1.p4.10.m2.1.1.2">ğ‘§</ci><ci id="S3.SS1.p4.10.m2.1.1.3.cmml" xref="S3.SS1.p4.10.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.10.m2.1c">z_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.10.m2.1d">italic_z start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> represent the latent depth code and video code, respectively.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Mixed-duration Training Strategy</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Real-world applications often encounter data in various formats, including images and variable-length videos.
To enhance the modelâ€™s generalization across tasks like image and video depth estimation, we implement a mixed-duration training strategy to ensure robustness across various inputs.
This strategy includes frame dropout augmentation, which preserves training efficiency when handling long video sequences, and a video packing technique that optimizes memory usage for variable-length videos, enabling our model to scale efficiently across different input formats.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.3"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.3.1">Frame Dropout.</span>
Directly training long-frame videos is computationally expensive, requiring substantial training time and GPU resources.
Inspired by context extension techniquesÂ <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib10" title="">2024</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib8" title="">2023</a>; Liu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib31" title="">2024</a>)</cite> in large language models, we propose frame dropout augmentation with rotary position encoding (RoPE)Â <cite class="ltx_cite ltx_citemacro_citep">(Su etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib46" title="">2021</a>)</cite> to enhance training efficiency while maintaining adaptability for long videos.
Concretely, in each temporal transformer block of the 3D UNet used in SVD, we replace the original sinusoidal absolute position encoding for fixed-frame videos with RoPE to support variable frames.
However, training on a short video with RoPE still struggles to generalize to longer ones with unlearned frame positions, as shown in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S3.F2" title="Figure 2 â€£ 3.1 Model Design â€£ 3 Generative Video Depth Model â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">2</span></a>(a).
To mitigate this, we retain the original frame position indices <math alttext="i=[0,\cdots,T-1]" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.3"><semantics id="S3.SS2.p2.1.m1.3a"><mrow id="S3.SS2.p2.1.m1.3.3" xref="S3.SS2.p2.1.m1.3.3.cmml"><mi id="S3.SS2.p2.1.m1.3.3.3" xref="S3.SS2.p2.1.m1.3.3.3.cmml">i</mi><mo id="S3.SS2.p2.1.m1.3.3.2" xref="S3.SS2.p2.1.m1.3.3.2.cmml">=</mo><mrow id="S3.SS2.p2.1.m1.3.3.1.1" xref="S3.SS2.p2.1.m1.3.3.1.2.cmml"><mo id="S3.SS2.p2.1.m1.3.3.1.1.2" stretchy="false" xref="S3.SS2.p2.1.m1.3.3.1.2.cmml">[</mo><mn id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">0</mn><mo id="S3.SS2.p2.1.m1.3.3.1.1.3" xref="S3.SS2.p2.1.m1.3.3.1.2.cmml">,</mo><mi id="S3.SS2.p2.1.m1.2.2" mathvariant="normal" xref="S3.SS2.p2.1.m1.2.2.cmml">â‹¯</mi><mo id="S3.SS2.p2.1.m1.3.3.1.1.4" xref="S3.SS2.p2.1.m1.3.3.1.2.cmml">,</mo><mrow id="S3.SS2.p2.1.m1.3.3.1.1.1" xref="S3.SS2.p2.1.m1.3.3.1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.3.3.1.1.1.2" xref="S3.SS2.p2.1.m1.3.3.1.1.1.2.cmml">T</mi><mo id="S3.SS2.p2.1.m1.3.3.1.1.1.1" xref="S3.SS2.p2.1.m1.3.3.1.1.1.1.cmml">âˆ’</mo><mn id="S3.SS2.p2.1.m1.3.3.1.1.1.3" xref="S3.SS2.p2.1.m1.3.3.1.1.1.3.cmml">1</mn></mrow><mo id="S3.SS2.p2.1.m1.3.3.1.1.5" stretchy="false" xref="S3.SS2.p2.1.m1.3.3.1.2.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.3b"><apply id="S3.SS2.p2.1.m1.3.3.cmml" xref="S3.SS2.p2.1.m1.3.3"><eq id="S3.SS2.p2.1.m1.3.3.2.cmml" xref="S3.SS2.p2.1.m1.3.3.2"></eq><ci id="S3.SS2.p2.1.m1.3.3.3.cmml" xref="S3.SS2.p2.1.m1.3.3.3">ğ‘–</ci><list id="S3.SS2.p2.1.m1.3.3.1.2.cmml" xref="S3.SS2.p2.1.m1.3.3.1.1"><cn id="S3.SS2.p2.1.m1.1.1.cmml" type="integer" xref="S3.SS2.p2.1.m1.1.1">0</cn><ci id="S3.SS2.p2.1.m1.2.2.cmml" xref="S3.SS2.p2.1.m1.2.2">â‹¯</ci><apply id="S3.SS2.p2.1.m1.3.3.1.1.1.cmml" xref="S3.SS2.p2.1.m1.3.3.1.1.1"><minus id="S3.SS2.p2.1.m1.3.3.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.3.3.1.1.1.1"></minus><ci id="S3.SS2.p2.1.m1.3.3.1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.3.3.1.1.1.2">ğ‘‡</ci><cn id="S3.SS2.p2.1.m1.3.3.1.1.1.3.cmml" type="integer" xref="S3.SS2.p2.1.m1.3.3.1.1.1.3">1</cn></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.3c">i=[0,\cdots,T-1]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.3d">italic_i = [ 0 , â‹¯ , italic_T - 1 ]</annotation></semantics></math> of the long video with <math alttext="T" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">italic_T</annotation></semantics></math> frames, and randomly sample <math alttext="K" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.1"><semantics id="S3.SS2.p2.3.m3.1a"><mi id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><ci id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.1d">italic_K</annotation></semantics></math> frames with their original indices for training.
This simple strategy helps the temporal layer generalize effectively across variable frame lengths.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1">Video Packing.</span>
To train videos of varying lengths, an intuitive way is to use only one sample per batch, as all data within a batch must maintain a consistent shape.
However, this leads to inefficient memory usage for shorter videos.
To solve this, we first group videos by similar resolution and crop them to a fixed size.
For each batch, we then sample examples from the same group and apply the same frame dropout parameter <math alttext="K" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_K</annotation></semantics></math>.
The process is illustrated in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S3.F2" title="Figure 2 â€£ 3.1 Model Design â€£ 3 Generative Video Depth Model â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">2</span></a>(b).
In particular, we increase the batch size for small-resolution and short-duration videos to improve training efficiency.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Long Video Inference</h3>
<figure class="ltx_figure ltx_align_floatright" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="146" id="S3.F3.g1" src="extracted/5923385/figure/interp_net.png" width="234"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Illustration of the <span class="ltx_text ltx_font_bold" id="S3.F3.2.1">frame interpolation network</span>, conditioned on key frames to produce coherent predictions.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.2">Using the trained model, we can process up to 32 frames at <math alttext="960\times 540" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mn id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">960</mn><mo id="S3.SS3.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS3.p1.1.m1.1.1.1.cmml">Ã—</mo><mn id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">540</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><times id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1"></times><cn id="S3.SS3.p1.1.m1.1.1.2.cmml" type="integer" xref="S3.SS3.p1.1.m1.1.1.2">960</cn><cn id="S3.SS3.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS3.p1.1.m1.1.1.3">540</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">960\times 540</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">960 Ã— 540</annotation></semantics></math> resolution in one forward pass on a single 80GB A100 GPU.
To handle longer high-resolution videos, <cite class="ltx_cite ltx_citemacro_citet">Wang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib49" title="">2023</a>)</cite> applies a sliding window to process short segments independently and concatenate the results.
However, this would lead to temporal inconsistencies and flickering artifacts between windows.
Thus, we first predict consistent key frames, and then each window generates intermediate frames using a frame interpolation network conditioned on these key frames to align the scale and shift of the depth distributions, as shown in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S3.F3" title="Figure 3 â€£ 3.3 Long Video Inference â€£ 3 Generative Video Depth Model â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">3</span></a>.
Specifically, the interpolation network is finetuned from the video depth model <math alttext="v_{\theta}" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><msub id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">v</mi><mi id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">ğ‘£</ci><ci id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">v_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">italic_v start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math> in Sec.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S3.SS1" title="3.1 Model Design â€£ 3 Generative Video Depth Model â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">3.1</span></a>.
Instead of conditioning solely on the video, the first and last key frames of each window are also used, with a masking map indicating which frames are known.
The frame interpolation is formulated as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\tilde{z}_{d}=v_{\theta}\left(\phi_{t}\left(z_{d}\right),z_{c},\hat{z}_{d},m,t%
\right)," class="ltx_Math" display="block" id="S3.E6.m1.3"><semantics id="S3.E6.m1.3a"><mrow id="S3.E6.m1.3.3.1" xref="S3.E6.m1.3.3.1.1.cmml"><mrow id="S3.E6.m1.3.3.1.1" xref="S3.E6.m1.3.3.1.1.cmml"><msub id="S3.E6.m1.3.3.1.1.5" xref="S3.E6.m1.3.3.1.1.5.cmml"><mover accent="true" id="S3.E6.m1.3.3.1.1.5.2" xref="S3.E6.m1.3.3.1.1.5.2.cmml"><mi id="S3.E6.m1.3.3.1.1.5.2.2" xref="S3.E6.m1.3.3.1.1.5.2.2.cmml">z</mi><mo id="S3.E6.m1.3.3.1.1.5.2.1" xref="S3.E6.m1.3.3.1.1.5.2.1.cmml">~</mo></mover><mi id="S3.E6.m1.3.3.1.1.5.3" xref="S3.E6.m1.3.3.1.1.5.3.cmml">d</mi></msub><mo id="S3.E6.m1.3.3.1.1.4" xref="S3.E6.m1.3.3.1.1.4.cmml">=</mo><mrow id="S3.E6.m1.3.3.1.1.3" xref="S3.E6.m1.3.3.1.1.3.cmml"><msub id="S3.E6.m1.3.3.1.1.3.5" xref="S3.E6.m1.3.3.1.1.3.5.cmml"><mi id="S3.E6.m1.3.3.1.1.3.5.2" xref="S3.E6.m1.3.3.1.1.3.5.2.cmml">v</mi><mi id="S3.E6.m1.3.3.1.1.3.5.3" xref="S3.E6.m1.3.3.1.1.3.5.3.cmml">Î¸</mi></msub><mo id="S3.E6.m1.3.3.1.1.3.4" xref="S3.E6.m1.3.3.1.1.3.4.cmml">â¢</mo><mrow id="S3.E6.m1.3.3.1.1.3.3.3" xref="S3.E6.m1.3.3.1.1.3.3.4.cmml"><mo id="S3.E6.m1.3.3.1.1.3.3.3.4" xref="S3.E6.m1.3.3.1.1.3.3.4.cmml">(</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.cmml"><msub id="S3.E6.m1.3.3.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.3.cmml"><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.3.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.3.2.cmml">Ï•</mi><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.3.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo id="S3.E6.m1.3.3.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml">d</mi></msub><mo id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.3.3.1.1.3.3.3.5" xref="S3.E6.m1.3.3.1.1.3.3.4.cmml">,</mo><msub id="S3.E6.m1.3.3.1.1.2.2.2.2" xref="S3.E6.m1.3.3.1.1.2.2.2.2.cmml"><mi id="S3.E6.m1.3.3.1.1.2.2.2.2.2" xref="S3.E6.m1.3.3.1.1.2.2.2.2.2.cmml">z</mi><mi id="S3.E6.m1.3.3.1.1.2.2.2.2.3" xref="S3.E6.m1.3.3.1.1.2.2.2.2.3.cmml">c</mi></msub><mo id="S3.E6.m1.3.3.1.1.3.3.3.6" xref="S3.E6.m1.3.3.1.1.3.3.4.cmml">,</mo><msub id="S3.E6.m1.3.3.1.1.3.3.3.3" xref="S3.E6.m1.3.3.1.1.3.3.3.3.cmml"><mover accent="true" id="S3.E6.m1.3.3.1.1.3.3.3.3.2" xref="S3.E6.m1.3.3.1.1.3.3.3.3.2.cmml"><mi id="S3.E6.m1.3.3.1.1.3.3.3.3.2.2" xref="S3.E6.m1.3.3.1.1.3.3.3.3.2.2.cmml">z</mi><mo id="S3.E6.m1.3.3.1.1.3.3.3.3.2.1" xref="S3.E6.m1.3.3.1.1.3.3.3.3.2.1.cmml">^</mo></mover><mi id="S3.E6.m1.3.3.1.1.3.3.3.3.3" xref="S3.E6.m1.3.3.1.1.3.3.3.3.3.cmml">d</mi></msub><mo id="S3.E6.m1.3.3.1.1.3.3.3.7" xref="S3.E6.m1.3.3.1.1.3.3.4.cmml">,</mo><mi id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml">m</mi><mo id="S3.E6.m1.3.3.1.1.3.3.3.8" xref="S3.E6.m1.3.3.1.1.3.3.4.cmml">,</mo><mi id="S3.E6.m1.2.2" xref="S3.E6.m1.2.2.cmml">t</mi><mo id="S3.E6.m1.3.3.1.1.3.3.3.9" xref="S3.E6.m1.3.3.1.1.3.3.4.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E6.m1.3.3.1.2" xref="S3.E6.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.3b"><apply id="S3.E6.m1.3.3.1.1.cmml" xref="S3.E6.m1.3.3.1"><eq id="S3.E6.m1.3.3.1.1.4.cmml" xref="S3.E6.m1.3.3.1.1.4"></eq><apply id="S3.E6.m1.3.3.1.1.5.cmml" xref="S3.E6.m1.3.3.1.1.5"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.5.1.cmml" xref="S3.E6.m1.3.3.1.1.5">subscript</csymbol><apply id="S3.E6.m1.3.3.1.1.5.2.cmml" xref="S3.E6.m1.3.3.1.1.5.2"><ci id="S3.E6.m1.3.3.1.1.5.2.1.cmml" xref="S3.E6.m1.3.3.1.1.5.2.1">~</ci><ci id="S3.E6.m1.3.3.1.1.5.2.2.cmml" xref="S3.E6.m1.3.3.1.1.5.2.2">ğ‘§</ci></apply><ci id="S3.E6.m1.3.3.1.1.5.3.cmml" xref="S3.E6.m1.3.3.1.1.5.3">ğ‘‘</ci></apply><apply id="S3.E6.m1.3.3.1.1.3.cmml" xref="S3.E6.m1.3.3.1.1.3"><times id="S3.E6.m1.3.3.1.1.3.4.cmml" xref="S3.E6.m1.3.3.1.1.3.4"></times><apply id="S3.E6.m1.3.3.1.1.3.5.cmml" xref="S3.E6.m1.3.3.1.1.3.5"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.3.5.1.cmml" xref="S3.E6.m1.3.3.1.1.3.5">subscript</csymbol><ci id="S3.E6.m1.3.3.1.1.3.5.2.cmml" xref="S3.E6.m1.3.3.1.1.3.5.2">ğ‘£</ci><ci id="S3.E6.m1.3.3.1.1.3.5.3.cmml" xref="S3.E6.m1.3.3.1.1.3.5.3">ğœƒ</ci></apply><vector id="S3.E6.m1.3.3.1.1.3.3.4.cmml" xref="S3.E6.m1.3.3.1.1.3.3.3"><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1"><times id="S3.E6.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.2"></times><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.3.2">italic-Ï•</ci><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.2">ğ‘§</ci><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.3">ğ‘‘</ci></apply></apply><apply id="S3.E6.m1.3.3.1.1.2.2.2.2.cmml" xref="S3.E6.m1.3.3.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.2.2.2.2.1.cmml" xref="S3.E6.m1.3.3.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E6.m1.3.3.1.1.2.2.2.2.2.cmml" xref="S3.E6.m1.3.3.1.1.2.2.2.2.2">ğ‘§</ci><ci id="S3.E6.m1.3.3.1.1.2.2.2.2.3.cmml" xref="S3.E6.m1.3.3.1.1.2.2.2.2.3">ğ‘</ci></apply><apply id="S3.E6.m1.3.3.1.1.3.3.3.3.cmml" xref="S3.E6.m1.3.3.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.3.3.3.3.1.cmml" xref="S3.E6.m1.3.3.1.1.3.3.3.3">subscript</csymbol><apply id="S3.E6.m1.3.3.1.1.3.3.3.3.2.cmml" xref="S3.E6.m1.3.3.1.1.3.3.3.3.2"><ci id="S3.E6.m1.3.3.1.1.3.3.3.3.2.1.cmml" xref="S3.E6.m1.3.3.1.1.3.3.3.3.2.1">^</ci><ci id="S3.E6.m1.3.3.1.1.3.3.3.3.2.2.cmml" xref="S3.E6.m1.3.3.1.1.3.3.3.3.2.2">ğ‘§</ci></apply><ci id="S3.E6.m1.3.3.1.1.3.3.3.3.3.cmml" xref="S3.E6.m1.3.3.1.1.3.3.3.3.3">ğ‘‘</ci></apply><ci id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1">ğ‘š</ci><ci id="S3.E6.m1.2.2.cmml" xref="S3.E6.m1.2.2">ğ‘¡</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.3c">\tilde{z}_{d}=v_{\theta}\left(\phi_{t}\left(z_{d}\right),z_{c},\hat{z}_{d},m,t%
\right),</annotation><annotation encoding="application/x-llamapun" id="S3.E6.m1.3d">over~ start_ARG italic_z end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT = italic_v start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_Ï• start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ) , italic_z start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , over^ start_ARG italic_z end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT , italic_m , italic_t ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p1.7">where <math alttext="\hat{z}_{d}" class="ltx_Math" display="inline" id="S3.SS3.p1.3.m1.1"><semantics id="S3.SS3.p1.3.m1.1a"><msub id="S3.SS3.p1.3.m1.1.1" xref="S3.SS3.p1.3.m1.1.1.cmml"><mover accent="true" id="S3.SS3.p1.3.m1.1.1.2" xref="S3.SS3.p1.3.m1.1.1.2.cmml"><mi id="S3.SS3.p1.3.m1.1.1.2.2" xref="S3.SS3.p1.3.m1.1.1.2.2.cmml">z</mi><mo id="S3.SS3.p1.3.m1.1.1.2.1" xref="S3.SS3.p1.3.m1.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS3.p1.3.m1.1.1.3" xref="S3.SS3.p1.3.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m1.1b"><apply id="S3.SS3.p1.3.m1.1.1.cmml" xref="S3.SS3.p1.3.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m1.1.1.1.cmml" xref="S3.SS3.p1.3.m1.1.1">subscript</csymbol><apply id="S3.SS3.p1.3.m1.1.1.2.cmml" xref="S3.SS3.p1.3.m1.1.1.2"><ci id="S3.SS3.p1.3.m1.1.1.2.1.cmml" xref="S3.SS3.p1.3.m1.1.1.2.1">^</ci><ci id="S3.SS3.p1.3.m1.1.1.2.2.cmml" xref="S3.SS3.p1.3.m1.1.1.2.2">ğ‘§</ci></apply><ci id="S3.SS3.p1.3.m1.1.1.3.cmml" xref="S3.SS3.p1.3.m1.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m1.1c">\hat{z}_{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.3.m1.1d">over^ start_ARG italic_z end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> represents the predicted key frames, with non-key frames padded with zeros. The masking map <math alttext="m" class="ltx_Math" display="inline" id="S3.SS3.p1.4.m2.1"><semantics id="S3.SS3.p1.4.m2.1a"><mi id="S3.SS3.p1.4.m2.1.1" xref="S3.SS3.p1.4.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m2.1b"><ci id="S3.SS3.p1.4.m2.1.1.cmml" xref="S3.SS3.p1.4.m2.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m2.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.4.m2.1d">italic_m</annotation></semantics></math> is used to indicate known key frames, which are set to <math alttext="1" class="ltx_Math" display="inline" id="S3.SS3.p1.5.m3.1"><semantics id="S3.SS3.p1.5.m3.1a"><mn id="S3.SS3.p1.5.m3.1.1" xref="S3.SS3.p1.5.m3.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m3.1b"><cn id="S3.SS3.p1.5.m3.1.1.cmml" type="integer" xref="S3.SS3.p1.5.m3.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m3.1c">1</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.5.m3.1d">1</annotation></semantics></math>, while other frames are set to <math alttext="0" class="ltx_Math" display="inline" id="S3.SS3.p1.6.m4.1"><semantics id="S3.SS3.p1.6.m4.1a"><mn id="S3.SS3.p1.6.m4.1.1" xref="S3.SS3.p1.6.m4.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m4.1b"><cn id="S3.SS3.p1.6.m4.1.1.cmml" type="integer" xref="S3.SS3.p1.6.m4.1.1">0</cn></annotation-xml></semantics></math>. The masking map is replicated four times to align with the latent feature dimensions.
To preserve the pre-trained structure and accommodate the expanded input, we duplicate input channels of <math alttext="v_{\theta}" class="ltx_Math" display="inline" id="S3.SS3.p1.7.m5.1"><semantics id="S3.SS3.p1.7.m5.1a"><msub id="S3.SS3.p1.7.m5.1.1" xref="S3.SS3.p1.7.m5.1.1.cmml"><mi id="S3.SS3.p1.7.m5.1.1.2" xref="S3.SS3.p1.7.m5.1.1.2.cmml">v</mi><mi id="S3.SS3.p1.7.m5.1.1.3" xref="S3.SS3.p1.7.m5.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m5.1b"><apply id="S3.SS3.p1.7.m5.1.1.cmml" xref="S3.SS3.p1.7.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.7.m5.1.1.1.cmml" xref="S3.SS3.p1.7.m5.1.1">subscript</csymbol><ci id="S3.SS3.p1.7.m5.1.1.2.cmml" xref="S3.SS3.p1.7.m5.1.1.2">ğ‘£</ci><ci id="S3.SS3.p1.7.m5.1.1.3.cmml" xref="S3.SS3.p1.7.m5.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m5.1c">v_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.7.m5.1d">italic_v start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math> and halve the input layerâ€™s weight tensor as initialization.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="528" id="S3.F4.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span class="ltx_text ltx_font_bold" id="S3.F4.2.1">Qualitative comparisons</span> of monocular depth estimation methods across
different datasets. We are able to capture fine-grained details and generalize effectively on in-the-wild data.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets and Evaluation Metrics</h3>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.1">Training Datasets.</span>
In addition to the collected DA-V dataset, we follow <cite class="ltx_cite ltx_citemacro_citet">Ke etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib27" title="">2024</a>)</cite> by incorporating two single-frame synthetic datasets, HypersimÂ <cite class="ltx_cite ltx_citemacro_citep">(Roberts etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib38" title="">2021</a>)</cite> and Virtual KITTI 2Â <cite class="ltx_cite ltx_citemacro_citep">(Cabon etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib7" title="">2020</a>)</cite>.
Hypersim is a photorealistic synthetic dataset featuring 461 indoor scenes, from which we use the official <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.2">train</span> and <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.3">val</span> split, totaling approximately 68K samples.
Virtual KITTI 2 is a synthetic urban dataset comprising 5 scenes with variations in weather and camera configurations, contributing about 25K samples to our training.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">Evaluation Datasets.</span>
For monocular depth estimation, we conduct a series of experiments to evaluate our modelâ€™s performance on four widely used benchmarks.
NYUv2Â <cite class="ltx_cite ltx_citemacro_citep">(Silberman etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib43" title="">2012</a>)</cite> and ScanNetÂ <cite class="ltx_cite ltx_citemacro_citep">(Yeshwanth etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib54" title="">2023</a>)</cite> provide RGB-D data from indoor environments captured using Kinect cameras. ETH3DÂ <cite class="ltx_cite ltx_citemacro_citep">(Schops etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib41" title="">2017</a>)</cite> features both indoor and outdoor scenes, with depth data collected by a laser scanner.
KITTIÂ <cite class="ltx_cite ltx_citemacro_citep">(Geiger etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib14" title="">2012</a>)</cite> comprises outdoor driving scenes captured by cameras and LiDAR sensors.
For video depth estimation, we sample 98 video clips from ScanNet++Â <cite class="ltx_cite ltx_citemacro_citep">(Yeshwanth etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib54" title="">2023</a>)</cite>, with each clip containing 32 frames.
The overlap ratio between adjacent frames in each clip exceeds 40%, ensuring sufficient continuity for video depth estimation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.4"><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.4.1">Evaluation Metrics.</span>
All evaluations are conducted in the zero-shot setting.
Following prior methodsÂ <cite class="ltx_cite ltx_citemacro_citep">(Ke etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib27" title="">2024</a>; Fu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib13" title="">2024</a>)</cite>, we evaluate affine-invariant depth predictions by optimizing for scale and shift between the predicted depth and the ground truth.
The quantitative comparisons are conducted with metrics AbsRel (absolute relative error: <math alttext="\frac{1}{N}\sum_{k=0}^{N-1}\frac{\left|\hat{x}_{d}-x_{d}\right|}{x_{d}}" class="ltx_Math" display="inline" id="S4.SS1.p3.1.m1.1"><semantics id="S4.SS1.p3.1.m1.1a"><mrow id="S4.SS1.p3.1.m1.1.2" xref="S4.SS1.p3.1.m1.1.2.cmml"><mfrac id="S4.SS1.p3.1.m1.1.2.2" xref="S4.SS1.p3.1.m1.1.2.2.cmml"><mn id="S4.SS1.p3.1.m1.1.2.2.2" xref="S4.SS1.p3.1.m1.1.2.2.2.cmml">1</mn><mi id="S4.SS1.p3.1.m1.1.2.2.3" xref="S4.SS1.p3.1.m1.1.2.2.3.cmml">N</mi></mfrac><mo id="S4.SS1.p3.1.m1.1.2.1" xref="S4.SS1.p3.1.m1.1.2.1.cmml">â¢</mo><mrow id="S4.SS1.p3.1.m1.1.2.3" xref="S4.SS1.p3.1.m1.1.2.3.cmml"><msubsup id="S4.SS1.p3.1.m1.1.2.3.1" xref="S4.SS1.p3.1.m1.1.2.3.1.cmml"><mo id="S4.SS1.p3.1.m1.1.2.3.1.2.2" xref="S4.SS1.p3.1.m1.1.2.3.1.2.2.cmml">âˆ‘</mo><mrow id="S4.SS1.p3.1.m1.1.2.3.1.2.3" xref="S4.SS1.p3.1.m1.1.2.3.1.2.3.cmml"><mi id="S4.SS1.p3.1.m1.1.2.3.1.2.3.2" xref="S4.SS1.p3.1.m1.1.2.3.1.2.3.2.cmml">k</mi><mo id="S4.SS1.p3.1.m1.1.2.3.1.2.3.1" xref="S4.SS1.p3.1.m1.1.2.3.1.2.3.1.cmml">=</mo><mn id="S4.SS1.p3.1.m1.1.2.3.1.2.3.3" xref="S4.SS1.p3.1.m1.1.2.3.1.2.3.3.cmml">0</mn></mrow><mrow id="S4.SS1.p3.1.m1.1.2.3.1.3" xref="S4.SS1.p3.1.m1.1.2.3.1.3.cmml"><mi id="S4.SS1.p3.1.m1.1.2.3.1.3.2" xref="S4.SS1.p3.1.m1.1.2.3.1.3.2.cmml">N</mi><mo id="S4.SS1.p3.1.m1.1.2.3.1.3.1" xref="S4.SS1.p3.1.m1.1.2.3.1.3.1.cmml">âˆ’</mo><mn id="S4.SS1.p3.1.m1.1.2.3.1.3.3" xref="S4.SS1.p3.1.m1.1.2.3.1.3.3.cmml">1</mn></mrow></msubsup><mfrac id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml"><mrow id="S4.SS1.p3.1.m1.1.1.1.1" xref="S4.SS1.p3.1.m1.1.1.1.2.cmml"><mo id="S4.SS1.p3.1.m1.1.1.1.1.2" xref="S4.SS1.p3.1.m1.1.1.1.2.1.cmml">|</mo><mrow id="S4.SS1.p3.1.m1.1.1.1.1.1" xref="S4.SS1.p3.1.m1.1.1.1.1.1.cmml"><msub id="S4.SS1.p3.1.m1.1.1.1.1.1.2" xref="S4.SS1.p3.1.m1.1.1.1.1.1.2.cmml"><mover accent="true" id="S4.SS1.p3.1.m1.1.1.1.1.1.2.2" xref="S4.SS1.p3.1.m1.1.1.1.1.1.2.2.cmml"><mi id="S4.SS1.p3.1.m1.1.1.1.1.1.2.2.2" xref="S4.SS1.p3.1.m1.1.1.1.1.1.2.2.2.cmml">x</mi><mo id="S4.SS1.p3.1.m1.1.1.1.1.1.2.2.1" xref="S4.SS1.p3.1.m1.1.1.1.1.1.2.2.1.cmml">^</mo></mover><mi id="S4.SS1.p3.1.m1.1.1.1.1.1.2.3" xref="S4.SS1.p3.1.m1.1.1.1.1.1.2.3.cmml">d</mi></msub><mo id="S4.SS1.p3.1.m1.1.1.1.1.1.1" xref="S4.SS1.p3.1.m1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S4.SS1.p3.1.m1.1.1.1.1.1.3" xref="S4.SS1.p3.1.m1.1.1.1.1.1.3.cmml"><mi id="S4.SS1.p3.1.m1.1.1.1.1.1.3.2" xref="S4.SS1.p3.1.m1.1.1.1.1.1.3.2.cmml">x</mi><mi id="S4.SS1.p3.1.m1.1.1.1.1.1.3.3" xref="S4.SS1.p3.1.m1.1.1.1.1.1.3.3.cmml">d</mi></msub></mrow><mo id="S4.SS1.p3.1.m1.1.1.1.1.3" xref="S4.SS1.p3.1.m1.1.1.1.2.1.cmml">|</mo></mrow><msub id="S4.SS1.p3.1.m1.1.1.3" xref="S4.SS1.p3.1.m1.1.1.3.cmml"><mi id="S4.SS1.p3.1.m1.1.1.3.2" xref="S4.SS1.p3.1.m1.1.1.3.2.cmml">x</mi><mi id="S4.SS1.p3.1.m1.1.1.3.3" xref="S4.SS1.p3.1.m1.1.1.3.3.cmml">d</mi></msub></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><apply id="S4.SS1.p3.1.m1.1.2.cmml" xref="S4.SS1.p3.1.m1.1.2"><times id="S4.SS1.p3.1.m1.1.2.1.cmml" xref="S4.SS1.p3.1.m1.1.2.1"></times><apply id="S4.SS1.p3.1.m1.1.2.2.cmml" xref="S4.SS1.p3.1.m1.1.2.2"><divide id="S4.SS1.p3.1.m1.1.2.2.1.cmml" xref="S4.SS1.p3.1.m1.1.2.2"></divide><cn id="S4.SS1.p3.1.m1.1.2.2.2.cmml" type="integer" xref="S4.SS1.p3.1.m1.1.2.2.2">1</cn><ci id="S4.SS1.p3.1.m1.1.2.2.3.cmml" xref="S4.SS1.p3.1.m1.1.2.2.3">ğ‘</ci></apply><apply id="S4.SS1.p3.1.m1.1.2.3.cmml" xref="S4.SS1.p3.1.m1.1.2.3"><apply id="S4.SS1.p3.1.m1.1.2.3.1.cmml" xref="S4.SS1.p3.1.m1.1.2.3.1"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.1.2.3.1.1.cmml" xref="S4.SS1.p3.1.m1.1.2.3.1">superscript</csymbol><apply id="S4.SS1.p3.1.m1.1.2.3.1.2.cmml" xref="S4.SS1.p3.1.m1.1.2.3.1"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.1.2.3.1.2.1.cmml" xref="S4.SS1.p3.1.m1.1.2.3.1">subscript</csymbol><sum id="S4.SS1.p3.1.m1.1.2.3.1.2.2.cmml" xref="S4.SS1.p3.1.m1.1.2.3.1.2.2"></sum><apply id="S4.SS1.p3.1.m1.1.2.3.1.2.3.cmml" xref="S4.SS1.p3.1.m1.1.2.3.1.2.3"><eq id="S4.SS1.p3.1.m1.1.2.3.1.2.3.1.cmml" xref="S4.SS1.p3.1.m1.1.2.3.1.2.3.1"></eq><ci id="S4.SS1.p3.1.m1.1.2.3.1.2.3.2.cmml" xref="S4.SS1.p3.1.m1.1.2.3.1.2.3.2">ğ‘˜</ci><cn id="S4.SS1.p3.1.m1.1.2.3.1.2.3.3.cmml" type="integer" xref="S4.SS1.p3.1.m1.1.2.3.1.2.3.3">0</cn></apply></apply><apply id="S4.SS1.p3.1.m1.1.2.3.1.3.cmml" xref="S4.SS1.p3.1.m1.1.2.3.1.3"><minus id="S4.SS1.p3.1.m1.1.2.3.1.3.1.cmml" xref="S4.SS1.p3.1.m1.1.2.3.1.3.1"></minus><ci id="S4.SS1.p3.1.m1.1.2.3.1.3.2.cmml" xref="S4.SS1.p3.1.m1.1.2.3.1.3.2">ğ‘</ci><cn id="S4.SS1.p3.1.m1.1.2.3.1.3.3.cmml" type="integer" xref="S4.SS1.p3.1.m1.1.2.3.1.3.3">1</cn></apply></apply><apply id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1"><divide id="S4.SS1.p3.1.m1.1.1.2.cmml" xref="S4.SS1.p3.1.m1.1.1"></divide><apply id="S4.SS1.p3.1.m1.1.1.1.2.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1"><abs id="S4.SS1.p3.1.m1.1.1.1.2.1.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1.2"></abs><apply id="S4.SS1.p3.1.m1.1.1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1.1"><minus id="S4.SS1.p3.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1.1.1"></minus><apply id="S4.SS1.p3.1.m1.1.1.1.1.1.2.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.1.1.1.1.1.2.1.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1.1.2">subscript</csymbol><apply id="S4.SS1.p3.1.m1.1.1.1.1.1.2.2.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1.1.2.2"><ci id="S4.SS1.p3.1.m1.1.1.1.1.1.2.2.1.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1.1.2.2.1">^</ci><ci id="S4.SS1.p3.1.m1.1.1.1.1.1.2.2.2.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1.1.2.2.2">ğ‘¥</ci></apply><ci id="S4.SS1.p3.1.m1.1.1.1.1.1.2.3.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1.1.2.3">ğ‘‘</ci></apply><apply id="S4.SS1.p3.1.m1.1.1.1.1.1.3.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.1.1.1.1.1.3.1.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.SS1.p3.1.m1.1.1.1.1.1.3.2.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1.1.3.2">ğ‘¥</ci><ci id="S4.SS1.p3.1.m1.1.1.1.1.1.3.3.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1.1.3.3">ğ‘‘</ci></apply></apply></apply><apply id="S4.SS1.p3.1.m1.1.1.3.cmml" xref="S4.SS1.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.1.1.3.1.cmml" xref="S4.SS1.p3.1.m1.1.1.3">subscript</csymbol><ci id="S4.SS1.p3.1.m1.1.1.3.2.cmml" xref="S4.SS1.p3.1.m1.1.1.3.2">ğ‘¥</ci><ci id="S4.SS1.p3.1.m1.1.1.3.3.cmml" xref="S4.SS1.p3.1.m1.1.1.3.3">ğ‘‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">\frac{1}{N}\sum_{k=0}^{N-1}\frac{\left|\hat{x}_{d}-x_{d}\right|}{x_{d}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.1.m1.1d">divide start_ARG 1 end_ARG start_ARG italic_N end_ARG âˆ‘ start_POSTSUBSCRIPT italic_k = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N - 1 end_POSTSUPERSCRIPT divide start_ARG | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT - italic_x start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT | end_ARG start_ARG italic_x start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT end_ARG</annotation></semantics></math>, where <math alttext="N" class="ltx_Math" display="inline" id="S4.SS1.p3.2.m2.1"><semantics id="S4.SS1.p3.2.m2.1a"><mi id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><ci id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.2.m2.1d">italic_N</annotation></semantics></math> denoting the number of pixels) and and <math alttext="\delta 1" class="ltx_Math" display="inline" id="S4.SS1.p3.3.m3.1"><semantics id="S4.SS1.p3.3.m3.1a"><mrow id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml"><mi id="S4.SS1.p3.3.m3.1.1.2" xref="S4.SS1.p3.3.m3.1.1.2.cmml">Î´</mi><mo id="S4.SS1.p3.3.m3.1.1.1" xref="S4.SS1.p3.3.m3.1.1.1.cmml">â¢</mo><mn id="S4.SS1.p3.3.m3.1.1.3" xref="S4.SS1.p3.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><apply id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1"><times id="S4.SS1.p3.3.m3.1.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1.1"></times><ci id="S4.SS1.p3.3.m3.1.1.2.cmml" xref="S4.SS1.p3.3.m3.1.1.2">ğ›¿</ci><cn id="S4.SS1.p3.3.m3.1.1.3.cmml" type="integer" xref="S4.SS1.p3.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">\delta 1</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.3.m3.1d">italic_Î´ 1</annotation></semantics></math> accuracy (percentage of <math alttext="\frac{1}{N}\sum_{k=0}^{N-1}\max(\frac{\hat{x}_{d}}{x_{d}},\frac{x_{d}}{\hat{x}%
_{d}})&lt;1.25" class="ltx_Math" display="inline" id="S4.SS1.p3.4.m4.3"><semantics id="S4.SS1.p3.4.m4.3a"><mrow id="S4.SS1.p3.4.m4.3.4" xref="S4.SS1.p3.4.m4.3.4.cmml"><mrow id="S4.SS1.p3.4.m4.3.4.2" xref="S4.SS1.p3.4.m4.3.4.2.cmml"><mfrac id="S4.SS1.p3.4.m4.3.4.2.2" xref="S4.SS1.p3.4.m4.3.4.2.2.cmml"><mn id="S4.SS1.p3.4.m4.3.4.2.2.2" xref="S4.SS1.p3.4.m4.3.4.2.2.2.cmml">1</mn><mi id="S4.SS1.p3.4.m4.3.4.2.2.3" xref="S4.SS1.p3.4.m4.3.4.2.2.3.cmml">N</mi></mfrac><mo id="S4.SS1.p3.4.m4.3.4.2.1" xref="S4.SS1.p3.4.m4.3.4.2.1.cmml">â¢</mo><mrow id="S4.SS1.p3.4.m4.3.4.2.3" xref="S4.SS1.p3.4.m4.3.4.2.3.cmml"><msubsup id="S4.SS1.p3.4.m4.3.4.2.3.1" xref="S4.SS1.p3.4.m4.3.4.2.3.1.cmml"><mo id="S4.SS1.p3.4.m4.3.4.2.3.1.2.2" xref="S4.SS1.p3.4.m4.3.4.2.3.1.2.2.cmml">âˆ‘</mo><mrow id="S4.SS1.p3.4.m4.3.4.2.3.1.2.3" xref="S4.SS1.p3.4.m4.3.4.2.3.1.2.3.cmml"><mi id="S4.SS1.p3.4.m4.3.4.2.3.1.2.3.2" xref="S4.SS1.p3.4.m4.3.4.2.3.1.2.3.2.cmml">k</mi><mo id="S4.SS1.p3.4.m4.3.4.2.3.1.2.3.1" xref="S4.SS1.p3.4.m4.3.4.2.3.1.2.3.1.cmml">=</mo><mn id="S4.SS1.p3.4.m4.3.4.2.3.1.2.3.3" xref="S4.SS1.p3.4.m4.3.4.2.3.1.2.3.3.cmml">0</mn></mrow><mrow id="S4.SS1.p3.4.m4.3.4.2.3.1.3" xref="S4.SS1.p3.4.m4.3.4.2.3.1.3.cmml"><mi id="S4.SS1.p3.4.m4.3.4.2.3.1.3.2" xref="S4.SS1.p3.4.m4.3.4.2.3.1.3.2.cmml">N</mi><mo id="S4.SS1.p3.4.m4.3.4.2.3.1.3.1" xref="S4.SS1.p3.4.m4.3.4.2.3.1.3.1.cmml">âˆ’</mo><mn id="S4.SS1.p3.4.m4.3.4.2.3.1.3.3" xref="S4.SS1.p3.4.m4.3.4.2.3.1.3.3.cmml">1</mn></mrow></msubsup><mrow id="S4.SS1.p3.4.m4.3.4.2.3.2.2" xref="S4.SS1.p3.4.m4.3.4.2.3.2.1.cmml"><mi id="S4.SS1.p3.4.m4.1.1" xref="S4.SS1.p3.4.m4.1.1.cmml">max</mi><mo id="S4.SS1.p3.4.m4.3.4.2.3.2.2a" xref="S4.SS1.p3.4.m4.3.4.2.3.2.1.cmml">â¡</mo><mrow id="S4.SS1.p3.4.m4.3.4.2.3.2.2.1" xref="S4.SS1.p3.4.m4.3.4.2.3.2.1.cmml"><mo id="S4.SS1.p3.4.m4.3.4.2.3.2.2.1.1" stretchy="false" xref="S4.SS1.p3.4.m4.3.4.2.3.2.1.cmml">(</mo><mfrac id="S4.SS1.p3.4.m4.2.2" xref="S4.SS1.p3.4.m4.2.2.cmml"><msub id="S4.SS1.p3.4.m4.2.2.2" xref="S4.SS1.p3.4.m4.2.2.2.cmml"><mover accent="true" id="S4.SS1.p3.4.m4.2.2.2.2" xref="S4.SS1.p3.4.m4.2.2.2.2.cmml"><mi id="S4.SS1.p3.4.m4.2.2.2.2.2" xref="S4.SS1.p3.4.m4.2.2.2.2.2.cmml">x</mi><mo id="S4.SS1.p3.4.m4.2.2.2.2.1" xref="S4.SS1.p3.4.m4.2.2.2.2.1.cmml">^</mo></mover><mi id="S4.SS1.p3.4.m4.2.2.2.3" xref="S4.SS1.p3.4.m4.2.2.2.3.cmml">d</mi></msub><msub id="S4.SS1.p3.4.m4.2.2.3" xref="S4.SS1.p3.4.m4.2.2.3.cmml"><mi id="S4.SS1.p3.4.m4.2.2.3.2" xref="S4.SS1.p3.4.m4.2.2.3.2.cmml">x</mi><mi id="S4.SS1.p3.4.m4.2.2.3.3" xref="S4.SS1.p3.4.m4.2.2.3.3.cmml">d</mi></msub></mfrac><mo id="S4.SS1.p3.4.m4.3.4.2.3.2.2.1.2" xref="S4.SS1.p3.4.m4.3.4.2.3.2.1.cmml">,</mo><mfrac id="S4.SS1.p3.4.m4.3.3" xref="S4.SS1.p3.4.m4.3.3.cmml"><msub id="S4.SS1.p3.4.m4.3.3.2" xref="S4.SS1.p3.4.m4.3.3.2.cmml"><mi id="S4.SS1.p3.4.m4.3.3.2.2" xref="S4.SS1.p3.4.m4.3.3.2.2.cmml">x</mi><mi id="S4.SS1.p3.4.m4.3.3.2.3" xref="S4.SS1.p3.4.m4.3.3.2.3.cmml">d</mi></msub><msub id="S4.SS1.p3.4.m4.3.3.3" xref="S4.SS1.p3.4.m4.3.3.3.cmml"><mover accent="true" id="S4.SS1.p3.4.m4.3.3.3.2" xref="S4.SS1.p3.4.m4.3.3.3.2.cmml"><mi id="S4.SS1.p3.4.m4.3.3.3.2.2" xref="S4.SS1.p3.4.m4.3.3.3.2.2.cmml">x</mi><mo id="S4.SS1.p3.4.m4.3.3.3.2.1" xref="S4.SS1.p3.4.m4.3.3.3.2.1.cmml">^</mo></mover><mi id="S4.SS1.p3.4.m4.3.3.3.3" xref="S4.SS1.p3.4.m4.3.3.3.3.cmml">d</mi></msub></mfrac><mo id="S4.SS1.p3.4.m4.3.4.2.3.2.2.1.3" stretchy="false" xref="S4.SS1.p3.4.m4.3.4.2.3.2.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S4.SS1.p3.4.m4.3.4.1" xref="S4.SS1.p3.4.m4.3.4.1.cmml">&lt;</mo><mn id="S4.SS1.p3.4.m4.3.4.3" xref="S4.SS1.p3.4.m4.3.4.3.cmml">1.25</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.4.m4.3b"><apply id="S4.SS1.p3.4.m4.3.4.cmml" xref="S4.SS1.p3.4.m4.3.4"><lt id="S4.SS1.p3.4.m4.3.4.1.cmml" xref="S4.SS1.p3.4.m4.3.4.1"></lt><apply id="S4.SS1.p3.4.m4.3.4.2.cmml" xref="S4.SS1.p3.4.m4.3.4.2"><times id="S4.SS1.p3.4.m4.3.4.2.1.cmml" xref="S4.SS1.p3.4.m4.3.4.2.1"></times><apply id="S4.SS1.p3.4.m4.3.4.2.2.cmml" xref="S4.SS1.p3.4.m4.3.4.2.2"><divide id="S4.SS1.p3.4.m4.3.4.2.2.1.cmml" xref="S4.SS1.p3.4.m4.3.4.2.2"></divide><cn id="S4.SS1.p3.4.m4.3.4.2.2.2.cmml" type="integer" xref="S4.SS1.p3.4.m4.3.4.2.2.2">1</cn><ci id="S4.SS1.p3.4.m4.3.4.2.2.3.cmml" xref="S4.SS1.p3.4.m4.3.4.2.2.3">ğ‘</ci></apply><apply id="S4.SS1.p3.4.m4.3.4.2.3.cmml" xref="S4.SS1.p3.4.m4.3.4.2.3"><apply id="S4.SS1.p3.4.m4.3.4.2.3.1.cmml" xref="S4.SS1.p3.4.m4.3.4.2.3.1"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.3.4.2.3.1.1.cmml" xref="S4.SS1.p3.4.m4.3.4.2.3.1">superscript</csymbol><apply id="S4.SS1.p3.4.m4.3.4.2.3.1.2.cmml" xref="S4.SS1.p3.4.m4.3.4.2.3.1"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.3.4.2.3.1.2.1.cmml" xref="S4.SS1.p3.4.m4.3.4.2.3.1">subscript</csymbol><sum id="S4.SS1.p3.4.m4.3.4.2.3.1.2.2.cmml" xref="S4.SS1.p3.4.m4.3.4.2.3.1.2.2"></sum><apply id="S4.SS1.p3.4.m4.3.4.2.3.1.2.3.cmml" xref="S4.SS1.p3.4.m4.3.4.2.3.1.2.3"><eq id="S4.SS1.p3.4.m4.3.4.2.3.1.2.3.1.cmml" xref="S4.SS1.p3.4.m4.3.4.2.3.1.2.3.1"></eq><ci id="S4.SS1.p3.4.m4.3.4.2.3.1.2.3.2.cmml" xref="S4.SS1.p3.4.m4.3.4.2.3.1.2.3.2">ğ‘˜</ci><cn id="S4.SS1.p3.4.m4.3.4.2.3.1.2.3.3.cmml" type="integer" xref="S4.SS1.p3.4.m4.3.4.2.3.1.2.3.3">0</cn></apply></apply><apply id="S4.SS1.p3.4.m4.3.4.2.3.1.3.cmml" xref="S4.SS1.p3.4.m4.3.4.2.3.1.3"><minus id="S4.SS1.p3.4.m4.3.4.2.3.1.3.1.cmml" xref="S4.SS1.p3.4.m4.3.4.2.3.1.3.1"></minus><ci id="S4.SS1.p3.4.m4.3.4.2.3.1.3.2.cmml" xref="S4.SS1.p3.4.m4.3.4.2.3.1.3.2">ğ‘</ci><cn id="S4.SS1.p3.4.m4.3.4.2.3.1.3.3.cmml" type="integer" xref="S4.SS1.p3.4.m4.3.4.2.3.1.3.3">1</cn></apply></apply><apply id="S4.SS1.p3.4.m4.3.4.2.3.2.1.cmml" xref="S4.SS1.p3.4.m4.3.4.2.3.2.2"><max id="S4.SS1.p3.4.m4.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1"></max><apply id="S4.SS1.p3.4.m4.2.2.cmml" xref="S4.SS1.p3.4.m4.2.2"><divide id="S4.SS1.p3.4.m4.2.2.1.cmml" xref="S4.SS1.p3.4.m4.2.2"></divide><apply id="S4.SS1.p3.4.m4.2.2.2.cmml" xref="S4.SS1.p3.4.m4.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.2.2.2.1.cmml" xref="S4.SS1.p3.4.m4.2.2.2">subscript</csymbol><apply id="S4.SS1.p3.4.m4.2.2.2.2.cmml" xref="S4.SS1.p3.4.m4.2.2.2.2"><ci id="S4.SS1.p3.4.m4.2.2.2.2.1.cmml" xref="S4.SS1.p3.4.m4.2.2.2.2.1">^</ci><ci id="S4.SS1.p3.4.m4.2.2.2.2.2.cmml" xref="S4.SS1.p3.4.m4.2.2.2.2.2">ğ‘¥</ci></apply><ci id="S4.SS1.p3.4.m4.2.2.2.3.cmml" xref="S4.SS1.p3.4.m4.2.2.2.3">ğ‘‘</ci></apply><apply id="S4.SS1.p3.4.m4.2.2.3.cmml" xref="S4.SS1.p3.4.m4.2.2.3"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.2.2.3.1.cmml" xref="S4.SS1.p3.4.m4.2.2.3">subscript</csymbol><ci id="S4.SS1.p3.4.m4.2.2.3.2.cmml" xref="S4.SS1.p3.4.m4.2.2.3.2">ğ‘¥</ci><ci id="S4.SS1.p3.4.m4.2.2.3.3.cmml" xref="S4.SS1.p3.4.m4.2.2.3.3">ğ‘‘</ci></apply></apply><apply id="S4.SS1.p3.4.m4.3.3.cmml" xref="S4.SS1.p3.4.m4.3.3"><divide id="S4.SS1.p3.4.m4.3.3.1.cmml" xref="S4.SS1.p3.4.m4.3.3"></divide><apply id="S4.SS1.p3.4.m4.3.3.2.cmml" xref="S4.SS1.p3.4.m4.3.3.2"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.3.3.2.1.cmml" xref="S4.SS1.p3.4.m4.3.3.2">subscript</csymbol><ci id="S4.SS1.p3.4.m4.3.3.2.2.cmml" xref="S4.SS1.p3.4.m4.3.3.2.2">ğ‘¥</ci><ci id="S4.SS1.p3.4.m4.3.3.2.3.cmml" xref="S4.SS1.p3.4.m4.3.3.2.3">ğ‘‘</ci></apply><apply id="S4.SS1.p3.4.m4.3.3.3.cmml" xref="S4.SS1.p3.4.m4.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.3.3.3.1.cmml" xref="S4.SS1.p3.4.m4.3.3.3">subscript</csymbol><apply id="S4.SS1.p3.4.m4.3.3.3.2.cmml" xref="S4.SS1.p3.4.m4.3.3.3.2"><ci id="S4.SS1.p3.4.m4.3.3.3.2.1.cmml" xref="S4.SS1.p3.4.m4.3.3.3.2.1">^</ci><ci id="S4.SS1.p3.4.m4.3.3.3.2.2.cmml" xref="S4.SS1.p3.4.m4.3.3.3.2.2">ğ‘¥</ci></apply><ci id="S4.SS1.p3.4.m4.3.3.3.3.cmml" xref="S4.SS1.p3.4.m4.3.3.3.3">ğ‘‘</ci></apply></apply></apply></apply></apply><cn id="S4.SS1.p3.4.m4.3.4.3.cmml" type="float" xref="S4.SS1.p3.4.m4.3.4.3">1.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.4.m4.3c">\frac{1}{N}\sum_{k=0}^{N-1}\max(\frac{\hat{x}_{d}}{x_{d}},\frac{x_{d}}{\hat{x}%
_{d}})&lt;1.25</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.4.m4.3d">divide start_ARG 1 end_ARG start_ARG italic_N end_ARG âˆ‘ start_POSTSUBSCRIPT italic_k = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N - 1 end_POSTSUPERSCRIPT roman_max ( divide start_ARG over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT end_ARG start_ARG italic_x start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT end_ARG , divide start_ARG italic_x start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT end_ARG start_ARG over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT end_ARG ) &lt; 1.25</annotation></semantics></math>).
To assess the temporal consistency of video depth, we further introduce the temporal alignment error (TAE):</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{TAE}=\frac{1}{2(T-2)}\sum_{k=0}^{T-1}\text{AbsRel}\left(f(\hat{x}_{d}^{k%
},p^{k}),\hat{x}_{d}^{k+1}\right)+\text{AbsRel}\left(f(\hat{x}_{d}^{k+1},p_{-}%
^{k+1}),\hat{x}_{d}^{k}\right)," class="ltx_Math" display="block" id="S4.E7.m1.2"><semantics id="S4.E7.m1.2a"><mrow id="S4.E7.m1.2.2.1" xref="S4.E7.m1.2.2.1.1.cmml"><mrow id="S4.E7.m1.2.2.1.1" xref="S4.E7.m1.2.2.1.1.cmml"><mtext id="S4.E7.m1.2.2.1.1.6" xref="S4.E7.m1.2.2.1.1.6a.cmml">TAE</mtext><mo id="S4.E7.m1.2.2.1.1.5" xref="S4.E7.m1.2.2.1.1.5.cmml">=</mo><mrow id="S4.E7.m1.2.2.1.1.4" xref="S4.E7.m1.2.2.1.1.4.cmml"><mrow id="S4.E7.m1.2.2.1.1.2.2" xref="S4.E7.m1.2.2.1.1.2.2.cmml"><mfrac id="S4.E7.m1.1.1" xref="S4.E7.m1.1.1.cmml"><mn id="S4.E7.m1.1.1.3" xref="S4.E7.m1.1.1.3.cmml">1</mn><mrow id="S4.E7.m1.1.1.1" xref="S4.E7.m1.1.1.1.cmml"><mn id="S4.E7.m1.1.1.1.3" xref="S4.E7.m1.1.1.1.3.cmml">2</mn><mo id="S4.E7.m1.1.1.1.2" xref="S4.E7.m1.1.1.1.2.cmml">â¢</mo><mrow id="S4.E7.m1.1.1.1.1.1" xref="S4.E7.m1.1.1.1.1.1.1.cmml"><mo id="S4.E7.m1.1.1.1.1.1.2" stretchy="false" xref="S4.E7.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E7.m1.1.1.1.1.1.1" xref="S4.E7.m1.1.1.1.1.1.1.cmml"><mi id="S4.E7.m1.1.1.1.1.1.1.2" xref="S4.E7.m1.1.1.1.1.1.1.2.cmml">T</mi><mo id="S4.E7.m1.1.1.1.1.1.1.1" xref="S4.E7.m1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mn id="S4.E7.m1.1.1.1.1.1.1.3" xref="S4.E7.m1.1.1.1.1.1.1.3.cmml">2</mn></mrow><mo id="S4.E7.m1.1.1.1.1.1.3" stretchy="false" xref="S4.E7.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mfrac><mo id="S4.E7.m1.2.2.1.1.2.2.3" xref="S4.E7.m1.2.2.1.1.2.2.3.cmml">â¢</mo><mrow id="S4.E7.m1.2.2.1.1.2.2.2" xref="S4.E7.m1.2.2.1.1.2.2.2.cmml"><munderover id="S4.E7.m1.2.2.1.1.2.2.2.3" xref="S4.E7.m1.2.2.1.1.2.2.2.3.cmml"><mo id="S4.E7.m1.2.2.1.1.2.2.2.3.2.2" movablelimits="false" xref="S4.E7.m1.2.2.1.1.2.2.2.3.2.2.cmml">âˆ‘</mo><mrow id="S4.E7.m1.2.2.1.1.2.2.2.3.2.3" xref="S4.E7.m1.2.2.1.1.2.2.2.3.2.3.cmml"><mi id="S4.E7.m1.2.2.1.1.2.2.2.3.2.3.2" xref="S4.E7.m1.2.2.1.1.2.2.2.3.2.3.2.cmml">k</mi><mo id="S4.E7.m1.2.2.1.1.2.2.2.3.2.3.1" xref="S4.E7.m1.2.2.1.1.2.2.2.3.2.3.1.cmml">=</mo><mn id="S4.E7.m1.2.2.1.1.2.2.2.3.2.3.3" xref="S4.E7.m1.2.2.1.1.2.2.2.3.2.3.3.cmml">0</mn></mrow><mrow id="S4.E7.m1.2.2.1.1.2.2.2.3.3" xref="S4.E7.m1.2.2.1.1.2.2.2.3.3.cmml"><mi id="S4.E7.m1.2.2.1.1.2.2.2.3.3.2" xref="S4.E7.m1.2.2.1.1.2.2.2.3.3.2.cmml">T</mi><mo id="S4.E7.m1.2.2.1.1.2.2.2.3.3.1" xref="S4.E7.m1.2.2.1.1.2.2.2.3.3.1.cmml">âˆ’</mo><mn id="S4.E7.m1.2.2.1.1.2.2.2.3.3.3" xref="S4.E7.m1.2.2.1.1.2.2.2.3.3.3.cmml">1</mn></mrow></munderover><mrow id="S4.E7.m1.2.2.1.1.2.2.2.2" xref="S4.E7.m1.2.2.1.1.2.2.2.2.cmml"><mtext id="S4.E7.m1.2.2.1.1.2.2.2.2.4" xref="S4.E7.m1.2.2.1.1.2.2.2.2.4a.cmml">AbsRel</mtext><mo id="S4.E7.m1.2.2.1.1.2.2.2.2.3" xref="S4.E7.m1.2.2.1.1.2.2.2.2.3.cmml">â¢</mo><mrow id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.3.cmml"><mo id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.3" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.3.cmml">(</mo><mrow id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.4" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.4.cmml">f</mi><mo id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">â¢</mo><mrow id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.cmml"><mo id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.3" stretchy="false" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.cmml">(</mo><msubsup id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">x</mi><mo id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.2.1" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml">^</mo></mover><mi id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">d</mi><mi id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">k</mi></msubsup><mo id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.4" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.cmml">,</mo><msup id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml">p</mi><mi id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml">k</mi></msup><mo id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.5" stretchy="false" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.4" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.3.cmml">,</mo><msubsup id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.cmml"><mover accent="true" id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.2" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.cmml"><mi id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.2" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.2.cmml">x</mi><mo id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.1" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.1.cmml">^</mo></mover><mi id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.3" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.3.cmml">d</mi><mrow id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.3" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.3.cmml"><mi id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.3.2" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.3.2.cmml">k</mi><mo id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.3.1" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.3.1.cmml">+</mo><mn id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.3.3" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.3.3.cmml">1</mn></mrow></msubsup><mo id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.5" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S4.E7.m1.2.2.1.1.4.5" xref="S4.E7.m1.2.2.1.1.4.5.cmml">+</mo><mrow id="S4.E7.m1.2.2.1.1.4.4" xref="S4.E7.m1.2.2.1.1.4.4.cmml"><mtext id="S4.E7.m1.2.2.1.1.4.4.4" xref="S4.E7.m1.2.2.1.1.4.4.4a.cmml">AbsRel</mtext><mo id="S4.E7.m1.2.2.1.1.4.4.3" xref="S4.E7.m1.2.2.1.1.4.4.3.cmml">â¢</mo><mrow id="S4.E7.m1.2.2.1.1.4.4.2.2" xref="S4.E7.m1.2.2.1.1.4.4.2.3.cmml"><mo id="S4.E7.m1.2.2.1.1.4.4.2.2.3" xref="S4.E7.m1.2.2.1.1.4.4.2.3.cmml">(</mo><mrow id="S4.E7.m1.2.2.1.1.3.3.1.1.1" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.cmml"><mi id="S4.E7.m1.2.2.1.1.3.3.1.1.1.4" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.4.cmml">f</mi><mo id="S4.E7.m1.2.2.1.1.3.3.1.1.1.3" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.3.cmml">â¢</mo><mrow id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.3.cmml"><mo id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.3" stretchy="false" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.3.cmml">(</mo><msubsup id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.cmml"><mover accent="true" id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.2" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.2.cmml"><mi id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.2.2" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.2.2.cmml">x</mi><mo id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.2.1" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.2.1.cmml">^</mo></mover><mi id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.3" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.3.cmml">d</mi><mrow id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.3" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.3.cmml"><mi id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.3.2" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.3.2.cmml">k</mi><mo id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.3.1" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.3.1.cmml">+</mo><mn id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.3.3" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msubsup><mo id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.4" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.3.cmml">,</mo><msubsup id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.cmml"><mi id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.2.2" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.2.2.cmml">p</mi><mo id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.2.3" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.2.3.cmml">âˆ’</mo><mrow id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.3" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.3.cmml"><mi id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.3.2" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.3.2.cmml">k</mi><mo id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.3.1" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.3.1.cmml">+</mo><mn id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.3.3" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.3.3.cmml">1</mn></mrow></msubsup><mo id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.5" stretchy="false" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S4.E7.m1.2.2.1.1.4.4.2.2.4" xref="S4.E7.m1.2.2.1.1.4.4.2.3.cmml">,</mo><msubsup id="S4.E7.m1.2.2.1.1.4.4.2.2.2" xref="S4.E7.m1.2.2.1.1.4.4.2.2.2.cmml"><mover accent="true" id="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.2" xref="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.2.cmml"><mi id="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.2.2" xref="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.2.2.cmml">x</mi><mo id="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.2.1" xref="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.2.1.cmml">^</mo></mover><mi id="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.3" xref="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.3.cmml">d</mi><mi id="S4.E7.m1.2.2.1.1.4.4.2.2.2.3" xref="S4.E7.m1.2.2.1.1.4.4.2.2.2.3.cmml">k</mi></msubsup><mo id="S4.E7.m1.2.2.1.1.4.4.2.2.5" xref="S4.E7.m1.2.2.1.1.4.4.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S4.E7.m1.2.2.1.2" xref="S4.E7.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E7.m1.2b"><apply id="S4.E7.m1.2.2.1.1.cmml" xref="S4.E7.m1.2.2.1"><eq id="S4.E7.m1.2.2.1.1.5.cmml" xref="S4.E7.m1.2.2.1.1.5"></eq><ci id="S4.E7.m1.2.2.1.1.6a.cmml" xref="S4.E7.m1.2.2.1.1.6"><mtext id="S4.E7.m1.2.2.1.1.6.cmml" xref="S4.E7.m1.2.2.1.1.6">TAE</mtext></ci><apply id="S4.E7.m1.2.2.1.1.4.cmml" xref="S4.E7.m1.2.2.1.1.4"><plus id="S4.E7.m1.2.2.1.1.4.5.cmml" xref="S4.E7.m1.2.2.1.1.4.5"></plus><apply id="S4.E7.m1.2.2.1.1.2.2.cmml" xref="S4.E7.m1.2.2.1.1.2.2"><times id="S4.E7.m1.2.2.1.1.2.2.3.cmml" xref="S4.E7.m1.2.2.1.1.2.2.3"></times><apply id="S4.E7.m1.1.1.cmml" xref="S4.E7.m1.1.1"><divide id="S4.E7.m1.1.1.2.cmml" xref="S4.E7.m1.1.1"></divide><cn id="S4.E7.m1.1.1.3.cmml" type="integer" xref="S4.E7.m1.1.1.3">1</cn><apply id="S4.E7.m1.1.1.1.cmml" xref="S4.E7.m1.1.1.1"><times id="S4.E7.m1.1.1.1.2.cmml" xref="S4.E7.m1.1.1.1.2"></times><cn id="S4.E7.m1.1.1.1.3.cmml" type="integer" xref="S4.E7.m1.1.1.1.3">2</cn><apply id="S4.E7.m1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.1.1.1.1.1"><minus id="S4.E7.m1.1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1"></minus><ci id="S4.E7.m1.1.1.1.1.1.1.2.cmml" xref="S4.E7.m1.1.1.1.1.1.1.2">ğ‘‡</ci><cn id="S4.E7.m1.1.1.1.1.1.1.3.cmml" type="integer" xref="S4.E7.m1.1.1.1.1.1.1.3">2</cn></apply></apply></apply><apply id="S4.E7.m1.2.2.1.1.2.2.2.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2"><apply id="S4.E7.m1.2.2.1.1.2.2.2.3.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.2.2.2.3.1.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.3">superscript</csymbol><apply id="S4.E7.m1.2.2.1.1.2.2.2.3.2.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.2.2.2.3.2.1.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.3">subscript</csymbol><sum id="S4.E7.m1.2.2.1.1.2.2.2.3.2.2.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.3.2.2"></sum><apply id="S4.E7.m1.2.2.1.1.2.2.2.3.2.3.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.3.2.3"><eq id="S4.E7.m1.2.2.1.1.2.2.2.3.2.3.1.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.3.2.3.1"></eq><ci id="S4.E7.m1.2.2.1.1.2.2.2.3.2.3.2.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.3.2.3.2">ğ‘˜</ci><cn id="S4.E7.m1.2.2.1.1.2.2.2.3.2.3.3.cmml" type="integer" xref="S4.E7.m1.2.2.1.1.2.2.2.3.2.3.3">0</cn></apply></apply><apply id="S4.E7.m1.2.2.1.1.2.2.2.3.3.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.3.3"><minus id="S4.E7.m1.2.2.1.1.2.2.2.3.3.1.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.3.3.1"></minus><ci id="S4.E7.m1.2.2.1.1.2.2.2.3.3.2.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.3.3.2">ğ‘‡</ci><cn id="S4.E7.m1.2.2.1.1.2.2.2.3.3.3.cmml" type="integer" xref="S4.E7.m1.2.2.1.1.2.2.2.3.3.3">1</cn></apply></apply><apply id="S4.E7.m1.2.2.1.1.2.2.2.2.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.2"><times id="S4.E7.m1.2.2.1.1.2.2.2.2.3.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.2.3"></times><ci id="S4.E7.m1.2.2.1.1.2.2.2.2.4a.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.2.4"><mtext id="S4.E7.m1.2.2.1.1.2.2.2.2.4.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.2.4">AbsRel</mtext></ci><interval closure="open" id="S4.E7.m1.2.2.1.1.2.2.2.2.2.3.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2"><apply id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1"><times id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.3"></times><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.4.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.4">ğ‘“</ci><interval closure="open" id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2"><apply id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.2"><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.2.1">^</ci><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2">ğ‘¥</ci></apply><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.3">ğ‘‘</ci></apply><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘˜</ci></apply><apply id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2">superscript</csymbol><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.2">ğ‘</ci><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.3">ğ‘˜</ci></apply></interval></apply><apply id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.1.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2">superscript</csymbol><apply id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.1.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2">subscript</csymbol><apply id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.2"><ci id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.1.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.1">^</ci><ci id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.2.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.2">ğ‘¥</ci></apply><ci id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.3.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.2.3">ğ‘‘</ci></apply><apply id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.3.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.3"><plus id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.3.1.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.3.1"></plus><ci id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.3.2.cmml" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.3.2">ğ‘˜</ci><cn id="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.3.3.cmml" type="integer" xref="S4.E7.m1.2.2.1.1.2.2.2.2.2.2.2.3.3">1</cn></apply></apply></interval></apply></apply></apply><apply id="S4.E7.m1.2.2.1.1.4.4.cmml" xref="S4.E7.m1.2.2.1.1.4.4"><times id="S4.E7.m1.2.2.1.1.4.4.3.cmml" xref="S4.E7.m1.2.2.1.1.4.4.3"></times><ci id="S4.E7.m1.2.2.1.1.4.4.4a.cmml" xref="S4.E7.m1.2.2.1.1.4.4.4"><mtext id="S4.E7.m1.2.2.1.1.4.4.4.cmml" xref="S4.E7.m1.2.2.1.1.4.4.4">AbsRel</mtext></ci><interval closure="open" id="S4.E7.m1.2.2.1.1.4.4.2.3.cmml" xref="S4.E7.m1.2.2.1.1.4.4.2.2"><apply id="S4.E7.m1.2.2.1.1.3.3.1.1.1.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1"><times id="S4.E7.m1.2.2.1.1.3.3.1.1.1.3.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.3"></times><ci id="S4.E7.m1.2.2.1.1.3.3.1.1.1.4.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.4">ğ‘“</ci><interval closure="open" id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.3.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2"><apply id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1">superscript</csymbol><apply id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.1.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1">subscript</csymbol><apply id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.2.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.2"><ci id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.2.1.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.2.1">^</ci><ci id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.2.2">ğ‘¥</ci></apply><ci id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.3.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.2.3">ğ‘‘</ci></apply><apply id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.3.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.3"><plus id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.3.1.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.3.1"></plus><ci id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.3.2.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.3.2">ğ‘˜</ci><cn id="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.3.3.cmml" type="integer" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.1.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2">superscript</csymbol><apply id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.2.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.2.1.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2">subscript</csymbol><ci id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.2.2.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.2.2">ğ‘</ci><minus id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.2.3.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.2.3"></minus></apply><apply id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.3.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.3"><plus id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.3.1.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.3.1"></plus><ci id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.3.2.cmml" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.3.2">ğ‘˜</ci><cn id="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.3.3.cmml" type="integer" xref="S4.E7.m1.2.2.1.1.3.3.1.1.1.2.2.2.3.3">1</cn></apply></apply></interval></apply><apply id="S4.E7.m1.2.2.1.1.4.4.2.2.2.cmml" xref="S4.E7.m1.2.2.1.1.4.4.2.2.2"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.4.4.2.2.2.1.cmml" xref="S4.E7.m1.2.2.1.1.4.4.2.2.2">superscript</csymbol><apply id="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.cmml" xref="S4.E7.m1.2.2.1.1.4.4.2.2.2"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.1.cmml" xref="S4.E7.m1.2.2.1.1.4.4.2.2.2">subscript</csymbol><apply id="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.2.cmml" xref="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.2"><ci id="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.2.1.cmml" xref="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.2.1">^</ci><ci id="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.2.2.cmml" xref="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.2.2">ğ‘¥</ci></apply><ci id="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.3.cmml" xref="S4.E7.m1.2.2.1.1.4.4.2.2.2.2.3">ğ‘‘</ci></apply><ci id="S4.E7.m1.2.2.1.1.4.4.2.2.2.3.cmml" xref="S4.E7.m1.2.2.1.1.4.4.2.2.2.3">ğ‘˜</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E7.m1.2c">\text{TAE}=\frac{1}{2(T-2)}\sum_{k=0}^{T-1}\text{AbsRel}\left(f(\hat{x}_{d}^{k%
},p^{k}),\hat{x}_{d}^{k+1}\right)+\text{AbsRel}\left(f(\hat{x}_{d}^{k+1},p_{-}%
^{k+1}),\hat{x}_{d}^{k}\right),</annotation><annotation encoding="application/x-llamapun" id="S4.E7.m1.2d">TAE = divide start_ARG 1 end_ARG start_ARG 2 ( italic_T - 2 ) end_ARG âˆ‘ start_POSTSUBSCRIPT italic_k = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T - 1 end_POSTSUPERSCRIPT AbsRel ( italic_f ( over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT , italic_p start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ) , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k + 1 end_POSTSUPERSCRIPT ) + AbsRel ( italic_f ( over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k + 1 end_POSTSUPERSCRIPT , italic_p start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k + 1 end_POSTSUPERSCRIPT ) , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS1.p3.11">where <math alttext="T" class="ltx_Math" display="inline" id="S4.SS1.p3.5.m1.1"><semantics id="S4.SS1.p3.5.m1.1a"><mi id="S4.SS1.p3.5.m1.1.1" xref="S4.SS1.p3.5.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.5.m1.1b"><ci id="S4.SS1.p3.5.m1.1.1.cmml" xref="S4.SS1.p3.5.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.5.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.5.m1.1d">italic_T</annotation></semantics></math> is the number of frames, <math alttext="f" class="ltx_Math" display="inline" id="S4.SS1.p3.6.m2.1"><semantics id="S4.SS1.p3.6.m2.1a"><mi id="S4.SS1.p3.6.m2.1.1" xref="S4.SS1.p3.6.m2.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.6.m2.1b"><ci id="S4.SS1.p3.6.m2.1.1.cmml" xref="S4.SS1.p3.6.m2.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.6.m2.1c">f</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.6.m2.1d">italic_f</annotation></semantics></math> is the projection function that uses transformation matrix <math alttext="p^{k}" class="ltx_Math" display="inline" id="S4.SS1.p3.7.m3.1"><semantics id="S4.SS1.p3.7.m3.1a"><msup id="S4.SS1.p3.7.m3.1.1" xref="S4.SS1.p3.7.m3.1.1.cmml"><mi id="S4.SS1.p3.7.m3.1.1.2" xref="S4.SS1.p3.7.m3.1.1.2.cmml">p</mi><mi id="S4.SS1.p3.7.m3.1.1.3" xref="S4.SS1.p3.7.m3.1.1.3.cmml">k</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.7.m3.1b"><apply id="S4.SS1.p3.7.m3.1.1.cmml" xref="S4.SS1.p3.7.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.7.m3.1.1.1.cmml" xref="S4.SS1.p3.7.m3.1.1">superscript</csymbol><ci id="S4.SS1.p3.7.m3.1.1.2.cmml" xref="S4.SS1.p3.7.m3.1.1.2">ğ‘</ci><ci id="S4.SS1.p3.7.m3.1.1.3.cmml" xref="S4.SS1.p3.7.m3.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.7.m3.1c">p^{k}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.7.m3.1d">italic_p start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT</annotation></semantics></math> to map depth <math alttext="\hat{x}_{d}^{k}" class="ltx_Math" display="inline" id="S4.SS1.p3.8.m4.1"><semantics id="S4.SS1.p3.8.m4.1a"><msubsup id="S4.SS1.p3.8.m4.1.1" xref="S4.SS1.p3.8.m4.1.1.cmml"><mover accent="true" id="S4.SS1.p3.8.m4.1.1.2.2" xref="S4.SS1.p3.8.m4.1.1.2.2.cmml"><mi id="S4.SS1.p3.8.m4.1.1.2.2.2" xref="S4.SS1.p3.8.m4.1.1.2.2.2.cmml">x</mi><mo id="S4.SS1.p3.8.m4.1.1.2.2.1" xref="S4.SS1.p3.8.m4.1.1.2.2.1.cmml">^</mo></mover><mi id="S4.SS1.p3.8.m4.1.1.2.3" xref="S4.SS1.p3.8.m4.1.1.2.3.cmml">d</mi><mi id="S4.SS1.p3.8.m4.1.1.3" xref="S4.SS1.p3.8.m4.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.8.m4.1b"><apply id="S4.SS1.p3.8.m4.1.1.cmml" xref="S4.SS1.p3.8.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.8.m4.1.1.1.cmml" xref="S4.SS1.p3.8.m4.1.1">superscript</csymbol><apply id="S4.SS1.p3.8.m4.1.1.2.cmml" xref="S4.SS1.p3.8.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.8.m4.1.1.2.1.cmml" xref="S4.SS1.p3.8.m4.1.1">subscript</csymbol><apply id="S4.SS1.p3.8.m4.1.1.2.2.cmml" xref="S4.SS1.p3.8.m4.1.1.2.2"><ci id="S4.SS1.p3.8.m4.1.1.2.2.1.cmml" xref="S4.SS1.p3.8.m4.1.1.2.2.1">^</ci><ci id="S4.SS1.p3.8.m4.1.1.2.2.2.cmml" xref="S4.SS1.p3.8.m4.1.1.2.2.2">ğ‘¥</ci></apply><ci id="S4.SS1.p3.8.m4.1.1.2.3.cmml" xref="S4.SS1.p3.8.m4.1.1.2.3">ğ‘‘</ci></apply><ci id="S4.SS1.p3.8.m4.1.1.3.cmml" xref="S4.SS1.p3.8.m4.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.8.m4.1c">\hat{x}_{d}^{k}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.8.m4.1d">over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT</annotation></semantics></math> from the <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p3.9.m5.1"><semantics id="S4.SS1.p3.9.m5.1a"><mi id="S4.SS1.p3.9.m5.1.1" xref="S4.SS1.p3.9.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.9.m5.1b"><ci id="S4.SS1.p3.9.m5.1.1.cmml" xref="S4.SS1.p3.9.m5.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.9.m5.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.9.m5.1d">italic_k</annotation></semantics></math>-th frame to the <math alttext="(k+1)" class="ltx_Math" display="inline" id="S4.SS1.p3.10.m6.1"><semantics id="S4.SS1.p3.10.m6.1a"><mrow id="S4.SS1.p3.10.m6.1.1.1" xref="S4.SS1.p3.10.m6.1.1.1.1.cmml"><mo id="S4.SS1.p3.10.m6.1.1.1.2" stretchy="false" xref="S4.SS1.p3.10.m6.1.1.1.1.cmml">(</mo><mrow id="S4.SS1.p3.10.m6.1.1.1.1" xref="S4.SS1.p3.10.m6.1.1.1.1.cmml"><mi id="S4.SS1.p3.10.m6.1.1.1.1.2" xref="S4.SS1.p3.10.m6.1.1.1.1.2.cmml">k</mi><mo id="S4.SS1.p3.10.m6.1.1.1.1.1" xref="S4.SS1.p3.10.m6.1.1.1.1.1.cmml">+</mo><mn id="S4.SS1.p3.10.m6.1.1.1.1.3" xref="S4.SS1.p3.10.m6.1.1.1.1.3.cmml">1</mn></mrow><mo id="S4.SS1.p3.10.m6.1.1.1.3" stretchy="false" xref="S4.SS1.p3.10.m6.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.10.m6.1b"><apply id="S4.SS1.p3.10.m6.1.1.1.1.cmml" xref="S4.SS1.p3.10.m6.1.1.1"><plus id="S4.SS1.p3.10.m6.1.1.1.1.1.cmml" xref="S4.SS1.p3.10.m6.1.1.1.1.1"></plus><ci id="S4.SS1.p3.10.m6.1.1.1.1.2.cmml" xref="S4.SS1.p3.10.m6.1.1.1.1.2">ğ‘˜</ci><cn id="S4.SS1.p3.10.m6.1.1.1.1.3.cmml" type="integer" xref="S4.SS1.p3.10.m6.1.1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.10.m6.1c">(k+1)</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.10.m6.1d">( italic_k + 1 )</annotation></semantics></math>-th frame, and <math alttext="p_{-}^{k+1}" class="ltx_Math" display="inline" id="S4.SS1.p3.11.m7.1"><semantics id="S4.SS1.p3.11.m7.1a"><msubsup id="S4.SS1.p3.11.m7.1.1" xref="S4.SS1.p3.11.m7.1.1.cmml"><mi id="S4.SS1.p3.11.m7.1.1.2.2" xref="S4.SS1.p3.11.m7.1.1.2.2.cmml">p</mi><mo id="S4.SS1.p3.11.m7.1.1.2.3" xref="S4.SS1.p3.11.m7.1.1.2.3.cmml">âˆ’</mo><mrow id="S4.SS1.p3.11.m7.1.1.3" xref="S4.SS1.p3.11.m7.1.1.3.cmml"><mi id="S4.SS1.p3.11.m7.1.1.3.2" xref="S4.SS1.p3.11.m7.1.1.3.2.cmml">k</mi><mo id="S4.SS1.p3.11.m7.1.1.3.1" xref="S4.SS1.p3.11.m7.1.1.3.1.cmml">+</mo><mn id="S4.SS1.p3.11.m7.1.1.3.3" xref="S4.SS1.p3.11.m7.1.1.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.11.m7.1b"><apply id="S4.SS1.p3.11.m7.1.1.cmml" xref="S4.SS1.p3.11.m7.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.11.m7.1.1.1.cmml" xref="S4.SS1.p3.11.m7.1.1">superscript</csymbol><apply id="S4.SS1.p3.11.m7.1.1.2.cmml" xref="S4.SS1.p3.11.m7.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.11.m7.1.1.2.1.cmml" xref="S4.SS1.p3.11.m7.1.1">subscript</csymbol><ci id="S4.SS1.p3.11.m7.1.1.2.2.cmml" xref="S4.SS1.p3.11.m7.1.1.2.2">ğ‘</ci><minus id="S4.SS1.p3.11.m7.1.1.2.3.cmml" xref="S4.SS1.p3.11.m7.1.1.2.3"></minus></apply><apply id="S4.SS1.p3.11.m7.1.1.3.cmml" xref="S4.SS1.p3.11.m7.1.1.3"><plus id="S4.SS1.p3.11.m7.1.1.3.1.cmml" xref="S4.SS1.p3.11.m7.1.1.3.1"></plus><ci id="S4.SS1.p3.11.m7.1.1.3.2.cmml" xref="S4.SS1.p3.11.m7.1.1.3.2">ğ‘˜</ci><cn id="S4.SS1.p3.11.m7.1.1.3.3.cmml" type="integer" xref="S4.SS1.p3.11.m7.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.11.m7.1c">p_{-}^{k+1}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.11.m7.1d">italic_p start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k + 1 end_POSTSUPERSCRIPT</annotation></semantics></math> is the inverse matrix for projection in the reverse direction.
The transformation matrix consists of both intrinsic and extrinsic camera parameters, which can be obtained from the dataset.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Implementation Details</h3>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.18">Our implementation is based on SVDÂ <cite class="ltx_cite ltx_citemacro_citep">(Blattmann etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib3" title="">2023a</a>)</cite>, using the diffusers libraryÂ <cite class="ltx_cite ltx_citemacro_citep">(von Platen etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib48" title="">2022</a>)</cite>.
We employ the AdamW optimizerÂ <cite class="ltx_cite ltx_citemacro_citep">(Loshchilov &amp; Hutter, <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib32" title="">2019</a>)</cite> with a learning rate of <math alttext="6.4\times 10^{-5}" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mn id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">6.4</mn><mo id="S4.SS2.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p1.1.m1.1.1.1.cmml">Ã—</mo><msup id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml"><mn id="S4.SS2.p1.1.m1.1.1.3.2" xref="S4.SS2.p1.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.SS2.p1.1.m1.1.1.3.3" xref="S4.SS2.p1.1.m1.1.1.3.3.cmml"><mo id="S4.SS2.p1.1.m1.1.1.3.3a" xref="S4.SS2.p1.1.m1.1.1.3.3.cmml">âˆ’</mo><mn id="S4.SS2.p1.1.m1.1.1.3.3.2" xref="S4.SS2.p1.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><times id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></times><cn id="S4.SS2.p1.1.m1.1.1.2.cmml" type="float" xref="S4.SS2.p1.1.m1.1.1.2">6.4</cn><apply id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.3.1.cmml" xref="S4.SS2.p1.1.m1.1.1.3">superscript</csymbol><cn id="S4.SS2.p1.1.m1.1.1.3.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1.3.2">10</cn><apply id="S4.SS2.p1.1.m1.1.1.3.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3"><minus id="S4.SS2.p1.1.m1.1.1.3.3.1.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3"></minus><cn id="S4.SS2.p1.1.m1.1.1.3.3.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">6.4\times 10^{-5}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">6.4 Ã— 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math>. The model is trained at various resolutions: <math alttext="512\times 512" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mn id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">512</mn><mo id="S4.SS2.p1.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p1.2.m2.1.1.1.cmml">Ã—</mo><mn id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">512</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><times id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1"></times><cn id="S4.SS2.p1.2.m2.1.1.2.cmml" type="integer" xref="S4.SS2.p1.2.m2.1.1.2">512</cn><cn id="S4.SS2.p1.2.m2.1.1.3.cmml" type="integer" xref="S4.SS2.p1.2.m2.1.1.3">512</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">512\times 512</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">512 Ã— 512</annotation></semantics></math>, <math alttext="480\times 640" class="ltx_Math" display="inline" id="S4.SS2.p1.3.m3.1"><semantics id="S4.SS2.p1.3.m3.1a"><mrow id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mn id="S4.SS2.p1.3.m3.1.1.2" xref="S4.SS2.p1.3.m3.1.1.2.cmml">480</mn><mo id="S4.SS2.p1.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p1.3.m3.1.1.1.cmml">Ã—</mo><mn id="S4.SS2.p1.3.m3.1.1.3" xref="S4.SS2.p1.3.m3.1.1.3.cmml">640</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><times id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1.1"></times><cn id="S4.SS2.p1.3.m3.1.1.2.cmml" type="integer" xref="S4.SS2.p1.3.m3.1.1.2">480</cn><cn id="S4.SS2.p1.3.m3.1.1.3.cmml" type="integer" xref="S4.SS2.p1.3.m3.1.1.3">640</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">480\times 640</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.3.m3.1d">480 Ã— 640</annotation></semantics></math>, <math alttext="707\times 707" class="ltx_Math" display="inline" id="S4.SS2.p1.4.m4.1"><semantics id="S4.SS2.p1.4.m4.1a"><mrow id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml"><mn id="S4.SS2.p1.4.m4.1.1.2" xref="S4.SS2.p1.4.m4.1.1.2.cmml">707</mn><mo id="S4.SS2.p1.4.m4.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p1.4.m4.1.1.1.cmml">Ã—</mo><mn id="S4.SS2.p1.4.m4.1.1.3" xref="S4.SS2.p1.4.m4.1.1.3.cmml">707</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><apply id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1"><times id="S4.SS2.p1.4.m4.1.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1.1"></times><cn id="S4.SS2.p1.4.m4.1.1.2.cmml" type="integer" xref="S4.SS2.p1.4.m4.1.1.2">707</cn><cn id="S4.SS2.p1.4.m4.1.1.3.cmml" type="integer" xref="S4.SS2.p1.4.m4.1.1.3">707</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">707\times 707</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.4.m4.1d">707 Ã— 707</annotation></semantics></math>, <math alttext="352\times 1216" class="ltx_Math" display="inline" id="S4.SS2.p1.5.m5.1"><semantics id="S4.SS2.p1.5.m5.1a"><mrow id="S4.SS2.p1.5.m5.1.1" xref="S4.SS2.p1.5.m5.1.1.cmml"><mn id="S4.SS2.p1.5.m5.1.1.2" xref="S4.SS2.p1.5.m5.1.1.2.cmml">352</mn><mo id="S4.SS2.p1.5.m5.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p1.5.m5.1.1.1.cmml">Ã—</mo><mn id="S4.SS2.p1.5.m5.1.1.3" xref="S4.SS2.p1.5.m5.1.1.3.cmml">1216</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m5.1b"><apply id="S4.SS2.p1.5.m5.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1"><times id="S4.SS2.p1.5.m5.1.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1.1"></times><cn id="S4.SS2.p1.5.m5.1.1.2.cmml" type="integer" xref="S4.SS2.p1.5.m5.1.1.2">352</cn><cn id="S4.SS2.p1.5.m5.1.1.3.cmml" type="integer" xref="S4.SS2.p1.5.m5.1.1.3">1216</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m5.1c">352\times 1216</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.5.m5.1d">352 Ã— 1216</annotation></semantics></math>, and <math alttext="1024\times 1024" class="ltx_Math" display="inline" id="S4.SS2.p1.6.m6.1"><semantics id="S4.SS2.p1.6.m6.1a"><mrow id="S4.SS2.p1.6.m6.1.1" xref="S4.SS2.p1.6.m6.1.1.cmml"><mn id="S4.SS2.p1.6.m6.1.1.2" xref="S4.SS2.p1.6.m6.1.1.2.cmml">1024</mn><mo id="S4.SS2.p1.6.m6.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p1.6.m6.1.1.1.cmml">Ã—</mo><mn id="S4.SS2.p1.6.m6.1.1.3" xref="S4.SS2.p1.6.m6.1.1.3.cmml">1024</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.6.m6.1b"><apply id="S4.SS2.p1.6.m6.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1"><times id="S4.SS2.p1.6.m6.1.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1.1"></times><cn id="S4.SS2.p1.6.m6.1.1.2.cmml" type="integer" xref="S4.SS2.p1.6.m6.1.1.2">1024</cn><cn id="S4.SS2.p1.6.m6.1.1.3.cmml" type="integer" xref="S4.SS2.p1.6.m6.1.1.3">1024</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.6.m6.1c">1024\times 1024</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.6.m6.1d">1024 Ã— 1024</annotation></semantics></math>, with corresponding batch sizes of <math alttext="384" class="ltx_Math" display="inline" id="S4.SS2.p1.7.m7.1"><semantics id="S4.SS2.p1.7.m7.1a"><mn id="S4.SS2.p1.7.m7.1.1" xref="S4.SS2.p1.7.m7.1.1.cmml">384</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.7.m7.1b"><cn id="S4.SS2.p1.7.m7.1.1.cmml" type="integer" xref="S4.SS2.p1.7.m7.1.1">384</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.7.m7.1c">384</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.7.m7.1d">384</annotation></semantics></math>, <math alttext="256" class="ltx_Math" display="inline" id="S4.SS2.p1.8.m8.1"><semantics id="S4.SS2.p1.8.m8.1a"><mn id="S4.SS2.p1.8.m8.1.1" xref="S4.SS2.p1.8.m8.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.8.m8.1b"><cn id="S4.SS2.p1.8.m8.1.1.cmml" type="integer" xref="S4.SS2.p1.8.m8.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.8.m8.1c">256</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.8.m8.1d">256</annotation></semantics></math>, <math alttext="192" class="ltx_Math" display="inline" id="S4.SS2.p1.9.m9.1"><semantics id="S4.SS2.p1.9.m9.1a"><mn id="S4.SS2.p1.9.m9.1.1" xref="S4.SS2.p1.9.m9.1.1.cmml">192</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.9.m9.1b"><cn id="S4.SS2.p1.9.m9.1.1.cmml" type="integer" xref="S4.SS2.p1.9.m9.1.1">192</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.9.m9.1c">192</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.9.m9.1d">192</annotation></semantics></math>, <math alttext="128" class="ltx_Math" display="inline" id="S4.SS2.p1.10.m10.1"><semantics id="S4.SS2.p1.10.m10.1a"><mn id="S4.SS2.p1.10.m10.1.1" xref="S4.SS2.p1.10.m10.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.10.m10.1b"><cn id="S4.SS2.p1.10.m10.1.1.cmml" type="integer" xref="S4.SS2.p1.10.m10.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.10.m10.1c">128</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.10.m10.1d">128</annotation></semantics></math>, and <math alttext="64" class="ltx_Math" display="inline" id="S4.SS2.p1.11.m11.1"><semantics id="S4.SS2.p1.11.m11.1a"><mn id="S4.SS2.p1.11.m11.1.1" xref="S4.SS2.p1.11.m11.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.11.m11.1b"><cn id="S4.SS2.p1.11.m11.1.1.cmml" type="integer" xref="S4.SS2.p1.11.m11.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.11.m11.1c">64</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.11.m11.1d">64</annotation></semantics></math>.
The video length is sampled from <math alttext="1" class="ltx_Math" display="inline" id="S4.SS2.p1.12.m12.1"><semantics id="S4.SS2.p1.12.m12.1a"><mn id="S4.SS2.p1.12.m12.1.1" xref="S4.SS2.p1.12.m12.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.12.m12.1b"><cn id="S4.SS2.p1.12.m12.1.1.cmml" type="integer" xref="S4.SS2.p1.12.m12.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.12.m12.1c">1</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.12.m12.1d">1</annotation></semantics></math> to <math alttext="6" class="ltx_Math" display="inline" id="S4.SS2.p1.13.m13.1"><semantics id="S4.SS2.p1.13.m13.1a"><mn id="S4.SS2.p1.13.m13.1.1" xref="S4.SS2.p1.13.m13.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.13.m13.1b"><cn id="S4.SS2.p1.13.m13.1.1.cmml" type="integer" xref="S4.SS2.p1.13.m13.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.13.m13.1c">6</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.13.m13.1d">6</annotation></semantics></math>, with the batch size adjusting correspondingly to meet GPU memory requirements.
Experiments are conducted on 32 NVIDIA A100 GPUs for <math alttext="20" class="ltx_Math" display="inline" id="S4.SS2.p1.14.m14.1"><semantics id="S4.SS2.p1.14.m14.1a"><mn id="S4.SS2.p1.14.m14.1.1" xref="S4.SS2.p1.14.m14.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.14.m14.1b"><cn id="S4.SS2.p1.14.m14.1.1.cmml" type="integer" xref="S4.SS2.p1.14.m14.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.14.m14.1c">20</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.14.m14.1d">20</annotation></semantics></math> epochs, with a total training time of approximately <math alttext="1" class="ltx_Math" display="inline" id="S4.SS2.p1.15.m15.1"><semantics id="S4.SS2.p1.15.m15.1a"><mn id="S4.SS2.p1.15.m15.1.1" xref="S4.SS2.p1.15.m15.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.15.m15.1b"><cn id="S4.SS2.p1.15.m15.1.1.cmml" type="integer" xref="S4.SS2.p1.15.m15.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.15.m15.1c">1</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.15.m15.1d">1</annotation></semantics></math> day.
For training efficiency, we utilize Fully Sharded Data Parallel (FSDP) with ZeRO Stage 2, gradient checkpointing, and mixed-precision training.
During inference, we set the number of denoising steps to <math alttext="3" class="ltx_Math" display="inline" id="S4.SS2.p1.16.m16.1"><semantics id="S4.SS2.p1.16.m16.1a"><mn id="S4.SS2.p1.16.m16.1.1" xref="S4.SS2.p1.16.m16.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.16.m16.1b"><cn id="S4.SS2.p1.16.m16.1.1.cmml" type="integer" xref="S4.SS2.p1.16.m16.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.16.m16.1c">3</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.16.m16.1d">3</annotation></semantics></math> and the ensemble size to <math alttext="20" class="ltx_Math" display="inline" id="S4.SS2.p1.17.m17.1"><semantics id="S4.SS2.p1.17.m17.1a"><mn id="S4.SS2.p1.17.m17.1.1" xref="S4.SS2.p1.17.m17.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.17.m17.1b"><cn id="S4.SS2.p1.17.m17.1.1.cmml" type="integer" xref="S4.SS2.p1.17.m17.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.17.m17.1c">20</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.17.m17.1d">20</annotation></semantics></math> for benchmark comparison, following <cite class="ltx_cite ltx_citemacro_citet">Ke etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib27" title="">2024</a>)</cite>, to ensure optimal performance.
In contrast, the ablation studies do not utilize the ensemble strategy to focus on the isolated impact of individual components.
The runtime evaluation is performed on a single NVIDIA A100 GPU with a resolution of <math alttext="480\times 640" class="ltx_Math" display="inline" id="S4.SS2.p1.18.m18.1"><semantics id="S4.SS2.p1.18.m18.1a"><mrow id="S4.SS2.p1.18.m18.1.1" xref="S4.SS2.p1.18.m18.1.1.cmml"><mn id="S4.SS2.p1.18.m18.1.1.2" xref="S4.SS2.p1.18.m18.1.1.2.cmml">480</mn><mo id="S4.SS2.p1.18.m18.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p1.18.m18.1.1.1.cmml">Ã—</mo><mn id="S4.SS2.p1.18.m18.1.1.3" xref="S4.SS2.p1.18.m18.1.1.3.cmml">640</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.18.m18.1b"><apply id="S4.SS2.p1.18.m18.1.1.cmml" xref="S4.SS2.p1.18.m18.1.1"><times id="S4.SS2.p1.18.m18.1.1.1.cmml" xref="S4.SS2.p1.18.m18.1.1.1"></times><cn id="S4.SS2.p1.18.m18.1.1.2.cmml" type="integer" xref="S4.SS2.p1.18.m18.1.1.2">480</cn><cn id="S4.SS2.p1.18.m18.1.1.3.cmml" type="integer" xref="S4.SS2.p1.18.m18.1.1.3">640</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.18.m18.1c">480\times 640</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.18.m18.1d">480 Ã— 640</annotation></semantics></math>.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span><span class="ltx_text ltx_font_bold" id="S4.T2.10.1">Quantitative comparisons</span> with state-of-the-art depth estimation methods using single-frame input across four zero-shot affine-invariant depth benchmarks.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.8" style="width:433.6pt;height:169.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-152.0pt,59.4pt) scale(0.587806030124394,0.587806030124394) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T2.8.8">
<tr class="ltx_tr" id="S4.T2.8.8.9">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T2.8.8.9.1" rowspan="2"><span class="ltx_text" id="S4.T2.8.8.9.1.1">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S4.T2.8.8.9.2"># Training Data</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T2.8.8.9.3">NYUv2</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T2.8.8.9.4">KITTI</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T2.8.8.9.5">ETH3D</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T2.8.8.9.6">ScanNet</td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8.8">
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.8.9">Real</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.8.8.8.10">Synthetic</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1">AbsRel <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T2.1.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.1.m1.1a"><mo id="S4.T2.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T2.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.1.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.2.2.2.2"><math alttext="\delta 1\uparrow" class="ltx_Math" display="inline" id="S4.T2.2.2.2.2.m1.1"><semantics id="S4.T2.2.2.2.2.m1.1a"><mrow id="S4.T2.2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.2.m1.1.1.cmml"><mrow id="S4.T2.2.2.2.2.m1.1.1.2" xref="S4.T2.2.2.2.2.m1.1.1.2.cmml"><mi id="S4.T2.2.2.2.2.m1.1.1.2.2" xref="S4.T2.2.2.2.2.m1.1.1.2.2.cmml">Î´</mi><mo id="S4.T2.2.2.2.2.m1.1.1.2.1" xref="S4.T2.2.2.2.2.m1.1.1.2.1.cmml">â¢</mo><mn id="S4.T2.2.2.2.2.m1.1.1.2.3" xref="S4.T2.2.2.2.2.m1.1.1.2.3.cmml">1</mn></mrow><mo id="S4.T2.2.2.2.2.m1.1.1.1" stretchy="false" xref="S4.T2.2.2.2.2.m1.1.1.1.cmml">â†‘</mo><mi id="S4.T2.2.2.2.2.m1.1.1.3" xref="S4.T2.2.2.2.2.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.2.m1.1b"><apply id="S4.T2.2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1"><ci id="S4.T2.2.2.2.2.m1.1.1.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1.1">â†‘</ci><apply id="S4.T2.2.2.2.2.m1.1.1.2.cmml" xref="S4.T2.2.2.2.2.m1.1.1.2"><times id="S4.T2.2.2.2.2.m1.1.1.2.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1.2.1"></times><ci id="S4.T2.2.2.2.2.m1.1.1.2.2.cmml" xref="S4.T2.2.2.2.2.m1.1.1.2.2">ğ›¿</ci><cn id="S4.T2.2.2.2.2.m1.1.1.2.3.cmml" type="integer" xref="S4.T2.2.2.2.2.m1.1.1.2.3">1</cn></apply><csymbol cd="latexml" id="S4.T2.2.2.2.2.m1.1.1.3.cmml" xref="S4.T2.2.2.2.2.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.2.m1.1c">\delta 1\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.2.2.m1.1d">italic_Î´ 1 â†‘</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.3.3">AbsRel <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T2.3.3.3.3.m1.1"><semantics id="S4.T2.3.3.3.3.m1.1a"><mo id="S4.T2.3.3.3.3.m1.1.1" stretchy="false" xref="S4.T2.3.3.3.3.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.3.m1.1b"><ci id="S4.T2.3.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.3.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.3.3.3.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4.4"><math alttext="\delta 1\uparrow" class="ltx_Math" display="inline" id="S4.T2.4.4.4.4.m1.1"><semantics id="S4.T2.4.4.4.4.m1.1a"><mrow id="S4.T2.4.4.4.4.m1.1.1" xref="S4.T2.4.4.4.4.m1.1.1.cmml"><mrow id="S4.T2.4.4.4.4.m1.1.1.2" xref="S4.T2.4.4.4.4.m1.1.1.2.cmml"><mi id="S4.T2.4.4.4.4.m1.1.1.2.2" xref="S4.T2.4.4.4.4.m1.1.1.2.2.cmml">Î´</mi><mo id="S4.T2.4.4.4.4.m1.1.1.2.1" xref="S4.T2.4.4.4.4.m1.1.1.2.1.cmml">â¢</mo><mn id="S4.T2.4.4.4.4.m1.1.1.2.3" xref="S4.T2.4.4.4.4.m1.1.1.2.3.cmml">1</mn></mrow><mo id="S4.T2.4.4.4.4.m1.1.1.1" stretchy="false" xref="S4.T2.4.4.4.4.m1.1.1.1.cmml">â†‘</mo><mi id="S4.T2.4.4.4.4.m1.1.1.3" xref="S4.T2.4.4.4.4.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.4.m1.1b"><apply id="S4.T2.4.4.4.4.m1.1.1.cmml" xref="S4.T2.4.4.4.4.m1.1.1"><ci id="S4.T2.4.4.4.4.m1.1.1.1.cmml" xref="S4.T2.4.4.4.4.m1.1.1.1">â†‘</ci><apply id="S4.T2.4.4.4.4.m1.1.1.2.cmml" xref="S4.T2.4.4.4.4.m1.1.1.2"><times id="S4.T2.4.4.4.4.m1.1.1.2.1.cmml" xref="S4.T2.4.4.4.4.m1.1.1.2.1"></times><ci id="S4.T2.4.4.4.4.m1.1.1.2.2.cmml" xref="S4.T2.4.4.4.4.m1.1.1.2.2">ğ›¿</ci><cn id="S4.T2.4.4.4.4.m1.1.1.2.3.cmml" type="integer" xref="S4.T2.4.4.4.4.m1.1.1.2.3">1</cn></apply><csymbol cd="latexml" id="S4.T2.4.4.4.4.m1.1.1.3.cmml" xref="S4.T2.4.4.4.4.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.4.m1.1c">\delta 1\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.4.4.4.m1.1d">italic_Î´ 1 â†‘</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.5.5.5">AbsRel <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T2.5.5.5.5.m1.1"><semantics id="S4.T2.5.5.5.5.m1.1a"><mo id="S4.T2.5.5.5.5.m1.1.1" stretchy="false" xref="S4.T2.5.5.5.5.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.5.m1.1b"><ci id="S4.T2.5.5.5.5.m1.1.1.cmml" xref="S4.T2.5.5.5.5.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.5.5.5.5.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.6.6"><math alttext="\delta 1\uparrow" class="ltx_Math" display="inline" id="S4.T2.6.6.6.6.m1.1"><semantics id="S4.T2.6.6.6.6.m1.1a"><mrow id="S4.T2.6.6.6.6.m1.1.1" xref="S4.T2.6.6.6.6.m1.1.1.cmml"><mrow id="S4.T2.6.6.6.6.m1.1.1.2" xref="S4.T2.6.6.6.6.m1.1.1.2.cmml"><mi id="S4.T2.6.6.6.6.m1.1.1.2.2" xref="S4.T2.6.6.6.6.m1.1.1.2.2.cmml">Î´</mi><mo id="S4.T2.6.6.6.6.m1.1.1.2.1" xref="S4.T2.6.6.6.6.m1.1.1.2.1.cmml">â¢</mo><mn id="S4.T2.6.6.6.6.m1.1.1.2.3" xref="S4.T2.6.6.6.6.m1.1.1.2.3.cmml">1</mn></mrow><mo id="S4.T2.6.6.6.6.m1.1.1.1" stretchy="false" xref="S4.T2.6.6.6.6.m1.1.1.1.cmml">â†‘</mo><mi id="S4.T2.6.6.6.6.m1.1.1.3" xref="S4.T2.6.6.6.6.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.6.6.m1.1b"><apply id="S4.T2.6.6.6.6.m1.1.1.cmml" xref="S4.T2.6.6.6.6.m1.1.1"><ci id="S4.T2.6.6.6.6.m1.1.1.1.cmml" xref="S4.T2.6.6.6.6.m1.1.1.1">â†‘</ci><apply id="S4.T2.6.6.6.6.m1.1.1.2.cmml" xref="S4.T2.6.6.6.6.m1.1.1.2"><times id="S4.T2.6.6.6.6.m1.1.1.2.1.cmml" xref="S4.T2.6.6.6.6.m1.1.1.2.1"></times><ci id="S4.T2.6.6.6.6.m1.1.1.2.2.cmml" xref="S4.T2.6.6.6.6.m1.1.1.2.2">ğ›¿</ci><cn id="S4.T2.6.6.6.6.m1.1.1.2.3.cmml" type="integer" xref="S4.T2.6.6.6.6.m1.1.1.2.3">1</cn></apply><csymbol cd="latexml" id="S4.T2.6.6.6.6.m1.1.1.3.cmml" xref="S4.T2.6.6.6.6.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.6.6.m1.1c">\delta 1\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.6.6.6.6.m1.1d">italic_Î´ 1 â†‘</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.7.7.7">AbsRel <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T2.7.7.7.7.m1.1"><semantics id="S4.T2.7.7.7.7.m1.1a"><mo id="S4.T2.7.7.7.7.m1.1.1" stretchy="false" xref="S4.T2.7.7.7.7.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.7.7.m1.1b"><ci id="S4.T2.7.7.7.7.m1.1.1.cmml" xref="S4.T2.7.7.7.7.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.7.7.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.7.7.7.7.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.8.8"><math alttext="\delta 1\uparrow" class="ltx_Math" display="inline" id="S4.T2.8.8.8.8.m1.1"><semantics id="S4.T2.8.8.8.8.m1.1a"><mrow id="S4.T2.8.8.8.8.m1.1.1" xref="S4.T2.8.8.8.8.m1.1.1.cmml"><mrow id="S4.T2.8.8.8.8.m1.1.1.2" xref="S4.T2.8.8.8.8.m1.1.1.2.cmml"><mi id="S4.T2.8.8.8.8.m1.1.1.2.2" xref="S4.T2.8.8.8.8.m1.1.1.2.2.cmml">Î´</mi><mo id="S4.T2.8.8.8.8.m1.1.1.2.1" xref="S4.T2.8.8.8.8.m1.1.1.2.1.cmml">â¢</mo><mn id="S4.T2.8.8.8.8.m1.1.1.2.3" xref="S4.T2.8.8.8.8.m1.1.1.2.3.cmml">1</mn></mrow><mo id="S4.T2.8.8.8.8.m1.1.1.1" stretchy="false" xref="S4.T2.8.8.8.8.m1.1.1.1.cmml">â†‘</mo><mi id="S4.T2.8.8.8.8.m1.1.1.3" xref="S4.T2.8.8.8.8.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.8.8.8.8.m1.1b"><apply id="S4.T2.8.8.8.8.m1.1.1.cmml" xref="S4.T2.8.8.8.8.m1.1.1"><ci id="S4.T2.8.8.8.8.m1.1.1.1.cmml" xref="S4.T2.8.8.8.8.m1.1.1.1">â†‘</ci><apply id="S4.T2.8.8.8.8.m1.1.1.2.cmml" xref="S4.T2.8.8.8.8.m1.1.1.2"><times id="S4.T2.8.8.8.8.m1.1.1.2.1.cmml" xref="S4.T2.8.8.8.8.m1.1.1.2.1"></times><ci id="S4.T2.8.8.8.8.m1.1.1.2.2.cmml" xref="S4.T2.8.8.8.8.m1.1.1.2.2">ğ›¿</ci><cn id="S4.T2.8.8.8.8.m1.1.1.2.3.cmml" type="integer" xref="S4.T2.8.8.8.8.m1.1.1.2.3">1</cn></apply><csymbol cd="latexml" id="S4.T2.8.8.8.8.m1.1.1.3.cmml" xref="S4.T2.8.8.8.8.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.8.8.8.m1.1c">\delta 1\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.8.8.8.8.m1.1d">italic_Î´ 1 â†‘</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8.10">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="11" id="S4.T2.8.8.10.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.T2.8.8.10.1.1">Discriminative Model:</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8.11">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.8.8.11.1">DiverseDepthÂ <cite class="ltx_cite ltx_citemacro_citep">(Yin etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib55" title="">2020</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.11.2">320K</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.8.8.11.3">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.11.4">11.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.11.5">87.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.11.6">19.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.11.7">70.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.11.8">22.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.11.9">69.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.11.10">10.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.11.11">88.2</td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.8.8.12.1">MiDaSÂ <cite class="ltx_cite ltx_citemacro_citep">(Lasinger etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib28" title="">2019</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.12.2">2M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.8.8.12.3">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.12.4">9.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.12.5">91.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.12.6">18.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.12.7">71.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.12.8">19.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.12.9">88.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.12.10">9.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.12.11">90.7</td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.8.8.13.1">LeReSÂ <cite class="ltx_cite ltx_citemacro_citep">(Yin etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib56" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.13.2">354K</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.8.8.13.3">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.13.4">9.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.13.5">91.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.13.6">14.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.13.7">78.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.13.8">17.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.13.9">77.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.13.10">9.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.13.11">91.7</td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8.14">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.8.8.14.1">OmnidataÂ <cite class="ltx_cite ltx_citemacro_citep">(Eftekhar etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib11" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.14.2">12.1M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.8.8.14.3">59K</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.14.4">7.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.14.5">94.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.14.6">14.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.14.7">83.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.14.8">16.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.14.9">77.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.14.10">7.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.14.11">93.6</td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8.15">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.8.8.15.1">HDNÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib58" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.15.2">300K</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.8.8.15.3">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.15.4">6.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.15.5">94.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.15.6">11.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.15.7">86.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.15.8">12.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.15.9">83.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.15.10">8.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.15.11">93.9</td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8.16">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.8.8.16.1">DPTÂ <cite class="ltx_cite ltx_citemacro_citep">(Ranftl etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib37" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.16.2">1.4M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.8.8.16.3">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.16.4">9.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.16.5">91.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.16.6">11.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.16.7">88.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.16.8">11.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.16.9">92.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.16.10">8.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.16.11">93.2</td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8.17">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.8.8.17.1">Metric3DÂ <cite class="ltx_cite ltx_citemacro_citep">(Yin etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib57" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.17.2">8M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.8.8.17.3">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.17.4">5.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.17.5">96.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.17.6">5.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.17.7">97.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.17.8">6.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.17.9">96.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.17.10">7.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.17.11">94.1</td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8.18">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.8.8.18.1">Depth AnythingÂ <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib51" title="">2024a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.18.2">63.5M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.8.8.18.3">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.18.4">4.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.18.5">98.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.18.6">8.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.18.7">94.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.18.8">6.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.18.9">98.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.18.10">4.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.18.11">98.1</td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8.19">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="11" id="S4.T2.8.8.19.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.T2.8.8.19.1.1">Generative Model:</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8.20">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.8.8.20.1">MarigoldÂ <cite class="ltx_cite ltx_citemacro_citep">(Ke etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib27" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.20.2">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.8.8.20.3">74K</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.20.4">5.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.20.5">96.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.20.6">9.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.20.7">91.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.20.8">6.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.20.9">96.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.20.10">6.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.20.11">95.1</td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8.21">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.8.8.21.1">DepthFMÂ <cite class="ltx_cite ltx_citemacro_citep">(Gui etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib15" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.21.2">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.8.8.21.3">63K</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.21.4">6.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.21.5">95.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.21.6">8.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.21.7">93.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.21.8">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.21.9">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.21.10">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.21.11">-</td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8.22">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.8.8.22.1">GeoWizardÂ <cite class="ltx_cite ltx_citemacro_citep">(Fu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib13" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.22.2">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.8.8.22.3">0.3M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.22.4">5.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.22.5">96.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.22.6">9.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.22.7">92.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.22.8">6.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.22.9">96.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.22.10">6.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.22.11">95.3</td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8.23">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.T2.8.8.23.1"><span class="ltx_text ltx_font_bold" id="S4.T2.8.8.23.1.1">Depth Any Video (Ours)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.8.8.23.2">-</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T2.8.8.23.3"><span class="ltx_text ltx_font_bold" id="S4.T2.8.8.23.3.1">6M</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.8.8.23.4"><span class="ltx_text ltx_font_bold" id="S4.T2.8.8.23.4.1">5.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.8.8.23.5"><span class="ltx_text ltx_font_bold" id="S4.T2.8.8.23.5.1">97.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.8.8.23.6"><span class="ltx_text ltx_font_bold" id="S4.T2.8.8.23.6.1">7.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.8.8.23.7"><span class="ltx_text ltx_font_bold" id="S4.T2.8.8.23.7.1">95.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.8.8.23.8"><span class="ltx_text ltx_font_bold" id="S4.T2.8.8.23.8.1">4.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.8.8.23.9"><span class="ltx_text ltx_font_bold" id="S4.T2.8.8.23.9.1">97.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.8.8.23.10"><span class="ltx_text ltx_font_bold" id="S4.T2.8.8.23.10.1">5.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.8.8.23.11"><span class="ltx_text ltx_font_bold" id="S4.T2.8.8.23.11.1">96.6</span></td>
</tr>
</table>
</span></div>
</figure>
<figure class="ltx_figure" id="S4.SS2.7">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_middle" id="S4.SS2.3.3" style="width:188.6pt;">
<span class="ltx_ERROR undefined" id="S4.SS2.3.3.4">\captionof</span>
<p class="ltx_p ltx_align_center" id="S4.SS2.3.3.3">table<span class="ltx_text ltx_font_bold" id="S4.SS2.3.3.3.4">Temporal consistency and spatial accuracy comparisons</span> on ScanNet++.


<span class="ltx_inline-block ltx_transformed_outer" id="S4.SS2.3.3.3.3" style="width:433.6pt;height:93.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(8.5pt,-1.8pt) scale(1.04090281425636,1.04090281425636) ;">
<span class="ltx_tabular ltx_align_middle" id="S4.SS2.3.3.3.3.3">
<span class="ltx_tr" id="S4.SS2.3.3.3.3.3.3">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.SS2.3.3.3.3.3.3.4" style="padding-left:5.5pt;padding-right:5.5pt;">Method</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.1.1.1.1.1.1.1" style="padding-left:5.5pt;padding-right:5.5pt;">AbsRel <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.SS2.1.1.1.1.1.1.1.m1.1"><semantics id="S4.SS2.1.1.1.1.1.1.1.m1.1a"><mo id="S4.SS2.1.1.1.1.1.1.1.m1.1.1" stretchy="false" xref="S4.SS2.1.1.1.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.1.1.1.1.1.1.1.m1.1b"><ci id="S4.SS2.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.SS2.1.1.1.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.1.1.1.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.1.1.1.1.1.1.1.m1.1d">â†“</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.2.2.2.2.2.2.2" style="padding-left:5.5pt;padding-right:5.5pt;"><math alttext="\delta 1\uparrow" class="ltx_Math" display="inline" id="S4.SS2.2.2.2.2.2.2.2.m1.1"><semantics id="S4.SS2.2.2.2.2.2.2.2.m1.1a"><mrow id="S4.SS2.2.2.2.2.2.2.2.m1.1.1" xref="S4.SS2.2.2.2.2.2.2.2.m1.1.1.cmml"><mrow id="S4.SS2.2.2.2.2.2.2.2.m1.1.1.2" xref="S4.SS2.2.2.2.2.2.2.2.m1.1.1.2.cmml"><mi id="S4.SS2.2.2.2.2.2.2.2.m1.1.1.2.2" xref="S4.SS2.2.2.2.2.2.2.2.m1.1.1.2.2.cmml">Î´</mi><mo id="S4.SS2.2.2.2.2.2.2.2.m1.1.1.2.1" xref="S4.SS2.2.2.2.2.2.2.2.m1.1.1.2.1.cmml">â¢</mo><mn id="S4.SS2.2.2.2.2.2.2.2.m1.1.1.2.3" xref="S4.SS2.2.2.2.2.2.2.2.m1.1.1.2.3.cmml">1</mn></mrow><mo id="S4.SS2.2.2.2.2.2.2.2.m1.1.1.1" stretchy="false" xref="S4.SS2.2.2.2.2.2.2.2.m1.1.1.1.cmml">â†‘</mo><mi id="S4.SS2.2.2.2.2.2.2.2.m1.1.1.3" xref="S4.SS2.2.2.2.2.2.2.2.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.2.2.2.2.2.2.2.m1.1b"><apply id="S4.SS2.2.2.2.2.2.2.2.m1.1.1.cmml" xref="S4.SS2.2.2.2.2.2.2.2.m1.1.1"><ci id="S4.SS2.2.2.2.2.2.2.2.m1.1.1.1.cmml" xref="S4.SS2.2.2.2.2.2.2.2.m1.1.1.1">â†‘</ci><apply id="S4.SS2.2.2.2.2.2.2.2.m1.1.1.2.cmml" xref="S4.SS2.2.2.2.2.2.2.2.m1.1.1.2"><times id="S4.SS2.2.2.2.2.2.2.2.m1.1.1.2.1.cmml" xref="S4.SS2.2.2.2.2.2.2.2.m1.1.1.2.1"></times><ci id="S4.SS2.2.2.2.2.2.2.2.m1.1.1.2.2.cmml" xref="S4.SS2.2.2.2.2.2.2.2.m1.1.1.2.2">ğ›¿</ci><cn id="S4.SS2.2.2.2.2.2.2.2.m1.1.1.2.3.cmml" type="integer" xref="S4.SS2.2.2.2.2.2.2.2.m1.1.1.2.3">1</cn></apply><csymbol cd="latexml" id="S4.SS2.2.2.2.2.2.2.2.m1.1.1.3.cmml" xref="S4.SS2.2.2.2.2.2.2.2.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.2.2.2.2.2.2.2.m1.1c">\delta 1\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.2.2.2.2.2.2.2.m1.1d">italic_Î´ 1 â†‘</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.3.3.3.3.3.3.3" style="padding-left:5.5pt;padding-right:5.5pt;">TAE <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.SS2.3.3.3.3.3.3.3.m1.1"><semantics id="S4.SS2.3.3.3.3.3.3.3.m1.1a"><mo id="S4.SS2.3.3.3.3.3.3.3.m1.1.1" stretchy="false" xref="S4.SS2.3.3.3.3.3.3.3.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.3.3.3.3.3.3.3.m1.1b"><ci id="S4.SS2.3.3.3.3.3.3.3.m1.1.1.cmml" xref="S4.SS2.3.3.3.3.3.3.3.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.3.3.3.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.3.3.3.3.3.3.3.m1.1d">â†“</annotation></semantics></math></span></span>
<span class="ltx_tr" id="S4.SS2.3.3.3.3.3.4">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.SS2.3.3.3.3.3.4.1" style="padding-left:5.5pt;padding-right:5.5pt;">NVDSÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib49" title="">2023</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.3.3.3.3.3.4.2" style="padding-left:5.5pt;padding-right:5.5pt;">22.2</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.3.3.3.3.3.4.3" style="padding-left:5.5pt;padding-right:5.5pt;">61.9</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.3.3.3.3.3.4.4" style="padding-left:5.5pt;padding-right:5.5pt;">3.7</span></span>
<span class="ltx_tr" id="S4.SS2.3.3.3.3.3.5">
<span class="ltx_td ltx_align_left ltx_border_r" id="S4.SS2.3.3.3.3.3.5.1" style="padding-left:5.5pt;padding-right:5.5pt;">ChronoDepthÂ <cite class="ltx_cite ltx_citemacro_citep">(Shao etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib42" title="">2024</a>)</cite></span>
<span class="ltx_td ltx_align_center" id="S4.SS2.3.3.3.3.3.5.2" style="padding-left:5.5pt;padding-right:5.5pt;">10.4</span>
<span class="ltx_td ltx_align_center" id="S4.SS2.3.3.3.3.3.5.3" style="padding-left:5.5pt;padding-right:5.5pt;">90.7</span>
<span class="ltx_td ltx_align_center" id="S4.SS2.3.3.3.3.3.5.4" style="padding-left:5.5pt;padding-right:5.5pt;">2.3</span></span>
<span class="ltx_tr" id="S4.SS2.3.3.3.3.3.6">
<span class="ltx_td ltx_align_left ltx_border_r" id="S4.SS2.3.3.3.3.3.6.1" style="padding-left:5.5pt;padding-right:5.5pt;">DepthCrafterÂ <cite class="ltx_cite ltx_citemacro_citep">(Hu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib22" title="">2024b</a>)</cite></span>
<span class="ltx_td ltx_align_center" id="S4.SS2.3.3.3.3.3.6.2" style="padding-left:5.5pt;padding-right:5.5pt;">11.5</span>
<span class="ltx_td ltx_align_center" id="S4.SS2.3.3.3.3.3.6.3" style="padding-left:5.5pt;padding-right:5.5pt;">88.1</span>
<span class="ltx_td ltx_align_center" id="S4.SS2.3.3.3.3.3.6.4" style="padding-left:5.5pt;padding-right:5.5pt;">2.2</span></span>
<span class="ltx_tr" id="S4.SS2.3.3.3.3.3.7">
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.SS2.3.3.3.3.3.7.1" style="padding-left:5.5pt;padding-right:5.5pt;"><span class="ltx_text ltx_font_bold" id="S4.SS2.3.3.3.3.3.7.1.1">Depth Any Video (Ours)</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS2.3.3.3.3.3.7.2" style="padding-left:5.5pt;padding-right:5.5pt;"><span class="ltx_text ltx_font_bold" id="S4.SS2.3.3.3.3.3.7.2.1">9.3</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS2.3.3.3.3.3.7.3" style="padding-left:5.5pt;padding-right:5.5pt;"><span class="ltx_text ltx_font_bold" id="S4.SS2.3.3.3.3.3.7.3.1">93.4</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS2.3.3.3.3.3.7.4" style="padding-left:5.5pt;padding-right:5.5pt;"><span class="ltx_text ltx_font_bold" id="S4.SS2.3.3.3.3.3.7.4.1">2.1</span></span></span>
</span>
</span></span></p>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_middle" id="S4.SS2.7.7" style="width:233.3pt;">
<span class="ltx_ERROR undefined" id="S4.SS2.7.7.5">\captionof</span>
<p class="ltx_p ltx_align_center" id="S4.SS2.7.7.4">table<span class="ltx_text ltx_font_bold" id="S4.SS2.7.7.4.5">Performance and inference efficiency comparisons</span> on the ScanNet dataset.


<span class="ltx_inline-block ltx_transformed_outer" id="S4.SS2.7.7.4.4" style="width:433.6pt;height:79.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-27.5pt,5.1pt) scale(0.887357867322486,0.887357867322486) ;">
<span class="ltx_tabular ltx_align_middle" id="S4.SS2.7.7.4.4.4">
<span class="ltx_tr" id="S4.SS2.7.7.4.4.4.4">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.SS2.7.7.4.4.4.4.5">Method</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.4.4.1.1.1.1.1">Step <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.SS2.4.4.1.1.1.1.1.m1.1"><semantics id="S4.SS2.4.4.1.1.1.1.1.m1.1a"><mo id="S4.SS2.4.4.1.1.1.1.1.m1.1.1" stretchy="false" xref="S4.SS2.4.4.1.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.4.4.1.1.1.1.1.m1.1b"><ci id="S4.SS2.4.4.1.1.1.1.1.m1.1.1.cmml" xref="S4.SS2.4.4.1.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.4.4.1.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.4.4.1.1.1.1.1.m1.1d">â†“</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.5.5.2.2.2.2.2"># Param. <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.SS2.5.5.2.2.2.2.2.m1.1"><semantics id="S4.SS2.5.5.2.2.2.2.2.m1.1a"><mo id="S4.SS2.5.5.2.2.2.2.2.m1.1.1" stretchy="false" xref="S4.SS2.5.5.2.2.2.2.2.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.5.5.2.2.2.2.2.m1.1b"><ci id="S4.SS2.5.5.2.2.2.2.2.m1.1.1.cmml" xref="S4.SS2.5.5.2.2.2.2.2.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.5.5.2.2.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.5.5.2.2.2.2.2.m1.1d">â†“</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.6.6.3.3.3.3.3">Runtime <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.SS2.6.6.3.3.3.3.3.m1.1"><semantics id="S4.SS2.6.6.3.3.3.3.3.m1.1a"><mo id="S4.SS2.6.6.3.3.3.3.3.m1.1.1" stretchy="false" xref="S4.SS2.6.6.3.3.3.3.3.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.6.6.3.3.3.3.3.m1.1b"><ci id="S4.SS2.6.6.3.3.3.3.3.m1.1.1.cmml" xref="S4.SS2.6.6.3.3.3.3.3.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.6.6.3.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.6.6.3.3.3.3.3.m1.1d">â†“</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.SS2.7.7.4.4.4.4.4"><math alttext="\delta 1\uparrow" class="ltx_Math" display="inline" id="S4.SS2.7.7.4.4.4.4.4.m1.1"><semantics id="S4.SS2.7.7.4.4.4.4.4.m1.1a"><mrow id="S4.SS2.7.7.4.4.4.4.4.m1.1.1" xref="S4.SS2.7.7.4.4.4.4.4.m1.1.1.cmml"><mrow id="S4.SS2.7.7.4.4.4.4.4.m1.1.1.2" xref="S4.SS2.7.7.4.4.4.4.4.m1.1.1.2.cmml"><mi id="S4.SS2.7.7.4.4.4.4.4.m1.1.1.2.2" xref="S4.SS2.7.7.4.4.4.4.4.m1.1.1.2.2.cmml">Î´</mi><mo id="S4.SS2.7.7.4.4.4.4.4.m1.1.1.2.1" xref="S4.SS2.7.7.4.4.4.4.4.m1.1.1.2.1.cmml">â¢</mo><mn id="S4.SS2.7.7.4.4.4.4.4.m1.1.1.2.3" xref="S4.SS2.7.7.4.4.4.4.4.m1.1.1.2.3.cmml">1</mn></mrow><mo id="S4.SS2.7.7.4.4.4.4.4.m1.1.1.1" stretchy="false" xref="S4.SS2.7.7.4.4.4.4.4.m1.1.1.1.cmml">â†‘</mo><mi id="S4.SS2.7.7.4.4.4.4.4.m1.1.1.3" xref="S4.SS2.7.7.4.4.4.4.4.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.7.7.4.4.4.4.4.m1.1b"><apply id="S4.SS2.7.7.4.4.4.4.4.m1.1.1.cmml" xref="S4.SS2.7.7.4.4.4.4.4.m1.1.1"><ci id="S4.SS2.7.7.4.4.4.4.4.m1.1.1.1.cmml" xref="S4.SS2.7.7.4.4.4.4.4.m1.1.1.1">â†‘</ci><apply id="S4.SS2.7.7.4.4.4.4.4.m1.1.1.2.cmml" xref="S4.SS2.7.7.4.4.4.4.4.m1.1.1.2"><times id="S4.SS2.7.7.4.4.4.4.4.m1.1.1.2.1.cmml" xref="S4.SS2.7.7.4.4.4.4.4.m1.1.1.2.1"></times><ci id="S4.SS2.7.7.4.4.4.4.4.m1.1.1.2.2.cmml" xref="S4.SS2.7.7.4.4.4.4.4.m1.1.1.2.2">ğ›¿</ci><cn id="S4.SS2.7.7.4.4.4.4.4.m1.1.1.2.3.cmml" type="integer" xref="S4.SS2.7.7.4.4.4.4.4.m1.1.1.2.3">1</cn></apply><csymbol cd="latexml" id="S4.SS2.7.7.4.4.4.4.4.m1.1.1.3.cmml" xref="S4.SS2.7.7.4.4.4.4.4.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.7.7.4.4.4.4.4.m1.1c">\delta 1\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.7.7.4.4.4.4.4.m1.1d">italic_Î´ 1 â†‘</annotation></semantics></math></span></span>
<span class="ltx_tr" id="S4.SS2.7.7.4.4.4.5">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.SS2.7.7.4.4.4.5.1">MarigoldÂ <cite class="ltx_cite ltx_citemacro_citep">(Ke etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib27" title="">2024</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.7.7.4.4.4.5.2">50</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.7.7.4.4.4.5.3">865.9M</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.7.7.4.4.4.5.4">2.06s</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.SS2.7.7.4.4.4.5.5">94.5</span></span>
<span class="ltx_tr" id="S4.SS2.7.7.4.4.4.6">
<span class="ltx_td ltx_align_left ltx_border_r" id="S4.SS2.7.7.4.4.4.6.1">ChronoDepthÂ <cite class="ltx_cite ltx_citemacro_citep">(Shao etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib42" title="">2024</a>)</cite></span>
<span class="ltx_td ltx_align_center" id="S4.SS2.7.7.4.4.4.6.2">10</span>
<span class="ltx_td ltx_align_center" id="S4.SS2.7.7.4.4.4.6.3">1524.6M</span>
<span class="ltx_td ltx_align_center" id="S4.SS2.7.7.4.4.4.6.4">1.04s</span>
<span class="ltx_td ltx_align_center" id="S4.SS2.7.7.4.4.4.6.5">93.4</span></span>
<span class="ltx_tr" id="S4.SS2.7.7.4.4.4.7">
<span class="ltx_td ltx_align_left ltx_border_r" id="S4.SS2.7.7.4.4.4.7.1">DepthCrafterÂ <cite class="ltx_cite ltx_citemacro_citep">(Hu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib22" title="">2024b</a>)</cite></span>
<span class="ltx_td ltx_align_center" id="S4.SS2.7.7.4.4.4.7.2">25</span>
<span class="ltx_td ltx_align_center" id="S4.SS2.7.7.4.4.4.7.3">2156.7M</span>
<span class="ltx_td ltx_align_center" id="S4.SS2.7.7.4.4.4.7.4">4.80s</span>
<span class="ltx_td ltx_align_center" id="S4.SS2.7.7.4.4.4.7.5">93.8</span></span>
<span class="ltx_tr" id="S4.SS2.7.7.4.4.4.8">
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.SS2.7.7.4.4.4.8.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.7.7.4.4.4.8.1.1">Depth Any Video (Ours)</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS2.7.7.4.4.4.8.2"><span class="ltx_text ltx_font_bold" id="S4.SS2.7.7.4.4.4.8.2.1">3</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS2.7.7.4.4.4.8.3"><span class="ltx_text ltx_font_bold" id="S4.SS2.7.7.4.4.4.8.3.1">1422.8M</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS2.7.7.4.4.4.8.4"><span class="ltx_text ltx_font_bold" id="S4.SS2.7.7.4.4.4.8.4.1">0.37s</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.SS2.7.7.4.4.4.8.5"><span class="ltx_text ltx_font_bold" id="S4.SS2.7.7.4.4.4.8.5.1">96.1</span></span></span>
</span>
</span></span></p>
</div>
</div>
</div>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Zero-shot Depth Estimation</h3>
<div class="ltx_para ltx_noindent" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Our model demonstrates exceptional zero-shot generalization in depth estimation across both indoor and outdoor datasets, as well as single-frame and multi-frame datasets.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.5"><span class="ltx_text ltx_font_bold" id="S4.SS3.p2.5.1">Quantitative Comparisons.</span>
TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.T2" title="Table 2 â€£ 4.2 Implementation Details â€£ 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">2</span></a> presents our modelâ€™s performance in comparison to state-of-the-art depth estimation models using single-frame inputs.
Our model significantly surpasses all previous generative models across various datasets and achieves results that are comparable to, and in some cases better than, those of top-performing discriminative models.
For example, compared to GeoWizardÂ <cite class="ltx_cite ltx_citemacro_citep">(Fu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib13" title="">2024</a>)</cite>, our model shows improvements of 0.4 in <math alttext="\delta 1" class="ltx_Math" display="inline" id="S4.SS3.p2.1.m1.1"><semantics id="S4.SS3.p2.1.m1.1a"><mrow id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mi id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml">Î´</mi><mo id="S4.SS3.p2.1.m1.1.1.1" xref="S4.SS3.p2.1.m1.1.1.1.cmml">â¢</mo><mn id="S4.SS3.p2.1.m1.1.1.3" xref="S4.SS3.p2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><times id="S4.SS3.p2.1.m1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1.1"></times><ci id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2">ğ›¿</ci><cn id="S4.SS3.p2.1.m1.1.1.3.cmml" type="integer" xref="S4.SS3.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">\delta 1</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.1.m1.1d">italic_Î´ 1</annotation></semantics></math> and 0.1 in AbsRel on the NYUv2 dataset, 3.0 in <math alttext="\delta 1" class="ltx_Math" display="inline" id="S4.SS3.p2.2.m2.1"><semantics id="S4.SS3.p2.2.m2.1a"><mrow id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml"><mi id="S4.SS3.p2.2.m2.1.1.2" xref="S4.SS3.p2.2.m2.1.1.2.cmml">Î´</mi><mo id="S4.SS3.p2.2.m2.1.1.1" xref="S4.SS3.p2.2.m2.1.1.1.cmml">â¢</mo><mn id="S4.SS3.p2.2.m2.1.1.3" xref="S4.SS3.p2.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><apply id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1"><times id="S4.SS3.p2.2.m2.1.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1.1"></times><ci id="S4.SS3.p2.2.m2.1.1.2.cmml" xref="S4.SS3.p2.2.m2.1.1.2">ğ›¿</ci><cn id="S4.SS3.p2.2.m2.1.1.3.cmml" type="integer" xref="S4.SS3.p2.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">\delta 1</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.2.m2.1d">italic_Î´ 1</annotation></semantics></math> and 2.4 in AbsRel on KITTI, 1.8 in <math alttext="\delta 1" class="ltx_Math" display="inline" id="S4.SS3.p2.3.m3.1"><semantics id="S4.SS3.p2.3.m3.1a"><mrow id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml"><mi id="S4.SS3.p2.3.m3.1.1.2" xref="S4.SS3.p2.3.m3.1.1.2.cmml">Î´</mi><mo id="S4.SS3.p2.3.m3.1.1.1" xref="S4.SS3.p2.3.m3.1.1.1.cmml">â¢</mo><mn id="S4.SS3.p2.3.m3.1.1.3" xref="S4.SS3.p2.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><apply id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"><times id="S4.SS3.p2.3.m3.1.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1.1"></times><ci id="S4.SS3.p2.3.m3.1.1.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2">ğ›¿</ci><cn id="S4.SS3.p2.3.m3.1.1.3.cmml" type="integer" xref="S4.SS3.p2.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">\delta 1</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.3.m3.1d">italic_Î´ 1</annotation></semantics></math> and 1.7 in AbsRel on ETH3D, and 1.3 in <math alttext="\delta_{1}" class="ltx_Math" display="inline" id="S4.SS3.p2.4.m4.1"><semantics id="S4.SS3.p2.4.m4.1a"><msub id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml"><mi id="S4.SS3.p2.4.m4.1.1.2" xref="S4.SS3.p2.4.m4.1.1.2.cmml">Î´</mi><mn id="S4.SS3.p2.4.m4.1.1.3" xref="S4.SS3.p2.4.m4.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><apply id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.4.m4.1.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1">subscript</csymbol><ci id="S4.SS3.p2.4.m4.1.1.2.cmml" xref="S4.SS3.p2.4.m4.1.1.2">ğ›¿</ci><cn id="S4.SS3.p2.4.m4.1.1.3.cmml" type="integer" xref="S4.SS3.p2.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">\delta_{1}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.4.m4.1d">italic_Î´ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> and 0.8 in AbsRel on the ScanNet dataset.
When compared to Depth AnythingÂ <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib51" title="">2024a</a>)</cite>, we achieve gains of 0.5 in <math alttext="\delta 1" class="ltx_Math" display="inline" id="S4.SS3.p2.5.m5.1"><semantics id="S4.SS3.p2.5.m5.1a"><mrow id="S4.SS3.p2.5.m5.1.1" xref="S4.SS3.p2.5.m5.1.1.cmml"><mi id="S4.SS3.p2.5.m5.1.1.2" xref="S4.SS3.p2.5.m5.1.1.2.cmml">Î´</mi><mo id="S4.SS3.p2.5.m5.1.1.1" xref="S4.SS3.p2.5.m5.1.1.1.cmml">â¢</mo><mn id="S4.SS3.p2.5.m5.1.1.3" xref="S4.SS3.p2.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.5.m5.1b"><apply id="S4.SS3.p2.5.m5.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1"><times id="S4.SS3.p2.5.m5.1.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1.1"></times><ci id="S4.SS3.p2.5.m5.1.1.2.cmml" xref="S4.SS3.p2.5.m5.1.1.2">ğ›¿</ci><cn id="S4.SS3.p2.5.m5.1.1.3.cmml" type="integer" xref="S4.SS3.p2.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.1c">\delta 1</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.5.m5.1d">italic_Î´ 1</annotation></semantics></math> and 0.7 in AbsRel on KITTI, along with a 1.5 improvement in the AbsRel metric on the ETH3D dataset.
The impressive results are primarily attributed to the large-scale synthetic data we collected.
TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.SS2" title="4.2 Implementation Details â€£ 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">4.2</span></a> presents a comprehensive comparison of our model against previous video depth models.
All generative models process multi-frame inputs in a single forward pass.
Notably, our model demonstrates improved temporal consistency and spatial accuracy on the ScanNet++ dataset, highlighting its effectiveness in video depth estimation.
TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.SS2" title="4.2 Implementation Details â€£ 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">4.2</span></a> presents detailed comparisons with previous generative methods without ensemble techniques.
Our model has fewer parameters than ChronoDepthÂ <cite class="ltx_cite ltx_citemacro_citep">(Shao etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib42" title="">2024</a>)</cite> because we utilize a parameter-free RoPE instead of learnable absolute positional embeddings.
It also reduces complexity compared to DepthCrafterÂ <cite class="ltx_cite ltx_citemacro_citep">(Hu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib22" title="">2024b</a>)</cite> by removing the clip embedding condition and classifier-free guidance.
Additionally, we achieve lower inference time and fewer denoising steps while attaining better spatial accuracy on the ScanNet dataset compared to Marigold, ChronoDepth, and DepthCrafter.</p>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="439" id="S4.F5.g1" src="x3.png" width="831"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span class="ltx_text ltx_font_bold" id="S4.F5.2.1">Qualitative comparisons</span> of depth estimation models on in-the-wild videos. Red boxes show changes in color or depth over time at vertical red lines in videos. Best viewed by zooming in.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span><span class="ltx_text ltx_font_bold" id="S4.T3.8.1">Ablation study</span> of each component. All variants are trained for <math alttext="10" class="ltx_Math" display="inline" id="S4.T3.2.m1.1"><semantics id="S4.T3.2.m1.1b"><mn id="S4.T3.2.m1.1.1" xref="S4.T3.2.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.T3.2.m1.1c"><cn id="S4.T3.2.m1.1.1.cmml" type="integer" xref="S4.T3.2.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.m1.1d">10</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.m1.1e">10</annotation></semantics></math> epochs to ensure training efficiency. <span class="ltx_text ltx_font_italic" id="S4.T3.9.2">Memory Util.</span> refers to the minimum GPU memory utilization across all GPUs, while <span class="ltx_text ltx_font_italic" id="S4.T3.10.3">Average Metric</span> represents the average accuracy across four datasets.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.4" style="width:433.6pt;height:82.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-112.7pt,21.5pt) scale(0.657940545231983,0.657940545231983) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T3.4.2">
<tr class="ltx_tr" id="S4.T3.4.2.3">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.4.2.3.1" style="padding-left:9.0pt;padding-right:9.0pt;">Generative</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.4.2.3.2" style="padding-left:9.0pt;padding-right:9.0pt;">Conditional</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.4.2.3.3" style="padding-left:9.0pt;padding-right:9.0pt;">Synthetic</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T3.4.2.3.4" style="padding-left:9.0pt;padding-right:9.0pt;">Mixed-duration</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.4.2.3.5" style="padding-left:9.0pt;padding-right:9.0pt;">Runtime</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.4.2.3.6" style="padding-left:9.0pt;padding-right:9.0pt;">Training Time</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.4.2.3.7" style="padding-left:9.0pt;padding-right:9.0pt;">Memory Util.</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T3.4.2.3.8" style="padding-left:9.0pt;padding-right:9.0pt;">Average Metric</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.2">
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.2.3" style="padding-left:9.0pt;padding-right:9.0pt;">Visual Prior</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.2.4" style="padding-left:9.0pt;padding-right:9.0pt;">Flow Matching</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.2.5" style="padding-left:9.0pt;padding-right:9.0pt;">Synthetic Data</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.2.2.6" style="padding-left:9.0pt;padding-right:9.0pt;">Training</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.2.7" style="padding-left:9.0pt;padding-right:9.0pt;">(s)</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.2.8" style="padding-left:9.0pt;padding-right:9.0pt;">(hours)</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.2.9" style="padding-left:9.0pt;padding-right:9.0pt;">(%)</td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.1.1.1" style="padding-left:9.0pt;padding-right:9.0pt;">AbsRel <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T3.3.1.1.1.m1.1"><semantics id="S4.T3.3.1.1.1.m1.1a"><mo id="S4.T3.3.1.1.1.m1.1.1" stretchy="false" xref="S4.T3.3.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T3.3.1.1.1.m1.1b"><ci id="S4.T3.3.1.1.1.m1.1.1.cmml" xref="S4.T3.3.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.3.1.1.1.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.2.2" style="padding-left:9.0pt;padding-right:9.0pt;"><math alttext="\delta 1\uparrow" class="ltx_Math" display="inline" id="S4.T3.4.2.2.2.m1.1"><semantics id="S4.T3.4.2.2.2.m1.1a"><mrow id="S4.T3.4.2.2.2.m1.1.1" xref="S4.T3.4.2.2.2.m1.1.1.cmml"><mrow id="S4.T3.4.2.2.2.m1.1.1.2" xref="S4.T3.4.2.2.2.m1.1.1.2.cmml"><mi id="S4.T3.4.2.2.2.m1.1.1.2.2" xref="S4.T3.4.2.2.2.m1.1.1.2.2.cmml">Î´</mi><mo id="S4.T3.4.2.2.2.m1.1.1.2.1" xref="S4.T3.4.2.2.2.m1.1.1.2.1.cmml">â¢</mo><mn id="S4.T3.4.2.2.2.m1.1.1.2.3" xref="S4.T3.4.2.2.2.m1.1.1.2.3.cmml">1</mn></mrow><mo id="S4.T3.4.2.2.2.m1.1.1.1" stretchy="false" xref="S4.T3.4.2.2.2.m1.1.1.1.cmml">â†‘</mo><mi id="S4.T3.4.2.2.2.m1.1.1.3" xref="S4.T3.4.2.2.2.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.4.2.2.2.m1.1b"><apply id="S4.T3.4.2.2.2.m1.1.1.cmml" xref="S4.T3.4.2.2.2.m1.1.1"><ci id="S4.T3.4.2.2.2.m1.1.1.1.cmml" xref="S4.T3.4.2.2.2.m1.1.1.1">â†‘</ci><apply id="S4.T3.4.2.2.2.m1.1.1.2.cmml" xref="S4.T3.4.2.2.2.m1.1.1.2"><times id="S4.T3.4.2.2.2.m1.1.1.2.1.cmml" xref="S4.T3.4.2.2.2.m1.1.1.2.1"></times><ci id="S4.T3.4.2.2.2.m1.1.1.2.2.cmml" xref="S4.T3.4.2.2.2.m1.1.1.2.2">ğ›¿</ci><cn id="S4.T3.4.2.2.2.m1.1.1.2.3.cmml" type="integer" xref="S4.T3.4.2.2.2.m1.1.1.2.3">1</cn></apply><csymbol cd="latexml" id="S4.T3.4.2.2.2.m1.1.1.3.cmml" xref="S4.T3.4.2.2.2.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.2.2.2.m1.1c">\delta 1\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.4.2.2.2.m1.1d">italic_Î´ 1 â†‘</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.4">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.2.4.1" style="padding-left:9.0pt;padding-right:9.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.2.4.2" style="padding-left:9.0pt;padding-right:9.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.2.4.3" style="padding-left:9.0pt;padding-right:9.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.2.4.4" style="padding-left:9.0pt;padding-right:9.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.2.4.5" style="padding-left:9.0pt;padding-right:9.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.2.4.6" style="padding-left:9.0pt;padding-right:9.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.2.4.7" style="padding-left:9.0pt;padding-right:9.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.2.4.8" style="padding-left:9.0pt;padding-right:9.0pt;">21.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.2.4.9" style="padding-left:9.0pt;padding-right:9.0pt;">65.1</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.5">
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.5.1" style="padding-left:9.0pt;padding-right:9.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.5.2" style="padding-left:9.0pt;padding-right:9.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.5.3" style="padding-left:9.0pt;padding-right:9.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.2.5.4" style="padding-left:9.0pt;padding-right:9.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.5.5" style="padding-left:9.0pt;padding-right:9.0pt;">2.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.5.6" style="padding-left:9.0pt;padding-right:9.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.5.7" style="padding-left:9.0pt;padding-right:9.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.5.8" style="padding-left:9.0pt;padding-right:9.0pt;">7.5</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.5.9" style="padding-left:9.0pt;padding-right:9.0pt;">93.8</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.6">
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.6.1" style="padding-left:9.0pt;padding-right:9.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.6.2" style="padding-left:9.0pt;padding-right:9.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.6.3" style="padding-left:9.0pt;padding-right:9.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.2.6.4" style="padding-left:9.0pt;padding-right:9.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.6.5" style="padding-left:9.0pt;padding-right:9.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.4.2.6.5.1">0.37</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.6.6" style="padding-left:9.0pt;padding-right:9.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.6.7" style="padding-left:9.0pt;padding-right:9.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.6.8" style="padding-left:9.0pt;padding-right:9.0pt;">6.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.6.9" style="padding-left:9.0pt;padding-right:9.0pt;">94.9</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.7">
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.7.1" style="padding-left:9.0pt;padding-right:9.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.7.2" style="padding-left:9.0pt;padding-right:9.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.7.3" style="padding-left:9.0pt;padding-right:9.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.2.7.4" style="padding-left:9.0pt;padding-right:9.0pt;">âœ—</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.7.5" style="padding-left:9.0pt;padding-right:9.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.7.6" style="padding-left:9.0pt;padding-right:9.0pt;">16</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.7.7" style="padding-left:9.0pt;padding-right:9.0pt;">23</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.7.8" style="padding-left:9.0pt;padding-right:9.0pt;">6.5</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.7.9" style="padding-left:9.0pt;padding-right:9.0pt;">95.6</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.8">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.2.8.1" style="padding-left:9.0pt;padding-right:9.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.2.8.2" style="padding-left:9.0pt;padding-right:9.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.2.8.3" style="padding-left:9.0pt;padding-right:9.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T3.4.2.8.4" style="padding-left:9.0pt;padding-right:9.0pt;">âœ“</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.2.8.5" style="padding-left:9.0pt;padding-right:9.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.2.8.6" style="padding-left:9.0pt;padding-right:9.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.4.2.8.6.1">12</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.2.8.7" style="padding-left:9.0pt;padding-right:9.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.4.2.8.7.1">63</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.2.8.8" style="padding-left:9.0pt;padding-right:9.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.4.2.8.8.1">6.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.2.8.9" style="padding-left:9.0pt;padding-right:9.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.4.2.8.9.1">95.8</span></td>
</tr>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p3.1.1">Qualitative Comparisons.</span>
FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S3.F4" title="Figure 4 â€£ 3.3 Long Video Inference â€£ 3 Generative Video Depth Model â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">4</span></a> presents qualitative monocular depth estimation results across different datasets. It highlights the ability of our model to capture fine-grained details compared to Depth Anything V2Â <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib52" title="">2024b</a>)</cite>, such as the cup in the NYUv2 dataset and the ladder in the ETH3D dataset.
Moreover, our model handles objects with similar colors more effectively.
For example, on the KITTI dataset, the personâ€™s head blends with the background, which Depth Anything V2 fails to predict.
Compared to generative methods like Marigold and ChronoDepth, our model generalizes well to in-the-wild data, offering a better distinction between the sky and foreground.
The diversity of DA-V significantly contributes to this, enabling our model to generalize effectively across various environments, particularly in complex, real-world scenarios.
FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.F5" title="Figure 5 â€£ 4.3 Zero-shot Depth Estimation â€£ 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">5</span></a> further demonstrates qualitative results of depth estimation on open-world videos, covering a wide range of scenarios such as dust and sand, animals, architecture, and human motion presented in both generated and real-world videos.
Following <cite class="ltx_cite ltx_citemacro_citet">Wang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib49" title="">2023</a>)</cite>, we visualize the changes in estimated depth values over time at the vertical red lines by slicing along the time axis to better capture temporal consistency.
Marigold exhibits zigzag artifacts on a per-frame basis, while ChronoDepth displays similar issues at a per-window level. DepthCrafter, with its large overlap between windows and interpolation of overlap space, achieves smoother transitions across windows but still struggles with window-wise flickering. In contrast, our method ensures global consistency by predicting key frames and interpolating intermediate frames, significantly reducing flicker artifacts between windows.</p>
</div>
<figure class="ltx_figure" id="S4.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F6.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="131" id="S4.F6.sf1.g1" src="extracted/5923385/figure/denoise_step.png" width="198"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Impact of denoising step</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F6.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="131" id="S4.F6.sf2.g1" src="extracted/5923385/figure/ensemble_size.png" width="198"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Impact of ensemble size</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F6.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="127" id="S4.F6.sf3.g1" src="extracted/5923385/figure/training_epoch.png" width="198"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Impact of training epoch</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span class="ltx_text ltx_font_bold" id="S4.F6.2.1">Ablation study</span> of hyper-parameters on depth estimation performance. Average accuracy across four datasets is reported to provide a comprehensive evaluation.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Ablation Studies</h3>
<div class="ltx_para ltx_noindent" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">In this section, we evaluate the effectiveness of each component in Depth Any Video. For training efficiency, unless otherwise specified, the model is trained for only <math alttext="10" class="ltx_Math" display="inline" id="S4.SS4.p1.1.m1.1"><semantics id="S4.SS4.p1.1.m1.1a"><mn id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><cn id="S4.SS4.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS4.p1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">10</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.1.m1.1d">10</annotation></semantics></math> epochs during ablation studies.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p2.1.1">Generative Visual Prior.</span>
We investigate the impact of prior visual knowledge from the stable video diffusion model, as shown in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.T3" title="Table 3 â€£ 4.3 Zero-shot Depth Estimation â€£ 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">3</span></a>.
The first two rows clearly demonstrate that incorporating this prior significantly boosts the modelâ€™s overall performance.
Additionally, FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.F6" title="Figure 6 â€£ 4.3 Zero-shot Depth Estimation â€£ 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">6</span></a>(c) illustrates that this prior provides a strong initialization, leading to fast training convergence and enabling the model to achieve impressive results with as few as five epochs. This suggests that the generative visual prior not only enhances model performance but also improves training efficiency.</p>
</div>
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="S4.F7.3" style="width:212.5pt;">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_middle" id="S4.F7.2" style="width:212.5pt;">
<span class="ltx_ERROR undefined" id="S4.F7.2.3">\captionof</span>
<p class="ltx_p ltx_align_center" id="S4.F7.2.2">table<span class="ltx_text ltx_font_bold" id="S4.F7.2.2.3">Ablation study</span> of the reconstruction quality of different variational autoencoders. We categorize the VAEs into 2D and 3D based on the presence of temporal feature interactions.


<span class="ltx_inline-block ltx_transformed_outer" id="S4.F7.2.2.2" style="width:433.6pt;height:93.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(8.3pt,-1.8pt) scale(1.0399320952562,1.0399320952562) ;">
<span class="ltx_tabular ltx_align_middle" id="S4.F7.2.2.2.2">
<span class="ltx_tr" id="S4.F7.2.2.2.2.2">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.F7.2.2.2.2.2.3" style="padding-left:9.0pt;padding-right:9.0pt;">Method</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.F7.2.2.2.2.2.4" style="padding-left:9.0pt;padding-right:9.0pt;">Type</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.F7.1.1.1.1.1.1" style="padding-left:9.0pt;padding-right:9.0pt;">AbsRel <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.F7.1.1.1.1.1.1.m1.1"><semantics id="S4.F7.1.1.1.1.1.1.m1.1a"><mo id="S4.F7.1.1.1.1.1.1.m1.1.1" stretchy="false" xref="S4.F7.1.1.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.F7.1.1.1.1.1.1.m1.1b"><ci id="S4.F7.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.F7.1.1.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.1.1.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.F7.1.1.1.1.1.1.m1.1d">â†“</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.F7.2.2.2.2.2.2" style="padding-left:9.0pt;padding-right:9.0pt;"><math alttext="\delta 1\uparrow" class="ltx_Math" display="inline" id="S4.F7.2.2.2.2.2.2.m1.1"><semantics id="S4.F7.2.2.2.2.2.2.m1.1a"><mrow id="S4.F7.2.2.2.2.2.2.m1.1.1" xref="S4.F7.2.2.2.2.2.2.m1.1.1.cmml"><mrow id="S4.F7.2.2.2.2.2.2.m1.1.1.2" xref="S4.F7.2.2.2.2.2.2.m1.1.1.2.cmml"><mi id="S4.F7.2.2.2.2.2.2.m1.1.1.2.2" xref="S4.F7.2.2.2.2.2.2.m1.1.1.2.2.cmml">Î´</mi><mo id="S4.F7.2.2.2.2.2.2.m1.1.1.2.1" xref="S4.F7.2.2.2.2.2.2.m1.1.1.2.1.cmml">â¢</mo><mn id="S4.F7.2.2.2.2.2.2.m1.1.1.2.3" xref="S4.F7.2.2.2.2.2.2.m1.1.1.2.3.cmml">1</mn></mrow><mo id="S4.F7.2.2.2.2.2.2.m1.1.1.1" stretchy="false" xref="S4.F7.2.2.2.2.2.2.m1.1.1.1.cmml">â†‘</mo><mi id="S4.F7.2.2.2.2.2.2.m1.1.1.3" xref="S4.F7.2.2.2.2.2.2.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.2.2.2.2.2.2.m1.1b"><apply id="S4.F7.2.2.2.2.2.2.m1.1.1.cmml" xref="S4.F7.2.2.2.2.2.2.m1.1.1"><ci id="S4.F7.2.2.2.2.2.2.m1.1.1.1.cmml" xref="S4.F7.2.2.2.2.2.2.m1.1.1.1">â†‘</ci><apply id="S4.F7.2.2.2.2.2.2.m1.1.1.2.cmml" xref="S4.F7.2.2.2.2.2.2.m1.1.1.2"><times id="S4.F7.2.2.2.2.2.2.m1.1.1.2.1.cmml" xref="S4.F7.2.2.2.2.2.2.m1.1.1.2.1"></times><ci id="S4.F7.2.2.2.2.2.2.m1.1.1.2.2.cmml" xref="S4.F7.2.2.2.2.2.2.m1.1.1.2.2">ğ›¿</ci><cn id="S4.F7.2.2.2.2.2.2.m1.1.1.2.3.cmml" type="integer" xref="S4.F7.2.2.2.2.2.2.m1.1.1.2.3">1</cn></apply><csymbol cd="latexml" id="S4.F7.2.2.2.2.2.2.m1.1.1.3.cmml" xref="S4.F7.2.2.2.2.2.2.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.2.2.2.2.2.2.m1.1c">\delta 1\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.F7.2.2.2.2.2.2.m1.1d">italic_Î´ 1 â†‘</annotation></semantics></math></span></span>
<span class="ltx_tr" id="S4.F7.2.2.2.2.3">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.F7.2.2.2.2.3.1" style="padding-left:9.0pt;padding-right:9.0pt;">SD2Â <cite class="ltx_cite ltx_citemacro_citep">(Rombach etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib39" title="">2022</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.F7.2.2.2.2.3.2" style="padding-left:9.0pt;padding-right:9.0pt;">2D</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.F7.2.2.2.2.3.3" style="padding-left:9.0pt;padding-right:9.0pt;">1.2</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.F7.2.2.2.2.3.4" style="padding-left:9.0pt;padding-right:9.0pt;">99.0</span></span>
<span class="ltx_tr" id="S4.F7.2.2.2.2.4">
<span class="ltx_td ltx_align_left ltx_border_r" id="S4.F7.2.2.2.2.4.1" style="padding-left:9.0pt;padding-right:9.0pt;">SD3Â <cite class="ltx_cite ltx_citemacro_citep">(Esser etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib12" title="">2024</a>)</cite></span>
<span class="ltx_td ltx_align_center" id="S4.F7.2.2.2.2.4.2" style="padding-left:9.0pt;padding-right:9.0pt;">2D</span>
<span class="ltx_td ltx_align_center" id="S4.F7.2.2.2.2.4.3" style="padding-left:9.0pt;padding-right:9.0pt;">0.6</span>
<span class="ltx_td ltx_align_center" id="S4.F7.2.2.2.2.4.4" style="padding-left:9.0pt;padding-right:9.0pt;">99.7</span></span>
<span class="ltx_tr" id="S4.F7.2.2.2.2.5">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.F7.2.2.2.2.5.1" style="padding-left:9.0pt;padding-right:9.0pt;">CogVideoXÂ <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib53" title="">2024c</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.F7.2.2.2.2.5.2" style="padding-left:9.0pt;padding-right:9.0pt;">3D</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.F7.2.2.2.2.5.3" style="padding-left:9.0pt;padding-right:9.0pt;">2.2</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.F7.2.2.2.2.5.4" style="padding-left:9.0pt;padding-right:9.0pt;">98.6</span></span>
<span class="ltx_tr" id="S4.F7.2.2.2.2.6">
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.F7.2.2.2.2.6.1" style="padding-left:9.0pt;padding-right:9.0pt;">SVDÂ <cite class="ltx_cite ltx_citemacro_citep">(Blattmann etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib3" title="">2023a</a>)</cite></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.F7.2.2.2.2.6.2" style="padding-left:9.0pt;padding-right:9.0pt;">3D</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.F7.2.2.2.2.6.3" style="padding-left:9.0pt;padding-right:9.0pt;">1.5</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.F7.2.2.2.2.6.4" style="padding-left:9.0pt;padding-right:9.0pt;">98.1</span></span>
</span>
</span></span></p>
</div>
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="376" id="S4.F7.3.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span><span class="ltx_text ltx_font_bold" id="S4.F7.3.5.1">Visualization</span> of reconstruction quality.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS4.p3">
<p class="ltx_p" id="S4.SS4.p3.2"><span class="ltx_text ltx_font_bold" id="S4.SS4.p3.2.1">Conditional Flow Matching.</span>
The second and third rows in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.T3" title="Table 3 â€£ 4.3 Zero-shot Depth Estimation â€£ 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">3</span></a> indicate that flow matching not only reduces inference time, achieving a 6.5<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS4.p3.1.m1.1"><semantics id="S4.SS4.p3.1.m1.1a"><mo id="S4.SS4.p3.1.m1.1.1" xref="S4.SS4.p3.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.1.m1.1b"><times id="S4.SS4.p3.1.m1.1.1.cmml" xref="S4.SS4.p3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p3.1.m1.1d">Ã—</annotation></semantics></math> acceleration compared to the original EDM scheduler in SVD, but also results in improvements of 0.6 in AbsRel and 1.1 in <math alttext="\delta 1" class="ltx_Math" display="inline" id="S4.SS4.p3.2.m2.1"><semantics id="S4.SS4.p3.2.m2.1a"><mrow id="S4.SS4.p3.2.m2.1.1" xref="S4.SS4.p3.2.m2.1.1.cmml"><mi id="S4.SS4.p3.2.m2.1.1.2" xref="S4.SS4.p3.2.m2.1.1.2.cmml">Î´</mi><mo id="S4.SS4.p3.2.m2.1.1.1" xref="S4.SS4.p3.2.m2.1.1.1.cmml">â¢</mo><mn id="S4.SS4.p3.2.m2.1.1.3" xref="S4.SS4.p3.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.2.m2.1b"><apply id="S4.SS4.p3.2.m2.1.1.cmml" xref="S4.SS4.p3.2.m2.1.1"><times id="S4.SS4.p3.2.m2.1.1.1.cmml" xref="S4.SS4.p3.2.m2.1.1.1"></times><ci id="S4.SS4.p3.2.m2.1.1.2.cmml" xref="S4.SS4.p3.2.m2.1.1.2">ğ›¿</ci><cn id="S4.SS4.p3.2.m2.1.1.3.cmml" type="integer" xref="S4.SS4.p3.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.2.m2.1c">\delta 1</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p3.2.m2.1d">italic_Î´ 1</annotation></semantics></math>. The faster inference is primarily attributed to the ability to achieve strong performance with fewer denoising steps, as shown in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.F6" title="Figure 6 â€£ 4.3 Zero-shot Depth Estimation â€£ 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">6</span></a>(a).
It demonstrates that even a single denoising step can yield strong results, with the sweet spot identified at three steps for optimal performance.
In FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.F6" title="Figure 6 â€£ 4.3 Zero-shot Depth Estimation â€£ 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">6</span></a>(b), we further evaluate the effectiveness of ensembling multiple predictions, as varying noise initializations produce minor variations in outputs. The results show consistent performance gains as the number of predictions increases, with improvements becoming less pronounced after five predictions.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.p4">
<p class="ltx_p" id="S4.SS4.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p4.1.1">Synthetic Data.</span>
In TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.T3" title="Table 3 â€£ 4.3 Zero-shot Depth Estimation â€£ 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">3</span></a>, the third and fourth rows show that our collected synthetic data brings gains of 0.7 in <math alttext="\delta 1" class="ltx_Math" display="inline" id="S4.SS4.p4.1.m1.1"><semantics id="S4.SS4.p4.1.m1.1a"><mrow id="S4.SS4.p4.1.m1.1.1" xref="S4.SS4.p4.1.m1.1.1.cmml"><mi id="S4.SS4.p4.1.m1.1.1.2" xref="S4.SS4.p4.1.m1.1.1.2.cmml">Î´</mi><mo id="S4.SS4.p4.1.m1.1.1.1" xref="S4.SS4.p4.1.m1.1.1.1.cmml">â¢</mo><mn id="S4.SS4.p4.1.m1.1.1.3" xref="S4.SS4.p4.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p4.1.m1.1b"><apply id="S4.SS4.p4.1.m1.1.1.cmml" xref="S4.SS4.p4.1.m1.1.1"><times id="S4.SS4.p4.1.m1.1.1.1.cmml" xref="S4.SS4.p4.1.m1.1.1.1"></times><ci id="S4.SS4.p4.1.m1.1.1.2.cmml" xref="S4.SS4.p4.1.m1.1.1.2">ğ›¿</ci><cn id="S4.SS4.p4.1.m1.1.1.3.cmml" type="integer" xref="S4.SS4.p4.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p4.1.m1.1c">\delta 1</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p4.1.m1.1d">italic_Î´ 1</annotation></semantics></math> and 0.4 in AbsRel. The accuracy improvement in outdoor scenes is particularly significant, as shown in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.T2" title="Table 2 â€£ 4.2 Implementation Details â€£ 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">2</span></a>, likely due to the diverse range of outdoor environments in our dataset.
Additionally, FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S3.F4" title="Figure 4 â€£ 3.3 Long Video Inference â€£ 3 Generative Video Depth Model â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">4</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.F5" title="Figure 5 â€£ 4.3 Zero-shot Depth Estimation â€£ 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">5</span></a> demonstrate that models trained on our synthetic data generalize well to in-the-wild scenarios, showcasing both the realism and effectiveness of our synthetic data.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.p5">
<p class="ltx_p" id="S4.SS4.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p5.1.1">Mixed-duration Training.</span>
The fourth and fifth entries in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.T3" title="Table 3 â€£ 4.3 Zero-shot Depth Estimation â€£ 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">3</span></a> show that the mixed-duration training strategy improves training efficiency while simultaneously enhancing spatial accuracy.
It can save 33% of training time and increase GPU utilization by 40% because different batch sizes can be applied to video sequences of varying lengths, thus optimizing training efficiency.
The accuracy improvement is attributed to the increased proportion of individual frames during training, achieved by randomly dropping out frames, which enhances the single-frame performance.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.p6">
<p class="ltx_p" id="S4.SS4.p6.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p6.1.1">VAE Variants.</span>
Since our depth is generated in the latent space, the quality of the VAE directly impacts the upper bound of the final result. Therefore, we provide a detailed comparison of the depth reconstruction results across different VAEs in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.F7.3" title="Figure 7 â€£ 4.4 Ablation Studies â€£ 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">7</span></a>.
We find that the 2D VAE surpasses the 3D VAE in reconstruction quality, particularly with the VAE from SD3Â <cite class="ltx_cite ltx_citemacro_citep">(Esser etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib12" title="">2024</a>)</cite>. This indicates there is still potential to further enhance our modelâ€™s performance.
In FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#S4.F7.3" title="Figure 7 â€£ 4.4 Ablation Studies â€£ 4 Experiments â€£ Depth Any Video with Scalable Synthetic Data"><span class="ltx_text ltx_ref_tag">7</span></a>, we present visual comparisons of the reconstructions produced by different 3D VAEs.
Specifically, (a) shows the input ground truth depth, (b) displays the reconstruction results from <cite class="ltx_cite ltx_citemacro_citet">Yang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib53" title="">2024c</a>)</cite>, which incorporates temporal compression, and (c) shows the results from <cite class="ltx_cite ltx_citemacro_citet">Blattmann etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib3" title="">2023a</a>)</cite>.
Although the VAE with temporal compression can reduce the computational complexity of the latent model, it struggles to handle fast motion effectively, as indicated by the red box in (b).</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Related Work</h2>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p" id="S5.p1.1"><span class="ltx_text ltx_font_bold" id="S5.p1.1.1">Monocular Depth Estimation.</span>
Existing models for monocular depth estimation can be roughly divided into two categories: discriminative and generative. Discriminative models are trained end-to-end to predict depth from images. For example, MiDaSÂ <cite class="ltx_cite ltx_citemacro_citep">(Lasinger etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib28" title="">2019</a>)</cite> focuses on relative depth estimation by factoring out scale, enabling robust training on mixed datasets. Depth AnythingÂ <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib51" title="">2024a</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib52" title="">b</a>)</cite> builds on this concept, leveraging both labeled and unlabeled images to further enhance generalization. ZoeDepthÂ <cite class="ltx_cite ltx_citemacro_citep">(Bhat etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib2" title="">2023</a>)</cite> and Metric3DÂ <cite class="ltx_cite ltx_citemacro_citep">(Yin etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib57" title="">2023</a>; Hu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib21" title="">2024a</a>)</cite> aim to directly estimate metric depth.
Generative modelsÂ <cite class="ltx_cite ltx_citemacro_citep">(Saxena etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib40" title="">2023</a>)</cite>, such as MarigoldÂ <cite class="ltx_cite ltx_citemacro_citep">(Ke etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib27" title="">2024</a>)</cite> and GeoWizardÂ <cite class="ltx_cite ltx_citemacro_citep">(Fu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib13" title="">2024</a>)</cite>, leverage powerful priors learned from large-scale real-world data, allowing them to generate depth estimates in a zero-shot manner, even on unseen datasets.
Our work falls into the second category, but focuses on video depth estimation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p2">
<p class="ltx_p" id="S5.p2.1"><span class="ltx_text ltx_font_bold" id="S5.p2.1.1">Video Depth Estimation.</span>
Unlike single-image depth estimation, video depth estimation requires maintaining temporal consistency between frames.
To eliminate flickering effects between consecutive frames, some worksÂ <cite class="ltx_cite ltx_citemacro_citep">(Luo etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib33" title="">2020</a>; Chen etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib9" title="">2019</a>; Zhang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib61" title="">2021</a>)</cite> use an optimization procedure to overfit each video during inference. Other approachesÂ <cite class="ltx_cite ltx_citemacro_citep">(Guizilini etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib16" title="">2022</a>; Zhang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib59" title="">2019</a>; Teed &amp; Deng, <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib47" title="">2020</a>)</cite> directly predict depth sequences from videos. For instance, NVDSÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib49" title="">2023</a>)</cite> proposes a refinement network to optimize temporal consistency from off-the-shelf depth predictors.
Some concurrent worksÂ <cite class="ltx_cite ltx_citemacro_citep">(Hu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib22" title="">2024b</a>; Shao etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib42" title="">2024</a>)</cite> have focused on leveraging video diffusion models to produce coherent predictions. However, they often face challenges due to a lack of sufficiently high-quality and realistic depth data.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p3">
<p class="ltx_p" id="S5.p3.1"><span class="ltx_text ltx_font_bold" id="S5.p3.1.1">Video Generation.</span>
Diffusion modelsÂ <cite class="ltx_cite ltx_citemacro_citep">(Ho etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib17" title="">2020</a>; Song etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib45" title="">2021</a>)</cite> have achieved high-fidelity image generation from text descriptions, benefiting from large-scale aligned image-text datasets. Building on this success, VDMÂ <cite class="ltx_cite ltx_citemacro_citep">(Ho etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib19" title="">2022b</a>)</cite> first introduces unconditional video generation in pixel space. Imagen VideoÂ <cite class="ltx_cite ltx_citemacro_citep">(Ho etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib18" title="">2022a</a>)</cite> and Make-a-VideoÂ <cite class="ltx_cite ltx_citemacro_citep">(Singer etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib44" title="">2023</a>)</cite> are cascade models designed for text-to-video generation. Align Your LatentÂ <cite class="ltx_cite ltx_citemacro_citep">(Blattmann etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib4" title="">2023b</a>)</cite> and SVDÂ <cite class="ltx_cite ltx_citemacro_citep">(Blattmann etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib3" title="">2023a</a>)</cite> extend <cite class="ltx_cite ltx_citemacro_citet">Rombach etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10815v1#bib.bib39" title="">2022</a>)</cite> by modeling videos in the latent space of an autoencoder.
Our model builds upon the generative visual prior of SVD, which is trained on diverse real video data, to maintain robust generalization in real-world scenarios.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">We present Depth Any Video, a novel approach for versatile image and video depth estimation, powered by generative video diffusion models. Leveraging diverse and high-quality depth data collected from diverse synthetic environments, our model could generate temporally consistent depth sequences with fine-grained details across a broad spectrum of unseen scenarios. Equipped with a mixed-duration training strategy and frame interpolation, it generalizes effectively to videos of various lengths and resolutions. Compared to previous generative depth estimation models, our approach sets a new state-of-the-art in performance while significantly enhancing efficiency.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p2">
<p class="ltx_p" id="S6.p2.1"><span class="ltx_text ltx_font_bold" id="S6.p2.1.1">Limitations.</span>
There are still certain issues in our model, such as difficulties in estimating depth for mirror-like reflections on water surfaces and challenges with extremely long videos. Future work will focus on collecting data for these challenging scenarios and improving model efficiency.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alahari etÂ al. (2013)</span>
<span class="ltx_bibblock">
Karteek Alahari, Guillaume Seguin, Josef Sivic, and Ivan Laptev.

</span>
<span class="ltx_bibblock">Pose estimation and segmentation of people in 3d movies.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pp.Â  2112â€“2119, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhat etÂ al. (2023)</span>
<span class="ltx_bibblock">
ShariqÂ Farooq Bhat, Reiner Birkl, Diana Wofk, Peter Wonka, and Matthias MÃ¼ller.

</span>
<span class="ltx_bibblock">Zoedepth: Zero-shot transfer by combining relative and metric depth.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv: Computing Research Repository</em>, abs/2302.12288, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blattmann etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Andreas Blattmann, Tim Dockhorn, Sumith Kulal, Daniel Mendelevitch, Maciej Kilian, Dominik Lorenz, Yam Levi, Zion English, Vikram Voleti, Adam Letts, Varun Jampani, and Robin Rombach.

</span>
<span class="ltx_bibblock">Stable video diffusion: Scaling latent video diffusion models to large datasets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv: Computing Research Repository</em>, abs/2311.15127, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blattmann etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Andreas Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn, SeungÂ Wook Kim, Sanja Fidler, and Karsten Kreis.

</span>
<span class="ltx_bibblock">Align your latents: High-resolution video synthesis with latent diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  22563â€“22575, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Borghi etÂ al. (2017)</span>
<span class="ltx_bibblock">
Guido Borghi, Marco Venturelli, Roberto Vezzani, and Rita Cucchiara.

</span>
<span class="ltx_bibblock">Poseidon: Face-from-depth for driver pose estimation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  5494â€“5503, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Butler etÂ al. (2012)</span>
<span class="ltx_bibblock">
DanielÂ J Butler, Jonas Wulff, GarrettÂ B Stanley, and MichaelÂ J Black.

</span>
<span class="ltx_bibblock">A naturalistic open source movie for optical flow evaluation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">European Conference on Computer Vision</em>, pp.Â  611â€“625, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cabon etÂ al. (2020)</span>
<span class="ltx_bibblock">
Yohann Cabon, Naila Murray, and Martin Humenberger.

</span>
<span class="ltx_bibblock">Virtual KITTI 2.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv: Computing Research Repository</em>, abs/2001.10773, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2023)</span>
<span class="ltx_bibblock">
Shouyuan Chen, Sherman Wong, Liangjian Chen, and Yuandong Tian.

</span>
<span class="ltx_bibblock">Extending context window of large language models via positional interpolation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv: Computing Research Repository</em>, abs/2306.15595, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2019)</span>
<span class="ltx_bibblock">
Yuhua Chen, Cordelia Schmid, and Cristian Sminchisescu.

</span>
<span class="ltx_bibblock">Self-supervised learning with geometric constraints in monocular video: Connecting flow, depth, and camera.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pp.Â  7063â€“7072, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2024)</span>
<span class="ltx_bibblock">
Yukang Chen, Shengju Qian, Haotian Tang, Xin Lai, Zhijian Liu, Song Han, and Jiaya Jia.

</span>
<span class="ltx_bibblock">Longlora: Efficient fine-tuning of long-context large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">International Conference on Learning Representations</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eftekhar etÂ al. (2021)</span>
<span class="ltx_bibblock">
Ainaz Eftekhar, Alexander Sax, Jitendra Malik, and Amir Zamir.

</span>
<span class="ltx_bibblock">Omnidata: A scalable pipeline for making multi-task mid-level vision datasets from 3d scans.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pp.Â  10786â€“10796, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Esser etÂ al. (2024)</span>
<span class="ltx_bibblock">
Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas MÃ¼ller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, etÂ al.

</span>
<span class="ltx_bibblock">Scaling rectified flow transformers for high-resolution image synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">International Conference on Machine Learning</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu etÂ al. (2024)</span>
<span class="ltx_bibblock">
Xiao Fu, Wei Yin, MuÂ Hu, Kaixuan Wang, Yuexin Ma, Ping Tan, Shaojie Shen, Dahua Lin, and Xiaoxiao Long.

</span>
<span class="ltx_bibblock">Geowizard: Unleashing the diffusion priors for 3d geometry estimation from a single image.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv: Computing Research Repository</em>, abs/2403.12013, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geiger etÂ al. (2012)</span>
<span class="ltx_bibblock">
Andreas Geiger, Philip Lenz, and Raquel Urtasun.

</span>
<span class="ltx_bibblock">Are we ready for autonomous driving? the kitti vision benchmark suite.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  3354â€“3361, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gui etÂ al. (2024)</span>
<span class="ltx_bibblock">
Ming Gui, JohannesÂ S. Fischer, Ulrich Prestel, Pingchuan Ma, Dmytro Kotovenko, Olga Grebenkova, StefanÂ Andreas Baumann, VincentÂ Tao Hu, and BjÃ¶rn Ommer.

</span>
<span class="ltx_bibblock">Depthfm: Fast monocular depth estimation with flow matching.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv: Computing Research Repository</em>, abs/2403.13788, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guizilini etÂ al. (2022)</span>
<span class="ltx_bibblock">
Vitor Guizilini, Rares Ambrus, Dian Chen, Sergey Zakharov, and Adrien Gaidon.

</span>
<span class="ltx_bibblock">Multi-frame self-supervised depth with transformers.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  160â€“170, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho etÂ al. (2020)</span>
<span class="ltx_bibblock">
Jonathan Ho, Ajay Jain, and Pieter Abbeel.

</span>
<span class="ltx_bibblock">Denoising diffusion probabilistic models.

</span>
<span class="ltx_bibblock">In Hugo Larochelle, Marcâ€™Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Advances in Neural Information Processing Systems</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho etÂ al. (2022a)</span>
<span class="ltx_bibblock">
Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, AlexeyÂ A. Gritsenko, DiederikÂ P. Kingma, Ben Poole, Mohammad Norouzi, DavidÂ J. Fleet, and Tim Salimans.

</span>
<span class="ltx_bibblock">Imagen video: High definition video generation with diffusion models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv: Computing Research Repository</em>, abs/2210.02303, 2022a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho etÂ al. (2022b)</span>
<span class="ltx_bibblock">
Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi, and DavidÂ J Fleet.

</span>
<span class="ltx_bibblock">Video diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Advances in Neural Information Processing Systems</em>, volumeÂ 35, pp.Â  8633â€“8646, 2022b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holynski &amp; Kopf (2018)</span>
<span class="ltx_bibblock">
Aleksander Holynski and Johannes Kopf.

</span>
<span class="ltx_bibblock">Fast depth densification for occlusion-aware augmented reality.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">ACM Transactions on Graphics</em>, 37(6):1â€“11, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu etÂ al. (2024a)</span>
<span class="ltx_bibblock">
MuÂ Hu, Wei Yin, Chi Zhang, Zhipeng Cai, Xiaoxiao Long, Hao Chen, Kaixuan Wang, Gang Yu, Chunhua Shen, and Shaojie Shen.

</span>
<span class="ltx_bibblock">Metric3d v2: A versatile monocular geometric foundation model for zero-shot metric depth and surface normal estimation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv: Computing Research Repository</em>, abs/2404.15506, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu etÂ al. (2024b)</span>
<span class="ltx_bibblock">
Wenbo Hu, Xiangjun Gao, Xiaoyu Li, Sijie Zhao, Xiaodong Cun, Yong Zhang, Long Quan, and Ying Shan.

</span>
<span class="ltx_bibblock">Depthcrafter: Generating consistent long depth sequences for open-world videos.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv: Computing Research Repository</em>, abs/2409.02095, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang etÂ al. (2018)</span>
<span class="ltx_bibblock">
Po-Han Huang, Kevin Matzen, Johannes Kopf, Narendra Ahuja, and Jia-Bin Huang.

</span>
<span class="ltx_bibblock">Deepmvs: Learning multi-view stereopsis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  2821â€“2830, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jing etÂ al. (2024)</span>
<span class="ltx_bibblock">
Junpeng Jing, YeÂ Mao, and Krystian Mikolajczyk.

</span>
<span class="ltx_bibblock">Match-stereo-videos: Bidirectional alignment for consistent dynamic stereo matching.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv: Computing Research Repository</em>, abs/2403.10755, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karaev etÂ al. (2023)</span>
<span class="ltx_bibblock">
Nikita Karaev, Ignacio Rocco, Benjamin Graham, Natalia Neverova, Andrea Vedaldi, and Christian Rupprecht.

</span>
<span class="ltx_bibblock">Dynamicstereo: Consistent dynamic depth from stereo videos.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  13229â€“13239, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karras etÂ al. (2022)</span>
<span class="ltx_bibblock">
Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine.

</span>
<span class="ltx_bibblock">Elucidating the design space of diffusion-based generative models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Advances in Neural Information Processing Systems</em>, volumeÂ 35, pp.Â  26565â€“26577, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ke etÂ al. (2024)</span>
<span class="ltx_bibblock">
Bingxin Ke, Anton Obukhov, Shengyu Huang, Nando Metzger, RodrigoÂ Caye Daudt, and Konrad Schindler.

</span>
<span class="ltx_bibblock">Repurposing diffusion-based image generators for monocular depth estimation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  9492â€“9502, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lasinger etÂ al. (2019)</span>
<span class="ltx_bibblock">
Katrin Lasinger, RenÃ© Ranftl, Konrad Schindler, and Vladlen Koltun.

</span>
<span class="ltx_bibblock">Towards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv: Computing Research Repository</em>, abs/1907.01341, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2023)</span>
<span class="ltx_bibblock">
Yixuan Li, Lihan Jiang, Linning Xu, Yuanbo Xiangli, Zhenzhi Wang, Dahua Lin, and BoÂ Dai.

</span>
<span class="ltx_bibblock">Matrixcity: A large-scale city dataset for city-scale neural rendering and beyond.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pp.Â  3182â€“3192. IEEE, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lipman etÂ al. (2023)</span>
<span class="ltx_bibblock">
Yaron Lipman, Ricky T.Â Q. Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew Le.

</span>
<span class="ltx_bibblock">Flow matching for generative modeling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">International Conference on Learning Representations</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2024)</span>
<span class="ltx_bibblock">
Jiaheng Liu, Zhiqi Bai, Yuanxing Zhang, Chenchen Zhang, YuÂ Zhang, GeÂ Zhang, Jiakai Wang, Haoran Que, Yukang Chen, Wenbo Su, Tiezheng Ge, Jie Fu, Wenhu Chen, and BoÂ Zheng.

</span>
<span class="ltx_bibblock">E^2-llm: Efficient and extreme length extension of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv: Computing Research Repository</em>, abs/2401.06951, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov &amp; Hutter (2019)</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">International Conference on Learning Representations</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo etÂ al. (2020)</span>
<span class="ltx_bibblock">
Xuan Luo, Jia-Bin Huang, Richard Szeliski, Kevin Matzen, and Johannes Kopf.

</span>
<span class="ltx_bibblock">Consistent video depth estimation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">ACM Transactions on Graphics</em>, 39(4):71â€“1, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2024)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Sora, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/index/sora/" title="">https://openai.com/index/sora/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng etÂ al. (2024)</span>
<span class="ltx_bibblock">
Bohao Peng, Jian Wang, Yuechen Zhang, Wenbo Li, Ming-Chang Yang, and Jiaya Jia.

</span>
<span class="ltx_bibblock">Controlnext: Powerful and efficient control for image and video generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">arXiv: Computing Research Repository</em>, abs/2408.06070, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford etÂ al. (2021)</span>
<span class="ltx_bibblock">
Alec Radford, JongÂ Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, etÂ al.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language supervision.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">International Conference on Machine Learning</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ranftl etÂ al. (2021)</span>
<span class="ltx_bibblock">
RenÃ© Ranftl, Alexey Bochkovskiy, and Vladlen Koltun.

</span>
<span class="ltx_bibblock">Vision transformers for dense prediction.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pp.Â  12179â€“12188, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roberts etÂ al. (2021)</span>
<span class="ltx_bibblock">
Mike Roberts, Jason Ramapuram, Anurag Ranjan, Atulit Kumar, MiguelÂ Ãngel Bautista, Nathan Paczan, Russ Webb, and JoshuaÂ M. Susskind.

</span>
<span class="ltx_bibblock">Hypersim: A photorealistic synthetic dataset for holistic indoor scene understanding.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pp.Â  10892â€“10902, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rombach etÂ al. (2022)</span>
<span class="ltx_bibblock">
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and BjÃ¶rn Ommer.

</span>
<span class="ltx_bibblock">High-resolution image synthesis with latent diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  10684â€“10695, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saxena etÂ al. (2023)</span>
<span class="ltx_bibblock">
Saurabh Saxena, Junhwa Hur, Charles Herrmann, Deqing Sun, and DavidÂ J. Fleet.

</span>
<span class="ltx_bibblock">Zero-shot metric depth with a field-of-view conditioned diffusion model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv: Computing Research Repository</em>, abs/2312.13252, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schops etÂ al. (2017)</span>
<span class="ltx_bibblock">
Thomas Schops, JohannesÂ L. Schonberger, Silvano Galliani, Torsten Sattler, Konrad Schindler, Marc Pollefeys, and Andreas Geiger.

</span>
<span class="ltx_bibblock">A multi-view stereo benchmark with high-resolution images and multi-camera videos.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  3260â€“3269, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shao etÂ al. (2024)</span>
<span class="ltx_bibblock">
Jiahao Shao, Yuanbo Yang, Hongyu Zhou, Youmin Zhang, Yujun Shen, Matteo Poggi, and Yiyi Liao.

</span>
<span class="ltx_bibblock">Learning temporally consistent video depth from video diffusion priors.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">arXiv: Computing Research Repository</em>, abs/2406.01493, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Silberman etÂ al. (2012)</span>
<span class="ltx_bibblock">
Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob Fergus.

</span>
<span class="ltx_bibblock">Indoor segmentation and support inference from RGBD images.

</span>
<span class="ltx_bibblock">In AndrewÂ W. Fitzgibbon, Svetlana Lazebnik, Pietro Perona, Yoichi Sato, and Cordelia Schmid (eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">European Conference on Computer Vision</em>, pp.Â  746â€“760, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singer etÂ al. (2023)</span>
<span class="ltx_bibblock">
Uriel Singer, Adam Polyak, Thomas Hayes, XiÂ Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman.

</span>
<span class="ltx_bibblock">Make-a-video: Text-to-video generation without text-video data.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">International Conference on Learning Representations</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song etÂ al. (2021)</span>
<span class="ltx_bibblock">
Yang Song, Jascha Sohl-Dickstein, DiederikÂ P. Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.

</span>
<span class="ltx_bibblock">Score-based generative modeling through stochastic differential equations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">International Conference on Learning Representations</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su etÂ al. (2021)</span>
<span class="ltx_bibblock">
Jianlin Su, YuÂ Lu, Shengfeng Pan, BoÂ Wen, and Yunfeng Liu.

</span>
<span class="ltx_bibblock">Roformer: Enhanced transformer with rotary position embedding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">arXiv: Computing Research Repository</em>, abs/2104.09864, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Teed &amp; Deng (2020)</span>
<span class="ltx_bibblock">
Zachary Teed and Jia Deng.

</span>
<span class="ltx_bibblock">Deepv2d: Video to depth with differentiable structure from motion.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">International Conference on Learning Representations</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">von Platen etÂ al. (2022)</span>
<span class="ltx_bibblock">
Patrick von Platen, Suraj Patil, Anton Lozhkov, Pedro Cuenca, Nathan Lambert, Kashif Rasul, Mishig Davaadorj, Dhruv Nair, Sayak Paul, William Berman, Yiyi Xu, Steven Liu, and Thomas Wolf.

</span>
<span class="ltx_bibblock">Diffusers: State-of-the-art diffusion models.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/huggingface/diffusers" title="">https://github.com/huggingface/diffusers</a>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Yiran Wang, Min Shi, Jiaqi Li, Zihao Huang, Zhiguo Cao, Jianming Zhang, KeÂ Xian, and Guosheng Lin.

</span>
<span class="ltx_bibblock">Neural video depth stabilizer.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pp.Â  9432â€“9442, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu etÂ al. (2023)</span>
<span class="ltx_bibblock">
Haofei Xu, Jing Zhang, Jianfei Cai, Hamid Rezatofighi, Fisher Yu, Dacheng Tao, and Andreas Geiger.

</span>
<span class="ltx_bibblock">Unifying flow, stereo and depth estimation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al. (2024a)</span>
<span class="ltx_bibblock">
Lihe Yang, Bingyi Kang, Zilong Huang, Xiaogang Xu, Jiashi Feng, and Hengshuang Zhao.

</span>
<span class="ltx_bibblock">Depth anything: Unleashing the power of large-scale unlabeled data.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  10371â€“10381, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al. (2024b)</span>
<span class="ltx_bibblock">
Lihe Yang, Bingyi Kang, Zilong Huang, Zhen Zhao, Xiaogang Xu, Jiashi Feng, and Hengshuang Zhao.

</span>
<span class="ltx_bibblock">Depth anything V2.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">arXiv: Computing Research Repository</em>, abs/2406.09414, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al. (2024c)</span>
<span class="ltx_bibblock">
Zhuoyi Yang, Jiayan Teng, Wendi Zheng, Ming Ding, Shiyu Huang, Jiazheng Xu, Yuanming Yang, Wenyi Hong, Xiaohan Zhang, Guanyu Feng, etÂ al.

</span>
<span class="ltx_bibblock">Cogvideox: Text-to-video diffusion models with an expert transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">arXiv: Computing Research Repository</em>, abs/2408.06072, 2024c.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yeshwanth etÂ al. (2023)</span>
<span class="ltx_bibblock">
Chandan Yeshwanth, Yueh-Cheng Liu, Matthias NieÃŸner, and Angela Dai.

</span>
<span class="ltx_bibblock">Scannet++: A high-fidelity dataset of 3d indoor scenes.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pp.Â  12â€“22, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin etÂ al. (2020)</span>
<span class="ltx_bibblock">
Wei Yin, Xinlong Wang, Chunhua Shen, Yifan Liu, Zhi Tian, Songcen Xu, Changming Sun, and Dou Renyin.

</span>
<span class="ltx_bibblock">Diversedepth: Affine-invariant depth prediction using diverse data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">arXiv: Computing Research Repository</em>, abs/2002.00569, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin etÂ al. (2021)</span>
<span class="ltx_bibblock">
Wei Yin, Jianming Zhang, Oliver Wang, Simon Niklaus, Long Mai, Simon Chen, and Chunhua Shen.

</span>
<span class="ltx_bibblock">Learning to recover 3d scene shape from a single image.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  204â€“213, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin etÂ al. (2023)</span>
<span class="ltx_bibblock">
Wei Yin, Chi Zhang, Hao Chen, Zhipeng Cai, Gang Yu, Kaixuan Wang, Xiaozhi Chen, and Chunhua Shen.

</span>
<span class="ltx_bibblock">Metric3d: Towards zero-shot metric 3d prediction from a single image.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pp.Â  9043â€“9053, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2022)</span>
<span class="ltx_bibblock">
Chi Zhang, Wei Yin, Billzb Wang, Gang Yu, Bin Fu, and Chunhua Shen.

</span>
<span class="ltx_bibblock">Hierarchical normalization for robust monocular depth estimation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">Advances in Neural Information Processing Systems</em>, volumeÂ 35, pp.Â  14128â€“14139, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2019)</span>
<span class="ltx_bibblock">
Haokui Zhang, Ying Li, Yuanzhouhan Cao, YuÂ Liu, Chunhua Shen, and Youliang Yan.

</span>
<span class="ltx_bibblock">Exploiting temporal consistency for real-time video depth estimation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pp.Â  1725â€“1734, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2024)</span>
<span class="ltx_bibblock">
Yabo Zhang, Yuxiang Wei, Dongsheng Jiang, Xiaopeng Zhang, Wangmeng Zuo, and QiÂ Tian.

</span>
<span class="ltx_bibblock">Controlvideo: Training-free controllable text-to-video generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">International Conference on Learning Representations</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2021)</span>
<span class="ltx_bibblock">
Zhoutong Zhang, Forrester Cole, Richard Tucker, WilliamÂ T Freeman, and Tali Dekel.

</span>
<span class="ltx_bibblock">Consistent depth of moving objects in video.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">ACM Transactions on Graphics</em>, 40(4):1â€“12, 2021.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sun Oct 13 16:47:28 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
