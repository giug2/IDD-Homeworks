<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2009.02649] Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality</title><meta property="og:description" content="Causality visualization can help people understand temporal chains of events, such as messages sent in a distributed system, cause and effect in a historical conflict, or the interplay between political actors over tim…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2009.02649">

<!--Generated on Sat Mar  9 05:28:04 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\onlineid</span>
<p id="p1.2" class="ltx_p">1136
<span id="p1.2.1" class="ltx_ERROR undefined">\vgtccategory</span>Research
<span id="p1.2.2" class="ltx_ERROR undefined">\vgtcpapertype</span>Algorithm/Technique



<span id="p1.2.3" class="ltx_ERROR undefined">\authorfooter</span>
Arjun Choudhry, Mandar Sharma, and Naren Ramakrishnan are with
Virginia Tech in Arlington, VA, USA.
Email: {aj07lfc, mandarsharma}@vt.edu, naren@cs.vt.edu
Pramod Chundury and Niklas Elmqvist are with the University of Maryland, College Park, MD, USA.
Email: {pchundur,elm}@umd.edu
Thomas Kapler and Derek W. S. Gray are with Uncharted Software in Toronto, ON, Canada.
Email: {tkapler,dgray}@uncharted.software

<span id="p1.2.4" class="ltx_ERROR undefined">\shortauthortitle</span>Once Upon A Time In Visualization</p>
</div>
<h1 class="ltx_title ltx_title_document">Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Arjun Choudhry
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Mandar Sharma
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Pramod Chundury
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Thomas Kapler
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Derek W. S. Gray
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Naren Ramakrishnan
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> and Niklas Elmqvist
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> <span id="2.1.1" class="ltx_text ltx_font_italic">Senior Member, IEEE</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="3.1" class="ltx_p">Causality visualization can help people understand temporal chains of events, such as messages sent in a distributed system, cause and effect in a historical conflict, or the interplay between political actors over time.
However, as the scale and complexity of these event sequences grows, even these visualizations can become overwhelming to use.
In this paper, we propose the use of textual narratives as a data-driven storytelling method to augment causality visualization.
We first propose a design space for how textual narratives can be used to describe causal data.
We then present results from a crowdsourced user study where participants were asked to recover causality information from two causality visualizations—causal graphs and Hasse diagrams—with and without an associated textual narrative.
Finally, we describe <span id="3.1.1" class="ltx_text ltx_font_smallcaps">CauseWorks</span>, a causality visualization system for understanding how specific interventions influence a causal model.
The system incorporates an automatic textual narrative mechanism based on our design space.
We validate <span id="3.1.2" class="ltx_text ltx_font_smallcaps">CauseWorks</span> through interviews with experts who used the system for understanding complex events.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>Causality visualization, natural language generation, data-driven storytelling, temporal data, quantitative studies.
</div>
<div id="p2" class="ltx_para">
<p id="p2.1" class="ltx_p">Introduction</p>
</div>
<div id="p3" class="ltx_para">
<p id="p3.1" class="ltx_p"><span id="p3.1.1" class="ltx_text ltx_font_bold">S</span>tories are a central part of what it means to be human <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>.
They teach, guide, and caution; they store, recall, and archive; they praise, spread joy, and inspire.
In particular, stories are especially useful for encapsulating <span id="p3.1.2" class="ltx_text ltx_font_italic">causality</span>—the cause and effect of events in a plot—in a regular, understandable, and memorable format.
This format is also surprisingly scalable.
Examples abound of textual narratives representing complex chains of cause and effect ranging from the winding plots of G. R. R. Martin’s <span id="p3.1.3" class="ltx_text ltx_font_italic">A Song of Ice and Fire</span> and Neal Stephenson’s <span id="p3.1.4" class="ltx_text ltx_font_italic">The Baroque Cycle</span>, through shelf yards of history books laying out the intricacies of the Napoleonic Wars or the American Revolution in all their gritty detail, and all the way to quarterly reports telling the story of a company’s accomplishments over the last three months.
However, despite all of this utility, little work exists on the use of textual narratives to represent causality in modern visualization tools.
On the contrary, visualization and visual analytics researchers tend to view textual narratives with suspicion, often instead opting to apply text analytics and visualization methods to minimize their use.</p>
</div>
<div id="p4" class="ltx_para">
<p id="p4.1" class="ltx_p">In this paper, we attempt to remedy this gap in the literature by investigating how textual narratives can be used to represent causality.
Our classification of narratives is primarily based on their utility as a complement to causality visualization techniques, such as dynamic graphs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> and Hasse diagrams <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.
Textual representations are generally much less compact than geometric ones (i.e., visualizations), and must thus be designed with specific questions in mind.
We first AJpropose and discuss a design space of causality representations, focusing in particular on textual narratives. AJWe then report on a crowdsourced user study where we operationalized parts of our design space and asked participants to recover causality information from dynamic graphs versus Hasse diagrams, with and without an associated textual narrative.
Our findings indicate that narratives can fill an important complementary role for key questions on causality, and thus serve as a “story-like” format to summarize a specific causal event chain.</p>
</div>
<div id="p5" class="ltx_para">
<p id="p5.1" class="ltx_p">To capitalize on these findings AJand demonstrate the use of our design space, we also present a textual narratives implementation in <span id="p5.1.1" class="ltx_text ltx_font_smallcaps">CauseWorks</span>, a causality visualization system on the Causal Exploration of Complex Operational Environments program <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> for understanding the impact of specific interventions in a causal model.
These narratives are based on best practices from our design space AJas well as the user study, and serve as a quick-reference textual summary of the selected interventions and objectives shown in a dynamic graph.
We studied the utility of these narratives by interviewing several users with experience of causality, who used the system to understand climate change data.
Our findings confirm many of the results from the crowdsourced study.</p>
</div>
<div id="p6" class="ltx_para">
<p id="p6.1" class="ltx_p">The contributions of our paper are the following: (1) a design space for complementary textual narratives in representing causality; (2) results from a crowdsourced study evaluating different causality visualizations with and without companion narratives; (3) an implementation of textual narratives in an existing causality analytics and visualization system (AJ<span id="p6.1.1" class="ltx_text ltx_font_smallcaps">CauseWorks</span>); and (4) qualitative results from 5 experts using these narratives to understand climate change data.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Background</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">AJHere we discuss the existing literature on causality, causality visualization, and data-driven storytelling.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Causality Visualization</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">Causal networks or directed acyclic graphs are commonly used to map relationships between variables <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>.
Much of the work in causal visualization aims to encode aspects of causality such as temporal developments of cause and effect <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> using interactivity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> and animations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> to improve the accuracy of causal inference.</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">Researchers have uncovered characteristics and shortcomings of specific visual representations of causality.
For example, Bae et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> find that multiple to/from connections from a particular node may influence how an analyst perceives indirect effects.
Similarly, Hasse diagrams are used widely, but require the user to backtrace every effect, and can also introduce an overwhelming number of crossings in a large-scale causal system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.
Wang et al. attempted to improve causal inference by overlaying salient statistical parameters such as p-values and regression co-efficients on 2D-graphs so that analysts can draw more reliable conclusions about causal relationships <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>.
However, interpreting these parameters requires understanding statistical inference.</p>
</div>
<div id="S1.SS1.p3" class="ltx_para">
<p id="S1.SS1.p3.1" class="ltx_p">Research on perceptions of causality also show that inference is context-dependent, and a non-expert with regards to statistics or domain could see an illusion of causality in data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>.
In our work, we propose to mitigate misinterpretation by both experts and non-experts alike through the use of textual narratives to augment causal visualizations.</p>
</div>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span>Narratives in Visualization</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p">AJHistorically spanning thousands of years <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>, <span id="S1.SS2.p1.1.1" class="ltx_text ltx_font_italic">storytelling</span> conveys a series of events, usually involving characters and locations—<span id="S1.SS2.p1.1.2" class="ltx_text ltx_font_italic">stories</span>—using speech, sound, and visuals <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. Generally, stories are communicated using visual media, such as illustrations, pictures, animations, video, and–now–visualization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>. Visualization, inherently, is inclined for communication by virtue of its graphical form, resulting in the notion of <span id="S1.SS2.p1.1.3" class="ltx_text ltx_font_italic">communication-minded visualization</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>. Combining the idea of <span id="S1.SS2.p1.1.4" class="ltx_text ltx_font_italic">communication-minded visualization</span> with <span id="S1.SS2.p1.1.5" class="ltx_text ltx_font_italic">storytelling</span> yields the notion of <span id="S1.SS2.p1.1.6" class="ltx_text ltx_font_italic">data-driven storytelling</span>: narrative techniques for data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>.</p>
</div>
<div id="S1.SS2.p2" class="ltx_para">
<p id="S1.SS2.p2.1" class="ltx_p">AJWe believe that data-driven storytelling naturally follows the idea of visualization for explanation (the latter). The production, presentation, and dissemination of analysis results is an important challenge in visualization and visual analytics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>. Gershon and Page first proposed using storytelling for visualization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, and their work has since been followed up by workshops <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, surveys <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>, and even commercial tools <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. Viégas and Wattenberg note the inclination of visualization for communication by virtue of its graphical form, and encourage focusing on so-called <span id="S1.SS2.p2.1.1" class="ltx_text ltx_font_italic">communication-minded visualization</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite> for social analysis. In recent years, the use of textual data to aid visualization and vice versa have been explored <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Furthermore, verbalization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> has also been used for understanding machine learning models.</p>
</div>
</section>
<section id="S1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.3 </span>Causality and Causal Networks</h3>

<div id="S1.SS3.p1" class="ltx_para">
<p id="S1.SS3.p1.1" class="ltx_p">The statistical and ML sciences have developed many formalisms to reason with both the structure and dynamics of causal networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.
To encapsulate causal structure, while there are many network formulations, one of the more popular ones is the Bayesian network formalism popularized by Pearl <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>.
A Bayesian network is a directed acyclic graph (DAG) and can be thought of as a way to represent a factorization of the underlying joint distribution of random variables.
However, interpreting such DAGs AJis difficult for humans and interpretation rules such as d-separation<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> and the ‘Bayes Ball’ algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> have been proposed.
These rules essentially are ways to read or infer conditional independence relationships from the networks.</p>
</div>
<div id="S1.SS3.p2" class="ltx_para">
<p id="S1.SS3.p2.1" class="ltx_p">To overcome such interpretation difficulties, other representational formalisms have been proposed, e.g., dependency networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>AJ, which allow cycles, and Markov networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> (also called Markov random fields, or MRFs), which are undirected.
In terms of dynamics, a causal representation must allow us to probe the effect of interventions and to posit and explore counterfactuals.
Interventions are modeled using a calculus (e.g., Pearl’s do-calculus) that mutates the given network to propagate and understand the downstream consequences of the intervention.
Counterfactuals allow us to ask more expressive questions and explore the progression of different variables in alternative worlds or situations.
We assume in this paper that the underlying causal representation is fixed and a suitable interpretation of dynamics is available to probe the effect of interventions, and focus on the role of visualization in communicating cause-effect relationships.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Design Space: Textual Narratives for Causality</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Visualizations are themselves considered as ways to tell stories with data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> and, in this paper, we view textual narratives as an augmented form of storytelling that aims to increase insight<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>, comprehension, and decision making.
We focus on textual narratives as a way to express causal information in event sequences, specifically as a complement to causality visualizations<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>, such as causal graphs or Hasse diagrams.
For this reason, we tend to think of these textual narratives as a form of <span id="S2.p1.1.1" class="ltx_text ltx_font_italic">data-driven storytelling</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>—the use of traditional narrative methods to convey data—that relies on a textual, rather than a visual, medium.
We believe that a textual narrative can also replace the visualization, at least to provide a high-level summaryAJ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Definitions</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.9" class="ltx_p">The causal relation <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mo stretchy="false" id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">\rightarrow</annotation></semantics></math> is a relation that connects two elements (events) <math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><mi id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">x</annotation></semantics></math> and <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><mi id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">y</annotation></semantics></math> as <math id="S2.SS1.p1.4.m4.1" class="ltx_Math" alttext="x\rightarrow y" display="inline"><semantics id="S2.SS1.p1.4.m4.1a"><mrow id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml"><mi id="S2.SS1.p1.4.m4.1.1.2" xref="S2.SS1.p1.4.m4.1.1.2.cmml">x</mi><mo stretchy="false" id="S2.SS1.p1.4.m4.1.1.1" xref="S2.SS1.p1.4.m4.1.1.1.cmml">→</mo><mi id="S2.SS1.p1.4.m4.1.1.3" xref="S2.SS1.p1.4.m4.1.1.3.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><apply id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1"><ci id="S2.SS1.p1.4.m4.1.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1.1">→</ci><ci id="S2.SS1.p1.4.m4.1.1.2.cmml" xref="S2.SS1.p1.4.m4.1.1.2">𝑥</ci><ci id="S2.SS1.p1.4.m4.1.1.3.cmml" xref="S2.SS1.p1.4.m4.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">x\rightarrow y</annotation></semantics></math> iff <math id="S2.SS1.p1.5.m5.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.SS1.p1.5.m5.1a"><mi id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><ci id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">x</annotation></semantics></math> is the cause of <math id="S2.SS1.p1.6.m6.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S2.SS1.p1.6.m6.1a"><mi id="S2.SS1.p1.6.m6.1.1" xref="S2.SS1.p1.6.m6.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.1b"><ci id="S2.SS1.p1.6.m6.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.1c">y</annotation></semantics></math>.
Sets of events are called processes <math id="S2.SS1.p1.7.m7.3" class="ltx_Math" alttext="P_{1},\ldots,P_{N}" display="inline"><semantics id="S2.SS1.p1.7.m7.3a"><mrow id="S2.SS1.p1.7.m7.3.3.2" xref="S2.SS1.p1.7.m7.3.3.3.cmml"><msub id="S2.SS1.p1.7.m7.2.2.1.1" xref="S2.SS1.p1.7.m7.2.2.1.1.cmml"><mi id="S2.SS1.p1.7.m7.2.2.1.1.2" xref="S2.SS1.p1.7.m7.2.2.1.1.2.cmml">P</mi><mn id="S2.SS1.p1.7.m7.2.2.1.1.3" xref="S2.SS1.p1.7.m7.2.2.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p1.7.m7.3.3.2.3" xref="S2.SS1.p1.7.m7.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.p1.7.m7.1.1" xref="S2.SS1.p1.7.m7.1.1.cmml">…</mi><mo id="S2.SS1.p1.7.m7.3.3.2.4" xref="S2.SS1.p1.7.m7.3.3.3.cmml">,</mo><msub id="S2.SS1.p1.7.m7.3.3.2.2" xref="S2.SS1.p1.7.m7.3.3.2.2.cmml"><mi id="S2.SS1.p1.7.m7.3.3.2.2.2" xref="S2.SS1.p1.7.m7.3.3.2.2.2.cmml">P</mi><mi id="S2.SS1.p1.7.m7.3.3.2.2.3" xref="S2.SS1.p1.7.m7.3.3.2.2.3.cmml">N</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m7.3b"><list id="S2.SS1.p1.7.m7.3.3.3.cmml" xref="S2.SS1.p1.7.m7.3.3.2"><apply id="S2.SS1.p1.7.m7.2.2.1.1.cmml" xref="S2.SS1.p1.7.m7.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.2.2.1.1.1.cmml" xref="S2.SS1.p1.7.m7.2.2.1.1">subscript</csymbol><ci id="S2.SS1.p1.7.m7.2.2.1.1.2.cmml" xref="S2.SS1.p1.7.m7.2.2.1.1.2">𝑃</ci><cn type="integer" id="S2.SS1.p1.7.m7.2.2.1.1.3.cmml" xref="S2.SS1.p1.7.m7.2.2.1.1.3">1</cn></apply><ci id="S2.SS1.p1.7.m7.1.1.cmml" xref="S2.SS1.p1.7.m7.1.1">…</ci><apply id="S2.SS1.p1.7.m7.3.3.2.2.cmml" xref="S2.SS1.p1.7.m7.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.3.3.2.2.1.cmml" xref="S2.SS1.p1.7.m7.3.3.2.2">subscript</csymbol><ci id="S2.SS1.p1.7.m7.3.3.2.2.2.cmml" xref="S2.SS1.p1.7.m7.3.3.2.2.2">𝑃</ci><ci id="S2.SS1.p1.7.m7.3.3.2.2.3.cmml" xref="S2.SS1.p1.7.m7.3.3.2.2.3">𝑁</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m7.3c">P_{1},\ldots,P_{N}</annotation></semantics></math>.
Internal events are sequential and causally related.
External events interconnect processes through messages.
We denote the events for a process <math id="S2.SS1.p1.8.m8.1" class="ltx_Math" alttext="P_{i}" display="inline"><semantics id="S2.SS1.p1.8.m8.1a"><msub id="S2.SS1.p1.8.m8.1.1" xref="S2.SS1.p1.8.m8.1.1.cmml"><mi id="S2.SS1.p1.8.m8.1.1.2" xref="S2.SS1.p1.8.m8.1.1.2.cmml">P</mi><mi id="S2.SS1.p1.8.m8.1.1.3" xref="S2.SS1.p1.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.8.m8.1b"><apply id="S2.SS1.p1.8.m8.1.1.cmml" xref="S2.SS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.8.m8.1.1.1.cmml" xref="S2.SS1.p1.8.m8.1.1">subscript</csymbol><ci id="S2.SS1.p1.8.m8.1.1.2.cmml" xref="S2.SS1.p1.8.m8.1.1.2">𝑃</ci><ci id="S2.SS1.p1.8.m8.1.1.3.cmml" xref="S2.SS1.p1.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.8.m8.1c">P_{i}</annotation></semantics></math> as <math id="S2.SS1.p1.9.m9.4" class="ltx_Math" alttext="E_{i}=\{e^{i}_{1},e^{i}_{2},e^{i}_{3},\ldots\}" display="inline"><semantics id="S2.SS1.p1.9.m9.4a"><mrow id="S2.SS1.p1.9.m9.4.4" xref="S2.SS1.p1.9.m9.4.4.cmml"><msub id="S2.SS1.p1.9.m9.4.4.5" xref="S2.SS1.p1.9.m9.4.4.5.cmml"><mi id="S2.SS1.p1.9.m9.4.4.5.2" xref="S2.SS1.p1.9.m9.4.4.5.2.cmml">E</mi><mi id="S2.SS1.p1.9.m9.4.4.5.3" xref="S2.SS1.p1.9.m9.4.4.5.3.cmml">i</mi></msub><mo id="S2.SS1.p1.9.m9.4.4.4" xref="S2.SS1.p1.9.m9.4.4.4.cmml">=</mo><mrow id="S2.SS1.p1.9.m9.4.4.3.3" xref="S2.SS1.p1.9.m9.4.4.3.4.cmml"><mo stretchy="false" id="S2.SS1.p1.9.m9.4.4.3.3.4" xref="S2.SS1.p1.9.m9.4.4.3.4.cmml">{</mo><msubsup id="S2.SS1.p1.9.m9.2.2.1.1.1" xref="S2.SS1.p1.9.m9.2.2.1.1.1.cmml"><mi id="S2.SS1.p1.9.m9.2.2.1.1.1.2.2" xref="S2.SS1.p1.9.m9.2.2.1.1.1.2.2.cmml">e</mi><mn id="S2.SS1.p1.9.m9.2.2.1.1.1.3" xref="S2.SS1.p1.9.m9.2.2.1.1.1.3.cmml">1</mn><mi id="S2.SS1.p1.9.m9.2.2.1.1.1.2.3" xref="S2.SS1.p1.9.m9.2.2.1.1.1.2.3.cmml">i</mi></msubsup><mo id="S2.SS1.p1.9.m9.4.4.3.3.5" xref="S2.SS1.p1.9.m9.4.4.3.4.cmml">,</mo><msubsup id="S2.SS1.p1.9.m9.3.3.2.2.2" xref="S2.SS1.p1.9.m9.3.3.2.2.2.cmml"><mi id="S2.SS1.p1.9.m9.3.3.2.2.2.2.2" xref="S2.SS1.p1.9.m9.3.3.2.2.2.2.2.cmml">e</mi><mn id="S2.SS1.p1.9.m9.3.3.2.2.2.3" xref="S2.SS1.p1.9.m9.3.3.2.2.2.3.cmml">2</mn><mi id="S2.SS1.p1.9.m9.3.3.2.2.2.2.3" xref="S2.SS1.p1.9.m9.3.3.2.2.2.2.3.cmml">i</mi></msubsup><mo id="S2.SS1.p1.9.m9.4.4.3.3.6" xref="S2.SS1.p1.9.m9.4.4.3.4.cmml">,</mo><msubsup id="S2.SS1.p1.9.m9.4.4.3.3.3" xref="S2.SS1.p1.9.m9.4.4.3.3.3.cmml"><mi id="S2.SS1.p1.9.m9.4.4.3.3.3.2.2" xref="S2.SS1.p1.9.m9.4.4.3.3.3.2.2.cmml">e</mi><mn id="S2.SS1.p1.9.m9.4.4.3.3.3.3" xref="S2.SS1.p1.9.m9.4.4.3.3.3.3.cmml">3</mn><mi id="S2.SS1.p1.9.m9.4.4.3.3.3.2.3" xref="S2.SS1.p1.9.m9.4.4.3.3.3.2.3.cmml">i</mi></msubsup><mo id="S2.SS1.p1.9.m9.4.4.3.3.7" xref="S2.SS1.p1.9.m9.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.p1.9.m9.1.1" xref="S2.SS1.p1.9.m9.1.1.cmml">…</mi><mo stretchy="false" id="S2.SS1.p1.9.m9.4.4.3.3.8" xref="S2.SS1.p1.9.m9.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.9.m9.4b"><apply id="S2.SS1.p1.9.m9.4.4.cmml" xref="S2.SS1.p1.9.m9.4.4"><eq id="S2.SS1.p1.9.m9.4.4.4.cmml" xref="S2.SS1.p1.9.m9.4.4.4"></eq><apply id="S2.SS1.p1.9.m9.4.4.5.cmml" xref="S2.SS1.p1.9.m9.4.4.5"><csymbol cd="ambiguous" id="S2.SS1.p1.9.m9.4.4.5.1.cmml" xref="S2.SS1.p1.9.m9.4.4.5">subscript</csymbol><ci id="S2.SS1.p1.9.m9.4.4.5.2.cmml" xref="S2.SS1.p1.9.m9.4.4.5.2">𝐸</ci><ci id="S2.SS1.p1.9.m9.4.4.5.3.cmml" xref="S2.SS1.p1.9.m9.4.4.5.3">𝑖</ci></apply><set id="S2.SS1.p1.9.m9.4.4.3.4.cmml" xref="S2.SS1.p1.9.m9.4.4.3.3"><apply id="S2.SS1.p1.9.m9.2.2.1.1.1.cmml" xref="S2.SS1.p1.9.m9.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.9.m9.2.2.1.1.1.1.cmml" xref="S2.SS1.p1.9.m9.2.2.1.1.1">subscript</csymbol><apply id="S2.SS1.p1.9.m9.2.2.1.1.1.2.cmml" xref="S2.SS1.p1.9.m9.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.9.m9.2.2.1.1.1.2.1.cmml" xref="S2.SS1.p1.9.m9.2.2.1.1.1">superscript</csymbol><ci id="S2.SS1.p1.9.m9.2.2.1.1.1.2.2.cmml" xref="S2.SS1.p1.9.m9.2.2.1.1.1.2.2">𝑒</ci><ci id="S2.SS1.p1.9.m9.2.2.1.1.1.2.3.cmml" xref="S2.SS1.p1.9.m9.2.2.1.1.1.2.3">𝑖</ci></apply><cn type="integer" id="S2.SS1.p1.9.m9.2.2.1.1.1.3.cmml" xref="S2.SS1.p1.9.m9.2.2.1.1.1.3">1</cn></apply><apply id="S2.SS1.p1.9.m9.3.3.2.2.2.cmml" xref="S2.SS1.p1.9.m9.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.9.m9.3.3.2.2.2.1.cmml" xref="S2.SS1.p1.9.m9.3.3.2.2.2">subscript</csymbol><apply id="S2.SS1.p1.9.m9.3.3.2.2.2.2.cmml" xref="S2.SS1.p1.9.m9.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.9.m9.3.3.2.2.2.2.1.cmml" xref="S2.SS1.p1.9.m9.3.3.2.2.2">superscript</csymbol><ci id="S2.SS1.p1.9.m9.3.3.2.2.2.2.2.cmml" xref="S2.SS1.p1.9.m9.3.3.2.2.2.2.2">𝑒</ci><ci id="S2.SS1.p1.9.m9.3.3.2.2.2.2.3.cmml" xref="S2.SS1.p1.9.m9.3.3.2.2.2.2.3">𝑖</ci></apply><cn type="integer" id="S2.SS1.p1.9.m9.3.3.2.2.2.3.cmml" xref="S2.SS1.p1.9.m9.3.3.2.2.2.3">2</cn></apply><apply id="S2.SS1.p1.9.m9.4.4.3.3.3.cmml" xref="S2.SS1.p1.9.m9.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.p1.9.m9.4.4.3.3.3.1.cmml" xref="S2.SS1.p1.9.m9.4.4.3.3.3">subscript</csymbol><apply id="S2.SS1.p1.9.m9.4.4.3.3.3.2.cmml" xref="S2.SS1.p1.9.m9.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.p1.9.m9.4.4.3.3.3.2.1.cmml" xref="S2.SS1.p1.9.m9.4.4.3.3.3">superscript</csymbol><ci id="S2.SS1.p1.9.m9.4.4.3.3.3.2.2.cmml" xref="S2.SS1.p1.9.m9.4.4.3.3.3.2.2">𝑒</ci><ci id="S2.SS1.p1.9.m9.4.4.3.3.3.2.3.cmml" xref="S2.SS1.p1.9.m9.4.4.3.3.3.2.3">𝑖</ci></apply><cn type="integer" id="S2.SS1.p1.9.m9.4.4.3.3.3.3.cmml" xref="S2.SS1.p1.9.m9.4.4.3.3.3.3">3</cn></apply><ci id="S2.SS1.p1.9.m9.1.1.cmml" xref="S2.SS1.p1.9.m9.1.1">…</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.9.m9.4c">E_{i}=\{e^{i}_{1},e^{i}_{2},e^{i}_{3},\ldots\}</annotation></semantics></math>.
The causal relation is typically irreflexive, asymmetric, and transitive.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.2" class="ltx_p">While some causal tasks are concerned with the entire causal model—i.e., the set of all processes and their associated events—many real-world tasks
use a more directed formulation.
Of most interest is the ability to impose specific <span id="S2.SS1.p2.2.1" class="ltx_text ltx_font_italic">interventions</span> or perturbations on a particular process and understanding the resulting impact on <span id="S2.SS1.p2.2.2" class="ltx_text ltx_font_italic">objective</span> process(es).
A causal model may involve a set of interventions <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mi id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><ci id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">I</annotation></semantics></math> and objectives <math id="S2.SS1.p2.2.m2.1" class="ltx_Math" alttext="O" display="inline"><semantics id="S2.SS1.p2.2.m2.1a"><mi id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">O</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">𝑂</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">O</annotation></semantics></math>, each corresponding to specific causes and effects.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Narrative Rendering Pipeline</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">We view the representation of causal data using textual narratives as an interactive <span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_italic">rendering pipeline</span>, akin to a classic graphics rendering or visualization pipeline.
In this model, we think of the <span id="S2.SS2.p1.1.2" class="ltx_text ltx_font_italic">sentence clause</span> as the building block.
Natural language generation (NLG) systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> tend to consist of several stages:</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Content selection:</span> Determining the causality data to display;</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Document structuring and aggregation:</span> Prioritizing the order of data and merging sentences on similar causal data (same source or destination processes) to improve readability;</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Realization:</span> Generating the actual text for each piece of causality information to render in the summary; and</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.1" class="ltx_p"><span id="S2.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Interaction:</span> Providing a feedback loop to allow interaction with the textual narratives, such as to drill down, link to related narratives, or brush to highlight items in associated views.</p>
</div>
</li>
</ol>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">Using natural language to represent data as text is quite different from using visualization, which uses geometric shapes.
Unlike visualization, natural language is typically precise.
This leads to early fixation, as well as serial representations, which limits parallel processing.
In practice, this means that natural language is better suited to presenting specific pieces of information rather than the holistic and parallel overviews that characterize data visualization.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Step 1: Extracting Causality Information</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Our proposed text generation pipeline starts with identifying the specific causality information that users desire.
This generally depends on the application, which we model using a degree-of-interest (DOI) function in the next language generation step.
Thus, our treatment here includes all potentially useful causality information, given our data model.
We organize this information into the following categories:</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<ul id="S2.I2" class="ltx_itemize">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p"><span id="S2.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Cause and effect:</span> A central question when reasoning about causality tends to be the factors that caused a specific effect, which we capture as interventions and objectives. <span id="S2.I2.i1.p1.1.2" class="ltx_text ltx_font_italic">Example:</span> a white cue ball striking the eight ball, sending it bouncing off the nearest wall of a pool table.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p"><span id="S2.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Correlation:</span> While correlation is not causation, many forms of causation have their roots in correlation.
Depending on the causality model, the exact cause and effect may not be known; in such cases, correlations between nodes—i.e., a change in one node followed by a change in another node—can be used as a weaker form.
<span id="S2.I2.i2.p1.1.2" class="ltx_text ltx_font_italic">Example:</span> a medication administered to a patient followed by their blood pressure dropping.</p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.1" class="ltx_p"><span id="S2.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Life cycle:</span> Processes may come and go, often as a result of them receiving an intervention or an internal event.
Such life cycle information is commonly of interest in causal reasoning.
<span id="S2.I2.i3.p1.1.2" class="ltx_text ltx_font_italic">Example:</span> traffic in a computer network being directed around a faulty router that is no longer responding.</p>
</div>
</li>
<li id="S2.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i4.p1" class="ltx_para">
<p id="S2.I2.i4.p1.1" class="ltx_p"><span id="S2.I2.i4.p1.1.1" class="ltx_text ltx_font_bold">Connectivity:</span> Causality modeled as above is essentially a graph, which means that understanding a causal model requires understanding the topology and dynamic connectivity of the events passed in the system.
<span id="S2.I2.i4.p1.1.2" class="ltx_text ltx_font_italic">Example:</span> tracing infections of an airborne virus in a population based on their social contacts.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">For all of the above causality information categories, we can also identify specific common metadata for them all:
<span id="S2.SS3.p3.1.1" class="ltx_text ltx_font_bold">path:</span> the processes on the path between source and destination; <span id="S2.SS3.p3.1.2" class="ltx_text ltx_font_bold">weights:</span> the values or weights associated with each process; and <span id="S2.SS3.p3.1.3" class="ltx_text ltx_font_bold">time:</span> the time stamps associated with each of the events. AJThe types of causal information described above are included in the generated narratives of the crowdsourced study and in <span id="S2.SS3.p3.1.4" class="ltx_text ltx_font_smallcaps">CauseWorks</span> (figure <a href="#S2.F1" title="Figure 1 ‣ 2.6 Step 4: Interacting with Narratives ‣ 2 Design Space: Textual Narratives for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows an example).</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Step 2: Calculating Order</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">Here we determine the structure and order of information that we will use for the textual narrative.
The primary challenge is that even a moderately complex causal system will have a significant number of candidate causal information to convey.</p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<p id="S2.SS4.p2.4" class="ltx_p">To address this challenge, we use a degree-of-interest (DOI) function <math id="S2.SS4.p2.1.m1.1" class="ltx_Math" alttext="f_{DOI}(e)\subseteq\mathbb{R}" display="inline"><semantics id="S2.SS4.p2.1.m1.1a"><mrow id="S2.SS4.p2.1.m1.1.2" xref="S2.SS4.p2.1.m1.1.2.cmml"><mrow id="S2.SS4.p2.1.m1.1.2.2" xref="S2.SS4.p2.1.m1.1.2.2.cmml"><msub id="S2.SS4.p2.1.m1.1.2.2.2" xref="S2.SS4.p2.1.m1.1.2.2.2.cmml"><mi id="S2.SS4.p2.1.m1.1.2.2.2.2" xref="S2.SS4.p2.1.m1.1.2.2.2.2.cmml">f</mi><mrow id="S2.SS4.p2.1.m1.1.2.2.2.3" xref="S2.SS4.p2.1.m1.1.2.2.2.3.cmml"><mi id="S2.SS4.p2.1.m1.1.2.2.2.3.2" xref="S2.SS4.p2.1.m1.1.2.2.2.3.2.cmml">D</mi><mo lspace="0em" rspace="0em" id="S2.SS4.p2.1.m1.1.2.2.2.3.1" xref="S2.SS4.p2.1.m1.1.2.2.2.3.1.cmml">​</mo><mi id="S2.SS4.p2.1.m1.1.2.2.2.3.3" xref="S2.SS4.p2.1.m1.1.2.2.2.3.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S2.SS4.p2.1.m1.1.2.2.2.3.1a" xref="S2.SS4.p2.1.m1.1.2.2.2.3.1.cmml">​</mo><mi id="S2.SS4.p2.1.m1.1.2.2.2.3.4" xref="S2.SS4.p2.1.m1.1.2.2.2.3.4.cmml">I</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.SS4.p2.1.m1.1.2.2.1" xref="S2.SS4.p2.1.m1.1.2.2.1.cmml">​</mo><mrow id="S2.SS4.p2.1.m1.1.2.2.3.2" xref="S2.SS4.p2.1.m1.1.2.2.cmml"><mo stretchy="false" id="S2.SS4.p2.1.m1.1.2.2.3.2.1" xref="S2.SS4.p2.1.m1.1.2.2.cmml">(</mo><mi id="S2.SS4.p2.1.m1.1.1" xref="S2.SS4.p2.1.m1.1.1.cmml">e</mi><mo stretchy="false" id="S2.SS4.p2.1.m1.1.2.2.3.2.2" xref="S2.SS4.p2.1.m1.1.2.2.cmml">)</mo></mrow></mrow><mo id="S2.SS4.p2.1.m1.1.2.1" xref="S2.SS4.p2.1.m1.1.2.1.cmml">⊆</mo><mi id="S2.SS4.p2.1.m1.1.2.3" xref="S2.SS4.p2.1.m1.1.2.3.cmml">ℝ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p2.1.m1.1b"><apply id="S2.SS4.p2.1.m1.1.2.cmml" xref="S2.SS4.p2.1.m1.1.2"><subset id="S2.SS4.p2.1.m1.1.2.1.cmml" xref="S2.SS4.p2.1.m1.1.2.1"></subset><apply id="S2.SS4.p2.1.m1.1.2.2.cmml" xref="S2.SS4.p2.1.m1.1.2.2"><times id="S2.SS4.p2.1.m1.1.2.2.1.cmml" xref="S2.SS4.p2.1.m1.1.2.2.1"></times><apply id="S2.SS4.p2.1.m1.1.2.2.2.cmml" xref="S2.SS4.p2.1.m1.1.2.2.2"><csymbol cd="ambiguous" id="S2.SS4.p2.1.m1.1.2.2.2.1.cmml" xref="S2.SS4.p2.1.m1.1.2.2.2">subscript</csymbol><ci id="S2.SS4.p2.1.m1.1.2.2.2.2.cmml" xref="S2.SS4.p2.1.m1.1.2.2.2.2">𝑓</ci><apply id="S2.SS4.p2.1.m1.1.2.2.2.3.cmml" xref="S2.SS4.p2.1.m1.1.2.2.2.3"><times id="S2.SS4.p2.1.m1.1.2.2.2.3.1.cmml" xref="S2.SS4.p2.1.m1.1.2.2.2.3.1"></times><ci id="S2.SS4.p2.1.m1.1.2.2.2.3.2.cmml" xref="S2.SS4.p2.1.m1.1.2.2.2.3.2">𝐷</ci><ci id="S2.SS4.p2.1.m1.1.2.2.2.3.3.cmml" xref="S2.SS4.p2.1.m1.1.2.2.2.3.3">𝑂</ci><ci id="S2.SS4.p2.1.m1.1.2.2.2.3.4.cmml" xref="S2.SS4.p2.1.m1.1.2.2.2.3.4">𝐼</ci></apply></apply><ci id="S2.SS4.p2.1.m1.1.1.cmml" xref="S2.SS4.p2.1.m1.1.1">𝑒</ci></apply><ci id="S2.SS4.p2.1.m1.1.2.3.cmml" xref="S2.SS4.p2.1.m1.1.2.3">ℝ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p2.1.m1.1c">f_{DOI}(e)\subseteq\mathbb{R}</annotation></semantics></math> based on user interest and task to prioritize each event <math id="S2.SS4.p2.2.m2.1" class="ltx_Math" alttext="e" display="inline"><semantics id="S2.SS4.p2.2.m2.1a"><mi id="S2.SS4.p2.2.m2.1.1" xref="S2.SS4.p2.2.m2.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p2.2.m2.1b"><ci id="S2.SS4.p2.2.m2.1.1.cmml" xref="S2.SS4.p2.2.m2.1.1">𝑒</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p2.2.m2.1c">e</annotation></semantics></math> involved in the sequence of causality data extracted from the prior step.
As a first level of prioritization, we propose limiting reports to the sets of interventions <math id="S2.SS4.p2.3.m3.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S2.SS4.p2.3.m3.1a"><mi id="S2.SS4.p2.3.m3.1.1" xref="S2.SS4.p2.3.m3.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p2.3.m3.1b"><ci id="S2.SS4.p2.3.m3.1.1.cmml" xref="S2.SS4.p2.3.m3.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p2.3.m3.1c">I</annotation></semantics></math> and objectives <math id="S2.SS4.p2.4.m4.1" class="ltx_Math" alttext="O" display="inline"><semantics id="S2.SS4.p2.4.m4.1a"><mi id="S2.SS4.p2.4.m4.1.1" xref="S2.SS4.p2.4.m4.1.1.cmml">O</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p2.4.m4.1b"><ci id="S2.SS4.p2.4.m4.1.1.cmml" xref="S2.SS4.p2.4.m4.1.1">𝑂</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p2.4.m4.1c">O</annotation></semantics></math>, as described in Section <a href="#S2.SS1" title="2.1 Definitions ‣ 2 Design Space: Textual Narratives for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>.
We group items on a per-process basis, and then further prioritize events based on their occurrences, magnitude of change, and influence.
To represent this information, we use a directed acyclic graph (DAG) as a scene graph to store the abstract data to render, where each causal process becomes a top-level container for associated causality data.</p>
</div>
<div id="S2.SS4.p3" class="ltx_para">
<p id="S2.SS4.p3.1" class="ltx_p">Generally speaking, generating a complete sentence for each clause—recall that a clause corresponds to an individual item of data—is the most clear and unambiguous approach.
However, this often leads to significant repetition, which is often seen as clumsy and unnatural to a reader, as well as unnecessary verbosity, which is wasteful given that summaries are often limited in length.
For this reason, we use <span id="S2.SS4.p3.1.1" class="ltx_text ltx_font_italic">aggregation</span> to merge similar clauses that share the same source or destination process into a single sentence. AJWe have aggregated events in our generated narratives (see Figures <a href="#S3.F2" title="Figure 2 ‣ 3.4 Experimental Design ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and <a href="#S3.F7" title="Figure 7 ‣ 3.9 Discussion ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>).</p>
</div>
</section>
<section id="S2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Step 3: Rendering Textual Narratives</h3>

<div id="S2.SS5.p1" class="ltx_para">
<p id="S2.SS5.p1.1" class="ltx_p">We think of realizing the ordered causality data to be expressed as <span id="S2.SS5.p1.1.1" class="ltx_text ltx_font_italic">rendering</span> the narrative, akin to how a computer graphics system may render a sorted list of triangles to generate a 3D scene.
Since our focus is on generating summaries, the notion of a <span id="S2.SS5.p1.1.2" class="ltx_text ltx_font_italic">character budget</span> is central to our approach: this is the maximum number of characters that we want to use to realize the textual narrative.
This budget is not prescriptive, only restrictive; in other words, if space is not an issue, the budget can be set to infinity, resulting in exhaustive textual summaries.</p>
</div>
<div id="S2.SS5.p2" class="ltx_para">
<p id="S2.SS5.p2.1" class="ltx_p">The actual rendering process proceeds by iterating through the sorted data graph, where items are grouped based on top-level processes, as described above.
By knowing the number of characters for each branch of the data graph, the renderer can determine how deeply to traverse while maintaining the character budget.
Furthermore, we can also identify the available visual channels for conveying data using text:</p>
</div>
<div id="S2.SS5.p3" class="ltx_para">
<ul id="S2.I3" class="ltx_itemize">
<li id="S2.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i1.p1" class="ltx_para">
<p id="S2.I3.i1.p1.1" class="ltx_p"><span id="S2.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">Textual content:</span> The primary visual channel is obviously the written content that the text spells out.</p>
</div>
</li>
<li id="S2.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i2.p1" class="ltx_para">
<p id="S2.I3.i2.p1.1" class="ltx_p"><span id="S2.I3.i2.p1.1.1" class="ltx_text ltx_font_bold">Font size:</span> Most summaries will use a uniform font size, as changing the size of individual words or sentences throughout a text can be disruptive to reading as well as when calculating its space needs.
However, it can be an effective way to show emphasis, particularly for titles and section headings.</p>
</div>
</li>
<li id="S2.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i3.p1" class="ltx_para">
<p id="S2.I3.i3.p1.1" class="ltx_p"><span id="S2.I3.i3.p1.1.1" class="ltx_text ltx_font_bold">Typographic emphasis:</span> A more common and typographically accepted practice is to use emphasis such as <span id="S2.I3.i3.p1.1.2" class="ltx_text ltx_font_bold">boldface</span>, <span id="S2.I3.i3.p1.1.3" class="ltx_text ltx_font_italic">italics</span>, or <span id="S2.I3.i3.p1.1.4" class="ltx_text ltx_framed ltx_framed_underline">underlining</span> to communicate data in the narrative, such as to mark processes, effects, or magnitudes.
Additional such emphasis markers include <span id="S2.I3.i3.p1.1.5" class="ltx_text ltx_font_smallcaps">Small Caps</span>, ALL CAPS, or the use of punctuation (!) or “quotation marks” in the text.</p>
</div>
</li>
<li id="S2.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i4.p1" class="ltx_para">
<p id="S2.I3.i4.p1.1" class="ltx_p"><span id="S2.I3.i4.p1.1.1" class="ltx_text ltx_font_bold">Color:</span> As for visualization, color can be an effective visual channel.
We differentiate between the use of <span id="S2.I3.i4.p1.1.2" class="ltx_text" style="color:#66FF66;">font color</span> and <span id="S2.I3.i4.p1.1.3" class="ltx_text" style="background-color:#B3B3FF;">background color</span>, which can be used to convey different data (although, as always, care must be taken to avoid interference).</p>
</div>
</li>
<li id="S2.I3.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i5.p1" class="ltx_para">
<p id="S2.I3.i5.p1.1" class="ltx_p"><span id="S2.I3.i5.p1.1.1" class="ltx_text ltx_font_bold">Hierarchical lists:</span> While not part of classic running prose, which tends to just use sentences and paragraphs as its typographic structures, we also consider lists—both enumerated and itemized ones—a useful visual channel.
In particular, nesting lists can allow for showing hierarchical part-of relationships.</p>
</div>
</li>
<li id="S2.I3.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i6.p1" class="ltx_para">
<p id="S2.I3.i6.p1.8" class="ltx_p"><span id="S2.I3.i6.p1.8.1" class="ltx_text ltx_font_bold">Word-scale graphics:</span> Despite our focus on written text, we cannot resist drawing on visualization, in the form of <span id="S2.I3.i6.p1.8.2" class="ltx_text ltx_font_italic">word-scale graphics</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>: small data-driven graphics that can be embedded into running text.
Examples include mathematical symbols such as <math id="S2.I3.i6.p1.1.m1.2" class="ltx_Math" alttext="\uparrow,\bigtriangleup" display="inline"><semantics id="S2.I3.i6.p1.1.m1.2a"><mrow id="S2.I3.i6.p1.1.m1.2.3.2" xref="S2.I3.i6.p1.1.m1.2.3.1.cmml"><mo rspace="0em" stretchy="false" id="S2.I3.i6.p1.1.m1.1.1" xref="S2.I3.i6.p1.1.m1.1.1.cmml">↑</mo><mo rspace="0em" id="S2.I3.i6.p1.1.m1.2.3.2.1" xref="S2.I3.i6.p1.1.m1.2.3.1.cmml">,</mo><mo lspace="0em" id="S2.I3.i6.p1.1.m1.2.2" xref="S2.I3.i6.p1.1.m1.2.2.cmml">△</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I3.i6.p1.1.m1.2b"><list id="S2.I3.i6.p1.1.m1.2.3.1.cmml" xref="S2.I3.i6.p1.1.m1.2.3.2"><ci id="S2.I3.i6.p1.1.m1.1.1.cmml" xref="S2.I3.i6.p1.1.m1.1.1">↑</ci><ci id="S2.I3.i6.p1.1.m1.2.2.cmml" xref="S2.I3.i6.p1.1.m1.2.2">△</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S2.I3.i6.p1.1.m1.2c">\uparrow,\bigtriangleup</annotation></semantics></math>, and <math id="S2.I3.i6.p1.2.m2.1" class="ltx_Math" alttext="\bowtie" display="inline"><semantics id="S2.I3.i6.p1.2.m2.1a"><mo id="S2.I3.i6.p1.2.m2.1.1" xref="S2.I3.i6.p1.2.m2.1.1.cmml">⋈</mo><annotation-xml encoding="MathML-Content" id="S2.I3.i6.p1.2.m2.1b"><ci id="S2.I3.i6.p1.2.m2.1.1.cmml" xref="S2.I3.i6.p1.2.m2.1.1">⋈</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I3.i6.p1.2.m2.1c">\bowtie</annotation></semantics></math>, icons such as <img src="/html/2009.02649/assets/figures/disk-icon.png" id="S2.I3.i6.p1.3.g1" class="ltx_graphics ltx_img_square" width="13" height="14" alt="[Uncaptioned image]">, <img src="/html/2009.02649/assets/figures/gamepad-icon.png" id="S2.I3.i6.p1.4.g2" class="ltx_graphics ltx_img_square" width="14" height="14" alt="[Uncaptioned image]">, and <img src="/html/2009.02649/assets/figures/camera-icon.png" id="S2.I3.i6.p1.5.g3" class="ltx_graphics ltx_img_landscape" width="18" height="14" alt="[Uncaptioned image]">, as well as micro visualizations such as <img src="/html/2009.02649/assets/figures/dots.png" id="S2.I3.i6.p1.6.g4" class="ltx_graphics ltx_img_square" width="14" height="14" alt="[Uncaptioned image]">, <img src="/html/2009.02649/assets/figures/barchart.png" id="S2.I3.i6.p1.7.g5" class="ltx_graphics ltx_img_landscape" width="19" height="14" alt="[Uncaptioned image]">, and <img src="/html/2009.02649/assets/figures/sparkline.png" id="S2.I3.i6.p1.8.g6" class="ltx_graphics ltx_img_landscape" width="60" height="14" alt="[Uncaptioned image]"> (sparklines).</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.6 </span>Step 4: Interacting with Narratives</h3>

<div id="S2.SS6.p1" class="ltx_para">
<p id="S2.SS6.p1.1" class="ltx_p">Finally, since our intended output format almost always is on a computer screen—and not paper—we should also consider how to interact with these textual narratives.
We propose the following possibilities:</p>
</div>
<div id="S2.SS6.p2" class="ltx_para">
<ul id="S2.I4" class="ltx_itemize">
<li id="S2.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I4.i1.p1" class="ltx_para">
<p id="S2.I4.i1.p1.1" class="ltx_p"><span id="S2.I4.i1.p1.1.1" class="ltx_text ltx_font_bold">Brushing:</span> Hovering over a process or an event in a narrative highlights all of its occurrences in related views (or narratives).</p>
</div>
</li>
<li id="S2.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I4.i2.p1" class="ltx_para">
<p id="S2.I4.i2.p1.1" class="ltx_p"><span id="S2.I4.i2.p1.1.1" class="ltx_text ltx_font_bold">Hyperlinking:</span> Entities in the narrative are hyperlinks where clicking on one will navigate to it in related views (or narratives).</p>
</div>
</li>
<li id="S2.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I4.i3.p1" class="ltx_para">
<p id="S2.I4.i3.p1.1" class="ltx_p"><span id="S2.I4.i3.p1.1.1" class="ltx_text ltx_font_bold">Drill-down/roll-up:</span> Dynamically changing the user’s degree of interest will allow for drilling down, e.g., by unfolding the items in a list or expanding suppressed elements in an enumeration.</p>
</div>
</li>
<li id="S2.I4.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I4.i4.p1" class="ltx_para">
<p id="S2.I4.i4.p1.1" class="ltx_p"><span id="S2.I4.i4.p1.1.1" class="ltx_text ltx_font_bold">Search:</span> Directly querying specific elements in a narrative by typing partial or complete search terms allows for quick access <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2009.02649/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Annotated example of a narrative conveying causal information about interventions and objectives.</figcaption>
</figure>
</section>
<section id="S2.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.7 </span>Discussion: What Makes an Effective Narrative?</h3>

<div id="S2.SS7.p1" class="ltx_para">
<p id="S2.SS7.p1.1" class="ltx_p">Textual narratives are slowly making their way into visualization systems, either as a way to generate data insights to accompany a visualization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> or to structure a visualization for better communication <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>.
Research into what makes an effective narrative is still in its infancy and is necessarily tied to the underlying analytical task and domain.
For the causal networks domain considered here we identify four facets:</p>
<ul id="S2.I5" class="ltx_itemize">
<li id="S2.I5.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I5.i1.p1" class="ltx_para">
<p id="S2.I5.i1.p1.1" class="ltx_p"><span id="S2.I5.i1.p1.1.1" class="ltx_text ltx_font_bold">Language diversity:</span>
More language diversity avoids monotony but might detract from conveying key messages and conclusions.
Less language diversity supports comparison of generated narratives but might lead to ‘glossing over’ by analysts.</p>
</div>
</li>
<li id="S2.I5.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I5.i2.p1" class="ltx_para">
<p id="S2.I5.i2.p1.1" class="ltx_p"><span id="S2.I5.i2.p1.1.1" class="ltx_text ltx_font_bold">Level of detail:</span> Should the narrative capture an executive summary or provide in-depth access to the underlying data?AJ We briefly discuss the preferred level of detail in our expert review.</p>
</div>
</li>
<li id="S2.I5.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I5.i3.p1" class="ltx_para">
<p id="S2.I5.i3.p1.1" class="ltx_p"><span id="S2.I5.i3.p1.1.1" class="ltx_text ltx_font_bold">Verbalizing numbers:</span> Verbalizing quantitative/probabilistic data (e.g., using Kent’s words of estimative probability <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> or the NIC/Mercyhurst standardization) is considered important in specific domains (e.g., intelligence analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>) but other applications argue for direct access to the original numeric information.</p>
</div>
</li>
<li id="S2.I5.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I5.i4.p1" class="ltx_para">
<p id="S2.I5.i4.p1.1" class="ltx_p"><span id="S2.I5.i4.p1.1.1" class="ltx_text ltx_font_bold">Human performance aspects:</span> Understanding the characteristics of narratives that lead to improved human performance is an ongoing research problem<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>.
Narratives provide increased comprehension, interest, and engagement and are known to contribute “distinct cognitive pathways of comprehension” with increased recall, ease of comprehension, and shorter reading times <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
Conversely, the challenge of the written word implies slowness and error-prone behavior due to short-term memory limits.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS7.p2" class="ltx_para">
<p id="S2.SS7.p2.1" class="ltx_p">In general, successful narrative research requires a standardization of both the generation and evaluation space, and an understanding of how a narrative fits into the larger comprehension process of the analyst.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Crowdsourced Study: Narration for Causality</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We conducted a crowdsourced study
to AJunderstand how narratives augment causal data exploration through visual analysis.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Participants</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">AJWe recruited our participants through crowdsourcing from <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">Amazon Mechanical Turk (MTurk)</span> to complete visual analysis tasks that did not require prior training or data visualization expertise.
Owing to the nature of MTurk, we had limited control over participant demographics, technology, and skill level.
However, prior work indicates that simple tasks such as ours are flexible to a crowdsourced study design <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.
We planned to recruit 150 participants; all were drawn from within the United States due to tax and compensation restrictions by our Institutional Review Board (IRB).
To ensure that our participants understood our task instructions, we screened our participants for working English knowledge.
Participants were allowed to participate only once.
We estimated our study completion time to be 20–30 minutes, and compensated our participants ethically at a rate of at least $8/hour (similar to the U.S. federal minimum wage in 2019 of $7.25).</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Apparatus</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We required our participants to use a desktop computer (no mobile devices), and the study was distributed through a web browser.
We ensured that the visual representations, textual narratives, and their labels were legible for all common device formats.
The testing platform was implemented as a <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">Qualtrics</span> survey with static trials saved as non-interactive AJmockups that were manually created using <span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_italic">Microsoft PowerPoint</span>, and were based on various factors such as polarity of links, link overlaps, and the number of intervening/objective nodes. The narratives were created manually based Section <a href="#S2.SS2" title="2.2 Narrative Rendering Pipeline ‣ 2 Design Space: Textual Narratives for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a> (Figure <a href="#S3.F2" title="Figure 2 ‣ 3.4 Experimental Design ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Experimental Factors</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">AJOur goal was to first experimentally understand how the presence of a narrative augments causal analysis using visual representation.
We chose a more familiar and less temporal causal representation (Causal Graph) and less familiar and more temporal causal representation (Hasse Diagram).
We modeled four factors in our experiment:</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Causality Visualization (VR)</span>:
The visual representation used for conveying causality.
We chose two levels:</p>
<ul id="S3.I1.i1.I1" class="ltx_itemize">
<li id="S3.I1.i1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I1.i1.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I1.i1.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Causal Graph (NL)</span>: A Causal Graph is a node-link representation of the causal network.</p>
</div>
</li>
<li id="S3.I1.i1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I1.i1.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I1.i1.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i1.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Hasse Diagram (HD)</span>: We use a similar representation of Hasse diagrams as seen in previous work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Textual Narrative (TN)</span>: This is a key factor in our study: the 1) presence <span id="S3.I1.i2.p1.1.2" class="ltx_text ltx_font_bold">(ON)</span> or 2) absence <span id="S3.I1.i2.p1.1.3" class="ltx_text ltx_font_bold">(OFF)</span> of a textual narrative.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Difficulty (DL)</span>: The difficulty of the trial is expressed in the size of the causal system involved in the event sequence.
We chose three levels for this factor:</p>
<ul id="S3.I1.i3.I1" class="ltx_itemize">
<li id="S3.I1.i3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I1.i3.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I1.i3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Simple (S)</span>: 3 or 5 nodes, and up to 4 time-hops (T1–T4)</p>
</div>
</li>
<li id="S3.I1.i3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I1.i3.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I1.i3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Medium (M)</span>: 5 to 8 nodes, and up 5 time-hops (T1–T5)</p>
</div>
</li>
<li id="S3.I1.i3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I1.i3.I1.i3.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I1.i3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Hard (H)</span>: 9 to 12 nodes, and up to 5 time-hops (T1–T5)</p>
</div>
<div id="S3.I1.i3.I1.i3.p2" class="ltx_para">
<p id="S3.I1.i3.I1.i3.p2.1" class="ltx_p">We settled on these values through pilot testing to ensure that our tasks can typically be completed in 30 minutes.</p>
</div>
</li>
</ul>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p"><span id="S3.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Narrative Scope (NS)</span>: Inherently, the Hasse diagram affords the explicit showing of changes in a node across time intervals (e.g. T1–T2; T2–T3, etc.).
On the other hand, the Causal Graph (NL) requires the user to follow the causal path between nodes to extrapolate temporal information.
This means that the accompanying textual narrative could describe effect propagation between successive time-hops—<span id="S3.I1.i4.p1.1.2" class="ltx_text ltx_font_bold">Instantaneous</span> (IS)—or can provide a <span id="S3.I1.i4.p1.1.3" class="ltx_text ltx_font_bold">Cumulative</span> (CU) summary across all observed time.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">This leads to 24 conditions.
Since NS is only relevant for situations when TN is ON, this yields a total of 18 conditions.
We presented a total of 12 causal graph systems (CGS) to each of our participants.   AJAlthough we do not include all aspects of our design space as experimental conditions, we use our narrative rendering pipeline in our mockups.
We were also limited by the non-interactivity of our stimulus.
Figure <a href="#S3.F2" title="Figure 2 ‣ 3.4 Experimental Design ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows a representation of the above mentioned factors, and also is annotated with applicable aspects of our narrative rendering pipeline.
 AJThe nodes and edges in both visual representations of our abstract data were drawn manually with the aim of reducing edge crossing and length minimization.
For larger and realistic datasets, we recommend using graph layout algorithms that minimize edge length and crossings.
We can also note that the generated narratives are similar to those in Figure <a href="#S2.F1" title="Figure 1 ‣ 2.6 Step 4: Interacting with Narratives ‣ 2 Design Space: Textual Narratives for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, which are a manifestation of the proposed design space.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Experimental Design</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">We used a mixed design in our study: between-subjects for VR, TN and NS; and within-subjects for DL (Table <a href="#S3.T1" title="Table 1 ‣ 3.4 Experimental Design ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Six groups with 25 participants per group; N=150 (25 <math id="S3.T1.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.2.m1.1b"><mo id="S3.T1.2.m1.1.1" xref="S3.T1.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.T1.2.m1.1c"><times id="S3.T1.2.m1.1.1.cmml" xref="S3.T1.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.m1.1d">\times</annotation></semantics></math> 6).</figcaption>
<table id="S3.T1.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.3.1.1" class="ltx_tr">
<th id="S3.T1.3.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<td id="S3.T1.3.1.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.3.1.1.2.1" class="ltx_text ltx_font_bold" style="background-color:#C0C0C0;">H1</span></td>
<td id="S3.T1.3.1.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.3.1.1.3.1" class="ltx_text ltx_font_bold" style="background-color:#C0C0C0;">H2</span></td>
<td id="S3.T1.3.1.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.3.1.1.4.1" class="ltx_text ltx_font_bold" style="background-color:#C0C0C0;">H3</span></td>
<td id="S3.T1.3.1.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.3.1.1.5.1" class="ltx_text ltx_font_bold" style="background-color:#C0C0C0;">N1</span></td>
<td id="S3.T1.3.1.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.3.1.1.6.1" class="ltx_text ltx_font_bold" style="background-color:#C0C0C0;">N2</span></td>
<td id="S3.T1.3.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.3.1.1.7.1" class="ltx_text ltx_font_bold" style="background-color:#C0C0C0;">N3</span></td>
</tr>
<tr id="S3.T1.3.2.2" class="ltx_tr">
<th id="S3.T1.3.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="background-color:#EFEFEF;"><span id="S3.T1.3.2.2.1.1" class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">VR</span></th>
<td id="S3.T1.3.2.2.2" class="ltx_td ltx_align_center ltx_border_t">HD</td>
<td id="S3.T1.3.2.2.3" class="ltx_td ltx_align_center ltx_border_t">HD</td>
<td id="S3.T1.3.2.2.4" class="ltx_td ltx_align_center ltx_border_t">HD</td>
<td id="S3.T1.3.2.2.5" class="ltx_td ltx_align_center ltx_border_t">NL</td>
<td id="S3.T1.3.2.2.6" class="ltx_td ltx_align_center ltx_border_t">NL</td>
<td id="S3.T1.3.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NL</td>
</tr>
<tr id="S3.T1.3.3.3" class="ltx_tr">
<th id="S3.T1.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="background-color:#EFEFEF;"><span id="S3.T1.3.3.3.1.1" class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">TN</span></th>
<td id="S3.T1.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t">OFF</td>
<td id="S3.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">ON</td>
<td id="S3.T1.3.3.3.4" class="ltx_td ltx_align_center ltx_border_t">ON</td>
<td id="S3.T1.3.3.3.5" class="ltx_td ltx_align_center ltx_border_t">OFF</td>
<td id="S3.T1.3.3.3.6" class="ltx_td ltx_align_center ltx_border_t">ON</td>
<td id="S3.T1.3.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ON</td>
</tr>
<tr id="S3.T1.3.4.4" class="ltx_tr">
<th id="S3.T1.3.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="background-color:#EFEFEF;"><span id="S3.T1.3.4.4.1.1" class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">NS</span></th>
<td id="S3.T1.3.4.4.2" class="ltx_td ltx_align_center ltx_border_t">–</td>
<td id="S3.T1.3.4.4.3" class="ltx_td ltx_align_center ltx_border_t">CU</td>
<td id="S3.T1.3.4.4.4" class="ltx_td ltx_align_center ltx_border_t">IS</td>
<td id="S3.T1.3.4.4.5" class="ltx_td ltx_align_center ltx_border_t">–</td>
<td id="S3.T1.3.4.4.6" class="ltx_td ltx_align_center ltx_border_t">CU</td>
<td id="S3.T1.3.4.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">IS</td>
</tr>
<tr id="S3.T1.3.5.5" class="ltx_tr">
<th id="S3.T1.3.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="background-color:#EFEFEF;"><span id="S3.T1.3.5.5.1.1" class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">DL</span></th>
<td id="S3.T1.3.5.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">
<table id="S3.T1.3.5.5.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.3.5.5.2.1.1" class="ltx_tr">
<td id="S3.T1.3.5.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">S</td>
</tr>
<tr id="S3.T1.3.5.5.2.1.2" class="ltx_tr">
<td id="S3.T1.3.5.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">M</td>
</tr>
<tr id="S3.T1.3.5.5.2.1.3" class="ltx_tr">
<td id="S3.T1.3.5.5.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">H</td>
</tr>
</table>
</td>
<td id="S3.T1.3.5.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">
<table id="S3.T1.3.5.5.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.3.5.5.3.1.1" class="ltx_tr">
<td id="S3.T1.3.5.5.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">S</td>
</tr>
<tr id="S3.T1.3.5.5.3.1.2" class="ltx_tr">
<td id="S3.T1.3.5.5.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">M</td>
</tr>
<tr id="S3.T1.3.5.5.3.1.3" class="ltx_tr">
<td id="S3.T1.3.5.5.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">H</td>
</tr>
</table>
</td>
<td id="S3.T1.3.5.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">
<table id="S3.T1.3.5.5.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.3.5.5.4.1.1" class="ltx_tr">
<td id="S3.T1.3.5.5.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">S</td>
</tr>
<tr id="S3.T1.3.5.5.4.1.2" class="ltx_tr">
<td id="S3.T1.3.5.5.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">M</td>
</tr>
<tr id="S3.T1.3.5.5.4.1.3" class="ltx_tr">
<td id="S3.T1.3.5.5.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">H</td>
</tr>
</table>
</td>
<td id="S3.T1.3.5.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">
<table id="S3.T1.3.5.5.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.3.5.5.5.1.1" class="ltx_tr">
<td id="S3.T1.3.5.5.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">S</td>
</tr>
<tr id="S3.T1.3.5.5.5.1.2" class="ltx_tr">
<td id="S3.T1.3.5.5.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">M</td>
</tr>
<tr id="S3.T1.3.5.5.5.1.3" class="ltx_tr">
<td id="S3.T1.3.5.5.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">H</td>
</tr>
</table>
</td>
<td id="S3.T1.3.5.5.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">
<table id="S3.T1.3.5.5.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.3.5.5.6.1.1" class="ltx_tr">
<td id="S3.T1.3.5.5.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">S</td>
</tr>
<tr id="S3.T1.3.5.5.6.1.2" class="ltx_tr">
<td id="S3.T1.3.5.5.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">M</td>
</tr>
<tr id="S3.T1.3.5.5.6.1.3" class="ltx_tr">
<td id="S3.T1.3.5.5.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">H</td>
</tr>
</table>
</td>
<td id="S3.T1.3.5.5.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<table id="S3.T1.3.5.5.7.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.3.5.5.7.1.1" class="ltx_tr">
<td id="S3.T1.3.5.5.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">S</td>
</tr>
<tr id="S3.T1.3.5.5.7.1.2" class="ltx_tr">
<td id="S3.T1.3.5.5.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">M</td>
</tr>
<tr id="S3.T1.3.5.5.7.1.3" class="ltx_tr">
<td id="S3.T1.3.5.5.7.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">H</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">Each participant saw all conditions of difficulty, but only one causality visualization.
The relatively small total number of conditions enabled us to keep the session duration shorter than 30 minutes in duration to minimize fatigue and maximize attention for crowdworkers.
In total, we planned to recruit 25 participants to each of six groups.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2009.02649/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="230" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span> AJSample stimuli (DL: Simple) used in our 6 groups, with Hasse Diagram (HD) and Causal Graphs (NL). Sample narrative from groups N2 and H2 has been annotated with elements used from our design space.</figcaption>
</figure>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Analysis Tasks</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">Causal systems are complex structures that involve many processes (events) and messages propagating through a network of connections.
In our user study, we use the words ‘node’ to mean a process and ‘link’ to mean a connection between ‘nodes’.
The comprehensibility of a cause-effect relationship between, say, two nodes might also require an understanding of other effects that have propagated or will propagate through the system.
Broadly, an understanding of <span id="S3.SS5.p1.1.1" class="ltx_text ltx_font_italic">causality</span> might require a user to ask questions such as a) what factors caused a specific effect?, b) how does the effect on a node affect other connected nodes and to what extent?, c) what are the sequential and temporal impacts of this effect on the entire system?, d) how does this effect change or not change the earlier trend of the node.
We adapted types of analysis tasks from previous work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, and created 24 tasks for our participants.</p>
</div>
<div id="S3.SS5.p2" class="ltx_para">
<p id="S3.SS5.p2.1" class="ltx_p">Each task was of one of the following three types <span id="S3.SS5.p2.1.1" class="ltx_text ltx_font_bold">(QT)</span>: 1) Influence analysis <span id="S3.SS5.p2.1.2" class="ltx_text ltx_font_bold">(I)</span>, 2) Cause-effect analysis <span id="S3.SS5.p2.1.3" class="ltx_text ltx_font_bold">(C)</span>, and 3) Life-cycle Analysis <span id="S3.SS5.p2.1.4" class="ltx_text ltx_font_bold">(L)</span>.
 AJThese task types are adaptations of causality information described in Section <a href="#S2.SS3" title="2.3 Step 1: Extracting Causality Information ‣ 2 Design Space: Textual Narratives for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>.
In the tutorial, we explained to our participants that we choose certain <span id="S3.SS5.p2.1.5" class="ltx_text ltx_font_italic">Intervention</span> and <span id="S3.SS5.p2.1.6" class="ltx_text ltx_font_italic">Objective</span> nodes to analyze causal relationships.
Table <a href="#S3.T2" title="Table 2 ‣ Subjective Responses. ‣ 3.6 Collected Metrics ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the 9 types of AJtasks included in our study.</p>
</div>
<div id="S3.SS5.p3" class="ltx_para">
<p id="S3.SS5.p3.4" class="ltx_p">AJWithin each group, each participant saw 12 graph systems (4 <math id="S3.SS5.p3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.SS5.p3.1.m1.1a"><mo id="S3.SS5.p3.1.m1.1.1" xref="S3.SS5.p3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.1.m1.1b"><times id="S3.SS5.p3.1.m1.1.1.cmml" xref="S3.SS5.p3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.1.m1.1c">\times</annotation></semantics></math> [S, M, H]).
A fixed order of increasing graph difficulty and tasks were used to improve familiarity by limiting chances of early task failure.
Each graph system had 2 analysis sub-tasks.
We distributed the first 8 task sub-types sequentially to each graph system within a DL, and alternated Trend (L4) with Spike (L5), in the event of a particular graph system showing a spike in a particular node (more on spikes in Section <a href="#S4.SS2" title="4.2 Extracting Causality ‣ 4 Application: The CauseWorks System ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>).
Thus, each DL covered all the Task types (QT).
Each sub-task required participants to read the question text and choose 1 out of 4 possible responses.
Thus, for 150 participants, we planned to collect a total of 3,600 trials –150 <math id="S3.SS5.p3.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.SS5.p3.2.m2.1a"><mo id="S3.SS5.p3.2.m2.1.1" xref="S3.SS5.p3.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.2.m2.1b"><times id="S3.SS5.p3.2.m2.1.1.cmml" xref="S3.SS5.p3.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.2.m2.1c">\times</annotation></semantics></math> 2 (questions) <math id="S3.SS5.p3.3.m3.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.SS5.p3.3.m3.1a"><mo id="S3.SS5.p3.3.m3.1.1" xref="S3.SS5.p3.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.3.m3.1b"><times id="S3.SS5.p3.3.m3.1.1.cmml" xref="S3.SS5.p3.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.3.m3.1c">\times</annotation></semantics></math> 4 (graph systems) <math id="S3.SS5.p3.4.m4.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.SS5.p3.4.m4.1a"><mo id="S3.SS5.p3.4.m4.1.1" xref="S3.SS5.p3.4.m4.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.4.m4.1b"><times id="S3.SS5.p3.4.m4.1.1.cmml" xref="S3.SS5.p3.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.4.m4.1c">\times</annotation></semantics></math> 3 (DL).</p>
</div>
<div id="S3.SS5.p4" class="ltx_para">
<p id="S3.SS5.p4.1" class="ltx_p">AJThese graph systems were modeled after abstract causal relationships with each node being labeled by alphabets (Figure <a href="#S3.F2" title="Figure 2 ‣ 3.4 Experimental Design ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).
We avoided modelling real-world phenomena to avoid knowledge bias affecting performance.
As described in Section <a href="#S3.SS3" title="3.3 Experimental Factors ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>, we assume that all 4 repetitions of a DL are equally simple or hard.
Each survey page consisted of a chart (VR + TN + NS) corresponding to the experimental group.</p>
</div>
</section>
<section id="S3.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.6 </span>Collected Metrics</h3>

<div id="S3.SS6.p1" class="ltx_para">
<p id="S3.SS6.p1.1" class="ltx_p">The tasks for all trials were controlled so that all participants saw the same graph systems, and were asked the same set of questions to allow comparison of participant performance between experimental groups.</p>
</div>
<section id="S3.SS6.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Performance Measures.</h4>

<div id="S3.SS6.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS6.SSS0.Px1.p1.1" class="ltx_p"><math id="S3.SS6.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="Correctness" display="inline"><semantics id="S3.SS6.SSS0.Px1.p1.1.m1.1a"><mrow id="S3.SS6.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1a" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.4" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1b" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.5" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1c" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.6" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1d" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.7" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.7.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1e" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.8" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.8.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1f" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.9" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.9.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1g" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.10" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.10.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1h" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.11" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.11.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1i" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.12" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.12.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS6.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1"><times id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.1"></times><ci id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.2">𝐶</ci><ci id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.3">𝑜</ci><ci id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.4.cmml" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.4">𝑟</ci><ci id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.5.cmml" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.5">𝑟</ci><ci id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.6.cmml" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.6">𝑒</ci><ci id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.7.cmml" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.7">𝑐</ci><ci id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.8.cmml" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.8">𝑡</ci><ci id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.9.cmml" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.9">𝑛</ci><ci id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.10.cmml" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.10">𝑒</ci><ci id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.11.cmml" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.11">𝑠</ci><ci id="S3.SS6.SSS0.Px1.p1.1.m1.1.1.12.cmml" xref="S3.SS6.SSS0.Px1.p1.1.m1.1.1.12">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS6.SSS0.Px1.p1.1.m1.1c">Correctness</annotation></semantics></math> (<span id="S3.SS6.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_smallcaps">true</span> or <span id="S3.SS6.SSS0.Px1.p1.1.2" class="ltx_text ltx_font_smallcaps">false</span>) is our primary performance measure to interpret the effectiveness of narratives in augmenting visual exploration.
We also recorded time spent on each trial (from when the two tasks were displayed until the participant submitted both the answers) to understand if and how <span id="S3.SS6.SSS0.Px1.p1.1.3" class="ltx_text ltx_font_italic">Completion Time</span> influences correctness.
However, due to a limitation in Qualtrics and the need to maintain low session time, we recorded both tasks together.</p>
</div>
</section>
<section id="S3.SS6.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Subjective Responses.</h4>

<div id="S3.SS6.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS6.SSS0.Px2.p1.1" class="ltx_p">AJWe also asked our participants to rate the ease-of-understanding of both graphs, and narratives (when applicable) after each DL.
This was measured on a 5-point Likert scale (1: extremely easy, 5: extremely difficult).
In the conditions where TN was ON, we also asked participants to rate the usefulness of the narratives on a 5-point scale (1: extremely useful, 5: not at all useful).
Participants also provided open-ended feedback about graphs and narratives.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Task type (QT)</span></td>
<td id="S3.T2.1.1.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T2.1.1.1.2.1" class="ltx_text ltx_font_bold">Task sub-type</span></td>
<td id="S3.T2.1.1.1.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T2.1.1.1.3.1" class="ltx_text ltx_font_bold">Question Structure</span></td>
</tr>
<tr id="S3.T2.1.2.2" class="ltx_tr">
<td id="S3.T2.1.2.2.1" class="ltx_td ltx_border_t"></td>
<td id="S3.T2.1.2.2.2" class="ltx_td ltx_align_left ltx_border_t">Major Cause (I1)</td>
<td id="S3.T2.1.2.2.3" class="ltx_td ltx_align_left ltx_border_t">Considering all the nodes, which node(s) caused the most influence on the system?</td>
</tr>
<tr id="S3.T2.1.3.3" class="ltx_tr">
<td id="S3.T2.1.3.3.1" class="ltx_td ltx_align_left"><span id="S3.T2.1.3.3.1.1" class="ltx_text">Influence (I)</span></td>
<td id="S3.T2.1.3.3.2" class="ltx_td ltx_align_left">Most Affected (I2)</td>
<td id="S3.T2.1.3.3.3" class="ltx_td ltx_align_left">Considering all the nodes, which node(s) were affected the most by changes in the system?</td>
</tr>
<tr id="S3.T2.1.4.4" class="ltx_tr">
<td id="S3.T2.1.4.4.1" class="ltx_td ltx_border_t"></td>
<td id="S3.T2.1.4.4.2" class="ltx_td ltx_align_left ltx_border_t">Cause-Effect (C1)</td>
<td id="S3.T2.1.4.4.3" class="ltx_td ltx_align_left ltx_border_t">Which statement best describes the cause-effect relationship between &lt;I&gt; and &lt;O&gt;?</td>
</tr>
<tr id="S3.T2.1.5.5" class="ltx_tr">
<td id="S3.T2.1.5.5.1" class="ltx_td ltx_align_left"><span id="S3.T2.1.5.5.1.1" class="ltx_text">Causality (C)</span></td>
<td id="S3.T2.1.5.5.2" class="ltx_td ltx_align_left">Major Factors (C2)</td>
<td id="S3.T2.1.5.5.3" class="ltx_td ltx_align_left">Choose all the nodes, including the objective that were affected by a change in &lt;I&gt;.</td>
</tr>
<tr id="S3.T2.1.6.6" class="ltx_tr">
<td id="S3.T2.1.6.6.1" class="ltx_td ltx_border_t"></td>
<td id="S3.T2.1.6.6.2" class="ltx_td ltx_align_left ltx_border_t">Max Increase (L1)</td>
<td id="S3.T2.1.6.6.3" class="ltx_td ltx_align_left ltx_border_t">Excluding interventions/objectives, which node(s) goes through the greatest increase?</td>
</tr>
<tr id="S3.T2.1.7.7" class="ltx_tr">
<td id="S3.T2.1.7.7.1" class="ltx_td"></td>
<td id="S3.T2.1.7.7.2" class="ltx_td ltx_align_left">Max Decrease (L2)</td>
<td id="S3.T2.1.7.7.3" class="ltx_td ltx_align_left">Excluding interventions/objectives, which node(s) goes through the greatest decrease?</td>
</tr>
<tr id="S3.T2.1.8.8" class="ltx_tr">
<td id="S3.T2.1.8.8.1" class="ltx_td"></td>
<td id="S3.T2.1.8.8.2" class="ltx_td ltx_align_left">Time-Change (L3)</td>
<td id="S3.T2.1.8.8.3" class="ltx_td ltx_align_left">In the above system, at which time does node &lt;X&gt; increase/decrease the most from its initial level?</td>
</tr>
<tr id="S3.T2.1.9.9" class="ltx_tr">
<td id="S3.T2.1.9.9.1" class="ltx_td"></td>
<td id="S3.T2.1.9.9.2" class="ltx_td ltx_align_left">Trend (L4)</td>
<td id="S3.T2.1.9.9.3" class="ltx_td ltx_align_left">Which statement best describes the trend that node &lt;X&gt; goes through?</td>
</tr>
<tr id="S3.T2.1.10.10" class="ltx_tr">
<td id="S3.T2.1.10.10.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S3.T2.1.10.10.1.1" class="ltx_text">Lifecycle (L)</span></td>
<td id="S3.T2.1.10.10.2" class="ltx_td ltx_align_left ltx_border_bb">Spike (L5)</td>
<td id="S3.T2.1.10.10.3" class="ltx_td ltx_align_left ltx_border_bb">In the above system, which node goes through a sharp increase or decrease?</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>List of task types and corresponding question structures for our user study.
Each trial corresponded to a given task sub-type.</figcaption>
</figure>
</section>
</section>
<section id="S3.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.7 </span>Procedure</h3>

<div id="S3.SS7.p1" class="ltx_para">
<p id="S3.SS7.p1.1" class="ltx_p">All recruitment was conducted via MTurk.
Participants that fit the eligibility criteria opened the Qualtrics survey in a separate browser window.
At the end of their participation, they copied a unique completion code back into the MTurk interface, and were later paid as their work was checked.
Each session started with a consent form with waived signed consent.
Failing to give consent terminated the experiment.
Participants were instructed that they could abandon their session at any time.
Unfortunately, due to constraints in Qualtrics, we were not able to pay participants who only completed a partial session.</p>
</div>
<div id="S3.SS7.p2" class="ltx_para">
<p id="S3.SS7.p2.1" class="ltx_p">After consenting, we showed participants a tutorial to explain the visualization and narrative that they would see.
We also explained causal relationships, and how to interpret them.
The tutorial included 3 examples of simple causal relationships.
There was also a separate page explaining the visual mappings that were used in our visualizations.
This legend information was also accessible across every survey page, along with the visualization and a sample narrative from the tutorial.</p>
</div>
<div id="S3.SS7.p3" class="ltx_para">
<p id="S3.SS7.p3.1" class="ltx_p">Then participants were shown a single illustrated page of instructions explaining the task.
Additionally, we also introduced 3 “attention trials,” which involved 3 easy cause-effect (C) tasks.
Each DL had one attention trial.
The purpose of these attention trials was to eliminate responses from crowdworkers who did not pay attention to the task and only “clicked through” the experiment.
Participants that spent less than 7 minutes (roughly 1/3rd the average study duration) were also discarded; these participants were also not paid.
We informed participants in the consent form that they would be paid only after response validation.</p>
</div>
<div id="S3.SS7.p4" class="ltx_para">
<p id="S3.SS7.p4.1" class="ltx_p">Typical sessions lasted between 7 to 50 minutes in duration.
A few participants took significantly longer to complete their sessions, but our logs indicate that these participants took significant breaks between trials (presumably due to interruptions halfway through).
Some participants also contacted us with reasons for the delay, such as trials genuinely being hard, or network issues.
We believe that the effective time spent on the experiment was no more than 23 minutes.
Participants were also asked some demographic questions about their age, education level, and knowledge of statistical concepts and graph visualizations.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2009.02649/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="154" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Correctness comparison between 6 experimental groups (error bars represent 95% confidence intervals derived through bootstrapping).</figcaption>
</figure>
</section>
<section id="S3.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.8 </span>Results</h3>

<div id="S3.SS8.p1" class="ltx_para">
<p id="S3.SS8.p1.1" class="ltx_p">We ran our crowdsourced graphical perception study on MTurk and collected a total of 4,824 responses from 201 unique respondents.
This was higher than the 150 we had initially planned.
During the recruitment process, we invalidated and rejected respondents (n=44) that just “clicked through” and completed the survey in less than 7 minutes.
Thus, 157 participants were compensated for their time.
During our analysis, we excluded data from participants (n=20) who spent less than 10 minutes on the survey.
We expected a reasonable attempt to take 20 minutes based on our pilot, and believe that our complex perception tasks along with the tutorial required at least half of the estimated time.
We also eliminated one participant that submitted a survey response after 3.8 hours.
We present below results from the analysis of n=134 participants that completed 3,216 tasks (trials).
The trials were distributed across experimental groups as follows: H1-480 (n=20) — H2-528 (n=22) — H3-528 (n=22) — N1-600 (n=25) — N2-552 (n=23) — N3-528 (n=22).
 AJWe analyzed all our data using estimation methods to derive 95% confidence intervals (CIs).
We employed non-parametric bootstrapping <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> with R = 1,000 iterations.
This was done to follow current best practices for fair statistics in the field of HCI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</p>
</div>
<section id="S3.SS8.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Task Correctness.</h4>

<div id="S3.SS8.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS8.SSS0.Px1.p1.1" class="ltx_p">Overall, we observed an accuracy of 51.6% (1,661/3,216) (Figure <a href="#S3.F3" title="Figure 3 ‣ 3.7 Procedure ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).
First, we observed that the participants assigned to experimental groups that included a textual narrative — H2, H3, N2, N3 — outperformed those assigned to groups without a narrative — H1, N1.
Secondly, we noted that participants that interacted with Causal Graphs (N1, N2, N3) performed better than those that used Hasse Diagrams (H1, H2, H3).
We believe this to be a byproduct of participants being more familiar with node-link diagrams.
We can infer that narratives providing Instantaneous NS (H3, N3) fare better across both VR, with the causal graphs (N3) outperforming all other groups.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2009.02649/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="131" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Comparing effectiveness of the narrative in answering different question types (error bars represent 95% confidence intervals).</figcaption>
</figure>
<div id="S3.SS8.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS8.SSS0.Px1.p2.1" class="ltx_p">Figure <a href="#S3.F4" title="Figure 4 ‣ Task Correctness. ‣ 3.8 Results ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> highlights the specific type of questions that the narratives were most effective in answering.
Although the correctness increases for each condition that includes narratives, participants found the presence of narratives most helpful in answering the Influence (<span id="S3.SS8.SSS0.Px1.p2.1.1" class="ltx_text ltx_font_bold">I</span>) and Life-cycle Analysis (<span id="S3.SS8.SSS0.Px1.p2.1.2" class="ltx_text ltx_font_bold">L</span>) questions, for both type of visualizations.
This became a useful insight while deciding on the modules in Section <a href="#S4" title="4 Application: The CauseWorks System ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2009.02649/assets/x5.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="131" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Comparing the correctness between graph difficulty levels (error bars represent 95% confidence intervals).</figcaption>
</figure>
<div id="S3.SS8.SSS0.Px1.p3" class="ltx_para">
<p id="S3.SS8.SSS0.Px1.p3.1" class="ltx_p">Figure <a href="#S3.F5" title="Figure 5 ‣ Task Correctness. ‣ 3.8 Results ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> further highlights the improvement in the correctness of participant’s scores, across each difficulty level (S, M, H), when the visualizations are coupled with textual narratives.  The comparatively lower task correctness improvements for the Hard (H) task type, in comparison to the Simple (S) and Medium (M) graph sets, can be attributed to the inherent added complexity, in terms of the added edges and number of nodes, within those datasets.</p>
</div>
<figure id="S3.F6" class="ltx_figure"><img src="/html/2009.02649/assets/x6.png" id="S3.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="150" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Completion time for the test trials across different conditions (error bars represent 95% confidence intervals).</figcaption>
</figure>
</section>
<section id="S3.SS8.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Completion Time.</h4>

<div id="S3.SS8.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS8.SSS0.Px2.p1.1" class="ltx_p">Completion time was measured per graph system.
There were 4 repetitions of graph systems for every DL — S, M, H.
In other words, completion time reflects time spent by a participant for two tasks.
We eliminated outlier trials three standard deviations away from the mean for our analysis (Figure <a href="#S3.F6" title="Figure 6 ‣ Task Correctness. ‣ 3.8 Results ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>).
We note that participants took much longer in groups where a narrative was present (AJH2, H3, N2, N3); with participants taking more time for Causal Graphs.
Participants who were provided with narratives (H2, H3, N2, N3) took on an average 23.6 seconds more to answer 2 analysis tasks per graph as compared to participants without the narrative.</p>
</div>
</section>
<section id="S3.SS8.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Subjective Responses.</h4>

<div id="S3.SS8.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS8.SSS0.Px3.p1.1" class="ltx_p">On an average, our participants ranked ease-of-understanding of the DL in the following order: Simple (mean=3.21), Medium (mean=3.68), Hard (mean=3.95).
Graphs were rated as more easily understandable in the conditions where textual narratives were present versus when narratives were absent:
Simple (mean=3.55 [OFF] vs. mean=3.0 [ON]); Medium (mean=3.82 [OFF] vs. mean=3.60 [ON]); Hard (mean=3.55 [OFF] vs. mean=3.0[ON]).
The same trend was observed in the ease-of-understanding of narratives for each DL: Simple (mean=2.98), Medium (mean=3.38), Hard (mean=3.80).
Additionally, the usefulness of the narratives decreased with increasing graph difficulty:
Simple (mean=2.22), Medium (mean=3.38), Hard (mean=3.05).</p>
</div>
<div id="S3.SS8.SSS0.Px3.p2" class="ltx_para">
<p id="S3.SS8.SSS0.Px3.p2.1" class="ltx_p">Reviewing open-ended feedback showed us that difficulty understanding was attributed to unfamiliarity with a visualization: “<span id="S3.SS8.SSS0.Px3.p2.1.1" class="ltx_text ltx_font_italic">It was somewhat challenging because I’m not familiar with this type of graph.</span>
Additionally, the abstract nature of our graph systems, and also novelty effects influenced difficulty.
P111 says, “<span id="S3.SS8.SSS0.Px3.p2.1.2" class="ltx_text ltx_font_italic">Their abstract nature was the most difficult to understand.
Observing this with a real life example would make it easier to visualize and conceptualize.</span>”
Finally, our participants indicated that they used both visualization and narratives for causal inference:  AJ“<span id="S3.SS8.SSS0.Px3.p2.1.3" class="ltx_text ltx_font_italic">I think having both the summary and the color coded chart makes it much easier to understand […].</span>”</p>
</div>
</section>
</section>
<section id="S3.SS9" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.9 </span>Discussion</h3>

<div id="S3.SS9.p1" class="ltx_para">
<p id="S3.SS9.p1.1" class="ltx_p">The main takeaway from our crowdsourced study is that narratives complement visualizations by providing descriptions to explain changes in the causal system.  AJBased on our analysis of difficulty level and subjective responses, we believe that narratives will be more useful as the complexity of the system increases.
Our participants also indicated that interactivity would have eased task difficulty—a known limitation in our study.
We also strongly believe that interactivity can be leveraged to facilitate details on-demand in the narratives, especially when system complexity is bound to increase verbosity. AJThe fact that Causal Graphs had a higher accuracy score than Hasse Diagrams further corroborated the prioritization of DAGs during the DOI step, and drove us to use them as the visualization medium in the <span id="S3.SS9.p1.1.1" class="ltx_text ltx_font_smallcaps">CauseWorks</span> system.
The study also encourages us to allocate a separate paragraph to talk about the trends followed by important nodes, owing to the high accuracy gains observed in the Lifecycle (<span id="S3.SS9.p1.1.2" class="ltx_text ltx_font_bold">L</span>) task.</p>
</div>
<div id="S3.SS9.p2" class="ltx_para">
<p id="S3.SS9.p2.1" class="ltx_p">We also observed that the experimental groups that had higher accuracy also demonstrated higher completion times.
We believe that the additional time stems from having to read the narratives before making an inference.  AJThis supports the aggregation DOI prioritization feature, wherein to reduce the verbosity of the textual snippets, nodes experiencing similar trends should be combined.
This corroborates with our prediction that narratives aid in causal inference by providing descriptive texts that explain the changes occurring in the network.</p>
</div>
<figure id="S3.F7" class="ltx_figure"><img src="/html/2009.02649/assets/x7.png" id="S3.F7.g1" class="ltx_graphics ltx_img_landscape" width="461" height="166" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Narrative explaining a detailed causal network.  AJThe ‘processes’ or ‘events’ are depicted within single-quotes in this figure.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Application: The CauseWorks System</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">AJ<span id="S4.p1.1.1" class="ltx_text ltx_font_smallcaps">CauseWorks</span>, a system for intelligence analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>, <a href="#bib.bib67" title="" class="ltx_ref">67</a>, <a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>, integrates a range of network analysis, natural language generation (NLG), and data analytics techniques to develop coherent, concise, and explainable causal visualizations augmented by narratives for use by analysts.
Drawing on our design space, our visualizations and narratives provide two main mechanisms (Figure <a href="#S3.F7" title="Figure 7 ‣ 3.9 Discussion ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>): (1) a summary of changes and their impact on the objectives; and (2) additional projected trends.</p>
</div>
<figure id="S4.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2009.02649/assets/figures/05-application/tool1.png" id="S4.F8.sf1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="295" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Screenshot of the <span id="S4.F8.sf1.2.1" class="ltx_text ltx_font_smallcaps">CauseWorks</span> system.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2009.02649/assets/x8.png" id="S4.F8.sf2.g1" class="ltx_graphics ltx_img_landscape" width="298" height="87" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>The use of color gradients to signify the polarity and impact of the effects with a darker shade corresponding to a higher impact.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F8.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2009.02649/assets/x9.png" id="S4.F8.sf3.g1" class="ltx_graphics ltx_img_landscape" width="298" height="87" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>The use of edge thickness to signify the effect propagation capability of the edges, with a thicker line corresponding to a larger effect propagation.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Overview of interface and features of the <span id="S4.F8.2.1" class="ltx_text ltx_font_smallcaps">CauseWorks</span> system.</figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>System Overview</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Figure <a href="#S4.F8.sf1" title="In Figure 8 ‣ 4 Application: The CauseWorks System ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8a</span></a> shows a screenshot of the <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_smallcaps">CauseWorks</span> system.  AJVarious visual aspects of the design space (Section  <a href="#S2.SS5" title="2.5 Step 3: Rendering Textual Narratives ‣ 2 Design Space: Textual Narratives for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.5</span></a> and <a href="#S2.SS6" title="2.6 Step 4: Interacting with Narratives ‣ 2 Design Space: Textual Narratives for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.6</span></a>), such as ‘Node Coloring’, ‘Hyperlinking’ and ‘Brushing’, form an integral part of the narrative rendering process and its subsequent interactivity.
Moreover, the performance metrics helped determine the usefulness of the various types of information snippets (Section <a href="#S2.SS3" title="2.3 Step 1: Extracting Causality Information ‣ 2 Design Space: Textual Narratives for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>), whereas the subjective responses played an important role in deciding the order in which the various information snippets are bundled together (Section <a href="#S2.SS4" title="2.4 Step 2: Calculating Order ‣ 2 Design Space: Textual Narratives for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.4</span></a>).
The left pane displays the <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_italic">whiteboard</span>, a drawing space for causal graphs that allows the user to create and edit the network by adding, deleting, and modifying nodes as well as the edges amongst nodes, thus defining the semantics of the network.
The <span id="S4.SS1.p1.1.3" class="ltx_text ltx_font_italic">whiteboard</span> itself is unbounded, which allows the pane to incorporate a large number of nodes, and can be navigated using the <span id="S4.SS1.p1.1.4" class="ltx_text ltx_font_italic">scrolling wheel</span> and the <span id="S4.SS1.p1.1.5" class="ltx_text ltx_font_italic">magnifying scope</span> tools on the top left.
Furthermore, the system also displays the chosen <span id="S4.SS1.p1.1.6" class="ltx_text ltx_font_italic">objective</span> nodes, <span id="S4.SS1.p1.1.7" class="ltx_text ltx_font_italic">intervention</span> nodes as well as the generated <span id="S4.SS1.p1.1.8" class="ltx_text ltx_font_italic">narrative</span>, the placeholders for which can be seen in the right pane. AJThe interactive GUI allows the user to select multiple intervention nodes and multiple objective nodes, and displays an explanatory narrative in real-time.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Extracting Causality</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The impact summary elucidates how interventions introduced over one or more nodes propagate through the network and change target nodes (<span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">Effect</span>) and the major nodes that help propagate that change (<span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_italic">Major Effect</span>).
Note that the interventions could be made over one or multiple source nodes, and, further, they could be point interventions introduced at a specific timestamp or a sustained intervention introduced over a time period.
The precise differences in how such interventions create observable changes in the target nodes is dependent on the causal model semantics (e.g., whether it is an ODE-based model or a discrete time-stamped Bayesian model), which is beyond the scope of this paper.
Irrespective of the causal semantics, the impact summary encapsulates the cumulative effect of the interventions and identifies nodes in the causal path that depict the highest and least changes.</p>
</div>
<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Impact Summary.</h4>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.1" class="ltx_p">Generating a summary of causal impacts is non-trivial due to the multitude of paths between source and target nodes.
An effective narrative must reduce the number of words utilized to describe the associated effects.
Below we detail how changes made on a set of interventions propagate through the network and affect the target nodes (<span id="S4.SS2.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_italic">Effect</span>), the major nodes that help propagate that change (<span id="S4.SS2.SSS0.Px1.p1.1.2" class="ltx_text ltx_font_italic">Major Effect</span>), the intervening nodes that have no observable variation on the target nodes (<span id="S4.SS2.SSS0.Px1.p1.1.3" class="ltx_text ltx_font_italic">No Effect</span>) and, finally, the nodes that experience the most impact (<span id="S4.SS2.SSS0.Px1.p1.1.4" class="ltx_text ltx_font_italic">Max Effect</span>).</p>
</div>
<div id="S4.SS2.SSS0.Px1.p2" class="ltx_para">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_bold" style="background-color:#C9DAF8;">Effect Module:</span>
The ‘Effect Module’ usually contributes the first sentence of the narrative and provides information on the propagation effect of each intervention on the specified target nodes.
The set of source nodes and target nodes are grouped together based on common nodes in their causal path via a dictionary of <math id="S4.I1.i1.p1.1.m1.2" class="ltx_Math" alttext="\langle key,value\rangle" display="inline"><semantics id="S4.I1.i1.p1.1.m1.2a"><mrow id="S4.I1.i1.p1.1.m1.2.2.2" xref="S4.I1.i1.p1.1.m1.2.2.3.cmml"><mo stretchy="false" id="S4.I1.i1.p1.1.m1.2.2.2.3" xref="S4.I1.i1.p1.1.m1.2.2.3.cmml">⟨</mo><mrow id="S4.I1.i1.p1.1.m1.1.1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.1.1.cmml"><mi id="S4.I1.i1.p1.1.m1.1.1.1.1.2" xref="S4.I1.i1.p1.1.m1.1.1.1.1.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.1.1.1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.1.1.1.1.3" xref="S4.I1.i1.p1.1.m1.1.1.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.1.1.1.1.1a" xref="S4.I1.i1.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.1.1.1.1.4" xref="S4.I1.i1.p1.1.m1.1.1.1.1.4.cmml">y</mi></mrow><mo id="S4.I1.i1.p1.1.m1.2.2.2.4" xref="S4.I1.i1.p1.1.m1.2.2.3.cmml">,</mo><mrow id="S4.I1.i1.p1.1.m1.2.2.2.2" xref="S4.I1.i1.p1.1.m1.2.2.2.2.cmml"><mi id="S4.I1.i1.p1.1.m1.2.2.2.2.2" xref="S4.I1.i1.p1.1.m1.2.2.2.2.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.2.2.2.2.1" xref="S4.I1.i1.p1.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.2.2.2.2.3" xref="S4.I1.i1.p1.1.m1.2.2.2.2.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.2.2.2.2.1a" xref="S4.I1.i1.p1.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.2.2.2.2.4" xref="S4.I1.i1.p1.1.m1.2.2.2.2.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.2.2.2.2.1b" xref="S4.I1.i1.p1.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.2.2.2.2.5" xref="S4.I1.i1.p1.1.m1.2.2.2.2.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.2.2.2.2.1c" xref="S4.I1.i1.p1.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.2.2.2.2.6" xref="S4.I1.i1.p1.1.m1.2.2.2.2.6.cmml">e</mi></mrow><mo stretchy="false" id="S4.I1.i1.p1.1.m1.2.2.2.5" xref="S4.I1.i1.p1.1.m1.2.2.3.cmml">⟩</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.1.m1.2b"><list id="S4.I1.i1.p1.1.m1.2.2.3.cmml" xref="S4.I1.i1.p1.1.m1.2.2.2"><apply id="S4.I1.i1.p1.1.m1.1.1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1.1.1"><times id="S4.I1.i1.p1.1.m1.1.1.1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1.1.1.1"></times><ci id="S4.I1.i1.p1.1.m1.1.1.1.1.2.cmml" xref="S4.I1.i1.p1.1.m1.1.1.1.1.2">𝑘</ci><ci id="S4.I1.i1.p1.1.m1.1.1.1.1.3.cmml" xref="S4.I1.i1.p1.1.m1.1.1.1.1.3">𝑒</ci><ci id="S4.I1.i1.p1.1.m1.1.1.1.1.4.cmml" xref="S4.I1.i1.p1.1.m1.1.1.1.1.4">𝑦</ci></apply><apply id="S4.I1.i1.p1.1.m1.2.2.2.2.cmml" xref="S4.I1.i1.p1.1.m1.2.2.2.2"><times id="S4.I1.i1.p1.1.m1.2.2.2.2.1.cmml" xref="S4.I1.i1.p1.1.m1.2.2.2.2.1"></times><ci id="S4.I1.i1.p1.1.m1.2.2.2.2.2.cmml" xref="S4.I1.i1.p1.1.m1.2.2.2.2.2">𝑣</ci><ci id="S4.I1.i1.p1.1.m1.2.2.2.2.3.cmml" xref="S4.I1.i1.p1.1.m1.2.2.2.2.3">𝑎</ci><ci id="S4.I1.i1.p1.1.m1.2.2.2.2.4.cmml" xref="S4.I1.i1.p1.1.m1.2.2.2.2.4">𝑙</ci><ci id="S4.I1.i1.p1.1.m1.2.2.2.2.5.cmml" xref="S4.I1.i1.p1.1.m1.2.2.2.2.5">𝑢</ci><ci id="S4.I1.i1.p1.1.m1.2.2.2.2.6.cmml" xref="S4.I1.i1.p1.1.m1.2.2.2.2.6">𝑒</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.1.m1.2c">\langle key,value\rangle</annotation></semantics></math> pairs.
Then, paths are grouped by merging source nodes that have at least one common node for each target node and then subsequently merging together target nodes.
This often requires multiple passes and merge operations over the dictionary constructed.
Figure <a href="#S3.F7" title="Figure 7 ‣ 3.9 Discussion ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> depicts a sample snippet detailing the effect of decreasing <span id="S4.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">Fossil Fuel Consumption</span> on <span id="S4.I1.i1.p1.1.3" class="ltx_text ltx_font_italic">Quality of Marine Ecosystem</span>.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_bold" style="background-color:#B6D7A8;">Major Effect Module:</span>
Each ‘Effect’ sentence in the above module may or may not be followed by a sentence from the ‘Major Effect’ module. This module tries to capture the important nodes along the causal path between the set of source and target nodes, thus shining light on those causal path nodes that experienced the highest variation in either direction. This enlightens the user regarding the nodes that were the highest contributors to the effect propagation. Sample text snippets are shown in Figure <a href="#S3.F7" title="Figure 7 ‣ 3.9 Discussion ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> to list out the major factors that propagate the effect between the chosen intervention and target nodes.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_bold" style="background-color:#EAD1DC;">No Effect Module:</span>
This module articulates the specific source nodes that aren’t responsible for the change observed in the target node as well as
the target nodes that remain unaffected due to the combined effect of all the interventions imposed on the network. This step can
potentially lead to highly verbose
sentences, thus affecting readability.
To address this problem we introduce
another grouping over the
(input, output) node pairs, create
n-grams of the source nodes, and
articulate the
most frequently occurring tuples amongst all the target nodes.
These groups of tuples are
then plugged into sentences, which are then included in the narrative.
Figure <a href="#S3.F7" title="Figure 7 ‣ 3.9 Discussion ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows sample text snippets showing the non-impact of the interventions on ‘Government Policies against Climate Change’ as well as describes the <math id="S4.I1.i3.p1.1.m1.2" class="ltx_Math" alttext="\langle Intervention,Objective\rangle" display="inline"><semantics id="S4.I1.i3.p1.1.m1.2a"><mrow id="S4.I1.i3.p1.1.m1.2.2.2" xref="S4.I1.i3.p1.1.m1.2.2.3.cmml"><mo stretchy="false" id="S4.I1.i3.p1.1.m1.2.2.2.3" xref="S4.I1.i3.p1.1.m1.2.2.3.cmml">⟨</mo><mrow id="S4.I1.i3.p1.1.m1.1.1.1.1" xref="S4.I1.i3.p1.1.m1.1.1.1.1.cmml"><mi id="S4.I1.i3.p1.1.m1.1.1.1.1.2" xref="S4.I1.i3.p1.1.m1.1.1.1.1.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.1.1.1.1.1" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.1.1.1.1.3" xref="S4.I1.i3.p1.1.m1.1.1.1.1.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.1.1.1.1.1a" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.1.1.1.1.4" xref="S4.I1.i3.p1.1.m1.1.1.1.1.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.1.1.1.1.1b" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.1.1.1.1.5" xref="S4.I1.i3.p1.1.m1.1.1.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.1.1.1.1.1c" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.1.1.1.1.6" xref="S4.I1.i3.p1.1.m1.1.1.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.1.1.1.1.1d" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.1.1.1.1.7" xref="S4.I1.i3.p1.1.m1.1.1.1.1.7.cmml">v</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.1.1.1.1.1e" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.1.1.1.1.8" xref="S4.I1.i3.p1.1.m1.1.1.1.1.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.1.1.1.1.1f" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.1.1.1.1.9" xref="S4.I1.i3.p1.1.m1.1.1.1.1.9.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.1.1.1.1.1g" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.1.1.1.1.10" xref="S4.I1.i3.p1.1.m1.1.1.1.1.10.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.1.1.1.1.1h" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.1.1.1.1.11" xref="S4.I1.i3.p1.1.m1.1.1.1.1.11.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.1.1.1.1.1i" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.1.1.1.1.12" xref="S4.I1.i3.p1.1.m1.1.1.1.1.12.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.1.1.1.1.1j" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.1.1.1.1.13" xref="S4.I1.i3.p1.1.m1.1.1.1.1.13.cmml">n</mi></mrow><mo id="S4.I1.i3.p1.1.m1.2.2.2.4" xref="S4.I1.i3.p1.1.m1.2.2.3.cmml">,</mo><mrow id="S4.I1.i3.p1.1.m1.2.2.2.2" xref="S4.I1.i3.p1.1.m1.2.2.2.2.cmml"><mi id="S4.I1.i3.p1.1.m1.2.2.2.2.2" xref="S4.I1.i3.p1.1.m1.2.2.2.2.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.2.2.2.2.1" xref="S4.I1.i3.p1.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.2.2.2.2.3" xref="S4.I1.i3.p1.1.m1.2.2.2.2.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.2.2.2.2.1a" xref="S4.I1.i3.p1.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.2.2.2.2.4" xref="S4.I1.i3.p1.1.m1.2.2.2.2.4.cmml">j</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.2.2.2.2.1b" xref="S4.I1.i3.p1.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.2.2.2.2.5" xref="S4.I1.i3.p1.1.m1.2.2.2.2.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.2.2.2.2.1c" xref="S4.I1.i3.p1.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.2.2.2.2.6" xref="S4.I1.i3.p1.1.m1.2.2.2.2.6.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.2.2.2.2.1d" xref="S4.I1.i3.p1.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.2.2.2.2.7" xref="S4.I1.i3.p1.1.m1.2.2.2.2.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.2.2.2.2.1e" xref="S4.I1.i3.p1.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.2.2.2.2.8" xref="S4.I1.i3.p1.1.m1.2.2.2.2.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.2.2.2.2.1f" xref="S4.I1.i3.p1.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.2.2.2.2.9" xref="S4.I1.i3.p1.1.m1.2.2.2.2.9.cmml">v</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.2.2.2.2.1g" xref="S4.I1.i3.p1.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.2.2.2.2.10" xref="S4.I1.i3.p1.1.m1.2.2.2.2.10.cmml">e</mi></mrow><mo stretchy="false" id="S4.I1.i3.p1.1.m1.2.2.2.5" xref="S4.I1.i3.p1.1.m1.2.2.3.cmml">⟩</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.1.m1.2b"><list id="S4.I1.i3.p1.1.m1.2.2.3.cmml" xref="S4.I1.i3.p1.1.m1.2.2.2"><apply id="S4.I1.i3.p1.1.m1.1.1.1.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1"><times id="S4.I1.i3.p1.1.m1.1.1.1.1.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1"></times><ci id="S4.I1.i3.p1.1.m1.1.1.1.1.2.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1.2">𝐼</ci><ci id="S4.I1.i3.p1.1.m1.1.1.1.1.3.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1.3">𝑛</ci><ci id="S4.I1.i3.p1.1.m1.1.1.1.1.4.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1.4">𝑡</ci><ci id="S4.I1.i3.p1.1.m1.1.1.1.1.5.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1.5">𝑒</ci><ci id="S4.I1.i3.p1.1.m1.1.1.1.1.6.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1.6">𝑟</ci><ci id="S4.I1.i3.p1.1.m1.1.1.1.1.7.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1.7">𝑣</ci><ci id="S4.I1.i3.p1.1.m1.1.1.1.1.8.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1.8">𝑒</ci><ci id="S4.I1.i3.p1.1.m1.1.1.1.1.9.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1.9">𝑛</ci><ci id="S4.I1.i3.p1.1.m1.1.1.1.1.10.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1.10">𝑡</ci><ci id="S4.I1.i3.p1.1.m1.1.1.1.1.11.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1.11">𝑖</ci><ci id="S4.I1.i3.p1.1.m1.1.1.1.1.12.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1.12">𝑜</ci><ci id="S4.I1.i3.p1.1.m1.1.1.1.1.13.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1.13">𝑛</ci></apply><apply id="S4.I1.i3.p1.1.m1.2.2.2.2.cmml" xref="S4.I1.i3.p1.1.m1.2.2.2.2"><times id="S4.I1.i3.p1.1.m1.2.2.2.2.1.cmml" xref="S4.I1.i3.p1.1.m1.2.2.2.2.1"></times><ci id="S4.I1.i3.p1.1.m1.2.2.2.2.2.cmml" xref="S4.I1.i3.p1.1.m1.2.2.2.2.2">𝑂</ci><ci id="S4.I1.i3.p1.1.m1.2.2.2.2.3.cmml" xref="S4.I1.i3.p1.1.m1.2.2.2.2.3">𝑏</ci><ci id="S4.I1.i3.p1.1.m1.2.2.2.2.4.cmml" xref="S4.I1.i3.p1.1.m1.2.2.2.2.4">𝑗</ci><ci id="S4.I1.i3.p1.1.m1.2.2.2.2.5.cmml" xref="S4.I1.i3.p1.1.m1.2.2.2.2.5">𝑒</ci><ci id="S4.I1.i3.p1.1.m1.2.2.2.2.6.cmml" xref="S4.I1.i3.p1.1.m1.2.2.2.2.6">𝑐</ci><ci id="S4.I1.i3.p1.1.m1.2.2.2.2.7.cmml" xref="S4.I1.i3.p1.1.m1.2.2.2.2.7">𝑡</ci><ci id="S4.I1.i3.p1.1.m1.2.2.2.2.8.cmml" xref="S4.I1.i3.p1.1.m1.2.2.2.2.8">𝑖</ci><ci id="S4.I1.i3.p1.1.m1.2.2.2.2.9.cmml" xref="S4.I1.i3.p1.1.m1.2.2.2.2.9">𝑣</ci><ci id="S4.I1.i3.p1.1.m1.2.2.2.2.10.cmml" xref="S4.I1.i3.p1.1.m1.2.2.2.2.10">𝑒</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i3.p1.1.m1.2c">\langle Intervention,Objective\rangle</annotation></semantics></math> pairs that are not connected.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p"><span id="S4.I1.i4.p1.1.2" class="ltx_text ltx_font_bold" style="background-color:#FFE599;">Maximum Effect Module:</span>
The narrative generated until now focuses only on a subset of the whole network. This subset covers the edges and the nodes that lie in the causal paths between the set of <span id="S4.I1.i4.p1.1.3" class="ltx_text ltx_font_italic">Intervention</span> and <span id="S4.I1.i4.p1.1.4" class="ltx_text ltx_font_italic">Objective</span> nodes. However, there may still be nodes that might have been affected by the interventions but may have not been considered before. These nodes may provide interesting insights to the user and thus are worth adding to the final narrative. Hence, this module traverses through all the nodes in the system, instead of only the causal path nodes, and finds the nodes experiencing the maximum variation along both the positive and negative axis. Finally, it wraps both the nodes in a well structured sentence and attaches it to the end of the <span id="S4.I1.i4.p1.1.5" class="ltx_text ltx_font_italic">Impact Summary</span> narrative. Figure <a href="#S3.F7" title="Figure 7 ‣ 3.9 Discussion ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> points out the most positively impacted node, <span id="S4.I1.i4.p1.1.6" class="ltx_text ltx_font_italic">(Risk of Diseases)</span>, as well as the most negatively impacted node, <span id="S4.I1.i4.p1.1.1" class="ltx_text ltx_font_italic">(Atmospheric <math id="S4.I1.i4.p1.1.1.m1.1" class="ltx_Math" alttext="CO_{2}" display="inline"><semantics id="S4.I1.i4.p1.1.1.m1.1a"><mrow id="S4.I1.i4.p1.1.1.m1.1.1" xref="S4.I1.i4.p1.1.1.m1.1.1.cmml"><mi id="S4.I1.i4.p1.1.1.m1.1.1.2" xref="S4.I1.i4.p1.1.1.m1.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.I1.i4.p1.1.1.m1.1.1.1" xref="S4.I1.i4.p1.1.1.m1.1.1.1.cmml">​</mo><msub id="S4.I1.i4.p1.1.1.m1.1.1.3" xref="S4.I1.i4.p1.1.1.m1.1.1.3.cmml"><mi id="S4.I1.i4.p1.1.1.m1.1.1.3.2" xref="S4.I1.i4.p1.1.1.m1.1.1.3.2.cmml">O</mi><mn id="S4.I1.i4.p1.1.1.m1.1.1.3.3" xref="S4.I1.i4.p1.1.1.m1.1.1.3.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i4.p1.1.1.m1.1b"><apply id="S4.I1.i4.p1.1.1.m1.1.1.cmml" xref="S4.I1.i4.p1.1.1.m1.1.1"><times id="S4.I1.i4.p1.1.1.m1.1.1.1.cmml" xref="S4.I1.i4.p1.1.1.m1.1.1.1"></times><ci id="S4.I1.i4.p1.1.1.m1.1.1.2.cmml" xref="S4.I1.i4.p1.1.1.m1.1.1.2">𝐶</ci><apply id="S4.I1.i4.p1.1.1.m1.1.1.3.cmml" xref="S4.I1.i4.p1.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.I1.i4.p1.1.1.m1.1.1.3.1.cmml" xref="S4.I1.i4.p1.1.1.m1.1.1.3">subscript</csymbol><ci id="S4.I1.i4.p1.1.1.m1.1.1.3.2.cmml" xref="S4.I1.i4.p1.1.1.m1.1.1.3.2">𝑂</ci><cn type="integer" id="S4.I1.i4.p1.1.1.m1.1.1.3.3.cmml" xref="S4.I1.i4.p1.1.1.m1.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i4.p1.1.1.m1.1c">CO_{2}</annotation></semantics></math>)</span>.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Projected Trends.</h4>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.1" class="ltx_p">While the <span id="S4.SS2.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">Impact Summary</span> articulates the overall influence of the source nodes on the target nodes, it leaves out information such as the temporal patterns observed by the nodes, or spikes in values that may have occurred in the course of the intervention, or other contextual information from external data sources (e.g., Wikipedia). We outline these parts of the narrative below.</p>
</div>
<div id="S4.SS2.SSS0.Px2.p2" class="ltx_para">
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p"><span id="S4.I2.i1.p1.1.1" class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Time Series Module:</span>
The Time Series module parses over the temporal information for entities in the causal path between the source and target nodes and captures key change trajectories observed over those nodes. Following a k-means clustering <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>
over the temporal progressions AJacross a 12 month period (with number
of clusters selected using the
Silhouette coefficient <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>), the clusters
are sorted based on the number of nodes in
each cluster and the high volume clusters
are verbalized in the narrative. To
limit the description length, a Pagerank
score <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> is used as a filtering criterion
to determine the most important nodes.
Figure <a href="#S3.F7" title="Figure 7 ‣ 3.9 Discussion ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> details the time series patterns observed by ‘Land Degradation’, ‘Deforestation’, ‘Methane Emissions’ and ‘Greenhouse Effect’.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p"><span id="S4.I2.i2.p1.1.1" class="ltx_text ltx_font_bold" style="background-color:#F4CCCC;">Spike Detection Module:</span>
Important nodes found in the previous step are further analyzed to check for presence of spikes or troughs during the timespan in consideration. This provides information to the user of any key abnormalities or milestones that might have occurred in these nodes. Each sentence of the <span id="S4.I2.i2.p1.1.2" class="ltx_text ltx_font_italic">Time Series module</span> may or may not be followed by an output
from the ‘Spike Detection’ module.
For detecting spikes in the timeseries, the concept of a moving window is used to
distinguish between gradual and sudden
rises or falls in the time series value.
Example text snippet showing the spikes in the time series value for ‘Quality of Marine Ecosystem’ is shown in Figure <a href="#S3.F7" title="Figure 7 ‣ 3.9 Discussion ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p id="S4.I2.i3.p1.1" class="ltx_p"><span id="S4.I2.i3.p1.1.1" class="ltx_text ltx_font_bold" style="background-color:#C8E6E1;">Wikification Module:</span>
This constitutes the final module of the generated narrative. However, similar to the scenario with previous module, the <span id="S4.I2.i3.p1.1.2" class="ltx_text ltx_font_italic">Wikification</span> module is also interleaved with the <span id="S4.I2.i3.p1.1.3" class="ltx_text ltx_font_italic">Time Series</span> module to provide a seamless and continuous reading experience to the user.
This module involves parsing through the  AJsummary paragraphs in the corresponding Wikipedia pages for important nodes mentioned in the <span id="S4.I2.i3.p1.1.4" class="ltx_text ltx_font_italic">Timeseries</span> module and attaching key descriptive information to provide context
to the narrative.
If a Wikipedia page does not exist for the node mentioned, this module is skipped in its entirety.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Generating Textual Narratives</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Figure <a href="#S3.F7" title="Figure 7 ‣ 3.9 Discussion ‣ 3 Crowdsourced Study: Narration for Causality ‣ Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows an example narrative<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Please refer to our supplementary material for the reference graph.</span></span></span>.
Most importantly, the narrative highlights important aspects of the cumulative causal impacts caused by the interventions on the specified objectives.
It also explains the effect that the interventions made on ‘Fossil Fuel Consumption(-31%)’, ‘Land Degradation(+21%)‘ and ‘Ozone Layer Depletion(+20%)‘ had on the target nodes, ‘Quality of Marine Ecosystem‘, ‘Food Availability‘ and ‘Government Policies against Climate Change‘.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">Beyond the basic cause and effect relationships, the narrative also accounts for the changes to the entire system by mentioning the nodes experiencing the highest rise and decline across the whole network.
Furthermore, it clusters together nodes experiencing the same value patterns, and details the time-series patterns as well as spikes for the important nodes in those clusters.
It also provides additional insights, by attaching the associated Wikipedia summary, for the available nodes.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Expert Review: <span id="S4.SS4.1.1" class="ltx_text ltx_font_smallcaps">CauseWorks</span> Narratives</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">We conducted an expert review <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> to validate the narrative engine.</p>
</div>
<section id="S4.SS4.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Method.</h4>

<div id="S4.SS4.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px1.p1.1" class="ltx_p">We recruited 5 experts who worked with causal systems in varying capacities (P1 and P5 were developers working on building system frameworks and analytics for causal systems; P2 and P4 were usability experts working on user research and visualization design for causal systems; and P3 was a visualization expert working with causal systems).
We engaged with our experts in an hour-long semi-structured feedback session in a remote video call where they indirectly interacted with the <span id="S4.SS4.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_smallcaps">CauseWorks</span> system.
We encouraged the participants to think aloud, and interrupt at any point
to ask questions, make, and share observations.
These experts all work with planners who model and infer causality with the aid of visualization.
P1, P3, and P5 were familiar with causal visualization and modelling, but were relatively unfamiliar with narrative generation.
We gave a brief tutorial that explained both the visualization and the narrative structure.
We created a scenario to demonstrate the system features.
Two researchers collaborated with experts in the review: one researcher and the expert performed pair-analytics<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> while exploring the scenario, while the second researcher asked questions.
We explained to our experts that the focus of the session was to critique the generated narratives in the system, and not features such as the visualization or other user-interface elements.</p>
</div>
</section>
<section id="S4.SS4.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4>

<div id="S4.SS4.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px2.p1.1" class="ltx_p">Overall, our experts were impressed with how the narrative augments the causal graph in the system, especially to tackle large-scale causal systems “<span id="S4.SS4.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">with multiple factors</span>” (P2), and the narrative “<span id="S4.SS4.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_italic">puts everything in context</span>” (P2) when beginning causal exploration.
 AJReferring to our design space, we summarize these results below:</p>
</div>
<div id="S4.SS4.SSS0.Px2.p2" class="ltx_para">
<ul id="S4.I3" class="ltx_itemize">
<li id="S4.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i1.p1" class="ltx_para">
<p id="S4.I3.i1.p1.1" class="ltx_p"><span id="S4.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">Content Generation:</span></p>
</div>
<div id="S4.I3.i1.p2" class="ltx_para">
<p id="S4.I3.i1.p2.1" class="ltx_p">P3 suggested making the narrative more robust by including a ‘model summary’ of the underlying causal model: “<span id="S4.I3.i1.p2.1.1" class="ltx_text ltx_font_italic">Narrative should try (very) hard to have model scope (temporal and geographic scope)</span>.”
Experts also noted that the narrative compensates for information loss from visual mapping by showing absolute values.
Said P2: “<span id="S4.I3.i1.p2.1.2" class="ltx_text ltx_font_italic">[my] first instinct was to look at the graph because that would tell the specific percentage</span>.”
P1 noted that the reliability of the narrative can be improved by “<span id="S4.I3.i1.p2.1.3" class="ltx_text ltx_font_italic">including the baseline trends</span>.”</p>
</div>
</li>
<li id="S4.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i2.p1" class="ltx_para">
<p id="S4.I3.i2.p1.1" class="ltx_p"><span id="S4.I3.i2.p1.1.1" class="ltx_text ltx_font_bold">Document Structuring and Aggregation:</span> Experts were satisfied with the presentation order of causal information.
P3 commented that the order of presentation can remain the same for a particular type of narrative and may change if more types are introduced.
For example, the impact summary, projected trends, and model summary may have different causal information—aggregated and structured in different order.</p>
</div>
</li>
<li id="S4.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i3.p1" class="ltx_para">
<p id="S4.I3.i3.p1.1" class="ltx_p"><span id="S4.I3.i3.p1.1.1" class="ltx_text ltx_font_bold">Realization and Interaction:</span> All 5 experts acknowledged the idea of a character budget, and that the current rendering of the textual narratives can be improved with the use of rendering effects such as hierarchical lists (all 5) and interactivity such as Brushing (P2, P4), Search (P5), and Sliders (P5).</p>
</div>
</li>
</ul>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">AJOur work indicates that textual narratives help users infer information from causal networks.
More specifically, the user study shows our method faring favorably for time, correctness, and confidence of information absorption.
These narratives also reinforce the ‘narrative intelligence’ viewpoint proposed by Blair and Meyer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
Narratives can be used to generate quick, precise, and informative reports (or subsections of reports) AJ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> owing to their structured representations.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">The <span id="S5.p2.1.1" class="ltx_text ltx_font_smallcaps">CauseWorks</span> system adds another layer of abstraction to narratives.
Furthermore, the use cases presented here support past findings on visualization rhetoric <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> in combining interactivity with organized information presentations to enhance the decision-making process for the end-user.
The findings are also in line with graph comics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, which explored the effectiveness of using textual snippets with graphical images for communicating changes in dynamic networks.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">AJAs we mentioned earlier, we did not experimentally validate all of our design space in the crowdsourced study.
However, we used our 4-step narrative rendering pipeline broadly in both the mockups of the crowdsourced study (e.g., causality information extraction, typographic emphasis, calculating order, and font size) and <span id="S5.p3.1.1" class="ltx_text ltx_font_smallcaps">CauseWorks</span> (causality information extraction, calculating order, textual rendering and color, word-scale graphics, and interactivity through brushing).
Our expert review results also validate our design choices.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">AJWe believe that future evaluations on the effectiveness of our narrative design space can help expand the space for causal systems, and eventually other systems.
To test this hypothesis, we also plan on conducting another user study with the <span id="S5.p4.1.1" class="ltx_text ltx_font_smallcaps">CauseWorks</span> system to evaluate the performance benefits offered by the system in a more interactive setting.
Limitations in our work pertain to the scope of questions about causality that it can answer, e.g., we have not focused on communicating dynamics of the system as a whole.  AJThe current methodology is also designed in-line with the temporal datasets. Future work will be targeted towards a more generic approach that ingests non-temporal datasets as well as incorporating a visual DOI function to focus the user’s attention on important nodes and links.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We have presented a review of the design space for a specialized form of data-driven storytelling: the use of natural language narratives for causal network data.
Based on the review, we isolated several interesting questions about the role of textual narratives for this purpose.
To answer these questions, we conducted a large-scale crowdsourced user study where participants saw causal systems of increasing complexity.
The data was displayed using one of two visualization techniques, causal graphs and Hasse diagrams, with and without the presence of textual narratives.
The main finding is that the coupling of causality visualization techniques with textual narratives significantly increases accuracy and acts as a pivotal complement to information visualization.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>This work was partially supported by the Defense Advanced Research Projects Agency (DARPA) under Contract Number FA8650-17-C-7720.
The views, opinions and/or findings expressed are those of the authors and should not be interpreted as representing the official views or policies of the Department of Defense or the U.S. Government.
The authors wish to thank all DARPA Causal Exploration collaborators for their support and encouragement.


</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
DARPA, Causal Exploration,
<a target="_blank" href="https://www.darpa.mil/program/causal-exploration" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.darpa.mil/program/causal-exploration</a>, 2018.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
R. Arias-Hernández, L. T. Kaastra, T. M. Green, and B. D. Fisher.

</span>
<span class="ltx_bibblock">Pair analytics: Capturing reasoning processes in collaborative visual
analytics.

</span>
<span class="ltx_bibblock">In <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Proceedings of the Hawaii International International
Conference on Systems Science</span>, pp. 1–10. IEEE Computer Society, 2011.
doi: 10 . 1109/HICSS . 2011 . 339

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
B. Bach, N. Kerracher, K. W. Hall, S. Carpendale, J. Kennedy, and
N. Henry Riche.

</span>
<span class="ltx_bibblock">Telling stories about dynamic networks with graph comics.

</span>
<span class="ltx_bibblock">In <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM Conference on Human Factors in
Computing Systems</span>, pp. 3670–3682, 2016. doi: 10 . 1145/2858036 . 2858387

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
J. Bae, T. Helldin, and M. Riveiro.

</span>
<span class="ltx_bibblock">Understanding indirect causal relationships in node-link graphs.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Computer Graphics Forum</span>, 36(3):411–421, 2017. doi: 10 . 1111/cgf . 13198

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
F. Beck, M. Burch, S. Diehl, and D. Weiskopf.

</span>
<span class="ltx_bibblock">The state of the art in visualizing dynamic graphs.

</span>
<span class="ltx_bibblock">In R. Borgo, R. Maciejewski, and I. Viola, eds., <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">State of the
Art Reports for the Eurographics Conference on Visualization</span>. Eurographics
Association, 2014. doi: 10 . 2312/eurovisstar . 20141174

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
F. Beck and D. Weiskopf.

</span>
<span class="ltx_bibblock">Word-sized graphics for scientific texts.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>,
23(6):1576–1587, 2017. doi: 10 . 1109/TVCG . 2017 . 2674958

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
D. Blair and T. Meyer.

</span>
<span class="ltx_bibblock">Tools for an interactive virtual cinema.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Creating Personalities for Synthetic Actors</span>, pp. 83–91.
Springer, 1997. doi: 10 . 1007/BFb0030572

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
M. Bunge.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Causality and Modern Science</span>.

</span>
<span class="ltx_bibblock">Dover Publications, 1979.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
R. Chang, C. Ziemkiewicz, T. M. Green, and W. Ribarsky.

</span>
<span class="ltx_bibblock">Defining insight for visual analytics.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">IEEE Computer Graphics and Applications</span>, 29(2):14–17, 2009.
doi: 10 . 1109/MCG . 2009 . 22

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
A. Chatzimparmpas, R. M. Martins, I. Jusufi, K. Kucher, F. Rossi, and
A. Kerren.

</span>
<span class="ltx_bibblock">The State of the Art in Enhancing Trust in Machine Learning Models
with the Use of Visualizations.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Computer Graphics Forum</span>, 2020. doi: 10 . 1111/cgf . 14034

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
M. F. Dahlstrom.

</span>
<span class="ltx_bibblock">Using narratives and storytelling to communicate science with
nonexpert audiences.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Proceedings of the National Academy of Sciences</span>, 111(Supplement
4):13614–13620, 2014. doi: 10 . 1073/pnas . 1320645111

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
N. Diakopoulos, J. DiMicco, J. Hullman, K. Karahalios, and A. Perer.

</span>
<span class="ltx_bibblock">Telling stories with data: The next chapter—a visweek 2011
workshop, 2011.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J. DiMicco, M. McKeon, and K. Karahalios.

</span>
<span class="ltx_bibblock">Telling stories with data—a VisWeek 2010 workshop, 2010.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
P. Dragicevic.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Fair Statistical Communication in HCI</span>, pp. 291–330.

</span>
<span class="ltx_bibblock">Springer International Publishing, Cham, 2016. doi: 10 . 1007/978-3-319-26633-6_13

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
B. Efron.

</span>
<span class="ltx_bibblock">Bootstrap methods: another look at the jackknife.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Breakthroughs in statistics</span>, pp. 569–593. Springer, 1992.
doi: 10 . 1007/978-1-4612-4380-9_41

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
W. Eisner.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Graphic Storytelling and Visual Narrative</span>.

</span>
<span class="ltx_bibblock">W. W. Norton &amp; Company, New York, NY, USA, 2008.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
N. Elmqvist and P. Tsigas.

</span>
<span class="ltx_bibblock">Causality visualization using animated growing polygons.

</span>
<span class="ltx_bibblock">In <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Symposium on Information
Visualization</span>, pp. 189–196, 2003. doi: 10 . 1109/INFVIS . 2003 . 1249025

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
N. Elmqvist and P. Tsigas.

</span>
<span class="ltx_bibblock">Growing squares: Animated visualization of causal relations.

</span>
<span class="ltx_bibblock">In <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM Symposium on Software Visualization</span>,
pp. 17–26, 2003. doi: 10 . 1145/774833 . 774836

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
N. Elmqvist and P. Tsigas.

</span>
<span class="ltx_bibblock">Animated visualization of causal relations through growing 2d
geometry.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Information Visualization</span>, 3:154–172, 07 2004. doi: 10 . 1057/palgrave . ivs . 9500074

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
F. Elwert.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Graphical Causal Models</span>, pp. 245–273.

</span>
<span class="ltx_bibblock">03 2013. doi: 10 . 1007/978-94-007-6094-3_13

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
M. Feng, C. Deng, E. M. Peck, and L. Harrison.

</span>
<span class="ltx_bibblock">The effects of adding search functionality to interactive
visualizations on the web.

</span>
<span class="ltx_bibblock">In R. L. Mandryk, M. Hancock, M. Perry, and A. L. Cox, eds., <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM Conference on Human Factors in Computing Systems</span>,
pp. 137:1–137:13. ACM, New York, NY, USA, 2018. doi: 10 . 1145/3173574 . 3173711

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
M. Gambhir and V. Gupta.

</span>
<span class="ltx_bibblock">Recent automatic text summarization techniques: a survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">Artificial Intelligence Review</span>, 47:1–66, 2016. doi: 10 . 1007/s10462-016-9475-9

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
D. Geiger, T. Verma, and J. Pearl.

</span>
<span class="ltx_bibblock">d-separation: From theorems to algorithms.

</span>
<span class="ltx_bibblock">In <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Machine Intelligence and Pattern Recognition</span>, vol. 10, pp.
139–148. Elsevier, 1990. doi: 10 . 1016/B978-0-444-88738-2 . 50018-X

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
N. D. Gershon and W. Page.

</span>
<span class="ltx_bibblock">What storytelling can do for information visualization.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">Communications of the ACM</span>, 44(8):31–37, 2001. doi: 10 . 1145/381641 . 381653

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
P. Goffin, J. Boy, W. Willett, and P. Isenberg.

</span>
<span class="ltx_bibblock">An exploratory study of word-scale graphics in data-rich text
documents.

</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>,
23(10):2275–2287, 2017. doi: 10 . 1109/TVCG . 2016 . 2618797

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
J. Gottschall.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">The Storytelling Animal: How Stories Make Us Human</span>.

</span>
<span class="ltx_bibblock">Mariner Books, New York, NY, USA, 2012. doi: 10 . 1075/ssol . 2 . 2 . 07bor

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
D. Heckerman, D. M. Chickering, C. Meek, R. Rounthwaite, and C. M. Kadie.

</span>
<span class="ltx_bibblock">Dependency networks for inference, collaborative filtering, and data
visualization.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">Journal of Machine Learning Resesearch</span>, 1:49–75, 2000. doi:
10 . 1162/153244301753344614

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
J. Heer and M. Bostock.

</span>
<span class="ltx_bibblock">Crowdsourcing graphical perception: Using mechanical turk to assess
visualization design.

</span>
<span class="ltx_bibblock">In <span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM Conference on Human Factors in
Computing Systems</span>, pp. 203–212. ACM, New York, NY, USA, 2010. doi: 10 . 1145/1753326 . 1753357

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
R. J. Heuer Jr.

</span>
<span class="ltx_bibblock">Analysis of competing hypotheses.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">Psychology of Intelligence Analysis</span>, pp. 95–110, 1999.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
F. Hohman, A. Srinivasan, and S. M. Drucker.

</span>
<span class="ltx_bibblock">TeleGam: Combining visualization and verbalization for
interpretable machine learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Conference on Visualization</span>, pp.
151–155, 2019. doi: 10 . 1109/VISUAL . 2019 . 8933695

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
J. Hullman and N. Diakopoulos.

</span>
<span class="ltx_bibblock">Visualization rhetoric: Framing effects in narrative visualization.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>,
17(12):2231–2240, 2011. doi: 10 . 1109/TVCG . 2011 . 255

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
J. Hullman and N. Diakopoulos.

</span>
<span class="ltx_bibblock">Visualization rhetoric: Framing effects in narrative visualization.

</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>,
17(12):2231–2240, 2011. doi: 10 . 1109/TVCG . 2011 . 255

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
J. Hullman, S. Drucker, N. H. Riche, B. Lee, D. Fisher, and E. Adar.

</span>
<span class="ltx_bibblock">A deeper understanding of sequence in narrative visualization.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>,
19(12):2406–2415, 2013. doi: 10 . 1109/TVCG . 2013 . 119

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
N. Kadaba, P. Irani, and J. Leboe.

</span>
<span class="ltx_bibblock">Visualizing causal semantics using animations.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>,
13:1254–61, 11 2007. doi: 10 . 1109/TVCG . 2007 . 70528

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
S. Kent.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Words of Estimative Probability</span>.

</span>
<span class="ltx_bibblock">1964.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
D. Koller and N. Friedman.

</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">Probabilistic Graphical Models: Principles and Techniques -
Adaptive Computation and Machine Learning</span>.

</span>
<span class="ltx_bibblock">The MIT Press, 2009. doi: 10 . 5555/1795555

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
R. Kosara.

</span>
<span class="ltx_bibblock">Story points in Tableau Software.

</span>
<span class="ltx_bibblock">Keynote at Tableau Customer Conference, Sept. 2013.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
S. Latif and F. Beck.

</span>
<span class="ltx_bibblock">Interactive map reports summarizing bivariate geographic data.

</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">Visual Informatics</span>, 3(1):27 – 37, 2019.

</span>
<span class="ltx_bibblock">Proceedings of PacificVAST. doi: 10 . 1016/j . visinf . 2019 . 03 . 004

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
S. Latif and F. Beck.

</span>
<span class="ltx_bibblock">Vis author profiles: Interactive descriptions of publication records
combining text and visualization.

</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>,
25(1):152–161, 2019. doi: 10 . 1109/TVCG . 2018 . 2865022

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
T. M. Leitch.

</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">What Stories Are: Narrative Theory and Interpretation</span>.

</span>
<span class="ltx_bibblock">Pennsylvania State University Press, University Park, PA, 1986.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
J. MacQueen et al.

</span>
<span class="ltx_bibblock">Some methods for classification and analysis of multivariate
observations.

</span>
<span class="ltx_bibblock">In <span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">Proceedings of the Berkeley Symposium on Mathematical
Statistics and Probability</span>, vol. 1, pp. 281–297. Oakland, CA, USA, 1967.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
R. Metoyer, Q. Zhi, B. Janczuk, and W. Scheirer.

</span>
<span class="ltx_bibblock">Coupling story to visualization: Using textual analysis as a bridge
between data and interpretation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM Conference on Intelligent User
Interfaces</span>, pp. 503–507, 2018. doi: 10 . 1145/3172944 . 3173007

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
M. Moezzi, K. B. Janda, and S. Rotmann.

</span>
<span class="ltx_bibblock">Using stories, narratives, and storytelling in energy and climate
change research.

</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">Energy Research &amp; Social Science</span>, 31:1–10, 2017. doi: 10 . 1016/j . erss . 2017 . 06 . 034

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
A. Nenkova and K. McKeown.

</span>
<span class="ltx_bibblock">A survey of text summarization techniques.

</span>
<span class="ltx_bibblock">In <span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">Mining Text Data</span>, 2012. doi: 10 . 1007/978-1-4614-3223-4_3

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
C. North.

</span>
<span class="ltx_bibblock">Toward measuring visualization insight.

</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">IEEE Computer Graphics &amp; Applications</span>, 26(3):6–9, 2006. doi:
10 . 1109/MCG . 2006 . 70

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
L. Page, S. Brin, R. Motwani, and T. Winograd.

</span>
<span class="ltx_bibblock">The PageRank citation ranking: Bringing order to the web.

</span>
<span class="ltx_bibblock">In <span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM Conference on the World Wide Web</span>,
1999. doi: 10 . 1 . 1 . 38 . 5427

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
J. Pearl.

</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">Causality: Models, Reasoning and Inference</span>.

</span>
<span class="ltx_bibblock">Cambridge University Press, USA, 2nd ed., 2009. doi: 10 . 5555/1642718

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
E. Reiter and R. Dale.

</span>
<span class="ltx_bibblock">Building applied natural language generation systems.

</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">Natural Language Engineering</span>, 3:57–87, 1997. doi: 10 . 1017/S1351324997001502

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
E. Reiter and R. Dale.

</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">Building Natural Language Generation Systems</span>.

</span>
<span class="ltx_bibblock">Studies in Natural Language Processing. Cambridge University Press,
2000. doi: 10 . 1017/CBO9780511519857

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
N. H. Riche, C. Hurter, N. Diakopoulos, and S. Carpendale.

</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">Data-Driven Storytelling</span>.

</span>
<span class="ltx_bibblock">A. K. Peters, Ltd., USA, 1st ed., 2018.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
C. Rooney, S. Attfield, B. L. W. Wong, and S. Choudhury.

</span>
<span class="ltx_bibblock">Invisque as a tool for intelligence analysis: The construction of
explanatory narratives.

</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">International Journal of Human–Computer Interaction</span>,
30(9):703–717, 2014. doi: 10 . 1080/10447318 . 2014 . 905422

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
P. J. Rousseeuw.

</span>
<span class="ltx_bibblock">Silhouettes: A graphical aid to the interpretation and validation of
cluster analysis.

</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">Journal of Computational and Applied Mathematics</span>, 20:53 – 65,
1987. doi: 10 . 1016/0377-0427(87)90125-7

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
R. C. Schank and R. P. Abelson.

</span>
<span class="ltx_bibblock">Knowledge and memory: The real story.

</span>
<span class="ltx_bibblock">In J. Robert S. Wyer, ed., <span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">Advances in Social Cognition</span>,
vol. 8, pp. 1–85. Lawrence Erlbaum Associates, Hillsdale, NJ, USA, 1995.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
E. Segel and J. Heer.

</span>
<span class="ltx_bibblock">Narrative visualization: Telling stories with data.

</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>,
16(6):1139–1148, 2010. doi: 10 . 1109/TVCG . 2010 . 179

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
R. Sevastjanova, F. Beck, B. Ell, C. Turkay, R. Henkin, M. Butt, D. A. Keim,
and M. El-Assady.

</span>
<span class="ltx_bibblock">Going beyond visualization: Verbalization as complementary medium to
explain machine learning models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">Workshop on Visualization for AI Explainability at IEEE VIS</span>,
2018.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
R. D. Shachter.

</span>
<span class="ltx_bibblock">Bayes-ball: The rational pastime (for determining irrelevance and
requisite information in belief networks and influence diagrams).

</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1301.7412</span>, 2013. doi: 10 . 5555/2074094 . 2074151

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
D. Sless.

</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">Learning and Visual Communication</span>.

</span>
<span class="ltx_bibblock">Wiley, New York, NY, USA, 1981.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
A. Srinivasan, S. M. Drucker, A. Endert, and J. Stasko.

</span>
<span class="ltx_bibblock">Augmenting visualizations with interactive data facts to facilitate
interpretation and communication.

</span>
<span class="ltx_bibblock"><span id="bib.bib58.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>,
25(1):672–681, 2018. doi: 10 . 1109/TVCG . 2018 . 2865145

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
A. Srinivasan, H. Park, A. Endert, and R. C. Basole.

</span>
<span class="ltx_bibblock">Graphiti: Interactive specification of attribute-based edges for
network modeling and visualization.

</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>,
24(1):226–235, 2017. doi: 10 . 1109/TVCG . 2017 . 2744843

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
J. J. Thomas and K. A. Cook.

</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">Illuminating the Path: The Research and Development Agenda for
Visual Analytics</span>.

</span>
<span class="ltx_bibblock">IEEE Computer Society, addrIEEECS, 2005.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
M. Tory and T. Möller.

</span>
<span class="ltx_bibblock">Evaluating visualizations: Do expert reviews work?

</span>
<span class="ltx_bibblock"><span id="bib.bib61.1.1" class="ltx_text ltx_font_italic">IEEE Computer Graphics and Applications</span>, 25(5):8–11, 2005.
doi: 10 . 1109/MCG . 2005 . 102

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
J. Vansina.

</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text ltx_font_italic">Oral Tradition as History</span>.

</span>
<span class="ltx_bibblock">University of Wisconsin Press, Madison, WI, USA, 1985. doi: 10 . 2307/3601125

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
F. Viégas and M. Wattenberg.

</span>
<span class="ltx_bibblock">Communication-minded visualization: A call to action.

</span>
<span class="ltx_bibblock"><span id="bib.bib63.1.1" class="ltx_text ltx_font_italic">IBM Systems Journal</span>, 45(4):801–812, 2006. doi: 10 . 1147/sj . 454 . 0801

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
J. Wang and K. Mueller.

</span>
<span class="ltx_bibblock">The visual causality analyst: An interactive interface for causal
reasoning.

</span>
<span class="ltx_bibblock"><span id="bib.bib64.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>,
22(1):230–239, 2016. doi: 10 . 1109/TVCG . 2015 . 2467931

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
C. Ware.

</span>
<span class="ltx_bibblock">Perceiving complex causation through interaction.

</span>
<span class="ltx_bibblock">In <span id="bib.bib65.1.1" class="ltx_text ltx_font_italic">Proceedings of the Symposium on Computational Aesthetics</span>,
pp. 29––35. Association for Computing Machinery, New York, NY, USA, 2013.
doi: 10 . 1145/2487276 . 2487279

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
W. Wright, D. Schroh, P. Proulx, A. Skaburskis, and B. Cort.

</span>
<span class="ltx_bibblock">The sandbox for analysis: Concepts and methods.

</span>
<span class="ltx_bibblock">In <span id="bib.bib66.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM Conference on Human Factors in
Computing Systems</span>, pp. 801––810. Association for Computing Machinery, New
York, NY, USA, 2006. doi: 10 . 1145/1124772 . 1124890

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
W. Wright, D. Sheffield, and S. Santosa.

</span>
<span class="ltx_bibblock">Argument mapper: Countering cognitive biases in analysis with
critical (visual) thinking.

</span>
<span class="ltx_bibblock">In <span id="bib.bib67.1.1" class="ltx_text ltx_font_italic">Proceedings of the International Conference on Information
Visualisation</span>, pp. 250–255, 2017.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
C. Xiong, J. Shapiro, J. Hullman, and S. Franconeri.

</span>
<span class="ltx_bibblock">Illusion of causality in visualized data.

</span>
<span class="ltx_bibblock"><span id="bib.bib68.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>,
26(1):853–862, 2019. doi: 10 . 1109/TVCG . 2019 . 2934399

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="id1a" class="ltx_logical-block">
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p ltx_align_center"><span id="p1.1.1" class="ltx_text ltx_font_sansserif" style="font-size:207%;">Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality<span id="p1.1.1.1" class="ltx_text ltx_font_serif"></span></span></p>
<p id="p1.2" class="ltx_p ltx_align_center"><span id="p1.2.1" class="ltx_text ltx_font_sansserif" style="font-size:144%;">Supplementary Materials<span id="p1.2.1.1" class="ltx_text ltx_font_serif"></span></span></p>
</div>
</div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Additional Figures</h2>

<figure id="A1.F1" class="ltx_figure"><img src="/html/2009.02649/assets/x10.png" id="A1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="664" height="310" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A: </span>Sample causal network visualized in <span id="A1.F1.2.1" class="ltx_text ltx_font_smallcaps">CauseWorks</span>.</figcaption>
</figure>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Video</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">We have attached a companion video showcasing the <span id="A2.p1.1.1" class="ltx_text ltx_font_smallcaps">CauseWorks</span> system.</p>
</div>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Graph Samples</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">We have also attached images of the graph systems that we used in our crowdsourced study.</p>
</div>
<div id="A3.p2" class="ltx_para">
<p id="A3.p2.1" class="ltx_p">The naming convention is: <span id="A3.p2.1.1" class="ltx_text ltx_font_bold">[Experimental condition][Difficulty Level][Repetition]</span></p>
</div>
<div id="A3.p3" class="ltx_para">
<p id="A3.p3.1" class="ltx_p">Example: [H1][N][1] — The file name will be ‘H1N1.png’</p>
</div>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Anonymized Performance Data</h2>

<div id="A4.p1" class="ltx_para">
<p id="A4.p1.1" class="ltx_p">We have attached anonymized correctness, time, and subjective responses.</p>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2009.02648" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2009.02649" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2009.02649">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2009.02649" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2009.02650" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  9 05:28:04 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
