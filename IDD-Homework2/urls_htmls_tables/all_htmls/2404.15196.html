<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Setting up the Data Printer with Improved English to Ukrainian Machine Translation</title>
<!--Generated on Fri Jul 12 10:03:29 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2404.15196v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#S1" title="In Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#S2" title="In Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Supervised Finetuning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#S3" title="In Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>First Phase: Heuristic Filtering of Paracrawl</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#S4" title="In Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Second Phase: Unsupervised Data Selection on Extended Multi30K</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#S5" title="In Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Few-Shot Translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#S6" title="In Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussion and Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#S7" title="In Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#S8" title="In Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#S9" title="In Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Contributions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#S10" title="In Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10 </span>Acknowledgements</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#S11" title="In Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">11 </span>References</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#A1" title="In Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Translation Examples</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#A1.SS0.SSS0.Px1" title="In Appendix A Translation Examples ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_title">Sample of top 5 worst examples by BLEU from FLORES devtest set</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#A1.SS0.SSS0.Px2" title="In Appendix A Translation Examples ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_title">Sample of top 5 best examples by BLEU from FLORES devtest set</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Setting up the Data Printer with Improved English to Ukrainian Machine Translation</h1>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">To build large language models for Ukrainian we need to expand our corpora with large amounts of new algorithmic tasks expressed in natural language. Examples of task performance expressed in English are abundant, so with a high-quality translation system our community will be enabled to curate datasets faster. To aid this goal, we introduce a recipe to build a translation system using supervised finetuning of a large pretrained language model with a noisy parallel dataset of 3M pairs of Ukrainian and English sentences followed by a second phase of training using 17K examples selected by k-fold perplexity filtering on another dataset of higher quality. Our decoder-only model named Dragoman beats performance of previous state of the art encoder-decoder models on the FLORES devtest set.

<br class="ltx_break"/>
<br class="ltx_break"/>
<span class="ltx_text ltx_font_bold" id="id2.id1.1">Keywords: </span>machine translation, parameter-efficient fine tuning, large language models, unsupervised data selection, perplexity filtering</p>
</div>
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\NAT@set@cites</span>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para" id="p2">
<p class="ltx_p" id="p2.1"><span class="ltx_text" id="p2.1.1"></span></p>
</div>
<div class="ltx_logical-block" id="id1">
<div class="ltx_para" id="id1.p1">
<p class="ltx_p ltx_align_center" id="id1.p1.1"><span class="ltx_text ltx_font_bold" id="id1.p1.1.1" style="font-size:144%;">Setting up the Data Printer with Improved English to Ukrainian Machine Translation</span></p>
<br class="ltx_break ltx_centering"/>
<table class="ltx_tabular ltx_centering ltx_align_top" id="id1.p1.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="id1.p1.2.1.1">
<td class="ltx_td ltx_align_center" id="id1.p1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="id1.p1.2.1.1.1.1" style="font-size:120%;">Yurii Paniv, Dmytro Chaplynskyi, Nikita Trynus, Volodymyr Kyrylov</span></td>
</tr>
<tr class="ltx_tr" id="id1.p1.2.2.2">
<td class="ltx_td ltx_align_center" id="id1.p1.2.2.2.1">Ukrainian Catholic University, lang-uk initiative,</td>
</tr>
<tr class="ltx_tr" id="id1.p1.2.3.3">
<td class="ltx_td ltx_align_center" id="id1.p1.2.3.3.1">Igor Sikorsky Kyiv Polytechnic Institute,
Università della Svizzera italiana</td>
</tr>
<tr class="ltx_tr" id="id1.p1.2.4.4">
<td class="ltx_td ltx_align_center" id="id1.p1.2.4.4.1">paniv@ucu.edu.ua, chaplinsky.dmitry@gmail.com, trynus.nikita@lll.kpi.ua, vol@wilab.org.ua</td>
</tr>
</tbody>
</table>
<p class="ltx_p ltx_align_center" id="id1.p1.3"><span class="ltx_text ltx_font_italic" id="id1.p1.3.1">Abstract content</span></p>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">1.   Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The availability of the data is the most important ingredient when one needs to pretrain general-purpose large language models for a specific natural language task or a set of tasks. While it is relatively easy to obtain a good and balanced dataset under specific domain for the English language, it is much harder to do the same for other under-resourced languages such as Ukrainian.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Since curating a corpus of tasks in Ukrainian is a large endeavor, and given a large body of work done for English, we consider existing instruction tuning datasets as a source of tasks to reuse in Ukrainian using automatic machine translation.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">This work focuses on improving the current state of machine translation from English to Ukrainian.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">We contribute a recipe for finetuning a large pretrained language model with publicly available data to build a translation system (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S3" title="3. First Phase: Heuristic Filtering of Paracrawl ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">section 3</span></a>, <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S4" title="4. Second Phase: Unsupervised Data Selection on Extended Multi30K ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">section 4</span></a>). This matches state of the art performance of the best encoder-decoder model on a common multilingual benchmark using a consumer GPU with 24 GiB of VRAM. We release training, evaluation code, datasets, and model at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/lang-uk/dragoman" title="">https://github.com/lang-uk/dragoman</a>. Our main results are summarized in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S1.T1" title="Table 1 ‣ 1. Introduction ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">Table 1</span></a>. We provide examples of the top-5 best and worst translations on the FLORES devtest set in the <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#A1" title="Appendix A Translation Examples ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">Appendix A</span></a>.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">We base pretrained model selection on evaluation in few-shot learning setting (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S5" title="5. Few-Shot Translation ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">section 5</span></a>). We find that it’s a promising method to design tasks without training, and the model can perform comparably to specialized systems given increased inference budget and auxiliary translation scoring functions, yet still underperforms our finetuned recipe.</p>
</div>
<figure class="ltx_table" id="S1.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S1.T1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S1.T1.1.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.1.1.2"><span class="ltx_text ltx_font_bold" id="S1.T1.1.1.2.1">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.1.1.1">
<span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.1">BLEU</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S1.T1.1.1.1.m1.1"><semantics id="S1.T1.1.1.1.m1.1a"><mo id="S1.T1.1.1.1.m1.1.1" stretchy="false" xref="S1.T1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S1.T1.1.1.1.m1.1b"><ci id="S1.T1.1.1.1.m1.1.1.cmml" xref="S1.T1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S1.T1.1.1.1.m1.1d">↑</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S1.T1.1.2.1.1.1">Finetuned</span></td>
<td class="ltx_td ltx_border_t" id="S1.T1.1.2.1.2"></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.3.2">
<td class="ltx_td ltx_align_left" id="S1.T1.1.3.2.1">Dragoman P, 10 beams (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S3" title="3. First Phase: Heuristic Filtering of Paracrawl ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">section 3</span></a>)</td>
<td class="ltx_td ltx_align_left" id="S1.T1.1.3.2.2">30.4</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.4.3">
<td class="ltx_td ltx_align_left" id="S1.T1.1.4.3.1">Dragoman PT, 10 beams (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S4" title="4. Second Phase: Unsupervised Data Selection on Extended Multi30K ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">section 4</span></a>)</td>
<td class="ltx_td ltx_align_left" id="S1.T1.1.4.3.2"><span class="ltx_text ltx_font_bold" id="S1.T1.1.4.3.2.1">32.3</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.1.5.4.1">
<span class="ltx_text ltx_font_bold" id="S1.T1.1.5.4.1.1">Zero shot and few shot</span> (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S5" title="5. Few-Shot Translation ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">section 5</span></a>)</td>
<td class="ltx_td ltx_border_t" id="S1.T1.1.5.4.2"></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.6.5">
<td class="ltx_td ltx_align_left" id="S1.T1.1.6.5.1">Llama 2 7B 2-shot, 10 beams</td>
<td class="ltx_td ltx_align_left" id="S1.T1.1.6.5.2">20.1</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.7.6">
<td class="ltx_td ltx_align_left" id="S1.T1.1.7.6.1">Mistral-7B-v0.1 2-shot, 10 beams</td>
<td class="ltx_td ltx_align_left" id="S1.T1.1.7.6.2">24.9</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.8.7">
<td class="ltx_td ltx_align_left" id="S1.T1.1.8.7.1">gpt-4 10-shot</td>
<td class="ltx_td ltx_align_left" id="S1.T1.1.8.7.2">29.5</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.9.8">
<td class="ltx_td ltx_align_left" id="S1.T1.1.9.8.1">gpt-4-turbo-preview 0-shot</td>
<td class="ltx_td ltx_align_left" id="S1.T1.1.9.8.2">30.4</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.10.9">
<td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.1.10.9.1"><span class="ltx_text ltx_font_bold" id="S1.T1.1.10.9.1.1">Pretrained encoder-decoder</span></td>
<td class="ltx_td ltx_border_t" id="S1.T1.1.10.9.2"></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.11.10">
<td class="ltx_td ltx_align_left" id="S1.T1.1.11.10.1">NLLB-3B, 10 beams</td>
<td class="ltx_td ltx_align_left" id="S1.T1.1.11.10.2">30.6</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.12.11">
<td class="ltx_td ltx_align_left ltx_border_b" id="S1.T1.1.12.11.1">OPUS-MT, 10 beams</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S1.T1.1.12.11.2"><span class="ltx_text ltx_font_bold" id="S1.T1.1.12.11.2.1">32.2</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Main results. Our Dragoman models improve existing state of the art on translation from English to Ukrainian on FLORES-101 devtest <cite class="ltx_cite ltx_citemacro_citep">(Goyal et al., <a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib8" title="">2022</a>)</cite>, a multilingual benchmark of translated sentences from web articles. We compare to state of the art encoder-decoder models, NLLB-3B <cite class="ltx_cite ltx_citemacro_cite">Team et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib30" title="">2022</a>)</cite> and OPUS-MT <cite class="ltx_cite ltx_citemacro_cite">Tiedemann and Thottingal (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib32" title="">2020</a>)</cite>.
</figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">2.   Supervised Finetuning</h2>
<figure class="ltx_table" id="S2.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S2.T2.1" style="width:455.2pt;height:88.8pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.8pt,5.6pt) scale(0.88765417123475,0.88765417123475) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T2.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S2.T2.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S2.T2.1.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S2.T2.1.1.1.2.1">Dataset</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S2.T2.1.1.1.3" rowspan="2"><span class="ltx_text ltx_font_bold" id="S2.T2.1.1.1.3.1">Pairs</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="S2.T2.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S2.T2.1.1.1.4.1">Filters</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S2.T2.1.1.1.5" rowspan="2"><span class="ltx_text ltx_font_bold" id="S2.T2.1.1.1.5.1">Example Order</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S2.T2.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S2.T2.1.1.1.1.1">Best BLEU <math alttext="\uparrow" class="ltx_Math" display="inline" id="S2.T2.1.1.1.1.1.1.m1.1"><semantics id="S2.T2.1.1.1.1.1.1.m1.1a"><mo id="S2.T2.1.1.1.1.1.1.m1.1.1" stretchy="false" xref="S2.T2.1.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S2.T2.1.1.1.1.1.1.m1.1b"><ci id="S2.T2.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T2.1.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.1.1.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S2.T2.1.1.1.1.1.1.m1.1d">↑</annotation></semantics></math></span></th>
</tr>
<tr class="ltx_tr" id="S2.T2.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S2.T2.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S2.T2.1.1.2.1.1.1">Lang</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S2.T2.1.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S2.T2.1.1.2.1.2.1">BPC</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S2.T2.1.1.2.1.3"><span class="ltx_text ltx_font_bold" id="S2.T2.1.1.2.1.3.1">LaBSE</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S2.T2.1.1.2.1.4"><span class="ltx_text ltx_font_bold" id="S2.T2.1.1.2.1.4.1">Len diff</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T2.1.1.3.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.1.1.3.1.1">1m unfiltered</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S2.T2.1.1.3.1.2">963k</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.1.1.3.1.3">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S2.T2.1.1.3.1.4">-</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.1.1.3.1.5">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S2.T2.1.1.3.1.6">-</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.1.1.3.1.7">Random</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S2.T2.1.1.3.1.8">28.26</td>
</tr>
<tr class="ltx_tr" id="S2.T2.1.1.4.2">
<td class="ltx_td ltx_align_left" id="S2.T2.1.1.4.2.1">1m filtered</td>
<td class="ltx_td ltx_align_right" id="S2.T2.1.1.4.2.2">958k</td>
<td class="ltx_td ltx_align_left" id="S2.T2.1.1.4.2.3">En/Uk</td>
<td class="ltx_td ltx_align_right" id="S2.T2.1.1.4.2.4">&lt;3.33</td>
<td class="ltx_td ltx_align_left" id="S2.T2.1.1.4.2.5">&gt;0.91</td>
<td class="ltx_td ltx_align_right" id="S2.T2.1.1.4.2.6">&lt;50</td>
<td class="ltx_td ltx_align_left" id="S2.T2.1.1.4.2.7">Random</td>
<td class="ltx_td ltx_align_right" id="S2.T2.1.1.4.2.8">29.47</td>
</tr>
<tr class="ltx_tr" id="S2.T2.1.1.5.3">
<td class="ltx_td ltx_align_left" id="S2.T2.1.1.5.3.1">3m filtered</td>
<td class="ltx_td ltx_align_right" id="S2.T2.1.1.5.3.2">2.9m</td>
<td class="ltx_td ltx_align_left" id="S2.T2.1.1.5.3.3">En/Uk</td>
<td class="ltx_td ltx_align_right" id="S2.T2.1.1.5.3.4">&lt;3.25</td>
<td class="ltx_td ltx_align_left" id="S2.T2.1.1.5.3.5">&gt;0.85</td>
<td class="ltx_td ltx_align_right" id="S2.T2.1.1.5.3.6">&lt;50</td>
<td class="ltx_td ltx_align_left" id="S2.T2.1.1.5.3.7">By LaBSE score, dissimilar first</td>
<td class="ltx_td ltx_align_right" id="S2.T2.1.1.5.3.8"><span class="ltx_text ltx_font_bold" id="S2.T2.1.1.5.3.8.1">30.37</span></td>
</tr>
<tr class="ltx_tr" id="S2.T2.1.1.6.4">
<td class="ltx_td ltx_align_left ltx_border_b" id="S2.T2.1.1.6.4.1">8m filtered</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S2.T2.1.1.6.4.2">8m</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S2.T2.1.1.6.4.3">En/Uk</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S2.T2.1.1.6.4.4">&lt;5</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S2.T2.1.1.6.4.5">&gt;0.5</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S2.T2.1.1.6.4.6">&lt;50</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S2.T2.1.1.6.4.7">By LaBSE score, dissimilar first</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S2.T2.1.1.6.4.8">30.19</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span> Summary of experiments with Paracrawl subcorpora. Legend of filters: <span class="ltx_text ltx_font_bold" id="S2.T2.6.1">Lang</span> denotes language filters, <span class="ltx_text ltx_font_bold" id="S2.T2.7.2">BPC</span> denotes maximum sum of bits per character measures, <span class="ltx_text ltx_font_bold" id="S2.T2.8.3">LaBSE</span> denotes maximum sentence embedding cosine similarity between source and target sentences, <span class="ltx_text ltx_font_bold" id="S2.T2.9.4">Len diff</span> denotes maximum difference in length between source and target in characters. Example ordering impacts data loading in the training loop.</figcaption>
</figure>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.3">We cast machine translation as a likelihood maximization of a density <math alttext="\operatorname{p}" class="ltx_Math" display="inline" id="S2.p1.1.m1.1"><semantics id="S2.p1.1.m1.1a"><mi id="S2.p1.1.m1.1.1" mathvariant="normal" xref="S2.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">p</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">\operatorname{p}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.1.m1.1d">roman_p</annotation></semantics></math> of Ukrainian sentences <math alttext='Y="\text{{перекладене речення}}"\in\mathcal{Y}' class="ltx_Math" display="inline" id="S2.p1.2.m2.1"><semantics id="S2.p1.2.m2.1a"><mrow id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml"><mi id="S2.p1.2.m2.1.1.2" xref="S2.p1.2.m2.1.1.2.cmml">Y</mi><mo id="S2.p1.2.m2.1.1.3" xref="S2.p1.2.m2.1.1.3.cmml">=</mo><mrow id="S2.p1.2.m2.1.1.4" xref="S2.p1.2.m2.1.1.4.cmml"><mi id="S2.p1.2.m2.1.1.4.2" mathvariant="normal" xref="S2.p1.2.m2.1.1.4.2.cmml">"</mi><mo id="S2.p1.2.m2.1.1.4.1" xref="S2.p1.2.m2.1.1.4.1.cmml">⁢</mo><mtext id="S2.p1.2.m2.1.1.4.3" xref="S2.p1.2.m2.1.1.4.3a.cmml">перекладене речення</mtext><mo id="S2.p1.2.m2.1.1.4.1a" xref="S2.p1.2.m2.1.1.4.1.cmml">⁢</mo><mi id="S2.p1.2.m2.1.1.4.4" mathvariant="normal" xref="S2.p1.2.m2.1.1.4.4.cmml">"</mi></mrow><mo id="S2.p1.2.m2.1.1.5" xref="S2.p1.2.m2.1.1.5.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.p1.2.m2.1.1.6" xref="S2.p1.2.m2.1.1.6.cmml">𝒴</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><apply id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1"><and id="S2.p1.2.m2.1.1a.cmml" xref="S2.p1.2.m2.1.1"></and><apply id="S2.p1.2.m2.1.1b.cmml" xref="S2.p1.2.m2.1.1"><eq id="S2.p1.2.m2.1.1.3.cmml" xref="S2.p1.2.m2.1.1.3"></eq><ci id="S2.p1.2.m2.1.1.2.cmml" xref="S2.p1.2.m2.1.1.2">𝑌</ci><apply id="S2.p1.2.m2.1.1.4.cmml" xref="S2.p1.2.m2.1.1.4"><times id="S2.p1.2.m2.1.1.4.1.cmml" xref="S2.p1.2.m2.1.1.4.1"></times><ci id="S2.p1.2.m2.1.1.4.2.cmml" xref="S2.p1.2.m2.1.1.4.2">"</ci><ci id="S2.p1.2.m2.1.1.4.3a.cmml" xref="S2.p1.2.m2.1.1.4.3"><mtext id="S2.p1.2.m2.1.1.4.3.cmml" xref="S2.p1.2.m2.1.1.4.3">перекладене речення</mtext></ci><ci id="S2.p1.2.m2.1.1.4.4.cmml" xref="S2.p1.2.m2.1.1.4.4">"</ci></apply></apply><apply id="S2.p1.2.m2.1.1c.cmml" xref="S2.p1.2.m2.1.1"><in id="S2.p1.2.m2.1.1.5.cmml" xref="S2.p1.2.m2.1.1.5"></in><share href="https://arxiv.org/html/2404.15196v2#S2.p1.2.m2.1.1.4.cmml" id="S2.p1.2.m2.1.1d.cmml" xref="S2.p1.2.m2.1.1"></share><ci id="S2.p1.2.m2.1.1.6.cmml" xref="S2.p1.2.m2.1.1.6">𝒴</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">Y="\text{{перекладене речення}}"\in\mathcal{Y}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.2.m2.1d">italic_Y = " перекладене речення " ∈ caligraphic_Y</annotation></semantics></math> conditioned on their English sources with quasi-instruction formatting: <math alttext='X="\text{[INST] translated sentence [/INST]}"\in\mathcal{X}' class="ltx_Math" display="inline" id="S2.p1.3.m3.1"><semantics id="S2.p1.3.m3.1a"><mrow id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml"><mi id="S2.p1.3.m3.1.1.2" xref="S2.p1.3.m3.1.1.2.cmml">X</mi><mo id="S2.p1.3.m3.1.1.3" xref="S2.p1.3.m3.1.1.3.cmml">=</mo><mrow id="S2.p1.3.m3.1.1.4" xref="S2.p1.3.m3.1.1.4.cmml"><mi id="S2.p1.3.m3.1.1.4.2" mathvariant="normal" xref="S2.p1.3.m3.1.1.4.2.cmml">"</mi><mo id="S2.p1.3.m3.1.1.4.1" xref="S2.p1.3.m3.1.1.4.1.cmml">⁢</mo><mtext id="S2.p1.3.m3.1.1.4.3" xref="S2.p1.3.m3.1.1.4.3a.cmml">[INST] translated sentence [/INST]</mtext><mo id="S2.p1.3.m3.1.1.4.1a" xref="S2.p1.3.m3.1.1.4.1.cmml">⁢</mo><mi id="S2.p1.3.m3.1.1.4.4" mathvariant="normal" xref="S2.p1.3.m3.1.1.4.4.cmml">"</mi></mrow><mo id="S2.p1.3.m3.1.1.5" xref="S2.p1.3.m3.1.1.5.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.p1.3.m3.1.1.6" xref="S2.p1.3.m3.1.1.6.cmml">𝒳</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><apply id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1"><and id="S2.p1.3.m3.1.1a.cmml" xref="S2.p1.3.m3.1.1"></and><apply id="S2.p1.3.m3.1.1b.cmml" xref="S2.p1.3.m3.1.1"><eq id="S2.p1.3.m3.1.1.3.cmml" xref="S2.p1.3.m3.1.1.3"></eq><ci id="S2.p1.3.m3.1.1.2.cmml" xref="S2.p1.3.m3.1.1.2">𝑋</ci><apply id="S2.p1.3.m3.1.1.4.cmml" xref="S2.p1.3.m3.1.1.4"><times id="S2.p1.3.m3.1.1.4.1.cmml" xref="S2.p1.3.m3.1.1.4.1"></times><ci id="S2.p1.3.m3.1.1.4.2.cmml" xref="S2.p1.3.m3.1.1.4.2">"</ci><ci id="S2.p1.3.m3.1.1.4.3a.cmml" xref="S2.p1.3.m3.1.1.4.3"><mtext id="S2.p1.3.m3.1.1.4.3.cmml" xref="S2.p1.3.m3.1.1.4.3">[INST] translated sentence [/INST]</mtext></ci><ci id="S2.p1.3.m3.1.1.4.4.cmml" xref="S2.p1.3.m3.1.1.4.4">"</ci></apply></apply><apply id="S2.p1.3.m3.1.1c.cmml" xref="S2.p1.3.m3.1.1"><in id="S2.p1.3.m3.1.1.5.cmml" xref="S2.p1.3.m3.1.1.5"></in><share href="https://arxiv.org/html/2404.15196v2#S2.p1.3.m3.1.1.4.cmml" id="S2.p1.3.m3.1.1d.cmml" xref="S2.p1.3.m3.1.1"></share><ci id="S2.p1.3.m3.1.1.6.cmml" xref="S2.p1.3.m3.1.1.6">𝒳</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">X="\text{[INST] translated sentence [/INST]}"\in\mathcal{X}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.3.m3.1d">italic_X = " [INST] translated sentence [/INST] " ∈ caligraphic_X</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">The density is parametrized using a neural network with frozen pretrained weights <math alttext="\theta" class="ltx_Math" display="inline" id="S2.p2.1.m1.1"><semantics id="S2.p2.1.m1.1a"><mi id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><ci id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S2.p2.1.m1.1d">italic_θ</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\operatorname{argmax}_{\phi}\operatorname{p}_{\theta,\phi}(Y|X)" class="ltx_Math" display="block" id="S2.E1.m1.4"><semantics id="S2.E1.m1.4a"><mrow id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml"><msub id="S2.E1.m1.4.4.3" xref="S2.E1.m1.4.4.3.cmml"><mi id="S2.E1.m1.4.4.3.2" xref="S2.E1.m1.4.4.3.2.cmml">argmax</mi><mi id="S2.E1.m1.4.4.3.3" xref="S2.E1.m1.4.4.3.3.cmml">ϕ</mi></msub><mo id="S2.E1.m1.4.4a" lspace="0.167em" xref="S2.E1.m1.4.4.cmml">⁡</mo><mrow id="S2.E1.m1.4.4.2.2" xref="S2.E1.m1.4.4.2.3.cmml"><msub id="S2.E1.m1.3.3.1.1.1" xref="S2.E1.m1.3.3.1.1.1.cmml"><mi id="S2.E1.m1.3.3.1.1.1.2" mathvariant="normal" xref="S2.E1.m1.3.3.1.1.1.2.cmml">p</mi><mrow id="S2.E1.m1.2.2.2.4" xref="S2.E1.m1.2.2.2.3.cmml"><mi id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml">θ</mi><mo id="S2.E1.m1.2.2.2.4.1" xref="S2.E1.m1.2.2.2.3.cmml">,</mo><mi id="S2.E1.m1.2.2.2.2" xref="S2.E1.m1.2.2.2.2.cmml">ϕ</mi></mrow></msub><mo id="S2.E1.m1.4.4.2.2a" xref="S2.E1.m1.4.4.2.3.cmml">⁡</mo><mrow id="S2.E1.m1.4.4.2.2.2" xref="S2.E1.m1.4.4.2.3.cmml"><mo id="S2.E1.m1.4.4.2.2.2.2" stretchy="false" xref="S2.E1.m1.4.4.2.3.cmml">(</mo><mrow id="S2.E1.m1.4.4.2.2.2.1" xref="S2.E1.m1.4.4.2.2.2.1.cmml"><mi id="S2.E1.m1.4.4.2.2.2.1.2" xref="S2.E1.m1.4.4.2.2.2.1.2.cmml">Y</mi><mo fence="false" id="S2.E1.m1.4.4.2.2.2.1.1" xref="S2.E1.m1.4.4.2.2.2.1.1.cmml">|</mo><mi id="S2.E1.m1.4.4.2.2.2.1.3" xref="S2.E1.m1.4.4.2.2.2.1.3.cmml">X</mi></mrow><mo id="S2.E1.m1.4.4.2.2.2.3" stretchy="false" xref="S2.E1.m1.4.4.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.4b"><apply id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4"><apply id="S2.E1.m1.4.4.3.cmml" xref="S2.E1.m1.4.4.3"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.3.1.cmml" xref="S2.E1.m1.4.4.3">subscript</csymbol><ci id="S2.E1.m1.4.4.3.2.cmml" xref="S2.E1.m1.4.4.3.2">argmax</ci><ci id="S2.E1.m1.4.4.3.3.cmml" xref="S2.E1.m1.4.4.3.3">italic-ϕ</ci></apply><apply id="S2.E1.m1.4.4.2.3.cmml" xref="S2.E1.m1.4.4.2.2"><apply id="S2.E1.m1.3.3.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1">subscript</csymbol><ci id="S2.E1.m1.3.3.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.2">p</ci><list id="S2.E1.m1.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.4"><ci id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1">𝜃</ci><ci id="S2.E1.m1.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2">italic-ϕ</ci></list></apply><apply id="S2.E1.m1.4.4.2.2.2.1.cmml" xref="S2.E1.m1.4.4.2.2.2.1"><csymbol cd="latexml" id="S2.E1.m1.4.4.2.2.2.1.1.cmml" xref="S2.E1.m1.4.4.2.2.2.1.1">conditional</csymbol><ci id="S2.E1.m1.4.4.2.2.2.1.2.cmml" xref="S2.E1.m1.4.4.2.2.2.1.2">𝑌</ci><ci id="S2.E1.m1.4.4.2.2.2.1.3.cmml" xref="S2.E1.m1.4.4.2.2.2.1.3">𝑋</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.4c">\operatorname{argmax}_{\phi}\operatorname{p}_{\theta,\phi}(Y|X)</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.4d">roman_argmax start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT roman_p start_POSTSUBSCRIPT italic_θ , italic_ϕ end_POSTSUBSCRIPT ( italic_Y | italic_X )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.2">We implement the conditional language modeling objective by masking out tokens of <math alttext="X" class="ltx_Math" display="inline" id="S2.p3.1.m1.1"><semantics id="S2.p3.1.m1.1a"><mi id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><ci id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">X</annotation><annotation encoding="application/x-llamapun" id="S2.p3.1.m1.1d">italic_X</annotation></semantics></math> when computing token-wise cross entropy of shifted targets.
We only optimize extra low rank adapter <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib10" title="">2022</a>)</cite> parameters <math alttext="\phi" class="ltx_Math" display="inline" id="S2.p3.2.m2.1"><semantics id="S2.p3.2.m2.1a"><mi id="S2.p3.2.m2.1.1" xref="S2.p3.2.m2.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S2.p3.2.m2.1b"><ci id="S2.p3.2.m2.1.1.cmml" xref="S2.p3.2.m2.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.2.m2.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S2.p3.2.m2.1d">italic_ϕ</annotation></semantics></math> after nf4 quantization <cite class="ltx_cite ltx_citemacro_citep">(Dettmers et al., <a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib5" title="">2023</a>)</cite>. In practice we use large rank values and adapter mixture weights. All training runs proceed for one epoch and we use dropout <cite class="ltx_cite ltx_citemacro_citep">(Srivastava et al., <a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib28" title="">2014</a>)</cite> for regularization against data noise.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">We use Mistral-7B-v0.1 <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib11" title="">2023</a>)</cite> as a base pretrained decoder-only transformer, as it performs favorably in our few-shot experiments (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S5" title="5. Few-Shot Translation ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">section 5</span></a>).</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">3.   First Phase: Heuristic Filtering of Paracrawl</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We use the publicly available Paracrawl dataset <cite class="ltx_cite ltx_citemacro_cite">Bañón et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib1" title="">2020</a>)</cite>. This dataset contains 13,354,365 English-Ukrainian sentence pairs, collected by automatically matching similar sentences in large corpora of internet text.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">We have identified issues with translation pairs, including a significant number of repetitive or incorrect examples. We encounter a large subset of repetitive weather forecasts following the template “The temperature in &lt;x&gt; is &lt;y&gt; degrees,” and sentences from site navigation menus. Additionally, many texts appear to be scraped from adult websites, containing low-quality, machine-translated samples. We have spotted numerous instances of incomplete or significantly incorrect translation pairs. Some target sentences were written in languages other than Ukrainian.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">To control the quality of the sentences, we apply multiple heuristics.</p>
</div>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px1">
<h3 class="ltx_title ltx_title_paragraph">Language filtering</h3>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p1.1">gcld3 library<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/google/cld3" title="">https://github.com/google/cld3</a></span></span></span> provides language detection capabilities. We remove all sentences that failed to verify as Ukrainian or English.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px2">
<h3 class="ltx_title ltx_title_paragraph">Perplexity thresholding</h3>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p1.1">We score source and target sentences using two decoder-only models trained on different monolingual datasets <cite class="ltx_cite ltx_citemacro_cite">Radford et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib24" title="">2019</a>); Minixhofer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib19" title="">2022</a>)</cite> and sum their bits per character measures.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px3">
<h3 class="ltx_title ltx_title_paragraph">Translation mismatch filtering</h3>
<div class="ltx_para" id="S3.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px3.p1.1">LaBSE <cite class="ltx_cite ltx_citemacro_cite">Feng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib6" title="">2022</a>)</cite> embeds sentences into a space, where similar sentences in different languages are close together. We use it to filter out badly aligned sentence pairs.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px4">
<h3 class="ltx_title ltx_title_paragraph">Length filtering</h3>
<div class="ltx_para" id="S3.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px4.p1.1">The lengths of the original and translated sentences reveal examples that are too short or too long. Absolute differences of lengths point to pairs with long target for the short source and vice versa.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px4.p2">
<p class="ltx_p" id="S3.SS0.SSS0.Px4.p2.1">We arbitrarily choose joint values of filtering thresholds to get the desired approximate example counts: 1 million, 3 million and 8 million. We perform multiple experiments with these splits while searching for optimal hyperparameters. We list threshold values in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S2.T2" title="Table 2 ‣ 2. Supervised Finetuning ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">Table 2</span></a> and best results for each subset.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">4.   Second Phase: Unsupervised Data Selection on Extended Multi30K</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We use the best checkpoint from the previous finetuning phase to train on a high-quality dataset: Extended Multi30K from <cite class="ltx_cite ltx_citemacro_citet">Saichyshyna et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib27" title="">2023</a>)</cite>. Switching datasets gives us a performance boost of 1.97 BLEU. We additionally delete 11600 sentences from the dataset using unsupervised perplexity filtering pipeline gaining 0.35 on the dev set that translates to 0.3 BLEU on the devtest subset of FLORES.</p>
</div>
<figure class="ltx_figure" id="S4.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="322" id="S4.F1.g1" src="x1.png" width="427"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Distributions of sentence log probabilities for each fold superimposed on top of each other. Every bar color represents a unique fold; every vertical line denotes a 60<sup class="ltx_sup" id="S4.F1.2.1">th</sup> percentile cutoff threshold. The best percentile is chosen using grid search shown in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S4.T3" title="Table 3 ‣ 4. Second Phase: Unsupervised Data Selection on Extended Multi30K ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">Table 3</span></a>.</figcaption>
</figure>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.3">We use perplexity as a data selection criterion to calculate thresholds to filter out highly surprising sentences.
We apply the <math alttext="k" class="ltx_Math" display="inline" id="S4.p2.1.m1.1"><semantics id="S4.p2.1.m1.1a"><mi id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><ci id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.p2.1.m1.1d">italic_k</annotation></semantics></math>-fold cross-validation technique to make the perplexity evaluation in-domain. We split the training data into <math alttext="k=5" class="ltx_Math" display="inline" id="S4.p2.2.m2.1"><semantics id="S4.p2.2.m2.1a"><mrow id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml"><mi id="S4.p2.2.m2.1.1.2" xref="S4.p2.2.m2.1.1.2.cmml">k</mi><mo id="S4.p2.2.m2.1.1.1" xref="S4.p2.2.m2.1.1.1.cmml">=</mo><mn id="S4.p2.2.m2.1.1.3" xref="S4.p2.2.m2.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><apply id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1"><eq id="S4.p2.2.m2.1.1.1.cmml" xref="S4.p2.2.m2.1.1.1"></eq><ci id="S4.p2.2.m2.1.1.2.cmml" xref="S4.p2.2.m2.1.1.2">𝑘</ci><cn id="S4.p2.2.m2.1.1.3.cmml" type="integer" xref="S4.p2.2.m2.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">k=5</annotation><annotation encoding="application/x-llamapun" id="S4.p2.2.m2.1d">italic_k = 5</annotation></semantics></math> folds and train <math alttext="k" class="ltx_Math" display="inline" id="S4.p2.3.m3.1"><semantics id="S4.p2.3.m3.1a"><mi id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><ci id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.p2.3.m3.1d">italic_k</annotation></semantics></math> models withholding one of the folds from each run. Then we score every sentence using the model that has not seen that sentence in training. Next, we sweep for acceptable threshold values by minimizing BLEU on the development set and report results in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S4.T3" title="Table 3 ‣ 4. Second Phase: Unsupervised Data Selection on Extended Multi30K ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">Table 3</span></a>. We plot the distribution of scores in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S4.F1" title="Figure 1 ‣ 4. Second Phase: Unsupervised Data Selection on Extended Multi30K ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">Figure 1</span></a>. We also provide threshold sweep results for training from base Mistral-7B-v0.1 checkpoint in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S11.T6" title="Table 6 ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">Table 6</span></a>. By comparing finetuned results, we demonstrate that data from the second phase alone is not enough to match the performance of our best checkpoint.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.2.1">Threshold</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.1">Examples</span></th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.1.1">
<span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1">BLEU</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.m1.1a"><mo id="S4.T3.1.1.1.m1.1.1" stretchy="false" xref="S4.T3.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.1.4"></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.3.1.1">percentile</th>
<th class="ltx_td ltx_th ltx_th_row" id="S4.T3.2.3.1.2"></th>
<td class="ltx_td ltx_align_left" id="S4.T3.2.3.1.3">dev</td>
<td class="ltx_td ltx_align_left" id="S4.T3.2.3.1.4">devtest</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.2.4.2.1">20<sup class="ltx_sup" id="S4.T3.2.4.2.1.1">th</sup>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.2.4.2.2">5800</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.2.4.2.3">31.57</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.2.4.2.4">32.06</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.5.3.1">40<sup class="ltx_sup" id="S4.T3.2.5.3.1.1">th</sup>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.5.3.2">11600</th>
<td class="ltx_td ltx_align_left" id="S4.T3.2.5.3.3">31.65</td>
<td class="ltx_td ltx_align_left" id="S4.T3.2.5.3.4">32.16</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.6.4.1">50<sup class="ltx_sup" id="S4.T3.2.6.4.1.1">th</sup>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.6.4.2">14500</th>
<td class="ltx_td ltx_align_left" id="S4.T3.2.6.4.3">31.76</td>
<td class="ltx_td ltx_align_left" id="S4.T3.2.6.4.4">32.36</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.7.5.1">60<sup class="ltx_sup" id="S4.T3.2.7.5.1.1">th</sup>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.7.5.2">17400</th>
<td class="ltx_td ltx_align_left" id="S4.T3.2.7.5.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.2.7.5.3.1">31.80</span></td>
<td class="ltx_td ltx_align_left" id="S4.T3.2.7.5.4"><span class="ltx_text ltx_font_bold" id="S4.T3.2.7.5.4.1">32.34</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.8.6.1">70<sup class="ltx_sup" id="S4.T3.2.8.6.1.1">th</sup>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.8.6.2">20300</th>
<td class="ltx_td ltx_align_left" id="S4.T3.2.8.6.3">31.51</td>
<td class="ltx_td ltx_align_left" id="S4.T3.2.8.6.4">32.17</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.9.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.9.7.1">80<sup class="ltx_sup" id="S4.T3.2.9.7.1.1">th</sup>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.9.7.2">23200</th>
<td class="ltx_td ltx_align_left" id="S4.T3.2.9.7.3">31.44</td>
<td class="ltx_td ltx_align_left" id="S4.T3.2.9.7.4">32.46</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.2.1">95.4<sup class="ltx_sup" id="S4.T3.2.2.1.1">th</sup> (<math alttext="2\sigma" class="ltx_Math" display="inline" id="S4.T3.2.2.1.m1.1"><semantics id="S4.T3.2.2.1.m1.1a"><mrow id="S4.T3.2.2.1.m1.1.1" xref="S4.T3.2.2.1.m1.1.1.cmml"><mn id="S4.T3.2.2.1.m1.1.1.2" xref="S4.T3.2.2.1.m1.1.1.2.cmml">2</mn><mo id="S4.T3.2.2.1.m1.1.1.1" xref="S4.T3.2.2.1.m1.1.1.1.cmml">⁢</mo><mi id="S4.T3.2.2.1.m1.1.1.3" xref="S4.T3.2.2.1.m1.1.1.3.cmml">σ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.1.m1.1b"><apply id="S4.T3.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.1.m1.1.1"><times id="S4.T3.2.2.1.m1.1.1.1.cmml" xref="S4.T3.2.2.1.m1.1.1.1"></times><cn id="S4.T3.2.2.1.m1.1.1.2.cmml" type="integer" xref="S4.T3.2.2.1.m1.1.1.2">2</cn><ci id="S4.T3.2.2.1.m1.1.1.3.cmml" xref="S4.T3.2.2.1.m1.1.1.3">𝜎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.1.m1.1c">2\sigma</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.1.m1.1d">2 italic_σ</annotation></semantics></math>)</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.2.2">28025</th>
<td class="ltx_td ltx_align_left" id="S4.T3.2.2.3">31.74</td>
<td class="ltx_td ltx_align_left" id="S4.T3.2.2.4">32.18</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.10.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.10.8.1">Full dataset</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.10.8.2">29000</th>
<td class="ltx_td ltx_align_left" id="S4.T3.2.10.8.3">31.45</td>
<td class="ltx_td ltx_align_left" id="S4.T3.2.10.8.4">32.04</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Extended Multi30K log probability thresholds swept on FLORES dev set. We choose the best checkpoint based on model performance on FLORES dev subset using grid search for optimal perplexity threshold value.
</figcaption>
</figure>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">5.   Few-Shot Translation</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Conditioning the model on a sequence of demonstrations of performing some task allows the model to learn this task in-context, also known as “few-shot learning” (e.g. <cite class="ltx_cite ltx_citemacro_citet">Brown et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib2" title="">2020</a>)</cite>), thanks to the ability of the Transformers to modulate representations of its future tokens using past context, implementing a specialized internal context-dependent learning algorithm inside its weights <cite class="ltx_cite ltx_citemacro_citep">(von Oswald et al., <a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib34" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">While few-shot learning allows to quickly try any task with a low number of demonstrations, <cite class="ltx_cite ltx_citemacro_citet">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib15" title="">2022</a>)</cite> have shown that parameter-efficient finetuning allows smaller models achieve better performance, effectively spending less floating point operations per test example at inference time.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">Setting up the model for finetuning requires a lot of work, and in-context learning allows to quickly probe capability of a large model using inference software that performs efficient management of key-value cache for speed <cite class="ltx_cite ltx_citemacro_cite">Kwon et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib14" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.1">To test backbone models before finetuning, we attempt decoding translations with a basic prompt shown in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S5.F2" title="Figure 2 ‣ 5. Few-Shot Translation ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">Figure 2</span></a>.</p>
</div>
<figure class="ltx_figure" id="S5.F2">
<p class="ltx_p" id="S5.F2.1">[INST] They are planning to host a party next weekend. [/INST] Вони планують провести вечірку наступного вікенду. 
<br class="ltx_break"/>[INST] I enjoy swimming in the ocean and feeling the salty breeze. [/INST] Мені подобається плавати в океані та відчувати солоний вітер. 
<br class="ltx_break"/>[INST]</p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Basic 2-shot prompt used for few-shot translation. <span class="ltx_text ltx_font_typewriter" id="S5.F2.4.1">[INST]</span> prefixes the beginning of the source sentence and <span class="ltx_text ltx_font_typewriter" id="S5.F2.5.2">[/INST]</span> denotes the beginning of the target translation. These separators are chosen arbitrarily (as in finetuning) and are not special vocabulary items, even though they bear visual resemblance to them.</figcaption>
</figure>
<div class="ltx_para" id="S5.p5">
<p class="ltx_p" id="S5.p5.1">We find that the model significantly underperforms compared to current state of the art translation models when using beam search <cite class="ltx_cite ltx_citemacro_citep">(Tillmann and Ney, <a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib33" title="">2003</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S5.p6">
<p class="ltx_p" id="S5.p6.1">This decoding algorithm performs pruned breadth-first expansion, scoring target sentence prefixes using model’s own log probability, approximating maximum a-posteriori estimation of the best translation.</p>
</div>
<div class="ltx_para" id="S5.p7">
<p class="ltx_p" id="S5.p7.1">Inspection of the n-best list of translation candidates (beams) reveals that the models can produce high-quality translations, however assign low probabilities to them. We find the best possible translation by rescoring beams using the BLEU score as a loss function <cite class="ltx_cite ltx_citemacro_citep">(Kumar and Byrne, <a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib13" title="">2004</a>)</cite> with respect to the reference translation (the so-called “oracle”).</p>
</div>
<div class="ltx_para" id="S5.p8">
<p class="ltx_p" id="S5.p8.1">We employ this oracle rescoring strategy to gauge the potential capability of the model to produce good translations without finetuning, and find that in a regime of increased computation (large width of the beam) and assuming perfect selection capability, a base model is competitive with specialized alternatives. We sweep over a grid of multiple beam widths and report highest attainable BLEU scores in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S5.T4" title="Table 4 ‣ 5. Few-Shot Translation ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">Table 4</span></a>.</p>
</div>
<figure class="ltx_table" id="S5.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T4.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S5.T4.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.2.1">Beams</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.1.1">Oracle BLEU <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T4.1.1.1.1.m1.1"><semantics id="S5.T4.1.1.1.1.m1.1a"><mo id="S5.T4.1.1.1.1.m1.1.1" stretchy="false" xref="S5.T4.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T4.1.1.1.1.m1.1b"><ci id="S5.T4.1.1.1.1.m1.1.1.cmml" xref="S5.T4.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.1.1.1.1.m1.1d">↑</annotation></semantics></math></span></th>
<td class="ltx_td ltx_border_t" id="S5.T4.1.1.3"></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.2.1">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T4.1.2.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T4.1.2.1.2">Mistral-7B-v.01</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T4.1.2.1.3">Llama 2 7B</th>
</tr>
<tr class="ltx_tr" id="S5.T4.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S5.T4.1.3.2.1">3</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.2.2">27.11</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.2.3">24.55</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T4.1.4.3.1">5</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.4.3.2">29.20</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.4.3.3">26.64</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.5.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T4.1.5.4.1">10</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.5.4.2">31.53</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.5.4.3">28.76</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.6.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T4.1.6.5.1">15</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.6.5.2">32.81</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.6.5.3">29.09</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.7.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T4.1.7.6.1">20</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.7.6.2">33.54</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.7.6.3">27.64</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.8.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T4.1.8.7.1">25</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.8.7.2">34.27</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.8.7.3">26.35</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.9.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T4.1.9.8.1">30</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.9.8.2">33.99</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.9.8.3"><span class="ltx_text" id="S5.T4.1.9.8.3.1" style="font-size:90%;">(decoder failure)</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.10.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T4.1.10.9.1">35</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.10.9.2">34.94</td>
<td class="ltx_td" id="S5.T4.1.10.9.3"></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.11.10">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b" id="S5.T4.1.11.10.1">40</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T4.1.11.10.2">34.61</td>
<td class="ltx_td ltx_border_b" id="S5.T4.1.11.10.3"></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>We establish the upper bound of the latent capability of pretrained base models to produce high quality translations with by varying beam width on the task of translating sentences from FLORES dev given a 2-shot prompt. The ground truth oracle determines the best beam. We use beam search implementation by <cite class="ltx_cite ltx_citemacro_citet">Kwon et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib14" title="">2023</a>)</cite> with presence penalty of 0.1.
The results do not improve monotonically with increasing beam size, and lengths of hypotheses grow with maximum beam size, yielding diminishing returns. This problem can be attributed to label bias <cite class="ltx_cite ltx_citemacro_cite">Murray and Chiang (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib20" title="">2018</a>)</cite>, and rectifying it will require extra regularization.</figcaption>
</figure>
<div class="ltx_para" id="S5.p9">
<p class="ltx_p" id="S5.p9.1">Consecutive sentences in FLORES are samples from the same document. We hypothesize, dynamically adjusting the prompt by inserting previous translations will improve results. We observe that the model indeed improves translation of certain words such as proper nouns through access to correct definitions provided in the context (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S5.F3" title="Figure 3 ‣ 5. Few-Shot Translation ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">Figure 3</span></a>), however its overall performance degrades in other examples.</p>
</div>
<figure class="ltx_figure" id="S5.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="S5.F3.1">Source:
<span class="ltx_text ltx_font_smallcaps ltx_framed ltx_framed_underline" id="S5.F3.1.1" style="font-size:90%;">RSPCA</span><span class="ltx_text ltx_font_smallcaps" id="S5.F3.1.2" style="font-size:90%;"> New South Wales chief inspector David O’Shannessy told the ABC that surveillance and inspections of abattoirs should be commonplace in Australia.</span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="S5.F3.2">Hypothesis given random 2-shot context: Головний інспектор <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.F3.2.1" style="color:#FF0000;">РСПКА</span><span class="ltx_text" id="S5.F3.2.2" style="color:#FF0000;"> Нового Південного Уельсу Девід О’Шеннесі повідомив ABC, що спостереження та інспекції аббатств повинні бути звичайним явищем в Австралії.</span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="S5.F3.3">Context example: <span class="ltx_text ltx_font_smallcaps" id="S5.F3.3.1" style="font-size:90%;">[INST] Animal Liberation and the <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.F3.3.1.1">Royal Society for the Prevention of Cruelty</span> <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.F3.3.1.2">to Animals</span> <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.F3.3.1.3">(RSPCA)</span> are again calling for the mandatory installation of CCTV cameras in all Australian abattoirs. [/INST]<span class="ltx_text ltx_font_upright" id="S5.F3.3.1.4"> Організація Звільнення тварин і <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.F3.3.1.4.1">Королівське товариство із запобігання</span> <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.F3.3.1.4.2">жорстокому поводженню з тваринами</span> <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.F3.3.1.4.3">(КТЗЖПТ)</span> знову закликають до обов’язкової установки камер спостереження на всіх австралійських бійнях.</span></span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="S5.F3.4">Hypothesis given relevant 2-shot context: <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.F3.4.1" style="font-size:90%;">Головний інспектор Королівського товариства</span><span class="ltx_text" id="S5.F3.4.2" style="font-size:90%;"> <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.F3.4.2.1">із запобігання жорстокому поводженню з тваринами</span> <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.F3.4.2.2" style="color:#0000FF;">(КТЗЖПТ)</span><span class="ltx_text" id="S5.F3.4.2.3" style="color:#0000FF;"> Нового Південного Уельсу Девід О’Шеннесі заявив, що спостереження та інспекції бійні повинні бути поширеними в Австралії.</span></span></p>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Few-shot translation with contextual prompting allows the model to learn named entities on the fly. Without context, the model makes a wrong guess trying to transliterate the abbreviation.</figcaption>
</figure>
<div class="ltx_para" id="S5.p10">
<p class="ltx_p" id="S5.p10.1">We additionally attempt basic 0-shot with a system prompt <span class="ltx_text ltx_font_typewriter" id="S5.p10.1.1">You translate English sentences into native Ukrainian.</span>, and 10-shot prompting using automatic prompt selection based on similarity between source sentences experiments with GPT-4 and GPT-4 Turbo and find that commerical systems perform similarly to other open source systems, as shown in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S1.T1" title="Table 1 ‣ 1. Introduction ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">Table 1</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">6.   Discussion and Limitations</h2>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px1">
<h3 class="ltx_title ltx_title_paragraph">Single-sentence translation</h3>
<div class="ltx_para" id="S6.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px1.p1.1">Our system is trained on demonstrations of standalone sentence pairs.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px2">
<h3 class="ltx_title ltx_title_paragraph">Decoder-only models with long context windows</h3>
<div class="ltx_para" id="S6.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px2.p1.1">We choose to finetune existing decoder-only models since the choice of models with almost the same architecture but different massive pretraining data is abundant. The number of open-source models released recently and their constant improvement offers a good prospective for the machine translation tasks.</p>
</div>
<div class="ltx_para" id="S6.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S6.SS0.SSS0.Px2.p2.1">These models receive gradient from all outputs during pretraining, and the self-attention mechanism can see the input, the partial output, and access past examples of translations in its context window using induction heads <cite class="ltx_cite ltx_citemacro_citep">(Olsson et al., <a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib21" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S6.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="S6.SS0.SSS0.Px2.p3.1">For efficiency, we only train on examples with single short sentence pairs and do not pack context windows full of tokens as done in pretraining. In our early experiments, we find that our models still generalize to inputs longer that what is seen in training. This generalization behavior is often attributed to relative position embeddings <cite class="ltx_cite ltx_citemacro_cite">Dai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib4" title="">2019</a>); Csordás et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib3" title="">2021</a>)</cite>. We leave evaluation of long context attention stability under these conditions for future work.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px3">
<h3 class="ltx_title ltx_title_paragraph">Training on the noisy dataset</h3>
<div class="ltx_para" id="S6.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px3.p1.1">Data cleaning has a positive effect on the resulting metrics. However, our models trained on 8 million filtered, examples perform worse than models trained on 3 million examples (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S2.T2" title="Table 2 ‣ 2. Supervised Finetuning ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">Table 2</span></a>).</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px4">
<h3 class="ltx_title ltx_title_paragraph">Tokenizer performance</h3>
<div class="ltx_para" id="S6.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px4.p1.1">We used the LLaMA and Mistral tokenizers during our experiments, which use at least twice as many tokens to compress a sentence in Ukrainian of the same length as an English sentence in character. In practice, that means that generating a sentence in Ukrainian takes at least twice as many steps to generate. We show a distribution of sentence token lengths in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S6.F4" title="Figure 4 ‣ Tokenizer performance ‣ 6. Discussion and Limitations ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">Figure 4</span></a>.</p>
</div>
<figure class="ltx_figure" id="S6.F4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="243" id="S6.F4.g1" src="x2.png" width="427"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Comparison of tokenizer compression rates between English and Ukrainian using the Mistral-7B tokenizer on the FLORES dev set.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px5">
<h3 class="ltx_title ltx_title_paragraph">Evaluation</h3>
<div class="ltx_para" id="S6.SS0.SSS0.Px5.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px5.p1.1">We choose BLEU-4 score <cite class="ltx_cite ltx_citemacro_cite">Papineni et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib22" title="">2002</a>)</cite> as our core evaluation metric and model selection criterion. BLEU-4 measures 4-gram precisions, where grams are defined as words. We use the implementation and rely on tokenization decisions of <cite class="ltx_cite ltx_citemacro_citet">Post (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib23" title="">2018</a>)</cite>. This metric is sensitive to minor differences that do not affect the meaning of the sentence, for example case inflections that tend to cascade to multiple adjacent words. BLEU is known to poorly correlate with human judgement of translation quality, and <cite class="ltx_cite ltx_citemacro_citet">Freitag et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib7" title="">2022</a>)</cite> recommend learned metrics.</p>
</div>
<div class="ltx_para" id="S6.SS0.SSS0.Px5.p2">
<p class="ltx_p" id="S6.SS0.SSS0.Px5.p2.1">Choosing an appropriate learned metric for judgements of translation quality of Ukrainian requires careful consideration, and incorporation of data informed by the language community, such as a curated corpus of grammar corrections that reflects proper modern use of language <cite class="ltx_cite ltx_citemacro_cite">Syvokon et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib29" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S6.SS0.SSS0.Px5.p3">
<p class="ltx_p" id="S6.SS0.SSS0.Px5.p3.1">Regardless of limitations of BLEU, improvement in BLEU still signals improvement in translation quality in our regime.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px6">
<h3 class="ltx_title ltx_title_paragraph">WMT22</h3>
<div class="ltx_para" id="S6.SS0.SSS0.Px6.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px6.p1.1">Our reviewers have pointed out that WMT22 benchmark <cite class="ltx_cite ltx_citemacro_cite">Kocmi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib12" title="">2022</a>)</cite> includes a test set for Ukrainian. Our model achieves 24.72 on the WMT22 test set without any postprocessing, ranking behind the best result of <cite class="ltx_cite ltx_citemacro_citet">Roussis and Papavassiliou (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib25" title="">2022</a>)</cite> at 25.2 BLEU. We note that the submission that scores relatively low on the WMT22 test, scores comparably to our results on FLORES. These data distribution properties require closer exploration.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">7.   Related Work</h2>
<section class="ltx_paragraph" id="S7.SS0.SSS0.Px1">
<h3 class="ltx_title ltx_title_paragraph">Translation to Ukrainian</h3>
<div class="ltx_para" id="S7.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S7.SS0.SSS0.Px1.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Maksymenko et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib17" title="">2023a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib18" title="">b</a>)</cite> explore translation controllability by conditioning the model on text embeddings that encode style by finetuning an encoder-decoder model. They claim high quality translations on a private test set.</p>
</div>
</section>
<section class="ltx_paragraph" id="S7.SS0.SSS0.Px2">
<h3 class="ltx_title ltx_title_paragraph">Instruction-tuned language models</h3>
<div class="ltx_para" id="S7.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S7.SS0.SSS0.Px2.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Üstün et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib36" title="">2024</a>)</cite> explore large-scale translation efforts to produce a multilingual instruction-tuned language model Aya. This work translates large datasets like the Flan Collection <cite class="ltx_cite ltx_citemacro_citep">(Longpre et al., <a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib16" title="">2023</a>)</cite> using the NLLB-3B model <cite class="ltx_cite ltx_citemacro_citep">(Team et al., <a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib30" title="">2022</a>)</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S7.SS0.SSS0.Px3">
<h3 class="ltx_title ltx_title_paragraph">Translation systems</h3>
<div class="ltx_para" id="S7.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S7.SS0.SSS0.Px3.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Han et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib9" title="">2021</a>)</cite> provide an iterated backtranslation recipe to bootstrap neural machine translation systems using generative models: zero-shot translation ability is used to produce candidates for few-shot demonstrations. Filtered few-shot demonstrations are used to sample new sentences for further finetuning for translation in two directions.</p>
</div>
</section>
<section class="ltx_paragraph" id="S7.SS0.SSS0.Px4">
<h3 class="ltx_title ltx_title_paragraph">Translation benchmarks</h3>
<div class="ltx_para" id="S7.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S7.SS0.SSS0.Px4.p1.1">Besides FLORES-101 (<cite class="ltx_cite ltx_citemacro_citet">Goyal et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib8" title="">2022</a>)</cite>, or FLORES-200 <cite class="ltx_cite ltx_citemacro_citep">(Team et al., <a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib30" title="">2022</a>)</cite>, both include the same data for Ukrainian) dataset used in this work, <cite class="ltx_cite ltx_citemacro_citet">Tiedemann (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib31" title="">2020</a>)</cite> provides an additional dataset for multilingual evaluation.</p>
</div>
</section>
<section class="ltx_paragraph" id="S7.SS0.SSS0.Px5">
<h3 class="ltx_title ltx_title_paragraph">Data selection techniques</h3>
<div class="ltx_para" id="S7.SS0.SSS0.Px5.p1">
<p class="ltx_p" id="S7.SS0.SSS0.Px5.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Yang and Li (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib35" title="">2023</a>)</cite> propose a perplexity filtering pipeline, in which the data is split into k folds to classify low quality augmentation generations produced by surrogate language models. <cite class="ltx_cite ltx_citemacro_citet">Sachdeva et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.15196v2#bib.bib26" title="">2024</a>)</cite> provide recipes on curating data for language models by directly asking language models to score examples.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">8.   Conclusion</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">In this work, we build a translation system using a two-phase data cleaning pipeline. We demonstrate matching performance to state-of-the-art encoder-decoder models for English-Ukrainian translation task. Notably, our system exhibits superior performance compared to the NLLB model, which was instrumental in generating the Aya dataset and contributed significantly to the advancement of multilingual language models. Improved machine translation could bring new capabilities to the next generation of large language models trained for the Ukrainian language. The recent improvements made for decoder-only backbones and the general dynamics of this process encourages us: we firmly believe that recipes we propose in this paper can be used to improve the quality of the translation by simply upgrading the backbone model.</p>
</div>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">9.   Contributions</h2>
<div class="ltx_para" id="S9.p1">
<p class="ltx_p" id="S9.p1.1">Yurii Paniv worked on unsupervised data selection on extended Multi30K dataset, Dmytro Chaplynskyi performed initial training using heuristic filtering of Paracrawl, Nikita Trynus worked on evaluation, Volodymyr Kyrylov designed few-shot learning experiments and evaluation.</p>
</div>
</section>
<section class="ltx_section" id="S10">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">10.   Acknowledgements</h2>
<div class="ltx_para" id="S10.p1">
<p class="ltx_p" id="S10.p1.1">The authors would like to thank Talents for Ukraine project of Kyiv School of Economics for the grant on compute, used for this paper, Ukrainian Catholic University, Roman Kyslyi, and Oleksii Turuta for the fruitful discussions and inspiration. We would also like to thank paper reviewers for their comments.</p>
</div>
</section>
<section class="ltx_section" id="S11">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">11.   References</h2>
<div class="ltx_para" id="S11.p1">
<span class="ltx_ERROR undefined" id="S11.p1.1">\c@NAT@ctr</span>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography"></h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bañón et al. (2020)</span>
<span class="ltx_bibblock">
Marta Bañón, Pinzhen Chen, Barry Haddow, Kenneth Heafield, Hieu Hoang, Miquel Esplà-Gomis, Mikel L. Forcada, Amir Kamran, Faheem Kirefu, Philipp Koehn, Sergio Ortiz Rojas, Leopoldo Pla Sempere, Gema Ramírez-Sánchez, Elsa Sarrías, Marek Strelec, Brian Thompson, William Waites, Dion Wiggins, and Jaume Zaragoza. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.417" title="">ParaCrawl: Web-scale acquisition of parallel corpora</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 4555–4567, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2020)</span>
<span class="ltx_bibblock">
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2005.14165" title="">Language models are few-shot learners</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Csordás et al. (2021)</span>
<span class="ltx_bibblock">
Róbert Csordás, Kazuki Irie, and Juergen Schmidhuber. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.emnlp-main.49" title="">The devil is in the detail: Simple tricks improve systematic generalization of transformers</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pages 619–634, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al. (2019)</span>
<span class="ltx_bibblock">
Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc Le, and Ruslan Salakhutdinov. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P19-1285" title="">Transformer-XL: Attentive language models beyond a fixed-length context</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, pages 2978–2988, Florence, Italy. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers et al. (2023)</span>
<span class="ltx_bibblock">
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/1feb87871436031bdc0f2beaa62a049b-Paper-Conference.pdf" title="">Qlora: Efficient finetuning of quantized llms</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Advances in Neural Information Processing Systems</em>, volume 36, pages 10088–10115. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al. (2022)</span>
<span class="ltx_bibblock">
Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen Arivazhagan, and Wei Wang. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2007.01852" title="">Language-agnostic bert sentence embedding</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag et al. (2022)</span>
<span class="ltx_bibblock">
Markus Freitag, Ricardo Rei, Nitika Mathur, Chi-kiu Lo, Craig Stewart, Eleftherios Avramidis, Tom Kocmi, George Foster, Alon Lavie, and André F. T. Martins. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.2" title="">Results of WMT22 metrics shared task: Stop using BLEU – neural metrics are better and more robust</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</em>, pages 46–68, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goyal et al. (2022)</span>
<span class="ltx_bibblock">
Naman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng-Jen Chen, Guillaume Wenzek, Da Ju, Sanjana Krishnan, Marc’Aurelio Ranzato, Francisco Guzmán, and Angela Fan. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1162/tacl_a_00474" title="">The Flores-101 evaluation benchmark for low-resource and multilingual machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Transactions of the Association for Computational Linguistics</em>, 10:522–538.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al. (2021)</span>
<span class="ltx_bibblock">
Jesse Michael Han, Igor Babuschkin, Harrison Edwards, Arvind Neelakantan, Tao Xu, Stanislas Polu, Alex Ray, Pranav Shyam, Aditya Ramesh, Alec Radford, and Ilya Sutskever. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:238583718" title="">Unsupervised neural machine translation with generative language models only</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">ArXiv</em>, abs/2110.05448.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2022)</span>
<span class="ltx_bibblock">
Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=nZeVKeeFYf9" title="">LoRA: Low-rank adaptation of large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023)</span>
<span class="ltx_bibblock">
Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2310.06825" title="">Mistral 7b</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocmi et al. (2022)</span>
<span class="ltx_bibblock">
Tom Kocmi, Rachel Bawden, Ondřej Bojar, Anton Dvorkovich, Christian Federmann, Mark Fishel, Thamme Gowda, Yvette Graham, Roman Grundkiewicz, Barry Haddow, Rebecca Knowles, Philipp Koehn, Christof Monz, Makoto Morishita, Masaaki Nagata, Toshiaki Nakazawa, Michal Novák, Martin Popel, and Maja Popović. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.1" title="">Findings of the 2022 conference on machine translation (WMT22)</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</em>, pages 1–45, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar and Byrne (2004)</span>
<span class="ltx_bibblock">
Shankar Kumar and William Byrne. 2004.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/N04-1022" title="">Minimum Bayes-risk decoding for statistical machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004</em>, pages 169–176, Boston, Massachusetts, USA. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwon et al. (2023)</span>
<span class="ltx_bibblock">
Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2309.06180" title="">Efficient memory management for large language model serving with PagedAttention</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2022)</span>
<span class="ltx_bibblock">
Haokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal, and Colin Raffel. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2205.05638" title="">Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Longpre et al. (2023)</span>
<span class="ltx_bibblock">
Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V Le, Barret Zoph, Jason Wei, et al. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2301.13688" title="">The Flan Collection: Designing Data and Methods for Effective Instruction Tuning</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2301.13688</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maksymenko et al. (2023a)</span>
<span class="ltx_bibblock">
Daniil Maksymenko, Nataliia Saichyshyna, Oleksii Turuta, Marcin Paprzycki, Maria Ganzha, and Mirela Alhasani. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:264108506" title="">Controllability for english-ukrainian machine translation by using style transfer techniques</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">2023 18th Conference on Computer Science and Intelligence Systems (FedCSIS)</em>, pages 1059–1068.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maksymenko et al. (2023b)</span>
<span class="ltx_bibblock">
Daniil Maksymenko, Olena Turuta, Nataliia Saichyshyna, Maksym Yerokhin, and Oleksii Turuta. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.multi3generation-1.1" title="">Controllability for English-Ukrainian machine translation based on specialized corpora</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the 1st International Workshop on Multilingual, Multimodal and Multitask Language Generation</em>, pages 1–9, Tampere, Finland. European Association for Machine Translation.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Minixhofer et al. (2022)</span>
<span class="ltx_bibblock">
Benjamin Minixhofer, Fabian Paischer, and Navid Rekabsaz. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.naacl-main.293" title="">WECHSEL: Effective initialization of subword embeddings for cross-lingual transfer of monolingual language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 3992–4006, Seattle, United States. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Murray and Chiang (2018)</span>
<span class="ltx_bibblock">
Kenton Murray and David Chiang. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W18-6322" title="">Correcting length bias in neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proceedings of the Third Conference on Machine Translation: Research Papers</em>, pages 212–223, Brussels, Belgium. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Olsson et al. (2022)</span>
<span class="ltx_bibblock">
Catherine Olsson, Nelson Elhage, Neel Nanda, Nicholas Joseph, Nova DasSarma, Tom Henighan, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Dawn Drain, Deep Ganguli, Zac Hatfield-Dodds, Danny Hernandez, Scott Johnston, Andy Jones, Jackson Kernion, Liane Lovitt, Kamal Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCandlish, and Chris Olah. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html" title="">In-context learning and induction heads</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Transformer Circuits Thread</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al. (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3115/1073083.1073135" title="">BLEU: a method for automatic evaluation of machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</em>, pages 311–318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Post (2018)</span>
<span class="ltx_bibblock">
Matt Post. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.aclweb.org/anthology/W18-6319" title="">A call for clarity in reporting BLEU scores</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the Third Conference on Machine Translation: Research Papers</em>, pages 186–191, Belgium, Brussels. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" title="">Language models are unsupervised multitask learners</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roussis and Papavassiliou (2022)</span>
<span class="ltx_bibblock">
Dimitrios Roussis and Vassilis Papavassiliou. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.31" title="">The ARC-NKUA submission for the English-Ukrainian general machine translation shared task at WMT22</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</em>, pages 358–365, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sachdeva et al. (2024)</span>
<span class="ltx_bibblock">
Noveen Sachdeva, Benjamin Coleman, Wang-Cheng Kang, Jianmo Ni, Lichan Hong, Ed H. Chi, James Caverlee, Julian McAuley, and Derek Zhiyuan Cheng. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2402.09668" title="">How to train data-efficient llms</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saichyshyna et al. (2023)</span>
<span class="ltx_bibblock">
Nataliia Saichyshyna, Daniil Maksymenko, Oleksii Turuta, Andriy Yerokhin, Andrii Babii, and Olena Turuta. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.unlp-1.7" title="">Extension Multi30K: Multimodal dataset for integrated vision and language research in Ukrainian</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the Second Ukrainian Natural Language Processing Workshop (UNLP)</em>, pages 54–61, Dubrovnik, Croatia. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Srivastava et al. (2014)</span>
<span class="ltx_bibblock">
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://jmlr.org/papers/v15/srivastava14a.html" title="">Dropout: A simple way to prevent neural networks from overfitting</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Journal of Machine Learning Research</em>, 15(56):1929–1958.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Syvokon et al. (2023)</span>
<span class="ltx_bibblock">
Oleksiy Syvokon, Olena Nahorna, Pavlo Kuchmiichuk, and Nastasiia Osidach. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.unlp-1.12" title="">UA-GEC: Grammatical error correction and fluency corpus for the Ukrainian language</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the Second Ukrainian Natural Language Processing Workshop (UNLP)</em>, pages 96–102, Dubrovnik, Croatia. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et al. (2022)</span>
<span class="ltx_bibblock">
NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, and Jeff Wang. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2207.04672" title="">No language left behind: Scaling human-centered machine translation</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tiedemann (2020)</span>
<span class="ltx_bibblock">
Jörg Tiedemann. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2020.wmt-1.139" title="">The tatoeba translation challenge – realistic data sets for low resource and multilingual MT</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proceedings of the Fifth Conference on Machine Translation</em>, pages 1174–1182, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tiedemann and Thottingal (2020)</span>
<span class="ltx_bibblock">
Jörg Tiedemann and Santhosh Thottingal. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2020.eamt-1.61" title="">OPUS-MT – building open translation services for the world</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Proceedings of the 22nd Annual Conference of the European Association for Machine Translation</em>, pages 479–480, Lisboa, Portugal. European Association for Machine Translation.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tillmann and Ney (2003)</span>
<span class="ltx_bibblock">
Christoph Tillmann and Hermann Ney. 2003.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1162/089120103321337458" title="">Word Reordering and a Dynamic Programming Beam Search Algorithm for Statistical Machine Translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Computational Linguistics</em>, 29(1):97–133.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">von Oswald et al. (2023)</span>
<span class="ltx_bibblock">
Johannes von Oswald, Eyvind Niklasson, Ettore Randazzo, João Sacramento, Alexander Mordvintsev, Andrey Zhmoginov, and Max Vladymyrov. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2212.07677" title="">Transformers learn in-context by gradient descent</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang and Li (2023)</span>
<span class="ltx_bibblock">
Heng Yang and Ke Li. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.findings-acl.105" title="">Boosting text augmentation via hybrid instance filtering framework</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Findings of the Association for Computational Linguistics: ACL 2023</em>, pages 1652–1669, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Üstün et al. (2024)</span>
<span class="ltx_bibblock">
Ahmet Üstün, Viraat Aryabumi, Zheng-Xin Yong, Wei-Yin Ko, Daniel D’souza, Gbemileke Onilude, Neel Bhandari, Shivalika Singh, Hui-Lee Ooi, Amr Kayid, Freddie Vargus, Phil Blunsom, Shayne Longpre, Niklas Muennighoff, Marzieh Fadaee, Julia Kreutzer, and Sara Hooker. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2402.07827" title="">Aya model: An instruction finetuned open-access multilingual language model</a>.

</span>
</li>
</ul>
</section>
<figure class="ltx_table" id="S11.T5">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S11.T5.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S11.T5.1.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S11.T5.1.1.2"><span class="ltx_text ltx_font_bold" id="S11.T5.1.1.2.1">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S11.T5.1.1.1">
<span class="ltx_text ltx_font_bold" id="S11.T5.1.1.1.1">BLEU</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S11.T5.1.1.1.m1.1"><semantics id="S11.T5.1.1.1.m1.1a"><mo id="S11.T5.1.1.1.m1.1.1" stretchy="false" xref="S11.T5.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S11.T5.1.1.1.m1.1b"><ci id="S11.T5.1.1.1.m1.1.1.cmml" xref="S11.T5.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S11.T5.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S11.T5.1.1.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S11.T5.1.1.3"><span class="ltx_text ltx_font_bold" id="S11.T5.1.1.3.1">spBLEU</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S11.T5.1.1.4"><span class="ltx_text ltx_font_bold" id="S11.T5.1.1.4.1">chrF</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S11.T5.1.1.5"><span class="ltx_text ltx_font_bold" id="S11.T5.1.1.5.1">chrF++</span></td>
</tr>
<tr class="ltx_tr" id="S11.T5.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S11.T5.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S11.T5.1.2.1.1.1">Finetuned</span></td>
<td class="ltx_td ltx_border_t" id="S11.T5.1.2.1.2"></td>
<td class="ltx_td ltx_border_t" id="S11.T5.1.2.1.3"></td>
<td class="ltx_td ltx_border_t" id="S11.T5.1.2.1.4"></td>
<td class="ltx_td ltx_border_t" id="S11.T5.1.2.1.5"></td>
</tr>
<tr class="ltx_tr" id="S11.T5.1.3.2">
<td class="ltx_td ltx_align_left" id="S11.T5.1.3.2.1">Dragoman P, 10 beams (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S3" title="3. First Phase: Heuristic Filtering of Paracrawl ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">section 3</span></a>)</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.3.2.2">30.38</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.3.2.3">37.93</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.3.2.4">59.49</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.3.2.5">56.41</td>
</tr>
<tr class="ltx_tr" id="S11.T5.1.4.3">
<td class="ltx_td ltx_align_left" id="S11.T5.1.4.3.1">Dragoman PT, 10 beams (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S4" title="4. Second Phase: Unsupervised Data Selection on Extended Multi30K ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">section 4</span></a>)</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.4.3.2"><span class="ltx_text ltx_font_bold" id="S11.T5.1.4.3.2.1">32.34</span></td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.4.3.3"><span class="ltx_text ltx_font_bold" id="S11.T5.1.4.3.3.1">39.93</span></td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.4.3.4"><span class="ltx_text ltx_font_bold" id="S11.T5.1.4.3.4.1">60.72</span></td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.4.3.5"><span class="ltx_text ltx_font_bold" id="S11.T5.1.4.3.5.1">57.82</span></td>
</tr>
<tr class="ltx_tr" id="S11.T5.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S11.T5.1.5.4.1">
<span class="ltx_text ltx_font_bold" id="S11.T5.1.5.4.1.1">Zero shot and few shot</span> (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2404.15196v2#S5" title="5. Few-Shot Translation ‣ Setting up the Data Printer with Improved English to Ukrainian Machine Translation"><span class="ltx_text ltx_ref_tag">section 5</span></a>)</td>
<td class="ltx_td ltx_border_t" id="S11.T5.1.5.4.2"></td>
<td class="ltx_td ltx_border_t" id="S11.T5.1.5.4.3"></td>
<td class="ltx_td ltx_border_t" id="S11.T5.1.5.4.4"></td>
<td class="ltx_td ltx_border_t" id="S11.T5.1.5.4.5"></td>
</tr>
<tr class="ltx_tr" id="S11.T5.1.6.5">
<td class="ltx_td ltx_align_left" id="S11.T5.1.6.5.1">LLaMa-2-7B 2-shot</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.6.5.2">20.1</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.6.5.3">26.78</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.6.5.4">49.22</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.6.5.5">46.29</td>
</tr>
<tr class="ltx_tr" id="S11.T5.1.7.6">
<td class="ltx_td ltx_align_left" id="S11.T5.1.7.6.1">RWKV-5-World-7B 0-shot</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.7.6.2">21.06</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.7.6.3">26.20</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.7.6.4">49.46</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.7.6.5">46.46</td>
</tr>
<tr class="ltx_tr" id="S11.T5.1.8.7">
<td class="ltx_td ltx_align_left" id="S11.T5.1.8.7.1">gpt-4 10-shot</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.8.7.2">29.48</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.8.7.3">37.94</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.8.7.4">58.37</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.8.7.5">55.38</td>
</tr>
<tr class="ltx_tr" id="S11.T5.1.9.8">
<td class="ltx_td ltx_align_left" id="S11.T5.1.9.8.1">gpt-4-turbo-preview 0-shot</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.9.8.2">30.36</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.9.8.3">36.75</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.9.8.4">59.18</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.9.8.5">56.19</td>
</tr>
<tr class="ltx_tr" id="S11.T5.1.10.9">
<td class="ltx_td ltx_align_left" id="S11.T5.1.10.9.1">Google Translate 0-shot</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.10.9.2">25.85</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.10.9.3">32.49</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.10.9.4">55.88</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.10.9.5">52.48</td>
</tr>
<tr class="ltx_tr" id="S11.T5.1.11.10">
<td class="ltx_td ltx_align_left ltx_border_t" id="S11.T5.1.11.10.1"><span class="ltx_text ltx_font_bold" id="S11.T5.1.11.10.1.1">Pretrained</span></td>
<td class="ltx_td ltx_border_t" id="S11.T5.1.11.10.2"></td>
<td class="ltx_td ltx_border_t" id="S11.T5.1.11.10.3"></td>
<td class="ltx_td ltx_border_t" id="S11.T5.1.11.10.4"></td>
<td class="ltx_td ltx_border_t" id="S11.T5.1.11.10.5"></td>
</tr>
<tr class="ltx_tr" id="S11.T5.1.12.11">
<td class="ltx_td ltx_align_left" id="S11.T5.1.12.11.1">NLLB 3B, 10 beams</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.12.11.2">30.46</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.12.11.3">37.22</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.12.11.4">58.11</td>
<td class="ltx_td ltx_align_left" id="S11.T5.1.12.11.5">55.32</td>
</tr>
<tr class="ltx_tr" id="S11.T5.1.13.12">
<td class="ltx_td ltx_align_left ltx_border_b" id="S11.T5.1.13.12.1">OPUS-MT, 10 beams</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S11.T5.1.13.12.2">32.2</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S11.T5.1.13.12.3">39.76</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S11.T5.1.13.12.4">60.23</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S11.T5.1.13.12.5">57.38</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>We evaluate generated translations with the sacrebleu library to calculate BLEU, spBLEU, chrF, and chrF++ metrics on the FLORES DEVTEST set. Metric spBLEU was calculated with default BLEU values and tokenizer flores101. Tokenization and detokenization are done using the models’ default tokenizers. Evaluation is performed on detokenized sentences with corresponding reference sentences.</figcaption>
</figure>
<figure class="ltx_table" id="S11.T6">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S11.T6.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S11.T6.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S11.T6.1.1.2"><span class="ltx_text ltx_font_bold" id="S11.T6.1.1.2.1">Threshold</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S11.T6.1.1.3"><span class="ltx_text ltx_font_bold" id="S11.T6.1.1.3.1">Examples</span></th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S11.T6.1.1.1">
<span class="ltx_text ltx_font_bold" id="S11.T6.1.1.1.1">BLEU</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S11.T6.1.1.1.m1.1"><semantics id="S11.T6.1.1.1.m1.1a"><mo id="S11.T6.1.1.1.m1.1.1" stretchy="false" xref="S11.T6.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S11.T6.1.1.1.m1.1b"><ci id="S11.T6.1.1.1.m1.1.1.cmml" xref="S11.T6.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S11.T6.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S11.T6.1.1.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_border_t" id="S11.T6.1.1.4"></td>
</tr>
<tr class="ltx_tr" id="S11.T6.2.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S11.T6.2.3.1.1">percentile</th>
<th class="ltx_td ltx_th ltx_th_row" id="S11.T6.2.3.1.2"></th>
<td class="ltx_td ltx_align_left" id="S11.T6.2.3.1.3">dev</td>
<td class="ltx_td ltx_align_left" id="S11.T6.2.3.1.4">devtest</td>
</tr>
<tr class="ltx_tr" id="S11.T6.2.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S11.T6.2.4.2.1">20<sup class="ltx_sup" id="S11.T6.2.4.2.1.1">th</sup>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S11.T6.2.4.2.2">5800</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S11.T6.2.4.2.3">25.14</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S11.T6.2.4.2.4">25.49</td>
</tr>
<tr class="ltx_tr" id="S11.T6.2.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S11.T6.2.5.3.1">40<sup class="ltx_sup" id="S11.T6.2.5.3.1.1">th</sup>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S11.T6.2.5.3.2">11600</th>
<td class="ltx_td ltx_align_left" id="S11.T6.2.5.3.3">25.39</td>
<td class="ltx_td ltx_align_left" id="S11.T6.2.5.3.4">25.45</td>
</tr>
<tr class="ltx_tr" id="S11.T6.2.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S11.T6.2.6.4.1">50<sup class="ltx_sup" id="S11.T6.2.6.4.1.1">th</sup>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S11.T6.2.6.4.2">14500</th>
<td class="ltx_td ltx_align_left" id="S11.T6.2.6.4.3">25.79</td>
<td class="ltx_td ltx_align_left" id="S11.T6.2.6.4.4">25.93</td>
</tr>
<tr class="ltx_tr" id="S11.T6.2.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S11.T6.2.7.5.1">60<sup class="ltx_sup" id="S11.T6.2.7.5.1.1">th</sup>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S11.T6.2.7.5.2">17400</th>
<td class="ltx_td ltx_align_left" id="S11.T6.2.7.5.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S11.T6.2.7.5.3.1">26.07</span></td>
<td class="ltx_td ltx_align_left" id="S11.T6.2.7.5.4"><span class="ltx_text ltx_font_bold" id="S11.T6.2.7.5.4.1">26.01</span></td>
</tr>
<tr class="ltx_tr" id="S11.T6.2.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S11.T6.2.8.6.1">70<sup class="ltx_sup" id="S11.T6.2.8.6.1.1">th</sup>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S11.T6.2.8.6.2">20300</th>
<td class="ltx_td ltx_align_left" id="S11.T6.2.8.6.3">26.00</td>
<td class="ltx_td ltx_align_left" id="S11.T6.2.8.6.4">25.72</td>
</tr>
<tr class="ltx_tr" id="S11.T6.2.9.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S11.T6.2.9.7.1">80<sup class="ltx_sup" id="S11.T6.2.9.7.1.1">th</sup>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S11.T6.2.9.7.2">23200</th>
<td class="ltx_td ltx_align_left" id="S11.T6.2.9.7.3">25.90</td>
<td class="ltx_td ltx_align_left" id="S11.T6.2.9.7.4">26.08</td>
</tr>
<tr class="ltx_tr" id="S11.T6.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S11.T6.2.2.1">95.4<sup class="ltx_sup" id="S11.T6.2.2.1.1">th</sup> (<math alttext="2\sigma" class="ltx_Math" display="inline" id="S11.T6.2.2.1.m1.1"><semantics id="S11.T6.2.2.1.m1.1a"><mrow id="S11.T6.2.2.1.m1.1.1" xref="S11.T6.2.2.1.m1.1.1.cmml"><mn id="S11.T6.2.2.1.m1.1.1.2" xref="S11.T6.2.2.1.m1.1.1.2.cmml">2</mn><mo id="S11.T6.2.2.1.m1.1.1.1" xref="S11.T6.2.2.1.m1.1.1.1.cmml">⁢</mo><mi id="S11.T6.2.2.1.m1.1.1.3" xref="S11.T6.2.2.1.m1.1.1.3.cmml">σ</mi></mrow><annotation-xml encoding="MathML-Content" id="S11.T6.2.2.1.m1.1b"><apply id="S11.T6.2.2.1.m1.1.1.cmml" xref="S11.T6.2.2.1.m1.1.1"><times id="S11.T6.2.2.1.m1.1.1.1.cmml" xref="S11.T6.2.2.1.m1.1.1.1"></times><cn id="S11.T6.2.2.1.m1.1.1.2.cmml" type="integer" xref="S11.T6.2.2.1.m1.1.1.2">2</cn><ci id="S11.T6.2.2.1.m1.1.1.3.cmml" xref="S11.T6.2.2.1.m1.1.1.3">𝜎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S11.T6.2.2.1.m1.1c">2\sigma</annotation><annotation encoding="application/x-llamapun" id="S11.T6.2.2.1.m1.1d">2 italic_σ</annotation></semantics></math>)</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S11.T6.2.2.2">28025</th>
<td class="ltx_td ltx_align_left" id="S11.T6.2.2.3">25.91</td>
<td class="ltx_td ltx_align_left" id="S11.T6.2.2.4">25.81</td>
</tr>
<tr class="ltx_tr" id="S11.T6.2.10.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S11.T6.2.10.8.1">Full dataset</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S11.T6.2.10.8.2">29000</th>
<td class="ltx_td ltx_align_left" id="S11.T6.2.10.8.3">25.74</td>
<td class="ltx_td ltx_align_left" id="S11.T6.2.10.8.4">25.67</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Evaluation scores for model, finetuned from Mistral-7B-v0.1 directly on Extended Multi30K dataset. We performed log probability thresholds sweep on FLORES dev set. We demonstrate that data from the second phase alone is not enough to match the performance of our best checkpoint. Perplexity filtering improves downstream performance over training on full Extended Multi30K dataset.
</figcaption>
</figure>
<section class="ltx_appendix" id="Ax1">
<h2 class="ltx_title ltx_title_appendix">Appendix</h2>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Translation Examples</h2>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px1">
<h3 class="ltx_title ltx_title_paragraph">Sample of top 5 worst examples by BLEU from FLORES devtest set</h3>
<div class="ltx_para" id="A1.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.1">Source:</span> <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px1.p1.1.2">While most of their food would be familiar to us, Romans did have their share of strange or unusual feast items, including wild boar, peacock, snails, and a type of rodent called a dormouse
<br class="ltx_break"/></span><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.3">Hypothesis:</span> Хоча більшість їхніх продуктів харчування було б знайомим для нас, римляни мали свою частку дивних або незвичайних страв, включаючи кабана, павича, равликів та гризунів, званих куницями.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.4">Reference:</span> Переважно римляни харчувались тим, що знайоме і нам, але були у них і свої дивні та незвичні бенкетні частування, серед яких дикий кабан, павич, слимаки і гризун під назвою вовчок.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.5">BLEU:</span> 1.72


<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.6">Source:</span> <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px1.p1.1.7">"I was moved every time we did a rehearsal on this, from the bottom of my heart."
<br class="ltx_break"/></span><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.8">Hypothesis:</span> "Я був зворушений кожного разу, коли ми робили репетицію з цього приводу, від щирого серця".
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.9">Reference:</span> Мене це торкало кожен раз під час репетиції до глибини душі.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.10">BLEU:</span> 1.91


<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.11">Source:</span> <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px1.p1.1.12">Feral children may have experienced severe child abuse or trauma before being abandoned or running away.
<br class="ltx_break"/></span><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.13">Hypothesis:</span> Дитина-дикун, можливо, пережила жорстоке насильство над дітьми або травму, перш ніж бути кинутою або втекти.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.14">Reference:</span> Може таке бути, що дикарські діти були об’єктами жорстокого поводження або отримали серйозні травми перед тим, як їх полишили або вони втекли.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.15">BLEU:</span> 2.31


<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.16">Source:</span> <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px1.p1.1.17">Workers must often get their superiors’ approval for any decisions they make, and are expected to obey their superiors’ instructions without question.
<br class="ltx_break"/></span><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.18">Hypothesis:</span> Працівники часто повинні отримувати схвалення своїх начальників на будь-які рішення, які вони приймають, і повинні беззаперечно виконувати вказівки своїх начальників.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.19">Reference:</span> Працівникам часто потрібно отримати схвалення керівника щодо будь-яких рішень, а також від них очікують беззаперечного дотримання настанов керівників.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.20">BLEU:</span> 2.32


<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.21">Source:</span> <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px1.p1.1.22">Typically there will be a tuition fee to enroll in these educational programs.
<br class="ltx_break"/></span><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.23">Hypothesis:</span> Як правило, буде плата за навчання, щоб зареєструватися в цих освітніх програмах.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.24">Reference:</span> Зазвичай такі освітні програми платні.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px1.p1.1.25">BLEU:</span> 2.62</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px2">
<h3 class="ltx_title ltx_title_paragraph">Sample of top 5 best examples by BLEU from FLORES devtest set</h3>
<div class="ltx_para" id="A1.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.1">Source:</span> <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px2.p1.1.2">The East African Islands are in the Indian Ocean off the eastern coast of Africa.
<br class="ltx_break"/></span><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.3">Hypothesis:</span> Східноафриканські острови знаходяться в Індійському океані біля східного узбережжя Африки.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.4">Reference:</span> Східноафриканські острови знаходяться в Індійському океані біля східного узбережжя Африки.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.5">BLEU:</span> 100.00


<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.6">Source:</span> <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px2.p1.1.7">Earlier the Chinese news agency Xinhua reported a plane to be hijacked.
<br class="ltx_break"/></span><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.8">Hypothesis:</span> Раніше китайське інформаційне агентство Сіньхуа повідомило про викрадення літака.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.9">Reference:</span> Раніше китайське інформаційне агентство Сіньхуа повідомило про викрадення літака.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.10">BLEU:</span> 100.00


<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.11">Source:</span> <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px2.p1.1.12">For instance, they didn’t have corn, nor tomatoes, nor potatoes, nor cocoa, and no ancient Roman ever tasted a turkey.
<br class="ltx_break"/></span><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.13">Hypothesis:</span> Наприклад, у них не було ні кукурудзи, ні помідорів, ні картоплі, ні какао, і жоден стародавній римлянин ніколи не скуштував індичку.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.14">Reference:</span> Наприклад, у них не було ні кукурудзи, ні помідорів, ні картоплі, ні какао, і жоден стародавній римлянин ніколи не куштував індичку.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.15">BLEU:</span> 90.95


<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.16">Source:</span> <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px2.p1.1.17">The luminosity and rotation are used together to determine a star’s Rossby number, which is related to plasma flow.
<br class="ltx_break"/></span><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.18">Hypothesis:</span> Світність і обертання використовуються разом для визначення числа Россбі зірки, яке пов’язане з потоком плазми.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.19">Reference:</span> Світність і обертання використовуються разом для визначення числа Россбі зірки, яке пов’язане з плазмовим потоком.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.20">BLEU:</span> 83.26


<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.21">Source:</span> <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px2.p1.1.22">But being placed in the "high tropics" just a few degrees north of equator you will need to deal with both heat (always) and strong sun (when the sky is clear, more rarely).
<br class="ltx_break"/></span><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.23">Hypothesis:</span> Але перебуваючи в "високих тропіках" всього в декількох градусах на північ від екватора, вам доведеться мати справу як з спекою (завжди), так і з сильним сонцем (коли небо чисте, рідше).
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.24">Reference:</span> Але, перебуваючи в "високих тропіках" всього в декількох градусах на північ від екватора, вам доведеться мати справу як зі спекою (завжди), так і з палючим сонцем (коли небо чисте, рідше).
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.SS0.SSS0.Px2.p1.1.25">BLEU:</span> 82.47</p>
</div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Jul 12 10:03:29 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
