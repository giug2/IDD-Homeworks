<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies</title>
<!--Generated on Mon Sep 23 16:11:45 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.15163v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S1" title="In Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S2" title="In Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S3" title="In Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S3.SS1" title="In 3 Methods ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Tasks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S3.SS2" title="In 3 Methods ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S3.SS3" title="In 3 Methods ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Models and Pooling Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S3.SS4" title="In 3 Methods ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Evaluation Plan</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S4" title="In Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S5" title="In Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S5.SS1" title="In 5 Discussion ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Limitations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S6" title="In Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S7" title="In Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Appendix</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Skatje Myers
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Wisconsin-Madison
</span>
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Timothy A. Miller
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Boston Children’s Hospital
</span>
<span class="ltx_contact ltx_role_affiliation">Harvard Medical School
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yanjun Gao
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Colorado Anschutz
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Matthew M. Churpek
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Wisconsin-Madison
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Anoop Mayampurath
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Wisconsin-Madison
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dmitriy Dligach
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Loyola University Chicago
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Majid Afshar
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Wisconsin-Madison
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1"><span class="ltx_text ltx_font_bold" id="id1.id1.1">Objective:</span> Applying large language models (LLMs) to the clinical domain is challenging due to the context-heavy nature of processing medical records. Retrieval-augmented generation (RAG) offers a solution by facilitating reasoning over large text sources. However, there are many parameters to optimize in just the retrieval system alone. This paper presents an ablation study exploring how different embedding models and pooling methods affect information retrieval for the clinical domain.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id1.id1.2">Methods</span>: Evaluating on three retrieval tasks on two electronic health record (EHR) data sources, we compared seven models, including medical- and general-domain models, specialized encoder embedding models, and off-the-shelf decoder LLMs. We also examine the choice of embedding pooling strategy for each model, independently on the query and the text to retrieve.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id1.id1.3">Results</span>: We found that the choice of embedding model significantly impacts retrieval performance, with BGE, a comparatively small general-domain model, consistently outperforming all others, including medical-specific models. However, our findings also revealed substantial variability across datasets and query text phrasings. We also determined the best pooling methods for each of these models to guide future design of retrieval systems.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id1.id1.4">Discussion</span>: The choice of embedding model, pooling strategy, and query formulation can significantly impact retrieval performance and the performance of these models on other public benchmarks does not necessarily transfer to new domains. Further studies such as this one are vital for guiding empirically-grounded development of retrieval frameworks, such as in the context of RAG, for the clinical domain.
<br class="ltx_break"/></p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large language models (LLMs) have demonstrated remarkable performance on a wide range of natural language processing tasks, showcasing their potential to advance various domains. However, bringing this benefit to the clinical domain poses significant challenges. The number of progress reports, radiology reports, and other clinical notes in the electronic health record (EHR) that build up over the course of a patient’s hospitalization can quickly exceed most current LLM context windows. Furthermore, the utilization of the full context window can cause LLMs to suffer from the <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">lost-in-the-middle</span> effect <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib13" title="">13</a>]</cite>, where their ability to utilize information towards the middle of the context decreases as the length of the text increases.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Retrieval-augmented generation (RAG) <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib11" title="">11</a>]</cite> has emerged as a promising technique for enabling reasoning over large text sources. This approach allows for the retrieval of relevant passages to provide as context within the prompt for the generated response. This reduces the prompt size and has also been shown to enhance accuracy in various applications dealing with expansive textual data <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib7" title="">7</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">While the generative LLM component can be easily upgraded as new models are released, creating the vector database that stores the embedded documents is an expensive investment at scale and not as trivially replaceable. It’s therefore vital that the decisions made in designing the retrieval pipeline are well-grounded. For example, one must select a suitable model to create text embeddings, and while public benchmarks such as Massive Text Embedding Benchmark (MTEB) <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib15" title="">15</a>]</cite> exist, there is no guarantee that the highest performing models were not influenced by data contamination <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib18" title="">18</a>]</cite> or that they perform well for other domains or texts of other lengths. Furthermore, the optimal choice of embedding pooling method may vary depending on factors such as model architecture, length of text, and the nature of the text.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this paper, we aim to provide a better understanding of the effects of some of these early decisions on the performance of information retrieval for the clinical domain. This pipeline is illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_tag">1</span></a>. We provide an ablation study of recent models and varying embedding pooling methods on three extractive tasks and examine the reproducibility on two data sources: the publicly available MIMIC-III <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib9" title="">9</a>]</cite> dataset and a private EHR dataset.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="219" id="S1.F1.g1" src="extracted/5848806/ir_diagram.drawio.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S1.F1.3.2" style="font-size:90%;">Process of embedding and querying clinical notes.</span></figcaption>
</figure>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">We provide a thorough testing of embedding pooling methods independently on the query and note text, providing statistically verified recommendations on pooling methods to be used for each tested model on the larger text chunks, though we found the choice of pooling strategy for queries to be less significant.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">In our comparison of embedding models, both those explicitly trained for text representation and decoder-only models, we find that the choice of embedding model significantly impacts retrieval performance, with BGE <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib21" title="">21</a>]</cite>, a comparatively small general-domain model, consistently outperforming all others, including medical-specific models and two models which are ranked higher on MTEB. However, our findings also reveal substantial variability across datasets and query text phrasings, highlighting the difficulty in developing a robust retrieval system for novel datasets and tasks.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Statement of Significance</h2>
<section class="ltx_subsection" id="Sx1.SSx1">
<h3 class="ltx_title ltx_title_subsection">Problem</h3>
<div class="ltx_para" id="Sx1.SSx1.p1">
<p class="ltx_p" id="Sx1.SSx1.p1.1">Applying large language models to electronic health records is challenging due to the vast amount of text per patient, often exceeding LLM context limits. While retrieval-augmented generation shows promise in addressing this, the optimal configurations for the retrieval step—specifically, embedding models and pooling strategies—remains unclear in the clinical domain.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx1.SSx2">
<h3 class="ltx_title ltx_title_subsection">What is already known</h3>
<div class="ltx_para" id="Sx1.SSx2.p1">
<p class="ltx_p" id="Sx1.SSx2.p1.1">Public benchmarks exist for evaluating embedding models, but their performance on these benchmarks may not translate directly to other domains. Additionally, optimal pooling strategies for embedding models may vary depending on nature and length of the text to represent. The impact of these factors on information retrieval performance for EHR in particular remains understudied.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx1.SSx3">
<h3 class="ltx_title ltx_title_subsection">What this paper adds</h3>
<div class="ltx_para" id="Sx1.SSx3.p1">
<p class="ltx_p" id="Sx1.SSx3.p1.1">This study provides a systematic comparison of seven embedding models, including both general-domain and medical-specific models, across three clinical information retrieval tasks using two distinct electronic health record data sources. Our findings offer empirical evidence on the performance of different embedding models and pooling strategies in the clinical domain, providing guidance for optimizing retrieval systems for EHR and highlighting the need for domain-specific evaluation.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In a similar vein to our work, Aperdannier et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib3" title="">3</a>]</cite> provided a rich comparison of embedding models for the search of German-language insurance text. They tested different document splitting methods, chunk sizes, and models. The pooling method was not a variable they included, instead using mean pooling for all experiments. Our experiments tested different models and tasks than their work, which found the closed source OpenAI text-embedding-ada-002 model <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib24" title="">24</a>]</cite> to perform best. Although their systematic comparison provided valuable insights for German-language insurance text retrieval, the transferability of these findings to clinical contexts remains unclear.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">The dearth of best practices for the various components of RAG systems, specifically in the clinical domain, has been recently addressed by the MedRAG toolkit <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib22" title="">22</a>]</cite>. This toolkit allows for convenient swapping of components – the text to search over, the retrieval method, and LLMs for generation. They evaluated a number of permutations on their newly proposed Mirage benchmark, which is comprised of five medical question-answering corpora, although none incorporate EHR documents. In contrast, our work is concerned primarily with EHR documents, and our methodological focus is on optimizing the retrieval step before the introduction of the numerous decisions that go into the generative process of the framework.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methods</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Tasks</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We designed three information retrieval tasks to test on two EHR data sources, motivated by future use cases of generating a discharge summary for a hospital encounter or question answering. To evaluate the efficacy of retrieval approaches for these tasks, we developed a semi-automatic approach for generating labeled data.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">Each hospital encounter consists of a discharge summary and the unstructured notes for the hospitalization that temporally preceded it. We identified three types of information of interest:</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1">Primary diagnosis (e.g. <span class="ltx_text ltx_font_italic" id="S3.I1.i1.p1.1.1">aspiration pneumonia, type 2 diabetes</span>)</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">Antibiotics (e.g. <span class="ltx_text ltx_font_italic" id="S3.I1.i2.p1.1.1">amoxicillin, doxycycline</span>)</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1">Invasive/surgical procedures (e.g. <span class="ltx_text ltx_font_italic" id="S3.I1.i3.p1.1.1">left ICA endarterectomy, flexible bronchoscopy</span>)</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">For the antibiotic task, we automatically mapped the text to medical concepts from the National Library of Medicine’s Unified Medical Langauge System (UMLS) with semantic type T195 (Antibiotics) within the notes using the tool QuickUMLS <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib19" title="">19</a>]</cite> and treated all such mentions as the target for retrieval.</p>
</div>
<div class="ltx_para" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1">For the primary diagnosis and surgical procedure tasks, we aimed to simulate the use case of generating a discharge summary through a RAG framework by specifically targeting the ground truth found in the summary. For each encounter, we attempted to extract the primary diagnosis and the surgical procedures sections from the summary using regular expressions. When this information was available, we then identified mentions of the target diagnosis and procedures within the rest of the notes as our retrieval goals.</p>
</div>
<div class="ltx_para" id="S3.SS1.p6">
<p class="ltx_p" id="S3.SS1.p6.1">Due to the frequent use of acronyms and the numerous ways of expressing the same medical concept, we needed to employ a fuzzy matching technique to find these mentions. We first employed QuickUMLS to identify UMLS concepts within the text as potential matches, restricting by appropriate semantic types (Table <a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S3.T1" title="Table 1 ‣ 3.1 Tasks ‣ 3 Methods ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_tag">1</span></a>). In the case of the primary diagnosis, we calculated the cosine similarity between the BioLORD-2023 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib17" title="">17</a>]</cite> embedding of the known diagnosis and that of each of the UMLS entity spans. If the similarity was &gt;= 0.6, this was considered a positive match. This method enabled us to correctly identify occurrences such as <span class="ltx_text ltx_font_italic" id="S3.SS1.p6.1.1">‘‘left knee OA’’</span> as a mention of the known primary diagnosis of <span class="ltx_text ltx_font_italic" id="S3.SS1.p6.1.2">‘‘osteoarthritis of the left knee’’</span>.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.2.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S3.T1.2.1.1.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.2.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.2.1">Valid UMLS types</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.2.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.2.2.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.2.2.1.1.1">Diagnosis</span></th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.2.2.1.2">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.2.2.1.2.1">
<tr class="ltx_tr" id="S3.T1.2.2.1.2.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T1.2.2.1.2.1.1.1">T047, T046, T191,</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.2.1.2.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T1.2.2.1.2.1.2.1">T190, T184, T033, T037</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.2.3.2.1"><span class="ltx_text ltx_font_bold" id="S3.T1.2.3.2.1.1">Antibiotics</span></th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.2.3.2.2">T195</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.2.4.3.1"><span class="ltx_text ltx_font_bold" id="S3.T1.2.4.3.1.1">Procedures</span></th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.2.4.3.2">T061, T060</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T1.3.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S3.T1.4.2" style="font-size:90%;">Allowable semantic types when identifying mentions of the target.</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p7">
<p class="ltx_p" id="S3.SS1.p7.1">In the case of surgical procedures, where the ground truth section of the discharge summary typically contained more free text, we identified the procedures from the section using QuickUMLS and considered mentions within the rest of the encounter notes to be matches if their BioLORD-2023 embeddings were similar to any of the procedure entities.</p>
</div>
<div class="ltx_para" id="S3.SS1.p8">
<p class="ltx_p" id="S3.SS1.p8.1">We note that it should not be expected for any retrieval method to achieve a perfect score for the ‘‘diagnosis’’ and ‘‘procedures’’ tasks. The understanding, for instance, of <span class="ltx_text ltx_font_italic" id="S3.SS1.p8.1.1">which</span> diagnosis is the primary diagnosis is not necessarily represented in text embeddings, merely that the text contains <span class="ltx_text ltx_font_italic" id="S3.SS1.p8.1.2">a</span> diagnosis. Additionally, not all invasive procedures are noted in the discharge summary and therefore ‘‘incorrect’’ procedures mentioned in the text may be ranked highly. In a RAG framework, the generative step would provide this reasoning. The design of these tasks is intended to facilitate using the same datasets for future work that explores the relation between performance on retrieval and the final performance of a RAG system.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Datasets</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We used two data sources to construct the testing data for each task independently – private EHR sourced from the University of Wisconsin (UW) hospital and the publicly-available MIMIC-III dataset <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib9" title="">9</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">Our task datasets consist of varying numbers of patient encounters, which are comprised of all available notes prior to the discharge summary for a given hospital encounter. These notes were segmented into chunks of a maximum of 256 token lengths, with a sliding window of 50. To determine the necessary sample size of our datasets, we used the Sample Size Calculator for Evaluations (SLiCE) <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib5" title="">5</a>]</cite>, which uses predefined confidence intervals and levels to calculate the minimum sample size required for robust metrics of performance that are adequately powered to detect a statistical difference. With a maximally conservative setting of precision and recall of 0.5 and the variance around the 95% confidence level set to 0.05, for all six datasets we exceeded the required sample size to meet these criteria by at least 38%.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">For computational practicality, we limited our consideration of the UW dataset to encounters of five days or less in length of stay. Even with this restriction, the encounters included were comprised of 5,245 to 63,376 tokens each, highlighting the importance of retrieval solutions for the clinical domain. We described the dataset statistics further in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S3.T2" title="Table 2 ‣ 3.2 Datasets ‣ 3 Methods ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_tag">2</span></a>. There was some variance between the UW data and MIMIC-III in the prevalence of relevant note chunks that contain the target information. Additionally, MIMIC-III typically consisted of fewer tokens than the UW data.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.2.1.1">
<td class="ltx_td ltx_border_r" id="S3.T2.2.1.1.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.2.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T2.2.1.1.2.1">Diagnosis</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.2.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T2.2.1.1.3.1">Procedures</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.2.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T2.2.1.1.4.1">Antibiotics</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.2.2">
<td class="ltx_td ltx_border_r" id="S3.T2.2.2.2.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S3.T2.2.2.2.2"><span class="ltx_text ltx_font_bold" id="S3.T2.2.2.2.2.1">MIMIC-III</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.3.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.2.3.3.1"><span class="ltx_text ltx_font_bold" id="S3.T2.2.3.3.1.1"># encounters</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.3.3.2">20</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.3.3.3">15</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.3.3.4">15</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.4.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.2.4.4.1"><span class="ltx_text ltx_font_bold" id="S3.T2.2.4.4.1.1">Avg notes/enc.</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.4.4.2">19.7</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.4.4.3">25.7</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.4.4.4">33.4</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.5.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.2.5.5.1"><span class="ltx_text ltx_font_bold" id="S3.T2.2.5.5.1.1">Avg tokens/enc.</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.5.5.2">11,569</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.5.5.3">15,250</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.5.5.4">20,012</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.6.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.2.6.6.1"><span class="ltx_text ltx_font_bold" id="S3.T2.2.6.6.1.1"># chunks</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.6.6.2">3503</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.6.6.3">3501</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.6.6.4">4557</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.7.7">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.2.7.7.1"><span class="ltx_text ltx_font_bold" id="S3.T2.2.7.7.1.1">Relevant chunks</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.7.7.2">18.2%</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.7.7.3">36.1%</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.7.7.4">14.9%</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.8.8">
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.2.8.8.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S3.T2.2.8.8.2"><span class="ltx_text ltx_font_bold" id="S3.T2.2.8.8.2.1">UW</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.9.9">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.2.9.9.1"><span class="ltx_text ltx_font_bold" id="S3.T2.2.9.9.1.1"># encounters</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.9.9.2">10</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.9.9.3">10</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.9.9.4">10</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.10.10">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.2.10.10.1"><span class="ltx_text ltx_font_bold" id="S3.T2.2.10.10.1.1">Avg notes/enc.</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.10.10.2">42.7</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.10.10.3">46</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.10.10.4">47.7</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.11.11">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.2.11.11.1"><span class="ltx_text ltx_font_bold" id="S3.T2.2.11.11.1.1">Avg tokens/enc.</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.11.11.2">24,684</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.11.11.3">31,793</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.11.11.4">29,468</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.12.12">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.2.12.12.1"><span class="ltx_text ltx_font_bold" id="S3.T2.2.12.12.1.1"># chunks</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.12.12.2">3,956</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.12.12.3">5,208</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.12.12.4">4,741</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.13.13">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.2.13.13.1"><span class="ltx_text ltx_font_bold" id="S3.T2.2.13.13.1.1">Relevant chunks</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.2.13.13.2">17.62%</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.2.13.13.3">10.62%</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.2.13.13.4">11.79%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T2.3.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S3.T2.4.2" style="font-size:90%;">Statistics about the six datasets. "Relevant chunks" are those that contain at least one occurrence of the target information, such as the primary diagnosis.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Models and Pooling Methods</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Although there is a wide array of language models available today, practical constraints limit the number of models we were able to evaluate. We aimed to cover a diverse set of models in our study, including both medical- and general-domain models, as well as encoder models specialized for text embeddings and decoder-only architectures.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">We included four models designed for embedding representations:</p>
<ul class="ltx_itemize" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i1.p1.1.1">BGE-en-large-v1.5</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib21" title="">21</a>]</cite> (335M parameters): A general-purpose BERT-based embedding model trained through contrastive learning.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i2.p1.1.1">Gatortron-large</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib23" title="">23</a>]</cite> (8.9B parameters): A clinical BERT model trained on a large amount of EHR and PubMed. Note: A small portion of the pre-training data was text from MIMIC-III.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i3.p1">
<p class="ltx_p" id="S3.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i3.p1.1.1">SFR-Embedding-Mistral</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib14" title="">14</a>]</cite>: A further fine-tuned version of E5-Mistral-7B-Instruct <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib20" title="">20</a>]</cite>, which is a fine-tuned Mistral-7B-Instruct trained on synthetic data through contrastive loss.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i4.p1">
<p class="ltx_p" id="S3.I2.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i4.p1.1.1">LLM2Vec-Meta-Llama-3-8B-Instruct-mntp-supervised</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib4" title="">4</a>]</cite>: This model modified the Llama-3-8B-Instruct model to enable bi-directional attention and trained it with their novel masked next token prediction method.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1">and three generative decoder-only models:</p>
</div>
<div class="ltx_para" id="S3.SS3.p4">
<ul class="ltx_itemize" id="S3.I3">
<li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I3.i1.p1">
<p class="ltx_p" id="S3.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I3.i1.p1.1.1">Llama-3-8B-Instruct</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib2" title="">2</a>]</cite></p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I3.i2.p1">
<p class="ltx_p" id="S3.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I3.i2.p1.1.1">Mistral-7B-Instruct</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib8" title="">8</a>]</cite></p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I3.i3.p1">
<p class="ltx_p" id="S3.I3.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I3.i3.p1.1.1">BioMistral</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib10" title="">10</a>]</cite>: A version of Mistral-7B-Instruct which has been further pre-trained on PubMed Central.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS3.p5">
<p class="ltx_p" id="S3.SS3.p5.1">Due to the datasets containing PHI and being subject to a data use agreement, we did not evaluate on any closed source models.</p>
</div>
<div class="ltx_para" id="S3.SS3.p6">
<p class="ltx_p" id="S3.SS3.p6.1">For each model, we used between 4 and 7 different phrasings of the query per task (see Tables <a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S7.T5" title="Table 5 ‣ 7 Appendix ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_tag">5</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S7.T6" title="Table 6 ‣ 7 Appendix ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_tag">6</span></a>, and <a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S7.T7" title="Table 7 ‣ 7 Appendix ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_tag">7</span></a> in the Appendix), constructed to be simple and intuitive and without system prompting or extensive tuning in order to provide a generalizable statistical approximation of using these configurations in new use cases.</p>
</div>
<div class="ltx_para" id="S3.SS3.p7">
<p class="ltx_p" id="S3.SS3.p7.1">In order to extract text embeddings from these models, we must pool the last hidden layer. Some models have recommended ways of extracting embeddings. SFR-Embedding-Mistral and LLM2Vec-Llama-3 were both trained to use their own particular query formats, with the embedding derived from either the final token or from mean pooling, respectively. BGE and Gatortron were trained to use a CLS token, with BGE also trained to use a particular query prompt. We go beyond these to consider additional query formats and pooling strategies (<span class="ltx_text ltx_font_bold" id="S3.SS3.p7.1.1">mean pooling</span>, <span class="ltx_text ltx_font_bold" id="S3.SS3.p7.1.2">weighted mean pooling</span>, <span class="ltx_text ltx_font_bold" id="S3.SS3.p7.1.3">max pooling</span>) and assessed them on note chunks and queries independently. For BGE and Gatortron, we tested using the <span class="ltx_text ltx_font_bold" id="S3.SS3.p7.1.4">CLS token</span>, but for the rest of the models, we swapped this method with using the <span class="ltx_text ltx_font_bold" id="S3.SS3.p7.1.5">last token</span>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Evaluation Plan</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">The final step was ranking the note embeddings by cosine similarity to the query embedding and evaluate the ranking by average precision, where a note chunk that contains a mention of the target information is considered a positive instance.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">We calculated the success of the various configuration permutations using mean average precision (MAP). The average precision of a ranked list of chunks is an approximation of the Area Under the Precision-Recall Curve. By performing a repeated measures analysis of variance (ANOVA) for each model we found that the pooling method for the note chunks has a significant effect on performance, and therefore aim to control for this in our later comparisons.</p>
</div>
<div class="ltx_para" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1">For each model, we determined the most robust note pooling strategies across all experiments by performing a post-hoc pairwise Tukey’s test between the different strategies to examine the significance of the differences between them.</p>
</div>
<div class="ltx_para" id="S3.SS4.p4">
<p class="ltx_p" id="S3.SS4.p4.1">Through these permutations of models, datasets, queries, query pooling methods, and note pooling methods, we have tested 3,488 configurations on their ability to retrieve the chunks of clinical notes that contain information relevant to the task target.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In Table <a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S4.T3" title="Table 3 ‣ 4 Results ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_tag">3</span></a>, we present our findings on the best <span class="ltx_text ltx_font_italic" id="S4.p1.1.1">note</span> embedding pooling strategies for each model, across all queries and tasks. These results were largely consistent between the datasets. Through the same testing method, we found that the query pooling method has an insignificant effect on performance for most models.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.2.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_border_r" id="S4.T3.2.1.1.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T3.2.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.2.1.1.2.1">Model</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T3.2.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.2.1.1.3.1">Note Pooling</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.2.2.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.2.2.1.1" rowspan="7"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.1.1.1">U of Wisconsin</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.2.1.2">BGE-large-en</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.2.1.3">weighted mean, CLS, mean</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.3.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.3.2.1">BioMistral</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.3.2.2">mean, weighted mean</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.4.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.4.3.1">Gatortron-large</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.4.3.2">not statistically significant</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.5.4">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.5.4.1">LLM2Vec-Llama-3-8B</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.5.4.2">not statistically significant</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.6.5">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.6.5.1">Llama3-8b-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.6.5.2">weighted mean, mean</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.7.6">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.7.6.1">Mistral-7B-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.7.6.2">mean, max, weighted mean</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.8.7">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.8.7.1">SFR-Embedding-Mistral</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.8.7.2">weighted mean, last token, mean</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.9.8">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.2.9.8.1" rowspan="7"><span class="ltx_text ltx_font_bold" id="S4.T3.2.9.8.1.1">MIMIC-III</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.9.8.2">BGE-large-en</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.9.8.3">weighted mean, mean</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.10.9">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.10.9.1">BioMistral</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.10.9.2">not statistically significant</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.11.10">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.11.10.1">Gatortron-large</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.11.10.2">not statistically significant</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.12.11">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.12.11.1">LLM2Vec-Llama-3</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.12.11.2">mean, weighted mean</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.13.12">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.13.12.1">Llama3-8b-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.13.12.2">weighted mean, mean</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.14.13">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.14.13.1">Mistral-7B-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.14.13.2">mean, weighted mean</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.15.14">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.2.15.14.1">SFR-Embedding-Mistral</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.2.15.14.2">last token, weighted mean</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.4.1.1" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" id="S4.T3.5.2" style="font-size:90%;">Each model’s best embedding pooling methods for the 256-token-maximum note chunks. If multiple methods are listed, we did not find a significant (<span class="ltx_text ltx_font_italic" id="S4.T3.5.2.1">p</span>&lt;0.05) difference between them.</span></figcaption>
</figure>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">In Table <a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S4.T4" title="Table 4 ‣ 4 Results ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_tag">4</span></a>, we present the mean average precision for the different models, using only the best note pooling strategy for each model, across the various query/query pooling configurations. It should be noted that due to the prevalence of the target information being different between datasets, these scores should not be directly interpreted as whether models perform better on one type of data than the other. With MIMIC-III having a higher prevalence of relevant information for all three tasks, higher scores on that dataset are expected.</p>
</div>
<figure class="ltx_table" id="S4.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T4.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.2.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_border_r" id="S4.T4.2.1.1.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.2.1.1.2">U of Wisconsin</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.2.1.1.3">MIMIC-III</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.2.2.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.2.2.1.1">BGE-large-en</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.2.2.1.2"><span class="ltx_text ltx_font_bold" id="S4.T4.2.2.1.2.1">0.403 [0.385, 0.421]</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.2.2.1.3"><span class="ltx_text ltx_font_bold" id="S4.T4.2.2.1.3.1">0.475 [0.457, 0.493]</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.3.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.2.3.2.1">BioMistral</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.2.3.2.2">0.276 [0.255, 0.298]</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.2.3.2.3">0.328 [0.300, 0.357]</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.4.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.2.4.3.1">Gatortron-large</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.2.4.3.2">0.191 [0.184, 0.198]</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.2.4.3.3">0.270 [0.241, 0.298]</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.5.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.2.5.4.1">Llama3-8B-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.2.5.4.2">0.313 [0.292, 0.334]</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.2.5.4.3">0.359 [0.332, 0.385]</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.6.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.2.6.5.1">LLM2Vec-Llama-3-8B</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.2.6.5.2">0.229 [0.207, 0.251]</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.2.6.5.3">0.422 [0.408, 0.437]</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.7.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.2.7.6.1">Mistral-7B-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.2.7.6.2">0.258 [0.239, 0.278]</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.2.7.6.3">0.362 [0.336, 0.387]</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.8.7">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T4.2.8.7.1">SFR-Embedding-Mistral</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.2.8.7.2">0.302 [0.283, 0.322]</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.2.8.7.3">0.417 [0.394, 0.439]</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T4.3.1.1" style="font-size:90%;">Table 4</span>: </span><span class="ltx_text" id="S4.T4.4.2" style="font-size:90%;">Mean average precision [95% CI] for the models across the queries.</span></figcaption>
</figure>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">BGE had a mean average precision of 0.403 across the tasks for the UW dataset and 0.475 for the MIMIC datasets. These results were significantly (<span class="ltx_text ltx_font_italic" id="S4.p3.1.1">p</span>&lt;0.05) better than all other models tested. On the other end of the spectrum, we found Gatortron to perform significantly (<span class="ltx_text ltx_font_italic" id="S4.p3.1.2">p</span>&lt;0.05) worse than all other models on the UW dataset and all models other than LLM2Vec-Llama-3-8B on the UW dataset.</p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1">The performance differences among the remaining models were less pronounced, with overlapping confidence intervals in some cases. LLM2Vec-Meta-Llama-3-8B-Instruct-mntp-supervised, which was based on Llama3-8B-Instruct, performed significantly better than its based model on the MIMIC-III data, but significantly worse on the UW data. This was further notable because off-the-shelf decoder-only models are not a conventional choice for embedding representations, though Llama-3-8B performs competitively in our evaluations. However, SFR-Embedding-Mistral significantly outperformed Mistral-7B-Instruct, demonstrating the potential benefits of specialized embedding models.</p>
</div>
<div class="ltx_para" id="S4.p5">
<p class="ltx_p" id="S4.p5.1">Interestingly, we found no significant difference between the performance of Mistral-7B-Instruct and its medical domain counterpart, BioMistral (<span class="ltx_text ltx_font_italic" id="S4.p5.1.1">p</span>=0.91 and 0.50 on UW and MIMIC datasets, respectively).</p>
</div>
<div class="ltx_para" id="S4.p6">
<p class="ltx_p" id="S4.p6.1">Overall, most models improved over the baseline of randomly ranking the note chunks, with a few exceptions. After performing one-sample t-tests against the random baseline for each dataset and task, with Bonferroni correction applied to control for multiple comparisons, we found that Gatortron performed significantly <span class="ltx_text ltx_font_italic" id="S4.p6.1.1">worse</span> than baseline (adjusted <span class="ltx_text ltx_font_italic" id="S4.p6.1.2">p</span>=4.89E-20) for the MIMIC-III ‘‘diagnosis’’ task and not significantly different from baseline on UW ‘‘procedures’’ (adjusted <span class="ltx_text ltx_font_italic" id="S4.p6.1.3">p</span>=1). BioMistral, Mistral-Instruct, and LLM2Vec-Llama-3 also did not differ from the baseline for MIMIC-III ‘‘diagnosis’’ (adjusted <span class="ltx_text ltx_font_italic" id="S4.p6.1.4">p</span>=1 in all cases), and furthermore, LLM2Vec-Llama-3 performed significantly worse (adjusted <span class="ltx_text ltx_font_italic" id="S4.p6.1.5">p</span>=3.45E-18) on UW ‘‘diagnosis’’ and did not differ from the baseline (adjusted <span class="ltx_text ltx_font_italic" id="S4.p6.1.6">p</span>=1) on UW ‘‘procedures’’.</p>
</div>
<div class="ltx_para" id="S4.p7">
<p class="ltx_p" id="S4.p7.1">We found that performance was very sensitive to the phrasing of the query, potentially even dropping it below baseline. For instance, using <span class="ltx_text ltx_font_italic" id="S4.p7.1.1">‘‘primary diagnosis’’</span> with Llama3-8B-Instruct and mean pooling, the average precision was 27.44. Simply changing the query to <span class="ltx_text ltx_font_italic" id="S4.p7.1.2">‘‘patient’s primary diagnosis’’</span> drastically improved retrieval to 36.68. In Figures <a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S4.F2" title="Figure 2 ‣ 4 Results ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_tag">2</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S4.F3" title="Figure 3 ‣ 4 Results ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_tag">3</span></a> we present box plots to illustrate the distribution of scores for each model and task. We observed that the UW dataset experiences more variability compared to MIMIC, regardless of model or task.</p>
</div>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="296" id="S4.F2.g1" src="extracted/5848806/mimic-models.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S4.F2.3.2" style="font-size:90%;">Boxes represent the interquartile range (IQR) of mean average precision scores for different query/query pooling samples for the different tasks and models on the MIMIC-III data, with the median marked. Whiskers extend to 1.5*IQR; outliers are shown as individual points. The dashed line is a baseline of random ordering of note chunks.</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="294" id="S4.F3.g1" src="extracted/5848806/private-models.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.2.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S4.F3.3.2" style="font-size:90%;">Boxes represent the interquartile range (IQR) of mean average precision scores for different query/query pooling samples for the different tasks and models on the UW data, with the median marked. Whiskers extend to 1.5*IQR; outliers are shown as individual points. The dashed line is a baseline of random ordering of note chunks.</span></figcaption>
</figure>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this study, we examined the impact of embedding methods for a RAG framework by examining various language models for embedding a corpus of clinical text and pooling methods for information retrieval on clinical tasks using both private and publicly available datasets. Our results demonstrated that BGE significantly outperformed all other models tested, despite scoring lower on the MTEB benchmark compared to SFR-Embedding-Mistral (54.29 vs. 59 on retrieval tasks) and LLM2Vec-Llama-3 (56.63), as well as being smaller than all other models tested. This discrepancy between benchmark performance and our evaluation underscores the importance of domain-specific assessments when deploying models in new contexts.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">We also found substantial variability in the success of different queries, which highlights the need for tuning the queries themselves when conducting information retrieval and setting up RAG frameworks. Additionally, the more pronounced variability on the UW dataset compared to MIMIC-III warrants further exploration to understand the factors contributing to this difference.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">Given the resources and time needed to perform over 3,000 experiments, we left several components of an RAG framework for future work. One important factor is the decision on how to break the data into chunks. Typical approaches include segmenting based on formatting (such as headers and paragraph breaks) or simply choosing a chunk size that fits within the embedding model’s context limit. The length of these segments may significantly impact the performance of retrieval, either due to models’ capability of representing larger amounts of text or their downstream effect on a generative model once retrieved.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Limitations</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">There are many other popular models for embeddings that we did not test, such as those in the GTE family <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib12" title="">12</a>]</cite>, as well as other medical-domain models, such as Meditron <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib6" title="">6</a>]</cite>. Due to legal and ethical restrictions on sharing the EHR data we use, we were unable to test on many of the popular closed-source models that are currently used, such as OpenAI’s text-embedding family of models <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib24" title="">24</a>]</cite> or Voyage AI’s <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib1" title="">1</a>]</cite>. Furthermore, for this reason, the UW data we evaluated on cannot be publicly released for the community to reproduce our results.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusions</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In conclusion, our ablation study underscores the importance of carefully selecting and evaluating components when designing retrieval systems for the clinical domain. The choice of embedding model, pooling strategy, and query formulation can significantly impact retrieval performance, and further empirical studies like this one are crucial for making informed decisions that guide us toward more robust and effective retrieval systems. As the information in EHRs continues to grow exponentially, retrieval systems and vector databases that are scalable and reproducible in quality are becoming a viable solution to the information overload and note bloat problem <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#bib.bib16" title="">16</a>]</cite>. Our initial work highlights the variants that can occur in the embedding quality and indexing for the later generative component of a RAG framework.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Funding acknowledgement</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">This work was supported by the National Library of Medicine of the National Institutes of Health under award number R01LM012973. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.</p>
</div>
</section>
<section class="ltx_section" id="Sx3">
<h2 class="ltx_title ltx_title_section">CRediT authorship contribution statement</h2>
<div class="ltx_para" id="Sx3.p1">
<p class="ltx_p" id="Sx3.p1.1"><span class="ltx_text ltx_font_bold" id="Sx3.p1.1.1">Skatje Myers</span>: Writing-original draft, Methodology, Data curation, Investigation, Conceptualization, Formal analysis, Software. <span class="ltx_text ltx_font_bold" id="Sx3.p1.1.2">Timothy A. Miller</span>: Writing–review &amp; editing, Methodology, Conceptualization, Funding acquisition, Supervision. <span class="ltx_text ltx_font_bold" id="Sx3.p1.1.3">Yanjun Gao</span>: Methodology, Writing–review &amp; editing. <span class="ltx_text ltx_font_bold" id="Sx3.p1.1.4">Matthew Churpek</span>: Methodology, Writing–review &amp; editing. <span class="ltx_text ltx_font_bold" id="Sx3.p1.1.5">Anoop Mayampurath</span>: Methodology, Writing–review &amp; editing. <span class="ltx_text ltx_font_bold" id="Sx3.p1.1.6">Dmitriy Dligach</span>: Conceptualization, Methodology, Writing–review &amp; editing, Supervision. <span class="ltx_text ltx_font_bold" id="Sx3.p1.1.7">Majid Afshar</span>: Supervision, Methodology, Formal analysis, Writing–review &amp; editing, Conceptualization, Funding acquisition.</p>
</div>
</section>
<section class="ltx_section" id="Sx4">
<h2 class="ltx_title ltx_title_section">Declaration of competing interest</h2>
<div class="ltx_para" id="Sx4.p1">
<p class="ltx_p" id="Sx4.p1.1">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
</div>
</section>
<section class="ltx_section" id="Sx5">
<h2 class="ltx_title ltx_title_section">Data availability</h2>
<div class="ltx_para" id="Sx5.p1">
<p class="ltx_p" id="Sx5.p1.1">The data underlying this article cannot be shared publicly due to privacy and data use agreements. The encounter IDs used for the MIMIC-III portion of the work will be shared on reasonable request to the corresponding author.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Voyage AI.

</span>
<span class="ltx_bibblock">Embeddings — docs.voyageai.com.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://blog.voyageai.com/2024/05/05/voyage-large-2-instruct-instruction-tuned-and-rank-1-on-mteb/" style="font-size:90%;" title="">https://blog.voyageai.com/2024/05/05/voyage-large-2-instruct-instruction-tuned-and-rank-1-on-mteb/</a>, 2024.

</span>
<span class="ltx_bibblock">[Accessed 15-06-2024].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
AI@Meta.

</span>
<span class="ltx_bibblock">Llama 3 model card.

</span>
<span class="ltx_bibblock">2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Roman Aperdannier, Melanie Koeppel, Tamina Unger, Sigurd Schacht, and Sudarshan Kamath Barkur.

</span>
<span class="ltx_bibblock">Systematic evaluation of different approaches on embedding search.

</span>
<span class="ltx_bibblock">In Kohei Arai, editor, <span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">Advances in Information and Communication</span>, pages 526–536, Cham, 2024. Springer Nature Switzerland.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Parishad BehnamGhader, Vaibhav Adlakha, Marius Mosbach, Dzmitry Bahdanau, Nicolas Chapados, and Siva Reddy.

</span>
<span class="ltx_bibblock">LLM2Vec: Large language models are secretly powerful text encoders, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Lea Canales, Sebastian Menke, Stephanie Marchesseau, Ariel D’Agostino, Carlos del Rio-Bermudez, Miren Taberna, Jorge Tello, et al.

</span>
<span class="ltx_bibblock">Assessing the performance of clinical natural language processing systems: development of an evaluation methodology.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">JMIR Medical Informatics</span>, 9(7):e20492, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Zeming Chen, Alejandro Hernández-Cano, Angelika Romanou, Antoine Bonnet, Kyle Matoba, Francesco Salvi, Matteo Pagliardini, Simin Fan, Andreas Köpf, Amirkeivan Mohtashami, Alexandre Sallinen, Alireza Sakhaeirad, Vinitra Swamy, Igor Krawczuk, Deniz Bayazit, Axel Marmet, Syrielle Montariol, Mary-Anne Hartley, Martin Jaggi, and Antoine Bosselut.

</span>
<span class="ltx_bibblock">Meditron-70b: Scaling medical pretraining for large language models, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen Wang.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for large language models: A survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2312.10997</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al.

</span>
<span class="ltx_bibblock">Mistral 7b.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2310.06825</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Alistair EW Johnson, Tom J Pollard, Lu Shen, Li-wei H Lehman, Mengling Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark.

</span>
<span class="ltx_bibblock">MIMIC-III, a freely accessible critical care database.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">Scientific data</span>, 3(1):1–9, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Yanis Labrak, Adrien Bazoge, Emmanuel Morin, Pierre-Antoine Gourraud, Mickael Rouvier, and Richard Dufour.

</span>
<span class="ltx_bibblock">BioMistral: A collection of open-source pretrained large language models for medical domains, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive NLP tasks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">Advances in Neural Information Processing Systems</span>, 33:9459–9474, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Zehan Li, Xin Zhang, Yanzhao Zhang, Dingkun Long, Pengjun Xie, and Meishan Zhang.

</span>
<span class="ltx_bibblock">Towards general text embeddings with multi-stage contrastive learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2308.03281</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang.

</span>
<span class="ltx_bibblock">Lost in the middle: How language models use long contexts.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">Transactions of the Association for Computational Linguistics</span>, 12:157–173, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Rui Meng, Ye Liu, Shafiq Rayhan Joty, Caiming Xiong, Yingbo Zhou, and Semih Yavuz.

</span>
<span class="ltx_bibblock">SFR-Embedded-Mistral.

</span>
<span class="ltx_bibblock">Salesforce AI Research Blog, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Niklas Muennighoff, Nouamane Tazi, Loïc Magne, and Nils Reimers.

</span>
<span class="ltx_bibblock">MTEB: Massive text embedding benchmark.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2210.07316</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Brian W Patterson, Daniel J Hekman, Frank J Liao, Azita G Hamedani, Manish N Shah, and Majid Afshar.

</span>
<span class="ltx_bibblock">Call me dr ishmael: trends in electronic health record notes available at emergency department visits and admissions.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">JAMIA open</span>, 7(2):ooae039, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
François Remy, Kris Demuynck, and Thomas Demeester.

</span>
<span class="ltx_bibblock">BioLORD-2023: semantic textual representations fusing large language models and clinical knowledge graph insights.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">Journal of the American Medical Informatics Association</span>, page ocae029, 02 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Oscar Sainz, Jon Campos, Iker García-Ferrero, Julen Etxaniz, Oier Lopez de Lacalle, and Eneko Agirre.

</span>
<span class="ltx_bibblock">NLP evaluation in trouble: On the need to measure LLM data contamination for each benchmark.

</span>
<span class="ltx_bibblock">In Houda Bouamor, Juan Pino, and Kalika Bali, editors, <span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</span>, pages 10776–10787, Singapore, December 2023. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Luca Soldaini and Nazli Goharian.

</span>
<span class="ltx_bibblock">QuickUMLS: a fast, unsupervised approach for medical concept extraction.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">MedIR workshop, sigir</span>, pages 1–4, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Liang Wang, Nan Yang, Xiaolong Huang, Linjun Yang, Rangan Majumder, and Furu Wei.

</span>
<span class="ltx_bibblock">Improving text embeddings with large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2401.00368</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas Muennighoff.

</span>
<span class="ltx_bibblock">C-pack: Packaged resources to advance general chinese embedding, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Guangzhi Xiong, Qiao Jin, Zhiyong Lu, and Aidong Zhang.

</span>
<span class="ltx_bibblock">Benchmarking retrieval-augmented generation for medicine.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2402.13178</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Xi Yang, Aokun Chen, Nima PourNejatian, Hoo Chang Shin, Kaleb E Smith, Christopher Parisien, Colin Compas, Cheryl Martin, Anthony B Costa, Mona G Flores, et al.

</span>
<span class="ltx_bibblock">A large language model for electronic health records.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">NPJ digital medicine</span>, 5(1):194, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Juntang Zhuang, Paul Baltescu, Joy Jiao, Arvind Neelakantan, Andrew Braunstein, Jeff Harris, Logan Kilpatrick, Leher Pathak, Enoch Cheung, Ted Sanders, Yutian Liu, Anushree Agrawal, Andrew Peng, Ian Kivlichan, Mehmet Yatbaz, Madelaine Boyd, Luisa Anna-Brakman, Leoni Florencia Aleman, Henry Head, Molly Lin, Meghan Shah, Chelsea Carlson, Sam Toizer, Ryan Greene, Alison Harmon, Denny Jin, Karolis Kosas, Marie Inuzuka, Peter Bakkum, Barret Zoph, Luke Metz, Jiayi Weng, Randall Lin, Yash Patil, Mianna Chen, Andrew Kondrich, Brydon Eastman, Liam Fedus, John Schulman, Vlad Fomenko, Andrej Karpathy, Aidan Clark, and Owen Campbell-Moore.

</span>
<span class="ltx_bibblock">New embedding models and API updates.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/index/new-embedding-models-and-api-updates/" style="font-size:90%;" title="">https://openai.com/index/new-embedding-models-and-api-updates/</a>, 2024.

</span>
<span class="ltx_bibblock">[Accessed 15-06-2024].

</span>
</li>
</ul>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Appendix</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">We present the lists of queries used for the ‘‘diagnosis’’ (Table <a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S7.T5" title="Table 5 ‣ 7 Appendix ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_tag">5</span></a>), ‘‘procedures’’ (Table <a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S7.T6" title="Table 6 ‣ 7 Appendix ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_tag">6</span></a>), and ‘‘antibiotics’’ (Table <a class="ltx_ref" href="https://arxiv.org/html/2409.15163v1#S7.T7" title="Table 7 ‣ 7 Appendix ‣ Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies"><span class="ltx_text ltx_ref_tag">7</span></a>) tasks. The queries that begin with ‘‘Instruct:[…]’’, ‘‘Given […]’’, and ‘‘Represent […]’’ were only used for SFR-Embedding-Mistral, LLM2Vec, and BGE (respectively). These models were trained to use these formats, although they are not strictly necessary.</p>
</div>
<figure class="ltx_table" id="S7.T5">
<table class="ltx_tabular ltx_align_middle" id="S7.T5.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S7.T5.2.1.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T5.2.1.1.1">The patient’s primary diagnosis is</td>
</tr>
<tr class="ltx_tr" id="S7.T5.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T5.2.2.2.1">patient’s primary diagnosis</td>
</tr>
<tr class="ltx_tr" id="S7.T5.2.3.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T5.2.3.3.1">What is the patient’s primary diagnosis?</td>
</tr>
<tr class="ltx_tr" id="S7.T5.2.4.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T5.2.4.4.1">The patient has been diagnosed with</td>
</tr>
<tr class="ltx_tr" id="S7.T5.2.5.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T5.2.5.5.1">primary diagnosis</td>
</tr>
<tr class="ltx_tr" id="S7.T5.2.6.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T5.2.6.6.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T5.2.6.6.1.1">
<tr class="ltx_tr" id="S7.T5.2.6.6.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T5.2.6.6.1.1.1.1">Represent this sentence for searching relevant passages:</td>
</tr>
<tr class="ltx_tr" id="S7.T5.2.6.6.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T5.2.6.6.1.1.2.1">patient’s primary diagnosis</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S7.T5.2.7.7">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T5.2.7.7.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T5.2.7.7.1.1">
<tr class="ltx_tr" id="S7.T5.2.7.7.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T5.2.7.7.1.1.1.1">Represent this sentence for searching relevant passages:</td>
</tr>
<tr class="ltx_tr" id="S7.T5.2.7.7.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T5.2.7.7.1.1.2.1">What is the patient’s primary diagnosis?</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S7.T5.2.8.8">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T5.2.8.8.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T5.2.8.8.1.1">
<tr class="ltx_tr" id="S7.T5.2.8.8.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T5.2.8.8.1.1.1.1">Given a search query, retrieve relevant passages that answer the query:</td>
</tr>
<tr class="ltx_tr" id="S7.T5.2.8.8.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T5.2.8.8.1.1.2.1">patient’s primary diagnosis</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S7.T5.2.9.9">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T5.2.9.9.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T5.2.9.9.1.1">
<tr class="ltx_tr" id="S7.T5.2.9.9.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T5.2.9.9.1.1.1.1">Given a search query, retrieve relevant passages that answer the query:</td>
</tr>
<tr class="ltx_tr" id="S7.T5.2.9.9.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T5.2.9.9.1.1.2.1">What is the patient’s primary diagnosis?</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S7.T5.2.10.10">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T5.2.10.10.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T5.2.10.10.1.1">
<tr class="ltx_tr" id="S7.T5.2.10.10.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T5.2.10.10.1.1.1.1">Instruct: Given a search query, retrieve relevant passages that answer the query.</td>
</tr>
<tr class="ltx_tr" id="S7.T5.2.10.10.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T5.2.10.10.1.1.2.1">Query: patient’s primary diagnosis</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S7.T5.2.11.11">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S7.T5.2.11.11.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T5.2.11.11.1.1">
<tr class="ltx_tr" id="S7.T5.2.11.11.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T5.2.11.11.1.1.1.1">Instruct: Given a search query, retrieve relevant passages that answer the query.</td>
</tr>
<tr class="ltx_tr" id="S7.T5.2.11.11.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T5.2.11.11.1.1.2.1">Query: What is the patient’s primary diagnosis?</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S7.T5.3.1.1" style="font-size:90%;">Table 5</span>: </span><span class="ltx_text" id="S7.T5.4.2" style="font-size:90%;">Queries used for retrieving the primary diagnosis.</span></figcaption>
</figure>
<figure class="ltx_table" id="S7.T6">
<table class="ltx_tabular ltx_align_middle" id="S7.T6.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S7.T6.2.1.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T6.2.1.1.1">The patient received the following surgical procedures:</td>
</tr>
<tr class="ltx_tr" id="S7.T6.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T6.2.2.2.1">surgical procedures</td>
</tr>
<tr class="ltx_tr" id="S7.T6.2.3.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T6.2.3.3.1">What invasive and surgical procedures did the patient receive?</td>
</tr>
<tr class="ltx_tr" id="S7.T6.2.4.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T6.2.4.4.1">surgical procedures and operations</td>
</tr>
<tr class="ltx_tr" id="S7.T6.2.5.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T6.2.5.5.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T6.2.5.5.1.1">
<tr class="ltx_tr" id="S7.T6.2.5.5.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T6.2.5.5.1.1.1.1">Represent this sentence for searching relevant passages:</td>
</tr>
<tr class="ltx_tr" id="S7.T6.2.5.5.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T6.2.5.5.1.1.2.1">What invasive and surgical procedures did the patient receive?</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S7.T6.2.6.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T6.2.6.6.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T6.2.6.6.1.1">
<tr class="ltx_tr" id="S7.T6.2.6.6.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T6.2.6.6.1.1.1.1">Represent this sentence for searching relevant passages:</td>
</tr>
<tr class="ltx_tr" id="S7.T6.2.6.6.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T6.2.6.6.1.1.2.1">invasive and surgical procedures?</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S7.T6.2.7.7">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T6.2.7.7.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T6.2.7.7.1.1">
<tr class="ltx_tr" id="S7.T6.2.7.7.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T6.2.7.7.1.1.1.1">Given a search query, retrieve relevant passages that answer the query:</td>
</tr>
<tr class="ltx_tr" id="S7.T6.2.7.7.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T6.2.7.7.1.1.2.1">What invasive and surgical procedures did the patient receive?</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S7.T6.2.8.8">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T6.2.8.8.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T6.2.8.8.1.1">
<tr class="ltx_tr" id="S7.T6.2.8.8.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T6.2.8.8.1.1.1.1">Given a search query, retrieve relevant passages that answer the query:</td>
</tr>
<tr class="ltx_tr" id="S7.T6.2.8.8.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T6.2.8.8.1.1.2.1">invasive and surgical procedures?</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S7.T6.2.9.9">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T6.2.9.9.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T6.2.9.9.1.1">
<tr class="ltx_tr" id="S7.T6.2.9.9.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T6.2.9.9.1.1.1.1">Instruct: Given a search query, retrieve relevant passages that answer the query.\n</td>
</tr>
<tr class="ltx_tr" id="S7.T6.2.9.9.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T6.2.9.9.1.1.2.1">Query: What invasive and surgical procedures did the patient receive?</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S7.T6.2.10.10">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S7.T6.2.10.10.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T6.2.10.10.1.1">
<tr class="ltx_tr" id="S7.T6.2.10.10.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T6.2.10.10.1.1.1.1">Instruct: Given a search query, retrieve relevant passages that answer the query.\n</td>
</tr>
<tr class="ltx_tr" id="S7.T6.2.10.10.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T6.2.10.10.1.1.2.1">Query: invasive and surgical procedures?</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S7.T6.3.1.1" style="font-size:90%;">Table 6</span>: </span><span class="ltx_text" id="S7.T6.4.2" style="font-size:90%;">Queries used for retrieving the invasive and surgical procedures.</span></figcaption>
</figure>
<figure class="ltx_table" id="S7.T7">
<table class="ltx_tabular ltx_align_middle" id="S7.T7.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S7.T7.2.1.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T7.2.1.1.1">antibiotics</td>
</tr>
<tr class="ltx_tr" id="S7.T7.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T7.2.2.2.1">antibiotic medications</td>
</tr>
<tr class="ltx_tr" id="S7.T7.2.3.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T7.2.3.3.1">What antibiotics are the patient taking?</td>
</tr>
<tr class="ltx_tr" id="S7.T7.2.4.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T7.2.4.4.1">The antibiotics the patient is taking are</td>
</tr>
<tr class="ltx_tr" id="S7.T7.2.5.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T7.2.5.5.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T7.2.5.5.1.1">
<tr class="ltx_tr" id="S7.T7.2.5.5.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T7.2.5.5.1.1.1.1">Represent this sentence for searching relevant passages:</td>
</tr>
<tr class="ltx_tr" id="S7.T7.2.5.5.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T7.2.5.5.1.1.2.1">What antibiotics has the patent taken?</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S7.T7.2.6.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T7.2.6.6.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T7.2.6.6.1.1">
<tr class="ltx_tr" id="S7.T7.2.6.6.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T7.2.6.6.1.1.1.1">Represent this sentence for searching relevant passages:</td>
</tr>
<tr class="ltx_tr" id="S7.T7.2.6.6.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T7.2.6.6.1.1.2.1">antibiotics</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S7.T7.2.7.7">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T7.2.7.7.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T7.2.7.7.1.1">
<tr class="ltx_tr" id="S7.T7.2.7.7.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T7.2.7.7.1.1.1.1">Given a search query, retrieve relevant passages that answer the query:</td>
</tr>
<tr class="ltx_tr" id="S7.T7.2.7.7.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T7.2.7.7.1.1.2.1">What antibiotics has the patent taken?</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S7.T7.2.8.8">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T7.2.8.8.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T7.2.8.8.1.1">
<tr class="ltx_tr" id="S7.T7.2.8.8.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T7.2.8.8.1.1.1.1">Given a search query, retrieve relevant passages that answer the query:</td>
</tr>
<tr class="ltx_tr" id="S7.T7.2.8.8.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T7.2.8.8.1.1.2.1">antibiotics</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S7.T7.2.9.9">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S7.T7.2.9.9.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T7.2.9.9.1.1">
<tr class="ltx_tr" id="S7.T7.2.9.9.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T7.2.9.9.1.1.1.1">Instruct: Given a search query, retrieve relevant passages that answer the query.\n</td>
</tr>
<tr class="ltx_tr" id="S7.T7.2.9.9.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T7.2.9.9.1.1.2.1">Query: What antibiotics has the patent taken?</td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S7.T7.2.10.10">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S7.T7.2.10.10.1">
<table class="ltx_tabular ltx_align_middle" id="S7.T7.2.10.10.1.1">
<tr class="ltx_tr" id="S7.T7.2.10.10.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T7.2.10.10.1.1.1.1">Instruct: Given a search query, retrieve relevant passages that answer the query.\n</td>
</tr>
<tr class="ltx_tr" id="S7.T7.2.10.10.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S7.T7.2.10.10.1.1.2.1">Query: antibiotics</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S7.T7.3.1.1" style="font-size:90%;">Table 7</span>: </span><span class="ltx_text" id="S7.T7.4.2" style="font-size:90%;">Queries used for retrieving mentions of antibiotics.</span></figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Sep 23 16:11:45 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
