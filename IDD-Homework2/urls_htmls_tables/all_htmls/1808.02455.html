<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[1808.02455] Data augmentation using synthetic data for time series classification with deep residual networks</title><meta property="og:description" content="Data augmentation in deep neural networks is the process of generating artificial data in order to reduce the variance of the classifier with the goal to reduce the number of errors.
This idea has been shown to improve…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Data augmentation using synthetic data for time series classification with deep residual networks">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Data augmentation using synthetic data for time series classification with deep residual networks">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/1808.02455">

<!--Generated on Sat Mar 16 18:37:04 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Time Series Classification Data augmentation Deep Learning Dynamic Time Warping ">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span id="id1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>
IRIMAS, Université de Haute-Alsace, 68100 Mulhouse, France
<br class="ltx_break"><span id="id1.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>{first-name}.{last-name}@uha.fr</span></span></span>
</span></span></span>
<h1 class="ltx_title ltx_title_document">Data augmentation using synthetic data for time series classification with deep residual networks</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hassan Ismail Fawaz
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Germain Forestier
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Jonathan Weber
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> 
<br class="ltx_break">Lhassane Idoumghar
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Pierre-Alain Muller
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Data augmentation in deep neural networks is the process of generating artificial data in order to reduce the variance of the classifier with the goal to reduce the number of errors.
This idea has been shown to improve deep neural network’s generalization capabilities in many computer vision tasks such as image recognition and object localization.
Apart from these applications, deep Convolutional Neural Networks (CNNs) have also recently gained popularity in the Time Series Classification (TSC) community.
However, unlike in image recognition problems, data augmentation techniques have not yet been investigated thoroughly for the TSC task.
This is surprising as the accuracy of deep learning models for TSC could potentially be improved, especially for small datasets that exhibit overfitting, when a data augmentation method is adopted.
In this paper, we fill this gap by investigating the application of a recently proposed data augmentation technique based on the Dynamic Time Warping distance, for a deep learning model for TSC.
To evaluate the potential of augmenting the training set, we performed extensive experiments using the UCR TSC benchmark.
Our preliminary experiments reveal that data augmentation can drastically increase deep CNN’s accuracy on some datasets and significantly improve the deep model’s accuracy when the method is used in an ensemble approach.

</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Time Series Classification Data augmentation Deep Learning Dynamic Time Warping 
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Deep learning usually benefits from large training sets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.
However, for many applications only relatively small training data exist.
In Time Series Classification (TSC), this phenomenon can be observed by analyzing the UCR archive’s datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, where 20 datasets have 50 or fewer training instances.
These numbers are relatively small compared to the billions of labeled images in computer vision, where deep learning has seen its most successful applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Although the recently proposed deep Convolutional Neural Networks (CNNs) reached state of the art performance in TSC on the UCR archive <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, they still show low generalization capabilities on some small datasets such as the DiatomSizeReduction dataset.
This is surprising since the nearest neighbor approach (1-NN) coupled with the Dynamic Time Warping (DTW) performs exceptionally well on this dataset which shows the relative easiness of this classification task.
Thus, inter-time series similarities in such small datasets cannot be captured by the CNNs due to the lack of labeled instances, which pushes the network’s optimization algorithm to be stuck in local minimums <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.
Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Data augmentation using synthetic data for time series classification with deep residual networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates on an example that the lack of labeled data can sometimes be compensated by the addition of synthetic data.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S1.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/1808.02455/assets/x1.png" id="S1.F1.sf1.g1" class="ltx_graphics ltx_img_landscape" width="216" height="173" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>DiatomSizeReduction</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S1.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/1808.02455/assets/x2.png" id="S1.F1.sf2.g1" class="ltx_graphics ltx_img_square" width="217" height="176" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Meat</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The model’s loss with/without data augmentation on the DiatomSizeReduction and Meat datasets (smoothed and clipped for visual clarity).</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">This phenomenon, also known as <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">overfitting</em> in the machine learning community, can be solved using different techniques such as regularization or simply collecting more <em id="S1.p3.1.2" class="ltx_emph ltx_font_italic">labeled</em> data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> (which in some domains are hard to obtain).
Another well-known technique is data augmentation, where synthetic data are generated using a specific method.
For example, images containing street numbers on houses can be slightly rotated without changing what number they actually are <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.
For deep learning models, these methods are usually proposed for image data and do not generalize well to time series <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>.
This is probably due to the fact that for images, a visual comparison can confirm if the transformation (such as rotation) did not alter the image’s class, while for time series data, one cannot easily confirm the effect of such ad-hoc transformations on the nature of a time series.
This is the main reason why data augmentation for TSC have been limited to mainly two relatively simple techniques: slicing and manual warping, which are further discussed in Section <a href="#S2" title="2 Related work ‣ Data augmentation using synthetic data for time series classification with deep residual networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this paper, we propose to leverage from a DTW based data augmentation technique specifically developed for time series, in order to boost the performance of a deep Residual Network (ResNet) for TSC.
Our preliminary experiments reveal that data augmentation can drastically increase the accuracy for CNNs on some datasets while having a small negative impact on other datasets.
We finally propose to combine the decision of the two trained models and show how it can reduce significantly the rare negative effect of data augmentation while maintaining its high gain in accuracy on other datasets.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The most used data augmentation method for TSC is the slicing window technique, originally introduced for deep CNNs in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
The method was originally inspired by the image cropping technique for data augmentation in computer vision tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.
This data transformation technique can, to a certain degree, guarantee that the cropped image still holds the same information as the original image.
On the other hand, for time series data, one cannot make sure that the discriminative information has not been lost when a certain region of the time series is cropped.
Nevertheless, this method was used in several TSC problems, such as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> where it improved the Support Vector Machines accuracy for classifying electroencephalographic time series.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, this slicing window technique was also adopted to improve the CNNs’ mortgage delinquency prediction using customers’ historical transactional data.
In addition to the slicing window technique, jittering, scaling, warping and permutation were proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> as generic time series data augmentation approaches.
The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> proposed a novel data augmentation method specific to wearable sensor time series data that rotates the trajectory of a person’s arm around an axis (e.g. <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.p1.1.m1.1a"><mi id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">x</annotation></semantics></math> axis).</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, the authors proposed to extend the slicing window technique with a warping window that generates synthetic time series by warping the data through time.
This method was used to improve the classification of their deep CNN for TSC, which was also shown to significantly decrease the accuracy of a NN-DTW classifier when compared to our adopted data augmentation algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
We should note that the use of a window slicing technique means that the model should classify each subsequence alone and then finally classify the whole time series using a majority voting approach.
Alternatively, our method does not crop time series into shorter subsequences which enables the network to learn discriminative properties from the whole time series in an end-to-end manner.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Architecture</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We have chosen to improve the generalization capability of the deep ResNet proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> for two main reasons, whose corresponding architecture is illustrated in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Architecture ‣ 3 Method ‣ Data augmentation using synthetic data for time series classification with deep residual networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
First, by adopting an already validated architecture, we can attribute any improvement in the network’s performance solely to the data augmentation technique.
The second reason is that ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, to the best of our knowledge, is the deepest neural network validated on large number of TSC tasks (such as the UCR archive <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>), which according to the deep learning literature will benefit the most from the data augmentation techniques as opposed to shallow architectures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.
Deep ResNets were first proposed by He et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> for computer vision tasks.
They are mainly composed of convolutions, with one important characteristic: the residual connections which acts like shortcuts that enable the flow of the gradient directly through these connections.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/1808.02455/assets/x3.png" id="S3.F2.g1" class="ltx_graphics ltx_img_landscape" width="263" height="67" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Residual network’s architecture.
Blue connections correspond to convolutions, violet to residual, red to average pooling and green are fully-connected.</figcaption>
</figure>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.3" class="ltx_p">The input of this network is a univariate time series with a varying length <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">l</annotation></semantics></math>.
The output consists of a probability distribution over the <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">C</annotation></semantics></math> classes in the dataset.
The network’s core contains three residual blocks followed by a Global Average Pooling layer and a final softmax classifier with <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">C</annotation></semantics></math> neurons.
Each residual block contains three 1-D convolutions of respectively 8, 5 and 3 filter lengths.
Each convolution is followed by a batch normalization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> and a Rectified Linear Unit (ReLU) as the activation function.
The residual connection consists in linking the input of a residual block to the input of its consecutive layer with the simple addition operation.
The number of filters in the first residual blocks is set to 64 filters, while the second and third blocks contains 128 filters.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.3" class="ltx_p">All network’s parameters were initialized using Glorot’s Uniform initialization method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.
These parameters were learned using Adam <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> as the optimization algorithm.
Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, without any fine-tuning, the learning rate was set to <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="0.001" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mn id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><cn type="float" id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">0.001</annotation></semantics></math> and the exponential decay rates of the first and second moment estimates were set to <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="0.9" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><mn id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">0.9</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><cn type="float" id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">0.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">0.9</annotation></semantics></math> and <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="0.999" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><mn id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml">0.999</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><cn type="float" id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">0.999</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">0.999</annotation></semantics></math> respectively.
Finally, the categorical cross-entropy was used as the objective cost function during the optimization process.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Data augmentation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The data augmentation method we have chosen to test with this deep architecture, was first proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> to augment the training set for a 1-NN coupled with the DTW distance in a cold start simulation problem.
In addition, the 1-NN was shown to sometimes benefit from augmenting the size of the train set even when the whole dataset is available for training.
Thus, we hypothesize that this synthetic time series generation method should improve deep neural network’s performance, especially that the generated examples in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> were shown to closely follow the distribution from which the original dataset was sampled.
The method is mainly based on a weighted form of DTW Barycentric Averaging (DBA) technique <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.
The latter algorithm averages a set of time series in a DTW induced space and by leveraging a weighted version of DBA, the method can thus create an infinite number of new time series from a given set of time series by simply varying these weights.
Three techniques were proposed to select these weights, from which we chose only one in our approach for the sake of simplicity, although we consider evaluating other techniques in our future work.
The weighting method is called Average Selected which consists of selecting a subset of close time series and fill their bounding boxes.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.3" class="ltx_p">We start by describing in details how the weights are assigned, which constitutes the main difference between an original version of DBA and the weighted version originally proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
Starting with a random initial time series chosen from the training set, we assign it a weight equal to <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mn id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><cn type="float" id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">0.5</annotation></semantics></math>.
The latter randomly selected time series will act as the initialization of DBA.
Then, we search for its 5 nearest neighbors using the DTW distance.
We then randomly select 2 out these 5 neighbors and assign them a weight value equal to 0.15 each, making thus the total sum of assigned weights till now equal to <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="0.5+2\times 0.15=0.8" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mrow id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mrow id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml"><mn id="S3.SS2.p2.2.m2.1.1.2.2" xref="S3.SS2.p2.2.m2.1.1.2.2.cmml">0.5</mn><mo id="S3.SS2.p2.2.m2.1.1.2.1" xref="S3.SS2.p2.2.m2.1.1.2.1.cmml">+</mo><mrow id="S3.SS2.p2.2.m2.1.1.2.3" xref="S3.SS2.p2.2.m2.1.1.2.3.cmml"><mn id="S3.SS2.p2.2.m2.1.1.2.3.2" xref="S3.SS2.p2.2.m2.1.1.2.3.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.2.m2.1.1.2.3.1" xref="S3.SS2.p2.2.m2.1.1.2.3.1.cmml">×</mo><mn id="S3.SS2.p2.2.m2.1.1.2.3.3" xref="S3.SS2.p2.2.m2.1.1.2.3.3.cmml">0.15</mn></mrow></mrow><mo id="S3.SS2.p2.2.m2.1.1.1" xref="S3.SS2.p2.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml">0.8</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><eq id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1"></eq><apply id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2"><plus id="S3.SS2.p2.2.m2.1.1.2.1.cmml" xref="S3.SS2.p2.2.m2.1.1.2.1"></plus><cn type="float" id="S3.SS2.p2.2.m2.1.1.2.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2.2">0.5</cn><apply id="S3.SS2.p2.2.m2.1.1.2.3.cmml" xref="S3.SS2.p2.2.m2.1.1.2.3"><times id="S3.SS2.p2.2.m2.1.1.2.3.1.cmml" xref="S3.SS2.p2.2.m2.1.1.2.3.1"></times><cn type="integer" id="S3.SS2.p2.2.m2.1.1.2.3.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2.3.2">2</cn><cn type="float" id="S3.SS2.p2.2.m2.1.1.2.3.3.cmml" xref="S3.SS2.p2.2.m2.1.1.2.3.3">0.15</cn></apply></apply><cn type="float" id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3">0.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">0.5+2\times 0.15=0.8</annotation></semantics></math>.
Therefore, in order to have a normalized sum of weights (equal to 1), the rest of the time series in the subset will share the rest of the weight <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mn id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><cn type="float" id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">0.2</annotation></semantics></math>.
We should note that the process of generating synthetic time series leveraged only the training set thus eliminating any bias due to having seen the test set’s distribution.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">As for computing the average sequence, we adopted the DBA algorithm in our data augmentation framework.
Although other time series averaging methods exist in the literature, we chose the weighted version of DBA since it was already proposed as a data augmentation technique to solve the cold start problem when using a nearest neighbor classifier <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
Therefore we emphasize that other weighted averaging methods such as soft-DTW <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> could be used instead of DBA in our framework, but we leave such exploration for our future work.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">We did not test the effect of imbalanced classes in the training set and how it could affect the model’s generalization capabilities.
Note that imbalanced time series classification is a recent active area of research that merits an empirical study of its own <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
At last, we should add that the number of generated time series in our framework was chosen to be equal to double the amount of time series in the most represented class (which is a hyper-parameter of our approach that we aim to further investigate in our future work).</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental Setup</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We evaluated the data augmentation method for ResNet on the UCR archive <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, which is the largest publicly available TSC benchmark.
The archive is composed of datasets from different real world applications with varying characteristics such the number of classes and the size of the training set.
Finally, for training the deep learning models, we leveraged the high computational power of more than 60 GPUs in one huge cluster<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Our source code is available on <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/hfawaz/aaltd18</span></span></span></span>
We should also note that the same parameters’ initial values were used for all compared approaches, thus eliminating any bias due to the random initialization of the network’s weights.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Effect of data augmentation</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.2" class="ltx_p">Our results show that data augmentation can drastically improve the accuracy of a deep learning model while having a small negative impact on some datasets in the worst case scenario.
Figure <a href="#S4.F3.sf1" title="In Figure 3 ‣ 4.2 Effect of data augmentation ‣ 4 Results ‣ Data augmentation using synthetic data for time series classification with deep residual networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3a</span></a> shows the difference in accuracy between ResNet with and without data augmentation, it shows that the data augmentation technique does not lead a significant decrease in accuracy.
Additionally, we observe a huge increase of accuracy for the DiatomSizeReduction dataset (the accuracy increases from <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="30\%" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mn id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">30</mn><mo id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">30\%</annotation></semantics></math> to <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="96\%" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mn id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">96</mn><mo id="S4.SS2.p1.2.m2.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><csymbol cd="latexml" id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">96</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">96\%</annotation></semantics></math> when using data augmentation).</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">This result is very interesting for two main reasons.
First, DiatomSizeReduction has the smallest training set in the UCR archive <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> (with 16 training instances), which shows the benefit of increasing the number of training instances by generating synthetic time series.
Secondly, the DiatomSizeReduction dataset is the one where ResNet yield the worst accuracy without augmentation.
On the other hand, the 1-NN coupled with DTW (or the Euclidean distance) gives an accuracy of <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="97\%" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mrow id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mn id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml">97</mn><mo id="S4.SS2.p2.1.m1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2">97</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">97\%</annotation></semantics></math> which shows the relative easiness of this dataset where time series exhibit similarities that can be captured by the simple Euclidean distance, but missed by the deep ResNet due to the lack of training data (which is compensated by our data augmentation technique).
The results for the Wine dataset (57 training instances) also show an important improvement when using data augmentation.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.6" class="ltx_p">While we did show that deep ResNet can benefit from synthetic time series on some datasets, we did not manage to show any significant improvement over the whole UCR archive (<math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mi id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><ci id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">p</annotation></semantics></math>-value <math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="&gt;0.41" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><mrow id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mi id="S4.SS2.p3.2.m2.1.1.2" xref="S4.SS2.p3.2.m2.1.1.2.cmml"></mi><mo id="S4.SS2.p3.2.m2.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.cmml">&gt;</mo><mn id="S4.SS2.p3.2.m2.1.1.3" xref="S4.SS2.p3.2.m2.1.1.3.cmml">0.41</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><gt id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1"></gt><csymbol cd="latexml" id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2">absent</csymbol><cn type="float" id="S4.SS2.p3.2.m2.1.1.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3">0.41</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">&gt;0.41</annotation></semantics></math> for the Wilcoxon signed rank test).
Therefore, we decided to leverage an ensemble technique where we take into consideration the decisions of two ResNets (trained with and without data augmentation).
In fact, we average the a posteriori probability for each class over both classifier outputs, then assign for each time series the label for which the averaged probability is maximum, thus giving a more robust approach to out-of-sample generated time series.
The results in Figure <a href="#S4.F3.sf2" title="In Figure 3 ‣ 4.2 Effect of data augmentation ‣ 4 Results ‣ Data augmentation using synthetic data for time series classification with deep residual networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3b</span></a> show that the datasets which benefited the most from data augmentation exhibit almost no change to their accuracy improvement.
While on the other hand the number of datasets where data augmentation harmed the model’s accuracy decreased from <math id="S4.SS2.p3.3.m3.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S4.SS2.p3.3.m3.1a"><mn id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><cn type="integer" id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">30</annotation></semantics></math> to <math id="S4.SS2.p3.4.m4.1" class="ltx_Math" alttext="21" display="inline"><semantics id="S4.SS2.p3.4.m4.1a"><mn id="S4.SS2.p3.4.m4.1.1" xref="S4.SS2.p3.4.m4.1.1.cmml">21</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.4.m4.1b"><cn type="integer" id="S4.SS2.p3.4.m4.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1">21</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.4.m4.1c">21</annotation></semantics></math>.
The Wilcoxon signed rank test shows a significant difference (<math id="S4.SS2.p3.5.m5.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.SS2.p3.5.m5.1a"><mi id="S4.SS2.p3.5.m5.1.1" xref="S4.SS2.p3.5.m5.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.5.m5.1b"><ci id="S4.SS2.p3.5.m5.1.1.cmml" xref="S4.SS2.p3.5.m5.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.5.m5.1c">p</annotation></semantics></math>-value <math id="S4.SS2.p3.6.m6.1" class="ltx_Math" alttext="&lt;0.0005" display="inline"><semantics id="S4.SS2.p3.6.m6.1a"><mrow id="S4.SS2.p3.6.m6.1.1" xref="S4.SS2.p3.6.m6.1.1.cmml"><mi id="S4.SS2.p3.6.m6.1.1.2" xref="S4.SS2.p3.6.m6.1.1.2.cmml"></mi><mo id="S4.SS2.p3.6.m6.1.1.1" xref="S4.SS2.p3.6.m6.1.1.1.cmml">&lt;</mo><mn id="S4.SS2.p3.6.m6.1.1.3" xref="S4.SS2.p3.6.m6.1.1.3.cmml">0.0005</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.6.m6.1b"><apply id="S4.SS2.p3.6.m6.1.1.cmml" xref="S4.SS2.p3.6.m6.1.1"><lt id="S4.SS2.p3.6.m6.1.1.1.cmml" xref="S4.SS2.p3.6.m6.1.1.1"></lt><csymbol cd="latexml" id="S4.SS2.p3.6.m6.1.1.2.cmml" xref="S4.SS2.p3.6.m6.1.1.2">absent</csymbol><cn type="float" id="S4.SS2.p3.6.m6.1.1.3.cmml" xref="S4.SS2.p3.6.m6.1.1.3">0.0005</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.6.m6.1c">&lt;0.0005</annotation></semantics></math>).
The ensemble’s results are in compliance with the recent consensus in the TSC community, where ensembles tend to improve the individual classifiers’ accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/1808.02455/assets/x4.png" id="S4.F3.sf1.g1" class="ltx_graphics ltx_img_landscape" width="216" height="172" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>ResNet with/without augmentation</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/1808.02455/assets/x5.png" id="S4.F3.sf2.g1" class="ltx_graphics ltx_img_landscape" width="216" height="171" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>ResNet ensemble vs ResNet</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Accuracy of ResNet with and/or without data augmentation.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we showed how overfitting small time series datasets can be mitigated using a recent data augmentation technique that is based on DTW and a weighted version of the DBA algorithm.
These findings are very interesting since no previous observation made a link between the space induced by the classic DTW and the features learned by the CNNs, whereas our experiments showed that by providing enough time series, CNNs are able to learn time invariant features that are useful for classification.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">In our future work, we aim to further test other variant weighting schemes for the DTW-based data augmentation technique, while providing a method that predicts when and for which datasets, data augmentation would be beneficial.</p>
</div>
<section id="S5.SS0.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Acknowledgements</h4>

<div id="S5.SS0.SSSx1.p1" class="ltx_para">
<p id="S5.SS0.SSSx1.p1.1" class="ltx_p">We would like to thank NVIDIA Corp. for the Quadro P6000 grant and the Mésocentre of Strasbourg for providing access to the cluster.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Bagnall, A., Lines, J., Bostrom, A., Large, J., Keogh, E.: The great time
series classification bake off: a review and experimental evaluation of
recent algorithmic advances. Data Mining and Knowledge Discovery
<span id="bib.bib1.1.1" class="ltx_text ltx_font_bold">31</span>(3), 606–660 (2017)

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Bengio, Y., Bastien, F., Bergeron, A., Boulanger–Lewandowski, N., Breuel, T.,
Chherawala, Y., Cisse, M., Côté, M., Erhan, D., Eustache, J., Glorot, X.,
Muller, X., Lebeuf, S.P., Pascanu, R., Rifai, S., Savard, F., Sicard, G.:
Deep learners benefit more from out-of-distribution examples. In:
International Conference on Artificial Intelligence and Statistics. vol. 15,
pp. 164–172 (2011)

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Chen, Y., Keogh, E., Hu, B., Begum, N., Bagnall, A., Mueen, A., Batista, G.:
The ucr time series classification archive (July 2015)

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Cui, Z., Chen, W., Chen, Y.: Multi-Scale Convolutional Neural Networks
for Time Series Classification. ArXiv e-prints (2016)

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Cutur, M., Blondel, M.: Soft-DTW: a Differentiable Loss Function for
Time-Series. In: International Conference on Machine Learning (2017)

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Forestier, G., Petitjean, F., Dau, H.A., Webb, G.I., Keogh, E.J.: Generating
synthetic time series to augment sparse datasets. In: IEEE International
Conference on Data Mining. pp. 865–870 (2017)

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Geng, Y., Luo, X.: Cost-sensitive convolution based neural networks for
imbalanced time-series classification. ArXiv (2018)

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Glorot, X., Bengio, Y.: Understanding the difficulty of training deep
feedforward neural networks. In: International Conference on Artificial
Intelligence and Statistics. vol. 9, pp. 249–256 (2010)

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image
recognition. In: IEEE Computer Vision and Pattern Recognition. pp. 770–778
(2016)

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Ioffe, S., Szegedy, C.: Batch normalization: Accelerating deep network training
by reducing internal covariate shift. In: International Conference on Machine
Learning. vol. 37, pp. 448–456 (2015)

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. In:
International Conference on Learning Representations (2015)

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Krell, M.M., Seeland, A., Kim, S.K.: Data Augmentation for
Brain-Computer Interfaces: Analysis on Event-Related Potentials Data. ArXiv
(2018)

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep
convolutional neural networks. In: Advances in Neural Information Processing
Systems 25, pp. 1097–1105 (2012)

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Kvamme, H., Sellereite, N., Aas, K., Sjursen, S.: Predicting mortgage default
using convolutional neural networks. Expert Systems with Applications
<span id="bib.bib14.1.1" class="ltx_text ltx_font_bold">102</span>, 207 – 217 (2018)

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Le Guennec, A., Malinowski, S., Tavenard, R.: Data Augmentation for Time
Series Classification using Convolutional Neural Networks. In: ECML/PKDD on
Advanced Analytics and Learning on Temporal Data (2016)

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
LeCun, Y., Bengio, Y., Hinton, G.: Deep learning. Nature <span id="bib.bib16.1.1" class="ltx_text ltx_font_bold">521</span>,
436–444 (2015)

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Petitjean, F., Forestier, G., Webb, G.I., Nicholson, A.E., Chen, Y., Keogh, E.:
Dynamic time warping averaging of time series allows faster and more accurate
classification. In: Data Mining (ICDM), 2014 IEEE International Conference
on. pp. 470–479. IEEE (2014)

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Petitjean, F., Forestier, G., Webb, G.I., Nicholson, A.E., Chen, Y., Keogh, E.:
Faster and more accurate classification of time series by exploiting a novel
dynamic time warping averaging algorithm. Knowledge and Information Systems
<span id="bib.bib18.1.1" class="ltx_text ltx_font_bold">47</span>(1), 1–26 (2016)

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Petitjean, F., Ketterlin, A., Gançarski, P.: A global averaging method for
dynamic time warping, with applications to clustering. Pattern Recognition
<span id="bib.bib19.1.1" class="ltx_text ltx_font_bold">44</span>(3), 678 – 693 (2011)

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Um, T.T., Pfister, F.M.J., Pichler, D., Endo, S., Lang, M., Hirche, S.,
Fietzek, U., Kulić, D.: Data augmentation of wearable sensor data for
parkinson’s disease monitoring using convolutional neural networks. In: ACM
International Conference on Multimodal Interaction. pp. 216–220 (2017)

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Wang, Z., Yan, W., Oates, T.: Time series classification from scratch with deep
neural networks: A strong baseline. In: International Joint Conference on
Neural Networks. pp. 1578–1585 (2017)

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Zhang, C., Bengio, S., Hardt, M., Recht, B., Vinyals, O.: Understanding deep
learning requires rethinking generalization. In: International Conference on
Learning Representations (2017)

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/1808.02454" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/1808.02455" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+1808.02455">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/1808.02455" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/1808.02456" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar 16 18:37:04 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
