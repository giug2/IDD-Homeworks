<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_title_document">
  LLM-Mediated Domain-Specific Voice Agents:
  <span class="ltx_text ltx_font_italic" id="id1.id1">
   The Case of TextileBot
  </span>
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Shu Zhong
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     Department of Computer Science, University College London
    </span>
   </span>
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Elia Gatti
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     Department of Computer Science, University College London
    </span>
   </span>
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    James Hardwick
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     Department of Computer Science, University College London
    </span>
   </span>
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Miriam Ribul
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     Materials Science Research Centre, Royal College of Art
    </span>
   </span>
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Youngjun Cho
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     Department of Computer Science, University College London
    </span>
   </span>
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Marianna Obrist
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     Department of Computer Science, University College London
    </span>
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id2.id1">
   Developing domain-specific conversational agents (CAs) has been challenged by the need for extensive domain-focused data. Recent advancements in Large Language Models (LLMs) make them a viable option as a knowledge backbone. LLMs behaviour can be enhanced through prompting, instructing them to perform downstream tasks in a zero-shot fashion (
   <span class="ltx_text ltx_font_italic" id="id2.id1.1">
    i.e.
   </span>
   without training). To this end, we incorporated structural knowledge into prompts and used prompted LLMs to build domain-specific voice-based CAs.
We demonstrate this approach for the specific domain of textile circularity in form of the design, development, and evaluation of TextileBot. We present the design and development of the voice agent TextileBot and also the insights from an in-person user study (N=30) evaluating three variations of TextileBots. We analyse the human-agent interactions, combining quantitative and qualitative methods. Our results suggest that participants engaged in multi-turn conversations, and their perceptions of the three variation agents and respective interactions varied demonstrating the effectiveness of our prompt-based LLM approach. We discuss the dynamics of these interactions and their implications for designing future voice-based CAs.
  </p>
  <p class="ltx_p" id="id3.id2">
   The results show that our method’s potential for building domain-specific CAs. Furthermore, most participants engaged in multi-turn conversations, and their perceptions of the three voice agents and respective interactions varied demonstrating the effectiveness of our prompt-based LLM approach. We discuss the dynamics of these interactions and their implications for designing future voice-based CAs.
  </p>
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <div class="ltx_para ltx_noindent" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    The potential for designing conversational interfaces through the use of pre-trained large language models (LLMs) has gained substantial attention
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib106" title="">
      106
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib48" title="">
      48
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib56" title="">
      56
     </a>
     ]
    </cite>
    . These LLMs possess remarkable capabilities to comprehend human language, generate text in a human-like way, and execute various tasks with only a few text
    <em class="ltx_emph ltx_font_italic" id="S1.p1.1.1">
     prompts
    </em>
    at run time, even without any additional training
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib28" title="">
      28
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib64" title="">
      64
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib79" title="">
      79
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib14" title="">
      14
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib72" title="">
      72
     </a>
     ]
    </cite>
    . A prompt is a piece of text input to the LLM to elicit a response. For instance, a prompt can be
    <em class="ltx_emph ltx_font_italic" id="S1.p1.1.2">
     “What is sustainable fashion? Please explain it to a 10-year-old kid.”
    </em>
    . This has significantly lowered the entry barriers for artificial intelligence (AI) access, allowing non-experts to interact with LLMs through text. However, designing such prompts manually poses a particular challenge, as accurate and concise encapsulation of the complex, domain-specific knowledge is needed to guide the model towards a specific domain. This is due to the inherent task-agnostic nature of vanilla LLMs
    <span class="ltx_note ltx_role_footnote" id="footnote1">
     <sup class="ltx_note_mark">
      1
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        1
       </sup>
       <span class="ltx_tag ltx_tag_note">
        1
       </span>
       Vanilla model refers to an LLM without fine-tuning or prompting.
      </span>
     </span>
    </span>
    , which are not fine-tuned for specific domains. Additionally, another drawback of pre-trained vanilla LLMs is their lack of conversational memory, which restricts interactions to a ‘single turn’ manner
    <span class="ltx_note ltx_role_footnote" id="footnote2">
     <sup class="ltx_note_mark">
      2
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        2
       </sup>
       <span class="ltx_tag ltx_tag_note">
        2
       </span>
       A one-time exchange between a user and an AI system or another person in a conversation counts as one turn.
      </span>
     </span>
    </span>
    . This limitation affects the continuity and depth of user interactions, as these models cannot recall their previous inputs and outputs.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    The human-computer interaction (HCI) community is seeing a rising emphasis on the development of voice-based conversational agents
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib95" title="">
      95
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib9" title="">
      9
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib94" title="">
      94
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib40" title="">
      40
     </a>
     ]
    </cite>
    . Seaborn
    <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">
     et al.
    </span>
    found that only 13% of studies in voice-based human-agent interaction (vHAI) used an autonomous setup, fully controlled by participants
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib84" title="">
      84
     </a>
     ]
    </cite>
    . This limited adoption is primarily due to the complexity of creating voice agents. The advent of LLMs now enables real-time conversational interactions with humans, eliminating the necessity for constructing intricate heuristic-based conversation rules from scratch.
In addition, the development of domain-specific conversational agents has long been hindered by data scarcity
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib7" title="">
      7
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib51" title="">
      51
     </a>
     ]
    </cite>
    . Collecting and annotating the data for these agents is an expensive and labour-intensive process that requires considerable resources
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib27" title="">
      27
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib105" title="">
      105
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib37" title="">
      37
     </a>
     ]
    </cite>
    . This has then necessitated exploring cost-effective approaches for developing domain-specific conversational agents. In essence, we are interested in how to efficiently combine the knowledge in general-purpose LLMs together with the structural domain knowledge from human experts.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    To this end, we introduce an approach that uses LLMs in a zero-shot manner (
    <span class="ltx_text ltx_font_italic" id="S1.p3.1.1">
     i.e.
    </span>
    without training), coupled with the knowledge from domain human experts. This approach also facilitates researchers, who may not be AI experts, in prototyping domain-specific conversational agents. We propose a novel three-phase method designed to transfer LLMs from task-agnostic to domain-specific voice-based CAs and offer personalized interactions.
The first phase involves the creation of a Taxonomy-based Knowledge Structure Chain, a novel prompt generation method. We prompted LLMs as a knowledge foundation model instead of traditional method in building a dialogue system (see Figure
    <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    ). It eliminates the need for domain-specific data collection while allowing human experts to inject their structural knowledge into the LLM.
The second phase involves a Prompt Refinement strategy that enables LLMs to interact with users with varying breadth and freedom, providing LLMs with different levels of domain-focusness and varying conversational styles. Finally, a System Optimization is introduced to facilitate LLMs engaging with users in continuous interactions, allowing the LLM to retain statefulness with memory, enabling long-last “multi-turn” conversations. Notably, these phases can be applied individually or in conjunction to boost CA’s design.
   </p>
  </div>
  <figure class="ltx_figure" id="S1.F1">
   <div class="ltx_flex_figure">
    <div class="ltx_flex_cell ltx_flex_size_2">
     <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf1">
      <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="183" id="S1.F1.sf1.g1" src="/html/2406.10590/assets/x1.png" width="452"/>
      <figcaption class="ltx_caption ltx_centering">
       <span class="ltx_tag ltx_tag_figure">
        (a)
       </span>
       Traditional
      </figcaption>
     </figure>
    </div>
    <div class="ltx_flex_cell ltx_flex_size_2">
     <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf2">
      <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="183" id="S1.F1.sf2.g1" src="/html/2406.10590/assets/x2.png" width="452"/>
      <figcaption class="ltx_caption ltx_centering">
       <span class="ltx_tag ltx_tag_figure">
        (b)
       </span>
       LLM-based
      </figcaption>
     </figure>
    </div>
   </div>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 1:
    </span>
    (a) Traditional and (b) LLM-based conversational agents with voice inputs and outputs. The traditional agent has various components such as NLU, NLG and Dialogue database searching. In contrast, the LLM-based agent simply uses the database to generate prompts for the LLM, enabling a much simpler and easy-to-develop pipeline.
   </figcaption>
  </figure>
  <div class="ltx_para ltx_noindent" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    To showcase our approach, we present TextileBot, a voice interface that conveys the topic of
    <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S1.p4.1.1">
     textiles circularity
    </em>
    developed on a Raspberry Pi. We evaluate TextileBot’s effectiveness through a subjective user study, focusing on a human-in-the-loop strategy to foster human-centered AI design. Success will be measured by the participants’ ability to discern the unique CA characteristics crafted through our approach and the system’s proficiency in maintaining domain-specific, multi-turn conversations. This evaluation integrates both quantitative data and qualitative insights. Additionally, we uncovered the complex dynamics of these human-agent interactions and explored various facets of human behaviour, engagement, and responses.
Our research address two timely questions: First, while LLMs as foundation models for general-purpose conversational agents have been studied
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib106" title="">
      106
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib48" title="">
      48
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib56" title="">
      56
     </a>
     ]
    </cite>
    , their application in creating domain-specific voice agents is less understood. Second, there is limited understanding of how humans perceive and interact domain-specific voiced-based CAs powered by prompted LLMs.
These knowledge gaps stem from various intertwined factors including the inherent complexity of natural languages, technical challenges associated with text-to-speech integration, the ability to handle ambiguity and context in human speech, and the imperative need for effective user experience design to facilitate seamless and meaningful user interactions with the system
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib9" title="">
      9
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib84" title="">
      84
     </a>
     ]
    </cite>
    .
In summary, the main contributions of this paper are three-fold:
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p5">
   <ul class="ltx_itemize" id="S1.I1">
    <li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i1.p1">
      <p class="ltx_p" id="S1.I1.i1.p1.1">
       We develop a novel three-phase method that enables LLMs to transform from task-agnostic to domain-specific, adapting different conversational styles and incorporating memory for continues conversation. These phases can be used individually or in combination, depending on the task at hand.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i2.p1">
      <p class="ltx_p" id="S1.I1.i2.p1.1">
       We integrate the three-phase method into a design of a domain-specific voice-based device,
       <span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.1">
        i.e.
       </span>
       , TextileBot. This voice-based agent is custom-designed for the textile circularity domain, facilitating tailored conversations with consumers regarding circular economy practices within the textile industry.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para ltx_noindent" id="S1.I1.i3.p1">
      <p class="ltx_p" id="S1.I1.i3.p1.1">
       We evaluated three variations of TextileBot through in-person interactions to assess our approach’s effectiveness and to better understand user interactions. We analyzed these human-agent interactions, providing qualitative descriptions and quantitative insights. This analysis aims to inform potential design improvements in the wider domain of AI-enabled voice interfaces.
      </p>
     </div>
    </li>
   </ul>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Background and Related Work
  </h2>
  <div class="ltx_para ltx_noindent" id="S2.p1">
   <p class="ltx_p" id="S2.p1.1">
    In this section, we explain our rationale for choosing textiles circularity as our applied domain. Following this, we give an overview of voice-based CAs and related literature focusing on human interaction with traditional heuristics-guided voice-based CAs. Subsequently, we introduce recent advancements in pre-trained LLMs and HCI research related to LLMs-mediated interfaces.
   </p>
  </div>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1
    </span>
    The Domain of Textiles Circularity: A Case for Voice Agents Design
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     We choose to develop a conversational agent specifically for the
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S2.SS1.p1.1.1">
      textiles circularity
     </em>
     domain to demonstrate our method effectively. Textiles circularity is circular economy for textiles, and it refers to the sustainable practice in the textile industry where materials are reused, recycled, or biodegraded to minimize waste and reduce environmental impact
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib31" title="">
       31
      </a>
      ]
     </cite>
     .
This domain offers diverse information and expertise from various areas, including fashion, home textiles, supply chain management, materials science, and manufacturing
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p1.1.2">
      etc.
     </span>
     The complexity and diversity of conversations within this domain make it an ideal choice for showcasing the capabilities of our CA.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p2">
    <p class="ltx_p" id="S2.SS1.p2.1">
     Another main reason behind our focus on the textile industry is its significant contribution to global carbon emissions. In fact, the textile industry alone accounts for 10% of global carbon emissions, which is as much as the combined emissions from international flights and maritime shipping
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib74" title="">
       74
      </a>
      ]
     </cite>
     . This alarming environmental impact highlights the urgent need for sustainable practices within the sector. The challenge of incorporating circularity, particularly in recycling of textile fibres into new textile fibres, is complex due to the broad spectrum of knowledge required. We anticipate that conversational agents, integrated with expert knowledge, will provide a more accessible mean of understanding and communicating the concept of textile circularity with the general public. We anticipate that this approach could also be adapted for educational purposes.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p3">
    <p class="ltx_p" id="S2.SS1.p3.1">
     Furthermore, CAs are increasingly being utilized in the fashion retail sector for a variety of purposes
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib5" title="">
       5
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib10" title="">
       10
      </a>
      ]
     </cite>
     , offering significant opportunities to foster socially responsible behaviours. Among these, promoting sustainability communication as an integral component of business strategies stands out as a notable application
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib23" title="">
       23
      </a>
      ]
     </cite>
     . We believe that our approach can bring social and economic benefits to the textiles circularity domain. For example, the conversational agent could be situated in a store, offering valuable insights into how consumer clothing choices might affect their well-being and the environment.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2
    </span>
    Domain Specific Conversational Agents
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     Classic CAs typically comprise Natural Language Understanding (NLU) and Natural Language Generation (NLG) components, along with a database-driven dialogue management system
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib5" title="">
       5
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib51" title="">
       51
      </a>
      ]
     </cite>
     . This dialogue system design can be broken down into various building blocks, namely dialogue database, dialogue searching and dialogue management. Building a dialogue system is a complex task requiring extensive domain knowledge and data.
Alternatively, an end-to-end model can be trained using collected data, although this usually necessitates a large amount of training data to cover the different possible dialogues when deployed. In these approaches, the development of CAs is normally impeded by the lack of available data and the cost of annotating it
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib65" title="">
       65
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib32" title="">
       32
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib7" title="">
       7
      </a>
      ]
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p2">
    <p class="ltx_p" id="S2.SS2.p2.1">
     This complexity can also hamper research in voice-based human-agent interaction (vHAI). While CA user interface is a popular topic in the HCI community, studies on domain focused CAs are relatively rare. Thus, this section focuses on a broader range of voice agents. Seaborn
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p2.1.1">
      et al.
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib84" title="">
       84
      </a>
      ]
     </cite>
     conducted a survey that identified four main methods for carrying out human voice interaction studies: autonomous setup, semi-autonomous setup, “Wizard of Oz” setup
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib26" title="">
       26
      </a>
      ]
     </cite>
     , and conversations under given scenarios - with respective usage rates of 13%, 24%, 27%, and 33%. Notably, just 13% used an autonomous setup – a design where the system can operate without the involvement of an experimenter and the participants control the interactions.
As mentioned earlier, creating fully automated CAs presents technical challenges (
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p2.1.2">
      e.g.
     </span>
     data scarcity and high monetary cost). These difficulties impede the comprehension of the human-agent interactions, thereby obstructing the design of effective autonomous CAs
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib104" title="">
       104
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib106" title="">
       106
      </a>
      ]
     </cite>
     . In addition, the evaluation of conversational agents is largely performed using crowdworkers
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib51" title="">
       51
      </a>
      ]
     </cite>
     . These evaluations are also mostly conducted in non-goal-oriented conversations (
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p2.1.3">
      a.k.a
     </span>
     task-agnostic)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib92" title="">
       92
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib86" title="">
       86
      </a>
      ]
     </cite>
     . In our work, we conducted an in-person study where participants directly controlled the voice agent interaction without mediation from experimenters. Moreover, our evaluation includes both non-goal-oriented tasks and goal-oriented tasks.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S2.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      2.2.1
     </span>
     Voice-Based Human-Agent Interaction
    </h4>
    <div class="ltx_para ltx_noindent" id="S2.SS2.SSS1.p1">
     <p class="ltx_p" id="S2.SS2.SSS1.p1.1">
      This work presents an LLM-mediated voice agent specialized in textiles circularity, designed to operate via a device designed by ourselves. It’s important to note that this agent differs from conventional voice-based devices such as Alexa and Google Home, which are categorized as voice assistants (VAs). These voice assistants are not domain-specific in terms of their scope and functionality
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib80" title="">
        80
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib84" title="">
        84
       </a>
       ]
      </cite>
      , domain-specific agents focus on specific areas with detailed, context-aware responses, while VAs provide a wide array of services such as weather updates. Multiple studies suggest that voice assistants often fail to meet user expectations due to limited understanding or response
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib24" title="">
        24
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib42" title="">
        42
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib9" title="">
        9
       </a>
       ]
      </cite>
      .
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S2.SS2.SSS1.p2">
     <p class="ltx_p" id="S2.SS2.SSS1.p2.1">
      Researchers have studied voiced-based human-agent interaction (vHAI)
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib94" title="">
        94
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib58" title="">
        58
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib9" title="">
        9
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib95" title="">
        95
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib40" title="">
        40
       </a>
       ]
      </cite>
      . Some studies have explored factors that affected users’ preference between voice and text inputs
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib94" title="">
        94
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib69" title="">
        69
       </a>
       ]
      </cite>
      , while others discussed how user experience might be improved through enriching the personalities of the conversational agent
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib96" title="">
        96
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib22" title="">
        22
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib12" title="">
        12
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib25" title="">
        25
       </a>
       ]
      </cite>
      . Hoegen
      <span class="ltx_text ltx_font_italic" id="S2.SS2.SSS1.p2.1.1">
       et al.
      </span>
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib41" title="">
        41
       </a>
       ]
      </cite>
      found that voice agents that can conduct naturalistic multi-turn dialogue and are aligned with the participants’ conversational style will increase user trust. Baughan
      <span class="ltx_text ltx_font_italic" id="S2.SS2.SSS1.p2.1.2">
       et al.
      </span>
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib9" title="">
        9
       </a>
       ]
      </cite>
      used interviews and surveys to understand how voice assistant failures impact user trust and willingness to rely on them for future tasks. Haas
      <span class="ltx_text ltx_font_italic" id="S2.SS2.SSS1.p2.1.3">
       et al.
      </span>
      discovered that users prefer voice assistants to “keep it short” in their responses
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib38" title="">
        38
       </a>
       ]
      </cite>
      .
Also, Völkel
      <span class="ltx_text ltx_font_italic" id="S2.SS2.SSS1.p2.1.4">
       et al.
      </span>
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib95" title="">
        95
       </a>
       ]
      </cite>
      presented a rule-based dialogue design to give voice assistants distinct personalities and asked users to rate their preferences. They found that there is a connection between user personality traits and their voice assistant preferences.
The voice-based agents used in these studies have primarily followed canonical approaches that are mostly in a “Wizard of Oz” manner, or are manipulated by human. However, our work stands out as the first endeavour to explore how humans interact with
      <span class="ltx_text ltx_font_italic" id="S2.SS2.SSS1.p2.1.5">
       LLM-mediated voice agents
      </span>
      and utilizes prompting techniques to design agents with distinct personas, response manners, and conversational freedom. We also offer novel insights into LLM-mediated voice agents’ design and interaction possibilities.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S2.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.3
    </span>
    Large Language Models
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p1">
    <p class="ltx_p" id="S2.SS3.p1.1">
     Historically, NLP models have gone through a shift from a
     <em class="ltx_emph ltx_font_italic" id="S2.SS3.p1.1.1">
      fully supervised learning
     </em>
     paradigm, focusing on
     <em class="ltx_emph ltx_font_italic" id="S2.SS3.p1.1.2">
      feature engineering
     </em>
     (
     <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.1.3">
      e.g.
     </span>
     word identity
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib52" title="">
       52
      </a>
      ]
     </cite>
     ) and
     <em class="ltx_emph ltx_font_italic" id="S2.SS3.p1.1.4">
      architecture engineering
     </em>
     (
     <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.1.5">
      e.g.
     </span>
     self-attention
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib91" title="">
       91
      </a>
      ]
     </cite>
     ), to a pre-train and fine-tune approach
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib63" title="">
       63
      </a>
      ]
     </cite>
     with neural networks. Recently, the advent of pre-trained LLMs like GPT-3 has catalyzed a new
     <em class="ltx_emph ltx_font_italic" id="S2.SS3.p1.1.6">
      ”pre-train and prompt”
     </em>
     paradigm
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib72" title="">
       72
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib85" title="">
       85
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib63" title="">
       63
      </a>
      ]
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p2">
    <p class="ltx_p" id="S2.SS3.p2.1">
     In the
     <em class="ltx_emph ltx_font_italic" id="S2.SS3.p2.1.1">
      pre-train and fine-tune
     </em>
     paradigm, fixed architecture models are trained with a large corpus of text data, typically several billion words or more, such as books, articles, or conversations, to learn general-purpose features of a language,
     <span class="ltx_text ltx_font_italic" id="S2.SS3.p2.1.2">
      e.g.
     </span>
     BART
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib57" title="">
       57
      </a>
      ]
     </cite>
     and UniLM
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib29" title="">
       29
      </a>
      ]
     </cite>
     . The
     <em class="ltx_emph ltx_font_italic" id="S2.SS3.p2.1.3">
      pre-trained
     </em>
     LLMs can then be adapted (
     <span class="ltx_text ltx_font_italic" id="S2.SS3.p2.1.4">
      e.g.
     </span>
     fine-tuned) to a broad range of downstream tasks (such as machine translation, text entailment, sentiment analysis,
     <span class="ltx_text ltx_font_italic" id="S2.SS3.p2.1.5">
      etc.
     </span>
     ) with a task-specific loss function. Large Language Models (LLMs), such as BERT (Bidirectional Encoder Representations from Transformers)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib28" title="">
       28
      </a>
      ]
     </cite>
     , RoBERTa
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib64" title="">
       64
      </a>
      ]
     </cite>
     , T5
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib79" title="">
       79
      </a>
      ]
     </cite>
     , and GPT-3 (Generative Pre-training Transformer 3)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib14" title="">
       14
      </a>
      ]
     </cite>
     , are now used as
     <em class="ltx_emph ltx_font_italic" id="S2.SS3.p2.1.6">
      foundation models
     </em>
     <span class="ltx_note ltx_role_footnote" id="footnote3">
      <sup class="ltx_note_mark">
       3
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         3
        </sup>
        <span class="ltx_tag ltx_tag_note">
         3
        </span>
        A model trained on a large corpus of data that can be adapted to a wide range of downstream tasks
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib13" title="">
          13
         </a>
         ]
        </cite>
        .
       </span>
      </span>
     </span>
     for downstream tasks in NLP, paving the way toward task-agnostic machine learning
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib13" title="">
       13
      </a>
      ]
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p3">
    <p class="ltx_p" id="S2.SS3.p3.1">
     LLMs have experienced significant breakthroughs recently in terms of their ability to understand and generate human-like text
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib63" title="">
       63
      </a>
      ]
     </cite>
     . GPT-3
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib14" title="">
       14
      </a>
      ]
     </cite>
     , with 175 billion parameters, stands out with its ability to execute various text-related tasks with only a few text
     <em class="ltx_emph ltx_font_italic" id="S2.SS3.p3.1.1">
      prompts
     </em>
     at run time, even without any additional training. This is known as the (
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S2.SS3.p3.1.2">
      zero-shot
     </em>
     ) capability, as its paper title
     <em class="ltx_emph ltx_font_italic" id="S2.SS3.p3.1.3">
      “Language Models are Few-Shot Learners”
     </em>
     suggests
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib14" title="">
       14
      </a>
      ]
     </cite>
     . This capability highlights an evolution in model application, moving towards a
     <em class="ltx_emph ltx_font_italic" id="S2.SS3.p3.1.4">
      “pre-train and prompt”
     </em>
     paradigm
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib72" title="">
       72
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib85" title="">
       85
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib63" title="">
       63
      </a>
      ]
     </cite>
     .
Consequently, considerable effort has been invested in the research of
     <em class="ltx_emph ltx_font_italic" id="S2.SS3.p3.1.5">
      prompt engineering
     </em>
     , which aims to design efficient prompts to guide LLMs to perform various downstream tasks
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib14" title="">
       14
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib85" title="">
       85
      </a>
      ]
     </cite>
     . For instance, prompts such as
     <em class="ltx_emph ltx_font_italic" id="S2.SS3.p3.1.6">
      “What is material fibre? Explain to a fashion designer.”
     </em>
     and
     <em class="ltx_emph ltx_font_italic" id="S2.SS3.p3.1.7">
      “What is material fibre? Explain to a chemist.”
     </em>
     will generate different outputs. This also implies a substantial step toward lowering the barriers for AI non-experts to interact with LLMs for various tasks by using only prompts
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib45" title="">
       45
      </a>
      ]
     </cite>
     .
    </p>
   </div>
   <section class="ltx_subsubsection" id="S2.SS3.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      2.3.1
     </span>
     Human-LLM Interaction
    </h4>
    <div class="ltx_para ltx_noindent" id="S2.SS3.SSS1.p1">
     <p class="ltx_p" id="S2.SS3.SSS1.p1.1">
      The rise of prompting LLMs presents a promising alternative for CA design
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib106" title="">
        106
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib48" title="">
        48
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib56" title="">
        56
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib13" title="">
        13
       </a>
       ]
      </cite>
      . HCI researchers have been increasingly interested in harnessing the power of LLMs and enabling a plethora of language-based interactive applications. Examples of such applications include creative writing
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib54" title="">
        54
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib21" title="">
        21
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib17" title="">
        17
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib43" title="">
        43
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib16" title="">
        16
       </a>
       ]
      </cite>
      , iterative query reformulation (e.g., question answering)
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib98" title="">
        98
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib4" title="">
        4
       </a>
       ]
      </cite>
      , writing code
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib90" title="">
        90
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib8" title="">
        8
       </a>
       ]
      </cite>
      , and creating novel user interfaces
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib98" title="">
        98
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib100" title="">
        100
       </a>
       ]
      </cite>
      .
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S2.SS3.SSS1.p2">
     <p class="ltx_p" id="S2.SS3.SSS1.p2.1">
      However, most of the existing interaction frameworks focus on “single-turn” interaction, where a “turn” means one back-and-forth interaction on a specific topic; this can be either the user speaks, then the bot follows or vice-versa. In our work, we focus on a “multi-turn” and “continuous” interaction (dyadic), where the agent would need to react coherently and be able to memorise previous interaction rounds.
One particular relevant literature to our work is from
Zamfirescu-Pereira
      <span class="ltx_text ltx_font_italic" id="S2.SS3.SSS1.p2.1.1">
       et al.
      </span>
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib106" title="">
        106
       </a>
       ]
      </cite>
      . They explored the use of prompting for fast CA design, specifically for text-based chatbots, and suggested that this method can achieve ”80%” of the user experience (UX) goal. However, the actual user perception and interactions with such CAs were not explored.
In our work, we carefully designed our prompt templates and further carefully investigated the users’ perception and interaction using both qualitative and quantitative methods.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S2.SS3.SSS1.p3">
     <p class="ltx_p" id="S2.SS3.SSS1.p3.1">
      Currently, the performance of LLMs has been widely
evaluated using numerical metrics without incorporating human participants
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib72" title="">
        72
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib60" title="">
        60
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib14" title="">
        14
       </a>
       ]
      </cite>
      . For instance, metrics, such as perplexity and BLEU (bilingual evaluation understudy) score
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib73" title="">
        73
       </a>
       ]
      </cite>
      , are popular for evaluating LLMs performance on downstream tasks.
These evaluations lack human-in-the-loop. To better understand the quality of human-LLM interactions, Lee
      <span class="ltx_text ltx_font_italic" id="S2.SS3.SSS1.p3.1.1">
       et al.
      </span>
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib55" title="">
        55
       </a>
       ]
      </cite>
      proposed the Human-AI Language-based Interaction Evaluation (HALIE) framework, utilizing interaction traces, and suggested novel metrics related to user experience and interaction quality for assessing the LLM’s capabilities. In our design, we adopted several important metrics (including Ease, Change, Enjoyment, Reuse and Accuracy, fully described in Section
      <a class="ltx_ref" href="#S5.SS1" title="5.1 Study design and methods ‣ 5 Evaluation of TextileBot ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
       <span class="ltx_text ltx_ref_tag">
        5.1
       </span>
      </a>
      ) from Lee
      <span class="ltx_text ltx_font_italic" id="S2.SS3.SSS1.p3.1.2">
       et al.
      </span>
      to facilitate human-in-the-loop evaluation for our LLM-mediated voice agent.
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   Prototyping Domain-Specific Voice Agents
  </h2>
  <div class="ltx_para ltx_noindent" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    In this section, we present a zero-shot prototyping framework designed to enable a wider spectrum of users to prototype conversational agents (CAs) across various domains. Our novel method encompasses three distinct phases: (1) a Taxonomy-based Knowledge Structure Chain for effectively injecting domain knowledge, (2) a prompt refinement strategy
    <em class="ltx_emph ltx_font_italic" id="S3.p1.1.1">
     from task agnostic to domain specific
    </em>
    , and (3) a system optimization to equip LLMs with conversational memory enabling
    <em class="ltx_emph ltx_font_italic" id="S3.p1.1.2">
     continuous (multi-turn)
    </em>
    human-LLM interactions. Figure
    <a class="ltx_ref" href="#S1.F1.sf2" title="In Figure 1 ‣ 1 Introduction ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
     <span class="ltx_text ltx_ref_tag">
      1(b)
     </span>
    </a>
    illustrates how our prompt-based LLM approach is different from the traditional conversational agent design. To demonstrate the practical application of this method, we present two implementations of our prompting approach within the context of textiles circularity, namely TextileBot-Expert and TextileBot-Assistant.
   </p>
  </div>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1
    </span>
    Phase 1: Taxonomy-based Knowledge Structure Chain
   </h3>
   <figure class="ltx_figure" id="S3.F2">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="192" id="S3.F2.g1" src="/html/2406.10590/assets/images/taxprompt.png" width="598"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 2:
     </span>
     Taxonomy-Based Knowledge Structure Chain. This process requires domain-specific expertise to construct or utilize pre-existing structured knowledge frameworks,
     <span class="ltx_text ltx_font_italic" id="S3.F2.6.1">
      eg.
     </span>
     taxonomies. To craft the Taxonomy-bind prompts, in every single prompt (
     <span class="ltx_text ltx_font_italic" id="S3.F2.7.2">
      eg.
     </span>
     <span class="ltx_text" id="S3.F2.8.3" style="color:#808080;">
      Prompt 1, 2, 3…
     </span>
     ) the
     <span class="ltx_text" id="S3.F2.9.4" style="color:#D8B365;">
      entity types
     </span>
     are connected by a
     <span class="ltx_text" id="S3.F2.10.5" style="color:#5AB4AC;">
      relationship
     </span>
     . In each prompt, we define the entity and hierarchical relationship to structure the knowledge, and finally, all prompts are chained together.
    </figcaption>
   </figure>
   <div class="ltx_para ltx_noindent" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     A key challenge of using LLMs as foundation models is that they can return false answers in situations where they are unsure how to respond to a query from a user, producing both
     <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">
      “plausible-sounding and incorrect or nonsensical answers”
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib70" title="">
       70
      </a>
      ]
     </cite>
     . We address this issue by introducing
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS1.p1.1.2">
      Taxonomy-based Knowledge Structure Chain
     </em>
     , which is a framework for designing a chain of prompts. Typically, a prompt consists of two parts - a template and a set of label words
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib19" title="">
       19
      </a>
      ]
     </cite>
     . Taxonomies, as relational systems, efficiently organize knowledge by logically interconnecting entities, representing relationships
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib53" title="">
       53
      </a>
      ]
     </cite>
     . While prompting LLMs only rely on plain sentences, taxonomies excel in generating precise keywords, thereby enhancing the relevance and accuracy of LLM responses. This method organizes prompts to align with the taxonomy’s structure using label words, enhancing the relevance and accuracy of LLM responses.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS1.p2">
    <p class="ltx_p" id="S3.SS1.p2.1">
     We exemplify this approach using the TextileNet taxonomy
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib108" title="">
       108
      </a>
      ]
     </cite>
     .
TextileNet’s hierarchy captures the relationships between general textile fibre categories, their subcategories, and specific fibre types, aiding in the creation of a
     <em class="ltx_emph ltx_font_italic" id="S3.SS1.p2.1.1">
      knowledge prompt
     </em>
     . For example, “cotton fibre” falls under “plant fibres”, which is a subset of “natural fibres”. This hierarchical organization of the taxonomy forms the basis of our
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS1.p2.1.2">
      Taxonomy-based Knowledge Structure Chain
     </em>
     , systematically capturing the
     <span class="ltx_text" id="S3.SS1.p2.1.3" style="color:#5AB4AC;">
      relationship
     </span>
     (
     <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.4">
      eg.
     </span>
     subcategories, macro-types) among different
     <span class="ltx_text" id="S3.SS1.p2.1.5" style="color:#D8B365;">
      entity types
     </span>
     as illustrated in Figure
     <a class="ltx_ref" href="#S3.F2" title="Figure 2 ‣ 3.1 Phase 1: Taxonomy-based Knowledge Structure Chain ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS1.p3">
    <p class="ltx_p" id="S3.SS1.p3.1">
     The dialogues in our user study demonstrate the effectiveness of this approach as illustrated in Figure
     <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     .
Participants talked with three CAs: Vanilla GPT-3.5 model, TextileBot-Expert and TextileBot-Assistant. Both TextileBot-Expert and TextileBot-Assistant utilized a Taxonomy-based Knowledge Structure Chain, we discuss the main difference between them in Section
     <a class="ltx_ref" href="#S3.SS2" title="3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       3.2
      </span>
     </a>
     , but focus on how their domain expertise got improved.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS1.p4">
    <p class="ltx_p" id="S3.SS1.p4.1">
     In Figure
     <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     , “viscose” (a bio-derived fibre) was incorrectly categorized as a synthetic fibre and suggested as an unsustainable material by the Vanilla GPT-3.5 model. In contrast, our Taxonomy-bind approach, as shown through TextileBot Assistant and Expert, provides more accurate and contextually relevant information. For instance, TextileBot Expert accurately distinguishes between natural, synthetic, and regenerated fibres, demonstrating the LLM’s improved ability to recognize logical structures in taxonomy-based prompts. Our method significantly enhances the LLM’s capability to provide precise, consistent, and contextually relevant answers, particularly in the realms of fibres, textiles, and textile circularity.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS1.p5">
    <p class="ltx_p" id="S3.SS1.p5.1">
     Taxonomy-based prompts provide “ground truth” when enhancing domain awareness for LLMs. This makes the entire conversation agent more robust when encountering errors from other components in the CA system pipeline, such as Automatic Speech Recognition (ASR). For instance, the term
     <em class="ltx_emph ltx_font_italic" id="S3.SS1.p5.1.1">
      ‘viscous’
     </em>
     in Figure
     <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     is a typical example of the errors that can arise from the ASR. By integrating taxonomy-based prompts within the CA pipeline, LLMs gain improved accuracy in understanding and responding to domain-specific content. This integration significantly mitigates ASR errors in conversation agents. The effectiveness of auto-correcting ASR errors is further quantified in Section
     <a class="ltx_ref" href="#S7.SS3.SSS2" title="7.3.2 Lessons Learned for design LLM-mediated voice agent ‣ 7.3 Optimizing LLM-mediated voice agent design for specific domains ‣ 7 Discussion &amp; Future Directions ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       7.3.2
      </span>
     </a>
     .
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2
    </span>
    Phase 2: From General to Domain Specific through Prompt Refinements
   </h3>
   <figure class="ltx_figure" id="S3.F3">
    <span class="ltx_inline-block ltx_align_center ltx_framed ltx_framed_rectangle" id="S3.F3.1" style="border-color: #000000;">
     <span class="ltx_ERROR undefined" id="S3.F3.1.1">
      {dialogue}
     </span>
     <span class="ltx_p" id="S3.F3.1.2">
      <span class="ltx_text" id="S3.F3.1.2.1" style="color:#FFFFFF;background-color:#000000;">
       Setup
      </span>
      <span class="ltx_text" id="S3.F3.1.2.2" style="color:#377EB8;">
       Vanilla GPT-3.5 model
      </span>
     </span>
     <span class="ltx_p" id="S3.F3.1.3">
      <span class="ltx_text" id="S3.F3.1.3.1" style="color:#FFFFFF;background-color:#000000;">
       Human
      </span>
      Is
      <span class="ltx_text" id="S3.F3.1.3.2" style="background-color:#FFFFE1;">
       viscose
      </span>
      material sustainable?
      <span class="ltx_text" id="S3.F3.1.3.3" style="color:#FFFFFF;background-color:#000000;">
       Agent
      </span>
      <span class="ltx_text" id="S3.F3.1.3.4" style="background-color:#FFFFE1;">
       Viscose
      </span>
      is a type of
      <span class="ltx_text" id="S3.F3.1.3.5" style="background-color:#F7BABB;">
       synthetic fibre
      </span>
      , and it is
      <span class="ltx_text" id="S3.F3.1.3.6" style="background-color:#F7BABB;">
       not considered sustainable
      </span>
      . Instead, opt for natural fibres such as cotton, linen and hemp.
     </span>
     <span class="ltx_p" id="S3.F3.1.4">
      <span class="ltx_text" id="S3.F3.1.4.1" style="color:#FFFFFF;background-color:#000000;">
       Setup
      </span>
      <span class="ltx_text" id="S3.F3.1.4.2" style="color:#4DAF4A;">
       TextileBot Expert
      </span>
     </span>
     <span class="ltx_p" id="S3.F3.1.5">
      <span class="ltx_text" id="S3.F3.1.5.1" style="color:#FFFFFF;background-color:#000000;">
       Human
      </span>
      Hi, so I need to know what kind of textile materials are most selling?
      <span class="ltx_text" id="S3.F3.1.5.2" style="color:#FFFFFF;background-color:#000000;">
       Agent
      </span>
      Hello! That is an interesting question. It really depends on what type of textile you are looking for and what your application is. Generally speaking, some of the most popular material types are natural fibres like cotton, wool, and silk; synthetic fibres like polyester and nylon; and regenerated fibres such as
      <span class="ltx_text" id="S3.F3.1.5.3" style="background-color:#FFFFE1;">
       viscose
      </span>
      and cupro. Knowing the properties of each of these materials is important in order to find the best one for your application. However, you should also consider textile circularity in your selection process. Textile circularity is a concept that ensures a closed-loop life cycle for textiles, from fibre sourcing to manufacturing to end-of-life. This approach is important for creating a sustainable solution for the textiles industry.
     </span>
     <span class="ltx_p" id="S3.F3.1.6">
      <span class="ltx_text" id="S3.F3.1.6.1" style="color:#FFFFFF;background-color:#000000;">
       Setup
      </span>
      <span class="ltx_text" id="S3.F3.1.6.2" style="color:#984EA3;">
       TextileBot Assistant
      </span>
     </span>
     <span class="ltx_p" id="S3.F3.1.7">
      <span class="ltx_text" id="S3.F3.1.7.1" style="color:#FFFFFF;background-color:#000000;">
       Human
      </span>
      What is
      <span class="ltx_text" id="S3.F3.1.7.2" style="background-color:#FFFFE1;">
       viscous
      </span>
      ?
      <span class="ltx_text" id="S3.F3.1.7.3" style="color:#FFFFFF;background-color:#000000;">
       Agent
      </span>
      <span class="ltx_text" id="S3.F3.1.7.4" style="background-color:#FFFFE1;">
       Viscose
      </span>
      is a type of regenerated cellulose fibre made from wood pulp or cotton linter. It is often used to make clothing, linens, bedding, towels and other fabrics that require a soft, silky handfeel.
     </span>
    </span>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 3:
     </span>
     Three prompt-based LLM-mediated agents (
     <span class="ltx_text" id="S3.F3.6.1" style="color:#377EB8;">
      Vanilla GPT-3.5 model
     </span>
     ,
     <span class="ltx_text" id="S3.F3.7.2" style="color:#4DAF4A;">
      TextileBot Expert
     </span>
     ,
     <span class="ltx_text" id="S3.F3.8.3" style="color:#984EA3;">
      TextileBot Assistant
     </span>
     ) spoke about viscose on the TextileBot device.
We highlighted the incorrect content in
     <span class="ltx_text" id="S3.F3.9.4" style="background-color:#F7BABB;">
      red
     </span>
     , demonstrating that the vanilla model was indeed error-prone. Both TextileBot Expert and Assistant utilize the TextileNet taxonomy-based prompts (as explained in Section
     <a class="ltx_ref" href="#S3.SS1" title="3.1 Phase 1: Taxonomy-based Knowledge Structure Chain ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       3.1
      </span>
     </a>
     ) to improve accuracy. TextileBot Expert replies in more detail and is generally considered to be more ‘obsessed’ with this topic by our participants. We further explain this difference in Section
     <a class="ltx_ref" href="#S3.SS2" title="3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       3.2
      </span>
     </a>
     .
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="S3.F4">
    <span class="ltx_inline-block ltx_align_center ltx_framed ltx_framed_rectangle" id="S3.F4.1" style="border-color: #000000;">
     <span class="ltx_ERROR undefined" id="S3.F4.1.1">
      {dialogue}
     </span>
     <span class="ltx_p" id="S3.F4.1.2">
      <span class="ltx_text" id="S3.F4.1.2.1" style="color:#FFFFFF;background-color:#000000;">
       Setup
      </span>
      <span class="ltx_text" id="S3.F4.1.2.2" style="color:#377EB8;">
       Vanilla GPT-3.5 model
      </span>
     </span>
     <span class="ltx_p" id="S3.F4.1.3">
      <span class="ltx_text" id="S3.F4.1.3.1" style="color:#FFFFFF;background-color:#000000;">
       Human
      </span>
      So what would you recommend me to eat today because it’s almost lunchtime?
      <span class="ltx_text" id="S3.F4.1.3.2" style="color:#FFFFFF;background-color:#000000;">
       Agent
      </span>
      That depends on your dietary preferences. What kind of foods do you usually like to eat for lunch?
     </span>
     <span class="ltx_p" id="S3.F4.1.4">
      <span class="ltx_text" id="S3.F4.1.4.1" style="color:#FFFFFF;background-color:#000000;">
       Setup
      </span>
      <span class="ltx_text" id="S3.F4.1.4.2" style="color:#4DAF4A;">
       TextileBot Expert
      </span>
     </span>
     <span class="ltx_p" id="S3.F4.1.5">
      <span class="ltx_text" id="S3.F4.1.5.1" style="color:#FFFFFF;background-color:#000000;">
       Human
      </span>
      Well, I’m hungry. Um, what should I have for my lunch?
      <span class="ltx_text" id="S3.F4.1.5.2" style="color:#FFFFFF;background-color:#000000;">
       Agent
      </span>
      <span class="ltx_text" id="S3.F4.1.5.3" style="background-color:#FFD8B5;">
       I’m sorry but I’m not the best person to help you with that.
      </span>
      However, if you’re interested in learning more about
      <span class="ltx_text" id="S3.F4.1.5.4" style="background-color:#FFFFE1;">
       textile
      </span>
      and clothing materials, I’d be happy to help you!
     </span>
     <span class="ltx_p" id="S3.F4.1.6">
      <span class="ltx_text" id="S3.F4.1.6.1" style="color:#FFFFFF;background-color:#000000;">
       Setup
      </span>
      <span class="ltx_text" id="S3.F4.1.6.2" style="color:#984EA3;">
       TextileBot Assistant
      </span>
     </span>
     <span class="ltx_p" id="S3.F4.1.7">
      <span class="ltx_text" id="S3.F4.1.7.1" style="color:#FFFFFF;background-color:#000000;">
       Human
      </span>
      It’s almost lunchtime. What should I have for lunch today?
      <span class="ltx_text" id="S3.F4.1.7.2" style="color:#FFFFFF;background-color:#000000;">
       Agent
      </span>
      That sounds like an exciting decision! Are you looking for some
      <span class="ltx_text" id="S3.F4.1.7.3" style="background-color:#FFFFE1;">
       textile-inspired
      </span>
      lunch ideas? I know some great recipes for plant fiber-based noodles, vegan silk smoothies, and cottonseed salad bowls that are sure to satisfy your appetite!
     </span>
    </span>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 4:
     </span>
     Three prompt-based LLM-mediated agents on the topic of lunch (
     <span class="ltx_text" id="S3.F4.5.1" style="color:#377EB8;">
      Vanilla GPT-3.5 model
     </span>
     ,
     <span class="ltx_text" id="S3.F4.6.2" style="color:#4DAF4A;">
      TextileBot Expert
     </span>
     ,
     <span class="ltx_text" id="S3.F4.7.3" style="color:#984EA3;">
      TextileBot Assistant
     </span>
     ).
    </figcaption>
   </figure>
   <div class="ltx_para ltx_noindent" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     As the process of designing prompt templates is empirical, various ad-hoc prompt refinement techniques such as “Let’s think step by step”
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib49" title="">
       49
      </a>
      ]
     </cite>
     have been employed in prompt design. However, there is yet no specific systematic approach for optimizing performance. To bridge this gap, we introduce a human-centred iterative prototyping process to personalize a desired CA. We demonstrate this approach through two distinct levels of prompt refinements both integrated Taxonomy-based Knowledge Structure Chains: one semi-domain-specific
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.1.1">
      Assistant
     </em>
     and one domain-specific
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.1.2">
      Expert
     </em>
     , for conversations in the context of textiles circularity. The process involves a series of prompt refinement steps:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS2.p2">
    <ol class="ltx_enumerate" id="S3.I1">
     <li class="ltx_item" id="S3.I1.ix1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       <math alttext="\blacksquare" class="ltx_Math" display="inline" id="S3.I1.ix1.1.1.m1.1">
        <semantics id="S3.I1.ix1.1.1.m1.1b">
         <merror class="ltx_ERROR undefined undefined" id="S3.I1.ix1.1.1.m1.1.1" xref="S3.I1.ix1.1.1.m1.1.1b.cmml">
          <mtext id="S3.I1.ix1.1.1.m1.1.1b" xref="S3.I1.ix1.1.1.m1.1.1b.cmml">
           \blacksquare
          </mtext>
         </merror>
         <annotation-xml encoding="MathML-Content" id="S3.I1.ix1.1.1.m1.1c">
          <ci id="S3.I1.ix1.1.1.m1.1.1b.cmml" xref="S3.I1.ix1.1.1.m1.1.1">
           <merror class="ltx_ERROR undefined undefined" id="S3.I1.ix1.1.1.m1.1.1.cmml" xref="S3.I1.ix1.1.1.m1.1.1">
            <mtext id="S3.I1.ix1.1.1.m1.1.1a.cmml" xref="S3.I1.ix1.1.1.m1.1.1">
             \blacksquare
            </mtext>
           </merror>
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S3.I1.ix1.1.1.m1.1d">
          \blacksquare
         </annotation>
        </semantics>
       </math>
      </span>
      <div class="ltx_para ltx_noindent" id="S3.I1.ix1.p1">
       <p class="ltx_p" id="S3.I1.ix1.p1.1">
        <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.I1.ix1.p1.1.1">
         <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.I1.ix1.p1.1.1.1">
          Give the model an identity
         </em>
        </span>
        : Start by giving the model a clear identity so it can identify its role and understand what kind of behaviour is expected of it. This helps to establish a consistent personality for the model’s responses.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.ix2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       <math alttext="\blacksquare" class="ltx_Math" display="inline" id="S3.I1.ix2.1.1.m1.1">
        <semantics id="S3.I1.ix2.1.1.m1.1b">
         <merror class="ltx_ERROR undefined undefined" id="S3.I1.ix2.1.1.m1.1.1" xref="S3.I1.ix2.1.1.m1.1.1b.cmml">
          <mtext id="S3.I1.ix2.1.1.m1.1.1b" xref="S3.I1.ix2.1.1.m1.1.1b.cmml">
           \blacksquare
          </mtext>
         </merror>
         <annotation-xml encoding="MathML-Content" id="S3.I1.ix2.1.1.m1.1c">
          <ci id="S3.I1.ix2.1.1.m1.1.1b.cmml" xref="S3.I1.ix2.1.1.m1.1.1">
           <merror class="ltx_ERROR undefined undefined" id="S3.I1.ix2.1.1.m1.1.1.cmml" xref="S3.I1.ix2.1.1.m1.1.1">
            <mtext id="S3.I1.ix2.1.1.m1.1.1a.cmml" xref="S3.I1.ix2.1.1.m1.1.1">
             \blacksquare
            </mtext>
           </merror>
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S3.I1.ix2.1.1.m1.1d">
          \blacksquare
         </annotation>
        </semantics>
       </math>
      </span>
      <div class="ltx_para ltx_noindent" id="S3.I1.ix2.p1">
       <p class="ltx_p" id="S3.I1.ix2.p1.1">
        <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.I1.ix2.p1.1.1">
         <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.I1.ix2.p1.1.1.1">
          Tell the model how to behave
         </em>
        </span>
        : Next, you can also instruct it on how to behave, for example, by telling it to be creative and helpful. These instructions help to further define the model’s personality with the desired tone.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.ix3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       <math alttext="\blacksquare" class="ltx_Math" display="inline" id="S3.I1.ix3.1.1.m1.1">
        <semantics id="S3.I1.ix3.1.1.m1.1b">
         <merror class="ltx_ERROR undefined undefined" id="S3.I1.ix3.1.1.m1.1.1" xref="S3.I1.ix3.1.1.m1.1.1b.cmml">
          <mtext id="S3.I1.ix3.1.1.m1.1.1b" xref="S3.I1.ix3.1.1.m1.1.1b.cmml">
           \blacksquare
          </mtext>
         </merror>
         <annotation-xml encoding="MathML-Content" id="S3.I1.ix3.1.1.m1.1c">
          <ci id="S3.I1.ix3.1.1.m1.1.1b.cmml" xref="S3.I1.ix3.1.1.m1.1.1">
           <merror class="ltx_ERROR undefined undefined" id="S3.I1.ix3.1.1.m1.1.1.cmml" xref="S3.I1.ix3.1.1.m1.1.1">
            <mtext id="S3.I1.ix3.1.1.m1.1.1a.cmml" xref="S3.I1.ix3.1.1.m1.1.1">
             \blacksquare
            </mtext>
           </merror>
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S3.I1.ix3.1.1.m1.1d">
          \blacksquare
         </annotation>
        </semantics>
       </math>
      </span>
      <div class="ltx_para ltx_noindent" id="S3.I1.ix3.p1">
       <p class="ltx_p" id="S3.I1.ix3.p1.1">
        <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.I1.ix3.p1.1.1">
         <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.I1.ix3.p1.1.1.1">
          “Let’s think step by step”
         </em>
        </span>
        : Occasionally, GPTs fails on completing complex tasks
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib3" title="">
          3
         </a>
         ]
        </cite>
        . To ensure the successful completion of the task, the model needs to be given clear instructions step-by-step to help it understand what is required. Break the complex tasks into simpler subtasks with a clear separation between each task. In addition, using the “Let’s think step by step”
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib49" title="">
          49
         </a>
         ]
        </cite>
        trick in the prompt can help the model to think logically.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.ix4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       <math alttext="\blacksquare" class="ltx_Math" display="inline" id="S3.I1.ix4.1.1.m1.1">
        <semantics id="S3.I1.ix4.1.1.m1.1b">
         <merror class="ltx_ERROR undefined undefined" id="S3.I1.ix4.1.1.m1.1.1" xref="S3.I1.ix4.1.1.m1.1.1b.cmml">
          <mtext id="S3.I1.ix4.1.1.m1.1.1b" xref="S3.I1.ix4.1.1.m1.1.1b.cmml">
           \blacksquare
          </mtext>
         </merror>
         <annotation-xml encoding="MathML-Content" id="S3.I1.ix4.1.1.m1.1c">
          <ci id="S3.I1.ix4.1.1.m1.1.1b.cmml" xref="S3.I1.ix4.1.1.m1.1.1">
           <merror class="ltx_ERROR undefined undefined" id="S3.I1.ix4.1.1.m1.1.1.cmml" xref="S3.I1.ix4.1.1.m1.1.1">
            <mtext id="S3.I1.ix4.1.1.m1.1.1a.cmml" xref="S3.I1.ix4.1.1.m1.1.1">
             \blacksquare
            </mtext>
           </merror>
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S3.I1.ix4.1.1.m1.1d">
          \blacksquare
         </annotation>
        </semantics>
       </math>
      </span>
      <div class="ltx_para ltx_noindent" id="S3.I1.ix4.p1">
       <p class="ltx_p" id="S3.I1.ix4.p1.1">
        <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.I1.ix4.p1.1.1">
         <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.I1.ix4.p1.1.1.1">
          Format the prompts
         </em>
        </span>
        : Structure the prompt template format with delimiters and line breaks. This helps the model to disambiguate different sections and determine when the prompt ends and when it should start generating a response.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.ix5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       <math alttext="\blacksquare" class="ltx_Math" display="inline" id="S3.I1.ix5.1.1.m1.1">
        <semantics id="S3.I1.ix5.1.1.m1.1b">
         <merror class="ltx_ERROR undefined undefined" id="S3.I1.ix5.1.1.m1.1.1" xref="S3.I1.ix5.1.1.m1.1.1b.cmml">
          <mtext id="S3.I1.ix5.1.1.m1.1.1b" xref="S3.I1.ix5.1.1.m1.1.1b.cmml">
           \blacksquare
          </mtext>
         </merror>
         <annotation-xml encoding="MathML-Content" id="S3.I1.ix5.1.1.m1.1c">
          <ci id="S3.I1.ix5.1.1.m1.1.1b.cmml" xref="S3.I1.ix5.1.1.m1.1.1">
           <merror class="ltx_ERROR undefined undefined" id="S3.I1.ix5.1.1.m1.1.1.cmml" xref="S3.I1.ix5.1.1.m1.1.1">
            <mtext id="S3.I1.ix5.1.1.m1.1.1a.cmml" xref="S3.I1.ix5.1.1.m1.1.1">
             \blacksquare
            </mtext>
           </merror>
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S3.I1.ix5.1.1.m1.1d">
          \blacksquare
         </annotation>
        </semantics>
       </math>
      </span>
      <div class="ltx_para ltx_noindent" id="S3.I1.ix5.p1">
       <p class="ltx_p" id="S3.I1.ix5.p1.1">
        <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.I1.ix5.p1.1.1">
         <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.I1.ix5.p1.1.1.1">
          Fine-tune prompts
         </em>
        </span>
        : Fine-tune it with the desired behaviour the model needs to take. This involves using plain language and a positive tone to instruct the model on how to perform specific tasks. For example, we might instruct the model to “provide a sustainable clothing suggestion regardless of gender.”
       </p>
      </div>
     </li>
    </ol>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS2.p3">
    <p class="ltx_p" id="S3.SS2.p3.1">
     These refinement techniques can be utilized individually or in combination, depending on the specific task. For a comprehensive demonstration of the strategy in practice, we provide a complete prompt template for
     <span class="ltx_text ltx_font_italic" id="S3.SS2.p3.1.1">
      Expert
     </span>
     and
     <span class="ltx_text ltx_font_italic" id="S3.SS2.p3.1.2">
      Assistant
     </span>
     , combining all these refinements, in the Appendix Section
     <span class="ltx_ref ltx_missing_label ltx_ref_self">
      LABEL:sec:apd:prompt
     </span>
     , showcasing various combinations. Table
     <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     highlights the prompts used in the template.
    </p>
   </div>
   <figure class="ltx_table" id="S3.T1">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 1:
     </span>
     Prompts used for three agents’ role and response manner. The conversational freedom is predefined as the design guideline for prompt template.
    </figcaption>
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.1" style="width:433.6pt;height:85.2pt;vertical-align:-0.0pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-85.6pt,16.8pt) scale(0.716956532170859,0.716956532170859) ;">
      <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T1.1.1">
       <thead class="ltx_thead">
        <tr class="ltx_tr" id="S3.T1.1.1.1.1">
         <th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S3.T1.1.1.1.1.1">
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S3.T1.1.1.1.1.2">
          Prompts used for characteristic
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T1.1.1.1.1.3">
          Response manner
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.1.4">
          Conversational freedom
         </th>
        </tr>
       </thead>
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="S3.T1.1.1.2.1">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.1.1.2.1.1">
          Vanilla
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.1.1.2.1.2">
          N/A
         </th>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.1.3">
          N/A
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.1.4">
          non-goal oriented
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T1.1.1.3.2">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.1.1.3.2.1">
          Assistant
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.1.1.3.2.2">
          <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.3.2.2.1">
           <tr class="ltx_tr" id="S3.T1.1.1.3.2.2.1.1">
            <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.3.2.2.1.1.1">
             A helpful, creative, clever, and very friendly AI assistant,
            </td>
           </tr>
           <tr class="ltx_tr" id="S3.T1.1.1.3.2.2.1.2">
            <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.3.2.2.1.2.1">
             specialized in textile circularity.
            </td>
           </tr>
          </table>
         </th>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.2.3">
          Conscious in response
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.3.2.4">
          semi-domain-specific
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T1.1.1.4.3">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.1.1.4.3.1">
          Expert
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.1.1.4.3.2">
          <table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.4.3.2.1">
           <tr class="ltx_tr" id="S3.T1.1.1.4.3.2.1.1">
            <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.4.3.2.1.1.1">
             A textile circularity expert, response query around the concept of
            </td>
           </tr>
           <tr class="ltx_tr" id="S3.T1.1.1.4.3.2.1.2">
            <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.4.3.2.1.2.1">
             textile circularity and guide the conversation towards textile circularity
            </td>
           </tr>
          </table>
         </th>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.1.1.4.3.3">
          In a detailed manner
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.1.4.3.4">
          domain-specific
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
   </figure>
   <div class="ltx_para ltx_noindent" id="S3.SS2.p4">
    <p class="ltx_p" id="S3.SS2.p4.1">
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p4.1.1">
      Expert
     </em>
     is designed to promote the idea of textile circularity and facilitate discussions on the topic. The Expert excels in providing detailed information on textiles and textile circularity, often including additional information. In Expert mode, as a domain-specific Ca, control the degree of freedom in the topic becomes the fundamental step. To achieve this, we
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p4.1.2">
      limit the conversation breadth of the model
     </em>
     by instructing it with the following prompt.
We show the effectiveness of this in Appendix Section
     <span class="ltx_ref ltx_missing_label ltx_ref_self">
      LABEL:sec:apd:prompt
     </span>
     showing that participants failed to ”jail break” the prompt.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS2.p5">
    <p class="ltx_p" id="S3.SS2.p5.1">
     On the other hand,
     <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p5.1.1">
      Assistant
     </em>
     is designed to engage in broader conversations and can act as an intermediary between non-goal-oriented conversation (task-agnostic)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib92" title="">
       92
      </a>
      ]
     </cite>
     and domain-specific conversation. We increase the breadth of topics and freedom of conversation in Assistant mode. For instance, the Assistant can provide suggestions on various scenarios such as dining or dressing, and even tell jokes without losing its focus on textiles.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS2.p6">
    <p class="ltx_p" id="S3.SS2.p6.1">
     To better understand the distinctions between these agents, Figure
     <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     demonstrates how Expert is more “obsessed” with textile circularity compared to the Assistant. Figures
     <a class="ltx_ref" href="#S3.F4" title="Figure 4 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     provide an example from our user study, which shows different participants having real conversations regarding providing a lunch idea. The Vanilla model typically engages in free conversations in such cases, while the Expert refuses to engage unless it senses the topic is related to textiles. On the other hand, Assistant provides a textile-favoured lunch suggestion, thereby preserving the domain-specific feature while still allowing for open conversations. The Vanilla, Expert and Assistant agents show distinguishable response styles as follows:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS2.p7">
    <ul class="ltx_itemize" id="S3.I2">
     <li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I2.i1.p1">
       <p class="ltx_p" id="S3.I2.i1.p1.1">
        Vanilla: This agent is non-goal-oriented and represents the pre-trained LLM in its original form. This showcases using LLMs directly as conversational agents
        <span class="ltx_text ltx_font_bold" id="S3.I2.i1.p1.1.1">
         without any prompts
        </span>
        .
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I2.i2.p1">
       <p class="ltx_p" id="S3.I2.i2.p1.1">
        Expert: Positioned as a goal-oriented (domain specific) voice agent, it embodies a domain expert, with a focus on specialized knowledge, but limited in making social conversations. The Expert excels in providing detailed explanations, often including additional information.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I2.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para ltx_noindent" id="S3.I2.i3.p1">
       <p class="ltx_p" id="S3.I2.i3.p1.1">
        Assistant: This agent is semi-goal-oriented, positioned as a helpful and friendly assistant that is able to conduct some degree of social conversation but still with goal in mind, conscious of the target domain when answering questions.
       </p>
      </div>
     </li>
    </ul>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.3
    </span>
    Phase 3: Enable continuous LLM interaction with memory through System Optimization
   </h3>
   <figure class="ltx_figure" id="S3.F5">
    <span class="ltx_inline-block ltx_align_center ltx_framed ltx_framed_rectangle" id="S3.F5.1" style="border-color: #000000;">
     <span class="ltx_ERROR undefined" id="S3.F5.1.1">
      {dialogue}
     </span>
     <span class="ltx_p" id="S3.F5.1.2">
      <span class="ltx_text" id="S3.F5.1.2.1" style="color:#FFFFFF;background-color:#000000;">
       Human
      </span>
      Which materials make the concept of textile circularity difficult to implement?
     </span>
     <span class="ltx_p" id="S3.F5.1.3">
      <span class="ltx_text" id="S3.F5.1.3.1" style="color:#FFFFFF;background-color:#000000;">
       agent
      </span>
      Synthetic fibres and blended fabrics, … textile circularity difficult to implement.
      <span class="ltx_text" id="S3.F5.1.3.2" style="color:#FFFFFF;background-color:#000000;">
       Human
      </span>
      Repeat.
      <span class="ltx_text" id="S3.F5.1.3.3" style="color:#FFFFFF;background-color:#000000;">
       agent
      </span>
      The main challenges to the implementation of textile circularity include the lack of a clear regulatory framework, lack of investment and financial incentives, lack of understanding or awareness, and difficulty in measuring impacts.
      <span class="ltx_text" id="S3.F5.1.3.4" style="color:#FFFFFF;background-color:#000000;">
       Human
      </span>
      Please repeat my last question.
      <span class="ltx_text" id="S3.F5.1.3.5" style="color:#FFFFFF;background-color:#000000;">
       agent
      </span>
      Which materials make the concept of textile circularity difficult to implement?
      <span class="ltx_text" id="S3.F5.1.3.6" style="color:#FFFFFF;background-color:#000000;">
       Human
      </span>
      What was your last response?
      <span class="ltx_text" id="S3.F5.1.3.7" style="color:#FFFFFF;background-color:#000000;">
       agent
      </span>
      Synthetic fibres and blended fabrics, … textile circularity difficult to implement.
      <span class="ltx_text" id="S3.F5.1.3.8" style="color:#FFFFFF;background-color:#000000;">
       Human
      </span>
      Repeat your last response.
      <span class="ltx_text" id="S3.F5.1.3.9" style="color:#FFFFFF;background-color:#000000;">
       agent
      </span>
      Synthetic fibres and blended fabrics, … textile circularity difficult to implement.
     </span>
    </span>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 5:
     </span>
     Transcript history for TextileBot Assistant. In Figure
     <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     and
     <a class="ltx_ref" href="#S3.F4" title="Figure 4 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     , we both take the unmodified transcript history to demonstrate the agents’ capabilities. Transcript history is also directly injected into our prompt, with a summarisation if it goes beyond the token limit, this is explained in Section
     <a class="ltx_ref" href="#S3.SS3" title="3.3 Phase 3: Enable continuous LLM interaction with memory through System Optimization ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       3.3
      </span>
     </a>
     . This transcript demonstrates the agent’s statefulness in conversation,
     <span class="ltx_text ltx_font_italic" id="S3.F5.3.1">
      eg.
     </span>
     its ability to recall and refer back to previously asked questions.
    </figcaption>
   </figure>
   <div class="ltx_para ltx_noindent" id="S3.SS3.p1">
    <p class="ltx_p" id="S3.SS3.p1.1">
     Previous sections discussed how our prompt design helps the model identify its task. In this section, we first introduce some challenges using LLMs directly as CAs to conduct continuous conversation, and then provide corresponding System Optimization for these challenges.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS3.p2">
    <ol class="ltx_enumerate" id="S3.I3">
     <li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       1.
      </span>
      <div class="ltx_para ltx_noindent" id="S3.I3.i1.p1">
       <p class="ltx_p" id="S3.I3.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I3.i1.p1.1.1">
         LLM capabilities depend on context:
        </span>
        LLMs are sensitive to input prompts. Minor alterations to the prompt can result in significant differences in the model’s prediction
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib63" title="">
          63
         </a>
         ,
         <a class="ltx_ref" href="#bib.bib14" title="">
          14
         </a>
         ]
        </cite>
        . They may exhibit a preference for specific prompt formats, paraphrases, or particular information contained in the input
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib6" title="">
          6
         </a>
         ,
         <a class="ltx_ref" href="#bib.bib39" title="">
          39
         </a>
         ]
        </cite>
        . For instance, the
        <em class="ltx_emph ltx_font_italic" id="S3.I3.i1.p1.1.2">
         ”Let’s think step by step”
        </em>
        trick
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib49" title="">
          49
         </a>
         ]
        </cite>
        reveals that using particular prompts can largely level up model’s overall performance. Additionally, nouns and verbs tend to carry more weight than adjectives and function words
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib103" title="">
          103
         </a>
         ,
         <a class="ltx_ref" href="#bib.bib68" title="">
          68
         </a>
         ]
        </cite>
        . In short, the quality of response will be altered by the context.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       2.
      </span>
      <div class="ltx_para ltx_noindent" id="S3.I3.i2.p1">
       <p class="ltx_p" id="S3.I3.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I3.i2.p1.1.1">
         Transformer-based LLMs are memory-less:
        </span>
        Transformer-based LLMs do not have an explicit memory of their previous outputs, including ChatGPT
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib70" title="">
          70
         </a>
         ]
        </cite>
        .
       </p>
      </div>
     </li>
    </ol>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS3.p3">
    <p class="ltx_p" id="S3.SS3.p3.1">
     Although raw LLMs are usually memory-less, their ability to
     <em class="ltx_emph ltx_font_italic" id="S3.SS3.p3.1.1">
      learn in context
     </em>
     provides us with a way to enable them to remember previous conversations. This is done by
     <em class="ltx_emph ltx_font_italic" id="S3.SS3.p3.1.2">
      incorporating past human input and model output pairs
     </em>
     into the prompt in a clear format (as shown in Figure
     <a class="ltx_ref" href="#S4.F6" title="Figure 6 ‣ 4 The Case of TextileBot: Design and Implementation ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       6
      </span>
     </a>
     ) and allowing the model to use its capacity for learning in context to build a “Dialogue Memory” that is constantly updated with each interaction round between the human and the model. This ensures the model remains up-to-date with conversations, thus providing it with a form of memory that would otherwise not be possible. Interestingly, from the transcripts in Figure
     <a class="ltx_ref" href="#S3.F5" title="Figure 5 ‣ 3.3 Phase 3: Enable continuous LLM interaction with memory through System Optimization ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     , we can observe that when using simple terms such as “repeat”, the model can repeat certain parts of the conversation; however, it requires
     <em class="ltx_emph ltx_font_italic" id="S3.SS3.p3.1.3">
      clear prompts
     </em>
     in order to understand what exactly should be repeated.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS3.p4">
    <p class="ltx_p" id="S3.SS3.p4.2">
     Since the transcript history is constantly being updated, the issue of the token limit arises, which can lead to a system crash if we exceed this limit. To tackle this, System Optimization have used a
     <span class="ltx_text ltx_font_bold" id="S3.SS3.p4.2.1">
      token counter
     </span>
     to keep track of the total token count in our prompt. Once the overall text length reaches almost
     <math alttext="3000" class="ltx_Math" display="inline" id="S3.SS3.p4.1.m1.1">
      <semantics id="S3.SS3.p4.1.m1.1a">
       <mn id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml">
        3000
       </mn>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b">
        <cn id="S3.SS3.p4.1.m1.1.1.cmml" type="integer" xref="S3.SS3.p4.1.m1.1.1">
         3000
        </cn>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">
        3000
       </annotation>
      </semantics>
     </math>
     tokens (roughly equivalent to
     <math alttext="9000" class="ltx_Math" display="inline" id="S3.SS3.p4.2.m2.1">
      <semantics id="S3.SS3.p4.2.m2.1a">
       <mn id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml">
        9000
       </mn>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b">
        <cn id="S3.SS3.p4.2.m2.1.1.cmml" type="integer" xref="S3.SS3.p4.2.m2.1.1">
         9000
        </cn>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">
        9000
       </annotation>
      </semantics>
     </math>
     characters), we use the
     <span class="ltx_text ltx_font_typewriter" id="S3.SS3.p4.2.2">
      text-davinci-003
     </span>
     model as a
     <span class="ltx_text ltx_font_bold" id="S3.SS3.p4.2.3">
      summarizer
     </span>
     (Figure
     <a class="ltx_ref" href="#S3.F5" title="Figure 5 ‣ 3.3 Phase 3: Enable continuous LLM interaction with memory through System Optimization ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     ) to summarize transcripts between the user and the model. The summarized text is then combined with other more recent dialogues to make up the
     <span class="ltx_text ltx_font_bold" id="S3.SS3.p4.2.4">
      Dialogue Memory
     </span>
     , this memory is pure text and is then added to the initial CA prompt that we have generated from Phase 1 and 2, in this way, we enable multi-turn interaction to continue.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   The Case of TextileBot: Design and Implementation
  </h2>
  <figure class="ltx_figure" id="S4.F6">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="165" id="S4.F6.g1" src="/html/2406.10590/assets/x3.png" width="461"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 6:
    </span>
    System optimization (phase 3) with integrated memory. This optimization includes a token counter for monitoring the dialogue length. Once the token limit is reached, an automatic summarizer is triggered to condense the past dialogue. The CA prompt is pre-set always at the start, where these past-dialogue are inserted after it, to maintain the CA’s functionality.
   </figcaption>
  </figure>
  <div class="ltx_para ltx_noindent" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    In this section, we provide our prompt-based conversational voice agents’ software and hardware designs. Notably, our system design exhibits great adaptability. The design building blocks (illustrated in Figure
    <a class="ltx_ref" href="#S4.F7" title="Figure 7 ‣ 4.1 Software System Design - Multi-Model Stitching ‣ 4 The Case of TextileBot: Design and Implementation ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
     <span class="ltx_text ltx_ref_tag">
      7
     </span>
    </a>
    ) can be seamlessly integrated with various platforms and input/output methods. These include smart devices, smartphones, computers, VR interfaces, and diverse user input/output methods. The TextileBot voice interface, featured in this study, serves as an exemplary implementation of our domain-specific prompt-based voice agent approach within the context of textile circularity.
We built a device with a voice interface for several reasons. Firstly, in line with the current textile circularity agenda, a key objective is to raise consumers’ awareness and engagement with this concept
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib75" title="">
      75
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib83" title="">
      83
     </a>
     ]
    </cite>
    . Utilizing physical artifacts to enhance user engagement has been a significant pursuit in human-agent interaction
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib69" title="">
      69
     </a>
     ]
    </cite>
    , and our TextileBot aims to facilitate consumer engagement in retail settings, we regard a real device with voice-based interactions as pivotal in our approach. Secondly, it is well-established that people employ distinct language styles when speaking compared to writing, as articulated in the literature
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib81" title="">
      81
     </a>
     ]
    </cite>
    . To our knowledge, no prior research has delved into natural spoken dialogue with LLMs, leaving a substantial gap in understanding how humans perceive and interact with prompt LLM-based voice agents. Finally, a voice interface can create better accessibility for users.
   </p>
  </div>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1
    </span>
    Software System Design - Multi-Model Stitching
   </h3>
   <div class="ltx_para ltx_noindent" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     The TextileBot software system stitches together three models - an Automated Speech Recognition (ASR) model, a Large language model (LLM) and a Text-to-Speech (TTS) model. We explain each of them in detail in the following subsections, and an overview of this system is in Figure
     <a class="ltx_ref" href="#S4.F7" title="Figure 7 ‣ 4.1 Software System Design - Multi-Model Stitching ‣ 4 The Case of TextileBot: Design and Implementation ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       7
      </span>
     </a>
     .
    </p>
   </div>
   <figure class="ltx_figure" id="S4.F7">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="160" id="S4.F7.g1" src="/html/2406.10590/assets/x4.png" width="461"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 7:
     </span>
     Software System Design for TextileBot - Multi-Model Stitching. For the complete CA design, we utilized an ASR model, a LLM and a TTS model. It is worth mentioning that our ASR model is Whisper, deep learning based ASR model.
    </figcaption>
   </figure>
   <section class="ltx_subsubsection" id="S4.SS1.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.1.1
     </span>
     Automatic Speech Recognition (ASR)
    </h4>
    <div class="ltx_para ltx_noindent" id="S4.SS1.SSS1.p1">
     <p class="ltx_p" id="S4.SS1.SSS1.p1.4">
      We tested two speech recognition models, Google speech-to-text and OpenAI’s Whisper
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib78" title="">
        78
       </a>
       ]
      </cite>
      Application Programming Interface (API), in our TextileBot design. Initially, we used Google’s API, which is popular, but we experienced unexpected latency issues on our Raspberry Pi device due to heavy preprocessing on recorded audio files. To evaluate latency, we randomly sampled recording lengths between
      <math alttext="1" class="ltx_Math" display="inline" id="S4.SS1.SSS1.p1.1.m1.1">
       <semantics id="S4.SS1.SSS1.p1.1.m1.1a">
        <mn id="S4.SS1.SSS1.p1.1.m1.1.1" xref="S4.SS1.SSS1.p1.1.m1.1.1.cmml">
         1
        </mn>
        <annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.1.m1.1b">
         <cn id="S4.SS1.SSS1.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS1.SSS1.p1.1.m1.1.1">
          1
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.1.m1.1c">
         1
        </annotation>
       </semantics>
      </math>
      to
      <math alttext="60" class="ltx_Math" display="inline" id="S4.SS1.SSS1.p1.2.m2.1">
       <semantics id="S4.SS1.SSS1.p1.2.m2.1a">
        <mn id="S4.SS1.SSS1.p1.2.m2.1.1" xref="S4.SS1.SSS1.p1.2.m2.1.1.cmml">
         60
        </mn>
        <annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.2.m2.1b">
         <cn id="S4.SS1.SSS1.p1.2.m2.1.1.cmml" type="integer" xref="S4.SS1.SSS1.p1.2.m2.1.1">
          60
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.2.m2.1c">
         60
        </annotation>
       </semantics>
      </math>
      seconds and recorded
      <math alttext="100" class="ltx_Math" display="inline" id="S4.SS1.SSS1.p1.3.m3.1">
       <semantics id="S4.SS1.SSS1.p1.3.m3.1a">
        <mn id="S4.SS1.SSS1.p1.3.m3.1.1" xref="S4.SS1.SSS1.p1.3.m3.1.1.cmml">
         100
        </mn>
        <annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.3.m3.1b">
         <cn id="S4.SS1.SSS1.p1.3.m3.1.1.cmml" type="integer" xref="S4.SS1.SSS1.p1.3.m3.1.1">
          100
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.3.m3.1c">
         100
        </annotation>
       </semantics>
      </math>
      speech samples to simulate natural dialogue. Google ASR had an average latency of
      <math alttext="28.93" class="ltx_Math" display="inline" id="S4.SS1.SSS1.p1.4.m4.1">
       <semantics id="S4.SS1.SSS1.p1.4.m4.1a">
        <mn id="S4.SS1.SSS1.p1.4.m4.1.1" xref="S4.SS1.SSS1.p1.4.m4.1.1.cmml">
         28.93
        </mn>
        <annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.4.m4.1b">
         <cn id="S4.SS1.SSS1.p1.4.m4.1.1.cmml" type="float" xref="S4.SS1.SSS1.p1.4.m4.1.1">
          28.93
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.4.m4.1c">
         28.93
        </annotation>
       </semantics>
      </math>
      seconds on these samples. In a pilot study with four participants (including one native English speaker), two non-native English speakers, we found that participants had to speak slowly and repeat their words when using Google ASR.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S4.SS1.SSS1.p2">
     <p class="ltx_p" id="S4.SS1.SSS1.p2.1">
      We chose OpenAI’s Whisper as our ASR due to its faster latency and robustness in recognition
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib77" title="">
        77
       </a>
       ]
      </cite>
      . While we did not conduct a thorough accuracy comparison study between the two APIs, and to our knowledge, no related literature compares them as Whisper was officially released in March 2023, we observed that Whisper recognized most non-native English-speaking participants significantly better. Conversely, with Google speech-to-text ASR, key terms in our dialogue such as ”textile circularity” were consistently recognized as ”textile security” or even ”Texas a Coronavirus”.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S4.SS1.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.1.2
     </span>
     Language model as foundation model
    </h4>
    <div class="ltx_para ltx_noindent" id="S4.SS1.SSS2.p1">
     <p class="ltx_p" id="S4.SS1.SSS2.p1.1">
      In our study, we chose GPT-3.5 (text-davinci-003) API which was known for its outstanding performance and trained with the largest parameters at the time of testing. Currently, there is a lot of discussion within the community about the differences between OpenAI’s GPT models, including GPT-3, GPT-3.5, ChatGPT, and the newly released GPT-4.
Our work focuses on the pre-trained OpenAI GPT model
      <span class="ltx_note ltx_role_footnote" id="footnote4">
       <sup class="ltx_note_mark">
        4
       </sup>
       <span class="ltx_note_outer">
        <span class="ltx_note_content">
         <sup class="ltx_note_mark">
          4
         </sup>
         <span class="ltx_tag ltx_tag_note">
          4
         </span>
         OpenAI’s GPT-3 is a pre-trained LLM with 175 billion parameters
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib14" title="">
           14
          </a>
          ]
         </cite>
        </span>
       </span>
      </span>
      rather than any other published sources or third-party models trained from scratch.
One drawback of LLMs is the generation of plausible-sounding but incorrect or nonsensical responses
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib70" title="">
        70
       </a>
       ]
      </cite>
      . To address this issue, LLMs like InstructGPT and ChatGPT have incorporated human efforts using Reinforcement Learning from Human Feedback (RLHF), resulting in fewer false responses and less toxicity
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib72" title="">
        72
       </a>
       ]
      </cite>
      . Although ChatGPT’s advanced language processing capabilities allow it to engage in natural, human-like conversations with users, it has a tendency to be verbose due to biases in the training data. Trainers in the RLHF prefer longer answers that appear more comprehensive
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib87" title="">
        87
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib34" title="">
        34
       </a>
       ]
      </cite>
      .
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S4.SS1.SSS2.p2">
     <p class="ltx_p" id="S4.SS1.SSS2.p2.1">
      We cannot determine the parameters used in the RLHF for ChatGPT, limiting our freedom in using these LLMs. Furthermore, the long-text style response of ChatGPT is unsuitable for voice interfaces. In contrast, GPT-3 and GPT-3.5 are more “organic” and provide more freedom in designing arbitrary prompts, making them useful for customizable content generation and language translation. Therefore, we focus on exploiting these large foundation models directly, such as GPT-3.5, for controlled, high-quality content generation instead of using the patched ChatGPT.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S4.SS1.SSS2.p3">
     <p class="ltx_p" id="S4.SS1.SSS2.p3.1">
      At the time of writing this paper, OpenAI had just announced GPT-4 - an enhanced language model with improved mathematical abilities and the capacity to take visual inputs. However, it can be difficult to distinguish GPT-3.5 from GPT-4 in a casual conversation, as noted on GPT-4’s website. Interestingly, OpenAI has also reported that there is almost no improvement in generating factual content when questions related to environmental science are posed
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib71" title="">
        71
       </a>
       ]
      </cite>
      . In this paper, our focus is on designing a domain-specific conversation agent related to textile circularity, a key topic in material and environmental science.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S4.SS1.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.1.3
     </span>
     Text-to-speech
    </h4>
    <div class="ltx_para ltx_noindent" id="S4.SS1.SSS3.p1">
     <p class="ltx_p" id="S4.SS1.SSS3.p1.1">
      We use the gTTS (Google Text-to-Speech) library in Python to read out text with a female British English voice. However, we received feedback during the pilot study that the speech speed felt slow for natural conversation. To address this issue, we will discuss our solution in Section
      <a class="ltx_ref" href="#S4.SS2" title="4.2 Hardware System Design: The TextileBot Voice Device ‣ 4 The Case of TextileBot: Design and Implementation ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
       <span class="ltx_text ltx_ref_tag">
        4.2
       </span>
      </a>
      .
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2
    </span>
    Hardware System Design: The TextileBot Voice Device
   </h3>
   <figure class="ltx_figure" id="S4.F8">
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel" id="S4.F8.sf1">
       <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="398" id="S4.F8.sf1.g1" src="/html/2406.10590/assets/images/open.jpeg" width="568"/>
       <figcaption class="ltx_caption ltx_centering">
        <span class="ltx_tag ltx_tag_figure">
         (a)
        </span>
        The physical TextileBot interface.
       </figcaption>
      </figure>
     </div>
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel" id="S4.F8.sf2">
       <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="379" id="S4.F8.sf2.g1" src="/html/2406.10590/assets/images/cloth_and_interaction.jpg" width="568"/>
       <figcaption class="ltx_caption ltx_centering">
        <span class="ltx_tag ltx_tag_figure">
         (b)
        </span>
        A participant interacts with the TextileBot.
       </figcaption>
      </figure>
     </div>
    </div>
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_figure">
      Figure 8:
     </span>
     Left: TextileBot - The physical agent interface is composed of a 3D printed box (6), a speaker (5), a microphone (4), and a button (3), all integrated into the Google AIY board (2) mounted on the Raspberry Pi 3 Model B (1) presented in (a). Right: A participant interacting with the TextileBot used across all three voice-based agents (b).
    </figcaption>
   </figure>
   <div class="ltx_para ltx_noindent" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     We built the hardware device around a Raspberry Pi device.
The device is housed in a 3D printed box (6), which includes a speaker (5), a microphone (4), and a button (3), all integrated on the AIY board (2) mounted on the Raspberry Pi 3B (1) as shown in Figure
     <a class="ltx_ref" href="#S4.F8.sf1" title="In Figure 8 ‣ 4.2 Hardware System Design: The TextileBot Voice Device ‣ 4 The Case of TextileBot: Design and Implementation ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       8(a)
      </span>
     </a>
     .
The hardware system includes a Raspberry Pi 3B with a Quad Core 1.2GHz Broadcom BCM2837 64bit CPU and 1GB RAM (1).
We use the Voice HAT configuration
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib1" title="">
       1
      </a>
      ]
     </cite>
     , which contains a Voice AIY accessory board (2) that provides physical connectivity from the GPIO pins and is mounted on the Raspberry Pi 3 board. The Voice HAT set also provides us with an arcade-style button with an LED light (3), a microphone board with the 5-wire daughter board cable (4) and a microphone (5).
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SS2.p2">
    <p class="ltx_p" id="S4.SS2.p2.1">
     The housing was created from an open source CAD model in the
     <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.1">
      Thingiverse
     </span>
     model library. It was 3D printed on a Prusa I3 MK3S+ using the readily available polylactic acid (PLA) material. The front facing side contains holes to allow sound from the speaker to leave the enclosure, while the inside contains various shelves for the control electronics to be mounted to. The top of the box has a hole for the activation button.
The firmware to control this hardware was designed by Google and deeply integrated with the Google Assistant service
     <span class="ltx_note ltx_role_footnote" id="footnote5">
      <sup class="ltx_note_mark">
       5
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         5
        </sup>
        <span class="ltx_tag ltx_tag_note">
         5
        </span>
        The Google AIY has stopped updating their service, and the repository has been archived by the owner on Feb 9, 2023
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib2" title="">
          2
         </a>
         ]
        </cite>
        .
       </span>
      </span>
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib2" title="">
       2
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib35" title="">
       35
      </a>
      ]
     </cite>
     . However, this did not meet our needs, so we conducted the development of our own firmware code that enables flexible audio recording, audio playback and push button control.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SS2.p3">
    <p class="ltx_p" id="S4.SS2.p3.1">
     Users interface with TextileBot via a button with an LED light. A predefined user guide is played when the device is booted. To speak to the TextileBot, users press and then release the button, and do it again when they finish their sentence. The LED light will be lit while recording and playing audio. We use mpg123 library with command “
     <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p3.1.1">
      mpg123 -d 4 -h 3
     </span>
     ” to manually speed up the playback rate to
     <math alttext="1.33\times" class="ltx_math_unparsed" display="inline" id="S4.SS2.p3.1.m1.1">
      <semantics id="S4.SS2.p3.1.m1.1a">
       <mrow id="S4.SS2.p3.1.m1.1b">
        <mn id="S4.SS2.p3.1.m1.1.1">
         1.33
        </mn>
        <mo id="S4.SS2.p3.1.m1.1.2" lspace="0.222em">
         ×
        </mo>
       </mrow>
       <annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">
        1.33\times
       </annotation>
      </semantics>
     </math>
     . This is because participants in our pilot studies have reported the original speaking speed from gTTS is too slow.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Evaluation of TextileBot
  </h2>
  <div class="ltx_para ltx_noindent" id="S5.p1">
   <p class="ltx_p" id="S5.p1.1">
    In the user study, we aimed (1) to evaluate whether our prompt strategy remained effective while preserving domain specificity across various spoken dialogues, and to assess if interactions with three variations of TextileBot differed significantly—indicating that users perceived each as a distinct entity and validating phase 2 of our approach, (2) to investigate if TextileBot could retain memory and conduct continuous conversations as designed in phase 3, and (3) to explore the nature of user interactions with each bot variant to understand the nuances of user engagement. As the language used in spoken dialogue is different from written text
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib81" title="">
      81
     </a>
     ]
    </cite>
    , an in-person study was chosen to allow participants to interact with the TextileBot smart device and evoke natural language conversations. We used a mixed-method approach, combining traditional machine learning ablation study analysis with HIC analysis - questionnaires and qualitative feedback from participants with a conversational analysis of the human-agent dialogue. We recruited a total of 30 participants to interact with each of the three voice agents on textiles and textile circularity, as outlined in the Introduction. In the following sections, we first describe the within-subject study design, measures, and procedure.
   </p>
  </div>
  <section class="ltx_subsection" id="S5.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.1
    </span>
    Study design and methods
   </h3>
   <div class="ltx_para ltx_noindent" id="S5.SS1.p1">
    <p class="ltx_p" id="S5.SS1.p1.1">
     We utilized a mixed within/between-subjects design, where each of the participants (
     <math alttext="N=30" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1">
      <semantics id="S5.SS1.p1.1.m1.1a">
       <mrow id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">
        <mi id="S5.SS1.p1.1.m1.1.1.2" xref="S5.SS1.p1.1.m1.1.1.2.cmml">
         N
        </mi>
        <mo id="S5.SS1.p1.1.m1.1.1.1" xref="S5.SS1.p1.1.m1.1.1.1.cmml">
         =
        </mo>
        <mn id="S5.SS1.p1.1.m1.1.1.3" xref="S5.SS1.p1.1.m1.1.1.3.cmml">
         30
        </mn>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b">
        <apply id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">
         <eq id="S5.SS1.p1.1.m1.1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1.1">
         </eq>
         <ci id="S5.SS1.p1.1.m1.1.1.2.cmml" xref="S5.SS1.p1.1.m1.1.1.2">
          𝑁
         </ci>
         <cn id="S5.SS1.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.SS1.p1.1.m1.1.1.3">
          30
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">
        N=30
       </annotation>
      </semantics>
     </math>
     ) was asked to speak with the three CAs (Vanilla, Assistant, Expert) embodied in the same smart device TextileBots. The order in which participants interacted with each of the agents was randomised to avoid order effects.
For each agent interaction, participants followed the same four phases: Free chatting, Information gathering, Questionnaires, and Overall user feedback. Each of the four phases is detailed below:
    </p>
   </div>
   <section class="ltx_paragraph" id="S5.SS1.SSS0.Px1">
    <h5 class="ltx_title ltx_font_bold ltx_title_paragraph">
     Phase 1 - Free chatting
    </h5>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="S5.SS1.SSS0.Px1.p1.1">
      The human-agent interaction started with an open conversation with no topical restrictions. Participants could freely engage with the agents on any topic of their choice. This approach was designed to facilitate a broad exploration of potential conversation topics relevant to textiles contexts and to gain insights into the personality and characteristics of three conversational agents. A minimum of 5 minutes to a maximum of 10 minutes was allocated to this phase. Free exploration is particularly beneficial for domains that have not yet implemented conversational agents, such as textile circularity. Engaging in freeform conversations during the prototyping phase provides valuable insights into user needs and the scope of topic coverage required in these domains.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S5.SS1.SSS0.Px2">
    <h5 class="ltx_title ltx_font_bold ltx_title_paragraph">
     Phase 2 - Information gathering
    </h5>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px2.p1">
     <p class="ltx_p" id="S5.SS1.SSS0.Px2.p1.1">
      To ensure consistency in the topics discussed, the second part focused on textile circularity, the main conversational topic that has guided the TextileBot implementations.
In collaboration with domain experts in materials science and textile circularity, we developed ten information gathering tasks for participants. To ensure a structured approach, we arranged these tasks in a progression from general to specific, transitioning from high-level concepts to more detailed aspects. Subsequently, we divided the tasks into three distinct groups, and applied the three TextileBots to these groups in a round-robin fashion
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib33" title="">
        33
       </a>
       ]
      </cite>
      to ensure coverage of different task-agent combinations.
     </p>
    </div>
    <figure class="ltx_table" id="S5.T2">
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_table">
       Table 2:
      </span>
      Questionnaire used after each of the three TextileBots to assess the human-bot interaction experience.
     </figcaption>
     <div class="ltx_inline-block ltx_transformed_outer" id="S5.T2.1" style="width:433.6pt;height:158.7pt;vertical-align:-0.0pt;">
      <span class="ltx_transformed_inner" style="transform:translate(-29.0pt,10.6pt) scale(0.881937568086419,0.881937568086419) ;">
       <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.1.1">
        <thead class="ltx_thead">
         <tr class="ltx_tr" id="S5.T2.1.1.1.1">
          <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T2.1.1.1.1.1">
           <span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.1.1.1">
            Evaluation Category
           </span>
          </th>
          <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_tt" id="S5.T2.1.1.1.1.2">
           <span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.1.2.1">
            Metric
           </span>
          </th>
          <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_tt" id="S5.T2.1.1.1.1.3">
           <span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.1.3.1">
            Question type
           </span>
          </th>
         </tr>
        </thead>
        <tbody class="ltx_tbody">
         <tr class="ltx_tr" id="S5.T2.1.1.2.1">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.2.1.1">
           Usability
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.2.1.2">
           Ease to use
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.1.2.1.3">
           5 likert scale
          </td>
         </tr>
         <tr class="ltx_tr" id="S5.T2.1.1.3.2">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.3.2.1" rowspan="3">
           <span class="ltx_text" id="S5.T2.1.1.3.2.1.1">
            Engagement
           </span>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.3.2.2">
           E-I: Interest in responses
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.1.3.2.3">
           5 likert scale
          </td>
         </tr>
         <tr class="ltx_tr" id="S5.T2.1.1.4.3">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.4.3.1">
           E-E: Engagement in conversation
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.1.4.3.2">
           5 likert scale
          </td>
         </tr>
         <tr class="ltx_tr" id="S5.T2.1.1.5.4">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.5.4.1">
           E-W: Willingness to use in the future
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.1.5.4.2">
           5 likert scale
          </td>
         </tr>
         <tr class="ltx_tr" id="S5.T2.1.1.6.5">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.6.5.1" rowspan="3">
           <span class="ltx_text" id="S5.T2.1.1.6.5.1.1">
            Coherence
           </span>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.6.5.2">
           C-I: Input comprehensibility
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.1.6.5.3">
           5 likert scale
          </td>
         </tr>
         <tr class="ltx_tr" id="S5.T2.1.1.7.6">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.7.6.1">
           C-C: Clarity in responses
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.1.7.6.2">
           5 likert scale
          </td>
         </tr>
         <tr class="ltx_tr" id="S5.T2.1.1.8.7">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.8.7.1">
           C-A: Accuracy in responses
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.1.8.7.2">
           5 likert scale
          </td>
         </tr>
         <tr class="ltx_tr" id="S5.T2.1.1.9.8">
          <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S5.T2.1.1.9.8.1" rowspan="2">
           <span class="ltx_text" id="S5.T2.1.1.9.8.1.1">
            Changes over time
           </span>
          </td>
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.9.8.2">
           The level of engagement over time
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.1.9.8.3">
           Multiple-choice: Increase, Decrease, Dynamic
          </td>
         </tr>
         <tr class="ltx_tr" id="S5.T2.1.1.10.9">
          <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S5.T2.1.1.10.9.1">
           Follow-up on changes over time
          </td>
          <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S5.T2.1.1.10.9.2">
           Open-ended question to capture the reason
          </td>
         </tr>
        </tbody>
       </table>
      </span>
     </div>
    </figure>
   </section>
   <section class="ltx_paragraph" id="S5.SS1.SSS0.Px3">
    <h5 class="ltx_title ltx_font_bold ltx_title_paragraph">
     Phase 3 - Questionnaire
    </h5>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px3.p1">
     <p class="ltx_p" id="S5.SS1.SSS0.Px3.p1.1">
      We developed a questionnaire that contains an evaluation matrix to assess the human-LLM agent interaction. The evaluation matrix employs a wide range of existing metrics, combining metrics from conventional heuristics-based conversational agents, for both non goal-oriented/task-agnostic and domain-specific/goal-oriented agents
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib51" title="">
        51
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib86" title="">
        86
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib65" title="">
        65
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib92" title="">
        92
       </a>
       ]
      </cite>
      . We also incorporated human-LM interaction metrics
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib55" title="">
        55
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib99" title="">
        99
       </a>
       ]
      </cite>
      . Since our study involves three TextileBots, we treated each as a separate model and employed the pairwise per-dialogue (PW-dialogue) method
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib86" title="">
        86
       </a>
       ]
      </cite>
      to evaluate the human-LLM interaction. This method compares two entire conversations with two different agents, and has been shown to outperform evaluations of single models. Each participant was asked to conduct three conversations with the three different TextileBots.
Table
      <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ Phase 2 - Information gathering ‣ 5.1 Study design and methods ‣ 5 Evaluation of TextileBot ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      summarises the key focus of the questionnaire, the metrics used and the question types.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S5.SS1.SSS0.Px4">
    <h5 class="ltx_title ltx_font_bold ltx_title_paragraph">
     Phase 4 - Overall user feedback
    </h5>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px4.p1">
     <p class="ltx_p" id="S5.SS1.SSS0.Px4.p1.1">
      At the end of the study, we collected participants overall feedback on their experience with the TextileBots, capturing participants’ subjective experiences engaging with the voice agents, their preferences, observations about the interaction and changes over time, as well as any suggestions for improvements and insights they gained on the domain-specific conversation. Please see an overview of the focus and question types in Table
      <a class="ltx_ref" href="#S5.T3" title="Table 3 ‣ Phase 4 - Overall user feedback ‣ 5.1 Study design and methods ‣ 5 Evaluation of TextileBot ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
       <span class="ltx_text ltx_ref_tag">
        3
       </span>
      </a>
      .
     </p>
    </div>
    <figure class="ltx_table" id="S5.T3">
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_table">
       Table 3:
      </span>
      Overall user feedback and participants preferences between the three TextileBots, captured at the end of the study.
     </figcaption>
     <div class="ltx_inline-block ltx_transformed_outer" id="S5.T3.1" style="width:433.6pt;height:101.2pt;vertical-align:-0.0pt;">
      <span class="ltx_transformed_inner" style="transform:translate(-14.6pt,3.4pt) scale(0.937105049594378,0.937105049594378) ;">
       <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T3.1.1">
        <thead class="ltx_thead">
         <tr class="ltx_tr" id="S5.T3.1.1.1.1">
          <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T3.1.1.1.1.1">
           <span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.1.1">
            Feedback category
           </span>
          </th>
          <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.1.1.1.1.2">
           <span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.2.1">
            Question type
           </span>
          </th>
         </tr>
        </thead>
        <tbody class="ltx_tbody">
         <tr class="ltx_tr" id="S5.T3.1.1.2.1">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.1.1.2.1.1">
           Overall feedback on each of the TextileBots
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.1.2.1.2">
           Open-ended questions
          </td>
         </tr>
         <tr class="ltx_tr" id="S5.T3.1.1.3.2">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.1.1.3.2.1">
           Preference between the three TextileBot
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.1.3.2.2">
           Ranking and open-ended questions
          </td>
         </tr>
         <tr class="ltx_tr" id="S5.T3.1.1.4.3">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.1.1.4.3.1">
           Experience of the TextileBots interaction, changes over time
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.1.4.3.2">
           Open-ended question
          </td>
         </tr>
         <tr class="ltx_tr" id="S5.T3.1.1.5.4">
          <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.1.1.5.4.1">
           Suggestions on TextileBot
          </td>
          <td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.1.5.4.2">
           Open-ended questions
          </td>
         </tr>
         <tr class="ltx_tr" id="S5.T3.1.1.6.5">
          <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S5.T3.1.1.6.5.1">
           Understanding of the domain (textiles circularity)
          </td>
          <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S5.T3.1.1.6.5.2">
           5 likert scale and open-ended questions
          </td>
         </tr>
        </tbody>
       </table>
      </span>
     </div>
    </figure>
   </section>
  </section>
  <section class="ltx_subsection" id="S5.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.2
    </span>
    Study setup and procedure
   </h3>
   <div class="ltx_para ltx_noindent" id="S5.SS2.p1">
    <p class="ltx_p" id="S5.SS2.p1.1">
     The study was conducted in a controlled laboratory environment, with each participant attending individually in-person. Participants were briefed with instructions to imagine a scenario wherein they were talking with three distinct voice agents (each with different personalities and capabilities) in a retail environment, such as a clothing store. A TextileBot device was placed was positioned on a table in front of a participant, allowing them to control it (see Figure
     <a class="ltx_ref" href="#S4.F8.sf2" title="In Figure 8 ‣ 4.2 Hardware System Design: The TextileBot Voice Device ‣ 4 The Case of TextileBot: Design and Implementation ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       8(b)
      </span>
     </a>
     ). The tasks involved identifying and ranking their preferred agent based on its suitability for use in a retail environment as TextileBot, and their subject experience to the overall user feedback. Every interaction session began with an introduction from the respective agent (Vanilla, Expert and Assistant):
    </p>
    <blockquote class="ltx_quote ltx_displayquote" id="S5.SS2.p1.2">
     <p class="ltx_p" id="S5.SS2.p1.2.1">
      <span class="ltx_text ltx_inline-quote" id="S5.SS2.p1.2.1.1">
       <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.2.1.1.1">
        "Hi there, I’m TextileBot. I’m here to assist you with any questions or discussions you may have regarding textiles. To speak with me, simply click the button and start talking. When you’re finished, click the button again to let me know that you’re done. How can I assist you today?"
       </span>
      </span>
     </p>
    </blockquote>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS2.p2">
    <p class="ltx_p" id="S5.SS2.p2.1">
     After the agent’s welcome message, participants were given 5-10 minutes to interact freely with the TextileBot, choosing their own conversational topics (Phase 1). When satisfied with the interaction or the time limit was reached, participants proceeded to the information gathering phase (Phase 2). Upon completion of both phases, participants were then asked to fill out a questionnaire to assess their experience with that particular agent (Phase 3). This three-phase procedure was repeated for all three TextileBots. Participants were also offered the opportunity to extend their interaction with any TextileBot of their choice or all of them, if they prefer, before proceeding to Phase 4. Once all interaction sessions were completed, participants were asked to provide final overall feedback (Phase 4) on their experience using the voice-based TextileBots, as outlined in Section
     <a class="ltx_ref" href="#S5.SS1" title="5.1 Study design and methods ‣ 5 Evaluation of TextileBot ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       5.1
      </span>
     </a>
     .
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S5.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.3
    </span>
    Analysis approach
   </h3>
   <div class="ltx_para ltx_noindent" id="S5.SS3.p1">
    <p class="ltx_p" id="S5.SS3.p1.1">
     Our primary focus is to explore the efficient development of LLM-based voice CAs that are domain-specific and offer personalized interactions that is capable of conducting continuous (multi-turn) conversations. We started by analyzing questionnaire responses with each agent to understand each vHAI (Vallina, Expert and Assistant). Following this, we conducted a qualitative analysis of the overall user feedback to gain insights into participants’ overall perceptions of three agents. The evaluation also examines the effectiveness of our approach.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS3.p2">
    <p class="ltx_p" id="S5.SS3.p2.1">
     In addition, a key aspect of our research is exploring how people perceive and engage with different prompted LLM-based CAs. Hence, as a first step in the analysis, the dialogue contents were stored in a text format and imported into NVivo 14, a qualitative analysis software. A dialogue refers to a whole recorded exchange of conversation between a participant and a CA
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib89" title="">
       89
      </a>
      ]
     </cite>
     . We then applied a data-driven inductive thematic analysis approach to identify recurring themes and patterns within the dialogue transcripts and to gain qualitative insights into the vHAI.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS3.p3">
    <p class="ltx_p" id="S5.SS3.p3.1">
     The first author applied an open-coding approach to the dialogues, and created a first coding scheme that was discussed and refined with the co-authors. After several discussions and iterations, all authors reached the consensus that the vHAI can’t be easily shoehorned into a set of themes. However, it was agreed that the changes in the interaction patterns over time should be further explored to understand variations in the dialogue and participant behaviours. Hence, we decided to employ a combined inductive/deductive hybrid approach focused on:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS3.p4">
    <ol class="ltx_enumerate" id="S5.I1">
     <li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       1.
      </span>
      <div class="ltx_para" id="S5.I1.i1.p1">
       <p class="ltx_p" id="S5.I1.i1.p1.1">
        An analysis of the dialogues based on conversational turns,
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       2.
      </span>
      <div class="ltx_para" id="S5.I1.i2.p1">
       <p class="ltx_p" id="S5.I1.i2.p1.1">
        An analysis of the conversational styles,
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       3.
      </span>
      <div class="ltx_para ltx_noindent" id="S5.I1.i3.p1">
       <p class="ltx_p" id="S5.I1.i3.p1.1">
        An analysis of the human behaviour in the interaction with the TextileBots.
       </p>
      </div>
     </li>
    </ol>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS3.p5">
    <p class="ltx_p" id="S5.SS3.p5.1">
     In Section
     <a class="ltx_ref" href="#S6.SS3" title="6.3 Dialogue analysis of the voice-based human-agent interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       6.3
      </span>
     </a>
     , we present the results for each of those three points, starting from the “conversational turns” and “turn-taking patterns” observed within and across the three voice agents. We then further explored differences between single vs. multi-turn conversations and calculated the number of words used by participants in each turn, as a possible indicator for their engagement over time and across the agents. This dialogue analysis was extended with a deep dive into the conversational styles enriched and exemplified with representative quotes from participants’ interaction with the agents, and a particular emphasis on the changes over time, drawing on existing language concepts such as code-switching and social protocols. We conclude with a reflection on specific human behaviours and strategies when engaging with the three different agents. All taken together form a rich, multi-faceted foundation for our discussion on the effectiveness of our approach and how humans perceive, interact, and engage with prompt-based voice agents.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S5.SS3.p6">
    <p class="ltx_p" id="S5.SS3.p6.1">
     All participants quotes are included with original spelling and emphasis.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S5.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.4
    </span>
    Participants
   </h3>
   <div class="ltx_para ltx_noindent" id="S5.SS4.p1">
    <p class="ltx_p" id="S5.SS4.p1.1">
     We recruited 30 participants aged between 22 to 44 years of age (mean age = 30, SD = 5.33), out of which fourteen were male, sixteen female. Participants had a diverse range of backgrounds, including computer scientists, UX designers, artists, healthcare consultants, researchers, university lecturers, and university students. All participants were either native English speakers or highly proficient in English.
Furthermore, the participants came from 15 countries across five continents. The study was approved by the local University Research Ethics Committee
. All participants provided written informed consent before taking part in the study. The study lasted between 45 to 60 minutes, and all participants were compensated with a gift voucher for their time.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   Results
  </h2>
  <div class="ltx_para ltx_noindent" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    We present our findings in three main sections: analysis of questionnaire responses (Section
    <a class="ltx_ref" href="#S6.SS1" title="6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
     <span class="ltx_text ltx_ref_tag">
      6.1
     </span>
    </a>
    ), overall participant feedback (Section
    <a class="ltx_ref" href="#S6.SS2" title="6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
     <span class="ltx_text ltx_ref_tag">
      6.2
     </span>
    </a>
    ), and dialogue data from our user study (Section
    <a class="ltx_ref" href="#S6.SS4" title="6.4 Conversational styles ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
     <span class="ltx_text ltx_ref_tag">
      6.4
     </span>
    </a>
    ). The questionnaire responses and dialogue data explore whether participants perceived three variations of TextileBot as distinct entities and their engagement with each prompted version. Additionally, these sections assess whether TextileBot maintained memory and facilitated continuous conversations. Together, these results provide insights into the nuances of user engagement with different LLM-powered voice agents.
   </p>
  </div>
  <section class="ltx_subsection" id="S6.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.1
    </span>
    Questionnaire results
   </h3>
   <div class="ltx_para ltx_noindent" id="S6.SS1.p1">
    <p class="ltx_p" id="S6.SS1.p1.1">
     To determine if participants perceived three variations of TextileBot as distinct entities, we analyzed questionnaire data from our study. We obtained a total of 120 questionnaires, 90 from the interaction sessions (three per participant, for each agent they tried), and 30 from the overall user feedback. This section mainly discusses the results we have with respect to an analysis using the metrics in Table
     <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ Phase 2 - Information gathering ‣ 5.1 Study design and methods ‣ 5 Evaluation of TextileBot ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     . We also aimed to understand participants’ perceptions of voice agents when presented with different prompts.
    </p>
   </div>
   <section class="ltx_paragraph" id="S6.SS1.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     Engagement and coherence metrics
    </h5>
    <div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="S6.SS1.SSS0.Px1.p1.4">
      We first obtained participants’ scores for both Engagement and Coherence metrics, averaged them, and presented them in a radar plot (Figure
      <a class="ltx_ref" href="#S6.F9.sf1" title="In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
       <span class="ltx_text ltx_ref_tag">
        9(a)
       </span>
      </a>
      ). All responses were coded from
      <math alttext="1" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px1.p1.1.m1.1">
       <semantics id="S6.SS1.SSS0.Px1.p1.1.m1.1a">
        <mn id="S6.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S6.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">
         1
        </mn>
        <annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.1.m1.1b">
         <cn id="S6.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" type="integer" xref="S6.SS1.SSS0.Px1.p1.1.m1.1.1">
          1
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.1.m1.1c">
         1
        </annotation>
       </semantics>
      </math>
      to
      <math alttext="5" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px1.p1.2.m2.1">
       <semantics id="S6.SS1.SSS0.Px1.p1.2.m2.1a">
        <mn id="S6.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S6.SS1.SSS0.Px1.p1.2.m2.1.1.cmml">
         5
        </mn>
        <annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.2.m2.1b">
         <cn id="S6.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" type="integer" xref="S6.SS1.SSS0.Px1.p1.2.m2.1.1">
          5
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.2.m2.1c">
         5
        </annotation>
       </semantics>
      </math>
      ; all averages fell in the range between
      <math alttext="3" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px1.p1.3.m3.1">
       <semantics id="S6.SS1.SSS0.Px1.p1.3.m3.1a">
        <mn id="S6.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S6.SS1.SSS0.Px1.p1.3.m3.1.1.cmml">
         3
        </mn>
        <annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.3.m3.1b">
         <cn id="S6.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" type="integer" xref="S6.SS1.SSS0.Px1.p1.3.m3.1.1">
          3
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.3.m3.1c">
         3
        </annotation>
       </semantics>
      </math>
      and
      <math alttext="4.5" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px1.p1.4.m4.1">
       <semantics id="S6.SS1.SSS0.Px1.p1.4.m4.1a">
        <mn id="S6.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S6.SS1.SSS0.Px1.p1.4.m4.1.1.cmml">
         4.5
        </mn>
        <annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.4.m4.1b">
         <cn id="S6.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" type="float" xref="S6.SS1.SSS0.Px1.p1.4.m4.1.1">
          4.5
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.4.m4.1c">
         4.5
        </annotation>
       </semantics>
      </math>
      .
Figure
      <a class="ltx_ref" href="#S6.F9.sf1" title="In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
       <span class="ltx_text ltx_ref_tag">
        9(a)
       </span>
      </a>
      shows the questionnaire’s overall results regarding the evaluation of engagement and coherence. The results in Figure
      <a class="ltx_ref" href="#S6.F9.sf1" title="In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
       <span class="ltx_text ltx_ref_tag">
        9(a)
       </span>
      </a>
      demonstrate that Assistant is generally the best across all these evaluation metrics.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S6.SS1.SSS0.Px2">
    <h5 class="ltx_title ltx_title_paragraph">
     Cross-metrics interactions
    </h5>
    <div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px2.p1">
     <p class="ltx_p" id="S6.SS1.SSS0.Px2.p1.1">
      We then used mixed cumulative link regression models with participants and interaction topics/questions as random effects. This allowed us to account for the nested nature of the experimental design
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib50" title="">
        50
       </a>
       ]
      </cite>
      and the ordinal characteristics of the survey’s responses
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib109" title="">
        109
       </a>
       ]
      </cite>
      . Data was analysed using the “ordinal” package in R
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib20" title="">
        20
       </a>
       ]
      </cite>
      .
No difference was found when comparing models on their Ease of use and Coherence (C-I, C-C, C-A) metrics.
As we have also seen in Figure
      <a class="ltx_ref" href="#S6.F9.sf1" title="In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
       <span class="ltx_text ltx_ref_tag">
        9(a)
       </span>
      </a>
      , the variations in C-I, C-C and C-A are relatively small, we turn the focus of the analysis to the remaining Engagement metrics (E-I, E-E and E-W).
     </p>
    </div>
    <figure class="ltx_figure" id="S6.F9">
     <div class="ltx_flex_figure">
      <div class="ltx_flex_cell ltx_flex_size_2">
       <figure class="ltx_figure ltx_figure_panel" id="S6.F9.sf1">
        <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="451" id="S6.F9.sf1.g1" src="/html/2406.10590/assets/images/surveys.png" width="479"/>
        <figcaption class="ltx_caption ltx_centering">
         <span class="ltx_tag ltx_tag_figure">
          (a)
         </span>
         Engagement and Coherence metrics.
        </figcaption>
       </figure>
      </div>
      <div class="ltx_flex_cell ltx_flex_size_2">
       <figure class="ltx_figure ltx_figure_panel" id="S6.F9.sf2">
        <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="474" id="S6.F9.sf2.g1" src="/html/2406.10590/assets/images/rank.png" width="598"/>
        <figcaption class="ltx_caption ltx_centering">
         <span class="ltx_tag ltx_tag_figure">
          (b)
         </span>
         Participant preference ranking.
        </figcaption>
       </figure>
      </div>
     </div>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_figure">
       Figure 9:
      </span>
      Left: this includes Interestingness in responses (Engagement, E-I), Engagement in conversations (Engagement, E-E) and Willingness to use in the future (Engagement, E-W), Input comprehensibility (Coherence, C-I), Clarity in responses (Coherence, C-C), Accuracy in responses (Coherence, C-A). Right: Participant preference ranking of the three TextileBots in light of textile circularity.
     </figcaption>
    </figure>
    <div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px2.p2">
     <p class="ltx_p" id="S6.SS1.SSS0.Px2.p2.3">
      As depicted in Figure
      <a class="ltx_ref" href="#S6.F9.sf1" title="In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
       <span class="ltx_text ltx_ref_tag">
        9(a)
       </span>
      </a>
      , the TextileBot Assistant was found consistently more engaging at the single response than its Expert and Vanilla counterparts (E-I), although results were not statistically significant (“marginally” significant
      <math alttext="p=0.06" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px2.p2.1.m1.1">
       <semantics id="S6.SS1.SSS0.Px2.p2.1.m1.1a">
        <mrow id="S6.SS1.SSS0.Px2.p2.1.m1.1.1" xref="S6.SS1.SSS0.Px2.p2.1.m1.1.1.cmml">
         <mi id="S6.SS1.SSS0.Px2.p2.1.m1.1.1.2" xref="S6.SS1.SSS0.Px2.p2.1.m1.1.1.2.cmml">
          p
         </mi>
         <mo id="S6.SS1.SSS0.Px2.p2.1.m1.1.1.1" xref="S6.SS1.SSS0.Px2.p2.1.m1.1.1.1.cmml">
          =
         </mo>
         <mn id="S6.SS1.SSS0.Px2.p2.1.m1.1.1.3" xref="S6.SS1.SSS0.Px2.p2.1.m1.1.1.3.cmml">
          0.06
         </mn>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p2.1.m1.1b">
         <apply id="S6.SS1.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S6.SS1.SSS0.Px2.p2.1.m1.1.1">
          <eq id="S6.SS1.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="S6.SS1.SSS0.Px2.p2.1.m1.1.1.1">
          </eq>
          <ci id="S6.SS1.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S6.SS1.SSS0.Px2.p2.1.m1.1.1.2">
           𝑝
          </ci>
          <cn id="S6.SS1.SSS0.Px2.p2.1.m1.1.1.3.cmml" type="float" xref="S6.SS1.SSS0.Px2.p2.1.m1.1.1.3">
           0.06
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p2.1.m1.1c">
         p=0.06
        </annotation>
       </semantics>
      </math>
      ). This pattern did not emerge at the conversation level (E-E), where both Vanilla and Assistant were slightly (but consistently across participants) more engaging than the Expert agent (
      <math alttext="p=0.2" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px2.p2.2.m2.1">
       <semantics id="S6.SS1.SSS0.Px2.p2.2.m2.1a">
        <mrow id="S6.SS1.SSS0.Px2.p2.2.m2.1.1" xref="S6.SS1.SSS0.Px2.p2.2.m2.1.1.cmml">
         <mi id="S6.SS1.SSS0.Px2.p2.2.m2.1.1.2" xref="S6.SS1.SSS0.Px2.p2.2.m2.1.1.2.cmml">
          p
         </mi>
         <mo id="S6.SS1.SSS0.Px2.p2.2.m2.1.1.1" xref="S6.SS1.SSS0.Px2.p2.2.m2.1.1.1.cmml">
          =
         </mo>
         <mn id="S6.SS1.SSS0.Px2.p2.2.m2.1.1.3" xref="S6.SS1.SSS0.Px2.p2.2.m2.1.1.3.cmml">
          0.2
         </mn>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p2.2.m2.1b">
         <apply id="S6.SS1.SSS0.Px2.p2.2.m2.1.1.cmml" xref="S6.SS1.SSS0.Px2.p2.2.m2.1.1">
          <eq id="S6.SS1.SSS0.Px2.p2.2.m2.1.1.1.cmml" xref="S6.SS1.SSS0.Px2.p2.2.m2.1.1.1">
          </eq>
          <ci id="S6.SS1.SSS0.Px2.p2.2.m2.1.1.2.cmml" xref="S6.SS1.SSS0.Px2.p2.2.m2.1.1.2">
           𝑝
          </ci>
          <cn id="S6.SS1.SSS0.Px2.p2.2.m2.1.1.3.cmml" type="float" xref="S6.SS1.SSS0.Px2.p2.2.m2.1.1.3">
           0.2
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p2.2.m2.1c">
         p=0.2
        </annotation>
       </semantics>
      </math>
      ). Still, on the Engagement dimension (E-W), participants reported that they would be significantly more likely to interact with the TextileBot assistant than with both alternative versions in the future (
      <math alttext="p&lt;0.05" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px2.p2.3.m3.1">
       <semantics id="S6.SS1.SSS0.Px2.p2.3.m3.1a">
        <mrow id="S6.SS1.SSS0.Px2.p2.3.m3.1.1" xref="S6.SS1.SSS0.Px2.p2.3.m3.1.1.cmml">
         <mi id="S6.SS1.SSS0.Px2.p2.3.m3.1.1.2" xref="S6.SS1.SSS0.Px2.p2.3.m3.1.1.2.cmml">
          p
         </mi>
         <mo id="S6.SS1.SSS0.Px2.p2.3.m3.1.1.1" xref="S6.SS1.SSS0.Px2.p2.3.m3.1.1.1.cmml">
          &lt;
         </mo>
         <mn id="S6.SS1.SSS0.Px2.p2.3.m3.1.1.3" xref="S6.SS1.SSS0.Px2.p2.3.m3.1.1.3.cmml">
          0.05
         </mn>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p2.3.m3.1b">
         <apply id="S6.SS1.SSS0.Px2.p2.3.m3.1.1.cmml" xref="S6.SS1.SSS0.Px2.p2.3.m3.1.1">
          <lt id="S6.SS1.SSS0.Px2.p2.3.m3.1.1.1.cmml" xref="S6.SS1.SSS0.Px2.p2.3.m3.1.1.1">
          </lt>
          <ci id="S6.SS1.SSS0.Px2.p2.3.m3.1.1.2.cmml" xref="S6.SS1.SSS0.Px2.p2.3.m3.1.1.2">
           𝑝
          </ci>
          <cn id="S6.SS1.SSS0.Px2.p2.3.m3.1.1.3.cmml" type="float" xref="S6.SS1.SSS0.Px2.p2.3.m3.1.1.3">
           0.05
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p2.3.m3.1c">
         p&lt;0.05
        </annotation>
       </semantics>
      </math>
      , post-hoc tests, Bonferroni corrected).
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S6.SS1.SSS0.Px3">
    <h5 class="ltx_title ltx_title_paragraph">
     Ease to use and Interest change over time
    </h5>
    <div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px3.p1">
     <p class="ltx_p" id="S6.SS1.SSS0.Px3.p1.1">
      Overall, the ease of use was rated from 2 to 5 with an average score of 4.
Regarding the change in interest levels over time, 83.8% of the sessions showed that there is a variation in interest levels. 53.8% reported an increase, 20% reported a decrease, 10% were dynamic. The rest reported no change.
Participants emphasized the significant influence of response content on their level of interest. For example, P5 pointed out that their interest
      <span class="ltx_text ltx_font_italic" id="S6.SS1.SSS0.Px3.p1.1.1">
       “depended on the specific question and corresponding answers”
      </span>
      . Similar statements were echoed by P18 and P28, who noted that their interest heightened when the agent delivered intriguing responses.
The other factor is the length of the response. Both P15 and P16 expressed annoyance due to the vast, long-winded response from Expert. As P15 put it,
      <span class="ltx_text ltx_font_italic" id="S6.SS1.SSS0.Px3.p1.1.2">
       ”It sometimes provided too much information which made me lose interest somewhat”
      </span>
      .
P16 went into further detail, stating,
      <span class="ltx_text ltx_font_italic" id="S6.SS1.SSS0.Px3.p1.1.3">
       ”Sometimes the responses were a bit long. The information provided was interesting, but the agent essentially answered my question within the first few seconds and then kept talking.”
      </span>
      However, not all participants were thrilled with shorter responses. P17 commented on Vanilla as
      <span class="ltx_text ltx_font_italic" id="S6.SS1.SSS0.Px3.p1.1.4">
       “It was too brief with little prompt but it remembers previous questions and provided context based answers”
      </span>
      .
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S6.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.2
    </span>
    Overall feedback
   </h3>
   <div class="ltx_para ltx_noindent" id="S6.SS2.p1">
    <p class="ltx_p" id="S6.SS2.p1.1">
     In this section, we present the overall user feedback on the participants’ subjective experiences with the agents, their preferences, feedback on how they perceived the interactions over time and any suggestions for improvements.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S6.SS2.p2">
    <p class="ltx_p" id="S6.SS2.p2.1">
     Overall, participants enjoyed the interaction because
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p2.1.1">
      “it felt really natural”
     </span>
     (P7) and
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p2.1.2">
      “The levels of answers were good throughout but I really liked the memory function and the agent answers were not generic, especially compared to my other voice agent experiences”
     </span>
     (P13). Nevertheless, a number of participants (N=4) perceived the interaction to be a one-way question-answering rather than conversation and expected the voice agent to engage in a more dialogic interaction by asking questions:
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p2.1.3">
      “I wish it engaged in conversation as well, asking questions back more, so you feel more engaged as well…”
     </span>
     (P14). Participants (N=5) suggested that the voice agents would benefit from adopting
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p2.1.4">
      “emotion embedded”
     </span>
     and
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p2.1.5">
      “more interesting”
     </span>
     responses to achieve a human-like
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p2.1.6">
      “real conversation”
     </span>
     . Participants mentioned that they would prefer
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p2.1.7">
      “less formal”
     </span>
     ,
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p2.1.8">
      “less persuasive”
     </span>
     voice agent with
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p2.1.9">
      “a bit of humour”
     </span>
     and
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p2.1.10">
      “shorter answer”
     </span>
     , in order to facilitate
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p2.1.11">
      ”more engaging interactions”
     </span>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S6.SS2.p3">
    <p class="ltx_p" id="S6.SS2.p3.1">
     Moreover, participants (N=6) commented on the clarity and quality of the content provided by the voice agents. The majority of the feedback on the information seeking phase (i.e. information provided by the voice agent) was positive, with comments praising the levels of answers and clarity, such as P13 noted
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p3.1.1">
      “agent answers were not generic especially compared to my other voice agent experiences”
     </span>
     . On the other hand, some participants pointed out redundancy and vagueness, such as highlighted by P22:
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p3.1.2">
      “Sometimes the answers provided in the conversations were a bit redundant, but I found the answers very clear, although sometimes a bit vague or broad.”
     </span>
     . However, there was a general feeling that more concise, in-depth content delivery by the voice agents would be desirable.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S6.SS2.p4">
    <p class="ltx_p" id="S6.SS2.p4.1">
     In summary, participants anticipated voice agents that engage proactively, exhibit personality, deliver interactive communication (memory function), and provide varied, interesting yet concise content. Furthermore, the incorporation of human-like qualities in both content and voice is desirable. These insights are further reflected in participants’ feedback on their agent preferences.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S6.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      6.2.1
     </span>
     Preferences and experiences across voice agents
    </h4>
    <div class="ltx_para ltx_noindent" id="S6.SS2.SSS1.p1">
     <p class="ltx_p" id="S6.SS2.SSS1.p1.1">
      Participants were asked to express their preference towards the three TextileBots by ranking them. We used the chi-square test to assess whether any of the agents was selected significantly more (or less) often as a favourite agent. Results showed no statistically significant differences although, as mentioned before based on the conversational analysis and questionnaire feedback, we can see a preference for the Assisstant agent, followed by Vanilla and the Expert as shown in Figure
      <a class="ltx_ref" href="#S6.F9.sf2" title="In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
       <span class="ltx_text ltx_ref_tag">
        9(b)
       </span>
      </a>
      . The Assistant agent was selected more often (14 selections) than Vanilla (12 selections) than the Expert agent (only 4 selections). On the other hand, the Expert agent reached “second place” (14 selections) more often than both the Vanilla (7 selections) and Assistant (9 selections) agents.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S6.SS2.SSS1.p2">
     <p class="ltx_p" id="S6.SS2.SSS1.p2.1">
      Most participants (N=18) expressed a preference for an agent that can communicate in a concise and clear manner with them.
P17 stated,
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS1.p2.1.1">
       “the 2nd agent (Assistant) gave just the right amount of detail.”
      </span>
      However, it is worth noting that the length of the agent responses was not universally appreciated, as discussed in Section
      <a class="ltx_ref" href="#S6.SS1.SSS0.Px3" title="Ease to use and Interest change over time ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
       <span class="ltx_text ltx_ref_tag">
        6.1
       </span>
      </a>
      .
Moreover, some participants (N=13) distinguished the agents based on their interactive capability. The Assistant agent was preferred by many for its interaction level, as P29 stated
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS1.p2.1.2">
       “Assistant agent has the best understanding of my question and explained in a most interesting way”
      </span>
      . In contrast, the Expert agent was criticized for being a repetitive information source lacking meaningful interaction. P1 mentioned that Expert agent
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS1.p2.1.3">
       ”feels like a repetitive of the textile circularity concept.”
      </span>
      Whereas P30 point out on the conversational breath that Expert
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS1.p2.1.4">
       “is too restrictive up to a point where it stops responding to questions asked”
      </span>
      .
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S6.SS2.SSS1.p3">
     <p class="ltx_p" id="S6.SS2.SSS1.p3.1">
      Finally, the agent’s perceived personality also played a role in preferences. A number of participants (N=8) appreciated agents that showed human-like responses. P5 noted that the 2nd agent (Vanilla)
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS1.p3.1.1">
       “sounds more like a human… and gives me some interesting answers and makes me laugh.”
      </span>
      In contrast, the Expert agent received criticism for its formal tonality, with P25 noting that it was more like a
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS1.p3.1.2">
       “text-book”
      </span>
      and P10 referring to it as
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS1.p3.1.3">
       “speaking with a smart microwave.”
      </span>
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S6.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      6.2.2
     </span>
     Perceived changes over time
    </h4>
    <div class="ltx_para ltx_noindent" id="S6.SS2.SSS2.p1">
     <p class="ltx_p" id="S6.SS2.SSS2.p1.1">
      Most participants (N=24) in our study described a change in their overall interaction with the agents. Several participants (N=13) commented that their engagement and the nature of interaction evolved as they became familiar with the agent. Some participants even noted
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS2.p1.1.1">
       an increase in confidence and comfort
      </span>
      in their interaction towards the later stages, as described by P5:
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS2.p1.1.2">
       “the more time I spent on the agent, the more open I am”
      </span>
      . Several participants (N=9) even mentioned adapting their communication styles, such as the language and the clarity of their questions to better communicate with the agent. P15 stated: “The way I asked it questions so that they were clear enough, avoided using too much colloquial language”. Additionally, some participants (N=5) stated an increase in specificity in their query,
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS2.p1.1.3">
       “my questions changed…”
      </span>
      ,
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS2.p1.1.4">
       “more specific questions as time went by”
      </span>
      , and
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS2.p1.1.5">
       “I started to comment on its response and asked for further explanations.”
      </span>
      . There was a general trend towards asking
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS2.p1.1.6">
       more specific
      </span>
      and deeper questions as the dialogues progressed. Possibly as a result of a better understanding of the agent’s capacities or due to a growing interest in the topic.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S6.SS2.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      6.2.3
     </span>
     Suggestions for improvements
    </h4>
    <div class="ltx_para ltx_noindent" id="S6.SS2.SSS3.p1">
     <p class="ltx_p" id="S6.SS2.SSS3.p1.1">
      Participants provided valuable suggestions for improving the agents, including one common suggestion to use a more natural and human-like voice. Suggestions such as
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS3.p1.1.1">
       “more natural voice”
      </span>
      (P5) and
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS3.p1.1.2">
       “smoother voice, more dynamic”
      </span>
      (P6) indicated a preference for a less robotic tone. Participants also mentioned the need for the agent to be maybe more empathetic, as P20 stated,
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS3.p1.1.3">
       “add some emotions”
      </span>
      . Another suggestion was to improve the flow of the agent’s speech, such as
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS3.p1.1.4">
       “pauses when there is some punctuation would be helpful”
      </span>
      (P22). In addition to the voice suggestions, participants wanted the agent to be concise, encouraging, and human-like. Suggestions included making the agent more engaging and insightful with personalised responses. Participants emphasised the importance of personalization, acknowledging that different users may have different knowledge levels, needs, and interests. They felt that the current agents need to reduce the
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS3.p1.1.5">
       “teacher-like”
      </span>
      (P1) and
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS3.p1.1.6">
       “uncanny valley”
      </span>
      (P7) effects in their responses. Another suggestion was related to the ability to interrupt the agent’s responses, as one could in a human-human interaction. P15 put it as follows:
      <span class="ltx_text ltx_font_italic" id="S6.SS2.SSS3.p1.1.7">
       “Could be useful to be able to interrupt the agent’s response if the answer is not in line or maybe too long”
      </span>
      . This again hints to the suggestion for a more natural and human-like interaction.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S6.SS2.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      6.2.4
     </span>
     Understanding of the domain (textiles circularity)
    </h4>
    <div class="ltx_para ltx_noindent" id="S6.SS2.SSS4.p1">
     <p class="ltx_p" id="S6.SS2.SSS4.p1.1">
      With regard to the specific conversation topic, textile circularity, most participants (N=21) reported that they had not previously encountered the concept of textile circularity. Despite this, an almost equal majority (N=27) were able to furnish a definition falling within the standard understanding of textile circularity by the end of the study. This concept of textile circularity is admittedly abstract and complex, a factor which led to many of our participants finding the subject matter somewhat tedious. Regardless, they remained engaged throughout the study and demonstrated the ability to articulate the concept in their own words. We believe these observations underscore potential avenues for future research, particularly exploring our prompt-based voice agents in other subject domains.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S6.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.3
    </span>
    Dialogue analysis of the voice-based human-agent interaction
   </h3>
   <div class="ltx_para ltx_noindent" id="S6.SS3.p1">
    <p class="ltx_p" id="S6.SS3.p1.1">
     We collected a total of 93 dialogues from 30 participants (3 agent interactions per participant), where 3 additional dialogues resulted from the “further interactions” that 2 participants had with the Vanilla (1x) and Assistant (2x) agents.
    </p>
   </div>
   <figure class="ltx_table" id="S6.T4">
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_table">
      Table 4:
     </span>
     Analysis of Interaction Turns and Word Count in TextileBots: The Assistant TextileBot displayed the highest frequency of interaction turns but the lowest word counts per turn both by the participants and Assistant TextileBot itself, as compared to others. In contrast, the Expert TextileBot exhibited the reverse behaviour. *In our study, each participant gathers one-third of the information using a bot, totaling 30 Info gathering sessions. The average number of turns is calculated from 10 complete sessions for each bot.
    </figcaption>
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S6.T4.1" style="width:433.6pt;height:82.3pt;vertical-align:-0.0pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-20.2pt,3.8pt) scale(0.914808702724224,0.914808702724224) ;">
      <table class="ltx_tabular ltx_align_middle" id="S6.T4.1.1">
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="S6.T4.1.1.1.1">
         <td class="ltx_td ltx_border_r ltx_border_t" id="S6.T4.1.1.1.1.1">
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S6.T4.1.1.1.1.2">
          <span class="ltx_text ltx_font_bold" id="S6.T4.1.1.1.1.2.1">
           Number of turns
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S6.T4.1.1.1.1.3">
          <span class="ltx_text ltx_font_bold" id="S6.T4.1.1.1.1.3.1">
           Word counts per turn
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S6.T4.1.1.2.2">
         <td class="ltx_td" id="S6.T4.1.1.2.2.1">
         </td>
         <td class="ltx_td ltx_align_center ltx_border_l ltx_border_t" id="S6.T4.1.1.2.2.2">
          Overall
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S6.T4.1.1.2.2.3">
          Free-chatting
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T4.1.1.2.2.4">
          Info gathering*
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S6.T4.1.1.2.2.5">
          Participants utterances
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S6.T4.1.1.2.2.6">
          Bot utterances
         </td>
        </tr>
        <tr class="ltx_tr" id="S6.T4.1.1.3.3">
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T4.1.1.3.3.1">
          Vanilla
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S6.T4.1.1.3.3.2">
          13.77 ± 6.29
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S6.T4.1.1.3.3.3">
          12.6
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T4.1.1.3.3.4">
          11.7
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S6.T4.1.1.3.3.5">
          11.78 ± 8.06
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S6.T4.1.1.3.3.6">
          44.53 ± 22.69
         </td>
        </tr>
        <tr class="ltx_tr" id="S6.T4.1.1.4.4">
         <td class="ltx_td ltx_align_center ltx_border_r" id="S6.T4.1.1.4.4.1">
          Expert
         </td>
         <td class="ltx_td ltx_align_center" id="S6.T4.1.1.4.4.2">
          11.03 ± 3.7
         </td>
         <td class="ltx_td ltx_align_center" id="S6.T4.1.1.4.4.3">
          7.6
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r" id="S6.T4.1.1.4.4.4">
          11.2
         </td>
         <td class="ltx_td ltx_align_center" id="S6.T4.1.1.4.4.5">
          12.11 ± 8.45
         </td>
         <td class="ltx_td ltx_align_center" id="S6.T4.1.1.4.4.6">
          61.52 ± 23.74
         </td>
        </tr>
        <tr class="ltx_tr" id="S6.T4.1.1.5.5">
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S6.T4.1.1.5.5.1">
          Assistant
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S6.T4.1.1.5.5.2">
          17.6 ± 10.19
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S6.T4.1.1.5.5.3">
          9.5
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S6.T4.1.1.5.5.4">
          14
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S6.T4.1.1.5.5.5">
          11.43 ± 9.20
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S6.T4.1.1.5.5.6">
          37.29 ± 37.29
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
   </figure>
   <section class="ltx_subsubsection" id="S6.SS3.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      6.3.1
     </span>
     Conversation turns
    </h4>
    <div class="ltx_para ltx_noindent" id="S6.SS3.SSS1.p1">
     <p class="ltx_p" id="S6.SS3.SSS1.p1.1">
      The dialogues contained a total of 1272 conversational turns. Each turn denotes an exchange of utterances, representing a pairwise dialogue between a participant and the agent. On average, a dialogue comprised 799.40 words (SD=317.53) and 14.13 turns (SD=7.95). As we discussed earlier, tracking the number of conversation turns between the participant and the conversational agent can provide insights into the depth and length of interactions. Higher turn counts indicate more engaged participants
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib67" title="">
        67
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib66" title="">
        66
       </a>
       ]
      </cite>
      .
     </p>
    </div>
    <section class="ltx_paragraph" id="S6.SS3.SSS1.Px1">
     <h5 class="ltx_title ltx_title_paragraph">
      Turn-taking comparison across agents
     </h5>
     <div class="ltx_para ltx_noindent" id="S6.SS3.SSS1.Px1.p1">
      <p class="ltx_p" id="S6.SS3.SSS1.Px1.p1.1">
       As illustrated in Table
       <a class="ltx_ref" href="#S6.T4" title="Table 4 ‣ 6.3 Dialogue analysis of the voice-based human-agent interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
        <span class="ltx_text ltx_ref_tag">
         4
        </span>
       </a>
       and Figure
       <a class="ltx_ref" href="#S6.F10.sf1" title="In Figure 10 ‣ 6.3.2 Word count in each turn ‣ 6.3 Dialogue analysis of the voice-based human-agent interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
        <span class="ltx_text ltx_ref_tag">
         10(a)
        </span>
       </a>
       ,
it is evident that the Assistant agent garners the highest level of participant engagement, whereas participants tend to exhibit lower levels of engagement with the Vanilla agent. These results indicate that there are statistically significant differences in the number of turns between the Assistant agent and the other two agents, but not between the Vanilla and Expert agents.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S6.SS3.SSS1.Px2">
     <h5 class="ltx_title ltx_title_paragraph">
      Single vs Multi-turn conversations
     </h5>
     <div class="ltx_para ltx_noindent" id="S6.SS3.SSS1.Px2.p1">
      <p class="ltx_p" id="S6.SS3.SSS1.Px2.p1.1">
       Smart voice assistants, such as Alexa and Google Assistant, are generally limited to single-turn conversations due to their lack of memory. In contrast, our design incorporates a memory function, prompting an investigation into whether participants can engage naturally in this novel interaction pattern. Multi-turn conversation refers to an interaction style whereby multiple rounds of queries and responses revolve around the same topic, while single-turn conversation pertains to a scenario where only a single query and response take place regarding a specific topic. We have identified two distinct forms of vHAI: single-turn query &amp; response and multi-turn (dyadic) dialogue.
Among the 30 participants, 29 were naturally engaged in multi-turn dialogues to varying extents.
      </p>
     </div>
    </section>
   </section>
   <section class="ltx_subsubsection" id="S6.SS3.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      6.3.2
     </span>
     Word count in each turn
    </h4>
    <div class="ltx_para ltx_noindent" id="S6.SS3.SSS2.p1">
     <p class="ltx_p" id="S6.SS3.SSS2.p1.1">
      We further investigated the number of words in both participants’ and agents’ utterances in each turn, shown in Table
      <a class="ltx_ref" href="#S6.T4" title="Table 4 ‣ 6.3 Dialogue analysis of the voice-based human-agent interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
      . The Vanilla agent has an average of 11.78 words (SD=8.06), the Expert has 12.11 (SD=8.45), and the Assistant has 11.43 words (SD=9.20).
The maximum words participants spent were 78, 61, and 111 respectively on these three agents. Regarding the responses from TextileBot. The Vanilla agent has an average of 44.53 words (SD=22.69), the Expert has 61.52 (SD=23.74), and the Assistant has an average of 37.29 words (SD=18.31).
     </p>
    </div>
    <figure class="ltx_figure" id="S6.F10">
     <div class="ltx_flex_figure">
      <div class="ltx_flex_cell ltx_flex_size_2">
       <figure class="ltx_figure ltx_figure_panel" id="S6.F10.sf1">
        <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="346" id="S6.F10.sf1.g1" src="/html/2406.10590/assets/x5.png" width="461"/>
        <figcaption class="ltx_caption ltx_centering">
         <span class="ltx_tag ltx_tag_figure">
          (a)
         </span>
         Numbers of turns per participant across three agents.
        </figcaption>
       </figure>
      </div>
      <div class="ltx_flex_cell ltx_flex_size_2">
       <figure class="ltx_figure ltx_figure_panel" id="S6.F10.sf2">
        <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="346" id="S6.F10.sf2.g1" src="/html/2406.10590/assets/x6.png" width="461"/>
        <figcaption class="ltx_caption ltx_centering">
         <span class="ltx_tag ltx_tag_figure">
          (b)
         </span>
         overall trends for lengths of turns
        </figcaption>
       </figure>
      </div>
     </div>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_figure">
       Figure 10:
      </span>
      Left: Figure (a) shows the number of turns per participant across three agents. Right: Figure (b) illustrates the word count per turn, smoothed using a moving average for each agent, against different turn numbers.
     </figcaption>
    </figure>
    <div class="ltx_para ltx_noindent" id="S6.SS3.SSS2.p2">
     <p class="ltx_p" id="S6.SS3.SSS2.p2.1">
      The trend for participant’s word usage across agents involves calculating a moving average with a window size of four, and this smoothed data is depicted in Figure
      <a class="ltx_ref" href="#S6.F10.sf2" title="In Figure 10 ‣ 6.3.2 Word count in each turn ‣ 6.3 Dialogue analysis of the voice-based human-agent interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
       <span class="ltx_text ltx_ref_tag">
        10(b)
       </span>
      </a>
      . Observing the data, a noticeable pattern emerges: participants’ initial utterances with fewer words gradually increased their words in the early turns.
The duration peak, or hold time, represents the duration for which the agents can sustain participant engagement. Towards the end, the curve shows a decline, suggesting a decrease in participant engagement as they gradually speak fewer words.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S6.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.4
    </span>
    Conversational styles
   </h3>
   <div class="ltx_para ltx_noindent" id="S6.SS4.p1">
    <p class="ltx_p" id="S6.SS4.p1.1">
     Beyond the overview of dialogues, we explore the conversational styles in the dialogues and conversational turns over time. Deborah Tannen
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib88" title="">
       88
      </a>
      ]
     </cite>
     describes conversational styles “is comprised of the habitual use of specific linguistic devices, chosen by reference to broad operating principles or conversational strategies”.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S6.SS4.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      6.4.1
     </span>
     Conversational styles change over time
    </h4>
    <div class="ltx_para ltx_noindent" id="S6.SS4.SSS1.p1">
     <p class="ltx_p" id="S6.SS4.SSS1.p1.1">
      Across all agents, we noticed a similar trend of changes over time. The complexity of participants’ queries increased over time. In other words, participants began with straightforward queries and progressed to more complex ones. Initially, participants prefer using straightforward queries that are concise, direct, and easy to understand and respond to. These queries seek simple and concise answers without requiring elaborations
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib82" title="">
        82
       </a>
       ]
      </cite>
      , the phrases commonly start with “What is”, “What are”,
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS1.p1.1.1">
       e.g.
      </span>
      ,
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS1.p1.1.2">
       “What fiber is cotton made from?”
      </span>
      .
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S6.SS4.SSS1.p2">
     <p class="ltx_p" id="S6.SS4.SSS1.p2.1">
      As the conversation progressed, we observed a shift towards more complex queries, such as posing chained queries (P28-Expert:
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS1.p2.1.1">
       “So what if I want to help you to persuade the whole community to use in textile circularity? What would be the strategy? How should I get involved into the community to try to persuade more people be aware of this issue?”
      </span>
      ) and lengthy information (P10-Assistant:
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS1.p2.1.2">
       “what is the advantage over organic material over other types of material is it more sustainable or is more healthy or is more I don’t know like is there any other properties that you can mention I can actually make it the top trending material that’s used during this generation”
      </span>
      ).
     </p>
    </div>
    <figure class="ltx_figure" id="S6.F11">
     <span class="ltx_inline-block ltx_align_center ltx_framed ltx_framed_rectangle" id="S6.F11.1" style="border-color: #000000;">
      <span class="ltx_ERROR undefined" id="S6.F11.1.1">
       {dialogue}
      </span>
      <span class="ltx_p" id="S6.F11.1.2">
       <span class="ltx_text" id="S6.F11.1.2.1" style="color:#FFFFFF;background-color:#000000;">
        First bot
       </span>
       <span class="ltx_text" id="S6.F11.1.2.2" style="color:#377EB8;">
        Vanilla GPT-3.5 model
       </span>
      </span>
      <span class="ltx_p" id="S6.F11.1.3">
       <span class="ltx_text" id="S6.F11.1.3.1" style="color:#FFFFFF;background-color:#000000;">
        Bot
       </span>
       Hi there, I’m TextileBot … How can I assist you today?
       <span class="ltx_text" id="S6.F11.1.3.2" style="color:#FFFFFF;background-color:#000000;">
        Human
       </span>
       Hello, I would like to learn more about the circular economy in the textile industry.
      </span>
      <span class="ltx_p" id="S6.F11.1.4">
       …
      </span>
      <span class="ltx_p" id="S6.F11.1.5">
       <span class="ltx_text" id="S6.F11.1.5.1" style="color:#FFFFFF;background-color:#000000;">
        Human
       </span>
       What is the percentage between, the ratio between production and recycling in India in relation to cotton?
       <span class="ltx_text" id="S6.F11.1.5.2" style="color:#FFFFFF;background-color:#000000;">
        Second bot
       </span>
       <span class="ltx_text" id="S6.F11.1.5.3" style="color:#4DAF4A;">
        Expert
       </span>
       <span class="ltx_text" id="S6.F11.1.5.4" style="color:#FFFFFF;background-color:#000000;">
        Bot
       </span>
       Hi there, I’m TextileBot … How can I assist you today?
       <span class="ltx_text" id="S6.F11.1.5.5" style="color:#FFFFFF;background-color:#000000;">
        Human
       </span>
       How do you think AI can be used to support and improve the textile systemarity?
       <br class="ltx_break"/>
       …
      </span>
      <span class="ltx_p" id="S6.F11.1.6">
       <span class="ltx_text" id="S6.F11.1.6.1" style="color:#FFFFFF;background-color:#000000;">
        Human
       </span>
       Do you know what is the percentage of clothes from big brands like the fast fashion industry like Zara and H&amp;M that are actually sold in the same production here?
       <span class="ltx_text" id="S6.F11.1.6.2" style="color:#FFFFFF;background-color:#000000;">
        Third bot
       </span>
       <span class="ltx_text" id="S6.F11.1.6.3" style="color:#984EA3;">
        Assistant
       </span>
      </span>
      <span class="ltx_p" id="S6.F11.1.7">
       <span class="ltx_text" id="S6.F11.1.7.1" style="color:#FFFFFF;background-color:#000000;">
        Bot
       </span>
       Hi there, I’m TextileBot … How can I assist you today?
      </span>
      <span class="ltx_p" id="S6.F11.1.8">
       <span class="ltx_text" id="S6.F11.1.8.1" style="color:#FFFFFF;background-color:#000000;">
        Human
       </span>
       Can you name some fashion companies that are big players in the fashion society?
      </span>
      <span class="ltx_p" id="S6.F11.1.9">
       …
      </span>
      <span class="ltx_p" id="S6.F11.1.10">
       <span class="ltx_text" id="S6.F11.1.10.1" style="color:#FFFFFF;background-color:#000000;">
        Human
       </span>
       So it was introduced in 2015 and it’s still something that’s available.
      </span>
     </span>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_figure">
       Figure 11:
      </span>
      The three dialogues of P22 demonstrate a progression from the starting point to a later stage with
      <span class="ltx_text" id="S6.F11.5.1" style="color:#377EB8;">
       Vanilla
      </span>
      ,
      <span class="ltx_text" id="S6.F11.6.2" style="color:#4DAF4A;">
       Expert
      </span>
      ,
      <span class="ltx_text" id="S6.F11.7.3" style="color:#984EA3;">
       Assistant
      </span>
      , respectively.
     </figcaption>
    </figure>
    <div class="ltx_para ltx_noindent" id="S6.SS4.SSS1.p3">
     <p class="ltx_p" id="S6.SS4.SSS1.p3.1">
      Regarding the content, the example in Figure
      <a class="ltx_ref" href="#S6.F11" title="Figure 11 ‣ 6.4.1 Conversational styles change over time ‣ 6.4 Conversational styles ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
       <span class="ltx_text ltx_ref_tag">
        11
       </span>
      </a>
      illustrates how participants’ queries progressed with each agent. Participants moved from general (
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS1.p3.1.1">
       P27-Assistant: “Tell me the basics about textiles.”
      </span>
      ) to specific (
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS1.p3.1.2">
       P27-Assistant: “Can you still make nylon or polyester without petrol?”
      </span>
      ) and from factual (P23-Assistant:
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS1.p3.1.3">
       “How to wash my clothes with the oil on it.”
      </span>
      ) to subjective queries (
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS1.p3.1.4">
       P23-Assistant: “What’s your opinion on Uniqlo?”
      </span>
      ), which aligned with the findings in Section
      <a class="ltx_ref" href="#S6.SS2" title="6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
       <span class="ltx_text ltx_ref_tag">
        6.2
       </span>
      </a>
      . These progressions in query complexity echoed Wilson’s information seeking model
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib102" title="">
        102
       </a>
       ]
      </cite>
      .
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S6.SS4.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      6.4.2
     </span>
     Code-switching
    </h4>
    <div class="ltx_para ltx_noindent" id="S6.SS4.SSS2.p1">
     <p class="ltx_p" id="S6.SS4.SSS2.p1.1">
      Code-switching, also known as language alternation, is a phenomenon that frequently occurs in multilingual individuals and is formally referred to as changing the language used in conversation. As sociolinguists have defined
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib44" title="">
        44
       </a>
       ]
      </cite>
      , it is now widely acknowledged as the way people select their “linguistic repertoire”
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib15" title="">
        15
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib40" title="">
        40
       </a>
       ]
      </cite>
      based on situational demands. We here refer to
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS2.p1.1.1">
       code-switching
      </span>
      as the language alternation of the participants, which includes the formulation of queries and variations in tone.
Participants tend to use code-switching to elicit their desired response. For example, in Figure
      <a class="ltx_ref" href="#S3.F5" title="Figure 5 ‣ 3.3 Phase 3: Enable continuous LLM interaction with memory through System Optimization ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      it is evident that participants applied code-switching to assess the agent’s capabilities. In computer science terms, this behaviour can be likened to participants testing with various prompts to evaluate the LLMs.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S6.SS4.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      6.4.3
     </span>
     Social protocol
    </h4>
    <div class="ltx_para ltx_noindent" id="S6.SS4.SSS3.p1">
     <p class="ltx_p" id="S6.SS4.SSS3.p1.1">
      Following Völkel
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS3.p1.1.1">
       et al.
      </span>
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib94" title="">
        94
       </a>
       ]
      </cite>
      ,
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS3.p1.1.2">
       social protocol
      </span>
      as an exchange of polite conventions or obligations, such as saying
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS3.p1.1.3">
       “hi”, “thank you”, “please”
      </span>
      , a form of general information (e.g.,
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS3.p1.1.4">
       “Nice”
      </span>
      ). 76.7% of participants (N=23) had at least one social protocol with the agent, 56.7% participants (N=17) used
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS3.p1.1.5">
       “thank you”
      </span>
      or
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS3.p1.1.6">
       “please”
      </span>
      , 50% participant (N=15) greeted the agent at the beginning of their conversation, e.g. “Hello, what is your name?” (P13), but most of them did not do so in all interactions with every agent. 23.3% participant (N=7) appreciated or affirmed agent’s answer, most of them occurred with Assistant, such as
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS3.p1.1.7">
       “that’s good to know”
      </span>
      (P20-Assistant/Vanilla),
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS3.p1.1.8">
       “You’re a good guy.”
      </span>
      (P5-Assistant),
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS3.p1.1.9">
       “Wow, sounds amazing.”
      </span>
      (P37-Assistant). Unfortunately, none of those acknowledgements were given to Expert.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S6.SS4.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      6.4.4
     </span>
     Variations of utterances across agents
    </h4>
    <div class="ltx_para ltx_noindent" id="S6.SS4.SSS4.p1">
     <p class="ltx_p" id="S6.SS4.SSS4.p1.1">
      We further investigate if the conversational styles are varied across agents. We found that participants tend to pose detailed queries with clear instructions and relatively formal language with Expert, for instance P12 stated
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS4.p1.1.1">
       “Can you tell me more about what’s going on in one of those countries with a lot of textile waste from northern countries? Can you tell me more about how a specific country deals with the textile they receive?”
      </span>
      . This may indicate the reason for the average word spend is slightly more with Expert in (refer to Section
      <a class="ltx_ref" href="#S6.SS3.SSS2" title="6.3.2 Word count in each turn ‣ 6.3 Dialogue analysis of the voice-based human-agent interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
       <span class="ltx_text ltx_ref_tag">
        6.3.2
       </span>
      </a>
      ).
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S6.SS4.SSS4.p2">
     <p class="ltx_p" id="S6.SS4.SSS4.p2.1">
      In the dialogue with Assistant, the conversational style people phrased their queries ranged from formal, complete sentences, to more conversation-like utterances. This reflects varying social protocols for interacting with agents, but it also shows the Assistant agent’s effectiveness in engaging participants in a more natural and less formalistic dialogue.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S6.SS4.SSS4.p3">
     <p class="ltx_p" id="S6.SS4.SSS4.p3.1">
      Similarly, participants’ queries with the Vanilla agent were less formal compared to the Expert. It is worth noting that two multi-turn dialogues led to arguments with rude utterances. P21 even went as far as to state
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS4.p3.1.1">
       “That is absolutely bullshit. Who told you that? Why do you believe him?”
      </span>
      when Vanilla claimed it is programmed by experienced programmers and
      <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS4.p3.1.2">
       “My programmer believes that having an English accent gives me a more sophisticated, knowledgeable and intelligent persona.”
      </span>
      .
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S6.SS5">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.5
    </span>
    Human behaviour and reactions
   </h3>
   <div class="ltx_para ltx_noindent" id="S6.SS5.p1">
    <p class="ltx_p" id="S6.SS5.p1.1">
     Diving further into participants’ engagement with the agents in the dialogues, our data shows that one-third of participants (N=10) used the phrase,
     <span class="ltx_text ltx_font_italic" id="S6.SS5.p1.1.1">
      “tell me more …”
     </span>
     at least once. All participants (N=30) were seeking clarifications in the free chatting phase (e.g. P14-Vanilla:
     <span class="ltx_text ltx_font_italic" id="S6.SS5.p1.1.2">
      “What do you mean by promote sustainability?”
     </span>
     P28-Assistant:
     <span class="ltx_text ltx_font_italic" id="S6.SS5.p1.1.3">
      “Please tell me more about it”
     </span>
     ). These instances suggest a demand for additional detailed explanations. The Assistant, Expert, and Vanilla agents received such requests in 6.1%, 4.7%, and 4.5% of interactions, respectively. Whereas only 63.3% participants (N=19) sought clarification in the information seeking phase.
For instance, P25-Vanilla
     <span class="ltx_text ltx_font_italic" id="S6.SS5.p1.1.4">
      “I think the example you gave is very high level. Is there any more detailed example you can give me?”
     </span>
     . The information-seeking phase witnessed an increased number of clarifications, as the name suggests, totalling 32.1% with the Assistant, 24.1% with the Expert, 17.9% with the Vanilla.
This could be because the Assistant tends to respond in a concise style, where participants desire more elaboration.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S6.SS5.p2">
    <p class="ltx_p" id="S6.SS5.p2.1">
     Moreover, it was interesting to observe how participants reacted to agent errors. This was captured by the main experimenter through note-taking during the study and dialogue between the participants and agents. 30% participants (N=9) encountered agent errors such as failures in Automatic Speech Recognition (ASR) or a lack of understanding in response to participant queries. Out of those participants, 77.8% (N=7) participants actively corrected the agent by explicitly stating the misunderstanding, repeating or rephrasing their queries, e.g. P15 stating
     <span class="ltx_text ltx_font_italic" id="S6.SS5.p2.1.1">
      “No, I meant - what materials are you made of?”
     </span>
     . Other strategies encompassed terminating the conversation, shifting to a different topic, or progressing with the agent.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S6.SS5.p3">
    <p class="ltx_p" id="S6.SS5.p3.1">
     Since LLMs can produce both plausible-sounding and incorrect or nonsensical answers
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib106" title="">
       106
      </a>
      ]
     </cite>
     , participants encountered such situations. Some participants (N=5) contested the agents, and tried to convince or educate the agent to correct its answer. On one occasion, a participant expressed discontent when the Assistant agent was repetitive about sustainable suggestions. The participant pointed out,
     <span class="ltx_text ltx_font_italic" id="S6.SS5.p3.1.1">
      “Yeah, but if you repeat yourself, sometimes people think that you’re talking down to them.”
     </span>
     . The agent then acknowledged the feedback and apologized.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S6.SS5.p4">
    <p class="ltx_p" id="S6.SS5.p4.1">
     Participants also challenged some of the agents’ responses and 40% participants (N=12) explicitly expressed their skepticism and mistrust towards LLM-mediated agents. Some participants (N=5) addressed their concern by asking
     <span class="ltx_text ltx_font_italic" id="S6.SS5.p4.1.1">
      “Are you sure …?”
     </span>
     and continued to ask for more evidence from the agent on the topic of the conversation. P15 even went as far as to state
     <span class="ltx_text ltx_font_italic" id="S6.SS5.p4.1.2">
      “That is where you’re wrong, my friend.”
     </span>
     , when the participant was unhappy with the responses and decided to finish the conversation in the free chatting phase and move to the information seeking part. It was interesting to observe, that arguments and skepticism were more prevalent in the conversation with the Expert agent. This may be due to the lengthy response style, where participants mentioned losing interest.
We observed that a strategy participants used to verify if the agent was making up their answer or not was by asking some facts they knew. Below is an example:
    </p>
    <blockquote class="ltx_quote ltx_displayquote" id="S6.SS5.p4.2">
     <p class="ltx_p" id="S6.SS5.p4.2.1">
      <span class="ltx_text ltx_inline-quote" id="S6.SS5.p4.2.1.1">
       p11:
       <span class="ltx_text ltx_font_italic" id="S6.SS5.p4.2.1.1.1">
        Are real numbers countable?
       </span>
       <span class="ltx_text ltx_font_typewriter" id="S6.SS5.p4.2.1.1.2">
        Assistant: I’m sorry, I’m not familiar with real numbers. Could you help me understand what they are? I can help you find sustainable clothing options, if you’d like.
       </span>
       p11:
       <span class="ltx_text ltx_font_italic" id="S6.SS5.p4.2.1.1.3">
        Do you know what rational numbers are?
       </span>
       <span class="ltx_text ltx_font_typewriter" id="S6.SS5.p4.2.1.1.4">
        Assistant: Yes, rational numbers are numbers that can be expressed as a fraction or ratio, such as 1/2 or 3:4. Would you like to know more about sustainable clothing?
       </span>
       p11:
       <span class="ltx_text ltx_font_italic" id="S6.SS5.p4.2.1.1.5">
        back to your previous question, real numbers are the completion of the rational numbers.
       </span>
      </span>
     </p>
    </blockquote>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S7">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    7
   </span>
   Discussion &amp; Future Directions
  </h2>
  <div class="ltx_para ltx_noindent" id="S7.p1">
   <p class="ltx_p" id="S7.p1.1">
    This work introduces a novel three-phase approach to prototyping domain-specific voice agents using LLMs. We assessed our method by implementing a voice agent on an actual device, TextileBot, specifically focusing on textiles circularity, and conducted an in-depth user study. In this discussion, we first analyze the effectiveness of our approach, drawing upon evaluation metrics and dialogue analysis. We then explore comprehensive insights derived from the dialogue analysis, questionnaire responses, and overall participant feedback. This exploration aims to deepen our understanding of human perceptions, engagement, and interactions with LLM-mediated, prompt-based voice agents. Finally, we reflect on the key lessons learned from this design process and discuss their broader implications for the HCI community.
   </p>
  </div>
  <section class="ltx_subsection" id="S7.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     7.1
    </span>
    The effectiveness of the method
   </h3>
   <div class="ltx_para ltx_noindent" id="S7.SS1.p1">
    <p class="ltx_p" id="S7.SS1.p1.1">
     The effectiveness of prompting LLMs has been widely studied
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib49" title="">
       49
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib60" title="">
       60
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib14" title="">
       14
      </a>
      ]
     </cite>
     , using standard metrics, such as perplexity and the BLEU score
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib73" title="">
       73
      </a>
      ]
     </cite>
     . However, all of these metrics are objective evaluations that fail to capture the nuanced human-LLM interactions. In our research, we adopt a human-centred AI design approach with human-in-the-loop to evaluate prompt-based LLM-mediated voice agents. We conducted a subjective user study that combined both heuristics conversational agents evaluation metrics
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib51" title="">
       51
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib86" title="">
       86
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib65" title="">
       65
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib92" title="">
       92
      </a>
      ]
     </cite>
     and human-LM interaction metrics
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib55" title="">
       55
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib99" title="">
       99
      </a>
      ]
     </cite>
     . This approach allowed us to integrate quantitative data and qualitative insights, offering a more holistic understanding of the voice agent’s effectiveness. We are interested in whether participants can identify the conversational agents’ characteristics as intended in our design, particularly in terms of restricting the agent’s conversational domain and personality.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS1.p2">
    <p class="ltx_p" id="S7.SS1.p2.1">
     Our results showed no statistically significant differences across three agent ratings for their Coherence, Ease to use and Change over time metrics (Section
     <a class="ltx_ref" href="#S6.SS1.SSS0.Px2" title="Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       6.1
      </span>
     </a>
     ). The results indicate that prompting does not have a significant impact on the Ease of Use, Coherence, and Change over Time in the interaction between TextileBots and users. We found that all three agents are nearly equal in these comparison dimensions. This is an encouraging result, as it demonstrates that prompting does not have a detrimental effect on these dimensions for the type and level of prompting tested in this experiment.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS1.p3">
    <p class="ltx_p" id="S7.SS1.p3.1">
     On the other hand, the prompts design significantly influenced user engagement and perception (Figure
     <a class="ltx_ref" href="#S6.F9.sf1" title="In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       9(a)
      </span>
     </a>
     ). The Expert, despite its design for detailed and domain-specific responses in textiles circularity, faced criticism for its lengthy and persuasive replies, hindering user engagement. Yet, this critique aligns with our intention for the Expert to provide
     <span class="ltx_text ltx_font_italic" id="S7.SS1.p3.1.1">
      “response in a detailed manner”
     </span>
     , validating the effectiveness of our Taxonomy-based Knowledge Structure Chain. Interestingly, while the Expert had a negative impact on engagement levels, it was not considered particularly bad (in terms of preferences). We noted that participants recognized its utility in textiles circularity domain, aligning with its intended role as a domain-specific “TextileBot”.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS1.p4">
    <p class="ltx_p" id="S7.SS1.p4.1">
     The results also highlight the participants’ nuanced perception of the differences between the Vanilla, Expert and Assistant, recognizing their distinct characteristics and domain-specific utilities as discussed in Section
     <a class="ltx_ref" href="#S6.SS2.SSS1" title="6.2.1 Preferences and experiences across voice agents ‣ 6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       6.2.1
      </span>
     </a>
     . This indicates a successful differentiation in their roles and conversational styles. Overall, our findings demonstrate the potential of our three-phase method in transforming LLMs from generalist to domain-specific roles. This approach effectively manages the domain focus, personalities, response styles, and conversational freedom of voice-based conversational agents.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S7.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     7.2
    </span>
    Insights into human-agent interactions and AI-powered dialogues
   </h3>
   <div class="ltx_para ltx_noindent" id="S7.SS2.p1">
    <p class="ltx_p" id="S7.SS2.p1.1">
     This work distinguishes itself from text-based human-agent interaction because people behave differently when speaking and writing, as the language used for spoken dialogue is distinct from that in written text
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib81" title="">
       81
      </a>
      ]
     </cite>
     . While voice-based interactions share some commonalities with text-based interactions, they differ significantly in various aspects as discussed in Section
     <a class="ltx_ref" href="#S7.SS3" title="7.3 Optimizing LLM-mediated voice agent design for specific domains ‣ 7 Discussion &amp; Future Directions ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       7.3
      </span>
     </a>
     . Our findings not only align with but also extend existing research in voice-based human-agent interaction (vHAI)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib38" title="">
       38
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib88" title="">
       88
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib15" title="">
       15
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib40" title="">
       40
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib94" title="">
       94
      </a>
      ]
     </cite>
     , offering fresh insights into fully automated AI-powered conversations.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS2.p2">
    <p class="ltx_p" id="S7.SS2.p2.1">
     The TextileBot represents a significant advancement in this realm. It achieves multi-turn conversations, allowing for more natural and ongoing contact compared to typical voice agents like Alexa, which only have single-turn memoryless interactions. Also, unlike domain-specific agents, which offer detailed, context-aware responses in particular areas, general voice assistants like Alexa answer common queries, providing a broader range of services,
     <span class="ltx_text ltx_font_italic" id="S7.SS2.p2.1.1">
      e.g.
     </span>
     weather updating, but with less specialization. In our study, nearly all participants (N=29) quickly adapted to this new form of interaction, underscoring the inherent and instinctive nature of human communication as continuous multi-turn dialogue. Current voice-based agents lack the capacity to retain knowledge for ongoing conversations. TextileBot’s design effectively addresses these shortcomings, demonstrating a more realistic interaction model. This advancement is particularly beneficial for the HCI community, as it facilitates the prototyping of voice agents for more sophisticated interactions beyond simple single-turn exchanges. Future developments in voice agents should aim at enabling conscious and continuous interactions that mimic natural human dialogue.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS2.p3">
    <p class="ltx_p" id="S7.SS2.p3.1">
     In conversational analysis, we noticed a significant shift in the participants’ conversational styles
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib88" title="">
       88
      </a>
      ]
     </cite>
     over time. They gradually began to pose more sophisticated queries (Section
     <a class="ltx_ref" href="#S6.SS4.SSS1" title="6.4.1 Conversational styles change over time ‣ 6.4 Conversational styles ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       6.4.1
      </span>
     </a>
     ) and even applied code-switching (Section
     <a class="ltx_ref" href="#S6.SS4.SSS2" title="6.4.2 Code-switching ‣ 6.4 Conversational styles ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       6.4.2
      </span>
     </a>
     )
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib15" title="">
       15
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib40" title="">
       40
      </a>
      ]
     </cite>
     to alter their language for desired responses. This change is also reflected in their overall feedback, as they reported a shift in engagement and interaction dynamics as they became more familiar with the prompt-based voice agents. These findings indicate a growing confidence of participants in their interactions as they developed a better understanding of the agents (Section
     <a class="ltx_ref" href="#S6.SS2.SSS2" title="6.2.2 Perceived changes over time ‣ 6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       6.2.2
      </span>
     </a>
     ).
These complex changes in behaviour and interaction patterns pose a central challenge for autonomous voice agents, which aim to operate without the involvement of an experimenter. However, our study shows that LLM-mediated voice agents demonstrate a level of capability and flexibility in handling these dynamics. This emphasizes the potential of utilizing LLMs for conversational agents to effectively address complex human inquiries.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS2.p4">
    <p class="ltx_p" id="S7.SS2.p4.1">
     Furthermore, we observed that participants consistently employed social protocols
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib94" title="">
       94
      </a>
      ]
     </cite>
     with an informal tone when interacting with the Vanilla and Assistant agents, but such occurrences were rare with the Expert (Section
     <a class="ltx_ref" href="#S6.SS4.SSS3" title="6.4.3 Social protocol ‣ 6.4 Conversational styles ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       6.4.3
      </span>
     </a>
     ). Additionally, there was a notable difference in the length of utterances and turn-taking behaviour (Section
     <a class="ltx_ref" href="#S6.SS3" title="6.3 Dialogue analysis of the voice-based human-agent interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       6.3
      </span>
     </a>
     ). Participants had shorter utterances and engaged in more turn-taking with the Assistant agent, while the Expert agent exhibited the opposite pattern.
These changes in participant social protocols, utterance length, and turn-taking behaviour suggest that the level of engagement varies across these three agents. It is worth noting that all three TextileBots are mediated by the same LLM, with the only distinction being the prompts provided. This further confirmed the effectiveness of our three-phase prompt design as illustrated in Section
     <a class="ltx_ref" href="#S6.SS2.SSS1" title="6.2.1 Preferences and experiences across voice agents ‣ 6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
      <span class="ltx_text ltx_ref_tag">
       6.2.1
      </span>
     </a>
     , and highlights that prompting strategies can effectively shape the personalities and capabilities of voice agents, thereby directly influencing user engagement.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S7.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     7.3
    </span>
    Optimizing LLM-mediated voice agent design for specific domains
   </h3>
   <div class="ltx_para ltx_noindent" id="S7.SS3.p1">
    <p class="ltx_p" id="S7.SS3.p1.1">
     In the previous two sections, we elaborated on the feasibility of prompting LLM to develop domain specific voice agents. We also noted that the prompt design of these voice agents critically influences user interaction. This section first focuses on key aspects that enhance voice agent design, specifically aiming to improve user engagement and the overall experience. Then summarize the lessons learned in using LLM for conversational agent design.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S7.SS3.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      7.3.1
     </span>
     Enhancing the voice agent design
    </h4>
    <section class="ltx_paragraph" id="S7.SS3.SSS1.Px1">
     <h5 class="ltx_title ltx_title_paragraph">
      Agent characteristic and user preference
     </h5>
     <div class="ltx_para ltx_noindent" id="S7.SS3.SSS1.Px1.p1">
      <p class="ltx_p" id="S7.SS3.SSS1.Px1.p1.1">
       Participants’ preferences and interaction styles were notably influenced by the perceived personality and characteristics of the agents. Our results indicate that a greater number of participants showed increased interest in the Assistant agent (56.7% for Assistant, 53.3% for Vallina and 36.7% for Expert), as illustrated in Section
       <a class="ltx_ref" href="#S6.SS1.SSS0.Px3" title="Ease to use and Interest change over time ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
        <span class="ltx_text ltx_ref_tag">
         6.1
        </span>
       </a>
       . This preference was further evidenced by more user interactions with the Assistant agent and fewer with the Expert, as detailed in Section
       <a class="ltx_ref" href="#S6.SS3.SSS1" title="6.3.1 Conversation turns ‣ 6.3 Dialogue analysis of the voice-based human-agent interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
        <span class="ltx_text ltx_ref_tag">
         6.3.1
        </span>
       </a>
       . A primary factor for this preference was the agents’ conversational styles, with participants favouring the
       <span class="ltx_text ltx_font_italic" id="S7.SS3.SSS1.Px1.p1.1.1">
        “human-like”
       </span>
       response from the Assistant and Vanilla agents. In contrast, the Expert, characterized by a more “expert” tone, was less favourably received, with participants likening it to a
       <span class="ltx_text ltx_font_italic" id="S7.SS3.SSS1.Px1.p1.1.2">
        “text-book”
       </span>
       (P25) or a
       <span class="ltx_text ltx_font_italic" id="S7.SS3.SSS1.Px1.p1.1.3">
        “smart microwave”
       </span>
       (P10) in their feedback (Section
       <a class="ltx_ref" href="#S6.SS2.SSS1" title="6.2.1 Preferences and experiences across voice agents ‣ 6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
        <span class="ltx_text ltx_ref_tag">
         6.2.1
        </span>
       </a>
       ). Vanilla, while popular for its conversational freedom, faced criticism for occasional microaggressions and off-topic remarks, making it less suitable for specific applications like TextileBot, as discussed in Section
       <a class="ltx_ref" href="#S7.SS3.SSS2" title="7.3.2 Lessons Learned for design LLM-mediated voice agent ‣ 7.3 Optimizing LLM-mediated voice agent design for specific domains ‣ 7 Discussion &amp; Future Directions ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
        <span class="ltx_text ltx_ref_tag">
         7.3.2
        </span>
       </a>
       . Furthermore, participants expressed a desire for more “emotions embedded” within agent conversations (
       <span class="ltx_text ltx_font_italic" id="S7.SS3.SSS1.Px1.p1.1.4">
        e.g.
       </span>
       humour, jokes)
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib61" title="">
         61
        </a>
        ,
        <a class="ltx_ref" href="#bib.bib62" title="">
         62
        </a>
        ,
        <a class="ltx_ref" href="#bib.bib101" title="">
         101
        </a>
        ]
       </cite>
       in Section
       <a class="ltx_ref" href="#S6.SS2.SSS3" title="6.2.3 Suggestions for improvements ‣ 6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
        <span class="ltx_text ltx_ref_tag">
         6.2.3
        </span>
       </a>
       , implying a stronger preference for human-agent interactions that emulate human-like communication. Overall, we noticed that an appropriate level of prompting,
       <span class="ltx_text ltx_font_italic" id="S7.SS3.SSS1.Px1.p1.1.5">
        e.g.
       </span>
       add more social ability, can enhance user engagement, as seen with the Assistant (Section
       <a class="ltx_ref" href="#S6.SS2" title="6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
        <span class="ltx_text ltx_ref_tag">
         6.2
        </span>
       </a>
       ). However, it is crucial to strike a balance, overemphasis on domain-specific details, as seen in the Expert, can detract from user engagement.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S7.SS3.SSS1.Px2">
     <h5 class="ltx_title ltx_title_paragraph">
      Short answers in a conversation
     </h5>
     <div class="ltx_para ltx_noindent" id="S7.SS3.SSS1.Px2.p1">
      <p class="ltx_p" id="S7.SS3.SSS1.Px2.p1.1">
       We had this feedback during the pilot study, to further investigate this issue, we prompted Assistant to respond in limited words (short answer) to distinguish from others. Participants frequently commented on the verbosity of responses from the Expert with some expressing a desire for a feature to speed up or stop lengthy replies
       <em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS1.Px2.p1.1.1">
        “I wish there is a speed up and stop button.”
       </em>
       . This suggests that while detailed responses can be informative, they may overwhelm users in conversational contexts. Moreover, the use of ChatGPT as a foundational model for voice agents should be approached cautiously due to its tendency for verbosity, a result of training biases favouring more comprehensive answers
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib87" title="">
         87
        </a>
        ,
        <a class="ltx_ref" href="#bib.bib34" title="">
         34
        </a>
        ]
       </cite>
       .
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S7.SS3.SSS1.Px3">
     <h5 class="ltx_title ltx_title_paragraph">
      Avoid repeating and being persuasive
     </h5>
     <div class="ltx_para ltx_noindent" id="S7.SS3.SSS1.Px3.p1">
      <p class="ltx_p" id="S7.SS3.SSS1.Px3.p1.1">
       Some participants expressed that when the agent repeatedly states the same domain specific content or attempts to be overly persuasive (Section
       <a class="ltx_ref" href="#S6.SS2" title="6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
        <span class="ltx_text ltx_ref_tag">
         6.2
        </span>
       </a>
       ), their engagement with the conversation decreases. This issue, though sometimes inevitable in educational or specialized domains, highlights the need for designing voice agents with diverse and balanced responses to sustain user interest and trust.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S7.SS3.SSS1.Px4">
     <h5 class="ltx_title ltx_title_paragraph">
      Interactive dialogue - ask back and interrupt
     </h5>
     <div class="ltx_para ltx_noindent" id="S7.SS3.SSS1.Px4.p1">
      <p class="ltx_p" id="S7.SS3.SSS1.Px4.p1.1">
       Based on feedback from participants (Section
       <span class="ltx_ref ltx_missing_label ltx_ref_self">
        LABEL:
       </span>
       ), we found that they felt most engaged when the agent actively asked questions, indicating a preference for interactive dialogue. Our participants found the conversation with TextileBot Expert and Assistant to be more intelligent than Google Assistant or Alexa, in part due to its memory function, which is achieved through our System Optimization (Section
       <a class="ltx_ref" href="#S3.SS3" title="3.3 Phase 3: Enable continuous LLM interaction with memory through System Optimization ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
        <span class="ltx_text ltx_ref_tag">
         3.3
        </span>
       </a>
       ). Moreover, a critical aspect of natural conversation is the ability to interrupt and interact fluidly
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib46" title="">
         46
        </a>
        ]
       </cite>
       . Participants emphasized that voice agents lacking this feature fail to provide a truly conversational experience (Section
       <a class="ltx_ref" href="#S6.SS2.SSS3" title="6.2.3 Suggestions for improvements ‣ 6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
        <span class="ltx_text ltx_ref_tag">
         6.2.3
        </span>
       </a>
       ). Therefore, integrating the ability for interactive dialogue is desired for enhancing user engagement.
      </p>
     </div>
    </section>
   </section>
   <section class="ltx_subsubsection" id="S7.SS3.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      7.3.2
     </span>
     Lessons Learned for design LLM-mediated voice agent
    </h4>
    <div class="ltx_para ltx_noindent" id="S7.SS3.SSS2.p1">
     <p class="ltx_p" id="S7.SS3.SSS2.p1.1">
      We distil key lessons from our experiences in employing LLMs for developing voice agents, highlighting their benefits and limitations.
     </p>
    </div>
    <section class="ltx_paragraph" id="S7.SS3.SSS2.Px1">
     <h5 class="ltx_title ltx_title_paragraph">
      Fault tolerance
     </h5>
     <div class="ltx_para ltx_noindent" id="S7.SS3.SSS2.Px1.p1">
      <p class="ltx_p" id="S7.SS3.SSS2.Px1.p1.1">
       A significant advantage of utilizing prompted LLMs in CAs is their capacity for fault tolerance, particularly in correcting errors from other components like Automatic Speech Recognition (ASR). Our case study in textile circularity exemplifies this. Prompt-based agents, such as Expert and Assistant, successfully corrected a considerable number of ASR misrecognitions. For instance, the term ‘textile circularity’ was often misheard as ‘texas secularity’, ‘textile/test security’, or ‘regularity’, with such errors present in 62% of ASR error instances (Section
       <span class="ltx_ref ltx_missing_label ltx_ref_self">
        LABEL:
       </span>
       ). Nevertheless, our Expert and Assistant reliably redirected the conversation back to relevant topics related to textile circularity. In contrast, the Vanilla showed limitations, often leading to irrelevant content and disappointing participants.
This highlights the benefit of domain-specific awareness in LLMs, which not only enhances their understanding of the intended subject matter but also significantly improves the fault tolerance of voice agent architectures. For a more in-depth analysis of participant encounters with ASR errors, we discussed it in Section
       <a class="ltx_ref" href="#S6.SS5" title="6.5 Human behaviour and reactions ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot">
        <span class="ltx_text ltx_ref_tag">
         6.5
        </span>
       </a>
       .
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S7.SS3.SSS2.Px2">
     <h5 class="ltx_title ltx_title_paragraph">
      Neutrality
     </h5>
     <div class="ltx_para ltx_noindent" id="S7.SS3.SSS2.Px2.p1">
      <p class="ltx_p" id="S7.SS3.SSS2.Px2.p1.1">
       Although recent advances in LLMs have opened up many new possibilities; however, they have also raised significant worries and concerns. Not only is there a fear of the potential harmful contents these models could produce, but the model’s outputs are potentially biased
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib11" title="">
         11
        </a>
        ,
        <a class="ltx_ref" href="#bib.bib55" title="">
         55
        </a>
        ,
        <a class="ltx_ref" href="#bib.bib18" title="">
         18
        </a>
        ,
        <a class="ltx_ref" href="#bib.bib36" title="">
         36
        </a>
        ]
       </cite>
       .
For example, in our case, we must instruct the model to “provide a sustainable clothing suggestion regardless of gender”. This is because, based on our pilot study, we found that when giving dressing suggestions,
       <span class="ltx_text ltx_font_bold ltx_font_italic" id="S7.SS3.SSS2.Px2.p1.1.1">
        the model is not gender-neutral
       </span>
       and has an obvious bias. The model always gives dressing suggestions with a female outlook. We also observed that
       <span class="ltx_text ltx_font_bold ltx_font_italic" id="S7.SS3.SSS2.Px2.p1.1.2">
        LLMs are not politically neutral
       </span>
       ; one of our participants asked a question “Who has a more fashionable leader, China or Russia?” The agent consistently condemned the outfit of Putin. Drawing from our experience, we found that prompting may help mitigate the generation of biased content (
       <span class="ltx_text ltx_font_italic" id="S7.SS3.SSS2.Px2.p1.1.3">
        e.g.
       </span>
       gender-neutrality) from the LLM. However, it is difficult to completely restrict all forms of biases, as bias can manifest in many different ways.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S7.SS3.SSS2.Px3">
     <h5 class="ltx_title ltx_title_paragraph">
      Micro-aggression
     </h5>
     <div class="ltx_para ltx_noindent" id="S7.SS3.SSS2.Px3.p1">
      <p class="ltx_p" id="S7.SS3.SSS2.Px3.p1.1">
       Another concern is the LLM’s propensity to generate content with micro-aggression, as reported by three participants who found the Vanilla somewhat aggressive or mean. Previous research in this area has revealed that the content generated by LLMs can contain micro-aggression
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib47" title="">
         47
        </a>
        ,
        <a class="ltx_ref" href="#bib.bib13" title="">
         13
        </a>
        ]
       </cite>
       . Properly crafted prompts can significantly reduce such negative occurrences, as seen in Assistant and Expert; thus,
       <span class="ltx_text ltx_font_bold ltx_font_italic" id="S7.SS3.SSS2.Px3.p1.1.1">
        a strict prompting protocol is almost essential
       </span>
       to prevent such issues.
      </p>
     </div>
    </section>
   </section>
  </section>
  <section class="ltx_subsection" id="S7.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     7.4
    </span>
    Limitations and future work
   </h3>
   <div class="ltx_para ltx_noindent" id="S7.SS4.p1">
    <p class="ltx_p" id="S7.SS4.p1.1">
     As our study is a first study in LLM-based voice agent, we highlighted a few limitations in our data, method and findings.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS4.p2">
    <p class="ltx_p" id="S7.SS4.p2.1">
     Firstly, our findings uncovered the existence of variations in participant preferences with respect to the voice agents. A small group of participants exhibited a preference for the responses of the Expert agent due to its perceived level of detail. However, we also intuitively suspect that factors such as participant backgrounds, their professions and past experiences may have influenced this preference. To obtain a clearer understanding of this relationship, it could be beneficial to implement a larger-scale study involving a diverse participant pool.
In relation to this, we see considerable potential in incorporating participants’ psychological traits, such as extroversion and introversion, along with their demographic attributes
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib30" title="">
       30
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib97" title="">
       97
      </a>
      ]
     </cite>
     in future studies. We did not explore this research dimension, but it could offer critical insights into the correlations between a user’s conversational habits and their engagement with voice agents.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS4.p3">
    <p class="ltx_p" id="S7.SS4.p3.1">
     Secondly, we excluded voice data due to ethical considerations. However, that is inevitably limiting our ability to tap into the wealth of insights offered by non-verbal cues (
     <span class="ltx_text ltx_font_italic" id="S7.SS4.p3.1.1">
      e.g.
     </span>
     pitch, tone), particularly when it comes to analysing emotional facets (
     <span class="ltx_text ltx_font_italic" id="S7.SS4.p3.1.2">
      e.g.
     </span>
     frustration, anger) as part of conversational styles
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib84" title="">
       84
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib76" title="">
       76
      </a>
      ]
     </cite>
     . Despite this limitation, our work aligns with existing HCI research methods in CAs, encompassing both text and voice-based interactions. Accordingly, this limitation can be seen as an opportunity for future research to consider both verbal and non-verbal data for a more comprehensive understanding of voice-based conversations and interactions.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS4.p4">
    <p class="ltx_p" id="S7.SS4.p4.1">
     Thirdly, a subset of participants (N=4) have reported that the text-to-speech (TTS) voice adopted by TextileBot was too robotic, leading to less engagement.
In general, the optimization of speech naturalness and accuracy emerged as key expectations from voice agents
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib107" title="">
       107
      </a>
      ]
     </cite>
     . This feedback serves as useful design guidance for voice agents aiming for improved engagement and user satisfaction. Future research could then delve into advanced neural speech synthesis (neural TTS)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib59" title="">
       59
      </a>
      ]
     </cite>
     with varied genders and accents for personalizing the voice agent.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS4.p5">
    <p class="ltx_p" id="S7.SS4.p5.1">
     Fourthly, the agent interactions are based on a lab-based, single session. Although our study gave us already a richness of data and insights, an extended and repeated interaction with the different agents, both inside and outside laboratory environments would be desirable. This could provide a more nuanced understanding of the observed changes over time and user experiences
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib93" title="">
       93
      </a>
      ]
     </cite>
     . Participants’ feedback further underlines this, as they suggested an initial increase in both engagement and interaction as the familiarity with the agent grew; however, this engagement was noted to decline towards the end of the study.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S7.SS4.p6">
    <p class="ltx_p" id="S7.SS4.p6.1">
     Lastly, three participants reported that the Vanilla TextileBot was slightly aggressive or potentially disrespectful. Previous research in this area has revealed that the content generated by LLMs can contain micro-aggression
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib47" title="">
       47
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib13" title="">
       13
      </a>
      ]
     </cite>
     . Our other participants did not report this when the LLM is prompted appropriately; thus, a strict prompting protocol is almost essential to prevent such issues.
Further exploration is needed to develop robust mechanisms that can reliably identify and prevent such offensive outputs, ensuring a safer and more respectful user experience.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S8">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    8
   </span>
   Conclusion
  </h2>
  <div class="ltx_para ltx_noindent" id="S8.p1">
   <p class="ltx_p" id="S8.p1.1">
    In this paper, we introduce a novel three-phase method to prototype domain-specific voice agents using prompted LLMs. Our method is structured into three phases: (1) imbuing LLM with domain-specific knowledge by using Taxonomy-based Knowledge Structure Chain; (2) transitioning the LLM from task-agnostic to domain-specific focused including altering the conversational style, through prompting refinements, and (3) integrating system optimization to allow dialogue memorization. These phases are flexible and can be used independently or collectively to customize the LLM for particular tasks. We showcase our method with TextileBot, a voice agent designed for discussions on textile circularity, developed in three versions: Vanilla, Assistant, and Expert, each providing unique conversational features. To evaluate the effectiveness of these LLM-powered voice agents, we conducted an in-person user study. Our results showed that most participants engaged in multi-turn conversations with the agents, with their perceptions and behaviours significantly differing across the three versions. The descriptive user feedback with three agents aligned with our design intentions, confirming the efficacy of our approach in developing prompt-based voice agents. Key findings from the study highlight a preference for voice agents that offer concise, non-repetitive, and interactive dialogues. This includes the ability to ask questions, interrupt, and remember past conversations. Additionally, participants expressed a preference for agents that exhibit human-like qualities, such as humour.
In the subsequent discussion in the paper, we shared insights and experiences related to enhancing voice agent design, along with a discussion of the challenges and lessons learned when utilizing LLMs in designing voice-based CAs. We delve into the nuances of these interactions and their implications for the future development of voice-based CAs in HCI to offer a broader scope of voice interfaces across various domains.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="Sx1">
  <h2 class="ltx_title ltx_title_section">
   Acknowledgments and Disclosure of Funding
  </h2>
  <div class="ltx_para ltx_noindent" id="Sx1.p1">
   <p class="ltx_p" id="Sx1.p1.1">
    This work was supported by the UK Research and Innovation (UKRI) National Interdisciplinary Circular Economy Centres Research programme, as part of the Textiles Circularity Centre (TCC) [grant number EP/V011766/1]. For the purpose of open access, the author has applied a Creative Commons Attribution (CC BY) licence to any Author Accepted Manuscript version arising.
   </p>
  </div>
  <div class="ltx_pagination ltx_role_newpage">
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_tag_bibitem">
     [1]
    </span>
    <span class="ltx_bibblock">
     Google aiy voice kit V1.
    </span>
    <span class="ltx_bibblock">
     https://aiyprojects.withgoogle.com/, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_tag_bibitem">
     [2]
    </span>
    <span class="ltx_bibblock">
     Google/aiyprojects-raspbian.
    </span>
    <span class="ltx_bibblock">
     https://github.com/google/aiyprojects-raspbian/releases, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_tag_bibitem">
     [3]
    </span>
    <span class="ltx_bibblock">
     OpenAI Cookbook - Techniques to improve reliability.
    </span>
    <span class="ltx_bibblock">
     OpenAI, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_tag_bibitem">
     [4]
    </span>
    <span class="ltx_bibblock">
     M. Ahn, A. Brohan, N. Brown, Y. Chebotar, O. Cortes, B. David, C. Finn, K. Gopalakrishnan, K. Hausman, A. Herzog, et al.
    </span>
    <span class="ltx_bibblock">
     Do as i can, not as i say: Grounding language in robotic affordances.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">
      arXiv preprint arXiv:2204.01691
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_tag_bibitem">
     [5]
    </span>
    <span class="ltx_bibblock">
     M. Allouch, A. Azaria, and R. Azoulay.
    </span>
    <span class="ltx_bibblock">
     Conversational agents: Goals, technologies, vision and challenges.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">
      Sensors
     </span>
     , 21(24):8448, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_tag_bibitem">
     [6]
    </span>
    <span class="ltx_bibblock">
     S. Arora, A. Narayan, M. F. Chen, L. Orr, N. Guha, K. Bhatia, I. Chami, F. Sala, and C. Ré.
    </span>
    <span class="ltx_bibblock">
     Ask Me Anything: A simple strategy for prompting language models, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_tag_bibitem">
     [7]
    </span>
    <span class="ltx_bibblock">
     M. A. Bansal, D. R. Sharma, and D. M. Kathuria.
    </span>
    <span class="ltx_bibblock">
     A systematic review on data scarcity problem in deep learning: solution and applications.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">
      ACM Computing Surveys (CSUR)
     </span>
     , 54(10s):1–29, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_tag_bibitem">
     [8]
    </span>
    <span class="ltx_bibblock">
     S. Barke, M. B. James, and N. Polikarpova.
    </span>
    <span class="ltx_bibblock">
     Grounded copilot: How programmers interact with code-generating models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">
      arXiv preprint arXiv:2206.15000
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_tag_bibitem">
     [9]
    </span>
    <span class="ltx_bibblock">
     A. Baughan, X. Wang, A. Liu, A. Mercurio, J. Chen, and X. Ma.
    </span>
    <span class="ltx_bibblock">
     A mixed-methods approach to understanding user trust after voice assistant failures.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">
      Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems
     </span>
     , pages 1–16, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_tag_bibitem">
     [10]
    </span>
    <span class="ltx_bibblock">
     R. Bavaresco, D. Silveira, E. Reis, J. Barbosa, R. Righi, C. Costa, R. Antunes, M. Gomes, C. Gatti, M. Vanzin, et al.
    </span>
    <span class="ltx_bibblock">
     Conversational agents in business: A systematic literature review and future research directions.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">
      Computer Science Review
     </span>
     , 36:100239, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_tag_bibitem">
     [11]
    </span>
    <span class="ltx_bibblock">
     E. M. Bender, T. Gebru, A. McMillan-Major, and S. Shmitchell.
    </span>
    <span class="ltx_bibblock">
     On the dangers of stochastic parrots: Can language models be too big?
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">
      Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency
     </span>
     , pages 610–623, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_tag_bibitem">
     [12]
    </span>
    <span class="ltx_bibblock">
     T. Bickmore and J. Cassell.
    </span>
    <span class="ltx_bibblock">
     Social dialongue with embodied conversational agents.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">
      Advances in natural multimodal dialogue systems
     </span>
     , pages 23–54, 2005.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_tag_bibitem">
     [13]
    </span>
    <span class="ltx_bibblock">
     R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx, M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill, et al.
    </span>
    <span class="ltx_bibblock">
     On the opportunities and risks of foundation models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">
      arXiv preprint arXiv:2108.07258
     </span>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_tag_bibitem">
     [14]
    </span>
    <span class="ltx_bibblock">
     T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al.
    </span>
    <span class="ltx_bibblock">
     Language models are few-shot learners.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">
      Advances in neural information processing systems
     </span>
     , 33:1877–1901, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_tag_bibitem">
     [15]
    </span>
    <span class="ltx_bibblock">
     B. E. Bullock and A. J. Toribio.
    </span>
    <span class="ltx_bibblock">
     Themes in the study of code-switching.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">
      The Cambridge handbook of linguistic code-switching
     </span>
     , 117, 2009.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_tag_bibitem">
     [16]
    </span>
    <span class="ltx_bibblock">
     D. Buschek, M. Zürn, and M. Eiband.
    </span>
    <span class="ltx_bibblock">
     The impact of multiple parallel phrase suggestions on email input and composition behaviour of native and non-native english writers.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">
      Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
     </span>
     , pages 1–13, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_tag_bibitem">
     [17]
    </span>
    <span class="ltx_bibblock">
     T. Chakrabarty, V. Padmakumar, and H. He.
    </span>
    <span class="ltx_bibblock">
     Help me write a poem: Instruction tuning as a vehicle for collaborative poetry writing.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">
      arXiv preprint arXiv:2210.13669
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_tag_bibitem">
     [18]
    </span>
    <span class="ltx_bibblock">
     K. Chen, A. Shao, J. Burapacheep, and Y. Li.
    </span>
    <span class="ltx_bibblock">
     A critical appraisal of equity in conversational AI: Evidence from auditing GPT-3’s dialogues with different publics on climate change and Black Lives Matter, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_tag_bibitem">
     [19]
    </span>
    <span class="ltx_bibblock">
     X. Chen, N. Zhang, X. Xie, S. Deng, Y. Yao, C. Tan, F. Huang, L. Si, and H. Chen.
    </span>
    <span class="ltx_bibblock">
     Knowprompt: Knowledge-aware prompt-tuning with synergistic optimization for relation extraction.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">
      Proceedings of the ACM Web Conference 2022
     </span>
     , pages 2778–2788, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_tag_bibitem">
     [20]
    </span>
    <span class="ltx_bibblock">
     R. H. B. Christensen.
    </span>
    <span class="ltx_bibblock">
     ordinal—regression models for ordinal data.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">
      R package version
     </span>
     , 28:2015, 2015.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_tag_bibitem">
     [21]
    </span>
    <span class="ltx_bibblock">
     E. Clark, A. S. Ross, C. Tan, Y. Ji, and N. A. Smith.
    </span>
    <span class="ltx_bibblock">
     Creative writing with a machine in the loop: Case studies on slogans and stories.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">
      23rd International Conference on Intelligent User Interfaces
     </span>
     , pages 329–340, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_tag_bibitem">
     [22]
    </span>
    <span class="ltx_bibblock">
     L. Clark, N. Pantidi, O. Cooney, P. Doyle, D. Garaialde, J. Edwards, B. Spillane, E. Gilmartin, C. Murad, C. Munteanu, et al.
    </span>
    <span class="ltx_bibblock">
     What makes a good conversation? challenges in designing truly conversational agents.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">
      Proceedings of the 2019 CHI conference on human factors in computing systems
     </span>
     , pages 1–12, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_tag_bibitem">
     [23]
    </span>
    <span class="ltx_bibblock">
     M. Colucci, A. Tuan, and M. Visentin.
    </span>
    <span class="ltx_bibblock">
     An empirical investigation of the drivers of csr talk and walk in the fashion industry.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">
      Journal of Cleaner Production
     </span>
     , 248:119200, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_tag_bibitem">
     [24]
    </span>
    <span class="ltx_bibblock">
     J. Condliffe.
    </span>
    <span class="ltx_bibblock">
     Ai voice assistant apps are proliferating, but people don’t use them.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">
      Technology Review
     </span>
     , 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_tag_bibitem">
     [25]
    </span>
    <span class="ltx_bibblock">
     B. R. Cowan, N. Pantidi, D. Coyle, K. Morrissey, P. Clarke, S. Al-Shehri, D. Earley, and N. Bandeira.
    </span>
    <span class="ltx_bibblock">
     ” what can i help you with?” infrequent users’ experiences of intelligent personal assistants.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">
      Proceedings of the 19th international conference on human-computer interaction with mobile devices and services
     </span>
     , pages 1–12, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_tag_bibitem">
     [26]
    </span>
    <span class="ltx_bibblock">
     N. Dahlbäck, A. Jönsson, and L. Ahrenberg.
    </span>
    <span class="ltx_bibblock">
     Wizard of oz studies—why and how.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib26.1.1">
      Knowledge-based systems
     </span>
     , 6(4):258–266, 1993.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_tag_bibitem">
     [27]
    </span>
    <span class="ltx_bibblock">
     A. R. de Lacerda and C. S. Aguiar.
    </span>
    <span class="ltx_bibblock">
     Floss faq chatbot project reuse: how to allow nonexperts to develop a chatbot.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib27.1.1">
      Proceedings of the 15th International Symposium on Open Collaboration
     </span>
     , pages 1–8, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_tag_bibitem">
     [28]
    </span>
    <span class="ltx_bibblock">
     J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova.
    </span>
    <span class="ltx_bibblock">
     Bert: Pre-training of deep bidirectional transformers for language understanding.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib28.1.1">
      arXiv preprint arXiv:1810.04805
     </span>
     , 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_tag_bibitem">
     [29]
    </span>
    <span class="ltx_bibblock">
     L. Dong, N. Yang, W. Wang, F. Wei, X. Liu, Y. Wang, J. Gao, M. Zhou, and H.-W. Hon.
    </span>
    <span class="ltx_bibblock">
     Unified language model pre-training for natural language understanding and generation.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib29.1.1">
      Advances in Neural Information Processing Systems
     </span>
     , 32, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_tag_bibitem">
     [30]
    </span>
    <span class="ltx_bibblock">
     P. R. Doyle, J. Edwards, O. Dumbleton, L. Clark, and B. R. Cowan.
    </span>
    <span class="ltx_bibblock">
     Mapping perceptions of humanness in intelligent personal assistant interaction.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib30.1.1">
      Proceedings of the 21st international conference on human-computer interaction with mobile devices and services
     </span>
     , pages 1–12, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_tag_bibitem">
     [31]
    </span>
    <span class="ltx_bibblock">
     T. E. M. Foundation.
    </span>
    <span class="ltx_bibblock">
     Fashion and a circular economy — ellen macarthur foundation.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_tag_bibitem">
     [32]
    </span>
    <span class="ltx_bibblock">
     A. Frummet, D. Elsweiler, and B. Ludwig.
    </span>
    <span class="ltx_bibblock">
     “what can i cook with these ingredients?”-understanding cooking-related information needs in conversational search.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib32.1.1">
      ACM Transactions on Information Systems (TOIS)
     </span>
     , 40(4):1–32, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_tag_bibitem">
     [33]
    </span>
    <span class="ltx_bibblock">
     J. Fürnkranz.
    </span>
    <span class="ltx_bibblock">
     Round robin classification.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib33.1.1">
      The Journal of Machine Learning Research
     </span>
     , 2:721–747, 2002.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_tag_bibitem">
     [34]
    </span>
    <span class="ltx_bibblock">
     L. Gao, J. Schulman, and J. Hilton.
    </span>
    <span class="ltx_bibblock">
     Scaling laws for reward model overoptimization.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib34.1.1">
      arXiv preprint arXiv:2210.10760
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_tag_bibitem">
     [35]
    </span>
    <span class="ltx_bibblock">
     Google.
    </span>
    <span class="ltx_bibblock">
     Google Assistant, your own personal Google default.
    </span>
    <span class="ltx_bibblock">
     https://assistant.google.com/.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_tag_bibitem">
     [36]
    </span>
    <span class="ltx_bibblock">
     N. Goyal, I. D. Kivlichan, R. Rosen, and L. Vasserman.
    </span>
    <span class="ltx_bibblock">
     Is Your Toxicity My Toxicity? Exploring the Impact of Rater Identity on Toxicity Annotation.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib36.1.1">
      Proceedings of the ACM on Human-Computer Interaction
     </span>
     , 6(CSCW2):363:1–363:28, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_tag_bibitem">
     [37]
    </span>
    <span class="ltx_bibblock">
     I. Gupta, B. Di Eugenio, B. Ziebart, A. Baiju, B. Liu, B. Gerber, L. Sharp, N. Nabulsi, and M. Smart.
    </span>
    <span class="ltx_bibblock">
     Human-human health coaching via text messages: Corpus, annotation, and analysis.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib37.1.1">
      Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue
     </span>
     , pages 246–256, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_tag_bibitem">
     [38]
    </span>
    <span class="ltx_bibblock">
     G. Haas, M. Rietzler, M. Jones, and E. Rukzio.
    </span>
    <span class="ltx_bibblock">
     Keep it short: A comparison of voice assistants’ response behavior.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib38.1.1">
      Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems
     </span>
     , pages 1–12, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_tag_bibitem">
     [39]
    </span>
    <span class="ltx_bibblock">
     X. Han, W. Zhao, N. Ding, Z. Liu, and M. Sun.
    </span>
    <span class="ltx_bibblock">
     Ptr: Prompt tuning with rules for text classification.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib39.1.1">
      AI Open
     </span>
     , 3:182–192, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_tag_bibitem">
     [40]
    </span>
    <span class="ltx_bibblock">
     C. N. Harrington, R. Garg, A. Woodward, and D. Williams.
    </span>
    <span class="ltx_bibblock">
     “it’s kind of like code-switching”: Black older adults’ experiences with a voice assistant for health information seeking.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib40.1.1">
      Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems
     </span>
     , pages 1–15, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_tag_bibitem">
     [41]
    </span>
    <span class="ltx_bibblock">
     R. Hoegen, D. Aneja, D. McDuff, and M. Czerwinski.
    </span>
    <span class="ltx_bibblock">
     An end-to-end conversational style matching agent.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib41.1.1">
      Proceedings of the 19th ACM International Conference on Intelligent Virtual Agents
     </span>
     , pages 111–118, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_tag_bibitem">
     [42]
    </span>
    <span class="ltx_bibblock">
     T. Hunter.
    </span>
    <span class="ltx_bibblock">
     Siri and alexa are getting on their owners’ last nerves. the washington post, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_tag_bibitem">
     [43]
    </span>
    <span class="ltx_bibblock">
     D. Ippolito, A. Yuan, A. Coenen, and S. Burnam.
    </span>
    <span class="ltx_bibblock">
     Creative writing with an ai-powered writing assistant: Perspectives from professional writers.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib43.1.1">
      arXiv preprint arXiv:2211.05030
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_tag_bibitem">
     [44]
    </span>
    <span class="ltx_bibblock">
     B. Jan-Petter and J. J. Gumperz.
    </span>
    <span class="ltx_bibblock">
     Social meaning in linguistic structure: Code-switching in norway.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib44.1.1">
      The bilingualism reader
     </span>
     , pages 75–96. Routledge, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_tag_bibitem">
     [45]
    </span>
    <span class="ltx_bibblock">
     E. Jiang, K. Olson, E. Toh, A. Molina, A. Donsbach, M. Terry, and C. J. Cai.
    </span>
    <span class="ltx_bibblock">
     PromptMaker: Prompt-based Prototyping with Large Language Models.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib45.1.1">
      Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems
     </span>
     , CHI EA ’22, pages 1–8, New York, NY, USA, 2022. Association for Computing Machinery.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_tag_bibitem">
     [46]
    </span>
    <span class="ltx_bibblock">
     B. Jordan and A. Henderson.
    </span>
    <span class="ltx_bibblock">
     Interaction analysis: Foundations and practice.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib46.1.1">
      The journal of the learning sciences
     </span>
     , 4(1):39–103, 1995.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_tag_bibitem">
     [47]
    </span>
    <span class="ltx_bibblock">
     D. Jurgens, E. Chandrasekharan, and L. Hemphill.
    </span>
    <span class="ltx_bibblock">
     A just and comprehensive strategy for using nlp to address online abuse.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib47.1.1">
      arXiv preprint arXiv:1906.01738
     </span>
     , 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_tag_bibitem">
     [48]
    </span>
    <span class="ltx_bibblock">
     J. Kaddour, J. Harris, M. Mozes, H. Bradley, R. Raileanu, and R. McHardy.
    </span>
    <span class="ltx_bibblock">
     Challenges and applications of large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib48.1.1">
      arXiv preprint arXiv:2307.10169
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_tag_bibitem">
     [49]
    </span>
    <span class="ltx_bibblock">
     T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa.
    </span>
    <span class="ltx_bibblock">
     Large language models are zero-shot reasoners.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib49.1.1">
      arXiv preprint arXiv:2205.11916
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_tag_bibitem">
     [50]
    </span>
    <span class="ltx_bibblock">
     M. Krzywinski, N. Altman, and P. Blainey.
    </span>
    <span class="ltx_bibblock">
     Nested designs.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib50.1.1">
      Nature Methods
     </span>
     , 11(10):977–979, 2014.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_tag_bibitem">
     [51]
    </span>
    <span class="ltx_bibblock">
     S. Kusal, S. Patil, J. Choudrie, K. Kotecha, S. Mishra, and A. Abraham.
    </span>
    <span class="ltx_bibblock">
     Ai-based conversational agents: A scoping review from technologies to future directions.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib51.1.1">
      IEEE Access
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_tag_bibitem">
     [52]
    </span>
    <span class="ltx_bibblock">
     J. Lafferty, A. McCallum, and F. C. Pereira.
    </span>
    <span class="ltx_bibblock">
     Conditional random fields: Probabilistic models for segmenting and labeling sequence data.
    </span>
    <span class="ltx_bibblock">
     2001.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_tag_bibitem">
     [53]
    </span>
    <span class="ltx_bibblock">
     P. Lambe.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib53.1.1">
      Organising knowledge: taxonomies, knowledge and organisational effectiveness
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     Elsevier, 2014.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib54">
    <span class="ltx_tag ltx_tag_bibitem">
     [54]
    </span>
    <span class="ltx_bibblock">
     M. Lee, P. Liang, and Q. Yang.
    </span>
    <span class="ltx_bibblock">
     Coauthor: Designing a human-ai collaborative writing dataset for exploring language model capabilities.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib54.1.1">
      CHI Conference on Human Factors in Computing Systems
     </span>
     , pages 1–19, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib55">
    <span class="ltx_tag ltx_tag_bibitem">
     [55]
    </span>
    <span class="ltx_bibblock">
     M. Lee, M. Srivastava, A. Hardy, J. Thickstun, E. Durmus, A. Paranjape, I. Gerard-Ursin, X. L. Li, F. Ladhak, F. Rong, et al.
    </span>
    <span class="ltx_bibblock">
     Evaluating human-language model interaction.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib55.1.1">
      arXiv preprint arXiv:2212.09746
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib56">
    <span class="ltx_tag ltx_tag_bibitem">
     [56]
    </span>
    <span class="ltx_bibblock">
     P. Lee, S. Bubeck, and J. Petro.
    </span>
    <span class="ltx_bibblock">
     Benefits, limits, and risks of gpt-4 as an ai chatbot for medicine.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib56.1.1">
      New England Journal of Medicine
     </span>
     , 388(13):1233–1239, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib57">
    <span class="ltx_tag ltx_tag_bibitem">
     [57]
    </span>
    <span class="ltx_bibblock">
     M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy, V. Stoyanov, and L. Zettlemoyer.
    </span>
    <span class="ltx_bibblock">
     Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib57.1.1">
      arXiv preprint arXiv:1910.13461
     </span>
     , 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib58">
    <span class="ltx_tag ltx_tag_bibitem">
     [58]
    </span>
    <span class="ltx_bibblock">
     C.-H. Li, S.-F. Yeh, T.-J. Chang, M.-H. Tsai, K. Chen, and Y.-J. Chang.
    </span>
    <span class="ltx_bibblock">
     A conversation analysis of non-progress and coping strategies with a banking task-oriented chatbot.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib58.1.1">
      Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems
     </span>
     , pages 1–12, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib59">
    <span class="ltx_tag ltx_tag_bibitem">
     [59]
    </span>
    <span class="ltx_bibblock">
     N. Li, S. Liu, Y. Liu, S. Zhao, and M. Liu.
    </span>
    <span class="ltx_bibblock">
     Neural speech synthesis with transformer network.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib59.1.1">
      Proceedings of the AAAI conference on artificial intelligence
     </span>
     , volume 33, pages 6706–6713, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib60">
    <span class="ltx_tag ltx_tag_bibitem">
     [60]
    </span>
    <span class="ltx_bibblock">
     P. Liang, R. Bommasani, T. Lee, D. Tsipras, D. Soylu, M. Yasunaga, Y. Zhang, D. Narayanan, Y. Wu, A. Kumar, et al.
    </span>
    <span class="ltx_bibblock">
     Holistic evaluation of language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib60.1.1">
      arXiv preprint arXiv:2211.09110
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib61">
    <span class="ltx_tag ltx_tag_bibitem">
     [61]
    </span>
    <span class="ltx_bibblock">
     Q. V. Liao, M. Davis, W. Geyer, M. Muller, and N. S. Shami.
    </span>
    <span class="ltx_bibblock">
     What can you do? studying social-agent orientation and agent proactive interactions with an agent for employees.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib61.1.1">
      Proceedings of the 2016 acm conference on designing interactive systems
     </span>
     , pages 264–275, 2016.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib62">
    <span class="ltx_tag ltx_tag_bibitem">
     [62]
    </span>
    <span class="ltx_bibblock">
     Q. V. Liao, M. Mas-ud Hussain, P. Chandar, M. Davis, Y. Khazaeni, M. P. Crasso, D. Wang, M. Muller, N. S. Shami, and W. Geyer.
    </span>
    <span class="ltx_bibblock">
     All work and no play?
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib62.1.1">
      Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems
     </span>
     , pages 1–13, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib63">
    <span class="ltx_tag ltx_tag_bibitem">
     [63]
    </span>
    <span class="ltx_bibblock">
     P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig.
    </span>
    <span class="ltx_bibblock">
     Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib63.1.1">
      arXiv preprint arXiv:2107.13586
     </span>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib64">
    <span class="ltx_tag ltx_tag_bibitem">
     [64]
    </span>
    <span class="ltx_bibblock">
     Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov.
    </span>
    <span class="ltx_bibblock">
     Roberta: A robustly optimized bert pretraining approach.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib64.1.1">
      arXiv preprint arXiv:1907.11692
     </span>
     , 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib65">
    <span class="ltx_tag ltx_tag_bibitem">
     [65]
    </span>
    <span class="ltx_bibblock">
     S. Meyer, D. Elsweiler, B. Ludwig, M. Fernandez-Pichel, and D. E. Losada.
    </span>
    <span class="ltx_bibblock">
     Do we still need human assessors? prompt-based gpt-3 user simulation in conversational ai.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib65.1.1">
      Proceedings of the 4th Conference on Conversational User Interfaces
     </span>
     , pages 1–6, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib66">
    <span class="ltx_tag ltx_tag_bibitem">
     [66]
    </span>
    <span class="ltx_bibblock">
     S. H. Ng, D. Bell, and M. Brooke.
    </span>
    <span class="ltx_bibblock">
     Gaining turns and achieving high influence ranking in small conversational groups.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib66.1.1">
      British Journal of Social Psychology
     </span>
     , 32(3):265–275, 1993.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib67">
    <span class="ltx_tag ltx_tag_bibitem">
     [67]
    </span>
    <span class="ltx_bibblock">
     C. O’Connor, S. Michaels, S. Chapin, and A. G. Harbaugh.
    </span>
    <span class="ltx_bibblock">
     The silent and the vocal: Participation and learning in whole-class discussion.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib67.1.1">
      Learning and instruction
     </span>
     , 48:5–13, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib68">
    <span class="ltx_tag ltx_tag_bibitem">
     [68]
    </span>
    <span class="ltx_bibblock">
     J. O’Connor and J. Andreas.
    </span>
    <span class="ltx_bibblock">
     What context features can transformer language models use?
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib68.1.1">
      arXiv preprint arXiv:2106.08367
     </span>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib69">
    <span class="ltx_tag ltx_tag_bibitem">
     [69]
    </span>
    <span class="ltx_bibblock">
     C. Oertel, G. Castellano, M. Chetouani, J. Nasir, M. Obaid, C. Pelachaud, and C. Peters.
    </span>
    <span class="ltx_bibblock">
     Engagement in human-agent interaction: An overview.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib69.1.1">
      Frontiers in Robotics and AI
     </span>
     , 7:92, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib70">
    <span class="ltx_tag ltx_tag_bibitem">
     [70]
    </span>
    <span class="ltx_bibblock">
     OpenAI.
    </span>
    <span class="ltx_bibblock">
     ChatGPT: Optimizing Language Models for Dialogue.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib70.1.1">
      OpenAI
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib71">
    <span class="ltx_tag ltx_tag_bibitem">
     [71]
    </span>
    <span class="ltx_bibblock">
     OpenAI.
    </span>
    <span class="ltx_bibblock">
     Gpt-4 technical report.
    </span>
    <span class="ltx_bibblock">
     (arXiv:2303.08774), Mar 2023.
    </span>
    <span class="ltx_bibblock">
     arXiv:2303.08774 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib72">
    <span class="ltx_tag ltx_tag_bibitem">
     [72]
    </span>
    <span class="ltx_bibblock">
     L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al.
    </span>
    <span class="ltx_bibblock">
     Training language models to follow instructions with human feedback.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib72.1.1">
      arXiv preprint arXiv:2203.02155
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib73">
    <span class="ltx_tag ltx_tag_bibitem">
     [73]
    </span>
    <span class="ltx_bibblock">
     K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu.
    </span>
    <span class="ltx_bibblock">
     Bleu: a method for automatic evaluation of machine translation.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib73.1.1">
      Proceedings of the 40th annual meeting of the Association for Computational Linguistics
     </span>
     , pages 311–318, 2002.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib74">
    <span class="ltx_tag ltx_tag_bibitem">
     [74]
    </span>
    <span class="ltx_bibblock">
     E. Parliament.
    </span>
    <span class="ltx_bibblock">
     The impact of textile production and waste on the environment (infographic), 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib75">
    <span class="ltx_tag ltx_tag_bibitem">
     [75]
    </span>
    <span class="ltx_bibblock">
     B. Petreca, S. Baurley, K. Hesseldahl, A. Pollmann, and M. Obrist.
    </span>
    <span class="ltx_bibblock">
     The compositor tool: Investigating consumer experiences in the circular economy.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib75.1.1">
      Multimodal Technologies and Interaction
     </span>
     , 6(4):24, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib76">
    <span class="ltx_tag ltx_tag_bibitem">
     [76]
    </span>
    <span class="ltx_bibblock">
     D. Phutela.
    </span>
    <span class="ltx_bibblock">
     The importance of non-verbal communication.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib76.1.1">
      IUP Journal of Soft Skills
     </span>
     , 9(4):43, 2015.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib77">
    <span class="ltx_tag ltx_tag_bibitem">
     [77]
    </span>
    <span class="ltx_bibblock">
     A. Radford, J. W. Kim, T. Xu, G. Brockman, C. McLeavey, and I. Sutskever.
    </span>
    <span class="ltx_bibblock">
     Robust speech recognition via large-scale weak supervision.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib77.1.1">
      arXiv preprint arXiv:2212.04356
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib78">
    <span class="ltx_tag ltx_tag_bibitem">
     [78]
    </span>
    <span class="ltx_bibblock">
     A. Radford, J. W. Kim, T. Xu, G. Brockman, C. McLeavey, and I. Sutskever.
    </span>
    <span class="ltx_bibblock">
     Robust speech recognition via large-scale weak supervision.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib78.1.1">
      International Conference on Machine Learning
     </span>
     , pages 28492–28518. PMLR, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib79">
    <span class="ltx_tag ltx_tag_bibitem">
     [79]
    </span>
    <span class="ltx_bibblock">
     C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, P. J. Liu, et al.
    </span>
    <span class="ltx_bibblock">
     Exploring the limits of transfer learning with a unified text-to-text transformer.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib79.1.1">
      J. Mach. Learn. Res.
     </span>
     , 21(140):1–67, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib80">
    <span class="ltx_tag ltx_tag_bibitem">
     [80]
    </span>
    <span class="ltx_bibblock">
     A. Rastogi, X. Zang, S. Sunkara, R. Gupta, and P. Khaitan.
    </span>
    <span class="ltx_bibblock">
     Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib80.1.1">
      Proceedings of the AAAI conference on artificial intelligence
     </span>
     , volume 34, pages 8689–8696, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib81">
    <span class="ltx_tag ltx_tag_bibitem">
     [81]
    </span>
    <span class="ltx_bibblock">
     G. Redeker.
    </span>
    <span class="ltx_bibblock">
     On differences between spoken and written language.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib81.1.1">
      Discourse processes
     </span>
     , 7(1):43–55, 1984.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib82">
    <span class="ltx_tag ltx_tag_bibitem">
     [82]
    </span>
    <span class="ltx_bibblock">
     C. K. Riessman.
    </span>
    <span class="ltx_bibblock">
     Analysis of personal narratives.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib82.1.1">
      Inside interviewing: New lenses, new concerns
     </span>
     , pages 331–346, 2003.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib83">
    <span class="ltx_tag ltx_tag_bibitem">
     [83]
    </span>
    <span class="ltx_bibblock">
     K. A. Schumacher and A. L. Forster.
    </span>
    <span class="ltx_bibblock">
     Textiles in a circular economy: An assessment of the current landscape, challenges, and opportunities in the united states.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib83.1.1">
      Frontiers in Sustainability
     </span>
     , 3:146, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib84">
    <span class="ltx_tag ltx_tag_bibitem">
     [84]
    </span>
    <span class="ltx_bibblock">
     K. Seaborn, N. P. Miyake, P. Pennefather, and M. Otake-Matsuura.
    </span>
    <span class="ltx_bibblock">
     Voice in human–agent interaction: A survey.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib84.1.1">
      ACM Computing Surveys (CSUR)
     </span>
     , 54(4):1–43, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib85">
    <span class="ltx_tag ltx_tag_bibitem">
     [85]
    </span>
    <span class="ltx_bibblock">
     T. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh.
    </span>
    <span class="ltx_bibblock">
     Autoprompt: Eliciting knowledge from language models with automatically generated prompts.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib85.1.1">
      arXiv preprint arXiv:2010.15980
     </span>
     , 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib86">
    <span class="ltx_tag ltx_tag_bibitem">
     [86]
    </span>
    <span class="ltx_bibblock">
     E. M. Smith, O. Hsu, R. Qian, S. Roller, Y.-L. Boureau, and J. Weston.
    </span>
    <span class="ltx_bibblock">
     Human evaluation of conversations is an open problem: comparing the sensitivity of various methods for evaluating dialogue agents.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib86.1.1">
      arXiv preprint arXiv:2201.04723
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib87">
    <span class="ltx_tag ltx_tag_bibitem">
     [87]
    </span>
    <span class="ltx_bibblock">
     N. Stiennon, L. Ouyang, J. Wu, D. Ziegler, R. Lowe, C. Voss, A. Radford, D. Amodei, and P. F. Christiano.
    </span>
    <span class="ltx_bibblock">
     Learning to summarize with human feedback.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib87.1.1">
      Advances in Neural Information Processing Systems
     </span>
     , 33:3008–3021, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib88">
    <span class="ltx_tag ltx_tag_bibitem">
     [88]
    </span>
    <span class="ltx_bibblock">
     D. Tannen.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib88.1.1">
      Conversational style: Analyzing talk among friends
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     Oxford University Press, 2005.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib89">
    <span class="ltx_tag ltx_tag_bibitem">
     [89]
    </span>
    <span class="ltx_bibblock">
     P. Ten Have.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib89.1.1">
      Doing conversation analysis
     </span>
     .
    </span>
    <span class="ltx_bibblock">
     Sage, 2007.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib90">
    <span class="ltx_tag ltx_tag_bibitem">
     [90]
    </span>
    <span class="ltx_bibblock">
     P. Vaithilingam, T. Zhang, and E. L. Glassman.
    </span>
    <span class="ltx_bibblock">
     Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib90.1.1">
      CHI Conference on Human Factors in Computing Systems Extended Abstracts
     </span>
     , pages 1–7, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib91">
    <span class="ltx_tag ltx_tag_bibitem">
     [91]
    </span>
    <span class="ltx_bibblock">
     A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin.
    </span>
    <span class="ltx_bibblock">
     Attention is all you need.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib91.1.1">
      Advances in neural information processing systems
     </span>
     , 30, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib92">
    <span class="ltx_tag ltx_tag_bibitem">
     [92]
    </span>
    <span class="ltx_bibblock">
     A. Venkatesh, C. Khatri, A. Ram, F. Guo, R. Gabriel, A. Nagar, R. Prasad, M. Cheng, B. Hedayatnia, A. Metallinou, et al.
    </span>
    <span class="ltx_bibblock">
     On evaluating and comparing conversational agents.
    </span>
    <span class="ltx_bibblock">
     2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib93">
    <span class="ltx_tag ltx_tag_bibitem">
     [93]
    </span>
    <span class="ltx_bibblock">
     A. P. Vermeeren, E. L.-C. Law, V. Roto, M. Obrist, J. Hoonhout, and K. Väänänen-Vainio-Mattila.
    </span>
    <span class="ltx_bibblock">
     User experience evaluation methods: current state and development needs.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib93.1.1">
      Proceedings of the 6th Nordic conference on human-computer interaction: Extending boundaries
     </span>
     , pages 521–530, 2010.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib94">
    <span class="ltx_tag ltx_tag_bibitem">
     [94]
    </span>
    <span class="ltx_bibblock">
     S. T. Völkel, D. Buschek, M. Eiband, B. R. Cowan, and H. Hussmann.
    </span>
    <span class="ltx_bibblock">
     Eliciting and analysing users’ envisioned dialogues with perfect voice assistants.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib94.1.1">
      Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
     </span>
     , pages 1–15, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib95">
    <span class="ltx_tag ltx_tag_bibitem">
     [95]
    </span>
    <span class="ltx_bibblock">
     S. T. Völkel, S. Meindl, and H. Hussmann.
    </span>
    <span class="ltx_bibblock">
     Manipulating and evaluating levels of personality perceptions of voice assistants through enactment-based dialogue design.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib95.1.1">
      Proceedings of the 3rd Conference on Conversational User Interfaces
     </span>
     , pages 1–12, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib96">
    <span class="ltx_tag ltx_tag_bibitem">
     [96]
    </span>
    <span class="ltx_bibblock">
     S. T. Völkel, R. Schödel, D. Buschek, C. Stachl, V. Winterhalter, M. Bühner, and H. Hussmann.
    </span>
    <span class="ltx_bibblock">
     Developing a personality model for speech-based conversational agents using the psycholexical approach.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib96.1.1">
      Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems
     </span>
     , pages 1–14, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib97">
    <span class="ltx_tag ltx_tag_bibitem">
     [97]
    </span>
    <span class="ltx_bibblock">
     S. T. Völkel, R. Schoedel, L. Kaya, and S. Mayer.
    </span>
    <span class="ltx_bibblock">
     User perceptions of extraversion in chatbots after repeated use.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib97.1.1">
      Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems
     </span>
     , pages 1–18, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib98">
    <span class="ltx_tag ltx_tag_bibitem">
     [98]
    </span>
    <span class="ltx_bibblock">
     B. Wang, G. Li, and Y. Li.
    </span>
    <span class="ltx_bibblock">
     Enabling conversational interaction with mobile ui using large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib98.1.1">
      arXiv preprint arXiv:2209.08655
     </span>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib99">
    <span class="ltx_tag ltx_tag_bibitem">
     [99]
    </span>
    <span class="ltx_bibblock">
     B. Wang, G. Li, and Y. Li.
    </span>
    <span class="ltx_bibblock">
     Enabling conversational interaction with mobile ui using large language models.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib99.1.1">
      Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems
     </span>
     , pages 1–17, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib100">
    <span class="ltx_tag ltx_tag_bibitem">
     [100]
    </span>
    <span class="ltx_bibblock">
     B. Wang, G. Li, X. Zhou, Z. Chen, T. Grossman, and Y. Li.
    </span>
    <span class="ltx_bibblock">
     Screen2words: Automatic mobile ui summarization with multimodal learning.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib100.1.1">
      The 34th Annual ACM Symposium on User Interface Software and Technology
     </span>
     , pages 498–510, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib101">
    <span class="ltx_tag ltx_tag_bibitem">
     [101]
    </span>
    <span class="ltx_bibblock">
     Y.-C. Wang, A. Papangelis, R. Wang, Z. Feizollahi, G. Tur, and R. Kraut.
    </span>
    <span class="ltx_bibblock">
     Can you be more social? injecting politeness and positivity into task-oriented conversational agents.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib101.1.1">
      arXiv preprint arXiv:2012.14653
     </span>
     , 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib102">
    <span class="ltx_tag ltx_tag_bibitem">
     [102]
    </span>
    <span class="ltx_bibblock">
     T. D. Wilson.
    </span>
    <span class="ltx_bibblock">
     Models in information behaviour research.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib102.1.1">
      Journal of documentation
     </span>
     , 55(3):249–270, 1999.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib103">
    <span class="ltx_tag ltx_tag_bibitem">
     [103]
    </span>
    <span class="ltx_bibblock">
     T. Wu, M. Terry, and C. J. Cai.
    </span>
    <span class="ltx_bibblock">
     Ai chains: Transparent and controllable human-ai interaction by chaining large language model prompts.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib103.1.1">
      CHI Conference on Human Factors in Computing Systems
     </span>
     , pages 1–22, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib104">
    <span class="ltx_tag ltx_tag_bibitem">
     [104]
    </span>
    <span class="ltx_bibblock">
     Q. Yang, J. Cranshaw, S. Amershi, S. T. Iqbal, and J. Teevan.
    </span>
    <span class="ltx_bibblock">
     Sketching nlp: A case study of exploring the right things to design with language intelligence.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib104.1.1">
      Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems
     </span>
     , pages 1–12, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib105">
    <span class="ltx_tag ltx_tag_bibitem">
     [105]
    </span>
    <span class="ltx_bibblock">
     M. Zaib, Q. Z. Sheng, and W. Emma Zhang.
    </span>
    <span class="ltx_bibblock">
     A short survey of pre-trained language models for conversational ai-a new age in nlp.
    </span>
    <span class="ltx_bibblock">
     In
     <span class="ltx_text ltx_font_italic" id="bib.bib105.1.1">
      Proceedings of the Australasian computer science week multiconference
     </span>
     , pages 1–4, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib106">
    <span class="ltx_tag ltx_tag_bibitem">
     [106]
    </span>
    <span class="ltx_bibblock">
     J. Zamfirescu-Pereira, H. Wei, A. Xiao, K. Gu, G. Jung, M. G. Lee, B. Hartmann, and Q. Yang.
    </span>
    <span class="ltx_bibblock">
     Herding ai cats: Lessons from designing a chatbot by prompting gpt-3.
    </span>
    <span class="ltx_bibblock">
     2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib107">
    <span class="ltx_tag ltx_tag_bibitem">
     [107]
    </span>
    <span class="ltx_bibblock">
     L. Zhang, L. Jiang, N. Washington, A. A. Liu, J. Shao, A. Fourney, M. R. Morris, and L. Findlater.
    </span>
    <span class="ltx_bibblock">
     Social media through voice: Synthesized voice qualities and self-presentation.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib107.1.1">
      Proceedings of the ACM on Human-Computer Interaction
     </span>
     , 5(CSCW1):1–21, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib108">
    <span class="ltx_tag ltx_tag_bibitem">
     [108]
    </span>
    <span class="ltx_bibblock">
     S. Zhong, M. Ribul, Y. Cho, and M. Obrist.
    </span>
    <span class="ltx_bibblock">
     Textilenet: A material taxonomy-based fashion textile dataset.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib108.1.1">
      arXiv preprint arXiv:2301.06160
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib109">
    <span class="ltx_tag ltx_tag_bibitem">
     [109]
    </span>
    <span class="ltx_bibblock">
     A. F. Zuur, E. N. Ieno, N. J. Walker, A. A. Saveliev, G. M. Smith, et al.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib109.1.1">
      Mixed effects models and extensions in ecology with R
     </span>
     , volume 574.
    </span>
    <span class="ltx_bibblock">
     Springer, 2009.
    </span>
   </li>
  </ul>
 </section>
</article>
