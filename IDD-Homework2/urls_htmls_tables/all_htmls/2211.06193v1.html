<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2211.06193] DocuT5: Seq2seq SQL Generation with Table Documentation</title><meta property="og:description" content="Current SQL generators based on pre-trained language models struggle to answer complex questions requiring domain context or understanding fine-grained table structure.
Humans would deal with these unknowns by reasonin…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="DocuT5: Seq2seq SQL Generation with Table Documentation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="DocuT5: Seq2seq SQL Generation with Table Documentation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2211.06193">

<!--Generated on Thu Mar 14 04:39:34 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">DocuT5: Seq2seq SQL Generation with Table Documentation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Elena Soare 
<br class="ltx_break">University of Glasgow 
<br class="ltx_break">elena.soare1998@gmail.com 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_ERROR undefined">\And</span>Iain Mackie 
<br class="ltx_break">University of Glasgow 
<br class="ltx_break">i.mackie.1@research.gla.ac.uk
<br class="ltx_break"><span id="id2.2.id2" class="ltx_ERROR undefined">\And</span>Jeffrey Dalton 
<br class="ltx_break">University of Glasgow 
<br class="ltx_break">jeff.dalton@glasgow.ac.uk
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id3.id1" class="ltx_p">Current SQL generators based on pre-trained language models struggle to answer complex questions requiring domain context or understanding fine-grained table structure.
Humans would deal with these unknowns by reasoning over the documentation of the tables.
Based on this hypothesis, we propose DocuT5, which uses off-the-shelf language model architecture and injects knowledge from external “documentation” to improve domain generalization.
We perform experiments on the Spider family of datasets that contain complex questions that are cross-domain and multi-table.
Specifically, we develop a new text-to-SQL failure taxonomy and find that 19.6% of errors are due to foreign key mistakes, and 49.2% are due to a lack of domain knowledge.
We proposed DocuT5, a method that captures knowledge from (1) table structure context of foreign keys and (2) domain knowledge through contextualizing tables and columns.
Both types of knowledge improve over state-of-the-art T5 with constrained decoding on Spider, and domain knowledge produces state-of-the-art comparable effectiveness on Spider-DK and Spider-SYN datasets. Our code is available at <a target="_blank" href="https://github.com/grill-lab/DocuT5" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/grill-lab/DocuT5</a>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Translating natural language utterances into logical forms (SQL) that are executable against a relational database (text-to-SQL) is an important real-world task, reducing the barriers to entry for data analysis.
While leveraging pre-trained language models as SQL generators shows strong performance <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>); Lin et al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>); Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>, there are still limitations due to a lack of domain or table knowledge.
This means that models struggle to adapt to new tables or domains, particularly when the natural language question does not explicitly reference the schema entities and relations.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Cross-domain annotated benchmarks WikiSQL <cite class="ltx_cite ltx_citemacro_cite">Zhong et al. (<a href="#bib.bib28" title="" class="ltx_ref">2017</a>)</cite> and Spider <cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a href="#bib.bib25" title="" class="ltx_ref">2018</a>)</cite> contain a high percentage of natural language questions that directly reference column names contained within the database schema.
However, when column mentions are replaced with synonyms <cite class="ltx_cite ltx_citemacro_cite">Gan et al. (<a href="#bib.bib5" title="" class="ltx_ref">2021a</a>)</cite>, or paraphrases <cite class="ltx_cite ltx_citemacro_cite">Gan et al. (<a href="#bib.bib6" title="" class="ltx_ref">2021b</a>)</cite>, prediction accuracy scores drop substantially, even when questions containing domain knowledge are mentioned in the training data.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Researchers leveraged graph neural networks which encoded the input as directed graphs <cite class="ltx_cite ltx_citemacro_cite">Bogin et al. (<a href="#bib.bib1" title="" class="ltx_ref">2019</a>); Guo et al. (<a href="#bib.bib7" title="" class="ltx_ref">2019</a>); Wang et al. (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite>, augmented with syntactic metadata of the natural language question and database <cite class="ltx_cite ltx_citemacro_cite">Hui et al. (<a href="#bib.bib10" title="" class="ltx_ref">2022</a>)</cite>, or enhanced the schema grounding modules <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a href="#bib.bib16" title="" class="ltx_ref">2022</a>); Wang et al. (<a href="#bib.bib23" title="" class="ltx_ref">2022</a>)</cite>.
However, these are complicated and often dataset-specific architectures that are non-trivial to adapt to new domains or datasets.
On the other hand, Most seq2seq SQL generators <cite class="ltx_cite ltx_citemacro_cite">Hwang et al. (<a href="#bib.bib11" title="" class="ltx_ref">2019</a>); Lin et al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>); Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite> only linearize the database schema by enumerating table and column names, and lack the explicit table or domain knowledge for complex operations.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2211.06193/assets/images/iain_fk_failure.png" id="S1.F1.g1" class="ltx_graphics ltx_img_landscape" width="424" height="248" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Foreign key failure example by seq2seq model <cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite> on Spider dev.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this work, our first contribution is an in-depth behavioural study on a state-of-the-art seq2seq model with constrained decoding <cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>.
We find that 19.6% of errors are due to foreign key mismatches, and another 49.2% are due to a lack of domain knowledge.
For example, Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ DocuT5: Seq2seq SQL Generation with Table Documentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows a foreign key error where the model fails to identify <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">countrycode</span> column in <span id="S1.p4.1.2" class="ltx_text ltx_font_italic">city</span> table is a foreign key to <span id="S1.p4.1.3" class="ltx_text ltx_font_italic">code</span> column in <span id="S1.p4.1.4" class="ltx_text ltx_font_italic">country</span> table.
Figure <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ DocuT5: Seq2seq SQL Generation with Table Documentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the model fails to understand the table context that the <span id="S1.p4.1.5" class="ltx_text ltx_font_italic">percentage</span> column is the proportion of <span id="S1.p4.1.6" class="ltx_text ltx_font_italic">language</span> speakers in <span id="S1.p4.1.7" class="ltx_text ltx_font_italic">Aruba</span>.</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2211.06193/assets/images/iain_sd_failure_3.png" id="S1.F2.g1" class="ltx_graphics ltx_img_landscape" width="424" height="248" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Domain knowledge failure example by seq2seq model <cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite> on Spider dev.</figcaption>
</figure>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">We argue that existing models suffer from these issues as they fail to incorporate knowledge in a way comparable to a human analyst.
Specifically, when translating a request to a SQL query, a person would typically consult the table documentation, especially if it is a new domain or there is uncertainty about terminology.
Inspired by this approach, we propose DocuT5 that injects “documentation” into an off-the-shelf seq2seq model without requiring model modification, providing table and domain context during the generation process.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Some recent work by <cite class="ltx_cite ltx_citemacro_citet">Dou et al. (<a href="#bib.bib4" title="" class="ltx_ref">2022</a>)</cite> has shown promising results in adding foreign key context into seq2seq models.
We take this a step further by proposing DocuT5, which adds rich domain knowledge via (1) a simplified means for encoding foreign keys (DocuT5-FK) and (2) textual schema descriptions that provide question context of the overall table and specific columns (DocuT5-SD).
Because the knowledge encoding is general, is it widely applicable to diverse language model classes and the results show consistent performance improvement across multiple dimensions.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">We study the behavior of DocuT5 and previous models on the Spider family of datasets that contain complex questions that are cross-domain and multi-table.
This includes the original Spider dev set, as well as Spider-DK <cite class="ltx_cite ltx_citemacro_cite">Gan et al. (<a href="#bib.bib6" title="" class="ltx_ref">2021b</a>)</cite> that requires domain knowledge, and Spider-SYN <cite class="ltx_cite ltx_citemacro_cite">Gan et al. (<a href="#bib.bib5" title="" class="ltx_ref">2021a</a>)</cite> that replaces question terms with synonyms.
We evaluate against comparable state-of-the-art SQL generators that leverage off-the-shelf pre-trained language models, including the BRIDGE, <cite class="ltx_cite ltx_citemacro_cite">Lin et al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>)</cite>, PICARD <cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>, and UniSAr <cite class="ltx_cite ltx_citemacro_cite">Dou et al. (<a href="#bib.bib4" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">Our experiments find that encoding foreign keys improves over T5 with constrained decoding by 3.1% and comparable reported results by 2.2% on Spider.
Separately, encoding schema description also improves on Spider against T5 with constrained decoding by 2.3% and comparable reported results by 1.4%.
Schema description also shows more significant relative improvements on Spider-DK (+2.4%) and Spider-SYN (+2.8%), where schema knowledge is most required.
Overall, DocuT5 achieves the best comparable results on Spider, Spider-DK, and Spider-SYN.
The contributions of this paper are:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Spider behavior analysis</span>: develop a new text-to-SQL failure taxonomy and categories state-of-the-art seq2seq model failures on Spider, with 19.6% attributed to foreign keys and 49.2% attributed to domain knowledge.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Foreign keys</span>: demonstrate that encoding foreign key knowledge improves model performance by 3.1% on Spider, achieving state-of-the-art against comparable models.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Schema descriptions</span> Use schema schema descriptions to improves model performance by 2.3% on Spider.
Incorporating domain knowledge produces the best reported results on Spider-DK and Spider-Syn datasets.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Task</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We focus on the text-to-SQL generation task in a cross-domain setting.
By definition, given a natural language question <span id="S2.p1.1.1" class="ltx_text ltx_font_italic">Q</span> and a database schema <span id="S2.p1.1.2" class="ltx_text ltx_font_italic">S</span>, we need to infer a correct <span id="S2.p1.1.3" class="ltx_text ltx_font_italic">SQL</span> query, which is executable against a database to retrieve an execution answer <span id="S2.p1.1.4" class="ltx_text ltx_font_italic">A</span> that satisfies <span id="S2.p1.1.5" class="ltx_text ltx_font_italic">Q</span>.
Each database schema consists of a set of tables <span id="S2.p1.1.6" class="ltx_text ltx_font_italic">T</span>, and a set of columns <span id="S2.p1.1.7" class="ltx_text ltx_font_italic">C</span> belonging to the tables such that <span id="S2.p1.1.8" class="ltx_text ltx_font_italic">S = &lt;T,C&gt;</span>.
A foreign key <span id="S2.p1.1.9" class="ltx_text ltx_font_italic">FK</span> is a column which links two tables based on matching values and schema description <span id="S2.p1.1.10" class="ltx_text ltx_font_italic">SD</span> are metadata explaining <span id="S2.p1.1.11" class="ltx_text ltx_font_italic">S = &lt;T,C&gt;</span>.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Datasets</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p"><span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_bold">Spider</span> <cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a href="#bib.bib25" title="" class="ltx_ref">2018</a>)</cite> is a cross-domain text-to-SQL dataset which contains 10,181 natural question utterances and 5,693 SQL statements for training, with a 535-question dev set.
Spider contains 200 databases across a large variety of domains, and most queries contain at least one ORDER BY, JOIN, GROUP BY, or HAVING statements, unlike WikiSQL <cite class="ltx_cite ltx_citemacro_cite">Zhong et al. (<a href="#bib.bib28" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p"><span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_bold">Spider-DK</span> <cite class="ltx_cite ltx_citemacro_cite">Gan et al. (<a href="#bib.bib6" title="" class="ltx_ref">2021b</a>)</cite> is a test set to assess the robustness of text-to-SQL models where questions require rarely observed domain knowledge or paraphrasing.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p"><span id="S2.SS1.p3.1.1" class="ltx_text ltx_font_bold">Spider-SYN</span> <cite class="ltx_cite ltx_citemacro_cite">Gan et al. (<a href="#bib.bib5" title="" class="ltx_ref">2021a</a>)</cite> is a variant developed by replacing schema-related words with synonyms that reflect real-world question paraphrases, eliminating explicit correspondence between questions and table schemas.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Metrics</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p"><span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_bold">Exact Set Match (EM)</span> <cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a href="#bib.bib25" title="" class="ltx_ref">2018</a>)</cite> converts the predicted SQL query into an orderless dictionary, which are compared to the gold SQL queries based on string matching.
Each clause has to be exact strings with the corresponding gold SQL clause for EM to be 1, otherwise EM is 0.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold">Execution Accuracy (EX)</span> is based on the results of executing SQL on the corresponding databases <cite class="ltx_cite ltx_citemacro_cite">Zhong et al. (<a href="#bib.bib27" title="" class="ltx_ref">2020</a>)</cite>.
This metric deals with the semantic equivalence of SQL statements, which produce the same execution results despite being syntactically different.
Specifically, EX is 1 if the predicted and gold SQL have equivalent execution results, and 0 otherwise.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Behavior Analysis</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we conduct an error analysis using a newly developed taxonomy to categorize errors within text-to-SQL models.
We reproduce T5 with constrained decoding <cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite> on Spider dev set.
We select the largest available T5 model (3 billion parameters) and activate the constrained decoding framework during inference.
Based on the EX accuracy, we save the incorrectly inferred SQL queries from the Spider dev set.
In total, there are 214 incorrect natural language questions and SQL pairs to manually categorise.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Failure Taxonomy</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The authors develop the following taxonomy of failure categories to identify text-to-SQL failure patterns.
It is important to understand “how” these models are failing to motivate future research directions, and this taxonomy can be used across any text-to-SQL dataset.
Experienced computer scientists with experience with SQL (the authors) discuss and agree on the categories of errors during annotation of the 214 failing Spider queries.
At least one author performs each annotation, and a majority vote resolves ambiguous instances. The failure taxonomy is:</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">Incomplete Queries</span>
The predicted SQL queries are only partially decoded because the model predicts the ending tag prematurely.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p"><span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_bold">False Negatives</span>
The natural language question is ambiguous, or generated SQL queries are incorrectly labelled as inaccurate.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">Foreign Keys</span> errors are prevalent in JOIN operations where wrong foreign key columns are used.
On a manual inspection, most of these errors are due to inconsistent naming within databases, making it non-trivial to reason over.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p"><span id="S3.SS1.p5.1.1" class="ltx_text ltx_font_bold">Logical Errors</span> errors miss logical implications within the natural language question.
For example, ordering people by age means ordering them in decreasing order of date of birth.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.1" class="ltx_p"><span id="S3.SS1.p6.1.1" class="ltx_text ltx_font_bold">Domain Knowledge</span>
In this scenario, the model cannot capture the <span id="S3.SS1.p6.1.2" class="ltx_text ltx_font_italic">meaning</span> of the database schema due to missing table or column knowledge.
We further divide this into subcategories:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Aggregation Errors</span>: Incorrect use of SUM, COUNT, MIN, and MAX functions.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Incorrect Table</span>: DB entries are retrieved from the incorrect table.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Incorrect Column</span>: Predicting the wrong columns in SELECT or WHERE clauses. Often attributable to implicitly referenced columns within the question.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p"><span id="S3.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Value Errors</span>: Incorrect values in WHERE clauses. Values mentioned in questions are not exact strings matches to the DB entries.</p>
</div>
</li>
<li id="S3.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i5.p1" class="ltx_para">
<p id="S3.I1.i5.p1.1" class="ltx_p"><span id="S3.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Complex Errors</span>: The model fails to understand a mix of paraphrases, complex table structures, and difficult required aggregations.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Findings</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Table <a href="#S3.T1" title="Table 1 ‣ 3.2 Findings ‣ 3 Behavior Analysis ‣ DocuT5: Seq2seq SQL Generation with Table Documentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the breakdown of T5 with constrained decoding errors on the Spider dev set.
We find that 22.4% of questions are False Negative, which is not a suitable target category for model improvement.
Furthermore, 6.2% of errors are due to Incomplete SQL and 2.8% are due to Logical Errors, both relatively small failure categories.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">We specifically focus on Foreign Keys and Domain Knowledge categories based on the disproportionate amount of errors.
For example, 19.6% of errors are due to table joins from incorrect foreign keys.
The overall errors caused by Domain Knowledge totalled 49.2% across five subcategories, with Aggregation Errors (17.2%), Incorrect Column (13.4%), and Complex Errors (11.0%).</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.1.1.1.1.1" class="ltx_text ltx_font_bold">Failure Categories</span></th>
<th id="S3.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.1.1.1.2.1" class="ltx_text ltx_font_bold">Percentage</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.1.2.1" class="ltx_tr">
<td id="S3.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Incomplete SQL</td>
<td id="S3.T1.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">6.2%</td>
</tr>
<tr id="S3.T1.1.3.2" class="ltx_tr">
<td id="S3.T1.1.3.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">False Negatives</td>
<td id="S3.T1.1.3.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">22.4%</td>
</tr>
<tr id="S3.T1.1.4.3" class="ltx_tr">
<td id="S3.T1.1.4.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Foreign Keys</td>
<td id="S3.T1.1.4.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">19.6%</td>
</tr>
<tr id="S3.T1.1.5.4" class="ltx_tr">
<td id="S3.T1.1.5.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Logical Errors</td>
<td id="S3.T1.1.5.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2.8%</td>
</tr>
<tr id="S3.T1.1.6.5" class="ltx_tr">
<td id="S3.T1.1.6.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">DK - Incorrect AGG</td>
<td id="S3.T1.1.6.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">17.2%</td>
</tr>
<tr id="S3.T1.1.7.6" class="ltx_tr">
<td id="S3.T1.1.7.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">DK - Incorrect Table</td>
<td id="S3.T1.1.7.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">3.8%</td>
</tr>
<tr id="S3.T1.1.8.7" class="ltx_tr">
<td id="S3.T1.1.8.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">DK - Incorrect Column</td>
<td id="S3.T1.1.8.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">13.4%</td>
</tr>
<tr id="S3.T1.1.9.8" class="ltx_tr">
<td id="S3.T1.1.9.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">DK - Incorrect Value</td>
<td id="S3.T1.1.9.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">3.8%</td>
</tr>
<tr id="S3.T1.1.10.9" class="ltx_tr">
<td id="S3.T1.1.10.9.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">DK - Complex</td>
<td id="S3.T1.1.10.9.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">11.0%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Error Analysis on Spider dev based on T5+3B with constrained decoding.</figcaption>
</figure>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">We investigate whether giving models access to contextual “documentation” helps with Foreign Keys and Domain Knowledge failure categories.
Therefore, this categorization is important because it helps us assess what context will help the model for specific failure categories.
For example, Value Errors motivate contextualizing column values, especially for hard-to-interpret boolean columns.
Incorrect Column errors are due to the model not mapping question intent with the correct column, requiring more context to ground the column for specific use cases.
Lastly, Incorrect Aggregation is when the model is having issues discerning the value type of a specific column and explicitly stating whether the column is a date or number would be beneficial.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Method</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">DocuT5 is a new method to include documentation into seq2seq models that is general and widely applicable to diverse models without requiring changes to model structure.
Specifically, we focus on improving schema serialization through explicit foreign keys mapping and domain knowledge through additional table and column context.
As is standard for seq2seq models, we concatenate the natural language question and serialized database schema and ask the model to generate the SQL.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">We employ an off-the-shelf pre-trained language model T5 <cite class="ltx_cite ltx_citemacro_cite">Raffel et al. (<a href="#bib.bib18" title="" class="ltx_ref">2020</a>)</cite>, experimenting with both the T5-Base and T5-Large variants.
For all DocuT5 variants, we serialized the database schema by enumerating the table and column names, similar to <cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>.
We also encode database content snippets (anchor texts) by performing fuzzy string matching on the natural language question and the database entries <cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>); Lin et al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>)</cite>.
Lastly, to reduce non-executable hallucinations, we employ constrained decoding to incrementally perform sanity checks at inference <cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>DocuT5-FK: Foreign Keys</h3>

<figure id="S4.F3" class="ltx_figure"><img src="/html/2211.06193/assets/images/iain_docut5-fk_2.png" id="S4.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="434" height="351" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>DocuT5-FK: jointly encoding the natural language question and database schema, including foreign key relations. After every foreign key column, we add a special marker “foreign key”, followed by the referenced table name.</figcaption>
</figure>
<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Encoding cross-table relations in textual form is more challenging than, for instance, column-table relations (column belongs to table) because foreign key relations are more intuitively mapped to directed graphs.
To reduce complexity and exploit the ability of pre-trained language models to grasp free-form text better than structured data, we add a special “foreign key” marker after every foreign key column in the serialized schema representation, followed by the name of the table it is referenced to.
For example, Figure <a href="#S4.F3" title="Figure 3 ‣ 4.1 DocuT5-FK: Foreign Keys ‣ 4 Method ‣ DocuT5: Seq2seq SQL Generation with Table Documentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the input design for the <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">city</span> table, where the foreign key <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_italic">column</span> is a reference to the <span id="S4.SS1.p1.1.3" class="ltx_text ltx_font_italic">id</span> in table <span id="S4.SS1.p1.1.4" class="ltx_text ltx_font_italic">country</span>.
We add only the table reference next to FK column <span id="S4.SS1.p1.1.5" class="ltx_text ltx_font_italic">country</span>: “foreign key country”.</p>
</div>
<figure id="S4.F4" class="ltx_figure ltx_align_center"><img src="/html/2211.06193/assets/images/iain_docut5_sd_2.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="770" height="420" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>DocuT5-SD: Adding semi-structured schema descriptions, which encapsulate schema-specific domain knowledge for both tables and columns.</figcaption>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Based on initial experimentation, we find that simple patterns for encoding foreign key information are easier for seq2seq models to learn.
Therefore, we avoided more complex column-to-column foreign keys , as used in UniSAr, including only the table name and linking the foreign key table directly in the schema serialization.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">We also only selectively add the most beneficial foreign key relation types to keep input less complex. Specifically:</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p"><span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_bold">1-to-1 relations</span> associate one record in a table with another record in another table.
We add the FK relation marker after <span id="S4.SS1.p4.1.2" class="ltx_text ltx_font_italic">both</span> columns if they represent primary keys,
otherwise, we add the relation marker <span id="S4.SS1.p4.1.3" class="ltx_text ltx_font_italic">only</span> after the non-primary key column.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p"><span id="S4.SS1.p5.1.1" class="ltx_text ltx_font_bold">1-to-Many relations</span> associate one record in a table with multiple records in another table.
In this case, we add the foreign key relation <span id="S4.SS1.p5.1.2" class="ltx_text ltx_font_italic">only</span> after the foreign key column on the <span id="S4.SS1.p5.1.3" class="ltx_text ltx_font_italic">-Many</span> sides.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>DocuT5-SD: Schema Descriptions</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">As identified in Section <a href="#S3.SS1" title="3.1 Failure Taxonomy ‣ 3 Behavior Analysis ‣ DocuT5: Seq2seq SQL Generation with Table Documentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>, around 50% of current seq2seq errors result from a lack of domain knowledge.
Specifically, the model makes errors due to missing table or column knowledge.
For example, when asked <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">Which language is the most popular in Aruba</span>, current models struggle to identify <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_italic">percentage</span> as the target column and what logical operations are required to compute the answer.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">To solve for missing domain knowledge, we introduce schema descriptions directly as textual input to leverage pre-trained language models’ ability to reason over text.
These descriptions aim to provide paraphrases or database context to create a more specific table definitions.
For example, a column named <span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_italic">date</span> within table <span id="S4.SS2.p2.1.2" class="ltx_text ltx_font_italic">company</span> can mean the date that the company was founded or when the database table was last updated, depending on the contents.
Furthermore, we tried to inject cross-table relations into natural language by describing schema entities concerning other entities.
Figure <a href="#S4.F4" title="Figure 4 ‣ 4.1 DocuT5-FK: Foreign Keys ‣ 4 Method ‣ DocuT5: Seq2seq SQL Generation with Table Documentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the model input that explains the table <span id="S4.SS2.p2.1.3" class="ltx_text ltx_font_italic">customer</span>, in relation to table <span id="S4.SS2.p2.1.4" class="ltx_text ltx_font_italic">store</span> and <span id="S4.SS2.p2.1.5" class="ltx_text ltx_font_italic">film</span>.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Computer scientists with working knowledge of SQL and access to a commercial search engine (the authors) develop these high-quality schema descriptions, which will be released as part of the paper.
Figure <a href="#S4.F4" title="Figure 4 ‣ 4.1 DocuT5-FK: Foreign Keys ‣ 4 Method ‣ DocuT5: Seq2seq SQL Generation with Table Documentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows how the schema descriptions are included alongside the question and serialized schema, separated by the “description” marker.
Annotators follow the subsequent guidelines to keep descriptions short, specific and consistent:</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p"><span id="S4.SS2.p4.1.1" class="ltx_text ltx_font_bold">Table definitions</span> describe all tables within a database schema.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p"><span id="S4.SS2.p5.1.1" class="ltx_text ltx_font_bold">Column definitions</span> describe only ambiguous columns, i.e. name is a partial match to its natural language reference (<span id="S4.SS2.p5.1.2" class="ltx_text ltx_font_italic">indepyear</span> is explained as <span id="S4.SS2.p5.1.3" class="ltx_text ltx_font_italic">independence year</span>) or vague.</p>
</div>
<div id="S4.SS2.p6" class="ltx_para">
<p id="S4.SS2.p6.1" class="ltx_p"><span id="S4.SS2.p6.1.1" class="ltx_text ltx_font_bold">Boolean columns</span> make implicit use of domain knowledge and are often ambiguous for pre-trained language models <cite class="ltx_cite ltx_citemacro_cite">Gan et al. (<a href="#bib.bib6" title="" class="ltx_ref">2021b</a>)</cite>.
In Figure <a href="#S4.F4" title="Figure 4 ‣ 4.1 DocuT5-FK: Foreign Keys ‣ 4 Method ‣ DocuT5: Seq2seq SQL Generation with Table Documentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, the definition of column <span id="S4.SS2.p6.1.2" class="ltx_text ltx_font_italic">active</span> in the DB <span id="S4.SS2.p6.1.3" class="ltx_text ltx_font_italic">sakila_1</span> contains explanations of the values “0” and “1”.</p>
</div>
<div id="S4.SS2.p7" class="ltx_para">
<p id="S4.SS2.p7.1" class="ltx_p"><span id="S4.SS2.p7.1.1" class="ltx_text ltx_font_bold">Structured descriptions</span>: We keep the table description semi-structured by ordering the table and column paraphrases with the same success as the baseline serialized schema, with different separator tokens between table and columns.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments and Evaluation</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this section we report the experimental results for including documentation into seq2seq models.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Experimental Setup</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">To evaluate our methods, we implement comparable and strong baseline SQL generation systems that use off-the-self pre-trained language models.
Specifically, we fine-tune <span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_bold">T5-Base</span> and <span id="S5.SS1.p1.1.2" class="ltx_text ltx_font_bold">T5-Large</span> models on the Spider train set, with evaluation on the Spider dev set <cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>.
We use the standard Huggingface checkpoints with cross-entropy loss, a constant learning rate of 0.0001 with an Adafactor optimizer, and train for around 400 epochs.
We perform an early stop and select the best scoring model by EM on Spider dev set, and evaluate zero-shot on Spider-DK and Spider-SYN testsets.
Additionally, we evaluate performance of both <span id="S5.SS1.p1.1.3" class="ltx_text ltx_font_bold">T5-Base<sup id="S5.SS1.p1.1.3.1" class="ltx_sup">CD</sup></span> and <span id="S5.SS1.p1.1.4" class="ltx_text ltx_font_bold">T5-Large<sup id="S5.SS1.p1.1.4.1" class="ltx_sup">CD</sup></span> with constrained decoding <cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">We also compare against the strongest reported results from comparable pre-trained language model SQL generators.
<span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold">PICARD</span> <cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite> uses constrained decoding and we compare against the comparable T5-Base and T5-Large models.
<span id="S5.SS1.p2.1.2" class="ltx_text ltx_font_bold">BRIDGE</span> <cite class="ltx_cite ltx_citemacro_cite">Lin et al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>)</cite> uses a BERT-large model for contextualization and a pointer-generator decoder.
The recently published <span id="S5.SS1.p2.1.3" class="ltx_text ltx_font_bold">UniSAr</span> <cite class="ltx_cite ltx_citemacro_cite">Dou et al. (<a href="#bib.bib4" title="" class="ltx_ref">2022</a>)</cite> encodes table structures within the textual input to BART-Large and uses constrained decoding.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">Similar to how we employ the T5 models, we train <span id="S5.SS1.p3.1.1" class="ltx_text ltx_font_bold">DocuT5-FK</span> and <span id="S5.SS1.p3.1.2" class="ltx_text ltx_font_bold">DocuT5-SD</span> using T5-Base and T5-Large models under the same training and evaluation methodology.
We also evaluate performance of <span id="S5.SS1.p3.1.3" class="ltx_text ltx_font_bold">DocuT5-FK<sup id="S5.SS1.p3.1.3.1" class="ltx_sup">CD</sup></span> and <span id="S5.SS1.p3.1.4" class="ltx_text ltx_font_bold">DocuT5-SD<sup id="S5.SS1.p3.1.4.1" class="ltx_sup">CD</sup></span> with constrained decoding <cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Results</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">We provide the results and analysis across schema serialization and schema descriptions.</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1 </span>Foreign Keys</h4>

<figure id="S5.T2" class="ltx_table ltx_align_center">
<table id="S5.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.1.1.1" class="ltx_tr">
<th id="S5.T2.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_t" colspan="2"></th>
<th id="S5.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2">Spider dev</th>
</tr>
<tr id="S5.T2.1.2.2" class="ltx_tr">
<th id="S5.T2.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">Model</th>
<th id="S5.T2.1.2.2.2" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S5.T2.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">EM</th>
<th id="S5.T2.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">EX</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.1.3.1" class="ltx_tr">
<th id="S5.T2.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">PICARD-Base</th>
<td id="S5.T2.1.3.1.2" class="ltx_td ltx_border_t"></td>
<td id="S5.T2.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">65.8%</td>
<td id="S5.T2.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">68.4%</td>
</tr>
<tr id="S5.T2.1.4.2" class="ltx_tr">
<th id="S5.T2.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">PICARD-Large</th>
<td id="S5.T2.1.4.2.2" class="ltx_td"></td>
<td id="S5.T2.1.4.2.3" class="ltx_td ltx_align_center">69.1%</td>
<td id="S5.T2.1.4.2.4" class="ltx_td ltx_align_center">72.9%</td>
</tr>
<tr id="S5.T2.1.5.3" class="ltx_tr">
<th id="S5.T2.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BRIDGE</th>
<td id="S5.T2.1.5.3.2" class="ltx_td"></td>
<td id="S5.T2.1.5.3.3" class="ltx_td ltx_align_center">70.0%</td>
<td id="S5.T2.1.5.3.4" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T2.1.6.4" class="ltx_tr">
<th id="S5.T2.1.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">UniSAr</th>
<td id="S5.T2.1.6.4.2" class="ltx_td"></td>
<td id="S5.T2.1.6.4.3" class="ltx_td ltx_align_center">70.0%</td>
<td id="S5.T2.1.6.4.4" class="ltx_td"></td>
</tr>
<tr id="S5.T2.1.7.5" class="ltx_tr">
<th id="S5.T2.1.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">T5-Base</th>
<td id="S5.T2.1.7.5.2" class="ltx_td ltx_border_t"></td>
<td id="S5.T2.1.7.5.3" class="ltx_td ltx_align_center ltx_border_t">59.4%</td>
<td id="S5.T2.1.7.5.4" class="ltx_td ltx_align_center ltx_border_t">60.0%</td>
</tr>
<tr id="S5.T2.1.8.6" class="ltx_tr">
<th id="S5.T2.1.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">DocuT5-Base-FK</th>
<td id="S5.T2.1.8.6.2" class="ltx_td"></td>
<td id="S5.T2.1.8.6.3" class="ltx_td ltx_align_center">57.1%</td>
<td id="S5.T2.1.8.6.4" class="ltx_td ltx_align_center">60.1%</td>
</tr>
<tr id="S5.T2.1.9.7" class="ltx_tr">
<th id="S5.T2.1.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">T5-Base<sup id="S5.T2.1.9.7.1.1" class="ltx_sup">CD</sup>
</th>
<td id="S5.T2.1.9.7.2" class="ltx_td"></td>
<td id="S5.T2.1.9.7.3" class="ltx_td ltx_align_center">66.6%</td>
<td id="S5.T2.1.9.7.4" class="ltx_td ltx_align_center">68.4%</td>
</tr>
<tr id="S5.T2.1.10.8" class="ltx_tr">
<th id="S5.T2.1.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">DocuT5-Base-FK<sup id="S5.T2.1.10.8.1.1" class="ltx_sup">CD</sup>
</th>
<td id="S5.T2.1.10.8.2" class="ltx_td"></td>
<td id="S5.T2.1.10.8.3" class="ltx_td ltx_align_center">67.0%</td>
<td id="S5.T2.1.10.8.4" class="ltx_td ltx_align_center">72.0%</td>
</tr>
<tr id="S5.T2.1.11.9" class="ltx_tr">
<th id="S5.T2.1.11.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">T5-Large</th>
<td id="S5.T2.1.11.9.2" class="ltx_td ltx_border_t"></td>
<td id="S5.T2.1.11.9.3" class="ltx_td ltx_align_center ltx_border_t">65.3%</td>
<td id="S5.T2.1.11.9.4" class="ltx_td ltx_align_center ltx_border_t">67.2%</td>
</tr>
<tr id="S5.T2.1.12.10" class="ltx_tr">
<th id="S5.T2.1.12.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">DocuT5-Large-FK</th>
<td id="S5.T2.1.12.10.2" class="ltx_td"></td>
<td id="S5.T2.1.12.10.3" class="ltx_td ltx_align_center">64.3%</td>
<td id="S5.T2.1.12.10.4" class="ltx_td ltx_align_center">67.5%</td>
</tr>
<tr id="S5.T2.1.13.11" class="ltx_tr">
<th id="S5.T2.1.13.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">T5-Large<sup id="S5.T2.1.13.11.1.1" class="ltx_sup">CD</sup>
</th>
<td id="S5.T2.1.13.11.2" class="ltx_td"></td>
<td id="S5.T2.1.13.11.3" class="ltx_td ltx_align_center">69.1%</td>
<td id="S5.T2.1.13.11.4" class="ltx_td ltx_align_center">72.9%</td>
</tr>
<tr id="S5.T2.1.14.12" class="ltx_tr">
<th id="S5.T2.1.14.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">DocuT5-Large-FK<sup id="S5.T2.1.14.12.1.1" class="ltx_sup">CD</sup>
</th>
<td id="S5.T2.1.14.12.2" class="ltx_td ltx_border_b"></td>
<td id="S5.T2.1.14.12.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S5.T2.1.14.12.3.1" class="ltx_text ltx_font_bold">72.2%</span></td>
<td id="S5.T2.1.14.12.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S5.T2.1.14.12.4.1" class="ltx_text ltx_font_bold">77.0%</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Spider results: serializing schema with foreign keys. Our results (bottom and middle) and relevant prior work (top). (<sup id="S5.T2.3.1" class="ltx_sup">CD</sup>) highlights when using constrained decoding <cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>. Prior work: PICARD <cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>, BRIDGE <cite class="ltx_cite ltx_citemacro_cite">Lin et al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>)</cite>, and UniSAr <cite class="ltx_cite ltx_citemacro_cite">Dou et al. (<a href="#bib.bib4" title="" class="ltx_ref">2022</a>)</cite></figcaption>
</figure>
<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.1" class="ltx_p">Table <a href="#S5.T2" title="Table 2 ‣ 5.2.1 Foreign Keys ‣ 5.2 Results ‣ 5 Experiments and Evaluation ‣ DocuT5: Seq2seq SQL Generation with Table Documentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the schema serialization results where foreign keys are explicitly encoded.
DocuT5-Base-FK<sup id="S5.SS2.SSS1.p1.1.1" class="ltx_sup">CD</sup> improves over the comparable T5-Base<sup id="S5.SS2.SSS1.p1.1.2" class="ltx_sup">CD</sup> model by 0.4% on EM and 1.6% on EX on Spider dev.
While results are even more impressive when focusing on T5-Large models.
DocuT5-Large-FK<sup id="S5.SS2.SSS1.p1.1.3" class="ltx_sup">CD</sup> improves over T5-Large<sup id="S5.SS2.SSS1.p1.1.4" class="ltx_sup">CD</sup> by 3.1% on EM and 3.9% on EX on Spider dev.
DocuT5-Large-FK<sup id="S5.SS2.SSS1.p1.1.5" class="ltx_sup">CD</sup> is also at least 1.4% better than reported results for similar-sized models, such as UniSar.
This is strong evidence that our simple method of injecting foreign key knowledge is highly effective.</p>
</div>
<figure id="S5.T3" class="ltx_table ltx_align_center">
<table id="S5.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T3.1.1.1" class="ltx_tr">
<th id="S5.T3.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_t" colspan="2"></th>
<th id="S5.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2">Spider dev</th>
<th id="S5.T3.1.1.1.3" class="ltx_td ltx_th ltx_th_column ltx_border_t"></th>
<th id="S5.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2">Spider-DK</th>
<th id="S5.T3.1.1.1.5" class="ltx_td ltx_th ltx_th_column ltx_border_t"></th>
<th id="S5.T3.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2">Spider-SYN</th>
</tr>
<tr id="S5.T3.1.2.2" class="ltx_tr">
<th id="S5.T3.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">Model</th>
<th id="S5.T3.1.2.2.2" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S5.T3.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">EM</th>
<th id="S5.T3.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">EX</th>
<th id="S5.T3.1.2.2.5" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S5.T3.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">EM</th>
<th id="S5.T3.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">EX</th>
<th id="S5.T3.1.2.2.8" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S5.T3.1.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">EM</th>
<th id="S5.T3.1.2.2.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">EX</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T3.1.3.1" class="ltx_tr">
<th id="S5.T3.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">PICARD-B<cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S5.T3.1.3.1.2" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">65.8%</td>
<td id="S5.T3.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">68.4%</td>
<td id="S5.T3.1.3.1.5" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S5.T3.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S5.T3.1.3.1.8" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.1.3.1.9" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S5.T3.1.3.1.10" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S5.T3.1.4.2" class="ltx_tr">
<th id="S5.T3.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">PICARD-L <cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S5.T3.1.4.2.2" class="ltx_td"></td>
<td id="S5.T3.1.4.2.3" class="ltx_td ltx_align_center">69.1%</td>
<td id="S5.T3.1.4.2.4" class="ltx_td ltx_align_center">72.9%</td>
<td id="S5.T3.1.4.2.5" class="ltx_td"></td>
<td id="S5.T3.1.4.2.6" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.1.4.2.7" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.1.4.2.8" class="ltx_td"></td>
<td id="S5.T3.1.4.2.9" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.1.4.2.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T3.1.5.3" class="ltx_tr">
<th id="S5.T3.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BRIDGE <cite class="ltx_cite ltx_citemacro_cite">Lin et al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S5.T3.1.5.3.2" class="ltx_td"></td>
<td id="S5.T3.1.5.3.3" class="ltx_td ltx_align_center">70.0%</td>
<td id="S5.T3.1.5.3.4" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.1.5.3.5" class="ltx_td"></td>
<td id="S5.T3.1.5.3.6" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.1.5.3.7" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.1.5.3.8" class="ltx_td"></td>
<td id="S5.T3.1.5.3.9" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.1.5.3.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T3.1.6.4" class="ltx_tr">
<th id="S5.T3.1.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">UniSAr <cite class="ltx_cite ltx_citemacro_cite">Dou et al. (<a href="#bib.bib4" title="" class="ltx_ref">2022</a>)</cite>
</th>
<td id="S5.T3.1.6.4.2" class="ltx_td"></td>
<td id="S5.T3.1.6.4.3" class="ltx_td ltx_align_center">70.0%</td>
<td id="S5.T3.1.6.4.4" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.1.6.4.5" class="ltx_td"></td>
<td id="S5.T3.1.6.4.6" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.1.6.4.7" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.1.6.4.8" class="ltx_td"></td>
<td id="S5.T3.1.6.4.9" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.1.6.4.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T3.1.7.5" class="ltx_tr">
<th id="S5.T3.1.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">T5-Large</th>
<td id="S5.T3.1.7.5.2" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.1.7.5.3" class="ltx_td ltx_align_center ltx_border_t">65.3%</td>
<td id="S5.T3.1.7.5.4" class="ltx_td ltx_align_center ltx_border_t">67.2%</td>
<td id="S5.T3.1.7.5.5" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.1.7.5.6" class="ltx_td ltx_align_center ltx_border_t">39.8%</td>
<td id="S5.T3.1.7.5.7" class="ltx_td ltx_align_center ltx_border_t">46.5%</td>
<td id="S5.T3.1.7.5.8" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.1.7.5.9" class="ltx_td ltx_align_center ltx_border_t">53.4%</td>
<td id="S5.T3.1.7.5.10" class="ltx_td ltx_align_center ltx_border_t">57.3%</td>
</tr>
<tr id="S5.T3.1.8.6" class="ltx_tr">
<th id="S5.T3.1.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">DocuT5-Large-SD</th>
<td id="S5.T3.1.8.6.2" class="ltx_td"></td>
<td id="S5.T3.1.8.6.3" class="ltx_td ltx_align_center">64.4%</td>
<td id="S5.T3.1.8.6.4" class="ltx_td ltx_align_center">66.3%</td>
<td id="S5.T3.1.8.6.5" class="ltx_td"></td>
<td id="S5.T3.1.8.6.6" class="ltx_td ltx_align_center">41.9%</td>
<td id="S5.T3.1.8.6.7" class="ltx_td ltx_align_center">50.5%</td>
<td id="S5.T3.1.8.6.8" class="ltx_td"></td>
<td id="S5.T3.1.8.6.9" class="ltx_td ltx_align_center">52.2%</td>
<td id="S5.T3.1.8.6.10" class="ltx_td ltx_align_center">55.7%</td>
</tr>
<tr id="S5.T3.1.9.7" class="ltx_tr">
<th id="S5.T3.1.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">T5-Large<sup id="S5.T3.1.9.7.1.1" class="ltx_sup">CD</sup>
</th>
<td id="S5.T3.1.9.7.2" class="ltx_td"></td>
<td id="S5.T3.1.9.7.3" class="ltx_td ltx_align_center">69.1%</td>
<td id="S5.T3.1.9.7.4" class="ltx_td ltx_align_center">72.9%</td>
<td id="S5.T3.1.9.7.5" class="ltx_td"></td>
<td id="S5.T3.1.9.7.6" class="ltx_td ltx_align_center">45.6%</td>
<td id="S5.T3.1.9.7.7" class="ltx_td ltx_align_center">55.0%</td>
<td id="S5.T3.1.9.7.8" class="ltx_td"></td>
<td id="S5.T3.1.9.7.9" class="ltx_td ltx_align_center">58.9%</td>
<td id="S5.T3.1.9.7.10" class="ltx_td ltx_align_center">64.5%</td>
</tr>
<tr id="S5.T3.1.10.8" class="ltx_tr">
<th id="S5.T3.1.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">DocuT5-Large-SD<sup id="S5.T3.1.10.8.1.1" class="ltx_sup">CD</sup>
</th>
<td id="S5.T3.1.10.8.2" class="ltx_td ltx_border_b"></td>
<td id="S5.T3.1.10.8.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S5.T3.1.10.8.3.1" class="ltx_text ltx_font_bold">71.4%</span></td>
<td id="S5.T3.1.10.8.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S5.T3.1.10.8.4.1" class="ltx_text ltx_font_bold">74.7%</span></td>
<td id="S5.T3.1.10.8.5" class="ltx_td ltx_border_b"></td>
<td id="S5.T3.1.10.8.6" class="ltx_td ltx_align_center ltx_border_b"><span id="S5.T3.1.10.8.6.1" class="ltx_text ltx_font_bold">48.0%</span></td>
<td id="S5.T3.1.10.8.7" class="ltx_td ltx_align_center ltx_border_b"><span id="S5.T3.1.10.8.7.1" class="ltx_text ltx_font_bold">59.6%</span></td>
<td id="S5.T3.1.10.8.8" class="ltx_td ltx_border_b"></td>
<td id="S5.T3.1.10.8.9" class="ltx_td ltx_align_center ltx_border_b"><span id="S5.T3.1.10.8.9.1" class="ltx_text ltx_font_bold">61.7%</span></td>
<td id="S5.T3.1.10.8.10" class="ltx_td ltx_align_center ltx_border_b"><span id="S5.T3.1.10.8.10.1" class="ltx_text ltx_font_bold">68.2%</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Spider Results: Schema Description. Our results (bottom) and relevant prior work (top). (<sup id="S5.T3.3.1" class="ltx_sup">CD</sup>) highlights when using constrained decoding <cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>.</figcaption>
</figure>
<div id="S5.SS2.SSS1.p2" class="ltx_para">
<p id="S5.SS2.SSS1.p2.1" class="ltx_p">Analyzing the individual questions, DocuT5-FK<sup id="S5.SS2.SSS1.p2.1.1" class="ltx_sup">CD</sup> does fix not only simple foreign key errors but also grounds natural language mentions to schema entities due to explicit context.
By comparison, T5-Large<sup id="S5.SS2.SSS1.p2.1.2" class="ltx_sup">CD</sup> generally attempts to find the “shortest path” across tables.
In the first example in Figure <a href="#A1.F5" title="Figure 5 ‣ Appendix A Appendix ‣ DocuT5: Seq2seq SQL Generation with Table Documentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, DocuT5-FK<sup id="S5.SS2.SSS1.p2.1.3" class="ltx_sup">CD</sup> fixes a Incorrect Table error type, because it receives explicit information that tables <span id="S5.SS2.SSS1.p2.1.4" class="ltx_text ltx_font_italic">car_data</span> and <span id="S5.SS2.SSS1.p2.1.5" class="ltx_text ltx_font_italic">car_names</span> are related.
While in the second example, DocuT5-FK<sup id="S5.SS2.SSS1.p2.1.6" class="ltx_sup">CD</sup> has higher confidence in joining multiple tables together, and can better ground the implicit mention “flights that arrive” to the foreign key “destairport”, which references table “airports”.</p>
</div>
<div id="S5.SS2.SSS1.p3" class="ltx_para">
<p id="S5.SS2.SSS1.p3.1" class="ltx_p">Using the failure taxonomy developed in Section <a href="#S3.SS1" title="3.1 Failure Taxonomy ‣ 3 Behavior Analysis ‣ DocuT5: Seq2seq SQL Generation with Table Documentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>, we investigate how many Foreign Key failure types our model alleviates.
For a fair comparison, we inspect the questions predicted correctly by DocuT5-Large-FK<sup id="S5.SS2.SSS1.p3.1.1" class="ltx_sup">CD</sup>, which T5-Large<sup id="S5.SS2.SSS1.p3.1.2" class="ltx_sup">CD</sup> fails to infer accurately.
Of this subset, our model can correctly predict 14 queries classified previously as Foreign Key failures.
This represents 5% of the total failed queries from the baseline T5-Large<sup id="S5.SS2.SSS1.p3.1.3" class="ltx_sup">CD</sup>.</p>
</div>
<div id="S5.SS2.SSS1.p4" class="ltx_para">
<p id="S5.SS2.SSS1.p4.1" class="ltx_p">Furthermore, we notice that a number of questions incorrectly predicted by T5-3b with constrained decoding were accurately predicted by our DocuT5-Base-FK<sup id="S5.SS2.SSS1.p4.1.1" class="ltx_sup">CD</sup> model, which shows that a careful input design can often outperform a significantly larger model.
Compared to T5-3b, we improve 95 queries, from which 24 were direct Foreign Key mismatches.
The rest of the improved queries were because our model combined tables better in aggregations to infer the correct SQL.</p>
</div>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2 </span>Schema Descriptions</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.1" class="ltx_p">Table <a href="#S5.T3" title="Table 3 ‣ 5.2.1 Foreign Keys ‣ 5.2 Results ‣ 5 Experiments and Evaluation ‣ DocuT5: Seq2seq SQL Generation with Table Documentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the schema description results where textual context is are explicitly encoded for tables and columns.
DocuT5-Large-SD<sup id="S5.SS2.SSS2.p1.1.1" class="ltx_sup">CD</sup> improves over T5-Large<sup id="S5.SS2.SSS2.p1.1.2" class="ltx_sup">CD</sup> by 2.3% on EM and 1.8% on EX on Spider dev.
However, we see a much more significant relative improvement within the Spider-DK and Spider-SYN datasets.
DocuT5-Large-SD<sup id="S5.SS2.SSS2.p1.1.3" class="ltx_sup">CD</sup> improves over T5-Large<sup id="S5.SS2.SSS2.p1.1.4" class="ltx_sup">CD</sup> by 2.4% EM in Spider-DK and 4.6% EX on Spider-DK, and 2.8% EM in Spider-DK and 3.7% EX on Spider-SYN.
Considering a large amount of exact question-schema overlap in the original Spider dev set, Spider-DK and Spider-SYN are good means to assess generalization.
Adding schema descriptions is beneficial and should motivate other methods to leverage schema descriptions.</p>
</div>
<div id="S5.SS2.SSS2.p2" class="ltx_para">
<p id="S5.SS2.SSS2.p2.1" class="ltx_p">Using the failure taxonomy developed in Section <a href="#S3.SS1" title="3.1 Failure Taxonomy ‣ 3 Behavior Analysis ‣ DocuT5: Seq2seq SQL Generation with Table Documentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>, we investigate how many Foreign Key and Domain Knowledge failure types our model alleviates.
We find that DocuT5-Large-SD<sup id="S5.SS2.SSS2.p2.1.1" class="ltx_sup">CD</sup> improves a total of 47 queries: Foreign Key (13) and split across Domain Knowledge by Incorrect Aggregation (8), Incorrect Table (5), Incorrect Column (7), and Incorrect Value (11).</p>
</div>
<div id="S5.SS2.SSS2.p3" class="ltx_para">
<p id="S5.SS2.SSS2.p3.1" class="ltx_p">Figure <a href="#A1.F6" title="Figure 6 ‣ Appendix A Appendix ‣ DocuT5: Seq2seq SQL Generation with Table Documentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows specific examples where using schema descriptions helps for each failure category.
For example, DocuT5-Large-SD<sup id="S5.SS2.SSS2.p3.1.1" class="ltx_sup">CD</sup> can use implicit mentions of schema entities within the question to identify the correct column based on descriptions, i.e. identify both columns <span id="S5.SS2.SSS2.p3.1.2" class="ltx_text ltx_font_italic">date_effective_from</span> and <span id="S5.SS2.SSS2.p3.1.3" class="ltx_text ltx_font_italic">date_effective_to</span> when asked about “effective date period”.
Extra column documentation on boolean columns is also beneficial in contexualising correct use cases, i.e. that “left handed players" are players with column <span id="S5.SS2.SSS2.p3.1.4" class="ltx_text ltx_font_italic">hand</span> set to “L” based on description “a player is a right-handed player then <span id="S5.SS2.SSS2.p3.1.5" class="ltx_text ltx_font_italic">hand</span> is <span id="S5.SS2.SSS2.p3.1.6" class="ltx_text ltx_font_italic">R</span> otherwise <span id="S5.SS2.SSS2.p3.1.7" class="ltx_text ltx_font_italic">L</span>”.</p>
</div>
<div id="S5.SS2.SSS2.p4" class="ltx_para">
<p id="S5.SS2.SSS2.p4.1" class="ltx_p">Looking at the Spider-DK dataset (Figure <a href="#A1.F7" title="Figure 7 ‣ Appendix A Appendix ‣ DocuT5: Seq2seq SQL Generation with Table Documentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>), we find we can correctly predict queries belonging to the Logical Failures, such as questions asking for the “youngest person”, which means the person with the minimum age or the maximum date of birth.
The additional context through schema descriptions allows the model to reason more effectively when there is a question-table word mismatch.
Furthermore, it is also clear that stating the column data type in the table documentation is advantageous; for example, "as a DateTime" results in the model getting less confused when identifying the correct logical operation.</p>
</div>
<div id="S5.SS2.SSS2.p5" class="ltx_para">
<p id="S5.SS2.SSS2.p5.1" class="ltx_p">On the other hand, Figure <a href="#A1.F7" title="Figure 7 ‣ Appendix A Appendix ‣ DocuT5: Seq2seq SQL Generation with Table Documentation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows the results on the Spider-SYN dataset, we find additional context reduces some of the original hallucinations encountered.
While we also observe the additional context makes the model more independent during inference.
Specifically, our model escapes some of the memorized patterns during training and adapts quickly to new domains, such as knowing that <span id="S5.SS2.SSS2.p5.1.1" class="ltx_text ltx_font_italic">puppies</span> refers to the <span id="S5.SS2.SSS2.p5.1.2" class="ltx_text ltx_font_italic">dogs</span> tables.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Related Work</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p"><span id="S6.p1.1.1" class="ltx_text ltx_font_bold">Table Structure:</span> Recently released benchmarks, such as Spider <cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a href="#bib.bib25" title="" class="ltx_ref">2018</a>)</cite> and WikiSQL <cite class="ltx_cite ltx_citemacro_cite">Zhong et al. (<a href="#bib.bib28" title="" class="ltx_ref">2017</a>)</cite> make cross-domain text-to-SQL prediction more challenging than previous single domain datasets <cite class="ltx_cite ltx_citemacro_cite">Dahl et al. (<a href="#bib.bib3" title="" class="ltx_ref">1994</a>); Zelle and Mooney (<a href="#bib.bib26" title="" class="ltx_ref">1996</a>)</cite>.
The cross-domain setting requires generalization to new database schemas and requires compositional SQL and identifying entity mentions in the natural language question.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">Prior works has attempted to encode table structure by converting the schema into a directed graph <cite class="ltx_cite ltx_citemacro_cite">Bogin et al. (<a href="#bib.bib1" title="" class="ltx_ref">2019</a>); Guo et al. (<a href="#bib.bib7" title="" class="ltx_ref">2019</a>)</cite> and adding global reasoning over the natural utterance through a question-contextualization <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite>.
More recently, there have been a number of complex GNN-based approaches that have shown strong performance in the cross-domain SQL setting.
Specifically, more advances schema grounded <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib23" title="" class="ltx_ref">2022</a>); Cao et al. (<a href="#bib.bib2" title="" class="ltx_ref">2021</a>)</cite>, including syntactic metadata <cite class="ltx_cite ltx_citemacro_cite">Hui et al. (<a href="#bib.bib10" title="" class="ltx_ref">2022</a>)</cite>, and iteratively build a semantic enhanced schema-linking graph <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite>.
Nevertheless, graph schema representations require complex model architectures with task-specific layers, and none of these methods enhance the schema-specific domain knowledge through the input.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">Treating text-to-SQL as a machine translation problem, allows exploiting pre-trained language models that showed semantic knowledge understanding <cite class="ltx_cite ltx_citemacro_cite">Hwang et al. (<a href="#bib.bib11" title="" class="ltx_ref">2019</a>); Li et al. (<a href="#bib.bib14" title="" class="ltx_ref">2020</a>)</cite>.
Most seq2seq SQL generators <cite class="ltx_cite ltx_citemacro_cite">Hwang et al. (<a href="#bib.bib11" title="" class="ltx_ref">2019</a>); Lin et al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>); Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite> only linearize the database schema by enumerating table and column names.
For example, PICARD <cite class="ltx_cite ltx_citemacro_cite">Scholak et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite> and BRIDGE <cite class="ltx_cite ltx_citemacro_cite">Lin et al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>)</cite> identified entity mentions within the natural utterance input through database look-ups and fuzzy string matching and appended them to the serialized database input.
Yet, as our behavior analysis identifies, complex table operations such as SQL join operations require richer table contextualization.
UniSAr <cite class="ltx_cite ltx_citemacro_cite">Dou et al. (<a href="#bib.bib4" title="" class="ltx_ref">2022</a>)</cite> showed encoding foreign key relationships is beneficial, however, their results are worse on Spider and our method encodes cross-table relations in a much simpler manner.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p"><span id="S6.p4.1.1" class="ltx_text ltx_font_bold">Schema Descriptions</span>: Relying solely on parametric memory learned during pre-training is not ideal, as revising the model’s <span id="S6.p4.1.2" class="ltx_text ltx_font_italic">world knowledge</span> is non-trivial to do in practice.
A hybrid model exploiting both parametric memory and a flexible external input allows easier adjustments <cite class="ltx_cite ltx_citemacro_cite">Lewis et al. (<a href="#bib.bib13" title="" class="ltx_ref">2020</a>); Shuster et al. (<a href="#bib.bib21" title="" class="ltx_ref">2021</a>); Izacard et al. (<a href="#bib.bib12" title="" class="ltx_ref">2022</a>)</cite>.
It can also reduce hallucinations and factual knowledge incorrectness, which are problems of generative models for knowledge intensive tasks <cite class="ltx_cite ltx_citemacro_cite">Roller et al. (<a href="#bib.bib19" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S6.p5" class="ltx_para">
<p id="S6.p5.1" class="ltx_p">In semantic parsing, input can be augmented by concatenating the top <span id="S6.p5.1.1" class="ltx_text ltx_font_italic">K</span> most similar natural utterance and logical form pairs.
<cite class="ltx_cite ltx_citemacro_citep">Gupta et al., <a href="#bib.bib8" title="" class="ltx_ref">2022</a></cite> augmented the inputs of a pre-trained language model with the top nearest neighbor semantic parses and <cite class="ltx_cite ltx_citemacro_citep">Pasupat et al., <a href="#bib.bib17" title="" class="ltx_ref">2021</a></cite> used custom retrieval index.</p>
</div>
<div id="S6.p6" class="ltx_para">
<p id="S6.p6.1" class="ltx_p">Another tangential work stream is pre-training seq2seq transformer-based models on
aligned tabular and textual data <cite class="ltx_cite ltx_citemacro_cite">Herzig et al. (<a href="#bib.bib9" title="" class="ltx_ref">2020</a>); Yin et al. (<a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite>.
However, the surrounding text is generally noisy and cannot inject much compositional bias.
We use a similar intuition: large pre-trained language models have been trained on free-form text, therefore high-quality table textual descriptions will provide better schema grounding in domain-specific knowledge.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">We introduce DocuT5, which allows diverse language model architectures to inject knowledge from external “documentation” to improve domain generalization.
Through a newly developed failure taxonomy, we identify that current model errors are 19.6% due to foreign key mistakes and 49.2% due to a lack of domain knowledge.
DocuT5 encodes knowledge from the table structure context of foreign keys and domain knowledge through contextualizing cross-table relations.
We show that both types of knowledge improve over state-of-the-art T5 with constrained decoding on SPIDER, and domain knowledge greatly helps on Spider-DK and Spider-SYN datasets.
Further analysis shows error reduction in foreign keys and domain knowledge failure categories and state-of-the-art performance over comparably pre-trained language SLQ generation models.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Acknowledgements</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">The authors would like to acknowledge Ix Tech Global Ltd, specifically Tom Martin and Brie Read, for supporting this research.
Additionally, this work is supported by the 2019 Bloomberg Data Science Research Grant and the Engineering and Physical Sciences Research Council grant EP/V025708/1.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bogin et al. (2019)</span>
<span class="ltx_bibblock">
Ben Bogin, Jonathan Berant, and Matt Gardner. 2019.

</span>
<span class="ltx_bibblock">Representing schema structure with graph neural networks for
text-to-sql parsing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 4560–4565.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao et al. (2021)</span>
<span class="ltx_bibblock">
Ruisheng Cao, Lu Chen, Zhi Chen, Yanbin Zhao, Su Zhu, and Kai Yu. 2021.

</span>
<span class="ltx_bibblock">Lgesql: Line graph enhanced text-to-sql model with mixed local and
non-local relations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association
for Computational Linguistics and the 11th International Joint Conference on
Natural Language Processing (Volume 1: Long Papers)</em>, pages 2541–2555.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dahl et al. (1994)</span>
<span class="ltx_bibblock">
Deborah A Dahl, Madeleine Bates, Michael K Brown, William M Fisher, Kate
Hunicke-Smith, David S Pallett, Christine Pao, Alexander Rudnicky, and
Elizabeth Shriberg. 1994.

</span>
<span class="ltx_bibblock">Expanding the scope of the atis task: The atis-3 corpus.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Human Language Technology: Proceedings of a Workshop held at
Plainsboro, New Jersey, March 8-11, 1994</em>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dou et al. (2022)</span>
<span class="ltx_bibblock">
Longxu Dou, Yan Gao, Mingyang Pan, Dingzirui Wang, Jian-Guang Lou, Wanxiang
Che, and Dechen Zhan. 2022.

</span>
<span class="ltx_bibblock">Unisar: A unified structure-aware autoregressive language model for
text-to-sql.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.07781</em>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gan et al. (2021a)</span>
<span class="ltx_bibblock">
Yujian Gan, Xinyun Chen, Qiuping Huang, Matthew Purver, John R Woodward, Jinxia
Xie, and Pengsheng Huang. 2021a.

</span>
<span class="ltx_bibblock">Towards robustness of text-to-sql models against synonym
substitution.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association
for Computational Linguistics and the 11th International Joint Conference on
Natural Language Processing (Volume 1: Long Papers)</em>, pages 2505–2515.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gan et al. (2021b)</span>
<span class="ltx_bibblock">
Yujian Gan, Xinyun Chen, and Matthew Purver. 2021b.

</span>
<span class="ltx_bibblock">Exploring underexplored limitations of cross-domain text-to-sql
generalization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in
Natural Language Processing</em>, pages 8926–8931.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. (2019)</span>
<span class="ltx_bibblock">
Jiaqi Guo, Zecheng Zhan, Yan Gao, Yan Xiao, Jian-Guang Lou, Ting Liu, and
Dongmei Zhang. 2019.

</span>
<span class="ltx_bibblock">Towards complex text-to-sql in cross-domain database with
intermediate representation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 4524–4535.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta et al. (2022)</span>
<span class="ltx_bibblock">
Vivek Gupta, Akshat Shrivastava, Adithya Sagar, Armen Aghajanyan, and Denis
Savenkov. 2022.

</span>
<span class="ltx_bibblock">Retronlu: Retrieval augmented task-oriented semantic parsing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 4th Workshop on NLP for Conversational
AI</em>, pages 184–196.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Herzig et al. (2020)</span>
<span class="ltx_bibblock">
Jonathan Herzig, Pawel Krzysztof Nowak, Thomas Mueller, Francesco Piccinno, and
Julian Eisenschlos. 2020.

</span>
<span class="ltx_bibblock">Tapas: Weakly supervised table parsing via pre-training.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 4320–4333.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hui et al. (2022)</span>
<span class="ltx_bibblock">
Binyuan Hui, Ruiying Geng, Lihan Wang, Bowen Qin, Yanyang Li, Bowen Li, Jian
Sun, and Yongbin Li. 2022.

</span>
<span class="ltx_bibblock">S2sql: Injecting syntax to question-schema interaction graph encoder
for text-to-sql parsers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics:
ACL 2022</em>, pages 1254–1262.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hwang et al. (2019)</span>
<span class="ltx_bibblock">
Wonseok Hwang, Jinyeong Yim, Seunghyun Park, and Minjoon Seo. 2019.

</span>
<span class="ltx_bibblock">A comprehensive exploration on wikisql with table-aware word
contextualization.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1902.01069</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard et al. (2022)</span>
<span class="ltx_bibblock">
Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni,
Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard
Grave. 2022.

</span>
<span class="ltx_bibblock">Few-shot learning with retrieval augmented language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2208.03299</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. (2020)</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim
Rocktäschel, et al. 2020.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:9459–9474.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2020)</span>
<span class="ltx_bibblock">
Ning Li, Bethany Keller, Mark Butler, and Daniel Cer. 2020.

</span>
<span class="ltx_bibblock">Seqgensql–a robust sequence generation model for structured query
language.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.03836</em>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2020)</span>
<span class="ltx_bibblock">
Xi Victoria Lin, Richard Socher, and Caiming Xiong. 2020.

</span>
<span class="ltx_bibblock">Bridging textual and tabular data for cross-domain text-to-sql
semantic parsing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics:
EMNLP 2020</em>, pages 4870–4888.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2022)</span>
<span class="ltx_bibblock">
Aiwei Liu, Xuming Hu, Li Lin, and Lijie Wen. 2022.

</span>
<span class="ltx_bibblock">Semantic enhanced text-to-sql parsing via iteratively learning schema
linking graph.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining</em>, pages 1021–1030.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pasupat et al. (2021)</span>
<span class="ltx_bibblock">
Panupong Pasupat, Yuan Zhang, and Kelvin Guu. 2021.

</span>
<span class="ltx_bibblock">Controllable semantic parsing via retrieval augmentation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in
Natural Language Processing</em>, pages 7683–7698.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text
transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, 21:1–67.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roller et al. (2021)</span>
<span class="ltx_bibblock">
Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu,
Jing Xu, Myle Ott, Eric Michael Smith, Y-Lan Boureau, et al. 2021.

</span>
<span class="ltx_bibblock">Recipes for building an open-domain chatbot.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th Conference of the European Chapter
of the Association for Computational Linguistics: Main Volume</em>, pages
300–325.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scholak et al. (2021)</span>
<span class="ltx_bibblock">
Torsten Scholak, Nathan Schucher, and Dzmitry Bahdanau. 2021.

</span>
<span class="ltx_bibblock">Picard: Parsing incrementally for constrained auto-regressive
decoding from language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in
Natural Language Processing</em>, pages 9895–9901.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shuster et al. (2021)</span>
<span class="ltx_bibblock">
Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. 2021.

</span>
<span class="ltx_bibblock">Retrieval augmentation reduces hallucination in conversation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics:
EMNLP 2021</em>, pages 3784–3803.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2020)</span>
<span class="ltx_bibblock">
Bailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov, and Matthew
Richardson. 2020.

</span>
<span class="ltx_bibblock">Rat-sql: Relation-aware schema encoding and linking for text-to-sql
parsers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 7567–7578.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022)</span>
<span class="ltx_bibblock">
Lihan Wang, Bowen Qin, Binyuan Hui, Bowen Li, Min Yang, Bailin Wang, Binhua Li,
Jian Sun, Fei Huang, Luo Si, et al. 2022.

</span>
<span class="ltx_bibblock">Proton: Probing schema linking information from pre-trained language
models for text-to-sql parsing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining</em>, pages 1889–1898.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al. (2020)</span>
<span class="ltx_bibblock">
Pengcheng Yin, Graham Neubig, Wen-tau Yih, and Sebastian Riedel. 2020.

</span>
<span class="ltx_bibblock">Tabert: Pretraining for joint understanding of textual and tabular
data.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.08314</em>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2018)</span>
<span class="ltx_bibblock">
Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James
Ma, Irene Li, Qingning Yao, Shanelle Roman, et al. 2018.

</span>
<span class="ltx_bibblock">Spider: A large-scale human-labeled dataset for complex and
cross-domain semantic parsing and text-to-sql task.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing</em>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zelle and Mooney (1996)</span>
<span class="ltx_bibblock">
John M Zelle and Raymond J Mooney. 1996.

</span>
<span class="ltx_bibblock">Learning to parse database queries using inductive logic programming.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the national conference on artificial
intelligence</em>, pages 1050–1055.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong et al. (2020)</span>
<span class="ltx_bibblock">
Ruiqi Zhong, Tao Yu, and Dan Klein. 2020.

</span>
<span class="ltx_bibblock">Semantic evaluation for text-to-sql with distilled test suites.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.02840</em>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong et al. (2017)</span>
<span class="ltx_bibblock">
Victor Zhong, Caiming Xiong, and Richard Socher. 2017.

</span>
<span class="ltx_bibblock">Seq2sql: Generating structured queries from natural language using
reinforcement learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>.

</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>

<figure id="A1.F5" class="ltx_figure ltx_align_center"><img src="/html/2211.06193/assets/images/iain_fk_analysis_vfinal.png" id="A1.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="895" height="376" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Spider dev: Text-to-SQL query comparing T5-Large<sup id="A1.F5.4.1" class="ltx_sup">CD</sup> and DocuT5-Large+FK<sup id="A1.F5.5.2" class="ltx_sup">CD</sup>, where regular T5 fails to infer that a JOIN was required or which foreign key to use.
The orange box is the augmented foreign key information DocuT5-Large+FK<sup id="A1.F5.6.3" class="ltx_sup">CD</sup> uses for the prediction.</figcaption>
</figure>
<figure id="A1.F6" class="ltx_figure ltx_align_center"><img src="/html/2211.06193/assets/images/iain_sd_analysis_vfinal.png" id="A1.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="880" height="285" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Spider dev: Text-to-SQL examples comparing T5-Large<sup id="A1.F6.4.1" class="ltx_sup">CD</sup> and DocuT5-Large+SD<sup id="A1.F6.5.2" class="ltx_sup">CD</sup>, where regular T5 fails due to lack of domain knowledge.
The orange box is the augmented table and column information DocuT5-Large+SD<sup id="A1.F6.6.3" class="ltx_sup">CD</sup> uses for the prediction.</figcaption>
</figure>
<figure id="A1.F7" class="ltx_figure ltx_align_center"><img src="/html/2211.06193/assets/images/docut5-sd-spider-dk.png" id="A1.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="859" height="186" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Spider-DK: Text-to-SQL examples comparing T5-Large<sup id="A1.F7.4.1" class="ltx_sup">CD</sup> and DocuT5-Large+SD<sup id="A1.F7.5.2" class="ltx_sup">CD</sup>, where regular T5 fails due to lack of domain knowledge.
The orange box is the augmented table and column information DocuT5-Large+SD<sup id="A1.F7.6.3" class="ltx_sup">CD</sup> uses for the prediction.</figcaption>
</figure>
<figure id="A1.F8" class="ltx_figure ltx_align_center"><img src="/html/2211.06193/assets/images/docut5-sd-spider-syn.png" id="A1.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="861" height="180" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Spider-SYN: Text-to-SQL examples comparing T5-Large<sup id="A1.F8.4.1" class="ltx_sup">CD</sup> and DocuT5-Large+SD<sup id="A1.F8.5.2" class="ltx_sup">CD</sup>, where regular T5 fails due to lack of domain knowledge.
The orange box is the augmented table and column information DocuT5-Large+SD<sup id="A1.F8.6.3" class="ltx_sup">CD</sup> uses for the prediction.</figcaption>
</figure>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2211.06192" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2211.06193" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2211.06193">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2211.06193" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2211.06194" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar 14 04:39:34 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
