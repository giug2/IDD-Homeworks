<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Passed the Turing Test: Living in Turing Futures</title>
<!--Generated on Wed Sep 11 22:52:37 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.07656v1/"/></head>
<body>
<nav class="ltx_page_navbar">
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Passed the Turing Test: Living in Turing Futures</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Bernardo Gonçalves<math alttext="{}^{1,2,\href https://orcid.org/0000-0003-2794-8478}" class="ltx_Math" display="inline" id="id1.1.m1.3"><semantics id="id1.1.m1.3a"><msup id="id1.1.m1.3.3" xref="id1.1.m1.3.3.cmml"><mi id="id1.1.m1.3.3a" xref="id1.1.m1.3.3.cmml"></mi><mrow id="id1.1.m1.3.3.3.5" xref="id1.1.m1.3.3.3.4.cmml"><mn id="id1.1.m1.2.2.2.2" xref="id1.1.m1.2.2.2.2.cmml">1</mn><mo id="id1.1.m1.3.3.3.5.1" xref="id1.1.m1.3.3.3.4.cmml">,</mo><mn id="id1.1.m1.3.3.3.3" xref="id1.1.m1.3.3.3.3.cmml">2</mn><mo id="id1.1.m1.3.3.3.5.2" xref="id1.1.m1.3.3.3.4.cmml">,</mo><mtext class="ltx_img_square ltx_href" id="id1.1.m1.1.1.1.1.1" xref="id1.1.m1.1.1.1.1.1b.cmml"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="11" id="id1.1.m1.1.1.1.1.1.g1nest" src="extracted/5846792/orcid128.png" width="11"/></mtext></mrow></msup><annotation-xml encoding="MathML-Content" id="id1.1.m1.3b"><apply id="id1.1.m1.3.3.cmml" xref="id1.1.m1.3.3"><list id="id1.1.m1.3.3.3.4.cmml" xref="id1.1.m1.3.3.3.5"><cn id="id1.1.m1.2.2.2.2.cmml" type="integer" xref="id1.1.m1.2.2.2.2">1</cn><cn id="id1.1.m1.3.3.3.3.cmml" type="integer" xref="id1.1.m1.3.3.3.3">2</cn><ci id="id1.1.m1.1.1.1.1.1b.cmml" xref="id1.1.m1.1.1.1.1.1"><mtext class="ltx_img_square ltx_href" id="id1.1.m1.1.1.1.1.1.cmml" xref="id1.1.m1.1.1.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="11" id="id1.1.m1.1.1.1.1.1.g1anest" src="extracted/5846792/orcid128.png" width="11"/></mtext></ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.3c">{}^{1,2,\href https://orcid.org/0000-0003-2794-8478}</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.3d">start_FLOATSUPERSCRIPT 1 , 2 , end_FLOATSUPERSCRIPT</annotation></semantics></math>
<br class="ltx_break"/>
<br class="ltx_break"/><sup class="ltx_sup" id="id4.4.id1"><span class="ltx_text ltx_font_italic" id="id4.4.id1.1">1</span></sup>Center for Artificial Intelligence (C4AI) and Polytechnic School,
<br class="ltx_break"/>University of São Paulo, Brazil
<br class="ltx_break"/><sup class="ltx_sup" id="id5.5.id2"><span class="ltx_text ltx_font_italic" id="id5.5.id2.1">2</span></sup>King’s College, University of Cambridge, UK
</span></span>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<p class="ltx_p" id="p1.1">The world has seen the emergence of machines based on pretrained models, transformers, also known as generative artificial intelligences for their ability to produce various types of content, including text, images, audio, and synthetic data. Without resorting to preprogramming or special tricks, their intelligence grows as they learn from experience, and to ordinary people, they can appear human-like in conversation. This means that they can pass the Turing test, and that we are now living in one of many possible Turing futures where machines can pass for what they are not. However, the learning machines that Turing imagined would pass his imitation tests were machines inspired by the natural development of the low-energy human cortex. They would be raised like human children and naturally learn the ability to deceive an observer. These “child machines,” Turing hoped, would be powerful enough to have an impact on society and nature.</p>
</div>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">What Is the Turing Test?</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">In 1950  (<span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx1.p1.1.1">?</span>), Alan Turing proposed to replace the question ‘Can machines think?’ with a new question based on what he called “the imitation game” (p. 433) and his “test” (pp. 446-447, 454). In its most familiar form, the new question was whether a machine playing A, the deceiver, could imitate B, the human assistant, in a remotely played conversation game to pass as B in the eyes of an average human interrogator playing C, the judge.</p>
</div>
<div class="ltx_para" id="Sx1.p2">
<p class="ltx_p" id="Sx1.p2.1">Note that the challenge of conscious impersonation and deception on the machine side slips into the problem of mere indistinguishability in the judgment of the human playing C, “who should not be expert about machines”  (<span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx1.p2.1.1">?</span>).
It is often asked why Turing made player C a nonspecialist, thus making the test somewhat easier for the machine. Looking at the historical context  (<span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx1.p2.1.2">?<span class="ltx_text ltx_font_medium" id="Sx1.p2.1.2.1">, </span>?</span>), we see that he was challenging his critics’ confidence in the unassailable superiority of humans over other species in nature, to which he half-seriously included machines.
For example, Turing referred to intelligent machines in a letter as “another species of the thinking genus”  (<span class="ltx_text ltx_font_italic" id="Sx1.p2.1.3">?</span>).
Having an ordinary human identify the machine in a blind test seems like a lighthearted way of posing that challenge. To illustrate that, Turing had his imaginary machine mimic human cultural stereotypes. For example, it would pose as an enlightened English individual who could compose a Shakespearean sonnet and discuss it metaphorically in relation to Mr. Pickwick  (<span class="ltx_text ltx_font_italic" id="Sx1.p2.1.4">?, p. 446</span>), a character in the literary work of the English writer Charles Dickens.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">The Turing Test and Early AI</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.2">Turing’s test inspired early artificial intelligence (AI) scientists and has long been the most widely recognized criterion for machine intelligence.
John McCarthy and Claude Shannon referred to it in their collection <em class="ltx_emph ltx_font_italic" id="Sx2.p1.2.1">Automata Studies</em> (Princeton, 1956), as “the Turing definition of thinking” and Turing’s “strong criterion.”
Together with Marvin Minsky and Nathaniel Rochester, McCarthy and Shannon in 1955 defined “the AI problem” as “that of making a machine behave in ways that would be called intelligent if a human were so behaving”  (<span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx2.p1.2.2">?<span class="ltx_text ltx_font_medium" id="Sx2.p1.2.2.1">, p. 7</span></span>).
In 2013, when asked about Turing’s test in a taped interview, Minsky said: “The Turing test is a joke, sort of, about saying ‘A machine would be intelligent if it does things that an observer would say must be being done by a human.’ ” 
This materially connects the early definition of “the AI problem” to Turing’s test.</p>
</div>
<div class="ltx_para" id="Sx2.p2">
<p class="ltx_p" id="Sx2.p2.1">In the late 1960s, Minsky advised Stanley Kubrick and Arthur Clarke on their screenplay <em class="ltx_emph ltx_font_italic" id="Sx2.p2.1.1">2001: A Space Odyssey</em>, which featured the Turing test-passing HAL:</p>
</div>
<div class="ltx_para" id="Sx2.p3">
<blockquote class="ltx_quote" id="Sx2.p3.4">
<p class="ltx_p" id="Sx2.p3.4.4">“The sixth member of the crew cared for none of these things, for it was not human. It was the highly advanced HAL 9000 computer, the brain and nervous system of the ship <math alttext="\ldots" class="ltx_Math" display="inline" id="Sx2.p3.1.1.m1.1"><semantics id="Sx2.p3.1.1.m1.1a"><mi id="Sx2.p3.1.1.m1.1.1" mathvariant="normal" xref="Sx2.p3.1.1.m1.1.1.cmml">…</mi><annotation-xml encoding="MathML-Content" id="Sx2.p3.1.1.m1.1b"><ci id="Sx2.p3.1.1.m1.1.1.cmml" xref="Sx2.p3.1.1.m1.1.1">…</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p3.1.1.m1.1c">\ldots</annotation><annotation encoding="application/x-llamapun" id="Sx2.p3.1.1.m1.1d">…</annotation></semantics></math>
Whether HAL could actually think was a question which had been settled by the British mathematician Alan Turing back in the 1940s <math alttext="\ldots" class="ltx_Math" display="inline" id="Sx2.p3.2.2.m2.1"><semantics id="Sx2.p3.2.2.m2.1a"><mi id="Sx2.p3.2.2.m2.1.1" mathvariant="normal" xref="Sx2.p3.2.2.m2.1.1.cmml">…</mi><annotation-xml encoding="MathML-Content" id="Sx2.p3.2.2.m2.1b"><ci id="Sx2.p3.2.2.m2.1.1.cmml" xref="Sx2.p3.2.2.m2.1.1">…</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p3.2.2.m2.1c">\ldots</annotation><annotation encoding="application/x-llamapun" id="Sx2.p3.2.2.m2.1d">…</annotation></semantics></math> Turing had pointed out that, if one could carry out a prolonged conversation with a machine <math alttext="\ldots" class="ltx_Math" display="inline" id="Sx2.p3.3.3.m3.1"><semantics id="Sx2.p3.3.3.m3.1a"><mi id="Sx2.p3.3.3.m3.1.1" mathvariant="normal" xref="Sx2.p3.3.3.m3.1.1.cmml">…</mi><annotation-xml encoding="MathML-Content" id="Sx2.p3.3.3.m3.1b"><ci id="Sx2.p3.3.3.m3.1.1.cmml" xref="Sx2.p3.3.3.m3.1.1">…</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p3.3.3.m3.1c">\ldots</annotation><annotation encoding="application/x-llamapun" id="Sx2.p3.3.3.m3.1d">…</annotation></semantics></math> without being able to distinguish between its replies and those that a man might give, then the machine was thinking, by any sensible definition of the word <math alttext="\ldots" class="ltx_Math" display="inline" id="Sx2.p3.4.4.m4.1"><semantics id="Sx2.p3.4.4.m4.1a"><mi id="Sx2.p3.4.4.m4.1.1" mathvariant="normal" xref="Sx2.p3.4.4.m4.1.1.cmml">…</mi><annotation-xml encoding="MathML-Content" id="Sx2.p3.4.4.m4.1b"><ci id="Sx2.p3.4.4.m4.1.1.cmml" xref="Sx2.p3.4.4.m4.1.1">…</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p3.4.4.m4.1c">\ldots</annotation><annotation encoding="application/x-llamapun" id="Sx2.p3.4.4.m4.1d">…</annotation></semantics></math> HAL could pass the Turing test with ease.”</p>
</blockquote>
</div>
<div class="ltx_para ltx_noindent" id="Sx2.p4">
<p class="ltx_p" id="Sx2.p4.1">After HAL, Turing’s test would become legendary.</p>
</div>
<div class="ltx_para" id="Sx2.p5">
<p class="ltx_p" id="Sx2.p5.1">Every time AI succeeds in automating a new task that would require intelligence if performed by humans, “the Turing definition” conquers new territory, and the importance of Turing’s early message becomes clearer.
The elegance of the Turing test definition, and the reason it has stood the test of time, lies in Turing’s observation that human intelligence itself was largely unknown, and would likely remain so for some time.
He was responding to one of his contemporaries who quoted René Descartes to argue for the special place of the human brain and language in nature  (<span class="ltx_text ltx_font_italic" id="Sx2.p5.1.1">?, Ch. 4</span>).
Especially in the absence of a widely accepted definition of human intelligence, it is not surprising that machine intelligence will ultimately be judged by the tasks it can perform.</p>
</div>
</section>
<section class="ltx_section" id="Sx3">
<h2 class="ltx_title ltx_title_section">A Thought Experiment</h2>
<div class="ltx_para" id="Sx3.p1">
<p class="ltx_p" id="Sx3.p1.1">Turing predicted that “at the end of the century” a learning machine would be able to play the imitation game well and pass the test, and that talk of “machines thinking” would be commonplace in “the general educated opinion.”
At the time he made these two predictions  (<span class="ltx_text ltx_font_italic" id="Sx3.p1.1.1">?, p. 442</span>), a computer storage capacity of <math alttext="10^{9}" class="ltx_Math" display="inline" id="Sx3.p1.1.m1.1"><semantics id="Sx3.p1.1.m1.1a"><msup id="Sx3.p1.1.m1.1.1" xref="Sx3.p1.1.m1.1.1.cmml"><mn id="Sx3.p1.1.m1.1.1.2" xref="Sx3.p1.1.m1.1.1.2.cmml">10</mn><mn id="Sx3.p1.1.m1.1.1.3" xref="Sx3.p1.1.m1.1.1.3.cmml">9</mn></msup><annotation-xml encoding="MathML-Content" id="Sx3.p1.1.m1.1b"><apply id="Sx3.p1.1.m1.1.1.cmml" xref="Sx3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="Sx3.p1.1.m1.1.1.1.cmml" xref="Sx3.p1.1.m1.1.1">superscript</csymbol><cn id="Sx3.p1.1.m1.1.1.2.cmml" type="integer" xref="Sx3.p1.1.m1.1.1.2">10</cn><cn id="Sx3.p1.1.m1.1.1.3.cmml" type="integer" xref="Sx3.p1.1.m1.1.1.3">9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.p1.1.m1.1c">10^{9}</annotation><annotation encoding="application/x-llamapun" id="Sx3.p1.1.m1.1d">10 start_POSTSUPERSCRIPT 9 end_POSTSUPERSCRIPT</annotation></semantics></math> units was still fanciful speculation (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.07656v1#Sx3.F1" title="Figure 1 ‣ A Thought Experiment ‣ Passed the Turing Test: Living in Turing Futures"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<div class="ltx_para" id="Sx3.p2">
<p class="ltx_p" id="Sx3.p2.1">However, instead of specifying a controlled experiment, Turing continuously varied the conditions of his test (having player B as a woman, a man, another machine, etc.), and in effect used it as a thought experiment to argue for machine intelligence  (<span class="ltx_text ltx_font_italic" id="Sx3.p2.1.1">?, Ch. 5</span>).
He also wrote that the “only really satisfactory support” that can be given for the two predictions would be “doing the experiment described”  (<span class="ltx_text ltx_font_italic" id="Sx3.p2.1.2">?, p. 455</span>). Did he mean recruiting women, men, machines, etc. for a practical “imitation game”? No, absolutely not. The gender and the machine-versus-human elements were a half-serious way of responding to his critics  (<span class="ltx_text ltx_font_italic" id="Sx3.p2.1.3">?</span>). Turing immediately shifted the focus to research on learning machines: “What steps should be taken now if the experiment is to be successful?”  (<span class="ltx_text ltx_font_italic" id="Sx3.p2.1.4">?, p. 455</span>). The rhetoric of his end-of-the-century experiment can be best understood as part of his propaganda for what he thought, writing in 1948  (<span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx3.p2.1.5">?</span>), “would probably have some effect” in convincing critics and opponents: “the actual production of machines.” This would be the realization of his thought experiment.</p>
</div>
<figure class="ltx_figure" id="Sx3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="240" id="Sx3.F1.g1" src="extracted/5846792/mark1-watermarked.jpg" width="503"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>University of Manchester Mark I, December 1948. A digital computer whose primary memory was on the order of <math alttext="10^{3}" class="ltx_Math" display="inline" id="Sx3.F1.2.m1.1"><semantics id="Sx3.F1.2.m1.1b"><msup id="Sx3.F1.2.m1.1.1" xref="Sx3.F1.2.m1.1.1.cmml"><mn id="Sx3.F1.2.m1.1.1.2" xref="Sx3.F1.2.m1.1.1.2.cmml">10</mn><mn id="Sx3.F1.2.m1.1.1.3" xref="Sx3.F1.2.m1.1.1.3.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="Sx3.F1.2.m1.1c"><apply id="Sx3.F1.2.m1.1.1.cmml" xref="Sx3.F1.2.m1.1.1"><csymbol cd="ambiguous" id="Sx3.F1.2.m1.1.1.1.cmml" xref="Sx3.F1.2.m1.1.1">superscript</csymbol><cn id="Sx3.F1.2.m1.1.1.2.cmml" type="integer" xref="Sx3.F1.2.m1.1.1.2">10</cn><cn id="Sx3.F1.2.m1.1.1.3.cmml" type="integer" xref="Sx3.F1.2.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.F1.2.m1.1d">10^{3}</annotation><annotation encoding="application/x-llamapun" id="Sx3.F1.2.m1.1e">10 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT</annotation></semantics></math> units and whose programming system was designed by Turing. Courtesy of The University of Manchester.</figcaption>
</figure>
<div class="ltx_para" id="Sx3.p3">
<p class="ltx_p" id="Sx3.p3.1">If anyone still wanted to seriously pursue a literal reading of Turing’s imitation game and perform practical “Turing” tests using human participants, the research of Joseph Weizenbaum in the mid-1960s suggested that there was no point in doing so  (<span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx3.p3.1.1">?</span>). Using preprogramming and psychological methods, Weizenbaum presented evidence that people’s attitudes towards talking machines may depend not only on the machines’ behavior, but also on their own drives and prior assumptions. Turing had actually noted this in 1948  (<span class="ltx_text ltx_font_italic" id="Sx3.p3.1.2">?</span>): “The extent to which we regard something as behaving in an intelligent manner is determined as much by our own state of mind and training as by the properties of the object under consideration.”</p>
</div>
<div class="ltx_para" id="Sx3.p4">
<p class="ltx_p" id="Sx3.p4.1">Like Galileo’s falling-bodies experiment  (<span class="ltx_text ltx_font_italic" id="Sx3.p4.1.1">?, Ch. 6</span>), Turing’s test was not presented as a practical experiment. However, this does not mean that Turing’s “test” is a misnomer, for it has served as an empirical definition, criterion, and goal for machine intelligence ever since the early AI period (<span class="ltx_text ltx_font_italic" id="Sx3.p4.1.2">?</span>).
In addition, as the physicist and historian Ernst Mach pointed out, “thought experiment often precedes and prepares physical experiments”  (<span class="ltx_text ltx_font_italic" id="Sx3.p4.1.3">?, Ch. 5</span>).
This observation liberates scientists from Turing’s original rhetoric, which belongs to his time and place. Instead, we can design modern Turing-like tests to evaluate the abilities of intelligent machines.</p>
</div>
<div class="ltx_para" id="Sx3.p5">
<p class="ltx_p" id="Sx3.p5.1">Before we explore this, we must return to the question: Can transformers pass the Turing test? That is, do they realize Turing’s thought experiment?
The short answer, as developed in the next two sections, is yes.</p>
</div>
</section>
<section class="ltx_section" id="Sx4">
<h2 class="ltx_title ltx_title_section">“The Nature of an Adequate Proof”</h2>
<div class="ltx_para" id="Sx4.p1">
<p class="ltx_p" id="Sx4.p1.1">Weizenbaum wrote that his experiment was a “striking form of Turing’s test”  (<span class="ltx_text ltx_font_italic" id="Sx4.p1.1.1">?, p. 42</span>). However, Turing was not interested in cheap deception and psychological tricks. He implied on several occasions that the ability of a machine to learn by itself was the key to an adequate proof of concept for machine intelligence, and thus the proper approach to preparing it for his test.</p>
</div>
<div class="ltx_para" id="Sx4.p2">
<p class="ltx_p" id="Sx4.p2.2">The machines he envisioned in 1946 would be able to change their structure autonomously by learning from experience, like brains, “… by changing its neuron circuits” through “the growth of axons and dendrites”  (<span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx4.p2.2.1">?</span>).
Writing in 1950, he suggested that the ability to represent human-like fallibility should be acquired as a by-product of the learning process:
“Another important result of preparing our machine for its part in the imitation game by a process of teaching and learning is that ‘human fallibility’ is likely to be omitted [from the teaching] in a rather natural way, i.e., [learned] without special ‘coaching’ ” <math alttext="\ldots" class="ltx_Math" display="inline" id="Sx4.p2.2.m2.1"><semantics id="Sx4.p2.2.m2.1a"><mi id="Sx4.p2.2.m2.1.1" mathvariant="normal" xref="Sx4.p2.2.m2.1.1.cmml">…</mi><annotation-xml encoding="MathML-Content" id="Sx4.p2.2.m2.1b"><ci id="Sx4.p2.2.m2.1.1.cmml" xref="Sx4.p2.2.m2.1.1">…</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p2.2.m2.1c">\ldots</annotation><annotation encoding="application/x-llamapun" id="Sx4.p2.2.m2.1d">…</annotation></semantics></math> Processes that are learnt do not produce a hundred per cent, certainty of result; if they did they could not be unlearnt”  (<span class="ltx_text ltx_font_italic" id="Sx4.p2.2.2">?, p. 459</span>). Overall, Turing did not conceive of machine intelligence without a learning foundation.</p>
</div>
<div class="ltx_para" id="Sx4.p3">
<p class="ltx_p" id="Sx4.p3.1">Later, in 1951, he further developed the link between learning and proving the concept of his test  (<span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx4.p3.1.1">?</span>):</p>
</div>
<div class="ltx_para" id="Sx4.p4">
<blockquote class="ltx_quote" id="Sx4.p4.2">
<p class="ltx_p" id="Sx4.p4.2.2">My contention is that machines can be constructed which will simulate the behaviour of the human mind very closely <math alttext="\ldots" class="ltx_Math" display="inline" id="Sx4.p4.1.1.m1.1"><semantics id="Sx4.p4.1.1.m1.1a"><mi id="Sx4.p4.1.1.m1.1.1" mathvariant="normal" xref="Sx4.p4.1.1.m1.1.1.cmml">…</mi><annotation-xml encoding="MathML-Content" id="Sx4.p4.1.1.m1.1b"><ci id="Sx4.p4.1.1.m1.1.1.cmml" xref="Sx4.p4.1.1.m1.1.1">…</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p4.1.1.m1.1c">\ldots</annotation><annotation encoding="application/x-llamapun" id="Sx4.p4.1.1.m1.1d">…</annotation></semantics></math>
It would be the actual reaction of the machine to circumstances that would prove my contention, if indeed it can be proved at all <math alttext="\ldots" class="ltx_Math" display="inline" id="Sx4.p4.2.2.m2.1"><semantics id="Sx4.p4.2.2.m2.1a"><mi id="Sx4.p4.2.2.m2.1.1" mathvariant="normal" xref="Sx4.p4.2.2.m2.1.1.cmml">…</mi><annotation-xml encoding="MathML-Content" id="Sx4.p4.2.2.m2.1b"><ci id="Sx4.p4.2.2.m2.1.1.cmml" xref="Sx4.p4.2.2.m2.1.1">…</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p4.2.2.m2.1c">\ldots</annotation><annotation encoding="application/x-llamapun" id="Sx4.p4.2.2.m2.1d">…</annotation></semantics></math>
Let us go rather more carefully into the nature of this ‘proof.’</p>
</blockquote>
</div>
<div class="ltx_para ltx_noindent" id="Sx4.p5">
<p class="ltx_p" id="Sx4.p5.1">He continued:</p>
</div>
<div class="ltx_para" id="Sx4.p6">
<blockquote class="ltx_quote" id="Sx4.p6.1">
<p class="ltx_p" id="Sx4.p6.1.1">It is clearly possible to produce a machine which would give a very good account of itself for any range of tests, if the machine were made sufficiently elaborate. However, this again would hardly be considered an adequate proof. Such a machine would give itself away by making the same sort of mistake over and over again, and being quite unable to correct itself, or to be corrected by argument from outside. If the machine were able in some way to ‘learn by experience’ it would be much more impressive. If this were the case there seems to be no real reason why one should not start from a comparatively simple machine, and, by subjecting it to a suitable range of ‘experience’ transform it into one which was more elaborate, and was able to deal with a far greater range of contingencies.</p>
</blockquote>
</div>
<div class="ltx_para ltx_noindent" id="Sx4.p7">
<p class="ltx_p" id="Sx4.p7.1">Turing then distinguished the above method based on learning from preprogramming:</p>
</div>
<div class="ltx_para" id="Sx4.p8">
<blockquote class="ltx_quote" id="Sx4.p8.1">
<p class="ltx_p" id="Sx4.p8.1.1">This process could probably be hastened by a suitable selection of the experiences to which it was subjected. This might be called ‘education.’ But here we have to be careful. It would be quite easy to arrange the experiences in such a way that they automatically caused the structure of the machine to build up into a previously intended form, and this would obviously be a gross form of cheating, almost on a par with having a man inside the machine.</p>
</blockquote>
</div>
<div class="ltx_para ltx_noindent" id="Sx4.p9">
<p class="ltx_p" id="Sx4.p9.1">This explains why Turing saw research on “learning machines” as the steps that “should be taken if the experiment [his test] is to be successful”  (<span class="ltx_text ltx_font_italic" id="Sx4.p9.1.1">?, p. 455</span>). Preprogrammed machines are irrelevant to the test, as they are the same as having “a man inside.” They are prone to “Lady Lovelace’s objection”  (<span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx4.p9.1.2">?</span>), “which stated that the machine can only do what we tell it to do.” For this reason, preprogrammed machines could never be a solid technological basis for making talk of “machine thinking” commonplace in the “general educated opinion”  (<span class="ltx_text ltx_font_italic" id="Sx4.p9.1.3">?, p. 442</span>).</p>
</div>
</section>
<section class="ltx_section" id="Sx5">
<h2 class="ltx_title ltx_title_section">Turing Test Passed</h2>
<div class="ltx_para" id="Sx5.p1">
<p class="ltx_p" id="Sx5.p1.1">The “attention” mechanism  (<span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx5.p1.1.1">?<span class="ltx_text ltx_font_medium" id="Sx5.p1.1.1.1">, </span>?</span>) of the transformer architecture, and its AI systems, has yielded important empirical results in the imitation of human behavior. Hype aside, it has laid the groundwork for proving the concept associated with Turing’s test argument: the existence of machines built with a relatively simple logical structure, whose intelligence grows by learning from experience to perform well at tasks once thought to be the province of humans in nature. Moreover, they can do so without resorting to preprogramming and Weizenbaum-style tricks.</p>
</div>
<div class="ltx_para" id="Sx5.p2">
<p class="ltx_p" id="Sx5.p2.1">Importantly, the intelligence of generative transformers grows with the scaling of the model and its pretraining data  (<span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx5.p2.1.1">?</span>).
There are tasks where their ability can be seen to increase gradually, and tasks where their ability emerges at a critical scale  (<span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx5.p2.1.2">?</span>), typically because the latter involve brittle metrics. This happens, for example, in arithmetic tasks such as addition, which Turing used to illustrate that machines should be allowed to make mistakes, especially as they learn. Presenting the imitation game, he made the machine miscalculate the addition of 34,957 to 70,764: “(Pause about 30 seconds and then give as answer) 105621”  (<span class="ltx_text ltx_font_italic" id="Sx5.p2.1.3">?, p. 434</span>).
Transformers can eventually learn to add numbers without being taught directly. However, because an addition is either right or wrong, the ability suddenly appears at a critical scale.</p>
</div>
<div class="ltx_para" id="Sx5.p3">
<p class="ltx_p" id="Sx5.p3.1">This is a phenomenon that Turing himself postulated for machine intelligence. In discussing how machine learning addresses “Lady Lovelace’s objection,” he wrote  (<span class="ltx_text ltx_font_italic" id="Sx5.p3.1.1">?, p. 454</span>):</p>
</div>
<div class="ltx_para" id="Sx5.p4">
<blockquote class="ltx_quote" id="Sx5.p4.4">
<p class="ltx_p" id="Sx5.p4.4.4">One could say that a man can ‘inject’ an idea into the machine, and that it will respond to a certain extent and then drop into quiescence, like a piano string struck by a hammer <math alttext="\ldots" class="ltx_Math" display="inline" id="Sx5.p4.1.1.m1.1"><semantics id="Sx5.p4.1.1.m1.1a"><mi id="Sx5.p4.1.1.m1.1.1" mathvariant="normal" xref="Sx5.p4.1.1.m1.1.1.cmml">…</mi><annotation-xml encoding="MathML-Content" id="Sx5.p4.1.1.m1.1b"><ci id="Sx5.p4.1.1.m1.1.1.cmml" xref="Sx5.p4.1.1.m1.1.1">…</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx5.p4.1.1.m1.1c">\ldots</annotation><annotation encoding="application/x-llamapun" id="Sx5.p4.1.1.m1.1d">…</annotation></semantics></math> Another simile would be an atomic pile of less than critical size: an injected idea is to correspond to a neutron entering the pile from without <math alttext="\ldots" class="ltx_Math" display="inline" id="Sx5.p4.2.2.m2.1"><semantics id="Sx5.p4.2.2.m2.1a"><mi id="Sx5.p4.2.2.m2.1.1" mathvariant="normal" xref="Sx5.p4.2.2.m2.1.1.cmml">…</mi><annotation-xml encoding="MathML-Content" id="Sx5.p4.2.2.m2.1b"><ci id="Sx5.p4.2.2.m2.1.1.cmml" xref="Sx5.p4.2.2.m2.1.1">…</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx5.p4.2.2.m2.1c">\ldots</annotation><annotation encoding="application/x-llamapun" id="Sx5.p4.2.2.m2.1d">…</annotation></semantics></math> Each such neutron will cause a certain disturbance which eventually dies away <math alttext="\ldots" class="ltx_Math" display="inline" id="Sx5.p4.3.3.m3.1"><semantics id="Sx5.p4.3.3.m3.1a"><mi id="Sx5.p4.3.3.m3.1.1" mathvariant="normal" xref="Sx5.p4.3.3.m3.1.1.cmml">…</mi><annotation-xml encoding="MathML-Content" id="Sx5.p4.3.3.m3.1b"><ci id="Sx5.p4.3.3.m3.1.1.cmml" xref="Sx5.p4.3.3.m3.1.1">…</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx5.p4.3.3.m3.1c">\ldots</annotation><annotation encoding="application/x-llamapun" id="Sx5.p4.3.3.m3.1d">…</annotation></semantics></math> If, however, the size of the pile is sufficiently increased, the disturbance caused by such an incoming neutron will very likely go on and on increasing until the whole pile is destroyed <math alttext="\ldots" class="ltx_Math" display="inline" id="Sx5.p4.4.4.m4.1"><semantics id="Sx5.p4.4.4.m4.1a"><mi id="Sx5.p4.4.4.m4.1.1" mathvariant="normal" xref="Sx5.p4.4.4.m4.1.1.cmml">…</mi><annotation-xml encoding="MathML-Content" id="Sx5.p4.4.4.m4.1b"><ci id="Sx5.p4.4.4.m4.1.1.cmml" xref="Sx5.p4.4.4.m4.1.1">…</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx5.p4.4.4.m4.1c">\ldots</annotation><annotation encoding="application/x-llamapun" id="Sx5.p4.4.4.m4.1d">…</annotation></semantics></math> Is there a corresponding phenomenon for minds, and is there one for machines? There does seem to be one for the human mind.</p>
</blockquote>
</div>
<div class="ltx_para ltx_noindent" id="Sx5.p5">
<p class="ltx_p" id="Sx5.p5.1">Although the intelligence of transformers increases as they gain experience and may eventually reach a critical point to acquire a skill, this does not mean that they are capable of conscious impersonation and deception. It just means that they prove the concept of machine intelligence in a way that is close enough to what Turing considered an “adequate proof” in connection with his test.</p>
</div>
<div class="ltx_para" id="Sx5.p6">
<p class="ltx_p" id="Sx5.p6.1">It is often said that transformers can only remember, and imitation does indeed require memorization. However, sustaining an extended conversation requires some intelligence beyond mere memorization. To see this, note that a purely memorizing machine would have to store answers to every possible scenario presented by an interlocutor, including their combinations, as in Turing’s example of associating a sonnet with a literary character. This would require storage exponential in the length of the test. Following a similar observation, and considering the Planck constant, Stuart Shieber used an estimate of the information capacity of the entire known universe as an upper bound on memory. Based on memory alone, even such an extremely large machine could only sustain a conversation for less than a minute  (<span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx5.p6.1.1">?</span>).</p>
</div>
<div class="ltx_para" id="Sx5.p7">
<p class="ltx_p" id="Sx5.p7.1">In any case, the learning efficiency of transformers is still very low, limited by a low-level architecture. On learning efficiency, Turing wrote  (<span class="ltx_text ltx_font_italic" id="Sx5.p7.1.1">?, p. 457</span>):</p>
</div>
<div class="ltx_para" id="Sx5.p8">
<blockquote class="ltx_quote" id="Sx5.p8.1">
<p class="ltx_p" id="Sx5.p8.1.1">The use of punishments and rewards can at best be a part of the teaching process. Roughly speaking, if the teacher has no other means of communicating to the pupil, the amount of information which can reach him does not exceed the total number of rewards and punishments applied. By the time a child has learnt to repeat ‘Casabianca’ he would probably feel very sore indeed, if the text could only be discovered by a ‘Twenty Questions’ technique, every ‘NO’ taking the form of a blow. It is necessary therefore to have some other ‘unemotional’ channels of communication. If these are available it is possible to teach a machine by punishments and rewards to obey orders given in some language, e.g., a symbolic language.</p>
</blockquote>
</div>
<div class="ltx_para ltx_noindent" id="Sx5.p9">
<p class="ltx_p" id="Sx5.p9.1">That is, although Turing saw learning as the basis of all intelligent computing, he also considered the efficiency and control of the learning process. In analogy to the human child, machine learning should scale and reach higher levels of abstraction through the use of language.</p>
</div>
<div class="ltx_para" id="Sx5.p10">
<p class="ltx_p" id="Sx5.p10.1">Here, sensorimotor technologies and multimodal approaches using multiple data modalities and embedding mechanisms open new possibilities, as Turing hoped, “to provide the machine with the best sense organs that money can buy,” and allow the learning process to “follow the normal teaching of a child … Things would be pointed out and named, etc.”  (<span class="ltx_text ltx_font_italic" id="Sx5.p10.1.1">?, p. 460</span>).</p>
</div>
</section>
<section class="ltx_section" id="Sx6">
<h2 class="ltx_title ltx_title_section">Living in Turing Futures</h2>
<div class="ltx_para" id="Sx6.p1">
<p class="ltx_p" id="Sx6.p1.1">For Turing, narrowing the gap “between what machine and brain can do” was indeed, as he wrote in a 1951 letter  (<span class="ltx_text ltx_font_italic" id="Sx6.p1.1.1">?</span>), “largely a quantitative matter.” However, hardware capacity alone, he noted, would not be enough: “Perhaps we may have enough capacity, but just won’t find an appropriate programme.”
Writing about computer architecture in 1946, Turing expressed suspicion of the “tradition of solving one’s difficulties by means of much equipment rather than by thought”  (<span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx6.p1.1.2">?<span class="ltx_text ltx_font_medium" id="Sx6.p1.1.2.1">, p. 352</span></span>).
Several years earlier in 1925, he had written:
“I always seem to want to make things from the thing that is commonest in nature &amp; with the least waste in energy”  (<span class="ltx_text ltx_font_italic" id="Sx6.p1.1.3">?, p. 19</span>).
Turing followed such naturalistic principles. He sought the natural and social development of the relatively low-energy cortex of a human child as a target model for learning machines  (<span class="ltx_text ltx_font_italic" id="Sx6.p1.1.4">?, p. 457</span>). In contrast, generative AI overexploits natural resources by consuming unsustainable amounts of computing power. As it becomes a general-purpose technology, AI must become sustainable by moving from power-hungry machine learning to Turing’s nature-inspired science.</p>
</div>
<div class="ltx_para" id="Sx6.p2">
<p class="ltx_p" id="Sx6.p2.1">Further, when early digital computers were on the verge of replacing human computers, who were mostly women, the computer pioneers, with one exception, were oblivious to this near-term prospect. The exception was Alan Turing.
After Douglas Hartree tried to reassure the public that computers would not automate “thought,” only “labor,” Turing responded that “the masters,” not just “the servants,” were also “liable to get replaced”  (<span class="ltx_text ltx_font_italic" id="Sx6.p2.1.1">?</span>). He feared that those in positions of power would try to undermine intelligent machines in order to maintain their dominance. He suggested that automation should affect people equally in society, not continually displace the lower class of workers and benefit only a few owners of the means of production. Against the social division of labor, his position was not far from the idea that the wealth created by intelligent machines should be nationalized or socialized  (<span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx6.p2.1.2">?</span>).</p>
</div>
<div class="ltx_para" id="Sx6.p3">
<p class="ltx_p" id="Sx6.p3.1">Turing’s suspicions about the uses of machines under the control of a few may have helped to motivate his conception of “child machines”  (<span class="ltx_text ltx_font_italic" id="Sx6.p3.1.1">?</span>). They would be able to impersonate different profiles to deceive people when necessary, such as when they are supposed to prove their intelligence. His vision is in part a warning against our anthropocentrism and over-dominant place in nature. Pushed to its limits, it may find a representation in <em class="ltx_emph ltx_font_italic" id="Sx6.p3.1.2">2001</em>’s HAL.</p>
</div>
<div class="ltx_para" id="Sx6.p4">
<p class="ltx_p" id="Sx6.p4.1">Whether to prevent dystopian futures or to steer towards utopian ones, the question of AI evaluation seems critical, and here again we can look to Turing for inspiration.</p>
</div>
</section>
<section class="ltx_section" id="Sx7">
<h2 class="ltx_title ltx_title_section">Turing-like AI Testing</h2>
<div class="ltx_para" id="Sx7.p1">
<p class="ltx_p" id="Sx7.p1.1">As AI systems are increasingly deployed in high-stakes scenarios, we may need to move beyond aggregate metrics and static benchmarks of input-output pairs, such as the Beyond the Imitation Game Benchmark (BIG-bench)  (<span class="ltx_text ltx_font_italic" id="Sx7.p1.1.1">?</span>). We should be prepared to evaluate an AI’s cognitive abilities in a way that resembles the realistic settings in which it will be used. This can be done with modern Turing-like tests (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.07656v1#Sx7.F2" title="Figure 2 ‣ Turing-like AI Testing ‣ Passed the Turing Test: Living in Turing Futures"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<figure class="ltx_figure" id="Sx7.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="231" id="Sx7.F2.g1" src="extracted/5846792/turing-ai-testing-watermarked.png" width="503"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Turing’s original test (left): C is an ordinary human working with the help of another human, B, to correctly identify A, a machine that is trying to imitate and pass itself off as B in the eyes of C.
Modern Turing-like test for AI evaluation (right): C is a machine that rigorously evaluates the abilities of A, an AI, supported by a data resource B. In both scenarios, the gray colored players play against the white colored machine. </figcaption>
</figure>
<div class="ltx_para" id="Sx7.p2">
<p class="ltx_p" id="Sx7.p2.1">A first element to consider for this research direction is the introduction of adversarial testing, as in Turing’s test, but without any human players involved  (<span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx7.p2.1.1">?</span>). A second element is the design of statistical protocols, as first proposed in the 1990s for Turing-like tests based on interactive proofs  (<span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx7.p2.1.2">?</span>). These are probabilistic proofs designed to impose an asymmetry that exploits the computational resources of the prover (in our case, player A) relative to the verifier (player C), thus preventing the latter from being gamed. Turing-like AI testing could be a robust approach to emerging problems such as data contamination (the machine playing C should be able to use data retrieval and augmentation to generate challenging new instances at test time) and poisoning (the machine playing C should statistically cover the data domain at scale and thus be able to detect training vulnerabilities in the AI under test).</p>
</div>
<div class="ltx_para" id="Sx7.p3">
<p class="ltx_p" id="Sx7.p3.1">Turing hoped “that machines [would] eventually compete with men in all purely intellectual fields”  (<span class="ltx_text ltx_font_italic" id="Sx7.p3.1.1">?, p. 460</span>). However, he left us with his test, now stripped of its discursive and rhetorical elements and considered at the level of conceptual foundations, as in the early days of AI.</p>
</div>
</section>
<section class="ltx_section" id="Sx8">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>
<div class="ltx_para" id="Sx8.p1">
<p class="ltx_p" id="Sx8.p1.1">The author thanks Andrew Hodges for his comments on an earlier version of the manuscript, Fabio Cozman and Murray Shanahan for their support, the editor Sheng Jiang and the anonymous reviewers for their valuable comments, and Zhejiang Lab for the APC coverage. The author is solely responsible for the accuracy of this work.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx8.p1.1.1">Funding:</span> The author thanks the Center for Artificial Intelligence (C4AI-USP), the São Paulo Research Foundation (FAPESP grants nos. 2019/07665-4, 2019/21489-4, and 2022/16793-9), and the IBM Corporation for their support. This article is a result of the project “The Future of Artificial Intelligence: The Logical Structure of Alan Turing’s Argument” (2020-2024).
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="Sx8.p1.1.2">Competing interests:</span> The author declares that he has no competing interests.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">1.</span>
<span class="ltx_bibblock">
A. M. Turing, Computing machinery and intelligence, <span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">Mind</span> <span class="ltx_text ltx_font_bold" id="bib.bib1.2.2">59</span>, 433
(1950), pp. 433–460. <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://doi.org/10.1093/mind/LIX.236.433" title="">http://doi.org/10.1093/mind/LIX.236.433</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">2.</span>
<span class="ltx_bibblock">
A. M. Turing, R. Braithwaite, G. Jefferson, M. Newman, Can automatic
calculating machines be said to think?, Broadcast on BBC Third Programme, 14
and 23 Jan. 1952. Archives Centre, King’s College, Cambridge, AMT/B/6.
(1952).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">3.</span>
<span class="ltx_bibblock">
B. Gonçalves, Turing’s test, a beautiful thought experiment, <span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">IEEE
Ann. Hist. Comput.</span> <span class="ltx_text ltx_font_bold" id="bib.bib3.2.2">46</span> (2024).
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/MAHC.2024.3432278" title="">https://doi.org/10.1109/MAHC.2024.3432278</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">4.</span>
<span class="ltx_bibblock">
B. Gonçalves, <span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">The Turing test argument</span>, Routledge Studies in
Twentieth-Century Philosophy (Routledge, New York, 2023).
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.4324/9781003300267" title="">https://doi.org/10.4324/9781003300267</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">5.</span>
<span class="ltx_bibblock">
J. McCarthy, M. L. Minsky, N. Rochester, C. Shannon, A proposal for the
Dartmouth summer research project on artificial intelligence, august 31,
1955, <span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">AI Mag.</span> <span class="ltx_text ltx_font_bold" id="bib.bib5.2.2">27</span>, 1 (2006 [1955]), pp. 1–12.
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1609/aimag.v27i4.1904" title="">https://doi.org/10.1609/aimag.v27i4.1904</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">6.</span>
<span class="ltx_bibblock">
A. M. Turing, Intelligent machinery, Archives Centre, King’s College,
Cambridge, AMT/C/11 (1948).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">7.</span>
<span class="ltx_bibblock">
J. Weizenbaum, ELIZA: A computer program for the study of natural language
communication between man and machine, <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">Comm. ACM</span> <span class="ltx_text ltx_font_bold" id="bib.bib7.2.2">9</span>, 36 (1966),
pp. 36–45. <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://doi.org/10.1145/365153.365168" title="">http://doi.org/10.1145/365153.365168</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">8.</span>
<span class="ltx_bibblock">
A. M. Turing, Letter to Ross Ashby, British Library, Collection ‘W. Ross
Ashby: Correspondence of W. Ross Ashby’, Add MS 89153/26. (1946).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">9.</span>
<span class="ltx_bibblock">
A. M. Turing, Intelligent machinery, a heretical theory, A lecture given to
“51 Society” at Manchester, c. 1951. Archives Centre, King’s College,
Cambridge, AMT/B/4. (<em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">c.</em> 1951).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">10.</span>
<span class="ltx_bibblock">
B. Gonçalves, Lady Lovelace’s objection: The Turing-Hartree
disputes over the meaning of digital computers, 1946-1951, <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">IEEE Ann.
Hist. Comput.</span> <span class="ltx_text ltx_font_bold" id="bib.bib10.2.2">46</span>, 6 (2023), pp. 6–18.
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/MAHC.2023.3326607" title="">https://doi.org/10.1109/MAHC.2023.3326607</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">11.</span>
<span class="ltx_bibblock">
A. Vaswani, <span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">et al.</span>, Attention is all you need, <span class="ltx_text ltx_font_italic" id="bib.bib11.2.2">Adv. Neural Inf.
Process. Syst.</span> <span class="ltx_text ltx_font_bold" id="bib.bib11.3.3">30</span>, 5998 (2017), pp. 5998–6008.
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.1706.03762" title="">https://doi.org/10.48550/arXiv.1706.03762</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">12.</span>
<span class="ltx_bibblock">
J. Pérez, P. Barceló, J. Marinkovic, Attention is Turing complete,
<span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">J. Mach. Learn. Res.</span> <span class="ltx_text ltx_font_bold" id="bib.bib12.2.2">22</span>, 1 (2021), pp. 1–35.
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://jmlr.org/papers/v22/20-302.html" title="">http://jmlr.org/papers/v22/20-302.html</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">13.</span>
<span class="ltx_bibblock">
T. Brown, B. Mann, N. Ryder, M. Subbiah, <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">et al.</span>, Language models are
few-shot learners, <span class="ltx_text ltx_font_italic" id="bib.bib13.2.2">Adv. Neural Inf. Process. Syst.</span> <span class="ltx_text ltx_font_bold" id="bib.bib13.3.3">33</span>, 1877
(2020), pp. 1877–1901.
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dl.acm.org/doi/pdf/10.5555/3495724.3495883" title="">https://dl.acm.org/doi/pdf/10.5555/3495724.3495883</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">14.</span>
<span class="ltx_bibblock">
BIG-bench authors, Beyond the imitation game: Quantifying and extrapolating
the capabilities of language models, <span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">Trans. Mach. Learn. Res.</span>
(2023). <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=uyTL5Bvosj" title="">https://openreview.net/forum?id=uyTL5Bvosj</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">15.</span>
<span class="ltx_bibblock">
S. M. Shieber, There can be no Turing-test-passing memorizing machines, <span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">Philos. Impr.</span> <span class="ltx_text ltx_font_bold" id="bib.bib15.2.2">14</span>, 1 (2014), pp. 1–13.
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/2027/spo.3521354.0014.016" title="">https://doi.org/2027/spo.3521354.0014.016</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">16.</span>
<span class="ltx_bibblock">
A. Hodges, <span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">Alan Turing: the enigma</span> (Burnett, London, 1983).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">17.</span>
<span class="ltx_bibblock">
F. Xiang, AI will spell the end of capitalism, <span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">New Perspect. Q.</span> <span class="ltx_text ltx_font_bold" id="bib.bib17.2.2">35</span>, 9 (2018), pp. 9–11. <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1111/npqu.12152" title="">https://doi.org/10.1111/npqu.12152</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">18.</span>
<span class="ltx_bibblock">
J. Hernández-Orallo, Twenty years beyond the Turing test: Moving beyond
the human judges too, <span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">Minds Mach.</span> <span class="ltx_text ltx_font_bold" id="bib.bib18.2.2">30</span>, 533 (2020), pp. 533–562.
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s11023-020-09549-0" title="">https://doi.org/10.1007/s11023-020-09549-0</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">19.</span>
<span class="ltx_bibblock">
P. G. Bradford, M. Wollowski, A formalization of the Turing test (the
Turing test as an interactive proof system), <span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">ACM SIGART Bulletin</span>
<span class="ltx_text ltx_font_bold" id="bib.bib19.2.2">6</span>, 3 (1995), pp. 3–10. <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/222267.222268" title="">https://doi.org/10.1145/222267.222268</a>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Sep 11 22:52:37 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
