<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>A Reproducible Analysis of Sequential Recommender Systems</title>
<!--Generated on Wed Aug  7 16:17:13 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Recommendation,  Sequential Recommendation,  Reproducibility,  Replicability,  Resource" lang="en" name="keywords"/>
<base href="/html/2408.03873v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S1" title="In A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S2" title="In A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S2.SS1" title="In 2. Related Work ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Sequential Recommender Systems</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S2.SS2" title="In 2. Related Work ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Reproducibility in SRSs</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S3" title="In A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Background</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S3.SS0.SSS0.Px1" title="In 3. Background ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title">Input sequence length</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S3.SS0.SSS0.Px2" title="In 3. Background ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title">Item Embedding</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S4" title="In A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Implementation Framework and Experimental Setup</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S4.SS1" title="In 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Resource</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S4.SS1.SSS0.Px1" title="In 4.1. Resource ‣ 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title">Reproducibility</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S4.SS1.SSS0.Px2" title="In 4.1. Resource ‣ 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title">Extensibility</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S4.SS1.SSS0.Px3" title="In 4.1. Resource ‣ 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title">Model implementations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S4.SS1.SSS0.Px4" title="In 4.1. Resource ‣ 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title">Running experiments</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S4.SS2" title="In 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Datasets</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S4.SS2.SSS0.Px1" title="In 4.2. Datasets ‣ 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title">Data pre-processing</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S4.SS3" title="In 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Models</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S4.SS3.SSS0.Px1" title="In 4.3. Models ‣ 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title">Training</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S4.SS4" title="In 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Metrics</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S4.SS4.SSS0.Px1" title="In 4.4. Metrics ‣ 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title">Tracking Emissions</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S4.SS5" title="In 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Comparisons</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S5" title="In A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S6" title="In A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">A Reproducible Analysis of Sequential Recommender Systems</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Filippo Betello
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:betello@diag.uniroma1.it">betello@diag.uniroma1.it</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0006-0945-9688" title="ORCID identifier">0009-0006-0945-9688</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Sapienza University of Rome</span><span class="ltx_text ltx_affiliation_city" id="id2.2.id2">Rome</span><span class="ltx_text ltx_affiliation_country" id="id3.3.id3">Italy</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Antonio Purificato
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:purificato@diag.uniroma1.it">purificato@diag.uniroma1.it</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0006-0945-9688" title="ORCID identifier">0009-0006-0945-9688</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id4.1.id1">Sapienza University of Rome</span><span class="ltx_text ltx_affiliation_city" id="id5.2.id2">Rome</span><span class="ltx_text ltx_affiliation_country" id="id6.3.id3">Italy</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Federico Siciliano
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:siciliano@diag.uniroma1.it">siciliano@diag.uniroma1.it</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0003-1339-6983" title="ORCID identifier">0000-0003-1339-6983</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id7.1.id1">Sapienza University of Rome</span><span class="ltx_text ltx_affiliation_city" id="id8.2.id2">Rome</span><span class="ltx_text ltx_affiliation_country" id="id9.3.id3">Italy</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Giovanni Trappolini
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:trappolini@diag.uniroma1.it">trappolini@diag.uniroma1.it</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-5515-634X" title="ORCID identifier">0000-0002-5515-634X</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id10.1.id1">Sapienza University of Rome</span><span class="ltx_text ltx_affiliation_city" id="id11.2.id2">Rome</span><span class="ltx_text ltx_affiliation_country" id="id12.3.id3">Italy</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Andrea Bacciu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:bacciu@diag.uniroma1.it">bacciu@diag.uniroma1.it</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0007-1322-343X" title="ORCID identifier">0009-0007-1322-343X</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id13.1.id1">Sapienza University of Rome</span><span class="ltx_text ltx_affiliation_city" id="id14.2.id2">Rome</span><span class="ltx_text ltx_affiliation_country" id="id15.3.id3">Italy</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nicola Tonellotto
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:nicola.tonellotto@unipi.it">nicola.tonellotto@unipi.it</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-7427-1001" title="ORCID identifier">0000-0002-7427-1001</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id16.1.id1">University of Pisa</span><span class="ltx_text ltx_affiliation_city" id="id17.2.id2">Pisa</span><span class="ltx_text ltx_affiliation_country" id="id18.3.id3">Italy</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Fabrizio Silvestri
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:fsilvestri@diag.uniroma1.it">fsilvestri@diag.uniroma1.it</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0001-7669-9055" title="ORCID identifier">0000-0001-7669-9055</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id19.1.id1">Sapienza University of Rome</span><span class="ltx_text ltx_affiliation_city" id="id20.2.id2">Rome</span><span class="ltx_text ltx_affiliation_country" id="id21.3.id3">Italy</span>
</span></span></span>
</div>
<div class="ltx_dates">(2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id22.id1">Sequential Recommender Systems (SRSs) have emerged as a highly efficient approach to recommendation systems. By leveraging sequential data, SRSs can identify temporal patterns in user behaviour, significantly improving recommendation accuracy and relevance.
Ensuring the reproducibility of these models is paramount for advancing research and facilitating comparisons between them. Existing works exhibit shortcomings in reproducibility and replicability of results, leading to inconsistent statements across papers.
Our work fills these gaps by standardising data pre-processing and model implementations, providing a comprehensive code resource, including a framework for developing SRSs and establishing a foundation for consistent and reproducible experimentation.
We conduct extensive experiments on several benchmark datasets, comparing various SRSs implemented in our resource.
We challenge prevailing performance benchmarks, offering new insights into the SR domain. For instance, SASRec does not consistently outperform GRU4Rec.
On the contrary, when the number of model parameters becomes substantial, SASRec starts to clearly dominate all the other SRSs.
This discrepancy underscores the significant impact that experimental configuration has on the outcomes and the importance of setting it up to ensure precise and comprehensive results.
Failure to do so can lead to significantly flawed conclusions, highlighting the need for rigorous experimental design and analysis in SRS research.
Our code is available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/antoniopurificato/recsys_repro_conf" title="">https://github.com/antoniopurificato/recsys_repro_conf</a>.</p>
</div>
<div class="ltx_keywords">Recommendation, Sequential Recommendation, Reproducibility, Replicability, Resource
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>; ; </span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_submissionid" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">submissionid: </span>397</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id6"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Recommender systems</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id7"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Neural networks</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id8"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Open source software</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recommender Systems (RSs) have been pivotal in enhancing user experience for many years by providing personalized recommendations across numerous online platforms <cite class="ltx_cite ltx_citemacro_citep">(Smith and Linden, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib34" title="">2017</a>)</cite>.
Among these, Sequential Recommender Systems (SRSs) have received significant attention for their ability to consider the temporal dynamics inherent in user preferences to predict the next item a user will engage with <cite class="ltx_cite ltx_citemacro_citep">(Quadrana et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib31" title="">2018</a>)</cite>.
Initially, SRSs used Markov chains to model user behaviour <cite class="ltx_cite ltx_citemacro_citep">(Rendle et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib32" title="">2010</a>)</cite>, but faced challenges in capturing complex dependencies in extended user sequences <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib40" title="">2019</a>)</cite>. The emergence of neural networks, especially recurrent structures <cite class="ltx_cite ltx_citemacro_citep">(Cho et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib5" title="">2014</a>; Hidasi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib16" title="">2016</a>)</cite>, marked a significant shift in this paradigm. Furthermore, the recent successes of transformer models <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib38" title="">2017</a>)</cite> have inspired the development of novel SRS architectures <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib35" title="">2019</a>; Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib19" title="">2018</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Despite these advancements, the reproducibility<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We refer to the definition of <span class="ltx_text ltx_font_italic" id="footnote1.1">reproducibility</span> of the ACM Artifact Review and Badging, version 1.1, available online at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.acm.org/publications/policies/artifact-review-and-badging-current" title="">https://www.acm.org/publications/policies/artifact-review-and-badging-current</a>.</span></span></span> of these models remains an open problem <cite class="ltx_cite ltx_citemacro_citep">(Ferrari Dacrema et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib10" title="">2019</a>; Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib36" title="">2020</a>)</cite>.
This issue is caused by several factors, mainly the lack of standardised benchmarks, uniform data pre-processing methods and consistent model implementations <cite class="ltx_cite ltx_citemacro_citep">(Ferrari Dacrema et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib11" title="">2020</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib9" title="">2021</a>; Cremonesi and Jannach, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib7" title="">2021</a>)</cite>, which exacerbate the problem of reproducibility. Researchers frequently adopt different configurations, including various choices of hyperparameters and evaluation metrics <cite class="ltx_cite ltx_citemacro_citep">(Hidasi and Czapp, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib14" title="">2023a</a>; Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib36" title="">2020</a>; Cremonesi and Jannach, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib7" title="">2021</a>)</cite>.
The variability of data processing methodologies across studies prevents direct comparability of results <cite class="ltx_cite ltx_citemacro_citep">(Hidasi and Czapp, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib15" title="">2023b</a>)</cite>.
Differences in model implementations make it difficult to conduct a reliable and comparable evaluation of SRSs <cite class="ltx_cite ltx_citemacro_citep">(Hidasi and Czapp, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib14" title="">2023a</a>; Petrov and Macdonald, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib30" title="">2022</a>)</cite>.
Finally, models are not consistently compared to the original settings described in the respective papers, introducing further ambiguity and preventing the establishment of a clear performance hierarchy <cite class="ltx_cite ltx_citemacro_citep">(Petrov and Macdonald, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib30" title="">2022</a>)</cite>.
The existence of different rankings of the proposed methods in each individual research paper hinders our ability to accurately assess real progress in the sequential recommendation domain.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">We present EasyRec, a novel library dedicated to Sequential Recommender Systems (SRSs), designed to simplify data preprocessing and streamline model implementation. EasyRec provides a set of datasets and models, giving researchers and practitioners with an easy-to-use platform to facilitate experimentation and accelerate progress in the field of SRSs. Moreover, we conduct extensive experiments on multiple benchmark datasets, systematically comparing different SRSs implemented within our framework. This allows for a fair and unbiased evaluation, shedding light on the impact of crucial factors such as the length of the input sequence and the number of parameters.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">The results of our study challenge existing performance benchmarks and provide new insights into the field of sequential recommendation. Surprisingly, our results show that SASRec does not consistently outperform GRU4Rec. However, an interesting shift occurs when the number of model parameters increases substantially: SASRec begins to clearly dominate all other SRSs.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Our contributions can be summarised as follows:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Provision of a comprehensive code resource, which allows different data pre-processing methods, facilitates the implementation of various SRSs, and ensures full experimental reproducibility.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Extensive experiments on multiple datasets and models, reducing biases in performance comparisons.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">In-depth analysis of the results, providing new insights into different models and the impact of key hyperparameters;</p>
<ol class="ltx_enumerate" id="S1.I1.i3.I1">
<li class="ltx_item" id="S1.I1.i3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S1.I1.i3.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i3.I1.i1.p1.1">Contrary to the prevailing notion in many articles, GRU4Rec consistently shows strong performance, often outperforming other SRSs.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S1.I1.i3.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i3.I1.i2.p1.1">Performance gains for transformer-based models are more pronounced at higher embedding dimensions compared to GRU-based models, leading to SASRec outperforming all other models.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S1.I1.i3.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.I1.i3.p1.1">The optimal input sequence length is related to the average user sequence length of each dataset, highlighting the importance of dataset-specific considerations.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(4)</span>
<div class="ltx_para" id="S1.I1.i3.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i3.I1.i4.p1.1">Transformer-based models exhibit exponential growth in size with increasing embedding dimensions, but performance improvements do not scale similarly. In addition, emissions are not only correlated with model size, but are significantly higher for models that require longer training times.</p>
</div>
</li>
</ol>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Sequential Recommender Systems</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Markov chain-based techniques <cite class="ltx_cite ltx_citemacro_citep">(Rendle et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib32" title="">2010</a>)</cite> are among the first approaches in SRSs, but they struggle to capture complex dependencies within long sequences <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib40" title="">2019</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">As a result, neural networks have recently emerged as the leading models for sequential recommendation. Recurrent Neural Networks <cite class="ltx_cite ltx_citemacro_citep">(Beutel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib4" title="">2018</a>)</cite> were among the first architectures introduced for this task. For instance, GRU4Rec <cite class="ltx_cite ltx_citemacro_citep">(Hidasi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib16" title="">2016</a>)</cite> is a recurrent neural network using Gated Recurrent Units (GRUs) <cite class="ltx_cite ltx_citemacro_citep">(Cho et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib5" title="">2014</a>)</cite>.
Another notable approach using GRUs is the Neural Attentive Recommendation Machine (NARM) <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib22" title="">2017</a>)</cite>, which features a hybrid encoder-decoder architecture with a custom attention mechanism. This mechanism captures both local and global preferences in user-item interactions.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">Advances in natural language processing have led to attention-based models. Self-Attentive Sequential Recommendation (SASRec) <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib19" title="">2018</a>)</cite> uses self-attention to discern the relevance of each item in the user’s sequence. BERT4Rec <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib35" title="">2019</a>)</cite> instead exploits the Bidirectional Encoder Representations for Transformer (BERT) architecture <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib8" title="">2019</a>)</cite>. Its bidirectional self-attention enables the model to obtain more accurate representations of user behaviour, improving recommendation performance. To avoid information leakage, BERT4Rec is trained on the Cloze task, i.e. predicting randomly masked items by jointly considering the left and right context in the input sequence.</p>
</div>
<div class="ltx_para" id="S2.SS1.p4">
<p class="ltx_p" id="S2.SS1.p4.1">A recent addition to the landscape of SRSs is CORE <cite class="ltx_cite ltx_citemacro_citep">(Hou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib17" title="">2022</a>)</cite>, which also integrates an attention mechanism. CORE offers two variants: one with custom attention computation and another using standard attention mechanisms. Both allow the model to weigh the contribution of each item in the input sequence, further refining the recommendation process.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Reproducibility in SRSs</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Despite being a long-standing issue, reproducibility in SRSs has not received sufficient attention. <cite class="ltx_cite ltx_citemacro_citet">Ferrari Dacrema et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib9" title="">2021</a>)</cite> sheds light on the problem, showing that only a fraction of top-quality work can be faithfully reproduced <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib23" title="">2023</a>)</cite>. In support of this observation, <cite class="ltx_cite ltx_citemacro_citet">Hidasi and Czapp (<a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib14" title="">2023a</a>)</cite> show that non-original implementations often produce inferior results than the original papers.
Even implementations found in common and widespread libraries, such as RecBole <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib42" title="">2021</a>)</cite>, present this issue <cite class="ltx_cite ltx_citemacro_citep">(Petrov and Macdonald, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib30" title="">2022</a>)</cite> and fail to faithfully reproduce reported results. Furthermore, even when results are reproducible, the lack of standardisation in faulty experimental setups (e.g. varying loss functions, user’ sequence length, etc.) <cite class="ltx_cite ltx_citemacro_citep">(Hidasi and Czapp, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib15" title="">2023b</a>)</cite> makes it impossible to establish a clear hierarchy between different models <cite class="ltx_cite ltx_citemacro_citep">(Petrov and Macdonald, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib30" title="">2022</a>; Klenitskiy and Vasilev, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib21" title="">2023</a>; Lin, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib24" title="">2019</a>; Ludewig and Jannach, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib25" title="">2018</a>)</cite> and to establish if we are really making progress in the SRS domain <cite class="ltx_cite ltx_citemacro_citep">(Ferrari Dacrema et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib10" title="">2019</a>)</cite>.
This inconsistency casts doubt on real progress in the SRS field <cite class="ltx_cite ltx_citemacro_citep">(Ferrari Dacrema et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib10" title="">2019</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Our work addresses these challenges by providing a comprehensive code resource using current versions of prominent Python libraries such as PyTorch and PyTorch Lightning. This framework ensures a faithful reproduction of the original paper results, demonstrating the robustness of our implementation. Furthermore, we conduct a rigorous comparative study under consistent conditions, allowing for a nuanced analysis of the hierarchy between SRSs. This approach contributes to a more reliable comparison process than current studies provide.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Background</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.9">The primary goal of sequential recommendation is to predict the next interaction within a sequence. Let’s consider a collection of <math alttext="n" class="ltx_Math" display="inline" id="S3.p1.1.m1.1"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.1d">italic_n</annotation></semantics></math> users, denoted as <math alttext="\mathcal{U}\subset\mathbb{N^{+}}" class="ltx_Math" display="inline" id="S3.p1.2.m2.1"><semantics id="S3.p1.2.m2.1a"><mrow id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">𝒰</mi><mo id="S3.p1.2.m2.1.1.1" xref="S3.p1.2.m2.1.1.1.cmml">⊂</mo><msup id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml"><mi id="S3.p1.2.m2.1.1.3.2" xref="S3.p1.2.m2.1.1.3.2.cmml">ℕ</mi><mo id="S3.p1.2.m2.1.1.3.3" xref="S3.p1.2.m2.1.1.3.3.cmml">+</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><subset id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1"></subset><ci id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2">𝒰</ci><apply id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.3.1.cmml" xref="S3.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.p1.2.m2.1.1.3.2.cmml" xref="S3.p1.2.m2.1.1.3.2">ℕ</ci><plus id="S3.p1.2.m2.1.1.3.3.cmml" xref="S3.p1.2.m2.1.1.3.3"></plus></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">\mathcal{U}\subset\mathbb{N^{+}}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.2.m2.1d">caligraphic_U ⊂ blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT</annotation></semantics></math> and a corresponding set of <math alttext="n" class="ltx_Math" display="inline" id="S3.p1.3.m3.1"><semantics id="S3.p1.3.m3.1a"><mi id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><ci id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.p1.3.m3.1d">italic_n</annotation></semantics></math> items denoted as <math alttext="\mathcal{I}\subset\mathbb{N^{+}}" class="ltx_Math" display="inline" id="S3.p1.4.m4.1"><semantics id="S3.p1.4.m4.1a"><mrow id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p1.4.m4.1.1.2" xref="S3.p1.4.m4.1.1.2.cmml">ℐ</mi><mo id="S3.p1.4.m4.1.1.1" xref="S3.p1.4.m4.1.1.1.cmml">⊂</mo><msup id="S3.p1.4.m4.1.1.3" xref="S3.p1.4.m4.1.1.3.cmml"><mi id="S3.p1.4.m4.1.1.3.2" xref="S3.p1.4.m4.1.1.3.2.cmml">ℕ</mi><mo id="S3.p1.4.m4.1.1.3.3" xref="S3.p1.4.m4.1.1.3.3.cmml">+</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><apply id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1"><subset id="S3.p1.4.m4.1.1.1.cmml" xref="S3.p1.4.m4.1.1.1"></subset><ci id="S3.p1.4.m4.1.1.2.cmml" xref="S3.p1.4.m4.1.1.2">ℐ</ci><apply id="S3.p1.4.m4.1.1.3.cmml" xref="S3.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.p1.4.m4.1.1.3.1.cmml" xref="S3.p1.4.m4.1.1.3">superscript</csymbol><ci id="S3.p1.4.m4.1.1.3.2.cmml" xref="S3.p1.4.m4.1.1.3.2">ℕ</ci><plus id="S3.p1.4.m4.1.1.3.3.cmml" xref="S3.p1.4.m4.1.1.3.3"></plus></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">\mathcal{I}\subset\mathbb{N^{+}}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.4.m4.1d">caligraphic_I ⊂ blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT</annotation></semantics></math>. Each user <math alttext="u\in\mathcal{U}" class="ltx_Math" display="inline" id="S3.p1.5.m5.1"><semantics id="S3.p1.5.m5.1a"><mrow id="S3.p1.5.m5.1.1" xref="S3.p1.5.m5.1.1.cmml"><mi id="S3.p1.5.m5.1.1.2" xref="S3.p1.5.m5.1.1.2.cmml">u</mi><mo id="S3.p1.5.m5.1.1.1" xref="S3.p1.5.m5.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.p1.5.m5.1.1.3" xref="S3.p1.5.m5.1.1.3.cmml">𝒰</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.1b"><apply id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1"><in id="S3.p1.5.m5.1.1.1.cmml" xref="S3.p1.5.m5.1.1.1"></in><ci id="S3.p1.5.m5.1.1.2.cmml" xref="S3.p1.5.m5.1.1.2">𝑢</ci><ci id="S3.p1.5.m5.1.1.3.cmml" xref="S3.p1.5.m5.1.1.3">𝒰</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.5.m5.1c">u\in\mathcal{U}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.5.m5.1d">italic_u ∈ caligraphic_U</annotation></semantics></math> is characterised by a temporally ordered sequence <math alttext="S_{u}=[s_{1},\dots,s_{L_{u}}]" class="ltx_Math" display="inline" id="S3.p1.6.m6.3"><semantics id="S3.p1.6.m6.3a"><mrow id="S3.p1.6.m6.3.3" xref="S3.p1.6.m6.3.3.cmml"><msub id="S3.p1.6.m6.3.3.4" xref="S3.p1.6.m6.3.3.4.cmml"><mi id="S3.p1.6.m6.3.3.4.2" xref="S3.p1.6.m6.3.3.4.2.cmml">S</mi><mi id="S3.p1.6.m6.3.3.4.3" xref="S3.p1.6.m6.3.3.4.3.cmml">u</mi></msub><mo id="S3.p1.6.m6.3.3.3" xref="S3.p1.6.m6.3.3.3.cmml">=</mo><mrow id="S3.p1.6.m6.3.3.2.2" xref="S3.p1.6.m6.3.3.2.3.cmml"><mo id="S3.p1.6.m6.3.3.2.2.3" stretchy="false" xref="S3.p1.6.m6.3.3.2.3.cmml">[</mo><msub id="S3.p1.6.m6.2.2.1.1.1" xref="S3.p1.6.m6.2.2.1.1.1.cmml"><mi id="S3.p1.6.m6.2.2.1.1.1.2" xref="S3.p1.6.m6.2.2.1.1.1.2.cmml">s</mi><mn id="S3.p1.6.m6.2.2.1.1.1.3" xref="S3.p1.6.m6.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.p1.6.m6.3.3.2.2.4" xref="S3.p1.6.m6.3.3.2.3.cmml">,</mo><mi id="S3.p1.6.m6.1.1" mathvariant="normal" xref="S3.p1.6.m6.1.1.cmml">…</mi><mo id="S3.p1.6.m6.3.3.2.2.5" xref="S3.p1.6.m6.3.3.2.3.cmml">,</mo><msub id="S3.p1.6.m6.3.3.2.2.2" xref="S3.p1.6.m6.3.3.2.2.2.cmml"><mi id="S3.p1.6.m6.3.3.2.2.2.2" xref="S3.p1.6.m6.3.3.2.2.2.2.cmml">s</mi><msub id="S3.p1.6.m6.3.3.2.2.2.3" xref="S3.p1.6.m6.3.3.2.2.2.3.cmml"><mi id="S3.p1.6.m6.3.3.2.2.2.3.2" xref="S3.p1.6.m6.3.3.2.2.2.3.2.cmml">L</mi><mi id="S3.p1.6.m6.3.3.2.2.2.3.3" xref="S3.p1.6.m6.3.3.2.2.2.3.3.cmml">u</mi></msub></msub><mo id="S3.p1.6.m6.3.3.2.2.6" stretchy="false" xref="S3.p1.6.m6.3.3.2.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.6.m6.3b"><apply id="S3.p1.6.m6.3.3.cmml" xref="S3.p1.6.m6.3.3"><eq id="S3.p1.6.m6.3.3.3.cmml" xref="S3.p1.6.m6.3.3.3"></eq><apply id="S3.p1.6.m6.3.3.4.cmml" xref="S3.p1.6.m6.3.3.4"><csymbol cd="ambiguous" id="S3.p1.6.m6.3.3.4.1.cmml" xref="S3.p1.6.m6.3.3.4">subscript</csymbol><ci id="S3.p1.6.m6.3.3.4.2.cmml" xref="S3.p1.6.m6.3.3.4.2">𝑆</ci><ci id="S3.p1.6.m6.3.3.4.3.cmml" xref="S3.p1.6.m6.3.3.4.3">𝑢</ci></apply><list id="S3.p1.6.m6.3.3.2.3.cmml" xref="S3.p1.6.m6.3.3.2.2"><apply id="S3.p1.6.m6.2.2.1.1.1.cmml" xref="S3.p1.6.m6.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.p1.6.m6.2.2.1.1.1.1.cmml" xref="S3.p1.6.m6.2.2.1.1.1">subscript</csymbol><ci id="S3.p1.6.m6.2.2.1.1.1.2.cmml" xref="S3.p1.6.m6.2.2.1.1.1.2">𝑠</ci><cn id="S3.p1.6.m6.2.2.1.1.1.3.cmml" type="integer" xref="S3.p1.6.m6.2.2.1.1.1.3">1</cn></apply><ci id="S3.p1.6.m6.1.1.cmml" xref="S3.p1.6.m6.1.1">…</ci><apply id="S3.p1.6.m6.3.3.2.2.2.cmml" xref="S3.p1.6.m6.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.p1.6.m6.3.3.2.2.2.1.cmml" xref="S3.p1.6.m6.3.3.2.2.2">subscript</csymbol><ci id="S3.p1.6.m6.3.3.2.2.2.2.cmml" xref="S3.p1.6.m6.3.3.2.2.2.2">𝑠</ci><apply id="S3.p1.6.m6.3.3.2.2.2.3.cmml" xref="S3.p1.6.m6.3.3.2.2.2.3"><csymbol cd="ambiguous" id="S3.p1.6.m6.3.3.2.2.2.3.1.cmml" xref="S3.p1.6.m6.3.3.2.2.2.3">subscript</csymbol><ci id="S3.p1.6.m6.3.3.2.2.2.3.2.cmml" xref="S3.p1.6.m6.3.3.2.2.2.3.2">𝐿</ci><ci id="S3.p1.6.m6.3.3.2.2.2.3.3.cmml" xref="S3.p1.6.m6.3.3.2.2.2.3.3">𝑢</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.6.m6.3c">S_{u}=[s_{1},\dots,s_{L_{u}}]</annotation><annotation encoding="application/x-llamapun" id="S3.p1.6.m6.3d">italic_S start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT = [ italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_s start_POSTSUBSCRIPT italic_L start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT end_POSTSUBSCRIPT ]</annotation></semantics></math>, where <math alttext="s_{i}\in\mathcal{I}" class="ltx_Math" display="inline" id="S3.p1.7.m7.1"><semantics id="S3.p1.7.m7.1a"><mrow id="S3.p1.7.m7.1.1" xref="S3.p1.7.m7.1.1.cmml"><msub id="S3.p1.7.m7.1.1.2" xref="S3.p1.7.m7.1.1.2.cmml"><mi id="S3.p1.7.m7.1.1.2.2" xref="S3.p1.7.m7.1.1.2.2.cmml">s</mi><mi id="S3.p1.7.m7.1.1.2.3" xref="S3.p1.7.m7.1.1.2.3.cmml">i</mi></msub><mo id="S3.p1.7.m7.1.1.1" xref="S3.p1.7.m7.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.p1.7.m7.1.1.3" xref="S3.p1.7.m7.1.1.3.cmml">ℐ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.7.m7.1b"><apply id="S3.p1.7.m7.1.1.cmml" xref="S3.p1.7.m7.1.1"><in id="S3.p1.7.m7.1.1.1.cmml" xref="S3.p1.7.m7.1.1.1"></in><apply id="S3.p1.7.m7.1.1.2.cmml" xref="S3.p1.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.p1.7.m7.1.1.2.1.cmml" xref="S3.p1.7.m7.1.1.2">subscript</csymbol><ci id="S3.p1.7.m7.1.1.2.2.cmml" xref="S3.p1.7.m7.1.1.2.2">𝑠</ci><ci id="S3.p1.7.m7.1.1.2.3.cmml" xref="S3.p1.7.m7.1.1.2.3">𝑖</ci></apply><ci id="S3.p1.7.m7.1.1.3.cmml" xref="S3.p1.7.m7.1.1.3">ℐ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.7.m7.1c">s_{i}\in\mathcal{I}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.7.m7.1d">italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ caligraphic_I</annotation></semantics></math> represents the <math alttext="i" class="ltx_Math" display="inline" id="S3.p1.8.m8.1"><semantics id="S3.p1.8.m8.1a"><mi id="S3.p1.8.m8.1.1" xref="S3.p1.8.m8.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p1.8.m8.1b"><ci id="S3.p1.8.m8.1.1.cmml" xref="S3.p1.8.m8.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.8.m8.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.p1.8.m8.1d">italic_i</annotation></semantics></math>-th item the user has interacted with. Here, <math alttext="L_{u}&gt;1" class="ltx_Math" display="inline" id="S3.p1.9.m9.1"><semantics id="S3.p1.9.m9.1a"><mrow id="S3.p1.9.m9.1.1" xref="S3.p1.9.m9.1.1.cmml"><msub id="S3.p1.9.m9.1.1.2" xref="S3.p1.9.m9.1.1.2.cmml"><mi id="S3.p1.9.m9.1.1.2.2" xref="S3.p1.9.m9.1.1.2.2.cmml">L</mi><mi id="S3.p1.9.m9.1.1.2.3" xref="S3.p1.9.m9.1.1.2.3.cmml">u</mi></msub><mo id="S3.p1.9.m9.1.1.1" xref="S3.p1.9.m9.1.1.1.cmml">&gt;</mo><mn id="S3.p1.9.m9.1.1.3" xref="S3.p1.9.m9.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.9.m9.1b"><apply id="S3.p1.9.m9.1.1.cmml" xref="S3.p1.9.m9.1.1"><gt id="S3.p1.9.m9.1.1.1.cmml" xref="S3.p1.9.m9.1.1.1"></gt><apply id="S3.p1.9.m9.1.1.2.cmml" xref="S3.p1.9.m9.1.1.2"><csymbol cd="ambiguous" id="S3.p1.9.m9.1.1.2.1.cmml" xref="S3.p1.9.m9.1.1.2">subscript</csymbol><ci id="S3.p1.9.m9.1.1.2.2.cmml" xref="S3.p1.9.m9.1.1.2.2">𝐿</ci><ci id="S3.p1.9.m9.1.1.2.3.cmml" xref="S3.p1.9.m9.1.1.2.3">𝑢</ci></apply><cn id="S3.p1.9.m9.1.1.3.cmml" type="integer" xref="S3.p1.9.m9.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.9.m9.1c">L_{u}&gt;1</annotation><annotation encoding="application/x-llamapun" id="S3.p1.9.m9.1d">italic_L start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT &gt; 1</annotation></semantics></math> denotes the sequence length, which may vary from user to user.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.9">A SRS, denoted as <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S3.p2.1.m1.1"><semantics id="S3.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.1.m1.1d">caligraphic_M</annotation></semantics></math>, takes as input the sequence up to the <math alttext="L" class="ltx_Math" display="inline" id="S3.p2.2.m2.1"><semantics id="S3.p2.2.m2.1a"><mi id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><ci id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">L</annotation><annotation encoding="application/x-llamapun" id="S3.p2.2.m2.1d">italic_L</annotation></semantics></math>-th item, expressed as <math alttext="S_{u}^{L}=[s_{1},\dots,s_{L}]" class="ltx_Math" display="inline" id="S3.p2.3.m3.3"><semantics id="S3.p2.3.m3.3a"><mrow id="S3.p2.3.m3.3.3" xref="S3.p2.3.m3.3.3.cmml"><msubsup id="S3.p2.3.m3.3.3.4" xref="S3.p2.3.m3.3.3.4.cmml"><mi id="S3.p2.3.m3.3.3.4.2.2" xref="S3.p2.3.m3.3.3.4.2.2.cmml">S</mi><mi id="S3.p2.3.m3.3.3.4.2.3" xref="S3.p2.3.m3.3.3.4.2.3.cmml">u</mi><mi id="S3.p2.3.m3.3.3.4.3" xref="S3.p2.3.m3.3.3.4.3.cmml">L</mi></msubsup><mo id="S3.p2.3.m3.3.3.3" xref="S3.p2.3.m3.3.3.3.cmml">=</mo><mrow id="S3.p2.3.m3.3.3.2.2" xref="S3.p2.3.m3.3.3.2.3.cmml"><mo id="S3.p2.3.m3.3.3.2.2.3" stretchy="false" xref="S3.p2.3.m3.3.3.2.3.cmml">[</mo><msub id="S3.p2.3.m3.2.2.1.1.1" xref="S3.p2.3.m3.2.2.1.1.1.cmml"><mi id="S3.p2.3.m3.2.2.1.1.1.2" xref="S3.p2.3.m3.2.2.1.1.1.2.cmml">s</mi><mn id="S3.p2.3.m3.2.2.1.1.1.3" xref="S3.p2.3.m3.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.p2.3.m3.3.3.2.2.4" xref="S3.p2.3.m3.3.3.2.3.cmml">,</mo><mi id="S3.p2.3.m3.1.1" mathvariant="normal" xref="S3.p2.3.m3.1.1.cmml">…</mi><mo id="S3.p2.3.m3.3.3.2.2.5" xref="S3.p2.3.m3.3.3.2.3.cmml">,</mo><msub id="S3.p2.3.m3.3.3.2.2.2" xref="S3.p2.3.m3.3.3.2.2.2.cmml"><mi id="S3.p2.3.m3.3.3.2.2.2.2" xref="S3.p2.3.m3.3.3.2.2.2.2.cmml">s</mi><mi id="S3.p2.3.m3.3.3.2.2.2.3" xref="S3.p2.3.m3.3.3.2.2.2.3.cmml">L</mi></msub><mo id="S3.p2.3.m3.3.3.2.2.6" stretchy="false" xref="S3.p2.3.m3.3.3.2.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.3b"><apply id="S3.p2.3.m3.3.3.cmml" xref="S3.p2.3.m3.3.3"><eq id="S3.p2.3.m3.3.3.3.cmml" xref="S3.p2.3.m3.3.3.3"></eq><apply id="S3.p2.3.m3.3.3.4.cmml" xref="S3.p2.3.m3.3.3.4"><csymbol cd="ambiguous" id="S3.p2.3.m3.3.3.4.1.cmml" xref="S3.p2.3.m3.3.3.4">superscript</csymbol><apply id="S3.p2.3.m3.3.3.4.2.cmml" xref="S3.p2.3.m3.3.3.4"><csymbol cd="ambiguous" id="S3.p2.3.m3.3.3.4.2.1.cmml" xref="S3.p2.3.m3.3.3.4">subscript</csymbol><ci id="S3.p2.3.m3.3.3.4.2.2.cmml" xref="S3.p2.3.m3.3.3.4.2.2">𝑆</ci><ci id="S3.p2.3.m3.3.3.4.2.3.cmml" xref="S3.p2.3.m3.3.3.4.2.3">𝑢</ci></apply><ci id="S3.p2.3.m3.3.3.4.3.cmml" xref="S3.p2.3.m3.3.3.4.3">𝐿</ci></apply><list id="S3.p2.3.m3.3.3.2.3.cmml" xref="S3.p2.3.m3.3.3.2.2"><apply id="S3.p2.3.m3.2.2.1.1.1.cmml" xref="S3.p2.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.p2.3.m3.2.2.1.1.1.1.cmml" xref="S3.p2.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S3.p2.3.m3.2.2.1.1.1.2.cmml" xref="S3.p2.3.m3.2.2.1.1.1.2">𝑠</ci><cn id="S3.p2.3.m3.2.2.1.1.1.3.cmml" type="integer" xref="S3.p2.3.m3.2.2.1.1.1.3">1</cn></apply><ci id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1">…</ci><apply id="S3.p2.3.m3.3.3.2.2.2.cmml" xref="S3.p2.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.p2.3.m3.3.3.2.2.2.1.cmml" xref="S3.p2.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S3.p2.3.m3.3.3.2.2.2.2.cmml" xref="S3.p2.3.m3.3.3.2.2.2.2">𝑠</ci><ci id="S3.p2.3.m3.3.3.2.2.2.3.cmml" xref="S3.p2.3.m3.3.3.2.2.2.3">𝐿</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.3c">S_{u}^{L}=[s_{1},\dots,s_{L}]</annotation><annotation encoding="application/x-llamapun" id="S3.p2.3.m3.3d">italic_S start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT = [ italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_s start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT ]</annotation></semantics></math>, and attempts to recommend the next item, <math alttext="s_{L+1}" class="ltx_Math" display="inline" id="S3.p2.4.m4.1"><semantics id="S3.p2.4.m4.1a"><msub id="S3.p2.4.m4.1.1" xref="S3.p2.4.m4.1.1.cmml"><mi id="S3.p2.4.m4.1.1.2" xref="S3.p2.4.m4.1.1.2.cmml">s</mi><mrow id="S3.p2.4.m4.1.1.3" xref="S3.p2.4.m4.1.1.3.cmml"><mi id="S3.p2.4.m4.1.1.3.2" xref="S3.p2.4.m4.1.1.3.2.cmml">L</mi><mo id="S3.p2.4.m4.1.1.3.1" xref="S3.p2.4.m4.1.1.3.1.cmml">+</mo><mn id="S3.p2.4.m4.1.1.3.3" xref="S3.p2.4.m4.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p2.4.m4.1b"><apply id="S3.p2.4.m4.1.1.cmml" xref="S3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p2.4.m4.1.1.1.cmml" xref="S3.p2.4.m4.1.1">subscript</csymbol><ci id="S3.p2.4.m4.1.1.2.cmml" xref="S3.p2.4.m4.1.1.2">𝑠</ci><apply id="S3.p2.4.m4.1.1.3.cmml" xref="S3.p2.4.m4.1.1.3"><plus id="S3.p2.4.m4.1.1.3.1.cmml" xref="S3.p2.4.m4.1.1.3.1"></plus><ci id="S3.p2.4.m4.1.1.3.2.cmml" xref="S3.p2.4.m4.1.1.3.2">𝐿</ci><cn id="S3.p2.4.m4.1.1.3.3.cmml" type="integer" xref="S3.p2.4.m4.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m4.1c">s_{L+1}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.4.m4.1d">italic_s start_POSTSUBSCRIPT italic_L + 1 end_POSTSUBSCRIPT</annotation></semantics></math>. The output of the recommendation, represented as <math alttext="r^{L+1}=\mathcal{M}(S_{u}^{L})\in\mathbb{R}^{m}" class="ltx_Math" display="inline" id="S3.p2.5.m5.1"><semantics id="S3.p2.5.m5.1a"><mrow id="S3.p2.5.m5.1.1" xref="S3.p2.5.m5.1.1.cmml"><msup id="S3.p2.5.m5.1.1.3" xref="S3.p2.5.m5.1.1.3.cmml"><mi id="S3.p2.5.m5.1.1.3.2" xref="S3.p2.5.m5.1.1.3.2.cmml">r</mi><mrow id="S3.p2.5.m5.1.1.3.3" xref="S3.p2.5.m5.1.1.3.3.cmml"><mi id="S3.p2.5.m5.1.1.3.3.2" xref="S3.p2.5.m5.1.1.3.3.2.cmml">L</mi><mo id="S3.p2.5.m5.1.1.3.3.1" xref="S3.p2.5.m5.1.1.3.3.1.cmml">+</mo><mn id="S3.p2.5.m5.1.1.3.3.3" xref="S3.p2.5.m5.1.1.3.3.3.cmml">1</mn></mrow></msup><mo id="S3.p2.5.m5.1.1.4" xref="S3.p2.5.m5.1.1.4.cmml">=</mo><mrow id="S3.p2.5.m5.1.1.1" xref="S3.p2.5.m5.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p2.5.m5.1.1.1.3" xref="S3.p2.5.m5.1.1.1.3.cmml">ℳ</mi><mo id="S3.p2.5.m5.1.1.1.2" xref="S3.p2.5.m5.1.1.1.2.cmml">⁢</mo><mrow id="S3.p2.5.m5.1.1.1.1.1" xref="S3.p2.5.m5.1.1.1.1.1.1.cmml"><mo id="S3.p2.5.m5.1.1.1.1.1.2" stretchy="false" xref="S3.p2.5.m5.1.1.1.1.1.1.cmml">(</mo><msubsup id="S3.p2.5.m5.1.1.1.1.1.1" xref="S3.p2.5.m5.1.1.1.1.1.1.cmml"><mi id="S3.p2.5.m5.1.1.1.1.1.1.2.2" xref="S3.p2.5.m5.1.1.1.1.1.1.2.2.cmml">S</mi><mi id="S3.p2.5.m5.1.1.1.1.1.1.2.3" xref="S3.p2.5.m5.1.1.1.1.1.1.2.3.cmml">u</mi><mi id="S3.p2.5.m5.1.1.1.1.1.1.3" xref="S3.p2.5.m5.1.1.1.1.1.1.3.cmml">L</mi></msubsup><mo id="S3.p2.5.m5.1.1.1.1.1.3" stretchy="false" xref="S3.p2.5.m5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.p2.5.m5.1.1.5" xref="S3.p2.5.m5.1.1.5.cmml">∈</mo><msup id="S3.p2.5.m5.1.1.6" xref="S3.p2.5.m5.1.1.6.cmml"><mi id="S3.p2.5.m5.1.1.6.2" xref="S3.p2.5.m5.1.1.6.2.cmml">ℝ</mi><mi id="S3.p2.5.m5.1.1.6.3" xref="S3.p2.5.m5.1.1.6.3.cmml">m</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.5.m5.1b"><apply id="S3.p2.5.m5.1.1.cmml" xref="S3.p2.5.m5.1.1"><and id="S3.p2.5.m5.1.1a.cmml" xref="S3.p2.5.m5.1.1"></and><apply id="S3.p2.5.m5.1.1b.cmml" xref="S3.p2.5.m5.1.1"><eq id="S3.p2.5.m5.1.1.4.cmml" xref="S3.p2.5.m5.1.1.4"></eq><apply id="S3.p2.5.m5.1.1.3.cmml" xref="S3.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.p2.5.m5.1.1.3.1.cmml" xref="S3.p2.5.m5.1.1.3">superscript</csymbol><ci id="S3.p2.5.m5.1.1.3.2.cmml" xref="S3.p2.5.m5.1.1.3.2">𝑟</ci><apply id="S3.p2.5.m5.1.1.3.3.cmml" xref="S3.p2.5.m5.1.1.3.3"><plus id="S3.p2.5.m5.1.1.3.3.1.cmml" xref="S3.p2.5.m5.1.1.3.3.1"></plus><ci id="S3.p2.5.m5.1.1.3.3.2.cmml" xref="S3.p2.5.m5.1.1.3.3.2">𝐿</ci><cn id="S3.p2.5.m5.1.1.3.3.3.cmml" type="integer" xref="S3.p2.5.m5.1.1.3.3.3">1</cn></apply></apply><apply id="S3.p2.5.m5.1.1.1.cmml" xref="S3.p2.5.m5.1.1.1"><times id="S3.p2.5.m5.1.1.1.2.cmml" xref="S3.p2.5.m5.1.1.1.2"></times><ci id="S3.p2.5.m5.1.1.1.3.cmml" xref="S3.p2.5.m5.1.1.1.3">ℳ</ci><apply id="S3.p2.5.m5.1.1.1.1.1.1.cmml" xref="S3.p2.5.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.5.m5.1.1.1.1.1.1.1.cmml" xref="S3.p2.5.m5.1.1.1.1.1">superscript</csymbol><apply id="S3.p2.5.m5.1.1.1.1.1.1.2.cmml" xref="S3.p2.5.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.5.m5.1.1.1.1.1.1.2.1.cmml" xref="S3.p2.5.m5.1.1.1.1.1">subscript</csymbol><ci id="S3.p2.5.m5.1.1.1.1.1.1.2.2.cmml" xref="S3.p2.5.m5.1.1.1.1.1.1.2.2">𝑆</ci><ci id="S3.p2.5.m5.1.1.1.1.1.1.2.3.cmml" xref="S3.p2.5.m5.1.1.1.1.1.1.2.3">𝑢</ci></apply><ci id="S3.p2.5.m5.1.1.1.1.1.1.3.cmml" xref="S3.p2.5.m5.1.1.1.1.1.1.3">𝐿</ci></apply></apply></apply><apply id="S3.p2.5.m5.1.1c.cmml" xref="S3.p2.5.m5.1.1"><in id="S3.p2.5.m5.1.1.5.cmml" xref="S3.p2.5.m5.1.1.5"></in><share href="https://arxiv.org/html/2408.03873v1#S3.p2.5.m5.1.1.1.cmml" id="S3.p2.5.m5.1.1d.cmml" xref="S3.p2.5.m5.1.1"></share><apply id="S3.p2.5.m5.1.1.6.cmml" xref="S3.p2.5.m5.1.1.6"><csymbol cd="ambiguous" id="S3.p2.5.m5.1.1.6.1.cmml" xref="S3.p2.5.m5.1.1.6">superscript</csymbol><ci id="S3.p2.5.m5.1.1.6.2.cmml" xref="S3.p2.5.m5.1.1.6.2">ℝ</ci><ci id="S3.p2.5.m5.1.1.6.3.cmml" xref="S3.p2.5.m5.1.1.6.3">𝑚</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.5.m5.1c">r^{L+1}=\mathcal{M}(S_{u}^{L})\in\mathbb{R}^{m}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.5.m5.1d">italic_r start_POSTSUPERSCRIPT italic_L + 1 end_POSTSUPERSCRIPT = caligraphic_M ( italic_S start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT ) ∈ blackboard_R start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT</annotation></semantics></math>, is a score distribution over all items. This distribution is used to generate a ranked list of items representing the most likely interactions for user <math alttext="u" class="ltx_Math" display="inline" id="S3.p2.6.m6.1"><semantics id="S3.p2.6.m6.1a"><mi id="S3.p2.6.m6.1.1" xref="S3.p2.6.m6.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.p2.6.m6.1b"><ci id="S3.p2.6.m6.1.1.cmml" xref="S3.p2.6.m6.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.6.m6.1c">u</annotation><annotation encoding="application/x-llamapun" id="S3.p2.6.m6.1d">italic_u</annotation></semantics></math> at step <math alttext="L+1" class="ltx_Math" display="inline" id="S3.p2.7.m7.1"><semantics id="S3.p2.7.m7.1a"><mrow id="S3.p2.7.m7.1.1" xref="S3.p2.7.m7.1.1.cmml"><mi id="S3.p2.7.m7.1.1.2" xref="S3.p2.7.m7.1.1.2.cmml">L</mi><mo id="S3.p2.7.m7.1.1.1" xref="S3.p2.7.m7.1.1.1.cmml">+</mo><mn id="S3.p2.7.m7.1.1.3" xref="S3.p2.7.m7.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.7.m7.1b"><apply id="S3.p2.7.m7.1.1.cmml" xref="S3.p2.7.m7.1.1"><plus id="S3.p2.7.m7.1.1.1.cmml" xref="S3.p2.7.m7.1.1.1"></plus><ci id="S3.p2.7.m7.1.1.2.cmml" xref="S3.p2.7.m7.1.1.2">𝐿</ci><cn id="S3.p2.7.m7.1.1.3.cmml" type="integer" xref="S3.p2.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.7.m7.1c">L+1</annotation><annotation encoding="application/x-llamapun" id="S3.p2.7.m7.1d">italic_L + 1</annotation></semantics></math>. The following item <math alttext="s_{L+1}" class="ltx_Math" display="inline" id="S3.p2.8.m8.1"><semantics id="S3.p2.8.m8.1a"><msub id="S3.p2.8.m8.1.1" xref="S3.p2.8.m8.1.1.cmml"><mi id="S3.p2.8.m8.1.1.2" xref="S3.p2.8.m8.1.1.2.cmml">s</mi><mrow id="S3.p2.8.m8.1.1.3" xref="S3.p2.8.m8.1.1.3.cmml"><mi id="S3.p2.8.m8.1.1.3.2" xref="S3.p2.8.m8.1.1.3.2.cmml">L</mi><mo id="S3.p2.8.m8.1.1.3.1" xref="S3.p2.8.m8.1.1.3.1.cmml">+</mo><mn id="S3.p2.8.m8.1.1.3.3" xref="S3.p2.8.m8.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p2.8.m8.1b"><apply id="S3.p2.8.m8.1.1.cmml" xref="S3.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.p2.8.m8.1.1.1.cmml" xref="S3.p2.8.m8.1.1">subscript</csymbol><ci id="S3.p2.8.m8.1.1.2.cmml" xref="S3.p2.8.m8.1.1.2">𝑠</ci><apply id="S3.p2.8.m8.1.1.3.cmml" xref="S3.p2.8.m8.1.1.3"><plus id="S3.p2.8.m8.1.1.3.1.cmml" xref="S3.p2.8.m8.1.1.3.1"></plus><ci id="S3.p2.8.m8.1.1.3.2.cmml" xref="S3.p2.8.m8.1.1.3.2">𝐿</ci><cn id="S3.p2.8.m8.1.1.3.3.cmml" type="integer" xref="S3.p2.8.m8.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.8.m8.1c">s_{L+1}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.8.m8.1d">italic_s start_POSTSUBSCRIPT italic_L + 1 end_POSTSUBSCRIPT</annotation></semantics></math>, is regarded as the <span class="ltx_text ltx_font_italic" id="S3.p2.9.1">positive</span> item, meaning that it is the item to be predicted. In contrast, all other items that should not be predicted at step <math alttext="L+1" class="ltx_Math" display="inline" id="S3.p2.9.m9.1"><semantics id="S3.p2.9.m9.1a"><mrow id="S3.p2.9.m9.1.1" xref="S3.p2.9.m9.1.1.cmml"><mi id="S3.p2.9.m9.1.1.2" xref="S3.p2.9.m9.1.1.2.cmml">L</mi><mo id="S3.p2.9.m9.1.1.1" xref="S3.p2.9.m9.1.1.1.cmml">+</mo><mn id="S3.p2.9.m9.1.1.3" xref="S3.p2.9.m9.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.9.m9.1b"><apply id="S3.p2.9.m9.1.1.cmml" xref="S3.p2.9.m9.1.1"><plus id="S3.p2.9.m9.1.1.1.cmml" xref="S3.p2.9.m9.1.1.1"></plus><ci id="S3.p2.9.m9.1.1.2.cmml" xref="S3.p2.9.m9.1.1.2">𝐿</ci><cn id="S3.p2.9.m9.1.1.3.cmml" type="integer" xref="S3.p2.9.m9.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.9.m9.1c">L+1</annotation><annotation encoding="application/x-llamapun" id="S3.p2.9.m9.1d">italic_L + 1</annotation></semantics></math> are labeled as <span class="ltx_text ltx_font_italic" id="S3.p2.9.2">negative</span> items.</p>
</div>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Input sequence length</h4>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p1.9">The choice of input sequence length <math alttext="L" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.1.m1.1"><semantics id="S3.SS0.SSS0.Px1.p1.1.m1.1a"><mi id="S3.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.1.m1.1b"><ci id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.1.m1.1c">L</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.1.m1.1d">italic_L</annotation></semantics></math> is a crucial hyperparameter: opting for short sequences may provide insufficient information to the model, while excessively long sequences may inject irrelevant information. Given the varying number of interactions per user <math alttext="L_{u}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.2.m2.1"><semantics id="S3.SS0.SSS0.Px1.p1.2.m2.1a"><msub id="S3.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1.2.cmml">L</mi><mi id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1.2">𝐿</ci><ci id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.2.m2.1c">L_{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.2.m2.1d">italic_L start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math>, it is possible that <math alttext="L_{u}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.3.m3.1"><semantics id="S3.SS0.SSS0.Px1.p1.3.m3.1a"><msub id="S3.SS0.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml">L</mi><mi id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.3.m3.1b"><apply id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.2">𝐿</ci><ci id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.3.m3.1c">L_{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.3.m3.1d">italic_L start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math> is shorter than the chosen <math alttext="L" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.4.m4.1"><semantics id="S3.SS0.SSS0.Px1.p1.4.m4.1a"><mi id="S3.SS0.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.4.m4.1b"><ci id="S3.SS0.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.4.m4.1c">L</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.4.m4.1d">italic_L</annotation></semantics></math>. In such cases, the sequence is padded at the beginning with a dedicated identifier <math alttext="pad\notin\mathcal{I}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.5.m5.1"><semantics id="S3.SS0.SSS0.Px1.p1.5.m5.1a"><mrow id="S3.SS0.SSS0.Px1.p1.5.m5.1.1" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.cmml"><mrow id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.cmml"><mi id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.2" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.2.cmml">p</mi><mo id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.1" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.1.cmml">⁢</mo><mi id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.3" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.3.cmml">a</mi><mo id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.1a" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.1.cmml">⁢</mo><mi id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.4" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.4.cmml">d</mi></mrow><mo id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.1" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.1.cmml">∉</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.3" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.3.cmml">ℐ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.5.m5.1b"><apply id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1"><notin id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.1"></notin><apply id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2"><times id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.1"></times><ci id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.2">𝑝</ci><ci id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.3.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.3">𝑎</ci><ci id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.4.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.4">𝑑</ci></apply><ci id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.3">ℐ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.5.m5.1c">pad\notin\mathcal{I}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.5.m5.1d">italic_p italic_a italic_d ∉ caligraphic_I</annotation></semantics></math>, typically <math alttext="0" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.6.m6.1"><semantics id="S3.SS0.SSS0.Px1.p1.6.m6.1a"><mn id="S3.SS0.SSS0.Px1.p1.6.m6.1.1" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.6.m6.1b"><cn id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.cmml" type="integer" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1">0</cn></annotation-xml></semantics></math>.
Consequently, if <math alttext="L_{u}&lt;L" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.7.m7.1"><semantics id="S3.SS0.SSS0.Px1.p1.7.m7.1a"><mrow id="S3.SS0.SSS0.Px1.p1.7.m7.1.1" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.cmml"><msub id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.cmml"><mi id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.2" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.2.cmml">L</mi><mi id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.3" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.3.cmml">u</mi></msub><mo id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.1" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.1.cmml">&lt;</mo><mi id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.3" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.3.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.7.m7.1b"><apply id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1"><lt id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.1"></lt><apply id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.2">𝐿</ci><ci id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.3.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.3">𝑢</ci></apply><ci id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.7.m7.1c">L_{u}&lt;L</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.7.m7.1d">italic_L start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT &lt; italic_L</annotation></semantics></math>, the sequence is modified to <math alttext="S_{u}^{L}=[pad,\dots,pad,s_{1},\dots,s_{L_{u}}]" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.8.m8.6"><semantics id="S3.SS0.SSS0.Px1.p1.8.m8.6a"><mrow id="S3.SS0.SSS0.Px1.p1.8.m8.6.6" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.cmml"><msubsup id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6.cmml"><mi id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6.2.2" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6.2.2.cmml">S</mi><mi id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6.2.3" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6.2.3.cmml">u</mi><mi id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6.3" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6.3.cmml">L</mi></msubsup><mo id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.5" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.5.cmml">=</mo><mrow id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.5.cmml"><mo id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.5" stretchy="false" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.5.cmml">[</mo><mrow id="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1" xref="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.cmml"><mi id="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.2" xref="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.2.cmml">p</mi><mo id="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.1" xref="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.1.cmml">⁢</mo><mi id="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.3" xref="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.3.cmml">a</mi><mo id="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.1a" xref="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.1.cmml">⁢</mo><mi id="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.4" xref="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.4.cmml">d</mi></mrow><mo id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.6" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.5.cmml">,</mo><mi id="S3.SS0.SSS0.Px1.p1.8.m8.1.1" mathvariant="normal" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1.cmml">…</mi><mo id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.7" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.5.cmml">,</mo><mrow id="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2" xref="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.cmml"><mi id="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.2" xref="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.2.cmml">p</mi><mo id="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.1" xref="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.1.cmml">⁢</mo><mi id="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.3" xref="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.3.cmml">a</mi><mo id="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.1a" xref="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.1.cmml">⁢</mo><mi id="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.4" xref="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.4.cmml">d</mi></mrow><mo id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.8" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.5.cmml">,</mo><msub id="S3.SS0.SSS0.Px1.p1.8.m8.5.5.3.3.3" xref="S3.SS0.SSS0.Px1.p1.8.m8.5.5.3.3.3.cmml"><mi id="S3.SS0.SSS0.Px1.p1.8.m8.5.5.3.3.3.2" xref="S3.SS0.SSS0.Px1.p1.8.m8.5.5.3.3.3.2.cmml">s</mi><mn id="S3.SS0.SSS0.Px1.p1.8.m8.5.5.3.3.3.3" xref="S3.SS0.SSS0.Px1.p1.8.m8.5.5.3.3.3.3.cmml">1</mn></msub><mo id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.9" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.5.cmml">,</mo><mi id="S3.SS0.SSS0.Px1.p1.8.m8.2.2" mathvariant="normal" xref="S3.SS0.SSS0.Px1.p1.8.m8.2.2.cmml">…</mi><mo id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.10" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.5.cmml">,</mo><msub id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.cmml"><mi id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.2" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.2.cmml">s</mi><msub id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.3" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.3.cmml"><mi id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.3.2" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.3.2.cmml">L</mi><mi id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.3.3" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.3.3.cmml">u</mi></msub></msub><mo id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.11" stretchy="false" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.5.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.8.m8.6b"><apply id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6"><eq id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.5.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.5"></eq><apply id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6.1.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6">superscript</csymbol><apply id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6.2.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6.2.1.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6.2.2.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6.2.2">𝑆</ci><ci id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6.2.3.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6.2.3">𝑢</ci></apply><ci id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6.3.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.6.3">𝐿</ci></apply><list id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.5.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4"><apply id="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1"><times id="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.1"></times><ci id="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.2">𝑝</ci><ci id="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.3">𝑎</ci><ci id="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.4.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.3.3.1.1.1.4">𝑑</ci></apply><ci id="S3.SS0.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1">…</ci><apply id="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2"><times id="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.1.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.1"></times><ci id="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.2.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.2">𝑝</ci><ci id="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.3.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.3">𝑎</ci><ci id="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.4.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.4.4.2.2.2.4">𝑑</ci></apply><apply id="S3.SS0.SSS0.Px1.p1.8.m8.5.5.3.3.3.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.5.5.3.3.3"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.8.m8.5.5.3.3.3.1.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.5.5.3.3.3">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.8.m8.5.5.3.3.3.2.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.5.5.3.3.3.2">𝑠</ci><cn id="S3.SS0.SSS0.Px1.p1.8.m8.5.5.3.3.3.3.cmml" type="integer" xref="S3.SS0.SSS0.Px1.p1.8.m8.5.5.3.3.3.3">1</cn></apply><ci id="S3.SS0.SSS0.Px1.p1.8.m8.2.2.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.2.2">…</ci><apply id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.1.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.2.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.2">𝑠</ci><apply id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.3.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.3"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.3.1.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.3">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.3.2.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.3.2">𝐿</ci><ci id="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.3.3.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.6.6.4.4.4.3.3">𝑢</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.8.m8.6c">S_{u}^{L}=[pad,\dots,pad,s_{1},\dots,s_{L_{u}}]</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.8.m8.6d">italic_S start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT = [ italic_p italic_a italic_d , … , italic_p italic_a italic_d , italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_s start_POSTSUBSCRIPT italic_L start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT end_POSTSUBSCRIPT ]</annotation></semantics></math>, with the number of padding instances equal to <math alttext="L-L_{u}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.9.m9.1"><semantics id="S3.SS0.SSS0.Px1.p1.9.m9.1a"><mrow id="S3.SS0.SSS0.Px1.p1.9.m9.1.1" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.cmml"><mi id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2.cmml">L</mi><mo id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.1" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.1.cmml">−</mo><msub id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3.cmml"><mi id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3.2" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3.2.cmml">L</mi><mi id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3.3" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3.3.cmml">u</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.9.m9.1b"><apply id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1"><minus id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.1"></minus><ci id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2">𝐿</ci><apply id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3.1.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3.2.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3.2">𝐿</ci><ci id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3.3.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3.3">𝑢</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.9.m9.1c">L-L_{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.9.m9.1d">italic_L - italic_L start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math>. This approach ensures consistency in sequence lengths and allows for effective use of the model while accommodating variations in user interaction lengths.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Item Embedding</h4>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p1.2">The representation of items by identifiers alone lacks essential information about their inherent properties. To provide these representations with meaningful content, it is common practice to use a lookup table <math alttext="\mathcal{E}:\mathcal{I}\rightarrow\mathbb{R}^{d}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="S3.SS0.SSS0.Px2.p1.1.m1.1a"><mrow id="S3.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">ℰ</mi><mo id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml">:</mo><mrow id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.2" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.2.cmml">ℐ</mi><mo id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.1" stretchy="false" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.1.cmml">→</mo><msup id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.3" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.cmml"><mi id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.2" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.2.cmml">ℝ</mi><mi id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.3" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.3.cmml">d</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1"><ci id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.1">:</ci><ci id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2">ℰ</ci><apply id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3"><ci id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.1.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.1">→</ci><ci id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.2.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.2">ℐ</ci><apply id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.3">superscript</csymbol><ci id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.2">ℝ</ci><ci id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.3.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.1.m1.1c">\mathcal{E}:\mathcal{I}\rightarrow\mathbb{R}^{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p1.1.m1.1d">caligraphic_E : caligraphic_I → blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math>. This table serves as a repository for embeddings, i.e. meaningful vectors that reside in a latent space with dimensionality <math alttext="d" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.2.m2.1"><semantics id="S3.SS0.SSS0.Px2.p1.2.m2.1a"><mi id="S3.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.2.m2.1b"><ci id="S3.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.2.m2.1c">d</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p1.2.m2.1d">italic_d</annotation></semantics></math>. This approach facilitates the transformation of item identifiers into rich, informative vectors that provide a nuanced and comprehensive representation of the main features of each item.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Implementation Framework and Experimental Setup</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Resource</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Our EasyRec library, is designed with several key features, listed below, that significantly enhance its utility for researchers and practitioners alike.</p>
</div>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Reproducibility</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">In our approach, we address two main challenges to improve the reproducibility of our experiments. First, we follow best practices for experimental seeding to ensure consistent and reliable results across multiple runs. Second, we specify the versions of the required Python packages, to prevent errors due to version mismatches, ensuring that our pipeline remains stable and predictable across different setups.
While the exact reproducibility of results is affected by non-negligible hardware and software factors, such as Python library versions and underlying hardware, we document all settings in our code repository<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/antoniopurificato/recsys_repro_conf" title="">https://github.com/antoniopurificato/recsys_repro_conf</a></span></span></span>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Extensibility</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">The resource is not restricted to the datasets, models or experimental setups used in this work. To include new datasets, it is sufficient to process them to adhere to the same format used in this work. For models, they can be easily added as PyTorch Module objects, with adjustments made in a configuration that specifies their input and output. The experimental setup is easily modifiable through a YAML file containing the entire configuration, enabling experimentation with scenarios not considered here. Further extensibility, described in detail in the code repository<a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#footnote2" title="Footnote 2 ‣ Reproducibility ‣ 4.1. Resource ‣ 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_tag">2</span></a>, includes the use of different loss functions, optimisers and more.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Model implementations</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p1.1">A common drawback of many existing implementations of popular SRSs is their overly complex and lengthy code, often using custom implementations of standardised methods. This makes it difficult to understand the model’s operation and to assess its compliance with the mathematical principles underlying the methodology.
To address this issue, we undertook a comprehensive rewrite of these models, condensing them down to the most essential lines of code. Using PyTorch’s pre-implemented methods, such as GRU and Attention, we were able to improve their clarity and comprehensibility.
Additionally, PyTorch implementations are widely adopted, standardized, and rigorously maintained, reducing the likelihood of errors and ensuring timely resolution of any issues.
By aligning with established PyTorch practices, our code stands to benefit from ongoing improvements in the PyTorch ecosystem. In addition, our library supports wandb<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://wandb.ai/site/" title="">https://wandb.ai/site/</a></span></span></span>, which can be used to track experiments and perform hyperparameter optimization.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Running experiments</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px4.p1.1">The software environment can be reproduced by taking the Python library versions specified in our library requirements.
A YAML file contains the experiment configuration, specifying all hyperparameters.
A Python script reads this configuration and streamlines model training.
Detailed information can be found in the code repository<a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#footnote2" title="Footnote 2 ‣ Reproducibility ‣ 4.1. Resource ‣ 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.4.2.1" style="font-size:90%;">Table 1</span>. </span><span class="ltx_text" id="S4.T1.2.1" style="font-size:90%;">Dataset statistics after pre-processing; users and items not having at least 5 interactions are removed. Avg. and Med. refer to the Average and Median of <math alttext="\frac{\mathrm{Actions}}{\mathrm{User}}" class="ltx_Math" display="inline" id="S4.T1.2.1.m1.1"><semantics id="S4.T1.2.1.m1.1b"><mfrac id="S4.T1.2.1.m1.1.1" xref="S4.T1.2.1.m1.1.1.cmml"><mi id="S4.T1.2.1.m1.1.1.2" xref="S4.T1.2.1.m1.1.1.2.cmml">Actions</mi><mi id="S4.T1.2.1.m1.1.1.3" xref="S4.T1.2.1.m1.1.1.3.cmml">User</mi></mfrac><annotation-xml encoding="MathML-Content" id="S4.T1.2.1.m1.1c"><apply id="S4.T1.2.1.m1.1.1.cmml" xref="S4.T1.2.1.m1.1.1"><divide id="S4.T1.2.1.m1.1.1.1.cmml" xref="S4.T1.2.1.m1.1.1"></divide><ci id="S4.T1.2.1.m1.1.1.2.cmml" xref="S4.T1.2.1.m1.1.1.2">Actions</ci><ci id="S4.T1.2.1.m1.1.1.3.cmml" xref="S4.T1.2.1.m1.1.1.3">User</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.1.m1.1d">\frac{\mathrm{Actions}}{\mathrm{User}}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.1.m1.1e">divide start_ARG roman_Actions end_ARG start_ARG roman_User end_ARG</annotation></semantics></math>, respectively.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T1.5" style="width:433.6pt;height:171.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(57.9pt,-23.0pt) scale(1.36465544079482,1.36465544079482) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.5.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt" id="S4.T1.5.1.1.1.1">Name</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.5.1.1.1.2">Users</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.5.1.1.1.3">Items</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T1.5.1.1.1.4">Interactions</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.5.1.1.1.5">Density</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.5.1.1.1.6">Avg.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.5.1.1.1.7">Med.</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.5.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S4.T1.5.1.2.1.1">Beauty</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.2.1.2">1,274</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.2.1.3">1,076</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.1.2.1.4">7,113</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.2.1.5">0.519</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.2.1.6">5,58</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.2.1.7">5</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S4.T1.5.1.3.2.1">FS-NYC</th>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.3.2.2">1,083</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.3.2.3">9,989</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.3.2.4">179,468</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.3.2.5">1.659</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.3.2.6">165</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.3.2.7">116</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S4.T1.5.1.4.3.1">FS-TKY</th>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.4.3.2">2,293</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.4.3.3">15,177</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.4.3.4">494,807</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.4.3.5">1.421</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.4.3.6">215</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.4.3.7">146</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S4.T1.5.1.5.4.1">ML-100k</th>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.5.4.2">943</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.5.4.3">1,349</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.5.4.4">99,287</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.5.4.5">7.805</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.5.4.6">105</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.5.4.7">64</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S4.T1.5.1.6.5.1">ML-1M</th>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.6.5.2">6,040</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.6.5.3">3,416</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.6.5.4">999,611</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.6.5.5">4.845</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.6.5.6">165</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.6.5.7">96</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr" id="S4.T1.5.1.7.6.1">ML-20M</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.5.1.7.6.2">138,493</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.5.1.7.6.3">18,345</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.5.1.7.6.4">19,984,024</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.5.1.7.6.5">0.787</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.5.1.7.6.6">144</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.5.1.7.6.7">68</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Datasets</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Our dataset collection includes the following:</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">Amazon<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://jmcauley.ucsd.edu/data/amazon/" title="">https://jmcauley.ucsd.edu/data/amazon/</a></span></span></span>: These datasets consist of product reviews collected from Amazon.com by <cite class="ltx_cite ltx_citemacro_citet">McAuley et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib26" title="">2015</a>)</cite>. The data are organized into distinct datasets based on Amazon’s primary product categories.
For our study, we focus on the “Beauty” category (Beauty).</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">Foursquare<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://sites.google.com/site/yangdingqi/home/foursquare-dataset" title="">https://sites.google.com/site/yangdingqi/home/foursquare-dataset</a></span></span></span>: These datasets contain check-ins collected over a period of approximately ten months <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib41" title="">2015</a>)</cite>. We use the New York City (FS-NYC) and Tokyo (FS-TKY) versions.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">MovieLens<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://grouplens.org/datasets/movielens" title="">https://grouplens.org/datasets/movielens</a></span></span></span>: The MovieLens dataset <cite class="ltx_cite ltx_citemacro_citep">(Harper and Konstan, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib13" title="">2015</a>)</cite> is widely recognized as a benchmark for evaluating recommendation algorithms. We utilize three versions: MovieLens 20M (ML-20M), MovieLens 1M (ML-1M) and MovieLens 100k (ML-100k).</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">The statistics of these datasets are presented in <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S4.T1" title="In Running experiments ‣ 4.1. Resource ‣ 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_figure" id="S4.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_landscape" height="476" id="S4.F1.g1" src="x1.png" width="747"/></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F1.11.5.1" style="font-size:90%;">Figure 1</span>. </span><span class="ltx_text" id="S4.F1.8.4" style="font-size:90%;">A visual depiction illustrating the core functionality of the considered SRSs. The input items <math alttext="{i_{1},i_{2},\dots,i_{L}}" class="ltx_Math" display="inline" id="S4.F1.5.1.m1.4"><semantics id="S4.F1.5.1.m1.4b"><mrow id="S4.F1.5.1.m1.4.4.3" xref="S4.F1.5.1.m1.4.4.4.cmml"><msub id="S4.F1.5.1.m1.2.2.1.1" xref="S4.F1.5.1.m1.2.2.1.1.cmml"><mi id="S4.F1.5.1.m1.2.2.1.1.2" xref="S4.F1.5.1.m1.2.2.1.1.2.cmml">i</mi><mn id="S4.F1.5.1.m1.2.2.1.1.3" xref="S4.F1.5.1.m1.2.2.1.1.3.cmml">1</mn></msub><mo id="S4.F1.5.1.m1.4.4.3.4" xref="S4.F1.5.1.m1.4.4.4.cmml">,</mo><msub id="S4.F1.5.1.m1.3.3.2.2" xref="S4.F1.5.1.m1.3.3.2.2.cmml"><mi id="S4.F1.5.1.m1.3.3.2.2.2" xref="S4.F1.5.1.m1.3.3.2.2.2.cmml">i</mi><mn id="S4.F1.5.1.m1.3.3.2.2.3" xref="S4.F1.5.1.m1.3.3.2.2.3.cmml">2</mn></msub><mo id="S4.F1.5.1.m1.4.4.3.5" xref="S4.F1.5.1.m1.4.4.4.cmml">,</mo><mi id="S4.F1.5.1.m1.1.1" mathvariant="normal" xref="S4.F1.5.1.m1.1.1.cmml">…</mi><mo id="S4.F1.5.1.m1.4.4.3.6" xref="S4.F1.5.1.m1.4.4.4.cmml">,</mo><msub id="S4.F1.5.1.m1.4.4.3.3" xref="S4.F1.5.1.m1.4.4.3.3.cmml"><mi id="S4.F1.5.1.m1.4.4.3.3.2" xref="S4.F1.5.1.m1.4.4.3.3.2.cmml">i</mi><mi id="S4.F1.5.1.m1.4.4.3.3.3" xref="S4.F1.5.1.m1.4.4.3.3.3.cmml">L</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.F1.5.1.m1.4c"><list id="S4.F1.5.1.m1.4.4.4.cmml" xref="S4.F1.5.1.m1.4.4.3"><apply id="S4.F1.5.1.m1.2.2.1.1.cmml" xref="S4.F1.5.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S4.F1.5.1.m1.2.2.1.1.1.cmml" xref="S4.F1.5.1.m1.2.2.1.1">subscript</csymbol><ci id="S4.F1.5.1.m1.2.2.1.1.2.cmml" xref="S4.F1.5.1.m1.2.2.1.1.2">𝑖</ci><cn id="S4.F1.5.1.m1.2.2.1.1.3.cmml" type="integer" xref="S4.F1.5.1.m1.2.2.1.1.3">1</cn></apply><apply id="S4.F1.5.1.m1.3.3.2.2.cmml" xref="S4.F1.5.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S4.F1.5.1.m1.3.3.2.2.1.cmml" xref="S4.F1.5.1.m1.3.3.2.2">subscript</csymbol><ci id="S4.F1.5.1.m1.3.3.2.2.2.cmml" xref="S4.F1.5.1.m1.3.3.2.2.2">𝑖</ci><cn id="S4.F1.5.1.m1.3.3.2.2.3.cmml" type="integer" xref="S4.F1.5.1.m1.3.3.2.2.3">2</cn></apply><ci id="S4.F1.5.1.m1.1.1.cmml" xref="S4.F1.5.1.m1.1.1">…</ci><apply id="S4.F1.5.1.m1.4.4.3.3.cmml" xref="S4.F1.5.1.m1.4.4.3.3"><csymbol cd="ambiguous" id="S4.F1.5.1.m1.4.4.3.3.1.cmml" xref="S4.F1.5.1.m1.4.4.3.3">subscript</csymbol><ci id="S4.F1.5.1.m1.4.4.3.3.2.cmml" xref="S4.F1.5.1.m1.4.4.3.3.2">𝑖</ci><ci id="S4.F1.5.1.m1.4.4.3.3.3.cmml" xref="S4.F1.5.1.m1.4.4.3.3.3">𝐿</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.F1.5.1.m1.4d">{i_{1},i_{2},\dots,i_{L}}</annotation><annotation encoding="application/x-llamapun" id="S4.F1.5.1.m1.4e">italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_i start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT</annotation></semantics></math> are processed to generate the final representations <math alttext="{z_{1},z_{2},\dots,z_{L}}" class="ltx_Math" display="inline" id="S4.F1.6.2.m2.4"><semantics id="S4.F1.6.2.m2.4b"><mrow id="S4.F1.6.2.m2.4.4.3" xref="S4.F1.6.2.m2.4.4.4.cmml"><msub id="S4.F1.6.2.m2.2.2.1.1" xref="S4.F1.6.2.m2.2.2.1.1.cmml"><mi id="S4.F1.6.2.m2.2.2.1.1.2" xref="S4.F1.6.2.m2.2.2.1.1.2.cmml">z</mi><mn id="S4.F1.6.2.m2.2.2.1.1.3" xref="S4.F1.6.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S4.F1.6.2.m2.4.4.3.4" xref="S4.F1.6.2.m2.4.4.4.cmml">,</mo><msub id="S4.F1.6.2.m2.3.3.2.2" xref="S4.F1.6.2.m2.3.3.2.2.cmml"><mi id="S4.F1.6.2.m2.3.3.2.2.2" xref="S4.F1.6.2.m2.3.3.2.2.2.cmml">z</mi><mn id="S4.F1.6.2.m2.3.3.2.2.3" xref="S4.F1.6.2.m2.3.3.2.2.3.cmml">2</mn></msub><mo id="S4.F1.6.2.m2.4.4.3.5" xref="S4.F1.6.2.m2.4.4.4.cmml">,</mo><mi id="S4.F1.6.2.m2.1.1" mathvariant="normal" xref="S4.F1.6.2.m2.1.1.cmml">…</mi><mo id="S4.F1.6.2.m2.4.4.3.6" xref="S4.F1.6.2.m2.4.4.4.cmml">,</mo><msub id="S4.F1.6.2.m2.4.4.3.3" xref="S4.F1.6.2.m2.4.4.3.3.cmml"><mi id="S4.F1.6.2.m2.4.4.3.3.2" xref="S4.F1.6.2.m2.4.4.3.3.2.cmml">z</mi><mi id="S4.F1.6.2.m2.4.4.3.3.3" xref="S4.F1.6.2.m2.4.4.3.3.3.cmml">L</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.F1.6.2.m2.4c"><list id="S4.F1.6.2.m2.4.4.4.cmml" xref="S4.F1.6.2.m2.4.4.3"><apply id="S4.F1.6.2.m2.2.2.1.1.cmml" xref="S4.F1.6.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S4.F1.6.2.m2.2.2.1.1.1.cmml" xref="S4.F1.6.2.m2.2.2.1.1">subscript</csymbol><ci id="S4.F1.6.2.m2.2.2.1.1.2.cmml" xref="S4.F1.6.2.m2.2.2.1.1.2">𝑧</ci><cn id="S4.F1.6.2.m2.2.2.1.1.3.cmml" type="integer" xref="S4.F1.6.2.m2.2.2.1.1.3">1</cn></apply><apply id="S4.F1.6.2.m2.3.3.2.2.cmml" xref="S4.F1.6.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S4.F1.6.2.m2.3.3.2.2.1.cmml" xref="S4.F1.6.2.m2.3.3.2.2">subscript</csymbol><ci id="S4.F1.6.2.m2.3.3.2.2.2.cmml" xref="S4.F1.6.2.m2.3.3.2.2.2">𝑧</ci><cn id="S4.F1.6.2.m2.3.3.2.2.3.cmml" type="integer" xref="S4.F1.6.2.m2.3.3.2.2.3">2</cn></apply><ci id="S4.F1.6.2.m2.1.1.cmml" xref="S4.F1.6.2.m2.1.1">…</ci><apply id="S4.F1.6.2.m2.4.4.3.3.cmml" xref="S4.F1.6.2.m2.4.4.3.3"><csymbol cd="ambiguous" id="S4.F1.6.2.m2.4.4.3.3.1.cmml" xref="S4.F1.6.2.m2.4.4.3.3">subscript</csymbol><ci id="S4.F1.6.2.m2.4.4.3.3.2.cmml" xref="S4.F1.6.2.m2.4.4.3.3.2">𝑧</ci><ci id="S4.F1.6.2.m2.4.4.3.3.3.cmml" xref="S4.F1.6.2.m2.4.4.3.3.3">𝐿</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.F1.6.2.m2.4d">{z_{1},z_{2},\dots,z_{L}}</annotation><annotation encoding="application/x-llamapun" id="S4.F1.6.2.m2.4e">italic_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_z start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT</annotation></semantics></math>, which are utilized to generate predictions at steps <math alttext="1,2,\dots,L" class="ltx_Math" display="inline" id="S4.F1.7.3.m3.4"><semantics id="S4.F1.7.3.m3.4b"><mrow id="S4.F1.7.3.m3.4.5.2" xref="S4.F1.7.3.m3.4.5.1.cmml"><mn id="S4.F1.7.3.m3.1.1" xref="S4.F1.7.3.m3.1.1.cmml">1</mn><mo id="S4.F1.7.3.m3.4.5.2.1" xref="S4.F1.7.3.m3.4.5.1.cmml">,</mo><mn id="S4.F1.7.3.m3.2.2" xref="S4.F1.7.3.m3.2.2.cmml">2</mn><mo id="S4.F1.7.3.m3.4.5.2.2" xref="S4.F1.7.3.m3.4.5.1.cmml">,</mo><mi id="S4.F1.7.3.m3.3.3" mathvariant="normal" xref="S4.F1.7.3.m3.3.3.cmml">…</mi><mo id="S4.F1.7.3.m3.4.5.2.3" xref="S4.F1.7.3.m3.4.5.1.cmml">,</mo><mi id="S4.F1.7.3.m3.4.4" xref="S4.F1.7.3.m3.4.4.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.F1.7.3.m3.4c"><list id="S4.F1.7.3.m3.4.5.1.cmml" xref="S4.F1.7.3.m3.4.5.2"><cn id="S4.F1.7.3.m3.1.1.cmml" type="integer" xref="S4.F1.7.3.m3.1.1">1</cn><cn id="S4.F1.7.3.m3.2.2.cmml" type="integer" xref="S4.F1.7.3.m3.2.2">2</cn><ci id="S4.F1.7.3.m3.3.3.cmml" xref="S4.F1.7.3.m3.3.3">…</ci><ci id="S4.F1.7.3.m3.4.4.cmml" xref="S4.F1.7.3.m3.4.4">𝐿</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.F1.7.3.m3.4d">1,2,\dots,L</annotation><annotation encoding="application/x-llamapun" id="S4.F1.7.3.m3.4e">1 , 2 , … , italic_L</annotation></semantics></math>, respectively. Intermediate representations <math alttext="{h_{1},h_{2},\dots,h_{L}}" class="ltx_Math" display="inline" id="S4.F1.8.4.m4.4"><semantics id="S4.F1.8.4.m4.4b"><mrow id="S4.F1.8.4.m4.4.4.3" xref="S4.F1.8.4.m4.4.4.4.cmml"><msub id="S4.F1.8.4.m4.2.2.1.1" xref="S4.F1.8.4.m4.2.2.1.1.cmml"><mi id="S4.F1.8.4.m4.2.2.1.1.2" xref="S4.F1.8.4.m4.2.2.1.1.2.cmml">h</mi><mn id="S4.F1.8.4.m4.2.2.1.1.3" xref="S4.F1.8.4.m4.2.2.1.1.3.cmml">1</mn></msub><mo id="S4.F1.8.4.m4.4.4.3.4" xref="S4.F1.8.4.m4.4.4.4.cmml">,</mo><msub id="S4.F1.8.4.m4.3.3.2.2" xref="S4.F1.8.4.m4.3.3.2.2.cmml"><mi id="S4.F1.8.4.m4.3.3.2.2.2" xref="S4.F1.8.4.m4.3.3.2.2.2.cmml">h</mi><mn id="S4.F1.8.4.m4.3.3.2.2.3" xref="S4.F1.8.4.m4.3.3.2.2.3.cmml">2</mn></msub><mo id="S4.F1.8.4.m4.4.4.3.5" xref="S4.F1.8.4.m4.4.4.4.cmml">,</mo><mi id="S4.F1.8.4.m4.1.1" mathvariant="normal" xref="S4.F1.8.4.m4.1.1.cmml">…</mi><mo id="S4.F1.8.4.m4.4.4.3.6" xref="S4.F1.8.4.m4.4.4.4.cmml">,</mo><msub id="S4.F1.8.4.m4.4.4.3.3" xref="S4.F1.8.4.m4.4.4.3.3.cmml"><mi id="S4.F1.8.4.m4.4.4.3.3.2" xref="S4.F1.8.4.m4.4.4.3.3.2.cmml">h</mi><mi id="S4.F1.8.4.m4.4.4.3.3.3" xref="S4.F1.8.4.m4.4.4.3.3.3.cmml">L</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.F1.8.4.m4.4c"><list id="S4.F1.8.4.m4.4.4.4.cmml" xref="S4.F1.8.4.m4.4.4.3"><apply id="S4.F1.8.4.m4.2.2.1.1.cmml" xref="S4.F1.8.4.m4.2.2.1.1"><csymbol cd="ambiguous" id="S4.F1.8.4.m4.2.2.1.1.1.cmml" xref="S4.F1.8.4.m4.2.2.1.1">subscript</csymbol><ci id="S4.F1.8.4.m4.2.2.1.1.2.cmml" xref="S4.F1.8.4.m4.2.2.1.1.2">ℎ</ci><cn id="S4.F1.8.4.m4.2.2.1.1.3.cmml" type="integer" xref="S4.F1.8.4.m4.2.2.1.1.3">1</cn></apply><apply id="S4.F1.8.4.m4.3.3.2.2.cmml" xref="S4.F1.8.4.m4.3.3.2.2"><csymbol cd="ambiguous" id="S4.F1.8.4.m4.3.3.2.2.1.cmml" xref="S4.F1.8.4.m4.3.3.2.2">subscript</csymbol><ci id="S4.F1.8.4.m4.3.3.2.2.2.cmml" xref="S4.F1.8.4.m4.3.3.2.2.2">ℎ</ci><cn id="S4.F1.8.4.m4.3.3.2.2.3.cmml" type="integer" xref="S4.F1.8.4.m4.3.3.2.2.3">2</cn></apply><ci id="S4.F1.8.4.m4.1.1.cmml" xref="S4.F1.8.4.m4.1.1">…</ci><apply id="S4.F1.8.4.m4.4.4.3.3.cmml" xref="S4.F1.8.4.m4.4.4.3.3"><csymbol cd="ambiguous" id="S4.F1.8.4.m4.4.4.3.3.1.cmml" xref="S4.F1.8.4.m4.4.4.3.3">subscript</csymbol><ci id="S4.F1.8.4.m4.4.4.3.3.2.cmml" xref="S4.F1.8.4.m4.4.4.3.3.2">ℎ</ci><ci id="S4.F1.8.4.m4.4.4.3.3.3.cmml" xref="S4.F1.8.4.m4.4.4.3.3.3">𝐿</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.F1.8.4.m4.4d">{h_{1},h_{2},\dots,h_{L}}</annotation><annotation encoding="application/x-llamapun" id="S4.F1.8.4.m4.4e">italic_h start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_h start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_h start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT</annotation></semantics></math> are also present for some models.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_figure_panel undefined" id="S4.F1.12">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="S4.F1.9">[A visual depiction illustrating the core functionality of the considered SRSs.]For each SRS, the input items are processed to generate the final representations, which are utilized to generate predictions at steps <math alttext="1,2,\dots,L" class="ltx_Math" display="inline" id="S4.F1.9.m1.4"><semantics id="S4.F1.9.m1.4a"><mrow id="S4.F1.9.m1.4.5.2" xref="S4.F1.9.m1.4.5.1.cmml"><mn id="S4.F1.9.m1.1.1" xref="S4.F1.9.m1.1.1.cmml">1</mn><mo id="S4.F1.9.m1.4.5.2.1" xref="S4.F1.9.m1.4.5.1.cmml">,</mo><mn id="S4.F1.9.m1.2.2" xref="S4.F1.9.m1.2.2.cmml">2</mn><mo id="S4.F1.9.m1.4.5.2.2" xref="S4.F1.9.m1.4.5.1.cmml">,</mo><mi id="S4.F1.9.m1.3.3" mathvariant="normal" xref="S4.F1.9.m1.3.3.cmml">…</mi><mo id="S4.F1.9.m1.4.5.2.3" xref="S4.F1.9.m1.4.5.1.cmml">,</mo><mi id="S4.F1.9.m1.4.4" xref="S4.F1.9.m1.4.4.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.F1.9.m1.4b"><list id="S4.F1.9.m1.4.5.1.cmml" xref="S4.F1.9.m1.4.5.2"><cn id="S4.F1.9.m1.1.1.cmml" type="integer" xref="S4.F1.9.m1.1.1">1</cn><cn id="S4.F1.9.m1.2.2.cmml" type="integer" xref="S4.F1.9.m1.2.2">2</cn><ci id="S4.F1.9.m1.3.3.cmml" xref="S4.F1.9.m1.3.3">…</ci><ci id="S4.F1.9.m1.4.4.cmml" xref="S4.F1.9.m1.4.4">𝐿</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.F1.9.m1.4c">1,2,\dots,L</annotation><annotation encoding="application/x-llamapun" id="S4.F1.9.m1.4d">1 , 2 , … , italic_L</annotation></semantics></math>, respectively.</p>
</div>
</div>
</figure>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Data pre-processing</h4>
<div class="ltx_para" id="S4.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px1.p1.1">Our pre-processing strategy follows established practices, such as treating ratings as implicit, i.e. use all interactions without considering the rating value, and removing users and items with fewer than 5 interactions <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib19" title="">2018</a>; Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib35" title="">2019</a>; Petrov and Macdonald, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib30" title="">2022</a>)</cite>.
For testing, as in <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib35" title="">2019</a>; Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib19" title="">2018</a>)</cite>, we keep the last interaction for each user, while for the validation set, the second to last action is retained. All remaining interactions contribute to the training set.
Each observed user-item interaction is treated as a positive instance, and negative items are sampled from items not previously consumed by the user.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Models</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">We employ five sequential recommendation models in our experiments, each based on seminal papers widely cited in the literature. While a more detailed discussion of these models is provided in <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S2" title="2. Related Work ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">2</span></a>, here we offer a succinct overview of their differences:</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1">BERT4Rec <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib35" title="">2019</a>)</cite>: This model is based on the BERT architecture, enabling it to capture complex relationships in user behaviour sequences through bidirectional self-attention.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1">CORE <cite class="ltx_cite ltx_citemacro_citep">(Hou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib17" title="">2022</a>)</cite>: it introduces an attention mechanism that enables the model to weigh the contribution of each item in the input sequence, enhancing recommendation accuracy.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i3.p1">
<p class="ltx_p" id="S4.I2.i3.p1.1">GRU4Rec <cite class="ltx_cite ltx_citemacro_citep">(Hidasi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib16" title="">2016</a>)</cite>: This model utilizes GRUs to capture temporal dependencies in user-item interactions.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i4.p1">
<p class="ltx_p" id="S4.I2.i4.p1.1">NARM <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib22" title="">2017</a>)</cite>: it also leverages GRUs, but incorporates a custom attention mechanism to capture both local and global preferences in user-item sequences.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i5.p1">
<p class="ltx_p" id="S4.I2.i5.p1.1">SASRec <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib19" title="">2018</a>)</cite>: this model is characterized by its use of self-attention mechanisms, allowing it to discern the relevance of each item within the user’s sequence.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">It’s crucial to distinguish between sequence-to-sequence models (GRU4Rec, SASRec, BERT4Rec) and sequence-to-item models (NARM, CORE). Sequence-to-sequence models analyze input sequences in detail, generating predictions at each step, addressing issues like vanishing gradients in long sequences <cite class="ltx_cite ltx_citemacro_citep">(Pascanu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib28" title="">2013</a>)</cite>. They require fewer samples as each sequence generates multiple predictions, effectively increasing training capacity. Conversely, sequence-to-item models process the entire input sequence but only predict at the last step, reducing training capacity compared to sequence-to-sequence models. The original works <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib22" title="">2017</a>; Hou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib17" title="">2022</a>)</cite> likely counter this by using shorter input lengths, reducing the need for a large number of training samples.
A schematic diagram illustrating the functioning of each model is provided in <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S4.F1" title="In 4.2. Datasets ‣ 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.14.3.1" style="font-size:90%;">Table 2</span>. </span><span class="ltx_text" id="S4.T2.4.2" style="font-size:90%;">Comparison using MovieLens 1M dataset. RecBole<sup class="ltx_sup" id="S4.T2.4.2.1"><span class="ltx_text ltx_font_italic" id="S4.T2.4.2.1.1">a</span></sup> represents a model trained until it matches our metrics, while RecBole<sup class="ltx_sup" id="S4.T2.4.2.2"><span class="ltx_text ltx_font_italic" id="S4.T2.4.2.2.1">b</span></sup> refers to the model trained for the same time as ours.</span></figcaption>
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.10">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.10.7.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.10.7.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.7.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T2.10.7.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.10.7.1.2.1">GRU4Rec</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T2.10.7.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.10.7.1.3.1">SASRec</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T2.10.7.1.4"><span class="ltx_text ltx_font_bold" id="S4.T2.10.7.1.4.1">BERT4Rec</span></th>
</tr>
<tr class="ltx_tr" id="S4.T2.10.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.10.6.7"><span class="ltx_text ltx_font_bold" id="S4.T2.10.6.7.1">Implementation</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.10.6.8"><span class="ltx_text ltx_font_italic" id="S4.T2.10.6.8.1">EasyRec</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.5.1.1"><span class="ltx_text ltx_font_italic" id="S4.T2.5.1.1.1">RecBole<sup class="ltx_sup" id="S4.T2.5.1.1.1.1">a</sup></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.6.2.2"><span class="ltx_text ltx_font_italic" id="S4.T2.6.2.2.1">RecBole<sup class="ltx_sup" id="S4.T2.6.2.2.1.1">b</sup></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.10.6.9"><span class="ltx_text ltx_font_italic" id="S4.T2.10.6.9.1">EasyRec</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.7.3.3"><span class="ltx_text ltx_font_italic" id="S4.T2.7.3.3.1">RecBole<sup class="ltx_sup" id="S4.T2.7.3.3.1.1">a</sup></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.8.4.4"><span class="ltx_text ltx_font_italic" id="S4.T2.8.4.4.1">RecBole<sup class="ltx_sup" id="S4.T2.8.4.4.1.1">b</sup></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.10.6.10"><span class="ltx_text ltx_font_italic" id="S4.T2.10.6.10.1">EasyRec</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.9.5.5"><span class="ltx_text ltx_font_italic" id="S4.T2.9.5.5.1">RecBole<sup class="ltx_sup" id="S4.T2.9.5.5.1.1">a</sup></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.10.6.6"><span class="ltx_text ltx_font_italic" id="S4.T2.10.6.6.1">RecBole<sup class="ltx_sup" id="S4.T2.10.6.6.1.1">b</sup></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.10.8.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.10.8.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.8.1.1.1">NDCG@10</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.10.8.1.2">0.56</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.10.8.1.3">0.56</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.10.8.1.4">0.48</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.10.8.1.5">0.51</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.10.8.1.6">0.51</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.10.8.1.7">0.45</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.10.8.1.8">0.49</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.10.8.1.9">0.49</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.10.8.1.10">0.43</td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.9.2">
<td class="ltx_td ltx_align_center" id="S4.T2.10.9.2.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.9.2.1.1">Recall@20</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.9.2.2">0.88</td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.9.2.3">0.88</td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.9.2.4">0.85</td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.9.2.5">0.86</td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.9.2.6">0.86</td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.9.2.7">0.84</td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.9.2.8">0.86</td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.9.2.9">0.86</td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.9.2.10">0.83</td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.10.3">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.10.10.3.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.10.3.1.1">Time</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.10.10.3.2">28min</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.10.10.3.3">1330min</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.10.10.3.4">32min</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.10.10.3.5">38min</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.10.10.3.6">360min</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.10.10.3.7">48min</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.10.10.3.8">51min</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.10.10.3.9">220min</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.10.10.3.10">68min</td>
</tr>
</tbody>
</table>
</figure>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Training</h4>
<div class="ltx_para" id="S4.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p1.1">A common loss function for training SRSs <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib19" title="">2018</a>; Tang and Wang, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib37" title="">2018</a>)</cite> is Binary Cross Entropy (BCE) <cite class="ltx_cite ltx_citemacro_citep">(Good, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib12" title="">1952</a>)</cite>. While some studies explore variations in training methods <cite class="ltx_cite ltx_citemacro_citep">(Hidasi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib16" title="">2016</a>; Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib22" title="">2017</a>)</cite>, our primary focus is on evaluating the architecture itself, with the aim of isolating its capabilities from the effects of different loss functions.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS0.Px1.p2">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p2.1">We trained all models for <math alttext="400" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px1.p2.1.m1.1"><semantics id="S4.SS3.SSS0.Px1.p2.1.m1.1a"><mn id="S4.SS3.SSS0.Px1.p2.1.m1.1.1" xref="S4.SS3.SSS0.Px1.p2.1.m1.1.1.cmml">400</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p2.1.m1.1b"><cn id="S4.SS3.SSS0.Px1.p2.1.m1.1.1.cmml" type="integer" xref="S4.SS3.SSS0.Px1.p2.1.m1.1.1">400</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p2.1.m1.1c">400</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px1.p2.1.m1.1d">400</annotation></semantics></math> epochs, and for each model, we selected the checkpoint from the epoch where it achieved the highest performance on the validation set.
We also utilize the same optimiser, batch size, number of negative items per training and testing instance, and other relevant parameters. By maintaining consistency in these aspects, we aim to eliminate potential confounding factors and facilitate a clear assessment of architectural differences.
For ease of reproducibility and transparency, all relevant parameters and configurations are carefully documented and made available in our code repository <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#footnote2" title="Footnote 2 ‣ Reproducibility ‣ 4.1. Resource ‣ 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_tag">2</span></a>. All experiments were performed on a single NVIDIA RTX A6000 with 10752 CUDA cores and 48 GB of VRAM.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Metrics</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">To evaluate the performance of sequential recommendation algorithms, we use four widely used metric, also common in Information Retrieval (IR): Precision, Recall, NDCG and MAP.</p>
</div>
<section class="ltx_paragraph" id="S4.SS4.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Tracking Emissions</h4>
<div class="ltx_para" id="S4.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS4.SSS0.Px1.p1.1">In the Glasgow Agreement <cite class="ltx_cite ltx_citemacro_citep">(Hunter et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib18" title="">2021</a>)</cite> climate change highlights the international commitment to reduce CO<sub class="ltx_sub" id="S4.SS4.SSS0.Px1.p1.1.1">2</sub> emissions. This is especially important in the field of Artificial Intelligence, where training GPUs has a significant environmental impact. The energy consumption associated with these computational processes contributes significantly to CO<sub class="ltx_sub" id="S4.SS4.SSS0.Px1.p1.1.2">2</sub> emissions, exacerbating climate change <cite class="ltx_cite ltx_citemacro_citep">(Patterson et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib29" title="">2021</a>)</cite>. It is therefore our responsibility to raise awareness of this issue.</p>
</div>
<div class="ltx_para" id="S4.SS4.SSS0.Px1.p2">
<p class="ltx_p" id="S4.SS4.SSS0.Px1.p2.1">In this study, we use CodeCarbon<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://codecarbon.io" title="">https://codecarbon.io</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Courty et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib6" title="">2023</a>)</cite>, a tool designed to track the power consumption of both CPUs and GPUs. This allows us to measure carbon dioxide equivalent (CO<sub class="ltx_sub" id="S4.SS4.SSS0.Px1.p2.1.1">2</sub>-eq), a widely accepted standard to monitor emissions of various greenhouse gases <cite class="ltx_cite ltx_citemacro_citep">(Kim and Neff, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib20" title="">2009</a>)</cite>. CO<sub class="ltx_sub" id="S4.SS4.SSS0.Px1.p2.1.2">2</sub>-eq facilitates the comparison of greenhouse gas emissions by converting quantities of different gases into an equivalent amount of CO<sub class="ltx_sub" id="S4.SS4.SSS0.Px1.p2.1.3">2</sub>, based on their respective global warming potentials.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5. </span>Comparisons</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.2">The importance of our resource lies primarily in the fact that it fills a notable gap in the existing literature and libraries. In particular, Elliot <cite class="ltx_cite ltx_citemacro_citep">(Anelli et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib2" title="">2021</a>)</cite> and DaisyRec <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib36" title="">2020</a>)</cite> lack SRS models, while Cornac <cite class="ltx_cite ltx_citemacro_citep">(Salah et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib33" title="">2020</a>)</cite> and RecPack <cite class="ltx_cite ltx_citemacro_citep">(Michiels et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib27" title="">2022</a>)</cite> provide only GRU4Rec among newer models. Although ReChorus <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib39" title="">2020</a>)</cite> supports many models, it lacks one of the most cited ones (BERT4Rec) and modern ones. Conversely, RecBole <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib42" title="">2021</a>)</cite> stands out as a comprehensive framework that is widely used in the field. However, it requires the creation of a subclass of its classes to develop new models or datasets. In contrast, our approach allows the extension of the PyTorch standard class for all new models. Furthermore, existing literature highlights suboptimal performance metrics, timing, and implementation quality in RecBole <cite class="ltx_cite ltx_citemacro_citep">(Hidasi and Czapp, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib14" title="">2023a</a>; Petrov and Macdonald, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib30" title="">2022</a>)</cite>. Recbole’s performance, evaluated on the same number of epochs, is compromised by performing many iterations per epoch due to their data augmentation method <span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://recbole.io/docs/recbole/recbole.data.dataset.sequential_dataset.html" title="">https://recbole.io/docs/recbole/recbole.data.dataset.sequential_dataset.html</a></span></span></span>. Moreover, they did not implement BCE loss, which is used in several works <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib19" title="">2018</a>)</cite>, as also indicated on the official GitHub repository <span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/RUCAIBox/RecBole/issues/1667" title="">https://github.com/RUCAIBox/RecBole/issues/1667</a></span></span></span>, so their implementations are not loyal to the originals. We changed their loss to be consistent with the original works. <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S4.T2" title="In 4.3. Models ‣ 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">2</span></a> shows the comparison between our implementation and that of RecBole using ML-1M and the three most common and widely used models in the literature: SASRec, GRU4Rec, and BERT4Rec, in terms of metrics and time. By RecBole<sup class="ltx_sup" id="S4.SS5.p1.2.1"><span class="ltx_text ltx_font_italic" id="S4.SS5.p1.2.1.1">a</span></sup>, we refer to models that are tracked until they reach our metrics, while by RecBole<sup class="ltx_sup" id="S4.SS5.p1.2.2"><span class="ltx_text ltx_font_italic" id="S4.SS5.p1.2.2.1">b</span></sup> we refer to models that are tracked for our own time. The experimental setup is the same as described in <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S5.SSx1" title="RQ1: Base Performance ‣ 5. Results ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5</span></a>. We outperform RecBole in every model.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Results</h2>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T3.39.5.1" style="font-size:90%;">Table 3</span>. </span><span class="ltx_text" id="S5.T3.8.4" style="font-size:90%;">Results of the proposed models in terms of Precision@K (P@K), Recall@K (R@K), NDCG@K and MAP@K, with <span class="ltx_text" id="S5.T3.5.1.1">K <math alttext="\mathbf{\in\{10,20\}}" class="ltx_Math" display="inline" id="S5.T3.5.1.1.m1.2"><semantics id="S5.T3.5.1.1.m1.2b"><mrow id="S5.T3.5.1.1.m1.2.3" xref="S5.T3.5.1.1.m1.2.3.cmml"><mi id="S5.T3.5.1.1.m1.2.3.2" xref="S5.T3.5.1.1.m1.2.3.2.cmml"></mi><mo id="S5.T3.5.1.1.m1.2.3.1" xref="S5.T3.5.1.1.m1.2.3.1.cmml">∈</mo><mrow id="S5.T3.5.1.1.m1.2.3.3.2" xref="S5.T3.5.1.1.m1.2.3.3.1.cmml"><mo id="S5.T3.5.1.1.m1.2.3.3.2.1" stretchy="false" xref="S5.T3.5.1.1.m1.2.3.3.1.cmml">{</mo><mn id="S5.T3.5.1.1.m1.1.1" xref="S5.T3.5.1.1.m1.1.1.cmml">𝟏𝟎</mn><mo id="S5.T3.5.1.1.m1.2.3.3.2.2" xref="S5.T3.5.1.1.m1.2.3.3.1.cmml">,</mo><mn id="S5.T3.5.1.1.m1.2.2" xref="S5.T3.5.1.1.m1.2.2.cmml">𝟐𝟎</mn><mo id="S5.T3.5.1.1.m1.2.3.3.2.3" stretchy="false" xref="S5.T3.5.1.1.m1.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.5.1.1.m1.2c"><apply id="S5.T3.5.1.1.m1.2.3.cmml" xref="S5.T3.5.1.1.m1.2.3"><in id="S5.T3.5.1.1.m1.2.3.1.cmml" xref="S5.T3.5.1.1.m1.2.3.1"></in><csymbol cd="latexml" id="S5.T3.5.1.1.m1.2.3.2.cmml" xref="S5.T3.5.1.1.m1.2.3.2">absent</csymbol><set id="S5.T3.5.1.1.m1.2.3.3.1.cmml" xref="S5.T3.5.1.1.m1.2.3.3.2"><cn id="S5.T3.5.1.1.m1.1.1.cmml" type="integer" xref="S5.T3.5.1.1.m1.1.1">10</cn><cn id="S5.T3.5.1.1.m1.2.2.cmml" type="integer" xref="S5.T3.5.1.1.m1.2.2">20</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.5.1.1.m1.2d">\mathbf{\in\{10,20\}}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.5.1.1.m1.2e">∈ { bold_10 , bold_20 }</annotation></semantics></math></span>. <span class="ltx_text ltx_font_bold" id="S5.T3.8.4.2">Bold</span> denotes the best model for a dataset by the metric in the main group, <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.8.4.3">underlined</span> the second best. <sup class="ltx_sup" id="S5.T3.8.4.4">†</sup> indicates a statistically significant result with <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S5.T3.8.4.5">p</span>-value <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S5.T3.8.4.6">¡ 0.01</span>.</span></figcaption>
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T3.32">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T3.32.25.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T3.32.25.1.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.25.1.1.1">Dataset</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S5.T3.32.25.1.2"><span class="ltx_text ltx_font_bold" id="S5.T3.32.25.1.2.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.32.25.1.3"><span class="ltx_text ltx_font_bold" id="S5.T3.32.25.1.3.1">P@10</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.32.25.1.4"><span class="ltx_text ltx_font_bold" id="S5.T3.32.25.1.4.1">R@10</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.32.25.1.5"><span class="ltx_text ltx_font_bold" id="S5.T3.32.25.1.5.1">NDCG@10</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T3.32.25.1.6"><span class="ltx_text ltx_font_bold" id="S5.T3.32.25.1.6.1">MAP@10</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.32.25.1.7"><span class="ltx_text ltx_font_bold" id="S5.T3.32.25.1.7.1">P@20</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.32.25.1.8"><span class="ltx_text ltx_font_bold" id="S5.T3.32.25.1.8.1">R@20</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.32.25.1.9"><span class="ltx_text ltx_font_bold" id="S5.T3.32.25.1.9.1">NDCG@20</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.32.25.1.10"><span class="ltx_text ltx_font_bold" id="S5.T3.32.25.1.10.1">MAP@20</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.32.26.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.32.26.1.1" rowspan="5"><span class="ltx_text ltx_font_bold" id="S5.T3.32.26.1.1.1">Beauty</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.32.26.1.2"><span class="ltx_text ltx_font_bold" id="S5.T3.32.26.1.2.1">BERT4Rec</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.26.1.3"><span class="ltx_text ltx_font_bold" id="S5.T3.32.26.1.3.1">0.0707</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.26.1.4"><span class="ltx_text ltx_font_bold" id="S5.T3.32.26.1.4.1">0.7072</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.26.1.5"><span class="ltx_text ltx_font_bold" id="S5.T3.32.26.1.5.1">0.6828</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.32.26.1.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.26.1.6.1">0.1991</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.26.1.7">0.0362</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.26.1.8">0.7237</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.26.1.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.26.1.9.1">0.6848</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.26.1.10"><span class="ltx_text ltx_font_bold" id="S5.T3.32.26.1.10.1">0.1233</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.27.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.27.2.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.27.2.1.1">CORE</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.27.2.2">0.0695</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.27.2.3">0.6954</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.27.2.4">0.6594</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.27.2.5">0.1926</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.27.2.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.27.2.6.1">0.0366</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.27.2.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.27.2.7.1">0.7316</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.27.2.8">0.6673</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.27.2.9">0.1199</td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.28.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.28.3.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.28.3.1.1">GRU4Rec</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.28.3.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.28.3.2.1">0.0704</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.28.3.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.28.3.3.1">0.7041</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.28.3.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.28.3.4.1">0.6823</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.28.3.5"><span class="ltx_text ltx_font_bold" id="S5.T3.32.28.3.5.1">0.1992</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.28.3.6">0.0360</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.28.3.7">0.7198</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.28.3.8"><span class="ltx_text ltx_font_bold" id="S5.T3.32.28.3.8.1">0.6855</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.28.3.9"><span class="ltx_text ltx_font_bold" id="S5.T3.32.28.3.9.1">0.1233</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.29.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.29.4.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.29.4.1.1">NARM</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.29.4.2">0.0695</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.29.4.3">0.6954</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.29.4.4">0.6701</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.29.4.5">0.1957</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.29.4.6"><span class="ltx_text ltx_font_bold" id="S5.T3.32.29.4.6.1">0.037</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.29.4.7"><span class="ltx_text ltx_font_bold" id="S5.T3.32.29.4.7.1">0.7394</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.29.4.8">0.6754</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.29.4.9">0.1212</td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.30.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.30.5.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.30.5.1.1">SASRec</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.30.5.2">0.0703</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.30.5.3">0.7033</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.30.5.4">0.6650</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.30.5.5">0.1942</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.30.5.6">0.0364</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.30.5.7">0.7276</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.30.5.8">0.6703</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.30.5.9">0.1209</td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.31.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.32.31.6.1" rowspan="5"><span class="ltx_text ltx_font_bold" id="S5.T3.32.31.6.1.1">FS-NYC</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.32.31.6.2"><span class="ltx_text ltx_font_bold" id="S5.T3.32.31.6.2.1">BERT4Rec</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.31.6.3"><span class="ltx_text ltx_font_bold" id="S5.T3.32.31.6.3.1">0.0789</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.31.6.4"><span class="ltx_text ltx_font_bold" id="S5.T3.32.31.6.4.1">0.7895</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.31.6.5"><span class="ltx_text ltx_font_bold" id="S5.T3.32.31.6.5.1">0.6689</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.32.31.6.6"><span class="ltx_text ltx_font_bold" id="S5.T3.32.31.6.6.1">0.1909</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.31.6.7"><span class="ltx_text ltx_font_bold" id="S5.T3.32.31.6.7.1">0.0430</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.31.6.8"><span class="ltx_text ltx_font_bold" id="S5.T3.32.31.6.8.1">0.8596</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.31.6.9"><span class="ltx_text ltx_font_bold" id="S5.T3.32.31.6.9.1">0.6856</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.31.6.10"><span class="ltx_text ltx_font_bold" id="S5.T3.32.31.6.10.1">0.1230</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.32.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.32.7.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.32.7.1.1">CORE</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.32.7.2">0.0510</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.32.7.3">0.5097</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.32.7.4">0.4237</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.32.7.5">0.1206</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.32.7.6">0.0297</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.32.7.7">0.5937</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.32.7.8">0.4453</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.32.7.9">0.0785</td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.33.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.33.8.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.33.8.1.1">GRU4Rec</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.33.8.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.33.8.2.1">0.0752</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.33.8.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.33.8.3.1">0.7516</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.33.8.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.33.8.4.1">0.6409</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.33.8.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.33.8.5.1">0.1837</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.33.8.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.33.8.6.1">0.041</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.33.8.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.33.8.7.1">0.8199</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.33.8.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.33.8.8.1">0.6593</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.33.8.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.33.8.9.1">0.1179</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.34.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.34.9.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.34.9.1.1">NARM</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.34.9.2">0.0338</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.34.9.3">0.338</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.34.9.4">0.2310</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.34.9.5">0.0629</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.34.9.6">0.0222</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.34.9.7">0.4432</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.34.9.8">0.2583</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.34.9.9">0.0445</td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.35.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.35.10.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.35.10.1.1">SASRec</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.35.10.2">0.0730</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.35.10.3">0.7304</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.35.10.4">0.6149</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.35.10.5">0.1760</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.35.10.6">0.0407</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.35.10.7">0.8135</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.35.10.8">0.6353</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.35.10.9">0.1137</td>
</tr>
<tr class="ltx_tr" id="S5.T3.10.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.10.2.3" rowspan="5"><span class="ltx_text ltx_font_bold" id="S5.T3.10.2.3.1">FS-TKY</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.10.2.4"><span class="ltx_text ltx_font_bold" id="S5.T3.10.2.4.1">BERT4Rec</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.10.2.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.10.2.5.1">0.0816</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.10.2.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.10.2.6.1">0.8155</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.10.2.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.10.2.7.1">0.6721</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.10.2.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.10.2.8.1">0.1921</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.9.1.1"><span class="ltx_text ltx_font_bold" id="S5.T3.9.1.1.1">0.0437<sup class="ltx_sup" id="S5.T3.9.1.1.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.9.1.1.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.10.2.2"><span class="ltx_text ltx_font_bold" id="S5.T3.10.2.2.1">0.8735<sup class="ltx_sup" id="S5.T3.10.2.2.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.10.2.2.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.10.2.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.10.2.9.1">0.6861</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.10.2.10"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.10.2.10.1">0.1242</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.36.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.36.11.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.36.11.1.1">CORE</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.36.11.2">0.0578</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.36.11.3">0.5778</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.36.11.4">0.4753</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.36.11.5">0.1351</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.36.11.6">0.0328</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.36.11.7">0.6568</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.36.11.8">0.4947</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.36.11.9">0.0882</td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.37.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.37.12.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.37.12.1.1">GRU4Rec</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.37.12.2">0.0772</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.37.12.3">0.7719</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.37.12.4">0.6259</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.37.12.5">0.1785</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.37.12.6">0.0422</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.37.12.7">0.8443</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.37.12.8">0.6448</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.37.12.9">0.1163</td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.38.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.38.13.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.38.13.1.1">NARM</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.38.13.2">0.0443</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.38.13.3">0.4431</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.38.13.4">0.3121</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.38.13.5">0.0858</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.38.13.6">0.0274</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.38.13.7">0.5473</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.38.13.8">0.3377</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.38.13.9">0.0595</td>
</tr>
<tr class="ltx_tr" id="S5.T3.16.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.16.8.7"><span class="ltx_text ltx_font_bold" id="S5.T3.16.8.7.1">SASRec</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.11.3.1"><span class="ltx_text ltx_font_bold" id="S5.T3.11.3.1.1">0.0820<sup class="ltx_sup" id="S5.T3.11.3.1.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.11.3.1.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.12.4.2"><span class="ltx_text ltx_font_bold" id="S5.T3.12.4.2.1">0.8203<sup class="ltx_sup" id="S5.T3.12.4.2.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.12.4.2.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.13.5.3"><span class="ltx_text ltx_font_bold" id="S5.T3.13.5.3.1">0.6896<sup class="ltx_sup" id="S5.T3.13.5.3.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.13.5.3.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.14.6.4"><span class="ltx_text ltx_font_bold" id="S5.T3.14.6.4.1">0.1981<sup class="ltx_sup" id="S5.T3.14.6.4.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.14.6.4.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.16.8.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.16.8.8.1">0.0435</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.16.8.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.16.8.9.1">0.8692</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.15.7.5"><span class="ltx_text ltx_font_bold" id="S5.T3.15.7.5.1">0.7023<sup class="ltx_sup" id="S5.T3.15.7.5.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.15.7.5.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.16.8.6"><span class="ltx_text ltx_font_bold" id="S5.T3.16.8.6.1">0.1274<sup class="ltx_sup" id="S5.T3.16.8.6.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.16.8.6.1.1.1">†</span></sup></span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.39.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.32.39.14.1" rowspan="5"><span class="ltx_text ltx_font_bold" id="S5.T3.32.39.14.1.1">ML-100k</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.32.39.14.2"><span class="ltx_text ltx_font_bold" id="S5.T3.32.39.14.2.1">BERT4Rec</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.39.14.3">0.0549</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.39.14.4">0.5493</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.39.14.5">0.3075</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.32.39.14.6">0.0785</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.39.14.7">0.0363</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.39.14.8">0.7253</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.39.14.9">0.3499</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.39.14.10">0.0604</td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.40.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.40.15.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.40.15.1.1">CORE</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.40.15.2">0.0352</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.40.15.3">0.3521</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.40.15.4">0.1886</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.40.15.5">0.0478</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.40.15.6">0.025</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.40.15.7">0.5005</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.40.15.8">0.2250</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.40.15.9">0.0378</td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.41.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.41.16.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.41.16.1.1">GRU4Rec</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.41.16.2"><span class="ltx_text ltx_font_bold" id="S5.T3.32.41.16.2.1">0.0643</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.41.16.3"><span class="ltx_text ltx_font_bold" id="S5.T3.32.41.16.3.1">0.6426</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.41.16.4"><span class="ltx_text ltx_font_bold" id="S5.T3.32.41.16.4.1">0.3736</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.41.16.5"><span class="ltx_text ltx_font_bold" id="S5.T3.32.41.16.5.1">0.0986</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.41.16.6"><span class="ltx_text ltx_font_bold" id="S5.T3.32.41.16.6.1">0.0393</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.41.16.7"><span class="ltx_text ltx_font_bold" id="S5.T3.32.41.16.7.1">0.7869</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.41.16.8"><span class="ltx_text ltx_font_bold" id="S5.T3.32.41.16.8.1">0.4138</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.41.16.9"><span class="ltx_text ltx_font_bold" id="S5.T3.32.41.16.9.1">0.073</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.42.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.42.17.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.42.17.1.1">NARM</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.42.17.2">0.0273</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.42.17.3">0.2725</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.42.17.4">0.1411</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.42.17.5">0.0352</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.42.17.6">0.022</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.42.17.7">0.4401</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.42.17.8">0.1813</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.42.17.9">0.0291</td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.43.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.43.18.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.43.18.1.1">SASRec</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.43.18.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.43.18.2.1">0.0602</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.43.18.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.43.18.3.1">0.6023</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.43.18.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.43.18.4.1">0.3354</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.43.18.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.43.18.5.1">0.0861</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.43.18.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.43.18.6.1">0.0383</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.43.18.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.43.18.7.1">0.7667</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.43.18.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.43.18.8.1">0.3754</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.43.18.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.43.18.9.1">0.0659</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.44.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.32.44.19.1" rowspan="5"><span class="ltx_text ltx_font_bold" id="S5.T3.32.44.19.1.1">ML-1M</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.32.44.19.2"><span class="ltx_text ltx_font_bold" id="S5.T3.32.44.19.2.1">BERT4Rec</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.44.19.3">0.0752</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.44.19.4">0.7517</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.44.19.5">0.4944</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.32.44.19.6">0.1357</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.44.19.7">0.0428</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.44.19.8">0.8561</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.44.19.9">0.5214</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.44.19.10">0.0949</td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.45.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.45.20.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.45.20.1.1">CORE</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.45.20.2">0.0457</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.45.20.3">0.4571</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.45.20.4">0.2601</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.45.20.5">0.0669</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.45.20.6">0.0312</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.45.20.7">0.6238</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.45.20.8">0.3029</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.45.20.9">0.0517</td>
</tr>
<tr class="ltx_tr" id="S5.T3.24.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.24.16.9"><span class="ltx_text ltx_font_bold" id="S5.T3.24.16.9.1">GRU4Rec</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.17.9.1"><span class="ltx_text ltx_font_bold" id="S5.T3.17.9.1.1">0.0788<sup class="ltx_sup" id="S5.T3.17.9.1.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.17.9.1.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.18.10.2"><span class="ltx_text ltx_font_bold" id="S5.T3.18.10.2.1">0.7876<sup class="ltx_sup" id="S5.T3.18.10.2.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.18.10.2.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.19.11.3"><span class="ltx_text ltx_font_bold" id="S5.T3.19.11.3.1">0.5614<sup class="ltx_sup" id="S5.T3.19.11.3.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.19.11.3.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.20.12.4"><span class="ltx_text ltx_font_bold" id="S5.T3.20.12.4.1">0.1572<sup class="ltx_sup" id="S5.T3.20.12.4.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.20.12.4.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.21.13.5"><span class="ltx_text ltx_font_bold" id="S5.T3.21.13.5.1">0.0438<sup class="ltx_sup" id="S5.T3.21.13.5.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.21.13.5.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.22.14.6"><span class="ltx_text ltx_font_bold" id="S5.T3.22.14.6.1">0.8758<sup class="ltx_sup" id="S5.T3.22.14.6.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.22.14.6.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.23.15.7"><span class="ltx_text ltx_font_bold" id="S5.T3.23.15.7.1">0.5837<sup class="ltx_sup" id="S5.T3.23.15.7.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.23.15.7.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.24.16.8"><span class="ltx_text ltx_font_bold" id="S5.T3.24.16.8.1">0.1065<sup class="ltx_sup" id="S5.T3.24.16.8.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.24.16.8.1.1.1">†</span></sup></span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.46.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.46.21.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.46.21.1.1">NARM</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.46.21.2">0.0428</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.46.21.3">0.4285</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.46.21.4">0.2398</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.46.21.5">0.0611</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.46.21.6">0.0303</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.46.21.7">0.6051</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.46.21.8">0.2840</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.46.21.9">0.0480</td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.47.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.47.22.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.47.22.1.1">SASRec</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.47.22.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.47.22.2.1">0.0761</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.47.22.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.47.22.3.1">0.7614</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.47.22.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.47.22.4.1">0.5063</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.47.22.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.47.22.5.1">0.1396</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.47.22.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.47.22.6.1">0.0431</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.47.22.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.47.22.7.1">0.8614</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.47.22.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.47.22.8.1">0.5319</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.47.22.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.47.22.9.1">0.0971</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.48.23">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S5.T3.32.48.23.1" rowspan="5"><span class="ltx_text ltx_font_bold" id="S5.T3.32.48.23.1.1">ML-20M</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.32.48.23.2"><span class="ltx_text ltx_font_bold" id="S5.T3.32.48.23.2.1">BERT4Rec</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.48.23.3">0.0942</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.48.23.4">0.9419</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.48.23.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.48.23.5.1">0.7381</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.32.48.23.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.48.23.6.1">0.2118</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.48.23.7">0.0489</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.48.23.8">0.9773</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.48.23.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.48.23.9.1">0.7471</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.32.48.23.10"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.48.23.10.1">0.1381</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.49.24">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.49.24.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.49.24.1.1">CORE</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.49.24.2">0.0786</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.49.24.3">0.7863</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.49.24.4">0.5269</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.49.24.5">0.1460</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.49.24.6">0.0451</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.49.24.7">0.9019</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.49.24.8">0.5578</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.49.24.9">0.1012</td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.24">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.24.9"><span class="ltx_text ltx_font_bold" id="S5.T3.32.24.9.1">GRU4Rec</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.25.17.1"><span class="ltx_text ltx_font_bold" id="S5.T3.25.17.1.1">0.0952<sup class="ltx_sup" id="S5.T3.25.17.1.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.25.17.1.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.26.18.2"><span class="ltx_text ltx_font_bold" id="S5.T3.26.18.2.1">0.9521<sup class="ltx_sup" id="S5.T3.26.18.2.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.26.18.2.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.27.19.3"><span class="ltx_text ltx_font_bold" id="S5.T3.27.19.3.1">0.7741<sup class="ltx_sup" id="S5.T3.27.19.3.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.27.19.3.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.28.20.4"><span class="ltx_text ltx_font_bold" id="S5.T3.28.20.4.1">0.2233<sup class="ltx_sup" id="S5.T3.28.20.4.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.28.20.4.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.29.21.5"><span class="ltx_text ltx_font_bold" id="S5.T3.29.21.5.1">0.0491<sup class="ltx_sup" id="S5.T3.29.21.5.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.29.21.5.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.30.22.6"><span class="ltx_text ltx_font_bold" id="S5.T3.30.22.6.1">0.9812<sup class="ltx_sup" id="S5.T3.30.22.6.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.30.22.6.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.31.23.7"><span class="ltx_text ltx_font_bold" id="S5.T3.31.23.7.1">0.7817<sup class="ltx_sup" id="S5.T3.31.23.7.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.31.23.7.1.1.1">†</span></sup></span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.24.8"><span class="ltx_text ltx_font_bold" id="S5.T3.32.24.8.1">0.1440<sup class="ltx_sup" id="S5.T3.32.24.8.1.1"><span class="ltx_text ltx_font_medium" id="S5.T3.32.24.8.1.1.1">†</span></sup></span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.50.25">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T3.32.50.25.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.50.25.1.1">NARM</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.32.50.25.2">0.0871</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.50.25.3">0.8706</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.50.25.4">0.6172</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.32.50.25.5">0.1736</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.50.25.6">0.0468</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.50.25.7">0.9355</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.50.25.8">0.6339</td>
<td class="ltx_td ltx_align_center" id="S5.T3.32.50.25.9">0.1172</td>
</tr>
<tr class="ltx_tr" id="S5.T3.32.51.26">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S5.T3.32.51.26.1"><span class="ltx_text ltx_font_bold" id="S5.T3.32.51.26.1.1">SASRec</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.32.51.26.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.51.26.2.1">0.0943</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.32.51.26.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.51.26.3.1">0.9432</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.32.51.26.4">0.7284</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T3.32.51.26.5">0.2086</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.32.51.26.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.51.26.6.1">0.0490</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.32.51.26.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.32.51.26.7.1">0.9807</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.32.51.26.8">0.7380</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.32.51.26.9">0.1366</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Our experiments aim to address the following research questions:</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1"><span class="ltx_text ltx_font_bold" id="S5.p2.1.1">RQ1</span>: What is the hierarchy of current SRSs and is it consistent with the existing literature?</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1"><span class="ltx_text ltx_font_bold" id="S5.p3.1.1">RQ2</span>: How does the performance of SRSs vary with changes in (a) embedding size and (b) input sequence length?</p>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.1"><span class="ltx_text ltx_font_bold" id="S5.p4.1.1">RQ3</span>: Using a more appropriate comparison based on the total number of parameters, what insights can be gained about the hierarchy of the models?</p>
</div>
<div class="ltx_para" id="S5.p5">
<p class="ltx_p" id="S5.p5.1"><span class="ltx_text ltx_font_bold" id="S5.p5.1.1">RQ4</span>: Is there a discernible trade-off between model performance and CO<sub class="ltx_sub" id="S5.p5.1.2">2</sub> emissions?</p>
</div>
<section class="ltx_subsection" id="S5.SSx1">
<h3 class="ltx_title ltx_title_subsection">RQ1: Base Performance</h3>
<div class="ltx_para" id="S5.SSx1.p1">
<p class="ltx_p" id="S5.SSx1.p1.1">In <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S5.T3" title="In 5. Results ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a> we present the performance metrics of the reproduced models on the six datasets considered in this study. For the sake of experimental consistency, we maintain a uniform embedding size of 50 across all models. The input sequence lengths are set to 200 for FS-TKY, ML-20M, ML-1M, 100 for ML-100k and FS-NYC, and 50 for Beauty.</p>
</div>
<div class="ltx_para" id="S5.SSx1.p2">
<p class="ltx_p" id="S5.SSx1.p2.1">We verify the consistency of our results by comparing them to those reported in the original studies, although with some limitations due to differences in dataset selection between different papers. For overlapping datasets and similar experimental setups, we observe similar performance metrics, which supports the reliability of our implementation.</p>
</div>
<div class="ltx_para" id="S5.SSx1.p3">
<p class="ltx_p" id="S5.SSx1.p3.1">The first novel insight proposed by our paper is that our results do not confirm the conventional belief that SASRec consistently outperforms GRU <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib19" title="">2018</a>; Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib35" title="">2019</a>; Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib22" title="">2017</a>; Hou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib17" title="">2022</a>)</cite>. Contrary to this notion, GRU4Rec beats the competitors on the 3 MovieLens datasets.</p>
</div>
<div class="ltx_para" id="S5.SSx1.p4">
<p class="ltx_p" id="S5.SSx1.p4.1">In particular, the exceptional performance of GRU4Rec in our experiments may be attributed to the quality of its implementation. As observed by <cite class="ltx_cite ltx_citemacro_citet">Hidasi and Czapp (<a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib14" title="">2023a</a>)</cite>, GRU4Rec inferior performance in other studies <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib19" title="">2018</a>; Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib35" title="">2019</a>; Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib22" title="">2017</a>; Hou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib17" title="">2022</a>)</cite> can be attributed to the quality of existing implementations being suboptimal. By using Torch’s implementation of the GRU, our framework benefits from a high-quality implementation, which may contribute to the observed superior performance compared to other frameworks.</p>
</div>
<div class="ltx_para" id="S5.SSx1.p5">
<p class="ltx_p" id="S5.SSx1.p5.1">Furthermore, the performance of NARM and CORE is consistently below that of other models. As mentioned in <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S4.SS3" title="4.3. Models ‣ 4. Implementation Framework and Experimental Setup ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.3</span></a>, this disparity can be attributed to the sequence-to-item training paradigm employed by these architectures, which differs from the sequence-to-sequence training employed by other models. Instead, they are able to achieve high results on datasets with short input sequences, such as Beauty, as evidenced by the best Precision and Recall @20. This finding is consistent with the observations of <cite class="ltx_cite ltx_citemacro_citet">Hou et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib17" title="">2022</a>)</cite>, which highlights the ability of CORE to effectively capture short-term user preferences.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SSx2">
<h3 class="ltx_title ltx_title_subsection">RQ2(a): Input Sequence Length</h3>
<figure class="ltx_figure" id="S5.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="830" id="S5.F2.g1" src="x2.png" width="830"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F2.2.1.1" style="font-size:90%;">Figure 2</span>. </span><span class="ltx_text" id="S5.F2.3.2" style="font-size:90%;">Effect of input sequence length on model performance, as measured by NDCG@10. Each plot shows the results of the five models on one dataset.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S5.F2.4">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S5.F2.5">[Effect of input sequence length on model performance, as measured by NDCG@10.]Each plot shows the results of the five models on one dataset with different values of sequence length.</p>
</div>
</div>
</figure>
<div class="ltx_para" id="S5.SSx2.p1">
<p class="ltx_p" id="S5.SSx2.p1.1"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S5.F2" title="In RQ2(a): Input Sequence Length ‣ 5. Results ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a> shows the results of a detailed investigation aimed at exploring the impact of sequence length on the model’s performance. In this experiment, we set the embedding size to 50 while varying the sequence length over the range of values {20, 50, 100, 200}.</p>
</div>
<div class="ltx_para" id="S5.SSx2.p2">
<p class="ltx_p" id="S5.SSx2.p2.1">Interestingly, for the Beauty dataset, characterized by generally short sequences, there was no significant difference in NDCG@10 when changing the input sequence length. This suggests that the models were able to maintain performance even with excessive padding. This is a positive finding, demonstrating robustness to potential noise introduced by padding in shorter sequences.</p>
</div>
<div class="ltx_para" id="S5.SSx2.p3">
<p class="ltx_p" id="S5.SSx2.p3.1">Conversely, for all other datasets, attention-based models like SASRec, BERT4Rec, and GRU4Rec, the NDCG@10 increased along with the sequence length. This finding aligns with the intuition that these models can potentially capture richer user preferences with access to a longer history of interactions. Furthermore, it contradicts the claim made in the original SASRec paper <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib19" title="">2018</a>)</cite> that the model does not scale effectively to very long sequences. Our results suggest that SASRec may benefit from longer sequences, prompting further investigation into this aspect.</p>
</div>
<div class="ltx_para" id="S5.SSx2.p4">
<p class="ltx_p" id="S5.SSx2.p4.1">NARM and CORE exhibited contrasting behaviour. In the ML-100k dataset, their NDCG@10 scores even decreased with increasing sequence length. This is noteworthy because the original CORE paper <cite class="ltx_cite ltx_citemacro_citep">(Hou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib17" title="">2022</a>)</cite> only evaluated sequences up to 50 items, limiting insights into its behaviour with longer sequences. Conversely, the original NARM paper <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib22" title="">2017</a>)</cite> claimed that NARM performs well in modeling long sessions, which aligns with our observations.</p>
</div>
<div class="ltx_para" id="S5.SSx2.p5">
<p class="ltx_p" id="S5.SSx2.p5.1">These findings highlight the importance of considering the model architecture and dataset characteristics when determining the optimal input sequence length for SRSs.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SSx3">
<h3 class="ltx_title ltx_title_subsection">RQ2(b): Embedding size</h3>
<div class="ltx_para" id="S5.SSx3.p1">
<p class="ltx_p" id="S5.SSx3.p1.1">A quick glance at the table could lead to the erroneous conclusion that GRU4Rec is generally the superior choice for an SRS. However, such a deduction would be deeply flawed.</p>
</div>
<div class="ltx_para" id="S5.SSx3.p2">
<p class="ltx_p" id="S5.SSx3.p2.1"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S5.F3" title="In RQ2(b): Embedding size ‣ 5. Results ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a> investigates how different embedding sizes – 32, 64, 128, 256, and 512 – affect various models.</p>
</div>
<div class="ltx_para" id="S5.SSx3.p3">
<p class="ltx_p" id="S5.SSx3.p3.1">One striking observation is the marked influence of embedding size on SASRec and BERT4Rec. As the embedding size increases, these models show a clear improvement in performance. This phenomenon suggests that their attention mechanisms effectively exploit higher-dimensional embeddings to refine input and output representations, leading to improved predictive capabilities.</p>
</div>
<figure class="ltx_figure" id="S5.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="830" id="S5.F3.g1" src="x3.png" width="830"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F3.2.1.1" style="font-size:90%;">Figure 3</span>. </span><span class="ltx_text" id="S5.F3.3.2" style="font-size:90%;">Effect of embedding size on model performance, as measured by NDCG@10. Each plot shows the results of the five models on one dataset.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S5.F3.4">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S5.F3.5">[Effect of embedding size on model performance, as measured by NDCG@10.]Each plot shows the results of the five models on one dataset with different values of embedding size.</p>
</div>
</div>
</figure>
<div class="ltx_para" id="S5.SSx3.p4">
<p class="ltx_p" id="S5.SSx3.p4.1">In contrast, the performance of GRU-based models, i.e. GRU4Rec and NARM, is relatively unaffected by changes in the dimensionality of the embeddings. This indicates that changes in embedding size primarily affect the number of parameters in the GRU layer without significantly impacting the computational capability.</p>
</div>
<div class="ltx_para" id="S5.SSx3.p5">
<p class="ltx_p" id="S5.SSx3.p5.1">CORE exhibits contrasting performance across different datasets. Remarkably, it demonstrates good performance on the Beauty and Foursquare datasets with increased embedding size.
However, on MovieLens datasets, CORE displays no discernible increase in performance despite variations in the embedding size.</p>
</div>
<div class="ltx_para" id="S5.SSx3.p6">
<p class="ltx_p" id="S5.SSx3.p6.1">A notable divergence from the traditional model hierarchy emerges from this analysis: transformer-based models outperform GRU-based models as embedding size increases. This suggests that, given adequate computational resources, transformer-based models offer a compelling advantage at larger embedding sizes.</p>
</div>
<div class="ltx_para" id="S5.SSx3.p7">
<p class="ltx_p" id="S5.SSx3.p7.1">Interestingly, SASRec emerges as the best-performing model when using the largest embedding size, a finding not immediately apparent from <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S5.T3" title="In 5. Results ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a>. This highlights the nuanced relationship between model architecture, embedding size and performance.</p>
</div>
<div class="ltx_para" id="S5.SSx3.p8">
<p class="ltx_p" id="S5.SSx3.p8.1">These results highlight the importance of considering both model architecture and embedding size when designing recommendation systems, particularly in resource-rich environments where computational cost is not a limiting factor.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SSx4">
<h3 class="ltx_title ltx_title_subsection">RQ3: Model Size</h3>
<figure class="ltx_figure" id="S5.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="830" id="S5.F4.g1" src="x4.png" width="830"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F4.2.1.1" style="font-size:90%;">Figure 4</span>. </span><span class="ltx_text" id="S5.F4.3.2" style="font-size:90%;">Effect of total number of model’s parameters on the performance, as measured by NDCG@10. Each plot shows the results of the five models on one dataset.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S5.F4.4">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S5.F4.5">[Effect of number of parameters size on model performance, as measured by NDCG@10.]Each plot shows the results of the five models on one dataset by also providing the number of parameters required by each model.</p>
</div>
</div>
</figure>
<div class="ltx_para" id="S5.SSx4.p1">
<p class="ltx_p" id="S5.SSx4.p1.1">A fundamental aspect of conducting a truly fair comparison between models is to consider their respective sizes in terms of parameters. This ensures that any differences in performance are due to inherent architectural differences and not simply to the number of parameters. <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S5.F4" title="In RQ3: Model Size ‣ 5. Results ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a> shows a comparison based on this principle.</p>
</div>
<div class="ltx_para" id="S5.SSx4.p2">
<p class="ltx_p" id="S5.SSx4.p2.1">We see how the comparison becomes more nuanced when model size is considered. For example, while the number of parameters in GRU4Rec remains relatively stable even with increasing embedding sizes, transformer-based models show a contrasting trend. These models tend to grow in number of parameters with increasing embedding size more than the others.</p>
</div>
<div class="ltx_para" id="S5.SSx4.p3">
<p class="ltx_p" id="S5.SSx4.p3.1">For specific datasets, such as ML-100k and Beauty, the analysis shows that NARM still has room for improvement, as it maintains a relatively lower total number of parameters compared to other models. This suggests that NARM may have untapped potential to improve performance without significantly increasing model complexity, making it an interesting avenue for further exploration and optimisation. Regarding the Foursquare datasets, the number of parameters for NARM increases significantly when changing the embedding size, while the results in terms of NDCG remain approximately the same.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SSx5">
<h3 class="ltx_title ltx_title_subsection">RQ4: Emissions</h3>
<div class="ltx_para" id="S5.SSx5.p1">
<p class="ltx_p" id="S5.SSx5.p1.1">In addition to evaluating model performance, we assess the environmental footprint of each model to identify potential trade-offs between performance and environmental impact. Our aim is to shed light on the sustainability implications associated with different model configurations.</p>
</div>
<div class="ltx_para" id="S5.SSx5.p2">
<p class="ltx_p" id="S5.SSx5.p2.1"><a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S5.F5" title="In RQ4: Emissions ‣ 5. Results ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">5</span></a> visualises the performance as a function of the environmental impact, described by CO<sub class="ltx_sub" id="S5.SSx5.p2.1.1">2</sub>-eq emissions in kg. A notable trend across all models is a positive correlation between CO<sub class="ltx_sub" id="S5.SSx5.p2.1.2">2</sub>-eq emissions and performance. While SASRec and BERT4Rec exhibit superior performance to GRU4Rec, particularly at larger embedding sizes as discussed in <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#S5.SSx3" title="RQ2(b): Embedding size ‣ 5. Results ‣ A Reproducible Analysis of Sequential Recommender Systems"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5</span></a>, they also have a generally higher environmental impact. Transformer-based models are known for their high computational requirements, driven by their large parameter sizes <cite class="ltx_cite ltx_citemacro_citep">(Bender et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03873v1#bib.bib3" title="">2021</a>)</cite>. This enhanced computational demand poses challenges in terms of hardware resources and raises concerns regarding energy consumption and environmental sustainability. In addition, it should be noted that the consumption for ML-20M is at least <math alttext="10" class="ltx_Math" display="inline" id="S5.SSx5.p2.1.m1.1"><semantics id="S5.SSx5.p2.1.m1.1a"><mn id="S5.SSx5.p2.1.m1.1.1" xref="S5.SSx5.p2.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S5.SSx5.p2.1.m1.1b"><cn id="S5.SSx5.p2.1.m1.1.1.cmml" type="integer" xref="S5.SSx5.p2.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SSx5.p2.1.m1.1c">10</annotation><annotation encoding="application/x-llamapun" id="S5.SSx5.p2.1.m1.1d">10</annotation></semantics></math> times higher than all other datasets.</p>
</div>
<figure class="ltx_figure" id="S5.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="830" id="S5.F5.g1" src="x5.png" width="830"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.3.1.1" style="font-size:90%;">Figure 5</span>. </span><span class="ltx_text" id="S5.F5.4.2" style="font-size:90%;">Relation between emissions, measured as CO<sub class="ltx_sub" id="S5.F5.4.2.1">2</sub>-eq in Kg, and performance, measured by NDCG@10. Each plot shows the results of the five models on one dataset.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S5.F5.5">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S5.F5.6">[Relation between emissions, measured as CO<sub class="ltx_sub" id="S5.F5.6.1">2</sub>-eq in Kg, and performance, measured by NDCG@10.]Relation between emissions, measured as CO<sub class="ltx_sub" id="S5.F5.6.2">2</sub>-eq in Kg, and performance, measured by NDCG@10.</p>
</div>
</div>
</figure>
<div class="ltx_para" id="S5.SSx5.p3">
<p class="ltx_p" id="S5.SSx5.p3.1">After careful consideration, the optimal compromise appears to be the use of SASRec with an embedding size of 256. This choice strikes a balance between achieving competitive NDCG@10 values and maintaining energy consumption levels comparable to other models. This finding highlights the importance of considering environmental sustainability alongside performance metrics when selecting and optimising recommendation models.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Our contribution addresses reproducibility concerns in Sequential Recommendation research by introducing a standardized pre-processing and training methodology for SRSs, along with a user-friendly framework, EasyRec, for creating custom models with minimal coding effort. Our experimental results challenge existing literature by demonstrating the effectiveness of GRU4Rec with low-dimensional embeddings and the superiority of transformer-based models with larger embedding sizes. We also highlight the importance of managing input sequence length based on dataset statistics. To ensure fair model comparison, we introduce an analysis based on the number of model parameters and conduct an energy consumption analysis, identifying a trade-off between sustainability and performance. Our work represents a step towards standardizing benchmarks and pre-processing methods, promoting consistency in future research. We plan to extend our code resource with additional models, datasets, and insights to contribute to the ongoing evolution of SRS research.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anelli et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Vito Walter Anelli, Alejandro Bellogín, Antonio Ferrara, Daniele Malitesta, Felice Antonio Merra, Claudio Pomo, Francesco Maria Donini, and Tommaso Di Noia. 2021.

</span>
<span class="ltx_bibblock">Elliot: A comprehensive and rigorous framework for reproducible recommender systems evaluation. In <em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval</em>. 2405–2414.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender et al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021.

</span>
<span class="ltx_bibblock">On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?. In <em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em> (Virtual Event, Canada) <em class="ltx_emph ltx_font_italic" id="bib.bib3.4.2">(FAccT ’21)</em>. Association for Computing Machinery, New York, NY, USA, 610–623.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3442188.3445922" title="">https://doi.org/10.1145/3442188.3445922</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beutel et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Alex Beutel, Paul Covington, Sagar Jain, Can Xu, Jia Li, Vince Gatto, and Ed H. Chi. 2018.

</span>
<span class="ltx_bibblock">Latent Cross: Making Use of Context in Recurrent Recommender Systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining</em> (Marina Del Rey, CA, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib4.4.2">(WSDM ’18)</em>. Association for Computing Machinery, New York, NY, USA, 46–54.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3159652.3159727" title="">https://doi.org/10.1145/3159652.3159727</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2014)</span>
<span class="ltx_bibblock">
Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014.

</span>
<span class="ltx_bibblock">Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1406.1078 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Courty et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Benoit Courty, Victor Schmidt, Goyal-Kamal, MarionCoutarel, Boris Feld, Jérémy Lecourt, SabAmine, kngoyal, Mathilde Léval, Alexis Cruveiller, inimaz, ouminasara, Franklin Zhao, Aditya Joshi, Alexis Bogroff, Amine Saboni, Hugues de Lavoreille, Niko Laskaris, Luis Blanche, Edoardo Abati, LiamConnell, Douglas Blank, Ziyao Wang, Armin Catovic, Michał Stęchły, alencon, JPW, MinervaBooks, Necmettin Çarkacı, and DomAlexRod. 2023.

</span>
<span class="ltx_bibblock">mlco2/codecarbon: v2.3.2.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.5281/zenodo.10213072" title="">https://doi.org/10.5281/zenodo.10213072</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cremonesi and Jannach (2021)</span>
<span class="ltx_bibblock">
Paolo Cremonesi and Dietmar Jannach. 2021.

</span>
<span class="ltx_bibblock">Progress in recommender systems research: Crisis? What crisis?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">AI Magazine</em> 42, 3 (2021), 43–54.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association for Computational Linguistics, Minneapolis, Minnesota, 4171–4186.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/N19-1423" title="">https://doi.org/10.18653/v1/N19-1423</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ferrari Dacrema et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Maurizio Ferrari Dacrema, Simone Boglio, Paolo Cremonesi, and Dietmar Jannach. 2021.

</span>
<span class="ltx_bibblock">A troubling analysis of reproducibility and progress in recommender systems research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">ACM Transactions on Information Systems (TOIS)</em> 39, 2 (2021), 1–49.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ferrari Dacrema et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Maurizio Ferrari Dacrema, Paolo Cremonesi, and Dietmar Jannach. 2019.

</span>
<span class="ltx_bibblock">Are we really making much progress? A worrying analysis of recent neural recommendation approaches.

</span>
<span class="ltx_bibblock">, 101–109 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ferrari Dacrema et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Maurizio Ferrari Dacrema, Paolo Cremonesi, Dietmar Jannach, et al<span class="ltx_text" id="bib.bib11.3.1">.</span> 2020.

</span>
<span class="ltx_bibblock">Methodological issues in recommender systems research.

</span>
<span class="ltx_bibblock">, 4706–4710 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Good (1952)</span>
<span class="ltx_bibblock">
Irving John Good. 1952.

</span>
<span class="ltx_bibblock">Rational decisions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Journal of the Royal Statistical Society: Series B (Methodological)</em> 14, 1 (1952), 107–114.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harper and Konstan (2015)</span>
<span class="ltx_bibblock">
F. Maxwell Harper and Joseph A. Konstan. 2015.

</span>
<span class="ltx_bibblock">The MovieLens Datasets: History and Context.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">ACM Trans. Interact. Intell. Syst.</em> 5, 4, Article 19 (dec 2015), 19 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2827872" title="">https://doi.org/10.1145/2827872</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hidasi and Czapp (2023a)</span>
<span class="ltx_bibblock">
Balázs Hidasi and Ádám Tibor Czapp. 2023a.

</span>
<span class="ltx_bibblock">The effect of third party implementations on reproducibility.

</span>
<span class="ltx_bibblock">, 272–282 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hidasi and Czapp (2023b)</span>
<span class="ltx_bibblock">
Balázs Hidasi and Ádám Tibor Czapp. 2023b.

</span>
<span class="ltx_bibblock">Widespread Flaws in Offline Evaluation of Recommender Systems.

</span>
<span class="ltx_bibblock">, 848–855 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hidasi et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016.

</span>
<span class="ltx_bibblock">Session-based Recommendations with Recurrent Neural Networks.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1511.06939 [cs.LG]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hou et al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Yupeng Hou, Binbin Hu, Zhiqiang Zhang, and Wayne Xin Zhao. 2022.

</span>
<span class="ltx_bibblock">Core: simple and effective session-based recommendation within consistent representation space.

</span>
<span class="ltx_bibblock">, 1796–1801 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hunter et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
David B Hunter, James E Salzman, and Durwood Zaelke. 2021.

</span>
<span class="ltx_bibblock">Glasgow climate summit: Cop26.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang and McAuley (2018)</span>
<span class="ltx_bibblock">
Wang-Cheng Kang and Julian McAuley. 2018.

</span>
<span class="ltx_bibblock">Self-Attentive Sequential Recommendation.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1808.09781 [cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim and Neff (2009)</span>
<span class="ltx_bibblock">
Brent Kim and Roni Neff. 2009.

</span>
<span class="ltx_bibblock">Measurement and communication of greenhouse gas emissions from US food consumption via carbon calculators.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Ecological Economics</em> 69, 1 (2009), 186–196.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Klenitskiy and Vasilev (2023)</span>
<span class="ltx_bibblock">
Anton Klenitskiy and Alexey Vasilev. 2023.

</span>
<span class="ltx_bibblock">Turning Dross Into Gold Loss: is BERT4Rec really better than SASRec?

</span>
<span class="ltx_bibblock">, 1120–1125 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017.

</span>
<span class="ltx_bibblock">Neural Attentive Session-based Recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib22.4.2">(CIKM ’17)</em>. Association for Computing Machinery, New York, NY, USA, 1419–1428.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3132847.3132926" title="">https://doi.org/10.1145/3132847.3132926</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Ming Li, Ali Vardasbi, Andrew Yates, and Maarten de Rijke. 2023.

</span>
<span class="ltx_bibblock">Repetition and Exploration in Sequential Recommendation.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin (2019)</span>
<span class="ltx_bibblock">
Jimmy Lin. 2019.

</span>
<span class="ltx_bibblock">The neural hype and comparisons against weak baselines.

</span>
<span class="ltx_bibblock">, 40–51 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ludewig and Jannach (2018)</span>
<span class="ltx_bibblock">
Malte Ludewig and Dietmar Jannach. 2018.

</span>
<span class="ltx_bibblock">Evaluation of session-based recommendation algorithms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">User Modeling and User-Adapted Interaction</em> 28 (2018), 331–390.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McAuley et al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton van den Hengel. 2015.

</span>
<span class="ltx_bibblock">Image-Based Recommendations on Styles and Substitutes. In <em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Santiago, Chile) <em class="ltx_emph ltx_font_italic" id="bib.bib26.4.2">(SIGIR ’15)</em>. Association for Computing Machinery, New York, NY, USA, 43–52.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2766462.2767755" title="">https://doi.org/10.1145/2766462.2767755</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Michiels et al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Lien Michiels, Robin Verachtert, and Bart Goethals. 2022.

</span>
<span class="ltx_bibblock">RecPack: An(Other) Experimentation Toolkit for Top-N Recommendation Using Implicit Feedback Data. In <em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">Proceedings of the 16th ACM Conference on Recommender Systems</em> (Seattle, WA, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib27.4.2">(RecSys ’22)</em>. Association for Computing Machinery, New York, NY, USA, 648–651.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3523227.3551472" title="">https://doi.org/10.1145/3523227.3551472</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pascanu et al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2013)</span>
<span class="ltx_bibblock">
Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio. 2013.

</span>
<span class="ltx_bibblock">On the difficulty of training Recurrent Neural Networks.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1211.5063 [cs.LG]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patterson et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
David Patterson, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David So, Maud Texier, and Jeff Dean. 2021.

</span>
<span class="ltx_bibblock">Carbon emissions and large neural network training.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petrov and Macdonald (2022)</span>
<span class="ltx_bibblock">
Aleksandr Petrov and Craig Macdonald. 2022.

</span>
<span class="ltx_bibblock">A systematic review and replicability study of bert4rec for sequential recommendation.

</span>
<span class="ltx_bibblock">, 436–447 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Quadrana et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Massimo Quadrana, Paolo Cremonesi, and Dietmar Jannach. 2018.

</span>
<span class="ltx_bibblock">Sequence-aware recommender systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">ACM Computing Surveys (CSUR)</em> 51, 4 (2018), 1–36.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rendle et al<span class="ltx_text" id="bib.bib32.2.2.1">.</span> (2010)</span>
<span class="ltx_bibblock">
Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010.

</span>
<span class="ltx_bibblock">Factorizing personalized Markov chains for next-basket recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib32.3.1">Proceedings of the 19th International Conference on World Wide Web</em> (Raleigh, North Carolina, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib32.4.2">(WWW ’10)</em>. Association for Computing Machinery, New York, NY, USA, 811–820.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1772690.1772773" title="">https://doi.org/10.1145/1772690.1772773</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salah et al<span class="ltx_text" id="bib.bib33.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Aghiles Salah, Quoc-Tuan Truong, and Hady W Lauw. 2020.

</span>
<span class="ltx_bibblock">Cornac: A Comparative Framework for Multimodal Recommender Systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.3.1">Journal of Machine Learning Research</em> 21, 95 (2020), 1–5.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith and Linden (2017)</span>
<span class="ltx_bibblock">
Brent Smith and Greg Linden. 2017.

</span>
<span class="ltx_bibblock">Two Decades of Recommender Systems at Amazon.com.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">IEEE Internet Computing</em> 21, 3 (2017), 12–18.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/MIC.2017.72" title="">https://doi.org/10.1109/MIC.2017.72</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span class="ltx_text" id="bib.bib35.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019.

</span>
<span class="ltx_bibblock">BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1904.06690 [cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Zhu Sun, Di Yu, Hui Fang, Jie Yang, Xinghua Qu, Jie Zhang, and Cong Geng. 2020.

</span>
<span class="ltx_bibblock">Are we evaluating rigorously? benchmarking recommendation for reproducible evaluation and fair comparison.

</span>
<span class="ltx_bibblock">, 23–32 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang and Wang (2018)</span>
<span class="ltx_bibblock">
Jiaxi Tang and Ke Wang. 2018.

</span>
<span class="ltx_bibblock">Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding. In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining</em> (Marina Del Rey, CA, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib37.2.2">(WSDM ’18)</em>. Association for Computing Machinery, New York, NY, USA, 565–573.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3159652.3159656" title="">https://doi.org/10.1145/3159652.3159656</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al<span class="ltx_text" id="bib.bib38.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.3.1">Advances in neural information processing systems</em> 30 (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib39.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Chenyang Wang, Min Zhang, Weizhi Ma, Yiqun Liu, and Shaoping Ma. 2020.

</span>
<span class="ltx_bibblock">Make it a chorus: knowledge-and time-aware item modeling for sequential recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib39.3.1">Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval</em>. 109–118.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Shoujin Wang, Liang Hu, Yan Wang, Longbing Cao, Quan Z. Sheng, and Mehmet Orgun. 2019.

</span>
<span class="ltx_bibblock">Sequential Recommender Systems: Challenges, Progress and Prospects.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.24963/ijcai.2019/883" title="">https://doi.org/10.24963/ijcai.2019/883</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Dingqi Yang, Daqing Zhang, Vincent W. Zheng, and Zhiyong Yu. 2015.

</span>
<span class="ltx_bibblock">Modeling User Activity Preference by Leveraging User Spatial Temporal Characteristics in LBSNs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.3.1">IEEE Transactions on Systems, Man, and Cybernetics: Systems</em> 45, 1 (2015), 129–142.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/TSMC.2014.2327053" title="">https://doi.org/10.1109/TSMC.2014.2327053</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span class="ltx_text" id="bib.bib42.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Wayne Xin Zhao, Shanlei Mu, Yupeng Hou, Zihan Lin, Yushuo Chen, Xingyu Pan, Kaiyuan Li, Yujie Lu, Hui Wang, Changxin Tian, Yingqian Min, Zhichao Feng, Xinyan Fan, Xu Chen, Pengfei Wang, Wendi Ji, Yaliang Li, Xiaoling Wang, and Ji-Rong Wen. 2021.

</span>
<span class="ltx_bibblock">RecBole: Towards a Unified, Comprehensive and Efficient Framework for Recommendation Algorithms.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2011.01731 [cs.IR]

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Aug  7 16:17:13 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
