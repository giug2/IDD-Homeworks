<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[1908.08340] An End-to-End Encrypted Neural Network for Gradient Updates Transmission in Federated Learning</title><meta property="og:description" content="Federated learning is a distributed learning method to train a shared model by aggregating the locally-computed gradient updates. In federated learning, bandwidth and privacy are two main concerns of gradient updates t…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="An End-to-End Encrypted Neural Network for Gradient Updates Transmission in Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="An End-to-End Encrypted Neural Network for Gradient Updates Transmission in Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/1908.08340">

<!--Generated on Sat Mar  9 08:57:16 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document" style="font-size:120%;">
<span id="id1.id1" class="ltx_text ltx_font_bold">An End-to-End Encrypted Neural Network for Gradient Updates Transmission in Federated Learning</span>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hongyu Li
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> and Tianqi Han
<br class="ltx_break">

<span id="id2.1.id1" class="ltx_tabular ltx_minipage ltx_align_middle" style="width:433.6pt;">
<span class="ltx_tbody">
<span id="id2.1.id1.1.1" class="ltx_tr">
<span id="id2.1.id1.1.1.1" class="ltx_td ltx_align_center"><span id="id2.1.id1.1.1.1.1" class="ltx_text" style="font-size:90%;">DL Lab, AI Institute</span></span>
<span id="id2.1.id1.1.1.2" class="ltx_td"></span>
<span id="id2.1.id1.1.1.3" class="ltx_td ltx_align_center"><span id="id2.1.id1.1.1.3.1" class="ltx_text" style="font-size:90%;">AI Lab</span></span></span>
<span id="id2.1.id1.2.2" class="ltx_tr">
<span id="id2.1.id1.2.2.1" class="ltx_td ltx_align_center"><span id="id2.1.id1.2.2.1.1" class="ltx_text" style="font-size:90%;">Tongdun Technology</span></span>
<span id="id2.1.id1.2.2.2" class="ltx_td"></span>
<span id="id2.1.id1.2.2.3" class="ltx_td ltx_align_center"><span id="id2.1.id1.2.2.3.1" class="ltx_text" style="font-size:90%;">ZhongAn Technology</span></span></span>
<span id="id2.1.id1.3.3" class="ltx_tr">
<span id="id2.1.id1.3.3.1" class="ltx_td ltx_align_center"><span id="id2.1.id1.3.3.1.1" class="ltx_text" style="font-size:90%;">Shanghai, China</span></span>
<span id="id2.1.id1.3.3.2" class="ltx_td"></span>
<span id="id2.1.id1.3.3.3" class="ltx_td ltx_align_center"><span id="id2.1.id1.3.3.3.1" class="ltx_text" style="font-size:90%;">Shanghai, China</span></span></span>
<span id="id2.1.id1.4.4" class="ltx_tr">
<span id="id2.1.id1.4.4.1" class="ltx_td ltx_align_center"><span id="id2.1.id1.4.4.1.1" class="ltx_text" style="font-size:90%;">✉hongyu.li@tongdun.net</span></span>
<span id="id2.1.id1.4.4.2" class="ltx_td"></span>
<span id="id2.1.id1.4.4.3" class="ltx_td ltx_align_center"><span id="id2.1.id1.4.4.3.1" class="ltx_text" style="font-size:90%;">hantianqi@zhongan.io</span></span></span>
</span>
</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id3.id1" class="ltx_p">Federated learning is a distributed learning method to train a shared model by aggregating the locally-computed gradient updates. In federated learning, bandwidth and privacy are two main concerns of gradient updates transmission. This paper<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>This paper is an extended version of a summary published in the Proc. of 2019 Data Compression Conference (DCC). The 1-page summary in the DCC proceedings can be found at: https://ieeexplore.ieee.org/document/8712695.</span></span></span> proposes an end-to-end encrypted neural network for gradient updates transmission. This network first encodes the input gradient updates to a lower-dimension space in each client, which significantly mitigates the pressure of data communication in federated learning. The encoded gradient updates are directly recovered as a whole, i.e. the aggregated gradient updates of the trained model, in the decoding layers of the network on the server. In this way, gradient updates encrypted in each client are not only prevented from interception during communication, but also unknown to the server. Based on the encrypted neural network, a novel federated learning framework is designed in real applications. Experimental results show that the proposed network can effectively achieve two goals, privacy protection and data compression, under a little sacrifice of the model accuracy in federated learning.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Recently, federated learning is proposed to learn a shared model by aggregating the locally-computed updates <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. In federated learning, the clients compute an updated model based on their local data and post gradient updates to the server. The server then aggregates these updates (e.g. by averaging) to construct an improved global model. One significant bottleneck of federated learning is the bandwidth for gradient updates transmission. To compress the transmitted updates, the quantization method was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> to use low-precision values to represent the gradient updates, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> made the updates sparse through restricting them only on a small subset of parameters. However, the gradient updates may still reveal private information—local data on a client <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, which is the other main concern in federated learning, after compression with either quantization or sparsification.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In this paper, we propose an end-to-end encrypted neural network (ENN) for compressing and encrypting dense gradient updates simultaneously. The encrypted neural network is composed of two different sub-networks: an encoding sub-network and a decoding sub-network. In the ENN-based federated learning framework, each client uses an encoding sub-network respectively to encrypt and compress the gradient updates with a lower-dimensional coding vector. Once encrypted vectors are transmitted to the server, a decoding sub-network deployed on the server is responsible to recover the aggregated updates from encrypted vectors. In this way, the original gradient updates will never appear both during transmission and after decoding. As a result, the proposed ENN can not only compress the dense gradient updates, but also protect the privacy of each client to avoid being intercepted during communication or directly exposed to the server.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.2" class="ltx_p">The proposed ENN is trained in an end-to-end manner, where it is assumed that the overall gradient updates can be directly aggregated on the server without the explicit reconstruction of each update.
For the purpose of network training, we generate a set of training samples under a Gaussian distribution with the mean of <math id="S1.p3.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S1.p3.1.m1.1a"><mn id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><cn type="integer" id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">0</cn></annotation-xml></semantics></math> and the standard deviation of <math id="S1.p3.2.m2.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S1.p3.2.m2.1a"><mn id="S1.p3.2.m2.1.1" xref="S1.p3.2.m2.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S1.p3.2.m2.1b"><cn type="float" id="S1.p3.2.m2.1.1.cmml" xref="S1.p3.2.m2.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.2.m2.1c">0.1</annotation></semantics></math>, assuming that gradient updates are under the same distribution.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this work, we attempt to solve this issue of the encryption and compression of gradient updates in federated learning to some extent and our major contributions are summarized
as follows:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">An encrypted neural network is proposed for encoding and compressing the updates on each client and decoding the aggregated updates on the server, to guarantee that the updates are both secure during communication and unexposed to the server;</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">An ENN-based federated learning framework is designed in real applications, where the encoding sub-network is flexible to extend to as many clients as desired.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Encrypted Neural Network</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.4" class="ltx_p">An autoencoder <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> is a type of artificial neural network to learn low-dimensional representations of data in a high-dimensional space. In the autoencoder, the input data <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{x}\in\mathbb{R}^{N}" display="inline"><semantics id="S2.p1.1.m1.1a"><mrow id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml"><mi id="S2.p1.1.m1.1.1.2" xref="S2.p1.1.m1.1.1.2.cmml">𝐱</mi><mo id="S2.p1.1.m1.1.1.1" xref="S2.p1.1.m1.1.1.1.cmml">∈</mo><msup id="S2.p1.1.m1.1.1.3" xref="S2.p1.1.m1.1.1.3.cmml"><mi id="S2.p1.1.m1.1.1.3.2" xref="S2.p1.1.m1.1.1.3.2.cmml">ℝ</mi><mi id="S2.p1.1.m1.1.1.3.3" xref="S2.p1.1.m1.1.1.3.3.cmml">N</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><apply id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1"><in id="S2.p1.1.m1.1.1.1.cmml" xref="S2.p1.1.m1.1.1.1"></in><ci id="S2.p1.1.m1.1.1.2.cmml" xref="S2.p1.1.m1.1.1.2">𝐱</ci><apply id="S2.p1.1.m1.1.1.3.cmml" xref="S2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.p1.1.m1.1.1.3.1.cmml" xref="S2.p1.1.m1.1.1.3">superscript</csymbol><ci id="S2.p1.1.m1.1.1.3.2.cmml" xref="S2.p1.1.m1.1.1.3.2">ℝ</ci><ci id="S2.p1.1.m1.1.1.3.3.cmml" xref="S2.p1.1.m1.1.1.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">\mathbf{x}\in\mathbb{R}^{N}</annotation></semantics></math> is first mapped to a lower-dimensional vector <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{y}\in\mathbb{R}^{M}" display="inline"><semantics id="S2.p1.2.m2.1a"><mrow id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml"><mi id="S2.p1.2.m2.1.1.2" xref="S2.p1.2.m2.1.1.2.cmml">𝐲</mi><mo id="S2.p1.2.m2.1.1.1" xref="S2.p1.2.m2.1.1.1.cmml">∈</mo><msup id="S2.p1.2.m2.1.1.3" xref="S2.p1.2.m2.1.1.3.cmml"><mi id="S2.p1.2.m2.1.1.3.2" xref="S2.p1.2.m2.1.1.3.2.cmml">ℝ</mi><mi id="S2.p1.2.m2.1.1.3.3" xref="S2.p1.2.m2.1.1.3.3.cmml">M</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><apply id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1"><in id="S2.p1.2.m2.1.1.1.cmml" xref="S2.p1.2.m2.1.1.1"></in><ci id="S2.p1.2.m2.1.1.2.cmml" xref="S2.p1.2.m2.1.1.2">𝐲</ci><apply id="S2.p1.2.m2.1.1.3.cmml" xref="S2.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.p1.2.m2.1.1.3.1.cmml" xref="S2.p1.2.m2.1.1.3">superscript</csymbol><ci id="S2.p1.2.m2.1.1.3.2.cmml" xref="S2.p1.2.m2.1.1.3.2">ℝ</ci><ci id="S2.p1.2.m2.1.1.3.3.cmml" xref="S2.p1.2.m2.1.1.3.3">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">\mathbf{y}\in\mathbb{R}^{M}</annotation></semantics></math>. Then the decoder approximately recovers the original data <math id="S2.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S2.p1.3.m3.1a"><mi id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><ci id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">\mathbf{x}</annotation></semantics></math> from the low-dimensional data <math id="S2.p1.4.m4.1" class="ltx_Math" alttext="\mathbf{y}" display="inline"><semantics id="S2.p1.4.m4.1a"><mi id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml">𝐲</mi><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><ci id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1">𝐲</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">\mathbf{y}</annotation></semantics></math>. The autoencoder learns the input data automatically and has been widely used in lossy compression applications, such as image compression <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> and denoising <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Motivated by the autoencoder, we design an encrypted neural network (ENN) to compress and encrypt dense gradient updates simultaneously in federated learning. Similar to the autoencoder, the proposed network is comprised of two sub-networks: encoder and decoder. But there are two clear differences between the ENN and the autoencoder:</p>
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">The encoder in the ENN can be distributed to multiple clients and is therefore suitable for use in federated learning,</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">The decoder in the ENN can accept the coding vectors from any number of clients as input and directly aggregate the updates without the explicit reconstruction.</p>
</div>
</li>
</ol>
<p id="S2.p2.2" class="ltx_p">Since the ENN can generate a decrypted result which matches the result of the operations as if they had been performed on the plaintext, it is in essence a homomorphic encryption technique <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> that allows computation on encrypted data without exposing sensitive data. The ENN-based federated learning framework and the structure of the proposed network will be respectively introduced in more detail below.</p>
</div>
<div id="S2.p3" class="ltx_para">
<span id="S2.p3.1" class="ltx_ERROR undefined">\SubSection</span>
<p id="S2.p3.2" class="ltx_p">Framework for federated learning</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/1908.08340/assets/x1.png" id="S2.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="423" height="321" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of the federated learning framework. Gradient updates for model training are first encrypted and compressed with encoder on clients before transmission and the aggregated updates are directly computed with decoder on the server.</figcaption>
</figure>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">The ENN-based framework for federated learning is illustrated in Fig. <a href="#S2.F1" title="Figure 1 ‣ 2 Encrypted Neural Network ‣ An End-to-End Encrypted Neural Network for Gradient Updates Transmission in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. In this framework, the encoder is first distributed to each client respectively and the decoder is deployed on the server.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.2" class="ltx_p">Clients will start to train a model with local data. During training, gradient updates <math id="S2.p5.1.m1.1" class="ltx_Math" alttext="\Delta\mathbf{w}" display="inline"><semantics id="S2.p5.1.m1.1a"><mrow id="S2.p5.1.m1.1.1" xref="S2.p5.1.m1.1.1.cmml"><mi mathvariant="normal" id="S2.p5.1.m1.1.1.2" xref="S2.p5.1.m1.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S2.p5.1.m1.1.1.1" xref="S2.p5.1.m1.1.1.1.cmml">​</mo><mi id="S2.p5.1.m1.1.1.3" xref="S2.p5.1.m1.1.1.3.cmml">𝐰</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.1.m1.1b"><apply id="S2.p5.1.m1.1.1.cmml" xref="S2.p5.1.m1.1.1"><times id="S2.p5.1.m1.1.1.1.cmml" xref="S2.p5.1.m1.1.1.1"></times><ci id="S2.p5.1.m1.1.1.2.cmml" xref="S2.p5.1.m1.1.1.2">Δ</ci><ci id="S2.p5.1.m1.1.1.3.cmml" xref="S2.p5.1.m1.1.1.3">𝐰</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.1.m1.1c">\Delta\mathbf{w}</annotation></semantics></math> are going to be passed to the encoder in order to encrypt and compress them. The encoder output a low-dimensional coding vector <math id="S2.p5.2.m2.1" class="ltx_Math" alttext="\mathbf{y}" display="inline"><semantics id="S2.p5.2.m2.1a"><mi id="S2.p5.2.m2.1.1" xref="S2.p5.2.m2.1.1.cmml">𝐲</mi><annotation-xml encoding="MathML-Content" id="S2.p5.2.m2.1b"><ci id="S2.p5.2.m2.1.1.cmml" xref="S2.p5.2.m2.1.1">𝐲</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.2.m2.1c">\mathbf{y}</annotation></semantics></math> and clients eventually post this vector to the server. As the encoding network is unrelated with local data on clients, the coding vector reflects no private information involving local data.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.2" class="ltx_p">Once the server receives coding vectors from a certain number, <math id="S2.p6.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.p6.1.m1.1a"><mi id="S2.p6.1.m1.1.1" xref="S2.p6.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.p6.1.m1.1b"><ci id="S2.p6.1.m1.1.1.cmml" xref="S2.p6.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.1.m1.1c">K</annotation></semantics></math>, of clients, the decoder will approximately compute the aggregated gradient updates <math id="S2.p6.2.m2.3" class="ltx_Math" alttext="a(\Delta\mathbf{w}_{1},\cdots,\Delta\mathbf{w}_{K})" display="inline"><semantics id="S2.p6.2.m2.3a"><mrow id="S2.p6.2.m2.3.3" xref="S2.p6.2.m2.3.3.cmml"><mi id="S2.p6.2.m2.3.3.4" xref="S2.p6.2.m2.3.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.p6.2.m2.3.3.3" xref="S2.p6.2.m2.3.3.3.cmml">​</mo><mrow id="S2.p6.2.m2.3.3.2.2" xref="S2.p6.2.m2.3.3.2.3.cmml"><mo stretchy="false" id="S2.p6.2.m2.3.3.2.2.3" xref="S2.p6.2.m2.3.3.2.3.cmml">(</mo><mrow id="S2.p6.2.m2.2.2.1.1.1" xref="S2.p6.2.m2.2.2.1.1.1.cmml"><mi mathvariant="normal" id="S2.p6.2.m2.2.2.1.1.1.2" xref="S2.p6.2.m2.2.2.1.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S2.p6.2.m2.2.2.1.1.1.1" xref="S2.p6.2.m2.2.2.1.1.1.1.cmml">​</mo><msub id="S2.p6.2.m2.2.2.1.1.1.3" xref="S2.p6.2.m2.2.2.1.1.1.3.cmml"><mi id="S2.p6.2.m2.2.2.1.1.1.3.2" xref="S2.p6.2.m2.2.2.1.1.1.3.2.cmml">𝐰</mi><mn id="S2.p6.2.m2.2.2.1.1.1.3.3" xref="S2.p6.2.m2.2.2.1.1.1.3.3.cmml">1</mn></msub></mrow><mo id="S2.p6.2.m2.3.3.2.2.4" xref="S2.p6.2.m2.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S2.p6.2.m2.1.1" xref="S2.p6.2.m2.1.1.cmml">⋯</mi><mo id="S2.p6.2.m2.3.3.2.2.5" xref="S2.p6.2.m2.3.3.2.3.cmml">,</mo><mrow id="S2.p6.2.m2.3.3.2.2.2" xref="S2.p6.2.m2.3.3.2.2.2.cmml"><mi mathvariant="normal" id="S2.p6.2.m2.3.3.2.2.2.2" xref="S2.p6.2.m2.3.3.2.2.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S2.p6.2.m2.3.3.2.2.2.1" xref="S2.p6.2.m2.3.3.2.2.2.1.cmml">​</mo><msub id="S2.p6.2.m2.3.3.2.2.2.3" xref="S2.p6.2.m2.3.3.2.2.2.3.cmml"><mi id="S2.p6.2.m2.3.3.2.2.2.3.2" xref="S2.p6.2.m2.3.3.2.2.2.3.2.cmml">𝐰</mi><mi id="S2.p6.2.m2.3.3.2.2.2.3.3" xref="S2.p6.2.m2.3.3.2.2.2.3.3.cmml">K</mi></msub></mrow><mo stretchy="false" id="S2.p6.2.m2.3.3.2.2.6" xref="S2.p6.2.m2.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p6.2.m2.3b"><apply id="S2.p6.2.m2.3.3.cmml" xref="S2.p6.2.m2.3.3"><times id="S2.p6.2.m2.3.3.3.cmml" xref="S2.p6.2.m2.3.3.3"></times><ci id="S2.p6.2.m2.3.3.4.cmml" xref="S2.p6.2.m2.3.3.4">𝑎</ci><vector id="S2.p6.2.m2.3.3.2.3.cmml" xref="S2.p6.2.m2.3.3.2.2"><apply id="S2.p6.2.m2.2.2.1.1.1.cmml" xref="S2.p6.2.m2.2.2.1.1.1"><times id="S2.p6.2.m2.2.2.1.1.1.1.cmml" xref="S2.p6.2.m2.2.2.1.1.1.1"></times><ci id="S2.p6.2.m2.2.2.1.1.1.2.cmml" xref="S2.p6.2.m2.2.2.1.1.1.2">Δ</ci><apply id="S2.p6.2.m2.2.2.1.1.1.3.cmml" xref="S2.p6.2.m2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S2.p6.2.m2.2.2.1.1.1.3.1.cmml" xref="S2.p6.2.m2.2.2.1.1.1.3">subscript</csymbol><ci id="S2.p6.2.m2.2.2.1.1.1.3.2.cmml" xref="S2.p6.2.m2.2.2.1.1.1.3.2">𝐰</ci><cn type="integer" id="S2.p6.2.m2.2.2.1.1.1.3.3.cmml" xref="S2.p6.2.m2.2.2.1.1.1.3.3">1</cn></apply></apply><ci id="S2.p6.2.m2.1.1.cmml" xref="S2.p6.2.m2.1.1">⋯</ci><apply id="S2.p6.2.m2.3.3.2.2.2.cmml" xref="S2.p6.2.m2.3.3.2.2.2"><times id="S2.p6.2.m2.3.3.2.2.2.1.cmml" xref="S2.p6.2.m2.3.3.2.2.2.1"></times><ci id="S2.p6.2.m2.3.3.2.2.2.2.cmml" xref="S2.p6.2.m2.3.3.2.2.2.2">Δ</ci><apply id="S2.p6.2.m2.3.3.2.2.2.3.cmml" xref="S2.p6.2.m2.3.3.2.2.2.3"><csymbol cd="ambiguous" id="S2.p6.2.m2.3.3.2.2.2.3.1.cmml" xref="S2.p6.2.m2.3.3.2.2.2.3">subscript</csymbol><ci id="S2.p6.2.m2.3.3.2.2.2.3.2.cmml" xref="S2.p6.2.m2.3.3.2.2.2.3.2">𝐰</ci><ci id="S2.p6.2.m2.3.3.2.2.2.3.3.cmml" xref="S2.p6.2.m2.3.3.2.2.2.3.3">𝐾</ci></apply></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.2.m2.3c">a(\Delta\mathbf{w}_{1},\cdots,\Delta\mathbf{w}_{K})</annotation></semantics></math> without explicitly recovering gradient updates of any client. The server will synchronously distribute the aggregated updates to these clients, and then a new round of iteration starts for model training on clients. Since the encoder is a lossy compression, the decoder will not 100 percent reconstruct the aggregated updates. But this reconstruction way is still able to guarantee that the trained model will finally converge as expected.</p>
</div>
<div id="S2.p7" class="ltx_para">
<span id="S2.p7.1" class="ltx_ERROR undefined">\SubSection</span>
<p id="S2.p7.2" class="ltx_p">Network structure</p>
</div>
<div id="S2.p8" class="ltx_para">
<p id="S2.p8.8" class="ltx_p">Suppose the input and output data, <math id="S2.p8.1.m1.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S2.p8.1.m1.1a"><mi id="S2.p8.1.m1.1.1" xref="S2.p8.1.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S2.p8.1.m1.1b"><ci id="S2.p8.1.m1.1.1.cmml" xref="S2.p8.1.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.1.m1.1c">\mathbf{x}</annotation></semantics></math> and <math id="S2.p8.2.m2.1" class="ltx_Math" alttext="\mathbf{y}" display="inline"><semantics id="S2.p8.2.m2.1a"><mi id="S2.p8.2.m2.1.1" xref="S2.p8.2.m2.1.1.cmml">𝐲</mi><annotation-xml encoding="MathML-Content" id="S2.p8.2.m2.1b"><ci id="S2.p8.2.m2.1.1.cmml" xref="S2.p8.2.m2.1.1">𝐲</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.2.m2.1c">\mathbf{y}</annotation></semantics></math>, to the encoder is respectively of <math id="S2.p8.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.p8.3.m3.1a"><mi id="S2.p8.3.m3.1.1" xref="S2.p8.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.p8.3.m3.1b"><ci id="S2.p8.3.m3.1.1.cmml" xref="S2.p8.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.3.m3.1c">N</annotation></semantics></math> and <math id="S2.p8.4.m4.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.p8.4.m4.1a"><mi id="S2.p8.4.m4.1.1" xref="S2.p8.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.p8.4.m4.1b"><ci id="S2.p8.4.m4.1.1.cmml" xref="S2.p8.4.m4.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.4.m4.1c">M</annotation></semantics></math> dimensions. To compress gradient updates in federated learning, it is necessary to ensure <math id="S2.p8.5.m5.1" class="ltx_Math" alttext="M&lt;N" display="inline"><semantics id="S2.p8.5.m5.1a"><mrow id="S2.p8.5.m5.1.1" xref="S2.p8.5.m5.1.1.cmml"><mi id="S2.p8.5.m5.1.1.2" xref="S2.p8.5.m5.1.1.2.cmml">M</mi><mo id="S2.p8.5.m5.1.1.1" xref="S2.p8.5.m5.1.1.1.cmml">&lt;</mo><mi id="S2.p8.5.m5.1.1.3" xref="S2.p8.5.m5.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p8.5.m5.1b"><apply id="S2.p8.5.m5.1.1.cmml" xref="S2.p8.5.m5.1.1"><lt id="S2.p8.5.m5.1.1.1.cmml" xref="S2.p8.5.m5.1.1.1"></lt><ci id="S2.p8.5.m5.1.1.2.cmml" xref="S2.p8.5.m5.1.1.2">𝑀</ci><ci id="S2.p8.5.m5.1.1.3.cmml" xref="S2.p8.5.m5.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.5.m5.1c">M&lt;N</annotation></semantics></math>. To protect local data on clients, the updates are required to be unknown to the server. In other words, given coding vectors <math id="S2.p8.6.m6.4" class="ltx_Math" alttext="(\mathbf{y}_{1},\mathbf{y}_{2},\cdots,\mathbf{y}_{K})\in\mathbb{R}^{M\times K}" display="inline"><semantics id="S2.p8.6.m6.4a"><mrow id="S2.p8.6.m6.4.4" xref="S2.p8.6.m6.4.4.cmml"><mrow id="S2.p8.6.m6.4.4.3.3" xref="S2.p8.6.m6.4.4.3.4.cmml"><mo stretchy="false" id="S2.p8.6.m6.4.4.3.3.4" xref="S2.p8.6.m6.4.4.3.4.cmml">(</mo><msub id="S2.p8.6.m6.2.2.1.1.1" xref="S2.p8.6.m6.2.2.1.1.1.cmml"><mi id="S2.p8.6.m6.2.2.1.1.1.2" xref="S2.p8.6.m6.2.2.1.1.1.2.cmml">𝐲</mi><mn id="S2.p8.6.m6.2.2.1.1.1.3" xref="S2.p8.6.m6.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.p8.6.m6.4.4.3.3.5" xref="S2.p8.6.m6.4.4.3.4.cmml">,</mo><msub id="S2.p8.6.m6.3.3.2.2.2" xref="S2.p8.6.m6.3.3.2.2.2.cmml"><mi id="S2.p8.6.m6.3.3.2.2.2.2" xref="S2.p8.6.m6.3.3.2.2.2.2.cmml">𝐲</mi><mn id="S2.p8.6.m6.3.3.2.2.2.3" xref="S2.p8.6.m6.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.p8.6.m6.4.4.3.3.6" xref="S2.p8.6.m6.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.p8.6.m6.1.1" xref="S2.p8.6.m6.1.1.cmml">⋯</mi><mo id="S2.p8.6.m6.4.4.3.3.7" xref="S2.p8.6.m6.4.4.3.4.cmml">,</mo><msub id="S2.p8.6.m6.4.4.3.3.3" xref="S2.p8.6.m6.4.4.3.3.3.cmml"><mi id="S2.p8.6.m6.4.4.3.3.3.2" xref="S2.p8.6.m6.4.4.3.3.3.2.cmml">𝐲</mi><mi id="S2.p8.6.m6.4.4.3.3.3.3" xref="S2.p8.6.m6.4.4.3.3.3.3.cmml">K</mi></msub><mo stretchy="false" id="S2.p8.6.m6.4.4.3.3.8" xref="S2.p8.6.m6.4.4.3.4.cmml">)</mo></mrow><mo id="S2.p8.6.m6.4.4.4" xref="S2.p8.6.m6.4.4.4.cmml">∈</mo><msup id="S2.p8.6.m6.4.4.5" xref="S2.p8.6.m6.4.4.5.cmml"><mi id="S2.p8.6.m6.4.4.5.2" xref="S2.p8.6.m6.4.4.5.2.cmml">ℝ</mi><mrow id="S2.p8.6.m6.4.4.5.3" xref="S2.p8.6.m6.4.4.5.3.cmml"><mi id="S2.p8.6.m6.4.4.5.3.2" xref="S2.p8.6.m6.4.4.5.3.2.cmml">M</mi><mo lspace="0.222em" rspace="0.222em" id="S2.p8.6.m6.4.4.5.3.1" xref="S2.p8.6.m6.4.4.5.3.1.cmml">×</mo><mi id="S2.p8.6.m6.4.4.5.3.3" xref="S2.p8.6.m6.4.4.5.3.3.cmml">K</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.p8.6.m6.4b"><apply id="S2.p8.6.m6.4.4.cmml" xref="S2.p8.6.m6.4.4"><in id="S2.p8.6.m6.4.4.4.cmml" xref="S2.p8.6.m6.4.4.4"></in><vector id="S2.p8.6.m6.4.4.3.4.cmml" xref="S2.p8.6.m6.4.4.3.3"><apply id="S2.p8.6.m6.2.2.1.1.1.cmml" xref="S2.p8.6.m6.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.p8.6.m6.2.2.1.1.1.1.cmml" xref="S2.p8.6.m6.2.2.1.1.1">subscript</csymbol><ci id="S2.p8.6.m6.2.2.1.1.1.2.cmml" xref="S2.p8.6.m6.2.2.1.1.1.2">𝐲</ci><cn type="integer" id="S2.p8.6.m6.2.2.1.1.1.3.cmml" xref="S2.p8.6.m6.2.2.1.1.1.3">1</cn></apply><apply id="S2.p8.6.m6.3.3.2.2.2.cmml" xref="S2.p8.6.m6.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.p8.6.m6.3.3.2.2.2.1.cmml" xref="S2.p8.6.m6.3.3.2.2.2">subscript</csymbol><ci id="S2.p8.6.m6.3.3.2.2.2.2.cmml" xref="S2.p8.6.m6.3.3.2.2.2.2">𝐲</ci><cn type="integer" id="S2.p8.6.m6.3.3.2.2.2.3.cmml" xref="S2.p8.6.m6.3.3.2.2.2.3">2</cn></apply><ci id="S2.p8.6.m6.1.1.cmml" xref="S2.p8.6.m6.1.1">⋯</ci><apply id="S2.p8.6.m6.4.4.3.3.3.cmml" xref="S2.p8.6.m6.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.p8.6.m6.4.4.3.3.3.1.cmml" xref="S2.p8.6.m6.4.4.3.3.3">subscript</csymbol><ci id="S2.p8.6.m6.4.4.3.3.3.2.cmml" xref="S2.p8.6.m6.4.4.3.3.3.2">𝐲</ci><ci id="S2.p8.6.m6.4.4.3.3.3.3.cmml" xref="S2.p8.6.m6.4.4.3.3.3.3">𝐾</ci></apply></vector><apply id="S2.p8.6.m6.4.4.5.cmml" xref="S2.p8.6.m6.4.4.5"><csymbol cd="ambiguous" id="S2.p8.6.m6.4.4.5.1.cmml" xref="S2.p8.6.m6.4.4.5">superscript</csymbol><ci id="S2.p8.6.m6.4.4.5.2.cmml" xref="S2.p8.6.m6.4.4.5.2">ℝ</ci><apply id="S2.p8.6.m6.4.4.5.3.cmml" xref="S2.p8.6.m6.4.4.5.3"><times id="S2.p8.6.m6.4.4.5.3.1.cmml" xref="S2.p8.6.m6.4.4.5.3.1"></times><ci id="S2.p8.6.m6.4.4.5.3.2.cmml" xref="S2.p8.6.m6.4.4.5.3.2">𝑀</ci><ci id="S2.p8.6.m6.4.4.5.3.3.cmml" xref="S2.p8.6.m6.4.4.5.3.3">𝐾</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.6.m6.4c">(\mathbf{y}_{1},\mathbf{y}_{2},\cdots,\mathbf{y}_{K})\in\mathbb{R}^{M\times K}</annotation></semantics></math> transmitted out from <math id="S2.p8.7.m7.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.p8.7.m7.1a"><mi id="S2.p8.7.m7.1.1" xref="S2.p8.7.m7.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.p8.7.m7.1b"><ci id="S2.p8.7.m7.1.1.cmml" xref="S2.p8.7.m7.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.7.m7.1c">K</annotation></semantics></math> different clients, the aggregated updates <math id="S2.p8.8.m8.4" class="ltx_Math" alttext="a(\mathbf{x}_{1},\mathbf{x}_{2},\cdots,\mathbf{x}_{K})\in\mathbb{R}^{N}" display="inline"><semantics id="S2.p8.8.m8.4a"><mrow id="S2.p8.8.m8.4.4" xref="S2.p8.8.m8.4.4.cmml"><mrow id="S2.p8.8.m8.4.4.3" xref="S2.p8.8.m8.4.4.3.cmml"><mi id="S2.p8.8.m8.4.4.3.5" xref="S2.p8.8.m8.4.4.3.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.p8.8.m8.4.4.3.4" xref="S2.p8.8.m8.4.4.3.4.cmml">​</mo><mrow id="S2.p8.8.m8.4.4.3.3.3" xref="S2.p8.8.m8.4.4.3.3.4.cmml"><mo stretchy="false" id="S2.p8.8.m8.4.4.3.3.3.4" xref="S2.p8.8.m8.4.4.3.3.4.cmml">(</mo><msub id="S2.p8.8.m8.2.2.1.1.1.1" xref="S2.p8.8.m8.2.2.1.1.1.1.cmml"><mi id="S2.p8.8.m8.2.2.1.1.1.1.2" xref="S2.p8.8.m8.2.2.1.1.1.1.2.cmml">𝐱</mi><mn id="S2.p8.8.m8.2.2.1.1.1.1.3" xref="S2.p8.8.m8.2.2.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.p8.8.m8.4.4.3.3.3.5" xref="S2.p8.8.m8.4.4.3.3.4.cmml">,</mo><msub id="S2.p8.8.m8.3.3.2.2.2.2" xref="S2.p8.8.m8.3.3.2.2.2.2.cmml"><mi id="S2.p8.8.m8.3.3.2.2.2.2.2" xref="S2.p8.8.m8.3.3.2.2.2.2.2.cmml">𝐱</mi><mn id="S2.p8.8.m8.3.3.2.2.2.2.3" xref="S2.p8.8.m8.3.3.2.2.2.2.3.cmml">2</mn></msub><mo id="S2.p8.8.m8.4.4.3.3.3.6" xref="S2.p8.8.m8.4.4.3.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.p8.8.m8.1.1" xref="S2.p8.8.m8.1.1.cmml">⋯</mi><mo id="S2.p8.8.m8.4.4.3.3.3.7" xref="S2.p8.8.m8.4.4.3.3.4.cmml">,</mo><msub id="S2.p8.8.m8.4.4.3.3.3.3" xref="S2.p8.8.m8.4.4.3.3.3.3.cmml"><mi id="S2.p8.8.m8.4.4.3.3.3.3.2" xref="S2.p8.8.m8.4.4.3.3.3.3.2.cmml">𝐱</mi><mi id="S2.p8.8.m8.4.4.3.3.3.3.3" xref="S2.p8.8.m8.4.4.3.3.3.3.3.cmml">K</mi></msub><mo stretchy="false" id="S2.p8.8.m8.4.4.3.3.3.8" xref="S2.p8.8.m8.4.4.3.3.4.cmml">)</mo></mrow></mrow><mo id="S2.p8.8.m8.4.4.4" xref="S2.p8.8.m8.4.4.4.cmml">∈</mo><msup id="S2.p8.8.m8.4.4.5" xref="S2.p8.8.m8.4.4.5.cmml"><mi id="S2.p8.8.m8.4.4.5.2" xref="S2.p8.8.m8.4.4.5.2.cmml">ℝ</mi><mi id="S2.p8.8.m8.4.4.5.3" xref="S2.p8.8.m8.4.4.5.3.cmml">N</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.p8.8.m8.4b"><apply id="S2.p8.8.m8.4.4.cmml" xref="S2.p8.8.m8.4.4"><in id="S2.p8.8.m8.4.4.4.cmml" xref="S2.p8.8.m8.4.4.4"></in><apply id="S2.p8.8.m8.4.4.3.cmml" xref="S2.p8.8.m8.4.4.3"><times id="S2.p8.8.m8.4.4.3.4.cmml" xref="S2.p8.8.m8.4.4.3.4"></times><ci id="S2.p8.8.m8.4.4.3.5.cmml" xref="S2.p8.8.m8.4.4.3.5">𝑎</ci><vector id="S2.p8.8.m8.4.4.3.3.4.cmml" xref="S2.p8.8.m8.4.4.3.3.3"><apply id="S2.p8.8.m8.2.2.1.1.1.1.cmml" xref="S2.p8.8.m8.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.p8.8.m8.2.2.1.1.1.1.1.cmml" xref="S2.p8.8.m8.2.2.1.1.1.1">subscript</csymbol><ci id="S2.p8.8.m8.2.2.1.1.1.1.2.cmml" xref="S2.p8.8.m8.2.2.1.1.1.1.2">𝐱</ci><cn type="integer" id="S2.p8.8.m8.2.2.1.1.1.1.3.cmml" xref="S2.p8.8.m8.2.2.1.1.1.1.3">1</cn></apply><apply id="S2.p8.8.m8.3.3.2.2.2.2.cmml" xref="S2.p8.8.m8.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S2.p8.8.m8.3.3.2.2.2.2.1.cmml" xref="S2.p8.8.m8.3.3.2.2.2.2">subscript</csymbol><ci id="S2.p8.8.m8.3.3.2.2.2.2.2.cmml" xref="S2.p8.8.m8.3.3.2.2.2.2.2">𝐱</ci><cn type="integer" id="S2.p8.8.m8.3.3.2.2.2.2.3.cmml" xref="S2.p8.8.m8.3.3.2.2.2.2.3">2</cn></apply><ci id="S2.p8.8.m8.1.1.cmml" xref="S2.p8.8.m8.1.1">⋯</ci><apply id="S2.p8.8.m8.4.4.3.3.3.3.cmml" xref="S2.p8.8.m8.4.4.3.3.3.3"><csymbol cd="ambiguous" id="S2.p8.8.m8.4.4.3.3.3.3.1.cmml" xref="S2.p8.8.m8.4.4.3.3.3.3">subscript</csymbol><ci id="S2.p8.8.m8.4.4.3.3.3.3.2.cmml" xref="S2.p8.8.m8.4.4.3.3.3.3.2">𝐱</ci><ci id="S2.p8.8.m8.4.4.3.3.3.3.3.cmml" xref="S2.p8.8.m8.4.4.3.3.3.3.3">𝐾</ci></apply></vector></apply><apply id="S2.p8.8.m8.4.4.5.cmml" xref="S2.p8.8.m8.4.4.5"><csymbol cd="ambiguous" id="S2.p8.8.m8.4.4.5.1.cmml" xref="S2.p8.8.m8.4.4.5">superscript</csymbol><ci id="S2.p8.8.m8.4.4.5.2.cmml" xref="S2.p8.8.m8.4.4.5.2">ℝ</ci><ci id="S2.p8.8.m8.4.4.5.3.cmml" xref="S2.p8.8.m8.4.4.5.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.8.m8.4c">a(\mathbf{x}_{1},\mathbf{x}_{2},\cdots,\mathbf{x}_{K})\in\mathbb{R}^{N}</annotation></semantics></math> should be directly worked out on the server. Meanwhile considering that the server usually has more powerful computing ability, we will adopt a deeper decoder but a simpler encoder in the encrypted neural network.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/1908.08340/assets/x2.png" id="S2.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="282" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Structure of the encrypted neural network.</figcaption>
</figure>
<div id="S2.p9" class="ltx_para">
<p id="S2.p9.3" class="ltx_p">As shown in Fig. <a href="#S2.F2" title="Figure 2 ‣ 2 Encrypted Neural Network ‣ An End-to-End Encrypted Neural Network for Gradient Updates Transmission in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the whole ENN is designed to consist of multiple encoding sub-networks <math id="S2.p9.1.m1.1" class="ltx_Math" alttext="f:\mathbb{R}^{N}\rightarrow\mathbb{R}^{M}" display="inline"><semantics id="S2.p9.1.m1.1a"><mrow id="S2.p9.1.m1.1.1" xref="S2.p9.1.m1.1.1.cmml"><mi id="S2.p9.1.m1.1.1.2" xref="S2.p9.1.m1.1.1.2.cmml">f</mi><mo lspace="0.278em" rspace="0.278em" id="S2.p9.1.m1.1.1.1" xref="S2.p9.1.m1.1.1.1.cmml">:</mo><mrow id="S2.p9.1.m1.1.1.3" xref="S2.p9.1.m1.1.1.3.cmml"><msup id="S2.p9.1.m1.1.1.3.2" xref="S2.p9.1.m1.1.1.3.2.cmml"><mi id="S2.p9.1.m1.1.1.3.2.2" xref="S2.p9.1.m1.1.1.3.2.2.cmml">ℝ</mi><mi id="S2.p9.1.m1.1.1.3.2.3" xref="S2.p9.1.m1.1.1.3.2.3.cmml">N</mi></msup><mo stretchy="false" id="S2.p9.1.m1.1.1.3.1" xref="S2.p9.1.m1.1.1.3.1.cmml">→</mo><msup id="S2.p9.1.m1.1.1.3.3" xref="S2.p9.1.m1.1.1.3.3.cmml"><mi id="S2.p9.1.m1.1.1.3.3.2" xref="S2.p9.1.m1.1.1.3.3.2.cmml">ℝ</mi><mi id="S2.p9.1.m1.1.1.3.3.3" xref="S2.p9.1.m1.1.1.3.3.3.cmml">M</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p9.1.m1.1b"><apply id="S2.p9.1.m1.1.1.cmml" xref="S2.p9.1.m1.1.1"><ci id="S2.p9.1.m1.1.1.1.cmml" xref="S2.p9.1.m1.1.1.1">:</ci><ci id="S2.p9.1.m1.1.1.2.cmml" xref="S2.p9.1.m1.1.1.2">𝑓</ci><apply id="S2.p9.1.m1.1.1.3.cmml" xref="S2.p9.1.m1.1.1.3"><ci id="S2.p9.1.m1.1.1.3.1.cmml" xref="S2.p9.1.m1.1.1.3.1">→</ci><apply id="S2.p9.1.m1.1.1.3.2.cmml" xref="S2.p9.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S2.p9.1.m1.1.1.3.2.1.cmml" xref="S2.p9.1.m1.1.1.3.2">superscript</csymbol><ci id="S2.p9.1.m1.1.1.3.2.2.cmml" xref="S2.p9.1.m1.1.1.3.2.2">ℝ</ci><ci id="S2.p9.1.m1.1.1.3.2.3.cmml" xref="S2.p9.1.m1.1.1.3.2.3">𝑁</ci></apply><apply id="S2.p9.1.m1.1.1.3.3.cmml" xref="S2.p9.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S2.p9.1.m1.1.1.3.3.1.cmml" xref="S2.p9.1.m1.1.1.3.3">superscript</csymbol><ci id="S2.p9.1.m1.1.1.3.3.2.cmml" xref="S2.p9.1.m1.1.1.3.3.2">ℝ</ci><ci id="S2.p9.1.m1.1.1.3.3.3.cmml" xref="S2.p9.1.m1.1.1.3.3.3">𝑀</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p9.1.m1.1c">f:\mathbb{R}^{N}\rightarrow\mathbb{R}^{M}</annotation></semantics></math> and a decoding network <math id="S2.p9.2.m2.1" class="ltx_Math" alttext="g:\mathbb{R}^{MK}\rightarrow\mathbb{R}^{N}" display="inline"><semantics id="S2.p9.2.m2.1a"><mrow id="S2.p9.2.m2.1.1" xref="S2.p9.2.m2.1.1.cmml"><mi id="S2.p9.2.m2.1.1.2" xref="S2.p9.2.m2.1.1.2.cmml">g</mi><mo lspace="0.278em" rspace="0.278em" id="S2.p9.2.m2.1.1.1" xref="S2.p9.2.m2.1.1.1.cmml">:</mo><mrow id="S2.p9.2.m2.1.1.3" xref="S2.p9.2.m2.1.1.3.cmml"><msup id="S2.p9.2.m2.1.1.3.2" xref="S2.p9.2.m2.1.1.3.2.cmml"><mi id="S2.p9.2.m2.1.1.3.2.2" xref="S2.p9.2.m2.1.1.3.2.2.cmml">ℝ</mi><mrow id="S2.p9.2.m2.1.1.3.2.3" xref="S2.p9.2.m2.1.1.3.2.3.cmml"><mi id="S2.p9.2.m2.1.1.3.2.3.2" xref="S2.p9.2.m2.1.1.3.2.3.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.p9.2.m2.1.1.3.2.3.1" xref="S2.p9.2.m2.1.1.3.2.3.1.cmml">​</mo><mi id="S2.p9.2.m2.1.1.3.2.3.3" xref="S2.p9.2.m2.1.1.3.2.3.3.cmml">K</mi></mrow></msup><mo stretchy="false" id="S2.p9.2.m2.1.1.3.1" xref="S2.p9.2.m2.1.1.3.1.cmml">→</mo><msup id="S2.p9.2.m2.1.1.3.3" xref="S2.p9.2.m2.1.1.3.3.cmml"><mi id="S2.p9.2.m2.1.1.3.3.2" xref="S2.p9.2.m2.1.1.3.3.2.cmml">ℝ</mi><mi id="S2.p9.2.m2.1.1.3.3.3" xref="S2.p9.2.m2.1.1.3.3.3.cmml">N</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p9.2.m2.1b"><apply id="S2.p9.2.m2.1.1.cmml" xref="S2.p9.2.m2.1.1"><ci id="S2.p9.2.m2.1.1.1.cmml" xref="S2.p9.2.m2.1.1.1">:</ci><ci id="S2.p9.2.m2.1.1.2.cmml" xref="S2.p9.2.m2.1.1.2">𝑔</ci><apply id="S2.p9.2.m2.1.1.3.cmml" xref="S2.p9.2.m2.1.1.3"><ci id="S2.p9.2.m2.1.1.3.1.cmml" xref="S2.p9.2.m2.1.1.3.1">→</ci><apply id="S2.p9.2.m2.1.1.3.2.cmml" xref="S2.p9.2.m2.1.1.3.2"><csymbol cd="ambiguous" id="S2.p9.2.m2.1.1.3.2.1.cmml" xref="S2.p9.2.m2.1.1.3.2">superscript</csymbol><ci id="S2.p9.2.m2.1.1.3.2.2.cmml" xref="S2.p9.2.m2.1.1.3.2.2">ℝ</ci><apply id="S2.p9.2.m2.1.1.3.2.3.cmml" xref="S2.p9.2.m2.1.1.3.2.3"><times id="S2.p9.2.m2.1.1.3.2.3.1.cmml" xref="S2.p9.2.m2.1.1.3.2.3.1"></times><ci id="S2.p9.2.m2.1.1.3.2.3.2.cmml" xref="S2.p9.2.m2.1.1.3.2.3.2">𝑀</ci><ci id="S2.p9.2.m2.1.1.3.2.3.3.cmml" xref="S2.p9.2.m2.1.1.3.2.3.3">𝐾</ci></apply></apply><apply id="S2.p9.2.m2.1.1.3.3.cmml" xref="S2.p9.2.m2.1.1.3.3"><csymbol cd="ambiguous" id="S2.p9.2.m2.1.1.3.3.1.cmml" xref="S2.p9.2.m2.1.1.3.3">superscript</csymbol><ci id="S2.p9.2.m2.1.1.3.3.2.cmml" xref="S2.p9.2.m2.1.1.3.3.2">ℝ</ci><ci id="S2.p9.2.m2.1.1.3.3.3.cmml" xref="S2.p9.2.m2.1.1.3.3.3">𝑁</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p9.2.m2.1c">g:\mathbb{R}^{MK}\rightarrow\mathbb{R}^{N}</annotation></semantics></math>, where <math id="S2.p9.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.p9.3.m3.1a"><mi id="S2.p9.3.m3.1.1" xref="S2.p9.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.p9.3.m3.1b"><ci id="S2.p9.3.m3.1.1.cmml" xref="S2.p9.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p9.3.m3.1c">K</annotation></semantics></math> is the maximal number of encoders (clients) accepted by the decoder(server).</p>
</div>
<div id="S2.p10" class="ltx_para">
<p id="S2.p10.6" class="ltx_p">The encoding sub-network consists of <math id="S2.p10.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S2.p10.1.m1.1a"><mn id="S2.p10.1.m1.1.1" xref="S2.p10.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S2.p10.1.m1.1b"><cn type="integer" id="S2.p10.1.m1.1.1.cmml" xref="S2.p10.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p10.1.m1.1c">2</annotation></semantics></math> fully connected (FC) layers together with an activation layer. The input data <math id="S2.p10.2.m2.1" class="ltx_Math" alttext="\mathbf{x}_{i}\in\mathbb{R}^{N}" display="inline"><semantics id="S2.p10.2.m2.1a"><mrow id="S2.p10.2.m2.1.1" xref="S2.p10.2.m2.1.1.cmml"><msub id="S2.p10.2.m2.1.1.2" xref="S2.p10.2.m2.1.1.2.cmml"><mi id="S2.p10.2.m2.1.1.2.2" xref="S2.p10.2.m2.1.1.2.2.cmml">𝐱</mi><mi id="S2.p10.2.m2.1.1.2.3" xref="S2.p10.2.m2.1.1.2.3.cmml">i</mi></msub><mo id="S2.p10.2.m2.1.1.1" xref="S2.p10.2.m2.1.1.1.cmml">∈</mo><msup id="S2.p10.2.m2.1.1.3" xref="S2.p10.2.m2.1.1.3.cmml"><mi id="S2.p10.2.m2.1.1.3.2" xref="S2.p10.2.m2.1.1.3.2.cmml">ℝ</mi><mi id="S2.p10.2.m2.1.1.3.3" xref="S2.p10.2.m2.1.1.3.3.cmml">N</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.p10.2.m2.1b"><apply id="S2.p10.2.m2.1.1.cmml" xref="S2.p10.2.m2.1.1"><in id="S2.p10.2.m2.1.1.1.cmml" xref="S2.p10.2.m2.1.1.1"></in><apply id="S2.p10.2.m2.1.1.2.cmml" xref="S2.p10.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.p10.2.m2.1.1.2.1.cmml" xref="S2.p10.2.m2.1.1.2">subscript</csymbol><ci id="S2.p10.2.m2.1.1.2.2.cmml" xref="S2.p10.2.m2.1.1.2.2">𝐱</ci><ci id="S2.p10.2.m2.1.1.2.3.cmml" xref="S2.p10.2.m2.1.1.2.3">𝑖</ci></apply><apply id="S2.p10.2.m2.1.1.3.cmml" xref="S2.p10.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.p10.2.m2.1.1.3.1.cmml" xref="S2.p10.2.m2.1.1.3">superscript</csymbol><ci id="S2.p10.2.m2.1.1.3.2.cmml" xref="S2.p10.2.m2.1.1.3.2">ℝ</ci><ci id="S2.p10.2.m2.1.1.3.3.cmml" xref="S2.p10.2.m2.1.1.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p10.2.m2.1c">\mathbf{x}_{i}\in\mathbb{R}^{N}</annotation></semantics></math> will be mapped with the encoder to a coding vector <math id="S2.p10.3.m3.1" class="ltx_Math" alttext="\mathbf{y}_{i}=f(\mathbf{x}_{i})" display="inline"><semantics id="S2.p10.3.m3.1a"><mrow id="S2.p10.3.m3.1.1" xref="S2.p10.3.m3.1.1.cmml"><msub id="S2.p10.3.m3.1.1.3" xref="S2.p10.3.m3.1.1.3.cmml"><mi id="S2.p10.3.m3.1.1.3.2" xref="S2.p10.3.m3.1.1.3.2.cmml">𝐲</mi><mi id="S2.p10.3.m3.1.1.3.3" xref="S2.p10.3.m3.1.1.3.3.cmml">i</mi></msub><mo id="S2.p10.3.m3.1.1.2" xref="S2.p10.3.m3.1.1.2.cmml">=</mo><mrow id="S2.p10.3.m3.1.1.1" xref="S2.p10.3.m3.1.1.1.cmml"><mi id="S2.p10.3.m3.1.1.1.3" xref="S2.p10.3.m3.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.p10.3.m3.1.1.1.2" xref="S2.p10.3.m3.1.1.1.2.cmml">​</mo><mrow id="S2.p10.3.m3.1.1.1.1.1" xref="S2.p10.3.m3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.p10.3.m3.1.1.1.1.1.2" xref="S2.p10.3.m3.1.1.1.1.1.1.cmml">(</mo><msub id="S2.p10.3.m3.1.1.1.1.1.1" xref="S2.p10.3.m3.1.1.1.1.1.1.cmml"><mi id="S2.p10.3.m3.1.1.1.1.1.1.2" xref="S2.p10.3.m3.1.1.1.1.1.1.2.cmml">𝐱</mi><mi id="S2.p10.3.m3.1.1.1.1.1.1.3" xref="S2.p10.3.m3.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S2.p10.3.m3.1.1.1.1.1.3" xref="S2.p10.3.m3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p10.3.m3.1b"><apply id="S2.p10.3.m3.1.1.cmml" xref="S2.p10.3.m3.1.1"><eq id="S2.p10.3.m3.1.1.2.cmml" xref="S2.p10.3.m3.1.1.2"></eq><apply id="S2.p10.3.m3.1.1.3.cmml" xref="S2.p10.3.m3.1.1.3"><csymbol cd="ambiguous" id="S2.p10.3.m3.1.1.3.1.cmml" xref="S2.p10.3.m3.1.1.3">subscript</csymbol><ci id="S2.p10.3.m3.1.1.3.2.cmml" xref="S2.p10.3.m3.1.1.3.2">𝐲</ci><ci id="S2.p10.3.m3.1.1.3.3.cmml" xref="S2.p10.3.m3.1.1.3.3">𝑖</ci></apply><apply id="S2.p10.3.m3.1.1.1.cmml" xref="S2.p10.3.m3.1.1.1"><times id="S2.p10.3.m3.1.1.1.2.cmml" xref="S2.p10.3.m3.1.1.1.2"></times><ci id="S2.p10.3.m3.1.1.1.3.cmml" xref="S2.p10.3.m3.1.1.1.3">𝑓</ci><apply id="S2.p10.3.m3.1.1.1.1.1.1.cmml" xref="S2.p10.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p10.3.m3.1.1.1.1.1.1.1.cmml" xref="S2.p10.3.m3.1.1.1.1.1">subscript</csymbol><ci id="S2.p10.3.m3.1.1.1.1.1.1.2.cmml" xref="S2.p10.3.m3.1.1.1.1.1.1.2">𝐱</ci><ci id="S2.p10.3.m3.1.1.1.1.1.1.3.cmml" xref="S2.p10.3.m3.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p10.3.m3.1c">\mathbf{y}_{i}=f(\mathbf{x}_{i})</annotation></semantics></math> of lower dimensions <math id="S2.p10.4.m4.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.p10.4.m4.1a"><mi id="S2.p10.4.m4.1.1" xref="S2.p10.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.p10.4.m4.1b"><ci id="S2.p10.4.m4.1.1.cmml" xref="S2.p10.4.m4.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p10.4.m4.1c">M</annotation></semantics></math>. Hence the compression ratio <math id="S2.p10.5.m5.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S2.p10.5.m5.1a"><mi id="S2.p10.5.m5.1.1" xref="S2.p10.5.m5.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.p10.5.m5.1b"><ci id="S2.p10.5.m5.1.1.cmml" xref="S2.p10.5.m5.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p10.5.m5.1c">r</annotation></semantics></math> is equal to <math id="S2.p10.6.m6.1" class="ltx_Math" alttext="N/M" display="inline"><semantics id="S2.p10.6.m6.1a"><mrow id="S2.p10.6.m6.1.1" xref="S2.p10.6.m6.1.1.cmml"><mi id="S2.p10.6.m6.1.1.2" xref="S2.p10.6.m6.1.1.2.cmml">N</mi><mo id="S2.p10.6.m6.1.1.1" xref="S2.p10.6.m6.1.1.1.cmml">/</mo><mi id="S2.p10.6.m6.1.1.3" xref="S2.p10.6.m6.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p10.6.m6.1b"><apply id="S2.p10.6.m6.1.1.cmml" xref="S2.p10.6.m6.1.1"><divide id="S2.p10.6.m6.1.1.1.cmml" xref="S2.p10.6.m6.1.1.1"></divide><ci id="S2.p10.6.m6.1.1.2.cmml" xref="S2.p10.6.m6.1.1.2">𝑁</ci><ci id="S2.p10.6.m6.1.1.3.cmml" xref="S2.p10.6.m6.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p10.6.m6.1c">N/M</annotation></semantics></math>. The related parameters are kept same for each encoding sub-network on clients.</p>
</div>
<div id="S2.p11" class="ltx_para">
<p id="S2.p11.9" class="ltx_p">Deeper than the encoding sub-network, the decoding one is designed with <math id="S2.p11.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.p11.1.m1.1a"><mi id="S2.p11.1.m1.1.1" xref="S2.p11.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.p11.1.m1.1b"><ci id="S2.p11.1.m1.1.1.cmml" xref="S2.p11.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p11.1.m1.1c">n</annotation></semantics></math> residual block <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>,where the input is the concatenation of coding vectors <math id="S2.p11.2.m2.2" class="ltx_Math" alttext="\mathbf{\hat{y}}=(\mathbf{y}_{1}^{\mathsf{T}},\cdots\mathbf{y}_{K}^{\mathsf{T}})^{\mathsf{T}}\in\mathbb{R}^{MK}" display="inline"><semantics id="S2.p11.2.m2.2a"><mrow id="S2.p11.2.m2.2.2" xref="S2.p11.2.m2.2.2.cmml"><mover accent="true" id="S2.p11.2.m2.2.2.4" xref="S2.p11.2.m2.2.2.4.cmml"><mi id="S2.p11.2.m2.2.2.4.2" xref="S2.p11.2.m2.2.2.4.2.cmml">𝐲</mi><mo id="S2.p11.2.m2.2.2.4.1" xref="S2.p11.2.m2.2.2.4.1.cmml">^</mo></mover><mo id="S2.p11.2.m2.2.2.5" xref="S2.p11.2.m2.2.2.5.cmml">=</mo><msup id="S2.p11.2.m2.2.2.2" xref="S2.p11.2.m2.2.2.2.cmml"><mrow id="S2.p11.2.m2.2.2.2.2.2" xref="S2.p11.2.m2.2.2.2.2.3.cmml"><mo stretchy="false" id="S2.p11.2.m2.2.2.2.2.2.3" xref="S2.p11.2.m2.2.2.2.2.3.cmml">(</mo><msubsup id="S2.p11.2.m2.1.1.1.1.1.1" xref="S2.p11.2.m2.1.1.1.1.1.1.cmml"><mi id="S2.p11.2.m2.1.1.1.1.1.1.2.2" xref="S2.p11.2.m2.1.1.1.1.1.1.2.2.cmml">𝐲</mi><mn id="S2.p11.2.m2.1.1.1.1.1.1.2.3" xref="S2.p11.2.m2.1.1.1.1.1.1.2.3.cmml">1</mn><mi id="S2.p11.2.m2.1.1.1.1.1.1.3" xref="S2.p11.2.m2.1.1.1.1.1.1.3.cmml">𝖳</mi></msubsup><mo id="S2.p11.2.m2.2.2.2.2.2.4" xref="S2.p11.2.m2.2.2.2.2.3.cmml">,</mo><mrow id="S2.p11.2.m2.2.2.2.2.2.2" xref="S2.p11.2.m2.2.2.2.2.2.2.cmml"><mi mathvariant="normal" id="S2.p11.2.m2.2.2.2.2.2.2.2" xref="S2.p11.2.m2.2.2.2.2.2.2.2.cmml">⋯</mi><mo lspace="0em" rspace="0em" id="S2.p11.2.m2.2.2.2.2.2.2.1" xref="S2.p11.2.m2.2.2.2.2.2.2.1.cmml">​</mo><msubsup id="S2.p11.2.m2.2.2.2.2.2.2.3" xref="S2.p11.2.m2.2.2.2.2.2.2.3.cmml"><mi id="S2.p11.2.m2.2.2.2.2.2.2.3.2.2" xref="S2.p11.2.m2.2.2.2.2.2.2.3.2.2.cmml">𝐲</mi><mi id="S2.p11.2.m2.2.2.2.2.2.2.3.2.3" xref="S2.p11.2.m2.2.2.2.2.2.2.3.2.3.cmml">K</mi><mi id="S2.p11.2.m2.2.2.2.2.2.2.3.3" xref="S2.p11.2.m2.2.2.2.2.2.2.3.3.cmml">𝖳</mi></msubsup></mrow><mo stretchy="false" id="S2.p11.2.m2.2.2.2.2.2.5" xref="S2.p11.2.m2.2.2.2.2.3.cmml">)</mo></mrow><mi id="S2.p11.2.m2.2.2.2.4" xref="S2.p11.2.m2.2.2.2.4.cmml">𝖳</mi></msup><mo id="S2.p11.2.m2.2.2.6" xref="S2.p11.2.m2.2.2.6.cmml">∈</mo><msup id="S2.p11.2.m2.2.2.7" xref="S2.p11.2.m2.2.2.7.cmml"><mi id="S2.p11.2.m2.2.2.7.2" xref="S2.p11.2.m2.2.2.7.2.cmml">ℝ</mi><mrow id="S2.p11.2.m2.2.2.7.3" xref="S2.p11.2.m2.2.2.7.3.cmml"><mi id="S2.p11.2.m2.2.2.7.3.2" xref="S2.p11.2.m2.2.2.7.3.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.p11.2.m2.2.2.7.3.1" xref="S2.p11.2.m2.2.2.7.3.1.cmml">​</mo><mi id="S2.p11.2.m2.2.2.7.3.3" xref="S2.p11.2.m2.2.2.7.3.3.cmml">K</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.p11.2.m2.2b"><apply id="S2.p11.2.m2.2.2.cmml" xref="S2.p11.2.m2.2.2"><and id="S2.p11.2.m2.2.2a.cmml" xref="S2.p11.2.m2.2.2"></and><apply id="S2.p11.2.m2.2.2b.cmml" xref="S2.p11.2.m2.2.2"><eq id="S2.p11.2.m2.2.2.5.cmml" xref="S2.p11.2.m2.2.2.5"></eq><apply id="S2.p11.2.m2.2.2.4.cmml" xref="S2.p11.2.m2.2.2.4"><ci id="S2.p11.2.m2.2.2.4.1.cmml" xref="S2.p11.2.m2.2.2.4.1">^</ci><ci id="S2.p11.2.m2.2.2.4.2.cmml" xref="S2.p11.2.m2.2.2.4.2">𝐲</ci></apply><apply id="S2.p11.2.m2.2.2.2.cmml" xref="S2.p11.2.m2.2.2.2"><csymbol cd="ambiguous" id="S2.p11.2.m2.2.2.2.3.cmml" xref="S2.p11.2.m2.2.2.2">superscript</csymbol><interval closure="open" id="S2.p11.2.m2.2.2.2.2.3.cmml" xref="S2.p11.2.m2.2.2.2.2.2"><apply id="S2.p11.2.m2.1.1.1.1.1.1.cmml" xref="S2.p11.2.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p11.2.m2.1.1.1.1.1.1.1.cmml" xref="S2.p11.2.m2.1.1.1.1.1.1">superscript</csymbol><apply id="S2.p11.2.m2.1.1.1.1.1.1.2.cmml" xref="S2.p11.2.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p11.2.m2.1.1.1.1.1.1.2.1.cmml" xref="S2.p11.2.m2.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p11.2.m2.1.1.1.1.1.1.2.2.cmml" xref="S2.p11.2.m2.1.1.1.1.1.1.2.2">𝐲</ci><cn type="integer" id="S2.p11.2.m2.1.1.1.1.1.1.2.3.cmml" xref="S2.p11.2.m2.1.1.1.1.1.1.2.3">1</cn></apply><ci id="S2.p11.2.m2.1.1.1.1.1.1.3.cmml" xref="S2.p11.2.m2.1.1.1.1.1.1.3">𝖳</ci></apply><apply id="S2.p11.2.m2.2.2.2.2.2.2.cmml" xref="S2.p11.2.m2.2.2.2.2.2.2"><times id="S2.p11.2.m2.2.2.2.2.2.2.1.cmml" xref="S2.p11.2.m2.2.2.2.2.2.2.1"></times><ci id="S2.p11.2.m2.2.2.2.2.2.2.2.cmml" xref="S2.p11.2.m2.2.2.2.2.2.2.2">⋯</ci><apply id="S2.p11.2.m2.2.2.2.2.2.2.3.cmml" xref="S2.p11.2.m2.2.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.p11.2.m2.2.2.2.2.2.2.3.1.cmml" xref="S2.p11.2.m2.2.2.2.2.2.2.3">superscript</csymbol><apply id="S2.p11.2.m2.2.2.2.2.2.2.3.2.cmml" xref="S2.p11.2.m2.2.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.p11.2.m2.2.2.2.2.2.2.3.2.1.cmml" xref="S2.p11.2.m2.2.2.2.2.2.2.3">subscript</csymbol><ci id="S2.p11.2.m2.2.2.2.2.2.2.3.2.2.cmml" xref="S2.p11.2.m2.2.2.2.2.2.2.3.2.2">𝐲</ci><ci id="S2.p11.2.m2.2.2.2.2.2.2.3.2.3.cmml" xref="S2.p11.2.m2.2.2.2.2.2.2.3.2.3">𝐾</ci></apply><ci id="S2.p11.2.m2.2.2.2.2.2.2.3.3.cmml" xref="S2.p11.2.m2.2.2.2.2.2.2.3.3">𝖳</ci></apply></apply></interval><ci id="S2.p11.2.m2.2.2.2.4.cmml" xref="S2.p11.2.m2.2.2.2.4">𝖳</ci></apply></apply><apply id="S2.p11.2.m2.2.2c.cmml" xref="S2.p11.2.m2.2.2"><in id="S2.p11.2.m2.2.2.6.cmml" xref="S2.p11.2.m2.2.2.6"></in><share href="#S2.p11.2.m2.2.2.2.cmml" id="S2.p11.2.m2.2.2d.cmml" xref="S2.p11.2.m2.2.2"></share><apply id="S2.p11.2.m2.2.2.7.cmml" xref="S2.p11.2.m2.2.2.7"><csymbol cd="ambiguous" id="S2.p11.2.m2.2.2.7.1.cmml" xref="S2.p11.2.m2.2.2.7">superscript</csymbol><ci id="S2.p11.2.m2.2.2.7.2.cmml" xref="S2.p11.2.m2.2.2.7.2">ℝ</ci><apply id="S2.p11.2.m2.2.2.7.3.cmml" xref="S2.p11.2.m2.2.2.7.3"><times id="S2.p11.2.m2.2.2.7.3.1.cmml" xref="S2.p11.2.m2.2.2.7.3.1"></times><ci id="S2.p11.2.m2.2.2.7.3.2.cmml" xref="S2.p11.2.m2.2.2.7.3.2">𝑀</ci><ci id="S2.p11.2.m2.2.2.7.3.3.cmml" xref="S2.p11.2.m2.2.2.7.3.3">𝐾</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p11.2.m2.2c">\mathbf{\hat{y}}=(\mathbf{y}_{1}^{\mathsf{T}},\cdots\mathbf{y}_{K}^{\mathsf{T}})^{\mathsf{T}}\in\mathbb{R}^{MK}</annotation></semantics></math> and the output <math id="S2.p11.3.m3.1" class="ltx_Math" alttext="\mathbf{z}=g(\mathbf{\hat{y}})" display="inline"><semantics id="S2.p11.3.m3.1a"><mrow id="S2.p11.3.m3.1.2" xref="S2.p11.3.m3.1.2.cmml"><mi id="S2.p11.3.m3.1.2.2" xref="S2.p11.3.m3.1.2.2.cmml">𝐳</mi><mo id="S2.p11.3.m3.1.2.1" xref="S2.p11.3.m3.1.2.1.cmml">=</mo><mrow id="S2.p11.3.m3.1.2.3" xref="S2.p11.3.m3.1.2.3.cmml"><mi id="S2.p11.3.m3.1.2.3.2" xref="S2.p11.3.m3.1.2.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.p11.3.m3.1.2.3.1" xref="S2.p11.3.m3.1.2.3.1.cmml">​</mo><mrow id="S2.p11.3.m3.1.2.3.3.2" xref="S2.p11.3.m3.1.1.cmml"><mo stretchy="false" id="S2.p11.3.m3.1.2.3.3.2.1" xref="S2.p11.3.m3.1.1.cmml">(</mo><mover accent="true" id="S2.p11.3.m3.1.1" xref="S2.p11.3.m3.1.1.cmml"><mi id="S2.p11.3.m3.1.1.2" xref="S2.p11.3.m3.1.1.2.cmml">𝐲</mi><mo id="S2.p11.3.m3.1.1.1" xref="S2.p11.3.m3.1.1.1.cmml">^</mo></mover><mo stretchy="false" id="S2.p11.3.m3.1.2.3.3.2.2" xref="S2.p11.3.m3.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p11.3.m3.1b"><apply id="S2.p11.3.m3.1.2.cmml" xref="S2.p11.3.m3.1.2"><eq id="S2.p11.3.m3.1.2.1.cmml" xref="S2.p11.3.m3.1.2.1"></eq><ci id="S2.p11.3.m3.1.2.2.cmml" xref="S2.p11.3.m3.1.2.2">𝐳</ci><apply id="S2.p11.3.m3.1.2.3.cmml" xref="S2.p11.3.m3.1.2.3"><times id="S2.p11.3.m3.1.2.3.1.cmml" xref="S2.p11.3.m3.1.2.3.1"></times><ci id="S2.p11.3.m3.1.2.3.2.cmml" xref="S2.p11.3.m3.1.2.3.2">𝑔</ci><apply id="S2.p11.3.m3.1.1.cmml" xref="S2.p11.3.m3.1.2.3.3.2"><ci id="S2.p11.3.m3.1.1.1.cmml" xref="S2.p11.3.m3.1.1.1">^</ci><ci id="S2.p11.3.m3.1.1.2.cmml" xref="S2.p11.3.m3.1.1.2">𝐲</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p11.3.m3.1c">\mathbf{z}=g(\mathbf{\hat{y}})</annotation></semantics></math> is of <math id="S2.p11.4.m4.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.p11.4.m4.1a"><mi id="S2.p11.4.m4.1.1" xref="S2.p11.4.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.p11.4.m4.1b"><ci id="S2.p11.4.m4.1.1.cmml" xref="S2.p11.4.m4.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p11.4.m4.1c">N</annotation></semantics></math> dimensions. Since <math id="S2.p11.5.m5.1" class="ltx_Math" alttext="\mathbf{z}" display="inline"><semantics id="S2.p11.5.m5.1a"><mi id="S2.p11.5.m5.1.1" xref="S2.p11.5.m5.1.1.cmml">𝐳</mi><annotation-xml encoding="MathML-Content" id="S2.p11.5.m5.1b"><ci id="S2.p11.5.m5.1.1.cmml" xref="S2.p11.5.m5.1.1">𝐳</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p11.5.m5.1c">\mathbf{z}</annotation></semantics></math> is used to approximate the aggregation, <math id="S2.p11.6.m6.3" class="ltx_Math" alttext="a(\mathbf{x}_{1},\mathbf{x}_{2},\cdots\mathbf{x}_{K})" display="inline"><semantics id="S2.p11.6.m6.3a"><mrow id="S2.p11.6.m6.3.3" xref="S2.p11.6.m6.3.3.cmml"><mi id="S2.p11.6.m6.3.3.5" xref="S2.p11.6.m6.3.3.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.p11.6.m6.3.3.4" xref="S2.p11.6.m6.3.3.4.cmml">​</mo><mrow id="S2.p11.6.m6.3.3.3.3" xref="S2.p11.6.m6.3.3.3.4.cmml"><mo stretchy="false" id="S2.p11.6.m6.3.3.3.3.4" xref="S2.p11.6.m6.3.3.3.4.cmml">(</mo><msub id="S2.p11.6.m6.1.1.1.1.1" xref="S2.p11.6.m6.1.1.1.1.1.cmml"><mi id="S2.p11.6.m6.1.1.1.1.1.2" xref="S2.p11.6.m6.1.1.1.1.1.2.cmml">𝐱</mi><mn id="S2.p11.6.m6.1.1.1.1.1.3" xref="S2.p11.6.m6.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.p11.6.m6.3.3.3.3.5" xref="S2.p11.6.m6.3.3.3.4.cmml">,</mo><msub id="S2.p11.6.m6.2.2.2.2.2" xref="S2.p11.6.m6.2.2.2.2.2.cmml"><mi id="S2.p11.6.m6.2.2.2.2.2.2" xref="S2.p11.6.m6.2.2.2.2.2.2.cmml">𝐱</mi><mn id="S2.p11.6.m6.2.2.2.2.2.3" xref="S2.p11.6.m6.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S2.p11.6.m6.3.3.3.3.6" xref="S2.p11.6.m6.3.3.3.4.cmml">,</mo><mrow id="S2.p11.6.m6.3.3.3.3.3" xref="S2.p11.6.m6.3.3.3.3.3.cmml"><mi mathvariant="normal" id="S2.p11.6.m6.3.3.3.3.3.2" xref="S2.p11.6.m6.3.3.3.3.3.2.cmml">⋯</mi><mo lspace="0em" rspace="0em" id="S2.p11.6.m6.3.3.3.3.3.1" xref="S2.p11.6.m6.3.3.3.3.3.1.cmml">​</mo><msub id="S2.p11.6.m6.3.3.3.3.3.3" xref="S2.p11.6.m6.3.3.3.3.3.3.cmml"><mi id="S2.p11.6.m6.3.3.3.3.3.3.2" xref="S2.p11.6.m6.3.3.3.3.3.3.2.cmml">𝐱</mi><mi id="S2.p11.6.m6.3.3.3.3.3.3.3" xref="S2.p11.6.m6.3.3.3.3.3.3.3.cmml">K</mi></msub></mrow><mo stretchy="false" id="S2.p11.6.m6.3.3.3.3.7" xref="S2.p11.6.m6.3.3.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p11.6.m6.3b"><apply id="S2.p11.6.m6.3.3.cmml" xref="S2.p11.6.m6.3.3"><times id="S2.p11.6.m6.3.3.4.cmml" xref="S2.p11.6.m6.3.3.4"></times><ci id="S2.p11.6.m6.3.3.5.cmml" xref="S2.p11.6.m6.3.3.5">𝑎</ci><vector id="S2.p11.6.m6.3.3.3.4.cmml" xref="S2.p11.6.m6.3.3.3.3"><apply id="S2.p11.6.m6.1.1.1.1.1.cmml" xref="S2.p11.6.m6.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p11.6.m6.1.1.1.1.1.1.cmml" xref="S2.p11.6.m6.1.1.1.1.1">subscript</csymbol><ci id="S2.p11.6.m6.1.1.1.1.1.2.cmml" xref="S2.p11.6.m6.1.1.1.1.1.2">𝐱</ci><cn type="integer" id="S2.p11.6.m6.1.1.1.1.1.3.cmml" xref="S2.p11.6.m6.1.1.1.1.1.3">1</cn></apply><apply id="S2.p11.6.m6.2.2.2.2.2.cmml" xref="S2.p11.6.m6.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.p11.6.m6.2.2.2.2.2.1.cmml" xref="S2.p11.6.m6.2.2.2.2.2">subscript</csymbol><ci id="S2.p11.6.m6.2.2.2.2.2.2.cmml" xref="S2.p11.6.m6.2.2.2.2.2.2">𝐱</ci><cn type="integer" id="S2.p11.6.m6.2.2.2.2.2.3.cmml" xref="S2.p11.6.m6.2.2.2.2.2.3">2</cn></apply><apply id="S2.p11.6.m6.3.3.3.3.3.cmml" xref="S2.p11.6.m6.3.3.3.3.3"><times id="S2.p11.6.m6.3.3.3.3.3.1.cmml" xref="S2.p11.6.m6.3.3.3.3.3.1"></times><ci id="S2.p11.6.m6.3.3.3.3.3.2.cmml" xref="S2.p11.6.m6.3.3.3.3.3.2">⋯</ci><apply id="S2.p11.6.m6.3.3.3.3.3.3.cmml" xref="S2.p11.6.m6.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S2.p11.6.m6.3.3.3.3.3.3.1.cmml" xref="S2.p11.6.m6.3.3.3.3.3.3">subscript</csymbol><ci id="S2.p11.6.m6.3.3.3.3.3.3.2.cmml" xref="S2.p11.6.m6.3.3.3.3.3.3.2">𝐱</ci><ci id="S2.p11.6.m6.3.3.3.3.3.3.3.cmml" xref="S2.p11.6.m6.3.3.3.3.3.3.3">𝐾</ci></apply></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p11.6.m6.3c">a(\mathbf{x}_{1},\mathbf{x}_{2},\cdots\mathbf{x}_{K})</annotation></semantics></math>, of the input data <math id="S2.p11.7.m7.1" class="ltx_Math" alttext="\mathbf{x}_{i}" display="inline"><semantics id="S2.p11.7.m7.1a"><msub id="S2.p11.7.m7.1.1" xref="S2.p11.7.m7.1.1.cmml"><mi id="S2.p11.7.m7.1.1.2" xref="S2.p11.7.m7.1.1.2.cmml">𝐱</mi><mi id="S2.p11.7.m7.1.1.3" xref="S2.p11.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p11.7.m7.1b"><apply id="S2.p11.7.m7.1.1.cmml" xref="S2.p11.7.m7.1.1"><csymbol cd="ambiguous" id="S2.p11.7.m7.1.1.1.cmml" xref="S2.p11.7.m7.1.1">subscript</csymbol><ci id="S2.p11.7.m7.1.1.2.cmml" xref="S2.p11.7.m7.1.1.2">𝐱</ci><ci id="S2.p11.7.m7.1.1.3.cmml" xref="S2.p11.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p11.7.m7.1c">\mathbf{x}_{i}</annotation></semantics></math>, we adopt the Euclidean loss as the loss function in this network to describe the approximation. Assuming that the aggregation operation utilizes the averaging method, i.e., <math id="S2.p11.8.m8.3" class="ltx_Math" alttext="a(\mathbf{x}_{1},\mathbf{x}_{2},\cdots\mathbf{x}_{K})=\frac{1}{K}\sum_{i=1}^{K}{\mathbf{x}_{i}}" display="inline"><semantics id="S2.p11.8.m8.3a"><mrow id="S2.p11.8.m8.3.3" xref="S2.p11.8.m8.3.3.cmml"><mrow id="S2.p11.8.m8.3.3.3" xref="S2.p11.8.m8.3.3.3.cmml"><mi id="S2.p11.8.m8.3.3.3.5" xref="S2.p11.8.m8.3.3.3.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.p11.8.m8.3.3.3.4" xref="S2.p11.8.m8.3.3.3.4.cmml">​</mo><mrow id="S2.p11.8.m8.3.3.3.3.3" xref="S2.p11.8.m8.3.3.3.3.4.cmml"><mo stretchy="false" id="S2.p11.8.m8.3.3.3.3.3.4" xref="S2.p11.8.m8.3.3.3.3.4.cmml">(</mo><msub id="S2.p11.8.m8.1.1.1.1.1.1" xref="S2.p11.8.m8.1.1.1.1.1.1.cmml"><mi id="S2.p11.8.m8.1.1.1.1.1.1.2" xref="S2.p11.8.m8.1.1.1.1.1.1.2.cmml">𝐱</mi><mn id="S2.p11.8.m8.1.1.1.1.1.1.3" xref="S2.p11.8.m8.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.p11.8.m8.3.3.3.3.3.5" xref="S2.p11.8.m8.3.3.3.3.4.cmml">,</mo><msub id="S2.p11.8.m8.2.2.2.2.2.2" xref="S2.p11.8.m8.2.2.2.2.2.2.cmml"><mi id="S2.p11.8.m8.2.2.2.2.2.2.2" xref="S2.p11.8.m8.2.2.2.2.2.2.2.cmml">𝐱</mi><mn id="S2.p11.8.m8.2.2.2.2.2.2.3" xref="S2.p11.8.m8.2.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S2.p11.8.m8.3.3.3.3.3.6" xref="S2.p11.8.m8.3.3.3.3.4.cmml">,</mo><mrow id="S2.p11.8.m8.3.3.3.3.3.3" xref="S2.p11.8.m8.3.3.3.3.3.3.cmml"><mi mathvariant="normal" id="S2.p11.8.m8.3.3.3.3.3.3.2" xref="S2.p11.8.m8.3.3.3.3.3.3.2.cmml">⋯</mi><mo lspace="0em" rspace="0em" id="S2.p11.8.m8.3.3.3.3.3.3.1" xref="S2.p11.8.m8.3.3.3.3.3.3.1.cmml">​</mo><msub id="S2.p11.8.m8.3.3.3.3.3.3.3" xref="S2.p11.8.m8.3.3.3.3.3.3.3.cmml"><mi id="S2.p11.8.m8.3.3.3.3.3.3.3.2" xref="S2.p11.8.m8.3.3.3.3.3.3.3.2.cmml">𝐱</mi><mi id="S2.p11.8.m8.3.3.3.3.3.3.3.3" xref="S2.p11.8.m8.3.3.3.3.3.3.3.3.cmml">K</mi></msub></mrow><mo stretchy="false" id="S2.p11.8.m8.3.3.3.3.3.7" xref="S2.p11.8.m8.3.3.3.3.4.cmml">)</mo></mrow></mrow><mo id="S2.p11.8.m8.3.3.4" xref="S2.p11.8.m8.3.3.4.cmml">=</mo><mrow id="S2.p11.8.m8.3.3.5" xref="S2.p11.8.m8.3.3.5.cmml"><mfrac id="S2.p11.8.m8.3.3.5.2" xref="S2.p11.8.m8.3.3.5.2.cmml"><mn id="S2.p11.8.m8.3.3.5.2.2" xref="S2.p11.8.m8.3.3.5.2.2.cmml">1</mn><mi id="S2.p11.8.m8.3.3.5.2.3" xref="S2.p11.8.m8.3.3.5.2.3.cmml">K</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.p11.8.m8.3.3.5.1" xref="S2.p11.8.m8.3.3.5.1.cmml">​</mo><mrow id="S2.p11.8.m8.3.3.5.3" xref="S2.p11.8.m8.3.3.5.3.cmml"><msubsup id="S2.p11.8.m8.3.3.5.3.1" xref="S2.p11.8.m8.3.3.5.3.1.cmml"><mo id="S2.p11.8.m8.3.3.5.3.1.2.2" xref="S2.p11.8.m8.3.3.5.3.1.2.2.cmml">∑</mo><mrow id="S2.p11.8.m8.3.3.5.3.1.2.3" xref="S2.p11.8.m8.3.3.5.3.1.2.3.cmml"><mi id="S2.p11.8.m8.3.3.5.3.1.2.3.2" xref="S2.p11.8.m8.3.3.5.3.1.2.3.2.cmml">i</mi><mo id="S2.p11.8.m8.3.3.5.3.1.2.3.1" xref="S2.p11.8.m8.3.3.5.3.1.2.3.1.cmml">=</mo><mn id="S2.p11.8.m8.3.3.5.3.1.2.3.3" xref="S2.p11.8.m8.3.3.5.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.p11.8.m8.3.3.5.3.1.3" xref="S2.p11.8.m8.3.3.5.3.1.3.cmml">K</mi></msubsup><msub id="S2.p11.8.m8.3.3.5.3.2" xref="S2.p11.8.m8.3.3.5.3.2.cmml"><mi id="S2.p11.8.m8.3.3.5.3.2.2" xref="S2.p11.8.m8.3.3.5.3.2.2.cmml">𝐱</mi><mi id="S2.p11.8.m8.3.3.5.3.2.3" xref="S2.p11.8.m8.3.3.5.3.2.3.cmml">i</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p11.8.m8.3b"><apply id="S2.p11.8.m8.3.3.cmml" xref="S2.p11.8.m8.3.3"><eq id="S2.p11.8.m8.3.3.4.cmml" xref="S2.p11.8.m8.3.3.4"></eq><apply id="S2.p11.8.m8.3.3.3.cmml" xref="S2.p11.8.m8.3.3.3"><times id="S2.p11.8.m8.3.3.3.4.cmml" xref="S2.p11.8.m8.3.3.3.4"></times><ci id="S2.p11.8.m8.3.3.3.5.cmml" xref="S2.p11.8.m8.3.3.3.5">𝑎</ci><vector id="S2.p11.8.m8.3.3.3.3.4.cmml" xref="S2.p11.8.m8.3.3.3.3.3"><apply id="S2.p11.8.m8.1.1.1.1.1.1.cmml" xref="S2.p11.8.m8.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p11.8.m8.1.1.1.1.1.1.1.cmml" xref="S2.p11.8.m8.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p11.8.m8.1.1.1.1.1.1.2.cmml" xref="S2.p11.8.m8.1.1.1.1.1.1.2">𝐱</ci><cn type="integer" id="S2.p11.8.m8.1.1.1.1.1.1.3.cmml" xref="S2.p11.8.m8.1.1.1.1.1.1.3">1</cn></apply><apply id="S2.p11.8.m8.2.2.2.2.2.2.cmml" xref="S2.p11.8.m8.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.p11.8.m8.2.2.2.2.2.2.1.cmml" xref="S2.p11.8.m8.2.2.2.2.2.2">subscript</csymbol><ci id="S2.p11.8.m8.2.2.2.2.2.2.2.cmml" xref="S2.p11.8.m8.2.2.2.2.2.2.2">𝐱</ci><cn type="integer" id="S2.p11.8.m8.2.2.2.2.2.2.3.cmml" xref="S2.p11.8.m8.2.2.2.2.2.2.3">2</cn></apply><apply id="S2.p11.8.m8.3.3.3.3.3.3.cmml" xref="S2.p11.8.m8.3.3.3.3.3.3"><times id="S2.p11.8.m8.3.3.3.3.3.3.1.cmml" xref="S2.p11.8.m8.3.3.3.3.3.3.1"></times><ci id="S2.p11.8.m8.3.3.3.3.3.3.2.cmml" xref="S2.p11.8.m8.3.3.3.3.3.3.2">⋯</ci><apply id="S2.p11.8.m8.3.3.3.3.3.3.3.cmml" xref="S2.p11.8.m8.3.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S2.p11.8.m8.3.3.3.3.3.3.3.1.cmml" xref="S2.p11.8.m8.3.3.3.3.3.3.3">subscript</csymbol><ci id="S2.p11.8.m8.3.3.3.3.3.3.3.2.cmml" xref="S2.p11.8.m8.3.3.3.3.3.3.3.2">𝐱</ci><ci id="S2.p11.8.m8.3.3.3.3.3.3.3.3.cmml" xref="S2.p11.8.m8.3.3.3.3.3.3.3.3">𝐾</ci></apply></apply></vector></apply><apply id="S2.p11.8.m8.3.3.5.cmml" xref="S2.p11.8.m8.3.3.5"><times id="S2.p11.8.m8.3.3.5.1.cmml" xref="S2.p11.8.m8.3.3.5.1"></times><apply id="S2.p11.8.m8.3.3.5.2.cmml" xref="S2.p11.8.m8.3.3.5.2"><divide id="S2.p11.8.m8.3.3.5.2.1.cmml" xref="S2.p11.8.m8.3.3.5.2"></divide><cn type="integer" id="S2.p11.8.m8.3.3.5.2.2.cmml" xref="S2.p11.8.m8.3.3.5.2.2">1</cn><ci id="S2.p11.8.m8.3.3.5.2.3.cmml" xref="S2.p11.8.m8.3.3.5.2.3">𝐾</ci></apply><apply id="S2.p11.8.m8.3.3.5.3.cmml" xref="S2.p11.8.m8.3.3.5.3"><apply id="S2.p11.8.m8.3.3.5.3.1.cmml" xref="S2.p11.8.m8.3.3.5.3.1"><csymbol cd="ambiguous" id="S2.p11.8.m8.3.3.5.3.1.1.cmml" xref="S2.p11.8.m8.3.3.5.3.1">superscript</csymbol><apply id="S2.p11.8.m8.3.3.5.3.1.2.cmml" xref="S2.p11.8.m8.3.3.5.3.1"><csymbol cd="ambiguous" id="S2.p11.8.m8.3.3.5.3.1.2.1.cmml" xref="S2.p11.8.m8.3.3.5.3.1">subscript</csymbol><sum id="S2.p11.8.m8.3.3.5.3.1.2.2.cmml" xref="S2.p11.8.m8.3.3.5.3.1.2.2"></sum><apply id="S2.p11.8.m8.3.3.5.3.1.2.3.cmml" xref="S2.p11.8.m8.3.3.5.3.1.2.3"><eq id="S2.p11.8.m8.3.3.5.3.1.2.3.1.cmml" xref="S2.p11.8.m8.3.3.5.3.1.2.3.1"></eq><ci id="S2.p11.8.m8.3.3.5.3.1.2.3.2.cmml" xref="S2.p11.8.m8.3.3.5.3.1.2.3.2">𝑖</ci><cn type="integer" id="S2.p11.8.m8.3.3.5.3.1.2.3.3.cmml" xref="S2.p11.8.m8.3.3.5.3.1.2.3.3">1</cn></apply></apply><ci id="S2.p11.8.m8.3.3.5.3.1.3.cmml" xref="S2.p11.8.m8.3.3.5.3.1.3">𝐾</ci></apply><apply id="S2.p11.8.m8.3.3.5.3.2.cmml" xref="S2.p11.8.m8.3.3.5.3.2"><csymbol cd="ambiguous" id="S2.p11.8.m8.3.3.5.3.2.1.cmml" xref="S2.p11.8.m8.3.3.5.3.2">subscript</csymbol><ci id="S2.p11.8.m8.3.3.5.3.2.2.cmml" xref="S2.p11.8.m8.3.3.5.3.2.2">𝐱</ci><ci id="S2.p11.8.m8.3.3.5.3.2.3.cmml" xref="S2.p11.8.m8.3.3.5.3.2.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p11.8.m8.3c">a(\mathbf{x}_{1},\mathbf{x}_{2},\cdots\mathbf{x}_{K})=\frac{1}{K}\sum_{i=1}^{K}{\mathbf{x}_{i}}</annotation></semantics></math>, the loss <math id="S2.p11.9.m9.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S2.p11.9.m9.1a"><mi id="S2.p11.9.m9.1.1" xref="S2.p11.9.m9.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.p11.9.m9.1b"><ci id="S2.p11.9.m9.1.1.cmml" xref="S2.p11.9.m9.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p11.9.m9.1c">L</annotation></semantics></math> can be defined as follows,</p>
<table id="S2.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex1.m1.3" class="ltx_Math" alttext="L(\mathbf{x})=\|g(\mathbf{\hat{y}})-\frac{1}{K}\sum_{i=1}^{K}{\mathbf{x}_{i}}\|^{2}_{,}" display="block"><semantics id="S2.Ex1.m1.3a"><mrow id="S2.Ex1.m1.3.3" xref="S2.Ex1.m1.3.3.cmml"><mrow id="S2.Ex1.m1.3.3.3" xref="S2.Ex1.m1.3.3.3.cmml"><mi id="S2.Ex1.m1.3.3.3.2" xref="S2.Ex1.m1.3.3.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.3.3.3.1" xref="S2.Ex1.m1.3.3.3.1.cmml">​</mo><mrow id="S2.Ex1.m1.3.3.3.3.2" xref="S2.Ex1.m1.3.3.3.cmml"><mo stretchy="false" id="S2.Ex1.m1.3.3.3.3.2.1" xref="S2.Ex1.m1.3.3.3.cmml">(</mo><mi id="S2.Ex1.m1.1.1" xref="S2.Ex1.m1.1.1.cmml">𝐱</mi><mo stretchy="false" id="S2.Ex1.m1.3.3.3.3.2.2" xref="S2.Ex1.m1.3.3.3.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.3.3.2" xref="S2.Ex1.m1.3.3.2.cmml">=</mo><msubsup id="S2.Ex1.m1.3.3.1" xref="S2.Ex1.m1.3.3.1.cmml"><mrow id="S2.Ex1.m1.3.3.1.1.1.1" xref="S2.Ex1.m1.3.3.1.1.1.2.cmml"><mo stretchy="false" id="S2.Ex1.m1.3.3.1.1.1.1.2" xref="S2.Ex1.m1.3.3.1.1.1.2.1.cmml">‖</mo><mrow id="S2.Ex1.m1.3.3.1.1.1.1.1" xref="S2.Ex1.m1.3.3.1.1.1.1.1.cmml"><mrow id="S2.Ex1.m1.3.3.1.1.1.1.1.2" xref="S2.Ex1.m1.3.3.1.1.1.1.1.2.cmml"><mi id="S2.Ex1.m1.3.3.1.1.1.1.1.2.2" xref="S2.Ex1.m1.3.3.1.1.1.1.1.2.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.3.3.1.1.1.1.1.2.1" xref="S2.Ex1.m1.3.3.1.1.1.1.1.2.1.cmml">​</mo><mrow id="S2.Ex1.m1.3.3.1.1.1.1.1.2.3.2" xref="S2.Ex1.m1.2.2.cmml"><mo stretchy="false" id="S2.Ex1.m1.3.3.1.1.1.1.1.2.3.2.1" xref="S2.Ex1.m1.2.2.cmml">(</mo><mover accent="true" id="S2.Ex1.m1.2.2" xref="S2.Ex1.m1.2.2.cmml"><mi id="S2.Ex1.m1.2.2.2" xref="S2.Ex1.m1.2.2.2.cmml">𝐲</mi><mo id="S2.Ex1.m1.2.2.1" xref="S2.Ex1.m1.2.2.1.cmml">^</mo></mover><mo stretchy="false" id="S2.Ex1.m1.3.3.1.1.1.1.1.2.3.2.2" xref="S2.Ex1.m1.2.2.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.3.3.1.1.1.1.1.1" xref="S2.Ex1.m1.3.3.1.1.1.1.1.1.cmml">−</mo><mrow id="S2.Ex1.m1.3.3.1.1.1.1.1.3" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.cmml"><mfrac id="S2.Ex1.m1.3.3.1.1.1.1.1.3.2" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.2.cmml"><mn id="S2.Ex1.m1.3.3.1.1.1.1.1.3.2.2" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.2.2.cmml">1</mn><mi id="S2.Ex1.m1.3.3.1.1.1.1.1.3.2.3" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.2.3.cmml">K</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.3.3.1.1.1.1.1.3.1" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.1.cmml">​</mo><mrow id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.cmml"><munderover id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.cmml"><mo movablelimits="false" id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.2" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.2.cmml">∑</mo><mrow id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.3" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.3.cmml"><mi id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.3.2" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.3.2.cmml">i</mi><mo id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.3.1" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.3.1.cmml">=</mo><mn id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.3.3" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.3" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.3.cmml">K</mi></munderover><msub id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.2" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.2.cmml"><mi id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.2.2" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.2.2.cmml">𝐱</mi><mi id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.2.3" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.2.3.cmml">i</mi></msub></mrow></mrow></mrow><mo stretchy="false" id="S2.Ex1.m1.3.3.1.1.1.1.3" xref="S2.Ex1.m1.3.3.1.1.1.2.1.cmml">‖</mo></mrow><mo id="S2.Ex1.m1.3.3.1.3" xref="S2.Ex1.m1.3.3.1.3.cmml">,</mo><mn id="S2.Ex1.m1.3.3.1.1.3" xref="S2.Ex1.m1.3.3.1.1.3.cmml">2</mn></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.3b"><apply id="S2.Ex1.m1.3.3.cmml" xref="S2.Ex1.m1.3.3"><eq id="S2.Ex1.m1.3.3.2.cmml" xref="S2.Ex1.m1.3.3.2"></eq><apply id="S2.Ex1.m1.3.3.3.cmml" xref="S2.Ex1.m1.3.3.3"><times id="S2.Ex1.m1.3.3.3.1.cmml" xref="S2.Ex1.m1.3.3.3.1"></times><ci id="S2.Ex1.m1.3.3.3.2.cmml" xref="S2.Ex1.m1.3.3.3.2">𝐿</ci><ci id="S2.Ex1.m1.1.1.cmml" xref="S2.Ex1.m1.1.1">𝐱</ci></apply><apply id="S2.Ex1.m1.3.3.1.cmml" xref="S2.Ex1.m1.3.3.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.3.3.1.2.cmml" xref="S2.Ex1.m1.3.3.1">subscript</csymbol><apply id="S2.Ex1.m1.3.3.1.1.cmml" xref="S2.Ex1.m1.3.3.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.3.3.1.1.2.cmml" xref="S2.Ex1.m1.3.3.1">superscript</csymbol><apply id="S2.Ex1.m1.3.3.1.1.1.2.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1"><csymbol cd="latexml" id="S2.Ex1.m1.3.3.1.1.1.2.1.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.2">norm</csymbol><apply id="S2.Ex1.m1.3.3.1.1.1.1.1.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1"><minus id="S2.Ex1.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.1"></minus><apply id="S2.Ex1.m1.3.3.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.2"><times id="S2.Ex1.m1.3.3.1.1.1.1.1.2.1.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.2.1"></times><ci id="S2.Ex1.m1.3.3.1.1.1.1.1.2.2.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.2.2">𝑔</ci><apply id="S2.Ex1.m1.2.2.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.2.3.2"><ci id="S2.Ex1.m1.2.2.1.cmml" xref="S2.Ex1.m1.2.2.1">^</ci><ci id="S2.Ex1.m1.2.2.2.cmml" xref="S2.Ex1.m1.2.2.2">𝐲</ci></apply></apply><apply id="S2.Ex1.m1.3.3.1.1.1.1.1.3.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3"><times id="S2.Ex1.m1.3.3.1.1.1.1.1.3.1.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.1"></times><apply id="S2.Ex1.m1.3.3.1.1.1.1.1.3.2.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.2"><divide id="S2.Ex1.m1.3.3.1.1.1.1.1.3.2.1.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.2"></divide><cn type="integer" id="S2.Ex1.m1.3.3.1.1.1.1.1.3.2.2.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.2.2">1</cn><ci id="S2.Ex1.m1.3.3.1.1.1.1.1.3.2.3.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.2.3">𝐾</ci></apply><apply id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3"><apply id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.1.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1">superscript</csymbol><apply id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.1.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1">subscript</csymbol><sum id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.2.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.2"></sum><apply id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.3.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.3"><eq id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.3.1.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.3.1"></eq><ci id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.3.2.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.3.2">𝑖</ci><cn type="integer" id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.3.3.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.2.3.3">1</cn></apply></apply><ci id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.3.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.1.3">𝐾</ci></apply><apply id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.2.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.2.1.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.2">subscript</csymbol><ci id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.2.2.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.2.2">𝐱</ci><ci id="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.2.3.cmml" xref="S2.Ex1.m1.3.3.1.1.1.1.1.3.3.2.3">𝑖</ci></apply></apply></apply></apply></apply><cn type="integer" id="S2.Ex1.m1.3.3.1.1.3.cmml" xref="S2.Ex1.m1.3.3.1.1.3">2</cn></apply><ci id="S2.Ex1.m1.3.3.1.3.cmml" xref="S2.Ex1.m1.3.3.1.3">,</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.3c">L(\mathbf{x})=\|g(\mathbf{\hat{y}})-\frac{1}{K}\sum_{i=1}^{K}{\mathbf{x}_{i}}\|^{2}_{,}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<table id="S2.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex2.m1.2" class="ltx_math_unparsed" alttext="s.t.,\ \mathbf{\hat{y}}=(f(\mathbf{x}_{1})^{\mathsf{T}},f(\mathbf{x}_{2})^{\mathsf{T}}\cdots f(\mathbf{x}_{K})^{\mathsf{T}})^{\mathsf{T}}." display="block"><semantics id="S2.Ex2.m1.2a"><mrow id="S2.Ex2.m1.2b"><mi id="S2.Ex2.m1.1.1">s</mi><mo lspace="0em" rspace="0.167em" id="S2.Ex2.m1.2.3">.</mo><mi id="S2.Ex2.m1.2.2">t</mi><mo lspace="0em" rspace="0.167em" id="S2.Ex2.m1.2.4">.</mo><mo rspace="0.667em" id="S2.Ex2.m1.2.5">,</mo><mover accent="true" id="S2.Ex2.m1.2.6"><mi id="S2.Ex2.m1.2.6.2">𝐲</mi><mo id="S2.Ex2.m1.2.6.1">^</mo></mover><mo id="S2.Ex2.m1.2.7">=</mo><msup id="S2.Ex2.m1.2.8"><mrow id="S2.Ex2.m1.2.8.2"><mo stretchy="false" id="S2.Ex2.m1.2.8.2.1">(</mo><mi id="S2.Ex2.m1.2.8.2.2">f</mi><msup id="S2.Ex2.m1.2.8.2.3"><mrow id="S2.Ex2.m1.2.8.2.3.2"><mo stretchy="false" id="S2.Ex2.m1.2.8.2.3.2.1">(</mo><msub id="S2.Ex2.m1.2.8.2.3.2.2"><mi id="S2.Ex2.m1.2.8.2.3.2.2.2">𝐱</mi><mn id="S2.Ex2.m1.2.8.2.3.2.2.3">1</mn></msub><mo stretchy="false" id="S2.Ex2.m1.2.8.2.3.2.3">)</mo></mrow><mi id="S2.Ex2.m1.2.8.2.3.3">𝖳</mi></msup><mo id="S2.Ex2.m1.2.8.2.4">,</mo><mi id="S2.Ex2.m1.2.8.2.5">f</mi><msup id="S2.Ex2.m1.2.8.2.6"><mrow id="S2.Ex2.m1.2.8.2.6.2"><mo stretchy="false" id="S2.Ex2.m1.2.8.2.6.2.1">(</mo><msub id="S2.Ex2.m1.2.8.2.6.2.2"><mi id="S2.Ex2.m1.2.8.2.6.2.2.2">𝐱</mi><mn id="S2.Ex2.m1.2.8.2.6.2.2.3">2</mn></msub><mo stretchy="false" id="S2.Ex2.m1.2.8.2.6.2.3">)</mo></mrow><mi id="S2.Ex2.m1.2.8.2.6.3">𝖳</mi></msup><mi mathvariant="normal" id="S2.Ex2.m1.2.8.2.7">⋯</mi><mi id="S2.Ex2.m1.2.8.2.8">f</mi><msup id="S2.Ex2.m1.2.8.2.9"><mrow id="S2.Ex2.m1.2.8.2.9.2"><mo stretchy="false" id="S2.Ex2.m1.2.8.2.9.2.1">(</mo><msub id="S2.Ex2.m1.2.8.2.9.2.2"><mi id="S2.Ex2.m1.2.8.2.9.2.2.2">𝐱</mi><mi id="S2.Ex2.m1.2.8.2.9.2.2.3">K</mi></msub><mo stretchy="false" id="S2.Ex2.m1.2.8.2.9.2.3">)</mo></mrow><mi id="S2.Ex2.m1.2.8.2.9.3">𝖳</mi></msup><mo stretchy="false" id="S2.Ex2.m1.2.8.2.10">)</mo></mrow><mi id="S2.Ex2.m1.2.8.3">𝖳</mi></msup><mo lspace="0em" id="S2.Ex2.m1.2.9">.</mo></mrow><annotation encoding="application/x-tex" id="S2.Ex2.m1.2c">s.t.,\ \mathbf{\hat{y}}=(f(\mathbf{x}_{1})^{\mathsf{T}},f(\mathbf{x}_{2})^{\mathsf{T}}\cdots f(\mathbf{x}_{K})^{\mathsf{T}})^{\mathsf{T}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S2.p12" class="ltx_para">
<p id="S2.p12.2" class="ltx_p">To train the proposed network, we generate a set of simulated data <math id="S2.p12.1.m1.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S2.p12.1.m1.1a"><mi id="S2.p12.1.m1.1.1" xref="S2.p12.1.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S2.p12.1.m1.1b"><ci id="S2.p12.1.m1.1.1.cmml" xref="S2.p12.1.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p12.1.m1.1c">\mathbf{x}</annotation></semantics></math> under an assumption of the Gaussian distribution with the mean of 0 and the standard deviation of 0.1. It must be admitted that this assumption is problematic to some extent, since the distribution of gradient updates is uncertain in real applications. Fortunately, for the purpose of federated learning, the trained model will gradually converge to a certain accuracy as long as the training samples are sufficient. But the convergence speed will be slower than the normal federated learning where the ENN is not used. In addition, the model accuracy will probably drop a little due to the lossy compression caused by the encoder.
The Adam optimizer with learning rate <math id="S2.p12.2.m2.1" class="ltx_Math" alttext="2e-4" display="inline"><semantics id="S2.p12.2.m2.1a"><mrow id="S2.p12.2.m2.1.1" xref="S2.p12.2.m2.1.1.cmml"><mrow id="S2.p12.2.m2.1.1.2" xref="S2.p12.2.m2.1.1.2.cmml"><mn id="S2.p12.2.m2.1.1.2.2" xref="S2.p12.2.m2.1.1.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S2.p12.2.m2.1.1.2.1" xref="S2.p12.2.m2.1.1.2.1.cmml">​</mo><mi id="S2.p12.2.m2.1.1.2.3" xref="S2.p12.2.m2.1.1.2.3.cmml">e</mi></mrow><mo id="S2.p12.2.m2.1.1.1" xref="S2.p12.2.m2.1.1.1.cmml">−</mo><mn id="S2.p12.2.m2.1.1.3" xref="S2.p12.2.m2.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p12.2.m2.1b"><apply id="S2.p12.2.m2.1.1.cmml" xref="S2.p12.2.m2.1.1"><minus id="S2.p12.2.m2.1.1.1.cmml" xref="S2.p12.2.m2.1.1.1"></minus><apply id="S2.p12.2.m2.1.1.2.cmml" xref="S2.p12.2.m2.1.1.2"><times id="S2.p12.2.m2.1.1.2.1.cmml" xref="S2.p12.2.m2.1.1.2.1"></times><cn type="integer" id="S2.p12.2.m2.1.1.2.2.cmml" xref="S2.p12.2.m2.1.1.2.2">2</cn><ci id="S2.p12.2.m2.1.1.2.3.cmml" xref="S2.p12.2.m2.1.1.2.3">𝑒</ci></apply><cn type="integer" id="S2.p12.2.m2.1.1.3.cmml" xref="S2.p12.2.m2.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p12.2.m2.1c">2e-4</annotation></semantics></math> is utilized during the ENN training.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Approximation error in MSE with different decoder structures and training schemes, where <math id="S2.T1.4.4.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.T1.4.4.m1.1b"><mi id="S2.T1.4.4.m1.1.1" xref="S2.T1.4.4.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.T1.4.4.m1.1c"><ci id="S2.T1.4.4.m1.1.1.cmml" xref="S2.T1.4.4.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.4.m1.1d">n</annotation></semantics></math> is the number of residual blocks in the decoding sub-network. With <math id="S2.T1.5.5.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.T1.5.5.m2.1b"><mi id="S2.T1.5.5.m2.1.1" xref="S2.T1.5.5.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.T1.5.5.m2.1c"><ci id="S2.T1.5.5.m2.1.1.cmml" xref="S2.T1.5.5.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.5.5.m2.1d">n</annotation></semantics></math> increasing to <math id="S2.T1.6.6.m3.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S2.T1.6.6.m3.1b"><mn id="S2.T1.6.6.m3.1.1" xref="S2.T1.6.6.m3.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S2.T1.6.6.m3.1c"><cn type="integer" id="S2.T1.6.6.m3.1.1.cmml" xref="S2.T1.6.6.m3.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.6.6.m3.1d">3</annotation></semantics></math> in the end-to-end training scheme, the error will not basically change any more.</figcaption>
<table id="S2.T1.7" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T1.7.1.1" class="ltx_tr">
<td id="S2.T1.7.1.1.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td id="S2.T1.7.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S2.T1.7.1.1.2.1" class="ltx_text" style="font-size:80%;">freezing decoder</span></td>
<td id="S2.T1.7.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S2.T1.7.1.1.3.1" class="ltx_text" style="font-size:80%;">freezing encoder</span></td>
<td id="S2.T1.7.1.1.4" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T1.7.1.1.4.1" class="ltx_text" style="font-size:80%;">end-to-end</span></td>
</tr>
<tr id="S2.T1.7.2.2" class="ltx_tr">
<td id="S2.T1.7.2.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S2.T1.7.2.2.1.1" class="ltx_text" style="font-size:80%;">n</span></td>
<td id="S2.T1.7.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S2.T1.7.2.2.2.1" class="ltx_text" style="font-size:80%;">3</span></td>
<td id="S2.T1.7.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S2.T1.7.2.2.3.1" class="ltx_text" style="font-size:80%;">3</span></td>
<td id="S2.T1.7.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S2.T1.7.2.2.4.1" class="ltx_text" style="font-size:80%;">0</span></td>
<td id="S2.T1.7.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S2.T1.7.2.2.5.1" class="ltx_text" style="font-size:80%;">3</span></td>
<td id="S2.T1.7.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S2.T1.7.2.2.6.1" class="ltx_text" style="font-size:80%;">7</span></td>
</tr>
<tr id="S2.T1.7.3.3" class="ltx_tr">
<td id="S2.T1.7.3.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><span id="S2.T1.7.3.3.1.1" class="ltx_text" style="font-size:80%;">MSE</span></td>
<td id="S2.T1.7.3.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S2.T1.7.3.3.2.1" class="ltx_text" style="font-size:80%;">0.0112</span></td>
<td id="S2.T1.7.3.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S2.T1.7.3.3.3.1" class="ltx_text" style="font-size:80%;">0.00232</span></td>
<td id="S2.T1.7.3.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S2.T1.7.3.3.4.1" class="ltx_text" style="font-size:80%;">0.00210</span></td>
<td id="S2.T1.7.3.3.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S2.T1.7.3.3.5.1" class="ltx_text" style="font-size:80%;">0.00166</span></td>
<td id="S2.T1.7.3.3.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S2.T1.7.3.3.6.1" class="ltx_text" style="font-size:80%;">0.00168</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Results</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we conducted two experiments to validate the performance of the proposed network. The first experiment is involved with the approximation ability of the ENN to the true aggregation of input data. In the second test, the model accuracy is analyzed on the MNIST dataset in the ENN-based federated learning framework.</p>
</div>
<div id="S3.p2" class="ltx_para">
<span id="S3.p2.2" class="ltx_ERROR undefined">\SubSection</span>
<p id="S3.p2.1" class="ltx_p">Approximation error
With the generated training data, we estimated the approximation errors under three different training schemes, i) training encoder only while freezing decoder with random weights, ii) training decoder only while freezing encoder with random weights, and iii) end-to-end training. In addition, we also compared three network structures of the decoder in the end-to-end training, where the number <math id="S3.p2.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.p2.1.m1.1a"><mi id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">n</annotation></semantics></math> of residual blocks is respectively 0, 3, and 7.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.2" class="ltx_p">The mean square error (MSE) was used to measure the approximation error. As shown in Table <a href="#S2.T1" title="Table 1 ‣ 2 Encrypted Neural Network ‣ An End-to-End Encrypted Neural Network for Gradient Updates Transmission in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, it is observed that the end-to-end training produced lower approximation errors than solely training either the encoder or decoder. Moderately increasing the depth of the decoding sub-network can decrease the approximation error. However, the MSE becomes stable and will not change any more when the number <math id="S3.p3.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.p3.1.m1.1a"><mi id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><ci id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">n</annotation></semantics></math> is larger than <math id="S3.p3.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.p3.2.m2.1a"><mn id="S3.p3.2.m2.1.1" xref="S3.p3.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.p3.2.m2.1b"><cn type="integer" id="S3.p3.2.m2.1.1.cmml" xref="S3.p3.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.2.m2.1c">3</annotation></semantics></math>. The approximation error mainly stems from the lossy compression during encoding, which also indicates that the aggregation of the input data is hardly to be exactly recovered due to data encryption. Luckily, the main concern in the federated learning is the model accuracy that will not be affected by the slight approximation error.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/1908.08340/assets/x3.png" id="S3.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="385" height="192" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Model accuracy under different compression ratio.</figcaption>
</figure>
<div id="S3.p4" class="ltx_para">
<span id="S3.p4.1" class="ltx_ERROR undefined">\SubSection</span>
<p id="S3.p4.2" class="ltx_p">Accuracy analysis in federated learning</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.3" class="ltx_p">To estimate the ENN-based federated learning framework, we simulated 100 clients connecting with a server and trained a convolutional neural network model for classification on the MNIST dataset with the proposed framework. In each iteration round, 9 clients were randomly picked from all 100 clients to train the model and update the gradients. For simplicity, a small neural network with <math id="S3.p5.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.p5.1.m1.1a"><mn id="S3.p5.1.m1.1.1" xref="S3.p5.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.p5.1.m1.1b"><cn type="integer" id="S3.p5.1.m1.1.1.cmml" xref="S3.p5.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.1.m1.1c">2</annotation></semantics></math> convolutional layers was constructed with total <math id="S3.p5.2.m2.1" class="ltx_Math" alttext="21840" display="inline"><semantics id="S3.p5.2.m2.1a"><mn id="S3.p5.2.m2.1.1" xref="S3.p5.2.m2.1.1.cmml">21840</mn><annotation-xml encoding="MathML-Content" id="S3.p5.2.m2.1b"><cn type="integer" id="S3.p5.2.m2.1.1.cmml" xref="S3.p5.2.m2.1.1">21840</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.2.m2.1c">21840</annotation></semantics></math> weights. The dataset was split into different groups as local data for model training on clients, where each group has only three types of characters. But in the test set, all types of character images were pooled together. In this way of data splitting, gradient updates of each client are indispensable to the aggregated model. For normal federated learning without using the ENN, the model accuracy can be as high as <math id="S3.p5.3.m3.1" class="ltx_Math" alttext="98\%" display="inline"><semantics id="S3.p5.3.m3.1a"><mrow id="S3.p5.3.m3.1.1" xref="S3.p5.3.m3.1.1.cmml"><mn id="S3.p5.3.m3.1.1.2" xref="S3.p5.3.m3.1.1.2.cmml">98</mn><mo id="S3.p5.3.m3.1.1.1" xref="S3.p5.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p5.3.m3.1b"><apply id="S3.p5.3.m3.1.1.cmml" xref="S3.p5.3.m3.1.1"><csymbol cd="latexml" id="S3.p5.3.m3.1.1.1.cmml" xref="S3.p5.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S3.p5.3.m3.1.1.2.cmml" xref="S3.p5.3.m3.1.1.2">98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.3.m3.1c">98\%</annotation></semantics></math> on the test set, which will act as a baseline in this experiment. When the ENN was applied to federated learning, weight updates will be compressed and the private local data on clients are more secure at the cost of sacrificing a little accuracy and training speed.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.10" class="ltx_p">Fig. <a href="#S3.F3" title="Figure 3 ‣ 3 Experimental Results ‣ An End-to-End Encrypted Neural Network for Gradient Updates Transmission in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates the test accuracy under different compression ratio <math id="S3.p6.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.p6.1.m1.1a"><mi id="S3.p6.1.m1.1.1" xref="S3.p6.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.p6.1.m1.1b"><ci id="S3.p6.1.m1.1.1.cmml" xref="S3.p6.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.1.m1.1c">r</annotation></semantics></math>. It is observed that the accuracy at the <math id="S3.p6.2.m2.1" class="ltx_math_unparsed" alttext="2\times" display="inline"><semantics id="S3.p6.2.m2.1a"><mrow id="S3.p6.2.m2.1b"><mn id="S3.p6.2.m2.1.1">2</mn><mo lspace="0.222em" id="S3.p6.2.m2.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S3.p6.2.m2.1c">2\times</annotation></semantics></math> compression ratio can almost reach the baseline after about <math id="S3.p6.3.m3.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S3.p6.3.m3.1a"><mn id="S3.p6.3.m3.1.1" xref="S3.p6.3.m3.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S3.p6.3.m3.1b"><cn type="integer" id="S3.p6.3.m3.1.1.cmml" xref="S3.p6.3.m3.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.3.m3.1c">100</annotation></semantics></math> iterations. When <math id="S3.p6.4.m4.1" class="ltx_Math" alttext="r=5" display="inline"><semantics id="S3.p6.4.m4.1a"><mrow id="S3.p6.4.m4.1.1" xref="S3.p6.4.m4.1.1.cmml"><mi id="S3.p6.4.m4.1.1.2" xref="S3.p6.4.m4.1.1.2.cmml">r</mi><mo id="S3.p6.4.m4.1.1.1" xref="S3.p6.4.m4.1.1.1.cmml">=</mo><mn id="S3.p6.4.m4.1.1.3" xref="S3.p6.4.m4.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p6.4.m4.1b"><apply id="S3.p6.4.m4.1.1.cmml" xref="S3.p6.4.m4.1.1"><eq id="S3.p6.4.m4.1.1.1.cmml" xref="S3.p6.4.m4.1.1.1"></eq><ci id="S3.p6.4.m4.1.1.2.cmml" xref="S3.p6.4.m4.1.1.2">𝑟</ci><cn type="integer" id="S3.p6.4.m4.1.1.3.cmml" xref="S3.p6.4.m4.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.4.m4.1c">r=5</annotation></semantics></math>, the model converged more slowly and became stable after <math id="S3.p6.5.m5.1" class="ltx_Math" alttext="300" display="inline"><semantics id="S3.p6.5.m5.1a"><mn id="S3.p6.5.m5.1.1" xref="S3.p6.5.m5.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S3.p6.5.m5.1b"><cn type="integer" id="S3.p6.5.m5.1.1.cmml" xref="S3.p6.5.m5.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.5.m5.1c">300</annotation></semantics></math> iterations at the accuracy of <math id="S3.p6.6.m6.1" class="ltx_Math" alttext="93.7\%" display="inline"><semantics id="S3.p6.6.m6.1a"><mrow id="S3.p6.6.m6.1.1" xref="S3.p6.6.m6.1.1.cmml"><mn id="S3.p6.6.m6.1.1.2" xref="S3.p6.6.m6.1.1.2.cmml">93.7</mn><mo id="S3.p6.6.m6.1.1.1" xref="S3.p6.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p6.6.m6.1b"><apply id="S3.p6.6.m6.1.1.cmml" xref="S3.p6.6.m6.1.1"><csymbol cd="latexml" id="S3.p6.6.m6.1.1.1.cmml" xref="S3.p6.6.m6.1.1.1">percent</csymbol><cn type="float" id="S3.p6.6.m6.1.1.2.cmml" xref="S3.p6.6.m6.1.1.2">93.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.6.m6.1c">93.7\%</annotation></semantics></math>. The larger the compression ratio, the more the test accuracy dropped. The accuracy will reduce to <math id="S3.p6.7.m7.1" class="ltx_Math" alttext="87.5\%" display="inline"><semantics id="S3.p6.7.m7.1a"><mrow id="S3.p6.7.m7.1.1" xref="S3.p6.7.m7.1.1.cmml"><mn id="S3.p6.7.m7.1.1.2" xref="S3.p6.7.m7.1.1.2.cmml">87.5</mn><mo id="S3.p6.7.m7.1.1.1" xref="S3.p6.7.m7.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p6.7.m7.1b"><apply id="S3.p6.7.m7.1.1.cmml" xref="S3.p6.7.m7.1.1"><csymbol cd="latexml" id="S3.p6.7.m7.1.1.1.cmml" xref="S3.p6.7.m7.1.1.1">percent</csymbol><cn type="float" id="S3.p6.7.m7.1.1.2.cmml" xref="S3.p6.7.m7.1.1.2">87.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.7.m7.1c">87.5\%</annotation></semantics></math> in the case of the <math id="S3.p6.8.m8.1" class="ltx_math_unparsed" alttext="10\times" display="inline"><semantics id="S3.p6.8.m8.1a"><mrow id="S3.p6.8.m8.1b"><mn id="S3.p6.8.m8.1.1">10</mn><mo lspace="0.222em" id="S3.p6.8.m8.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S3.p6.8.m8.1c">10\times</annotation></semantics></math> compression ratio after <math id="S3.p6.9.m9.1" class="ltx_Math" alttext="300" display="inline"><semantics id="S3.p6.9.m9.1a"><mn id="S3.p6.9.m9.1.1" xref="S3.p6.9.m9.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S3.p6.9.m9.1b"><cn type="integer" id="S3.p6.9.m9.1.1.cmml" xref="S3.p6.9.m9.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.9.m9.1c">300</annotation></semantics></math> iterations. In summary, the compression ratio of <math id="S3.p6.10.m10.1" class="ltx_math_unparsed" alttext="5\times" display="inline"><semantics id="S3.p6.10.m10.1a"><mrow id="S3.p6.10.m10.1b"><mn id="S3.p6.10.m10.1.1">5</mn><mo lspace="0.222em" id="S3.p6.10.m10.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S3.p6.10.m10.1c">5\times</annotation></semantics></math> seems acceptable to balance the model accuracy and compression for gradient updates transmission.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this paper, we propose an end-to-end encrypted neural network (ENN) for compressing and encrypting dense gradient updates simultaneously. The encrypted neural network is composed of two different sub-networks: an encoding sub-network and a decoding sub-network. In the ENN-based federated learning framework, each client uses an encoding sub-network respectively to encrypt and compress the gradient updates with a lower-dimensional coding vector. Once encrypted vectors are transmitted to the server, a decoding sub-network deployed on the server is responsible to recover the aggregated updates from encrypted vectors. In this way, the original gradient updates will never appear both during transmission and after decoding. As a result, the proposed ENN can not only compress the dense gradient updates, but also protect the privacy of each client to avoid being intercepted during communication or directly exposed to the server.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>References</h2>

</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
H. Brendan McMahan, Eider Moore, Daniel Ramage, and Blaise Agüera
y Arcas,

</span>
<span class="ltx_bibblock">“Federated learning of deep networks using model averaging,”

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">CoRR</span>, vol. abs/1602.05629, 2016.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Reza Shokri and Vitaly Shmatikov,

</span>
<span class="ltx_bibblock">“Privacy-preserving deep learning,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Proceedings of the 22Nd ACM SIGSAC Conference on Computer and
Communications Security</span>, New York, NY, USA, 2015, CCS ’15, pp. 1310–1321,
ACM.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Frank Seide, Hao Fu, Jasha Droppo, Gang Li, and Dong Yu,

</span>
<span class="ltx_bibblock">“1-bit stochastic gradient descent and application to data-parallel
distributed training of speech DNNs,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Interspeech 2014</span>, September 2014.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Wei Wen, Cong Xu, Feng Yan, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li,

</span>
<span class="ltx_bibblock">“Terngrad: Ternary gradients to reduce communication in distributed
deep learning,”

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">CoRR</span>, vol. abs/1705.07878, 2017.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Nikko Strom,

</span>
<span class="ltx_bibblock">“Scalable distributed DNN training using commodity GPU cloud
computing,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Sixteenth Annual Conference of the International Speech
Communication Association</span>, 2015.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Alham Fikri Aji and Kenneth Heafield,

</span>
<span class="ltx_bibblock">“Sparse communication for distributed gradient descent,”

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">CoRR</span>, vol. abs/1704.05021, 2017.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Jakub Kone<math id="bib.bib7.1.m1.1" class="ltx_Math" alttext="\breve{c}" display="inline"><semantics id="bib.bib7.1.m1.1a"><mover accent="true" id="bib.bib7.1.m1.1.1" xref="bib.bib7.1.m1.1.1.cmml"><mi id="bib.bib7.1.m1.1.1.2" xref="bib.bib7.1.m1.1.1.2.cmml">c</mi><mo id="bib.bib7.1.m1.1.1.1" xref="bib.bib7.1.m1.1.1.1.cmml">˘</mo></mover><annotation-xml encoding="MathML-Content" id="bib.bib7.1.m1.1b"><apply id="bib.bib7.1.m1.1.1.cmml" xref="bib.bib7.1.m1.1.1"><ci id="bib.bib7.1.m1.1.1.1.cmml" xref="bib.bib7.1.m1.1.1.1">˘</ci><ci id="bib.bib7.1.m1.1.1.2.cmml" xref="bib.bib7.1.m1.1.1.2">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="bib.bib7.1.m1.1c">\breve{c}</annotation></semantics></math>ný, H. Brendan McMahan, Felix X. Yu, Peter
Richtárik, Ananda Theertha Suresh, and Dave Bacon,

</span>
<span class="ltx_bibblock">“Federated learning: Strategies for improving communication
efficiency,”

</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text ltx_font_italic">CoRR</span>, vol. abs/1610.05492, 2016.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Robin C. Geyer, Tassilo Klein, and Moin Nabi,

</span>
<span class="ltx_bibblock">“Differentially private federated learning: A client level
perspective,”

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">CoRR</span>, vol. abs/1712.07557, 2017.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Cheng-Yuan Liou, Wei-Chen Cheng, Jiun-Wei Liou, and Daw-Ran Liou,

</span>
<span class="ltx_bibblock">“Autoencoder for words,”

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Neurocomputing</span>, vol. 139, pp. 84 – 96, 2014.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Alex Krizhevsky and Geoffrey E. Hinton,

</span>
<span class="ltx_bibblock">“Using very deep autoencoders for content-based image retrieval,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">ESANN 2011, 19th European Symposium on Artificial Neural
Networks, Bruges, Belgium, April 27-29, 2011, Proceedings</span>, 2011.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol,

</span>
<span class="ltx_bibblock">“Extracting and composing robust features with denoising
autoencoders,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Proceedings of the 25th International Conference on Machine
Learning</span>, New York, NY, USA, 2008, ICML ’08, pp. 1096–1103, ACM.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Craig Gentry,

</span>
<span class="ltx_bibblock">“Fully homomorphic encryption using ideal lattices,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Proceedings of the Forty-first Annual ACM Symposium on Theory
of Computing</span>, New York, NY, USA, 2009, STOC ’09, pp. 169–178, ACM.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun,

</span>
<span class="ltx_bibblock">“Deep residual learning for image recognition,”

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">CoRR</span>, vol. abs/1512.03385, 2015.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/1908.08338" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/1908.08340" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+1908.08340">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/1908.08340" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/1908.08341" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  9 08:57:16 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
