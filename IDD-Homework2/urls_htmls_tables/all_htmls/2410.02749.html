<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Training Language Models on Synthetic Edit Sequences Improves Code Synthesis</title>
<!--Generated on Tue Oct 15 03:41:16 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.02749v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S1" title="In Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S2" title="In Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>LintSeq: Code Synthesis as a Sequential Edit Problem</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S2.SS1" title="In 2 LintSeq: Code Synthesis as a Sequential Edit Problem ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Reparameterizing Code Datasets with Edits</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S2.SS2" title="In 2 LintSeq: Code Synthesis as a Sequential Edit Problem ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Generating Linter-Guided Synthetic Edit Sequences</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S2.SS2.SSS0.Px1" title="In 2.2 Generating Linter-Guided Synthetic Edit Sequences ‣ 2 LintSeq: Code Synthesis as a Sequential Edit Problem ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title">Phase I: Backward Sampling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S2.SS2.SSS0.Px2" title="In 2.2 Generating Linter-Guided Synthetic Edit Sequences ‣ 2 LintSeq: Code Synthesis as a Sequential Edit Problem ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title">Phase II: Forward Edit Computation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S2.SS3" title="In 2 LintSeq: Code Synthesis as a Sequential Edit Problem ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Properties of LintSeq Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S2.SS4" title="In 2 LintSeq: Code Synthesis as a Sequential Edit Problem ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Practicalities of Training Language Models on LintSeq Data</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3" title="In Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS1" title="In 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Pretraining Tiny LMs for Code Understanding</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS2" title="In 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Generating a Synthetic Dataset with LintSeq</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS3" title="In 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Finetuning Language Models on LintSeq Edit Sequences</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS3.SSS1" title="In 3.3 Finetuning Language Models on LintSeq Edit Sequences ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.1 </span>TinyCodeLM</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS3.SSS2" title="In 3.3 Finetuning Language Models on LintSeq Edit Sequences ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.2 </span>Gemma 2, Phi-3, and Llama 3.1</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS4" title="In 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Ablating Linter-Guidance</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S4" title="In Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S4.SS0.SSS0.Px1" title="In 4 Related Work ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title">Foundation Models for Code</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S4.SS0.SSS0.Px2" title="In 4 Related Work ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title">Finetuning on Synthetic Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S4.SS0.SSS0.Px3" title="In 4 Related Work ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title">Finetuning on Edits</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S4.SS0.SSS0.Px4" title="In 4 Related Work ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title">“On Device” Language Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S4.SS0.SSS0.Px5" title="In 4 Related Work ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title">Inference-Time Compute Scaling</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S5" title="In Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion, Limitations, and Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A1" title="In Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>More on Edit Sequences and Diffs</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A1.SS1" title="In Appendix A More on Edit Sequences and Diffs ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Reading Unix Diffs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A1.SS2" title="In Appendix A More on Edit Sequences and Diffs ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Resolving Edit Sequences</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A1.SS3" title="In Appendix A More on Edit Sequences and Diffs ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Controllability of Code Synthesis with Edit Sequence LMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A1.SS4" title="In Appendix A More on Edit Sequences and Diffs ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4 </span>Future Work: Searching in Edit Space</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A2" title="In Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A2.SS1" title="In Appendix B Evaluation ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Prompting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A2.SS2" title="In Appendix B Evaluation ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Generation and Parsing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A2.SS3" title="In Appendix B Evaluation ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3 </span>Evaluating Model Checkpoints</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A2.SS3.SSS1" title="In B.3 Evaluating Model Checkpoints ‣ Appendix B Evaluation ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3.1 </span>Philosophy</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A2.SS3.SSS2" title="In B.3 Evaluating Model Checkpoints ‣ Appendix B Evaluation ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3.2 </span>Computing Coverage (Pass@K)</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A3" title="In Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Pretraining</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A3.SS1" title="In Appendix C Pretraining ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>Model Architectures and Pretraining Hyperparameters</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A3.SS2" title="In Appendix C Pretraining ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2 </span>Pretraining Data Mix</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A4" title="In Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Instruction Finetuning</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A4.SS1" title="In Appendix D Instruction Finetuning ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.1 </span>Baseline Instruction Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A4.SS2" title="In Appendix D Instruction Finetuning ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.2 </span>Procedures and Hyperparameters</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A5" title="In Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>More on Synthetic Data Generation with LintSeq</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A5.SS1" title="In Appendix E More on Synthetic Data Generation with LintSeq ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.1 </span>Examples of Generated Synthetic Edit Trajectories</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A5.SS2" title="In Appendix E More on Synthetic Data Generation with LintSeq ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.2 </span>Tuning LintSeq Example Count</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6" title="In Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Additional Results</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.SS1" title="In Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F.1 </span>Pretraining TinyCodeLM</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.SS2" title="In Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F.2 </span>Finetuning TinyCodeLM</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.SS2.SSS1" title="In F.2 Finetuning TinyCodeLM ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F.2.1 </span>Inference-Time Scaling Laws</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.SS3" title="In Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F.3 </span>Finetuning Gemma 2, Phi-3, and Llama 3.1</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.SS3.SSS1" title="In F.3 Finetuning Gemma 2, Phi-3, and Llama 3.1 ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F.3.1 </span>Inference-Time Scaling Laws</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.SS4" title="In Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F.4 </span>Computing HumanEval Coverage vs Cumulative Inference-Time FLOPs</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Training Language Models on Synthetic Edit Sequences Improves Code Synthesis</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ulyana Piterbarg, Lerrel Pinto, Rob Fergus  
<br class="ltx_break"/>New York University
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.1.id1">up2021@cims.nyu.edu</span>
<br class="ltx_break"/>
</span><span class="ltx_author_notes">We open-source our code and tiny code LM models to <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://lintseq.github.io/" title="">https://lintseq.github.io/</a>.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.1">Software engineers mainly write code by editing existing programs. In contrast, large language models (LLMs) autoregressively synthesize programs in a single pass. One explanation for this is the scarcity of open-sourced edit data. While high-quality instruction data for code synthesis is already scarce, high-quality edit data is even scarcer. To fill this gap, we develop a synthetic data generation algorithm called LintSeq. This algorithm refactors existing code into a sequence of code edits by using a <em class="ltx_emph ltx_font_italic" id="id1.1.1">linter</em> to procedurally sample across the error-free insertions that can be used to sequentially write programs. It outputs edit sequences as text strings consisting of consecutive program <span class="ltx_text ltx_font_italic" id="id1.1.2">diffs</span>. To test LintSeq, we use it to refactor a dataset of instruction + program pairs into instruction + program-diff-sequence tuples. Then, we instruction finetune a series of smaller LLMs ranging from 2.6B to 14B parameters on both the re-factored and original versions of this dataset, comparing zero-shot performance on code synthesis benchmarks. We show that during repeated sampling, edit sequence finetuned models produce more diverse programs than baselines. This results in better inference-time scaling for benchmark coverage as a function of samples, i.e. the fraction of problems “pass@k” solved by any attempt given “k” tries. For example, on HumanEval pass@50, small LLMs finetuned on synthetic edit sequences are competitive with GPT-4 and outperform models finetuned on the baseline dataset by +20% (<math alttext="\pm" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mo id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><csymbol cd="latexml" id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">±</annotation></semantics></math>3%) in absolute score. Finally, we also pretrain our own tiny LMs for code understanding. We show that finetuning tiny models on synthetic code edits results in state-of-the-art code synthesis for the on-device model class. Our 150M parameter edit sequence LM matches or outperforms code models with twice as many parameters, both with and without repeated sampling, including Codex and AlphaCode.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The successes of large language models (LLMs) are difficult to overstate. However, consistent and correct zero-shot generation in code synthesis remains out-of-reach for all but the largest models <cite class="ltx_cite ltx_citemacro_citep">(Abdin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib1" title="">2024</a>; Groeneveld et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib16" title="">2024</a>; Dubey et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib12" title="">2024</a>)</cite>. Compared to other reasoning tasks, this setting has two challenging properties, namely solutions are both structured and long-form.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Humans tackle problems that have these properties by leveraging abstract mental models, first developing a plan for their solution that reflects the setting’s structure and then executing the plan one step at a time <cite class="ltx_cite ltx_citemacro_citep">(Gopnik, <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib15" title="">1982</a>; Kirsh, <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib19" title="">2009</a>)</cite>. For example, a software engineer might employ object-oriented programming when creating a new code-base by developing a “class” object and then gradually adding new functionality to this class as their code-base becomes more complex.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="151" id="S1.F1.g1" src="extracted/5927317/template/figures/method_viz_teaser_v43.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span class="ltx_text ltx_font_bold" id="S1.F1.3.1">Code synthesis with LMs trained on synthetic code edit sequences</span>. Left: An example generation from an LM trained to synthesize code as a stream of static-error-free edits. Right: Comparing zero-shot HumanEval coverage (in %) as a function of FLOPs for large external LLMs vs the smaller LMs that we instruction finetune in this paper. <span class="ltx_text ltx_font_bold" id="S1.F1.4.2">Repeatedly sampling from edit sequence LMs yields coding problem solutions that are competitive with GPT-4 and GPT-4-Omni, and have total cost similar to sampling once from the best open-source LLMs</span>
(see Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.SS4" title="F.4 Computing HumanEval Coverage vs Cumulative Inference-Time FLOPs ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">F.4</span></a>).</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In contrast, LLMs are trained to autoregressively synthesize entire programs from scratch. This makes repeatedly editing a program with an LLM extremely expensive – current state-of-the-art, LLM-powered code editing tools like Cursor repeatedly prompt models to rewrite entire programs during every edit generation call <cite class="ltx_cite ltx_citemacro_citep">(Sanger, <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib36" title="">2024</a>)</cite>. LLM outputs also suffer from degrading quality as sequence lengths grow and exhibit limited diversity across samples <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib11" title="">2021</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib24" title="">2022b</a>; Roziere et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib35" title="">2023</a>; Lozhkov et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib26" title="">2024</a>)</cite>. The consequence of these pathologies is that there does not exist a reliable trade-off between zero-shot generation quality and inference-time compute cost under the current paradigm of autoregressive code synthesis, particularly for smaller models.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this paper, we claim that these issues can be mitigated at the data-level by reparameterizing code synthesis as a sequential edit problem. Rather than training models for single-step generation of entire programs, we propose that models be trained to generate code by predicting <span class="ltx_text ltx_font_italic" id="S1.p4.1.1">code edit sequences</span>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">This objective has a major obstacle: while high-quality solution data for code synthesis is scarce, open-source edit data with good coverage over the distribution of all error-free code “diffs” is non-existent <cite class="ltx_cite ltx_citemacro_citep">(Muennighoff et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib28" title="">2023</a>)</cite>. To address this, we introduce an algorithm titled “LintSeq” that re-factors existing programs into sequences of static error-free code edits. LMs trained on data generated with our algorithm output code edits that effect interdependent lines of a program. LintSeq is parameter-free. It consists of two phases: a backward sampling phase, which takes a source file as input and uses a static program verifier to sample sequences of error-free program states that begin with this file and end with empty programs; and a forward edit computation phase, which reverses each sequence of programs, employing the Unix <span class="ltx_text ltx_font_typewriter" id="S1.p5.1.1">diff</span> <cite class="ltx_cite ltx_citemacro_citep">(Thompson &amp; Ritchie, <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib41" title="">1975</a>)</cite> operator to compute deltas between consecutive versions of the source file, and outputs edit sequences. The static program verifier used by LintSeq in its backward sampling phase is also referred to as a <span class="ltx_text ltx_font_italic" id="S1.p5.1.2">linter</span>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">To test the impact of finetuning LMs to synthesize code with edit sequences via LintSeq instruction data, we conduct a series of experiments comparing these models to those finetuned on a standard version of the same instruction data. We evaluate LMs zero-shot on the code synthesis benchmarks HumanEval <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib11" title="">2021</a>)</cite> and MBPP <cite class="ltx_cite ltx_citemacro_citep">(Austin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib4" title="">2021</a>)</cite> by computing coverage, the proportion of problems solved by any attempt, as a function of samples. We do not allow LMs to use chain-of-thought reasoning <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib47" title="">2022</a>)</cite> during evaluation. Our results are five-fold:</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p7">
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Across models ranging in scale from 150M to 14B parameters, instruction finetuning LMs on edit sequences vs full programs improves the quality and diversity of synthesized code.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">The improved diversity of samples means that pass@k performance increases smoothly as a function of inference-time compute, allowing for a better trade-off between the two.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Tiny edit sequence LMs have state-of-the-art performance in their model class (Table <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.T1" title="Table 1 ‣ 3.2 Generating a Synthetic Dataset with LintSeq ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">For smaller LLMs, repeatedly sampling from edit sequence models results in HumanEval coverage that is competitive with GPT-4 models and has similar cumulative cost to sampling once per problem from open-source LLMs like Llama 3.1 405B (Figures <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.F4" title="Figure 4 ‣ 3.3 Finetuning Language Models on LintSeq Edit Sequences ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">4</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para ltx_noindent" id="S1.I1.i5.p1">
<p class="ltx_p" id="S1.I1.i5.p1.1">Ablating the linter from edit sampling during data generation hurts the downstream quality of programs synthesized by edit sequence models (Figures <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.F5" title="Figure 5 ‣ 3.3.2 Gemma 2, Phi-3, and Llama 3.1 ‣ 3.3 Finetuning Language Models on LintSeq Edit Sequences ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">5</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.F6" title="Figure 6 ‣ 3.4 Ablating Linter-Guidance ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">6</span></a>).</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>LintSeq: Code Synthesis as a Sequential Edit Problem</h2>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="191" id="S2.F2.g1" src="extracted/5927317/template/figures/algorithm_viz_v16.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span class="ltx_text ltx_font_bold" id="S2.F2.2.1">Visualizing LintSeq</span>, an algorithm for re-factoring programs into sequences of edits. This algorithm samples across all of the static error-free line insertions that can be used to write a program chunk-by-chunk. It uses the Unix-diff operator to express generated edit sequences as text strings. </figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">LintSeq is an algorithm for synthetic data generation that samples across sequences of insertions that can be used to sequentially write a program, leveraging a <span class="ltx_text ltx_font_italic" id="S2.p1.1.1">linter</span> to repeatedly check program states for static errors during generation. A linter is a type of standard code analysis tool that verifies the correctness of programs. The LintSeq algorithm is loosely inspired by recent work on discrete diffusion methods for text generation, where decoding is non-autoregressive <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib23" title="">2022a</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">The key hypothesis underlying LintSeq is as follows: by training LMs on code edit sequences with teacher-forced supervised learning, we can potentially achieve a better trade-off between generation quality and compute at inference-time while still benefiting from the training and sampling efficiency of the autoregressive modeling paradigm. In this section, we provide a formalism for the edit sequence re-parameterization of code synthesis and we formally introduce LintSeq.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Reparameterizing Code Datasets with Edits</h3>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.5">We operate in the textual supervised learning setting in this paper, where we have access to a code dataset <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S2.SS1.p1.1.m1.1"><semantics id="S2.SS1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.1.m1.1d">caligraphic_D</annotation></semantics></math> of <math alttext="N" class="ltx_Math" display="inline" id="S2.SS1.p1.2.m2.1"><semantics id="S2.SS1.p1.2.m2.1a"><mi id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.2.m2.1d">italic_N</annotation></semantics></math> example programs <math alttext="y" class="ltx_Math" display="inline" id="S2.SS1.p1.3.m3.1"><semantics id="S2.SS1.p1.3.m3.1a"><mi id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.3.m3.1d">italic_y</annotation></semantics></math>, each of which may be optionally paired with a corresponding natural language instruction <math alttext="x" class="ltx_Math" display="inline" id="S2.SS1.p1.4.m4.1"><semantics id="S2.SS1.p1.4.m4.1a"><mi id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><ci id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.4.m4.1d">italic_x</annotation></semantics></math> that describes the program’s function, i.e. <math alttext="\mathcal{D}=\{(x^{i},y^{i})\}_{i=1}^{N}" class="ltx_Math" display="inline" id="S2.SS1.p1.5.m5.1"><semantics id="S2.SS1.p1.5.m5.1a"><mrow id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.5.m5.1.1.3" xref="S2.SS1.p1.5.m5.1.1.3.cmml">𝒟</mi><mo id="S2.SS1.p1.5.m5.1.1.2" xref="S2.SS1.p1.5.m5.1.1.2.cmml">=</mo><msubsup id="S2.SS1.p1.5.m5.1.1.1" xref="S2.SS1.p1.5.m5.1.1.1.cmml"><mrow id="S2.SS1.p1.5.m5.1.1.1.1.1.1" xref="S2.SS1.p1.5.m5.1.1.1.1.1.2.cmml"><mo id="S2.SS1.p1.5.m5.1.1.1.1.1.1.2" stretchy="false" xref="S2.SS1.p1.5.m5.1.1.1.1.1.2.cmml">{</mo><mrow id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.3.cmml"><mo id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2.3" stretchy="false" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.3.cmml">(</mo><msup id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.1.1" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.1.1.2" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.1.1.3" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msup><mo id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2.4" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.3.cmml">,</mo><msup id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2.2" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2.2.cmml"><mi id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2.2.2" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2.2.2.cmml">y</mi><mi id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2.2.3" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2.2.3.cmml">i</mi></msup><mo id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2.5" stretchy="false" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.3.cmml">)</mo></mrow><mo id="S2.SS1.p1.5.m5.1.1.1.1.1.1.3" stretchy="false" xref="S2.SS1.p1.5.m5.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.SS1.p1.5.m5.1.1.1.1.3" xref="S2.SS1.p1.5.m5.1.1.1.1.3.cmml"><mi id="S2.SS1.p1.5.m5.1.1.1.1.3.2" xref="S2.SS1.p1.5.m5.1.1.1.1.3.2.cmml">i</mi><mo id="S2.SS1.p1.5.m5.1.1.1.1.3.1" xref="S2.SS1.p1.5.m5.1.1.1.1.3.1.cmml">=</mo><mn id="S2.SS1.p1.5.m5.1.1.1.1.3.3" xref="S2.SS1.p1.5.m5.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S2.SS1.p1.5.m5.1.1.1.3" xref="S2.SS1.p1.5.m5.1.1.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><apply id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1"><eq id="S2.SS1.p1.5.m5.1.1.2.cmml" xref="S2.SS1.p1.5.m5.1.1.2"></eq><ci id="S2.SS1.p1.5.m5.1.1.3.cmml" xref="S2.SS1.p1.5.m5.1.1.3">𝒟</ci><apply id="S2.SS1.p1.5.m5.1.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.1.1.1.2.cmml" xref="S2.SS1.p1.5.m5.1.1.1">superscript</csymbol><apply id="S2.SS1.p1.5.m5.1.1.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.1.1.1.1.2.cmml" xref="S2.SS1.p1.5.m5.1.1.1">subscript</csymbol><set id="S2.SS1.p1.5.m5.1.1.1.1.1.2.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1"><interval closure="open" id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2"><apply id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2.2.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2.2.1.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2.2">superscript</csymbol><ci id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2.2.2">𝑦</ci><ci id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2.2.3.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.2.2.3">𝑖</ci></apply></interval></set><apply id="S2.SS1.p1.5.m5.1.1.1.1.3.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.3"><eq id="S2.SS1.p1.5.m5.1.1.1.1.3.1.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.3.1"></eq><ci id="S2.SS1.p1.5.m5.1.1.1.1.3.2.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.3.2">𝑖</ci><cn id="S2.SS1.p1.5.m5.1.1.1.1.3.3.cmml" type="integer" xref="S2.SS1.p1.5.m5.1.1.1.1.3.3">1</cn></apply></apply><ci id="S2.SS1.p1.5.m5.1.1.1.3.cmml" xref="S2.SS1.p1.5.m5.1.1.1.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">\mathcal{D}=\{(x^{i},y^{i})\}_{i=1}^{N}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.5.m5.1d">caligraphic_D = { ( italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ) } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Let <math alttext="\Delta(\cdot,\cdot)" class="ltx_Math" display="inline" id="S2.SS1.p2.1.m1.2"><semantics id="S2.SS1.p2.1.m1.2a"><mrow id="S2.SS1.p2.1.m1.2.3" xref="S2.SS1.p2.1.m1.2.3.cmml"><mi id="S2.SS1.p2.1.m1.2.3.2" mathvariant="normal" xref="S2.SS1.p2.1.m1.2.3.2.cmml">Δ</mi><mo id="S2.SS1.p2.1.m1.2.3.1" xref="S2.SS1.p2.1.m1.2.3.1.cmml">⁢</mo><mrow id="S2.SS1.p2.1.m1.2.3.3.2" xref="S2.SS1.p2.1.m1.2.3.3.1.cmml"><mo id="S2.SS1.p2.1.m1.2.3.3.2.1" stretchy="false" xref="S2.SS1.p2.1.m1.2.3.3.1.cmml">(</mo><mo id="S2.SS1.p2.1.m1.1.1" lspace="0em" rspace="0em" xref="S2.SS1.p2.1.m1.1.1.cmml">⋅</mo><mo id="S2.SS1.p2.1.m1.2.3.3.2.2" rspace="0em" xref="S2.SS1.p2.1.m1.2.3.3.1.cmml">,</mo><mo id="S2.SS1.p2.1.m1.2.2" lspace="0em" rspace="0em" xref="S2.SS1.p2.1.m1.2.2.cmml">⋅</mo><mo id="S2.SS1.p2.1.m1.2.3.3.2.3" stretchy="false" xref="S2.SS1.p2.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.2b"><apply id="S2.SS1.p2.1.m1.2.3.cmml" xref="S2.SS1.p2.1.m1.2.3"><times id="S2.SS1.p2.1.m1.2.3.1.cmml" xref="S2.SS1.p2.1.m1.2.3.1"></times><ci id="S2.SS1.p2.1.m1.2.3.2.cmml" xref="S2.SS1.p2.1.m1.2.3.2">Δ</ci><interval closure="open" id="S2.SS1.p2.1.m1.2.3.3.1.cmml" xref="S2.SS1.p2.1.m1.2.3.3.2"><ci id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">⋅</ci><ci id="S2.SS1.p2.1.m1.2.2.cmml" xref="S2.SS1.p2.1.m1.2.2">⋅</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.2c">\Delta(\cdot,\cdot)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.1.m1.2d">roman_Δ ( ⋅ , ⋅ )</annotation></semantics></math> denote the Unix <span class="ltx_text ltx_font_typewriter" id="S2.SS1.p2.1.1">diff</span> operator <cite class="ltx_cite ltx_citemacro_citep">(Thompson &amp; Ritchie, <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib41" title="">1975</a>)</cite>, which computes a text difference between a pair of strings by performing a line-by-line matching and returns a string summarizing the detected differences. The <span class="ltx_text ltx_font_typewriter" id="S2.SS1.p2.1.2">diff</span> operator is implemented by popular version control and software development systems to help programmers track edits or code “diffs” between versions of text files. A single edit computed with the <span class="ltx_text ltx_font_typewriter" id="S2.SS1.p2.1.3">diff</span> operator may consist of multiple line deletions and/or line insertions.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.5">Fix a program <math alttext="y" class="ltx_Math" display="inline" id="S2.SS1.p3.1.m1.1"><semantics id="S2.SS1.p3.1.m1.1a"><mi id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><ci id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.1.m1.1d">italic_y</annotation></semantics></math> in the dataset <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S2.SS1.p3.2.m2.1"><semantics id="S2.SS1.p3.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p3.2.m2.1.1" xref="S2.SS1.p3.2.m2.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m2.1b"><ci id="S2.SS1.p3.2.m2.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m2.1c">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.2.m2.1d">caligraphic_D</annotation></semantics></math>. Consider a sequence <math alttext="\bm{\sigma}_{y}" class="ltx_Math" display="inline" id="S2.SS1.p3.3.m3.1"><semantics id="S2.SS1.p3.3.m3.1a"><msub id="S2.SS1.p3.3.m3.1.1" xref="S2.SS1.p3.3.m3.1.1.cmml"><mi id="S2.SS1.p3.3.m3.1.1.2" xref="S2.SS1.p3.3.m3.1.1.2.cmml">𝝈</mi><mi id="S2.SS1.p3.3.m3.1.1.3" xref="S2.SS1.p3.3.m3.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.3.m3.1b"><apply id="S2.SS1.p3.3.m3.1.1.cmml" xref="S2.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.3.m3.1.1.1.cmml" xref="S2.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.p3.3.m3.1.1.2.cmml" xref="S2.SS1.p3.3.m3.1.1.2">𝝈</ci><ci id="S2.SS1.p3.3.m3.1.1.3.cmml" xref="S2.SS1.p3.3.m3.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.3.m3.1c">\bm{\sigma}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.3.m3.1d">bold_italic_σ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math> of <math alttext="j" class="ltx_Math" display="inline" id="S2.SS1.p3.4.m4.1"><semantics id="S2.SS1.p3.4.m4.1a"><mi id="S2.SS1.p3.4.m4.1.1" xref="S2.SS1.p3.4.m4.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.4.m4.1b"><ci id="S2.SS1.p3.4.m4.1.1.cmml" xref="S2.SS1.p3.4.m4.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.4.m4.1c">j</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.4.m4.1d">italic_j</annotation></semantics></math> text strings corresponding to programs or program states that terminates at <math alttext="y" class="ltx_Math" display="inline" id="S2.SS1.p3.5.m5.1"><semantics id="S2.SS1.p3.5.m5.1a"><mi id="S2.SS1.p3.5.m5.1.1" xref="S2.SS1.p3.5.m5.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.5.m5.1b"><ci id="S2.SS1.p3.5.m5.1.1.cmml" xref="S2.SS1.p3.5.m5.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.5.m5.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.5.m5.1d">italic_y</annotation></semantics></math>.</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\bm{\sigma}_{y}=(y_{1},\dots,y_{j-1},y)" class="ltx_Math" display="block" id="S2.E1.m1.4"><semantics id="S2.E1.m1.4a"><mrow id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml"><msub id="S2.E1.m1.4.4.4" xref="S2.E1.m1.4.4.4.cmml"><mi id="S2.E1.m1.4.4.4.2" xref="S2.E1.m1.4.4.4.2.cmml">𝝈</mi><mi id="S2.E1.m1.4.4.4.3" xref="S2.E1.m1.4.4.4.3.cmml">y</mi></msub><mo id="S2.E1.m1.4.4.3" xref="S2.E1.m1.4.4.3.cmml">=</mo><mrow id="S2.E1.m1.4.4.2.2" xref="S2.E1.m1.4.4.2.3.cmml"><mo id="S2.E1.m1.4.4.2.2.3" stretchy="false" xref="S2.E1.m1.4.4.2.3.cmml">(</mo><msub id="S2.E1.m1.3.3.1.1.1" xref="S2.E1.m1.3.3.1.1.1.cmml"><mi id="S2.E1.m1.3.3.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.2.cmml">y</mi><mn id="S2.E1.m1.3.3.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.3.cmml">1</mn></msub><mo id="S2.E1.m1.4.4.2.2.4" xref="S2.E1.m1.4.4.2.3.cmml">,</mo><mi id="S2.E1.m1.1.1" mathvariant="normal" xref="S2.E1.m1.1.1.cmml">…</mi><mo id="S2.E1.m1.4.4.2.2.5" xref="S2.E1.m1.4.4.2.3.cmml">,</mo><msub id="S2.E1.m1.4.4.2.2.2" xref="S2.E1.m1.4.4.2.2.2.cmml"><mi id="S2.E1.m1.4.4.2.2.2.2" xref="S2.E1.m1.4.4.2.2.2.2.cmml">y</mi><mrow id="S2.E1.m1.4.4.2.2.2.3" xref="S2.E1.m1.4.4.2.2.2.3.cmml"><mi id="S2.E1.m1.4.4.2.2.2.3.2" xref="S2.E1.m1.4.4.2.2.2.3.2.cmml">j</mi><mo id="S2.E1.m1.4.4.2.2.2.3.1" xref="S2.E1.m1.4.4.2.2.2.3.1.cmml">−</mo><mn id="S2.E1.m1.4.4.2.2.2.3.3" xref="S2.E1.m1.4.4.2.2.2.3.3.cmml">1</mn></mrow></msub><mo id="S2.E1.m1.4.4.2.2.6" xref="S2.E1.m1.4.4.2.3.cmml">,</mo><mi id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">y</mi><mo id="S2.E1.m1.4.4.2.2.7" stretchy="false" xref="S2.E1.m1.4.4.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.4b"><apply id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4"><eq id="S2.E1.m1.4.4.3.cmml" xref="S2.E1.m1.4.4.3"></eq><apply id="S2.E1.m1.4.4.4.cmml" xref="S2.E1.m1.4.4.4"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.4.1.cmml" xref="S2.E1.m1.4.4.4">subscript</csymbol><ci id="S2.E1.m1.4.4.4.2.cmml" xref="S2.E1.m1.4.4.4.2">𝝈</ci><ci id="S2.E1.m1.4.4.4.3.cmml" xref="S2.E1.m1.4.4.4.3">𝑦</ci></apply><vector id="S2.E1.m1.4.4.2.3.cmml" xref="S2.E1.m1.4.4.2.2"><apply id="S2.E1.m1.3.3.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1">subscript</csymbol><ci id="S2.E1.m1.3.3.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.2">𝑦</ci><cn id="S2.E1.m1.3.3.1.1.1.3.cmml" type="integer" xref="S2.E1.m1.3.3.1.1.1.3">1</cn></apply><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">…</ci><apply id="S2.E1.m1.4.4.2.2.2.cmml" xref="S2.E1.m1.4.4.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.2.2.2.1.cmml" xref="S2.E1.m1.4.4.2.2.2">subscript</csymbol><ci id="S2.E1.m1.4.4.2.2.2.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2">𝑦</ci><apply id="S2.E1.m1.4.4.2.2.2.3.cmml" xref="S2.E1.m1.4.4.2.2.2.3"><minus id="S2.E1.m1.4.4.2.2.2.3.1.cmml" xref="S2.E1.m1.4.4.2.2.2.3.1"></minus><ci id="S2.E1.m1.4.4.2.2.2.3.2.cmml" xref="S2.E1.m1.4.4.2.2.2.3.2">𝑗</ci><cn id="S2.E1.m1.4.4.2.2.2.3.3.cmml" type="integer" xref="S2.E1.m1.4.4.2.2.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">𝑦</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.4c">\bm{\sigma}_{y}=(y_{1},\dots,y_{j-1},y)</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.4d">bold_italic_σ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT = ( italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_y start_POSTSUBSCRIPT italic_j - 1 end_POSTSUBSCRIPT , italic_y )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p4">
<p class="ltx_p" id="S2.SS1.p4.4">We can equivalently re-express <math alttext="\bm{\sigma}_{y}" class="ltx_Math" display="inline" id="S2.SS1.p4.1.m1.1"><semantics id="S2.SS1.p4.1.m1.1a"><msub id="S2.SS1.p4.1.m1.1.1" xref="S2.SS1.p4.1.m1.1.1.cmml"><mi id="S2.SS1.p4.1.m1.1.1.2" xref="S2.SS1.p4.1.m1.1.1.2.cmml">𝝈</mi><mi id="S2.SS1.p4.1.m1.1.1.3" xref="S2.SS1.p4.1.m1.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.1.m1.1b"><apply id="S2.SS1.p4.1.m1.1.1.cmml" xref="S2.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p4.1.m1.1.1.1.cmml" xref="S2.SS1.p4.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p4.1.m1.1.1.2.cmml" xref="S2.SS1.p4.1.m1.1.1.2">𝝈</ci><ci id="S2.SS1.p4.1.m1.1.1.3.cmml" xref="S2.SS1.p4.1.m1.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.1.m1.1c">\bm{\sigma}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p4.1.m1.1d">bold_italic_σ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math> as an edit sequence <math alttext="\bm{\delta}_{y}" class="ltx_Math" display="inline" id="S2.SS1.p4.2.m2.1"><semantics id="S2.SS1.p4.2.m2.1a"><msub id="S2.SS1.p4.2.m2.1.1" xref="S2.SS1.p4.2.m2.1.1.cmml"><mi id="S2.SS1.p4.2.m2.1.1.2" xref="S2.SS1.p4.2.m2.1.1.2.cmml">𝜹</mi><mi id="S2.SS1.p4.2.m2.1.1.3" xref="S2.SS1.p4.2.m2.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.2.m2.1b"><apply id="S2.SS1.p4.2.m2.1.1.cmml" xref="S2.SS1.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p4.2.m2.1.1.1.cmml" xref="S2.SS1.p4.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.p4.2.m2.1.1.2.cmml" xref="S2.SS1.p4.2.m2.1.1.2">𝜹</ci><ci id="S2.SS1.p4.2.m2.1.1.3.cmml" xref="S2.SS1.p4.2.m2.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.2.m2.1c">\bm{\delta}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p4.2.m2.1d">bold_italic_δ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math> of length <math alttext="j" class="ltx_Math" display="inline" id="S2.SS1.p4.3.m3.1"><semantics id="S2.SS1.p4.3.m3.1a"><mi id="S2.SS1.p4.3.m3.1.1" xref="S2.SS1.p4.3.m3.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.3.m3.1b"><ci id="S2.SS1.p4.3.m3.1.1.cmml" xref="S2.SS1.p4.3.m3.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.3.m3.1c">j</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p4.3.m3.1d">italic_j</annotation></semantics></math> by first computing a diff between an empty program <math alttext="\epsilon" class="ltx_Math" display="inline" id="S2.SS1.p4.4.m4.1"><semantics id="S2.SS1.p4.4.m4.1a"><mi id="S2.SS1.p4.4.m4.1.1" xref="S2.SS1.p4.4.m4.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.4.m4.1b"><ci id="S2.SS1.p4.4.m4.1.1.cmml" xref="S2.SS1.p4.4.m4.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.4.m4.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p4.4.m4.1d">italic_ϵ</annotation></semantics></math> and the first program in the sequence, and then computing diffs between all pairs of consecutive programs, as shown below.</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\bm{\delta}_{y}=(\Delta(\varepsilon,y_{1}),\Delta(y_{1},y_{2}),\Delta(y_{2},y_%
{3}),\dots,\Delta(y_{j-1},y))" class="ltx_Math" display="block" id="S2.E2.m1.7"><semantics id="S2.E2.m1.7a"><mrow id="S2.E2.m1.7.7" xref="S2.E2.m1.7.7.cmml"><msub id="S2.E2.m1.7.7.6" xref="S2.E2.m1.7.7.6.cmml"><mi id="S2.E2.m1.7.7.6.2" xref="S2.E2.m1.7.7.6.2.cmml">𝜹</mi><mi id="S2.E2.m1.7.7.6.3" xref="S2.E2.m1.7.7.6.3.cmml">y</mi></msub><mo id="S2.E2.m1.7.7.5" xref="S2.E2.m1.7.7.5.cmml">=</mo><mrow id="S2.E2.m1.7.7.4.4" xref="S2.E2.m1.7.7.4.5.cmml"><mo id="S2.E2.m1.7.7.4.4.5" stretchy="false" xref="S2.E2.m1.7.7.4.5.cmml">(</mo><mrow id="S2.E2.m1.4.4.1.1.1" xref="S2.E2.m1.4.4.1.1.1.cmml"><mi id="S2.E2.m1.4.4.1.1.1.3" mathvariant="normal" xref="S2.E2.m1.4.4.1.1.1.3.cmml">Δ</mi><mo id="S2.E2.m1.4.4.1.1.1.2" xref="S2.E2.m1.4.4.1.1.1.2.cmml">⁢</mo><mrow id="S2.E2.m1.4.4.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.2.cmml"><mo id="S2.E2.m1.4.4.1.1.1.1.1.2" stretchy="false" xref="S2.E2.m1.4.4.1.1.1.1.2.cmml">(</mo><mi id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml">ε</mi><mo id="S2.E2.m1.4.4.1.1.1.1.1.3" xref="S2.E2.m1.4.4.1.1.1.1.2.cmml">,</mo><msub id="S2.E2.m1.4.4.1.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.2.cmml">y</mi><mn id="S2.E2.m1.4.4.1.1.1.1.1.1.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.E2.m1.4.4.1.1.1.1.1.4" stretchy="false" xref="S2.E2.m1.4.4.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.7.7.4.4.6" xref="S2.E2.m1.7.7.4.5.cmml">,</mo><mrow id="S2.E2.m1.5.5.2.2.2" xref="S2.E2.m1.5.5.2.2.2.cmml"><mi id="S2.E2.m1.5.5.2.2.2.4" mathvariant="normal" xref="S2.E2.m1.5.5.2.2.2.4.cmml">Δ</mi><mo id="S2.E2.m1.5.5.2.2.2.3" xref="S2.E2.m1.5.5.2.2.2.3.cmml">⁢</mo><mrow id="S2.E2.m1.5.5.2.2.2.2.2" xref="S2.E2.m1.5.5.2.2.2.2.3.cmml"><mo id="S2.E2.m1.5.5.2.2.2.2.2.3" stretchy="false" xref="S2.E2.m1.5.5.2.2.2.2.3.cmml">(</mo><msub id="S2.E2.m1.5.5.2.2.2.1.1.1" xref="S2.E2.m1.5.5.2.2.2.1.1.1.cmml"><mi id="S2.E2.m1.5.5.2.2.2.1.1.1.2" xref="S2.E2.m1.5.5.2.2.2.1.1.1.2.cmml">y</mi><mn id="S2.E2.m1.5.5.2.2.2.1.1.1.3" xref="S2.E2.m1.5.5.2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.E2.m1.5.5.2.2.2.2.2.4" xref="S2.E2.m1.5.5.2.2.2.2.3.cmml">,</mo><msub id="S2.E2.m1.5.5.2.2.2.2.2.2" xref="S2.E2.m1.5.5.2.2.2.2.2.2.cmml"><mi id="S2.E2.m1.5.5.2.2.2.2.2.2.2" xref="S2.E2.m1.5.5.2.2.2.2.2.2.2.cmml">y</mi><mn id="S2.E2.m1.5.5.2.2.2.2.2.2.3" xref="S2.E2.m1.5.5.2.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S2.E2.m1.5.5.2.2.2.2.2.5" stretchy="false" xref="S2.E2.m1.5.5.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.7.7.4.4.7" xref="S2.E2.m1.7.7.4.5.cmml">,</mo><mrow id="S2.E2.m1.6.6.3.3.3" xref="S2.E2.m1.6.6.3.3.3.cmml"><mi id="S2.E2.m1.6.6.3.3.3.4" mathvariant="normal" xref="S2.E2.m1.6.6.3.3.3.4.cmml">Δ</mi><mo id="S2.E2.m1.6.6.3.3.3.3" xref="S2.E2.m1.6.6.3.3.3.3.cmml">⁢</mo><mrow id="S2.E2.m1.6.6.3.3.3.2.2" xref="S2.E2.m1.6.6.3.3.3.2.3.cmml"><mo id="S2.E2.m1.6.6.3.3.3.2.2.3" stretchy="false" xref="S2.E2.m1.6.6.3.3.3.2.3.cmml">(</mo><msub id="S2.E2.m1.6.6.3.3.3.1.1.1" xref="S2.E2.m1.6.6.3.3.3.1.1.1.cmml"><mi id="S2.E2.m1.6.6.3.3.3.1.1.1.2" xref="S2.E2.m1.6.6.3.3.3.1.1.1.2.cmml">y</mi><mn id="S2.E2.m1.6.6.3.3.3.1.1.1.3" xref="S2.E2.m1.6.6.3.3.3.1.1.1.3.cmml">2</mn></msub><mo id="S2.E2.m1.6.6.3.3.3.2.2.4" xref="S2.E2.m1.6.6.3.3.3.2.3.cmml">,</mo><msub id="S2.E2.m1.6.6.3.3.3.2.2.2" xref="S2.E2.m1.6.6.3.3.3.2.2.2.cmml"><mi id="S2.E2.m1.6.6.3.3.3.2.2.2.2" xref="S2.E2.m1.6.6.3.3.3.2.2.2.2.cmml">y</mi><mn id="S2.E2.m1.6.6.3.3.3.2.2.2.3" xref="S2.E2.m1.6.6.3.3.3.2.2.2.3.cmml">3</mn></msub><mo id="S2.E2.m1.6.6.3.3.3.2.2.5" stretchy="false" xref="S2.E2.m1.6.6.3.3.3.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.7.7.4.4.8" xref="S2.E2.m1.7.7.4.5.cmml">,</mo><mi id="S2.E2.m1.3.3" mathvariant="normal" xref="S2.E2.m1.3.3.cmml">…</mi><mo id="S2.E2.m1.7.7.4.4.9" xref="S2.E2.m1.7.7.4.5.cmml">,</mo><mrow id="S2.E2.m1.7.7.4.4.4" xref="S2.E2.m1.7.7.4.4.4.cmml"><mi id="S2.E2.m1.7.7.4.4.4.3" mathvariant="normal" xref="S2.E2.m1.7.7.4.4.4.3.cmml">Δ</mi><mo id="S2.E2.m1.7.7.4.4.4.2" xref="S2.E2.m1.7.7.4.4.4.2.cmml">⁢</mo><mrow id="S2.E2.m1.7.7.4.4.4.1.1" xref="S2.E2.m1.7.7.4.4.4.1.2.cmml"><mo id="S2.E2.m1.7.7.4.4.4.1.1.2" stretchy="false" xref="S2.E2.m1.7.7.4.4.4.1.2.cmml">(</mo><msub id="S2.E2.m1.7.7.4.4.4.1.1.1" xref="S2.E2.m1.7.7.4.4.4.1.1.1.cmml"><mi id="S2.E2.m1.7.7.4.4.4.1.1.1.2" xref="S2.E2.m1.7.7.4.4.4.1.1.1.2.cmml">y</mi><mrow id="S2.E2.m1.7.7.4.4.4.1.1.1.3" xref="S2.E2.m1.7.7.4.4.4.1.1.1.3.cmml"><mi id="S2.E2.m1.7.7.4.4.4.1.1.1.3.2" xref="S2.E2.m1.7.7.4.4.4.1.1.1.3.2.cmml">j</mi><mo id="S2.E2.m1.7.7.4.4.4.1.1.1.3.1" xref="S2.E2.m1.7.7.4.4.4.1.1.1.3.1.cmml">−</mo><mn id="S2.E2.m1.7.7.4.4.4.1.1.1.3.3" xref="S2.E2.m1.7.7.4.4.4.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S2.E2.m1.7.7.4.4.4.1.1.3" xref="S2.E2.m1.7.7.4.4.4.1.2.cmml">,</mo><mi id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml">y</mi><mo id="S2.E2.m1.7.7.4.4.4.1.1.4" stretchy="false" xref="S2.E2.m1.7.7.4.4.4.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.7.7.4.4.10" stretchy="false" xref="S2.E2.m1.7.7.4.5.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.7b"><apply id="S2.E2.m1.7.7.cmml" xref="S2.E2.m1.7.7"><eq id="S2.E2.m1.7.7.5.cmml" xref="S2.E2.m1.7.7.5"></eq><apply id="S2.E2.m1.7.7.6.cmml" xref="S2.E2.m1.7.7.6"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.6.1.cmml" xref="S2.E2.m1.7.7.6">subscript</csymbol><ci id="S2.E2.m1.7.7.6.2.cmml" xref="S2.E2.m1.7.7.6.2">𝜹</ci><ci id="S2.E2.m1.7.7.6.3.cmml" xref="S2.E2.m1.7.7.6.3">𝑦</ci></apply><vector id="S2.E2.m1.7.7.4.5.cmml" xref="S2.E2.m1.7.7.4.4"><apply id="S2.E2.m1.4.4.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1"><times id="S2.E2.m1.4.4.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.2"></times><ci id="S2.E2.m1.4.4.1.1.1.3.cmml" xref="S2.E2.m1.4.4.1.1.1.3">Δ</ci><interval closure="open" id="S2.E2.m1.4.4.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1"><ci id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1">𝜀</ci><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.2">𝑦</ci><cn id="S2.E2.m1.4.4.1.1.1.1.1.1.3.cmml" type="integer" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3">1</cn></apply></interval></apply><apply id="S2.E2.m1.5.5.2.2.2.cmml" xref="S2.E2.m1.5.5.2.2.2"><times id="S2.E2.m1.5.5.2.2.2.3.cmml" xref="S2.E2.m1.5.5.2.2.2.3"></times><ci id="S2.E2.m1.5.5.2.2.2.4.cmml" xref="S2.E2.m1.5.5.2.2.2.4">Δ</ci><interval closure="open" id="S2.E2.m1.5.5.2.2.2.2.3.cmml" xref="S2.E2.m1.5.5.2.2.2.2.2"><apply id="S2.E2.m1.5.5.2.2.2.1.1.1.cmml" xref="S2.E2.m1.5.5.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.5.5.2.2.2.1.1.1.1.cmml" xref="S2.E2.m1.5.5.2.2.2.1.1.1">subscript</csymbol><ci id="S2.E2.m1.5.5.2.2.2.1.1.1.2.cmml" xref="S2.E2.m1.5.5.2.2.2.1.1.1.2">𝑦</ci><cn id="S2.E2.m1.5.5.2.2.2.1.1.1.3.cmml" type="integer" xref="S2.E2.m1.5.5.2.2.2.1.1.1.3">1</cn></apply><apply id="S2.E2.m1.5.5.2.2.2.2.2.2.cmml" xref="S2.E2.m1.5.5.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.5.5.2.2.2.2.2.2.1.cmml" xref="S2.E2.m1.5.5.2.2.2.2.2.2">subscript</csymbol><ci id="S2.E2.m1.5.5.2.2.2.2.2.2.2.cmml" xref="S2.E2.m1.5.5.2.2.2.2.2.2.2">𝑦</ci><cn id="S2.E2.m1.5.5.2.2.2.2.2.2.3.cmml" type="integer" xref="S2.E2.m1.5.5.2.2.2.2.2.2.3">2</cn></apply></interval></apply><apply id="S2.E2.m1.6.6.3.3.3.cmml" xref="S2.E2.m1.6.6.3.3.3"><times id="S2.E2.m1.6.6.3.3.3.3.cmml" xref="S2.E2.m1.6.6.3.3.3.3"></times><ci id="S2.E2.m1.6.6.3.3.3.4.cmml" xref="S2.E2.m1.6.6.3.3.3.4">Δ</ci><interval closure="open" id="S2.E2.m1.6.6.3.3.3.2.3.cmml" xref="S2.E2.m1.6.6.3.3.3.2.2"><apply id="S2.E2.m1.6.6.3.3.3.1.1.1.cmml" xref="S2.E2.m1.6.6.3.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.6.6.3.3.3.1.1.1.1.cmml" xref="S2.E2.m1.6.6.3.3.3.1.1.1">subscript</csymbol><ci id="S2.E2.m1.6.6.3.3.3.1.1.1.2.cmml" xref="S2.E2.m1.6.6.3.3.3.1.1.1.2">𝑦</ci><cn id="S2.E2.m1.6.6.3.3.3.1.1.1.3.cmml" type="integer" xref="S2.E2.m1.6.6.3.3.3.1.1.1.3">2</cn></apply><apply id="S2.E2.m1.6.6.3.3.3.2.2.2.cmml" xref="S2.E2.m1.6.6.3.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.6.6.3.3.3.2.2.2.1.cmml" xref="S2.E2.m1.6.6.3.3.3.2.2.2">subscript</csymbol><ci id="S2.E2.m1.6.6.3.3.3.2.2.2.2.cmml" xref="S2.E2.m1.6.6.3.3.3.2.2.2.2">𝑦</ci><cn id="S2.E2.m1.6.6.3.3.3.2.2.2.3.cmml" type="integer" xref="S2.E2.m1.6.6.3.3.3.2.2.2.3">3</cn></apply></interval></apply><ci id="S2.E2.m1.3.3.cmml" xref="S2.E2.m1.3.3">…</ci><apply id="S2.E2.m1.7.7.4.4.4.cmml" xref="S2.E2.m1.7.7.4.4.4"><times id="S2.E2.m1.7.7.4.4.4.2.cmml" xref="S2.E2.m1.7.7.4.4.4.2"></times><ci id="S2.E2.m1.7.7.4.4.4.3.cmml" xref="S2.E2.m1.7.7.4.4.4.3">Δ</ci><interval closure="open" id="S2.E2.m1.7.7.4.4.4.1.2.cmml" xref="S2.E2.m1.7.7.4.4.4.1.1"><apply id="S2.E2.m1.7.7.4.4.4.1.1.1.cmml" xref="S2.E2.m1.7.7.4.4.4.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.4.4.4.1.1.1.1.cmml" xref="S2.E2.m1.7.7.4.4.4.1.1.1">subscript</csymbol><ci id="S2.E2.m1.7.7.4.4.4.1.1.1.2.cmml" xref="S2.E2.m1.7.7.4.4.4.1.1.1.2">𝑦</ci><apply id="S2.E2.m1.7.7.4.4.4.1.1.1.3.cmml" xref="S2.E2.m1.7.7.4.4.4.1.1.1.3"><minus id="S2.E2.m1.7.7.4.4.4.1.1.1.3.1.cmml" xref="S2.E2.m1.7.7.4.4.4.1.1.1.3.1"></minus><ci id="S2.E2.m1.7.7.4.4.4.1.1.1.3.2.cmml" xref="S2.E2.m1.7.7.4.4.4.1.1.1.3.2">𝑗</ci><cn id="S2.E2.m1.7.7.4.4.4.1.1.1.3.3.cmml" type="integer" xref="S2.E2.m1.7.7.4.4.4.1.1.1.3.3">1</cn></apply></apply><ci id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2">𝑦</ci></interval></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.7c">\bm{\delta}_{y}=(\Delta(\varepsilon,y_{1}),\Delta(y_{1},y_{2}),\Delta(y_{2},y_%
{3}),\dots,\Delta(y_{j-1},y))</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m1.7d">bold_italic_δ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT = ( roman_Δ ( italic_ε , italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , roman_Δ ( italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) , roman_Δ ( italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) , … , roman_Δ ( italic_y start_POSTSUBSCRIPT italic_j - 1 end_POSTSUBSCRIPT , italic_y ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p5">
<p class="ltx_p" id="S2.SS1.p5.5">If <math alttext="\mathcal{D}^{\prime}" class="ltx_Math" display="inline" id="S2.SS1.p5.1.m1.1"><semantics id="S2.SS1.p5.1.m1.1a"><msup id="S2.SS1.p5.1.m1.1.1" xref="S2.SS1.p5.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p5.1.m1.1.1.2" xref="S2.SS1.p5.1.m1.1.1.2.cmml">𝒟</mi><mo id="S2.SS1.p5.1.m1.1.1.3" xref="S2.SS1.p5.1.m1.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.1.m1.1b"><apply id="S2.SS1.p5.1.m1.1.1.cmml" xref="S2.SS1.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p5.1.m1.1.1.1.cmml" xref="S2.SS1.p5.1.m1.1.1">superscript</csymbol><ci id="S2.SS1.p5.1.m1.1.1.2.cmml" xref="S2.SS1.p5.1.m1.1.1.2">𝒟</ci><ci id="S2.SS1.p5.1.m1.1.1.3.cmml" xref="S2.SS1.p5.1.m1.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.1.m1.1c">\mathcal{D}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p5.1.m1.1d">caligraphic_D start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> is a dataset such that for every pair <math alttext="(x,y)\in\mathcal{D}" class="ltx_Math" display="inline" id="S2.SS1.p5.2.m2.2"><semantics id="S2.SS1.p5.2.m2.2a"><mrow id="S2.SS1.p5.2.m2.2.3" xref="S2.SS1.p5.2.m2.2.3.cmml"><mrow id="S2.SS1.p5.2.m2.2.3.2.2" xref="S2.SS1.p5.2.m2.2.3.2.1.cmml"><mo id="S2.SS1.p5.2.m2.2.3.2.2.1" stretchy="false" xref="S2.SS1.p5.2.m2.2.3.2.1.cmml">(</mo><mi id="S2.SS1.p5.2.m2.1.1" xref="S2.SS1.p5.2.m2.1.1.cmml">x</mi><mo id="S2.SS1.p5.2.m2.2.3.2.2.2" xref="S2.SS1.p5.2.m2.2.3.2.1.cmml">,</mo><mi id="S2.SS1.p5.2.m2.2.2" xref="S2.SS1.p5.2.m2.2.2.cmml">y</mi><mo id="S2.SS1.p5.2.m2.2.3.2.2.3" stretchy="false" xref="S2.SS1.p5.2.m2.2.3.2.1.cmml">)</mo></mrow><mo id="S2.SS1.p5.2.m2.2.3.1" xref="S2.SS1.p5.2.m2.2.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p5.2.m2.2.3.3" xref="S2.SS1.p5.2.m2.2.3.3.cmml">𝒟</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.2.m2.2b"><apply id="S2.SS1.p5.2.m2.2.3.cmml" xref="S2.SS1.p5.2.m2.2.3"><in id="S2.SS1.p5.2.m2.2.3.1.cmml" xref="S2.SS1.p5.2.m2.2.3.1"></in><interval closure="open" id="S2.SS1.p5.2.m2.2.3.2.1.cmml" xref="S2.SS1.p5.2.m2.2.3.2.2"><ci id="S2.SS1.p5.2.m2.1.1.cmml" xref="S2.SS1.p5.2.m2.1.1">𝑥</ci><ci id="S2.SS1.p5.2.m2.2.2.cmml" xref="S2.SS1.p5.2.m2.2.2">𝑦</ci></interval><ci id="S2.SS1.p5.2.m2.2.3.3.cmml" xref="S2.SS1.p5.2.m2.2.3.3">𝒟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.2.m2.2c">(x,y)\in\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p5.2.m2.2d">( italic_x , italic_y ) ∈ caligraphic_D</annotation></semantics></math>, there exists a pair <math alttext="(x,\bm{\delta}_{y})\in\mathcal{D}^{\prime}" class="ltx_Math" display="inline" id="S2.SS1.p5.3.m3.2"><semantics id="S2.SS1.p5.3.m3.2a"><mrow id="S2.SS1.p5.3.m3.2.2" xref="S2.SS1.p5.3.m3.2.2.cmml"><mrow id="S2.SS1.p5.3.m3.2.2.1.1" xref="S2.SS1.p5.3.m3.2.2.1.2.cmml"><mo id="S2.SS1.p5.3.m3.2.2.1.1.2" stretchy="false" xref="S2.SS1.p5.3.m3.2.2.1.2.cmml">(</mo><mi id="S2.SS1.p5.3.m3.1.1" xref="S2.SS1.p5.3.m3.1.1.cmml">x</mi><mo id="S2.SS1.p5.3.m3.2.2.1.1.3" xref="S2.SS1.p5.3.m3.2.2.1.2.cmml">,</mo><msub id="S2.SS1.p5.3.m3.2.2.1.1.1" xref="S2.SS1.p5.3.m3.2.2.1.1.1.cmml"><mi id="S2.SS1.p5.3.m3.2.2.1.1.1.2" xref="S2.SS1.p5.3.m3.2.2.1.1.1.2.cmml">𝜹</mi><mi id="S2.SS1.p5.3.m3.2.2.1.1.1.3" xref="S2.SS1.p5.3.m3.2.2.1.1.1.3.cmml">y</mi></msub><mo id="S2.SS1.p5.3.m3.2.2.1.1.4" stretchy="false" xref="S2.SS1.p5.3.m3.2.2.1.2.cmml">)</mo></mrow><mo id="S2.SS1.p5.3.m3.2.2.2" xref="S2.SS1.p5.3.m3.2.2.2.cmml">∈</mo><msup id="S2.SS1.p5.3.m3.2.2.3" xref="S2.SS1.p5.3.m3.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p5.3.m3.2.2.3.2" xref="S2.SS1.p5.3.m3.2.2.3.2.cmml">𝒟</mi><mo id="S2.SS1.p5.3.m3.2.2.3.3" xref="S2.SS1.p5.3.m3.2.2.3.3.cmml">′</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.3.m3.2b"><apply id="S2.SS1.p5.3.m3.2.2.cmml" xref="S2.SS1.p5.3.m3.2.2"><in id="S2.SS1.p5.3.m3.2.2.2.cmml" xref="S2.SS1.p5.3.m3.2.2.2"></in><interval closure="open" id="S2.SS1.p5.3.m3.2.2.1.2.cmml" xref="S2.SS1.p5.3.m3.2.2.1.1"><ci id="S2.SS1.p5.3.m3.1.1.cmml" xref="S2.SS1.p5.3.m3.1.1">𝑥</ci><apply id="S2.SS1.p5.3.m3.2.2.1.1.1.cmml" xref="S2.SS1.p5.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p5.3.m3.2.2.1.1.1.1.cmml" xref="S2.SS1.p5.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S2.SS1.p5.3.m3.2.2.1.1.1.2.cmml" xref="S2.SS1.p5.3.m3.2.2.1.1.1.2">𝜹</ci><ci id="S2.SS1.p5.3.m3.2.2.1.1.1.3.cmml" xref="S2.SS1.p5.3.m3.2.2.1.1.1.3">𝑦</ci></apply></interval><apply id="S2.SS1.p5.3.m3.2.2.3.cmml" xref="S2.SS1.p5.3.m3.2.2.3"><csymbol cd="ambiguous" id="S2.SS1.p5.3.m3.2.2.3.1.cmml" xref="S2.SS1.p5.3.m3.2.2.3">superscript</csymbol><ci id="S2.SS1.p5.3.m3.2.2.3.2.cmml" xref="S2.SS1.p5.3.m3.2.2.3.2">𝒟</ci><ci id="S2.SS1.p5.3.m3.2.2.3.3.cmml" xref="S2.SS1.p5.3.m3.2.2.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.3.m3.2c">(x,\bm{\delta}_{y})\in\mathcal{D}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p5.3.m3.2d">( italic_x , bold_italic_δ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ) ∈ caligraphic_D start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>, then we say that <math alttext="\mathcal{D}^{\prime}" class="ltx_Math" display="inline" id="S2.SS1.p5.4.m4.1"><semantics id="S2.SS1.p5.4.m4.1a"><msup id="S2.SS1.p5.4.m4.1.1" xref="S2.SS1.p5.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p5.4.m4.1.1.2" xref="S2.SS1.p5.4.m4.1.1.2.cmml">𝒟</mi><mo id="S2.SS1.p5.4.m4.1.1.3" xref="S2.SS1.p5.4.m4.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.4.m4.1b"><apply id="S2.SS1.p5.4.m4.1.1.cmml" xref="S2.SS1.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.p5.4.m4.1.1.1.cmml" xref="S2.SS1.p5.4.m4.1.1">superscript</csymbol><ci id="S2.SS1.p5.4.m4.1.1.2.cmml" xref="S2.SS1.p5.4.m4.1.1.2">𝒟</ci><ci id="S2.SS1.p5.4.m4.1.1.3.cmml" xref="S2.SS1.p5.4.m4.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.4.m4.1c">\mathcal{D}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p5.4.m4.1d">caligraphic_D start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> is an <span class="ltx_text ltx_font_italic" id="S2.SS1.p5.5.1">edit sequence re-factoring</span> of <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S2.SS1.p5.5.m5.1"><semantics id="S2.SS1.p5.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p5.5.m5.1.1" xref="S2.SS1.p5.5.m5.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.5.m5.1b"><ci id="S2.SS1.p5.5.m5.1.1.cmml" xref="S2.SS1.p5.5.m5.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.5.m5.1c">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p5.5.m5.1d">caligraphic_D</annotation></semantics></math>.</p>
</div>
<figure class="ltx_figure" id="S2.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="105" id="S2.F3.g1" src="extracted/5927317/template/figures/data_stats_viz_v3.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span class="ltx_text ltx_font_bold" id="S2.F3.4.1">Empirics of processing code data with LintSeq</span>. Left: Lines per example in a dataset of instruction finetuning data for Python synthesis before and after processing with LintSeq via the linter <span class="ltx_text ltx_font_typewriter" id="S2.F3.5.2">pylint</span> (see Section <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS2" title="3.2 Generating a Synthetic Dataset with LintSeq ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">3.2</span></a>). LintSeq processing adds lines of <span class="ltx_text ltx_font_typewriter" id="S2.F3.6.3">diff</span> metadata to examples (see Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A1" title="Appendix A More on Edit Sequences and Diffs ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">A</span></a>). Right: The corresponding edit counts per synthetic code edit sequence. On a dataset of short programs (14 lines of code, on average), the mean LintSeq edit sequence contains four edits. </figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Generating Linter-Guided Synthetic Edit Sequences</h3>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.7">Recall from above that a single program edit computed by the <span class="ltx_text ltx_font_typewriter" id="S2.SS2.p1.7.1">diff</span> operator <math alttext="\Delta(\cdot,\cdot)" class="ltx_Math" display="inline" id="S2.SS2.p1.1.m1.2"><semantics id="S2.SS2.p1.1.m1.2a"><mrow id="S2.SS2.p1.1.m1.2.3" xref="S2.SS2.p1.1.m1.2.3.cmml"><mi id="S2.SS2.p1.1.m1.2.3.2" mathvariant="normal" xref="S2.SS2.p1.1.m1.2.3.2.cmml">Δ</mi><mo id="S2.SS2.p1.1.m1.2.3.1" xref="S2.SS2.p1.1.m1.2.3.1.cmml">⁢</mo><mrow id="S2.SS2.p1.1.m1.2.3.3.2" xref="S2.SS2.p1.1.m1.2.3.3.1.cmml"><mo id="S2.SS2.p1.1.m1.2.3.3.2.1" stretchy="false" xref="S2.SS2.p1.1.m1.2.3.3.1.cmml">(</mo><mo id="S2.SS2.p1.1.m1.1.1" lspace="0em" rspace="0em" xref="S2.SS2.p1.1.m1.1.1.cmml">⋅</mo><mo id="S2.SS2.p1.1.m1.2.3.3.2.2" rspace="0em" xref="S2.SS2.p1.1.m1.2.3.3.1.cmml">,</mo><mo id="S2.SS2.p1.1.m1.2.2" lspace="0em" rspace="0em" xref="S2.SS2.p1.1.m1.2.2.cmml">⋅</mo><mo id="S2.SS2.p1.1.m1.2.3.3.2.3" stretchy="false" xref="S2.SS2.p1.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.2b"><apply id="S2.SS2.p1.1.m1.2.3.cmml" xref="S2.SS2.p1.1.m1.2.3"><times id="S2.SS2.p1.1.m1.2.3.1.cmml" xref="S2.SS2.p1.1.m1.2.3.1"></times><ci id="S2.SS2.p1.1.m1.2.3.2.cmml" xref="S2.SS2.p1.1.m1.2.3.2">Δ</ci><interval closure="open" id="S2.SS2.p1.1.m1.2.3.3.1.cmml" xref="S2.SS2.p1.1.m1.2.3.3.2"><ci id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">⋅</ci><ci id="S2.SS2.p1.1.m1.2.2.cmml" xref="S2.SS2.p1.1.m1.2.2">⋅</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.2c">\Delta(\cdot,\cdot)</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.1.m1.2d">roman_Δ ( ⋅ , ⋅ )</annotation></semantics></math> can consist of any number of deletions and insertions. LintSeq is an algorithm for computing edit sequence re-factorings <math alttext="\mathcal{D^{\prime}}" class="ltx_Math" display="inline" id="S2.SS2.p1.2.m2.1"><semantics id="S2.SS2.p1.2.m2.1a"><msup id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.2.m2.1.1.2" xref="S2.SS2.p1.2.m2.1.1.2.cmml">𝒟</mi><mo id="S2.SS2.p1.2.m2.1.1.3" xref="S2.SS2.p1.2.m2.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><apply id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.1.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S2.SS2.p1.2.m2.1.1.2.cmml" xref="S2.SS2.p1.2.m2.1.1.2">𝒟</ci><ci id="S2.SS2.p1.2.m2.1.1.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">\mathcal{D^{\prime}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.2.m2.1d">caligraphic_D start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> such that all data <math alttext="(x,\bm{\delta}_{y})\in\mathcal{D^{\prime}}" class="ltx_Math" display="inline" id="S2.SS2.p1.3.m3.2"><semantics id="S2.SS2.p1.3.m3.2a"><mrow id="S2.SS2.p1.3.m3.2.2" xref="S2.SS2.p1.3.m3.2.2.cmml"><mrow id="S2.SS2.p1.3.m3.2.2.1.1" xref="S2.SS2.p1.3.m3.2.2.1.2.cmml"><mo id="S2.SS2.p1.3.m3.2.2.1.1.2" stretchy="false" xref="S2.SS2.p1.3.m3.2.2.1.2.cmml">(</mo><mi id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml">x</mi><mo id="S2.SS2.p1.3.m3.2.2.1.1.3" xref="S2.SS2.p1.3.m3.2.2.1.2.cmml">,</mo><msub id="S2.SS2.p1.3.m3.2.2.1.1.1" xref="S2.SS2.p1.3.m3.2.2.1.1.1.cmml"><mi id="S2.SS2.p1.3.m3.2.2.1.1.1.2" xref="S2.SS2.p1.3.m3.2.2.1.1.1.2.cmml">𝜹</mi><mi id="S2.SS2.p1.3.m3.2.2.1.1.1.3" xref="S2.SS2.p1.3.m3.2.2.1.1.1.3.cmml">y</mi></msub><mo id="S2.SS2.p1.3.m3.2.2.1.1.4" stretchy="false" xref="S2.SS2.p1.3.m3.2.2.1.2.cmml">)</mo></mrow><mo id="S2.SS2.p1.3.m3.2.2.2" xref="S2.SS2.p1.3.m3.2.2.2.cmml">∈</mo><msup id="S2.SS2.p1.3.m3.2.2.3" xref="S2.SS2.p1.3.m3.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.3.m3.2.2.3.2" xref="S2.SS2.p1.3.m3.2.2.3.2.cmml">𝒟</mi><mo id="S2.SS2.p1.3.m3.2.2.3.3" xref="S2.SS2.p1.3.m3.2.2.3.3.cmml">′</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.2b"><apply id="S2.SS2.p1.3.m3.2.2.cmml" xref="S2.SS2.p1.3.m3.2.2"><in id="S2.SS2.p1.3.m3.2.2.2.cmml" xref="S2.SS2.p1.3.m3.2.2.2"></in><interval closure="open" id="S2.SS2.p1.3.m3.2.2.1.2.cmml" xref="S2.SS2.p1.3.m3.2.2.1.1"><ci id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">𝑥</ci><apply id="S2.SS2.p1.3.m3.2.2.1.1.1.cmml" xref="S2.SS2.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.2.2.1.1.1.1.cmml" xref="S2.SS2.p1.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S2.SS2.p1.3.m3.2.2.1.1.1.2.cmml" xref="S2.SS2.p1.3.m3.2.2.1.1.1.2">𝜹</ci><ci id="S2.SS2.p1.3.m3.2.2.1.1.1.3.cmml" xref="S2.SS2.p1.3.m3.2.2.1.1.1.3">𝑦</ci></apply></interval><apply id="S2.SS2.p1.3.m3.2.2.3.cmml" xref="S2.SS2.p1.3.m3.2.2.3"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.2.2.3.1.cmml" xref="S2.SS2.p1.3.m3.2.2.3">superscript</csymbol><ci id="S2.SS2.p1.3.m3.2.2.3.2.cmml" xref="S2.SS2.p1.3.m3.2.2.3.2">𝒟</ci><ci id="S2.SS2.p1.3.m3.2.2.3.3.cmml" xref="S2.SS2.p1.3.m3.2.2.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.2c">(x,\bm{\delta}_{y})\in\mathcal{D^{\prime}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.3.m3.2d">( italic_x , bold_italic_δ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ) ∈ caligraphic_D start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> have a particular property: every edit in <math alttext="\bm{\delta}_{y}" class="ltx_Math" display="inline" id="S2.SS2.p1.4.m4.1"><semantics id="S2.SS2.p1.4.m4.1a"><msub id="S2.SS2.p1.4.m4.1.1" xref="S2.SS2.p1.4.m4.1.1.cmml"><mi id="S2.SS2.p1.4.m4.1.1.2" xref="S2.SS2.p1.4.m4.1.1.2.cmml">𝜹</mi><mi id="S2.SS2.p1.4.m4.1.1.3" xref="S2.SS2.p1.4.m4.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.1b"><apply id="S2.SS2.p1.4.m4.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.4.m4.1.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS2.p1.4.m4.1.1.2.cmml" xref="S2.SS2.p1.4.m4.1.1.2">𝜹</ci><ci id="S2.SS2.p1.4.m4.1.1.3.cmml" xref="S2.SS2.p1.4.m4.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.1c">\bm{\delta}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.4.m4.1d">bold_italic_δ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math> consists of <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.7.2">insertions only</span>. There are two phases in LintSeq: a backward sampling phase that is used to compute program state sequences <math alttext="\bm{\sigma}_{y}" class="ltx_Math" display="inline" id="S2.SS2.p1.5.m5.1"><semantics id="S2.SS2.p1.5.m5.1a"><msub id="S2.SS2.p1.5.m5.1.1" xref="S2.SS2.p1.5.m5.1.1.cmml"><mi id="S2.SS2.p1.5.m5.1.1.2" xref="S2.SS2.p1.5.m5.1.1.2.cmml">𝝈</mi><mi id="S2.SS2.p1.5.m5.1.1.3" xref="S2.SS2.p1.5.m5.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m5.1b"><apply id="S2.SS2.p1.5.m5.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.5.m5.1.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS2.p1.5.m5.1.1.2.cmml" xref="S2.SS2.p1.5.m5.1.1.2">𝝈</ci><ci id="S2.SS2.p1.5.m5.1.1.3.cmml" xref="S2.SS2.p1.5.m5.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m5.1c">\bm{\sigma}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.5.m5.1d">bold_italic_σ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math>, and a forward edit sequence computation phase that is used to re-express <math alttext="\bm{\sigma}_{y}" class="ltx_Math" display="inline" id="S2.SS2.p1.6.m6.1"><semantics id="S2.SS2.p1.6.m6.1a"><msub id="S2.SS2.p1.6.m6.1.1" xref="S2.SS2.p1.6.m6.1.1.cmml"><mi id="S2.SS2.p1.6.m6.1.1.2" xref="S2.SS2.p1.6.m6.1.1.2.cmml">𝝈</mi><mi id="S2.SS2.p1.6.m6.1.1.3" xref="S2.SS2.p1.6.m6.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.6.m6.1b"><apply id="S2.SS2.p1.6.m6.1.1.cmml" xref="S2.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.6.m6.1.1.1.cmml" xref="S2.SS2.p1.6.m6.1.1">subscript</csymbol><ci id="S2.SS2.p1.6.m6.1.1.2.cmml" xref="S2.SS2.p1.6.m6.1.1.2">𝝈</ci><ci id="S2.SS2.p1.6.m6.1.1.3.cmml" xref="S2.SS2.p1.6.m6.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.6.m6.1c">\bm{\sigma}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.6.m6.1d">bold_italic_σ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math> as edit sequences <math alttext="\bm{\delta}_{y}" class="ltx_Math" display="inline" id="S2.SS2.p1.7.m7.1"><semantics id="S2.SS2.p1.7.m7.1a"><msub id="S2.SS2.p1.7.m7.1.1" xref="S2.SS2.p1.7.m7.1.1.cmml"><mi id="S2.SS2.p1.7.m7.1.1.2" xref="S2.SS2.p1.7.m7.1.1.2.cmml">𝜹</mi><mi id="S2.SS2.p1.7.m7.1.1.3" xref="S2.SS2.p1.7.m7.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.7.m7.1b"><apply id="S2.SS2.p1.7.m7.1.1.cmml" xref="S2.SS2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.7.m7.1.1.1.cmml" xref="S2.SS2.p1.7.m7.1.1">subscript</csymbol><ci id="S2.SS2.p1.7.m7.1.1.2.cmml" xref="S2.SS2.p1.7.m7.1.1.2">𝜹</ci><ci id="S2.SS2.p1.7.m7.1.1.3.cmml" xref="S2.SS2.p1.7.m7.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.7.m7.1c">\bm{\delta}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.7.m7.1d">bold_italic_δ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math>. An illustration of these phases is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S2.F2" title="Figure 2 ‣ 2 LintSeq: Code Synthesis as a Sequential Edit Problem ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">2</span></a>. Full examples of edit sequences generated with LintSeq are provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A5" title="Appendix E More on Synthetic Data Generation with LintSeq ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">E</span></a> (Figures <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A5.F9" title="Figure 9 ‣ E.1 Examples of Generated Synthetic Edit Trajectories ‣ Appendix E More on Synthetic Data Generation with LintSeq ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">9</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A5.F10" title="Figure 10 ‣ E.1 Examples of Generated Synthetic Edit Trajectories ‣ Appendix E More on Synthetic Data Generation with LintSeq ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">10</span></a>).</p>
</div>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Phase I: Backward Sampling</h5>
<div class="ltx_para ltx_noindent" id="S2.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px1.p1.9">In the backward sampling phase of LintSeq, for each of the <math alttext="N" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.1.m1.1"><semantics id="S2.SS2.SSS0.Px1.p1.1.m1.1a"><mi id="S2.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.1.m1.1b"><ci id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.1.m1.1d">italic_N</annotation></semantics></math> pairs <math alttext="(x,y)\in\mathcal{D}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.2.m2.2"><semantics id="S2.SS2.SSS0.Px1.p1.2.m2.2a"><mrow id="S2.SS2.SSS0.Px1.p1.2.m2.2.3" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.cmml"><mrow id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.2" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.1.cmml"><mo id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.2.1" stretchy="false" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.1.cmml">(</mo><mi id="S2.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">x</mi><mo id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.2.2" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.1.cmml">,</mo><mi id="S2.SS2.SSS0.Px1.p1.2.m2.2.2" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.2.cmml">y</mi><mo id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.2.3" stretchy="false" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.1.cmml">)</mo></mrow><mo id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.1" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.cmml">𝒟</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.2.m2.2b"><apply id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3"><in id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.1"></in><interval closure="open" id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.2.2"><ci id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1">𝑥</ci><ci id="S2.SS2.SSS0.Px1.p1.2.m2.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.2">𝑦</ci></interval><ci id="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.2.3.3">𝒟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.2.m2.2c">(x,y)\in\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.2.m2.2d">( italic_x , italic_y ) ∈ caligraphic_D</annotation></semantics></math>, we generate <math alttext="s" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.3.m3.1"><semantics id="S2.SS2.SSS0.Px1.p1.3.m3.1a"><mi id="S2.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.3.m3.1b"><ci id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.3.m3.1c">s</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.3.m3.1d">italic_s</annotation></semantics></math> sequences of intermediate program states <math alttext="\bm{\sigma}_{y}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.4.m4.1"><semantics id="S2.SS2.SSS0.Px1.p1.4.m4.1a"><msub id="S2.SS2.SSS0.Px1.p1.4.m4.1.1" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.2" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.2.cmml">𝝈</mi><mi id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.3" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.4.m4.1b"><apply id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.2">𝝈</ci><ci id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.4.m4.1c">\bm{\sigma}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.4.m4.1d">bold_italic_σ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math> that begin with the empty program and terminate at the original program <math alttext="y" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.5.m5.1"><semantics id="S2.SS2.SSS0.Px1.p1.5.m5.1a"><mi id="S2.SS2.SSS0.Px1.p1.5.m5.1.1" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.5.m5.1b"><ci id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.5.m5.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.5.m5.1d">italic_y</annotation></semantics></math>. These sequences are generated in reverse or backwards using a simple procedure that we dub <span class="ltx_text ltx_font_italic" id="S2.SS2.SSS0.Px1.p1.9.1">linter-guided sampling</span>. Starting with the program <math alttext="y" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.6.m6.1"><semantics id="S2.SS2.SSS0.Px1.p1.6.m6.1a"><mi id="S2.SS2.SSS0.Px1.p1.6.m6.1.1" xref="S2.SS2.SSS0.Px1.p1.6.m6.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.6.m6.1b"><ci id="S2.SS2.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.6.m6.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.6.m6.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.6.m6.1d">italic_y</annotation></semantics></math>, we sequentially generate each predecessor program in <math alttext="\bm{\sigma}_{y}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.7.m7.1"><semantics id="S2.SS2.SSS0.Px1.p1.7.m7.1a"><msub id="S2.SS2.SSS0.Px1.p1.7.m7.1.1" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.2" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1.2.cmml">𝝈</mi><mi id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.3" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.7.m7.1b"><apply id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1.2">𝝈</ci><ci id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.7.m7.1c">\bm{\sigma}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.7.m7.1d">bold_italic_σ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math> from its successor by following these steps: (1) delete a line from the current program by sampling uniformly at random; (2) run a linter or other verifier on the remaining code; (3) if the deletion induced new errors, remove all affected lines; and (4) repeat steps 2 and 3 until no errors are caught by the linter. We repeat these steps until all lines have been removed from the original program <math alttext="y" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.8.m8.1"><semantics id="S2.SS2.SSS0.Px1.p1.8.m8.1a"><mi id="S2.SS2.SSS0.Px1.p1.8.m8.1.1" xref="S2.SS2.SSS0.Px1.p1.8.m8.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.8.m8.1b"><ci id="S2.SS2.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.8.m8.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.8.m8.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.8.m8.1d">italic_y</annotation></semantics></math>, at which point <math alttext="\bm{\sigma}_{y}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.9.m9.1"><semantics id="S2.SS2.SSS0.Px1.p1.9.m9.1a"><msub id="S2.SS2.SSS0.Px1.p1.9.m9.1.1" xref="S2.SS2.SSS0.Px1.p1.9.m9.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p1.9.m9.1.1.2" xref="S2.SS2.SSS0.Px1.p1.9.m9.1.1.2.cmml">𝝈</mi><mi id="S2.SS2.SSS0.Px1.p1.9.m9.1.1.3" xref="S2.SS2.SSS0.Px1.p1.9.m9.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.9.m9.1b"><apply id="S2.SS2.SSS0.Px1.p1.9.m9.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.9.m9.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m9.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.9.m9.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m9.1.1.2">𝝈</ci><ci id="S2.SS2.SSS0.Px1.p1.9.m9.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m9.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.9.m9.1c">\bm{\sigma}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.9.m9.1d">bold_italic_σ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math> has been generated.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Phase II: Forward Edit Computation</h5>
<div class="ltx_para ltx_noindent" id="S2.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px2.p1.13">Once <math alttext="s" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.1.m1.1"><semantics id="S2.SS2.SSS0.Px2.p1.1.m1.1a"><mi id="S2.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.1.m1.1b"><ci id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.1.m1.1c">s</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.1.m1.1d">italic_s</annotation></semantics></math> program state sequences <math alttext="\bm{\sigma}_{y}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.2.m2.1"><semantics id="S2.SS2.SSS0.Px2.p1.2.m2.1a"><msub id="S2.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p1.2.m2.1.1.2" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml">𝝈</mi><mi id="S2.SS2.SSS0.Px2.p1.2.m2.1.1.3" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.2.m2.1b"><apply id="S2.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1.2">𝝈</ci><ci id="S2.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.2.m2.1c">\bm{\sigma}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.2.m2.1d">bold_italic_σ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math> have been generated for each <math alttext="(x,y)\in\mathcal{D}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.3.m3.2"><semantics id="S2.SS2.SSS0.Px2.p1.3.m3.2a"><mrow id="S2.SS2.SSS0.Px2.p1.3.m3.2.3" xref="S2.SS2.SSS0.Px2.p1.3.m3.2.3.cmml"><mrow id="S2.SS2.SSS0.Px2.p1.3.m3.2.3.2.2" xref="S2.SS2.SSS0.Px2.p1.3.m3.2.3.2.1.cmml"><mo id="S2.SS2.SSS0.Px2.p1.3.m3.2.3.2.2.1" stretchy="false" xref="S2.SS2.SSS0.Px2.p1.3.m3.2.3.2.1.cmml">(</mo><mi id="S2.SS2.SSS0.Px2.p1.3.m3.1.1" xref="S2.SS2.SSS0.Px2.p1.3.m3.1.1.cmml">x</mi><mo id="S2.SS2.SSS0.Px2.p1.3.m3.2.3.2.2.2" xref="S2.SS2.SSS0.Px2.p1.3.m3.2.3.2.1.cmml">,</mo><mi id="S2.SS2.SSS0.Px2.p1.3.m3.2.2" xref="S2.SS2.SSS0.Px2.p1.3.m3.2.2.cmml">y</mi><mo id="S2.SS2.SSS0.Px2.p1.3.m3.2.3.2.2.3" stretchy="false" xref="S2.SS2.SSS0.Px2.p1.3.m3.2.3.2.1.cmml">)</mo></mrow><mo id="S2.SS2.SSS0.Px2.p1.3.m3.2.3.1" xref="S2.SS2.SSS0.Px2.p1.3.m3.2.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px2.p1.3.m3.2.3.3" xref="S2.SS2.SSS0.Px2.p1.3.m3.2.3.3.cmml">𝒟</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.3.m3.2b"><apply id="S2.SS2.SSS0.Px2.p1.3.m3.2.3.cmml" xref="S2.SS2.SSS0.Px2.p1.3.m3.2.3"><in id="S2.SS2.SSS0.Px2.p1.3.m3.2.3.1.cmml" xref="S2.SS2.SSS0.Px2.p1.3.m3.2.3.1"></in><interval closure="open" id="S2.SS2.SSS0.Px2.p1.3.m3.2.3.2.1.cmml" xref="S2.SS2.SSS0.Px2.p1.3.m3.2.3.2.2"><ci id="S2.SS2.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.3.m3.1.1">𝑥</ci><ci id="S2.SS2.SSS0.Px2.p1.3.m3.2.2.cmml" xref="S2.SS2.SSS0.Px2.p1.3.m3.2.2">𝑦</ci></interval><ci id="S2.SS2.SSS0.Px2.p1.3.m3.2.3.3.cmml" xref="S2.SS2.SSS0.Px2.p1.3.m3.2.3.3">𝒟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.3.m3.2c">(x,y)\in\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.3.m3.2d">( italic_x , italic_y ) ∈ caligraphic_D</annotation></semantics></math>, we run the forward edit computation phase of our algorithm. In this phase, we apply Equation <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S2.E2" title="In 2.1 Reparameterizing Code Datasets with Edits ‣ 2 LintSeq: Code Synthesis as a Sequential Edit Problem ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">2</span></a> from above to compute an edit sequence <math alttext="\bm{\delta}_{y}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.4.m4.1"><semantics id="S2.SS2.SSS0.Px2.p1.4.m4.1a"><msub id="S2.SS2.SSS0.Px2.p1.4.m4.1.1" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p1.4.m4.1.1.2" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.1.2.cmml">𝜹</mi><mi id="S2.SS2.SSS0.Px2.p1.4.m4.1.1.3" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.4.m4.1b"><apply id="S2.SS2.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.4.m4.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.4.m4.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.1.2">𝜹</ci><ci id="S2.SS2.SSS0.Px2.p1.4.m4.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.4.m4.1c">\bm{\delta}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.4.m4.1d">bold_italic_δ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math> for each <math alttext="\bm{\sigma}_{y}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.5.m5.1"><semantics id="S2.SS2.SSS0.Px2.p1.5.m5.1a"><msub id="S2.SS2.SSS0.Px2.p1.5.m5.1.1" xref="S2.SS2.SSS0.Px2.p1.5.m5.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p1.5.m5.1.1.2" xref="S2.SS2.SSS0.Px2.p1.5.m5.1.1.2.cmml">𝝈</mi><mi id="S2.SS2.SSS0.Px2.p1.5.m5.1.1.3" xref="S2.SS2.SSS0.Px2.p1.5.m5.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.5.m5.1b"><apply id="S2.SS2.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.5.m5.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.5.m5.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.5.m5.1.1.2">𝝈</ci><ci id="S2.SS2.SSS0.Px2.p1.5.m5.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.5.m5.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.5.m5.1c">\bm{\sigma}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.5.m5.1d">bold_italic_σ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math>. Starting from the last program that was added to <math alttext="\bm{\sigma}_{y}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.6.m6.1"><semantics id="S2.SS2.SSS0.Px2.p1.6.m6.1a"><msub id="S2.SS2.SSS0.Px2.p1.6.m6.1.1" xref="S2.SS2.SSS0.Px2.p1.6.m6.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p1.6.m6.1.1.2" xref="S2.SS2.SSS0.Px2.p1.6.m6.1.1.2.cmml">𝝈</mi><mi id="S2.SS2.SSS0.Px2.p1.6.m6.1.1.3" xref="S2.SS2.SSS0.Px2.p1.6.m6.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.6.m6.1b"><apply id="S2.SS2.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.6.m6.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.6.m6.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.6.m6.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.6.m6.1.1.2">𝝈</ci><ci id="S2.SS2.SSS0.Px2.p1.6.m6.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.6.m6.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.6.m6.1c">\bm{\sigma}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.6.m6.1d">bold_italic_σ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math>, we use the <span class="ltx_text ltx_font_typewriter" id="S2.SS2.SSS0.Px2.p1.13.1">diff</span> operator to compute edits between each pair of consecutive programs in <math alttext="\bm{\sigma}_{y}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.7.m7.1"><semantics id="S2.SS2.SSS0.Px2.p1.7.m7.1a"><msub id="S2.SS2.SSS0.Px2.p1.7.m7.1.1" xref="S2.SS2.SSS0.Px2.p1.7.m7.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p1.7.m7.1.1.2" xref="S2.SS2.SSS0.Px2.p1.7.m7.1.1.2.cmml">𝝈</mi><mi id="S2.SS2.SSS0.Px2.p1.7.m7.1.1.3" xref="S2.SS2.SSS0.Px2.p1.7.m7.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.7.m7.1b"><apply id="S2.SS2.SSS0.Px2.p1.7.m7.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.7.m7.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.7.m7.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.7.m7.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.7.m7.1.1.2">𝝈</ci><ci id="S2.SS2.SSS0.Px2.p1.7.m7.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.7.m7.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.7.m7.1c">\bm{\sigma}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.7.m7.1d">bold_italic_σ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math> up to the original program <math alttext="y" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.8.m8.1"><semantics id="S2.SS2.SSS0.Px2.p1.8.m8.1a"><mi id="S2.SS2.SSS0.Px2.p1.8.m8.1.1" xref="S2.SS2.SSS0.Px2.p1.8.m8.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.8.m8.1b"><ci id="S2.SS2.SSS0.Px2.p1.8.m8.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.8.m8.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.8.m8.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.8.m8.1d">italic_y</annotation></semantics></math>. Finally, we pair each edit sequence <math alttext="\bm{\delta}_{y}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.9.m9.1"><semantics id="S2.SS2.SSS0.Px2.p1.9.m9.1a"><msub id="S2.SS2.SSS0.Px2.p1.9.m9.1.1" xref="S2.SS2.SSS0.Px2.p1.9.m9.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p1.9.m9.1.1.2" xref="S2.SS2.SSS0.Px2.p1.9.m9.1.1.2.cmml">𝜹</mi><mi id="S2.SS2.SSS0.Px2.p1.9.m9.1.1.3" xref="S2.SS2.SSS0.Px2.p1.9.m9.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.9.m9.1b"><apply id="S2.SS2.SSS0.Px2.p1.9.m9.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.9.m9.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.9.m9.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.9.m9.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.9.m9.1.1.2">𝜹</ci><ci id="S2.SS2.SSS0.Px2.p1.9.m9.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.9.m9.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.9.m9.1c">\bm{\delta}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.9.m9.1d">bold_italic_δ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math> with its instruction <math alttext="x" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.10.m10.1"><semantics id="S2.SS2.SSS0.Px2.p1.10.m10.1a"><mi id="S2.SS2.SSS0.Px2.p1.10.m10.1.1" xref="S2.SS2.SSS0.Px2.p1.10.m10.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.10.m10.1b"><ci id="S2.SS2.SSS0.Px2.p1.10.m10.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.10.m10.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.10.m10.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.10.m10.1d">italic_x</annotation></semantics></math> (if present) to yield an edit sequence re-factoring <math alttext="\mathcal{D}^{\prime}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.11.m11.1"><semantics id="S2.SS2.SSS0.Px2.p1.11.m11.1a"><msup id="S2.SS2.SSS0.Px2.p1.11.m11.1.1" xref="S2.SS2.SSS0.Px2.p1.11.m11.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px2.p1.11.m11.1.1.2" xref="S2.SS2.SSS0.Px2.p1.11.m11.1.1.2.cmml">𝒟</mi><mo id="S2.SS2.SSS0.Px2.p1.11.m11.1.1.3" xref="S2.SS2.SSS0.Px2.p1.11.m11.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.11.m11.1b"><apply id="S2.SS2.SSS0.Px2.p1.11.m11.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.11.m11.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.11.m11.1.1">superscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.11.m11.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.11.m11.1.1.2">𝒟</ci><ci id="S2.SS2.SSS0.Px2.p1.11.m11.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.11.m11.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.11.m11.1c">\mathcal{D}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.11.m11.1d">caligraphic_D start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> of <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.12.m12.1"><semantics id="S2.SS2.SSS0.Px2.p1.12.m12.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px2.p1.12.m12.1.1" xref="S2.SS2.SSS0.Px2.p1.12.m12.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.12.m12.1b"><ci id="S2.SS2.SSS0.Px2.p1.12.m12.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.12.m12.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.12.m12.1c">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.12.m12.1d">caligraphic_D</annotation></semantics></math> with size <math alttext="sN" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.13.m13.1"><semantics id="S2.SS2.SSS0.Px2.p1.13.m13.1a"><mrow id="S2.SS2.SSS0.Px2.p1.13.m13.1.1" xref="S2.SS2.SSS0.Px2.p1.13.m13.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p1.13.m13.1.1.2" xref="S2.SS2.SSS0.Px2.p1.13.m13.1.1.2.cmml">s</mi><mo id="S2.SS2.SSS0.Px2.p1.13.m13.1.1.1" xref="S2.SS2.SSS0.Px2.p1.13.m13.1.1.1.cmml">⁢</mo><mi id="S2.SS2.SSS0.Px2.p1.13.m13.1.1.3" xref="S2.SS2.SSS0.Px2.p1.13.m13.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.13.m13.1b"><apply id="S2.SS2.SSS0.Px2.p1.13.m13.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.13.m13.1.1"><times id="S2.SS2.SSS0.Px2.p1.13.m13.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.13.m13.1.1.1"></times><ci id="S2.SS2.SSS0.Px2.p1.13.m13.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.13.m13.1.1.2">𝑠</ci><ci id="S2.SS2.SSS0.Px2.p1.13.m13.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.13.m13.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.13.m13.1c">sN</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.13.m13.1d">italic_s italic_N</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Properties of LintSeq Data</h3>
<div class="ltx_para ltx_noindent" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.14">Synthetic edit sequences generated by LintSeq have a few other important properties. Let <math alttext="\bm{\delta}_{y}" class="ltx_Math" display="inline" id="S2.SS3.p1.1.m1.1"><semantics id="S2.SS3.p1.1.m1.1a"><msub id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml"><mi id="S2.SS3.p1.1.m1.1.1.2" xref="S2.SS3.p1.1.m1.1.1.2.cmml">𝜹</mi><mi id="S2.SS3.p1.1.m1.1.1.3" xref="S2.SS3.p1.1.m1.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b"><apply id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.1.m1.1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS3.p1.1.m1.1.1.2.cmml" xref="S2.SS3.p1.1.m1.1.1.2">𝜹</ci><ci id="S2.SS3.p1.1.m1.1.1.3.cmml" xref="S2.SS3.p1.1.m1.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">\bm{\delta}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.1.m1.1d">bold_italic_δ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math> be an arbitrary <math alttext="j" class="ltx_Math" display="inline" id="S2.SS3.p1.2.m2.1"><semantics id="S2.SS3.p1.2.m2.1a"><mi id="S2.SS3.p1.2.m2.1.1" xref="S2.SS3.p1.2.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.1b"><ci id="S2.SS3.p1.2.m2.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.1c">j</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.2.m2.1d">italic_j</annotation></semantics></math>-length edit sequence in <math alttext="\mathcal{D}^{\prime}" class="ltx_Math" display="inline" id="S2.SS3.p1.3.m3.1"><semantics id="S2.SS3.p1.3.m3.1a"><msup id="S2.SS3.p1.3.m3.1.1" xref="S2.SS3.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p1.3.m3.1.1.2" xref="S2.SS3.p1.3.m3.1.1.2.cmml">𝒟</mi><mo id="S2.SS3.p1.3.m3.1.1.3" xref="S2.SS3.p1.3.m3.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.3.m3.1b"><apply id="S2.SS3.p1.3.m3.1.1.cmml" xref="S2.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.3.m3.1.1.1.cmml" xref="S2.SS3.p1.3.m3.1.1">superscript</csymbol><ci id="S2.SS3.p1.3.m3.1.1.2.cmml" xref="S2.SS3.p1.3.m3.1.1.2">𝒟</ci><ci id="S2.SS3.p1.3.m3.1.1.3.cmml" xref="S2.SS3.p1.3.m3.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.3.m3.1c">\mathcal{D}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.3.m3.1d">caligraphic_D start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> generated with LintSeq, <math alttext="\bm{\delta}_{y}=(\Delta(\varepsilon,y_{1}),\dots,\Delta(y_{j-1},y))" class="ltx_Math" display="inline" id="S2.SS3.p1.4.m4.5"><semantics id="S2.SS3.p1.4.m4.5a"><mrow id="S2.SS3.p1.4.m4.5.5" xref="S2.SS3.p1.4.m4.5.5.cmml"><msub id="S2.SS3.p1.4.m4.5.5.4" xref="S2.SS3.p1.4.m4.5.5.4.cmml"><mi id="S2.SS3.p1.4.m4.5.5.4.2" xref="S2.SS3.p1.4.m4.5.5.4.2.cmml">𝜹</mi><mi id="S2.SS3.p1.4.m4.5.5.4.3" xref="S2.SS3.p1.4.m4.5.5.4.3.cmml">y</mi></msub><mo id="S2.SS3.p1.4.m4.5.5.3" xref="S2.SS3.p1.4.m4.5.5.3.cmml">=</mo><mrow id="S2.SS3.p1.4.m4.5.5.2.2" xref="S2.SS3.p1.4.m4.5.5.2.3.cmml"><mo id="S2.SS3.p1.4.m4.5.5.2.2.3" stretchy="false" xref="S2.SS3.p1.4.m4.5.5.2.3.cmml">(</mo><mrow id="S2.SS3.p1.4.m4.4.4.1.1.1" xref="S2.SS3.p1.4.m4.4.4.1.1.1.cmml"><mi id="S2.SS3.p1.4.m4.4.4.1.1.1.3" mathvariant="normal" xref="S2.SS3.p1.4.m4.4.4.1.1.1.3.cmml">Δ</mi><mo id="S2.SS3.p1.4.m4.4.4.1.1.1.2" xref="S2.SS3.p1.4.m4.4.4.1.1.1.2.cmml">⁢</mo><mrow id="S2.SS3.p1.4.m4.4.4.1.1.1.1.1" xref="S2.SS3.p1.4.m4.4.4.1.1.1.1.2.cmml"><mo id="S2.SS3.p1.4.m4.4.4.1.1.1.1.1.2" stretchy="false" xref="S2.SS3.p1.4.m4.4.4.1.1.1.1.2.cmml">(</mo><mi id="S2.SS3.p1.4.m4.1.1" xref="S2.SS3.p1.4.m4.1.1.cmml">ε</mi><mo id="S2.SS3.p1.4.m4.4.4.1.1.1.1.1.3" xref="S2.SS3.p1.4.m4.4.4.1.1.1.1.2.cmml">,</mo><msub id="S2.SS3.p1.4.m4.4.4.1.1.1.1.1.1" xref="S2.SS3.p1.4.m4.4.4.1.1.1.1.1.1.cmml"><mi id="S2.SS3.p1.4.m4.4.4.1.1.1.1.1.1.2" xref="S2.SS3.p1.4.m4.4.4.1.1.1.1.1.1.2.cmml">y</mi><mn id="S2.SS3.p1.4.m4.4.4.1.1.1.1.1.1.3" xref="S2.SS3.p1.4.m4.4.4.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS3.p1.4.m4.4.4.1.1.1.1.1.4" stretchy="false" xref="S2.SS3.p1.4.m4.4.4.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.SS3.p1.4.m4.5.5.2.2.4" xref="S2.SS3.p1.4.m4.5.5.2.3.cmml">,</mo><mi id="S2.SS3.p1.4.m4.3.3" mathvariant="normal" xref="S2.SS3.p1.4.m4.3.3.cmml">…</mi><mo id="S2.SS3.p1.4.m4.5.5.2.2.5" xref="S2.SS3.p1.4.m4.5.5.2.3.cmml">,</mo><mrow id="S2.SS3.p1.4.m4.5.5.2.2.2" xref="S2.SS3.p1.4.m4.5.5.2.2.2.cmml"><mi id="S2.SS3.p1.4.m4.5.5.2.2.2.3" mathvariant="normal" xref="S2.SS3.p1.4.m4.5.5.2.2.2.3.cmml">Δ</mi><mo id="S2.SS3.p1.4.m4.5.5.2.2.2.2" xref="S2.SS3.p1.4.m4.5.5.2.2.2.2.cmml">⁢</mo><mrow id="S2.SS3.p1.4.m4.5.5.2.2.2.1.1" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.2.cmml"><mo id="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.2" stretchy="false" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.2.cmml">(</mo><msub id="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.cmml"><mi id="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.2" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.2.cmml">y</mi><mrow id="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.3" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.3.cmml"><mi id="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.3.2" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.3.2.cmml">j</mi><mo id="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.3.1" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.3.1.cmml">−</mo><mn id="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.3.3" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.3" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.2.cmml">,</mo><mi id="S2.SS3.p1.4.m4.2.2" xref="S2.SS3.p1.4.m4.2.2.cmml">y</mi><mo id="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.4" stretchy="false" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.2.cmml">)</mo></mrow></mrow><mo id="S2.SS3.p1.4.m4.5.5.2.2.6" stretchy="false" xref="S2.SS3.p1.4.m4.5.5.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.4.m4.5b"><apply id="S2.SS3.p1.4.m4.5.5.cmml" xref="S2.SS3.p1.4.m4.5.5"><eq id="S2.SS3.p1.4.m4.5.5.3.cmml" xref="S2.SS3.p1.4.m4.5.5.3"></eq><apply id="S2.SS3.p1.4.m4.5.5.4.cmml" xref="S2.SS3.p1.4.m4.5.5.4"><csymbol cd="ambiguous" id="S2.SS3.p1.4.m4.5.5.4.1.cmml" xref="S2.SS3.p1.4.m4.5.5.4">subscript</csymbol><ci id="S2.SS3.p1.4.m4.5.5.4.2.cmml" xref="S2.SS3.p1.4.m4.5.5.4.2">𝜹</ci><ci id="S2.SS3.p1.4.m4.5.5.4.3.cmml" xref="S2.SS3.p1.4.m4.5.5.4.3">𝑦</ci></apply><vector id="S2.SS3.p1.4.m4.5.5.2.3.cmml" xref="S2.SS3.p1.4.m4.5.5.2.2"><apply id="S2.SS3.p1.4.m4.4.4.1.1.1.cmml" xref="S2.SS3.p1.4.m4.4.4.1.1.1"><times id="S2.SS3.p1.4.m4.4.4.1.1.1.2.cmml" xref="S2.SS3.p1.4.m4.4.4.1.1.1.2"></times><ci id="S2.SS3.p1.4.m4.4.4.1.1.1.3.cmml" xref="S2.SS3.p1.4.m4.4.4.1.1.1.3">Δ</ci><interval closure="open" id="S2.SS3.p1.4.m4.4.4.1.1.1.1.2.cmml" xref="S2.SS3.p1.4.m4.4.4.1.1.1.1.1"><ci id="S2.SS3.p1.4.m4.1.1.cmml" xref="S2.SS3.p1.4.m4.1.1">𝜀</ci><apply id="S2.SS3.p1.4.m4.4.4.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.4.m4.4.4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.4.m4.4.4.1.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.4.m4.4.4.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS3.p1.4.m4.4.4.1.1.1.1.1.1.2.cmml" xref="S2.SS3.p1.4.m4.4.4.1.1.1.1.1.1.2">𝑦</ci><cn id="S2.SS3.p1.4.m4.4.4.1.1.1.1.1.1.3.cmml" type="integer" xref="S2.SS3.p1.4.m4.4.4.1.1.1.1.1.1.3">1</cn></apply></interval></apply><ci id="S2.SS3.p1.4.m4.3.3.cmml" xref="S2.SS3.p1.4.m4.3.3">…</ci><apply id="S2.SS3.p1.4.m4.5.5.2.2.2.cmml" xref="S2.SS3.p1.4.m4.5.5.2.2.2"><times id="S2.SS3.p1.4.m4.5.5.2.2.2.2.cmml" xref="S2.SS3.p1.4.m4.5.5.2.2.2.2"></times><ci id="S2.SS3.p1.4.m4.5.5.2.2.2.3.cmml" xref="S2.SS3.p1.4.m4.5.5.2.2.2.3">Δ</ci><interval closure="open" id="S2.SS3.p1.4.m4.5.5.2.2.2.1.2.cmml" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.1"><apply id="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.cmml" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.1.cmml" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1">subscript</csymbol><ci id="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.2.cmml" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.2">𝑦</ci><apply id="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.3.cmml" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.3"><minus id="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.3.1.cmml" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.3.1"></minus><ci id="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.3.2.cmml" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.3.2">𝑗</ci><cn id="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.3.3.cmml" type="integer" xref="S2.SS3.p1.4.m4.5.5.2.2.2.1.1.1.3.3">1</cn></apply></apply><ci id="S2.SS3.p1.4.m4.2.2.cmml" xref="S2.SS3.p1.4.m4.2.2">𝑦</ci></interval></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.4.m4.5c">\bm{\delta}_{y}=(\Delta(\varepsilon,y_{1}),\dots,\Delta(y_{j-1},y))</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.4.m4.5d">bold_italic_δ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT = ( roman_Δ ( italic_ε , italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , … , roman_Δ ( italic_y start_POSTSUBSCRIPT italic_j - 1 end_POSTSUBSCRIPT , italic_y ) )</annotation></semantics></math>. First, we observe that there is a simple correspondence between <math alttext="\bm{\delta}_{y}" class="ltx_Math" display="inline" id="S2.SS3.p1.5.m5.1"><semantics id="S2.SS3.p1.5.m5.1a"><msub id="S2.SS3.p1.5.m5.1.1" xref="S2.SS3.p1.5.m5.1.1.cmml"><mi id="S2.SS3.p1.5.m5.1.1.2" xref="S2.SS3.p1.5.m5.1.1.2.cmml">𝜹</mi><mi id="S2.SS3.p1.5.m5.1.1.3" xref="S2.SS3.p1.5.m5.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.5.m5.1b"><apply id="S2.SS3.p1.5.m5.1.1.cmml" xref="S2.SS3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.5.m5.1.1.1.cmml" xref="S2.SS3.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS3.p1.5.m5.1.1.2.cmml" xref="S2.SS3.p1.5.m5.1.1.2">𝜹</ci><ci id="S2.SS3.p1.5.m5.1.1.3.cmml" xref="S2.SS3.p1.5.m5.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.5.m5.1c">\bm{\delta}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.5.m5.1d">bold_italic_δ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math> and the original program <math alttext="y" class="ltx_Math" display="inline" id="S2.SS3.p1.6.m6.1"><semantics id="S2.SS3.p1.6.m6.1a"><mi id="S2.SS3.p1.6.m6.1.1" xref="S2.SS3.p1.6.m6.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.6.m6.1b"><ci id="S2.SS3.p1.6.m6.1.1.cmml" xref="S2.SS3.p1.6.m6.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.6.m6.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.6.m6.1d">italic_y</annotation></semantics></math> used to generate it: <math alttext="y" class="ltx_Math" display="inline" id="S2.SS3.p1.7.m7.1"><semantics id="S2.SS3.p1.7.m7.1a"><mi id="S2.SS3.p1.7.m7.1.1" xref="S2.SS3.p1.7.m7.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.7.m7.1b"><ci id="S2.SS3.p1.7.m7.1.1.cmml" xref="S2.SS3.p1.7.m7.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.7.m7.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.7.m7.1d">italic_y</annotation></semantics></math> can be re-constructed by starting with an empty program, and successively applying each edit in <math alttext="\bm{\delta}_{y}" class="ltx_Math" display="inline" id="S2.SS3.p1.8.m8.1"><semantics id="S2.SS3.p1.8.m8.1a"><msub id="S2.SS3.p1.8.m8.1.1" xref="S2.SS3.p1.8.m8.1.1.cmml"><mi id="S2.SS3.p1.8.m8.1.1.2" xref="S2.SS3.p1.8.m8.1.1.2.cmml">𝜹</mi><mi id="S2.SS3.p1.8.m8.1.1.3" xref="S2.SS3.p1.8.m8.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.8.m8.1b"><apply id="S2.SS3.p1.8.m8.1.1.cmml" xref="S2.SS3.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.8.m8.1.1.1.cmml" xref="S2.SS3.p1.8.m8.1.1">subscript</csymbol><ci id="S2.SS3.p1.8.m8.1.1.2.cmml" xref="S2.SS3.p1.8.m8.1.1.2">𝜹</ci><ci id="S2.SS3.p1.8.m8.1.1.3.cmml" xref="S2.SS3.p1.8.m8.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.8.m8.1c">\bm{\delta}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.8.m8.1d">bold_italic_δ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math> to this program one-by-one. In other words, the edit sequence <math alttext="\bm{\delta}_{y}" class="ltx_Math" display="inline" id="S2.SS3.p1.9.m9.1"><semantics id="S2.SS3.p1.9.m9.1a"><msub id="S2.SS3.p1.9.m9.1.1" xref="S2.SS3.p1.9.m9.1.1.cmml"><mi id="S2.SS3.p1.9.m9.1.1.2" xref="S2.SS3.p1.9.m9.1.1.2.cmml">𝜹</mi><mi id="S2.SS3.p1.9.m9.1.1.3" xref="S2.SS3.p1.9.m9.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.9.m9.1b"><apply id="S2.SS3.p1.9.m9.1.1.cmml" xref="S2.SS3.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.9.m9.1.1.1.cmml" xref="S2.SS3.p1.9.m9.1.1">subscript</csymbol><ci id="S2.SS3.p1.9.m9.1.1.2.cmml" xref="S2.SS3.p1.9.m9.1.1.2">𝜹</ci><ci id="S2.SS3.p1.9.m9.1.1.3.cmml" xref="S2.SS3.p1.9.m9.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.9.m9.1c">\bm{\delta}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.9.m9.1d">bold_italic_δ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.10.1">resolves to <math alttext="y" class="ltx_Math" display="inline" id="S2.SS3.p1.10.1.m1.1"><semantics id="S2.SS3.p1.10.1.m1.1a"><mi id="S2.SS3.p1.10.1.m1.1.1" xref="S2.SS3.p1.10.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.10.1.m1.1b"><ci id="S2.SS3.p1.10.1.m1.1.1.cmml" xref="S2.SS3.p1.10.1.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.10.1.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.10.1.m1.1d">italic_y</annotation></semantics></math></span>. Furthermore, by construction, every prefix subsequence of <math alttext="\bm{\delta}_{y}" class="ltx_Math" display="inline" id="S2.SS3.p1.11.m10.1"><semantics id="S2.SS3.p1.11.m10.1a"><msub id="S2.SS3.p1.11.m10.1.1" xref="S2.SS3.p1.11.m10.1.1.cmml"><mi id="S2.SS3.p1.11.m10.1.1.2" xref="S2.SS3.p1.11.m10.1.1.2.cmml">𝜹</mi><mi id="S2.SS3.p1.11.m10.1.1.3" xref="S2.SS3.p1.11.m10.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.11.m10.1b"><apply id="S2.SS3.p1.11.m10.1.1.cmml" xref="S2.SS3.p1.11.m10.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.11.m10.1.1.1.cmml" xref="S2.SS3.p1.11.m10.1.1">subscript</csymbol><ci id="S2.SS3.p1.11.m10.1.1.2.cmml" xref="S2.SS3.p1.11.m10.1.1.2">𝜹</ci><ci id="S2.SS3.p1.11.m10.1.1.3.cmml" xref="S2.SS3.p1.11.m10.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.11.m10.1c">\bm{\delta}_{y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.11.m10.1d">bold_italic_δ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT</annotation></semantics></math> resolves to a sub-program of <math alttext="y" class="ltx_Math" display="inline" id="S2.SS3.p1.12.m11.1"><semantics id="S2.SS3.p1.12.m11.1a"><mi id="S2.SS3.p1.12.m11.1.1" xref="S2.SS3.p1.12.m11.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.12.m11.1b"><ci id="S2.SS3.p1.12.m11.1.1.cmml" xref="S2.SS3.p1.12.m11.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.12.m11.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.12.m11.1d">italic_y</annotation></semantics></math> that is error-free, i.e. that throws no errors when checked with the linter or the verifier used during generation. These two properties, in conjunction with the uniform sampling step used in the first phase of the algorithm, show that LintSeq samples <math alttext="s" class="ltx_Math" display="inline" id="S2.SS3.p1.13.m12.1"><semantics id="S2.SS3.p1.13.m12.1a"><mi id="S2.SS3.p1.13.m12.1.1" xref="S2.SS3.p1.13.m12.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.13.m12.1b"><ci id="S2.SS3.p1.13.m12.1.1.cmml" xref="S2.SS3.p1.13.m12.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.13.m12.1c">s</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.13.m12.1d">italic_s</annotation></semantics></math> examples across all possible static error-free sequences of line insertions that can be used to sequentially write a program <math alttext="y" class="ltx_Math" display="inline" id="S2.SS3.p1.14.m13.1"><semantics id="S2.SS3.p1.14.m13.1a"><mi id="S2.SS3.p1.14.m13.1.1" xref="S2.SS3.p1.14.m13.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.14.m13.1b"><ci id="S2.SS3.p1.14.m13.1.1.cmml" xref="S2.SS3.p1.14.m13.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.14.m13.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.14.m13.1d">italic_y</annotation></semantics></math> from-scratch.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">We show an example of program synthesis dataset statistics before and after LintSeq processing in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S2.F3" title="Figure 3 ‣ 2.1 Reparameterizing Code Datasets with Edits ‣ 2 LintSeq: Code Synthesis as a Sequential Edit Problem ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">3</span></a>. In the worst case, re-expressing a program as an edit sequence increases the length of a training example by a token count that is constant in the number of program lines (Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A1" title="Appendix A More on Edit Sequences and Diffs ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">A</span></a>).</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Practicalities of Training Language Models on LintSeq Data</h3>
<div class="ltx_para ltx_noindent" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">LintSeq can be run on any code data. It is agnostic to the contents of a program, and only depends on knowledge of the programming language that a file is written in and the existence of a linter or another kind of verifier for written program files.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS4.p2">
<p class="ltx_p" id="S2.SS4.p2.1">We use teacher-forced supervised learning <cite class="ltx_cite ltx_citemacro_citep">(Williams &amp; Zipser, <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib50" title="">1989</a>)</cite> to train models on LintSeq data, concatenating edit sequences into a single string by interleaving edits with special tokens, “<span class="ltx_text ltx_font_typewriter" id="S2.SS4.p2.1.1">&lt;|diff|&gt;</span>,” and computing instruction-conditioned losses over the resultant sequences. During inference, finetuned models can be prompted to synthesize programs with edit sequences by appending these special tokens to the ends of prompts. More details are provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A1" title="Appendix A More on Edit Sequences and Diffs ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS4.p3">
<p class="ltx_p" id="S2.SS4.p3.5">Synthetic data generation with LintSeq is controlled by a single hyperparameter: the number of edit sequences <math alttext="s" class="ltx_Math" display="inline" id="S2.SS4.p3.1.m1.1"><semantics id="S2.SS4.p3.1.m1.1a"><mi id="S2.SS4.p3.1.m1.1.1" xref="S2.SS4.p3.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p3.1.m1.1b"><ci id="S2.SS4.p3.1.m1.1.1.cmml" xref="S2.SS4.p3.1.m1.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p3.1.m1.1c">s</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p3.1.m1.1d">italic_s</annotation></semantics></math> that are sampled for each example in the source code dataset <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S2.SS4.p3.2.m2.1"><semantics id="S2.SS4.p3.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p3.2.m2.1.1" xref="S2.SS4.p3.2.m2.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p3.2.m2.1b"><ci id="S2.SS4.p3.2.m2.1.1.cmml" xref="S2.SS4.p3.2.m2.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p3.2.m2.1c">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p3.2.m2.1d">caligraphic_D</annotation></semantics></math>. Edit sequence sampling can optionally be constrained to avoid repetitions, though this may yield a dataset <math alttext="\mathcal{D}^{\prime}" class="ltx_Math" display="inline" id="S2.SS4.p3.3.m3.1"><semantics id="S2.SS4.p3.3.m3.1a"><msup id="S2.SS4.p3.3.m3.1.1" xref="S2.SS4.p3.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p3.3.m3.1.1.2" xref="S2.SS4.p3.3.m3.1.1.2.cmml">𝒟</mi><mo id="S2.SS4.p3.3.m3.1.1.3" xref="S2.SS4.p3.3.m3.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS4.p3.3.m3.1b"><apply id="S2.SS4.p3.3.m3.1.1.cmml" xref="S2.SS4.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS4.p3.3.m3.1.1.1.cmml" xref="S2.SS4.p3.3.m3.1.1">superscript</csymbol><ci id="S2.SS4.p3.3.m3.1.1.2.cmml" xref="S2.SS4.p3.3.m3.1.1.2">𝒟</ci><ci id="S2.SS4.p3.3.m3.1.1.3.cmml" xref="S2.SS4.p3.3.m3.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p3.3.m3.1c">\mathcal{D}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p3.3.m3.1d">caligraphic_D start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> with fewer than <math alttext="s|\mathcal{D}|" class="ltx_Math" display="inline" id="S2.SS4.p3.4.m4.1"><semantics id="S2.SS4.p3.4.m4.1a"><mrow id="S2.SS4.p3.4.m4.1.2" xref="S2.SS4.p3.4.m4.1.2.cmml"><mi id="S2.SS4.p3.4.m4.1.2.2" xref="S2.SS4.p3.4.m4.1.2.2.cmml">s</mi><mo id="S2.SS4.p3.4.m4.1.2.1" xref="S2.SS4.p3.4.m4.1.2.1.cmml">⁢</mo><mrow id="S2.SS4.p3.4.m4.1.2.3.2" xref="S2.SS4.p3.4.m4.1.2.3.1.cmml"><mo id="S2.SS4.p3.4.m4.1.2.3.2.1" stretchy="false" xref="S2.SS4.p3.4.m4.1.2.3.1.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p3.4.m4.1.1" xref="S2.SS4.p3.4.m4.1.1.cmml">𝒟</mi><mo id="S2.SS4.p3.4.m4.1.2.3.2.2" stretchy="false" xref="S2.SS4.p3.4.m4.1.2.3.1.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p3.4.m4.1b"><apply id="S2.SS4.p3.4.m4.1.2.cmml" xref="S2.SS4.p3.4.m4.1.2"><times id="S2.SS4.p3.4.m4.1.2.1.cmml" xref="S2.SS4.p3.4.m4.1.2.1"></times><ci id="S2.SS4.p3.4.m4.1.2.2.cmml" xref="S2.SS4.p3.4.m4.1.2.2">𝑠</ci><apply id="S2.SS4.p3.4.m4.1.2.3.1.cmml" xref="S2.SS4.p3.4.m4.1.2.3.2"><abs id="S2.SS4.p3.4.m4.1.2.3.1.1.cmml" xref="S2.SS4.p3.4.m4.1.2.3.2.1"></abs><ci id="S2.SS4.p3.4.m4.1.1.cmml" xref="S2.SS4.p3.4.m4.1.1">𝒟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p3.4.m4.1c">s|\mathcal{D}|</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p3.4.m4.1d">italic_s | caligraphic_D |</annotation></semantics></math> examples if there are programs in <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S2.SS4.p3.5.m5.1"><semantics id="S2.SS4.p3.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p3.5.m5.1.1" xref="S2.SS4.p3.5.m5.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p3.5.m5.1b"><ci id="S2.SS4.p3.5.m5.1.1.cmml" xref="S2.SS4.p3.5.m5.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p3.5.m5.1c">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p3.5.m5.1d">caligraphic_D</annotation></semantics></math> with no non-empty and static error-free sub-programs.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">To study LintSeq and the impact of re-parameterizing program synthesis as a sequential edit generation problem, we conduct a multi-pronged set of instruction finetuning experiments. These experiments study code synthesis in Python and are designed to answer the following questions:</p>
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1">How does finetuning tiny LMs on re-factorized code edit data generated with LintSeq impact benchmark coverage compared to finetuning on the original code data?</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">Do performance improvements hold across model scales, families, and tokenizers?</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1">How does ablating linter-guidance from LintSeq to finetune on randomly sampled edit sequences impact code synthesis?</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">Similar to previous works <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib11" title="">2021</a>)</cite>, we evaluate models by computing zero-shot coverage statistics on code synthesis benchmarks with and without repeated sampling. We expound upon our motivation for evaluating models in this manner in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A2.SS3.SSS1" title="B.3.1 Philosophy ‣ B.3 Evaluating Model Checkpoints ‣ Appendix B Evaluation ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">B.3.1</span></a>.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Pretraining Tiny LMs for Code Understanding</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We begin our investigations by pre-training two tiny decoder-only transformers, <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p1.1.1">TinyCodeLM-150M</span> and <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p1.1.2">TinyCodeLM-400M</span>, for Python code understanding on 72 billion tokens of text. Pretraining our own language models grants us a data contamination-free test-bed to study code synthesis with edit sequences, rapidly evaluate LintSeq, and broadly re-examine the trade-off between inference-time compute and generation quality in code synthesis for models that can be updated on-device.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">We rely on open-source data and libraries to pretrain our models <cite class="ltx_cite ltx_citemacro_citep">(Penedo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib31" title="">2024</a>; Lozhkov et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib26" title="">2024</a>; Soldaini et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib39" title="">2024</a>; Groeneveld et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib16" title="">2024</a>)</cite>. Our pretraining data mix is inspired by Code Llama <cite class="ltx_cite ltx_citemacro_citep">(Roziere et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib35" title="">2023</a>)</cite>, and reflects a code-skewed mixture of web text and raw Python sampled from FineWeb and TheStack, respectively <cite class="ltx_cite ltx_citemacro_citep">(Penedo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib31" title="">2024</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib22" title="">2023</a>)</cite>. The architecture of our models respectively mimics the two smallest versions of GPT-2 <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib33" title="">2019</a>)</cite>, but integrates the transformer architecture changes proposed by the OLMo framework. This includes the absence of bias terms and the addition of non-parametric layer norms <cite class="ltx_cite ltx_citemacro_citep">(Ba, <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib5" title="">2016</a>)</cite>, as well as the use of SwiGLU <cite class="ltx_cite ltx_citemacro_citep">(Shazeer, <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib37" title="">2020</a>)</cite>, rotary positional embeddings <cite class="ltx_cite ltx_citemacro_citep">(Su et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib40" title="">2024</a>)</cite>, and the GPT-NeoX-20B tokenizer <cite class="ltx_cite ltx_citemacro_citep">(Black et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib8" title="">2022</a>)</cite>. We train both models for two epochs with a batch size of 524,288 tokens on an NVIDIA H100 node with four GPUs. Our experiments are supported by Pytorch FSDP <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib53" title="">2023</a>)</cite>. More details on our pretraining procedures are in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A3" title="Appendix C Pretraining ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Generating a Synthetic Dataset with LintSeq</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Next, to support our finetuning experiments, we prepare a large “baseline” dataset of paired instruction and program data. We re-factorize the programs in this dataset into code edit sequences with LintSeq.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Summary of <span class="ltx_text ltx_font_bold" id="S3.T1.3.1">temperature-tuned coding benchmark results for LMs with <math alttext="\mathbf{\leq 0.2}" class="ltx_Math" display="inline" id="S3.T1.3.1.m1.1"><semantics id="S3.T1.3.1.m1.1b"><mrow id="S3.T1.3.1.m1.1.1" xref="S3.T1.3.1.m1.1.1.cmml"><mi id="S3.T1.3.1.m1.1.1.2" xref="S3.T1.3.1.m1.1.1.2.cmml"></mi><mo id="S3.T1.3.1.m1.1.1.1" xref="S3.T1.3.1.m1.1.1.1.cmml">≤</mo><mn class="ltx_mathvariant_bold" id="S3.T1.3.1.m1.1.1.3" mathvariant="bold" xref="S3.T1.3.1.m1.1.1.3.cmml">0.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.3.1.m1.1c"><apply id="S3.T1.3.1.m1.1.1.cmml" xref="S3.T1.3.1.m1.1.1"><leq id="S3.T1.3.1.m1.1.1.1.cmml" xref="S3.T1.3.1.m1.1.1.1"></leq><csymbol cd="latexml" id="S3.T1.3.1.m1.1.1.2.cmml" xref="S3.T1.3.1.m1.1.1.2">absent</csymbol><cn id="S3.T1.3.1.m1.1.1.3.cmml" type="float" xref="S3.T1.3.1.m1.1.1.3">0.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.1.m1.1d">\mathbf{\leq 0.2}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.1.m1.1e">≤ bold_0.2</annotation></semantics></math>B parameters</span>. Scores annotated with “(<math alttext="\dagger" class="ltx_Math" display="inline" id="S3.T1.4.m1.1"><semantics id="S3.T1.4.m1.1b"><mo id="S3.T1.4.m1.1.1" xref="S3.T1.4.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S3.T1.4.m1.1c"><ci id="S3.T1.4.m1.1.1.cmml" xref="S3.T1.4.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.m1.1d">\dagger</annotation><annotation encoding="application/x-llamapun" id="S3.T1.4.m1.1e">†</annotation></semantics></math>)” indicate external model evaluations that we ran using the procedure described in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A2" title="Appendix B Evaluation ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">B</span></a>, and all other scores are as reported by model authors. We list models in order of increasing HumanEval pass@1 score.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.7">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.7.4.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S3.T1.7.4.1.1"></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S3.T1.7.4.1.2"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S3.T1.7.4.1.3">HumanEval</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S3.T1.7.4.1.4">MBPP(+)</th>
<td class="ltx_td ltx_border_tt" id="S3.T1.7.4.1.5"></td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S3.T1.7.5.2.1">Model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.7.5.2.2">Size</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.7.5.2.3">pass@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.7.5.2.4">pass@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.7.5.2.5">pass@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.7.5.2.6">pass@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.7.5.2.7">Open-Source</th>
</tr>
<tr class="ltx_tr" id="S3.T1.7.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S3.T1.7.6.3.1">PolyCoder</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.7.6.3.2">160M</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.7.6.3.3">2.1</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.7.6.3.4">3.4</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.7.6.3.5">-</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.7.6.3.6">-</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.7.6.3.7">🌑</td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.7.7.4.1">AlphaCode</th>
<td class="ltx_td ltx_align_center" id="S3.T1.7.7.4.2">89M</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.7.4.3">4.3</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.7.4.4">12.2</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.7.4.5">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.7.4.6">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.7.4.7">🌕</td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.8.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.7.8.5.1">Codex</th>
<td class="ltx_td ltx_align_center" id="S3.T1.7.8.5.2">85M</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.8.5.3">8.2</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.8.5.4">12.8</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.8.5.5">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.8.5.6">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.8.5.7">🌕</td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.7.3.4">SmolLM-Instruct</th>
<td class="ltx_td ltx_align_center" id="S3.T1.7.3.5">135M</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.3.6">7.6</td>
<td class="ltx_td ltx_align_center" id="S3.T1.5.1.1">14.4(<math alttext="\dagger" class="ltx_Math" display="inline" id="S3.T1.5.1.1.m1.1"><semantics id="S3.T1.5.1.1.m1.1a"><mo id="S3.T1.5.1.1.m1.1.1" xref="S3.T1.5.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S3.T1.5.1.1.m1.1b"><ci id="S3.T1.5.1.1.m1.1.1.cmml" xref="S3.T1.5.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.1.1.m1.1c">\dagger</annotation><annotation encoding="application/x-llamapun" id="S3.T1.5.1.1.m1.1d">†</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.2.2">10.1(<math alttext="\dagger" class="ltx_Math" display="inline" id="S3.T1.6.2.2.m1.1"><semantics id="S3.T1.6.2.2.m1.1a"><mo id="S3.T1.6.2.2.m1.1.1" xref="S3.T1.6.2.2.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S3.T1.6.2.2.m1.1b"><ci id="S3.T1.6.2.2.m1.1.1.cmml" xref="S3.T1.6.2.2.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.2.2.m1.1c">\dagger</annotation><annotation encoding="application/x-llamapun" id="S3.T1.6.2.2.m1.1d">†</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.3.3">14.6(<math alttext="\dagger" class="ltx_Math" display="inline" id="S3.T1.7.3.3.m1.1"><semantics id="S3.T1.7.3.3.m1.1a"><mo id="S3.T1.7.3.3.m1.1.1" xref="S3.T1.7.3.3.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S3.T1.7.3.3.m1.1b"><ci id="S3.T1.7.3.3.m1.1.1.cmml" xref="S3.T1.7.3.3.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.3.3.m1.1c">\dagger</annotation><annotation encoding="application/x-llamapun" id="S3.T1.7.3.3.m1.1d">†</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.3.7">🌑</td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.9.6" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.7.9.6.1"><span class="ltx_text" id="S3.T1.7.9.6.1.1" style="background-color:#E6E6E6;">TinyCodeLM-Instruct</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.7.9.6.2"><span class="ltx_text" id="S3.T1.7.9.6.2.1" style="background-color:#E6E6E6;">150M</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.9.6.3"><span class="ltx_text" id="S3.T1.7.9.6.3.1" style="background-color:#E6E6E6;">9.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.9.6.4"><span class="ltx_text" id="S3.T1.7.9.6.4.1" style="background-color:#E6E6E6;">13.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.9.6.5"><span class="ltx_text" id="S3.T1.7.9.6.5.1" style="background-color:#E6E6E6;">11.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.9.6.6"><span class="ltx_text" id="S3.T1.7.9.6.6.1" style="background-color:#E6E6E6;">16.4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.9.6.7"><span class="ltx_text" id="S3.T1.7.9.6.7.1" style="background-color:#E6E6E6;">🌑</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.10.7" style="background-color:#DCD3FB;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T1.7.10.7.1"><span class="ltx_text" id="S3.T1.7.10.7.1.1" style="background-color:#DCD3FB;">TinyCodeLM-LintSeqInstruct</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.7.10.7.2"><span class="ltx_text" id="S3.T1.7.10.7.2.1" style="background-color:#DCD3FB;">150M</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.7.10.7.3"><span class="ltx_text" id="S3.T1.7.10.7.3.1" style="background-color:#DCD3FB;">12.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.7.10.7.4"><span class="ltx_text" id="S3.T1.7.10.7.4.1" style="background-color:#DCD3FB;">20.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.7.10.7.5"><span class="ltx_text" id="S3.T1.7.10.7.5.1" style="background-color:#DCD3FB;">13.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.7.10.7.6"><span class="ltx_text" id="S3.T1.7.10.7.6.1" style="background-color:#DCD3FB;">24.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.7.10.7.7"><span class="ltx_text" id="S3.T1.7.10.7.7.1" style="background-color:#DCD3FB;">🌑</span></td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Summary of <span class="ltx_text ltx_font_bold" id="S3.T2.4.2">temperature-tuned coding benchmark results for <math alttext="\mathbf{0.2}" class="ltx_Math" display="inline" id="S3.T2.3.1.m1.1"><semantics id="S3.T2.3.1.m1.1b"><mn class="ltx_mathvariant_bold" id="S3.T2.3.1.m1.1.1" mathvariant="bold" xref="S3.T2.3.1.m1.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S3.T2.3.1.m1.1c"><cn id="S3.T2.3.1.m1.1.1.cmml" type="float" xref="S3.T2.3.1.m1.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.1.m1.1d">\mathbf{0.2}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.3.1.m1.1e">bold_0.2</annotation></semantics></math>B to <math alttext="\mathbf{0.4}" class="ltx_Math" display="inline" id="S3.T2.4.2.m2.1"><semantics id="S3.T2.4.2.m2.1b"><mn class="ltx_mathvariant_bold" id="S3.T2.4.2.m2.1.1" mathvariant="bold" xref="S3.T2.4.2.m2.1.1.cmml">0.4</mn><annotation-xml encoding="MathML-Content" id="S3.T2.4.2.m2.1c"><cn id="S3.T2.4.2.m2.1.1.cmml" type="float" xref="S3.T2.4.2.m2.1.1">0.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.2.m2.1d">\mathbf{0.4}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.4.2.m2.1e">bold_0.4</annotation></semantics></math>B parameter language models</span>. Annotations, model order, and evaluation procedure are the same as in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.T1" title="Table 1 ‣ 3.2 Generating a Synthetic Dataset with LintSeq ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">1</span></a>.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.9">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.9.6.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S3.T2.9.6.1.1"></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S3.T2.9.6.1.2"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S3.T2.9.6.1.3">HumanEval</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S3.T2.9.6.1.4">MBPP(+)</th>
<td class="ltx_td ltx_border_tt" id="S3.T2.9.6.1.5"></td>
</tr>
<tr class="ltx_tr" id="S3.T2.9.7.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S3.T2.9.7.2.1">Model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.9.7.2.2">Size</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T2.9.7.2.3">pass@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T2.9.7.2.4">pass@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T2.9.7.2.5">pass@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T2.9.7.2.6">pass@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.9.7.2.7">Open-Source</th>
</tr>
<tr class="ltx_tr" id="S3.T2.9.8.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S3.T2.9.8.3.1">PolyCoder</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.9.8.3.2">400M</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.9.8.3.3">3.0</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.9.8.3.4">5.3</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.9.8.3.5">-</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.9.8.3.6">-</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.9.8.3.7">🌑</td>
</tr>
<tr class="ltx_tr" id="S3.T2.9.9.4" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.9.9.4.1"><span class="ltx_text" id="S3.T2.9.9.4.1.1" style="background-color:#E6E6E6;">TinyCodeLM-Instruct</span></th>
<td class="ltx_td ltx_align_center" id="S3.T2.9.9.4.2"><span class="ltx_text" id="S3.T2.9.9.4.2.1" style="background-color:#E6E6E6;">400M</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.9.4.3"><span class="ltx_text" id="S3.T2.9.9.4.3.1" style="background-color:#E6E6E6;">9.6</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.9.4.4"><span class="ltx_text" id="S3.T2.9.9.4.4.1" style="background-color:#E6E6E6;">18.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.9.4.5"><span class="ltx_text" id="S3.T2.9.9.4.5.1" style="background-color:#E6E6E6;">15.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.9.4.6"><span class="ltx_text" id="S3.T2.9.9.4.6.1" style="background-color:#E6E6E6;">22.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.9.4.7"><span class="ltx_text" id="S3.T2.9.9.4.7.1" style="background-color:#E6E6E6;">🌑</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.7.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.7.3.4">SmolLM-Instruct</th>
<td class="ltx_td ltx_align_center" id="S3.T2.7.3.5">360M</td>
<td class="ltx_td ltx_align_center" id="S3.T2.7.3.6">11.3</td>
<td class="ltx_td ltx_align_center" id="S3.T2.5.1.1">19.3(<math alttext="\dagger" class="ltx_Math" display="inline" id="S3.T2.5.1.1.m1.1"><semantics id="S3.T2.5.1.1.m1.1a"><mo id="S3.T2.5.1.1.m1.1.1" xref="S3.T2.5.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S3.T2.5.1.1.m1.1b"><ci id="S3.T2.5.1.1.m1.1.1.cmml" xref="S3.T2.5.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.1.1.m1.1c">\dagger</annotation><annotation encoding="application/x-llamapun" id="S3.T2.5.1.1.m1.1d">†</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.2.2">19.4(<math alttext="\dagger" class="ltx_Math" display="inline" id="S3.T2.6.2.2.m1.1"><semantics id="S3.T2.6.2.2.m1.1a"><mo id="S3.T2.6.2.2.m1.1.1" xref="S3.T2.6.2.2.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S3.T2.6.2.2.m1.1b"><ci id="S3.T2.6.2.2.m1.1.1.cmml" xref="S3.T2.6.2.2.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.6.2.2.m1.1c">\dagger</annotation><annotation encoding="application/x-llamapun" id="S3.T2.6.2.2.m1.1d">†</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center" id="S3.T2.7.3.3">23.1(<math alttext="\dagger" class="ltx_Math" display="inline" id="S3.T2.7.3.3.m1.1"><semantics id="S3.T2.7.3.3.m1.1a"><mo id="S3.T2.7.3.3.m1.1.1" xref="S3.T2.7.3.3.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S3.T2.7.3.3.m1.1b"><ci id="S3.T2.7.3.3.m1.1.1.cmml" xref="S3.T2.7.3.3.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.3.3.m1.1c">\dagger</annotation><annotation encoding="application/x-llamapun" id="S3.T2.7.3.3.m1.1d">†</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center" id="S3.T2.7.3.7">🌑</td>
</tr>
<tr class="ltx_tr" id="S3.T2.9.10.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.9.10.5.1">AlphaCode</th>
<td class="ltx_td ltx_align_center" id="S3.T2.9.10.5.2">302M</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.10.5.3">11.6</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.10.5.4">18.8</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.10.5.5">-</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.10.5.6">-</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.10.5.7">🌕</td>
</tr>
<tr class="ltx_tr" id="S3.T2.9.11.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.9.11.6.1">CodeT5+</th>
<td class="ltx_td ltx_align_center" id="S3.T2.9.11.6.2">220M</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.11.6.3">12.0</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.11.6.4">20.7</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.11.6.5">-</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.11.6.6">-</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.11.6.7">🌑</td>
</tr>
<tr class="ltx_tr" id="S3.T2.9.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.9.5.3">Codegen-Mono</th>
<td class="ltx_td ltx_align_center" id="S3.T2.9.5.4">350M</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.5.5">12.8</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.5.6">23.1</td>
<td class="ltx_td ltx_align_center" id="S3.T2.8.4.1">9.4(<math alttext="\dagger" class="ltx_Math" display="inline" id="S3.T2.8.4.1.m1.1"><semantics id="S3.T2.8.4.1.m1.1a"><mo id="S3.T2.8.4.1.m1.1.1" xref="S3.T2.8.4.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S3.T2.8.4.1.m1.1b"><ci id="S3.T2.8.4.1.m1.1.1.cmml" xref="S3.T2.8.4.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.4.1.m1.1c">\dagger</annotation><annotation encoding="application/x-llamapun" id="S3.T2.8.4.1.m1.1d">†</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.5.2">15.2(<math alttext="\dagger" class="ltx_Math" display="inline" id="S3.T2.9.5.2.m1.1"><semantics id="S3.T2.9.5.2.m1.1a"><mo id="S3.T2.9.5.2.m1.1.1" xref="S3.T2.9.5.2.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S3.T2.9.5.2.m1.1b"><ci id="S3.T2.9.5.2.m1.1.1.cmml" xref="S3.T2.9.5.2.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.9.5.2.m1.1c">\dagger</annotation><annotation encoding="application/x-llamapun" id="S3.T2.9.5.2.m1.1d">†</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.5.7">🌑</td>
</tr>
<tr class="ltx_tr" id="S3.T2.9.12.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.9.12.7.1">Codex</th>
<td class="ltx_td ltx_align_center" id="S3.T2.9.12.7.2">300M</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.12.7.3">13.2</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.12.7.4">20.4</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.12.7.5">-</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.12.7.6">-</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.12.7.7">🌕</td>
</tr>
<tr class="ltx_tr" id="S3.T2.9.13.8" style="background-color:#DCD3FB;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T2.9.13.8.1"><span class="ltx_text" id="S3.T2.9.13.8.1.1" style="background-color:#DCD3FB;">TinyCodeLM-LintSeqInstruct</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.9.13.8.2"><span class="ltx_text" id="S3.T2.9.13.8.2.1" style="background-color:#DCD3FB;">400M</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.9.13.8.3"><span class="ltx_text" id="S3.T2.9.13.8.3.1" style="background-color:#DCD3FB;">13.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.9.13.8.4"><span class="ltx_text" id="S3.T2.9.13.8.4.1" style="background-color:#DCD3FB;">20.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.9.13.8.5"><span class="ltx_text" id="S3.T2.9.13.8.5.1" style="background-color:#DCD3FB;">19.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.9.13.8.6"><span class="ltx_text" id="S3.T2.9.13.8.6.1" style="background-color:#DCD3FB;">29.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.9.13.8.7"><span class="ltx_text" id="S3.T2.9.13.8.7.1" style="background-color:#DCD3FB;">🌑</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">To that end, we first pool the Python portions of two open-source instruction datasets for code synthesis: the GPT 3.5/4-based Magicoder instruction tuning dataset and the StarCoder2-15B-based self-alignment training dataset <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib49" title="">2024b</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib48" title="">a</a>)</cite>. These datasets are generated with the OSS-Instruct approach by <cite class="ltx_cite ltx_citemacro_citet">Wei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib49" title="">2024b</a>)</cite> and have undergone decontamination for the benchmarks that we evaluate on in this paper. We conduct de-duplication on the pooled data to check for repeated examples. Furthermore, we strip any chain-of-thought-like natural language explanations from completion data. The resultant dataset has over 88,900 instruction-Python program pairs.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.2">With our baseline dataset prepared, we run LintSeq to generate <math alttext="s=5" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mrow id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">s</mi><mo id="S3.SS2.p3.1.m1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><eq id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1"></eq><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">𝑠</ci><cn id="S3.SS2.p3.1.m1.1.1.3.cmml" type="integer" xref="S3.SS2.p3.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">s=5</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_s = 5</annotation></semantics></math> synthetic edit trajectory samples for each instruction-program pair. As described in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S2.SS4" title="2.4 Practicalities of Training Language Models on LintSeq Data ‣ 2 LintSeq: Code Synthesis as a Sequential Edit Problem ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">2.4</span></a>, we concatenate each synthetic edit trajectory into a single string by interleaving consecutive edits with a special reserved “edit” token. Inspired by <cite class="ltx_cite ltx_citemacro_citet">Muennighoff et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib29" title="">2024</a>)</cite>, we do not restrict against edit sequence repetitions. We use the popular Python linter <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p3.2.1">pylint</span> to guide edit sampling during generation. Examples of generated edit sequences and experiments testing the effect of varying <math alttext="s" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">s</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_s</annotation></semantics></math> are in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A5" title="Appendix E More on Synthetic Data Generation with LintSeq ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">E</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Finetuning Language Models on LintSeq Edit Sequences</h3>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">We now probe the impact of instruction finetuning a variety of autoregressive LMs to synthesize code with edit sequences, compared to standard generation of full programs. We use two code synthesis benchmarks to support our model evaluations: HumanEval <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib11" title="">2021</a>)</cite> and Mostly Basic Programming Problems (MBPP) <cite class="ltx_cite ltx_citemacro_citep">(Austin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib4" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">Using both the code edit re-factorized and baseline instruction datasets obtained in section <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS2" title="3.2 Generating a Synthetic Dataset with LintSeq ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">3.2</span></a>, we run pairs of finetuning experiments with six different models. In each experiment pair, we finetune an LM on both datasets for an equal number of optimizer steps and with the same learning rate schedule, saving intermediate checkpoints throughout finetuning. We run full benchmark evaluations on HumanEval and MBPP on each saved checkpoint<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>To process the generations of edit sequence LMs into executable programs, we simply resolve each of the predicted code edits one-by-one. This procedure is visualized in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">1</span></a> and described in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A1.SS2" title="A.2 Resolving Edit Sequences ‣ Appendix A More on Edit Sequences and Diffs ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">A.2</span></a>.</span></span></span>, performing no prompt tuning. Then, we compare the best inference-time scaling behavior, i.e. benchmark coverage (pass@k) as a function of samples (k), obtained by edit sequence finetuning vs standard finetuning for each model. A more detailed description of the computed metrics as well as a full specification of the evaluation and finetuning procedures is provided in Appendices <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A2" title="Appendix B Evaluation ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">B</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A4" title="Appendix D Instruction Finetuning ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="191" id="S3.F4.g1" src="extracted/5927317/template/figures/diff_vs_raw_finetuning_agg_v8.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span class="ltx_text ltx_font_bold" id="S3.F4.6.1">HumanEval and MBPP coverage with repeated sampling</span> (“pass@k vs. k”) achieved by instruction finetuning Gemma 2, Phi-3, and Llama 3.1 language models on a dataset of LintSeq edit sequence re-factored vs standard Python code (temperature <math alttext="=1" class="ltx_Math" display="inline" id="S3.F4.3.m1.1"><semantics id="S3.F4.3.m1.1b"><mrow id="S3.F4.3.m1.1.1" xref="S3.F4.3.m1.1.1.cmml"><mi id="S3.F4.3.m1.1.1.2" xref="S3.F4.3.m1.1.1.2.cmml"></mi><mo id="S3.F4.3.m1.1.1.1" xref="S3.F4.3.m1.1.1.1.cmml">=</mo><mn id="S3.F4.3.m1.1.1.3" xref="S3.F4.3.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F4.3.m1.1c"><apply id="S3.F4.3.m1.1.1.cmml" xref="S3.F4.3.m1.1.1"><eq id="S3.F4.3.m1.1.1.1.cmml" xref="S3.F4.3.m1.1.1.1"></eq><csymbol cd="latexml" id="S3.F4.3.m1.1.1.2.cmml" xref="S3.F4.3.m1.1.1.2">absent</csymbol><cn id="S3.F4.3.m1.1.1.3.cmml" type="integer" xref="S3.F4.3.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.3.m1.1d">=1</annotation><annotation encoding="application/x-llamapun" id="S3.F4.3.m1.1e">= 1</annotation></semantics></math>, top-p <math alttext="=0.95" class="ltx_Math" display="inline" id="S3.F4.4.m2.1"><semantics id="S3.F4.4.m2.1b"><mrow id="S3.F4.4.m2.1.1" xref="S3.F4.4.m2.1.1.cmml"><mi id="S3.F4.4.m2.1.1.2" xref="S3.F4.4.m2.1.1.2.cmml"></mi><mo id="S3.F4.4.m2.1.1.1" xref="S3.F4.4.m2.1.1.1.cmml">=</mo><mn id="S3.F4.4.m2.1.1.3" xref="S3.F4.4.m2.1.1.3.cmml">0.95</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F4.4.m2.1c"><apply id="S3.F4.4.m2.1.1.cmml" xref="S3.F4.4.m2.1.1"><eq id="S3.F4.4.m2.1.1.1.cmml" xref="S3.F4.4.m2.1.1.1"></eq><csymbol cd="latexml" id="S3.F4.4.m2.1.1.2.cmml" xref="S3.F4.4.m2.1.1.2">absent</csymbol><cn id="S3.F4.4.m2.1.1.3.cmml" type="float" xref="S3.F4.4.m2.1.1.3">0.95</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.4.m2.1d">=0.95</annotation><annotation encoding="application/x-llamapun" id="S3.F4.4.m2.1e">= 0.95</annotation></semantics></math>).</figcaption>
</figure>
<section class="ltx_subsubsection" id="S3.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>TinyCodeLM</h4>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS1.p1">
<p class="ltx_p" id="S3.SS3.SSS1.p1.1">We run our first two pairs of finetuning experiments on
<span class="ltx_text ltx_font_typewriter" id="S3.SS3.SSS1.p1.1.1">TinyCodeLM-150M</span> and <span class="ltx_text ltx_font_typewriter" id="S3.SS3.SSS1.p1.1.2">TinyCodeLM-400M</span>. These models were not pretrained on code synthesis instruction data, nor were they pretrained on any “diff”-like edit data. Our experimental results are summarized in Tables <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.T1" title="Table 1 ‣ 3.2 Generating a Synthetic Dataset with LintSeq ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.T2" title="Table 2 ‣ 3.2 Generating a Synthetic Dataset with LintSeq ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">2</span></a>, where we compare the temperature-tuned performance of our models to the reported benchmark coverage of existing code LMs at similar parameter scales. We also report the inference-time scaling of benchmark coverage as a function of samples for our finetuned models in Appendix Tables <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.T8" title="Table 8 ‣ F.2.1 Inference-Time Scaling Laws ‣ F.2 Finetuning TinyCodeLM ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">8</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.T9" title="Table 9 ‣ F.2.1 Inference-Time Scaling Laws ‣ F.2 Finetuning TinyCodeLM ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS1.p2">
<p class="ltx_p" id="S3.SS3.SSS1.p2.1">For both the 150M and 400M parameter versions of TinyCodeLM, we find that finetuning LMs to synthesize code with edits via LintSeq data dramatically improves benchmark performance compared to baseline finetuning. Indeed, the edit sequence variants of TinyCodeLM outperform all existing code language models of comparable scale that we are aware of, including AlphaCode <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib24" title="">2022b</a>)</cite>, Codex <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib11" title="">2021</a>)</cite>, CodeT5+ <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib45" title="">2023b</a>)</cite>, and the recent SmolLM-Instruct <cite class="ltx_cite ltx_citemacro_citep">(Ben Allal et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib7" title="">2024</a>)</cite>. Our smaller edit sequence-finetuned model is particularly strong for its size, roughly matching or out-performing models with twice as many parameters including the 300M parameter version of Codex and the 302M-parameter version of AlphaCode (Tables <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.T1" title="Table 1 ‣ 3.2 Generating a Synthetic Dataset with LintSeq ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.T2" title="Table 2 ‣ 3.2 Generating a Synthetic Dataset with LintSeq ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Gemma 2, Phi-3, and Llama 3.1</h4>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS2.p1">
<p class="ltx_p" id="S3.SS3.SSS2.p1.1">The results above raise a natural question: do performance improvements from finetuning LMs to synthesize code with edit sequences hold for other model scales, architectures, and tokenizers? To test this, we conduct four additional pairs of instruction finetuning experiments on LMs from three model families, Gemma 2, Phi-3, and Llama 3.1, ranging in size from 2.6B to 14B. We employ pretrained-only model weights, if available. The results of these experiments are in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.F4" title="Figure 4 ‣ 3.3 Finetuning Language Models on LintSeq Edit Sequences ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">4</span></a>, where we plot zero-shot benchmark coverage as a function of samples for instruction finetuned models. Raw coverage scores are reported in Appendix Tables <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.T10" title="Table 10 ‣ F.3.1 Inference-Time Scaling Laws ‣ F.3 Finetuning Gemma 2, Phi-3, and Llama 3.1 ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">10</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.T11" title="Table 11 ‣ F.3.1 Inference-Time Scaling Laws ‣ F.3 Finetuning Gemma 2, Phi-3, and Llama 3.1 ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">11</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS2.p2">
<p class="ltx_p" id="S3.SS3.SSS2.p2.2">Most of our findings echo those of Section <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS3.SSS1" title="3.3.1 TinyCodeLM ‣ 3.3 Finetuning Language Models on LintSeq Edit Sequences ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">3.3.1</span></a>. Aggregating across sample counts, we find that finetuning models to synthesize code with edits improves overall zero-shot performance on HumanEval and MBPP compared to finetuning on the original data. This suggests that re-factoring code with edit sequences is an architecture- and tokenizer-independent mechanism for improving downstream LM outputs. Furthermore, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.F4" title="Figure 4 ‣ 3.3 Finetuning Language Models on LintSeq Edit Sequences ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">4</span></a> and Tables <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.T10" title="Table 10 ‣ F.3.1 Inference-Time Scaling Laws ‣ F.3 Finetuning Gemma 2, Phi-3, and Llama 3.1 ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">10</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.T11" title="Table 11 ‣ F.3.1 Inference-Time Scaling Laws ‣ F.3 Finetuning Gemma 2, Phi-3, and Llama 3.1 ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">11</span></a>, we find that the degree by which edit sequence LMs outperform baseline model variants increases with repeated sampling for all tested models, culminating in an average absolute gain in pass@50 of +20% (<math alttext="\pm" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p2.1.m1.1"><semantics id="S3.SS3.SSS2.p2.1.m1.1a"><mo id="S3.SS3.SSS2.p2.1.m1.1.1" xref="S3.SS3.SSS2.p2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.1.m1.1b"><csymbol cd="latexml" id="S3.SS3.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.p2.1.m1.1d">±</annotation></semantics></math> 3%) on HumanEval and +12% (<math alttext="\pm" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p2.2.m2.1"><semantics id="S3.SS3.SSS2.p2.2.m2.1a"><mo id="S3.SS3.SSS2.p2.2.m2.1.1" xref="S3.SS3.SSS2.p2.2.m2.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.2.m2.1b"><csymbol cd="latexml" id="S3.SS3.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS3.SSS2.p2.2.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.2.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.p2.2.m2.1d">±</annotation></semantics></math> 2%) on MBPP. This observation confirms the hypothesis posed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S2" title="2 LintSeq: Code Synthesis as a Sequential Edit Problem ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">2</span></a>, showing that training LMs to synthesize code with edits using LintSeq data improves the relationship between cumulative inference-time compute and zero-shot performance.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS2.p3">
<p class="ltx_p" id="S3.SS3.SSS2.p3.1">At pass@1, however, our results are slightly more mixed than in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS3.SSS1" title="3.3.1 TinyCodeLM ‣ 3.3 Finetuning Language Models on LintSeq Edit Sequences ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">3.3.1</span></a>. For Phi-3 models, we observe either no difference or a decrease in score between each pair of model-data variants. One explanation for this is bias: the Phi-3 models have been previously instruction finetuned and were likely to have been trained on standard code data, putting LM variants finetuned to generate edit sequence re-factorized code at a comparative disadvantage due to distributional shift.</p>
</div>
<figure class="ltx_figure" id="S3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="95" id="S3.F5.g1" src="extracted/5927317/template/figures/linter_ablation_v12.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>HumanEval and MBPP “pass@k vs. k” achieved by finetuning TinyCodeLM models on <span class="ltx_text ltx_font_bold" id="S3.F5.6.1">linter-guided vs randomly sampled code edit sequences</span> (temperature <math alttext="=1" class="ltx_Math" display="inline" id="S3.F5.3.m1.1"><semantics id="S3.F5.3.m1.1b"><mrow id="S3.F5.3.m1.1.1" xref="S3.F5.3.m1.1.1.cmml"><mi id="S3.F5.3.m1.1.1.2" xref="S3.F5.3.m1.1.1.2.cmml"></mi><mo id="S3.F5.3.m1.1.1.1" xref="S3.F5.3.m1.1.1.1.cmml">=</mo><mn id="S3.F5.3.m1.1.1.3" xref="S3.F5.3.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F5.3.m1.1c"><apply id="S3.F5.3.m1.1.1.cmml" xref="S3.F5.3.m1.1.1"><eq id="S3.F5.3.m1.1.1.1.cmml" xref="S3.F5.3.m1.1.1.1"></eq><csymbol cd="latexml" id="S3.F5.3.m1.1.1.2.cmml" xref="S3.F5.3.m1.1.1.2">absent</csymbol><cn id="S3.F5.3.m1.1.1.3.cmml" type="integer" xref="S3.F5.3.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F5.3.m1.1d">=1</annotation><annotation encoding="application/x-llamapun" id="S3.F5.3.m1.1e">= 1</annotation></semantics></math>, top-p <math alttext="=0.95" class="ltx_Math" display="inline" id="S3.F5.4.m2.1"><semantics id="S3.F5.4.m2.1b"><mrow id="S3.F5.4.m2.1.1" xref="S3.F5.4.m2.1.1.cmml"><mi id="S3.F5.4.m2.1.1.2" xref="S3.F5.4.m2.1.1.2.cmml"></mi><mo id="S3.F5.4.m2.1.1.1" xref="S3.F5.4.m2.1.1.1.cmml">=</mo><mn id="S3.F5.4.m2.1.1.3" xref="S3.F5.4.m2.1.1.3.cmml">0.95</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F5.4.m2.1c"><apply id="S3.F5.4.m2.1.1.cmml" xref="S3.F5.4.m2.1.1"><eq id="S3.F5.4.m2.1.1.1.cmml" xref="S3.F5.4.m2.1.1.1"></eq><csymbol cd="latexml" id="S3.F5.4.m2.1.1.2.cmml" xref="S3.F5.4.m2.1.1.2">absent</csymbol><cn id="S3.F5.4.m2.1.1.3.cmml" type="float" xref="S3.F5.4.m2.1.1.3">0.95</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F5.4.m2.1d">=0.95</annotation><annotation encoding="application/x-llamapun" id="S3.F5.4.m2.1e">= 0.95</annotation></semantics></math>).</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Ablating Linter-Guidance</h3>
<div class="ltx_para ltx_noindent" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">The backward sampling phase of LintSeq uses a linter or other verifier to group interdependent lines of a program together during edit sequence generation, ensuring that all code edits resolve to programs that are free of static errors. We conclude our experiments by testing the importance of this design choice with TinyCodeLM models.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.3">To do this, we replace the backwards procedure described in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S2.SS2" title="2.2 Generating Linter-Guided Synthetic Edit Sequences ‣ 2 LintSeq: Code Synthesis as a Sequential Edit Problem ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">2.2</span></a> with exclusively random sampling; during each step of the algorithm, we first sample the number of lines to delete from the current program uniformly at random, before sampling a set of lines with the desired count. Using this linter-ablated version of the algorithm, we generate a new synthetic edit sequence dataset with the same size as the LintSeq dataset used in all previous finetuning experiments, i.e. with <math alttext="s=5" class="ltx_Math" display="inline" id="S3.SS4.p2.1.m1.1"><semantics id="S3.SS4.p2.1.m1.1a"><mrow id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml"><mi id="S3.SS4.p2.1.m1.1.1.2" xref="S3.SS4.p2.1.m1.1.1.2.cmml">s</mi><mo id="S3.SS4.p2.1.m1.1.1.1" xref="S3.SS4.p2.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS4.p2.1.m1.1.1.3" xref="S3.SS4.p2.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><apply id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1"><eq id="S3.SS4.p2.1.m1.1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1.1"></eq><ci id="S3.SS4.p2.1.m1.1.1.2.cmml" xref="S3.SS4.p2.1.m1.1.1.2">𝑠</ci><cn id="S3.SS4.p2.1.m1.1.1.3.cmml" type="integer" xref="S3.SS4.p2.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">s=5</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.1.m1.1d">italic_s = 5</annotation></semantics></math> example sequences per sample in the source dataset. The average number of edits per example in this dataset (<math alttext="\overline{E}_{\text{RandSeqInstruct}}=3.9" class="ltx_Math" display="inline" id="S3.SS4.p2.2.m2.1"><semantics id="S3.SS4.p2.2.m2.1a"><mrow id="S3.SS4.p2.2.m2.1.1" xref="S3.SS4.p2.2.m2.1.1.cmml"><msub id="S3.SS4.p2.2.m2.1.1.2" xref="S3.SS4.p2.2.m2.1.1.2.cmml"><mover accent="true" id="S3.SS4.p2.2.m2.1.1.2.2" xref="S3.SS4.p2.2.m2.1.1.2.2.cmml"><mi id="S3.SS4.p2.2.m2.1.1.2.2.2" xref="S3.SS4.p2.2.m2.1.1.2.2.2.cmml">E</mi><mo id="S3.SS4.p2.2.m2.1.1.2.2.1" xref="S3.SS4.p2.2.m2.1.1.2.2.1.cmml">¯</mo></mover><mtext id="S3.SS4.p2.2.m2.1.1.2.3" xref="S3.SS4.p2.2.m2.1.1.2.3a.cmml">RandSeqInstruct</mtext></msub><mo id="S3.SS4.p2.2.m2.1.1.1" xref="S3.SS4.p2.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS4.p2.2.m2.1.1.3" xref="S3.SS4.p2.2.m2.1.1.3.cmml">3.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.2.m2.1b"><apply id="S3.SS4.p2.2.m2.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1"><eq id="S3.SS4.p2.2.m2.1.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1.1"></eq><apply id="S3.SS4.p2.2.m2.1.1.2.cmml" xref="S3.SS4.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p2.2.m2.1.1.2.1.cmml" xref="S3.SS4.p2.2.m2.1.1.2">subscript</csymbol><apply id="S3.SS4.p2.2.m2.1.1.2.2.cmml" xref="S3.SS4.p2.2.m2.1.1.2.2"><ci id="S3.SS4.p2.2.m2.1.1.2.2.1.cmml" xref="S3.SS4.p2.2.m2.1.1.2.2.1">¯</ci><ci id="S3.SS4.p2.2.m2.1.1.2.2.2.cmml" xref="S3.SS4.p2.2.m2.1.1.2.2.2">𝐸</ci></apply><ci id="S3.SS4.p2.2.m2.1.1.2.3a.cmml" xref="S3.SS4.p2.2.m2.1.1.2.3"><mtext id="S3.SS4.p2.2.m2.1.1.2.3.cmml" mathsize="70%" xref="S3.SS4.p2.2.m2.1.1.2.3">RandSeqInstruct</mtext></ci></apply><cn id="S3.SS4.p2.2.m2.1.1.3.cmml" type="float" xref="S3.SS4.p2.2.m2.1.1.3">3.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.2.m2.1c">\overline{E}_{\text{RandSeqInstruct}}=3.9</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.2.m2.1d">over¯ start_ARG italic_E end_ARG start_POSTSUBSCRIPT RandSeqInstruct end_POSTSUBSCRIPT = 3.9</annotation></semantics></math>) is empirically similar to its linter-guided counterpart (<math alttext="\overline{E}_{\text{LintSeqInstruct}}=3.8" class="ltx_Math" display="inline" id="S3.SS4.p2.3.m3.1"><semantics id="S3.SS4.p2.3.m3.1a"><mrow id="S3.SS4.p2.3.m3.1.1" xref="S3.SS4.p2.3.m3.1.1.cmml"><msub id="S3.SS4.p2.3.m3.1.1.2" xref="S3.SS4.p2.3.m3.1.1.2.cmml"><mover accent="true" id="S3.SS4.p2.3.m3.1.1.2.2" xref="S3.SS4.p2.3.m3.1.1.2.2.cmml"><mi id="S3.SS4.p2.3.m3.1.1.2.2.2" xref="S3.SS4.p2.3.m3.1.1.2.2.2.cmml">E</mi><mo id="S3.SS4.p2.3.m3.1.1.2.2.1" xref="S3.SS4.p2.3.m3.1.1.2.2.1.cmml">¯</mo></mover><mtext id="S3.SS4.p2.3.m3.1.1.2.3" xref="S3.SS4.p2.3.m3.1.1.2.3a.cmml">LintSeqInstruct</mtext></msub><mo id="S3.SS4.p2.3.m3.1.1.1" xref="S3.SS4.p2.3.m3.1.1.1.cmml">=</mo><mn id="S3.SS4.p2.3.m3.1.1.3" xref="S3.SS4.p2.3.m3.1.1.3.cmml">3.8</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.3.m3.1b"><apply id="S3.SS4.p2.3.m3.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1"><eq id="S3.SS4.p2.3.m3.1.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1.1"></eq><apply id="S3.SS4.p2.3.m3.1.1.2.cmml" xref="S3.SS4.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p2.3.m3.1.1.2.1.cmml" xref="S3.SS4.p2.3.m3.1.1.2">subscript</csymbol><apply id="S3.SS4.p2.3.m3.1.1.2.2.cmml" xref="S3.SS4.p2.3.m3.1.1.2.2"><ci id="S3.SS4.p2.3.m3.1.1.2.2.1.cmml" xref="S3.SS4.p2.3.m3.1.1.2.2.1">¯</ci><ci id="S3.SS4.p2.3.m3.1.1.2.2.2.cmml" xref="S3.SS4.p2.3.m3.1.1.2.2.2">𝐸</ci></apply><ci id="S3.SS4.p2.3.m3.1.1.2.3a.cmml" xref="S3.SS4.p2.3.m3.1.1.2.3"><mtext id="S3.SS4.p2.3.m3.1.1.2.3.cmml" mathsize="70%" xref="S3.SS4.p2.3.m3.1.1.2.3">LintSeqInstruct</mtext></ci></apply><cn id="S3.SS4.p2.3.m3.1.1.3.cmml" type="float" xref="S3.SS4.p2.3.m3.1.1.3">3.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.3.m3.1c">\overline{E}_{\text{LintSeqInstruct}}=3.8</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.3.m3.1d">over¯ start_ARG italic_E end_ARG start_POSTSUBSCRIPT LintSeqInstruct end_POSTSUBSCRIPT = 3.8</annotation></semantics></math>, see Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S2.F3" title="Figure 3 ‣ 2.1 Reparameterizing Code Datasets with Edits ‣ 2 LintSeq: Code Synthesis as a Sequential Edit Problem ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">3</span></a>). We employ the same procedure as the one used in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS3" title="3.3 Finetuning Language Models on LintSeq Edit Sequences ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">3.3</span></a> to instruction finetune TinyCodeLM models on the dataset of randomly sampled edit sequences.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.5">In Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.F5" title="Figure 5 ‣ 3.3.2 Gemma 2, Phi-3, and Llama 3.1 ‣ 3.3 Finetuning Language Models on LintSeq Edit Sequences ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">5</span></a>, we compare the temperature <math alttext="1" class="ltx_Math" display="inline" id="S3.SS4.p3.1.m1.1"><semantics id="S3.SS4.p3.1.m1.1a"><mn id="S3.SS4.p3.1.m1.1.1" xref="S3.SS4.p3.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.1.m1.1b"><cn id="S3.SS4.p3.1.m1.1.1.cmml" type="integer" xref="S3.SS4.p3.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.1.m1.1d">1</annotation></semantics></math> inference-time scaling laws on HumanEval and MBPP obtained by finetuning models on randomly sampled vs static error-free edit sequences. Raw model scores are also provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6" title="Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">F</span></a>, Tables <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.T8" title="Table 8 ‣ F.2.1 Inference-Time Scaling Laws ‣ F.2 Finetuning TinyCodeLM ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">8</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.T9" title="Table 9 ‣ F.2.1 Inference-Time Scaling Laws ‣ F.2 Finetuning TinyCodeLM ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">9</span></a>. Ablating linter-guidance results in a decline in benchmark coverage. On HumanEval, linter ablation reduces absolute pass@50 score on TinyCodeLM-150M (<math alttext="22.6\%\mapsto 17.7\%" class="ltx_Math" display="inline" id="S3.SS4.p3.2.m2.1"><semantics id="S3.SS4.p3.2.m2.1a"><mrow id="S3.SS4.p3.2.m2.1.1" xref="S3.SS4.p3.2.m2.1.1.cmml"><mrow id="S3.SS4.p3.2.m2.1.1.2" xref="S3.SS4.p3.2.m2.1.1.2.cmml"><mn id="S3.SS4.p3.2.m2.1.1.2.2" xref="S3.SS4.p3.2.m2.1.1.2.2.cmml">22.6</mn><mo id="S3.SS4.p3.2.m2.1.1.2.1" xref="S3.SS4.p3.2.m2.1.1.2.1.cmml">%</mo></mrow><mo id="S3.SS4.p3.2.m2.1.1.1" stretchy="false" xref="S3.SS4.p3.2.m2.1.1.1.cmml">↦</mo><mrow id="S3.SS4.p3.2.m2.1.1.3" xref="S3.SS4.p3.2.m2.1.1.3.cmml"><mn id="S3.SS4.p3.2.m2.1.1.3.2" xref="S3.SS4.p3.2.m2.1.1.3.2.cmml">17.7</mn><mo id="S3.SS4.p3.2.m2.1.1.3.1" xref="S3.SS4.p3.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.2.m2.1b"><apply id="S3.SS4.p3.2.m2.1.1.cmml" xref="S3.SS4.p3.2.m2.1.1"><csymbol cd="latexml" id="S3.SS4.p3.2.m2.1.1.1.cmml" xref="S3.SS4.p3.2.m2.1.1.1">maps-to</csymbol><apply id="S3.SS4.p3.2.m2.1.1.2.cmml" xref="S3.SS4.p3.2.m2.1.1.2"><csymbol cd="latexml" id="S3.SS4.p3.2.m2.1.1.2.1.cmml" xref="S3.SS4.p3.2.m2.1.1.2.1">percent</csymbol><cn id="S3.SS4.p3.2.m2.1.1.2.2.cmml" type="float" xref="S3.SS4.p3.2.m2.1.1.2.2">22.6</cn></apply><apply id="S3.SS4.p3.2.m2.1.1.3.cmml" xref="S3.SS4.p3.2.m2.1.1.3"><csymbol cd="latexml" id="S3.SS4.p3.2.m2.1.1.3.1.cmml" xref="S3.SS4.p3.2.m2.1.1.3.1">percent</csymbol><cn id="S3.SS4.p3.2.m2.1.1.3.2.cmml" type="float" xref="S3.SS4.p3.2.m2.1.1.3.2">17.7</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.2.m2.1c">22.6\%\mapsto 17.7\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.2.m2.1d">22.6 % ↦ 17.7 %</annotation></semantics></math>) and on TinyCodeLM-400M (<math alttext="26.8\%\mapsto 22.0\%" class="ltx_Math" display="inline" id="S3.SS4.p3.3.m3.1"><semantics id="S3.SS4.p3.3.m3.1a"><mrow id="S3.SS4.p3.3.m3.1.1" xref="S3.SS4.p3.3.m3.1.1.cmml"><mrow id="S3.SS4.p3.3.m3.1.1.2" xref="S3.SS4.p3.3.m3.1.1.2.cmml"><mn id="S3.SS4.p3.3.m3.1.1.2.2" xref="S3.SS4.p3.3.m3.1.1.2.2.cmml">26.8</mn><mo id="S3.SS4.p3.3.m3.1.1.2.1" xref="S3.SS4.p3.3.m3.1.1.2.1.cmml">%</mo></mrow><mo id="S3.SS4.p3.3.m3.1.1.1" stretchy="false" xref="S3.SS4.p3.3.m3.1.1.1.cmml">↦</mo><mrow id="S3.SS4.p3.3.m3.1.1.3" xref="S3.SS4.p3.3.m3.1.1.3.cmml"><mn id="S3.SS4.p3.3.m3.1.1.3.2" xref="S3.SS4.p3.3.m3.1.1.3.2.cmml">22.0</mn><mo id="S3.SS4.p3.3.m3.1.1.3.1" xref="S3.SS4.p3.3.m3.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.3.m3.1b"><apply id="S3.SS4.p3.3.m3.1.1.cmml" xref="S3.SS4.p3.3.m3.1.1"><csymbol cd="latexml" id="S3.SS4.p3.3.m3.1.1.1.cmml" xref="S3.SS4.p3.3.m3.1.1.1">maps-to</csymbol><apply id="S3.SS4.p3.3.m3.1.1.2.cmml" xref="S3.SS4.p3.3.m3.1.1.2"><csymbol cd="latexml" id="S3.SS4.p3.3.m3.1.1.2.1.cmml" xref="S3.SS4.p3.3.m3.1.1.2.1">percent</csymbol><cn id="S3.SS4.p3.3.m3.1.1.2.2.cmml" type="float" xref="S3.SS4.p3.3.m3.1.1.2.2">26.8</cn></apply><apply id="S3.SS4.p3.3.m3.1.1.3.cmml" xref="S3.SS4.p3.3.m3.1.1.3"><csymbol cd="latexml" id="S3.SS4.p3.3.m3.1.1.3.1.cmml" xref="S3.SS4.p3.3.m3.1.1.3.1">percent</csymbol><cn id="S3.SS4.p3.3.m3.1.1.3.2.cmml" type="float" xref="S3.SS4.p3.3.m3.1.1.3.2">22.0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.3.m3.1c">26.8\%\mapsto 22.0\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.3.m3.1d">26.8 % ↦ 22.0 %</annotation></semantics></math>). MBPP pass@50 is similarly affected, dropping for both models (<math alttext="34.5\%\to 30.2\%" class="ltx_Math" display="inline" id="S3.SS4.p3.4.m4.1"><semantics id="S3.SS4.p3.4.m4.1a"><mrow id="S3.SS4.p3.4.m4.1.1" xref="S3.SS4.p3.4.m4.1.1.cmml"><mrow id="S3.SS4.p3.4.m4.1.1.2" xref="S3.SS4.p3.4.m4.1.1.2.cmml"><mn id="S3.SS4.p3.4.m4.1.1.2.2" xref="S3.SS4.p3.4.m4.1.1.2.2.cmml">34.5</mn><mo id="S3.SS4.p3.4.m4.1.1.2.1" xref="S3.SS4.p3.4.m4.1.1.2.1.cmml">%</mo></mrow><mo id="S3.SS4.p3.4.m4.1.1.1" stretchy="false" xref="S3.SS4.p3.4.m4.1.1.1.cmml">→</mo><mrow id="S3.SS4.p3.4.m4.1.1.3" xref="S3.SS4.p3.4.m4.1.1.3.cmml"><mn id="S3.SS4.p3.4.m4.1.1.3.2" xref="S3.SS4.p3.4.m4.1.1.3.2.cmml">30.2</mn><mo id="S3.SS4.p3.4.m4.1.1.3.1" xref="S3.SS4.p3.4.m4.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.4.m4.1b"><apply id="S3.SS4.p3.4.m4.1.1.cmml" xref="S3.SS4.p3.4.m4.1.1"><ci id="S3.SS4.p3.4.m4.1.1.1.cmml" xref="S3.SS4.p3.4.m4.1.1.1">→</ci><apply id="S3.SS4.p3.4.m4.1.1.2.cmml" xref="S3.SS4.p3.4.m4.1.1.2"><csymbol cd="latexml" id="S3.SS4.p3.4.m4.1.1.2.1.cmml" xref="S3.SS4.p3.4.m4.1.1.2.1">percent</csymbol><cn id="S3.SS4.p3.4.m4.1.1.2.2.cmml" type="float" xref="S3.SS4.p3.4.m4.1.1.2.2">34.5</cn></apply><apply id="S3.SS4.p3.4.m4.1.1.3.cmml" xref="S3.SS4.p3.4.m4.1.1.3"><csymbol cd="latexml" id="S3.SS4.p3.4.m4.1.1.3.1.cmml" xref="S3.SS4.p3.4.m4.1.1.3.1">percent</csymbol><cn id="S3.SS4.p3.4.m4.1.1.3.2.cmml" type="float" xref="S3.SS4.p3.4.m4.1.1.3.2">30.2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.4.m4.1c">34.5\%\to 30.2\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.4.m4.1d">34.5 % → 30.2 %</annotation></semantics></math> and <math alttext="39.6\%\mapsto 34.5\%" class="ltx_Math" display="inline" id="S3.SS4.p3.5.m5.1"><semantics id="S3.SS4.p3.5.m5.1a"><mrow id="S3.SS4.p3.5.m5.1.1" xref="S3.SS4.p3.5.m5.1.1.cmml"><mrow id="S3.SS4.p3.5.m5.1.1.2" xref="S3.SS4.p3.5.m5.1.1.2.cmml"><mn id="S3.SS4.p3.5.m5.1.1.2.2" xref="S3.SS4.p3.5.m5.1.1.2.2.cmml">39.6</mn><mo id="S3.SS4.p3.5.m5.1.1.2.1" xref="S3.SS4.p3.5.m5.1.1.2.1.cmml">%</mo></mrow><mo id="S3.SS4.p3.5.m5.1.1.1" stretchy="false" xref="S3.SS4.p3.5.m5.1.1.1.cmml">↦</mo><mrow id="S3.SS4.p3.5.m5.1.1.3" xref="S3.SS4.p3.5.m5.1.1.3.cmml"><mn id="S3.SS4.p3.5.m5.1.1.3.2" xref="S3.SS4.p3.5.m5.1.1.3.2.cmml">34.5</mn><mo id="S3.SS4.p3.5.m5.1.1.3.1" xref="S3.SS4.p3.5.m5.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.5.m5.1b"><apply id="S3.SS4.p3.5.m5.1.1.cmml" xref="S3.SS4.p3.5.m5.1.1"><csymbol cd="latexml" id="S3.SS4.p3.5.m5.1.1.1.cmml" xref="S3.SS4.p3.5.m5.1.1.1">maps-to</csymbol><apply id="S3.SS4.p3.5.m5.1.1.2.cmml" xref="S3.SS4.p3.5.m5.1.1.2"><csymbol cd="latexml" id="S3.SS4.p3.5.m5.1.1.2.1.cmml" xref="S3.SS4.p3.5.m5.1.1.2.1">percent</csymbol><cn id="S3.SS4.p3.5.m5.1.1.2.2.cmml" type="float" xref="S3.SS4.p3.5.m5.1.1.2.2">39.6</cn></apply><apply id="S3.SS4.p3.5.m5.1.1.3.cmml" xref="S3.SS4.p3.5.m5.1.1.3"><csymbol cd="latexml" id="S3.SS4.p3.5.m5.1.1.3.1.cmml" xref="S3.SS4.p3.5.m5.1.1.3.1">percent</csymbol><cn id="S3.SS4.p3.5.m5.1.1.3.2.cmml" type="float" xref="S3.SS4.p3.5.m5.1.1.3.2">34.5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.5.m5.1c">39.6\%\mapsto 34.5\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.5.m5.1d">39.6 % ↦ 34.5 %</annotation></semantics></math>). These results suggest that the error-free nature of edits in LintSeq instruction finetuning data does indeed have a positive impact on the coding problem coverage of sampled solutions.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p4">
<p class="ltx_p" id="S3.SS4.p4.1">To conclude our analysis, we probe whether training models on error-free edit sequences also has an effect on the presence of errors in across all generated programs, aside from its positive effects on coverage. To assess this, we run the Python linter <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p4.1.1">pylint</span> over each of the synthesized programs used to compute the reported temperature <math alttext="1" class="ltx_Math" display="inline" id="S3.SS4.p4.1.m1.1"><semantics id="S3.SS4.p4.1.m1.1a"><mn id="S3.SS4.p4.1.m1.1.1" xref="S3.SS4.p4.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.1.m1.1b"><cn id="S3.SS4.p4.1.m1.1.1.cmml" type="integer" xref="S3.SS4.p4.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p4.1.m1.1d">1</annotation></semantics></math> pass@k metrics, checking code for static errors.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p5">
<p class="ltx_p" id="S3.SS4.p5.1">In Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.F6" title="Figure 6 ‣ 3.4 Ablating Linter-Guidance ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">6</span></a>, we plot the total proportions of synthesized program samples with at least one static error across finetuned model variants. On both benchmarks, LMs trained on randomly sampled edits (dark grey) appear to generate “buggy” code with much higher frequency than all other models. Furthermore, on HumanEval, we find that LintSeq models (indigo) synthesize programs with static errors at a higher frequency than baseline models (light grey), despite their higher coverage of benchmark coding problems. This additional finding suggests that model performance gains from LintSeq cannot simply be attributed to improvement in static error frequency across code – training on re-factored code must be helping models write generally better, more diverse programs.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p6">
<p class="ltx_p" id="S3.SS4.p6.1">In summary, the error-free nature of the linter-guided edits sampled in LintSeq appears to indeed be important for improving both the quality and diversity of sampled programs (Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.F5" title="Figure 5 ‣ 3.3.2 Gemma 2, Phi-3, and Llama 3.1 ‣ 3.3 Finetuning Language Models on LintSeq Edit Sequences ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">5</span></a>), as well as the overall correctness (Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.F6" title="Figure 6 ‣ 3.4 Ablating Linter-Guidance ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">6</span></a>) of code synthesized by language models trained on edit sequences.</p>
</div>
<figure class="ltx_figure" id="S3.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="98" id="S3.F6.g1" src="extracted/5927317/template/figures/code_error_rate_v5.png" width="439"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Comparing <span class="ltx_text ltx_font_bold" id="S3.F6.8.1">static error frequency in synthesized code samples</span> across baseline vs edit sequence instruction finetuned model variants (n <math alttext="=50" class="ltx_Math" display="inline" id="S3.F6.4.m1.1"><semantics id="S3.F6.4.m1.1b"><mrow id="S3.F6.4.m1.1.1" xref="S3.F6.4.m1.1.1.cmml"><mi id="S3.F6.4.m1.1.1.2" xref="S3.F6.4.m1.1.1.2.cmml"></mi><mo id="S3.F6.4.m1.1.1.1" xref="S3.F6.4.m1.1.1.1.cmml">=</mo><mn id="S3.F6.4.m1.1.1.3" xref="S3.F6.4.m1.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F6.4.m1.1c"><apply id="S3.F6.4.m1.1.1.cmml" xref="S3.F6.4.m1.1.1"><eq id="S3.F6.4.m1.1.1.1.cmml" xref="S3.F6.4.m1.1.1.1"></eq><csymbol cd="latexml" id="S3.F6.4.m1.1.1.2.cmml" xref="S3.F6.4.m1.1.1.2">absent</csymbol><cn id="S3.F6.4.m1.1.1.3.cmml" type="integer" xref="S3.F6.4.m1.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F6.4.m1.1d">=50</annotation><annotation encoding="application/x-llamapun" id="S3.F6.4.m1.1e">= 50</annotation></semantics></math>, temperature <math alttext="=1" class="ltx_Math" display="inline" id="S3.F6.5.m2.1"><semantics id="S3.F6.5.m2.1b"><mrow id="S3.F6.5.m2.1.1" xref="S3.F6.5.m2.1.1.cmml"><mi id="S3.F6.5.m2.1.1.2" xref="S3.F6.5.m2.1.1.2.cmml"></mi><mo id="S3.F6.5.m2.1.1.1" xref="S3.F6.5.m2.1.1.1.cmml">=</mo><mn id="S3.F6.5.m2.1.1.3" xref="S3.F6.5.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F6.5.m2.1c"><apply id="S3.F6.5.m2.1.1.cmml" xref="S3.F6.5.m2.1.1"><eq id="S3.F6.5.m2.1.1.1.cmml" xref="S3.F6.5.m2.1.1.1"></eq><csymbol cd="latexml" id="S3.F6.5.m2.1.1.2.cmml" xref="S3.F6.5.m2.1.1.2">absent</csymbol><cn id="S3.F6.5.m2.1.1.3.cmml" type="integer" xref="S3.F6.5.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F6.5.m2.1d">=1</annotation><annotation encoding="application/x-llamapun" id="S3.F6.5.m2.1e">= 1</annotation></semantics></math>, top-p <math alttext="=0.95" class="ltx_Math" display="inline" id="S3.F6.6.m3.1"><semantics id="S3.F6.6.m3.1b"><mrow id="S3.F6.6.m3.1.1" xref="S3.F6.6.m3.1.1.cmml"><mi id="S3.F6.6.m3.1.1.2" xref="S3.F6.6.m3.1.1.2.cmml"></mi><mo id="S3.F6.6.m3.1.1.1" xref="S3.F6.6.m3.1.1.1.cmml">=</mo><mn id="S3.F6.6.m3.1.1.3" xref="S3.F6.6.m3.1.1.3.cmml">0.95</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F6.6.m3.1c"><apply id="S3.F6.6.m3.1.1.cmml" xref="S3.F6.6.m3.1.1"><eq id="S3.F6.6.m3.1.1.1.cmml" xref="S3.F6.6.m3.1.1.1"></eq><csymbol cd="latexml" id="S3.F6.6.m3.1.1.2.cmml" xref="S3.F6.6.m3.1.1.2">absent</csymbol><cn id="S3.F6.6.m3.1.1.3.cmml" type="float" xref="S3.F6.6.m3.1.1.3">0.95</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F6.6.m3.1d">=0.95</annotation><annotation encoding="application/x-llamapun" id="S3.F6.6.m3.1e">= 0.95</annotation></semantics></math>).</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Related Work</h2>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Foundation Models for Code</h5>
<div class="ltx_para ltx_noindent" id="S4.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p1.1">Code synthesis is one of the oldest problems in computer science. Neural language model-based approaches such as Codex, AlphaCode, CodeT5+, CodeGen, StarCoder, and Code Llama have recently proven to be extremely competitive with previous methods <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib11" title="">2021</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib24" title="">2022b</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib45" title="">2023b</a>; Nijkamp et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib30" title="">2022</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib22" title="">2023</a>; Roziere et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib35" title="">2023</a>)</cite>. Today, foundation models trained on web text and code data dominate, and LLM-powered code editing tools like Github Copilot and Cursor are used by thousands of engineers every day <cite class="ltx_cite ltx_citemacro_citep">(Heaven, <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib17" title="">2024</a>)</cite>. Many general-purpose LLMs are also trained on code data. While the largest of these LLMs show strong performance on coding benchmarks, generations continue to suffer from limited meaningful output diversity, prompt sensitivity, and degrading quality on long-contexts <cite class="ltx_cite ltx_citemacro_citep">(Achiam et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib2" title="">2023</a>; Gemini Team et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib13" title="">2023</a>; Dubey et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib12" title="">2024</a>)</cite>. Smaller models also lag behind <cite class="ltx_cite ltx_citemacro_citep">(Abdin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib1" title="">2024</a>; Gemma Team et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib14" title="">2024</a>; Ben Allal et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib7" title="">2024</a>)</cite>. As of the writing of this paper, directly prompting LLMs to generate code “diffs” results in low quality edits across models <cite class="ltx_cite ltx_citemacro_citep">(Sanger, <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib36" title="">2024</a>)</cite>. We claim that this is the result of a data problem and we attempt to address it in this work.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Finetuning on Synthetic Data</h5>
<div class="ltx_para ltx_noindent" id="S4.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.1">LLM post-training methods like supervised finetuning have been shown to be extremely powerful for improving model performance across tasks <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib46" title="">2021</a>)</cite>. However, high-quality datasets of paired instruction-response examples are extremely expensive to curate. One possible solution lies in synthetic data generation methods like Self-Instruct, wherein an LLM is prompted to generate instructions and/or responses from examples <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib43" title="">2022</a>)</cite>. Such data have been used extensively for improving LLM performance through self-refinement and/or knowledge distillation on coding tasks <cite class="ltx_cite ltx_citemacro_citep">(Chaudhary, <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib10" title="">2023</a>; Roziere et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib35" title="">2023</a>; Abdin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib1" title="">2024</a>; Lozhkov et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib26" title="">2024</a>)</cite>. We employ post-processed instruction data for code synthesis created with a method from this family, OSS-Instruct <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib49" title="">2024b</a>)</cite>, as the base of our experiments on re-factorizing code with code edit sequences via LintSeq. Unlike Self-Instruct-like synthetic data generation methods, our algorithm does not employ an LLM for data generation, and instead generates examples of error-free edit sequences from existing code data by using a simple linter.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Finetuning on Edits</h5>
<div class="ltx_para ltx_noindent" id="S4.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px3.p1.1">Several works have investigated finetuning code LLMs on edit data. Notably, <cite class="ltx_cite ltx_citemacro_cite">Muennighoff et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib28" title="">2023</a>)</cite> instruction tune models on a 4TB dataset of GitHub commits pairing code changes with human instructions. Relatedly, <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib21" title="">2024</a>)</cite> use GitHub commit data sourced from Python repositories to generate code editing instruction data with GPT 3.5/ChatGPT. Both of these works specifically focus on better-equipping LLMs for natural language-prompted code editing tasks, in which a model is <span class="ltx_text ltx_font_italic" id="S4.SS0.SSS0.Px3.p1.1.1">explicitly</span> prompted to generate an edit in response to a natural language specification. Our work differs in three important ways: first, we study edit sequences rather than single edits; second, we train LLMs to predict edits <span class="ltx_text ltx_font_italic" id="S4.SS0.SSS0.Px3.p1.1.2">implicitly</span> during code synthesis; third, our synthetic edit generation algorithm does not rely on the existence of any kind of commit data.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">“On Device” Language Models</h5>
<div class="ltx_para ltx_noindent" id="S4.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px4.p1.1">As the capabilities of LLMs have improved, so to have those of small language models. Recent projects like SmolLM <cite class="ltx_cite ltx_citemacro_citep">(Ben Allal et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib7" title="">2024</a>)</cite> and OpenELM <cite class="ltx_cite ltx_citemacro_citep">(Mehta et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib27" title="">2024</a>)</cite> re-examine the potential of tiny language models that can be run and even updated “on-device,” i.e. on a smart phone or laptop. The representations learned by such models during pretraining are weaker than those of scaled-up LLMs <cite class="ltx_cite ltx_citemacro_citep">(Kaplan et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib18" title="">2020</a>)</cite>. This is particularly true for harder tasks that involve reasoning, such as code synthesis <cite class="ltx_cite ltx_citemacro_citep">(Gemma Team et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib14" title="">2024</a>; Abdin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib1" title="">2024</a>)</cite>. To our knowledge, the most recent open-source work studying small language models pretrained entirely for code understanding is from several years ago <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib52" title="">2022</a>; Nijkamp et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib30" title="">2022</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib44" title="">2021</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib45" title="">2023b</a>)</cite>. The 150M and 400M parameter TinyCodeLM models pretrained in this paper belong to the “on device” model family and build upon previous works. These models provide an efficient test-bed for experiments on LM code synthesis that is updated to recent advancements in high throughput pretraining and to improvements in open-source data quality.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px5">
<h5 class="ltx_title ltx_title_paragraph">Inference-Time Compute Scaling</h5>
<div class="ltx_para ltx_noindent" id="S4.SS0.SSS0.Px5.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px5.p1.1">The performance of language models can be boosted during inference by using scaled-up sample counts, hand-engineered prompting schema, and/or search <cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib9" title="">2024</a>; Snell et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib38" title="">2024</a>)</cite>. These methods dramatically increase inference costs. Their effectiveness is tightly linked to the expressivity of learned model representations and the diversity of outputs across samples. Our experiments with smaller language models are inspired by these works – we study whether it is possible to (1) improve the expressivity of representations for code synthesis across LM parameter scales during finetuning, and (2) take advantage of this property to improve the inference-time performance of smaller LMs by larger margins during repeated sampling.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion, Limitations, and Conclusion</h2>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">This paper introduces an algorithm, LintSeq, for generating synthetic code edit sequences from existing programs. LintSeq enables LLM reasoning settings like code synthesis to be re-parameterized at the data-level as sequential edit generation tasks. The algorithm is parameter-free, requires only CPU to run, and makes no assumptions about the content or structure of code files.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Re-parameterizing code generation with edits has a few immediate benefits. For example, it makes code generation with LLMs much more controllable at the prompt-level (Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A1.SS3" title="A.3 Controllability of Code Synthesis with Edit Sequence LMs ‣ Appendix A More on Edit Sequences and Diffs ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">A.3</span></a>) and it reduces the cost of predicting useful and correct code insertions with models, since synthetic edit-trained LLMs do not need to be prompted to re-synthesize entire programs from scratch (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S2.SS4" title="2.4 Practicalities of Training Language Models on LintSeq Data ‣ 2 LintSeq: Code Synthesis as a Sequential Edit Problem ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">2.4</span></a>).</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">In our experiments with LintSeq, we also show the following:</p>
<ol class="ltx_enumerate" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para ltx_noindent" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1">Tiny LMs can be efficiently finetuned to synthesize Python programs with edit sequences via LintSeq data. This results in state-of-the-art code benchmark performance for models that can be trained “on device” (Sections <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS1" title="3.1 Pretraining Tiny LMs for Code Understanding ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">3.1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS3.SSS1" title="3.3.1 TinyCodeLM ‣ 3.3 Finetuning Language Models on LintSeq Edit Sequences ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">3.3.1</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1">Across other tested models from the Phi, Gemma, and Llama families, finetuning on LintSeq data also improves the diversity of zero-shot generations, boosting the inference-time scaling of coverage on HumanEval and MBPP at fixed sample counts (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS3.SSS2" title="3.3.2 Gemma 2, Phi-3, and Llama 3.1 ‣ 3.3 Finetuning Language Models on LintSeq Edit Sequences ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">3.3.2</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S5.I1.i3.p1">
<p class="ltx_p" id="S5.I1.i3.p1.1">On HumanEval, the cumulative inference cost of repeatedly sampling from small edit sequence LLMs is similar to sampling once from larger LLMs and yields coverage that is competitive with GPT-4, GPT-4-Omni, and Llama 3.1 405B (Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">1</span></a>, Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.SS4" title="F.4 Computing HumanEval Coverage vs Cumulative Inference-Time FLOPs ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">F.4</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para ltx_noindent" id="S5.I1.i4.p1">
<p class="ltx_p" id="S5.I1.i4.p1.1">Ablating linter-guidance from LintSeq hurts the quality, diversity, and correctness of code synthesized by instruction finetuned models (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS4" title="3.4 Ablating Linter-Guidance ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">3.4</span></a>).</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="S5.p4">
<p class="ltx_p" id="S5.p4.1">There are several limitations to our work.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p5">
<p class="ltx_p" id="S5.p5.1">First, as currently formulated, LintSeq can only be used to generate synthetic sequences of insertion edits. This is a consequence of the parameter-free nature of the algorithm – every edit in a LintSeq sequence reflects an existing line of code in the source file used to generate it. As a result, LintSeq edit data can only be used to train models for synthesis-like tasks, rather than for refinement.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p6">
<p class="ltx_p" id="S5.p6.1">Second, our experiments with LintSeq study code synthesis in Python only. We look forward to testing LintSeq with other programming languages, verifiers, and problems in future work. One other exciting setting where LintSeq might improve the tradeoff between model generation quality and inference-time compute is in mathematical reasoning and formal theorem proving.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Ethics Statement</h2>
<div class="ltx_para ltx_noindent" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This work explores data-driven mechanisms for improving the quality of language model-generated code. Our synthetic data generation method relies on open-source data and our experiments leverage open-source software and resources. It is important to acknowledge that all language models for code synthesis have the potential to be misused – whether intentionally or unintentionally – for generation of code with vulnerabilities and/or malicious behaviors. Any and all model generated code has the potential to be harmful and must not be executed without precautions.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>
<div class="ltx_para ltx_noindent" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">This work was supported by grants from NSF award 2339096 and ONR awards N00014-21-1-2758 and N00014-22-1-2773. We are grateful to Shenglong Wang and NYU High Performance Computing for their support of this project. UP is funded by an NSF GRFP Award, and LP is funded by the Packard Fellowship. We would like to thank Nate Rahn, Mahi Shafiullah, and David Brandfonbrener for helpful comments and discussions.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdin et al. (2024)</span>
<span class="ltx_bibblock">
Marah Abdin, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Harkirat Behl, et al.

</span>
<span class="ltx_bibblock">Phi-3 technical report: A highly capable language model locally on your phone.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2404.14219</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et al. (2023)</span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2303.08774</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Adler et al. (2024)</span>
<span class="ltx_bibblock">
Bo Adler, Niket Agarwal, Ashwath Aithal, Dong H Anh, Pallab Bhattacharya, Annika Brundyn, Jared Casper, Bryan Catanzaro, Sharon Clay, Jonathan Cohen, et al.

</span>
<span class="ltx_bibblock">Nemotron-4 340b technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2406.11704</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Austin et al. (2021)</span>
<span class="ltx_bibblock">
Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al.

</span>
<span class="ltx_bibblock">Program synthesis with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2108.07732</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ba (2016)</span>
<span class="ltx_bibblock">
JL Ba.

</span>
<span class="ltx_bibblock">Layer normalization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:1607.06450</em>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ben Allal et al. (2022)</span>
<span class="ltx_bibblock">
Loubna Ben Allal, Niklas Muennighoff, Logesh Kumar Umapathi, Ben Lipkin, and Leandro von Werra.

</span>
<span class="ltx_bibblock">A framework for the evaluation of code generation models.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/bigcode-project/bigcode-evaluation-harness" title="">https://github.com/bigcode-project/bigcode-evaluation-harness</a>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ben Allal et al. (2024)</span>
<span class="ltx_bibblock">
Loubna Ben Allal, Anton Lozhkov, and Elie Bakouch.

</span>
<span class="ltx_bibblock">Smollm - blazingly fast and remarkably powerful.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/blog/smollm" title="">https://huggingface.co/blog/smollm</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-09-02.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Black et al. (2022)</span>
<span class="ltx_bibblock">
Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, et al.

</span>
<span class="ltx_bibblock">Gpt-neox-20b: An open-source autoregressive language model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2204.06745</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2024)</span>
<span class="ltx_bibblock">
Bradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc V Le, Christopher Ré, and Azalia Mirhoseini.

</span>
<span class="ltx_bibblock">Large language monkeys: Scaling inference compute with repeated sampling.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2407.21787</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chaudhary (2023)</span>
<span class="ltx_bibblock">
Sahil Chaudhary.

</span>
<span class="ltx_bibblock">Code alpaca: An instruction-following llama model for code generation.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/sahil280114/codealpaca" title="">https://github.com/sahil280114/codealpaca</a>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2021)</span>
<span class="ltx_bibblock">
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al.

</span>
<span class="ltx_bibblock">Evaluating large language models trained on code.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2107.03374</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubey et al. (2024)</span>
<span class="ltx_bibblock">
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al.

</span>
<span class="ltx_bibblock">The llama 3 herd of models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2407.21783</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gemini Team et al. (2023)</span>
<span class="ltx_bibblock">
Google Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al.

</span>
<span class="ltx_bibblock">Gemini: a family of highly capable multimodal models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2312.11805</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gemma Team et al. (2024)</span>
<span class="ltx_bibblock">
Google Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivière, Mihir Sanjay Kale, Juliette Love, et al.

</span>
<span class="ltx_bibblock">Gemma: Open models based on gemini research and technology.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2403.08295</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gopnik (1982)</span>
<span class="ltx_bibblock">
Alison Gopnik.

</span>
<span class="ltx_bibblock">Words and plans: Early language and the development of intelligent action.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Journal of Child Language</em>, 9(2):303–318, 1982.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Groeneveld et al. (2024)</span>
<span class="ltx_bibblock">
Dirk Groeneveld, Iz Beltagy, Pete Walsh, Akshita Bhagia, Rodney Kinney, Oyvind Tafjord, Ananya Harsh Jha, Hamish Ivison, Ian Magnusson, Yizhong Wang, et al.

</span>
<span class="ltx_bibblock">Olmo: Accelerating the science of language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2402.00838</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heaven (2024)</span>
<span class="ltx_bibblock">
Will Douglas Heaven.

</span>
<span class="ltx_bibblock">How ai assistants are already changing the way code gets made.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.technologyreview.com/2023/12/06/1084457/ai-assistants-copilot-changing-code-software-development-github-openai/" title="">https://www.technologyreview.com/2023/12/06/1084457/ai-assistants-copilot-changing-code-software-development-github-openai/</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-09-20.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaplan et al. (2020)</span>
<span class="ltx_bibblock">
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.

</span>
<span class="ltx_bibblock">Scaling laws for neural language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2001.08361</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirsh (2009)</span>
<span class="ltx_bibblock">
David Kirsh.

</span>
<span class="ltx_bibblock">Problem solving and situated cognition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">The Cambridge Handbook of Situated Cognition</em>, pp.  264–306, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocetkov et al. (2022)</span>
<span class="ltx_bibblock">
Denis Kocetkov, Raymond Li, Loubna Ben Allal, Jia Li, Chenghao Mou, Carlos Muñoz Ferrandis, Yacine Jernite, Margaret Mitchell, Sean Hughes, Thomas Wolf, et al.

</span>
<span class="ltx_bibblock">The stack: 3 tb of permissively licensed source code.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2211.15533</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2024)</span>
<span class="ltx_bibblock">
Kaixin Li, Qisheng Hu, James Zhao, Hui Chen, Yuxi Xie, Tiedong Liu, Michael Shieh, and Junxian He.

</span>
<span class="ltx_bibblock">Instructcoder: Instruction tuning large language models for code editing.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)</em>, pp.  50–70, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, et al.

</span>
<span class="ltx_bibblock">Starcoder: may the source be with you!

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2305.06161</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2022a)</span>
<span class="ltx_bibblock">
Xiang Li, John Thickstun, Ishaan Gulrajani, Percy S Liang, and Tatsunori B Hashimoto.

</span>
<span class="ltx_bibblock">Diffusion-lm improves controllable text generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Advances in Neural Information Processing Systems</em>, 35:4328–4343, 2022a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2022b)</span>
<span class="ltx_bibblock">
Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al.

</span>
<span class="ltx_bibblock">Competition-level code generation with alphacode.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Science</em>, 378(6624):1092–1097, 2022b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023)</span>
<span class="ltx_bibblock">
Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang.

</span>
<span class="ltx_bibblock">Is your code generated by chatGPT really correct? rigorous evaluation of large language models for code generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Thirty-seventh Conference on Neural Information Processing Systems</em>, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=1qvx610Cu7" title="">https://openreview.net/forum?id=1qvx610Cu7</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lozhkov et al. (2024)</span>
<span class="ltx_bibblock">
Anton Lozhkov, Raymond Li, Loubna Ben Allal, Federico Cassano, Joel Lamy-Poirier, Nouamane Tazi, Ao Tang, Dmytro Pykhtar, Jiawei Liu, Yuxiang Wei, et al.

</span>
<span class="ltx_bibblock">Starcoder 2 and the stack v2: The next generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2402.19173</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mehta et al. (2024)</span>
<span class="ltx_bibblock">
Sachin Mehta, Mohammad Hossein Sekhavat, Qingqing Cao, Maxwell Horton, Yanzi Jin, Chenfan Sun, Seyed Iman Mirzadeh, Mahyar Najibi, Dmitry Belenko, Peter Zatloukal, and Mohammad Rastegari.

</span>
<span class="ltx_bibblock">OpenELM: An efficient language model family with open training and inference framework.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Workshop on Efficient Systems for Foundation Models II @ ICML2024</em>, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=XNMbTkxroF" title="">https://openreview.net/forum?id=XNMbTkxroF</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Muennighoff et al. (2023)</span>
<span class="ltx_bibblock">
Niklas Muennighoff, Qian Liu, Armel Zebaze, Qinkai Zheng, Binyuan Hui, Terry Yue Zhuo, Swayam Singh, Xiangru Tang, Leandro Von Werra, and Shayne Longpre.

</span>
<span class="ltx_bibblock">Octopack: Instruction tuning code large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2308.07124</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Muennighoff et al. (2024)</span>
<span class="ltx_bibblock">
Niklas Muennighoff, Alexander Rush, Boaz Barak, Teven Le Scao, Nouamane Tazi, Aleksandra Piktus, Sampo Pyysalo, Thomas Wolf, and Colin A Raffel.

</span>
<span class="ltx_bibblock">Scaling data-constrained language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Advances in Neural Information Processing Systems</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nijkamp et al. (2022)</span>
<span class="ltx_bibblock">
Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, and Caiming Xiong.

</span>
<span class="ltx_bibblock">Codegen: An open large language model for code with multi-turn program synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2203.13474</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Penedo et al. (2024)</span>
<span class="ltx_bibblock">
Guilherme Penedo, Hynek Kydlíček, Anton Lozhkov, Margaret Mitchell, Colin Raffel, Leandro Von Werra, Thomas Wolf, et al.

</span>
<span class="ltx_bibblock">The fineweb datasets: Decanting the web for the finest text data at scale.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:2406.17557</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Piterbarg et al. (2024)</span>
<span class="ltx_bibblock">
Ulyana Piterbarg, Lerrel Pinto, and Rob Fergus.

</span>
<span class="ltx_bibblock">diff history for neural language agents.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Forty-first International Conference on Machine Learning</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">OpenAI blog</em>, 1(8):9, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren et al. (2021)</span>
<span class="ltx_bibblock">
Jie Ren, Samyam Rajbhandari, Reza Yazdani Aminabadi, Olatunji Ruwase, Shuangyan Yang, Minjia Zhang, Dong Li, and Yuxiong He.

</span>
<span class="ltx_bibblock"><math alttext="\{" class="ltx_Math" display="inline" id="bib.bib34.1.m1.1"><semantics id="bib.bib34.1.m1.1a"><mo id="bib.bib34.1.m1.1.1" stretchy="false" xref="bib.bib34.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib34.1.m1.1b"><ci id="bib.bib34.1.m1.1.1.cmml" xref="bib.bib34.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib34.1.m1.1c">\{</annotation><annotation encoding="application/x-llamapun" id="bib.bib34.1.m1.1d">{</annotation></semantics></math>ZeRO-Offload<math alttext="\}" class="ltx_Math" display="inline" id="bib.bib34.2.m2.1"><semantics id="bib.bib34.2.m2.1a"><mo id="bib.bib34.2.m2.1.1" stretchy="false" xref="bib.bib34.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib34.2.m2.1b"><ci id="bib.bib34.2.m2.1.1.cmml" xref="bib.bib34.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib34.2.m2.1c">\}</annotation><annotation encoding="application/x-llamapun" id="bib.bib34.2.m2.1d">}</annotation></semantics></math>: Democratizing <math alttext="\{" class="ltx_Math" display="inline" id="bib.bib34.3.m3.1"><semantics id="bib.bib34.3.m3.1a"><mo id="bib.bib34.3.m3.1.1" stretchy="false" xref="bib.bib34.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib34.3.m3.1b"><ci id="bib.bib34.3.m3.1.1.cmml" xref="bib.bib34.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib34.3.m3.1c">\{</annotation><annotation encoding="application/x-llamapun" id="bib.bib34.3.m3.1d">{</annotation></semantics></math>Billion-Scale<math alttext="\}" class="ltx_Math" display="inline" id="bib.bib34.4.m4.1"><semantics id="bib.bib34.4.m4.1a"><mo id="bib.bib34.4.m4.1.1" stretchy="false" xref="bib.bib34.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib34.4.m4.1b"><ci id="bib.bib34.4.m4.1.1.cmml" xref="bib.bib34.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib34.4.m4.1c">\}</annotation><annotation encoding="application/x-llamapun" id="bib.bib34.4.m4.1d">}</annotation></semantics></math> model training.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.5.1">2021 USENIX Annual Technical Conference (USENIX ATC 21)</em>, pp.  551–564, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roziere et al. (2023)</span>
<span class="ltx_bibblock">
Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, et al.

</span>
<span class="ltx_bibblock">Code llama: Open foundation models for code.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">arXiv preprint arXiv:2308.12950</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanger (2024)</span>
<span class="ltx_bibblock">
Aman Sanger.

</span>
<span class="ltx_bibblock">Editing files at 1000 tokens per second.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.cursor.com/blog/instant-apply" title="">https://www.cursor.com/blog/instant-apply</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-09-02.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shazeer (2020)</span>
<span class="ltx_bibblock">
Noam Shazeer.

</span>
<span class="ltx_bibblock">Glu variants improve transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">arXiv preprint arXiv:2002.05202</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Snell et al. (2024)</span>
<span class="ltx_bibblock">
Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar.

</span>
<span class="ltx_bibblock">Scaling llm test-time compute optimally can be more effective than scaling model parameters.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">arXiv preprint arXiv:2408.03314</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Soldaini et al. (2024)</span>
<span class="ltx_bibblock">
Luca Soldaini, Rodney Kinney, Akshita Bhagia, Dustin Schwenk, David Atkinson, Russell Authur, Ben Bogin, Khyathi Chandu, Jennifer Dumas, Yanai Elazar, et al.

</span>
<span class="ltx_bibblock">Dolma: An open corpus of three trillion tokens for language model pretraining research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:2402.00159</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et al. (2024)</span>
<span class="ltx_bibblock">
Jianlin Su, Murtadha Ahmed, Yu Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu.

</span>
<span class="ltx_bibblock">Roformer: Enhanced transformer with rotary position embedding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Neurocomputing</em>, 568:127063, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thompson &amp; Ritchie (1975)</span>
<span class="ltx_bibblock">
Ken Thompson and Dennis M Ritchie.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">unix Programmer’s Manual</em>.

</span>
<span class="ltx_bibblock">Bell Telephone Laboratories, 1975.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023a)</span>
<span class="ltx_bibblock">
Guanhua Wang, Heyang Qin, Sam Ade Jacobs, Connor Holmes, Samyam Rajbhandari, Olatunji Ruwase, Feng Yan, Lei Yang, and Yuxiong He.

</span>
<span class="ltx_bibblock">Zero++: Extremely efficient collective communication for giant model training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">arXiv preprint arXiv:2306.10209</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022)</span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi.

</span>
<span class="ltx_bibblock">Self-instruct: Aligning language models with self-generated instructions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">arXiv preprint arXiv:2212.10560</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2021)</span>
<span class="ltx_bibblock">
Yue Wang, Weishi Wang, Shafiq Joty, and Steven CH Hoi.

</span>
<span class="ltx_bibblock">Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">arXiv preprint arXiv:2109.00859</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023b)</span>
<span class="ltx_bibblock">
Yue Wang, Hung Le, Akhilesh Deepak Gotmare, Nghi DQ Bui, Junnan Li, and Steven CH Hoi.

</span>
<span class="ltx_bibblock">Codet5+: Open code large language models for code understanding and generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">arXiv preprint arXiv:2305.07922</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2021)</span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le.

</span>
<span class="ltx_bibblock">Finetuned language models are zero-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">arXiv preprint arXiv:2109.01652</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Advances in neural information processing systems</em>, 35:24824–24837, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2024a)</span>
<span class="ltx_bibblock">
Yuxiang Wei, Federico Cassano, Jiawei Liu, Yifeng Ding, Naman Jain, Harm de Vries, Leandro von Werra, Arjun Guha, and Lingming Zhang.

</span>
<span class="ltx_bibblock">Starcoder2-instruct: Fully transparent and permissive self-alignment for code generation.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/blog/sc2-instruct" title="">https://huggingface.co/blog/sc2-instruct</a>, 2024a.

</span>
<span class="ltx_bibblock">Accessed: 2024-09-08.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2024b)</span>
<span class="ltx_bibblock">
Yuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, and Lingming Zhang.

</span>
<span class="ltx_bibblock">Magicoder: Empowering code generation with oss-instruct.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Forty-first International Conference on Machine Learning</em>, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Williams &amp; Zipser (1989)</span>
<span class="ltx_bibblock">
Ronald J Williams and David Zipser.

</span>
<span class="ltx_bibblock">A learning algorithm for continually running fully recurrent neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Neural computation</em>, 1(2):270–280, 1989.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wolf et al. (2020)</span>
<span class="ltx_bibblock">
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Perric Cistac, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush.

</span>
<span class="ltx_bibblock">Transformers: State-of-the-Art Natural Language Processing.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">Association for Computational Linguistics</em>, pp.  38–45, October 2020.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.aclweb.org/anthology/2020.emnlp-demos.6" title="">https://www.aclweb.org/anthology/2020.emnlp-demos.6</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2022)</span>
<span class="ltx_bibblock">
Frank F Xu, Uri Alon, Graham Neubig, and Vincent Josua Hellendoorn.

</span>
<span class="ltx_bibblock">A systematic evaluation of large language models of code.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming</em>, pp.  1–10, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2023)</span>
<span class="ltx_bibblock">
Yanli Zhao, Andrew Gu, Rohan Varma, Liang Luo, Chien-Chin Huang, Min Xu, Less Wright, Hamid Shojanazeri, Myle Ott, Sam Shleifer, et al.

</span>
<span class="ltx_bibblock">Pytorch fsdp: experiences on scaling fully sharded data parallel.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">arXiv preprint arXiv:2304.11277</em>, 2023.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>More on Edit Sequences and Diffs</h2>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Reading Unix Diffs</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.2">We provide a guide to reading Unix-style diffs below in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A1.F7" title="Figure 7 ‣ A.1 Reading Unix Diffs ‣ Appendix A More on Edit Sequences and Diffs ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">7</span></a>. The diff shown in this figure is computed using the Python library <span class="ltx_text ltx_font_typewriter" id="A1.SS1.p1.2.1">difflib</span>, which is the implementation that we use to compactly represent edits in our synthetic data generation experiments. Note that the total extra tokens present in an insertion edit sequence representation of a program scales with the number of program lines <math alttext="L" class="ltx_Math" display="inline" id="A1.SS1.p1.1.m1.1"><semantics id="A1.SS1.p1.1.m1.1a"><mi id="A1.SS1.p1.1.m1.1.1" xref="A1.SS1.p1.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.1.m1.1b"><ci id="A1.SS1.p1.1.m1.1.1.cmml" xref="A1.SS1.p1.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.1.m1.1c">L</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.1.m1.1d">italic_L</annotation></semantics></math>, and can be upper-bounded as <math alttext="T_{\text{diff}}\leq L\cdot((\text{chars in ``decorator''})+(\text{extra chars %
per line in ``body''}))=16L" class="ltx_Math" display="inline" id="A1.SS1.p1.2.m2.3"><semantics id="A1.SS1.p1.2.m2.3a"><mrow id="A1.SS1.p1.2.m2.3.3" xref="A1.SS1.p1.2.m2.3.3.cmml"><msub id="A1.SS1.p1.2.m2.3.3.3" xref="A1.SS1.p1.2.m2.3.3.3.cmml"><mi id="A1.SS1.p1.2.m2.3.3.3.2" xref="A1.SS1.p1.2.m2.3.3.3.2.cmml">T</mi><mtext id="A1.SS1.p1.2.m2.3.3.3.3" xref="A1.SS1.p1.2.m2.3.3.3.3a.cmml">diff</mtext></msub><mo id="A1.SS1.p1.2.m2.3.3.4" xref="A1.SS1.p1.2.m2.3.3.4.cmml">≤</mo><mrow id="A1.SS1.p1.2.m2.3.3.1" xref="A1.SS1.p1.2.m2.3.3.1.cmml"><mi id="A1.SS1.p1.2.m2.3.3.1.3" xref="A1.SS1.p1.2.m2.3.3.1.3.cmml">L</mi><mo id="A1.SS1.p1.2.m2.3.3.1.2" lspace="0.222em" rspace="0.222em" xref="A1.SS1.p1.2.m2.3.3.1.2.cmml">⋅</mo><mrow id="A1.SS1.p1.2.m2.3.3.1.1.1" xref="A1.SS1.p1.2.m2.3.3.1.1.1.1.cmml"><mo id="A1.SS1.p1.2.m2.3.3.1.1.1.2" stretchy="false" xref="A1.SS1.p1.2.m2.3.3.1.1.1.1.cmml">(</mo><mrow id="A1.SS1.p1.2.m2.3.3.1.1.1.1" xref="A1.SS1.p1.2.m2.3.3.1.1.1.1.cmml"><mrow id="A1.SS1.p1.2.m2.3.3.1.1.1.1.2.2" xref="A1.SS1.p1.2.m2.1.1a.cmml"><mo id="A1.SS1.p1.2.m2.3.3.1.1.1.1.2.2.1" stretchy="false" xref="A1.SS1.p1.2.m2.1.1a.cmml">(</mo><mtext id="A1.SS1.p1.2.m2.1.1" xref="A1.SS1.p1.2.m2.1.1.cmml">chars in “decorator”</mtext><mo id="A1.SS1.p1.2.m2.3.3.1.1.1.1.2.2.2" stretchy="false" xref="A1.SS1.p1.2.m2.1.1a.cmml">)</mo></mrow><mo id="A1.SS1.p1.2.m2.3.3.1.1.1.1.1" xref="A1.SS1.p1.2.m2.3.3.1.1.1.1.1.cmml">+</mo><mrow id="A1.SS1.p1.2.m2.3.3.1.1.1.1.3.2" xref="A1.SS1.p1.2.m2.2.2a.cmml"><mo id="A1.SS1.p1.2.m2.3.3.1.1.1.1.3.2.1" stretchy="false" xref="A1.SS1.p1.2.m2.2.2a.cmml">(</mo><mtext id="A1.SS1.p1.2.m2.2.2" xref="A1.SS1.p1.2.m2.2.2.cmml">extra chars per line in “body”</mtext><mo id="A1.SS1.p1.2.m2.3.3.1.1.1.1.3.2.2" stretchy="false" xref="A1.SS1.p1.2.m2.2.2a.cmml">)</mo></mrow></mrow><mo id="A1.SS1.p1.2.m2.3.3.1.1.1.3" stretchy="false" xref="A1.SS1.p1.2.m2.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.SS1.p1.2.m2.3.3.5" xref="A1.SS1.p1.2.m2.3.3.5.cmml">=</mo><mrow id="A1.SS1.p1.2.m2.3.3.6" xref="A1.SS1.p1.2.m2.3.3.6.cmml"><mn id="A1.SS1.p1.2.m2.3.3.6.2" xref="A1.SS1.p1.2.m2.3.3.6.2.cmml">16</mn><mo id="A1.SS1.p1.2.m2.3.3.6.1" xref="A1.SS1.p1.2.m2.3.3.6.1.cmml">⁢</mo><mi id="A1.SS1.p1.2.m2.3.3.6.3" xref="A1.SS1.p1.2.m2.3.3.6.3.cmml">L</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.2.m2.3b"><apply id="A1.SS1.p1.2.m2.3.3.cmml" xref="A1.SS1.p1.2.m2.3.3"><and id="A1.SS1.p1.2.m2.3.3a.cmml" xref="A1.SS1.p1.2.m2.3.3"></and><apply id="A1.SS1.p1.2.m2.3.3b.cmml" xref="A1.SS1.p1.2.m2.3.3"><leq id="A1.SS1.p1.2.m2.3.3.4.cmml" xref="A1.SS1.p1.2.m2.3.3.4"></leq><apply id="A1.SS1.p1.2.m2.3.3.3.cmml" xref="A1.SS1.p1.2.m2.3.3.3"><csymbol cd="ambiguous" id="A1.SS1.p1.2.m2.3.3.3.1.cmml" xref="A1.SS1.p1.2.m2.3.3.3">subscript</csymbol><ci id="A1.SS1.p1.2.m2.3.3.3.2.cmml" xref="A1.SS1.p1.2.m2.3.3.3.2">𝑇</ci><ci id="A1.SS1.p1.2.m2.3.3.3.3a.cmml" xref="A1.SS1.p1.2.m2.3.3.3.3"><mtext id="A1.SS1.p1.2.m2.3.3.3.3.cmml" mathsize="70%" xref="A1.SS1.p1.2.m2.3.3.3.3">diff</mtext></ci></apply><apply id="A1.SS1.p1.2.m2.3.3.1.cmml" xref="A1.SS1.p1.2.m2.3.3.1"><ci id="A1.SS1.p1.2.m2.3.3.1.2.cmml" xref="A1.SS1.p1.2.m2.3.3.1.2">⋅</ci><ci id="A1.SS1.p1.2.m2.3.3.1.3.cmml" xref="A1.SS1.p1.2.m2.3.3.1.3">𝐿</ci><apply id="A1.SS1.p1.2.m2.3.3.1.1.1.1.cmml" xref="A1.SS1.p1.2.m2.3.3.1.1.1"><plus id="A1.SS1.p1.2.m2.3.3.1.1.1.1.1.cmml" xref="A1.SS1.p1.2.m2.3.3.1.1.1.1.1"></plus><ci id="A1.SS1.p1.2.m2.1.1a.cmml" xref="A1.SS1.p1.2.m2.3.3.1.1.1.1.2.2"><mtext id="A1.SS1.p1.2.m2.1.1.cmml" xref="A1.SS1.p1.2.m2.1.1">chars in “decorator”</mtext></ci><ci id="A1.SS1.p1.2.m2.2.2a.cmml" xref="A1.SS1.p1.2.m2.3.3.1.1.1.1.3.2"><mtext id="A1.SS1.p1.2.m2.2.2.cmml" xref="A1.SS1.p1.2.m2.2.2">extra chars per line in “body”</mtext></ci></apply></apply></apply><apply id="A1.SS1.p1.2.m2.3.3c.cmml" xref="A1.SS1.p1.2.m2.3.3"><eq id="A1.SS1.p1.2.m2.3.3.5.cmml" xref="A1.SS1.p1.2.m2.3.3.5"></eq><share href="https://arxiv.org/html/2410.02749v2#A1.SS1.p1.2.m2.3.3.1.cmml" id="A1.SS1.p1.2.m2.3.3d.cmml" xref="A1.SS1.p1.2.m2.3.3"></share><apply id="A1.SS1.p1.2.m2.3.3.6.cmml" xref="A1.SS1.p1.2.m2.3.3.6"><times id="A1.SS1.p1.2.m2.3.3.6.1.cmml" xref="A1.SS1.p1.2.m2.3.3.6.1"></times><cn id="A1.SS1.p1.2.m2.3.3.6.2.cmml" type="integer" xref="A1.SS1.p1.2.m2.3.3.6.2">16</cn><ci id="A1.SS1.p1.2.m2.3.3.6.3.cmml" xref="A1.SS1.p1.2.m2.3.3.6.3">𝐿</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.2.m2.3c">T_{\text{diff}}\leq L\cdot((\text{chars in ``decorator''})+(\text{extra chars %
per line in ``body''}))=16L</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.2.m2.3d">italic_T start_POSTSUBSCRIPT diff end_POSTSUBSCRIPT ≤ italic_L ⋅ ( ( chars in “decorator” ) + ( extra chars per line in “body” ) ) = 16 italic_L</annotation></semantics></math>.</p>
</div>
<figure class="ltx_figure" id="A1.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="149" id="A1.F7.g1" src="extracted/5927317/template/figures/diff_anatomy_v2.png" width="299"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span><span class="ltx_text ltx_font_bold" id="A1.F7.5.1">The anatomy of a Unix diff</span>: A diagrammatic visualization of the different parts of a Unix-style diff, as computed by <span class="ltx_text ltx_font_typewriter" id="A1.F7.6.2">difflib</span>. The <span class="ltx_text ltx_font_italic" id="A1.F7.7.3">body</span> of a diff can consist of multiple line deletions, followed by multiple line insertions. The <span class="ltx_text ltx_font_italic" id="A1.F7.8.4">decorator</span> portion of the diff respectively indicates the location and size of these deletions and insertions, if any. Like the diff shown above, the edits in synthetic edit sequences generated by LintSeq consist of line insertions only.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Resolving Edit Sequences</h3>
<div class="ltx_para ltx_noindent" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">During inference, LMs that have been finetuned on LintSeq instruct data will synthesize code via edit sequences, outputting text strings that consist of a sequence of consecutive Python diffs interleaved with newline characters and “<span class="ltx_text ltx_font_typewriter" id="A1.SS2.p1.1.1">&lt;|diff|&gt;</span>” tokens, similar to  <cite class="ltx_cite ltx_citemacro_cite">Piterbarg et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib32" title="">2024</a>)</cite>. Each of these diffs will be structured as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A1.F7" title="Figure 7 ‣ A.1 Reading Unix Diffs ‣ Appendix A More on Edit Sequences and Diffs ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">7</span></a>, if correctly formatted by the language model.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS2.p2">
<p class="ltx_p" id="A1.SS2.p2.1">Resolving an edit sequence generated by a language model into an executable Python program is simple: starting with an empty program, we consecutively apply the line insertions and/or deletions in the body of each diff to the lines of the program specified in its decorator. We continue this process until all of the diffs in the generated edit sequence have been parsed and resolved.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS2.p3">
<p class="ltx_p" id="A1.SS2.p3.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">1</span></a> shows a code edit sequence generation from a LintSeq instruction finetuned LM and the corresponding resolved, executable Python program.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Controllability of Code Synthesis with Edit Sequence LMs</h3>
<div class="ltx_para ltx_noindent" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.1">The structure of Unix-style diffs affects the downstream controllability of code synthesis with models that have been trained on edit sequence re-parameterized programs. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A1.F7" title="Figure 7 ‣ A.1 Reading Unix Diffs ‣ Appendix A More on Edit Sequences and Diffs ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">7</span></a>, the first line of every diff is a decorator that describes the location and the numbers of lines changed by the edit. During inference, autoregressive language models that have been trained on Unix-style diffs with this format can be prompted to predict an edit in any desired target location within the program being synthesized by “intervening” on a model generation.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Future Work: Searching in Edit Space</h3>
<div class="ltx_para ltx_noindent" id="A1.SS4.p1">
<p class="ltx_p" id="A1.SS4.p1.1">If we apply the lens of reinforcement learning or search to this setting, we might say that re-parameterizing the code data used to train a language model re-parameterizes the model’s <span class="ltx_text ltx_font_italic" id="A1.SS4.p1.1.1">generative action space</span>. It is possible that combining edit sequence LMs with more sophisticated decoding mechanisms, inference-time search, and/or interactive post-training may result in even larger improvements to the quality of generated code than those of the zero-shot code synthesis settings studied in this paper. We look forward to testing this hypothesis in future work.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Evaluation</h2>
<div class="ltx_para ltx_noindent" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">HumanEval <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib11" title="">2021</a>)</cite> and Mostly-Basic Programming Problems (MBPP) <cite class="ltx_cite ltx_citemacro_citep">(Austin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib4" title="">2021</a>)</cite> are two of the most studied benchmarks for evaluating code LMs <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib25" title="">2023</a>)</cite>. These benchmarks probe the code synthesis capabilities of models, and consist of pairs of natural language program descriptions and test-cases. We employ the extended MBPP test cases released as MBPP(+) by <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib25" title="">2023</a>)</cite> to add additional rigour to our testing procedure. All of the code LMs that we compare our models against evaluate HumanEval performance using the original set of benchmark test cases; for consistency, we employ these same test cases in our evaluations when comparing the performance of our models to the reported scores of external LMs.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.p2">
<p class="ltx_p" id="A2.p2.1">During testing on both HumanEval and MBPP(+), LMs are prompted to generate outputs using the natural language descriptions of target programs. Their outputs are then evaluated on the paired test cases. A generation is considered “correct” if and only if it passes all of the test cases upon execution, subject to a fixed timeout setting. Previous works on code synthesis with language models report scores on HumanEval and MBPP(+) across samples. The most common of these metrics is known as pass@k <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib11" title="">2021</a>; Austin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib4" title="">2021</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib24" title="">2022b</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib45" title="">2023b</a>)</cite>. This is the metric that we use to report and compare model performance throughout this paper. Our implementation of HumanEval and MBPP(+) evaluations mimics the Big Code Evaluation Harness by <cite class="ltx_cite ltx_citemacro_cite">Ben Allal et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib6" title="">2022</a>)</cite>. We do not allow models to use chain-of-thought during generation.</p>
</div>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Prompting</h3>
<div class="ltx_para" id="A2.SS1.p1">
<p class="ltx_p" id="A2.SS1.p1.1">The primary goal of this paper is to introduce a method for re-factorizing code synthesis with LMs by finetuning them on synthetic instruction data. As a result, we evaluate all models using minimal prompt formats, performing no prompt tuning (see Figures <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A5.F9" title="Figure 9 ‣ E.1 Examples of Generated Synthetic Edit Trajectories ‣ Appendix E More on Synthetic Data Generation with LintSeq ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">9</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A5.F10" title="Figure 10 ‣ E.1 Examples of Generated Synthetic Edit Trajectories ‣ Appendix E More on Synthetic Data Generation with LintSeq ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">10</span></a>). Examples of the prompt formats that we use during evaluation are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A2.F8" title="Figure 8 ‣ B.1 Prompting ‣ Appendix B Evaluation ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">8</span></a>.</p>
</div>
<figure class="ltx_figure" id="A2.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="214" id="A2.F8.g1" src="extracted/5927317/template/figures/prompting_examples_v2.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Examples of formatted HumanEval and MBPP(+) prompts used in model evaluations.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A2.SS1.p2">
<p class="ltx_p" id="A2.SS1.p2.1">We finetune all tested models on example outputs exclusively corresponding to Python code, and as a result, we do not use Markdown formatting to separate Python code from natural language in either our instruction data nor in our inference-time prompts.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS1.p3">
<p class="ltx_p" id="A2.SS1.p3.1">To evaluate models on HumanEval, we use both the default “Python version” prompt format in the original benchmark dataset, where a natural language program description is provided to an LM within a docstring, as well as the equivalent, fully natural language prompt format from HumanEvalPack <cite class="ltx_cite ltx_citemacro_citep">(Muennighoff et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib28" title="">2023</a>)</cite>. The latter format is similar to the structure of the instructions in our finetuning datasets.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS1.p4">
<p class="ltx_p" id="A2.SS1.p4.1">To evaluate models on MBPP(+), we use the default prompts from the MBPP benchmark dataset, formatted with specification of the target function name and arguments both inside and outside of the natural language instruction, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A2.F8" title="Figure 8 ‣ B.1 Prompting ‣ Appendix B Evaluation ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">8</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS1.p5">
<p class="ltx_p" id="A2.SS1.p5.1">During LM benchmark evaluations, we test models on each of the format variants described above and report scores on the better performing variant for each benchmark only.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Generation and Parsing</h3>
<div class="ltx_para ltx_noindent" id="A2.SS2.p1">
<p class="ltx_p" id="A2.SS2.p1.1">During generation, we continue decoding until an end-of-sequence token is output by an LM. We treat all LM outputs as either Python code or sequences of Python code edits, depending on whether an LM was finetuned on standard instruct or LintSeq instruct data. In the latter case, we post-process outputs by resolving the output edit sequences using the procedure described in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A1.SS2" title="A.2 Resolving Edit Sequences ‣ Appendix A More on Edit Sequences and Diffs ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">A.2</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Evaluating Model Checkpoints</h3>
<section class="ltx_subsubsection" id="A2.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">B.3.1 </span>Philosophy</h4>
<div class="ltx_para ltx_noindent" id="A2.SS3.SSS1.p1">
<p class="ltx_p" id="A2.SS3.SSS1.p1.1">There is a well-known trade-off between the temperature used for sampling from autoregressive code LMs and the benchmark coverage achievable by models, i.e. the proportion of problems “pass@k” for which an LM is able to generate at least one output that passes all test cases given “k” tries. This trade-off was first described by <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib11" title="">2021</a>)</cite>. Informally, increasing the sampling temperature increases the width of the distribution from which tokens are sampled, producing more diverse but noisier (and possibly lower quality) generations. For larger repeated sample counts, the pass@k score typically increases with sampling temperature up to some threshold, beyond which the negative effects of noise overpower the positive effects of diversity. The benchmark coverage achievable by an LM at any temperature and in the limit of samples, i.e. on pass@k for <math alttext="k\uparrow\infty" class="ltx_Math" display="inline" id="A2.SS3.SSS1.p1.1.m1.1"><semantics id="A2.SS3.SSS1.p1.1.m1.1a"><mrow id="A2.SS3.SSS1.p1.1.m1.1.1" xref="A2.SS3.SSS1.p1.1.m1.1.1.cmml"><mi id="A2.SS3.SSS1.p1.1.m1.1.1.2" xref="A2.SS3.SSS1.p1.1.m1.1.1.2.cmml">k</mi><mo id="A2.SS3.SSS1.p1.1.m1.1.1.1" stretchy="false" xref="A2.SS3.SSS1.p1.1.m1.1.1.1.cmml">↑</mo><mi id="A2.SS3.SSS1.p1.1.m1.1.1.3" mathvariant="normal" xref="A2.SS3.SSS1.p1.1.m1.1.1.3.cmml">∞</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.SSS1.p1.1.m1.1b"><apply id="A2.SS3.SSS1.p1.1.m1.1.1.cmml" xref="A2.SS3.SSS1.p1.1.m1.1.1"><ci id="A2.SS3.SSS1.p1.1.m1.1.1.1.cmml" xref="A2.SS3.SSS1.p1.1.m1.1.1.1">↑</ci><ci id="A2.SS3.SSS1.p1.1.m1.1.1.2.cmml" xref="A2.SS3.SSS1.p1.1.m1.1.1.2">𝑘</ci><infinity id="A2.SS3.SSS1.p1.1.m1.1.1.3.cmml" xref="A2.SS3.SSS1.p1.1.m1.1.1.3"></infinity></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.SSS1.p1.1.m1.1c">k\uparrow\infty</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.SSS1.p1.1.m1.1d">italic_k ↑ ∞</annotation></semantics></math>, ultimately depends on both the power and expressivity of the code language model’s learned representation.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS3.SSS1.p2">
<p class="ltx_p" id="A2.SS3.SSS1.p2.2">From a practical perspective, while smaller language models may have weaker representational power than larger models, the representational expressivity of the former may enable them to overtake the latter at fixed computational budgets by leveraging extra compute at inference-time, e.g. generating a larger number of samples per problem and using the provided test cases to check each one for correctness before returning an output <cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib9" title="">2024</a>; Snell et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib38" title="">2024</a>)</cite>. For example, an LLM that has an 85<math alttext="\%" class="ltx_Math" display="inline" id="A2.SS3.SSS1.p2.1.m1.1"><semantics id="A2.SS3.SSS1.p2.1.m1.1a"><mo id="A2.SS3.SSS1.p2.1.m1.1.1" xref="A2.SS3.SSS1.p2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="A2.SS3.SSS1.p2.1.m1.1b"><csymbol cd="latexml" id="A2.SS3.SSS1.p2.1.m1.1.1.cmml" xref="A2.SS3.SSS1.p2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.SSS1.p2.1.m1.1c">\%</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.SSS1.p2.1.m1.1d">%</annotation></semantics></math> pass@1 score on an arbitrary task may be more expensive in total serving cost (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">1</span></a>) than a smaller LM with a <math alttext="90\%" class="ltx_Math" display="inline" id="A2.SS3.SSS1.p2.2.m2.1"><semantics id="A2.SS3.SSS1.p2.2.m2.1a"><mrow id="A2.SS3.SSS1.p2.2.m2.1.1" xref="A2.SS3.SSS1.p2.2.m2.1.1.cmml"><mn id="A2.SS3.SSS1.p2.2.m2.1.1.2" xref="A2.SS3.SSS1.p2.2.m2.1.1.2.cmml">90</mn><mo id="A2.SS3.SSS1.p2.2.m2.1.1.1" xref="A2.SS3.SSS1.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.SSS1.p2.2.m2.1b"><apply id="A2.SS3.SSS1.p2.2.m2.1.1.cmml" xref="A2.SS3.SSS1.p2.2.m2.1.1"><csymbol cd="latexml" id="A2.SS3.SSS1.p2.2.m2.1.1.1.cmml" xref="A2.SS3.SSS1.p2.2.m2.1.1.1">percent</csymbol><cn id="A2.SS3.SSS1.p2.2.m2.1.1.2.cmml" type="integer" xref="A2.SS3.SSS1.p2.2.m2.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.SSS1.p2.2.m2.1c">90\%</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.SSS1.p2.2.m2.1d">90 %</annotation></semantics></math> pass@50 score on the same task. A small LM can only have this property, however, if it exhibits a reliable trade-off between generation quality and inference-time sampling cost across tasks. In other words, its representation must be sufficiently expressive.</p>
</div>
</section>
<section class="ltx_subsubsection" id="A2.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">B.3.2 </span>Computing Coverage (Pass@K)</h4>
<div class="ltx_para ltx_noindent" id="A2.SS3.SSS2.p1">
<p class="ltx_p" id="A2.SS3.SSS2.p1.2">Our goal is to probe whether re-parameterizing code synthesis with edit sequences can improve the expressivity of smaller LLM representations, boosting benchmark coverage as a function of samples-per-problem. Hence, we primarily compare finetuned models by evaluating them with the procedures described above on HumanEval and MBPP(+) at a high temperature and a large sample count, computing pass@k for k<math alttext="\ \in\{1,5,10,20,50\}" class="ltx_Math" display="inline" id="A2.SS3.SSS2.p1.1.m1.5"><semantics id="A2.SS3.SSS2.p1.1.m1.5a"><mrow id="A2.SS3.SSS2.p1.1.m1.5.6" xref="A2.SS3.SSS2.p1.1.m1.5.6.cmml"><mi id="A2.SS3.SSS2.p1.1.m1.5.6.2" xref="A2.SS3.SSS2.p1.1.m1.5.6.2.cmml"></mi><mo id="A2.SS3.SSS2.p1.1.m1.5.6.1" lspace="0.778em" xref="A2.SS3.SSS2.p1.1.m1.5.6.1.cmml">∈</mo><mrow id="A2.SS3.SSS2.p1.1.m1.5.6.3.2" xref="A2.SS3.SSS2.p1.1.m1.5.6.3.1.cmml"><mo id="A2.SS3.SSS2.p1.1.m1.5.6.3.2.1" stretchy="false" xref="A2.SS3.SSS2.p1.1.m1.5.6.3.1.cmml">{</mo><mn id="A2.SS3.SSS2.p1.1.m1.1.1" xref="A2.SS3.SSS2.p1.1.m1.1.1.cmml">1</mn><mo id="A2.SS3.SSS2.p1.1.m1.5.6.3.2.2" xref="A2.SS3.SSS2.p1.1.m1.5.6.3.1.cmml">,</mo><mn id="A2.SS3.SSS2.p1.1.m1.2.2" xref="A2.SS3.SSS2.p1.1.m1.2.2.cmml">5</mn><mo id="A2.SS3.SSS2.p1.1.m1.5.6.3.2.3" xref="A2.SS3.SSS2.p1.1.m1.5.6.3.1.cmml">,</mo><mn id="A2.SS3.SSS2.p1.1.m1.3.3" xref="A2.SS3.SSS2.p1.1.m1.3.3.cmml">10</mn><mo id="A2.SS3.SSS2.p1.1.m1.5.6.3.2.4" xref="A2.SS3.SSS2.p1.1.m1.5.6.3.1.cmml">,</mo><mn id="A2.SS3.SSS2.p1.1.m1.4.4" xref="A2.SS3.SSS2.p1.1.m1.4.4.cmml">20</mn><mo id="A2.SS3.SSS2.p1.1.m1.5.6.3.2.5" xref="A2.SS3.SSS2.p1.1.m1.5.6.3.1.cmml">,</mo><mn id="A2.SS3.SSS2.p1.1.m1.5.5" xref="A2.SS3.SSS2.p1.1.m1.5.5.cmml">50</mn><mo id="A2.SS3.SSS2.p1.1.m1.5.6.3.2.6" stretchy="false" xref="A2.SS3.SSS2.p1.1.m1.5.6.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.SSS2.p1.1.m1.5b"><apply id="A2.SS3.SSS2.p1.1.m1.5.6.cmml" xref="A2.SS3.SSS2.p1.1.m1.5.6"><in id="A2.SS3.SSS2.p1.1.m1.5.6.1.cmml" xref="A2.SS3.SSS2.p1.1.m1.5.6.1"></in><csymbol cd="latexml" id="A2.SS3.SSS2.p1.1.m1.5.6.2.cmml" xref="A2.SS3.SSS2.p1.1.m1.5.6.2">absent</csymbol><set id="A2.SS3.SSS2.p1.1.m1.5.6.3.1.cmml" xref="A2.SS3.SSS2.p1.1.m1.5.6.3.2"><cn id="A2.SS3.SSS2.p1.1.m1.1.1.cmml" type="integer" xref="A2.SS3.SSS2.p1.1.m1.1.1">1</cn><cn id="A2.SS3.SSS2.p1.1.m1.2.2.cmml" type="integer" xref="A2.SS3.SSS2.p1.1.m1.2.2">5</cn><cn id="A2.SS3.SSS2.p1.1.m1.3.3.cmml" type="integer" xref="A2.SS3.SSS2.p1.1.m1.3.3">10</cn><cn id="A2.SS3.SSS2.p1.1.m1.4.4.cmml" type="integer" xref="A2.SS3.SSS2.p1.1.m1.4.4">20</cn><cn id="A2.SS3.SSS2.p1.1.m1.5.5.cmml" type="integer" xref="A2.SS3.SSS2.p1.1.m1.5.5">50</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.SSS2.p1.1.m1.5c">\ \in\{1,5,10,20,50\}</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.SSS2.p1.1.m1.5d">∈ { 1 , 5 , 10 , 20 , 50 }</annotation></semantics></math> with <math alttext="N=50" class="ltx_Math" display="inline" id="A2.SS3.SSS2.p1.2.m2.1"><semantics id="A2.SS3.SSS2.p1.2.m2.1a"><mrow id="A2.SS3.SSS2.p1.2.m2.1.1" xref="A2.SS3.SSS2.p1.2.m2.1.1.cmml"><mi id="A2.SS3.SSS2.p1.2.m2.1.1.2" xref="A2.SS3.SSS2.p1.2.m2.1.1.2.cmml">N</mi><mo id="A2.SS3.SSS2.p1.2.m2.1.1.1" xref="A2.SS3.SSS2.p1.2.m2.1.1.1.cmml">=</mo><mn id="A2.SS3.SSS2.p1.2.m2.1.1.3" xref="A2.SS3.SSS2.p1.2.m2.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.SSS2.p1.2.m2.1b"><apply id="A2.SS3.SSS2.p1.2.m2.1.1.cmml" xref="A2.SS3.SSS2.p1.2.m2.1.1"><eq id="A2.SS3.SSS2.p1.2.m2.1.1.1.cmml" xref="A2.SS3.SSS2.p1.2.m2.1.1.1"></eq><ci id="A2.SS3.SSS2.p1.2.m2.1.1.2.cmml" xref="A2.SS3.SSS2.p1.2.m2.1.1.2">𝑁</ci><cn id="A2.SS3.SSS2.p1.2.m2.1.1.3.cmml" type="integer" xref="A2.SS3.SSS2.p1.2.m2.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.SSS2.p1.2.m2.1c">N=50</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.SSS2.p1.2.m2.1d">italic_N = 50</annotation></semantics></math> samples<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>These are the largest sample counts that are feasible to compute on our hardware given the scope of our experiments.</span></span></span> at temperature 1, top-p 0.95. We compute pass@k statistics with the same procedure as <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib11" title="">2021</a>)</cite>. The results of these evaluations are reported throughout the paper and shown in Figures <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.F4" title="Figure 4 ‣ 3.3 Finetuning Language Models on LintSeq Edit Sequences ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">4</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.F5" title="Figure 5 ‣ 3.3.2 Gemma 2, Phi-3, and Llama 3.1 ‣ 3.3 Finetuning Language Models on LintSeq Edit Sequences ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">5</span></a> and Tables <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.T8" title="Table 8 ‣ F.2.1 Inference-Time Scaling Laws ‣ F.2 Finetuning TinyCodeLM ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">8</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.T9" title="Table 9 ‣ F.2.1 Inference-Time Scaling Laws ‣ F.2 Finetuning TinyCodeLM ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">9</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.T10" title="Table 10 ‣ F.3.1 Inference-Time Scaling Laws ‣ F.3 Finetuning Gemma 2, Phi-3, and Llama 3.1 ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">10</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.T11" title="Table 11 ‣ F.3.1 Inference-Time Scaling Laws ‣ F.3 Finetuning Gemma 2, Phi-3, and Llama 3.1 ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">11</span></a>. In each of these Figures and Tables, we identify the most performant checkpoint from each model-data finetuning run by comparing pass@50 score at temperature 1 on HumanEval and MBPP(+) across checkpoints.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS3.SSS2.p2">
<p class="ltx_p" id="A2.SS3.SSS2.p2.3">Many existing state-of-the-art code synthesis LMs only report temperature-tuned pass@k scores on HumanEval, including Codex, AlphaCode, and Codegen-Mono <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib11" title="">2021</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib24" title="">2022b</a>; Nijkamp et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib30" title="">2022</a>)</cite>. Thus, in Tables <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.T1" title="Table 1 ‣ 3.2 Generating a Synthetic Dataset with LintSeq ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.T2" title="Table 2 ‣ 3.2 Generating a Synthetic Dataset with LintSeq ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">2</span></a>, we select the single best overall checkpoint of each TinyCodeLM model by averaging HumanEval and MBPP(+) pass@50 score. Then, we temperature-tune each checkpoint’s pass@1 and pass@10 scores when reporting results. On HumanEval, we test temperatures <math alttext="\tau\in\{0.0,0.2,0.4,0.8,1.0\}" class="ltx_Math" display="inline" id="A2.SS3.SSS2.p2.1.m1.5"><semantics id="A2.SS3.SSS2.p2.1.m1.5a"><mrow id="A2.SS3.SSS2.p2.1.m1.5.6" xref="A2.SS3.SSS2.p2.1.m1.5.6.cmml"><mi id="A2.SS3.SSS2.p2.1.m1.5.6.2" xref="A2.SS3.SSS2.p2.1.m1.5.6.2.cmml">τ</mi><mo id="A2.SS3.SSS2.p2.1.m1.5.6.1" xref="A2.SS3.SSS2.p2.1.m1.5.6.1.cmml">∈</mo><mrow id="A2.SS3.SSS2.p2.1.m1.5.6.3.2" xref="A2.SS3.SSS2.p2.1.m1.5.6.3.1.cmml"><mo id="A2.SS3.SSS2.p2.1.m1.5.6.3.2.1" stretchy="false" xref="A2.SS3.SSS2.p2.1.m1.5.6.3.1.cmml">{</mo><mn id="A2.SS3.SSS2.p2.1.m1.1.1" xref="A2.SS3.SSS2.p2.1.m1.1.1.cmml">0.0</mn><mo id="A2.SS3.SSS2.p2.1.m1.5.6.3.2.2" xref="A2.SS3.SSS2.p2.1.m1.5.6.3.1.cmml">,</mo><mn id="A2.SS3.SSS2.p2.1.m1.2.2" xref="A2.SS3.SSS2.p2.1.m1.2.2.cmml">0.2</mn><mo id="A2.SS3.SSS2.p2.1.m1.5.6.3.2.3" xref="A2.SS3.SSS2.p2.1.m1.5.6.3.1.cmml">,</mo><mn id="A2.SS3.SSS2.p2.1.m1.3.3" xref="A2.SS3.SSS2.p2.1.m1.3.3.cmml">0.4</mn><mo id="A2.SS3.SSS2.p2.1.m1.5.6.3.2.4" xref="A2.SS3.SSS2.p2.1.m1.5.6.3.1.cmml">,</mo><mn id="A2.SS3.SSS2.p2.1.m1.4.4" xref="A2.SS3.SSS2.p2.1.m1.4.4.cmml">0.8</mn><mo id="A2.SS3.SSS2.p2.1.m1.5.6.3.2.5" xref="A2.SS3.SSS2.p2.1.m1.5.6.3.1.cmml">,</mo><mn id="A2.SS3.SSS2.p2.1.m1.5.5" xref="A2.SS3.SSS2.p2.1.m1.5.5.cmml">1.0</mn><mo id="A2.SS3.SSS2.p2.1.m1.5.6.3.2.6" stretchy="false" xref="A2.SS3.SSS2.p2.1.m1.5.6.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.SSS2.p2.1.m1.5b"><apply id="A2.SS3.SSS2.p2.1.m1.5.6.cmml" xref="A2.SS3.SSS2.p2.1.m1.5.6"><in id="A2.SS3.SSS2.p2.1.m1.5.6.1.cmml" xref="A2.SS3.SSS2.p2.1.m1.5.6.1"></in><ci id="A2.SS3.SSS2.p2.1.m1.5.6.2.cmml" xref="A2.SS3.SSS2.p2.1.m1.5.6.2">𝜏</ci><set id="A2.SS3.SSS2.p2.1.m1.5.6.3.1.cmml" xref="A2.SS3.SSS2.p2.1.m1.5.6.3.2"><cn id="A2.SS3.SSS2.p2.1.m1.1.1.cmml" type="float" xref="A2.SS3.SSS2.p2.1.m1.1.1">0.0</cn><cn id="A2.SS3.SSS2.p2.1.m1.2.2.cmml" type="float" xref="A2.SS3.SSS2.p2.1.m1.2.2">0.2</cn><cn id="A2.SS3.SSS2.p2.1.m1.3.3.cmml" type="float" xref="A2.SS3.SSS2.p2.1.m1.3.3">0.4</cn><cn id="A2.SS3.SSS2.p2.1.m1.4.4.cmml" type="float" xref="A2.SS3.SSS2.p2.1.m1.4.4">0.8</cn><cn id="A2.SS3.SSS2.p2.1.m1.5.5.cmml" type="float" xref="A2.SS3.SSS2.p2.1.m1.5.5">1.0</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.SSS2.p2.1.m1.5c">\tau\in\{0.0,0.2,0.4,0.8,1.0\}</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.SSS2.p2.1.m1.5d">italic_τ ∈ { 0.0 , 0.2 , 0.4 , 0.8 , 1.0 }</annotation></semantics></math>. On MBPP(+), we sweep over a smaller temperature range, <math alttext="\tau\in\{0.0,0.1,1.0\}" class="ltx_Math" display="inline" id="A2.SS3.SSS2.p2.2.m2.3"><semantics id="A2.SS3.SSS2.p2.2.m2.3a"><mrow id="A2.SS3.SSS2.p2.2.m2.3.4" xref="A2.SS3.SSS2.p2.2.m2.3.4.cmml"><mi id="A2.SS3.SSS2.p2.2.m2.3.4.2" xref="A2.SS3.SSS2.p2.2.m2.3.4.2.cmml">τ</mi><mo id="A2.SS3.SSS2.p2.2.m2.3.4.1" xref="A2.SS3.SSS2.p2.2.m2.3.4.1.cmml">∈</mo><mrow id="A2.SS3.SSS2.p2.2.m2.3.4.3.2" xref="A2.SS3.SSS2.p2.2.m2.3.4.3.1.cmml"><mo id="A2.SS3.SSS2.p2.2.m2.3.4.3.2.1" stretchy="false" xref="A2.SS3.SSS2.p2.2.m2.3.4.3.1.cmml">{</mo><mn id="A2.SS3.SSS2.p2.2.m2.1.1" xref="A2.SS3.SSS2.p2.2.m2.1.1.cmml">0.0</mn><mo id="A2.SS3.SSS2.p2.2.m2.3.4.3.2.2" xref="A2.SS3.SSS2.p2.2.m2.3.4.3.1.cmml">,</mo><mn id="A2.SS3.SSS2.p2.2.m2.2.2" xref="A2.SS3.SSS2.p2.2.m2.2.2.cmml">0.1</mn><mo id="A2.SS3.SSS2.p2.2.m2.3.4.3.2.3" xref="A2.SS3.SSS2.p2.2.m2.3.4.3.1.cmml">,</mo><mn id="A2.SS3.SSS2.p2.2.m2.3.3" xref="A2.SS3.SSS2.p2.2.m2.3.3.cmml">1.0</mn><mo id="A2.SS3.SSS2.p2.2.m2.3.4.3.2.4" stretchy="false" xref="A2.SS3.SSS2.p2.2.m2.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.SSS2.p2.2.m2.3b"><apply id="A2.SS3.SSS2.p2.2.m2.3.4.cmml" xref="A2.SS3.SSS2.p2.2.m2.3.4"><in id="A2.SS3.SSS2.p2.2.m2.3.4.1.cmml" xref="A2.SS3.SSS2.p2.2.m2.3.4.1"></in><ci id="A2.SS3.SSS2.p2.2.m2.3.4.2.cmml" xref="A2.SS3.SSS2.p2.2.m2.3.4.2">𝜏</ci><set id="A2.SS3.SSS2.p2.2.m2.3.4.3.1.cmml" xref="A2.SS3.SSS2.p2.2.m2.3.4.3.2"><cn id="A2.SS3.SSS2.p2.2.m2.1.1.cmml" type="float" xref="A2.SS3.SSS2.p2.2.m2.1.1">0.0</cn><cn id="A2.SS3.SSS2.p2.2.m2.2.2.cmml" type="float" xref="A2.SS3.SSS2.p2.2.m2.2.2">0.1</cn><cn id="A2.SS3.SSS2.p2.2.m2.3.3.cmml" type="float" xref="A2.SS3.SSS2.p2.2.m2.3.3">1.0</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.SSS2.p2.2.m2.3c">\tau\in\{0.0,0.1,1.0\}</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.SSS2.p2.2.m2.3d">italic_τ ∈ { 0.0 , 0.1 , 1.0 }</annotation></semantics></math>. We perform the same temperature tuning procedure when reporting external model benchmark scores as well, i.e. the scores annotated with “<math alttext="(\dagger)" class="ltx_Math" display="inline" id="A2.SS3.SSS2.p2.3.m3.1"><semantics id="A2.SS3.SSS2.p2.3.m3.1a"><mrow id="A2.SS3.SSS2.p2.3.m3.1.2.2"><mo id="A2.SS3.SSS2.p2.3.m3.1.2.2.1" stretchy="false">(</mo><mo id="A2.SS3.SSS2.p2.3.m3.1.1" lspace="0em" rspace="0em" xref="A2.SS3.SSS2.p2.3.m3.1.1.cmml">†</mo><mo id="A2.SS3.SSS2.p2.3.m3.1.2.2.2" stretchy="false">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.SSS2.p2.3.m3.1b"><ci id="A2.SS3.SSS2.p2.3.m3.1.1.cmml" xref="A2.SS3.SSS2.p2.3.m3.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.SSS2.p2.3.m3.1c">(\dagger)</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.SSS2.p2.3.m3.1d">( † )</annotation></semantics></math>” in Tables <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.T1" title="Table 1 ‣ 3.2 Generating a Synthetic Dataset with LintSeq ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.T2" title="Table 2 ‣ 3.2 Generating a Synthetic Dataset with LintSeq ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">2</span></a>. When running benchmark evaluations with these external code LMs, we stray from the prompt formatting, generation, and parsing procedures described in Appendices <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A2.SS1" title="B.1 Prompting ‣ Appendix B Evaluation ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">B.1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A2.SS2" title="B.2 Generation and Parsing ‣ Appendix B Evaluation ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">B.2</span></a>; instead, in the interest of a fair evaluation, we reproduce the conventions reported by model authors to report other scores.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Pretraining</h2>
<div class="ltx_para ltx_noindent" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">We rely on data and libraries open-sourced by the HuggingFace, FineWeb, StarCoder, Dolma, OLMo, and PyTorch FSDP projects to pretrain our models <cite class="ltx_cite ltx_citemacro_citep">(Wolf et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib51" title="">2020</a>; Penedo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib31" title="">2024</a>; Lozhkov et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib26" title="">2024</a>; Soldaini et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib39" title="">2024</a>; Groeneveld et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib16" title="">2024</a>; Zhao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib53" title="">2023</a>)</cite>.</p>
</div>
<section class="ltx_subsection" id="A3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Model Architectures and Pretraining Hyperparameters</h3>
<figure class="ltx_table" id="A3.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span><span class="ltx_text ltx_font_bold" id="A3.T3.5.1">Architectural and pretraining hyperparameters</span> of our “on device” 150M and 400M parameter TinyCodeLM models, pretrained on a mixture of Web text and code for Python understanding.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A3.T3.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T3.3.4.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="A3.T3.3.4.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T3.3.4.1.2"><span class="ltx_text ltx_font_bold" id="A3.T3.3.4.1.2.1">TinyCodeLM</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.5.2">
<th class="ltx_td ltx_th ltx_th_row" id="A3.T3.3.5.2.1"></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="A3.T3.3.5.2.2">Smallest, 150M Parameters</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A3.T3.3.5.2.3">Small, 400M Parameters</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="A3.T3.3.6.3.1">Transformer Architecture</th>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A3.T3.3.6.3.2">decoder-only</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A3.T3.3.6.3.3">decoder-only</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.7.4.1">Model Family</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.7.4.2"><span class="ltx_text ltx_font_typewriter" id="A3.T3.3.7.4.2.1">OlmoForCausalLM</span></td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.7.4.3"><span class="ltx_text ltx_font_typewriter" id="A3.T3.3.7.4.3.1">OlmoForCausalLM</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.8.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.8.5.1">Tokenizer</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.8.5.2">GPT-NeoX-20B-OLMo</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.8.5.3">GPT-NeoX-20B-OLMo</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.9.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.9.6.1">Attention Bias</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.9.6.2">False</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.9.6.3">False</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.10.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.10.7.1">Attention Dropout</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.10.7.2">0.0</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.10.7.3">0.0</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.11.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.11.8.1">Hidden Activation</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.11.8.2"><span class="ltx_text ltx_font_typewriter" id="A3.T3.3.11.8.2.1">SwiGLU</span></td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.11.8.3"><span class="ltx_text ltx_font_typewriter" id="A3.T3.3.11.8.3.1">SwiGLU</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.12.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.12.9.1">Hidden Size</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.12.9.2">768</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.12.9.3">1024</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.13.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.13.10.1">Intermediate Size</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.13.10.2">3072</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.13.10.3">4096</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.14.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.14.11.1">Number of Attention Heads</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.14.11.2">12</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.14.11.3">16</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.15.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.15.12.1">Number of Hidden Layers</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.15.12.2">12</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.15.12.3">24</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.16.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.16.13.1">Number of Key-Value Heads</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.16.13.2">12</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.16.13.3">16</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.17.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.17.14.1">Vocabulary Size</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.17.14.2">50304</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.17.14.3">50304</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.18.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.18.15.1">Positional Encodings</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.18.15.2">Rotary (<span class="ltx_text ltx_font_typewriter" id="A3.T3.3.18.15.2.1">RoPE</span>)</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.18.15.3">Rotary (<span class="ltx_text ltx_font_typewriter" id="A3.T3.3.18.15.3.1">RoPE</span>)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.19.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.19.16.1">Mixed Precision</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.19.16.2"><span class="ltx_text ltx_font_typewriter" id="A3.T3.3.19.16.2.1">BFLOAT16</span></td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.19.16.3"><span class="ltx_text ltx_font_typewriter" id="A3.T3.3.19.16.3.1">BFLOAT16</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.20.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.20.17.1">Weight Tying</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.20.17.2">True</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.20.17.3">True</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.21.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.21.18.1">Flash Attention 2</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.21.18.2">True</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.21.18.3">True</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.22.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="A3.T3.3.22.19.1">Optimizer</th>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A3.T3.3.22.19.2">AdamW</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A3.T3.3.22.19.3">AdamW</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.23.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.23.20.1">Learning Rate</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.23.20.2">0.0003</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.23.20.3">0.0003</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.24.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.24.21.1">Weight Decay</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.24.21.2">0.01</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.24.21.3">0.01</td>
</tr>
<tr class="ltx_tr" id="A3.T3.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.2.2.3">Betas</th>
<td class="ltx_td ltx_align_right" id="A3.T3.1.1.1"><math alttext="(0.9,0.95)" class="ltx_Math" display="inline" id="A3.T3.1.1.1.m1.2"><semantics id="A3.T3.1.1.1.m1.2a"><mrow id="A3.T3.1.1.1.m1.2.3.2" xref="A3.T3.1.1.1.m1.2.3.1.cmml"><mo id="A3.T3.1.1.1.m1.2.3.2.1" stretchy="false" xref="A3.T3.1.1.1.m1.2.3.1.cmml">(</mo><mn id="A3.T3.1.1.1.m1.1.1" xref="A3.T3.1.1.1.m1.1.1.cmml">0.9</mn><mo id="A3.T3.1.1.1.m1.2.3.2.2" xref="A3.T3.1.1.1.m1.2.3.1.cmml">,</mo><mn id="A3.T3.1.1.1.m1.2.2" xref="A3.T3.1.1.1.m1.2.2.cmml">0.95</mn><mo id="A3.T3.1.1.1.m1.2.3.2.3" stretchy="false" xref="A3.T3.1.1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.1.1.1.m1.2b"><interval closure="open" id="A3.T3.1.1.1.m1.2.3.1.cmml" xref="A3.T3.1.1.1.m1.2.3.2"><cn id="A3.T3.1.1.1.m1.1.1.cmml" type="float" xref="A3.T3.1.1.1.m1.1.1">0.9</cn><cn id="A3.T3.1.1.1.m1.2.2.cmml" type="float" xref="A3.T3.1.1.1.m1.2.2">0.95</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.1.1.1.m1.2c">(0.9,0.95)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.1.1.1.m1.2d">( 0.9 , 0.95 )</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="A3.T3.2.2.2"><math alttext="(0.9,0.95)" class="ltx_Math" display="inline" id="A3.T3.2.2.2.m1.2"><semantics id="A3.T3.2.2.2.m1.2a"><mrow id="A3.T3.2.2.2.m1.2.3.2" xref="A3.T3.2.2.2.m1.2.3.1.cmml"><mo id="A3.T3.2.2.2.m1.2.3.2.1" stretchy="false" xref="A3.T3.2.2.2.m1.2.3.1.cmml">(</mo><mn id="A3.T3.2.2.2.m1.1.1" xref="A3.T3.2.2.2.m1.1.1.cmml">0.9</mn><mo id="A3.T3.2.2.2.m1.2.3.2.2" xref="A3.T3.2.2.2.m1.2.3.1.cmml">,</mo><mn id="A3.T3.2.2.2.m1.2.2" xref="A3.T3.2.2.2.m1.2.2.cmml">0.95</mn><mo id="A3.T3.2.2.2.m1.2.3.2.3" stretchy="false" xref="A3.T3.2.2.2.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.2.2.2.m1.2b"><interval closure="open" id="A3.T3.2.2.2.m1.2.3.1.cmml" xref="A3.T3.2.2.2.m1.2.3.2"><cn id="A3.T3.2.2.2.m1.1.1.cmml" type="float" xref="A3.T3.2.2.2.m1.1.1">0.9</cn><cn id="A3.T3.2.2.2.m1.2.2.cmml" type="float" xref="A3.T3.2.2.2.m1.2.2">0.95</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.2.2.2.m1.2c">(0.9,0.95)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.2.2.2.m1.2d">( 0.9 , 0.95 )</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.25.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.25.22.1">Epsilon</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.25.22.2">1.0e-05</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.25.22.3">1.0e-05</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.26.23">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="A3.T3.3.26.23.1">Learning Rate Scheduler</th>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A3.T3.3.26.23.2">cosine (with warmup)</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A3.T3.3.26.23.3">cosine (with warmup)</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.27.24">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.27.24.1">Number of Warm-Up Steps</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.27.24.2">100</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.27.24.3">100</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.3.3.1">Alpha-f (<math alttext="\alpha_{f}" class="ltx_Math" display="inline" id="A3.T3.3.3.1.m1.1"><semantics id="A3.T3.3.3.1.m1.1a"><msub id="A3.T3.3.3.1.m1.1.1" xref="A3.T3.3.3.1.m1.1.1.cmml"><mi id="A3.T3.3.3.1.m1.1.1.2" xref="A3.T3.3.3.1.m1.1.1.2.cmml">α</mi><mi id="A3.T3.3.3.1.m1.1.1.3" xref="A3.T3.3.3.1.m1.1.1.3.cmml">f</mi></msub><annotation-xml encoding="MathML-Content" id="A3.T3.3.3.1.m1.1b"><apply id="A3.T3.3.3.1.m1.1.1.cmml" xref="A3.T3.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="A3.T3.3.3.1.m1.1.1.1.cmml" xref="A3.T3.3.3.1.m1.1.1">subscript</csymbol><ci id="A3.T3.3.3.1.m1.1.1.2.cmml" xref="A3.T3.3.3.1.m1.1.1.2">𝛼</ci><ci id="A3.T3.3.3.1.m1.1.1.3.cmml" xref="A3.T3.3.3.1.m1.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.3.3.1.m1.1c">\alpha_{f}</annotation><annotation encoding="application/x-llamapun" id="A3.T3.3.3.1.m1.1d">italic_α start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT</annotation></semantics></math>)</th>
<td class="ltx_td ltx_align_right" id="A3.T3.3.3.2">0.1</td>
<td class="ltx_td ltx_align_right" id="A3.T3.3.3.3">0.1</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.28.25">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A3.T3.3.28.25.1">Total Epochs of Pretraining</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A3.T3.3.28.25.2">2</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A3.T3.3.28.25.3">2</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="A3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Pretraining Data Mix</h3>
<figure class="ltx_table" id="A3.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span><span class="ltx_text ltx_font_bold" id="A3.T4.2.1">Pretraining data mix</span> used to train both TinyCodeLM models. Datasets were tokenized and prepared using HuggingFace and Dolma tooling <cite class="ltx_cite ltx_citemacro_citep">(Wolf et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib51" title="">2020</a>; Soldaini et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib39" title="">2024</a>)</cite>.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A3.T4.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A3.T4.3.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A3.T4.3.1.1.1">Pretraining Data Source</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A3.T4.3.1.1.2">Subset</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A3.T4.3.1.1.3">Tokens</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A3.T4.3.1.1.4">Documents</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T4.3.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="A3.T4.3.2.1.1">FineWeb <cite class="ltx_cite ltx_citemacro_citep">(Penedo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib31" title="">2024</a>)</cite>
</th>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A3.T4.3.2.1.2">10BT Sample</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A3.T4.3.2.1.3">10.4BT</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A3.T4.3.2.1.4">14.9M</td>
</tr>
<tr class="ltx_tr" id="A3.T4.3.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A3.T4.3.3.2.1">The Stack <cite class="ltx_cite ltx_citemacro_citep">(Kocetkov et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib20" title="">2022</a>)</cite>
</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A3.T4.3.3.2.2">Python Only</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A3.T4.3.3.2.3">61.8BT</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A3.T4.3.3.2.4">24.2M</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Instruction Finetuning</h2>
<section class="ltx_subsection" id="A4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>Baseline Instruction Dataset</h3>
<div class="ltx_para ltx_noindent" id="A4.SS1.p1">
<p class="ltx_p" id="A4.SS1.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A4.T5" title="Table 5 ‣ D.1 Baseline Instruction Dataset ‣ Appendix D Instruction Finetuning ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">5</span></a> displays the data sources that are used to prepare the dataset described in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS2" title="3.2 Generating a Synthetic Dataset with LintSeq ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">3.2</span></a>. These data are pooled and preprocessed into instruction-program pairs by stripping away Markdown formatting and natural language explanations from completions (Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A5.F9" title="Figure 9 ‣ E.1 Examples of Generated Synthetic Edit Trajectories ‣ Appendix E More on Synthetic Data Generation with LintSeq ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">9</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A5.F10" title="Figure 10 ‣ E.1 Examples of Generated Synthetic Edit Trajectories ‣ Appendix E More on Synthetic Data Generation with LintSeq ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">10</span></a>). In our experiments, we use the resultant data to finetune baseline models, comparing their performance to those of LMs finetuned on edit sequences generated with LintSeq from the same set of instruction-program pairs.</p>
</div>
<figure class="ltx_table" id="A4.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A4.T5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A4.T5.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A4.T5.1.1.1.1">HuggingFace Instruction Data Source</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A4.T5.1.1.1.2">Subset</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A4.T5.1.1.1.3">Examples</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.T5.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A4.T5.1.2.1.1"><span class="ltx_text ltx_font_typewriter" id="A4.T5.1.2.1.1.1">bigcode/self-oss-instruct-sc2-exec-filter-50k</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A4.T5.1.2.1.2">Full</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A4.T5.1.2.1.3">50,661</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.3.2">
<td class="ltx_td ltx_align_left" id="A4.T5.1.3.2.1"><span class="ltx_text ltx_font_typewriter" id="A4.T5.1.3.2.1.1">ise-uiuc/Magicoder-OSS-Instruct-75K</span></td>
<td class="ltx_td ltx_align_right" id="A4.T5.1.3.2.2">Python</td>
<td class="ltx_td ltx_align_right" id="A4.T5.1.3.2.3">38,284</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.4.3">
<td class="ltx_td ltx_border_bb ltx_border_t" id="A4.T5.1.4.3.1"></td>
<td class="ltx_td ltx_border_bb ltx_border_t" id="A4.T5.1.4.3.2"></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="A4.T5.1.4.3.3"><span class="ltx_text ltx_font_bold" id="A4.T5.1.4.3.3.1">88,945</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span><span class="ltx_text ltx_font_bold" id="A4.T5.3.1">Instruction data mix</span> used to prepare the baseline instruction dataset in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS2" title="3.2 Generating a Synthetic Dataset with LintSeq ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">3.2</span></a>.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.2 </span>Procedures and Hyperparameters</h3>
<div class="ltx_para ltx_noindent" id="A4.SS2.p1">
<p class="ltx_p" id="A4.SS2.p1.1">We instruction finetune all models with Microsoft DeepSpeed using the ZeRO++ protocol for stage three sharding. For the largest of these models, we also use CPU parameter offloading to accelerate experiments <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib42" title="">2023a</a>; Ren et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib34" title="">2021</a>)</cite>. When finetuning models on LintSeq data, we add a new token “<span class="ltx_text ltx_font_typewriter" id="A4.SS2.p1.1.1">&lt;|diff|&gt;</span>” to tokenizers (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S2.SS4" title="2.4 Practicalities of Training Language Models on LintSeq Data ‣ 2 LintSeq: Code Synthesis as a Sequential Edit Problem ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">2.4</span></a>) and resize model embeddings accordingly.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.SS2.p2">
<p class="ltx_p" id="A4.SS2.p2.1">In our experiments with Gemma 2, Phi-3, and Llama 3.1 models, we use HuggingFace to access and load pretrained model weights and tokenizers. As mentioned in the main body of the paper, we instruction finetune <span class="ltx_text ltx_font_italic" id="A4.SS2.p2.1.1">pretrained-only</span> weights if open-sourced and available. This is the case for Gemma 2 and Llama 3.1 only, as of the writing of this paper.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.SS2.p3">
<p class="ltx_p" id="A4.SS2.p3.1">Across all of the finetuning experiments conducted in this paper, we train model-data variants with the same batch size and for an equal number of total optimizer steps. This optimizer step count corresponds to ten epochs of finetuning with the baseline instruction tuning dataset described in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS2" title="3.2 Generating a Synthetic Dataset with LintSeq ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">3.2</span></a>. We save intermediate checkpoints at equal optimizer step intervals in all experiments.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.SS2.p4">
<p class="ltx_p" id="A4.SS2.p4.2">In order to tune the peak learning rates used in each set of model experiments, we run a full sweep <math alttext="\alpha\in\{" class="ltx_math_unparsed" display="inline" id="A4.SS2.p4.1.m1.1"><semantics id="A4.SS2.p4.1.m1.1a"><mrow id="A4.SS2.p4.1.m1.1b"><mi id="A4.SS2.p4.1.m1.1.1">α</mi><mo id="A4.SS2.p4.1.m1.1.2">∈</mo><mo id="A4.SS2.p4.1.m1.1.3" stretchy="false">{</mo></mrow><annotation encoding="application/x-tex" id="A4.SS2.p4.1.m1.1c">\alpha\in\{</annotation><annotation encoding="application/x-llamapun" id="A4.SS2.p4.1.m1.1d">italic_α ∈ {</annotation></semantics></math>6e-4, 3e-4, 1e-4, 5e-5, 1e-5, 5e-6<math alttext="\}" class="ltx_Math" display="inline" id="A4.SS2.p4.2.m2.1"><semantics id="A4.SS2.p4.2.m2.1a"><mo id="A4.SS2.p4.2.m2.1.1" stretchy="false" xref="A4.SS2.p4.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="A4.SS2.p4.2.m2.1b"><ci id="A4.SS2.p4.2.m2.1.1.cmml" xref="A4.SS2.p4.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS2.p4.2.m2.1c">\}</annotation><annotation encoding="application/x-llamapun" id="A4.SS2.p4.2.m2.1d">}</annotation></semantics></math> in the baseline instruction data setting for each model. We select peak learning rate values by tracking the best-achieved downstream benchmark performance across models. The chosen values are displayed in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A4.T6" title="Table 6 ‣ D.2 Procedures and Hyperparameters ‣ Appendix D Instruction Finetuning ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">6</span></a>. All other finetuning hyperparameters are kept fixed at the settings in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A4.T7" title="Table 7 ‣ D.2 Procedures and Hyperparameters ‣ Appendix D Instruction Finetuning ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">7</span></a> across experiments.</p>
</div>
<figure class="ltx_table" id="A4.T6">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A4.T6.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.T6.1.2.1">
<td class="ltx_td ltx_border_tt" id="A4.T6.1.2.1.1"></td>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="A4.T6.1.2.1.2">TinyCodeLM</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A4.T6.1.2.1.3">Gemma 2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="A4.T6.1.2.1.4">Phi-3</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A4.T6.1.2.1.5">Llama 3.1</th>
</tr>
<tr class="ltx_tr" id="A4.T6.1.3.2">
<td class="ltx_td" id="A4.T6.1.3.2.1"></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A4.T6.1.3.2.2">150M</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A4.T6.1.3.2.3">400M</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A4.T6.1.3.2.4">2B</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A4.T6.1.3.2.5">3.8B</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A4.T6.1.3.2.6">14B</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A4.T6.1.3.2.7">8B</td>
</tr>
<tr class="ltx_tr" id="A4.T6.1.1">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="A4.T6.1.1.1">Peak Learning Rate (<math alttext="\alpha" class="ltx_Math" display="inline" id="A4.T6.1.1.1.m1.1"><semantics id="A4.T6.1.1.1.m1.1a"><mi id="A4.T6.1.1.1.m1.1.1" xref="A4.T6.1.1.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="A4.T6.1.1.1.m1.1b"><ci id="A4.T6.1.1.1.m1.1.1.cmml" xref="A4.T6.1.1.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.1.1.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="A4.T6.1.1.1.m1.1d">italic_α</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="A4.T6.1.1.2">3e-4</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="A4.T6.1.1.3">3e-4</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="A4.T6.1.1.4">5e-5</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="A4.T6.1.1.5">5e-5</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="A4.T6.1.1.6">1e-5</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="A4.T6.1.1.7">1e-5</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span><span class="ltx_text ltx_font_bold" id="A4.T6.3.1">Peak learning rates</span> used to instruction finetune models.</figcaption>
</figure>
<figure class="ltx_table" id="A4.T7">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A4.T7.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A4.T7.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="A4.T7.1.1.1.1"></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A4.T7.1.1.1.2">Hyperparameter Setting</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.T7.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="A4.T7.1.2.1.1">Learning Rate Scheduler</th>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A4.T7.1.2.1.2">linear</td>
</tr>
<tr class="ltx_tr" id="A4.T7.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A4.T7.1.3.2.1">Warmup Ratio</th>
<td class="ltx_td ltx_align_right" id="A4.T7.1.3.2.2">0.001</td>
</tr>
<tr class="ltx_tr" id="A4.T7.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A4.T7.1.4.3.1">Weight Decay</th>
<td class="ltx_td ltx_align_right" id="A4.T7.1.4.3.2">0.01</td>
</tr>
<tr class="ltx_tr" id="A4.T7.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A4.T7.1.5.4.1">Total Batch Size</th>
<td class="ltx_td ltx_align_right" id="A4.T7.1.5.4.2">512</td>
</tr>
<tr class="ltx_tr" id="A4.T7.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A4.T7.1.6.5.1">Batch Loss Reduction</th>
<td class="ltx_td ltx_align_right" id="A4.T7.1.6.5.2">sum</td>
</tr>
<tr class="ltx_tr" id="A4.T7.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A4.T7.1.7.6.1">Mixed Precision</th>
<td class="ltx_td ltx_align_right" id="A4.T7.1.7.6.2"><span class="ltx_text ltx_font_typewriter" id="A4.T7.1.7.6.2.1">BFLOAT16</span></td>
</tr>
<tr class="ltx_tr" id="A4.T7.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A4.T7.1.8.7.1">Max Sequence Length</th>
<td class="ltx_td ltx_align_right" id="A4.T7.1.8.7.2">1024</td>
</tr>
<tr class="ltx_tr" id="A4.T7.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A4.T7.1.9.8.1">Total Optimizer Steps</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A4.T7.1.9.8.2">1740</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span><span class="ltx_text ltx_font_bold" id="A4.T7.3.1">All other instruction finetuning settings</span>, re-used across experiments.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>More on Synthetic Data Generation with LintSeq</h2>
<section class="ltx_subsection" id="A5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>Examples of Generated Synthetic Edit Trajectories</h3>
<figure class="ltx_figure" id="A5.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="253" id="A5.F9.g1" src="extracted/5927317/template/figures/data_example_A_v5.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>LintSeq edit sequence samples vs baseline instruction-program data, <span class="ltx_text ltx_font_bold" id="A5.F9.2.1">example A</span>.</figcaption>
</figure>
<figure class="ltx_figure" id="A5.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="251" id="A5.F10.g1" src="extracted/5927317/template/figures/data_example_B_v5.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>LintSeq edit sequence samples vs baseline instruction-program data, <span class="ltx_text ltx_font_bold" id="A5.F10.2.1">example B</span>.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.2 </span>Tuning LintSeq Example Count</h3>
<figure class="ltx_figure" id="A5.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="104" id="A5.F11.g1" src="extracted/5927317/template/figures/tuning_lintseq_sample_count_v6.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span><span class="ltx_text ltx_font_bold" id="A5.F11.8.1">Probing the effect of varying the number of edit sequences sampled with LintSeq per instruction-example pair during data generation</span>: Using the source dataset described in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.SS2" title="3.2 Generating a Synthetic Dataset with LintSeq ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">3.2</span></a>, we sweep over the value of the LintSeq parameter <math alttext="s" class="ltx_Math" display="inline" id="A5.F11.4.m1.1"><semantics id="A5.F11.4.m1.1b"><mi id="A5.F11.4.m1.1.1" xref="A5.F11.4.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="A5.F11.4.m1.1c"><ci id="A5.F11.4.m1.1.1.cmml" xref="A5.F11.4.m1.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.F11.4.m1.1d">s</annotation><annotation encoding="application/x-llamapun" id="A5.F11.4.m1.1e">italic_s</annotation></semantics></math> used during synthetic data generation to yield three different edit sequence instruction datasets with <math alttext="s\in\{1,5,10\}" class="ltx_Math" display="inline" id="A5.F11.5.m2.3"><semantics id="A5.F11.5.m2.3b"><mrow id="A5.F11.5.m2.3.4" xref="A5.F11.5.m2.3.4.cmml"><mi id="A5.F11.5.m2.3.4.2" xref="A5.F11.5.m2.3.4.2.cmml">s</mi><mo id="A5.F11.5.m2.3.4.1" xref="A5.F11.5.m2.3.4.1.cmml">∈</mo><mrow id="A5.F11.5.m2.3.4.3.2" xref="A5.F11.5.m2.3.4.3.1.cmml"><mo id="A5.F11.5.m2.3.4.3.2.1" stretchy="false" xref="A5.F11.5.m2.3.4.3.1.cmml">{</mo><mn id="A5.F11.5.m2.1.1" xref="A5.F11.5.m2.1.1.cmml">1</mn><mo id="A5.F11.5.m2.3.4.3.2.2" xref="A5.F11.5.m2.3.4.3.1.cmml">,</mo><mn id="A5.F11.5.m2.2.2" xref="A5.F11.5.m2.2.2.cmml">5</mn><mo id="A5.F11.5.m2.3.4.3.2.3" xref="A5.F11.5.m2.3.4.3.1.cmml">,</mo><mn id="A5.F11.5.m2.3.3" xref="A5.F11.5.m2.3.3.cmml">10</mn><mo id="A5.F11.5.m2.3.4.3.2.4" stretchy="false" xref="A5.F11.5.m2.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A5.F11.5.m2.3c"><apply id="A5.F11.5.m2.3.4.cmml" xref="A5.F11.5.m2.3.4"><in id="A5.F11.5.m2.3.4.1.cmml" xref="A5.F11.5.m2.3.4.1"></in><ci id="A5.F11.5.m2.3.4.2.cmml" xref="A5.F11.5.m2.3.4.2">𝑠</ci><set id="A5.F11.5.m2.3.4.3.1.cmml" xref="A5.F11.5.m2.3.4.3.2"><cn id="A5.F11.5.m2.1.1.cmml" type="integer" xref="A5.F11.5.m2.1.1">1</cn><cn id="A5.F11.5.m2.2.2.cmml" type="integer" xref="A5.F11.5.m2.2.2">5</cn><cn id="A5.F11.5.m2.3.3.cmml" type="integer" xref="A5.F11.5.m2.3.3">10</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.F11.5.m2.3d">s\in\{1,5,10\}</annotation><annotation encoding="application/x-llamapun" id="A5.F11.5.m2.3e">italic_s ∈ { 1 , 5 , 10 }</annotation></semantics></math>. We finetune TinyCodeLM models on each of these datasets, and compare the resultant HumanEval and MBPP(+) performance vs samples (i.e. pass@k vs k) at temperature 1. The most performant values is <math alttext="s=5" class="ltx_Math" display="inline" id="A5.F11.6.m3.1"><semantics id="A5.F11.6.m3.1b"><mrow id="A5.F11.6.m3.1.1" xref="A5.F11.6.m3.1.1.cmml"><mi id="A5.F11.6.m3.1.1.2" xref="A5.F11.6.m3.1.1.2.cmml">s</mi><mo id="A5.F11.6.m3.1.1.1" xref="A5.F11.6.m3.1.1.1.cmml">=</mo><mn id="A5.F11.6.m3.1.1.3" xref="A5.F11.6.m3.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A5.F11.6.m3.1c"><apply id="A5.F11.6.m3.1.1.cmml" xref="A5.F11.6.m3.1.1"><eq id="A5.F11.6.m3.1.1.1.cmml" xref="A5.F11.6.m3.1.1.1"></eq><ci id="A5.F11.6.m3.1.1.2.cmml" xref="A5.F11.6.m3.1.1.2">𝑠</ci><cn id="A5.F11.6.m3.1.1.3.cmml" type="integer" xref="A5.F11.6.m3.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.F11.6.m3.1d">s=5</annotation><annotation encoding="application/x-llamapun" id="A5.F11.6.m3.1e">italic_s = 5</annotation></semantics></math>.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Additional Results</h2>
<section class="ltx_subsection" id="A6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">F.1 </span>Pretraining TinyCodeLM</h3>
<figure class="ltx_figure" id="A6.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="237" id="A6.F12.g1" src="extracted/5927317/template/figures/tinycodelm150_pt_curves_v1.png" width="494"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Evaluating the zero-shot Python synthesis capabilities of <span class="ltx_text ltx_font_bold" id="A6.F12.2.1">TinyCodeLM-150M</span> during pretraining on HumanEval and MBPP(+).</figcaption>
</figure>
<figure class="ltx_figure" id="A6.F13"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="239" id="A6.F13.g1" src="extracted/5927317/template/figures/tinycodelm400_pt_curves_v0.png" width="494"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Evaluating the zero-shot Python synthesis capabilities of <span class="ltx_text ltx_font_bold" id="A6.F13.2.1">TinyCodeLM-400M</span> during pretraining on HumanEval and MBPP(+).</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_subsection" id="A6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">F.2 </span>Finetuning TinyCodeLM</h3>
<section class="ltx_subsubsection" id="A6.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">F.2.1 </span>Inference-Time Scaling Laws</h4>
<figure class="ltx_table" id="A6.T8">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span><span class="ltx_text ltx_font_bold" id="A6.T8.3.1">HumanEval</span> fixed-temperature coverage scaling results achieved by finetuning <span class="ltx_text ltx_font_typewriter" id="A6.T8.4.2">TinyCodeLM</span> models (zero-shot, temperature = 1, top-p = 0.95).</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A6.T8.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A6.T8.5.1.1">
<td class="ltx_td ltx_border_tt" id="A6.T8.5.1.1.1"></td>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="A6.T8.5.1.1.2"></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="A6.T8.5.1.1.3"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5" id="A6.T8.5.1.1.4">HumanEval</th>
</tr>
<tr class="ltx_tr" id="A6.T8.5.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="A6.T8.5.2.2.1">Model Variant</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="A6.T8.5.2.2.2">Size</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A6.T8.5.2.2.3">
<span class="ltx_inline-block" id="A6.T8.5.2.2.3.1">
<span class="ltx_p" id="A6.T8.5.2.2.3.1.1">Linter</span>
<span class="ltx_p" id="A6.T8.5.2.2.3.1.2">Guided</span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T8.5.2.2.4">pass@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T8.5.2.2.5">pass@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T8.5.2.2.6">pass@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T8.5.2.2.7">pass@20</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T8.5.2.2.8">pass@50</th>
</tr>
<tr class="ltx_tr" id="A6.T8.5.3.3">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A6.T8.5.3.3.1">tinycodeLM-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A6.T8.5.3.3.2">150M</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T8.5.3.3.3">-</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T8.5.3.3.4">6.2</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T8.5.3.3.5">10.4</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T8.5.3.3.6">12.3</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T8.5.3.3.7">14.5</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T8.5.3.3.8">18.3</td>
</tr>
<tr class="ltx_tr" id="A6.T8.5.4.4">
<td class="ltx_td ltx_align_left" id="A6.T8.5.4.4.1">tinycodeLM-RandSeqInstruct</td>
<td class="ltx_td ltx_align_left" id="A6.T8.5.4.4.2">150M</td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.4.4.3"><span class="ltx_text" id="A6.T8.5.4.4.3.1">✗</span></td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.4.4.4">4.0</td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.4.4.5">9.7</td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.4.4.6">11.9</td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.4.4.7">14.4</td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.4.4.8">17.7 (<span class="ltx_text ltx_font_bold" id="A6.T8.5.4.4.8.1">-0.6</span>)</td>
</tr>
<tr class="ltx_tr" id="A6.T8.5.5.5">
<td class="ltx_td ltx_align_left" id="A6.T8.5.5.5.1">tinycodeLM-LintSeqInstruct</td>
<td class="ltx_td ltx_align_left" id="A6.T8.5.5.5.2">150M</td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.5.5.3"><span class="ltx_text" id="A6.T8.5.5.5.3.1" style="color:#4F25E9;">✓</span></td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.5.5.4">6.4</td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.5.5.5">14.3</td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.5.5.6">17.7</td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.5.5.7">20.4</td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.5.5.8">22.6 (<span class="ltx_text ltx_font_bold" id="A6.T8.5.5.5.8.1" style="color:#4F25E9;">+4.3</span>)</td>
</tr>
<tr class="ltx_tr" id="A6.T8.5.6.6">
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T8.5.6.6.1">tinycodeLM-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T8.5.6.6.2">400M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T8.5.6.6.3">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T8.5.6.6.4">6.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T8.5.6.6.5">11.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T8.5.6.6.6">13.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T8.5.6.6.7">16.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T8.5.6.6.8">18.9</td>
</tr>
<tr class="ltx_tr" id="A6.T8.5.7.7">
<td class="ltx_td ltx_align_left" id="A6.T8.5.7.7.1">tinycodeLM-RandSeqInstruct</td>
<td class="ltx_td ltx_align_left" id="A6.T8.5.7.7.2">400M</td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.7.7.3"><span class="ltx_text" id="A6.T8.5.7.7.3.1">✗</span></td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.7.7.4">7.2</td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.7.7.5">12.7</td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.7.7.6">15.6</td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.7.7.7">18.6</td>
<td class="ltx_td ltx_align_center" id="A6.T8.5.7.7.8">22.0 (<span class="ltx_text ltx_font_bold" id="A6.T8.5.7.7.8.1">+3.1</span>)</td>
</tr>
<tr class="ltx_tr" id="A6.T8.5.8.8">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A6.T8.5.8.8.1">tinycodeLM-LintSeqInstruct</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A6.T8.5.8.8.2">400M</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T8.5.8.8.3"><span class="ltx_text" id="A6.T8.5.8.8.3.1" style="color:#4F25E9;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T8.5.8.8.4">7.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T8.5.8.8.5">14.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T8.5.8.8.6">18.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T8.5.8.8.7">21.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T8.5.8.8.8">26.8 ( <span class="ltx_text ltx_font_bold" id="A6.T8.5.8.8.8.1" style="color:#4F25E9;">+7.9</span>)</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="A6.T9">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span><span class="ltx_text ltx_font_bold" id="A6.T9.3.1">MBPP(+)</span> fixed-temperature coverage scaling results achieved by finetuning <span class="ltx_text ltx_font_typewriter" id="A6.T9.4.2">TinyCodeLM</span> models (zero-shot, temperature = 1, top-p = 0.95).</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A6.T9.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A6.T9.5.1.1">
<td class="ltx_td ltx_border_tt" id="A6.T9.5.1.1.1"></td>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="A6.T9.5.1.1.2"></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="A6.T9.5.1.1.3"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5" id="A6.T9.5.1.1.4">MBPP(+)</th>
</tr>
<tr class="ltx_tr" id="A6.T9.5.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="A6.T9.5.2.2.1">Model Variant</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="A6.T9.5.2.2.2">Size</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A6.T9.5.2.2.3">
<span class="ltx_inline-block" id="A6.T9.5.2.2.3.1">
<span class="ltx_p" id="A6.T9.5.2.2.3.1.1">Linter</span>
<span class="ltx_p" id="A6.T9.5.2.2.3.1.2">Guided</span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T9.5.2.2.4">pass@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T9.5.2.2.5">pass@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T9.5.2.2.6">pass@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T9.5.2.2.7">pass@20</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T9.5.2.2.8">pass@50</th>
</tr>
<tr class="ltx_tr" id="A6.T9.5.3.3">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A6.T9.5.3.3.1">tinycodeLM-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A6.T9.5.3.3.2">150M</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T9.5.3.3.3">-</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T9.5.3.3.4">7.3</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T9.5.3.3.5">16.4</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T9.5.3.3.6">20.4</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T9.5.3.3.7">24.6</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T9.5.3.3.8">30.6</td>
</tr>
<tr class="ltx_tr" id="A6.T9.5.4.4">
<td class="ltx_td ltx_align_left" id="A6.T9.5.4.4.1">tinycodeLM-RandSeqInstruct</td>
<td class="ltx_td ltx_align_left" id="A6.T9.5.4.4.2">150M</td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.4.4.3"><span class="ltx_text" id="A6.T9.5.4.4.3.1">✗</span></td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.4.4.4">4.3</td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.4.4.5">13.1</td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.4.4.6">18.4</td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.4.4.7">23.7</td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.4.4.8">30.2 (<span class="ltx_text ltx_font_bold" id="A6.T9.5.4.4.8.1">-0.4</span>)</td>
</tr>
<tr class="ltx_tr" id="A6.T9.5.5.5">
<td class="ltx_td ltx_align_left" id="A6.T9.5.5.5.1">tinycodeLM-LintSeqInstruct</td>
<td class="ltx_td ltx_align_left" id="A6.T9.5.5.5.2">150M</td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.5.5.3"><span class="ltx_text" id="A6.T9.5.5.5.3.1" style="color:#4F25E9;">✓</span></td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.5.5.4">7.5</td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.5.5.5">18.2</td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.5.5.6">23.4</td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.5.5.7">28.5</td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.5.5.8">34.5 (<span class="ltx_text ltx_font_bold" id="A6.T9.5.5.5.8.1" style="color:#4F25E9;">+3.9</span>)</td>
</tr>
<tr class="ltx_tr" id="A6.T9.5.6.6">
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T9.5.6.6.1">tinycodeLM-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T9.5.6.6.2">400M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T9.5.6.6.3">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T9.5.6.6.4">9.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T9.5.6.6.5">17.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T9.5.6.6.6">22.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T9.5.6.6.7">26.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T9.5.6.6.8">32.4</td>
</tr>
<tr class="ltx_tr" id="A6.T9.5.7.7">
<td class="ltx_td ltx_align_left" id="A6.T9.5.7.7.1">tinycodeLM-RandSeqInstruct</td>
<td class="ltx_td ltx_align_left" id="A6.T9.5.7.7.2">400M</td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.7.7.3"><span class="ltx_text" id="A6.T9.5.7.7.3.1">✗</span></td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.7.7.4">5.5</td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.7.7.5">15.9</td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.7.7.6">21.5</td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.7.7.7">27.0</td>
<td class="ltx_td ltx_align_center" id="A6.T9.5.7.7.8">34.5 (<span class="ltx_text ltx_font_bold" id="A6.T9.5.7.7.8.1">+2.1</span>)</td>
</tr>
<tr class="ltx_tr" id="A6.T9.5.8.8">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A6.T9.5.8.8.1">tinycodeLM-LintSeqInstruct</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A6.T9.5.8.8.2">400M</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T9.5.8.8.3"><span class="ltx_text" id="A6.T9.5.8.8.3.1" style="color:#4F25E9;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T9.5.8.8.4">13.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T9.5.8.8.5">25.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T9.5.8.8.6">29.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T9.5.8.8.7">34.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T9.5.8.8.8">39.6 (<span class="ltx_text ltx_font_bold" id="A6.T9.5.8.8.8.1" style="color:#4F25E9;">+7.2</span>)</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_subsection" id="A6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">F.3 </span>Finetuning Gemma 2, Phi-3, and Llama 3.1</h3>
<section class="ltx_subsubsection" id="A6.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">F.3.1 </span>Inference-Time Scaling Laws</h4>
<figure class="ltx_table" id="A6.T10">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span><span class="ltx_text ltx_font_bold" id="A6.T10.2.1">HumanEval</span> fixed-temperature coverage scaling results achieved by finetuning Gemma 2, Phi-3, and Llama 3.1 models (zero-shot, temperature = 1, top-p = 0.95).</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A6.T10.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A6.T10.3.1.1">
<td class="ltx_td ltx_border_tt" id="A6.T10.3.1.1.1"></td>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="A6.T10.3.1.1.2"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5" id="A6.T10.3.1.1.3">HumanEval</th>
</tr>
<tr class="ltx_tr" id="A6.T10.3.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="A6.T10.3.2.2.1">Model Variant</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="A6.T10.3.2.2.2">Parameters</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T10.3.2.2.3">pass@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T10.3.2.2.4">pass@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T10.3.2.2.5">pass@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T10.3.2.2.6">pass@20</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T10.3.2.2.7">pass@50</th>
</tr>
<tr class="ltx_tr" id="A6.T10.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A6.T10.3.3.3.1">Gemma-2-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A6.T10.3.3.3.2">2.6B</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T10.3.3.3.3">16.1</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T10.3.3.3.4">26.3</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T10.3.3.3.5">30.5</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T10.3.3.3.6">34.6</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T10.3.3.3.7">40.2</td>
</tr>
<tr class="ltx_tr" id="A6.T10.3.4.4">
<td class="ltx_td ltx_align_left" id="A6.T10.3.4.4.1">Gemma-2-LintSeqInstruct</td>
<td class="ltx_td ltx_align_left" id="A6.T10.3.4.4.2">2.6B</td>
<td class="ltx_td ltx_align_center" id="A6.T10.3.4.4.3">21.6</td>
<td class="ltx_td ltx_align_center" id="A6.T10.3.4.4.4">35.0</td>
<td class="ltx_td ltx_align_center" id="A6.T10.3.4.4.5">41.2</td>
<td class="ltx_td ltx_align_center" id="A6.T10.3.4.4.6">48.3</td>
<td class="ltx_td ltx_align_center" id="A6.T10.3.4.4.7">58.5 (<span class="ltx_text ltx_font_bold" id="A6.T10.3.4.4.7.1" style="color:#4F25E9;">+18.3</span>)</td>
</tr>
<tr class="ltx_tr" id="A6.T10.3.5.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T10.3.5.5.1">Phi-3-Mini-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T10.3.5.5.2">3.8B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T10.3.5.5.3">40.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T10.3.5.5.4">48.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T10.3.5.5.5">52.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T10.3.5.5.6">55.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T10.3.5.5.7">57.3</td>
</tr>
<tr class="ltx_tr" id="A6.T10.3.6.6">
<td class="ltx_td ltx_align_left" id="A6.T10.3.6.6.1">Phi-3-Mini-LintSeqInstruct</td>
<td class="ltx_td ltx_align_left" id="A6.T10.3.6.6.2">3.8B</td>
<td class="ltx_td ltx_align_center" id="A6.T10.3.6.6.3">38.3</td>
<td class="ltx_td ltx_align_center" id="A6.T10.3.6.6.4">63.6</td>
<td class="ltx_td ltx_align_center" id="A6.T10.3.6.6.5">72.0</td>
<td class="ltx_td ltx_align_center" id="A6.T10.3.6.6.6">79.0</td>
<td class="ltx_td ltx_align_center" id="A6.T10.3.6.6.7">86.6 (<span class="ltx_text ltx_font_bold" id="A6.T10.3.6.6.7.1" style="color:#4F25E9;">+29.3</span>)</td>
</tr>
<tr class="ltx_tr" id="A6.T10.3.7.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T10.3.7.7.1">Llama-3.1-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T10.3.7.7.2">8B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T10.3.7.7.3">34.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T10.3.7.7.4">50.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T10.3.7.7.5">55.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T10.3.7.7.6">59.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T10.3.7.7.7">63.4</td>
</tr>
<tr class="ltx_tr" id="A6.T10.3.8.8">
<td class="ltx_td ltx_align_left" id="A6.T10.3.8.8.1">Llama-3.1-LintSeqInstruct</td>
<td class="ltx_td ltx_align_left" id="A6.T10.3.8.8.2">8B</td>
<td class="ltx_td ltx_align_center" id="A6.T10.3.8.8.3">37.6</td>
<td class="ltx_td ltx_align_center" id="A6.T10.3.8.8.4">61.1</td>
<td class="ltx_td ltx_align_center" id="A6.T10.3.8.8.5">69.2</td>
<td class="ltx_td ltx_align_center" id="A6.T10.3.8.8.6">75.3</td>
<td class="ltx_td ltx_align_center" id="A6.T10.3.8.8.7">82.3 (<span class="ltx_text ltx_font_bold" id="A6.T10.3.8.8.7.1" style="color:#4F25E9;">+18.9</span>)</td>
</tr>
<tr class="ltx_tr" id="A6.T10.3.9.9">
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T10.3.9.9.1">Phi-3-Med-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T10.3.9.9.2">14B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T10.3.9.9.3">52.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T10.3.9.9.4">67.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T10.3.9.9.5">72.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T10.3.9.9.6">75.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T10.3.9.9.7">77.4</td>
</tr>
<tr class="ltx_tr" id="A6.T10.3.10.10">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A6.T10.3.10.10.1">Phi-3-Med-LintSeqInstruct</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A6.T10.3.10.10.2">14B</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T10.3.10.10.3">44.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T10.3.10.10.4">73.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T10.3.10.10.5">80.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T10.3.10.10.6">84.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T10.3.10.10.7">90.2 (<span class="ltx_text ltx_font_bold" id="A6.T10.3.10.10.7.1" style="color:#4F25E9;">+12.8</span>)</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="A6.T11">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span><span class="ltx_text ltx_font_bold" id="A6.T11.2.1">MBPP(+)</span> fixed-temperature coverage scaling results achieved by finetuning Gemma 2, Phi-3, and Llama 3.1 models (zero-shot, temperature = 1, top-p = 0.95).</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A6.T11.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A6.T11.3.1.1">
<td class="ltx_td ltx_border_tt" id="A6.T11.3.1.1.1"></td>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="A6.T11.3.1.1.2"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5" id="A6.T11.3.1.1.3">MBPP(+)</th>
</tr>
<tr class="ltx_tr" id="A6.T11.3.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="A6.T11.3.2.2.1">Model Variant</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="A6.T11.3.2.2.2">Parameters</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T11.3.2.2.3">pass@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T11.3.2.2.4">pass@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T11.3.2.2.5">pass@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T11.3.2.2.6">pass@20</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A6.T11.3.2.2.7">pass@50</th>
</tr>
<tr class="ltx_tr" id="A6.T11.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A6.T11.3.3.3.1">Gemma-2-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A6.T11.3.3.3.2">2.6B</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T11.3.3.3.3">22.8</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T11.3.3.3.4">34.2</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T11.3.3.3.5">37.8</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T11.3.3.3.6">41.2</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T11.3.3.3.7">44.6</td>
</tr>
<tr class="ltx_tr" id="A6.T11.3.4.4">
<td class="ltx_td ltx_align_left" id="A6.T11.3.4.4.1">Gemma-2-LintSeqInstruct</td>
<td class="ltx_td ltx_align_left" id="A6.T11.3.4.4.2">2.6B</td>
<td class="ltx_td ltx_align_center" id="A6.T11.3.4.4.3">27.7</td>
<td class="ltx_td ltx_align_center" id="A6.T11.3.4.4.4">41.3</td>
<td class="ltx_td ltx_align_center" id="A6.T11.3.4.4.5">46.3</td>
<td class="ltx_td ltx_align_center" id="A6.T11.3.4.4.6">50.5</td>
<td class="ltx_td ltx_align_center" id="A6.T11.3.4.4.7">54.7 (<span class="ltx_text ltx_font_bold" id="A6.T11.3.4.4.7.1" style="color:#4F25E9;">+10.1</span>)</td>
</tr>
<tr class="ltx_tr" id="A6.T11.3.5.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T11.3.5.5.1">Phi-3-Mini-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T11.3.5.5.2">3.8B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T11.3.5.5.3">35.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T11.3.5.5.4">45.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T11.3.5.5.5">49.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T11.3.5.5.6">52.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T11.3.5.5.7">56.1</td>
</tr>
<tr class="ltx_tr" id="A6.T11.3.6.6">
<td class="ltx_td ltx_align_left" id="A6.T11.3.6.6.1">Phi-3-Mini-LintSeqInstruct</td>
<td class="ltx_td ltx_align_left" id="A6.T11.3.6.6.2">3.8B</td>
<td class="ltx_td ltx_align_center" id="A6.T11.3.6.6.3">39.3</td>
<td class="ltx_td ltx_align_center" id="A6.T11.3.6.6.4">57.5</td>
<td class="ltx_td ltx_align_center" id="A6.T11.3.6.6.5">62.4</td>
<td class="ltx_td ltx_align_center" id="A6.T11.3.6.6.6">65.9</td>
<td class="ltx_td ltx_align_center" id="A6.T11.3.6.6.7">69.4 (<span class="ltx_text ltx_font_bold" id="A6.T11.3.6.6.7.1" style="color:#4F25E9;">+13.3</span>)</td>
</tr>
<tr class="ltx_tr" id="A6.T11.3.7.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T11.3.7.7.1">Llama-3.1-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T11.3.7.7.2">8B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T11.3.7.7.3">38.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T11.3.7.7.4">50.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T11.3.7.7.5">53.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T11.3.7.7.6">56.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T11.3.7.7.7">59.4</td>
</tr>
<tr class="ltx_tr" id="A6.T11.3.8.8">
<td class="ltx_td ltx_align_left" id="A6.T11.3.8.8.1">Llama-3.1-LintSeqInstruct</td>
<td class="ltx_td ltx_align_left" id="A6.T11.3.8.8.2">8B</td>
<td class="ltx_td ltx_align_center" id="A6.T11.3.8.8.3">38.5</td>
<td class="ltx_td ltx_align_center" id="A6.T11.3.8.8.4">56.5</td>
<td class="ltx_td ltx_align_center" id="A6.T11.3.8.8.5">61.6</td>
<td class="ltx_td ltx_align_center" id="A6.T11.3.8.8.6">65.7</td>
<td class="ltx_td ltx_align_center" id="A6.T11.3.8.8.7">69.8 (<span class="ltx_text ltx_font_bold" id="A6.T11.3.8.8.7.1" style="color:#4F25E9;">+10.4</span>)</td>
</tr>
<tr class="ltx_tr" id="A6.T11.3.9.9">
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T11.3.9.9.1">Phi-3-Med-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T11.3.9.9.2">14B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T11.3.9.9.3">40.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T11.3.9.9.4">51.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T11.3.9.9.5">54.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T11.3.9.9.6">56.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T11.3.9.9.7">59.0</td>
</tr>
<tr class="ltx_tr" id="A6.T11.3.10.10">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A6.T11.3.10.10.1">Phi-3-Med-LintSeqInstruct</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A6.T11.3.10.10.2">14B</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T11.3.10.10.3">40.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T11.3.10.10.4">60.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T11.3.10.10.5">67.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T11.3.10.10.6">71.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T11.3.10.10.7">75.9 (<span class="ltx_text ltx_font_bold" id="A6.T11.3.10.10.7.1" style="color:#4F25E9;">+16.9</span>)</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_subsection" id="A6.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">F.4 </span>Computing HumanEval Coverage vs Cumulative Inference-Time FLOPs</h3>
<div class="ltx_para ltx_noindent" id="A6.SS4.p1">
<p class="ltx_p" id="A6.SS4.p1.1">In Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">1</span></a>, we plot HumanEval coverage as a function of cumulative inference-time FLOPs, comparing the performance and total cost of repeatedly sampling from our instruction finetuned Phi-3 and Llama 3.1 models vs sampling a single generation per problem from very large models like Llama 3.1 405B <cite class="ltx_cite ltx_citemacro_citep">(Dubey et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib12" title="">2024</a>)</cite> and Nemotron 4 340B <cite class="ltx_cite ltx_citemacro_citep">(Adler et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib3" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.SS4.p2">
<p class="ltx_p" id="A6.SS4.p2.1">We use the approximations below, drawn from <cite class="ltx_cite ltx_citemacro_cite">Kaplan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib18" title="">2020</a>)</cite>, to conservatively estimate the cumulative inference costs of synthesizing solutions to all of the <math alttext="164" class="ltx_Math" display="inline" id="A6.SS4.p2.1.m1.1"><semantics id="A6.SS4.p2.1.m1.1a"><mn id="A6.SS4.p2.1.m1.1.1" xref="A6.SS4.p2.1.m1.1.1.cmml">164</mn><annotation-xml encoding="MathML-Content" id="A6.SS4.p2.1.m1.1b"><cn id="A6.SS4.p2.1.m1.1.1.cmml" type="integer" xref="A6.SS4.p2.1.m1.1.1">164</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p2.1.m1.1c">164</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p2.1.m1.1d">164</annotation></semantics></math> HumanEval benchmark problems across different models. The models that we compare are all dense transformers, where the majority of the parameters are used in matrix multiplications.</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A6.EGx1">
<tbody id="A6.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span class="ltx_text ltx_markedasmath" id="A6.Ex1.2.1.1.1">FLOPs per token</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\approx 2\cdot(N_{\text{model-params}}+2\cdot L_{\text{model-%
layers}}\cdot C_{\text{context}})" class="ltx_Math" display="inline" id="A6.Ex1.m2.1"><semantics id="A6.Ex1.m2.1a"><mrow id="A6.Ex1.m2.1.1" xref="A6.Ex1.m2.1.1.cmml"><mi id="A6.Ex1.m2.1.1.3" xref="A6.Ex1.m2.1.1.3.cmml"></mi><mo id="A6.Ex1.m2.1.1.2" xref="A6.Ex1.m2.1.1.2.cmml">≈</mo><mrow id="A6.Ex1.m2.1.1.1" xref="A6.Ex1.m2.1.1.1.cmml"><mn id="A6.Ex1.m2.1.1.1.3" xref="A6.Ex1.m2.1.1.1.3.cmml">2</mn><mo id="A6.Ex1.m2.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="A6.Ex1.m2.1.1.1.2.cmml">⋅</mo><mrow id="A6.Ex1.m2.1.1.1.1.1" xref="A6.Ex1.m2.1.1.1.1.1.1.cmml"><mo id="A6.Ex1.m2.1.1.1.1.1.2" stretchy="false" xref="A6.Ex1.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="A6.Ex1.m2.1.1.1.1.1.1" xref="A6.Ex1.m2.1.1.1.1.1.1.cmml"><msub id="A6.Ex1.m2.1.1.1.1.1.1.2" xref="A6.Ex1.m2.1.1.1.1.1.1.2.cmml"><mi id="A6.Ex1.m2.1.1.1.1.1.1.2.2" xref="A6.Ex1.m2.1.1.1.1.1.1.2.2.cmml">N</mi><mtext id="A6.Ex1.m2.1.1.1.1.1.1.2.3" xref="A6.Ex1.m2.1.1.1.1.1.1.2.3a.cmml">model-params</mtext></msub><mo id="A6.Ex1.m2.1.1.1.1.1.1.1" xref="A6.Ex1.m2.1.1.1.1.1.1.1.cmml">+</mo><mrow id="A6.Ex1.m2.1.1.1.1.1.1.3" xref="A6.Ex1.m2.1.1.1.1.1.1.3.cmml"><mn id="A6.Ex1.m2.1.1.1.1.1.1.3.2" xref="A6.Ex1.m2.1.1.1.1.1.1.3.2.cmml">2</mn><mo id="A6.Ex1.m2.1.1.1.1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="A6.Ex1.m2.1.1.1.1.1.1.3.1.cmml">⋅</mo><msub id="A6.Ex1.m2.1.1.1.1.1.1.3.3" xref="A6.Ex1.m2.1.1.1.1.1.1.3.3.cmml"><mi id="A6.Ex1.m2.1.1.1.1.1.1.3.3.2" xref="A6.Ex1.m2.1.1.1.1.1.1.3.3.2.cmml">L</mi><mtext id="A6.Ex1.m2.1.1.1.1.1.1.3.3.3" xref="A6.Ex1.m2.1.1.1.1.1.1.3.3.3a.cmml">model-layers</mtext></msub><mo id="A6.Ex1.m2.1.1.1.1.1.1.3.1a" lspace="0.222em" rspace="0.222em" xref="A6.Ex1.m2.1.1.1.1.1.1.3.1.cmml">⋅</mo><msub id="A6.Ex1.m2.1.1.1.1.1.1.3.4" xref="A6.Ex1.m2.1.1.1.1.1.1.3.4.cmml"><mi id="A6.Ex1.m2.1.1.1.1.1.1.3.4.2" xref="A6.Ex1.m2.1.1.1.1.1.1.3.4.2.cmml">C</mi><mtext id="A6.Ex1.m2.1.1.1.1.1.1.3.4.3" xref="A6.Ex1.m2.1.1.1.1.1.1.3.4.3a.cmml">context</mtext></msub></mrow></mrow><mo id="A6.Ex1.m2.1.1.1.1.1.3" stretchy="false" xref="A6.Ex1.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.Ex1.m2.1b"><apply id="A6.Ex1.m2.1.1.cmml" xref="A6.Ex1.m2.1.1"><approx id="A6.Ex1.m2.1.1.2.cmml" xref="A6.Ex1.m2.1.1.2"></approx><csymbol cd="latexml" id="A6.Ex1.m2.1.1.3.cmml" xref="A6.Ex1.m2.1.1.3">absent</csymbol><apply id="A6.Ex1.m2.1.1.1.cmml" xref="A6.Ex1.m2.1.1.1"><ci id="A6.Ex1.m2.1.1.1.2.cmml" xref="A6.Ex1.m2.1.1.1.2">⋅</ci><cn id="A6.Ex1.m2.1.1.1.3.cmml" type="integer" xref="A6.Ex1.m2.1.1.1.3">2</cn><apply id="A6.Ex1.m2.1.1.1.1.1.1.cmml" xref="A6.Ex1.m2.1.1.1.1.1"><plus id="A6.Ex1.m2.1.1.1.1.1.1.1.cmml" xref="A6.Ex1.m2.1.1.1.1.1.1.1"></plus><apply id="A6.Ex1.m2.1.1.1.1.1.1.2.cmml" xref="A6.Ex1.m2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A6.Ex1.m2.1.1.1.1.1.1.2.1.cmml" xref="A6.Ex1.m2.1.1.1.1.1.1.2">subscript</csymbol><ci id="A6.Ex1.m2.1.1.1.1.1.1.2.2.cmml" xref="A6.Ex1.m2.1.1.1.1.1.1.2.2">𝑁</ci><ci id="A6.Ex1.m2.1.1.1.1.1.1.2.3a.cmml" xref="A6.Ex1.m2.1.1.1.1.1.1.2.3"><mtext id="A6.Ex1.m2.1.1.1.1.1.1.2.3.cmml" mathsize="70%" xref="A6.Ex1.m2.1.1.1.1.1.1.2.3">model-params</mtext></ci></apply><apply id="A6.Ex1.m2.1.1.1.1.1.1.3.cmml" xref="A6.Ex1.m2.1.1.1.1.1.1.3"><ci id="A6.Ex1.m2.1.1.1.1.1.1.3.1.cmml" xref="A6.Ex1.m2.1.1.1.1.1.1.3.1">⋅</ci><cn id="A6.Ex1.m2.1.1.1.1.1.1.3.2.cmml" type="integer" xref="A6.Ex1.m2.1.1.1.1.1.1.3.2">2</cn><apply id="A6.Ex1.m2.1.1.1.1.1.1.3.3.cmml" xref="A6.Ex1.m2.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="A6.Ex1.m2.1.1.1.1.1.1.3.3.1.cmml" xref="A6.Ex1.m2.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="A6.Ex1.m2.1.1.1.1.1.1.3.3.2.cmml" xref="A6.Ex1.m2.1.1.1.1.1.1.3.3.2">𝐿</ci><ci id="A6.Ex1.m2.1.1.1.1.1.1.3.3.3a.cmml" xref="A6.Ex1.m2.1.1.1.1.1.1.3.3.3"><mtext id="A6.Ex1.m2.1.1.1.1.1.1.3.3.3.cmml" mathsize="70%" xref="A6.Ex1.m2.1.1.1.1.1.1.3.3.3">model-layers</mtext></ci></apply><apply id="A6.Ex1.m2.1.1.1.1.1.1.3.4.cmml" xref="A6.Ex1.m2.1.1.1.1.1.1.3.4"><csymbol cd="ambiguous" id="A6.Ex1.m2.1.1.1.1.1.1.3.4.1.cmml" xref="A6.Ex1.m2.1.1.1.1.1.1.3.4">subscript</csymbol><ci id="A6.Ex1.m2.1.1.1.1.1.1.3.4.2.cmml" xref="A6.Ex1.m2.1.1.1.1.1.1.3.4.2">𝐶</ci><ci id="A6.Ex1.m2.1.1.1.1.1.1.3.4.3a.cmml" xref="A6.Ex1.m2.1.1.1.1.1.1.3.4.3"><mtext id="A6.Ex1.m2.1.1.1.1.1.1.3.4.3.cmml" mathsize="70%" xref="A6.Ex1.m2.1.1.1.1.1.1.3.4.3">context</mtext></ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.Ex1.m2.1c">\displaystyle\approx 2\cdot(N_{\text{model-params}}+2\cdot L_{\text{model-%
layers}}\cdot C_{\text{context}})</annotation><annotation encoding="application/x-llamapun" id="A6.Ex1.m2.1d">≈ 2 ⋅ ( italic_N start_POSTSUBSCRIPT model-params end_POSTSUBSCRIPT + 2 ⋅ italic_L start_POSTSUBSCRIPT model-layers end_POSTSUBSCRIPT ⋅ italic_C start_POSTSUBSCRIPT context end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="A6.Ex2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span class="ltx_text ltx_markedasmath" id="A6.Ex2.2.1.1.1">Total FLOPs</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\approx\text{FLOPs per token}\cdot T_{\text{avg-total-tokens-per-%
sample}}\cdot K_{\text{samples}}\cdot M_{\text{problems}}" class="ltx_Math" display="inline" id="A6.Ex2.m2.1"><semantics id="A6.Ex2.m2.1a"><mrow id="A6.Ex2.m2.1.1" xref="A6.Ex2.m2.1.1.cmml"><mi id="A6.Ex2.m2.1.1.2" xref="A6.Ex2.m2.1.1.2.cmml"></mi><mo id="A6.Ex2.m2.1.1.1" xref="A6.Ex2.m2.1.1.1.cmml">≈</mo><mrow id="A6.Ex2.m2.1.1.3" xref="A6.Ex2.m2.1.1.3.cmml"><mtext id="A6.Ex2.m2.1.1.3.2" xref="A6.Ex2.m2.1.1.3.2a.cmml">FLOPs per token</mtext><mo id="A6.Ex2.m2.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="A6.Ex2.m2.1.1.3.1.cmml">⋅</mo><msub id="A6.Ex2.m2.1.1.3.3" xref="A6.Ex2.m2.1.1.3.3.cmml"><mi id="A6.Ex2.m2.1.1.3.3.2" xref="A6.Ex2.m2.1.1.3.3.2.cmml">T</mi><mtext id="A6.Ex2.m2.1.1.3.3.3" xref="A6.Ex2.m2.1.1.3.3.3a.cmml">avg-total-tokens-per-sample</mtext></msub><mo id="A6.Ex2.m2.1.1.3.1a" lspace="0.222em" rspace="0.222em" xref="A6.Ex2.m2.1.1.3.1.cmml">⋅</mo><msub id="A6.Ex2.m2.1.1.3.4" xref="A6.Ex2.m2.1.1.3.4.cmml"><mi id="A6.Ex2.m2.1.1.3.4.2" xref="A6.Ex2.m2.1.1.3.4.2.cmml">K</mi><mtext id="A6.Ex2.m2.1.1.3.4.3" xref="A6.Ex2.m2.1.1.3.4.3a.cmml">samples</mtext></msub><mo id="A6.Ex2.m2.1.1.3.1b" lspace="0.222em" rspace="0.222em" xref="A6.Ex2.m2.1.1.3.1.cmml">⋅</mo><msub id="A6.Ex2.m2.1.1.3.5" xref="A6.Ex2.m2.1.1.3.5.cmml"><mi id="A6.Ex2.m2.1.1.3.5.2" xref="A6.Ex2.m2.1.1.3.5.2.cmml">M</mi><mtext id="A6.Ex2.m2.1.1.3.5.3" xref="A6.Ex2.m2.1.1.3.5.3a.cmml">problems</mtext></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.Ex2.m2.1b"><apply id="A6.Ex2.m2.1.1.cmml" xref="A6.Ex2.m2.1.1"><approx id="A6.Ex2.m2.1.1.1.cmml" xref="A6.Ex2.m2.1.1.1"></approx><csymbol cd="latexml" id="A6.Ex2.m2.1.1.2.cmml" xref="A6.Ex2.m2.1.1.2">absent</csymbol><apply id="A6.Ex2.m2.1.1.3.cmml" xref="A6.Ex2.m2.1.1.3"><ci id="A6.Ex2.m2.1.1.3.1.cmml" xref="A6.Ex2.m2.1.1.3.1">⋅</ci><ci id="A6.Ex2.m2.1.1.3.2a.cmml" xref="A6.Ex2.m2.1.1.3.2"><mtext id="A6.Ex2.m2.1.1.3.2.cmml" xref="A6.Ex2.m2.1.1.3.2">FLOPs per token</mtext></ci><apply id="A6.Ex2.m2.1.1.3.3.cmml" xref="A6.Ex2.m2.1.1.3.3"><csymbol cd="ambiguous" id="A6.Ex2.m2.1.1.3.3.1.cmml" xref="A6.Ex2.m2.1.1.3.3">subscript</csymbol><ci id="A6.Ex2.m2.1.1.3.3.2.cmml" xref="A6.Ex2.m2.1.1.3.3.2">𝑇</ci><ci id="A6.Ex2.m2.1.1.3.3.3a.cmml" xref="A6.Ex2.m2.1.1.3.3.3"><mtext id="A6.Ex2.m2.1.1.3.3.3.cmml" mathsize="70%" xref="A6.Ex2.m2.1.1.3.3.3">avg-total-tokens-per-sample</mtext></ci></apply><apply id="A6.Ex2.m2.1.1.3.4.cmml" xref="A6.Ex2.m2.1.1.3.4"><csymbol cd="ambiguous" id="A6.Ex2.m2.1.1.3.4.1.cmml" xref="A6.Ex2.m2.1.1.3.4">subscript</csymbol><ci id="A6.Ex2.m2.1.1.3.4.2.cmml" xref="A6.Ex2.m2.1.1.3.4.2">𝐾</ci><ci id="A6.Ex2.m2.1.1.3.4.3a.cmml" xref="A6.Ex2.m2.1.1.3.4.3"><mtext id="A6.Ex2.m2.1.1.3.4.3.cmml" mathsize="70%" xref="A6.Ex2.m2.1.1.3.4.3">samples</mtext></ci></apply><apply id="A6.Ex2.m2.1.1.3.5.cmml" xref="A6.Ex2.m2.1.1.3.5"><csymbol cd="ambiguous" id="A6.Ex2.m2.1.1.3.5.1.cmml" xref="A6.Ex2.m2.1.1.3.5">subscript</csymbol><ci id="A6.Ex2.m2.1.1.3.5.2.cmml" xref="A6.Ex2.m2.1.1.3.5.2">𝑀</ci><ci id="A6.Ex2.m2.1.1.3.5.3a.cmml" xref="A6.Ex2.m2.1.1.3.5.3"><mtext id="A6.Ex2.m2.1.1.3.5.3.cmml" mathsize="70%" xref="A6.Ex2.m2.1.1.3.5.3">problems</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.Ex2.m2.1c">\displaystyle\approx\text{FLOPs per token}\cdot T_{\text{avg-total-tokens-per-%
sample}}\cdot K_{\text{samples}}\cdot M_{\text{problems}}</annotation><annotation encoding="application/x-llamapun" id="A6.Ex2.m2.1d">≈ FLOPs per token ⋅ italic_T start_POSTSUBSCRIPT avg-total-tokens-per-sample end_POSTSUBSCRIPT ⋅ italic_K start_POSTSUBSCRIPT samples end_POSTSUBSCRIPT ⋅ italic_M start_POSTSUBSCRIPT problems end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="A6.Ex3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\approx\text{FLOPs per token}\cdot T_{\text{avg-total-tokens-per-%
sample}}\cdot K_{\text{samples}}\cdot 164" class="ltx_Math" display="inline" id="A6.Ex3.m1.1"><semantics id="A6.Ex3.m1.1a"><mrow id="A6.Ex3.m1.1.1" xref="A6.Ex3.m1.1.1.cmml"><mi id="A6.Ex3.m1.1.1.2" xref="A6.Ex3.m1.1.1.2.cmml"></mi><mo id="A6.Ex3.m1.1.1.1" xref="A6.Ex3.m1.1.1.1.cmml">≈</mo><mrow id="A6.Ex3.m1.1.1.3" xref="A6.Ex3.m1.1.1.3.cmml"><mtext id="A6.Ex3.m1.1.1.3.2" xref="A6.Ex3.m1.1.1.3.2a.cmml">FLOPs per token</mtext><mo id="A6.Ex3.m1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="A6.Ex3.m1.1.1.3.1.cmml">⋅</mo><msub id="A6.Ex3.m1.1.1.3.3" xref="A6.Ex3.m1.1.1.3.3.cmml"><mi id="A6.Ex3.m1.1.1.3.3.2" xref="A6.Ex3.m1.1.1.3.3.2.cmml">T</mi><mtext id="A6.Ex3.m1.1.1.3.3.3" xref="A6.Ex3.m1.1.1.3.3.3a.cmml">avg-total-tokens-per-sample</mtext></msub><mo id="A6.Ex3.m1.1.1.3.1a" lspace="0.222em" rspace="0.222em" xref="A6.Ex3.m1.1.1.3.1.cmml">⋅</mo><msub id="A6.Ex3.m1.1.1.3.4" xref="A6.Ex3.m1.1.1.3.4.cmml"><mi id="A6.Ex3.m1.1.1.3.4.2" xref="A6.Ex3.m1.1.1.3.4.2.cmml">K</mi><mtext id="A6.Ex3.m1.1.1.3.4.3" xref="A6.Ex3.m1.1.1.3.4.3a.cmml">samples</mtext></msub><mo id="A6.Ex3.m1.1.1.3.1b" lspace="0.222em" rspace="0.222em" xref="A6.Ex3.m1.1.1.3.1.cmml">⋅</mo><mn id="A6.Ex3.m1.1.1.3.5" xref="A6.Ex3.m1.1.1.3.5.cmml">164</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.Ex3.m1.1b"><apply id="A6.Ex3.m1.1.1.cmml" xref="A6.Ex3.m1.1.1"><approx id="A6.Ex3.m1.1.1.1.cmml" xref="A6.Ex3.m1.1.1.1"></approx><csymbol cd="latexml" id="A6.Ex3.m1.1.1.2.cmml" xref="A6.Ex3.m1.1.1.2">absent</csymbol><apply id="A6.Ex3.m1.1.1.3.cmml" xref="A6.Ex3.m1.1.1.3"><ci id="A6.Ex3.m1.1.1.3.1.cmml" xref="A6.Ex3.m1.1.1.3.1">⋅</ci><ci id="A6.Ex3.m1.1.1.3.2a.cmml" xref="A6.Ex3.m1.1.1.3.2"><mtext id="A6.Ex3.m1.1.1.3.2.cmml" xref="A6.Ex3.m1.1.1.3.2">FLOPs per token</mtext></ci><apply id="A6.Ex3.m1.1.1.3.3.cmml" xref="A6.Ex3.m1.1.1.3.3"><csymbol cd="ambiguous" id="A6.Ex3.m1.1.1.3.3.1.cmml" xref="A6.Ex3.m1.1.1.3.3">subscript</csymbol><ci id="A6.Ex3.m1.1.1.3.3.2.cmml" xref="A6.Ex3.m1.1.1.3.3.2">𝑇</ci><ci id="A6.Ex3.m1.1.1.3.3.3a.cmml" xref="A6.Ex3.m1.1.1.3.3.3"><mtext id="A6.Ex3.m1.1.1.3.3.3.cmml" mathsize="70%" xref="A6.Ex3.m1.1.1.3.3.3">avg-total-tokens-per-sample</mtext></ci></apply><apply id="A6.Ex3.m1.1.1.3.4.cmml" xref="A6.Ex3.m1.1.1.3.4"><csymbol cd="ambiguous" id="A6.Ex3.m1.1.1.3.4.1.cmml" xref="A6.Ex3.m1.1.1.3.4">subscript</csymbol><ci id="A6.Ex3.m1.1.1.3.4.2.cmml" xref="A6.Ex3.m1.1.1.3.4.2">𝐾</ci><ci id="A6.Ex3.m1.1.1.3.4.3a.cmml" xref="A6.Ex3.m1.1.1.3.4.3"><mtext id="A6.Ex3.m1.1.1.3.4.3.cmml" mathsize="70%" xref="A6.Ex3.m1.1.1.3.4.3">samples</mtext></ci></apply><cn id="A6.Ex3.m1.1.1.3.5.cmml" type="integer" xref="A6.Ex3.m1.1.1.3.5">164</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.Ex3.m1.1c">\displaystyle\approx\text{FLOPs per token}\cdot T_{\text{avg-total-tokens-per-%
sample}}\cdot K_{\text{samples}}\cdot 164</annotation><annotation encoding="application/x-llamapun" id="A6.Ex3.m1.1d">≈ FLOPs per token ⋅ italic_T start_POSTSUBSCRIPT avg-total-tokens-per-sample end_POSTSUBSCRIPT ⋅ italic_K start_POSTSUBSCRIPT samples end_POSTSUBSCRIPT ⋅ 164</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A6.SS4.p3">
<p class="ltx_p" id="A6.SS4.p3.1">For our instruction finetuned models, we determine the quantities <math alttext="T_{\text{avg-total-tokens-per-sample}}" class="ltx_Math" display="inline" id="A6.SS4.p3.1.m1.1"><semantics id="A6.SS4.p3.1.m1.1a"><msub id="A6.SS4.p3.1.m1.1.1" xref="A6.SS4.p3.1.m1.1.1.cmml"><mi id="A6.SS4.p3.1.m1.1.1.2" xref="A6.SS4.p3.1.m1.1.1.2.cmml">T</mi><mtext id="A6.SS4.p3.1.m1.1.1.3" xref="A6.SS4.p3.1.m1.1.1.3a.cmml">avg-total-tokens-per-sample</mtext></msub><annotation-xml encoding="MathML-Content" id="A6.SS4.p3.1.m1.1b"><apply id="A6.SS4.p3.1.m1.1.1.cmml" xref="A6.SS4.p3.1.m1.1.1"><csymbol cd="ambiguous" id="A6.SS4.p3.1.m1.1.1.1.cmml" xref="A6.SS4.p3.1.m1.1.1">subscript</csymbol><ci id="A6.SS4.p3.1.m1.1.1.2.cmml" xref="A6.SS4.p3.1.m1.1.1.2">𝑇</ci><ci id="A6.SS4.p3.1.m1.1.1.3a.cmml" xref="A6.SS4.p3.1.m1.1.1.3"><mtext id="A6.SS4.p3.1.m1.1.1.3.cmml" mathsize="70%" xref="A6.SS4.p3.1.m1.1.1.3">avg-total-tokens-per-sample</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p3.1.m1.1c">T_{\text{avg-total-tokens-per-sample}}</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p3.1.m1.1d">italic_T start_POSTSUBSCRIPT avg-total-tokens-per-sample end_POSTSUBSCRIPT</annotation></semantics></math> by computing token counts over all sets of samples per problem that we obtained to compute the coverage statistics in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#S3.F4" title="Figure 4 ‣ 3.3 Finetuning Language Models on LintSeq Edit Sequences ‣ 3 Experiments ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">4</span></a> and Table <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.T10" title="Table 10 ‣ F.3.1 Inference-Time Scaling Laws ‣ F.3 Finetuning Gemma 2, Phi-3, and Llama 3.1 ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">10</span></a> above. These token statistics are provided in the table below.</p>
</div>
<figure class="ltx_table" id="A6.T12">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span><span class="ltx_text ltx_font_bold" id="A6.T12.7.1">HumanEval total tokens per sample</span> for finetuned Gemma 2, Phi-3, and Llama 3.1 models (zero-shot, temperature <math alttext="=1" class="ltx_Math" display="inline" id="A6.T12.3.m1.1"><semantics id="A6.T12.3.m1.1b"><mrow id="A6.T12.3.m1.1.1" xref="A6.T12.3.m1.1.1.cmml"><mi id="A6.T12.3.m1.1.1.2" xref="A6.T12.3.m1.1.1.2.cmml"></mi><mo id="A6.T12.3.m1.1.1.1" xref="A6.T12.3.m1.1.1.1.cmml">=</mo><mn id="A6.T12.3.m1.1.1.3" xref="A6.T12.3.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.T12.3.m1.1c"><apply id="A6.T12.3.m1.1.1.cmml" xref="A6.T12.3.m1.1.1"><eq id="A6.T12.3.m1.1.1.1.cmml" xref="A6.T12.3.m1.1.1.1"></eq><csymbol cd="latexml" id="A6.T12.3.m1.1.1.2.cmml" xref="A6.T12.3.m1.1.1.2">absent</csymbol><cn id="A6.T12.3.m1.1.1.3.cmml" type="integer" xref="A6.T12.3.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T12.3.m1.1d">=1</annotation><annotation encoding="application/x-llamapun" id="A6.T12.3.m1.1e">= 1</annotation></semantics></math>, top-p <math alttext="=0.95" class="ltx_Math" display="inline" id="A6.T12.4.m2.1"><semantics id="A6.T12.4.m2.1b"><mrow id="A6.T12.4.m2.1.1" xref="A6.T12.4.m2.1.1.cmml"><mi id="A6.T12.4.m2.1.1.2" xref="A6.T12.4.m2.1.1.2.cmml"></mi><mo id="A6.T12.4.m2.1.1.1" xref="A6.T12.4.m2.1.1.1.cmml">=</mo><mn id="A6.T12.4.m2.1.1.3" xref="A6.T12.4.m2.1.1.3.cmml">0.95</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.T12.4.m2.1c"><apply id="A6.T12.4.m2.1.1.cmml" xref="A6.T12.4.m2.1.1"><eq id="A6.T12.4.m2.1.1.1.cmml" xref="A6.T12.4.m2.1.1.1"></eq><csymbol cd="latexml" id="A6.T12.4.m2.1.1.2.cmml" xref="A6.T12.4.m2.1.1.2">absent</csymbol><cn id="A6.T12.4.m2.1.1.3.cmml" type="float" xref="A6.T12.4.m2.1.1.3">0.95</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T12.4.m2.1d">=0.95</annotation><annotation encoding="application/x-llamapun" id="A6.T12.4.m2.1e">= 0.95</annotation></semantics></math>). These counts reflect prompt and completion tokens. They are computed using the same samples whose coverage statistics are reported in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.T10" title="Table 10 ‣ F.3.1 Inference-Time Scaling Laws ‣ F.3 Finetuning Gemma 2, Phi-3, and Llama 3.1 ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">10</span></a>.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A6.T12.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A6.T12.5.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A6.T12.5.1.2">Model Variant</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A6.T12.5.1.3">Parameters</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A6.T12.5.1.1">
<span class="ltx_inline-block" id="A6.T12.5.1.1.1">
<span class="ltx_p" id="A6.T12.5.1.1.1.2">Avg. Total Tokens</span>
<span class="ltx_p" id="A6.T12.5.1.1.1.1">Per HumanEval Sample (<math alttext="n=50" class="ltx_Math" display="inline" id="A6.T12.5.1.1.1.1.m1.1"><semantics id="A6.T12.5.1.1.1.1.m1.1a"><mrow id="A6.T12.5.1.1.1.1.m1.1.1" xref="A6.T12.5.1.1.1.1.m1.1.1.cmml"><mi id="A6.T12.5.1.1.1.1.m1.1.1.2" xref="A6.T12.5.1.1.1.1.m1.1.1.2.cmml">n</mi><mo id="A6.T12.5.1.1.1.1.m1.1.1.1" xref="A6.T12.5.1.1.1.1.m1.1.1.1.cmml">=</mo><mn id="A6.T12.5.1.1.1.1.m1.1.1.3" xref="A6.T12.5.1.1.1.1.m1.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.T12.5.1.1.1.1.m1.1b"><apply id="A6.T12.5.1.1.1.1.m1.1.1.cmml" xref="A6.T12.5.1.1.1.1.m1.1.1"><eq id="A6.T12.5.1.1.1.1.m1.1.1.1.cmml" xref="A6.T12.5.1.1.1.1.m1.1.1.1"></eq><ci id="A6.T12.5.1.1.1.1.m1.1.1.2.cmml" xref="A6.T12.5.1.1.1.1.m1.1.1.2">𝑛</ci><cn id="A6.T12.5.1.1.1.1.m1.1.1.3.cmml" type="integer" xref="A6.T12.5.1.1.1.1.m1.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T12.5.1.1.1.1.m1.1c">n=50</annotation><annotation encoding="application/x-llamapun" id="A6.T12.5.1.1.1.1.m1.1d">italic_n = 50</annotation></semantics></math>)</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A6.T12.5.2.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A6.T12.5.2.1.1">Gemma-2-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A6.T12.5.2.1.2">2.6B</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T12.5.2.1.3">172</td>
</tr>
<tr class="ltx_tr" id="A6.T12.5.3.2">
<td class="ltx_td ltx_align_left" id="A6.T12.5.3.2.1">Gemma-2-LintSeqInstruct</td>
<td class="ltx_td ltx_align_left" id="A6.T12.5.3.2.2">2.6B</td>
<td class="ltx_td ltx_align_center" id="A6.T12.5.3.2.3">205</td>
</tr>
<tr class="ltx_tr" id="A6.T12.5.4.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T12.5.4.3.1">Phi-3-Mini-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T12.5.4.3.2">3.8B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T12.5.4.3.3">218</td>
</tr>
<tr class="ltx_tr" id="A6.T12.5.5.4">
<td class="ltx_td ltx_align_left" id="A6.T12.5.5.4.1">Phi-3-Mini-LintSeqInstruct</td>
<td class="ltx_td ltx_align_left" id="A6.T12.5.5.4.2">3.8B</td>
<td class="ltx_td ltx_align_center" id="A6.T12.5.5.4.3">247</td>
</tr>
<tr class="ltx_tr" id="A6.T12.5.6.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T12.5.6.5.1">Llama-3.1-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T12.5.6.5.2">8B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T12.5.6.5.3">178</td>
</tr>
<tr class="ltx_tr" id="A6.T12.5.7.6">
<td class="ltx_td ltx_align_left" id="A6.T12.5.7.6.1">Llama-3.1-LintSeqInstruct</td>
<td class="ltx_td ltx_align_left" id="A6.T12.5.7.6.2">8B</td>
<td class="ltx_td ltx_align_center" id="A6.T12.5.7.6.3">201</td>
</tr>
<tr class="ltx_tr" id="A6.T12.5.8.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T12.5.8.7.1">Phi-3-Med-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T12.5.8.7.2">14B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T12.5.8.7.3">230</td>
</tr>
<tr class="ltx_tr" id="A6.T12.5.9.8">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A6.T12.5.9.8.1">Phi-3-Med-LintSeqInstruct</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A6.T12.5.9.8.2">14B</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T12.5.9.8.3">247</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="A6.SS4.p4">
<p class="ltx_p" id="A6.SS4.p4.1">Note that edit sequence (i.e. LintSeqInstruct finetuned) LMs have slightly higher average token counts per sample due to presence of “diff” descriptor tokens in generations (see Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A1" title="Appendix A More on Edit Sequences and Diffs ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">A</span></a>).</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.SS4.p5">
<p class="ltx_p" id="A6.SS4.p5.1">We report zero-shot HumanEval coverage for external models by using the evaluation statistics from <cite class="ltx_cite ltx_citemacro_cite">Dubey et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#bib.bib12" title="">2024</a>)</cite> (Table 18, column one). To estimate cumulative inference-time FLOPs for these models, we employ the approximation expression above and estimate <math alttext="T_{\text{avg-total-tokens-per-sample}}\approx 200" class="ltx_Math" display="inline" id="A6.SS4.p5.1.m1.1"><semantics id="A6.SS4.p5.1.m1.1a"><mrow id="A6.SS4.p5.1.m1.1.1" xref="A6.SS4.p5.1.m1.1.1.cmml"><msub id="A6.SS4.p5.1.m1.1.1.2" xref="A6.SS4.p5.1.m1.1.1.2.cmml"><mi id="A6.SS4.p5.1.m1.1.1.2.2" xref="A6.SS4.p5.1.m1.1.1.2.2.cmml">T</mi><mtext id="A6.SS4.p5.1.m1.1.1.2.3" xref="A6.SS4.p5.1.m1.1.1.2.3a.cmml">avg-total-tokens-per-sample</mtext></msub><mo id="A6.SS4.p5.1.m1.1.1.1" xref="A6.SS4.p5.1.m1.1.1.1.cmml">≈</mo><mn id="A6.SS4.p5.1.m1.1.1.3" xref="A6.SS4.p5.1.m1.1.1.3.cmml">200</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.SS4.p5.1.m1.1b"><apply id="A6.SS4.p5.1.m1.1.1.cmml" xref="A6.SS4.p5.1.m1.1.1"><approx id="A6.SS4.p5.1.m1.1.1.1.cmml" xref="A6.SS4.p5.1.m1.1.1.1"></approx><apply id="A6.SS4.p5.1.m1.1.1.2.cmml" xref="A6.SS4.p5.1.m1.1.1.2"><csymbol cd="ambiguous" id="A6.SS4.p5.1.m1.1.1.2.1.cmml" xref="A6.SS4.p5.1.m1.1.1.2">subscript</csymbol><ci id="A6.SS4.p5.1.m1.1.1.2.2.cmml" xref="A6.SS4.p5.1.m1.1.1.2.2">𝑇</ci><ci id="A6.SS4.p5.1.m1.1.1.2.3a.cmml" xref="A6.SS4.p5.1.m1.1.1.2.3"><mtext id="A6.SS4.p5.1.m1.1.1.2.3.cmml" mathsize="70%" xref="A6.SS4.p5.1.m1.1.1.2.3">avg-total-tokens-per-sample</mtext></ci></apply><cn id="A6.SS4.p5.1.m1.1.1.3.cmml" type="integer" xref="A6.SS4.p5.1.m1.1.1.3">200</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p5.1.m1.1c">T_{\text{avg-total-tokens-per-sample}}\approx 200</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p5.1.m1.1d">italic_T start_POSTSUBSCRIPT avg-total-tokens-per-sample end_POSTSUBSCRIPT ≈ 200</annotation></semantics></math>, reflecting an ensemble over the per sample token counts of standard “Instruct” finetuned models shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.02749v2#A6.T12" title="Table 12 ‣ F.4 Computing HumanEval Coverage vs Cumulative Inference-Time FLOPs ‣ Appendix F Additional Results ‣ Training Language Models on Synthetic Edit Sequences Improves Code Synthesis"><span class="ltx_text ltx_ref_tag">12</span></a>. Note that this ensembled statistic reflects program generations without chain-of-thought only. As a result, we believe it to be a conservative estimator.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Oct 15 03:41:16 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
