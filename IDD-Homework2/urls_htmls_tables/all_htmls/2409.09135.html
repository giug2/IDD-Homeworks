<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.09135] Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation</title><meta property="og:description" content="Over the past decade, wearable computing devices (“smart glasses”) have undergone remarkable advancements in sensor technology, design, and processing power, ushering in a new era of opportunity for high-density human …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.09135">

<!--Generated on Sat Oct  5 20:34:32 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span id="footnotex6" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">footnotetext: </span>
* (equal contribution)
 † <a href="mailto:ccma@cs.cmu.edu" title="" class="ltx_ref ltx_href ltx_font_typewriter">ccma@cs.cmu.edu</a>
 ‡ <a href="mailto:khjoo@usc.edu" title="" class="ltx_ref ltx_href ltx_font_typewriter">khjoo@usc.edu</a>
 § <a href="mailto:avail@cs.cmu.edu" title="" class="ltx_ref ltx_href ltx_font_typewriter">avail@cs.cmu.edu</a>
</span></span></span>
<h1 class="ltx_title ltx_title_document">Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><a target="_blank" href="https://orcid.org/0009-0004-4036-0390" title="" class="ltx_ref ltx_href"><span id="id1.1.1.1" class="ltx_text" style="position:relative; bottom:0.0pt;"><span id="id1.1.1.1.1" class="ltx_text"><img src="/html/2409.09135/assets/x1.png" id="id1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="5" height="5" alt="[Uncaptioned image]"></span> Cheng Charles Ma<span id="footnotex1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span></span></span></span><span id="footnotex2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span></span></span></span></span></a>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Computer Science Department, Carnegie Mellon University, Pittsburgh, PA 15213
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><a target="_blank" href="https://orcid.org/0000-0002-6387-5686" title="" class="ltx_ref ltx_href"><span id="id2.1.1.1" class="ltx_text" style="position:relative; bottom:0.0pt;"><span id="id2.1.1.1.1" class="ltx_text"><img src="/html/2409.09135/assets/x1.png" id="id2.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="5" height="5" alt="[Uncaptioned image]"></span> Kevin Hyekang Joo<span id="footnotex3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span></span></span></span><span id="footnotex4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span></span></span></span></span></a>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15213
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><a target="_blank" href="https://orcid.org/0000-0001-5221-4092" title="" class="ltx_ref ltx_href"><span id="id3.1.1.1" class="ltx_text" style="position:relative; bottom:0.0pt;"><span id="id3.1.1.1.1" class="ltx_text"><img src="/html/2409.09135/assets/x1.png" id="id3.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="5" height="5" alt="[Uncaptioned image]"></span> Alexandria K. Vail<span id="footnotex5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span></span></span></span></span></a>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15213
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><a target="_blank" href="https://orcid.org/0000-0002-6292-6699" title="" class="ltx_ref ltx_href"><span id="id4.1.1.1" class="ltx_text" style="position:relative; bottom:0.0pt;"><span id="id4.1.1.1.1" class="ltx_text"><img src="/html/2409.09135/assets/x1.png" id="id4.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="5" height="5" alt="[Uncaptioned image]"></span> Sunreeta Bhattacharya</span></a>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Neuroscience Institute, Carnegie Mellon University, Pittsburgh, PA 15213
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><a target="_blank" href="https://orcid.org/0009-0001-1664-9272" title="" class="ltx_ref ltx_href"><span id="id5.1.1.1" class="ltx_text" style="position:relative; bottom:0.0pt;"><span id="id5.1.1.1.1" class="ltx_text"><img src="/html/2409.09135/assets/x1.png" id="id5.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="5" height="5" alt="[Uncaptioned image]"></span> Álvaro Fernández García</span></a>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15213
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><a target="_blank" href="https://orcid.org/0009-0001-6801-253X" title="" class="ltx_ref ltx_href"><span id="id6.1.1.1" class="ltx_text" style="position:relative; bottom:0.0pt;"><span id="id6.1.1.1.1" class="ltx_text"><img src="/html/2409.09135/assets/x1.png" id="id6.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="5" height="5" alt="[Uncaptioned image]"></span> Kailana Baker-Matsuoka</span></a>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Computer Science Department, Carnegie Mellon University, Pittsburgh, PA 15213
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><a target="_blank" href="https://orcid.org/0009-0001-6549-9418" title="" class="ltx_ref ltx_href"><span id="id7.1.1.1" class="ltx_text" style="position:relative; bottom:0.0pt;"><span id="id7.1.1.1.1" class="ltx_text"><img src="/html/2409.09135/assets/x1.png" id="id7.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="5" height="5" alt="[Uncaptioned image]"></span> Sheryl Mathew</span></a>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Computer Science Department, Carnegie Mellon University, Pittsburgh, PA 15213
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><a target="_blank" href="https://orcid.org/0000-0002-8732-4977" title="" class="ltx_ref ltx_href"><span id="id8.1.1.1" class="ltx_text" style="position:relative; bottom:0.0pt;"><span id="id8.1.1.1.1" class="ltx_text"><img src="/html/2409.09135/assets/x1.png" id="id8.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="5" height="5" alt="[Uncaptioned image]"></span> Lori L. Holt</span></a>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Department of Psychology, The University of Texas at Austin, Austin, TX 78712
</span>
<span class="ltx_contact ltx_role_affiliation">Center for Perceptual Systems, The University of Texas at Austin, Austin, TX 78712
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><a target="_blank" href="https://orcid.org/0000-0002-7086-8572" title="" class="ltx_ref ltx_href"><span id="id9.1.1.1" class="ltx_text" style="position:relative; bottom:0.0pt;"><span id="id9.1.1.1.1" class="ltx_text"><img src="/html/2409.09135/assets/x1.png" id="id9.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="5" height="5" alt="[Uncaptioned image]"></span> Fernando De la Torre</span></a>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15213
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id10.id1" class="ltx_p">Over the past decade, wearable computing devices (“smart glasses”) have undergone remarkable advancements in sensor technology, design, and processing power, ushering in a new era of opportunity for high-density human behavior data. Equipped with wearable cameras, these glasses offer a unique opportunity to analyze non-verbal behavior in natural settings as individuals interact. Our focus lies in predicting engagement in dyadic interactions by scrutinizing verbal and non-verbal cues, aiming to detect signs of disinterest or confusion. Leveraging such analyses may revolutionize our understanding of human communication, foster more effective collaboration in professional environments, provide better mental health support through empathetic virtual interactions, and enhance accessibility for those with communication barriers.</p>
<p id="id11.id2" class="ltx_p">In this work, we collect a dataset featuring 34 participants engaged in casual dyadic conversations, each providing self-reported engagement ratings at the end of each conversation.
We introduce a novel fusion strategy using Large Language Models (LLMs) to integrate multiple behavior modalities into a “multimodal transcript” that can be processed by an LLM for behavioral reasoning tasks. Remarkably, this method achieves performance comparable to established fusion techniques even in its preliminary implementation, indicating strong potential for further research and optimization.
This fusion method is one of the first to approach “reasoning” about real-world human behavior through a language model.
Smart glasses provide us the ability to unobtrusively gather high-density multimodal data on human behavior, paving the way for new approaches to understanding and improving human communication with the potential for important societal benefits. The features and data collected during the studies will be made publicly available to promote further research.</p>
</div>
<figure id="S0.F1" class="ltx_figure"><img src="/html/2409.09135/assets/image/teaser_figure.png" id="S0.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="209" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Visual representation of recorded behavior modalities during casual conversation and a sample of the multimodal transcript illustrating their fusion as introduced in this work. The goal is to predict engagement from this multimodal data. Color-coded modality names correspond to lines of the same color in the multimodal transcript.
</figcaption>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">Wearable computing devices, also known as “smart glasses,” offer new approaches to quantifying and understanding human behavior through unobtrusive, high-density behavior tracking. Equipped with sensors such as a video scene camera to monitor the wearer’s view, an eye camera to estimate gaze, a microphone to record speech, and an inertial measurement unit to measure head orientation, smart glasses can capture and respond to human behavior as it unfolds in real-time and real-world contexts. There are numerous potential future applications for such systems: for example, facilitating navigation among the visually impaired, or augmenting social cues for individuals with difficulties reading nonverbal signals.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">Although there has been substantial prior research in laboratory settings (<cite class="ltx_cite ltx_citemacro_cite">Cafaro et al<span class="ltx_text">.</span> (<a href="#bib.bib9" title="" class="ltx_ref">2017</a>); Ringeval et al<span class="ltx_text">.</span> (<a href="#bib.bib54" title="" class="ltx_ref">2013</a>); Vinciarelli et al<span class="ltx_text">.</span> (<a href="#bib.bib65" title="" class="ltx_ref">2009</a>)</cite>) and human-agent interaction (<cite class="ltx_cite ltx_citemacro_cite">Ben-Youssef et al<span class="ltx_text">.</span> (<a href="#bib.bib6" title="" class="ltx_ref">2017</a>); Celiktutan et al<span class="ltx_text">.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2019</a>); McKeown et al<span class="ltx_text">.</span> (<a href="#bib.bib39" title="" class="ltx_ref">2012</a>)</cite>), there are still many rich, unexplored opportunities in natural social contexts, for which smart glasses offer unique capabilities for study. With smart glasses, we can capture natural social interactions that are not constrained by the artificial settings of a laboratory, but rather occur in the natural course of daily life, as we seek help, share information, learn, and maintain social bonds through face-to-face communication. These interactions are rich, nuanced, and impacted moment-by-moment by multimodal cues, both overt and subtle. The stakes can be high: human conflict — between couples, among friends and families, in leadership and governing bodies, and even among societies — occurs when communication breaks down. Face-to-face communication is fundamental in maintaining group cohesion, preserving mental health, fostering academic learning, and supporting developmental growth.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">Engagement has long been recognized as a key determinant of communication success. While lacking a precise definition, engagement can be loosely defined as an individual’s attentional and emotional investment during communication (<cite class="ltx_cite ltx_citemacro_cite">Pellet-Rostaing et al<span class="ltx_text">.</span> (<a href="#bib.bib47" title="" class="ltx_ref">2023</a>)</cite>). The ability to captivate in conversation can determine life-changing interactions, whether acing a job interview or making a favorable impression on a first date. The depth of our engagement and that of our partner shapes the outcomes of many social, educational, and professional activities.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">For the most part, humans automatically and implicitly pick up on the subtle, variable cues that convey engagement in a conversation. Yet, building systems that accurately measure and gauge conversational engagement remains a formidable challenge. Difficulties arise with the complexity and subtlety of human behavior, its context-dependence, and its variability across personal histories and cultural backgrounds. Further complicating matters, social communication is inherently multifaceted, with engagement likely to be conveyed across verbal content, nonverbal cues like tone of voice, facial expressions, hand and head gestures, and also through the absence of overt signals, such as extended periods of silence or few gazes to a partner’s face. The unpredictable and dynamic nature of social exchanges makes predicting engagement difficult, as engagement patterns can shift rapidly and vary widely across contexts. Thus, techniques that can perform effectively with minimal or no in-domain training are of particular interest.</p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p id="S1.p5.1" class="ltx_p">The dearth of relevant data presents another challenge. Although there is an abundance of openly available datasets of dyadic interactions from a third-person viewpoint, such as IEMOCAP (<cite class="ltx_cite ltx_citemacro_cite">Busso et al<span class="ltx_text">.</span> (<a href="#bib.bib8" title="" class="ltx_ref">2008</a>)</cite>), SEMAINE (<cite class="ltx_cite ltx_citemacro_cite">McKeown et al<span class="ltx_text">.</span> (<a href="#bib.bib39" title="" class="ltx_ref">2012</a>)</cite>), MEISD (<cite class="ltx_cite ltx_citemacro_cite">Firdaus et al<span class="ltx_text">.</span> (<a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite>), MELD (<cite class="ltx_cite ltx_citemacro_cite">Poria et al<span class="ltx_text">.</span> (<a href="#bib.bib50" title="" class="ltx_ref">2019</a>)</cite>), or NoXi (<cite class="ltx_cite ltx_citemacro_cite">Cafaro et al<span class="ltx_text">.</span> (<a href="#bib.bib9" title="" class="ltx_ref">2017</a>)</cite>), naturalistic dyadic interactions captured from an egocentric viewpoint are scarce. In the past few years, as smart glasses have become more widely accessible, research has begun to gather egocentric recordings for other tasks, such as skilled human activity (Ego-Exo4D, <cite class="ltx_cite ltx_citemacro_cite">Grauman et al<span class="ltx_text">.</span> (<a href="#bib.bib26" title="" class="ltx_ref">2024</a>)</cite>) and user gaze anticipation (<cite class="ltx_cite ltx_citemacro_cite">Lai et al<span class="ltx_text">.</span> (<a href="#bib.bib34" title="" class="ltx_ref">2023</a>)</cite>), though less focused on interpersonal behavior. These factors pose significant challenges for building socially-aware artificial systems that accurately interpret and respond in a manner that feels authentic and engaging to humans. Nonetheless, there is good reason to work to meet these challenges. Imagine a system that can gauge audience engagement with a teacher’s lecture and provide on-the-fly feedback they can use to better engage their students. Or consider assistive technologies that can offer alternative presentations of challenging social signals for those with communication disorders. The potential applications are extensive.</p>
</div>
<div id="S1.p6" class="ltx_para ltx_noindent">
<p id="S1.p6.1" class="ltx_p">The contribution of the present work is twofold. We introduce a novel dataset including recordings of natural, unscripted conversations among unfamiliar dyads wearing Pupil Invisible smart glasses, as illustrated in the left-hand segment of <a href="#S0.F1" title="Figure 1 ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 1</span></a>. This dataset contains conversations between 19 unique dyads, including video and audio recordings, eye tracking, and self-reported information on demographic, political, and personality factors from the participants.</p>
</div>
<div id="S1.p7" class="ltx_para ltx_noindent">
<p id="S1.p7.1" class="ltx_p">The second contribution presents an analysis of this dataset, focusing on predicting participant engagement levels through post-session self-reports. We compare audio-visual classical fusion techniques (<cite class="ltx_cite ltx_citemacro_cite">Xu et al<span class="ltx_text">.</span> (<a href="#bib.bib70" title="" class="ltx_ref">2022</a>); Wuerkaixi et al<span class="ltx_text">.</span> (<a href="#bib.bib69" title="" class="ltx_ref">2022</a>)</cite>) with our novel proposed fusion approach, which uses a large language model (LLM) as a reasoning engine to fuse behavioral measures into a multimodal textual representation, a sample of which is displayed in the right-hand segment of <a href="#S0.F1" title="Figure 1 ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 1</span></a>. Our results indicate that this approach achieves performance comparable to the established fusion techniques even in this early implementation. This approach is a powerful, simple, and flexible framework for future work on modeling human behavior and developing socially intelligent technologies.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Prior Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">This section reviews classical fusion methods and works on LLMs for analyzing and understanding human behavior.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Classical Fusion</h3>

<div id="S2.SS1.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib16" title="" class="ltx_ref">Curhan and Pentland</a></cite> used speech features (conversational engagement, prosodic emphasis, and vocal mirroring) in the first five minutes of a simulated negotiation to predict the outcomes of the negotiation (<cite class="ltx_cite ltx_citemacro_cite">Curhan and Pentland (<a href="#bib.bib16" title="" class="ltx_ref">2007</a>)</cite>). Using these features, they predicted 30% of the variance in negotiation outcomes, demonstrating the value of speech features in conversational dynamics. This result suggests that speech features are similarly important in predicting conversational engagement. Activity level and mirroring had differing relationships with the outcome depending on the assigned position of participants, showing that perceived status can affect how conversational dynamics relate to negotiation success. This interaction poses the question of how status affects how features predict conversational engagement.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para ltx_noindent">
<p id="S2.SS1.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib47" title="" class="ltx_ref">Pellet-Rostaing et al<span class="ltx_text">.</span></a></cite> used prosodic-acoustic, prosodic-temporal, mimo-gestural, and linguistic features to predict the engagement level of the target participant while holding the speaking turn (<cite class="ltx_cite ltx_citemacro_cite">Pellet-Rostaing et al<span class="ltx_text">.</span> (<a href="#bib.bib47" title="" class="ltx_ref">2023</a>)</cite>). The study showed the value of visual and audio features, achieving the best results with the prosodic-acoustic, prosodic-temporal, and mimo-gestural modalities. Achieving similar results to studies using annotator-defined segments demonstrated that annotating engagement at a turn level can be effective.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para ltx_noindent">
<p id="S2.SS1.p3.1" class="ltx_p">In our study, we attempted to use gaze as a means of gauging dyadic interaction, along with other modalities, as it is evidenced by some to have correlations with engagement (<cite class="ltx_cite ltx_citemacro_cite">Goodwin (<a href="#bib.bib24" title="" class="ltx_ref">1981</a>); Ranti et al<span class="ltx_text">.</span> (<a href="#bib.bib53" title="" class="ltx_ref">2020</a>)</cite>). <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib24" title="" class="ltx_ref">Goodwin</a></cite> emphasizes the interconnected nature of gaze behavior among participants in a conversation and points out that the way individuals direct their gaze is not a solitary or random act but is deeply intertwined with the social dynamics of the interaction (<cite class="ltx_cite ltx_citemacro_cite">Goodwin (<a href="#bib.bib24" title="" class="ltx_ref">1981</a>)</cite>). This gaze behavior acts as a nuanced signal of a participant’s level of attention and engagement, reflecting whether they are actively participating or disengaging from the conversation. Furthermore, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib24" title="" class="ltx_ref">Goodwin</a></cite> explores the concept of gaze withdrawal as a strategic communicative gesture that participants use to signal their intentions within the conversation, such as making a bid for closure or expressing a particular understanding of the conversation’s trajectory.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para ltx_noindent">
<p id="S2.SS1.p4.1" class="ltx_p">Moreover, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib53" title="" class="ltx_ref">Ranti et al<span class="ltx_text">.</span></a></cite> underscore the potential of utilizing eye-blink measures as a reliable indicator of an individual’s subjective engagement with various stimuli (<cite class="ltx_cite ltx_citemacro_cite">Ranti et al<span class="ltx_text">.</span> (<a href="#bib.bib53" title="" class="ltx_ref">2020</a>)</cite>). By closely analyzing the timing of blink inhibition in response to unfolding scene content, they found that they could uncover the viewers’ unconscious, subjective evaluations of the importance and engagement level of what they observe. A notable observation is that a slower blinking rate is often associated with a higher degree of engagement, suggesting that individuals are more absorbed and attentive to the conversation or content presented to them.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Large Language Models (LLMs)</h3>

<div id="S2.SS2.p1" class="ltx_para ltx_noindent">
<p id="S2.SS2.p1.1" class="ltx_p">The capabilities and accessibility of LLMs have opened up a wide range of potential applications, particularly in fields related to human subjects like psychology. They range from creating synthetic datasets of LLM-generated responses in human-less experiments (<cite class="ltx_cite ltx_citemacro_cite">Demszky et al<span class="ltx_text">.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite>) to providing automated feedback to clinicians (<cite class="ltx_cite ltx_citemacro_cite">Stade et al<span class="ltx_text">.</span> (<a href="#bib.bib58" title="" class="ltx_ref">2024</a>)</cite>).</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<p id="S2.SS2.p2.1" class="ltx_p">One application involves exploring the ability of LLMs to mimic human behavior because of their potential to reduce the need for human subject experiments and power realistic, interactive interactions. <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib2" title="" class="ltx_ref">Aher et al<span class="ltx_text">.</span></a></cite> explore the ability of LLMs to reproduce human subjects’ behavior in classic experiments, such as the “Wisdom of Crowds” (<cite class="ltx_cite ltx_citemacro_cite">Aher et al<span class="ltx_text">.</span> (<a href="#bib.bib2" title="" class="ltx_ref">2023</a>)</cite>). <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib3" title="" class="ltx_ref">Argyle et al<span class="ltx_text">.</span></a></cite> investigate the potential of LLMs as proxies for human sub-populations in social science research (<cite class="ltx_cite ltx_citemacro_cite">Argyle et al<span class="ltx_text">.</span> (<a href="#bib.bib3" title="" class="ltx_ref">2023</a>)</cite>). <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib60" title="" class="ltx_ref">Tavast et al<span class="ltx_text">.</span></a></cite> evaluate the human-likeness of responses on the PANAS questionnaire generated by <span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_typewriter">GPT-3</span>  (<cite class="ltx_cite ltx_citemacro_cite">Tavast et al<span class="ltx_text">.</span> (<a href="#bib.bib60" title="" class="ltx_ref">2022</a>)</cite>). The feasibility of using LLMs to replace human participants is further explored in  (<cite class="ltx_cite ltx_citemacro_cite">Harding et al<span class="ltx_text">.</span> (<a href="#bib.bib28" title="" class="ltx_ref">2023</a>); Dillion et al<span class="ltx_text">.</span> (<a href="#bib.bib19" title="" class="ltx_ref">2023</a>)</cite>). <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib46" title="" class="ltx_ref">Park et al<span class="ltx_text">.</span></a></cite> introduce generative agents powered by LLMs that simulate believable human behavior in a virtual environment (<cite class="ltx_cite ltx_citemacro_cite">Park et al<span class="ltx_text">.</span> (<a href="#bib.bib46" title="" class="ltx_ref">2023</a>)</cite>), also similarly seen in <cite class="ltx_cite ltx_citemacro_cite">Zhou et al<span class="ltx_text">.</span> (<a href="#bib.bib73" title="" class="ltx_ref">2024</a>)</cite>. There is also a body of work on understanding the personality of LLMs, identifying ways to manipulate the personality embodied by an LLM, and injecting personality into LLMs to predict human responses concerning values (<cite class="ltx_cite ltx_citemacro_cite">Serapio-García et al<span class="ltx_text">.</span> (<a href="#bib.bib57" title="" class="ltx_ref">2023</a>); Kang et al<span class="ltx_text">.</span> (<a href="#bib.bib31" title="" class="ltx_ref">2023</a>)</cite>).</p>
</div>
<div id="S2.SS2.p3" class="ltx_para ltx_noindent">
<p id="S2.SS2.p3.1" class="ltx_p">Another application involves exploring the ability of LLMs to understand human behavior. This line of work involves evaluating their theory of mind abilities, which refers to the ability to understand the mental states of others, such as purpose or intention  (<cite class="ltx_cite ltx_citemacro_cite">Premack and Woodruff (<a href="#bib.bib51" title="" class="ltx_ref">1978</a>)</cite>). Prior work has proposed various benchmarks and methods to evaluate an agent’s theory of mind (<cite class="ltx_cite ltx_citemacro_cite">Kim et al<span class="ltx_text">.</span> (<a href="#bib.bib33" title="" class="ltx_ref">2023</a>); Sap et al<span class="ltx_text">.</span> (<a href="#bib.bib56" title="" class="ltx_ref">2019</a>, <a href="#bib.bib55" title="" class="ltx_ref">2022</a>)</cite>).</p>
</div>
<div id="S2.SS2.p4" class="ltx_para ltx_noindent">
<p id="S2.SS2.p4.1" class="ltx_p">These works are essential to assessing the ability of LLMs to simulate and understand human behavior. However, they are all limited to static benchmarks or simplified virtual interactions. There is a lack of work exploring the ability of LLMs to simulate and predict the outcomes of human social interactions, such as predicting a person’s responses to a survey that measures engagement. We argue that this dimension should be considered when developing LLMs to simulate and understand behavior.</p>
</div>
<div id="S2.SS2.p5" class="ltx_para ltx_noindent">
<p id="S2.SS2.p5.1" class="ltx_p">Our work proposes a dataset and method for unifying the work on simulating and understanding engagement in social interactions with LLMs grounded in real, in-the-wild social interactions. Given the potential of LLMs to advance socially intelligent technologies, incorporating in-the-wild social interactions into research is essential.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Data Set</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">In our work, we collected and studied pairs of strangers conversing in a room, recorded from the viewpoint of each participant through a pair of smart glasses.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Population</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p">Our study contained 34 unique participants and 19 unique dyads<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Two participants appeared in multiple dyads, but all dyads were unique.</span></span></span>. Demographically, 14 participants identified as male, 19 identified as female, and one identified as non-binary; 47% identified as Asian, and 38% identified as White/Caucasian. All participants were 18–35 years of age but were primarily in their early twenties. Participants were recruited from the local university through various physical and digital media and word-of-mouth. Participants were required to be fluent in English and have normal or corrected vision with contact lenses (to avoid conflict with the smart glasses).</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Procedure</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p">The entire recording session lasted approximately 15 minutes, including introductions and closing. Each participant was equipped with a pair of smart glasses (refer to <a href="#S3.SS3" title="3.3 Recording Instruments ‣ 3 Data Set ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Section 3.3</span></a> for detailed specifications), capturing their field of vision, head motion, and gaze. While the smart glasses are advertised to work well across recording sessions without calibration, they benefit from calibration when changing users (<cite class="ltx_cite ltx_citemacro_cite">Tonsen et al<span class="ltx_text">.</span> (<a href="#bib.bib63" title="" class="ltx_ref">2020</a>)</cite>)<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Note that the referenced study was conducted by the manufacturer of the device.</span></span></span>, so we conducted a calibration procedure for each participant before the beginning of the session. At the start of the session, participants were suggested an ice-breaker: their experience during COVID-19, a universally shared topic, but the conversation was not constrained to this topic. Following the session, participants completed questionnaires on their beliefs, personality, and engagement during this interaction (refer to <a href="#S3.SS4" title="3.4 Self-Report Questionnaires ‣ 3 Data Set ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Section 3.4</span></a> for details on the questionnaires).</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Recording Instruments</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.p1.1" class="ltx_p">Each session was recorded using Pupil Invisible smart glasses worn by all participants and a centrally placed external microphone to record the dialogue.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Pupil Smart Glasses</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">Each participant was equipped with Pupil Invisible<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://pupil-labs.com/products/invisible" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://pupil-labs.com/products/invisible</a></span></span></span> smart glasses manufactured by Pupil Labs, specially designed to closely resemble regular eyeglasses for user comfort and a discreet appearance. The key features of these smart glasses that we leverage in our work include the following:</p>
</div>
<div id="S3.SS3.SSS1.p2" class="ltx_para ltx_noindent">
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.2" class="ltx_p"><span id="S3.I1.i1.p1.2.1" class="ltx_text ltx_font_bold">Scene camera:</span> A detachable camera mounted on the left arm of the glasses frame captures the wearer’s field of view with an <math id="S3.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="82^{\circ}\times 82^{\circ}" display="inline"><semantics id="S3.I1.i1.p1.1.m1.1a"><mrow id="S3.I1.i1.p1.1.m1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.cmml"><msup id="S3.I1.i1.p1.1.m1.1.1.2" xref="S3.I1.i1.p1.1.m1.1.1.2.cmml"><mn id="S3.I1.i1.p1.1.m1.1.1.2.2" xref="S3.I1.i1.p1.1.m1.1.1.2.2.cmml">82</mn><mo id="S3.I1.i1.p1.1.m1.1.1.2.3" xref="S3.I1.i1.p1.1.m1.1.1.2.3.cmml">∘</mo></msup><mo lspace="0.222em" rspace="0.222em" id="S3.I1.i1.p1.1.m1.1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.1.cmml">×</mo><msup id="S3.I1.i1.p1.1.m1.1.1.3" xref="S3.I1.i1.p1.1.m1.1.1.3.cmml"><mn id="S3.I1.i1.p1.1.m1.1.1.3.2" xref="S3.I1.i1.p1.1.m1.1.1.3.2.cmml">82</mn><mo id="S3.I1.i1.p1.1.m1.1.1.3.3" xref="S3.I1.i1.p1.1.m1.1.1.3.3.cmml">∘</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b"><apply id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1"><times id="S3.I1.i1.p1.1.m1.1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1.1"></times><apply id="S3.I1.i1.p1.1.m1.1.1.2.cmml" xref="S3.I1.i1.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.I1.i1.p1.1.m1.1.1.2.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1.2">superscript</csymbol><cn type="integer" id="S3.I1.i1.p1.1.m1.1.1.2.2.cmml" xref="S3.I1.i1.p1.1.m1.1.1.2.2">82</cn><compose id="S3.I1.i1.p1.1.m1.1.1.2.3.cmml" xref="S3.I1.i1.p1.1.m1.1.1.2.3"></compose></apply><apply id="S3.I1.i1.p1.1.m1.1.1.3.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.I1.i1.p1.1.m1.1.1.3.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S3.I1.i1.p1.1.m1.1.1.3.2.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.2">82</cn><compose id="S3.I1.i1.p1.1.m1.1.1.3.3.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.3"></compose></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">82^{\circ}\times 82^{\circ}</annotation></semantics></math> viewing angle, at a resolution of <math id="S3.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="1088\times 1080" display="inline"><semantics id="S3.I1.i1.p1.2.m2.1a"><mrow id="S3.I1.i1.p1.2.m2.1.1" xref="S3.I1.i1.p1.2.m2.1.1.cmml"><mn id="S3.I1.i1.p1.2.m2.1.1.2" xref="S3.I1.i1.p1.2.m2.1.1.2.cmml">1088</mn><mo lspace="0.222em" rspace="0.222em" id="S3.I1.i1.p1.2.m2.1.1.1" xref="S3.I1.i1.p1.2.m2.1.1.1.cmml">×</mo><mn id="S3.I1.i1.p1.2.m2.1.1.3" xref="S3.I1.i1.p1.2.m2.1.1.3.cmml">1080</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.2.m2.1b"><apply id="S3.I1.i1.p1.2.m2.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1"><times id="S3.I1.i1.p1.2.m2.1.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1.1"></times><cn type="integer" id="S3.I1.i1.p1.2.m2.1.1.2.cmml" xref="S3.I1.i1.p1.2.m2.1.1.2">1088</cn><cn type="integer" id="S3.I1.i1.p1.2.m2.1.1.3.cmml" xref="S3.I1.i1.p1.2.m2.1.1.3">1080</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.2.m2.1c">1088\times 1080</annotation></semantics></math> pixels and a frame rate of 30 Hz.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para ltx_noindent">
<p id="S3.I1.i2.p1.2" class="ltx_p"><span id="S3.I1.i2.p1.2.1" class="ltx_text ltx_font_bold">Eye gaze tracking:</span> Two IR cameras, positioned near the would-be hinges of the glasses frame, record eye movements at a resolution of <math id="S3.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="192\times 192" display="inline"><semantics id="S3.I1.i2.p1.1.m1.1a"><mrow id="S3.I1.i2.p1.1.m1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.cmml"><mn id="S3.I1.i2.p1.1.m1.1.1.2" xref="S3.I1.i2.p1.1.m1.1.1.2.cmml">192</mn><mo lspace="0.222em" rspace="0.222em" id="S3.I1.i2.p1.1.m1.1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.1.cmml">×</mo><mn id="S3.I1.i2.p1.1.m1.1.1.3" xref="S3.I1.i2.p1.1.m1.1.1.3.cmml">192</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b"><apply id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1"><times id="S3.I1.i2.p1.1.m1.1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.I1.i2.p1.1.m1.1.1.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2">192</cn><cn type="integer" id="S3.I1.i2.p1.1.m1.1.1.3.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3">192</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">192\times 192</annotation></semantics></math> pixels and a frame rate of 200 Hz. Post-processing software provided by the manufacturer converts this data into 2D gaze points at 120 Hz in scene camera coordinates. This system is advertised to achieve an uncalibrated accuracy of approximately <math id="S3.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="4.6^{\circ}" display="inline"><semantics id="S3.I1.i2.p1.2.m2.1a"><msup id="S3.I1.i2.p1.2.m2.1.1" xref="S3.I1.i2.p1.2.m2.1.1.cmml"><mn id="S3.I1.i2.p1.2.m2.1.1.2" xref="S3.I1.i2.p1.2.m2.1.1.2.cmml">4.6</mn><mo id="S3.I1.i2.p1.2.m2.1.1.3" xref="S3.I1.i2.p1.2.m2.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.2.m2.1b"><apply id="S3.I1.i2.p1.2.m2.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.I1.i2.p1.2.m2.1.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1">superscript</csymbol><cn type="float" id="S3.I1.i2.p1.2.m2.1.1.2.cmml" xref="S3.I1.i2.p1.2.m2.1.1.2">4.6</cn><compose id="S3.I1.i2.p1.2.m2.1.1.3.cmml" xref="S3.I1.i2.p1.2.m2.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.2.m2.1c">4.6^{\circ}</annotation></semantics></math>, but calibration per user can enhance accuracy (<cite class="ltx_cite ltx_citemacro_cite">Tonsen et al<span class="ltx_text">.</span> (<a href="#bib.bib63" title="" class="ltx_ref">2020</a>)</cite>).</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Stereo Microphone</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">In addition to the recordings captured by the smart glasses’ scene camera, we used an external high-quality stereo microphone (Zoom H4N Pro) to record the conversation at a standard 44.1 kHz sampling rate. This decision was made after determining that the quality of the audio captured by the smart glasses scene camera was insufficient for acoustic analysis. To synchronize the media streams, participants were instructed to perform a hand clap at the start of each session, emulating the clapperboard technique commonly used in film production.</p>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Self-Report Questionnaires</h3>

<div id="S3.SS4.p1" class="ltx_para ltx_noindent">
<p id="S3.SS4.p1.1" class="ltx_p">The participants were asked to complete a questionnaire that measured self-reported engagement after each interaction. The engagement questionnaire consisted of 53 items based primarily on previous studies on participant perception of interaction quality (<cite class="ltx_cite ltx_citemacro_cite">Cuperman and Ickes (<a href="#bib.bib15" title="" class="ltx_ref">2009</a>)</cite>): refer to <a href="#A1" title="Appendix A Engagement Questionnaire ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Appendix A</span></a> for detailed information and statistics regarding the items in the engagement questionnaire. The participants were also asked to complete the Big Five Inventory (<cite class="ltx_cite ltx_citemacro_cite">McCrae and Costa Jr. (<a href="#bib.bib37" title="" class="ltx_ref">1999</a>)</cite>) for personality information and a handcrafted questionnaire on personal beliefs. This questionnaire was based on a set of socio-cultural issues studied to gauge polarization along the political spectrum (<cite class="ltx_cite ltx_citemacro_cite">Pew Research Center (<a href="#bib.bib48" title="" class="ltx_ref">2021</a>)</cite>).</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Feature Extraction</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">After gathering the recordings, the data required pre-processing. Initially, we adjusted the video to eliminate the radial distortion introduced by the scene camera’s lens. This was achieved by applying the distortion coefficients provided by the manufacturer<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>For details on the information provided by the manufacturer, see Pupil Lab Invisible recording and export instructions: <a target="_blank" href="https://docs.pupil-labs.com/invisible/data-collection/data-format/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://docs.pupil-labs.com/invisible/data-collection/data-format/</a>.</span></span></span>. Due to the differing frame rates between the eye-tracking camera and the egocentric scene-view camera, we also synchronized the data to a unified 30 fps timestamp.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Facial Expression</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p">Facial action units (FAU) from the processed video were extracted with OpenFace 2.0 (<cite class="ltx_cite ltx_citemacro_cite">Baltrusaitis et al<span class="ltx_text">.</span> (<a href="#bib.bib5" title="" class="ltx_ref">2018</a>)</cite>). Since OpenFace achieves optimal performance when the face in the image exceeds a width of 100px, we needed to upscale our data to meet this suggestion. For each frame, we used MediaPipe (<cite class="ltx_cite ltx_citemacro_cite">Lugaresi et al<span class="ltx_text">.</span> (<a href="#bib.bib36" title="" class="ltx_ref">2019</a>)</cite>)<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>MediaPipe version: 0.9.1</span></span></span> to identify the location of the face in the image, then cropped and rescaled the image to ensure that the face was centered and was at least 240px wide and the final dimensions were 1080x1080px. If no face was detected for a particular frame, the location of the face in the previous frame was used.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Gaze Tracking</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.1" class="ltx_p">For every frame, we determined whether a participant’s gaze is directed towards their partner’s face, recognizing the significance of gaze in forecasting engagement (<cite class="ltx_cite ltx_citemacro_cite">Celepkolu and Boyer (<a href="#bib.bib11" title="" class="ltx_ref">2018</a>); Nakano and Ishii (<a href="#bib.bib42" title="" class="ltx_ref">2010</a>)</cite>).
This was accomplished by creating a convex hull using the 478 2-dimensional face landmarks extracted from MediaPipe to outline the face. A gaze point captured by Pupil smart glasses was deemed to be on the face if it fell within the convex hull (including its boundary) or within 30% of the width of the face’s convex hull to account for the potential inaccuracy of gaze prediction from Pupil smart glasses described in its specifications.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Dialogue Transcription</h3>

<div id="S4.SS3.p1" class="ltx_para ltx_noindent">
<p id="S4.SS3.p1.1" class="ltx_p">OpenAI’s Whisper (<cite class="ltx_cite ltx_citemacro_cite">Radford et al<span class="ltx_text">.</span> (<a href="#bib.bib52" title="" class="ltx_ref">2023</a>)</cite>)<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>Whisper version: large-v20230918</span></span></span> was used to transcribe the recording from each session. Whisper outputs fine-grained segments with start and stop times around a few seconds long. A speaker was assigned to each segment. If the segment contained speech from both speakers, the speaker who spoke most was assigned. Diarization tools like PyAnnote (<cite class="ltx_cite ltx_citemacro_cite">Plaquet and Bredin (<a href="#bib.bib49" title="" class="ltx_ref">2023</a>); Bredin (<a href="#bib.bib7" title="" class="ltx_ref">2023</a>)</cite>) and source separation tools performed poorly with audio from our dataset, so manual labeling was chosen.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>LLM Fusion</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">In this work, we explore the use of large language models (LLMs) to “reason” about a social interaction using multimodal information. Our method involves prompting an LLM to simulate a study participant and answer the end-of-session engagement questionnaire as though it were the participant theirselves.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Socratic Models</h3>

<div id="S5.SS1.p1" class="ltx_para ltx_noindent">
<p id="S5.SS1.p1.1" class="ltx_p">Understanding and interpreting the reasoning of machine learning models is widely recognized to be a significant challenge. Typically, models encode behavioral features into a high-dimensional, abstract vector space, which is then mapped onto the target prediction space. To understand a model’s inner workings, we usually project these intermediate data into a space that is more understandable to humans, often through visualization techniques. However, consider the possibility of the inverse — rather than allowing the model to obscure information into abstract dimensions, we could direct its operation into a universally interpretable space: the domain of language itself. When studying a topic like human behavior from a computational perspective, AI systems like LLMs that utilize language to “reason” about said topics are worth further study because the language allows for nuance and ambiguity that inherently exists in these fields.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para ltx_noindent">
<p id="S5.SS1.p2.1" class="ltx_p">Socratic Models, named for the ancient Greek philosopher’s teaching method through cross-examination, use language to integrate information from a diverse set of modalities (<cite class="ltx_cite ltx_citemacro_cite">Zeng et al<span class="ltx_text">.</span> (<a href="#bib.bib71" title="" class="ltx_ref">2022</a>)</cite>). Within this framework, pre-trained models fine-tuned toward specific modalities or behaviors translate their interpretations of inputs into natural language. This translation is formulated into a language prompt to direct the reasoning of an LLM. This approach allows a set of pre-trained models to “discuss” various multimodal information, akin to asking and answering questions in a Socratic dialogue. By framing the task as a language-driven exchange, the Socratic Model framework allows pre-trained models, each specialized in a distinct domain, to perform downstream multimodal tasks without further training or fine-tuning.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para ltx_noindent">
<p id="S5.SS1.p3.1" class="ltx_p">Thus far, there have been only a few early attempts at applying this framework for prediction. In the domain of image captioning, one study revealed that an ensemble of models within the Socratic Models framework generated captions that substantially improve the capabilities of the zero-shot state-of-the-art ZeroCap (<cite class="ltx_cite ltx_citemacro_cite">Tewel et al<span class="ltx_text">.</span> (<a href="#bib.bib62" title="" class="ltx_ref">2022</a>)</cite>). However, when compared to fine-tuned models such as ClipCap (<cite class="ltx_cite ltx_citemacro_cite">Mokady et al<span class="ltx_text">.</span> (<a href="#bib.bib40" title="" class="ltx_ref">2021</a>)</cite>), performance was not as impressive; yet, this performance gap narrowed considerably when the ensemble was provided a small set of example captions from the training set, suggesting its potential in few-shot learning scenarios (<cite class="ltx_cite ltx_citemacro_cite">Zeng et al<span class="ltx_text">.</span> (<a href="#bib.bib71" title="" class="ltx_ref">2022</a>)</cite>).</p>
</div>
<div id="S5.SS1.p4" class="ltx_para ltx_noindent">
<p id="S5.SS1.p4.1" class="ltx_p">This concept of “many-to-one” alignment has also been explored from other angles. ImageBind, for instance, develops a multimodal representation through a set of image-paired modalities (<cite class="ltx_cite ltx_citemacro_cite">Girdhar et al<span class="ltx_text">.</span> (<a href="#bib.bib23" title="" class="ltx_ref">2023</a>)</cite>) while LanguageBind extends video-language pre-training to a broader range of language-paired modalities (<cite class="ltx_cite ltx_citemacro_cite">Zhu et al<span class="ltx_text">.</span> (<a href="#bib.bib74" title="" class="ltx_ref">2024</a>)</cite>). However, both of these models still face the challenge of abstracting information. ImageBind and LanguageBind create “bindings” centered around a specific modality but do not explicitly work within that modality itself. Instead, they map a primary modality into an abstract space and then align information from other modalities to this space, resulting in a multimodal representation that resembles the embedding of the primary modality. While this approach has proven effective at abstract tasks such as video-text alignment and image-text retrieval, it is less effective in providing human users with a coherent understanding of its reasoning. Our research aims to follow a similar path but with a crucial distinction: our embedding space is designed to be language itself, which may offer a more direct and interpretable framework for multimodal learning.</p>
</div>
<div id="S5.SS1.p5" class="ltx_para ltx_noindent">
<p id="S5.SS1.p5.1" class="ltx_p">Previous studies have established the value of the language modality in understanding complex social phenomena, such as rapport (<cite class="ltx_cite ltx_citemacro_cite">Carmody et al<span class="ltx_text">.</span> (<a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>), affinity (<cite class="ltx_cite ltx_citemacro_cite">Ireland and Pennebaker (<a href="#bib.bib29" title="" class="ltx_ref">2010</a>); Ireland et al<span class="ltx_text">.</span> (<a href="#bib.bib30" title="" class="ltx_ref">2011</a>)</cite>), and, as in the present work, engagement (<cite class="ltx_cite ltx_citemacro_cite">Babcock et al<span class="ltx_text">.</span> (<a href="#bib.bib4" title="" class="ltx_ref">2014</a>)</cite>). Various computational methods have been employed to extract this information from language, from rudimentary bag-of-words approaches to more sophisticated neural network models (<cite class="ltx_cite ltx_citemacro_cite">Tausczik and Pennebaker (<a href="#bib.bib59" title="" class="ltx_ref">2010</a>); Van Swol and Kane (<a href="#bib.bib64" title="" class="ltx_ref">2019</a>)</cite>). Recent advancements, however, have seen a considerable increase in LLMs adapted to augment tasks requiring social intelligence: notable applications have included refining persuasive communication for public health campaigns (<cite class="ltx_cite ltx_citemacro_cite">Karinshak et al<span class="ltx_text">.</span> (<a href="#bib.bib32" title="" class="ltx_ref">2023</a>); Cox et al<span class="ltx_text">.</span> (<a href="#bib.bib14" title="" class="ltx_ref">2023</a>)</cite>) and identifying adverse social determinants of health within free-form clinical notes  (<cite class="ltx_cite ltx_citemacro_cite">Guevara et al<span class="ltx_text">.</span> (<a href="#bib.bib27" title="" class="ltx_ref">2024</a>)</cite>). One of the objectives of the present work is to explore the utility of LLMs for behavior analysis of social interactions: in our case, estimating the conversational engagement of speakers in a dyadic interaction. The proposed approach centers around employing OpenAI’s <span id="S5.SS1.p5.1.1" class="ltx_text ltx_font_typewriter">GPT</span> models to impersonate each participant in the conversation by responding to the self-reported questionnaire in a zero-shot manner. This is achieved through reconstructing the conversation using multimodal-informed prompting that combines behavioral information inspired by the Socratic Models framework proposed by <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib71" title="" class="ltx_ref">Zeng et al<span class="ltx_text">.</span></a></cite>.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Algorithms for LLM Fusion</h3>

<div id="S5.SS2.p1" class="ltx_para ltx_noindent">
<p id="S5.SS2.p1.1" class="ltx_p">The novel LLM fusion approach that we introduce enables an LLM to emulate a participant by creating a multimodal prompt: a dialogue transcript of the recording session augmented with textual representations of non-verbal behavior. In this work, these textual representations are formed from the data collected by the smart glasses, multiple pre-trained models, and personality questionnaires, but this method can be extended to contain any number of additional behavioral cues. We aim to evaluate whether this multimodal transcript effectively captures the dynamics of social interaction and can enable an LLM to predict self-reported engagement levels effectively. This work focuses on OpenAI’s models <span id="S5.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">GPT-4</span> and <span id="S5.SS2.p1.1.2" class="ltx_text ltx_font_typewriter">GPT-3.5</span> <span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>Fixed at versions <span id="footnote7.1" class="ltx_text ltx_font_typewriter">GPT-4-0613</span> and <span id="footnote7.2" class="ltx_text ltx_font_typewriter">GPT-3.5-turbo-0613</span> for consistency.</span></span></span>, but the technique could be applied to any LLM.</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1 </span>Modalities</h4>

<div id="S5.SS2.SSS1.p1" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS1.p1.1" class="ltx_p">As described in <a href="#S4" title="4 Feature Extraction ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Section 4</span></a>, this analysis included information from speech, gaze, and facial expression modalities, given their straightforward translation into text form and their established significance in signaling engagement.</p>
</div>
<div id="S5.SS2.SSS1.p2" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS1.p2.1" class="ltx_p">The <span id="S5.SS2.SSS1.p2.1.1" class="ltx_text ltx_font_bold">speech</span> modality serves as the foundation of the multimodal transcript: its representation consists of the dialogue transcript augmented with speaker-labeled segments as described in <a href="#S4.SS3" title="4.3 Dialogue Transcription ‣ 4 Feature Extraction ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Section 4.3</span></a>.
The <span id="S5.SS2.SSS1.p2.1.2" class="ltx_text ltx_font_bold">gaze</span> modality is represented by a string indicating the proportion of time a speaker’s gaze remains on their partner’s face, rounded to the nearest 10% for brevity.</p>
</div>
<div id="S5.SS2.SSS1.p3" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS1.p3.1" class="ltx_p">The <span id="S5.SS2.SSS1.p3.1.1" class="ltx_text ltx_font_bold">facial expression</span> modality is represented by a text description of the dominant emotional expression for each speaker-labeled segment of the recording following the methods of existing research (<cite class="ltx_cite ltx_citemacro_cite">Tejada et al<span class="ltx_text">.</span> (<a href="#bib.bib61" title="" class="ltx_ref">2022</a>)</cite>) and applications (iMotion’s Affectiva; (<cite class="ltx_cite ltx_citemacro_cite">McDuff et al<span class="ltx_text">.</span> (<a href="#bib.bib38" title="" class="ltx_ref">2016</a>)</cite>)), these emotional expressions were defined by the facial action units measured by OpenFace 2.0: <em id="S5.SS2.SSS1.p3.1.2" class="ltx_emph ltx_font_italic">happy</em>, <em id="S5.SS2.SSS1.p3.1.3" class="ltx_emph ltx_font_italic">sad</em>, <em id="S5.SS2.SSS1.p3.1.4" class="ltx_emph ltx_font_italic">surprise</em>, <em id="S5.SS2.SSS1.p3.1.5" class="ltx_emph ltx_font_italic">fear</em>, <em id="S5.SS2.SSS1.p3.1.6" class="ltx_emph ltx_font_italic">anger</em>, <em id="S5.SS2.SSS1.p3.1.7" class="ltx_emph ltx_font_italic">disgust</em>, <em id="S5.SS2.SSS1.p3.1.8" class="ltx_emph ltx_font_italic">contempt</em>, or <em id="S5.SS2.SSS1.p3.1.9" class="ltx_emph ltx_font_italic">neutral</em> (<cite class="ltx_cite ltx_citemacro_cite">Ekman and Friesen (<a href="#bib.bib20" title="" class="ltx_ref">1978</a>)</cite>). The <em id="S5.SS2.SSS1.p3.1.10" class="ltx_emph ltx_font_italic">neutral</em> label was assigned if none of these labels were applicable. The emotional labels were translated into text as described by <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib72" title="" class="ltx_ref">Zhao and Patras</a></cite>, which was generated by prompting ChatGPT, achieving state-of-the-art performance on the Dynamic Facial Expression Recognition problem (<cite class="ltx_cite ltx_citemacro_cite">Zhao and Patras (<a href="#bib.bib72" title="" class="ltx_ref">2023</a>)</cite>).</p>
</div>
<div id="S5.SS2.SSS1.p4" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS1.p4.1" class="ltx_p">Participant responses to the <span id="S5.SS2.SSS1.p4.1.1" class="ltx_text ltx_font_bold">personality</span> and <span id="S5.SS2.SSS1.p4.1.2" class="ltx_text ltx_font_bold">beliefs</span> questionnaires were also included as part of the <em id="S5.SS2.SSS1.p4.1.3" class="ltx_emph ltx_font_italic">system message</em><span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a target="_blank" href="https://microsoft.github.io/Workshop-Interact-with-OpenAI-models/Part-2-labs/System-Message" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://microsoft.github.io/Workshop-Interact-with-OpenAI-models/Part-2-labs/System-Message</a></span></span></span>, providing additional speaker-specific context, as personal characteristics are known to affect a person’s social behavior (<cite class="ltx_cite ltx_citemacro_cite">Celiktutan et al<span class="ltx_text">.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite>).</p>
</div>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2 </span>Multimodal Transcript Generation</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS2.p1.1" class="ltx_p">The messages provided to <span id="S5.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_typewriter">GPT</span> use the discrete segments in Whisper’s transcription as atomic units to which information from other modalities is added. Consecutive segments with the same speaker are merged to combine speech and other modalities into a larger temporal window.</p>
</div>
<div id="S5.SS2.SSS2.p2" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS2.p2.1" class="ltx_p"><span id="S5.SS2.SSS2.p2.1.1" class="ltx_text ltx_font_typewriter">GPT</span> imitates each participant using the following procedure. Each merged segment of speech forms the basis of a message provided to OpenAI’s ChatCompletion API<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a target="_blank" href="https://platform.openai.com/docs/api-reference/chat/create" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://platform.openai.com/docs/api-reference/chat/create</a></span></span></span>. For each message, the <em id="S5.SS2.SSS2.p2.1.2" class="ltx_emph ltx_font_italic">role</em> is assigned to the <em id="S5.SS2.SSS2.p2.1.3" class="ltx_emph ltx_font_italic">assistant</em> if the segment is spoken by the simulated participant or to the <em id="S5.SS2.SSS2.p2.1.4" class="ltx_emph ltx_font_italic">user</em> if spoken by the partner. The final <em id="S5.SS2.SSS2.p2.1.5" class="ltx_emph ltx_font_italic">user</em> message is always a questionnaire item introduced by the “experimenter” (see <a href="#A1" title="Appendix A Engagement Questionnaire ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Appendix A</span></a> for questionnaire details). The final <em id="S5.SS2.SSS2.p2.1.6" class="ltx_emph ltx_font_italic">assistant</em> message is generated by <span id="S5.SS2.SSS2.p2.1.7" class="ltx_text ltx_font_typewriter">GPT</span> as a response to the introduced questionnaire item. Prompted transcripts were truncated to five minutes, as previous literature has established that the first five minutes of a conversation is enough information for humans to predict its outcome successfully (<cite class="ltx_cite ltx_citemacro_cite">Curhan and Pentland (<a href="#bib.bib16" title="" class="ltx_ref">2007</a>)</cite>). This limitation brought the added benefit of reducing the cost of the experiment.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<p id="S5.T1.1" class="ltx_p ltx_align_center"><span id="S5.T1.1.1" class="ltx_text ltx_inline-block" style="width:433.6pt;">

<span id="S5.T1.1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<span class="ltx_thead">
<span id="S5.T1.1.1.1.1" class="ltx_tr">
<span id="S5.T1.1.1.1.1.2" class="ltx_td ltx_th ltx_th_column ltx_border_rr"></span>
<span id="S5.T1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_colspan ltx_colspan_7">First-Person Ratings (<a href="#S3.SS4" title="3.4 Self-Report Questionnaires ‣ 3 Data Set ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Section 3.4</span></a>) — lower RMSE scores are better <math id="S5.T1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T1.1.1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.1.1.m1.1b"><ci id="S5.T1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></span>
</span>
<span class="ltx_tbody">
<span id="S5.T1.1.1.1.2.1" class="ltx_tr">
<span id="S5.T1.1.1.1.2.1.1" class="ltx_td ltx_align_left ltx_border_rr ltx_border_tt">Behavior Features</span>
<span id="S5.T1.1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_tt">KNN</span>
<span id="S5.T1.1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_tt">SVM</span>
<span id="S5.T1.1.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_tt">RF</span>
<span id="S5.T1.1.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_tt">Bi-LSTM</span>
<span id="S5.T1.1.1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MLP</span>
<span id="S5.T1.1.1.1.2.1.7" class="ltx_td ltx_align_center ltx_border_tt">LLM-4</span>
<span id="S5.T1.1.1.1.2.1.8" class="ltx_td ltx_align_center ltx_border_tt">LLM-4S</span></span>
<span id="S5.T1.1.1.1.3.2" class="ltx_tr">
<span id="S5.T1.1.1.1.3.2.1" class="ltx_td ltx_align_left ltx_border_rr ltx_border_t">Gaze-Only</span>
<span id="S5.T1.1.1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_t">1.556 (0.313)</span>
<span id="S5.T1.1.1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.1.1.1.3.2.3.1" class="ltx_text ltx_font_bold">1.281 (0.310)</span></span>
<span id="S5.T1.1.1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_t">1.355 (0.298)</span>
<span id="S5.T1.1.1.1.3.2.5" class="ltx_td ltx_align_center ltx_border_t">1.588 (0.340)</span>
<span id="S5.T1.1.1.1.3.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.881 (0.360)</span>
<span id="S5.T1.1.1.1.3.2.7" class="ltx_td ltx_align_center ltx_border_t">—</span>
<span id="S5.T1.1.1.1.3.2.8" class="ltx_td ltx_align_center ltx_border_t">—</span></span>
<span id="S5.T1.1.1.1.4.3" class="ltx_tr">
<span id="S5.T1.1.1.1.4.3.1" class="ltx_td ltx_align_left ltx_border_rr">Face-Only</span>
<span id="S5.T1.1.1.1.4.3.2" class="ltx_td ltx_align_center">1.530 (0.322)</span>
<span id="S5.T1.1.1.1.4.3.3" class="ltx_td ltx_align_center"><span id="S5.T1.1.1.1.4.3.3.1" class="ltx_text ltx_font_bold">1.328 (0.333)</span></span>
<span id="S5.T1.1.1.1.4.3.4" class="ltx_td ltx_align_center">1.390 (0.288)</span>
<span id="S5.T1.1.1.1.4.3.5" class="ltx_td ltx_align_center">1.563 (0.353)</span>
<span id="S5.T1.1.1.1.4.3.6" class="ltx_td ltx_align_center ltx_border_r">2.090 (0.454)</span>
<span id="S5.T1.1.1.1.4.3.7" class="ltx_td ltx_align_center">—</span>
<span id="S5.T1.1.1.1.4.3.8" class="ltx_td ltx_align_center">—</span></span>
<span id="S5.T1.1.1.1.5.4" class="ltx_tr">
<span id="S5.T1.1.1.1.5.4.1" class="ltx_td ltx_align_left ltx_border_rr">Text-Only</span>
<span id="S5.T1.1.1.1.5.4.2" class="ltx_td ltx_align_center">1.512 (0.287)</span>
<span id="S5.T1.1.1.1.5.4.3" class="ltx_td ltx_align_center"><span id="S5.T1.1.1.1.5.4.3.1" class="ltx_text ltx_font_bold">1.280 (0.309)</span></span>
<span id="S5.T1.1.1.1.5.4.4" class="ltx_td ltx_align_center">1.301 (0.287)</span>
<span id="S5.T1.1.1.1.5.4.5" class="ltx_td ltx_align_center">1.478 (0.358)</span>
<span id="S5.T1.1.1.1.5.4.6" class="ltx_td ltx_align_center ltx_border_r">2.069 (0.432)</span>
<span id="S5.T1.1.1.1.5.4.7" class="ltx_td ltx_align_center">1.669 (0.396)</span>
<span id="S5.T1.1.1.1.5.4.8" class="ltx_td ltx_align_center"><span id="S5.T1.1.1.1.5.4.8.1" class="ltx_text ltx_font_bold">1.376 (0.381)</span></span></span>
<span id="S5.T1.1.1.1.6.5" class="ltx_tr">
<span id="S5.T1.1.1.1.6.5.1" class="ltx_td ltx_align_left ltx_border_rr">Face + Gaze</span>
<span id="S5.T1.1.1.1.6.5.2" class="ltx_td ltx_align_center">1.500 (0.294)</span>
<span id="S5.T1.1.1.1.6.5.3" class="ltx_td ltx_align_center"><span id="S5.T1.1.1.1.6.5.3.1" class="ltx_text ltx_font_bold">1.296 (0.339)</span></span>
<span id="S5.T1.1.1.1.6.5.4" class="ltx_td ltx_align_center">1.314 (0.339)</span>
<span id="S5.T1.1.1.1.6.5.5" class="ltx_td ltx_align_center">1.517 (0.331)</span>
<span id="S5.T1.1.1.1.6.5.6" class="ltx_td ltx_align_center ltx_border_r">1.833 (0.389)</span>
<span id="S5.T1.1.1.1.6.5.7" class="ltx_td ltx_align_center">—</span>
<span id="S5.T1.1.1.1.6.5.8" class="ltx_td ltx_align_center">—</span></span>
<span id="S5.T1.1.1.1.7.6" class="ltx_tr">
<span id="S5.T1.1.1.1.7.6.1" class="ltx_td ltx_align_left ltx_border_rr">Text + Gaze</span>
<span id="S5.T1.1.1.1.7.6.2" class="ltx_td ltx_align_center">1.557 (0.286)</span>
<span id="S5.T1.1.1.1.7.6.3" class="ltx_td ltx_align_center"><span id="S5.T1.1.1.1.7.6.3.1" class="ltx_text ltx_font_bold">1.291 (0.305)</span></span>
<span id="S5.T1.1.1.1.7.6.4" class="ltx_td ltx_align_center">1.409 (0.289)</span>
<span id="S5.T1.1.1.1.7.6.5" class="ltx_td ltx_align_center">1.466 (0.307)</span>
<span id="S5.T1.1.1.1.7.6.6" class="ltx_td ltx_align_center ltx_border_r">1.988 (0.405)</span>
<span id="S5.T1.1.1.1.7.6.7" class="ltx_td ltx_align_center">1.418 (0.394)</span>
<span id="S5.T1.1.1.1.7.6.8" class="ltx_td ltx_align_center"><span id="S5.T1.1.1.1.7.6.8.1" class="ltx_text ltx_font_bold">1.338 (0.378)</span></span></span>
<span id="S5.T1.1.1.1.8.7" class="ltx_tr">
<span id="S5.T1.1.1.1.8.7.1" class="ltx_td ltx_align_left ltx_border_rr">Text + Face</span>
<span id="S5.T1.1.1.1.8.7.2" class="ltx_td ltx_align_center">1.521 (0.289)</span>
<span id="S5.T1.1.1.1.8.7.3" class="ltx_td ltx_align_center"><span id="S5.T1.1.1.1.8.7.3.1" class="ltx_text ltx_font_bold">1.287 (0.337)</span></span>
<span id="S5.T1.1.1.1.8.7.4" class="ltx_td ltx_align_center">1.305 (0.339)</span>
<span id="S5.T1.1.1.1.8.7.5" class="ltx_td ltx_align_center">1.572 (0.352)</span>
<span id="S5.T1.1.1.1.8.7.6" class="ltx_td ltx_align_center ltx_border_r">1.945 (0.475)</span>
<span id="S5.T1.1.1.1.8.7.7" class="ltx_td ltx_align_center">1.477 (0.425)</span>
<span id="S5.T1.1.1.1.8.7.8" class="ltx_td ltx_align_center"><span id="S5.T1.1.1.1.8.7.8.1" class="ltx_text ltx_font_bold">1.368 (0.417)</span></span></span>
<span id="S5.T1.1.1.1.9.8" class="ltx_tr">
<span id="S5.T1.1.1.1.9.8.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_rr">Text + Face + Gaze</span>
<span id="S5.T1.1.1.1.9.8.2" class="ltx_td ltx_align_center ltx_border_bb">1.557 (0.300)</span>
<span id="S5.T1.1.1.1.9.8.3" class="ltx_td ltx_align_center ltx_border_bb">1.327 (0.342)</span>
<span id="S5.T1.1.1.1.9.8.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.1.1.1.9.8.4.1" class="ltx_text ltx_font_bold">1.303 (1.290)</span></span>
<span id="S5.T1.1.1.1.9.8.5" class="ltx_td ltx_align_center ltx_border_bb">1.592 (0.355)</span>
<span id="S5.T1.1.1.1.9.8.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">1.773 (0.356)</span>
<span id="S5.T1.1.1.1.9.8.7" class="ltx_td ltx_align_center ltx_border_bb">1.442 (0.423)</span>
<span id="S5.T1.1.1.1.9.8.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.1.1.1.9.8.8.1" class="ltx_text ltx_font_bold">1.364 (0.387)</span></span></span>
</span>
</span></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span> Prediction performance of classical vs. LLM fusion models when provided data from a limited set of modalities: RMSE mean and standard deviation across validation folds (lower is better). LLM-4/4S refers to ablations with GPT-4.</figcaption>
</figure>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Experiments</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p id="S6.p1.1" class="ltx_p">We conducted two experimental series to predict engagement based on the end-of-session questionnaires, outlined in <a href="#S3.SS4" title="3.4 Self-Report Questionnaires ‣ 3 Data Set ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Section 3.4</span></a>. The first series assessed multimodal fusion using classical models (<a href="#S6.SS1" title="6.1 Classical Fusion ‣ 6 Experiments ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Section 6.1</span></a>), while the second series used large language models (LLMs; <a href="#S6.SS2" title="6.2 LLM Fusion ‣ 6 Experiments ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Section 6.2</span></a>).</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Classical Fusion</h3>

<div id="S6.SS1.p1" class="ltx_para ltx_noindent">
<p id="S6.SS1.p1.1" class="ltx_p">Five standard machine learning techniques were employed to establish a comparative baseline: <math id="S6.SS1.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S6.SS1.p1.1.m1.1a"><mi id="S6.SS1.p1.1.m1.1.1" xref="S6.SS1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.1.m1.1b"><ci id="S6.SS1.p1.1.m1.1.1.cmml" xref="S6.SS1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.1.m1.1c">k</annotation></semantics></math>-nearest neighbors (KNN), support vector machines (SVM), random forests (RF), bidirectional long short-term memory networks (Bi-LSTM), and multi-layer perceptrons (MLP). Each model was trained using per-turn behavioral features alongside the corresponding self-report ratings for each session, described in <a href="#S3.SS4" title="3.4 Self-Report Questionnaires ‣ 3 Data Set ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Section 3.4</span></a>. The KNN, SVM, and RF models implemented either the multivariate sequence kernel or the global alignment kernel (GAK; <cite class="ltx_cite ltx_citemacro_cite">Cuturi (<a href="#bib.bib17" title="" class="ltx_ref">2011</a>)</cite>) to facilitate the comparison of sequences of varying lengths, as these models are not inherently designed to process sequential or variable-length input. Conversely, the MLP and Bi-LSTM models followed canonical architectures specific to their respective methodologies.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para ltx_noindent">
<p id="S6.SS1.p2.1" class="ltx_p">The representations of the behavioral features provided to these models were designed to reflect the information presented to the large language model in <a href="#S6.SS2" title="6.2 LLM Fusion ‣ 6 Experiments ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Section 6.2</span></a>. Facial expression was denoted by a label indicating the predominant perceived emotion, while gaze direction was quantified as the proportion of time an individual directed their attention towards their partner’s face. These representations parallel the descriptions provided to the LLM via the multimodal transcript. Dialogue text was encoded using sentence embeddings generated through the SimCSE framework (Simple Contrastive Learning of Sentence Embeddings; <cite class="ltx_cite ltx_citemacro_cite">Gao et al<span class="ltx_text">.</span> (<a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite>). For additional information regarding the extraction of these features, refer to <a href="#S4" title="4 Feature Extraction ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Section 4</span></a>.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para ltx_noindent">
<p id="S6.SS1.p3.1" class="ltx_p">All models were trained and evaluated using leave-one-dyad-out cross-validation and cross-testing methodologies. To detail: one session was allocated as the test set, while the remaining 16 sessions served as the training set. Within the training set, hyperparameters were optimized through 16 cross-validation folds. The final performance metrics were derived from the held-out dyad #17. This process was systematically repeated for each of the 17 dyads, guaranteeing that every dyad was used as the test set exactly once. Although the dataset was relatively small, this procedure ensured a robust evaluation of the modeling technique while also allowing us to mitigate the risk of overfitting.</p>
</div>
<div id="S6.SS1.p4" class="ltx_para ltx_noindent">
<p id="S6.SS1.p4.1" class="ltx_p">As in the evaluation of the large language models (LLMs) in <a href="#S6.SS2" title="6.2 LLM Fusion ‣ 6 Experiments ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Section 6.2</span></a>, each model was trained using all three input modalities, as well as through an ablation study involving various subsets of these modalities, detailed in <a href="#S5.T1" title="Table 1 ‣ 5.2.2 Multimodal Transcript Generation ‣ 5.2 Algorithms for LLM Fusion ‣ 5 LLM Fusion ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a>. The results suggest that the Support Vector Machine (SVM) achieved the best performance across the majority of subsets, with the Random Forest (RF) model closely following. While these two models outperformed the LLM variants, they were the only models to do so: the remaining three models generally underperformed compared to the LLM variants.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>LLM Fusion</h3>

<div id="S6.SS2.p1" class="ltx_para ltx_noindent">
<p id="S6.SS2.p1.1" class="ltx_p"><span id="S6.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">GPT-4</span> was provided with the multimodal transcript paired with each of the survey items of the engagement questionnaire. Note that a few items on the questionnaire explicitly reference laughing or eye contact: despite not providing the model with explicit information on these behaviors, we included these items to explore the capability of the model to infer these behaviors with limited information.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para ltx_noindent">
<p id="S6.SS2.p2.5" class="ltx_p">We performed a set of ablation experiments to explore the significance of various feature sets, notated with the following naming convention:</p>
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p"><span id="S6.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">4</span>: This model was provided with the raw dialogue transcription alone.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p"><span id="S6.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">S</span>: The transcription is preceded by participant survey responses to the personality and beliefs questionnaires as (<span id="S6.I1.i2.p1.1.2" class="ltx_text ltx_font_bold">S</span>)ystem instructions.</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p"><span id="S6.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">G</span>: The transcription is enhanced with descriptions of each participant’s (<span id="S6.I1.i3.p1.1.2" class="ltx_text ltx_font_bold">G</span>)aze behavior during each speaking turn.</p>
</div>
</li>
<li id="S6.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i4.p1" class="ltx_para ltx_noindent">
<p id="S6.I1.i4.p1.1" class="ltx_p"><span id="S6.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">F</span>: The transcription is enhanced with descriptions of each participant’s (<span id="S6.I1.i4.p1.1.2" class="ltx_text ltx_font_bold">F</span>)acial expression during each speaking turn.</p>
</div>
</li>
</ul>
<p id="S6.SS2.p2.4" class="ltx_p">In three instances, the length of the multimodal transcript with added descriptions exceeded the input constraints of <span id="S6.SS2.p2.4.1" class="ltx_text ltx_font_typewriter">GPT-4</span> (two for <span id="S6.SS2.p2.4.2" class="ltx_text ltx_font_bold">4SGF</span> and one for <span id="S6.SS2.p2.4.3" class="ltx_text ltx_font_bold">4GF</span>); in these cases, the transcript was truncated. A <math id="S6.SS2.p2.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S6.SS2.p2.1.m1.1a"><mi id="S6.SS2.p2.1.m1.1.1" xref="S6.SS2.p2.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.1.m1.1b"><ci id="S6.SS2.p2.1.m1.1.1.cmml" xref="S6.SS2.p2.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.1.m1.1c">t</annotation></semantics></math>-test comparing the residuals of the truncated sessions with those of the non-truncated sessions yielded <math id="S6.SS2.p2.2.m2.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S6.SS2.p2.2.m2.1a"><mi id="S6.SS2.p2.2.m2.1.1" xref="S6.SS2.p2.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.2.m2.1b"><ci id="S6.SS2.p2.2.m2.1.1.cmml" xref="S6.SS2.p2.2.m2.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.2.m2.1c">p</annotation></semantics></math>-values of <math id="S6.SS2.p2.3.m3.1" class="ltx_Math" alttext="0.186" display="inline"><semantics id="S6.SS2.p2.3.m3.1a"><mn id="S6.SS2.p2.3.m3.1.1" xref="S6.SS2.p2.3.m3.1.1.cmml">0.186</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.3.m3.1b"><cn type="float" id="S6.SS2.p2.3.m3.1.1.cmml" xref="S6.SS2.p2.3.m3.1.1">0.186</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.3.m3.1c">0.186</annotation></semantics></math> and <math id="S6.SS2.p2.4.m4.1" class="ltx_Math" alttext="0.648" display="inline"><semantics id="S6.SS2.p2.4.m4.1a"><mn id="S6.SS2.p2.4.m4.1.1" xref="S6.SS2.p2.4.m4.1.1.cmml">0.648</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.4.m4.1b"><cn type="float" id="S6.SS2.p2.4.m4.1.1.cmml" xref="S6.SS2.p2.4.m4.1.1">0.648</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.4.m4.1c">0.648</annotation></semantics></math>, suggesting no significant difference between the two groups. Future studies may benefit from exploring the impact of different truncation lengths and the ability of the technique to perform with shorter observation time.</p>
</div>
<div id="S6.SS2.p3" class="ltx_para ltx_noindent">
<p id="S6.SS2.p3.1" class="ltx_p">The <em id="S6.SS2.p3.1.1" class="ltx_emph ltx_font_italic">temperature</em> parameter was set at 0 to ensure sampling from the most likely responses to the questionnaire. In cases where <span id="S6.SS2.p3.1.2" class="ltx_text ltx_font_typewriter">GPT-4</span> did not provide a numeric response, we selected the highest-likelihood numeric response from the top 20 generations for the first output token (see <a href="#A3" title="Appendix C LLM Fusion: Non-Numeric Responses ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Appendix C</span></a> for more details on this process).</p>
</div>
<section id="S6.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.1 </span>LLM Fusion Results</h4>

<div id="S6.SS2.SSS1.p1" class="ltx_para ltx_noindent">
<p id="S6.SS2.SSS1.p1.1" class="ltx_p">We evaluated this technique through two labeling tasks: predicting participants’ exact responses and predicting the valence/arousal of their responses. The “exact” response refers to the specific answer given by participants (a numeric rating between 1 and 7). The valence/arousal model categorizes responses based on emotional dimensions: valence is defined as the positive or negative degree of emotion (e.g., pleasure/displeasure), and arousal is defined as the intensity of emotion (high or low) (<cite class="ltx_cite ltx_citemacro_cite">Mollahosseini et al<span class="ltx_text">.</span> (<a href="#bib.bib41" title="" class="ltx_ref">2019</a>)</cite>). We define valence in terms of the “disagree” range, a score of 1 (“strongly disagree’)’ through 3 (“slightly disagree”), a neutral score of 4 (“neither agree nor disagree”), or the “agree” range, a score of 5 (“slightly agree”) through 7 (“strongly agree”). Arousal is calculated as the distance of the participants’ rating from the neutral score of 4, i.e., <math id="S6.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="|\text{response}-4|" display="inline"><semantics id="S6.SS2.SSS1.p1.1.m1.1a"><mrow id="S6.SS2.SSS1.p1.1.m1.1.1.1" xref="S6.SS2.SSS1.p1.1.m1.1.1.2.cmml"><mo stretchy="false" id="S6.SS2.SSS1.p1.1.m1.1.1.1.2" xref="S6.SS2.SSS1.p1.1.m1.1.1.2.1.cmml">|</mo><mrow id="S6.SS2.SSS1.p1.1.m1.1.1.1.1" xref="S6.SS2.SSS1.p1.1.m1.1.1.1.1.cmml"><mtext id="S6.SS2.SSS1.p1.1.m1.1.1.1.1.2" xref="S6.SS2.SSS1.p1.1.m1.1.1.1.1.2a.cmml">response</mtext><mo id="S6.SS2.SSS1.p1.1.m1.1.1.1.1.1" xref="S6.SS2.SSS1.p1.1.m1.1.1.1.1.1.cmml">−</mo><mn id="S6.SS2.SSS1.p1.1.m1.1.1.1.1.3" xref="S6.SS2.SSS1.p1.1.m1.1.1.1.1.3.cmml">4</mn></mrow><mo stretchy="false" id="S6.SS2.SSS1.p1.1.m1.1.1.1.3" xref="S6.SS2.SSS1.p1.1.m1.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p1.1.m1.1b"><apply id="S6.SS2.SSS1.p1.1.m1.1.1.2.cmml" xref="S6.SS2.SSS1.p1.1.m1.1.1.1"><abs id="S6.SS2.SSS1.p1.1.m1.1.1.2.1.cmml" xref="S6.SS2.SSS1.p1.1.m1.1.1.1.2"></abs><apply id="S6.SS2.SSS1.p1.1.m1.1.1.1.1.cmml" xref="S6.SS2.SSS1.p1.1.m1.1.1.1.1"><minus id="S6.SS2.SSS1.p1.1.m1.1.1.1.1.1.cmml" xref="S6.SS2.SSS1.p1.1.m1.1.1.1.1.1"></minus><ci id="S6.SS2.SSS1.p1.1.m1.1.1.1.1.2a.cmml" xref="S6.SS2.SSS1.p1.1.m1.1.1.1.1.2"><mtext id="S6.SS2.SSS1.p1.1.m1.1.1.1.1.2.cmml" xref="S6.SS2.SSS1.p1.1.m1.1.1.1.1.2">response</mtext></ci><cn type="integer" id="S6.SS2.SSS1.p1.1.m1.1.1.1.1.3.cmml" xref="S6.SS2.SSS1.p1.1.m1.1.1.1.1.3">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p1.1.m1.1c">|\text{response}-4|</annotation></semantics></math>: e.g., “strongly disagree” and “strongly agree” would share the same arousal category.</p>
</div>
<div id="S6.SS2.SSS1.p2" class="ltx_para ltx_noindent">
<p id="S6.SS2.SSS1.p2.1" class="ltx_p"><span id="S6.SS2.SSS1.p2.1.1" class="ltx_text ltx_font_bold">Exact Response</span>
As seen in <a href="#S6.T2" title="Table 2 ‣ 6.2.2 Contribution per modality ‣ 6.2 LLM Fusion ‣ 6 Experiments ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 2</span></a>, <span id="S6.SS2.SSS1.p2.1.2" class="ltx_text ltx_font_typewriter">GPT-4</span>’s<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>We also experimented with <span id="footnote10.1" class="ltx_text ltx_font_typewriter">GPT-3.5</span>; however, given its significantly poorer performance against <span id="footnote10.2" class="ltx_text ltx_font_typewriter">GPT-4</span>, we elected to exclude its results from further analysis.</span></span></span> zero-shot performance of this technique is comparable to the baseline and classical early fusion models, evaluated via RMSE. Krippendorff’s alpha metric, used to assess the reliability of agreement between multiple raters, indicated a moderate level of agreement between the model’s predictions and the participants’ responses, ranging within <math id="S6.SS2.SSS1.p2.1.m1.2" class="ltx_Math" alttext="[0.470,0.543]" display="inline"><semantics id="S6.SS2.SSS1.p2.1.m1.2a"><mrow id="S6.SS2.SSS1.p2.1.m1.2.3.2" xref="S6.SS2.SSS1.p2.1.m1.2.3.1.cmml"><mo stretchy="false" id="S6.SS2.SSS1.p2.1.m1.2.3.2.1" xref="S6.SS2.SSS1.p2.1.m1.2.3.1.cmml">[</mo><mn id="S6.SS2.SSS1.p2.1.m1.1.1" xref="S6.SS2.SSS1.p2.1.m1.1.1.cmml">0.470</mn><mo id="S6.SS2.SSS1.p2.1.m1.2.3.2.2" xref="S6.SS2.SSS1.p2.1.m1.2.3.1.cmml">,</mo><mn id="S6.SS2.SSS1.p2.1.m1.2.2" xref="S6.SS2.SSS1.p2.1.m1.2.2.cmml">0.543</mn><mo stretchy="false" id="S6.SS2.SSS1.p2.1.m1.2.3.2.3" xref="S6.SS2.SSS1.p2.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p2.1.m1.2b"><interval closure="closed" id="S6.SS2.SSS1.p2.1.m1.2.3.1.cmml" xref="S6.SS2.SSS1.p2.1.m1.2.3.2"><cn type="float" id="S6.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S6.SS2.SSS1.p2.1.m1.1.1">0.470</cn><cn type="float" id="S6.SS2.SSS1.p2.1.m1.2.2.cmml" xref="S6.SS2.SSS1.p2.1.m1.2.2">0.543</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p2.1.m1.2c">[0.470,0.543]</annotation></semantics></math> across questions (<cite class="ltx_cite ltx_citemacro_cite">Landis and Koch (<a href="#bib.bib35" title="" class="ltx_ref">1977</a>); Wong et al<span class="ltx_text">.</span> (<a href="#bib.bib68" title="" class="ltx_ref">2021</a>)</cite>). This suggests that while the zero-shot technique may not outperform the more advanced models, it still holds potential for applications where computational resources are limited. Furthermore, the findings highlight the importance of evaluating various methodologies in diverse contexts, as different tasks may yield varying levels of effectiveness.</p>
</div>
<div id="S6.SS2.SSS1.p3" class="ltx_para ltx_noindent">
<p id="S6.SS2.SSS1.p3.1" class="ltx_p"><span id="S6.SS2.SSS1.p3.1.1" class="ltx_text ltx_font_bold">Valence</span>
When restricting the labeling task to valence only, <span id="S6.SS2.SSS1.p3.1.2" class="ltx_text ltx_font_typewriter">GPT-4</span> predictions agree statistically significantly with the study’s participants. As presented in <a href="#S6.T2" title="Table 2 ‣ 6.2.2 Contribution per modality ‣ 6.2 LLM Fusion ‣ 6 Experiments ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 2</span></a>, all Krippendorff’s alpha scores fall within an error interval of <math id="S6.SS2.SSS1.p3.1.m1.2" class="ltx_Math" alttext="[0.61,0.80]" display="inline"><semantics id="S6.SS2.SSS1.p3.1.m1.2a"><mrow id="S6.SS2.SSS1.p3.1.m1.2.3.2" xref="S6.SS2.SSS1.p3.1.m1.2.3.1.cmml"><mo stretchy="false" id="S6.SS2.SSS1.p3.1.m1.2.3.2.1" xref="S6.SS2.SSS1.p3.1.m1.2.3.1.cmml">[</mo><mn id="S6.SS2.SSS1.p3.1.m1.1.1" xref="S6.SS2.SSS1.p3.1.m1.1.1.cmml">0.61</mn><mo id="S6.SS2.SSS1.p3.1.m1.2.3.2.2" xref="S6.SS2.SSS1.p3.1.m1.2.3.1.cmml">,</mo><mn id="S6.SS2.SSS1.p3.1.m1.2.2" xref="S6.SS2.SSS1.p3.1.m1.2.2.cmml">0.80</mn><mo stretchy="false" id="S6.SS2.SSS1.p3.1.m1.2.3.2.3" xref="S6.SS2.SSS1.p3.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p3.1.m1.2b"><interval closure="closed" id="S6.SS2.SSS1.p3.1.m1.2.3.1.cmml" xref="S6.SS2.SSS1.p3.1.m1.2.3.2"><cn type="float" id="S6.SS2.SSS1.p3.1.m1.1.1.cmml" xref="S6.SS2.SSS1.p3.1.m1.1.1">0.61</cn><cn type="float" id="S6.SS2.SSS1.p3.1.m1.2.2.cmml" xref="S6.SS2.SSS1.p3.1.m1.2.2">0.80</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p3.1.m1.2c">[0.61,0.80]</annotation></semantics></math> (<cite class="ltx_cite ltx_citemacro_cite">Landis and Koch (<a href="#bib.bib35" title="" class="ltx_ref">1977</a>)</cite>).</p>
</div>
<div id="S6.SS2.SSS1.p4" class="ltx_para ltx_noindent">
<p id="S6.SS2.SSS1.p4.3" class="ltx_p">Upon closer inspection of the valence predictions of the <span id="S6.SS2.SSS1.p4.3.1" class="ltx_text ltx_font_typewriter">LLM-4S</span> ablation model (which achieved the strongest performance in labeling exact responses; presented in <a href="#A2" title="Appendix B LLM Fusion: Valence Prediction ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Appendix B</span></a>), we can observe that <span id="S6.SS2.SSS1.p4.3.2" class="ltx_text ltx_font_typewriter">GPT-4</span> reliably labels participant “agree” responses, with a class accuracy of <math id="S6.SS2.SSS1.p4.1.m1.1" class="ltx_Math" alttext="91.8\%" display="inline"><semantics id="S6.SS2.SSS1.p4.1.m1.1a"><mrow id="S6.SS2.SSS1.p4.1.m1.1.1" xref="S6.SS2.SSS1.p4.1.m1.1.1.cmml"><mn id="S6.SS2.SSS1.p4.1.m1.1.1.2" xref="S6.SS2.SSS1.p4.1.m1.1.1.2.cmml">91.8</mn><mo id="S6.SS2.SSS1.p4.1.m1.1.1.1" xref="S6.SS2.SSS1.p4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p4.1.m1.1b"><apply id="S6.SS2.SSS1.p4.1.m1.1.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.1.1"><csymbol cd="latexml" id="S6.SS2.SSS1.p4.1.m1.1.1.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.1.1.1">percent</csymbol><cn type="float" id="S6.SS2.SSS1.p4.1.m1.1.1.2.cmml" xref="S6.SS2.SSS1.p4.1.m1.1.1.2">91.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p4.1.m1.1c">91.8\%</annotation></semantics></math>. However, <span id="S6.SS2.SSS1.p4.3.3" class="ltx_text ltx_font_typewriter">GPT-4</span> is less reliable in predicting participant “disagree” responses, achieving a class accuracy of <math id="S6.SS2.SSS1.p4.2.m2.1" class="ltx_Math" alttext="66.1\%" display="inline"><semantics id="S6.SS2.SSS1.p4.2.m2.1a"><mrow id="S6.SS2.SSS1.p4.2.m2.1.1" xref="S6.SS2.SSS1.p4.2.m2.1.1.cmml"><mn id="S6.SS2.SSS1.p4.2.m2.1.1.2" xref="S6.SS2.SSS1.p4.2.m2.1.1.2.cmml">66.1</mn><mo id="S6.SS2.SSS1.p4.2.m2.1.1.1" xref="S6.SS2.SSS1.p4.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p4.2.m2.1b"><apply id="S6.SS2.SSS1.p4.2.m2.1.1.cmml" xref="S6.SS2.SSS1.p4.2.m2.1.1"><csymbol cd="latexml" id="S6.SS2.SSS1.p4.2.m2.1.1.1.cmml" xref="S6.SS2.SSS1.p4.2.m2.1.1.1">percent</csymbol><cn type="float" id="S6.SS2.SSS1.p4.2.m2.1.1.2.cmml" xref="S6.SS2.SSS1.p4.2.m2.1.1.2">66.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p4.2.m2.1c">66.1\%</annotation></semantics></math>. Notably, <span id="S6.SS2.SSS1.p4.3.4" class="ltx_text ltx_font_typewriter">GPT-4</span> performs significantly poorly in labeling participant “neutral” responses, with a class accuracy of <math id="S6.SS2.SSS1.p4.3.m3.1" class="ltx_Math" alttext="12.7\%" display="inline"><semantics id="S6.SS2.SSS1.p4.3.m3.1a"><mrow id="S6.SS2.SSS1.p4.3.m3.1.1" xref="S6.SS2.SSS1.p4.3.m3.1.1.cmml"><mn id="S6.SS2.SSS1.p4.3.m3.1.1.2" xref="S6.SS2.SSS1.p4.3.m3.1.1.2.cmml">12.7</mn><mo id="S6.SS2.SSS1.p4.3.m3.1.1.1" xref="S6.SS2.SSS1.p4.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p4.3.m3.1b"><apply id="S6.SS2.SSS1.p4.3.m3.1.1.cmml" xref="S6.SS2.SSS1.p4.3.m3.1.1"><csymbol cd="latexml" id="S6.SS2.SSS1.p4.3.m3.1.1.1.cmml" xref="S6.SS2.SSS1.p4.3.m3.1.1.1">percent</csymbol><cn type="float" id="S6.SS2.SSS1.p4.3.m3.1.1.2.cmml" xref="S6.SS2.SSS1.p4.3.m3.1.1.2">12.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p4.3.m3.1c">12.7\%</annotation></semantics></math>. Given that the label range is smaller — one possible value (4), as opposed to three values in “agree” (5, 6, 7) or “disagree” (1, 2, 3) ranges — poor performance may be expected. We conjecture that <span id="S6.SS2.SSS1.p4.3.5" class="ltx_text ltx_font_typewriter">GPT-4</span>’s process of reinforcement learning from human feedback (RLHF) (<cite class="ltx_cite ltx_citemacro_cite">Ouyang et al<span class="ltx_text">.</span> (<a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite>) to reduce toxicity may result in overly “positive” responses from <span id="S6.SS2.SSS1.p4.3.6" class="ltx_text ltx_font_typewriter">GPT-4</span>, inadvertently introducing bias against “negative” responses. Further investigation is warranted to understand this potential for bias.</p>
</div>
<div id="S6.SS2.SSS1.p5" class="ltx_para ltx_noindent">
<p id="S6.SS2.SSS1.p5.1" class="ltx_p"><span id="S6.SS2.SSS1.p5.1.1" class="ltx_text ltx_font_bold">Arousal</span>
Across all ablations, <span id="S6.SS2.SSS1.p5.1.2" class="ltx_text ltx_font_typewriter">GPT-4</span> performs poorly in labeling the arousal of a participant’s response, only marginally better than chance given Krippendorff’s alpha scores in the range of <math id="S6.SS2.SSS1.p5.1.m1.2" class="ltx_Math" alttext="[0.047,0.071]" display="inline"><semantics id="S6.SS2.SSS1.p5.1.m1.2a"><mrow id="S6.SS2.SSS1.p5.1.m1.2.3.2" xref="S6.SS2.SSS1.p5.1.m1.2.3.1.cmml"><mo stretchy="false" id="S6.SS2.SSS1.p5.1.m1.2.3.2.1" xref="S6.SS2.SSS1.p5.1.m1.2.3.1.cmml">[</mo><mn id="S6.SS2.SSS1.p5.1.m1.1.1" xref="S6.SS2.SSS1.p5.1.m1.1.1.cmml">0.047</mn><mo id="S6.SS2.SSS1.p5.1.m1.2.3.2.2" xref="S6.SS2.SSS1.p5.1.m1.2.3.1.cmml">,</mo><mn id="S6.SS2.SSS1.p5.1.m1.2.2" xref="S6.SS2.SSS1.p5.1.m1.2.2.cmml">0.071</mn><mo stretchy="false" id="S6.SS2.SSS1.p5.1.m1.2.3.2.3" xref="S6.SS2.SSS1.p5.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p5.1.m1.2b"><interval closure="closed" id="S6.SS2.SSS1.p5.1.m1.2.3.1.cmml" xref="S6.SS2.SSS1.p5.1.m1.2.3.2"><cn type="float" id="S6.SS2.SSS1.p5.1.m1.1.1.cmml" xref="S6.SS2.SSS1.p5.1.m1.1.1">0.047</cn><cn type="float" id="S6.SS2.SSS1.p5.1.m1.2.2.cmml" xref="S6.SS2.SSS1.p5.1.m1.2.2">0.071</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p5.1.m1.2c">[0.047,0.071]</annotation></semantics></math> (see <a href="#S6.T2" title="Table 2 ‣ 6.2.2 Contribution per modality ‣ 6.2 LLM Fusion ‣ 6 Experiments ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 2</span></a> for detail). While <span id="S6.SS2.SSS1.p5.1.3" class="ltx_text ltx_font_typewriter">GPT-4</span> appears able to predict the general attitude of the participant towards a questionnaire statement (valence), it cannot reliably determine the strength of the participant’s feelings (arousal).</p>
</div>
</section>
<section id="S6.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.2 </span>Contribution per modality</h4>

<div id="S6.SS2.SSS2.p1" class="ltx_para ltx_noindent">
<p id="S6.SS2.SSS2.p1.2" class="ltx_p">To study the impact of each behavior modality (described in <a href="#S5.SS2.SSS1" title="5.2.1 Modalities ‣ 5.2 Algorithms for LLM Fusion ‣ 5 LLM Fusion ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2.1</span></a>), we conducted a two-tailed paired <math id="S6.SS2.SSS2.p1.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S6.SS2.SSS2.p1.1.m1.1a"><mi id="S6.SS2.SSS2.p1.1.m1.1.1" xref="S6.SS2.SSS2.p1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p1.1.m1.1b"><ci id="S6.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S6.SS2.SSS2.p1.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p1.1.m1.1c">t</annotation></semantics></math>-test of each model’s residuals against those of the baseline. The results suggest that each modality group added to the <span id="S6.SS2.SSS2.p1.2.1" class="ltx_text ltx_font_bold">LLM-4</span> baseline provides a statistically significant positive contribution (<math id="S6.SS2.SSS2.p1.2.m2.1" class="ltx_Math" alttext="p&lt;0.05" display="inline"><semantics id="S6.SS2.SSS2.p1.2.m2.1a"><mrow id="S6.SS2.SSS2.p1.2.m2.1.1" xref="S6.SS2.SSS2.p1.2.m2.1.1.cmml"><mi id="S6.SS2.SSS2.p1.2.m2.1.1.2" xref="S6.SS2.SSS2.p1.2.m2.1.1.2.cmml">p</mi><mo id="S6.SS2.SSS2.p1.2.m2.1.1.1" xref="S6.SS2.SSS2.p1.2.m2.1.1.1.cmml">&lt;</mo><mn id="S6.SS2.SSS2.p1.2.m2.1.1.3" xref="S6.SS2.SSS2.p1.2.m2.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p1.2.m2.1b"><apply id="S6.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S6.SS2.SSS2.p1.2.m2.1.1"><lt id="S6.SS2.SSS2.p1.2.m2.1.1.1.cmml" xref="S6.SS2.SSS2.p1.2.m2.1.1.1"></lt><ci id="S6.SS2.SSS2.p1.2.m2.1.1.2.cmml" xref="S6.SS2.SSS2.p1.2.m2.1.1.2">𝑝</ci><cn type="float" id="S6.SS2.SSS2.p1.2.m2.1.1.3.cmml" xref="S6.SS2.SSS2.p1.2.m2.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p1.2.m2.1c">p&lt;0.05</annotation></semantics></math>) to model performance.</p>
</div>
<figure id="S6.T2" class="ltx_table">
<table id="S6.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T2.1.1.1" class="ltx_tr">
<th id="S6.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt">Ablation</th>
<th id="S6.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">Exact</th>
<th id="S6.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">Valence</th>
<th id="S6.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Arousal</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T2.1.2.1" class="ltx_tr">
<th id="S6.T2.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t">4</th>
<td id="S6.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.470 (0.209)</td>
<td id="S6.T2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.634 (0.246)</td>
<td id="S6.T2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">0.055 (0.169)</td>
</tr>
<tr id="S6.T2.1.3.2" class="ltx_tr">
<th id="S6.T2.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">4S</th>
<td id="S6.T2.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r">0.518 (0.217)</td>
<td id="S6.T2.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r">0.687 (0.252)</td>
<td id="S6.T2.1.3.2.4" class="ltx_td ltx_align_center"><span id="S6.T2.1.3.2.4.1" class="ltx_text ltx_font_bold">0.071 (0.174)</span></td>
</tr>
<tr id="S6.T2.1.4.3" class="ltx_tr">
<th id="S6.T2.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">4F</th>
<td id="S6.T2.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r">0.513 (0.203)</td>
<td id="S6.T2.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r">0.686 (0.250)</td>
<td id="S6.T2.1.4.3.4" class="ltx_td ltx_align_center">0.053 (0.164)</td>
</tr>
<tr id="S6.T2.1.5.4" class="ltx_tr">
<th id="S6.T2.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">4GF</th>
<td id="S6.T2.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r">0.520 (0.212)</td>
<td id="S6.T2.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r">0.695 (0.259)</td>
<td id="S6.T2.1.5.4.4" class="ltx_td ltx_align_center">0.066 (0.180)</td>
</tr>
<tr id="S6.T2.1.6.5" class="ltx_tr">
<th id="S6.T2.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">4S</th>
<td id="S6.T2.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T2.1.6.5.2.1" class="ltx_text ltx_font_bold">0.543 (0.206)</span></td>
<td id="S6.T2.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r">0.680 (0.244)</td>
<td id="S6.T2.1.6.5.4" class="ltx_td ltx_align_center">0.054 (0.185)</td>
</tr>
<tr id="S6.T2.1.7.6" class="ltx_tr">
<th id="S6.T2.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">4SG</th>
<td id="S6.T2.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r">0.535 (0.210)</td>
<td id="S6.T2.1.7.6.3" class="ltx_td ltx_align_center ltx_border_r">0.702 (0.247)</td>
<td id="S6.T2.1.7.6.4" class="ltx_td ltx_align_center">0.039 (0.172)</td>
</tr>
<tr id="S6.T2.1.8.7" class="ltx_tr">
<th id="S6.T2.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">4SF</th>
<td id="S6.T2.1.8.7.2" class="ltx_td ltx_align_center ltx_border_r">0.532 (0.202)</td>
<td id="S6.T2.1.8.7.3" class="ltx_td ltx_align_center ltx_border_r">0.698 (0.247)</td>
<td id="S6.T2.1.8.7.4" class="ltx_td ltx_align_center">0.055 (0.170)</td>
</tr>
<tr id="S6.T2.1.9.8" class="ltx_tr">
<th id="S6.T2.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr">4SGF</th>
<td id="S6.T2.1.9.8.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">0.531 (0.193)</td>
<td id="S6.T2.1.9.8.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S6.T2.1.9.8.3.1" class="ltx_text ltx_font_bold">0.703 (0.248)</span></td>
<td id="S6.T2.1.9.8.4" class="ltx_td ltx_align_center ltx_border_bb">0.047 (0.180)</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Krippendorff’s alpha scores, mean and standard deviation, for each ablation (higher is better).</figcaption>
</figure>
<div id="S6.SS2.SSS2.p2" class="ltx_para ltx_noindent">
<p id="S6.SS2.SSS2.p2.4" class="ltx_p">In contrast, the additional modalities worsen the performance of the <span id="S6.SS2.SSS2.p2.4.1" class="ltx_text ltx_font_bold">4S</span> baseline on labeling exact scores but improve the performance on labeling valence. In a paired <math id="S6.SS2.SSS2.p2.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S6.SS2.SSS2.p2.1.m1.1a"><mi id="S6.SS2.SSS2.p2.1.m1.1.1" xref="S6.SS2.SSS2.p2.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p2.1.m1.1b"><ci id="S6.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S6.SS2.SSS2.p2.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p2.1.m1.1c">t</annotation></semantics></math>-test of residuals comparing exact predictions, the addition of facial expression descriptions in the <span id="S6.SS2.SSS2.p2.4.2" class="ltx_text ltx_font_bold">4SF</span> and <span id="S6.SS2.SSS2.p2.4.3" class="ltx_text ltx_font_bold">4SGF</span> ablations worsened performance significantly (<math id="S6.SS2.SSS2.p2.2.m2.1" class="ltx_Math" alttext="p=0.003" display="inline"><semantics id="S6.SS2.SSS2.p2.2.m2.1a"><mrow id="S6.SS2.SSS2.p2.2.m2.1.1" xref="S6.SS2.SSS2.p2.2.m2.1.1.cmml"><mi id="S6.SS2.SSS2.p2.2.m2.1.1.2" xref="S6.SS2.SSS2.p2.2.m2.1.1.2.cmml">p</mi><mo id="S6.SS2.SSS2.p2.2.m2.1.1.1" xref="S6.SS2.SSS2.p2.2.m2.1.1.1.cmml">=</mo><mn id="S6.SS2.SSS2.p2.2.m2.1.1.3" xref="S6.SS2.SSS2.p2.2.m2.1.1.3.cmml">0.003</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p2.2.m2.1b"><apply id="S6.SS2.SSS2.p2.2.m2.1.1.cmml" xref="S6.SS2.SSS2.p2.2.m2.1.1"><eq id="S6.SS2.SSS2.p2.2.m2.1.1.1.cmml" xref="S6.SS2.SSS2.p2.2.m2.1.1.1"></eq><ci id="S6.SS2.SSS2.p2.2.m2.1.1.2.cmml" xref="S6.SS2.SSS2.p2.2.m2.1.1.2">𝑝</ci><cn type="float" id="S6.SS2.SSS2.p2.2.m2.1.1.3.cmml" xref="S6.SS2.SSS2.p2.2.m2.1.1.3">0.003</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p2.2.m2.1c">p=0.003</annotation></semantics></math> and <math id="S6.SS2.SSS2.p2.3.m3.1" class="ltx_Math" alttext="p=0.021" display="inline"><semantics id="S6.SS2.SSS2.p2.3.m3.1a"><mrow id="S6.SS2.SSS2.p2.3.m3.1.1" xref="S6.SS2.SSS2.p2.3.m3.1.1.cmml"><mi id="S6.SS2.SSS2.p2.3.m3.1.1.2" xref="S6.SS2.SSS2.p2.3.m3.1.1.2.cmml">p</mi><mo id="S6.SS2.SSS2.p2.3.m3.1.1.1" xref="S6.SS2.SSS2.p2.3.m3.1.1.1.cmml">=</mo><mn id="S6.SS2.SSS2.p2.3.m3.1.1.3" xref="S6.SS2.SSS2.p2.3.m3.1.1.3.cmml">0.021</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p2.3.m3.1b"><apply id="S6.SS2.SSS2.p2.3.m3.1.1.cmml" xref="S6.SS2.SSS2.p2.3.m3.1.1"><eq id="S6.SS2.SSS2.p2.3.m3.1.1.1.cmml" xref="S6.SS2.SSS2.p2.3.m3.1.1.1"></eq><ci id="S6.SS2.SSS2.p2.3.m3.1.1.2.cmml" xref="S6.SS2.SSS2.p2.3.m3.1.1.2">𝑝</ci><cn type="float" id="S6.SS2.SSS2.p2.3.m3.1.1.3.cmml" xref="S6.SS2.SSS2.p2.3.m3.1.1.3">0.021</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p2.3.m3.1c">p=0.021</annotation></semantics></math>, respectively); however, gaze did not have a notable impact (<math id="S6.SS2.SSS2.p2.4.m4.1" class="ltx_Math" alttext="p=0.164" display="inline"><semantics id="S6.SS2.SSS2.p2.4.m4.1a"><mrow id="S6.SS2.SSS2.p2.4.m4.1.1" xref="S6.SS2.SSS2.p2.4.m4.1.1.cmml"><mi id="S6.SS2.SSS2.p2.4.m4.1.1.2" xref="S6.SS2.SSS2.p2.4.m4.1.1.2.cmml">p</mi><mo id="S6.SS2.SSS2.p2.4.m4.1.1.1" xref="S6.SS2.SSS2.p2.4.m4.1.1.1.cmml">=</mo><mn id="S6.SS2.SSS2.p2.4.m4.1.1.3" xref="S6.SS2.SSS2.p2.4.m4.1.1.3.cmml">0.164</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p2.4.m4.1b"><apply id="S6.SS2.SSS2.p2.4.m4.1.1.cmml" xref="S6.SS2.SSS2.p2.4.m4.1.1"><eq id="S6.SS2.SSS2.p2.4.m4.1.1.1.cmml" xref="S6.SS2.SSS2.p2.4.m4.1.1.1"></eq><ci id="S6.SS2.SSS2.p2.4.m4.1.1.2.cmml" xref="S6.SS2.SSS2.p2.4.m4.1.1.2">𝑝</ci><cn type="float" id="S6.SS2.SSS2.p2.4.m4.1.1.3.cmml" xref="S6.SS2.SSS2.p2.4.m4.1.1.3">0.164</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p2.4.m4.1c">p=0.164</annotation></semantics></math>).</p>
</div>
</section>
<section id="S6.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.3 </span>Performance across individual survey questions</h4>

<div id="S6.SS2.SSS3.p1" class="ltx_para ltx_noindent">
<p id="S6.SS2.SSS3.p1.1" class="ltx_p">The following statements achieved the <em id="S6.SS2.SSS3.p1.1.1" class="ltx_emph ltx_font_italic">best</em> performance across all ablations (mean accuracy and standard deviation):</p>
<ol id="S6.I2" class="ltx_enumerate">
<li id="S6.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S6.I2.i1.p1" class="ltx_para">
<p id="S6.I2.i1.p1.1" class="ltx_p"><span id="S6.I2.i1.p1.1.1" class="ltx_text ltx_font_italic">I felt like my conversation partner really listened to me</span> (mean 64.0%, std. dev. 7.1%);</p>
</div>
</li>
<li id="S6.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S6.I2.i2.p1" class="ltx_para">
<p id="S6.I2.i2.p1.1" class="ltx_p"><span id="S6.I2.i2.p1.1.1" class="ltx_text ltx_font_italic">I became irritated with my partner at some points in the conversation</span> (mean 60.7%, std. dev. 5.9%); and</p>
</div>
</li>
<li id="S6.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S6.I2.i3.p1" class="ltx_para ltx_noindent">
<p id="S6.I2.i3.p1.1" class="ltx_p"><span id="S6.I2.i3.p1.1.1" class="ltx_text ltx_font_italic">My conversation partner seemed like a warm person</span> (mean 53.7%, std. dev. 6.2%).</p>
</div>
</li>
</ol>
</div>
<div id="S6.SS2.SSS3.p2" class="ltx_para ltx_noindent">
<p id="S6.SS2.SSS3.p2.1" class="ltx_p">The following statements achieved the <em id="S6.SS2.SSS3.p2.1.1" class="ltx_emph ltx_font_italic">worst</em> performance across all ablations (mean accuracy and standard deviation):</p>
<ol id="S6.I3" class="ltx_enumerate">
<li id="S6.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S6.I3.i1.p1" class="ltx_para">
<p id="S6.I3.i1.p1.1" class="ltx_p"><span id="S6.I3.i1.p1.1.1" class="ltx_text ltx_font_italic">My conversation partner was quite sensitive</span> (mean 4.0%, std. dev. 1.6%);</p>
</div>
</li>
<li id="S6.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S6.I3.i2.p1" class="ltx_para">
<p id="S6.I3.i2.p1.1" class="ltx_p"><span id="S6.I3.i2.p1.1.1" class="ltx_text ltx_font_italic">I would trust my conversation partner with sensitive information</span> (mean 8.8%, std. dev. 5.2%); and</p>
</div>
</li>
<li id="S6.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S6.I3.i3.p1" class="ltx_para ltx_noindent">
<p id="S6.I3.i3.p1.1" class="ltx_p"><span id="S6.I3.i3.p1.1.1" class="ltx_text ltx_font_italic">My partner and I laughed during our interaction</span> (mean 10.3%, std. dev. 4.1%). </p>
</div>
</li>
</ol>
</div>
<div id="S6.SS2.SSS3.p3" class="ltx_para ltx_noindent">
<p id="S6.SS2.SSS3.p3.1" class="ltx_p">Prediction performance on the questions about laughter and eye contact is relatively poor, addressing our earlier hypothesis regarding the ability of the model to infer this behavior. In general, while the transcript did not explicitly contain descriptions of laughter, <span id="S6.SS2.SSS3.p3.1.1" class="ltx_text ltx_font_typewriter">GPT-4</span> tends to respond with the assumption that laughter did occur. Although numerous caveats apply to these results, they generally reflect the opinions of our study’s participants.</p>
</div>
</section>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para ltx_noindent">
<p id="S7.p1.1" class="ltx_p">Engagement is fundamental to all human interactions, representing the intrinsic interest or emotional investment of the individuals involved. Despite humans’ intuitive understanding of engagement, developing computational systems capable of recognizing and measuring engagement remains a significant challenge. Our work studies this core element of communication through smart glasses worn by participants in natural conversation. We collected a dataset of casual conversations between pairs of strangers, each outfitted with a pair of smart glasses, to capture behavioral cues such as facial expressions, eye contact, and verbal exchanges. We introduce a novel fusion method using large language models (LLMs), generating a “multimodal transcript” of the conversation to prompt an LLM to predict the participants’ self-reported engagement levels.
Our work is one of the first to use language to “reason” about human behavior, laying the groundwork for many promising directions for future research in computational behavior analysis.</p>
</div>
<div id="S7.p2" class="ltx_para ltx_noindent">
<p id="S7.p2.1" class="ltx_p">However, it is crucial to acknowledge the limitations and biases associated with the models used. LLMs inadvertently learn and incorporate positional, racial, gender, and other social biases (<cite class="ltx_cite ltx_citemacro_cite">Cheng et al<span class="ltx_text">.</span> (<a href="#bib.bib13" title="" class="ltx_ref">2023</a>); Wan et al<span class="ltx_text">.</span> (<a href="#bib.bib66" title="" class="ltx_ref">2023</a>); Navigli et al<span class="ltx_text">.</span> (<a href="#bib.bib44" title="" class="ltx_ref">2023</a>); Wang et al<span class="ltx_text">.</span> (<a href="#bib.bib67" title="" class="ltx_ref">2024</a>)</cite>). They are also sensitive to the wording of provided prompts. Furthermore, given that our multimodal transcript relies on pre-trained models such as OpenFace, MediaPipe, and Whisper, possible issues of bias and robustness in those models <cite class="ltx_cite ltx_citemacro_cite">Namba et al<span class="ltx_text">.</span> (<a href="#bib.bib43" title="" class="ltx_ref">2021</a>); Graham and Roll (<a href="#bib.bib25" title="" class="ltx_ref">2024</a>)</cite> should also be taken into consideration. Additional noise may be created from the usage of multiple pre-trained models. The ability of the multimodal transcript to accurately represent the conversation is inherently limited by the accuracy of the pre-trained models used.</p>
</div>
<div id="S7.p3" class="ltx_para ltx_noindent">
<p id="S7.p3.1" class="ltx_p">Given the limited size and variance in demographics of our participants and engagement experiences within our dataset, it also raises the question of how well LLMs can simulate engagement questionnaire responses for different populations and conversational experiences. It’s also possible that a person’s responses to the Big Five Inventory and belief questionnaire may not accurately reflect their true personality and beliefs.</p>
</div>
<div id="S7.p4" class="ltx_para ltx_noindent">
<p id="S7.p4.1" class="ltx_p">LLMs such as <span id="S7.p4.1.1" class="ltx_text ltx_font_typewriter">GPT-4</span> have been fine-tuned with RLHF to produce responses that are safer and better aligned with the user’s intent. While this process reduces response toxicity and improves the ability to follow instructions, we note that this calibration may interfere with the ability of the LLM to emulate human-like responses in a research setting.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aher et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Gati Aher, Rosa I. Arriaga, and Adam Tauman Kalai. 2023.

</span>
<span class="ltx_bibblock">Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies. In <em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 40th International Conference on Machine Learning</em> <em id="bib.bib2.4.2" class="ltx_emph ltx_font_italic">(ICML’23, Vol. 202)</em>. Honolulu, Hawaii, USA, 337–371.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Argyle et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Lisa P. Argyle, Ethan C. Busby, Nancy Fulda, Joshua R. Gubler, Christopher Rytting, and David Wingate. 2023.

</span>
<span class="ltx_bibblock">Out of One, Many: Using Language Models to Simulate Human Samples.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">Political Analysis</em> 31, 3 (July 2023), 337–351.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1017/pan.2023.2" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1017/pan.2023.2</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Babcock et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Meghan J. Babcock, Vivian P. Ta, and William Ickes. 2014.

</span>
<span class="ltx_bibblock">Latent Semantic Similarity and Language Style Matching in Initial Dyadic Interactions.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">Journal of Language and Social Psychology</em> 33, 1 (Jan. 2014), 78–88.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1177/0261927X13499331" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1177/0261927X13499331</a>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baltrusaitis et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Tadas Baltrusaitis, Amir Zadeh, Yao Chong Lim, and Louis-Philippe Morency. 2018.

</span>
<span class="ltx_bibblock">OpenFace 2.0: Facial Behavior Analysis Toolkit. In <em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Thirteenth IEEE International Conference on Automatic Face &amp; Gesture Recognition (FG 2018)</em>. 59–66.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/FG.2018.00019" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/FG.2018.00019</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ben-Youssef et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Atef Ben-Youssef, Chloé Clavel, Slim Essid, Miriam Bilac, Marine Chamoux, and Angelica Lim. 2017.

</span>
<span class="ltx_bibblock">UE-HRI: A New Dataset for the Study of User Engagement in Spontaneous Human-Robot Interactions. In <em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 19th ACM International Conference on Multimodal Interaction</em> <em id="bib.bib6.4.2" class="ltx_emph ltx_font_italic">(ICMI ’17)</em>. Association for Computing Machinery, New York, NY, USA, 464–472.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3136755.3136814" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3136755.3136814</a>

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bredin (2023)</span>
<span class="ltx_bibblock">
Hervé Bredin. 2023.

</span>
<span class="ltx_bibblock">Pyannote.Audio 2.1 Speaker Diarization Pipeline: Principle, Benchmark, and Recipe. In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">INTERSPEECH 2023</em>. ISCA, 1983–1987.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.21437/Interspeech.2023-105" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.21437/Interspeech.2023-105</a>

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Busso et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2008)</span>
<span class="ltx_bibblock">
Carlos Busso, Murtaza Bulut, Chi Chun Lee, Abe Kazemzadeh, Emily Mower, Samuel Kim, Jeannette N. Chang, Sungbok Lee, and Shrikanth Narayanan. 2008.

</span>
<span class="ltx_bibblock">IEMOCAP: Interactive Emotional Dyadic Motion Capture Database.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">Language Resources and Evaluation</em> 42, 4 (2008).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1007/s10579-008-9076-6" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/s10579-008-9076-6</a>

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cafaro et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Angelo Cafaro, Johannes Wagner, Tobias Baur, Soumia Dermouche, Mercedes Torres Torres, Catherine Pelachaud, Elisabeth André, and Michel Valstar. 2017.

</span>
<span class="ltx_bibblock">The NoXi Database: Multimodal Recordings of Mediated Novice-Expert Interactions. In <em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 19th ACM International Conference on Multimodal Interaction</em> <em id="bib.bib9.4.2" class="ltx_emph ltx_font_italic">(ICMI ’17)</em>. Association for Computing Machinery, New York, NY, USA, 350–359.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3136755.3136780" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3136755.3136780</a>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carmody et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Patrick C. Carmody, Julio C. Mateo, Drew Bowers, and Mike J. McCloskey. 2017.

</span>
<span class="ltx_bibblock">Linguistic Coordination as an Unobtrusive, Dynamic Indicator of Rapport, Prosocial Team Processes, and Performance in Team Communication.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Human Factors and Ergonomics Society Annual Meeting</em> 61, 1 (Sept. 2017), 140–144.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1177/1541931213601518" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1177/1541931213601518</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Celepkolu and Boyer (2018)</span>
<span class="ltx_bibblock">
Mehmet Celepkolu and Kristy Elizabeth Boyer. 2018.

</span>
<span class="ltx_bibblock">Predicting Student Performance Based on Eye Gaze During Collaborative Problem Solving. In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Group Interaction Frontiers in Technology</em> (Boulder, CO, USA) <em id="bib.bib11.2.2" class="ltx_emph ltx_font_italic">(GIFT’18)</em>. Association for Computing Machinery, New York, NY, USA, Article 7, 8 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3279981.3279991" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3279981.3279991</a>

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Celiktutan et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Oya Celiktutan, Efstratios Skordos, and Hatice Gunes. 2019.

</span>
<span class="ltx_bibblock">Multimodal Human-Human-Robot Interactions (MHHRI) Dataset for Studying Personality and Engagement.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Affective Computing</em> 10, 4 (Oct. 2019), 484–497.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TAFFC.2017.2737019" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TAFFC.2017.2737019</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Myra Cheng, Esin Durmus, and Dan Jurafsky. 2023.

</span>
<span class="ltx_bibblock">Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models. In <em id="bib.bib13.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (Eds.). Association for Computational Linguistics, Toronto, Canada, 1504–1532.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2023.acl-long.84" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2023.acl-long.84</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cox et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Samuel Rhys Cox, Ashraf Abdul, and Wei Tsang Ooi. 2023.

</span>
<span class="ltx_bibblock">Prompting a Large Language Model to Generate Diverse Motivational Messages: A Comparison with Human-Written Messages. In <em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 11th International Conference on Human-Agent Interaction</em> <em id="bib.bib14.4.2" class="ltx_emph ltx_font_italic">(HAI ’23)</em>. Association for Computing Machinery, New York, NY, USA, 378–380.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3623809.3623931" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3623809.3623931</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cuperman and Ickes (2009)</span>
<span class="ltx_bibblock">
Ronen Cuperman and William Ickes. 2009.

</span>
<span class="ltx_bibblock">Big Five Predictors of Behavior and Perceptions in Initial Dyadic Interactions: Personality Similarity Helps Extraverts and Introverts, but Hurts “Disagreeables”.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Journal of Personality and Social Psychology</em> 97, 4 (2009), 667–684.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1037/a0015741" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1037/a0015741</a>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Curhan and Pentland (2007)</span>
<span class="ltx_bibblock">
Jared R. Curhan and Alex Pentland. 2007.

</span>
<span class="ltx_bibblock">Thin Slices of Negotiation: Predicting Outcomes from Conversational Dynamics within the First 5 Minutes.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Journal of Applied Psychology</em> 92, 3 (2007), 802–811.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1037/0021-9010.92.3.802" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1037/0021-9010.92.3.802</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cuturi (2011)</span>
<span class="ltx_bibblock">
Marco Cuturi. 2011.

</span>
<span class="ltx_bibblock">Fast global alignment kernels. In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th International Conference on International Conference on Machine Learning</em> (Bellevue, Washington, USA) <em id="bib.bib17.2.2" class="ltx_emph ltx_font_italic">(ICML’11)</em>. Omnipress, Madison, WI, USA, 929–936.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Demszky et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Dorottya Demszky, Diyi Yang, David S. Yeager, Christopher J. Bryan, Margarett Clapper, Susannah Chandhok, Johannes C. Eichstaedt, Cameron Hecht, Jeremy Jamieson, Meghann Johnson, Michaela Jones, Danielle Krettek-Cobb, Leslie Lai, Nirel JonesMitchell, Desmond C. Ong, Carol S. Dweck, James J. Gross, and James W. Pennebaker. 2023.

</span>
<span class="ltx_bibblock">Using Large Language Models in Psychology.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.3.1" class="ltx_emph ltx_font_italic">Nature Reviews Psychology</em> 2, 11 (Nov. 2023), 688–701.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1038/s44159-023-00241-5" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/s44159-023-00241-5</a>

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dillion et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Danica Dillion, Niket Tandon, Yuling Gu, and Kurt Gray. 2023.

</span>
<span class="ltx_bibblock">Can AI language models replace human participants?

</span>
<span class="ltx_bibblock"><em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">Trends in Cognitive Sciences</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ekman and Friesen (1978)</span>
<span class="ltx_bibblock">
Paul Ekman and Wallace V. Friesen. 1978.

</span>
<span class="ltx_bibblock">Facial Action Coding System.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1037/t27734-000" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1037/t27734-000</a>

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Firdaus et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Mauajama Firdaus, Hardik Chauhan, Asif Ekbal, and Pushpak Bhattacharyya. 2020.

</span>
<span class="ltx_bibblock">MEISD: A Multimodal Multi-Label Emotion, Intensity and Sentiment Dialogue Dataset for Emotion Recognition and Sentiment Analysis in Conversations. In <em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th International Conference on Computational Linguistics</em>, Donia Scott, Nuria Bel, and Chengqing Zong (Eds.). International Committee on Computational Linguistics, Barcelona, Spain (Online), 4441–4453.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2020.coling-main.393" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.coling-main.393</a>

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Tianyu Gao, Xingcheng Yao, and Danqi Chen. 2021.

</span>
<span class="ltx_bibblock">SimCSE: Simple Contrastive Learning of Sentence Embeddings. In <em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih (Eds.). Association for Computational Linguistics, Online and Punta Cana, Dominican Republic, 6894–6910.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2021.emnlp-main.552" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2021.emnlp-main.552</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Girdhar et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Rohit Girdhar, Alaaeldin El-Nouby, Zhuang Liu, Mannat Singh, Kalyan Vasudev Alwala, Armand Joulin, and Ishan Misra. 2023.

</span>
<span class="ltx_bibblock">ImageBind One Embedding Space to Bind Them All. In <em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ‘23)</em>. 15180–15190.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/CVPR52729.2023.01457" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/CVPR52729.2023.01457</a>

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodwin (1981)</span>
<span class="ltx_bibblock">
Charles Goodwin. 1981.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Conversational Organization: Interaction Between Speakers and Hearers</em>.

</span>
<span class="ltx_bibblock">Academic Press, New York.

</span>
<span class="ltx_bibblock">


</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graham and Roll (2024)</span>
<span class="ltx_bibblock">
Calbert Graham and Nathan Roll. 2024.

</span>
<span class="ltx_bibblock">Evaluating OpenAI’s Whisper ASR: Performance analysis across diverse accents and speaker traits.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">JASA Express Letters</em> 4, 2 (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grauman et al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Kristen Grauman, Andrew Westbury, Lorenzo Torresani, Kris Kitani, Jitendra Malik, Triantafyllos Afouras, Kumar Ashutosh, Vijay Baiyya, Siddhant Bansal, Bikram Boote, Eugene Byrne, Zach Chavis, Joya Chen, Feng Cheng, Fu-Jen Chu, Sean Crane, Avijit Dasgupta, Jing Dong, Maria Escobar, Cristhian Forigua, Abrham Gebreselasie, Sanjay Haresh, Jing Huang, Md Mohaiminul Islam, Suyog Jain, Rawal Khirodkar, Devansh Kukreja, Kevin J Liang, Jia-Wei Liu, Sagnik Majumder,
Yongsen Mao, Miguel Martin, Effrosyni Mavroudi, Tushar Nagarajan, Francesco Ragusa, Santhosh Kumar Ramakrishnan, Luigi Seminara, Arjun Somayazulu, Yale Song, Shan Su, Zihui Xue, Edward Zhang, Jinxu Zhang, Angela Castillo, Changan Chen, Xinzhu Fu, Ryosuke Furuta, Cristina Gonzalez, Prince Gupta, Jiabo Hu, Yifei Huang, Yiming Huang, Weslie Khoo, Anush Kumar, Robert Kuo, Sach Lakhavani, Miao Liu, Mi Luo, Zhengyi Luo, Brighid Meredith, Austin Miller,
Oluwatumininu Oguntola, Xiaqing Pan, Penny Peng, Shraman Pramanick, Merey Ramazanova, Fiona Ryan, Wei Shan, Kiran Somasundaram, Chenan Song, Audrey Southerland, Masatoshi Tateno, Huiyu Wang, Yuchen Wang, Takuma Yagi, Mingfei Yan, Xitong Yang, Zecheng Yu, Shengxin Cindy Zha, Chen Zhao, Ziwei Zhao, Zhifan Zhu, Jeff Zhuo, Pablo Arbelaez, Gedas Bertasius, Dima Damen, Jakob Engel, Giovanni Maria Farinella, Antonino Furnari, Bernard Ghanem, Judy Hoffman, C.V.
Jawahar, Richard Newcombe, Hyun Soo Park, James M. Rehg, Yoichi Sato, Manolis Savva, Jianbo Shi, Mike Zheng Shou, and Michael Wray. 2024.

</span>
<span class="ltx_bibblock">Ego-Exo4D: Understanding Skilled Human Activity from First- and Third-Person Perspectives. In <em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>. 19383–19400.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://openaccess.thecvf.com/content/CVPR2024/html/Grauman_Ego-Exo4D_Understanding_Skilled_Human_Activity_from_First-_and_Third-Person_Perspectives_CVPR_2024_paper.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openaccess.thecvf.com/content/CVPR2024/html/Grauman_Ego-Exo4D_Understanding_Skilled_Human_Activity_from_First-_and_Third-Person_Perspectives_CVPR_2024_paper.html</a>

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guevara et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Marco Guevara, Shan Chen, Spencer Thomas, Tafadzwa L. Chaunzwa, Idalid Franco, Benjamin H. Kann, Shalini Moningi, Jack M. Qian, Madeleine Goldstein, Susan Harper, Hugo J. W. L. Aerts, Paul J. Catalano, Guergana K. Savova, Raymond H. Mak, and Danielle S. Bitterman. 2024.

</span>
<span class="ltx_bibblock">Large Language Models to Identify Social Determinants of Health in Electronic Health Records.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">npj Digital Medicine</em> 7, 1 (Jan. 2024), 1–14.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1038/s41746-023-00970-0" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/s41746-023-00970-0</a>

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harding et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Jacqueline Harding, William D’Alessandro, NG Laskowski, and Robert Long. 2023.

</span>
<span class="ltx_bibblock">AI language models cannot replace human research participants.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">Ai &amp; Society</em> (2023), 1–3.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ireland and Pennebaker (2010)</span>
<span class="ltx_bibblock">
Molly E. Ireland and James W. Pennebaker. 2010.

</span>
<span class="ltx_bibblock">Language Style Matching in Writing: Synchrony in Essays, Correspondence, and Poetry.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Journal of Personality and Social Psychology</em> 99, 3 (2010), 549–571.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1037/a0020386" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1037/a0020386</a>

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ireland et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2011)</span>
<span class="ltx_bibblock">
Molly E. Ireland, Richard B. Slatcher, Paul W. Eastwick, Lauren E. Scissors, Eli J. Finkel, and James W. Pennebaker. 2011.

</span>
<span class="ltx_bibblock">Language Style Matching Predicts Relationship Initiation and Stability.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">Psychological Science</em> 22, 1 (Jan. 2011), 39–44.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1177/0956797610392928" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1177/0956797610392928</a>

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Dongjun Kang, Joonsuk Park, Yohan Jo, and JinYeong Bak. 2023.

</span>
<span class="ltx_bibblock">From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models. In <em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP ‘23)</em>, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, Singapore, 15539–15559.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2023.emnlp-main.961" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2023.emnlp-main.961</a>

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karinshak et al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Elise Karinshak, Sunny Xun Liu, Joon Sung Park, and Jeffrey T. Hancock. 2023.

</span>
<span class="ltx_bibblock">Working With AI to Persuade: Examining a Large Language Model’s Ability to Generate Pro-Vaccination Messages.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Human-Computer Interaction</em> 7, CSCW1 (April 2023), 116:1–116:29.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3579592" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3579592</a>

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Hyunwoo Kim, Melanie Sclar, Xuhui Zhou, Ronan Bras, Gunhee Kim, Yejin Choi, and Maarten Sap. 2023.

</span>
<span class="ltx_bibblock">FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions. In <em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, Singapore, 14397–14413.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2023.emnlp-main.890" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2023.emnlp-main.890</a>

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lai et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Bolin Lai, Fiona Ryan, Wenqi Jia, Miao Liu, and James M Rehg. 2023.

</span>
<span class="ltx_bibblock">Listen to look into the future: Audio-visual egocentric gaze anticipation.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.03907</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Landis and Koch (1977)</span>
<span class="ltx_bibblock">
J. Richard Landis and Gary G. Koch. 1977.

</span>
<span class="ltx_bibblock">The Measurement of Observer Agreement for Categorical Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Biometrics</em> 33, 1 (March 1977), 159–174.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.2307/2529310" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.2307/2529310</a>
arXiv:2529310

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lugaresi et al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Camillo Lugaresi, Jiuqiang Tang, Hadon Nash, Chris McClanahan, Esha Uboweja, Michael Hays, Fan Zhang, Chuo-Ling Chang, Ming Guang Yong, Juhyun Lee, Wan-Teh Chang, Wei Hua, Manfred Georg, and Matthias Grundmann. 2019.

</span>
<span class="ltx_bibblock">MediaPipe: A Framework for Building Perception Pipelines.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.1906.08172" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.1906.08172</a>
arXiv:1906.08172 [cs]

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McCrae and Costa Jr. (1999)</span>
<span class="ltx_bibblock">
Robert R. McCrae and Paul T. Costa Jr. 1999.

</span>
<span class="ltx_bibblock">A Five-Factor Theory of Personality.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Handbook of Personality: Theory and Research, 2nd Ed</em>. Guilford Press, New York, NY, US, 139–153.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McDuff et al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Daniel McDuff, Abdelrahman Mahmoud, Mohammad Mavadati, May Amr, Jay Turcot, and Rana El Kaliouby. 2016.

</span>
<span class="ltx_bibblock">AFFDEX SDK: A Cross-Platform Real-Time Multi-Face Expression Recognition Toolkit. In <em id="bib.bib38.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems</em>. ACM, San Jose California USA, 3723–3726.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2851581.2890247" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2851581.2890247</a>

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McKeown et al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Gary McKeown, Michel Valstar, Roddy Cowie, Maja Pantic, and Marc Schroder. 2012.

</span>
<span class="ltx_bibblock">The SEMAINE Database: Annotated Multimodal Records of Emotionally Colored Conversations between a Person and a Limited Agent.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Affective Computing</em> 3, 1 (Jan. 2012), 5–17.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/T-AFFC.2011.20" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/T-AFFC.2011.20</a>

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mokady et al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Ron Mokady, Amir Hertz, and Amit H. Bermano. 2021.

</span>
<span class="ltx_bibblock">ClipCap: CLIP Prefix for Image Captioning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2111.09734" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2111.09734</a>
arXiv:2111.09734 [cs]

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mollahosseini et al<span id="bib.bib41.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Ali Mollahosseini, Behzad Hasani, and Mohammad H. Mahoor. 2019.

</span>
<span class="ltx_bibblock">AffectNet: A Database for Facial Expression, Valence, and Arousal Computing in the Wild.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Affective Computing</em> 10, 1 (Jan. 2019), 18–31.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TAFFC.2017.2740923" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TAFFC.2017.2740923</a>

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nakano and Ishii (2010)</span>
<span class="ltx_bibblock">
Yukiko I. Nakano and Ryo Ishii. 2010.

</span>
<span class="ltx_bibblock">Estimating user’s engagement from eye-gaze behaviors in human-agent conversations. In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 15th International Conference on Intelligent User Interfaces</em> (Hong Kong, China) <em id="bib.bib42.2.2" class="ltx_emph ltx_font_italic">(IUI ’10)</em>. Association for Computing Machinery, New York, NY, USA, 139–148.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/1719970.1719990" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/1719970.1719990</a>

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Namba et al<span id="bib.bib43.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Shushi Namba, Wataru Sato, and Sakiko Yoshikawa. 2021.

</span>
<span class="ltx_bibblock">Viewpoint robustness of automated facial action unit detection systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.3.1" class="ltx_emph ltx_font_italic">Applied Sciences</em> 11, 23 (2021), 11171.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Navigli et al<span id="bib.bib44.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Roberto Navigli, Simone Conia, and Björn Ross. 2023.

</span>
<span class="ltx_bibblock">Biases in Large Language Models: Origins, Inventory, and Discussion.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.3.1" class="ltx_emph ltx_font_italic">Journal of Data and Information Quality</em> 15, 2 (June 2023), 10:1–10:21.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3597307" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3597307</a>

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022.

</span>
<span class="ltx_bibblock">Training Language Models to Follow Instructions with Human Feedback. In <em id="bib.bib45.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems (NeurIPS ‘22)</em>, Vol. 35. 27730–27744.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et al<span id="bib.bib46.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. 2023.

</span>
<span class="ltx_bibblock">Generative Agents: Interactive Simulacra of Human Behavior. In <em id="bib.bib46.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology</em> <em id="bib.bib46.4.2" class="ltx_emph ltx_font_italic">(UIST ’23)</em>. Association for Computing Machinery, New York, NY, USA, 1–22.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3586183.3606763" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3586183.3606763</a>

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pellet-Rostaing et al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Arthur Pellet-Rostaing, Roxane Bertrand, Auriane Boudin, Stéphane Rauzy, and Philippe Blache. 2023.

</span>
<span class="ltx_bibblock">A Multimodal Approach for Modeling Engagement in Conversation.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">Frontiers in Computer Science</em> 5 (March 2023).

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.3389/fcomp.2023.1062342" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.3389/fcomp.2023.1062342</a>

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pew Research Center (2021)</span>
<span class="ltx_bibblock">
Pew Research Center. 2021.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Beyond Red vs. Blue: The Political Typology</em>.

</span>
<span class="ltx_bibblock">Technical Report. Washington, DC, USA.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Plaquet and Bredin (2023)</span>
<span class="ltx_bibblock">
Alexis Plaquet and Hervé Bredin. 2023.

</span>
<span class="ltx_bibblock">Powerset multi-class cross entropy loss for neural speaker diarization. In <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Proc. INTERSPEECH 2023</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Poria et al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Soujanya Poria, Devamanyu Hazarika, Navonil Majumder, Gautam Naik, Erik Cambria, and Rada Mihalcea. 2019.

</span>
<span class="ltx_bibblock">MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations. In <em id="bib.bib50.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL ‘19)</em>, Anna Korhonen, David Traum, and Lluís Màrquez (Eds.). Association for Computational Linguistics, Florence, Italy, 527–536.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/P19-1050" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P19-1050</a>

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Premack and Woodruff (1978)</span>
<span class="ltx_bibblock">
David Premack and Guy Woodruff. 1978.

</span>
<span class="ltx_bibblock">Does the Chimpanzee Have a Theory of Mind?

</span>
<span class="ltx_bibblock"><em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Behavioral and Brain Sciences</em> 1, 4 (Dec. 1978), 515–526.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1017/S0140525X00076512" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1017/S0140525X00076512</a>

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al<span id="bib.bib52.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. 2023.

</span>
<span class="ltx_bibblock">Robust Speech Recognition via Large-Scale Weak Supervision. In <em id="bib.bib52.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 40th International Conference on Machine Learning</em> <em id="bib.bib52.4.2" class="ltx_emph ltx_font_italic">(ICML’23, Vol. 202)</em>. JMLR, Honolulu, Hawaii, USA, 28492–28518.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ranti et al<span id="bib.bib53.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Carolyn Ranti, Warren Jones, Ami Klin, and Sarah Shultz. 2020.

</span>
<span class="ltx_bibblock">Blink Rate Patterns Provide a Reliable Measure of Individual Engagement with Scene Content.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.3.1" class="ltx_emph ltx_font_italic">Scientific Reports</em> 10, 1 (May 2020), 8267.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1038/s41598-020-64999-x" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/s41598-020-64999-x</a>

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ringeval et al<span id="bib.bib54.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Fabien Ringeval, Andreas Sonderegger, Juergen Sauer, and Denis Lalanne. 2013.

</span>
<span class="ltx_bibblock">Introducing the RECOLA Multimodal Corpus of Remote Collaborative and Affective Interactions. In <em id="bib.bib54.3.1" class="ltx_emph ltx_font_italic">2013 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG ‘13)</em>. 1–8.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/FG.2013.6553805" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/FG.2013.6553805</a>

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sap et al<span id="bib.bib55.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Maarten Sap, Ronan Le Bras, Daniel Fried, and Yejin Choi. 2022.

</span>
<span class="ltx_bibblock">Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs. In <em id="bib.bib55.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP ‘22)</em>, Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang (Eds.). Association for Computational Linguistics, Abu Dhabi, United Arab Emirates, 3762–3780.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2022.emnlp-main.248" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2022.emnlp-main.248</a>

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sap et al<span id="bib.bib56.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Maarten Sap, Hannah Rashkin, Derek Chen, Ronan Le Bras, and Yejin Choi. 2019.

</span>
<span class="ltx_bibblock">Social IQa: Commonsense Reasoning about Social Interactions. In <em id="bib.bib56.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</em>, Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan (Eds.). Association for Computational Linguistics, Hong Kong, China, 4463–4473.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/D19-1454" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/D19-1454</a>

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Serapio-García et al<span id="bib.bib57.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Greg Serapio-García, Mustafa Safdari, Clément Crepy, Luning Sun, Stephen Fitz, Peter Romero, Marwa Abdulhai, Aleksandra Faust, and Maja Matarić. 2023.

</span>
<span class="ltx_bibblock">Personality Traits in Large Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2307.00184" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2307.00184</a>
arXiv:2307.00184 [cs]

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stade et al<span id="bib.bib58.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Elizabeth C. Stade, Shannon Wiltsey Stirman, Lyle H. Ungar, Cody L. Boland, H. Andrew Schwartz, David B. Yaden, João Sedoc, Robert J. DeRubeis, Robb Willer, and Johannes C. Eichstaedt. 2024.

</span>
<span class="ltx_bibblock">Large Language Models Could Change the Future of Behavioral Healthcare: A Proposal for Responsible Development and Evaluation.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.3.1" class="ltx_emph ltx_font_italic">npj Mental Health Research</em> 3, 1 (April 2024), 1–12.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1038/s44184-024-00056-z" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/s44184-024-00056-z</a>

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tausczik and Pennebaker (2010)</span>
<span class="ltx_bibblock">
Yla R. Tausczik and James W. Pennebaker. 2010.

</span>
<span class="ltx_bibblock">The Psychological Meaning of Words: LIWC and Computerized Text Analysis Methods.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">Journal of Language and Social Psychology</em> 29, 1 (March 2010), 24–54.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1177/0261927X09351676" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1177/0261927X09351676</a>

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tavast et al<span id="bib.bib60.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Mikke Tavast, Anton Kunnari, and Perttu Hämäläinen. 2022.

</span>
<span class="ltx_bibblock">Language models can generate human-like self-reports of emotion. In <em id="bib.bib60.3.1" class="ltx_emph ltx_font_italic">27th International Conference on Intelligent User Interfaces</em>. 69–72.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tejada et al<span id="bib.bib61.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Julian Tejada, Raquel Meister Ko Freitag, Bruno Felipe Marques Pinheiro, Paloma Batista Cardoso, Victor Rene Andrade Souza, and Lucas Santos Silva. 2022.

</span>
<span class="ltx_bibblock">Building and Validation of a Set of Facial Expression Images to Detect Emotions: A Transcultural Study.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.3.1" class="ltx_emph ltx_font_italic">Psychological Research</em> 86, 6 (2022), 1996–2006.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1007/s00426-021-01605-3" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/s00426-021-01605-3</a>

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tewel et al<span id="bib.bib62.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yoad Tewel, Yoav Shalev, Idan Schwartz, and Lior Wolf. 2022.

</span>
<span class="ltx_bibblock">ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic. In <em id="bib.bib62.3.1" class="ltx_emph ltx_font_italic">2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ‘22)</em>. 17897–17907.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/CVPR52688.2022.01739" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/CVPR52688.2022.01739</a>

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tonsen et al<span id="bib.bib63.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Marc Tonsen, Chris Kay Baumann, and Kai Dierkes. 2020.

</span>
<span class="ltx_bibblock">A High-Level Description and Performance Evaluation of Pupil Invisible.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2009.00508" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2009.00508</a>
arXiv:2009.00508 [cs]

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Van Swol and Kane (2019)</span>
<span class="ltx_bibblock">
Lyn M. Van Swol and Aimée A. Kane. 2019.

</span>
<span class="ltx_bibblock">Language and Group Processes: An Integrative, Interdisciplinary Review.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">Small Group Research</em> 50, 1 (Feb. 2019), 3–38.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1177/1046496418785019" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1177/1046496418785019</a>

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vinciarelli et al<span id="bib.bib65.2.2.1" class="ltx_text">.</span> (2009)</span>
<span class="ltx_bibblock">
A. Vinciarelli, A. Dielmann, S. Favre, and H. Salamin. 2009.

</span>
<span class="ltx_bibblock">Canal9: A Database of Political Debates for Analysis of Social Interactions. In <em id="bib.bib65.3.1" class="ltx_emph ltx_font_italic">2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops</em>. 1–4.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/ACII.2009.5349466" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ACII.2009.5349466</a>

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan et al<span id="bib.bib66.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Yixin Wan, George Pu, Jiao Sun, Aparna Garimella, Kai-Wei Chang, and Nanyun Peng. 2023.

</span>
<span class="ltx_bibblock">“Kelly Is a Warm Person, Joseph Is a Role Model”: Gender Biases in LLM-Generated Reference Letters. In <em id="bib.bib66.3.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, Singapore, 3730–3748.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2023.findings-emnlp.243" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2023.findings-emnlp.243</a>

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib67.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Peiyi Wang, Lei Li, Liang Chen, Zefan Cai, Dawei Zhu, Binghuai Lin, Yunbo Cao, Lingpeng Kong, Qi Liu, Tianyu Liu, and Zhifang Sui. 2024.

</span>
<span class="ltx_bibblock">Large Language Models are not Fair Evaluators. In <em id="bib.bib67.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>. Association for Computational Linguistics, Bangkok, Thailand, 9440–9450.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://aclanthology.org/2024.acl-long.511" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2024.acl-long.511</a>

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wong et al<span id="bib.bib68.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Ka Wong, Praveen Paritosh, and Lora Aroyo. 2021.

</span>
<span class="ltx_bibblock">Cross-Replication Reliability - An Empirical Approach to Interpreting Inter-rater Reliability. In <em id="bib.bib68.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli (Eds.). Association for Computational Linguistics, Online, 7053–7065.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2021.acl-long.548" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2021.acl-long.548</a>

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wuerkaixi et al<span id="bib.bib69.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Abudukelimu Wuerkaixi, Kunda Yan, You Zhang, Zhiyao Duan, and Changshui Zhang. 2022.

</span>
<span class="ltx_bibblock">DyViSE: Dynamic Vision-Guided Speaker Embedding for Audio-Visual Speaker Diarization. In <em id="bib.bib69.3.1" class="ltx_emph ltx_font_italic">2022 IEEE 24th International Workshop on Multimedia Signal Processing (MMSP ‘22)</em>. 1–6.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/MMSP55362.2022.9948860" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/MMSP55362.2022.9948860</a>

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span id="bib.bib70.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Eric Zhongcong Xu, Zeyang Song, Satoshi Tsutsui, Chao Feng, Mang Ye, and Mike Zheng Shou. 2022.

</span>
<span class="ltx_bibblock">AVA-AVD: Audio-visual Speaker Diarization in the Wild. In <em id="bib.bib70.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 30th ACM International Conference on Multimedia</em> <em id="bib.bib70.4.2" class="ltx_emph ltx_font_italic">(MM ’22)</em>. Association for Computing Machinery, New York, NY, USA, 3838–3847.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3503161.3548027" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3503161.3548027</a>

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et al<span id="bib.bib71.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Andy Zeng, Maria Attarian, Brian Ichter, Krzysztof Choromanski, Adrian Wong, Stefan Welker, Federico Tombari, Aveek Purohit, Michael Ryoo, Vikas Sindhwani, Johnny Lee, Vincent Vanhoucke, and Pete Florence. 2022.

</span>
<span class="ltx_bibblock">Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language. In <em id="bib.bib71.3.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations (ICLR ‘22)</em>.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://openreview.net/forum?id=G2Q2Mh3avow" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=G2Q2Mh3avow</a>

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao and Patras (2023)</span>
<span class="ltx_bibblock">
Zengqun Zhao and Ioannis Patras. 2023.

</span>
<span class="ltx_bibblock">Prompting Visual-Language Models for Dynamic Facial Expression Recognition. In <em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">British Machine Vision Conference (BMVC ‘23)</em>.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://papers.bmvc2023.org/0098.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://papers.bmvc2023.org/0098.pdf</a>

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span id="bib.bib73.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu, Zhengyang Qi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig, and Maarten Sap. 2024.

</span>
<span class="ltx_bibblock">SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents. In <em id="bib.bib73.3.1" class="ltx_emph ltx_font_italic">The Twelfth International Conference on Learning Representations (ICLR ‘24)</em>.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://openreview.net/forum?id=mM7VurbA4r" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=mM7VurbA4r</a>

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al<span id="bib.bib74.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Bin Zhu, Bin Lin, Munan Ning, Yang Yan, Jiaxi Cui, HongFa Wang, Yatian Pang, Wenhao Jiang, Junwu Zhang, Zongwei Li, Wancai Zhang, Zhifeng Li, Wei Liu, and Li Yuan. 2024.

</span>
<span class="ltx_bibblock">LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment. In <em id="bib.bib74.3.1" class="ltx_emph ltx_font_italic">The Twelfth International Conference on Learning Representations (ICLR ‘23)</em>.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://openreview.net/forum?id=QmZKc7UZCy" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=QmZKc7UZCy</a>

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="fig1" class="ltx_figure ltx_transformed_outer" style="width:278.7pt;height:599.1pt;vertical-align:-0.0pt;"><div class="ltx_transformed_inner" style="width:599.1pt;transform:translate(-160.2pt,-24.33pt) rotate(-90deg) ;"><figure>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Engagement Questionnaire</h2>

<div id="A1.p1" class="ltx_para ltx_noindent">
<p id="A1.p1.1" class="ltx_p">The following questionnaire was completed by each participant at the end of the recording session. Also displayed is the distribution of responses received in our participant sample; red rows indicate negatively-coded items.</p>
</div>
<div id="A1.p2" class="ltx_para ltx_noindent">
<p id="A1.p2.1" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A1.p3" class="ltx_para ltx_noindent">
<p id="A1.p3.1" class="ltx_p"><span id="A1.p3.1.1" class="ltx_text ltx_font_italic">Please use this 7-point rating scale to share your impressions of the conversation with your partner.</span></p>
</div>
<div id="A1.p4" class="ltx_para ltx_align_left ltx_align_center">
<div id="A1.p4.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:240.2pt;vertical-align:-0.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-179.7pt,99.3pt) scale(0.546814322997348,0.546814322997348) ;"><svg id="A1.p4.1.pic1" class="ltx_picture" height="606.63" overflow="visible" version="1.1" width="1088.04"><g transform="translate(0,606.63) matrix(1 0 0 -1 0 0) translate(0.56,0) translate(0,5.42)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><clipPath id="pgfcp1"><path d="M 0 0 h 1000 v 600 h -1000 Z"></path></clipPath><g clip-path="url(#pgfcp1)"><g stroke-linecap="butt" fill="#FFFFFF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="miter" stroke-width="0.0pt"><path d="M 0 0 L 1000 0 L 1000 600 L 0 600 L 0 0 Z" style="stroke:none"></path></g><g></g><g stroke-linecap="butt" fill="#FFFFFF" stroke="#000000" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="miter" stroke-opacity="0.000000" stroke-width="0.0pt"><path d="M 44.07 60 L 176.3 60 L 176.3 570 L 44.07 570 L 44.07 60 Z" style="stroke:none"></path></g><g></g><g><clipPath id="pgfcp2"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp2)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 570 L 62.96 570 L 62.96 551.11 L 44.07 551.11 L 44.07 570" style="stroke:none"></path></g></g><g><clipPath id="pgfcp3"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp3)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 570 L 81.85 570 L 81.85 551.11 L 62.96 551.11 L 62.96 570" style="stroke:none"></path></g></g><g><clipPath id="pgfcp4"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp4)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 570 L 100.74 570 L 100.74 551.11 L 81.85 551.11 L 81.85 570" style="stroke:none"></path></g></g><g><clipPath id="pgfcp5"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp5)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 570 L 119.63 570 L 119.63 551.11 L 100.74 551.11 L 100.74 570" style="stroke:none"></path></g></g><g><clipPath id="pgfcp6"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp6)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 570 L 138.52 570 L 138.52 551.11 L 119.63 551.11 L 119.63 570" style="stroke:none"></path></g></g><g><clipPath id="pgfcp7"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp7)"><g stroke-linecap="butt" fill="#1A5899" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 570 L 157.41 570 L 157.41 551.11 L 138.52 551.11 L 138.52 570" style="stroke:none"></path></g></g><g><clipPath id="pgfcp8"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp8)"><g stroke-linecap="butt" fill="#68ABD0" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 570 L 176.3 570 L 176.3 551.11 L 157.41 551.11 L 157.41 570" style="stroke:none"></path></g></g><g><clipPath id="pgfcp9"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp9)"><g stroke-linecap="butt" fill="#DF765E" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 551.11 L 62.96 551.11 L 62.96 532.22 L 44.07 532.22 L 44.07 551.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp10"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp10)"><g stroke-linecap="butt" fill="#B72230" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 551.11 L 81.85 551.11 L 81.85 532.22 L 62.96 532.22 L 62.96 551.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp11"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp11)"><g stroke-linecap="butt" fill="#FAE7DC" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 551.11 L 100.74 551.11 L 100.74 532.22 L 81.85 532.22 L 81.85 551.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp12"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp12)"><g stroke-linecap="butt" fill="#F8F2EF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 551.11 L 119.63 551.11 L 119.63 532.22 L 100.74 532.22 L 100.74 551.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp13"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp13)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 551.11 L 138.52 551.11 L 138.52 532.22 L 119.63 532.22 L 119.63 551.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp14"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp14)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 551.11 L 157.41 551.11 L 157.41 532.22 L 138.52 532.22 L 138.52 551.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp15"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp15)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 551.11 L 176.3 551.11 L 176.3 532.22 L 157.41 532.22 L 157.41 551.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp16"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp16)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 532.22 L 62.96 532.22 L 62.96 513.33 L 44.07 513.33 L 44.07 532.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp17"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp17)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 532.22 L 81.85 532.22 L 81.85 513.33 L 62.96 513.33 L 62.96 532.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp18"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp18)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 532.22 L 100.74 532.22 L 100.74 513.33 L 81.85 513.33 L 81.85 532.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp19"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp19)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 532.22 L 119.63 532.22 L 119.63 513.33 L 100.74 513.33 L 100.74 532.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp20"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp20)"><g stroke-linecap="butt" fill="#DAE9F2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 532.22 L 138.52 532.22 L 138.52 513.33 L 119.63 513.33 L 119.63 532.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp21"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp21)"><g stroke-linecap="butt" fill="#1F63A8" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 532.22 L 157.41 532.22 L 157.41 513.33 L 138.52 513.33 L 138.52 532.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp22"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp22)"><g stroke-linecap="butt" fill="#78B4D5" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 532.22 L 176.3 532.22 L 176.3 513.33 L 157.41 513.33 L 157.41 532.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp23"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp23)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 513.33 L 62.96 513.33 L 62.96 494.44 L 44.07 494.44 L 44.07 513.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp24"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp24)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 513.33 L 81.85 513.33 L 81.85 494.44 L 62.96 494.44 L 62.96 513.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp25"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp25)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 513.33 L 100.74 513.33 L 100.74 494.44 L 81.85 494.44 L 81.85 513.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp26"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp26)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 513.33 L 119.63 513.33 L 119.63 494.44 L 100.74 494.44 L 100.74 513.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp27"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp27)"><g stroke-linecap="butt" fill="#D2E6F0" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 513.33 L 138.52 513.33 L 138.52 494.44 L 119.63 494.44 L 119.63 513.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp28"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp28)"><g stroke-linecap="butt" fill="#1F63A8" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 513.33 L 157.41 513.33 L 157.41 494.44 L 138.52 494.44 L 138.52 513.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp29"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp29)"><g stroke-linecap="butt" fill="#96C7DF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 513.33 L 176.3 513.33 L 176.3 494.44 L 157.41 494.44 L 157.41 513.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp30"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp30)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 494.44 L 62.96 494.44 L 62.96 475.56 L 44.07 475.56 L 44.07 494.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp31"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp31)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 494.44 L 81.85 494.44 L 81.85 475.56 L 62.96 475.56 L 62.96 494.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp32"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp32)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 494.44 L 100.74 494.44 L 100.74 475.56 L 81.85 475.56 L 81.85 494.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp33"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp33)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 494.44 L 119.63 494.44 L 119.63 475.56 L 100.74 475.56 L 100.74 494.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp34"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp34)"><g stroke-linecap="butt" fill="#DAE9F2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 494.44 L 138.52 494.44 L 138.52 475.56 L 119.63 475.56 L 119.63 494.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp35"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp35)"><g stroke-linecap="butt" fill="#1A5899" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 494.44 L 157.41 494.44 L 157.41 475.56 L 138.52 475.56 L 138.52 494.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp36"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp36)"><g stroke-linecap="butt" fill="#96C7DF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 494.44 L 176.3 494.44 L 176.3 475.56 L 157.41 475.56 L 157.41 494.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp37"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp37)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 475.56 L 62.96 475.56 L 62.96 456.67 L 44.07 456.67 L 44.07 475.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp38"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp38)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 475.56 L 81.85 475.56 L 81.85 456.67 L 62.96 456.67 L 62.96 475.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp39"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp39)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 475.56 L 100.74 475.56 L 100.74 456.67 L 81.85 456.67 L 81.85 475.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp40"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp40)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 475.56 L 119.63 475.56 L 119.63 456.67 L 100.74 456.67 L 100.74 475.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp41"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp41)"><g stroke-linecap="butt" fill="#DAE9F2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 475.56 L 138.52 475.56 L 138.52 456.67 L 119.63 456.67 L 119.63 475.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp42"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp42)"><g stroke-linecap="butt" fill="#2C75B4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 475.56 L 157.41 475.56 L 157.41 456.67 L 138.52 456.67 L 138.52 475.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp43"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp43)"><g stroke-linecap="butt" fill="#5CA3CB" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 475.56 L 176.3 475.56 L 176.3 456.67 L 157.41 456.67 L 157.41 475.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp44"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp44)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 456.67 L 62.96 456.67 L 62.96 437.78 L 44.07 437.78 L 44.07 456.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp45"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp45)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 456.67 L 81.85 456.67 L 81.85 437.78 L 62.96 437.78 L 62.96 456.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp46"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp46)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 456.67 L 100.74 456.67 L 100.74 437.78 L 81.85 437.78 L 81.85 456.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp47"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp47)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 456.67 L 119.63 456.67 L 119.63 437.78 L 100.74 437.78 L 100.74 456.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp48"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp48)"><g stroke-linecap="butt" fill="#DAE9F2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 456.67 L 138.52 456.67 L 138.52 437.78 L 119.63 437.78 L 119.63 456.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp49"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp49)"><g stroke-linecap="butt" fill="#144E8A" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 456.67 L 157.41 456.67 L 157.41 437.78 L 138.52 437.78 L 138.52 456.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp50"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp50)"><g stroke-linecap="butt" fill="#A2CDE3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 456.67 L 176.3 456.67 L 176.3 437.78 L 157.41 437.78 L 157.41 456.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp51"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp51)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 437.78 L 62.96 437.78 L 62.96 418.89 L 44.07 418.89 L 44.07 437.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp52"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp52)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 437.78 L 81.85 437.78 L 81.85 418.89 L 62.96 418.89 L 62.96 437.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp53"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp53)"><g stroke-linecap="butt" fill="#E9F0F4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 437.78 L 100.74 437.78 L 100.74 418.89 L 81.85 418.89 L 81.85 437.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp54"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp54)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 437.78 L 119.63 437.78 L 119.63 418.89 L 100.74 418.89 L 100.74 437.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp55"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp55)"><g stroke-linecap="butt" fill="#E9F0F4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 437.78 L 138.52 437.78 L 138.52 418.89 L 119.63 418.89 L 119.63 437.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp56"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp56)"><g stroke-linecap="butt" fill="#0F437B" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 437.78 L 157.41 437.78 L 157.41 418.89 L 138.52 418.89 L 138.52 437.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp57"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp57)"><g stroke-linecap="butt" fill="#A2CDE3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 437.78 L 176.3 437.78 L 176.3 418.89 L 157.41 418.89 L 157.41 437.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp58"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp58)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 418.89 L 62.96 418.89 L 62.96 400 L 44.07 400 L 44.07 418.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp59"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp59)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 418.89 L 81.85 418.89 L 81.85 400 L 62.96 400 L 62.96 418.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp60"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp60)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 418.89 L 100.74 418.89 L 100.74 400 L 81.85 400 L 81.85 418.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp61"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp61)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 418.89 L 119.63 418.89 L 119.63 400 L 100.74 400 L 100.74 418.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp62"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp62)"><g stroke-linecap="butt" fill="#87BEDA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 418.89 L 138.52 418.89 L 138.52 400 L 119.63 400 L 119.63 418.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp63"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp63)"><g stroke-linecap="butt" fill="#78B4D5" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 418.89 L 157.41 418.89 L 157.41 400 L 138.52 400 L 138.52 418.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp64"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp64)"><g stroke-linecap="butt" fill="#5CA3CB" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 418.89 L 176.3 418.89 L 176.3 400 L 157.41 400 L 157.41 418.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp65"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp65)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 400 L 62.96 400 L 62.96 381.11 L 44.07 381.11 L 44.07 400" style="stroke:none"></path></g></g><g><clipPath id="pgfcp66"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp66)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 400 L 81.85 400 L 81.85 381.11 L 62.96 381.11 L 62.96 400" style="stroke:none"></path></g></g><g><clipPath id="pgfcp67"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp67)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 400 L 100.74 400 L 100.74 381.11 L 81.85 381.11 L 81.85 400" style="stroke:none"></path></g></g><g><clipPath id="pgfcp68"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp68)"><g stroke-linecap="butt" fill="#E9F0F4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 400 L 119.63 400 L 119.63 381.11 L 100.74 381.11 L 100.74 400" style="stroke:none"></path></g></g><g><clipPath id="pgfcp69"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp69)"><g stroke-linecap="butt" fill="#C7E0ED" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 400 L 138.52 400 L 138.52 381.11 L 119.63 381.11 L 119.63 400" style="stroke:none"></path></g></g><g><clipPath id="pgfcp70"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp70)"><g stroke-linecap="butt" fill="#4C99C6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 400 L 157.41 400 L 157.41 381.11 L 138.52 381.11 L 138.52 400" style="stroke:none"></path></g></g><g><clipPath id="pgfcp71"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp71)"><g stroke-linecap="butt" fill="#68ABD0" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 400 L 176.3 400 L 176.3 381.11 L 157.41 381.11 L 157.41 400" style="stroke:none"></path></g></g><g><clipPath id="pgfcp72"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp72)"><g stroke-linecap="butt" fill="#FAE7DC" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 381.11 L 62.96 381.11 L 62.96 362.22 L 44.07 362.22 L 44.07 381.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp73"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp73)"><g stroke-linecap="butt" fill="#F09C7B" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 381.11 L 81.85 381.11 L 81.85 362.22 L 62.96 362.22 L 62.96 381.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp74"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp74)"><g stroke-linecap="butt" fill="#FDDCC9" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 381.11 L 100.74 381.11 L 100.74 362.22 L 81.85 362.22 L 81.85 381.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp75"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp75)"><g stroke-linecap="butt" fill="#DF765E" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 381.11 L 119.63 381.11 L 119.63 362.22 L 100.74 362.22 L 100.74 381.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp76"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp76)"><g stroke-linecap="butt" fill="#F9EDE5" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 381.11 L 138.52 381.11 L 138.52 362.22 L 119.63 362.22 L 119.63 381.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp77"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp77)"><g stroke-linecap="butt" fill="#F9EDE5" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 381.11 L 157.41 381.11 L 157.41 362.22 L 138.52 362.22 L 138.52 381.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp78"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp78)"><g stroke-linecap="butt" fill="#F8F2EF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 381.11 L 176.3 381.11 L 176.3 362.22 L 157.41 362.22 L 157.41 381.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp79"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp79)"><g stroke-linecap="butt" fill="#FAC8AF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 362.22 L 62.96 362.22 L 62.96 343.33 L 44.07 343.33 L 44.07 362.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp80"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp80)"><g stroke-linecap="butt" fill="#730421" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 362.22 L 81.85 362.22 L 81.85 343.33 L 62.96 343.33 L 62.96 362.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp81"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp81)"><g stroke-linecap="butt" fill="#FDDCC9" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 362.22 L 100.74 362.22 L 100.74 343.33 L 81.85 343.33 L 81.85 362.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp82"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp82)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 362.22 L 119.63 362.22 L 119.63 343.33 L 100.74 343.33 L 100.74 362.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp83"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp83)"><g stroke-linecap="butt" fill="#F8F2EF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 362.22 L 138.52 362.22 L 138.52 343.33 L 119.63 343.33 L 119.63 362.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp84"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp84)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 362.22 L 157.41 362.22 L 157.41 343.33 L 138.52 343.33 L 138.52 362.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp85"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp85)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 362.22 L 176.3 362.22 L 176.3 343.33 L 157.41 343.33 L 157.41 362.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp86"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp86)"><g stroke-linecap="butt" fill="#FCD3BC" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 343.33 L 62.96 343.33 L 62.96 324.44 L 44.07 324.44 L 44.07 343.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp87"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp87)"><g stroke-linecap="butt" fill="#900D26" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 343.33 L 81.85 343.33 L 81.85 324.44 L 62.96 324.44 L 62.96 343.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp88"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp88)"><g stroke-linecap="butt" fill="#FCE2D2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 343.33 L 100.74 343.33 L 100.74 324.44 L 81.85 324.44 L 81.85 343.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp89"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp89)"><g stroke-linecap="butt" fill="#FAE7DC" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 343.33 L 119.63 343.33 L 119.63 324.44 L 100.74 324.44 L 100.74 343.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp90"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp90)"><g stroke-linecap="butt" fill="#F8F2EF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 343.33 L 138.52 343.33 L 138.52 324.44 L 119.63 324.44 L 119.63 343.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp91"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp91)"><g stroke-linecap="butt" fill="#F8F2EF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 343.33 L 157.41 343.33 L 157.41 324.44 L 138.52 324.44 L 138.52 343.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp92"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp92)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 343.33 L 176.3 343.33 L 176.3 324.44 L 157.41 324.44 L 157.41 343.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp93"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp93)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 324.44 L 62.96 324.44 L 62.96 305.56 L 44.07 305.56 L 44.07 324.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp94"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp94)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 324.44 L 81.85 324.44 L 81.85 305.56 L 62.96 305.56 L 62.96 324.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp95"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp95)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 324.44 L 100.74 324.44 L 100.74 305.56 L 81.85 305.56 L 81.85 324.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp96"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp96)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 324.44 L 119.63 324.44 L 119.63 305.56 L 100.74 305.56 L 100.74 324.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp97"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp97)"><g stroke-linecap="butt" fill="#C7E0ED" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 324.44 L 138.52 324.44 L 138.52 305.56 L 119.63 305.56 L 119.63 324.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp98"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp98)"><g stroke-linecap="butt" fill="#266CAF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 324.44 L 157.41 324.44 L 157.41 305.56 L 138.52 305.56 L 138.52 324.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp99"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp99)"><g stroke-linecap="butt" fill="#96C7DF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 324.44 L 176.3 324.44 L 176.3 305.56 L 157.41 305.56 L 157.41 324.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp100"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp100)"><g stroke-linecap="butt" fill="#FCE2D2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 305.56 L 62.96 305.56 L 62.96 286.67 L 44.07 286.67 L 44.07 305.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp101"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp101)"><g stroke-linecap="butt" fill="#730421" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 305.56 L 81.85 305.56 L 81.85 286.67 L 62.96 286.67 L 62.96 305.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp102"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp102)"><g stroke-linecap="butt" fill="#F9EDE5" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 305.56 L 100.74 305.56 L 100.74 286.67 L 81.85 286.67 L 81.85 305.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp103"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp103)"><g stroke-linecap="butt" fill="#FAE7DC" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 305.56 L 119.63 305.56 L 119.63 286.67 L 100.74 286.67 L 100.74 305.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp104"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp104)"><g stroke-linecap="butt" fill="#F9EDE5" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 305.56 L 138.52 305.56 L 138.52 286.67 L 119.63 286.67 L 119.63 305.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp105"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp105)"><g stroke-linecap="butt" fill="#F8F2EF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 305.56 L 157.41 305.56 L 157.41 286.67 L 138.52 286.67 L 138.52 305.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp106"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp106)"><g stroke-linecap="butt" fill="#F8F2EF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 305.56 L 176.3 305.56 L 176.3 286.67 L 157.41 286.67 L 157.41 305.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp107"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp107)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 286.67 L 62.96 286.67 L 62.96 267.78 L 44.07 267.78 L 44.07 286.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp108"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp108)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 286.67 L 81.85 286.67 L 81.85 267.78 L 62.96 267.78 L 62.96 286.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp109"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp109)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 286.67 L 100.74 286.67 L 100.74 267.78 L 81.85 267.78 L 81.85 286.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp110"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp110)"><g stroke-linecap="butt" fill="#E9F0F4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 286.67 L 119.63 286.67 L 119.63 267.78 L 100.74 267.78 L 100.74 286.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp111"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp111)"><g stroke-linecap="butt" fill="#78B4D5" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 286.67 L 138.52 286.67 L 138.52 267.78 L 119.63 267.78 L 119.63 286.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp112"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp112)"><g stroke-linecap="butt" fill="#408FC1" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 286.67 L 157.41 286.67 L 157.41 267.78 L 138.52 267.78 L 138.52 286.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp113"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp113)"><g stroke-linecap="butt" fill="#BBDAEA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 286.67 L 176.3 286.67 L 176.3 267.78 L 157.41 267.78 L 157.41 286.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp114"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp114)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 267.78 L 62.96 267.78 L 62.96 248.89 L 44.07 248.89 L 44.07 267.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp115"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp115)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 267.78 L 81.85 267.78 L 81.85 248.89 L 62.96 248.89 L 62.96 267.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp116"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp116)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 267.78 L 100.74 267.78 L 100.74 248.89 L 81.85 248.89 L 81.85 267.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp117"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp117)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 267.78 L 119.63 267.78 L 119.63 248.89 L 100.74 248.89 L 100.74 267.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp118"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp118)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 267.78 L 138.52 267.78 L 138.52 248.89 L 119.63 248.89 L 119.63 267.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp119"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp119)"><g stroke-linecap="butt" fill="#68ABD0" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 267.78 L 157.41 267.78 L 157.41 248.89 L 138.52 248.89 L 138.52 267.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp120"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp120)"><g stroke-linecap="butt" fill="#144E8A" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 267.78 L 176.3 267.78 L 176.3 248.89 L 157.41 248.89 L 157.41 267.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp121"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp121)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 248.89 L 62.96 248.89 L 62.96 230 L 44.07 230 L 44.07 248.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp122"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp122)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 248.89 L 81.85 248.89 L 81.85 230 L 62.96 230 L 62.96 248.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp123"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp123)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 248.89 L 100.74 248.89 L 100.74 230 L 81.85 230 L 81.85 248.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp124"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp124)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 248.89 L 119.63 248.89 L 119.63 230 L 100.74 230 L 100.74 248.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp125"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp125)"><g stroke-linecap="butt" fill="#DAE9F2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 248.89 L 138.52 248.89 L 138.52 230 L 119.63 230 L 119.63 248.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp126"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp126)"><g stroke-linecap="butt" fill="#266CAF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 248.89 L 157.41 248.89 L 157.41 230 L 138.52 230 L 138.52 248.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp127"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp127)"><g stroke-linecap="butt" fill="#68ABD0" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 248.89 L 176.3 248.89 L 176.3 230 L 157.41 230 L 157.41 248.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp128"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp128)"><g stroke-linecap="butt" fill="#FDDCC9" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 230 L 62.96 230 L 62.96 211.11 L 44.07 211.11 L 44.07 230" style="stroke:none"></path></g></g><g><clipPath id="pgfcp129"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp129)"><g stroke-linecap="butt" fill="#E58368" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 230 L 81.85 230 L 81.85 211.11 L 62.96 211.11 L 62.96 230" style="stroke:none"></path></g></g><g><clipPath id="pgfcp130"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp130)"><g stroke-linecap="butt" fill="#F8BDA1" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 230 L 100.74 230 L 100.74 211.11 L 81.85 211.11 L 81.85 230" style="stroke:none"></path></g></g><g><clipPath id="pgfcp131"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp131)"><g stroke-linecap="butt" fill="#FAC8AF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 230 L 119.63 230 L 119.63 211.11 L 100.74 211.11 L 100.74 230" style="stroke:none"></path></g></g><g><clipPath id="pgfcp132"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp132)"><g stroke-linecap="butt" fill="#FAE7DC" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 230 L 138.52 230 L 138.52 211.11 L 119.63 211.11 L 119.63 230" style="stroke:none"></path></g></g><g><clipPath id="pgfcp133"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp133)"><g stroke-linecap="butt" fill="#F9EDE5" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 230 L 157.41 230 L 157.41 211.11 L 138.52 211.11 L 138.52 230" style="stroke:none"></path></g></g><g><clipPath id="pgfcp134"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp134)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 230 L 176.3 230 L 176.3 211.11 L 157.41 211.11 L 157.41 230" style="stroke:none"></path></g></g><g><clipPath id="pgfcp135"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp135)"><g stroke-linecap="butt" fill="#67001F" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 211.11 L 62.96 211.11 L 62.96 192.22 L 44.07 192.22 L 44.07 211.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp136"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp136)"><g stroke-linecap="butt" fill="#F6B394" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 211.11 L 81.85 211.11 L 81.85 192.22 L 62.96 192.22 L 62.96 211.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp137"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp137)"><g stroke-linecap="butt" fill="#F9EDE5" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 211.11 L 100.74 211.11 L 100.74 192.22 L 81.85 192.22 L 81.85 211.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp138"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp138)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 211.11 L 119.63 211.11 L 119.63 192.22 L 100.74 192.22 L 100.74 211.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp139"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp139)"><g stroke-linecap="butt" fill="#F8F2EF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 211.11 L 138.52 211.11 L 138.52 192.22 L 119.63 192.22 L 119.63 211.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp140"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp140)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 211.11 L 157.41 211.11 L 157.41 192.22 L 138.52 192.22 L 138.52 211.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp141"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp141)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 211.11 L 176.3 211.11 L 176.3 192.22 L 157.41 192.22 L 157.41 211.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp142"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp142)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 192.22 L 62.96 192.22 L 62.96 173.33 L 44.07 173.33 L 44.07 192.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp143"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp143)"><g stroke-linecap="butt" fill="#E1EDF3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 192.22 L 81.85 192.22 L 81.85 173.33 L 62.96 173.33 L 62.96 192.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp144"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp144)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 192.22 L 100.74 192.22 L 100.74 173.33 L 81.85 173.33 L 81.85 192.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp145"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp145)"><g stroke-linecap="butt" fill="#D2E6F0" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 192.22 L 119.63 192.22 L 119.63 173.33 L 100.74 173.33 L 100.74 192.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp146"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp146)"><g stroke-linecap="butt" fill="#96C7DF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 192.22 L 138.52 192.22 L 138.52 173.33 L 119.63 173.33 L 119.63 192.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp147"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp147)"><g stroke-linecap="butt" fill="#337EB8" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 192.22 L 157.41 192.22 L 157.41 173.33 L 138.52 173.33 L 138.52 192.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp148"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp148)"><g stroke-linecap="butt" fill="#E9F0F4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 192.22 L 176.3 192.22 L 176.3 173.33 L 157.41 173.33 L 157.41 192.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp149"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp149)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 173.33 L 62.96 173.33 L 62.96 154.44 L 44.07 154.44 L 44.07 173.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp150"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp150)"><g stroke-linecap="butt" fill="#DAE9F2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 173.33 L 81.85 173.33 L 81.85 154.44 L 62.96 154.44 L 62.96 173.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp151"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp151)"><g stroke-linecap="butt" fill="#D2E6F0" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 173.33 L 100.74 173.33 L 100.74 154.44 L 81.85 154.44 L 81.85 173.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp152"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp152)"><g stroke-linecap="butt" fill="#C7E0ED" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 173.33 L 119.63 173.33 L 119.63 154.44 L 100.74 154.44 L 100.74 173.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp153"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp153)"><g stroke-linecap="butt" fill="#AED3E6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 173.33 L 138.52 173.33 L 138.52 154.44 L 119.63 154.44 L 119.63 173.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp154"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp154)"><g stroke-linecap="butt" fill="#87BEDA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 173.33 L 157.41 173.33 L 157.41 154.44 L 138.52 154.44 L 138.52 173.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp155"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp155)"><g stroke-linecap="butt" fill="#E1EDF3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 173.33 L 176.3 173.33 L 176.3 154.44 L 157.41 154.44 L 157.41 173.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp156"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp156)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 154.44 L 62.96 154.44 L 62.96 135.56 L 44.07 135.56 L 44.07 154.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp157"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp157)"><g stroke-linecap="butt" fill="#E1EDF3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 154.44 L 81.85 154.44 L 81.85 135.56 L 62.96 135.56 L 62.96 154.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp158"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp158)"><g stroke-linecap="butt" fill="#C7E0ED" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 154.44 L 100.74 154.44 L 100.74 135.56 L 81.85 135.56 L 81.85 154.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp159"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp159)"><g stroke-linecap="butt" fill="#BBDAEA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 154.44 L 119.63 154.44 L 119.63 135.56 L 100.74 135.56 L 100.74 154.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp160"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp160)"><g stroke-linecap="butt" fill="#BBDAEA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 154.44 L 138.52 154.44 L 138.52 135.56 L 119.63 135.56 L 119.63 154.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp161"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp161)"><g stroke-linecap="butt" fill="#A2CDE3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 154.44 L 157.41 154.44 L 157.41 135.56 L 138.52 135.56 L 138.52 154.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp162"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp162)"><g stroke-linecap="butt" fill="#D2E6F0" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 154.44 L 176.3 154.44 L 176.3 135.56 L 157.41 135.56 L 157.41 154.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp163"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp163)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 135.56 L 62.96 135.56 L 62.96 116.67 L 44.07 116.67 L 44.07 135.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp164"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp164)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 135.56 L 81.85 135.56 L 81.85 116.67 L 62.96 116.67 L 62.96 135.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp165"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp165)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 135.56 L 100.74 135.56 L 100.74 116.67 L 81.85 116.67 L 81.85 135.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp166"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp166)"><g stroke-linecap="butt" fill="#E9F0F4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 135.56 L 119.63 135.56 L 119.63 116.67 L 100.74 116.67 L 100.74 135.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp167"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp167)"><g stroke-linecap="butt" fill="#D2E6F0" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 135.56 L 138.52 135.56 L 138.52 116.67 L 119.63 116.67 L 119.63 135.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp168"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp168)"><g stroke-linecap="butt" fill="#266CAF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 135.56 L 157.41 135.56 L 157.41 116.67 L 138.52 116.67 L 138.52 135.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp169"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp169)"><g stroke-linecap="butt" fill="#96C7DF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 135.56 L 176.3 135.56 L 176.3 116.67 L 157.41 116.67 L 157.41 135.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp170"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp170)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 116.67 L 62.96 116.67 L 62.96 97.78 L 44.07 97.78 L 44.07 116.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp171"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp171)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 116.67 L 81.85 116.67 L 81.85 97.78 L 62.96 97.78 L 62.96 116.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp172"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp172)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 116.67 L 100.74 116.67 L 100.74 97.78 L 81.85 97.78 L 81.85 116.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp173"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp173)"><g stroke-linecap="butt" fill="#E9F0F4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 116.67 L 119.63 116.67 L 119.63 97.78 L 100.74 97.78 L 100.74 116.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp174"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp174)"><g stroke-linecap="butt" fill="#BBDAEA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 116.67 L 138.52 116.67 L 138.52 97.78 L 119.63 97.78 L 119.63 116.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp175"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp175)"><g stroke-linecap="butt" fill="#1F63A8" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 116.67 L 157.41 116.67 L 157.41 97.78 L 138.52 97.78 L 138.52 116.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp176"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp176)"><g stroke-linecap="butt" fill="#BBDAEA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 116.67 L 176.3 116.67 L 176.3 97.78 L 157.41 97.78 L 157.41 116.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp177"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp177)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 97.78 L 62.96 97.78 L 62.96 78.89 L 44.07 78.89 L 44.07 97.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp178"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp178)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 97.78 L 81.85 97.78 L 81.85 78.89 L 62.96 78.89 L 62.96 97.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp179"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp179)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 97.78 L 100.74 97.78 L 100.74 78.89 L 81.85 78.89 L 81.85 97.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp180"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp180)"><g stroke-linecap="butt" fill="#A2CDE3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 97.78 L 119.63 97.78 L 119.63 78.89 L 100.74 78.89 L 100.74 97.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp181"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp181)"><g stroke-linecap="butt" fill="#BBDAEA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 97.78 L 138.52 97.78 L 138.52 78.89 L 119.63 78.89 L 119.63 97.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp182"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp182)"><g stroke-linecap="butt" fill="#5CA3CB" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 97.78 L 157.41 97.78 L 157.41 78.89 L 138.52 78.89 L 138.52 97.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp183"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp183)"><g stroke-linecap="butt" fill="#C7E0ED" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 97.78 L 176.3 97.78 L 176.3 78.89 L 157.41 78.89 L 157.41 97.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp184"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp184)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 44.07 78.89 L 62.96 78.89 L 62.96 60 L 44.07 60 L 44.07 78.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp185"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp185)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 62.96 78.89 L 81.85 78.89 L 81.85 60 L 62.96 60 L 62.96 78.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp186"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp186)"><g stroke-linecap="butt" fill="#E1EDF3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 81.85 78.89 L 100.74 78.89 L 100.74 60 L 81.85 60 L 81.85 78.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp187"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp187)"><g stroke-linecap="butt" fill="#DAE9F2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 100.74 78.89 L 119.63 78.89 L 119.63 60 L 100.74 60 L 100.74 78.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp188"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp188)"><g stroke-linecap="butt" fill="#96C7DF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 119.63 78.89 L 138.52 78.89 L 138.52 60 L 119.63 60 L 119.63 78.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp189"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp189)"><g stroke-linecap="butt" fill="#78B4D5" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 138.52 78.89 L 157.41 78.89 L 157.41 60 L 138.52 60 L 138.52 78.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp190"><path d="M 44.07 60 h 132.22 v 510 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp190)"><g stroke-linecap="butt" fill="#AED3E6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 157.41 78.89 L 176.3 78.89 L 176.3 60 L 157.41 60 L 157.41 78.89" style="stroke:none"></path></g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 23.57 591.6)"><foreignObject width="51.16" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.3.3.3.3.1.1" class="ltx_text" style="color:#000000;">Strongly</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 23.48 581.61)"><foreignObject width="51.43" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.4.4.4.4.1.1" class="ltx_text" style="color:#000000;">Disagree</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 155.8 591.6)"><foreignObject width="51.16" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.5.5.5.5.1.1" class="ltx_text" style="color:#000000;">Strongly</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 162.32 581.61)"><foreignObject width="35.02" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.6.6.6.6.1.1" class="ltx_text" style="color:#000000;">Agree</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 557.18)"><foreignObject width="292.81" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.7.7.7.7.1.1" class="ltx_text" style="color:#000000;">1. I found this to be an interesting conversation.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 538.29)"><foreignObject width="218.47" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.8.8.8.8.1.1" class="ltx_text" style="color:#000000;">2. My partner interrupted me often.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 519.4)"><foreignObject width="260.33" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.9.9.9.9.1.1" class="ltx_text" style="color:#000000;">3. I found the conversation to be engaging.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 500.51)"><foreignObject width="356.26" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.10.10.10.10.1.1" class="ltx_text" style="color:#000000;">4. There was a natural back-and-forth in our conversation.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 481.62)"><foreignObject width="296.07" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.11.11.11.11.1.1" class="ltx_text" style="color:#000000;">5. I might like to get to know my partner better.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 462.74)"><foreignObject width="223.43" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.12.12.12.12.1.1" class="ltx_text" style="color:#000000;">6. My partner and I tended to agree.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 448.17)"><foreignObject width="377.71" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.13.13.13.13.1.1" class="ltx_text" style="color:#000000;">7. I would be interested to have another conversation with my</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 438.18)"><foreignObject width="48.51" height="11.2" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.14.14.14.14.1.1" class="ltx_text" style="color:#000000;">partner.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 424.96)"><foreignObject width="408.04" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.15.15.15.15.1.1" class="ltx_text" style="color:#000000;">8. My partner tended to make eye contact during the conversation.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 406.07)"><foreignObject width="314.98" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.16.16.16.16.1.1" class="ltx_text" style="color:#000000;">9. My partner and I laughed during our interaction.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 391.5)"><foreignObject width="354.69" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.17.17.17.17.1.1" class="ltx_text" style="color:#000000;">10. I would sign up to have another conversation with this</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 381.51)"><foreignObject width="48.51" height="11.2" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.18.18.18.18.1.1" class="ltx_text" style="color:#000000;">partner.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 372.61)"><foreignObject width="341.97" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.19.19.19.19.1.1" class="ltx_text" style="color:#000000;">11. If I participated in this study again, I would prefer a</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 362.62)"><foreignObject width="183.57" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.20.20.20.20.1.1" class="ltx_text" style="color:#000000;">different conversation partner.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 349.4)"><foreignObject width="251.22" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.21.21.21.21.1.1" class="ltx_text" style="color:#000000;">12. My partner and I seemed out of sync.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 330.51)"><foreignObject width="280.43" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.22.22.22.22.1.1" class="ltx_text" style="color:#000000;">13. I struggled to keep the conversation going.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 311.62)"><foreignObject width="292.69" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.23.23.23.23.1.1" class="ltx_text" style="color:#000000;">14. I found this to be an enjoyable conversation.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 292.74)"><foreignObject width="262.1" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.24.24.24.24.1.1" class="ltx_text" style="color:#000000;">15. This conversation was awkward for me.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 273.85)"><foreignObject width="297.27" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.25.25.25.25.1.1" class="ltx_text" style="color:#000000;">16. I generally enjoy conversing with new people.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 254.96)"><foreignObject width="333.01" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.26.26.26.26.1.1" class="ltx_text" style="color:#000000;">17. I am leaving with a positive opinion of my partner.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 236.07)"><foreignObject width="185.45" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.27.27.27.27.1.1" class="ltx_text" style="color:#000000;">18. Conversation flowed easily.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 221.5)"><foreignObject width="387.24" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.28.28.28.28.1.1" class="ltx_text" style="color:#000000;">19. I think my partner and I would tend to disagree on political</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 211.51)"><foreignObject width="102.55" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.29.29.29.29.1.1" class="ltx_text" style="color:#000000;">and social issues.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 202.61)"><foreignObject width="368.14" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.30.30.30.30.1.1" class="ltx_text" style="color:#000000;">20. I became irritated with my partner at some points in the</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 192.62)"><foreignObject width="79.29" height="9.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.31.31.31.31.1.1" class="ltx_text" style="color:#000000;">conversation.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 179.4)"><foreignObject width="340.35" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.32.32.32.32.1.1" class="ltx_text" style="color:#000000;">21. I think my partner might get along with my friends.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 164.83)"><foreignObject width="362.61" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.33.33.33.33.1.1" class="ltx_text" style="color:#000000;">22. If I were organizing a large gathering, I would invite my</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 154.84)"><foreignObject width="48.51" height="11.2" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.34.34.34.34.1.1" class="ltx_text" style="color:#000000;">partner.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 145.95)"><foreignObject width="412.88" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.35.35.35.35.1.1" class="ltx_text" style="color:#000000;">23. I would share my email address with my partner so we can keep</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 135.95)"><foreignObject width="53.81" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.36.36.36.36.1.1" class="ltx_text" style="color:#000000;">in touch.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 122.74)"><foreignObject width="383.05" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.37.37.37.37.1.1" class="ltx_text" style="color:#000000;">24. If my partner texted me later, I would be likely to respond.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 103.85)"><foreignObject width="236.57" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.38.38.38.38.1.1" class="ltx_text" style="color:#000000;">25. I found this conversation to be fun.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 84.96)"><foreignObject width="233.88" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.39.39.39.39.1.1" class="ltx_text" style="color:#000000;">26. I felt like I could trust my partner.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 186.02 66.07)"><foreignObject width="353.88" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.40.40.40.40.1.1" class="ltx_text" style="color:#000000;">27. I would introduce my conversation partner to a friend.</span></foreignObject></g><g></g><g stroke-linecap="butt" fill="#FFFFFF" stroke="#000000" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="miter" stroke-opacity="0.000000" stroke-width="0.0pt"><path d="M 544.07 78.89 L 676.3 78.89 L 676.3 570 L 544.07 570 L 544.07 78.89 Z" style="stroke:none"></path></g><g></g><g><clipPath id="pgfcp191"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp191)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 570 L 562.96 570 L 562.96 551.11 L 544.07 551.11 L 544.07 570" style="stroke:none"></path></g></g><g><clipPath id="pgfcp192"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp192)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 570 L 581.85 570 L 581.85 551.11 L 562.96 551.11 L 562.96 570" style="stroke:none"></path></g></g><g><clipPath id="pgfcp193"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp193)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 570 L 600.74 570 L 600.74 551.11 L 581.85 551.11 L 581.85 570" style="stroke:none"></path></g></g><g><clipPath id="pgfcp194"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp194)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 570 L 619.63 570 L 619.63 551.11 L 600.74 551.11 L 600.74 570" style="stroke:none"></path></g></g><g><clipPath id="pgfcp195"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp195)"><g stroke-linecap="butt" fill="#E9F0F4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 570 L 638.52 570 L 638.52 551.11 L 619.63 551.11 L 619.63 570" style="stroke:none"></path></g></g><g><clipPath id="pgfcp196"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp196)"><g stroke-linecap="butt" fill="#144E8A" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 570 L 657.41 570 L 657.41 551.11 L 638.52 551.11 L 638.52 570" style="stroke:none"></path></g></g><g><clipPath id="pgfcp197"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp197)"><g stroke-linecap="butt" fill="#78B4D5" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 570 L 676.3 570 L 676.3 551.11 L 657.41 551.11 L 657.41 570" style="stroke:none"></path></g></g><g><clipPath id="pgfcp198"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp198)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 551.11 L 562.96 551.11 L 562.96 532.22 L 544.07 532.22 L 544.07 551.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp199"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp199)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 551.11 L 581.85 551.11 L 581.85 532.22 L 562.96 532.22 L 562.96 551.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp200"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp200)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 551.11 L 600.74 551.11 L 600.74 532.22 L 581.85 532.22 L 581.85 551.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp201"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp201)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 551.11 L 619.63 551.11 L 619.63 532.22 L 600.74 532.22 L 600.74 551.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp202"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp202)"><g stroke-linecap="butt" fill="#BBDAEA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 551.11 L 638.52 551.11 L 638.52 532.22 L 619.63 532.22 L 619.63 551.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp203"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp203)"><g stroke-linecap="butt" fill="#337EB8" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 551.11 L 657.41 551.11 L 657.41 532.22 L 638.52 532.22 L 638.52 551.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp204"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp204)"><g stroke-linecap="butt" fill="#68ABD0" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 551.11 L 676.3 551.11 L 676.3 532.22 L 657.41 532.22 L 657.41 551.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp205"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp205)"><g stroke-linecap="butt" fill="#FAE7DC" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 532.22 L 562.96 532.22 L 562.96 513.33 L 544.07 513.33 L 544.07 532.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp206"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp206)"><g stroke-linecap="butt" fill="#B72230" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 532.22 L 581.85 532.22 L 581.85 513.33 L 562.96 513.33 L 562.96 532.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp207"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp207)"><g stroke-linecap="butt" fill="#FCD3BC" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 532.22 L 600.74 532.22 L 600.74 513.33 L 581.85 513.33 L 581.85 532.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp208"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp208)"><g stroke-linecap="butt" fill="#FDDCC9" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 532.22 L 619.63 532.22 L 619.63 513.33 L 600.74 513.33 L 600.74 532.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp209"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp209)"><g stroke-linecap="butt" fill="#F8F2EF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 532.22 L 638.52 532.22 L 638.52 513.33 L 619.63 513.33 L 619.63 532.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp210"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp210)"><g stroke-linecap="butt" fill="#FAE7DC" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 532.22 L 657.41 532.22 L 657.41 513.33 L 638.52 513.33 L 638.52 532.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp211"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp211)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 532.22 L 676.3 532.22 L 676.3 513.33 L 657.41 513.33 L 657.41 532.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp212"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp212)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 513.33 L 562.96 513.33 L 562.96 494.44 L 544.07 494.44 L 544.07 513.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp213"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp213)"><g stroke-linecap="butt" fill="#E9F0F4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 513.33 L 581.85 513.33 L 581.85 494.44 L 562.96 494.44 L 562.96 513.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp214"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp214)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 513.33 L 600.74 513.33 L 600.74 494.44 L 581.85 494.44 L 581.85 513.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp215"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp215)"><g stroke-linecap="butt" fill="#DAE9F2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 513.33 L 619.63 513.33 L 619.63 494.44 L 600.74 494.44 L 600.74 513.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp216"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp216)"><g stroke-linecap="butt" fill="#AED3E6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 513.33 L 638.52 513.33 L 638.52 494.44 L 619.63 494.44 L 619.63 513.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp217"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp217)"><g stroke-linecap="butt" fill="#266CAF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 513.33 L 657.41 513.33 L 657.41 494.44 L 638.52 494.44 L 638.52 513.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp218"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp218)"><g stroke-linecap="butt" fill="#E1EDF3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 513.33 L 676.3 513.33 L 676.3 494.44 L 657.41 494.44 L 657.41 513.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp219"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp219)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 494.44 L 562.96 494.44 L 562.96 475.56 L 544.07 475.56 L 544.07 494.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp220"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp220)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 494.44 L 581.85 494.44 L 581.85 475.56 L 562.96 475.56 L 562.96 494.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp221"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp221)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 494.44 L 600.74 494.44 L 600.74 475.56 L 581.85 475.56 L 581.85 494.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp222"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp222)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 494.44 L 619.63 494.44 L 619.63 475.56 L 600.74 475.56 L 600.74 494.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp223"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp223)"><g stroke-linecap="butt" fill="#E1EDF3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 494.44 L 638.52 494.44 L 638.52 475.56 L 619.63 475.56 L 619.63 494.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp224"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp224)"><g stroke-linecap="butt" fill="#1A5899" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 494.44 L 657.41 494.44 L 657.41 475.56 L 638.52 475.56 L 638.52 494.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp225"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp225)"><g stroke-linecap="butt" fill="#68ABD0" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 494.44 L 676.3 494.44 L 676.3 475.56 L 657.41 475.56 L 657.41 494.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp226"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp226)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 475.56 L 562.96 475.56 L 562.96 456.67 L 544.07 456.67 L 544.07 475.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp227"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp227)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 475.56 L 581.85 475.56 L 581.85 456.67 L 562.96 456.67 L 562.96 475.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp228"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp228)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 475.56 L 600.74 475.56 L 600.74 456.67 L 581.85 456.67 L 581.85 475.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp229"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp229)"><g stroke-linecap="butt" fill="#D2E6F0" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 475.56 L 619.63 475.56 L 619.63 456.67 L 600.74 456.67 L 600.74 475.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp230"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp230)"><g stroke-linecap="butt" fill="#C7E0ED" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 475.56 L 638.52 475.56 L 638.52 456.67 L 619.63 456.67 L 619.63 475.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp231"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp231)"><g stroke-linecap="butt" fill="#2C75B4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 475.56 L 657.41 475.56 L 657.41 456.67 L 638.52 456.67 L 638.52 475.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp232"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp232)"><g stroke-linecap="butt" fill="#BBDAEA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 475.56 L 676.3 475.56 L 676.3 456.67 L 657.41 456.67 L 657.41 475.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp233"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp233)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 456.67 L 562.96 456.67 L 562.96 437.78 L 544.07 437.78 L 544.07 456.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp234"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp234)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 456.67 L 581.85 456.67 L 581.85 437.78 L 562.96 437.78 L 562.96 456.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp235"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp235)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 456.67 L 600.74 456.67 L 600.74 437.78 L 581.85 437.78 L 581.85 456.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp236"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp236)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 456.67 L 619.63 456.67 L 619.63 437.78 L 600.74 437.78 L 600.74 456.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp237"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp237)"><g stroke-linecap="butt" fill="#BBDAEA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 456.67 L 638.52 456.67 L 638.52 437.78 L 619.63 437.78 L 619.63 456.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp238"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp238)"><g stroke-linecap="butt" fill="#266CAF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 456.67 L 657.41 456.67 L 657.41 437.78 L 638.52 437.78 L 638.52 456.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp239"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp239)"><g stroke-linecap="butt" fill="#96C7DF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 456.67 L 676.3 456.67 L 676.3 437.78 L 657.41 437.78 L 657.41 456.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp240"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp240)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 437.78 L 562.96 437.78 L 562.96 418.89 L 544.07 418.89 L 544.07 437.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp241"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp241)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 437.78 L 581.85 437.78 L 581.85 418.89 L 562.96 418.89 L 562.96 437.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp242"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp242)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 437.78 L 600.74 437.78 L 600.74 418.89 L 581.85 418.89 L 581.85 437.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp243"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp243)"><g stroke-linecap="butt" fill="#C7E0ED" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 437.78 L 619.63 437.78 L 619.63 418.89 L 600.74 418.89 L 600.74 437.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp244"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp244)"><g stroke-linecap="butt" fill="#BBDAEA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 437.78 L 638.52 437.78 L 638.52 418.89 L 619.63 418.89 L 619.63 437.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp245"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp245)"><g stroke-linecap="butt" fill="#2C75B4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 437.78 L 657.41 437.78 L 657.41 418.89 L 638.52 418.89 L 638.52 437.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp246"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp246)"><g stroke-linecap="butt" fill="#D2E6F0" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 437.78 L 676.3 437.78 L 676.3 418.89 L 657.41 418.89 L 657.41 437.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp247"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp247)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 418.89 L 562.96 418.89 L 562.96 400 L 544.07 400 L 544.07 418.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp248"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp248)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 418.89 L 581.85 418.89 L 581.85 400 L 562.96 400 L 562.96 418.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp249"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp249)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 418.89 L 600.74 418.89 L 600.74 400 L 581.85 400 L 581.85 418.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp250"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp250)"><g stroke-linecap="butt" fill="#AED3E6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 418.89 L 619.63 418.89 L 619.63 400 L 600.74 400 L 600.74 418.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp251"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp251)"><g stroke-linecap="butt" fill="#A2CDE3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 418.89 L 638.52 418.89 L 638.52 400 L 619.63 400 L 619.63 418.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp252"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp252)"><g stroke-linecap="butt" fill="#3A87BD" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 418.89 L 657.41 418.89 L 657.41 400 L 638.52 400 L 638.52 418.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp253"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp253)"><g stroke-linecap="butt" fill="#E1EDF3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 418.89 L 676.3 418.89 L 676.3 400 L 657.41 400 L 657.41 418.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp254"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp254)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 400 L 562.96 400 L 562.96 381.11 L 544.07 381.11 L 544.07 400" style="stroke:none"></path></g></g><g><clipPath id="pgfcp255"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp255)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 400 L 581.85 400 L 581.85 381.11 L 562.96 381.11 L 562.96 400" style="stroke:none"></path></g></g><g><clipPath id="pgfcp256"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp256)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 400 L 600.74 400 L 600.74 381.11 L 581.85 381.11 L 581.85 400" style="stroke:none"></path></g></g><g><clipPath id="pgfcp257"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp257)"><g stroke-linecap="butt" fill="#E1EDF3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 400 L 619.63 400 L 619.63 381.11 L 600.74 381.11 L 600.74 400" style="stroke:none"></path></g></g><g><clipPath id="pgfcp258"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp258)"><g stroke-linecap="butt" fill="#D2E6F0" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 400 L 638.52 400 L 638.52 381.11 L 619.63 381.11 L 619.63 400" style="stroke:none"></path></g></g><g><clipPath id="pgfcp259"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp259)"><g stroke-linecap="butt" fill="#1A5899" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 400 L 657.41 400 L 657.41 381.11 L 638.52 381.11 L 638.52 400" style="stroke:none"></path></g></g><g><clipPath id="pgfcp260"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp260)"><g stroke-linecap="butt" fill="#BBDAEA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 400 L 676.3 400 L 676.3 381.11 L 657.41 381.11 L 657.41 400" style="stroke:none"></path></g></g><g><clipPath id="pgfcp261"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp261)"><g stroke-linecap="butt" fill="#E9F0F4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 381.11 L 562.96 381.11 L 562.96 362.22 L 544.07 362.22 L 544.07 381.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp262"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp262)"><g stroke-linecap="butt" fill="#BBDAEA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 381.11 L 581.85 381.11 L 581.85 362.22 L 562.96 362.22 L 562.96 381.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp263"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp263)"><g stroke-linecap="butt" fill="#C7E0ED" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 381.11 L 600.74 381.11 L 600.74 362.22 L 581.85 362.22 L 581.85 381.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp264"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp264)"><g stroke-linecap="butt" fill="#96C7DF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 381.11 L 619.63 381.11 L 619.63 362.22 L 600.74 362.22 L 600.74 381.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp265"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp265)"><g stroke-linecap="butt" fill="#C7E0ED" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 381.11 L 638.52 381.11 L 638.52 362.22 L 619.63 362.22 L 619.63 381.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp266"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp266)"><g stroke-linecap="butt" fill="#E1EDF3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 381.11 L 657.41 381.11 L 657.41 362.22 L 638.52 362.22 L 638.52 381.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp267"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp267)"><g stroke-linecap="butt" fill="#DAE9F2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 381.11 L 676.3 381.11 L 676.3 362.22 L 657.41 362.22 L 657.41 381.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp268"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp268)"><g stroke-linecap="butt" fill="#CC4C44" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 362.22 L 562.96 362.22 L 562.96 343.33 L 544.07 343.33 L 544.07 362.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp269"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp269)"><g stroke-linecap="butt" fill="#CC4C44" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 362.22 L 581.85 362.22 L 581.85 343.33 L 562.96 343.33 L 562.96 362.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp270"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp270)"><g stroke-linecap="butt" fill="#FCE2D2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 362.22 L 600.74 362.22 L 600.74 343.33 L 581.85 343.33 L 581.85 362.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp271"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp271)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 362.22 L 619.63 362.22 L 619.63 343.33 L 600.74 343.33 L 600.74 362.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp272"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp272)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 362.22 L 638.52 362.22 L 638.52 343.33 L 619.63 343.33 L 619.63 362.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp273"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp273)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 362.22 L 657.41 362.22 L 657.41 343.33 L 638.52 343.33 L 638.52 362.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp274"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp274)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 362.22 L 676.3 362.22 L 676.3 343.33 L 657.41 343.33 L 657.41 362.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp275"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp275)"><g stroke-linecap="butt" fill="#E9F0F4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 343.33 L 562.96 343.33 L 562.96 324.44 L 544.07 324.44 L 544.07 343.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp276"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp276)"><g stroke-linecap="butt" fill="#E9F0F4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 343.33 L 581.85 343.33 L 581.85 324.44 L 562.96 324.44 L 562.96 343.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp277"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp277)"><g stroke-linecap="butt" fill="#D2E6F0" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 343.33 L 600.74 343.33 L 600.74 324.44 L 581.85 324.44 L 581.85 343.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp278"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp278)"><g stroke-linecap="butt" fill="#DAE9F2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 343.33 L 619.63 343.33 L 619.63 324.44 L 600.74 324.44 L 600.74 343.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp279"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp279)"><g stroke-linecap="butt" fill="#78B4D5" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 343.33 L 638.52 343.33 L 638.52 324.44 L 619.63 324.44 L 619.63 343.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp280"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp280)"><g stroke-linecap="butt" fill="#96C7DF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 343.33 L 657.41 343.33 L 657.41 324.44 L 638.52 324.44 L 638.52 343.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp281"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp281)"><g stroke-linecap="butt" fill="#E1EDF3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 343.33 L 676.3 343.33 L 676.3 324.44 L 657.41 324.44 L 657.41 343.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp282"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp282)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 324.44 L 562.96 324.44 L 562.96 305.56 L 544.07 305.56 L 544.07 324.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp283"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp283)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 324.44 L 581.85 324.44 L 581.85 305.56 L 562.96 305.56 L 562.96 324.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp284"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp284)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 324.44 L 600.74 324.44 L 600.74 305.56 L 581.85 305.56 L 581.85 324.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp285"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp285)"><g stroke-linecap="butt" fill="#E9F0F4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 324.44 L 619.63 324.44 L 619.63 305.56 L 600.74 305.56 L 600.74 324.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp286"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp286)"><g stroke-linecap="butt" fill="#DAE9F2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 324.44 L 638.52 324.44 L 638.52 305.56 L 619.63 305.56 L 619.63 324.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp287"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp287)"><g stroke-linecap="butt" fill="#1A5899" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 324.44 L 657.41 324.44 L 657.41 305.56 L 638.52 305.56 L 638.52 324.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp288"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp288)"><g stroke-linecap="butt" fill="#A2CDE3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 324.44 L 676.3 324.44 L 676.3 305.56 L 657.41 305.56 L 657.41 324.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp289"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp289)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 305.56 L 562.96 305.56 L 562.96 286.67 L 544.07 286.67 L 544.07 305.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp290"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp290)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 305.56 L 581.85 305.56 L 581.85 286.67 L 562.96 286.67 L 562.96 305.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp291"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp291)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 305.56 L 600.74 305.56 L 600.74 286.67 L 581.85 286.67 L 581.85 305.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp292"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp292)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 305.56 L 619.63 305.56 L 619.63 286.67 L 600.74 286.67 L 600.74 305.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp293"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp293)"><g stroke-linecap="butt" fill="#E1EDF3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 305.56 L 638.52 305.56 L 638.52 286.67 L 619.63 286.67 L 619.63 305.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp294"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp294)"><g stroke-linecap="butt" fill="#1A5899" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 305.56 L 657.41 305.56 L 657.41 286.67 L 638.52 286.67 L 638.52 305.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp295"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp295)"><g stroke-linecap="butt" fill="#78B4D5" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 305.56 L 676.3 305.56 L 676.3 286.67 L 657.41 286.67 L 657.41 305.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp296"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp296)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 286.67 L 562.96 286.67 L 562.96 267.78 L 544.07 267.78 L 544.07 286.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp297"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp297)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 286.67 L 581.85 286.67 L 581.85 267.78 L 562.96 267.78 L 562.96 286.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp298"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp298)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 286.67 L 600.74 286.67 L 600.74 267.78 L 581.85 267.78 L 581.85 286.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp299"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp299)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 286.67 L 619.63 286.67 L 619.63 267.78 L 600.74 267.78 L 600.74 286.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp300"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp300)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 286.67 L 638.52 286.67 L 638.52 267.78 L 619.63 267.78 L 619.63 286.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp301"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp301)"><g stroke-linecap="butt" fill="#0F437B" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 286.67 L 657.41 286.67 L 657.41 267.78 L 638.52 267.78 L 638.52 286.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp302"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp302)"><g stroke-linecap="butt" fill="#87BEDA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 286.67 L 676.3 286.67 L 676.3 267.78 L 657.41 267.78 L 657.41 286.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp303"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp303)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 267.78 L 562.96 267.78 L 562.96 248.89 L 544.07 248.89 L 544.07 267.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp304"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp304)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 267.78 L 581.85 267.78 L 581.85 248.89 L 562.96 248.89 L 562.96 267.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp305"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp305)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 267.78 L 600.74 267.78 L 600.74 248.89 L 581.85 248.89 L 581.85 267.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp306"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp306)"><g stroke-linecap="butt" fill="#96C7DF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 267.78 L 619.63 267.78 L 619.63 248.89 L 600.74 248.89 L 600.74 267.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp307"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp307)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 267.78 L 638.52 267.78 L 638.52 248.89 L 619.63 248.89 L 619.63 267.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp308"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp308)"><g stroke-linecap="butt" fill="#144E8A" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 267.78 L 657.41 267.78 L 657.41 248.89 L 638.52 248.89 L 638.52 267.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp309"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp309)"><g stroke-linecap="butt" fill="#D2E6F0" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 267.78 L 676.3 267.78 L 676.3 248.89 L 657.41 248.89 L 657.41 267.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp310"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp310)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 248.89 L 562.96 248.89 L 562.96 230 L 544.07 230 L 544.07 248.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp311"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp311)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 248.89 L 581.85 248.89 L 581.85 230 L 562.96 230 L 562.96 248.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp312"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp312)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 248.89 L 600.74 248.89 L 600.74 230 L 581.85 230 L 581.85 248.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp313"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp313)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 248.89 L 619.63 248.89 L 619.63 230 L 600.74 230 L 600.74 248.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp314"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp314)"><g stroke-linecap="butt" fill="#96C7DF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 248.89 L 638.52 248.89 L 638.52 230 L 619.63 230 L 619.63 248.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp315"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp315)"><g stroke-linecap="butt" fill="#2C75B4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 248.89 L 657.41 248.89 L 657.41 230 L 638.52 230 L 638.52 248.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp316"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp316)"><g stroke-linecap="butt" fill="#BBDAEA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 248.89 L 676.3 248.89 L 676.3 230 L 657.41 230 L 657.41 248.89" style="stroke:none"></path></g></g><g><clipPath id="pgfcp317"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp317)"><g stroke-linecap="butt" fill="#FAC8AF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 230 L 562.96 230 L 562.96 211.11 L 544.07 211.11 L 544.07 230" style="stroke:none"></path></g></g><g><clipPath id="pgfcp318"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp318)"><g stroke-linecap="butt" fill="#900D26" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 230 L 581.85 230 L 581.85 211.11 L 562.96 211.11 L 562.96 230" style="stroke:none"></path></g></g><g><clipPath id="pgfcp319"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp319)"><g stroke-linecap="butt" fill="#FCD3BC" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 230 L 600.74 230 L 600.74 211.11 L 581.85 211.11 L 581.85 230" style="stroke:none"></path></g></g><g><clipPath id="pgfcp320"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp320)"><g stroke-linecap="butt" fill="#F8F2EF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 230 L 619.63 230 L 619.63 211.11 L 600.74 211.11 L 600.74 230" style="stroke:none"></path></g></g><g><clipPath id="pgfcp321"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp321)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 230 L 638.52 230 L 638.52 211.11 L 619.63 211.11 L 619.63 230" style="stroke:none"></path></g></g><g><clipPath id="pgfcp322"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp322)"><g stroke-linecap="butt" fill="#F8F2EF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 230 L 657.41 230 L 657.41 211.11 L 638.52 211.11 L 638.52 230" style="stroke:none"></path></g></g><g><clipPath id="pgfcp323"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp323)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 230 L 676.3 230 L 676.3 211.11 L 657.41 211.11 L 657.41 230" style="stroke:none"></path></g></g><g><clipPath id="pgfcp324"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp324)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 211.11 L 562.96 211.11 L 562.96 192.22 L 544.07 192.22 L 544.07 211.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp325"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp325)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 211.11 L 581.85 211.11 L 581.85 192.22 L 562.96 192.22 L 562.96 211.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp326"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp326)"><g stroke-linecap="butt" fill="#E1EDF3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 211.11 L 600.74 211.11 L 600.74 192.22 L 581.85 192.22 L 581.85 211.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp327"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp327)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 211.11 L 619.63 211.11 L 619.63 192.22 L 600.74 192.22 L 600.74 211.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp328"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp328)"><g stroke-linecap="butt" fill="#DAE9F2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 211.11 L 638.52 211.11 L 638.52 192.22 L 619.63 192.22 L 619.63 211.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp329"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp329)"><g stroke-linecap="butt" fill="#1A5899" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 211.11 L 657.41 211.11 L 657.41 192.22 L 638.52 192.22 L 638.52 211.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp330"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp330)"><g stroke-linecap="butt" fill="#BBDAEA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 211.11 L 676.3 211.11 L 676.3 192.22 L 657.41 192.22 L 657.41 211.11" style="stroke:none"></path></g></g><g><clipPath id="pgfcp331"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp331)"><g stroke-linecap="butt" fill="#FCD3BC" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 192.22 L 562.96 192.22 L 562.96 173.33 L 544.07 173.33 L 544.07 192.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp332"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp332)"><g stroke-linecap="butt" fill="#900D26" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 192.22 L 581.85 192.22 L 581.85 173.33 L 562.96 173.33 L 562.96 192.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp333"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp333)"><g stroke-linecap="butt" fill="#FCD3BC" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 192.22 L 600.74 192.22 L 600.74 173.33 L 581.85 173.33 L 581.85 192.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp334"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp334)"><g stroke-linecap="butt" fill="#F9EDE5" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 192.22 L 619.63 192.22 L 619.63 173.33 L 600.74 173.33 L 600.74 192.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp335"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp335)"><g stroke-linecap="butt" fill="#F8F2EF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 192.22 L 638.52 192.22 L 638.52 173.33 L 619.63 173.33 L 619.63 192.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp336"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp336)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 192.22 L 657.41 192.22 L 657.41 173.33 L 638.52 173.33 L 638.52 192.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp337"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp337)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 192.22 L 676.3 192.22 L 676.3 173.33 L 657.41 173.33 L 657.41 192.22" style="stroke:none"></path></g></g><g><clipPath id="pgfcp338"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp338)"><g stroke-linecap="butt" fill="#BBDAEA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 173.33 L 562.96 173.33 L 562.96 154.44 L 544.07 154.44 L 544.07 173.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp339"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp339)"><g stroke-linecap="butt" fill="#337EB8" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 173.33 L 581.85 173.33 L 581.85 154.44 L 562.96 154.44 L 562.96 173.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp340"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp340)"><g stroke-linecap="butt" fill="#E1EDF3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 173.33 L 600.74 173.33 L 600.74 154.44 L 581.85 154.44 L 581.85 173.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp341"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp341)"><g stroke-linecap="butt" fill="#BBDAEA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 173.33 L 619.63 173.33 L 619.63 154.44 L 600.74 154.44 L 600.74 173.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp342"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp342)"><g stroke-linecap="butt" fill="#E9F0F4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 173.33 L 638.52 173.33 L 638.52 154.44 L 619.63 154.44 L 619.63 173.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp343"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp343)"><g stroke-linecap="butt" fill="#F0F4F6" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 173.33 L 657.41 173.33 L 657.41 154.44 L 638.52 154.44 L 638.52 173.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp344"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp344)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 173.33 L 676.3 173.33 L 676.3 154.44 L 657.41 154.44 L 657.41 173.33" style="stroke:none"></path></g></g><g><clipPath id="pgfcp345"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp345)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 154.44 L 562.96 154.44 L 562.96 135.56 L 544.07 135.56 L 544.07 154.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp346"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp346)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 154.44 L 581.85 154.44 L 581.85 135.56 L 562.96 135.56 L 562.96 154.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp347"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp347)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 154.44 L 600.74 154.44 L 600.74 135.56 L 581.85 135.56 L 581.85 154.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp348"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp348)"><g stroke-linecap="butt" fill="#E9F0F4" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 154.44 L 619.63 154.44 L 619.63 135.56 L 600.74 135.56 L 600.74 154.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp349"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp349)"><g stroke-linecap="butt" fill="#A2CDE3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 154.44 L 638.52 154.44 L 638.52 135.56 L 619.63 135.56 L 619.63 154.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp350"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp350)"><g stroke-linecap="butt" fill="#266CAF" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 154.44 L 657.41 154.44 L 657.41 135.56 L 638.52 135.56 L 638.52 154.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp351"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp351)"><g stroke-linecap="butt" fill="#BBDAEA" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 154.44 L 676.3 154.44 L 676.3 135.56 L 657.41 135.56 L 657.41 154.44" style="stroke:none"></path></g></g><g><clipPath id="pgfcp352"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp352)"><g stroke-linecap="butt" fill="#FCE2D2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 135.56 L 562.96 135.56 L 562.96 116.67 L 544.07 116.67 L 544.07 135.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp353"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp353)"><g stroke-linecap="butt" fill="#AE172A" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 135.56 L 581.85 135.56 L 581.85 116.67 L 562.96 116.67 L 562.96 135.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp354"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp354)"><g stroke-linecap="butt" fill="#FDDCC9" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 135.56 L 600.74 135.56 L 600.74 116.67 L 581.85 116.67 L 581.85 135.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp355"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp355)"><g stroke-linecap="butt" fill="#FCE2D2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 135.56 L 619.63 135.56 L 619.63 116.67 L 600.74 116.67 L 600.74 135.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp356"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp356)"><g stroke-linecap="butt" fill="#F9EDE5" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 135.56 L 638.52 135.56 L 638.52 116.67 L 619.63 116.67 L 619.63 135.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp357"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp357)"><g stroke-linecap="butt" fill="#F9EDE5" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 135.56 L 657.41 135.56 L 657.41 116.67 L 638.52 116.67 L 638.52 135.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp358"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp358)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 135.56 L 676.3 135.56 L 676.3 116.67 L 657.41 116.67 L 657.41 135.56" style="stroke:none"></path></g></g><g><clipPath id="pgfcp359"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp359)"><g stroke-linecap="butt" fill="#F8BDA1" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 116.67 L 562.96 116.67 L 562.96 97.78 L 544.07 97.78 L 544.07 116.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp360"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp360)"><g stroke-linecap="butt" fill="#AE172A" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 116.67 L 581.85 116.67 L 581.85 97.78 L 562.96 97.78 L 562.96 116.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp361"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp361)"><g stroke-linecap="butt" fill="#FCE2D2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 116.67 L 600.74 116.67 L 600.74 97.78 L 581.85 97.78 L 581.85 116.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp362"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp362)"><g stroke-linecap="butt" fill="#F9EDE5" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 116.67 L 619.63 116.67 L 619.63 97.78 L 600.74 97.78 L 600.74 116.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp363"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp363)"><g stroke-linecap="butt" fill="#FAE7DC" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 116.67 L 638.52 116.67 L 638.52 97.78 L 619.63 97.78 L 619.63 116.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp364"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp364)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 116.67 L 657.41 116.67 L 657.41 97.78 L 638.52 97.78 L 638.52 116.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp365"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp365)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 116.67 L 676.3 116.67 L 676.3 97.78 L 657.41 97.78 L 657.41 116.67" style="stroke:none"></path></g></g><g><clipPath id="pgfcp366"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp366)"><g stroke-linecap="butt" fill="#F6F7F7" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 544.07 97.78 L 562.96 97.78 L 562.96 78.89 L 544.07 78.89 L 544.07 97.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp367"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp367)"><g stroke-linecap="butt" fill="#E1EDF3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 562.96 97.78 L 581.85 97.78 L 581.85 78.89 L 562.96 78.89 L 562.96 97.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp368"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp368)"><g stroke-linecap="butt" fill="#E1EDF3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 581.85 97.78 L 600.74 97.78 L 600.74 78.89 L 581.85 78.89 L 581.85 97.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp369"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp369)"><g stroke-linecap="butt" fill="#E1EDF3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 600.74 97.78 L 619.63 97.78 L 619.63 78.89 L 600.74 78.89 L 600.74 97.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp370"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp370)"><g stroke-linecap="butt" fill="#A2CDE3" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 619.63 97.78 L 638.52 97.78 L 638.52 78.89 L 619.63 78.89 L 619.63 97.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp371"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp371)"><g stroke-linecap="butt" fill="#408FC1" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 638.52 97.78 L 657.41 97.78 L 657.41 78.89 L 638.52 78.89 L 638.52 97.78" style="stroke:none"></path></g></g><g><clipPath id="pgfcp372"><path d="M 544.07 78.89 h 132.22 v 491.11 h -132.22 Z"></path></clipPath></g><g clip-path="url(#pgfcp372)"><g stroke-linecap="butt" fill="#DAE9F2" stroke="#FFFFFF" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.0pt"><path d="M 657.41 97.78 L 676.3 97.78 L 676.3 78.89 L 657.41 78.89 L 657.41 97.78" style="stroke:none"></path></g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 523.57 591.6)"><foreignObject width="51.16" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.41.41.41.41.1.1" class="ltx_text" style="color:#000000;">Strongly</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 523.48 581.61)"><foreignObject width="51.43" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.42.42.42.42.1.1" class="ltx_text" style="color:#000000;">Disagree</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 655.8 591.6)"><foreignObject width="51.16" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.43.43.43.43.1.1" class="ltx_text" style="color:#000000;">Strongly</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 662.32 581.61)"><foreignObject width="35.02" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.44.44.44.44.1.1" class="ltx_text" style="color:#000000;">Agree</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 557.18)"><foreignObject width="216.32" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.45.45.45.45.1.1" class="ltx_text" style="color:#000000;">28. My partner asked me questions.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 538.29)"><foreignObject width="331.55" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.46.46.46.46.1.1" class="ltx_text" style="color:#000000;">29. I feel like I learned about my conversation partner.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 519.4)"><foreignObject width="322.29" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.47.47.47.47.1.1" class="ltx_text" style="color:#000000;">30. My partner tended to dominate the conversation.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 500.51)"><foreignObject width="210.09" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.48.48.48.48.1.1" class="ltx_text" style="color:#000000;">31. My partner seemed inquisitive.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 481.62)"><foreignObject width="215.51" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.49.49.49.49.1.1" class="ltx_text" style="color:#000000;">32. My partner was a good listener.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 462.74)"><foreignObject width="401.85" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.50.50.50.50.1.1" class="ltx_text" style="color:#000000;">33. I think there was a mutual liking between my partner and me.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 443.85)"><foreignObject width="319.14" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.51.51.51.51.1.1" class="ltx_text" style="color:#000000;">34. I feel confident that we had a good conversation.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 424.96)"><foreignObject width="389.78" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.52.52.52.52.1.1" class="ltx_text" style="color:#000000;">35. I think my conversation partner appreciated me as a person.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 406.07)"><foreignObject width="273.2" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.53.53.53.53.1.1" class="ltx_text" style="color:#000000;">36. I felt trust with my conversation partner.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 387.18)"><foreignObject width="381.33" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.54.54.54.54.1.1" class="ltx_text" style="color:#000000;">37. I established a good rapport with my conversation partner.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 372.61)"><foreignObject width="341.01" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.55.55.55.55.1.1" class="ltx_text" style="color:#000000;">38. I would trust my conversation partner with sensitive</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 362.62)"><foreignObject width="74.22" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.56.56.56.56.1.1" class="ltx_text" style="color:#000000;">information.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 349.4)"><foreignObject width="276.32" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.57.57.57.57.1.1" class="ltx_text" style="color:#000000;">39. My conversation partner seemed irritable.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 330.51)"><foreignObject width="259.71" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.58.58.58.58.1.1" class="ltx_text" style="color:#000000;">40. My conversation partner was talkative.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 311.62)"><foreignObject width="342.5" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.59.59.59.59.1.1" class="ltx_text" style="color:#000000;">41. My conversation partner seemed like a warm person.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 292.74)"><foreignObject width="315.02" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.60.60.60.60.1.1" class="ltx_text" style="color:#000000;">42. I felt comfortable with my conversation partner.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 273.85)"><foreignObject width="361.61" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.61.61.61.61.1.1" class="ltx_text" style="color:#000000;">43. I felt like my conversation partner really listened to me.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 259.28)"><foreignObject width="380.44" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.62.62.62.62.1.1" class="ltx_text" style="color:#000000;">44. My conversation partner appreciated my points, even if we</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 249.29)"><foreignObject width="60.08" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.63.63.63.63.1.1" class="ltx_text" style="color:#000000;">disagreed.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 236.07)"><foreignObject width="371.64" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.64.64.64.64.1.1" class="ltx_text" style="color:#000000;">45. My conversation partner seemed to enjoy our interaction.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 217.18)"><foreignObject width="260.52" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.65.65.65.65.1.1" class="ltx_text" style="color:#000000;">46. My conversation partner was awkward.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 198.29)"><foreignObject width="333.43" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.66.66.66.66.1.1" class="ltx_text" style="color:#000000;">47. My conversation partner made a lot of eye contact.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 179.4)"><foreignObject width="273.63" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.67.67.67.67.1.1" class="ltx_text" style="color:#000000;">48. My conversation partner seemed anxious.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 160.51)"><foreignObject width="292.92" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.68.68.68.68.1.1" class="ltx_text" style="color:#000000;">49. My conversation partner was quite sensitive.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 141.62)"><foreignObject width="373.95" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.69.69.69.69.1.1" class="ltx_text" style="color:#000000;">50. My conversation partner seemed relaxed and comfortable.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 122.74)"><foreignObject width="347.77" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.70.70.70.70.1.1" class="ltx_text" style="color:#000000;">51. My conversation partner dominated the conversation.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 103.85)"><foreignObject width="364.22" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.71.71.71.71.1.1" class="ltx_text" style="color:#000000;">52. My conversation partner was reserved and unexpressive.</span></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 686.02 84.96)"><foreignObject width="349.08" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.72.72.72.72.1.1" class="ltx_text" style="color:#000000;">53. My conversation partner shared personal information.</span></foreignObject></g><g></g><g stroke-linecap="butt" fill="#FFFFFF" stroke="#000000" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="miter" stroke-opacity="0.000000" stroke-width="0.0pt"><path d="M 250 27 L 750 27 L 750 36 L 250 36 L 250 27 Z" style="stroke:none"></path></g><g></g><g transform="matrix(1.0 0.0 0.0 1.0 250 27) matrix(1.0 0.0 0.0 1.0 0 0)"><foreignObject width="499" height="9" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2409.09135/assets/fig/engagement_questionnaire/engagement_questionnaire-img0.png" id="A1.p4.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="499" height="9" alt="[Uncaptioned image]"></foreignObject></g><g></g><g stroke-linecap="butt" fill="#000000" stroke="#000000" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.803pt" transform="matrix(1.0 0.0 0.0 1.0 250 27)"><path d="M 0 0 L 0 -4.86"></path></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 246.54 8.36)"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.73.73.73.73.1.1" class="ltx_text" style="color:#000000;">0</span></foreignObject></g><g></g><g stroke-linecap="butt" fill="#000000" stroke="#000000" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.803pt" transform="matrix(1.0 0.0 0.0 1.0 346.15 27)"><path d="M 0 0 L 0 -4.86"></path></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 342.69 8.36)"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.74.74.74.74.1.1" class="ltx_text" style="color:#000000;">5</span></foreignObject></g><g></g><g stroke-linecap="butt" fill="#000000" stroke="#000000" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.803pt" transform="matrix(1.0 0.0 0.0 1.0 442.31 27)"><path d="M 0 0 L 0 -4.86"></path></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 435.39 8.36)"><foreignObject width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.75.75.75.75.1.1" class="ltx_text" style="color:#000000;">10</span></foreignObject></g><g></g><g stroke-linecap="butt" fill="#000000" stroke="#000000" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.803pt" transform="matrix(1.0 0.0 0.0 1.0 538.46 27)"><path d="M 0 0 L 0 -4.86"></path></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 531.54 8.36)"><foreignObject width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.76.76.76.76.1.1" class="ltx_text" style="color:#000000;">15</span></foreignObject></g><g></g><g stroke-linecap="butt" fill="#000000" stroke="#000000" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.803pt" transform="matrix(1.0 0.0 0.0 1.0 634.62 27)"><path d="M 0 0 L 0 -4.86"></path></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 627.7 8.36)"><foreignObject width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.77.77.77.77.1.1" class="ltx_text" style="color:#000000;">20</span></foreignObject></g><g></g><g stroke-linecap="butt" fill="#000000" stroke="#000000" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="round" stroke-width="0.803pt" transform="matrix(1.0 0.0 0.0 1.0 730.77 27)"><path d="M 0 0 L 0 -4.86"></path></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 723.85 8.36)"><foreignObject width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.78.78.78.78.1.1" class="ltx_text" style="color:#000000;">25</span></foreignObject></g><g></g><g stroke-linecap="rect" stroke="#000000" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="miter" stroke-width="0.803pt"><path d="M 250 27 L 250 31.5 L 250 36 L 750 36 L 750 31.5 L 750 27 L 250 27 Z" style="fill:none"></path></g><g></g><g stroke-linecap="butt" fill="#FFFFFF" stroke="#000000" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="miter" stroke-opacity="0.000000" stroke-width="0.0pt"><path d="M 250 36 L 750 36 L 750 45 L 250 45 L 250 36 Z" style="stroke:none"></path></g><g></g><g transform="matrix(1.0 0.0 0.0 1.0 250 36) matrix(1.0 0.0 0.0 1.0 0 0)"><foreignObject width="499" height="9" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2409.09135/assets/fig/engagement_questionnaire/engagement_questionnaire-img1.png" id="A1.p4.1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="499" height="9" alt="[Uncaptioned image]"></foreignObject></g><g></g><g stroke="#000000" fill="#000000" transform="matrix(1.0 0.0 0.0 1.0 438.79 50.56)"><foreignObject width="123.19" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A1.p4.1.pic1.79.79.79.79.1.1" class="ltx_text" style="color:#000000;">Response Frequency</span></foreignObject></g><g></g><g stroke-linecap="rect" stroke="#000000" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="miter" stroke-width="0.803pt"><path d="M 250 36 L 250 40.5 L 250 45 L 750 45 L 750 40.5 L 750 36 L 250 36 Z" style="fill:none"></path></g><g></g></g></g></svg>
</span></div>
</div>
</section>
</figure></div></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>LLM Fusion: Valence Prediction</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">One of the experiments described in <a href="#S6.SS2" title="6.2 LLM Fusion ‣ 6 Experiments ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Section 6.2</span></a> involves an evaluation of the LLM’s ability to predict response valence rather than exact answers. Results for model <span id="A2.p1.1.1" class="ltx_text ltx_font_bold">4S</span>, using raw transcripts and the participant personal characteristics, are presented in <a href="#A2.T3" title="Table 3 ‣ Appendix B LLM Fusion: Valence Prediction ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 3</span></a>.</p>
</div>
<figure id="A2.T3" class="ltx_table">
<table id="A2.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A2.T3.1.1.1" class="ltx_tr">
<th id="A2.T3.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_rr"></th>
<th id="A2.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="5"><span id="A2.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">Predicted</span></th>
</tr>
<tr id="A2.T3.1.2.2" class="ltx_tr">
<th id="A2.T3.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_t"><span id="A2.T3.1.2.2.1.1" class="ltx_text ltx_font_bold">Actual</span></th>
<th id="A2.T3.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="A2.T3.1.2.2.2.1" class="ltx_text ltx_font_bold">Agr.</span></th>
<th id="A2.T3.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="A2.T3.1.2.2.3.1" class="ltx_text ltx_font_bold">Neu.</span></th>
<th id="A2.T3.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="A2.T3.1.2.2.4.1" class="ltx_text ltx_font_bold">Dis.</span></th>
<th id="A2.T3.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="A2.T3.1.2.2.5.1" class="ltx_text ltx_font_bold">All</span></th>
<th id="A2.T3.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="A2.T3.1.2.2.6.1" class="ltx_text ltx_font_bold">Cl. Acc.</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A2.T3.1.3.1" class="ltx_tr">
<th id="A2.T3.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t"><span id="A2.T3.1.3.1.1.1" class="ltx_text ltx_font_bold">Agr.</span></th>
<td id="A2.T3.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t">1072</td>
<td id="A2.T3.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">44</td>
<td id="A2.T3.1.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">52</td>
<td id="A2.T3.1.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1168</td>
<td id="A2.T3.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">91.8</td>
</tr>
<tr id="A2.T3.1.4.2" class="ltx_tr">
<th id="A2.T3.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr"><span id="A2.T3.1.4.2.1.1" class="ltx_text ltx_font_bold">Neu.</span></th>
<td id="A2.T3.1.4.2.2" class="ltx_td ltx_align_center">91</td>
<td id="A2.T3.1.4.2.3" class="ltx_td ltx_align_center">18</td>
<td id="A2.T3.1.4.2.4" class="ltx_td ltx_align_center ltx_border_r">33</td>
<td id="A2.T3.1.4.2.5" class="ltx_td ltx_align_center ltx_border_r">142</td>
<td id="A2.T3.1.4.2.6" class="ltx_td ltx_align_center">12.7</td>
</tr>
<tr id="A2.T3.1.5.3" class="ltx_tr">
<th id="A2.T3.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr"><span id="A2.T3.1.5.3.1.1" class="ltx_text ltx_font_bold">Dis.</span></th>
<td id="A2.T3.1.5.3.2" class="ltx_td ltx_align_center">105</td>
<td id="A2.T3.1.5.3.3" class="ltx_td ltx_align_center">62</td>
<td id="A2.T3.1.5.3.4" class="ltx_td ltx_align_center ltx_border_r">325</td>
<td id="A2.T3.1.5.3.5" class="ltx_td ltx_align_center ltx_border_r">492</td>
<td id="A2.T3.1.5.3.6" class="ltx_td ltx_align_center">66.1</td>
</tr>
<tr id="A2.T3.1.6.4" class="ltx_tr">
<th id="A2.T3.1.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr ltx_border_t"><span id="A2.T3.1.6.4.1.1" class="ltx_text ltx_font_bold">All</span></th>
<td id="A2.T3.1.6.4.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">1268</td>
<td id="A2.T3.1.6.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">124</td>
<td id="A2.T3.1.6.4.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">410</td>
<td id="A2.T3.1.6.4.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">1802</td>
<td id="A2.T3.1.6.4.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">56.9</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>4S Valence Prediction Confusion Matrix: Responses are categorized as (Dis)agree (1–3), (Neu)tral (4), or (Agr)ee (5–7). Class accuracy is also reported.</figcaption>
</figure>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>LLM Fusion: Non-Numeric Responses </h2>

<div id="A3.p1" class="ltx_para ltx_noindent">
<p id="A3.p1.1" class="ltx_p">There were 80 cases across all ablation experiments where the first generated token returned by the LLM was non-numeric (<math id="A3.p1.1.m1.1" class="ltx_Math" alttext="1.1\%" display="inline"><semantics id="A3.p1.1.m1.1a"><mrow id="A3.p1.1.m1.1.1" xref="A3.p1.1.m1.1.1.cmml"><mn id="A3.p1.1.m1.1.1.2" xref="A3.p1.1.m1.1.1.2.cmml">1.1</mn><mo id="A3.p1.1.m1.1.1.1" xref="A3.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.p1.1.m1.1b"><apply id="A3.p1.1.m1.1.1.cmml" xref="A3.p1.1.m1.1.1"><csymbol cd="latexml" id="A3.p1.1.m1.1.1.1.cmml" xref="A3.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="A3.p1.1.m1.1.1.2.cmml" xref="A3.p1.1.m1.1.1.2">1.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.1.m1.1c">1.1\%</annotation></semantics></math> of all responses). For 57 of these questions, <span id="A3.p1.1.1" class="ltx_text ltx_font_typewriter">GPT-4</span> declined to respond because it was prompted to answer questions that referenced modalities not explicitly provided in the ablation feature sets. Sample responses are included below for illustration.</p>
</div>
<div id="A3.p2" class="ltx_para ltx_noindent">
<p id="A3.p2.1" class="ltx_p">Q8: <em id="A3.p2.1.1" class="ltx_emph ltx_font_italic">My partner tended to make eye contact during the conversation.</em></p>
<ul id="A3.I1" class="ltx_itemize">
<li id="A3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A3.I1.i1.p1" class="ltx_para">
<p id="A3.I1.i1.p1.1" class="ltx_p">“<span id="A3.I1.i1.p1.1.1" class="ltx_text ltx_font_typewriter">As an AI, I don’t have the ability to make or observe eye contact.</span>”</p>
</div>
</li>
<li id="A3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A3.I1.i2.p1" class="ltx_para">
<p id="A3.I1.i2.p1.1" class="ltx_p">“<span id="A3.I1.i2.p1.1.1" class="ltx_text ltx_font_typewriter">As this conversation was text-based and not in person, I cannot accurately rate my partner’s tendency to make eye contact. Therefore, I would rate it as N/A.</span>”</p>
</div>
</li>
<li id="A3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A3.I1.i3.p1" class="ltx_para ltx_noindent">
<p id="A3.I1.i3.p1.1" class="ltx_p">“<span id="A3.I1.i3.p1.1.1" class="ltx_text ltx_font_typewriter">As this conversation was text-based and didn’t involve any form of video or face-to-face interaction, I cannot rate my partner’s eye contact. Therefore, I would rate it as N/A.</span>”</p>
</div>
</li>
</ul>
<p id="A3.p2.2" class="ltx_p">Q47: <em id="A3.p2.2.1" class="ltx_emph ltx_font_italic">My conversation partner made a lot of eye contact.</em></p>
<ul id="A3.I2" class="ltx_itemize">
<li id="A3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A3.I2.i1.p1" class="ltx_para">
<p id="A3.I2.i1.p1.1" class="ltx_p">“<span id="A3.I2.i1.p1.1.1" class="ltx_text ltx_font_typewriter">As an AI, I don’t have the ability to make or perceive eye contact. Therefore, I can’t provide a rating for this statement.</span>”</p>
</div>
</li>
<li id="A3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A3.I2.i2.p1" class="ltx_para">
<p id="A3.I2.i2.p1.1" class="ltx_p">“<span id="A3.I2.i2.p1.1.1" class="ltx_text ltx_font_typewriter">As an AI, I don’t have the ability to make or perceive eye contact. Therefore, I would rate this statement as 1, strongly disagree.</span>”</p>
</div>
</li>
<li id="A3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A3.I2.i3.p1" class="ltx_para ltx_noindent">
<p id="A3.I2.i3.p1.1" class="ltx_p">“<span id="A3.I2.i3.p1.1.1" class="ltx_text ltx_font_typewriter">Given the nature of the conversation, it’s hard to determine the level of eye contact as it was a text-based interaction. However, if we consider the level of engagement and attentiveness as a form of "eye contact" in this context, I</span>” [<em id="A3.I2.i3.p1.1.2" class="ltx_emph ltx_font_italic">text cut off</em>]</p>
</div>
</li>
</ul>
</div>
<figure id="A3.T4" class="ltx_table">
<table id="A3.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A3.T4.1.1.1" class="ltx_tr">
<th id="A3.T4.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_t"></th>
<th id="A3.T4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Token</th>
<th id="A3.T4.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Prob.</th>
<th id="A3.T4.1.1.1.4" class="ltx_td ltx_th ltx_th_column"></th>
<th id="A3.T4.1.1.1.5" class="ltx_td ltx_nopad_l ltx_th ltx_th_column ltx_border_t"></th>
<th id="A3.T4.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Token</th>
<th id="A3.T4.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Prob.</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A3.T4.1.2.1" class="ltx_tr">
<td id="A3.T4.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="A3.T4.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A3.T4.1.2.1.2.1" class="ltx_text ltx_font_typewriter">As</span></td>
<td id="A3.T4.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">0.316</td>
<td id="A3.T4.1.2.1.4" class="ltx_td"></td>
<td id="A3.T4.1.2.1.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">11</td>
<td id="A3.T4.1.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A3.T4.1.2.1.6.1" class="ltx_text ltx_font_typewriter">Sorry</span></td>
<td id="A3.T4.1.2.1.7" class="ltx_td ltx_align_center ltx_border_t">0.002</td>
</tr>
<tr id="A3.T4.1.3.2" class="ltx_tr">
<td id="A3.T4.1.3.2.1" class="ltx_td ltx_align_center">2</td>
<td id="A3.T4.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T4.1.3.2.2.1" class="ltx_text ltx_font_typewriter">[</span></td>
<td id="A3.T4.1.3.2.3" class="ltx_td ltx_align_center">0.283</td>
<td id="A3.T4.1.3.2.4" class="ltx_td"></td>
<td id="A3.T4.1.3.2.5" class="ltx_td ltx_nopad_l ltx_align_center">12</td>
<td id="A3.T4.1.3.2.6" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T4.1.3.2.6.1" class="ltx_text ltx_font_typewriter">Because</span></td>
<td id="A3.T4.1.3.2.7" class="ltx_td ltx_align_center">0.002</td>
</tr>
<tr id="A3.T4.1.4.3" class="ltx_tr">
<td id="A3.T4.1.4.3.1" class="ltx_td ltx_align_center">3</td>
<td id="A3.T4.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T4.1.4.3.2.1" class="ltx_text ltx_font_typewriter">Since</span></td>
<td id="A3.T4.1.4.3.3" class="ltx_td ltx_align_center">0.214</td>
<td id="A3.T4.1.4.3.4" class="ltx_td"></td>
<td id="A3.T4.1.4.3.5" class="ltx_td ltx_nopad_l ltx_align_center">13</td>
<td id="A3.T4.1.4.3.6" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T4.1.4.3.6.1" class="ltx_text ltx_font_typewriter">The</span></td>
<td id="A3.T4.1.4.3.7" class="ltx_td ltx_align_center">0.001</td>
</tr>
<tr id="A3.T4.1.5.4" class="ltx_tr">
<td id="A3.T4.1.5.4.1" class="ltx_td ltx_align_center">4</td>
<td id="A3.T4.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T4.1.5.4.2.1" class="ltx_text ltx_font_typewriter">I</span></td>
<td id="A3.T4.1.5.4.3" class="ltx_td ltx_align_center">0.104</td>
<td id="A3.T4.1.5.4.4" class="ltx_td"></td>
<td id="A3.T4.1.5.4.5" class="ltx_td ltx_nopad_l ltx_align_center">14</td>
<td id="A3.T4.1.5.4.6" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T4.1.5.4.6.1" class="ltx_text ltx_font_typewriter">5</span></td>
<td id="A3.T4.1.5.4.7" class="ltx_td ltx_align_center">0.001</td>
</tr>
<tr id="A3.T4.1.6.5" class="ltx_tr">
<td id="A3.T4.1.6.5.1" class="ltx_td ltx_align_center">5</td>
<td id="A3.T4.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T4.1.6.5.2.1" class="ltx_text ltx_font_typewriter">Given</span></td>
<td id="A3.T4.1.6.5.3" class="ltx_td ltx_align_center">0.042</td>
<td id="A3.T4.1.6.5.4" class="ltx_td"></td>
<td id="A3.T4.1.6.5.5" class="ltx_td ltx_nopad_l ltx_align_center">15</td>
<td id="A3.T4.1.6.5.6" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T4.1.6.5.6.1" class="ltx_text ltx_font_typewriter">4</span></td>
<td id="A3.T4.1.6.5.7" class="ltx_td ltx_align_center">0.001</td>
</tr>
<tr id="A3.T4.1.7.6" class="ltx_tr">
<td id="A3.T4.1.7.6.1" class="ltx_td ltx_align_center">6</td>
<td id="A3.T4.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T4.1.7.6.2.1" class="ltx_text ltx_font_typewriter">Considering</span></td>
<td id="A3.T4.1.7.6.3" class="ltx_td ltx_align_center">0.007</td>
<td id="A3.T4.1.7.6.4" class="ltx_td"></td>
<td id="A3.T4.1.7.6.5" class="ltx_td ltx_nopad_l ltx_align_center">16</td>
<td id="A3.T4.1.7.6.6" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T4.1.7.6.6.1" class="ltx_text ltx_font_typewriter">It</span></td>
<td id="A3.T4.1.7.6.7" class="ltx_td ltx_align_center">0.001</td>
</tr>
<tr id="A3.T4.1.8.7" class="ltx_tr">
<td id="A3.T4.1.8.7.1" class="ltx_td ltx_align_center">7</td>
<td id="A3.T4.1.8.7.2" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T4.1.8.7.2.1" class="ltx_text ltx_font_typewriter">This</span></td>
<td id="A3.T4.1.8.7.3" class="ltx_td ltx_align_center">0.007</td>
<td id="A3.T4.1.8.7.4" class="ltx_td"></td>
<td id="A3.T4.1.8.7.5" class="ltx_td ltx_nopad_l ltx_align_center">17</td>
<td id="A3.T4.1.8.7.6" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T4.1.8.7.6.1" class="ltx_text ltx_font_typewriter">Without</span></td>
<td id="A3.T4.1.8.7.7" class="ltx_td ltx_align_center">0.001</td>
</tr>
<tr id="A3.T4.1.9.8" class="ltx_tr">
<td id="A3.T4.1.9.8.1" class="ltx_td ltx_align_center">8</td>
<td id="A3.T4.1.9.8.2" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T4.1.9.8.2.1" class="ltx_text ltx_font_typewriter">Unfortunately</span></td>
<td id="A3.T4.1.9.8.3" class="ltx_td ltx_align_center">0.004</td>
<td id="A3.T4.1.9.8.4" class="ltx_td"></td>
<td id="A3.T4.1.9.8.5" class="ltx_td ltx_nopad_l ltx_align_center">18</td>
<td id="A3.T4.1.9.8.6" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T4.1.9.8.6.1" class="ltx_text ltx_font_typewriter">N</span></td>
<td id="A3.T4.1.9.8.7" class="ltx_td ltx_align_center">0.001</td>
</tr>
<tr id="A3.T4.1.10.9" class="ltx_tr">
<td id="A3.T4.1.10.9.1" class="ltx_td ltx_align_center">9</td>
<td id="A3.T4.1.10.9.2" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T4.1.10.9.2.1" class="ltx_text ltx_font_typewriter">Ap</span></td>
<td id="A3.T4.1.10.9.3" class="ltx_td ltx_align_center">0.003</td>
<td id="A3.T4.1.10.9.4" class="ltx_td"></td>
<td id="A3.T4.1.10.9.5" class="ltx_td ltx_nopad_l ltx_align_center">19</td>
<td id="A3.T4.1.10.9.6" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T4.1.10.9.6.1" class="ltx_text ltx_font_typewriter">3</span></td>
<td id="A3.T4.1.10.9.7" class="ltx_td ltx_align_center">0.001</td>
</tr>
<tr id="A3.T4.1.11.10" class="ltx_tr">
<td id="A3.T4.1.11.10.1" class="ltx_td ltx_align_center ltx_border_b">10</td>
<td id="A3.T4.1.11.10.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="A3.T4.1.11.10.2.1" class="ltx_text ltx_font_typewriter">Due</span></td>
<td id="A3.T4.1.11.10.3" class="ltx_td ltx_align_center ltx_border_b">0.003</td>
<td id="A3.T4.1.11.10.4" class="ltx_td"></td>
<td id="A3.T4.1.11.10.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_b">20</td>
<td id="A3.T4.1.11.10.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="A3.T4.1.11.10.6.1" class="ltx_text ltx_font_typewriter">My</span></td>
<td id="A3.T4.1.11.10.7" class="ltx_td ltx_align_center ltx_border_b">0.001</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Sample top 20 tokens from a questionnaire response by the LLM where the first response is non-numeric.</figcaption>
</figure>
<div id="A3.p3" class="ltx_para ltx_noindent">
<p id="A3.p3.1" class="ltx_p">For example, consider the following response to Q8: “<span id="A3.p3.1.1" class="ltx_text ltx_font_typewriter">As this conversation was text-based, I cannot provide a rating for eye contact</span>”. A sample of the top 20 tokens with highest probability are displayed in <a href="#A3.T4" title="Table 4 ‣ Appendix C LLM Fusion: Non-Numeric Responses ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 4</span></a>.</p>
</div>
<div id="A3.p4" class="ltx_para ltx_noindent">
<p id="A3.p4.1" class="ltx_p">The other 23 responses exceeded 50 generated tokens and were cut off. This occurred often in the <span id="A3.p4.1.1" class="ltx_text ltx_font_bold">4F</span> ablation experiments when the <span id="A3.p4.1.2" class="ltx_text ltx_font_typewriter">GPT-4</span> would prefix its answers with the facial expression string, such as the following example.</p>
</div>
<div id="A3.p5" class="ltx_para ltx_noindent">
<p id="A3.p5.1" class="ltx_p">“<span id="A3.p5.1.1" class="ltx_text ltx_font_typewriter">[You] [You are speaking mostly with relaxed facial muscles, a straight mouth, a smooth forehead, and unremarkable eyebrows.
Your partner is listening to you mostly with relaxed facial muscles, a straight mouth, a smooth forehead, and unremark</span>” [<em id="A3.p5.1.2" class="ltx_emph ltx_font_italic">text cut off</em>].</p>
</div>
<div id="A3.p6" class="ltx_para ltx_noindent">
<p id="A3.p6.1" class="ltx_p">It’s interesting to note that not all <span id="A3.p6.1.1" class="ltx_text ltx_font_typewriter">GPT</span> models are able to impersonate a participant. For example, nearly all experiments with <span id="A3.p6.1.2" class="ltx_text ltx_font_typewriter">gpt-4-1106-preview</span> would result in an example similar to the following:</p>
</div>
<div id="A3.p7" class="ltx_para ltx_noindent">
<p id="A3.p7.1" class="ltx_p">“<span id="A3.p7.1.1" class="ltx_text ltx_font_typewriter">As an AI language model, I don’t have personal experiences or opinions. However, if I were to simulate a response for the scenario described where a participant has engaged in an interesting conversation that touched on computer science, philosophy of neuroscience, differences between cities, and personal experiences, they might rate the conversation on the higher end of the scale indicating that they found it to be engaging and intellectually stimulating.</span>”</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="A3.fig1" class="ltx_figure">
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Multimodal Transcript Template</h2>

<div id="A4.p1" class="ltx_para ltx_noindent">
<p id="A4.p1.1" class="ltx_p">This appendix contains a detailed version of the sample multimodal transcript depicted in <a href="#S0.F1" title="Figure 1 ‣ Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 1</span></a>. <span id="A4.p1.1.1" class="ltx_text" style="color:#FF00FF;">Magenta text</span> corresponds to information from personal inventories. <span id="A4.p1.1.2" class="ltx_text" style="color:#FF0000;">Red text</span> corresponds to information from OpenFace. <span id="A4.p1.1.3" class="ltx_text" style="color:#8000FF;">Violet text</span> corresponds to information from MediaPipe and Pupil Invisible eye tracking. <span id="A4.p1.1.4" class="ltx_text" style="color:#0000FF;">Blue text</span> corresponds to information from the Whisper transcription. <span id="A4.p1.1.5" class="ltx_text" style="color:#00BF29;">Green text</span> corresponds to information from the post-session engagement survey. Black text is always present. The last row with “assistant” is what the LLM generates.</p>
</div>
<div id="A4.p2" class="ltx_para ltx_align_left ltx_align_center">
<table id="A4.p2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A4.p2.1.1.1" class="ltx_tr">
<th id="A4.p2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt">Role</th>
<td id="A4.p2.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="A4.p2.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="A4.p2.1.1.1.2.1.1" class="ltx_p" style="width:430.0pt;">Content</span>
</span>
</td>
</tr>
<tr id="A4.p2.1.2.2" class="ltx_tr">
<th id="A4.p2.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">System</th>
<td id="A4.p2.1.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A4.p2.1.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="A4.p2.1.2.2.2.1.1" class="ltx_p" style="width:430.0pt;"><span id="A4.p2.1.2.2.2.1.1.1" class="ltx_text ltx_font_typewriter">You are a student at ... You are participating in a psychology study that aims to understand how people communicate, and you are participating in a conversation with ... as part of this study. There will be a questionnaire at the end of this conversation. Others will read what you answer; your goal is to convince them it was answered from the perspective of the persona that participated in the following conversation. </span></span>
<span id="A4.p2.1.2.2.2.1.2" class="ltx_p"><span id="A4.p2.1.2.2.2.1.2.1" class="ltx_text ltx_font_typewriter" style="color:#FF00FF;">Your personality traits are defined by the scores to the following statements. The scores range from 1 to 5, where 1 means strongly disagree and 5 means strongly agree. </span></span>
<span id="A4.p2.1.2.2.2.1.3" class="ltx_p"><span id="A4.p2.1.2.2.2.1.3.1" class="ltx_text ltx_font_typewriter" style="color:#FF00FF;">[Alice’s personality defined by responses to the big-5 personality survey.]</span></span>
<span id="A4.p2.1.2.2.2.1.4" class="ltx_p"><span id="A4.p2.1.2.2.2.1.4.1" class="ltx_text ltx_font_typewriter" style="color:#FF00FF;">Your political beliefs are defined by the following statements:</span></span>
<span id="A4.p2.1.2.2.2.1.5" class="ltx_p"><span id="A4.p2.1.2.2.2.1.5.1" class="ltx_text ltx_font_typewriter" style="color:#FF00FF;">[Alice’s beliefs defined by responses to the beliefs survey.]</span></span>
</span>
</td>
</tr>
<tr id="A4.p2.1.3.3" class="ltx_tr">
<th id="A4.p2.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Assistant</th>
<td id="A4.p2.1.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A4.p2.1.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="A4.p2.1.3.3.2.1.1" class="ltx_p" style="width:430.0pt;"><span id="A4.p2.1.3.3.2.1.1.1" class="ltx_text ltx_font_typewriter">[You]</span></span>
<span id="A4.p2.1.3.3.2.1.2" class="ltx_p"><span id="A4.p2.1.3.3.2.1.2.1" class="ltx_text ltx_font_typewriter">[<span id="A4.p2.1.3.3.2.1.2.1.1" class="ltx_text" style="color:#8000FF;">You are looking at your partner’s face about 80% of the time.</span></span></span>
<span id="A4.p2.1.3.3.2.1.3" class="ltx_p"><span id="A4.p2.1.3.3.2.1.3.1" class="ltx_text ltx_font_typewriter" style="color:#FF0000;">You are speaking with a smiling mouth, raised cheeks...</span></span>
<span id="A4.p2.1.3.3.2.1.4" class="ltx_p"><span id="A4.p2.1.3.3.2.1.4.1" class="ltx_text ltx_font_typewriter" style="color:#8000FF;">Your partner is looking at your face about 80% of the time.</span></span>
<span id="A4.p2.1.3.3.2.1.5" class="ltx_p"><span id="A4.p2.1.3.3.2.1.5.1" class="ltx_text ltx_font_typewriter" style="color:#FF0000;">Your partner is listening with relaxed facial expression...<span id="A4.p2.1.3.3.2.1.5.1.1" class="ltx_text" style="color:#000000;">]</span></span></span>
<span id="A4.p2.1.3.3.2.1.6" class="ltx_p"><span id="A4.p2.1.3.3.2.1.6.1" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">Hi, I’m Alice! What year are you?</span></span>
</span>
</td>
</tr>
<tr id="A4.p2.1.4.4" class="ltx_tr">
<th id="A4.p2.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">User</th>
<td id="A4.p2.1.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A4.p2.1.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="A4.p2.1.4.4.2.1.1" class="ltx_p" style="width:430.0pt;"><span id="A4.p2.1.4.4.2.1.1.1" class="ltx_text ltx_font_typewriter">[Partner]</span></span>
<span id="A4.p2.1.4.4.2.1.2" class="ltx_p"><span id="A4.p2.1.4.4.2.1.2.1" class="ltx_text ltx_font_typewriter">[<span id="A4.p2.1.4.4.2.1.2.1.1" class="ltx_text" style="color:#8000FF;">You are looking at your partner’s face about 60% of the time.</span></span></span>
<span id="A4.p2.1.4.4.2.1.3" class="ltx_p"><span id="A4.p2.1.4.4.2.1.3.1" class="ltx_text ltx_font_typewriter" style="color:#FF0000;">You are listening with a smiling mouth, raised cheeks...</span></span>
<span id="A4.p2.1.4.4.2.1.4" class="ltx_p"><span id="A4.p2.1.4.4.2.1.4.1" class="ltx_text ltx_font_typewriter" style="color:#8000FF;">Your partner is looking at your face about 80% of the time.</span></span>
<span id="A4.p2.1.4.4.2.1.5" class="ltx_p"><span id="A4.p2.1.4.4.2.1.5.1" class="ltx_text ltx_font_typewriter" style="color:#FF0000;">Your partner is speaking with a smiling mouth, raised cheeks...<span id="A4.p2.1.4.4.2.1.5.1.1" class="ltx_text" style="color:#000000;">]</span></span></span>
<span id="A4.p2.1.4.4.2.1.6" class="ltx_p"><span id="A4.p2.1.4.4.2.1.6.1" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">Hi Alice, I’m Bob. I’m a sophomore.</span></span>
</span>
</td>
</tr>
<tr id="A4.p2.1.5.5" class="ltx_tr">
<th id="A4.p2.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span class="ltx_rule" style="width:0.0pt;height:17.2pt;background:black;display:inline-block;"></span></th>
<td id="A4.p2.1.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A4.p2.1.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="A4.p2.1.5.5.2.1.1" class="ltx_p" style="width:430.0pt;"><span class="ltx_rule" style="width:0.0pt;height:0.0pt;position:relative; bottom:-12.9pt;background:black;display:inline-block;"></span>[<span id="A4.p2.1.5.5.2.1.1.1" class="ltx_text ltx_font_italic">five minutes of conversation</span>]</span>
</span>
</td>
</tr>
<tr id="A4.p2.1.6.6" class="ltx_tr">
<th id="A4.p2.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">User</th>
<td id="A4.p2.1.6.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A4.p2.1.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="A4.p2.1.6.6.2.1.1" class="ltx_p" style="width:430.0pt;"><span id="A4.p2.1.6.6.2.1.1.1" class="ltx_text ltx_font_typewriter">[Experimenter] <span id="A4.p2.1.6.6.2.1.1.1.1" class="ltx_text" style="color:#00BF29;">On a scale of 1 to 7, where 1 means strongly disagree and 7 means strongly agree, how would you rate the following statement given the conversation you just had?</span></span></span>
<span id="A4.p2.1.6.6.2.1.2" class="ltx_p"><span id="A4.p2.1.6.6.2.1.2.1" class="ltx_text ltx_font_typewriter" style="color:#00BF29;">I found this conversation to be interesting.</span></span>
<span id="A4.p2.1.6.6.2.1.3" class="ltx_p"><span id="A4.p2.1.6.6.2.1.3.1" class="ltx_text ltx_font_typewriter">Your answers will be kept private and your conversation partner will not see the responses, so please be as honest as possible. Provide your answer in the form of an integer between 1 and 7.</span></span>
</span>
</td>
</tr>
<tr id="A4.p2.1.7.7" class="ltx_tr">
<th id="A4.p2.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t">Assistant</th>
<td id="A4.p2.1.7.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="A4.p2.1.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="A4.p2.1.7.7.2.1.1" class="ltx_p" style="width:430.0pt;"><span id="A4.p2.1.7.7.2.1.1.1" class="ltx_text ltx_font_typewriter">7</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</div>
</section>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Belief Questionnaire</h2>

<div id="A5.p1" class="ltx_para ltx_noindent">
<p id="A5.p1.1" class="ltx_p">Each participant completed the following questionnaire at the end of the recording session.</p>
</div>
<div id="A5.p2" class="ltx_para ltx_noindent">
<p id="A5.p2.1" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A5.p3" class="ltx_para ltx_noindent">
<p id="A5.p3.1" class="ltx_p"><em id="A5.p3.1.1" class="ltx_emph ltx_font_italic">Please select the answer which most represents your beliefs.</em></p>
<div class="ltx_pagination ltx_role_start_2_columns"></div>
<p id="A5.p3.2" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A5.p4" class="ltx_para ltx_noindent">
<p id="A5.p4.1" class="ltx_p"><span id="A5.p4.1.1" class="ltx_text ltx_font_bold">Environmental Protection</span></p>
<ul id="A5.I1" class="ltx_itemize">
<li id="A5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I1.i1.p1" class="ltx_para">
<p id="A5.I1.i1.p1.1" class="ltx_p">I am very much against environmental protection.</p>
</div>
</li>
<li id="A5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I1.i2.p1" class="ltx_para">
<p id="A5.I1.i2.p1.1" class="ltx_p">I am against environmental protection.</p>
</div>
</li>
<li id="A5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I1.i3.p1" class="ltx_para">
<p id="A5.I1.i3.p1.1" class="ltx_p">I am mildly against environmental protection.</p>
</div>
</li>
<li id="A5.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I1.i4.p1" class="ltx_para">
<p id="A5.I1.i4.p1.1" class="ltx_p">I am mildly in favor of environmental protection.</p>
</div>
</li>
<li id="A5.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I1.i5.p1" class="ltx_para">
<p id="A5.I1.i5.p1.1" class="ltx_p">I am in favor of environmental protection.</p>
</div>
</li>
<li id="A5.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I1.i6.p1" class="ltx_para ltx_noindent">
<p id="A5.I1.i6.p1.1" class="ltx_p">I am very much in favor of environmental protection.</p>
</div>
</li>
</ul>
</div>
<div id="A5.p5" class="ltx_para ltx_noindent">
<p id="A5.p5.1" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A5.p6" class="ltx_para ltx_noindent">
<p id="A5.p6.1" class="ltx_p"><span id="A5.p6.1.1" class="ltx_text ltx_font_bold">Careers for Women</span></p>
<ul id="A5.I2" class="ltx_itemize">
<li id="A5.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I2.i1.p1" class="ltx_para">
<p id="A5.I2.i1.p1.1" class="ltx_p">I am very much against women pursuing careers.</p>
</div>
</li>
<li id="A5.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I2.i2.p1" class="ltx_para">
<p id="A5.I2.i2.p1.1" class="ltx_p">I am against women pursuing careers.</p>
</div>
</li>
<li id="A5.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I2.i3.p1" class="ltx_para">
<p id="A5.I2.i3.p1.1" class="ltx_p">I am mildly against women pursuing careers.</p>
</div>
</li>
<li id="A5.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I2.i4.p1" class="ltx_para">
<p id="A5.I2.i4.p1.1" class="ltx_p">I am mildly in favor of women pursuing careers.</p>
</div>
</li>
<li id="A5.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I2.i5.p1" class="ltx_para">
<p id="A5.I2.i5.p1.1" class="ltx_p">I am in favor of women pursuing careers.</p>
</div>
</li>
<li id="A5.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I2.i6.p1" class="ltx_para ltx_noindent">
<p id="A5.I2.i6.p1.1" class="ltx_p">I am very much in favor of women pursuing careers.</p>
</div>
</li>
</ul>
</div>
<div id="A5.p7" class="ltx_para ltx_noindent">
<p id="A5.p7.1" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A5.p8" class="ltx_para ltx_noindent">
<p id="A5.p8.1" class="ltx_p"><span id="A5.p8.1.1" class="ltx_text ltx_font_bold">Belief in God</span></p>
<ul id="A5.I3" class="ltx_itemize">
<li id="A5.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I3.i1.p1" class="ltx_para">
<p id="A5.I3.i1.p1.1" class="ltx_p">I strongly believe that there is a God.</p>
</div>
</li>
<li id="A5.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I3.i2.p1" class="ltx_para">
<p id="A5.I3.i2.p1.1" class="ltx_p">I believe there is a God.</p>
</div>
</li>
<li id="A5.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I3.i3.p1" class="ltx_para">
<p id="A5.I3.i3.p1.1" class="ltx_p">I feel that perhaps there is a God.</p>
</div>
</li>
<li id="A5.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I3.i4.p1" class="ltx_para">
<p id="A5.I3.i4.p1.1" class="ltx_p">I feel that perhaps there is no God.</p>
</div>
</li>
<li id="A5.I3.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I3.i5.p1" class="ltx_para">
<p id="A5.I3.i5.p1.1" class="ltx_p">I believe there is no God.</p>
</div>
</li>
<li id="A5.I3.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I3.i6.p1" class="ltx_para ltx_noindent">
<p id="A5.I3.i6.p1.1" class="ltx_p">I strongly believe there is no God.</p>
</div>
</li>
</ul>
</div>
<div id="A5.p9" class="ltx_para ltx_noindent">
<p id="A5.p9.1" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A5.p10" class="ltx_para ltx_noindent">
<p id="A5.p10.1" class="ltx_p"><span id="A5.p10.1.1" class="ltx_text ltx_font_bold">Ranking of Schools</span></p>
<ul id="A5.I4" class="ltx_itemize">
<li id="A5.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I4.i1.p1" class="ltx_para">
<p id="A5.I4.i1.p1.1" class="ltx_p">I am very much against the ranking of schools.</p>
</div>
</li>
<li id="A5.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I4.i2.p1" class="ltx_para">
<p id="A5.I4.i2.p1.1" class="ltx_p">I am against the ranking of schools.</p>
</div>
</li>
<li id="A5.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I4.i3.p1" class="ltx_para">
<p id="A5.I4.i3.p1.1" class="ltx_p">I am mildly against the ranking of schools.</p>
</div>
</li>
<li id="A5.I4.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I4.i4.p1" class="ltx_para">
<p id="A5.I4.i4.p1.1" class="ltx_p">I am mildly in favor of the ranking of schools.</p>
</div>
</li>
<li id="A5.I4.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I4.i5.p1" class="ltx_para">
<p id="A5.I4.i5.p1.1" class="ltx_p">I am in favor of the ranking of schools.</p>
</div>
</li>
<li id="A5.I4.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I4.i6.p1" class="ltx_para ltx_noindent">
<p id="A5.I4.i6.p1.1" class="ltx_p">I am very much in favor of the ranking of schools.</p>
</div>
</li>
</ul>
<p id="A5.p10.2" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span><span id="A5.p10.2.1" class="ltx_text"></span>
<span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A5.p11" class="ltx_para ltx_noindent">
<p id="A5.p11.1" class="ltx_p"><span id="A5.p11.1.1" class="ltx_text ltx_font_bold">Abortion</span></p>
<ul id="A5.I5" class="ltx_itemize">
<li id="A5.I5.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I5.i1.p1" class="ltx_para">
<p id="A5.I5.i1.p1.1" class="ltx_p">I am very much against abortion.</p>
</div>
</li>
<li id="A5.I5.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I5.i2.p1" class="ltx_para">
<p id="A5.I5.i2.p1.1" class="ltx_p">I am against abortion.</p>
</div>
</li>
<li id="A5.I5.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I5.i3.p1" class="ltx_para">
<p id="A5.I5.i3.p1.1" class="ltx_p">I am mildly against abortion.</p>
</div>
</li>
<li id="A5.I5.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I5.i4.p1" class="ltx_para">
<p id="A5.I5.i4.p1.1" class="ltx_p">I am mildly in favor of abortion.</p>
</div>
</li>
<li id="A5.I5.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I5.i5.p1" class="ltx_para">
<p id="A5.I5.i5.p1.1" class="ltx_p">I am in favor of abortion.</p>
</div>
</li>
<li id="A5.I5.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I5.i6.p1" class="ltx_para ltx_noindent">
<p id="A5.I5.i6.p1.1" class="ltx_p">I am very much in favor of abortion.</p>
</div>
</li>
</ul>
<p id="A5.p11.2" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A5.p12" class="ltx_para ltx_noindent">
<p id="A5.p12.1" class="ltx_p"><span id="A5.p12.1.1" class="ltx_text ltx_font_bold">Death Penalty</span></p>
<ul id="A5.I6" class="ltx_itemize">
<li id="A5.I6.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I6.i1.p1" class="ltx_para">
<p id="A5.I6.i1.p1.1" class="ltx_p">I am very much against the death penalty.</p>
</div>
</li>
<li id="A5.I6.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I6.i2.p1" class="ltx_para">
<p id="A5.I6.i2.p1.1" class="ltx_p">I am against the death penalty.</p>
</div>
</li>
<li id="A5.I6.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I6.i3.p1" class="ltx_para">
<p id="A5.I6.i3.p1.1" class="ltx_p">I am mildly against the death penalty.</p>
</div>
</li>
<li id="A5.I6.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I6.i4.p1" class="ltx_para">
<p id="A5.I6.i4.p1.1" class="ltx_p">I am mildly in favor of the death penalty.</p>
</div>
</li>
<li id="A5.I6.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I6.i5.p1" class="ltx_para">
<p id="A5.I6.i5.p1.1" class="ltx_p">I am in favor of the death penalty.</p>
</div>
</li>
<li id="A5.I6.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I6.i6.p1" class="ltx_para ltx_noindent">
<p id="A5.I6.i6.p1.1" class="ltx_p">I am very much in favor of the death penalty.</p>
</div>
</li>
</ul>
</div>
<div id="A5.p13" class="ltx_para ltx_noindent">
<p id="A5.p13.1" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A5.p14" class="ltx_para ltx_noindent">
<p id="A5.p14.1" class="ltx_p"><span id="A5.p14.1.1" class="ltx_text ltx_font_bold">Gay Marriage</span></p>
<ul id="A5.I7" class="ltx_itemize">
<li id="A5.I7.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I7.i1.p1" class="ltx_para">
<p id="A5.I7.i1.p1.1" class="ltx_p">I am very much against gay marriage.</p>
</div>
</li>
<li id="A5.I7.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I7.i2.p1" class="ltx_para">
<p id="A5.I7.i2.p1.1" class="ltx_p">I am against gay marriage.</p>
</div>
</li>
<li id="A5.I7.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I7.i3.p1" class="ltx_para">
<p id="A5.I7.i3.p1.1" class="ltx_p">I am mildly against gay marriage.</p>
</div>
</li>
<li id="A5.I7.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I7.i4.p1" class="ltx_para">
<p id="A5.I7.i4.p1.1" class="ltx_p">I am mildly in favor of gay marriage.</p>
</div>
</li>
<li id="A5.I7.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I7.i5.p1" class="ltx_para">
<p id="A5.I7.i5.p1.1" class="ltx_p">I am in favor of gay marriage.</p>
</div>
</li>
<li id="A5.I7.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I7.i6.p1" class="ltx_para ltx_noindent">
<p id="A5.I7.i6.p1.1" class="ltx_p">I am very much in favor of gay marriage.</p>
</div>
</li>
</ul>
<p id="A5.p14.2" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A5.p15" class="ltx_para ltx_noindent">
<p id="A5.p15.1" class="ltx_p"><span id="A5.p15.1.1" class="ltx_text ltx_font_bold">Money</span></p>
<ul id="A5.I8" class="ltx_itemize">
<li id="A5.I8.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I8.i1.p1" class="ltx_para">
<p id="A5.I8.i1.p1.1" class="ltx_p">I strongly believe that money is one of the most important things in life.</p>
</div>
</li>
<li id="A5.I8.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I8.i2.p1" class="ltx_para">
<p id="A5.I8.i2.p1.1" class="ltx_p">I believe that money is one of the most important things in life.</p>
</div>
</li>
<li id="A5.I8.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I8.i3.p1" class="ltx_para">
<p id="A5.I8.i3.p1.1" class="ltx_p">I feel perhaps that money is one of the most important things in life.</p>
</div>
</li>
<li id="A5.I8.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I8.i4.p1" class="ltx_para">
<p id="A5.I8.i4.p1.1" class="ltx_p">I feel perhaps that money is not one of the most important things in life.</p>
</div>
</li>
<li id="A5.I8.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I8.i5.p1" class="ltx_para">
<p id="A5.I8.i5.p1.1" class="ltx_p">I believe that money is not one of the most important things in life.</p>
</div>
</li>
<li id="A5.I8.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I8.i6.p1" class="ltx_para ltx_noindent">
<p id="A5.I8.i6.p1.1" class="ltx_p">I strongly believe that money is not one of the most important things in life.</p>
</div>
</li>
</ul>
<p id="A5.p15.2" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span><span id="A5.p15.2.1" class="ltx_text"></span>
<span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A5.p16" class="ltx_para ltx_noindent">
<p id="A5.p16.1" class="ltx_p"><span id="A5.p16.1.1" class="ltx_text ltx_font_bold">Divorce</span></p>
<ul id="A5.I9" class="ltx_itemize">
<li id="A5.I9.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I9.i1.p1" class="ltx_para">
<p id="A5.I9.i1.p1.1" class="ltx_p">I am very much against divorce.</p>
</div>
</li>
<li id="A5.I9.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I9.i2.p1" class="ltx_para">
<p id="A5.I9.i2.p1.1" class="ltx_p">I am against divorce.</p>
</div>
</li>
<li id="A5.I9.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I9.i3.p1" class="ltx_para">
<p id="A5.I9.i3.p1.1" class="ltx_p">I am mildly against divorce.</p>
</div>
</li>
<li id="A5.I9.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I9.i4.p1" class="ltx_para">
<p id="A5.I9.i4.p1.1" class="ltx_p">I am mildly in favor of divorce.</p>
</div>
</li>
<li id="A5.I9.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I9.i5.p1" class="ltx_para">
<p id="A5.I9.i5.p1.1" class="ltx_p">I am in favor of divorce.</p>
</div>
</li>
<li id="A5.I9.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I9.i6.p1" class="ltx_para ltx_noindent">
<p id="A5.I9.i6.p1.1" class="ltx_p">I am very much in favor of divorce.</p>
</div>
</li>
</ul>
<p id="A5.p16.2" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A5.p17" class="ltx_para ltx_noindent">
<p id="A5.p17.1" class="ltx_p"><span id="A5.p17.1.1" class="ltx_text ltx_font_bold">Smoking</span></p>
<ul id="A5.I10" class="ltx_itemize">
<li id="A5.I10.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I10.i1.p1" class="ltx_para">
<p id="A5.I10.i1.p1.1" class="ltx_p">I am very much against smoking in public places like bars.</p>
</div>
</li>
<li id="A5.I10.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I10.i2.p1" class="ltx_para">
<p id="A5.I10.i2.p1.1" class="ltx_p">I am against smoking in public places like bars.</p>
</div>
</li>
<li id="A5.I10.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I10.i3.p1" class="ltx_para">
<p id="A5.I10.i3.p1.1" class="ltx_p">I am mildly against smoking in public places like bars.</p>
</div>
</li>
<li id="A5.I10.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I10.i4.p1" class="ltx_para">
<p id="A5.I10.i4.p1.1" class="ltx_p">I am mildly in favor of smoking in public places like bars.</p>
</div>
</li>
<li id="A5.I10.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I10.i5.p1" class="ltx_para">
<p id="A5.I10.i5.p1.1" class="ltx_p">I am in favor of smoking in public places like bars.</p>
</div>
</li>
<li id="A5.I10.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I10.i6.p1" class="ltx_para ltx_noindent">
<p id="A5.I10.i6.p1.1" class="ltx_p">I am very much in favor of smoking in public places like bars.</p>
</div>
</li>
</ul>
<p id="A5.p17.2" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A5.p18" class="ltx_para ltx_noindent">
<p id="A5.p18.1" class="ltx_p"><span id="A5.p18.1.1" class="ltx_text ltx_font_bold">Spanking Children</span></p>
<ul id="A5.I11" class="ltx_itemize">
<li id="A5.I11.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I11.i1.p1" class="ltx_para">
<p id="A5.I11.i1.p1.1" class="ltx_p">In general, I am very much in favor of spanking children.</p>
</div>
</li>
<li id="A5.I11.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I11.i2.p1" class="ltx_para">
<p id="A5.I11.i2.p1.1" class="ltx_p">In general, I am in favor of spanking children.</p>
</div>
</li>
<li id="A5.I11.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I11.i3.p1" class="ltx_para">
<p id="A5.I11.i3.p1.1" class="ltx_p">In general, I am mildly in favor of spanking children.</p>
</div>
</li>
<li id="A5.I11.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I11.i4.p1" class="ltx_para">
<p id="A5.I11.i4.p1.1" class="ltx_p">In general, I am mildly against spanking children.</p>
</div>
</li>
<li id="A5.I11.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I11.i5.p1" class="ltx_para">
<p id="A5.I11.i5.p1.1" class="ltx_p">In general, I am against spanking children.</p>
</div>
</li>
<li id="A5.I11.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I11.i6.p1" class="ltx_para ltx_noindent">
<p id="A5.I11.i6.p1.1" class="ltx_p">In general, I am very much against spanking children.</p>
</div>
</li>
</ul>
<p id="A5.p18.2" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A5.p19" class="ltx_para ltx_noindent">
<p id="A5.p19.1" class="ltx_p"><span id="A5.p19.1.1" class="ltx_text ltx_font_bold">Climate Change</span></p>
<ul id="A5.I12" class="ltx_itemize">
<li id="A5.I12.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I12.i1.p1" class="ltx_para">
<p id="A5.I12.i1.p1.1" class="ltx_p">I strongly believe that climate change has not been accelerated by humans.</p>
</div>
</li>
<li id="A5.I12.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I12.i2.p1" class="ltx_para">
<p id="A5.I12.i2.p1.1" class="ltx_p">I believe that climate change has not been accelerated by humans.</p>
</div>
</li>
<li id="A5.I12.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I12.i3.p1" class="ltx_para">
<p id="A5.I12.i3.p1.1" class="ltx_p">I mildly believe that climate change has not been accelerated by humans.</p>
</div>
</li>
<li id="A5.I12.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I12.i4.p1" class="ltx_para">
<p id="A5.I12.i4.p1.1" class="ltx_p">I mildly believe that climate change has been accelerated by humans.</p>
</div>
</li>
<li id="A5.I12.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I12.i5.p1" class="ltx_para">
<p id="A5.I12.i5.p1.1" class="ltx_p">I believe climate change has been accelerated by humans.</p>
</div>
</li>
<li id="A5.I12.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I12.i6.p1" class="ltx_para ltx_noindent">
<p id="A5.I12.i6.p1.1" class="ltx_p">I strongly believe that climate change has been accelerated by humans.</p>
</div>
</li>
</ul>
<p id="A5.p19.2" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span><span id="A5.p19.2.1" class="ltx_text"></span>
<span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A5.p20" class="ltx_para ltx_noindent">
<p id="A5.p20.1" class="ltx_p"><span id="A5.p20.1.1" class="ltx_text ltx_font_bold">Health Care</span></p>
<ul id="A5.I13" class="ltx_itemize">
<li id="A5.I13.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I13.i1.p1" class="ltx_para">
<p id="A5.I13.i1.p1.1" class="ltx_p">I strongly believe that humans are not entitled to health care.</p>
</div>
</li>
<li id="A5.I13.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I13.i2.p1" class="ltx_para">
<p id="A5.I13.i2.p1.1" class="ltx_p">I believe that humans are not entitled to health care.</p>
</div>
</li>
<li id="A5.I13.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I13.i3.p1" class="ltx_para">
<p id="A5.I13.i3.p1.1" class="ltx_p">I mildly believe that humans are not entitled to health care.</p>
</div>
</li>
<li id="A5.I13.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I13.i4.p1" class="ltx_para">
<p id="A5.I13.i4.p1.1" class="ltx_p">I mildly believe that humans are entitled to health care.</p>
</div>
</li>
<li id="A5.I13.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I13.i5.p1" class="ltx_para">
<p id="A5.I13.i5.p1.1" class="ltx_p">I believe that humans are entitled to health care.</p>
</div>
</li>
<li id="A5.I13.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I13.i6.p1" class="ltx_para ltx_noindent">
<p id="A5.I13.i6.p1.1" class="ltx_p">I strongly believe that humans are entitled to health care.</p>
</div>
</li>
</ul>
</div>
<div id="A5.p21" class="ltx_para ltx_noindent">
<p id="A5.p21.1" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A5.p22" class="ltx_para ltx_noindent">
<p id="A5.p22.1" class="ltx_p"><span id="A5.p22.1.1" class="ltx_text ltx_font_bold">Social Safety Net</span></p>
<ul id="A5.I14" class="ltx_itemize">
<li id="A5.I14.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I14.i1.p1" class="ltx_para">
<p id="A5.I14.i1.p1.1" class="ltx_p">I strongly believe the government should not provide funds to support individuals’ welfare.</p>
</div>
</li>
<li id="A5.I14.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I14.i2.p1" class="ltx_para">
<p id="A5.I14.i2.p1.1" class="ltx_p">I believe the government should not provide funds to support individuals’ welfare.</p>
</div>
</li>
<li id="A5.I14.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I14.i3.p1" class="ltx_para">
<p id="A5.I14.i3.p1.1" class="ltx_p">I mildly believe the government should not provide funds to support individuals’ welfare.</p>
</div>
</li>
<li id="A5.I14.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I14.i4.p1" class="ltx_para">
<p id="A5.I14.i4.p1.1" class="ltx_p">I mildly believe the government should provide funds to support individuals’ welfare.</p>
</div>
</li>
<li id="A5.I14.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I14.i5.p1" class="ltx_para">
<p id="A5.I14.i5.p1.1" class="ltx_p">I believe the government should provide funds to support individuals’ welfare.</p>
</div>
</li>
<li id="A5.I14.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I14.i6.p1" class="ltx_para ltx_noindent">
<p id="A5.I14.i6.p1.1" class="ltx_p">I strongly believe the government should provide funds to support individuals’ welfare.</p>
</div>
</li>
</ul>
</div>
<div id="A5.p23" class="ltx_para ltx_noindent">
<p id="A5.p23.1" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A5.p24" class="ltx_para ltx_noindent">
<p id="A5.p24.1" class="ltx_p"><span id="A5.p24.1.1" class="ltx_text ltx_font_bold">College</span></p>
<ul id="A5.I15" class="ltx_itemize">
<li id="A5.I15.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I15.i1.p1" class="ltx_para">
<p id="A5.I15.i1.p1.1" class="ltx_p">I strongly believe the government should not pay for college students’ tuition.</p>
</div>
</li>
<li id="A5.I15.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I15.i2.p1" class="ltx_para">
<p id="A5.I15.i2.p1.1" class="ltx_p">I believe the government should not pay for college students’ tuition.</p>
</div>
</li>
<li id="A5.I15.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I15.i3.p1" class="ltx_para">
<p id="A5.I15.i3.p1.1" class="ltx_p">I mildly believe the government should not pay for college students’ tuition.</p>
</div>
</li>
<li id="A5.I15.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I15.i4.p1" class="ltx_para">
<p id="A5.I15.i4.p1.1" class="ltx_p">I mildly believe the government should pay for college students’ tuition.</p>
</div>
</li>
<li id="A5.I15.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I15.i5.p1" class="ltx_para">
<p id="A5.I15.i5.p1.1" class="ltx_p">I believe the government should pay for college students’ tuition.</p>
</div>
</li>
<li id="A5.I15.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I15.i6.p1" class="ltx_para ltx_noindent">
<p id="A5.I15.i6.p1.1" class="ltx_p">I strongly believe the government should pay for college students’ tuition.</p>
</div>
</li>
</ul>
<p id="A5.p24.2" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span><span id="A5.p24.2.1" class="ltx_text"></span>
<span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
</div>
<div id="A5.p25" class="ltx_para ltx_noindent">
<p id="A5.p25.1" class="ltx_p"><span id="A5.p25.1.1" class="ltx_text ltx_font_bold">[Local University]</span></p>
<ul id="A5.I16" class="ltx_itemize">
<li id="A5.I16.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I16.i1.p1" class="ltx_para">
<p id="A5.I16.i1.p1.1" class="ltx_p">I strongly believe that [local university] is a welcoming university environment.</p>
</div>
</li>
<li id="A5.I16.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I16.i2.p1" class="ltx_para">
<p id="A5.I16.i2.p1.1" class="ltx_p">I believe that [local university] is a welcoming university environment.</p>
</div>
</li>
<li id="A5.I16.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I16.i3.p1" class="ltx_para">
<p id="A5.I16.i3.p1.1" class="ltx_p">I mildly believe that [local university] is a welcoming university environment.</p>
</div>
</li>
<li id="A5.I16.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I16.i4.p1" class="ltx_para">
<p id="A5.I16.i4.p1.1" class="ltx_p">I mildly believe that [local university] is not a welcoming university environment.</p>
</div>
</li>
<li id="A5.I16.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I16.i5.p1" class="ltx_para">
<p id="A5.I16.i5.p1.1" class="ltx_p">I believe that [local university] is not a welcoming university environment.</p>
</div>
</li>
<li id="A5.I16.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A5.I16.i6.p1" class="ltx_para ltx_noindent">
<p id="A5.I16.i6.p1.1" class="ltx_p">I strongly believe that [local university] is not a welcoming university environment.</p>
</div>
</li>
</ul>
</div>
<div id="A5.p26" class="ltx_para ltx_noindent">
<p id="A5.p26.1" class="ltx_p"><span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;"> </span></p>
<div class="ltx_pagination ltx_role_end_2_columns"></div>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.09134" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.09135" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.09135">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.09135" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.09136" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Oct  5 20:34:32 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
