<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2402.09902] Towards Federated Learning on the Quantum Internet</title><meta property="og:description" content="While the majority of focus in quantum computing has so far been on monolithic quantum systems, quantum communication networks and the quantum internet in particular are increasingly receiving attention from researcher…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Towards Federated Learning on the Quantum Internet">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Towards Federated Learning on the Quantum Internet">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2402.09902">

<!--Generated on Tue Mar  5 15:19:58 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Quantum Federated Learning Quantum Internet Quantum Machine Learning Quantum Communication Networks">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span id="id1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>Institute for Informatics, LMU Munich, Germany 
<br class="ltx_break"><span id="id1.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>leo.suenkel@ifi.lmu.de</span></span></span>
</span></span></span>
<h1 class="ltx_title ltx_title_document">Towards Federated Learning on the Quantum Internet</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Leo Sünkel
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Michael Kölle
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tobias Rohe
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Thomas Gabor
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">While the majority of focus in quantum computing has so far been on monolithic quantum systems, quantum communication networks and the quantum internet in particular are increasingly receiving attention from researchers and industry alike. The quantum internet may allow a plethora of applications such as distributed or blind quantum computing, though research still is at an early stage, both for its physical implementation as well as algorithms; thus suitable applications are an open research question. We evaluate a potential application for the quantum internet, namely quantum federated learning.
We run experiments under different settings in various scenarios (e.g. network constraints) using several datasets from different domains and show that (1) quantum federated learning is a valid alternative for regular training and (2) network topology and nature of training are crucial considerations as they may drastically influence the models performance. The results indicate that more comprehensive research is required to optimally deploy quantum federated learning on a potential quantum internet.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Quantum Federated Learning Quantum Internet Quantum Machine Learning Quantum Communication Networks
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Establishing a quantum communication network over large distances and thereby connecting a multitude of quantum devices with varying architectures and capabilities may allow the <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">quantum internet</span> to rise. However, what exactly such a potential network should look like remains an active research question <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>.
Given that the field is still largely in its infancy, it is vital to identify and examine the potential applications that such a large-scale network could enable. Distributed quantum computing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, quantum key distribution, blind quantum computing, and quantum federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> are all applications that have been discussed in recent years, and more are yet to be discovered. As quantum machine learning has sparked an interest in a wide range of disciplines in recent years, it is no surprise that, sooner or later, combining this area with the field of quantum communication will increasingly attract attention as this provides new opportunities and research avenues. Quantum federated learning already is a step in this direction, and it is this field that is the main topic of discussion in this paper. The idea behind federated learning is to train a global model by a collection of clients that communicate over a network. The crucial point is that each client trains their model on their local dataset, i.e., they keep their data private. Rather than exchanging private data, clients only communicate their models weights; the global model is trained by aggregating weights from participating clients. This (classical) approach can easily be transferred to the quantum domain, resulting in quantum federated learning. However, this field is also still in its infancy and thus many open research questions remain. In this paper, we evaluate different approaches to quantum federated learning under varies constraints that may be present in a quantum internet. More specifically, we run experiments using two different network topologies where the number of qubits of the quantum clients differ. Furthermore, we run experiments where clients are trained on subsets of the same dataset as well where each client is trained on a distinct one. We show that quantum federated learning is a compelling alternative to regular model training while it is crucial to take certain network constraints (e.g. each nodes qubit capacity) as well as the models training approach (e.g. nature of weight aggregation and exchange) into account. This paper is structured as follows. In Section <a href="#S2" title="2 Background ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> we cover the background of quantum communication networks, variational quantum circuits as well as quantum federated learning and discuss related work in Section <a href="#S3" title="3 Related Work ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. We illustrate our approach and architecture in Section <a href="#S4" title="4 Approach ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and discuss our experimental setup in Section <a href="#S5" title="5 Experimental Setup ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. We present our results in Section <a href="#S6" title="6 Results ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> and conclude in Section <a href="#S7" title="7 Conclusion ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We begin this section with a brief recapitulation of the basic building blocks of quantum communication networks (QCNs) and what we understand as the quantum internet. We then discuss potential applications and what this novel form of communication means for quantum algorithms in general while also for quantum machine learning in particular. However, we will not be covering the basics of quantum computation and information (e.g. qubits, entanglement, superposition) and instead refer the reader to other resources <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> for an in depth introduction to these topics. Once we have reviewed the fundamental concepts of quantum networks, we will discuss federated quantum machine learning, the main topic of this paper.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Quantum Networks and the Quantum Internet</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">We define a QCN as a number of quantum computers that are connected via classical and quantum channels, i.e., they have the means to communicate classical messages as well as qubits or quantum states with each other. We will refer to these quantum computers as QPUs or nodes in the network, and we use these terms interchangeably. Furthermore, a QCN can be seen as a graph where the nodes are quantum devices (QPUs) and the edges are the communication channels. An example of such a simple network can be seen in Figure <a href="#S2.F1" title="Figure 1 ‣ 2.1 Quantum Networks and the Quantum Internet ‣ 2 Background ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. This example network consists of 9 nodes (QPUs) each with a different qubit capacity. Each edge in the network serves a dual purpose, facilitating both classical and quantum communications.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2402.09902/assets/Images/Architecture/example_network.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="301" height="189" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F1.3.2" class="ltx_text" style="font-size:90%;">Example of a network with random topology where nodes represent available QPUs. The QPUs in this network have varying capacity, i.e., number of qubits and the network is not fully connected. Both facts cause ramifications and constraints for applications and network design. </span></figcaption>
</figure>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Unfortunately, quantum channels can be noisy, thus information loss is inevitable. Moreover, quantum information cannot be copied as this is prohibited by the <span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_italic">no cloning theorem</span>, and so classical protocols to overcome information loss as well as sending messages cannot be transferred into the quantum realm in a straightforward manner. In a QCN, qubits are <span id="S2.SS1.p2.1.2" class="ltx_text ltx_font_italic">teleported</span> over quantum channels to other nodes in the network. However, qubits are not physically teleported, it is the state that is transferred to another qubit, however, the state of the original qubit is destroyed in this process, that is, the qubit cannot be copied. The teleportation protocol requires an <span id="S2.SS1.p2.1.3" class="ltx_text ltx_font_italic">EPR-pair</span>, i.e., two qubits that are maximally entangled as well as a classical and a quantum channel. In order to teleport qubits over large distances, <span id="S2.SS1.p2.1.4" class="ltx_text ltx_font_italic">quantum repeaters</span> can be deployed along the way to combat decoherence, i.e., the loss of information. Quantum repeaters perform <span id="S2.SS1.p2.1.5" class="ltx_text ltx_font_italic">entanglement swapping</span> and possibly <span id="S2.SS1.p2.1.6" class="ltx_text ltx_font_italic">entanglement distillation</span> that (1) transfer the quantum state and (2) increase the entanglement fidelity.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">With these building blocks established, one can envision a large quantum network that is akin to a so-called quantum internet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. However, how concretely such a quantum internet exactly should look like is up to debate and a crucial research question in quantum communication and quantum computing alike <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. A quantum internet may connect QPUs with vastly different architectures, i.e., consist of heterogeneous nodes, a fact that will become relevant later in this work.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">In summary, a quantum network consists of multiple QPUs connected via classical and quantum channels that allow them to exchange classical as well as quantum information. However, due to various constraints imposed by the laws of quantum physics, many of the classical protocols cannot be transferred to the quantum setting. Moreover, decoherence and the loss of information are major challenges and while countermeasures have been proposed, more research is required to establish a working quantum internet.</p>
</div>
<div id="S2.SS1.p5" class="ltx_para">
<p id="S2.SS1.p5.1" class="ltx_p">This introduction is intended as a short recap of the fundamentals required to follow the work performed in this paper, for an in depth introduction we refer to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Variational Quantum Circuits</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Variational Quantum Circuits (VQCs)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> stand out from classical circuits by leveraging quantum phenomena such as superposition and entanglement. These circuits consist of parameterized gates that are optimized through classical techniques, making them a hybrid approach suited for tasks like quantum machine learning. We summarize the essential components of VQCs in this section and describe how we apply them in the approach introduced in Section <a href="#S4" title="4 Approach ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">VQCs can, for example, be applied to classification problems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> and are a promising hybrid approach to QML in the NISQ-era. As this is a classical-quantum hybrid approach it consists of essentially two parts, namely the quantum circuit and the classical optimization routine. The quantum part, i.e. the VQC, can loosely be divided into three distinct constituents: (i) feature encoding, (ii) a series (layers) of parameterized rotation gates followed by entangling gates and finally (iii) the measurement operations. An example circuit with two layers is depicted in Figure <a href="#S2.F2" title="Figure 2 ‣ 2.2 Variational Quantum Circuits ‣ 2 Background ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The parameters of the rotations correspond to the weights that are optimized by a classical optimizer while the measurement results are interpreted as predictions and are also used by the optimizer. This approach is iterative, i.e., it executes until a number of epochs or steps has been reached. For an in depth introduction to this topic we refer to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.</p>
</div>
<figure id="S2.F2" class="ltx_figure">
<table id="S2.Ex1" class="ltx_equation ltx_centering ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_centering ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex1.m1.4" class="ltx_math_unparsed" alttext="\Qcircuit@C=1em@R=.9em{\lstick{|0\rangle}&amp;\gate{\color[rgb]{0,0.5,1}R_{x}(\phi_{0})}\qw\ctrl{1}\qw\qw\targ\gate{\color[rgb]{0,0.88,0}R_{y}(\theta_{0})}\qw\ctrl{1}\qw\qw\targ\gate{\color[rgb]{0,0.88,0}R_{y}(\theta_{4})}\meter\\
\lstick{|0\rangle}\gate{\color[rgb]{0,0.5,1}R_{x}(\phi_{1})}\qw\targ\ctrl{1}\qw\qw\gate{\color[rgb]{0,0.88,0}R_{y}(\theta_{1})}\qw\targ\ctrl{1}\qw\qw\gate{\color[rgb]{0,0.88,0}R_{y}(\theta_{5})}\meter\\
\lstick{|0\rangle}\gate{\color[rgb]{0,0.5,1}R_{x}(\phi_{2})}\qw\qw\targ\ctrl{1}\qw\gate{\color[rgb]{0,0.88,0}R_{y}(\theta_{2})}\qw\qw\targ\ctrl{1}\qw\gate{\color[rgb]{0,0.88,0}R_{y}(\theta_{6})}\meter\\
\lstick{|0\rangle}\gate{\color[rgb]{0,0.5,1}R_{x}(\phi_{2})}\qw\qw\qw\targ\ctrl{-3}\gate{\color[rgb]{0,0.88,0}R_{y}(\theta_{3})}\qw\qw\qw\targ\ctrl{-3}\gate{\color[rgb]{0,0.88,0}R_{y}(\theta_{7})}\meter\gategroup{1}{2}{4}{2}{.7em}{--}\gategroup{1}{4}{4}{14}{.7em}{--}\gategroup{1}{15}{4}{15}{.7em}{--}\\
\\
\mbox{1. Encoding}\mbox{2. Layers}\mbox{3. Measurement}}" display="block"><semantics id="S2.Ex1.m1.4a"><mrow id="S2.Ex1.m1.4b"><mrow id="S2.Ex1.m1.4.5"><mrow id="S2.Ex1.m1.4.5.1"><mrow id="S2.Ex1.m1.4.5.1.1"><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.1.1.1"><mtext id="S2.Ex1.m1.4.5.1.1.1a">\Qcircuit</mtext></merror><mi mathvariant="normal" id="S2.Ex1.m1.4.5.1.1.2">@</mi><mi id="S2.Ex1.m1.4.5.1.1.3">C</mi><mo id="S2.Ex1.m1.4.5.1.1.4">=</mo><mn id="S2.Ex1.m1.4.5.1.1.5">1</mn><mi id="S2.Ex1.m1.4.5.1.1.6">e</mi><mi id="S2.Ex1.m1.4.5.1.1.7">m</mi><mi mathvariant="normal" id="S2.Ex1.m1.4.5.1.1.8">@</mi><mi id="S2.Ex1.m1.4.5.1.1.9">R</mi><mo id="S2.Ex1.m1.4.5.1.1.10">=</mo><mn id="S2.Ex1.m1.4.5.1.1.11">.9</mn><mi id="S2.Ex1.m1.4.5.1.1.12">e</mi><mi id="S2.Ex1.m1.4.5.1.1.13">m</mi><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.1.1.14"><mtext id="S2.Ex1.m1.4.5.1.1.14a">\lstick</mtext></merror><mo fence="false" rspace="0.167em" stretchy="false" id="S2.Ex1.m1.4.5.1.1.15">|</mo><mn id="S2.Ex1.m1.1.1">0</mn><mo stretchy="false" id="S2.Ex1.m1.4.5.1.1.16">⟩</mo></mrow><mi mathvariant="normal" id="S2.Ex1.m1.4.5.1.2">&amp;</mi><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.1.3"><mtext id="S2.Ex1.m1.4.5.1.3a">\gate</mtext></merror><msub id="S2.Ex1.m1.4.5.1.4"><mi mathcolor="#0080FF" id="S2.Ex1.m1.4.5.1.4.2">R</mi><mi mathcolor="#0080FF" id="S2.Ex1.m1.4.5.1.4.3">x</mi></msub><mrow id="S2.Ex1.m1.4.5.1.5"><mo mathcolor="#0080FF" stretchy="false" id="S2.Ex1.m1.4.5.1.5.1">(</mo><msub id="S2.Ex1.m1.4.5.1.5.2"><mi mathcolor="#0080FF" id="S2.Ex1.m1.4.5.1.5.2.2">ϕ</mi><mn mathcolor="#0080FF" id="S2.Ex1.m1.4.5.1.5.2.3">0</mn></msub><mo mathcolor="#0080FF" stretchy="false" id="S2.Ex1.m1.4.5.1.5.3">)</mo></mrow><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.1.6"><mtext id="S2.Ex1.m1.4.5.1.6a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.1.7"><mtext id="S2.Ex1.m1.4.5.1.7a">\ctrl</mtext></merror><mn id="S2.Ex1.m1.4.5.1.8">1</mn><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.1.9"><mtext id="S2.Ex1.m1.4.5.1.9a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.1.10"><mtext id="S2.Ex1.m1.4.5.1.10a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.1.11"><mtext id="S2.Ex1.m1.4.5.1.11a">\targ</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.1.12"><mtext id="S2.Ex1.m1.4.5.1.12a">\gate</mtext></merror><msub id="S2.Ex1.m1.4.5.1.13"><mi mathcolor="#00E000" id="S2.Ex1.m1.4.5.1.13.2">R</mi><mi mathcolor="#00E000" id="S2.Ex1.m1.4.5.1.13.3">y</mi></msub><mrow id="S2.Ex1.m1.4.5.1.14"><mo mathcolor="#00E000" stretchy="false" id="S2.Ex1.m1.4.5.1.14.1">(</mo><msub id="S2.Ex1.m1.4.5.1.14.2"><mi mathcolor="#00E000" id="S2.Ex1.m1.4.5.1.14.2.2">θ</mi><mn mathcolor="#00E000" id="S2.Ex1.m1.4.5.1.14.2.3">0</mn></msub><mo mathcolor="#00E000" stretchy="false" id="S2.Ex1.m1.4.5.1.14.3">)</mo></mrow><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.1.15"><mtext id="S2.Ex1.m1.4.5.1.15a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.1.16"><mtext id="S2.Ex1.m1.4.5.1.16a">\ctrl</mtext></merror><mn id="S2.Ex1.m1.4.5.1.17">1</mn><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.1.18"><mtext id="S2.Ex1.m1.4.5.1.18a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.1.19"><mtext id="S2.Ex1.m1.4.5.1.19a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.1.20"><mtext id="S2.Ex1.m1.4.5.1.20a">\targ</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.1.21"><mtext id="S2.Ex1.m1.4.5.1.21a">\gate</mtext></merror><msub id="S2.Ex1.m1.4.5.1.22"><mi mathcolor="#00E000" id="S2.Ex1.m1.4.5.1.22.2">R</mi><mi mathcolor="#00E000" id="S2.Ex1.m1.4.5.1.22.3">y</mi></msub><mrow id="S2.Ex1.m1.4.5.1.23"><mo mathcolor="#00E000" stretchy="false" id="S2.Ex1.m1.4.5.1.23.1">(</mo><msub id="S2.Ex1.m1.4.5.1.23.2"><mi mathcolor="#00E000" id="S2.Ex1.m1.4.5.1.23.2.2">θ</mi><mn mathcolor="#00E000" id="S2.Ex1.m1.4.5.1.23.2.3">4</mn></msub><mo mathcolor="#00E000" stretchy="false" id="S2.Ex1.m1.4.5.1.23.3">)</mo></mrow><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.1.24"><mtext id="S2.Ex1.m1.4.5.1.24a">\meter</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.1.25"><mtext id="S2.Ex1.m1.4.5.1.25a">\lstick</mtext></merror><mo fence="false" rspace="0.167em" stretchy="false" id="S2.Ex1.m1.4.5.1.26">|</mo><mn id="S2.Ex1.m1.2.2">0</mn><mo stretchy="false" id="S2.Ex1.m1.4.5.1.27">⟩</mo></mrow><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.2"><mtext id="S2.Ex1.m1.4.5.2a">\gate</mtext></merror><msub id="S2.Ex1.m1.4.5.3"><mi mathcolor="#0080FF" id="S2.Ex1.m1.4.5.3.2">R</mi><mi mathcolor="#0080FF" id="S2.Ex1.m1.4.5.3.3">x</mi></msub><mrow id="S2.Ex1.m1.4.5.4"><mo mathcolor="#0080FF" stretchy="false" id="S2.Ex1.m1.4.5.4.1">(</mo><msub id="S2.Ex1.m1.4.5.4.2"><mi mathcolor="#0080FF" id="S2.Ex1.m1.4.5.4.2.2">ϕ</mi><mn mathcolor="#0080FF" id="S2.Ex1.m1.4.5.4.2.3">1</mn></msub><mo mathcolor="#0080FF" stretchy="false" id="S2.Ex1.m1.4.5.4.3">)</mo></mrow><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.5"><mtext id="S2.Ex1.m1.4.5.5a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.6"><mtext id="S2.Ex1.m1.4.5.6a">\targ</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.7"><mtext id="S2.Ex1.m1.4.5.7a">\ctrl</mtext></merror><mn id="S2.Ex1.m1.4.5.8">1</mn><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.9"><mtext id="S2.Ex1.m1.4.5.9a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.10"><mtext id="S2.Ex1.m1.4.5.10a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.11"><mtext id="S2.Ex1.m1.4.5.11a">\gate</mtext></merror><msub id="S2.Ex1.m1.4.5.12"><mi mathcolor="#00E000" id="S2.Ex1.m1.4.5.12.2">R</mi><mi mathcolor="#00E000" id="S2.Ex1.m1.4.5.12.3">y</mi></msub><mrow id="S2.Ex1.m1.4.5.13"><mo mathcolor="#00E000" stretchy="false" id="S2.Ex1.m1.4.5.13.1">(</mo><msub id="S2.Ex1.m1.4.5.13.2"><mi mathcolor="#00E000" id="S2.Ex1.m1.4.5.13.2.2">θ</mi><mn mathcolor="#00E000" id="S2.Ex1.m1.4.5.13.2.3">1</mn></msub><mo mathcolor="#00E000" stretchy="false" id="S2.Ex1.m1.4.5.13.3">)</mo></mrow><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.14"><mtext id="S2.Ex1.m1.4.5.14a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.15"><mtext id="S2.Ex1.m1.4.5.15a">\targ</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.16"><mtext id="S2.Ex1.m1.4.5.16a">\ctrl</mtext></merror><mn id="S2.Ex1.m1.4.5.17">1</mn><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.18"><mtext id="S2.Ex1.m1.4.5.18a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.19"><mtext id="S2.Ex1.m1.4.5.19a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.20"><mtext id="S2.Ex1.m1.4.5.20a">\gate</mtext></merror><msub id="S2.Ex1.m1.4.5.21"><mi mathcolor="#00E000" id="S2.Ex1.m1.4.5.21.2">R</mi><mi mathcolor="#00E000" id="S2.Ex1.m1.4.5.21.3">y</mi></msub><mrow id="S2.Ex1.m1.4.5.22"><mo mathcolor="#00E000" stretchy="false" id="S2.Ex1.m1.4.5.22.1">(</mo><msub id="S2.Ex1.m1.4.5.22.2"><mi mathcolor="#00E000" id="S2.Ex1.m1.4.5.22.2.2">θ</mi><mn mathcolor="#00E000" id="S2.Ex1.m1.4.5.22.2.3">5</mn></msub><mo mathcolor="#00E000" stretchy="false" id="S2.Ex1.m1.4.5.22.3">)</mo></mrow><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.23"><mtext id="S2.Ex1.m1.4.5.23a">\meter</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.5.24"><mtext id="S2.Ex1.m1.4.5.24a">\lstick</mtext></merror><mo fence="false" rspace="0.167em" stretchy="false" id="S2.Ex1.m1.4.5.25">|</mo><mn id="S2.Ex1.m1.3.3">0</mn><mo stretchy="false" id="S2.Ex1.m1.4.5.26">⟩</mo></mrow><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.6"><mtext id="S2.Ex1.m1.4.6a">\gate</mtext></merror><msub id="S2.Ex1.m1.4.7"><mi mathcolor="#0080FF" id="S2.Ex1.m1.4.7.2">R</mi><mi mathcolor="#0080FF" id="S2.Ex1.m1.4.7.3">x</mi></msub><mrow id="S2.Ex1.m1.4.8"><mo mathcolor="#0080FF" stretchy="false" id="S2.Ex1.m1.4.8.1">(</mo><msub id="S2.Ex1.m1.4.8.2"><mi mathcolor="#0080FF" id="S2.Ex1.m1.4.8.2.2">ϕ</mi><mn mathcolor="#0080FF" id="S2.Ex1.m1.4.8.2.3">2</mn></msub><mo mathcolor="#0080FF" stretchy="false" id="S2.Ex1.m1.4.8.3">)</mo></mrow><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.9"><mtext id="S2.Ex1.m1.4.9a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.10"><mtext id="S2.Ex1.m1.4.10a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.11"><mtext id="S2.Ex1.m1.4.11a">\targ</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.12"><mtext id="S2.Ex1.m1.4.12a">\ctrl</mtext></merror><mn id="S2.Ex1.m1.4.13">1</mn><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.14"><mtext id="S2.Ex1.m1.4.14a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.15"><mtext id="S2.Ex1.m1.4.15a">\gate</mtext></merror><msub id="S2.Ex1.m1.4.16"><mi mathcolor="#00E000" id="S2.Ex1.m1.4.16.2">R</mi><mi mathcolor="#00E000" id="S2.Ex1.m1.4.16.3">y</mi></msub><mrow id="S2.Ex1.m1.4.17"><mo mathcolor="#00E000" stretchy="false" id="S2.Ex1.m1.4.17.1">(</mo><msub id="S2.Ex1.m1.4.17.2"><mi mathcolor="#00E000" id="S2.Ex1.m1.4.17.2.2">θ</mi><mn mathcolor="#00E000" id="S2.Ex1.m1.4.17.2.3">2</mn></msub><mo mathcolor="#00E000" stretchy="false" id="S2.Ex1.m1.4.17.3">)</mo></mrow><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.18"><mtext id="S2.Ex1.m1.4.18a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.19"><mtext id="S2.Ex1.m1.4.19a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.20"><mtext id="S2.Ex1.m1.4.20a">\targ</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.21"><mtext id="S2.Ex1.m1.4.21a">\ctrl</mtext></merror><mn id="S2.Ex1.m1.4.22">1</mn><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.23"><mtext id="S2.Ex1.m1.4.23a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.24"><mtext id="S2.Ex1.m1.4.24a">\gate</mtext></merror><msub id="S2.Ex1.m1.4.25"><mi mathcolor="#00E000" id="S2.Ex1.m1.4.25.2">R</mi><mi mathcolor="#00E000" id="S2.Ex1.m1.4.25.3">y</mi></msub><mrow id="S2.Ex1.m1.4.26"><mo mathcolor="#00E000" stretchy="false" id="S2.Ex1.m1.4.26.1">(</mo><msub id="S2.Ex1.m1.4.26.2"><mi mathcolor="#00E000" id="S2.Ex1.m1.4.26.2.2">θ</mi><mn mathcolor="#00E000" id="S2.Ex1.m1.4.26.2.3">6</mn></msub><mo mathcolor="#00E000" stretchy="false" id="S2.Ex1.m1.4.26.3">)</mo></mrow><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.27"><mtext id="S2.Ex1.m1.4.27a">\meter</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.28"><mtext id="S2.Ex1.m1.4.28a">\lstick</mtext></merror><mo fence="false" rspace="0.167em" stretchy="false" id="S2.Ex1.m1.4.29">|</mo><mn id="S2.Ex1.m1.4.4">0</mn><mo stretchy="false" id="S2.Ex1.m1.4.30">⟩</mo><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.31"><mtext id="S2.Ex1.m1.4.31a">\gate</mtext></merror><mi mathcolor="#0080FF" id="S2.Ex1.m1.4.32">R</mi><msub id="S2.Ex1.m1.4.33"><mi id="S2.Ex1.m1.4.33a"></mi><mi mathcolor="#0080FF" id="S2.Ex1.m1.4.33.1">x</mi></msub><mo mathcolor="#0080FF" stretchy="false" id="S2.Ex1.m1.4.34">(</mo><msub id="S2.Ex1.m1.4.35"><mi mathcolor="#0080FF" id="S2.Ex1.m1.4.35.2">ϕ</mi><mn mathcolor="#0080FF" id="S2.Ex1.m1.4.35.3">2</mn></msub><mo mathcolor="#0080FF" stretchy="false" id="S2.Ex1.m1.4.36">)</mo><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.37"><mtext id="S2.Ex1.m1.4.37a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.38"><mtext id="S2.Ex1.m1.4.38a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.39"><mtext id="S2.Ex1.m1.4.39a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.40"><mtext id="S2.Ex1.m1.4.40a">\targ</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.41"><mtext id="S2.Ex1.m1.4.41a">\ctrl</mtext></merror><mo id="S2.Ex1.m1.4.42">−</mo><mn id="S2.Ex1.m1.4.43">3</mn><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.44"><mtext id="S2.Ex1.m1.4.44a">\gate</mtext></merror><mi mathcolor="#00E000" id="S2.Ex1.m1.4.45">R</mi><msub id="S2.Ex1.m1.4.46"><mi id="S2.Ex1.m1.4.46a"></mi><mi mathcolor="#00E000" id="S2.Ex1.m1.4.46.1">y</mi></msub><mo mathcolor="#00E000" stretchy="false" id="S2.Ex1.m1.4.47">(</mo><msub id="S2.Ex1.m1.4.48"><mi mathcolor="#00E000" id="S2.Ex1.m1.4.48.2">θ</mi><mn mathcolor="#00E000" id="S2.Ex1.m1.4.48.3">3</mn></msub><mo mathcolor="#00E000" stretchy="false" id="S2.Ex1.m1.4.49">)</mo><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.50"><mtext id="S2.Ex1.m1.4.50a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.51"><mtext id="S2.Ex1.m1.4.51a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.52"><mtext id="S2.Ex1.m1.4.52a">\qw</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.53"><mtext id="S2.Ex1.m1.4.53a">\targ</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.54"><mtext id="S2.Ex1.m1.4.54a">\ctrl</mtext></merror><mo id="S2.Ex1.m1.4.55">−</mo><mn id="S2.Ex1.m1.4.56">3</mn><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.57"><mtext id="S2.Ex1.m1.4.57a">\gate</mtext></merror><mi mathcolor="#00E000" id="S2.Ex1.m1.4.58">R</mi><msub id="S2.Ex1.m1.4.59"><mi id="S2.Ex1.m1.4.59a"></mi><mi mathcolor="#00E000" id="S2.Ex1.m1.4.59.1">y</mi></msub><mo mathcolor="#00E000" stretchy="false" id="S2.Ex1.m1.4.60">(</mo><msub id="S2.Ex1.m1.4.61"><mi mathcolor="#00E000" id="S2.Ex1.m1.4.61.2">θ</mi><mn mathcolor="#00E000" id="S2.Ex1.m1.4.61.3">7</mn></msub><mo mathcolor="#00E000" stretchy="false" id="S2.Ex1.m1.4.62">)</mo><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.63"><mtext id="S2.Ex1.m1.4.63a">\meter</mtext></merror><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.64"><mtext id="S2.Ex1.m1.4.64a">\gategroup</mtext></merror><mn id="S2.Ex1.m1.4.65">1242.7</mn><mi id="S2.Ex1.m1.4.66">e</mi><mi id="S2.Ex1.m1.4.67">m</mi><mo rspace="0em" id="S2.Ex1.m1.4.68">−</mo><mo lspace="0em" id="S2.Ex1.m1.4.69">−</mo><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.70"><mtext id="S2.Ex1.m1.4.70a">\gategroup</mtext></merror><mn id="S2.Ex1.m1.4.71">14414.7</mn><mi id="S2.Ex1.m1.4.72">e</mi><mi id="S2.Ex1.m1.4.73">m</mi><mo rspace="0em" id="S2.Ex1.m1.4.74">−</mo><mo lspace="0em" id="S2.Ex1.m1.4.75">−</mo><merror class="ltx_ERROR undefined undefined" id="S2.Ex1.m1.4.76"><mtext id="S2.Ex1.m1.4.76a">\gategroup</mtext></merror><mn id="S2.Ex1.m1.4.77">115415.7</mn><mi id="S2.Ex1.m1.4.78">e</mi><mi id="S2.Ex1.m1.4.79">m</mi><mo rspace="0em" id="S2.Ex1.m1.4.80">−</mo><mo lspace="0em" id="S2.Ex1.m1.4.81">−</mo><mrow id="S2.Ex1.m1.4.82"><mtext id="S2.Ex1.m1.4.82a">1. Encoding</mtext><mtext id="S2.Ex1.m1.4.82b">2. Layers</mtext><mtext id="S2.Ex1.m1.4.82c">3. Measurement</mtext></mrow></mrow><annotation encoding="application/x-tex" id="S2.Ex1.m1.4c">\Qcircuit@C=1em@R=.9em{\lstick{|0\rangle}&amp;\gate{\color[rgb]{0,0.5,1}R_{x}(\phi_{0})}\qw\ctrl{1}\qw\qw\targ\gate{\color[rgb]{0,0.88,0}R_{y}(\theta_{0})}\qw\ctrl{1}\qw\qw\targ\gate{\color[rgb]{0,0.88,0}R_{y}(\theta_{4})}\meter\\
\lstick{|0\rangle}\gate{\color[rgb]{0,0.5,1}R_{x}(\phi_{1})}\qw\targ\ctrl{1}\qw\qw\gate{\color[rgb]{0,0.88,0}R_{y}(\theta_{1})}\qw\targ\ctrl{1}\qw\qw\gate{\color[rgb]{0,0.88,0}R_{y}(\theta_{5})}\meter\\
\lstick{|0\rangle}\gate{\color[rgb]{0,0.5,1}R_{x}(\phi_{2})}\qw\qw\targ\ctrl{1}\qw\gate{\color[rgb]{0,0.88,0}R_{y}(\theta_{2})}\qw\qw\targ\ctrl{1}\qw\gate{\color[rgb]{0,0.88,0}R_{y}(\theta_{6})}\meter\\
\lstick{|0\rangle}\gate{\color[rgb]{0,0.5,1}R_{x}(\phi_{2})}\qw\qw\qw\targ\ctrl{-3}\gate{\color[rgb]{0,0.88,0}R_{y}(\theta_{3})}\qw\qw\qw\targ\ctrl{-3}\gate{\color[rgb]{0,0.88,0}R_{y}(\theta_{7})}\meter\gategroup{1}{2}{4}{2}{.7em}{--}\gategroup{1}{4}{4}{14}{.7em}{--}\gategroup{1}{15}{4}{15}{.7em}{--}\\
\\
\mbox{1. Encoding}\mbox{2. Layers}\mbox{3. Measurement}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.4.2.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.2.1" class="ltx_text" style="font-size:90%;">Example of a variational quantum circuit (VQC): Features are embedded through rotations (depicted blue) in the first step. This is followed by two repeating layers of CNOT-gates and parameterized rotations (green), the <math id="S2.F2.2.1.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S2.F2.2.1.m1.1b"><mi id="S2.F2.2.1.m1.1.1" xref="S2.F2.2.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.F2.2.1.m1.1c"><ci id="S2.F2.2.1.m1.1.1.cmml" xref="S2.F2.2.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.2.1.m1.1d">\theta</annotation></semantics></math> values are the weights being optimized. In the final step, the qubits are measured resulting in a classical output (0 or 1) for each qubit. </span></figcaption>
</figure>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Quantum Federated Learning</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Before discussing QFL we will first give a short recap of the central idea behind federated learning in general, i.e., its origins in classical machine learning. We will then discuss quantum variants of this learning approach.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">Federated learning (FL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> allows for the collective training of a global model by multiple clients, each contributing to the model without exposing their private data. This ensures that each client’s data remains confidential and local to them. Rather than sharing data, clients transmit their model weights to a central server, where these weights are aggregated, updated, and then redistributed to all clients for further training iterations. Moreover, each client may be trained on different subsets or even entirely different datasets. Furthermore, many variants and approaches to FL have been proposed; the approach here is a basic and straightforward one, as we focus on QFL in this paper. For our purposes, it suffices to define FL as an decentralized learning approach in which a global model is trained by multiple clients without revealing their private data. For more comprehensive introduction to the topic we refer to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite></p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">QFL follows a similar line, however, many different approaches can also be employed here; though we will be focusing on simplicity. In QFL, the client models can be replaced by VQCs, and weights can be communicated through classical as well as quantum channels, though the former does not necessarily require a quantum network while the latter does. Analog to the classical approach, each client (e.g. VQC) is then trained on its own local dataset. We will discuss the peculiar details arising through the quantum internet in Section <a href="#S4" title="4 Approach ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Related Work</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Several different approaches and aspects of QFL have been explored by the research community. For example, privacy aspects are investigated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> while combining QFL with blind quantum computing is discussed by Li et al. in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> and Zhang et al. propose a quantum method for parameter aggregation in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. Challenges of QFL in the context of quantum networks are discussed by Chehimi et al. in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. Wang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> apply QFL on a binary classification task using a ring topology, i.e., without a central model. Moreover, they use quantum weights in their approach. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> the authors evaluate a hybrid quantum-classical approach on a binary classification task using images.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Approach</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we describe our approach to QFL. We discuss quantum clients and the overall architecture of our methods. This includes network constraints as well as how the models train and communicate.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Quantum Clients</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">In our proposed QFL approach, the client model is a VQC running on a quantum node in a (quantum) communication network. More specifically, we consider the quantum internet in which nodes are quantum computers each with potentially a different qubit capacity. It’s important to note that the necessity for a quantum communication channel hinges on the specific methodology of weight exchange in the applied QFL approach. That is, weights can be exchanged classically and thus a simple classical channel connecting quantum nodes suffices. Furthermore, in our scenario each node executes the model of only a single client. Thus, the clients in our QFL approach execute VQCs with a different number of qubits and hence number of trainable parameters. Consider the example network in Figure <a href="#S2.F1" title="Figure 1 ‣ 2.1 Quantum Networks and the Quantum Internet ‣ 2 Background ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Here, 9 nodes are connected to form a network where nodes have different qubit capacities.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Architecture</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We evaluate two different approaches to QFL as part of this work that differ in the topology of the arrangement of clients and how weights are aggregated and exchanged. In the first approach, a global model is collectively trained by multiple clients who only exchange their weights with the global model. The global model is then responsible for aggregating, updating and distributing the weights among all participants in each training round. An example of this architecture is depicted in Figure <a href="#S4.F3" title="Figure 3 ‣ 4.2 Architecture ‣ 4 Approach ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2402.09902/assets/Images/Architecture/global_model_topology_example.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="284" height="101" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.3.2" class="ltx_text" style="font-size:90%;">Example of a QFL approach where a global model is collectively trained by 4 different clients with different qubit capacities. Clients send their weights to the global model that aggregates, updates and distributes the new weights for the next round of training.</span></figcaption>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">In the second approach, clients are arranged in a ring topology (cf. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>) and no global model is trained. More specifically, clients train their model using their local dataset and send their weights to the succeeding client after completing a training round. This approach is shown in Figure <a href="#S4.F4" title="Figure 4 ‣ 4.2 Architecture ‣ 4 Approach ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. As the clients capacity, i.e., number of qubits may vary from one to the next, the number of weights must be adjusted when sent to the following client. In our experiments we adjust the number of weights in the following way. If the next client contains less qubits (and thus weights), the client discards superfluous weights, i.e., it only uses the first <span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_italic">n</span> weights required. In the case where the next client contains more qubits, the client uses all weights from the previous one while filling up the missing weights with its own from the last round. Note that this is an ad-hoc approach and the appropriate aggregation of weights in the context of trainability is its own research topic and merits its own discussion, however, is not in the scope of this work.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2402.09902/assets/Images/Architecture/ring_topology_example.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="177" height="111" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.3.2" class="ltx_text" style="font-size:90%;">Example of clients with varying qubit capacity arranged in a ring topology. In this scenario, when clients transfer their weights to the next, the number of weights is adjusted accordingly.</span></figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Quantum Circuits</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In our model, we apply two different VQCs that differ only in the embedding method applied and number of qubits. That is, we use angle embedding in one set of experiments and amplitude embedding in another.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental Setup</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This section outlines the models, datasets, and parameters used in our experiments.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Datasets</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Our experiments utilize three datasets, detailed as follows. Note that we focus solely on binary classification in this work. In datasets that contain more than two classes, we divide the dataset into subsets such that each only contains images of two classes.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold">Moons:</span> The moons dataset contains 2 features for a binary classification problem where each class is shaped as a half circle and is provided by scikit-learn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. We used a dataset with 3000 samples. The training set used is visualised in Figure <a href="#S5.F5" title="Figure 5 ‣ 5.1 Datasets ‣ 5 Experimental Setup ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<figure id="S5.F5" class="ltx_figure"><img src="/html/2402.09902/assets/Images/moons_data.png" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="384" height="288" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S5.F5.3.2" class="ltx_text" style="font-size:90%;">Two half circles ("moons" dataset) with added noise factor of 0.1 created with sci-kit learn.</span></figcaption>
</figure>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p"><span id="S5.SS1.p3.1.1" class="ltx_text ltx_font_bold">FashionMNIST:</span> The FashionMNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> dataset contains 70000 grayscale images for 10 different classes where each image has a size of <math id="S5.SS1.p3.1.m1.1" class="ltx_Math" alttext="28\times 28" display="inline"><semantics id="S5.SS1.p3.1.m1.1a"><mrow id="S5.SS1.p3.1.m1.1.1" xref="S5.SS1.p3.1.m1.1.1.cmml"><mn id="S5.SS1.p3.1.m1.1.1.2" xref="S5.SS1.p3.1.m1.1.1.2.cmml">28</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.p3.1.m1.1.1.1" xref="S5.SS1.p3.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS1.p3.1.m1.1.1.3" xref="S5.SS1.p3.1.m1.1.1.3.cmml">28</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.m1.1b"><apply id="S5.SS1.p3.1.m1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1"><times id="S5.SS1.p3.1.m1.1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1.1"></times><cn type="integer" id="S5.SS1.p3.1.m1.1.1.2.cmml" xref="S5.SS1.p3.1.m1.1.1.2">28</cn><cn type="integer" id="S5.SS1.p3.1.m1.1.1.3.cmml" xref="S5.SS1.p3.1.m1.1.1.3">28</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.m1.1c">28\times 28</annotation></semantics></math>. Note that there are 60.000 training and 10000 test images. We used this dataset provided by PyTorch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.1" class="ltx_p"><span id="S5.SS1.p4.1.1" class="ltx_text ltx_font_bold">PneumoniaMNIST:</span> The PneumoniaMNIST dataset contains 5856 chest X-ray images with a size of <math id="S5.SS1.p4.1.m1.1" class="ltx_Math" alttext="28\times 28" display="inline"><semantics id="S5.SS1.p4.1.m1.1a"><mrow id="S5.SS1.p4.1.m1.1.1" xref="S5.SS1.p4.1.m1.1.1.cmml"><mn id="S5.SS1.p4.1.m1.1.1.2" xref="S5.SS1.p4.1.m1.1.1.2.cmml">28</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.p4.1.m1.1.1.1" xref="S5.SS1.p4.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS1.p4.1.m1.1.1.3" xref="S5.SS1.p4.1.m1.1.1.3.cmml">28</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.1.m1.1b"><apply id="S5.SS1.p4.1.m1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1"><times id="S5.SS1.p4.1.m1.1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1.1"></times><cn type="integer" id="S5.SS1.p4.1.m1.1.1.2.cmml" xref="S5.SS1.p4.1.m1.1.1.2">28</cn><cn type="integer" id="S5.SS1.p4.1.m1.1.1.3.cmml" xref="S5.SS1.p4.1.m1.1.1.3">28</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.1.m1.1c">28\times 28</annotation></semantics></math> for binary classification. We used the dataset provided by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. Note that for all datasets, we used 1000 images per epoch in training.</p>
</div>
<div id="S5.SS1.p5" class="ltx_para">
<p id="S5.SS1.p5.1" class="ltx_p"><span id="S5.SS1.p5.1.1" class="ltx_text ltx_font_bold">Preprocessing:</span> Images were resized for QPUs with lesser capacity than required to embed the entire image, the number of features used is shown in Table <a href="#S5.T1" title="Table 1 ‣ 5.2.1 Multiple clients, single dataset: ‣ 5.2 Training ‣ 5 Experimental Setup ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Training</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">In this section, we discuss the two training approaches we apply in our experiments. In the first, multiple clients are trained on a single dataset while in the second each client is trained on a different dataset.</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1 </span>Multiple clients, single dataset:</h4>

<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.1" class="ltx_p">In this experiment, each client is trained on a single dataset (moons), however, the dataset is subdivided into distinct subsets prior, i.e., each client is trained on a different subset of the same dataset. Furthermore, in this experiment each client has an equal number of qubits (2) and uses a VQC with angle embedding as its model. The parameters used are listed in Table <a href="#S5.T1" title="Table 1 ‣ 5.2.1 Multiple clients, single dataset: ‣ 5.2 Training ‣ 5 Experimental Setup ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. This experiment was run using both topologies described in Section <a href="#S4" title="4 Approach ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a></p>
</div>
<figure id="S5.T1" class="ltx_table">
<table id="S5.T1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T1.2.1.1" class="ltx_tr">
<th id="S5.T1.2.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<td id="S5.T1.2.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T1.2.1.1.2.1" class="ltx_text ltx_font_bold">MCSD</span></td>
<td id="S5.T1.2.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T1.2.1.1.3.1" class="ltx_text ltx_font_bold">MCMD</span></td>
<td id="S5.T1.2.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T1.2.1.1.4.1" class="ltx_text ltx_font_bold">Baseline (MCSD)</span></td>
<td id="S5.T1.2.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T1.2.1.1.5.1" class="ltx_text ltx_font_bold">Baseline (MCMD)</span></td>
</tr>
<tr id="S5.T1.2.2.2" class="ltx_tr">
<th id="S5.T1.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S5.T1.2.2.2.1.1" class="ltx_text ltx_font_bold">Features</span></th>
<td id="S5.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td id="S5.T1.2.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">[16, 64, 784, 784]</td>
<td id="S5.T1.2.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td id="S5.T1.2.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">784</td>
</tr>
<tr id="S5.T1.2.3.3" class="ltx_tr">
<th id="S5.T1.2.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S5.T1.2.3.3.1.1" class="ltx_text ltx_font_bold">Depth</span></th>
<td id="S5.T1.2.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">8</td>
<td id="S5.T1.2.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10</td>
<td id="S5.T1.2.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">8</td>
<td id="S5.T1.2.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10</td>
</tr>
<tr id="S5.T1.2.4.4" class="ltx_tr">
<th id="S5.T1.2.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S5.T1.2.4.4.1.1" class="ltx_text ltx_font_bold">Qubits</span></th>
<td id="S5.T1.2.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td id="S5.T1.2.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">[4, 6, 10, 10]</td>
<td id="S5.T1.2.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td id="S5.T1.2.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10</td>
</tr>
<tr id="S5.T1.2.5.5" class="ltx_tr">
<th id="S5.T1.2.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S5.T1.2.5.5.1.1" class="ltx_text ltx_font_bold">Clients</span></th>
<td id="S5.T1.2.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3</td>
<td id="S5.T1.2.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4</td>
<td id="S5.T1.2.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S5.T1.2.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S5.T1.2.6.6" class="ltx_tr">
<th id="S5.T1.2.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><span id="S5.T1.2.6.6.1.1" class="ltx_text ltx_font_bold">Embedding</span></th>
<td id="S5.T1.2.6.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Angle</td>
<td id="S5.T1.2.6.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Amplitude</td>
<td id="S5.T1.2.6.6.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Angle</td>
<td id="S5.T1.2.6.6.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Amplitude</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T1.3.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S5.T1.4.2" class="ltx_text" style="font-size:90%;">Parameters used in the QFL and quantum baseline experiments. (MCSD=multiple clients single dataset, MCMD=multiple clients multiple datasets). Note that in the experiments where all clients have an equal capacity, the capacity is set to the number of qubits required to embed all features (i.e., 2 for the moons and 10 for the image datasets).</span></figcaption>
</figure>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2 </span>Multiple clients, multiple datasets:</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.1" class="ltx_p">In this experiment, multiple datasets are used in training, that is, each client is trained on a different trainingset or subset. More specifically, we used three distinct subsets of FashionMNIST ("Trouser vs. Pullover", "Sandal vs. Sneaker" and "Dress vs. Coat") and the pneumonia dataset, where each client was trained on one of these sets. For example, client 1 is trained on images depicting trousers and pullovers, client 2 on sandals and sneakers while the third client is trained on chest X-ray images and the fourth on images of dresses and coats, each in a binary classification task. Moreover, each client may have a different capacity (i.e. qubits). This means that each client also embed, and thus are trained, using a different number of features of the input image. Parameters of this approach are depicted in Table <a href="#S5.T1" title="Table 1 ‣ 5.2.1 Multiple clients, single dataset: ‣ 5.2 Training ‣ 5 Experimental Setup ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Like the first experiment, this one was also run using both topologies described in Section <a href="#S4" title="4 Approach ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Results</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We discuss the results of all experiments conducted as part of this work in this section. We first examine the experiments with multiple clients, single dataset using both QFL approaches described earlier. We then move on to the experiments with multiple clients, multiple datasts. All experiments were run with 5 different seeds and plots depict the mean of the aggregated results. Note that for baselines, we aggregated the results of all individual binary classification experiments, which is a crucial fact to keep in mind when comparing all approaches. Moreover, in the test results of the experiments using the ring topology, each client uses the final parameters after training for its own model on its respective test dataset and the results depicted below are aggregated over all clients.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Multiple Clients, Single Dataset</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">Recall that in this setting, we train multiple clients on a single dataset (we abbreviate this approach as MCSD), however, each client receives its own distinct subset. Furthermore, we evaluated this approach on two different QFL architectures, i.e., topologies, namely star and ring. Training and test results for this experiment with the star topology are shown in Figure <a href="#S6.F6.sf1" title="In Figure 6 ‣ 6.1 Multiple Clients, Single Dataset ‣ 6 Results ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a> and Figure <a href="#S6.F6.sf2" title="In Figure 6 ‣ 6.1 Multiple Clients, Single Dataset ‣ 6 Results ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a> respectively. The classical baseline delivers the best training and test accuracy, though this was to be expected as this approach consists of vastly more parameters and a problem of this scale generally is not problematic for classical neural networks. The QFL approach achieves similar performance as the quantum baseline; the difference being only minuscule.</p>
</div>
<figure id="S6.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F6.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2402.09902/assets/Images/Results/mcsd_star_train_accuracy_plot.png" id="S6.F6.sf1.g1" class="ltx_graphics ltx_img_landscape" width="256" height="192" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F6.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S6.F6.sf1.3.2" class="ltx_text" style="font-size:90%;">Training accuracy..</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F6.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2402.09902/assets/Images/Results/mcsd_star_test_accuracy.png" id="S6.F6.sf2.g1" class="ltx_graphics ltx_img_landscape" width="256" height="192" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F6.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S6.F6.sf2.3.2" class="ltx_text" style="font-size:90%;">Test accuracy.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S6.F6.3.2" class="ltx_text" style="font-size:90%;">Results for the MCSD experiments using the star topology.</span></figcaption>
</figure>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">The train and test results using a ring topology with the moons data is shown in Figure <a href="#S6.F7.sf1" title="In Figure 7 ‣ 6.1 Multiple Clients, Single Dataset ‣ 6 Results ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(a)</span></a> and <a href="#S6.F7.sf2" title="In Figure 7 ‣ 6.1 Multiple Clients, Single Dataset ‣ 6 Results ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(b)</span></a> respectively. While the quantum baseline performs slightly better earlier in training, both approaches perform almost identical and converge relatively fast. Testing results are in a similar range for both quantum methods.</p>
</div>
<figure id="S6.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F7.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2402.09902/assets/Images/Results/mcsd_ring_train_accuracy_plot.png" id="S6.F7.sf1.g1" class="ltx_graphics ltx_img_landscape" width="256" height="192" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F7.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S6.F7.sf1.3.2" class="ltx_text" style="font-size:90%;">Training accuracy. </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F7.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2402.09902/assets/Images/Results/mcsd_ring_test_accuracy.png" id="S6.F7.sf2.g1" class="ltx_graphics ltx_img_landscape" width="256" height="192" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F7.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S6.F7.sf2.3.2" class="ltx_text" style="font-size:90%;">Test accuracy. </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S6.F7.3.2" class="ltx_text" style="font-size:90%;">Training and test results on MCSD experiments with the ring topology.</span></figcaption>
</figure>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Multiple Clients, Multiple Datasets</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">We discuss the experiments using multiple clients, multiple datasets (MCMD) next. Recall that in these experiments, each client is trained on a different dataset, that is, the first client is trained using images of two distinct classes from FashionMNIST, the second uses two different classes from the same dataset while the third client is trained using the PneumoniaMNIST dataset and a fourth client is trained from two different classes from FashionMNIST. Note that the baselines were also trained on these datasates individually, the results depicted in the plots are aggregated over the individual experiments. Moreover, we ran the QFL experiments in two different settings in each topology; results of both are shown in each plot. In one setting, the QPU capacity (i.e., number of qubits) varies for each client. As QPUs therefore run slightly different circuits, the number of features embedded also vary. To accommodate this, the images were resized for each client individually such that it fits the capacity of the respective client. Details on number of qubits and embedded features for each client are listed in Table <a href="#S5.T1" title="Table 1 ‣ 5.2.1 Multiple clients, single dataset: ‣ 5.2 Training ‣ 5 Experimental Setup ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. In the second setting, we ran the QFL experiments in which each client has the same capacity; the capacity was chosen such that the entire image could be embedded. The motivation behind the first approach is the fact that in a potential quantum internet, quantum computers of different architectures, capacity, etc. might be connected; we evaluated such a setting on a small scale.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p">Figures <a href="#S6.F8.sf1" title="In Figure 8 ‣ 6.2 Multiple Clients, Multiple Datasets ‣ 6 Results ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(a)</span></a> and <a href="#S6.F8.sf2" title="In Figure 8 ‣ 6.2 Multiple Clients, Multiple Datasets ‣ 6 Results ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a> show the training and test results using the star topology. While the QFL approach with varying QPU capacity delivers better training results than with equal capacity, its results on the test set are less stable.</p>
</div>
<figure id="S6.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F8.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2402.09902/assets/Images/Results/mcmd_star_train_accuracy_plot.png" id="S6.F8.sf1.g1" class="ltx_graphics ltx_img_landscape" width="256" height="192" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F8.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S6.F8.sf1.3.2" class="ltx_text" style="font-size:90%;">Training accuracy.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F8.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2402.09902/assets/Images/Results/mcmd_star_test_accuracy.png" id="S6.F8.sf2.g1" class="ltx_graphics ltx_img_landscape" width="256" height="192" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F8.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S6.F8.sf2.3.2" class="ltx_text" style="font-size:90%;">Test accuracy.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S6.F8.3.2" class="ltx_text" style="font-size:90%;">MCMD experiment results using the star topology.</span></figcaption>
</figure>
<div id="S6.SS2.p3" class="ltx_para">
<p id="S6.SS2.p3.1" class="ltx_p">The results using the ring topology are shown in Figure <a href="#S6.F9.sf1" title="In Figure 9 ‣ 6.2 Multiple Clients, Multiple Datasets ‣ 6 Results ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(a)</span></a> and <a href="#S6.F9.sf2" title="In Figure 9 ‣ 6.2 Multiple Clients, Multiple Datasets ‣ 6 Results ‣ Towards Federated Learning on the Quantum Internet" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(b)</span></a>. In this approach, the quantum baseline delivers the best quantum results in both training and test accuracy. All approaches, including the classical baseline, converge relatively early though.</p>
</div>
<figure id="S6.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F9.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2402.09902/assets/Images/Results/mcmd_ring_train_accuracy_plot.png" id="S6.F9.sf1.g1" class="ltx_graphics ltx_img_landscape" width="256" height="192" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F9.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S6.F9.sf1.3.2" class="ltx_text" style="font-size:90%;">Training accuracy.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F9.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2402.09902/assets/Images/Results/mcmd_ring_test_accuracy.png" id="S6.F9.sf2.g1" class="ltx_graphics ltx_img_landscape" width="256" height="192" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F9.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S6.F9.sf2.3.2" class="ltx_text" style="font-size:90%;">Test accuracy.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F9.2.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S6.F9.3.2" class="ltx_text" style="font-size:90%;">MCMD results using the ring topology.</span></figcaption>
</figure>
<div id="S6.SS2.p4" class="ltx_para">
<p id="S6.SS2.p4.1" class="ltx_p">Overall, the baselines deliver the best results in our experiments on image data, however, the QFL approaches produce acceptable results all the same. Though the differences in accuracy between both training approaches in QFL, i.e., ring and star, require further investigation. While the star approach seems less stable during training, the training accuracy nonetheless performs much better than the ring approach. However, on the test set the ring approach performs slightly better. Adjusting hyperparamters and the nature of weight exchange and aggregation are likely to affect the models performance, though optimizing for performance (i.e., accuracy) was not the objective of these experiments and is left for future work.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">Though the quantum internet promises diverse applications, it remains in nascent stages of development. Determining its exact nature, benefits, and optimal applications requires further comprehensive research. QFL is one such potential application, having its roots in classical machine learning, it can nonetheless be transferred to the field of quantum computing. And while QFL has been studied by the QML research community in recent years, far more research is required, especially when taking concrete ramifications of quantum communication into account as new challenges will inevitably arise through the incorporation of this novel communication medium.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">In this paper, we presented and evaluated different scenarios of QFL that may arise on a potential quantum internet. We ran experiments using different network constraints that also differ how the clients are trained. Moreover, we ran these experiments in two settings, i.e., (1) QPUs with varying capacity and (2) equal capacity, where the former may be a more realistic setting in a large-scale quantum internet. Our results show that QFL is a viable alternative to regular training of quantum models, we furthermore show that the topology, i.e., the way models are trained influences the models performance. Note, however, we only simulated our experiments, moreover, weights were exchanged classically. Using quantum communication (e.g. teleportation) for the weight exchange should be investigated in future studies. Other relevant factors such as trainability and scalability should also be explored.</p>
</div>
<div id="S7.p3" class="ltx_para">
<span id="S7.p3.1" class="ltx_ERROR undefined">{credits}</span>
</div>
<section id="S7.SS0.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.0.1 </span>Acknowledgements</h4>

<div id="S7.SS0.SSS1.p1" class="ltx_para">
<p id="S7.SS0.SSS1.p1.1" class="ltx_p">This work is sponsored in part by the Bavarian Ministry of Economic Affairs, Regional Development and Energy as part of the 6GQT project (<a target="_blank" href="https://6gqt.de" title="" class="ltx_ref">https://6gqt.de</a>)</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Caleffi, M., Amoretti, M., Ferrari, D., Cuomo, D., Illiano, J., Manzalini, A., Cacciapuoti, A.S.: Distributed quantum computing: a survey. arXiv preprint arXiv:2212.10609 (2022)

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Caleffi, M., Cacciapuoti, A.S., Bianchi, G.: Quantum internet: From communication to distributed computing! In: Proceedings of the 5th ACM international conference on nanoscale computing and communication. pp. 1–4 (2018)

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Cerezo, M., Arrasmith, A., Babbush, R., Benjamin, S.C., Endo, S., Fujii, K., McClean, J.R., Mitarai, K., Yuan, X., Cincio, L., et al.: Variational quantum algorithms. Nature Reviews Physics <span id="bib.bib3.1.1" class="ltx_text ltx_font_bold">3</span>(9), 625–644 (2021)

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Chehimi, M., Chen, S.Y.C., Saad, W., Towsley, D., Debbah, M.: Foundations of Quantum Federated Learning Over Classical and Quantum Networks (Oct 2023), arXiv:2310.14516 [quant-ph]

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Chen, S.Y.C., Yoo, S.: Federated quantum machine learning. Entropy <span id="bib.bib5.1.1" class="ltx_text ltx_font_bold">23</span>(4),  460 (2021)

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Geyer, R.C., Klein, T., Nabi, M.: Differentially private federated learning: A client level perspective. arXiv preprint arXiv:1712.07557 (2017)

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Illiano, J., Caleffi, M., Manzalini, A., Cacciapuoti, A.S.: Quantum internet protocol stack: A comprehensive survey. Computer Networks <span id="bib.bib7.1.1" class="ltx_text ltx_font_bold">213</span>, 109092 (2022)

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Kimble, H.J.: The quantum internet. Nature <span id="bib.bib8.1.1" class="ltx_text ltx_font_bold">453</span>(7198), 1023–1030 (2008)

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Konečnỳ, J., McMahan, H.B., Yu, F.X., Richtárik, P., Suresh, A.T., Bacon, D.: Federated learning: Strategies for improving communication efficiency. arXiv preprint arXiv:1610.05492 (2016)

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Kozlowski, W., Wehner, S.: Towards large-scale quantum networks. In: Proceedings of the sixth annual ACM international conference on nanoscale computing and communication. pp. 1–7 (2019)

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Li, C., Kumar, N., Song, Z., Chakrabarti, S., Pistoia, M.: Privacy-preserving quantum federated learning via gradient hiding (2023)

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Li, W., Lu, S., Deng, D.L.: Quantum federated learning through blind quantum computing. Science China Physics, Mechanics &amp; Astronomy <span id="bib.bib12.1.1" class="ltx_text ltx_font_bold">64</span>(10), 100312 (2021). https://doi.org/10.1007/s11433-021-1753-3, <a target="_blank" href="http://arxiv.org/abs/2103.08403" title="" class="ltx_ref">http://arxiv.org/abs/2103.08403</a>, arXiv:2103.08403 [quant-ph]

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
McMahan, B., Moore, E., Ramage, D., Hampson, S., y Arcas, B.A.: Communication-efficient learning of deep networks from decentralized data. In: Artificial intelligence and statistics. pp. 1273–1282. PMLR (2017)

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Mitarai, K., Negoro, M., Kitagawa, M., Fujii, K.: Quantum circuit learning. Physical Review A <span id="bib.bib14.1.1" class="ltx_text ltx_font_bold">98</span>(3), 032309 (2018)

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Nielsen, M.A., Chuang, I.L.: Quantum computation and quantum information. Cambridge university press (2010)

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., et al.: Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems <span id="bib.bib16.1.1" class="ltx_text ltx_font_bold">32</span> (2019)

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, E.: Scikit-learn: Machine learning in Python. Journal of Machine Learning Research <span id="bib.bib17.1.1" class="ltx_text ltx_font_bold">12</span>, 2825–2830 (2011)

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Rofougaran, R., Yoo, S., Tseng, H.H., Chen, S.Y.C.: Federated Quantum Machine Learning with Differential Privacy (2023)

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Schuld, M., Bocharov, A., Svore, K.M., Wiebe, N.: Circuit-centric quantum classifiers. Physical Review A <span id="bib.bib19.1.1" class="ltx_text ltx_font_bold">101</span>(3), 032308 (2020)

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Simon, C.: Towards a global quantum network. Nature Photonics <span id="bib.bib20.1.1" class="ltx_text ltx_font_bold">11</span>(11), 678–680 (2017)

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Van Meter, R., Satoh, R., Benchasattabuse, N., Teramoto, K., Matsuo, T., Hajdušek, M., Satoh, T., Nagayama, S., Suzuki, S.: A quantum internet architecture. In: 2022 IEEE International Conference on Quantum Computing and Engineering (QCE). pp. 341–352. IEEE (2022)

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Van Meter, R., Touch, J.: Designing quantum repeater networks. IEEE Communications Magazine <span id="bib.bib22.1.1" class="ltx_text ltx_font_bold">51</span>(8), 64–71 (2013)

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Wang, H., Yurochkin, M., Sun, Y., Papailiopoulos, D., Khazaeni, Y.: Federated learning with matched averaging. arXiv preprint arXiv:2002.06440 (2020)

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Wang, T., Tseng, H.H., Yoo, S.: Quantum federated learning with quantum networks. arXiv preprint arXiv:2310.15084 (2023)

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Watrous, J.: The theory of quantum information. Cambridge university press (2018)

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Wehner, S., Elkouss, D., Hanson, R.: Quantum internet: A vision for the road ahead. Science <span id="bib.bib26.1.1" class="ltx_text ltx_font_bold">362</span>(6412), eaam9288 (2018)

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Xiao, H., Rasul, K., Vollgraf, R.: Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms (2017)

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Yang, J., Shi, R., Wei, D., Liu, Z., Zhao, L., Ke, B., Pfister, H., Ni, B.: Medmnist v2-a large-scale lightweight benchmark for 2d and 3d biomedical image classification. Scientific Data <span id="bib.bib28.1.1" class="ltx_text ltx_font_bold">10</span>(1),  41 (2023)

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Yang, Q., Liu, Y., Chen, T., Tong, Y.: Federated machine learning: Concept and applications. ACM Transactions on Intelligent Systems and Technology (TIST) <span id="bib.bib29.1.1" class="ltx_text ltx_font_bold">10</span>(2), 1–19 (2019)

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Zhang, Y., Zhang, C., Zhang, C., Fan, L., Zeng, B., Yang, Q.: Federated Learning with Quantum Secure Aggregation (2023)

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2402.09901" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2402.09902" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2402.09902">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2402.09902" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2402.09903" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar  5 15:19:58 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
