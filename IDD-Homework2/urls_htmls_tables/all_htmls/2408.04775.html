<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Hybrid Student-Teacher Large Language Model Refinement for Cancer Toxicity Symptom Extraction</title>
<!--Generated on Thu Aug  8 22:14:15 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2408.04775v1/"/></head>
<body>
<nav class="ltx_page_navbar">
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Hybrid Student-Teacher Large Language Model Refinement for Cancer Toxicity Symptom Extraction</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Reza Khanmohammadi 
<br class="ltx_break"/>Michigan State University 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">khanreza@msu.edu</span>
<br class="ltx_break"/>Ahmed I. Ghanem
<br class="ltx_break"/>Henry Ford Cancer Institute 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.2.id2">aghanem1@hfhs.org</span>
<br class="ltx_break"/>Kyle Verdecchia 
<br class="ltx_break"/>Henry Ford Cancer Institute 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id3.3.id3">kverdec1@hfhs.org</span>
<br class="ltx_break"/>Ryan Hall 
<br class="ltx_break"/>Henry Ford Cancer Institute 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id4.4.id4">rhall14@hfhs.org</span>
<br class="ltx_break"/>Mohamed Elshaikh 
<br class="ltx_break"/>Henry Ford Cancer Institute 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id5.5.id5">melshai1@hfhs.org</span>
<br class="ltx_break"/>Benjamin Movsas 
<br class="ltx_break"/>Henry Ford Cancer Institute 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id6.6.id6">bmovsas1@hfhs.org</span>
<br class="ltx_break"/>Hassan Bagher-Ebadian 
<br class="ltx_break"/>Henry Ford Cancer Institute
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id7.7.id7">hbagher1@hfhs.org</span>
<br class="ltx_break"/>Bing Luo 
<br class="ltx_break"/>Henry Ford Cancer Institute 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id8.8.id8">bluo1@hfhs.org</span>
<br class="ltx_break"/>Indrin J. Chetty 
<br class="ltx_break"/>Cedars Sinai Medical Center
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id9.9.id9">indrin.chetty@cshs.org</span>
<br class="ltx_break"/>Tuka Alhanai 
<br class="ltx_break"/>New York University Abu Dhabi 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id10.10.id10">tuka.alhanai@nyu.edu</span>
<br class="ltx_break"/>Kundan Thind 
<br class="ltx_break"/>Henry Ford Cancer Institute
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id11.11.id11">kthind1@hfhs.org</span>
<br class="ltx_break"/>Mohammad M. Ghassemi<span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">2</span></span></span></span>
<br class="ltx_break"/>Michigan State University 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id12.12.id12">ghassem3@msu.edu</span>
<br class="ltx_break"/>
</span><span class="ltx_author_notes">Corresponding author: Reza Khanmohammadi (khanreza@msu.edu).Shared senior author.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id13.id1">Large Language Models (LLMs) offer significant potential for clinical symptom extraction, but their deployment in healthcare settings is constrained by privacy concerns, computational limitations, and operational costs. This study investigates the optimization of compact LLMs for cancer toxicity symptom extraction using a novel iterative refinement approach. We employ a student-teacher architecture, utilizing Zephyr-7b-beta and Phi3-mini-128 as student models and GPT-4o as the teacher, to dynamically select between prompt refinement, Retrieval-Augmented Generation (RAG), and fine-tuning strategies. Our experiments on 294 clinical notes covering 12 post-radiotherapy toxicity symptoms demonstrate the effectiveness of this approach. The RAG method proved most efficient, improving average accuracy scores from 0.32 to 0.73 for Zephyr-7b-beta and from 0.40 to 0.87 for Phi3-mini-128 during refinement. In the test set, both models showed an approximate 0.20 increase in accuracy across symptoms. Notably, this improvement was achieved at a cost 45 times lower than GPT-4o for Zephyr and 79 times lower for Phi-3. These results highlight the potential of iterative refinement techniques in enhancing the capabilities of compact LLMs for clinical applications, offering a balance between performance, cost-effectiveness, and privacy preservation in healthcare settings.</p>
</div>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Introduction</h2>
<section class="ltx_subsection" id="Sx1.SSx1">
<h3 class="ltx_title ltx_title_subsection">The Need for Optimized LLMs in Clinical Settings</h3>
<div class="ltx_para ltx_noindent" id="Sx1.SSx1.p1">
<p class="ltx_p" id="Sx1.SSx1.p1.1"><span class="ltx_text ltx_font_bold" id="Sx1.SSx1.p1.1.1">Opportunities and Challenges:</span> The integration of Large Language Models (LLMs) into clinical informatics presents both significant opportunities and unique challenges <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib1" title="">1</a>]</cite>. Clinical institutions face a critical need for advanced natural language processing capabilities, particularly in symptom extraction from unstructured texts. However, this need is tempered by several constraints inherent to the healthcare environment <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib2" title="">2</a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx1.SSx1.p2">
<p class="ltx_p" id="Sx1.SSx1.p2.1"><span class="ltx_text ltx_font_bold" id="Sx1.SSx1.p2.1.1">Privacy Concerns and Resource Limitations:</span> Foremost among these constraints is the imperative to protect patient privacy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib3" title="">3</a>]</cite>. This concern often leads clinical institutions to prefer on-premises deployment of LLMs, avoiding the risks associated with transmitting sensitive data to external servers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib3" title="">3</a>]</cite>. However, this preference introduces its own set of challenges. Large-scale LLMs, while powerful, require substantial computational resources that many healthcare facilities find difficult to maintain and operate on-site <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib4" title="">4</a>]</cite>. The associated costs can be prohibitive, both in terms of initial investment and ongoing operational expenses.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx1.SSx1.p3">
<p class="ltx_p" id="Sx1.SSx1.p3.1"><span class="ltx_text ltx_font_bold" id="Sx1.SSx1.p3.1.1">Smaller LLMs and Their Limitations:</span> Consequently, there is a growing interest in smaller LLMs that are more suitable for local deployment <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib5" title="">5</a>]</cite>. These compact models offer a potential solution to the resource and cost constraints many clinical settings face. However, they come with their own limitations, primarily stemming from their reduced exposure to comprehensive clinical corpora <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib6" title="">6</a>]</cite>. The relative scarcity of clinical text data and the typically smaller training sets in this domain exacerbate this challenge.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx1.SSx1.p4">
<p class="ltx_p" id="Sx1.SSx1.p4.1"><span class="ltx_text ltx_font_bold" id="Sx1.SSx1.p4.1.1">Economic Barriers to Third-Party Solutions:</span> Furthermore, the use of third-party generative AI models through APIs, such as OpenAI‚Äôs ChatGPT, while potentially powerful, often proves economically unfeasible for many clinical environments due to high usage costs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib7" title="">7</a>]</cite>. This economic barrier emphasizes the need for efficient, locally deployable solutions.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx1.SSx1.p5">
<p class="ltx_p" id="Sx1.SSx1.p5.1"><span class="ltx_text ltx_font_bold" id="Sx1.SSx1.p5.1.1">Optimization Challenges:</span> The primary challenge, therefore, lies in optimizing smaller LLMs to robustly process clinical data, despite constraints in computational capacity and training data availability. There is a pressing need to develop techniques that can enhance the performance of these compact models, particularly in tasks such as symptom extraction and analysis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib8" title="">8</a>]</cite>. The goal is to achieve an optimal balance between preserving data privacy, managing operational costs, and ensuring high-fidelity performance in clinical applications.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx1.SSx1.p6">
<p class="ltx_p" id="Sx1.SSx1.p6.1"><span class="ltx_text ltx_font_bold" id="Sx1.SSx1.p6.1.1">Demand for Novel Strategies:</span> This complex landscape of needs and constraints underscores the importance of developing innovative approaches to LLM refinement and deployment in clinical settings. It calls for solutions that can leverage the power of advanced language models while addressing the unique requirements and limitations of the healthcare environment.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx1.SSx2">
<h3 class="ltx_title ltx_title_subsection">Clinical Symptom Extraction with LLMs</h3>
<div class="ltx_para" id="Sx1.SSx2.p1">
<p class="ltx_p" id="Sx1.SSx2.p1.1">Recent studies have explored LLMs for extracting clinical information from unstructured EHR texts. Mahbub et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib9" title="">9</a>]</cite> used zero-shot learning with Flan-T5 for SUD severity extraction, outperforming rule-based approaches. Reese et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib10" title="">10</a>]</cite> found GPT-4‚Äôs performance in clinical diagnostics to be sensitive to prompt formulation. Shyr et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib11" title="">11</a>]</cite> demonstrated ChatGPT‚Äôs efficacy in zero- and few-shot settings for rare disease phenotype extraction. Guevara et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib12" title="">12</a>]</cite> showed fine-tuned Flan-T5 models‚Äô superiority in extracting social determinants of health, especially with synthetic data augmentation.
These studies underscore LLMs‚Äô potential to enhance critical health information extraction from clinical texts, improving symptom and phenotype identification for effective radiation oncology toxicity management.</p>
</div>
<figure class="ltx_figure" id="Sx1.F1">
<p class="ltx_p ltx_align_center" id="Sx1.F1.1"><span class="ltx_text" id="Sx1.F1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="394" id="Sx1.F1.1.1.g1" src="extracted/5782180/hybrid-llm-refinement.png" width="837"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The diagram illustrates the iterative refinement method, involving a student model (Phi3-mini-128 or Zephyr-7B-beta) and a teacher model (GPT-4o). The process starts with the student model receiving clinical notes and a target symptom, generating initial labels and reasoning. The teacher model then assesses performance and decides between prompt refinement and fine-tuning. In prompt refinement, the teacher improves the prompt and adds RAG examples. In fine-tuning, the teacher selects relevant samples and sets hyperparameters for the student model. In the hybrid approach, the teacher model acts as an intelligent agent, dynamically deciding between prompt refinement and fine-tuning based on the student‚Äôs performance and needs. The refined approach is iteratively applied, optimizing the student model‚Äôs performance in symptom extraction.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="Sx1.SSx3">
<h3 class="ltx_title ltx_title_subsection">Iterative LLM Refinement Techniques</h3>
<div class="ltx_para ltx_noindent" id="Sx1.SSx3.p1">
<p class="ltx_p" id="Sx1.SSx3.p1.1"><span class="ltx_text ltx_font_bold" id="Sx1.SSx3.p1.1.1">Single LLM Refinement:</span> Recent advancements in LLMs have focused on iterative refinement techniques to enhance performance across diverse tasks. Chen et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib13" title="">13</a>]</cite> demonstrated that multiple refinement rounds significantly improve translation fluency and naturalness. Building on this concept, Xiong et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib14" title="">14</a>]</cite> developed the IPR framework, which outperformed established baselines in complex interactive tasks. Madaan et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib15" title="">15</a>]</cite> further advanced this approach with Self-Refine, yielding significant improvements without additional training data. Yan et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib16" title="">16</a>]</cite> extended these principles to enable resource-efficient performance enhancements in less capable models. In the domain of bioinformatics, Chen et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib17" title="">17</a>]</cite> applied iterative prompt refinement to substantially improve ChatGPT‚Äôs accuracy in extracting gene relationships and biological pathways.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx1.SSx3.p2">
<p class="ltx_p" id="Sx1.SSx3.p2.1"><span class="ltx_text ltx_font_bold" id="Sx1.SSx3.p2.1.1">Collaborative LLM Refinement:</span> Recent advancements have explored collaborative frameworks utilizing multiple LLMs. Lee et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib18" title="">18</a>]</cite> introduced LLM2LLM, where a teacher LLM augments small datasets to enhance student LLM performance in low-data scenarios. Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib19" title="">19</a>]</cite> developed TS-Align, aligning LLMs with human preferences without manual annotations. Saha et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib20" title="">20</a>]</cite> demonstrated significant improvements in student LLM performance through teacher-generated personalized explanations. Yuan et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib21" title="">21</a>]</cite> showed that teacher-generated analogies substantially improve student LLMs‚Äô scientific concept comprehension and question-answering capabilities. These studies collectively demonstrate the efficacy of collaborative LLM frameworks in enhancing model performance across diverse domains and tasks, particularly in scenarios with limited data or complex reasoning requirements.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx1.SSx4">
<h3 class="ltx_title ltx_title_subsection">LLM Refinement in Symptom Extraction</h3>
<div class="ltx_para" id="Sx1.SSx4.p1">
<p class="ltx_p" id="Sx1.SSx4.p1.1">Recent research has focused on integrating advanced LLM techniques with clinical symptom extraction, presenting significant potential for clinical informatics advancements. Clinical institutions prefer local LLM deployment for data privacy, but face challenges with the high costs and computational demands of large models. Smaller LLMs, while more suitable for on-premises use, are limited by reduced exposure to comprehensive clinical corpora. The primary challenge lies in optimizing these compact LLMs for robust clinical data processing, given constraints in computational capacity and data availability. Iterative refinement techniques and data augmentation strategies offer promising solutions to enhance LLM performance in clinical settings, aiming to balance data privacy, operational costs, and extraction accuracy. A notable attempt to address these challenges is presented in the work by Khanmohammadi et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib22" title="">22</a>]</cite>, who introduce a novel student-teacher architecture, using Mixtral as the student model and GPT-4 as the teacher for prostate cancer radiotherapy symptom extraction. Their approach demonstrates significant improvements, highlighting the potential of advanced prompt engineering in LLMs for radiation oncology applications.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx1.SSx5">
<h3 class="ltx_title ltx_title_subsection">Remaining Gaps</h3>
<div class="ltx_para" id="Sx1.SSx5.p1">
<p class="ltx_p" id="Sx1.SSx5.p1.1">Despite significant progress in integrating LLMs with clinical symptom extraction, several research gaps persist:</p>
<ul class="ltx_itemize" id="Sx1.I1">
<li class="ltx_item" id="Sx1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx1.I1.i1.p1">
<p class="ltx_p" id="Sx1.I1.i1.p1.1">The application of iterative student-teacher frameworks to smaller LLMs for on-premises clinical deployment remains unexplored.</p>
</div>
</li>
<li class="ltx_item" id="Sx1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx1.I1.i2.p1">
<p class="ltx_p" id="Sx1.I1.i2.p1.1">Incorporation of Retrieval-Augmented Generation (RAG) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib23" title="">23</a>]</cite> into prompt refinement techniques to enhance contextual understanding and accuracy.</p>
</div>
</li>
<li class="ltx_item" id="Sx1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx1.I1.i3.p1">
<p class="ltx_p" id="Sx1.I1.i3.p1.1">Further investigation of fine-tuning for domain-specific adaptations within the student-teacher paradigm.</p>
</div>
</li>
<li class="ltx_item" id="Sx1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx1.I1.i4.p1">
<p class="ltx_p" id="Sx1.I1.i4.p1.1">Expansion of the teacher‚Äôs role in guiding the student model‚Äôs fine-tuning process.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="Sx1.SSx5.p1.2">Addressing these gaps could provide valuable insights into the practical implementation and effectiveness of advanced LLM techniques in clinical settings, contributing to the broader discourse on healthcare informatics.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx1.SSx6">
<h3 class="ltx_title ltx_title_subsection">Contributions of This Work</h3>
<div class="ltx_para" id="Sx1.SSx6.p1">
<p class="ltx_p" id="Sx1.SSx6.p1.1">This study investigates several aspects of the student-teacher framework for clinical symptom extraction:</p>
<ul class="ltx_itemize" id="Sx1.I2">
<li class="ltx_item" id="Sx1.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx1.I2.i1.p1">
<p class="ltx_p" id="Sx1.I2.i1.p1.1">Application of the framework to smaller LLMs (7 and 3.8 billion parameters) for clinical settings.</p>
</div>
</li>
<li class="ltx_item" id="Sx1.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx1.I2.i2.p1">
<p class="ltx_p" id="Sx1.I2.i2.p1.1">Integration of RAG within prompt refinement to enhance contextual understanding and accuracy.</p>
</div>
</li>
<li class="ltx_item" id="Sx1.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx1.I2.i3.p1">
<p class="ltx_p" id="Sx1.I2.i3.p1.1">Exploration of iterative fine-tuning for domain-specific adaptations in clinical contexts.</p>
</div>
</li>
<li class="ltx_item" id="Sx1.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx1.I2.i4.p1">
<p class="ltx_p" id="Sx1.I2.i4.p1.1">Implementation of an advanced student-teacher framework where the teacher model acts as a decision-making agent for optimizing refinement strategies.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="Sx1.SSx6.p1.2">These investigations aim to enhance the student-teacher framework for clinical symptom extraction, addressing current research gaps. The project implementation, including full prompt templates, is available on GitHub (removed for blind revision).</p>
</div>
</section>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Experiments</h2>
<section class="ltx_subsection" id="Sx2.SSx1">
<h3 class="ltx_title ltx_title_subsection">Data Description</h3>
<div class="ltx_para" id="Sx2.SSx1.p1">
<p class="ltx_p" id="Sx2.SSx1.p1.1">The dataset used in this study comprises clinical notes from prostate cancer patients definitively treated with 78 Gy radiotherapy (RT) between 2013 and 2020. We extracted 294 clinical notes documented beyond 6 months post-RT to focus on long-term toxicities, selecting notes that exhibited single symptoms. Our analysis concentrated on twelve common late post-RT toxicity symptoms: Cystitis, Dysuria, Erectile Dysfunction, Hematuria, Incontinence, Nocturia, Proctitis, Rectal Bleeding, Stricture, Urgency, Urinary Obstruction, and Urothelial Carcinoma. The dataset was structured with a training set of 20 notes per symptom (15 for Urothelial Carcinoma due to limited availability) and a test set of 5 notes per symptom (4 for Urothelial Carcinoma). Each note was labeled with a symptom assignment of -1 (absence), 0 (unknown status), or 1 (presence). The use of clinical notes and the overall study design were reviewed and approved by the institutional review board, ensuring ethical compliance and data protection standards were met throughout the research process.</p>
</div>
<div class="ltx_para" id="Sx2.SSx1.p2">
<p class="ltx_p" id="Sx2.SSx1.p2.1">In addition to the clinical notes, we specifically utilized selected categories from the Massive Multitask Language Understanding (MMLU) dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib24" title="">24</a>]</cite> for fine-tuning. MMLU is a benchmark designed to assess models on a wide range of subjects. Our study focused on the following categories to form a clinical subset: anatomy, clinical knowledge, college medicine, human sexuality, medical genetics, and professional medicine. This selection resulted in a total of 1225 records, denoted as <math alttext="M" class="ltx_Math" display="inline" id="Sx2.SSx1.p2.1.m1.1"><semantics id="Sx2.SSx1.p2.1.m1.1a"><mi id="Sx2.SSx1.p2.1.m1.1.1" xref="Sx2.SSx1.p2.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p2.1.m1.1b"><ci id="Sx2.SSx1.p2.1.m1.1.1.cmml" xref="Sx2.SSx1.p2.1.m1.1.1">ùëÄ</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx1.p2.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="Sx2.SSx1.p2.1.m1.1d">italic_M</annotation></semantics></math>. We selected this data based on the Superficial Alignment Hypothesis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib25" title="">25</a>]</cite>, which posits that a model‚Äôs knowledge and capabilities are largely learned during pretraining, while fine-tuning can effectively teach the model-specific subdistributions and formats using a relatively small set of examples. By applying this hypothesis to the clinical domain, we aim to enhance the model‚Äôs familiarity and focus on clinical knowledge, thereby improving its performance in clinical symptom extraction tasks.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx2.SSx2">
<h3 class="ltx_title ltx_title_subsection">Data Preprocessing</h3>
<div class="ltx_para" id="Sx2.SSx2.p1">
<p class="ltx_p" id="Sx2.SSx2.p1.2">Our data preprocessing involves two key steps: embedding training clinical notes and generating context-reasoning (<math alttext="C_{R}" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.1.m1.1"><semantics id="Sx2.SSx2.p1.1.m1.1a"><msub id="Sx2.SSx2.p1.1.m1.1.1" xref="Sx2.SSx2.p1.1.m1.1.1.cmml"><mi id="Sx2.SSx2.p1.1.m1.1.1.2" xref="Sx2.SSx2.p1.1.m1.1.1.2.cmml">C</mi><mi id="Sx2.SSx2.p1.1.m1.1.1.3" xref="Sx2.SSx2.p1.1.m1.1.1.3.cmml">R</mi></msub><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.1.m1.1b"><apply id="Sx2.SSx2.p1.1.m1.1.1.cmml" xref="Sx2.SSx2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="Sx2.SSx2.p1.1.m1.1.1.1.cmml" xref="Sx2.SSx2.p1.1.m1.1.1">subscript</csymbol><ci id="Sx2.SSx2.p1.1.m1.1.1.2.cmml" xref="Sx2.SSx2.p1.1.m1.1.1.2">ùê∂</ci><ci id="Sx2.SSx2.p1.1.m1.1.1.3.cmml" xref="Sx2.SSx2.p1.1.m1.1.1.3">ùëÖ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.1.m1.1c">C_{R}</annotation><annotation encoding="application/x-llamapun" id="Sx2.SSx2.p1.1.m1.1d">italic_C start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT</annotation></semantics></math>) pairs. We utilize <span class="ltx_text ltx_font_typewriter" id="Sx2.SSx2.p1.2.1">Bio_ClinicalBERT</span> to embed each clinical note in the training set into a 768-dimensional vector space, capturing the semantic content of the notes. These embeddings are then stored in a vector database for efficient retrieval during the refinement process.
To enrich the dataset, we employ GPT-4o to generate (<math alttext="C_{R}" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.2.m2.1"><semantics id="Sx2.SSx2.p1.2.m2.1a"><msub id="Sx2.SSx2.p1.2.m2.1.1" xref="Sx2.SSx2.p1.2.m2.1.1.cmml"><mi id="Sx2.SSx2.p1.2.m2.1.1.2" xref="Sx2.SSx2.p1.2.m2.1.1.2.cmml">C</mi><mi id="Sx2.SSx2.p1.2.m2.1.1.3" xref="Sx2.SSx2.p1.2.m2.1.1.3.cmml">R</mi></msub><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.2.m2.1b"><apply id="Sx2.SSx2.p1.2.m2.1.1.cmml" xref="Sx2.SSx2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="Sx2.SSx2.p1.2.m2.1.1.1.cmml" xref="Sx2.SSx2.p1.2.m2.1.1">subscript</csymbol><ci id="Sx2.SSx2.p1.2.m2.1.1.2.cmml" xref="Sx2.SSx2.p1.2.m2.1.1.2">ùê∂</ci><ci id="Sx2.SSx2.p1.2.m2.1.1.3.cmml" xref="Sx2.SSx2.p1.2.m2.1.1.3">ùëÖ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.2.m2.1c">C_{R}</annotation><annotation encoding="application/x-llamapun" id="Sx2.SSx2.p1.2.m2.1d">italic_C start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT</annotation></semantics></math>) pairs for each note. For every clinical note, its associated toxicity, and ground truth label, GPT-4o extracts the relevant textual context supporting the label and generates a reasoning explaining the labeling decision. These pairs are subsequently added as metadata to their corresponding note entries in the vector database.
This preprocessing approach serves to create a semantically rich dataset that combines dense vector representations with interpretable explanations, thus providing a robust foundation for our iterative refinement process and enabling more context-aware improvements to the student model‚Äôs performance.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx2.SSx3">
<h3 class="ltx_title ltx_title_subsection">Iterative Refinement in the Student-Teacher Framework</h3>
<section class="ltx_subsubsection" id="Sx2.SSx3.SSSx1">
<h4 class="ltx_title ltx_title_subsubsection">Concepts and Terminologies</h4>
<div class="ltx_para" id="Sx2.SSx3.SSSx1.p1">
<p class="ltx_p" id="Sx2.SSx3.SSSx1.p1.1">The iterative refinement process in a student-teacher framework involves two primary components:</p>
<ul class="ltx_itemize" id="Sx2.I3">
<li class="ltx_item" id="Sx2.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx2.I3.i1.p1">
<p class="ltx_p" id="Sx2.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="Sx2.I3.i1.p1.1.1">Student Model:</span> The student model, such as Phi3-mini-128 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib26" title="">26</a>]</cite> or Zephyr-7B-beta <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#bib.bib27" title="">27</a>]</cite>, is responsible for the initial task of symptom extraction from clinical notes. The student model generates outputs based on specific inputs and prompts.</p>
</div>
</li>
<li class="ltx_item" id="Sx2.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx2.I3.i2.p1">
<p class="ltx_p" id="Sx2.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="Sx2.I3.i2.p1.1.1">Teacher Model:</span> The teacher model, GPT-4o in our case, oversees the refinement process. It evaluates the performance of the student model, maintains a history of interactions, and generates refined prompts or fine-tuning configurations to improve the student model‚Äôs performance iteratively.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsubsection" id="Sx2.SSx3.SSSx2">
<h4 class="ltx_title ltx_title_subsubsection">Iterative Refinement Process</h4>
<div class="ltx_para" id="Sx2.SSx3.SSSx2.p1">
<p class="ltx_p" id="Sx2.SSx3.SSSx2.p1.1">As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#Sx1.F1" title="Figure 1 ‚Ä£ Clinical Symptom Extraction with LLMs ‚Ä£ Introduction ‚Ä£ Hybrid Student-Teacher Large Language Model Refinement for Cancer Toxicity Symptom Extraction"><span class="ltx_text ltx_ref_tag">1</span></a>, the iterative refinement process operates as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx2.SSx3.SSSx2.p2">
<p class="ltx_p" id="Sx2.SSx3.SSSx2.p2.1"><span class="ltx_text ltx_font_bold" id="Sx2.SSx3.SSSx2.p2.1.1">1. The student classifies notes</span> The student model receives a set of inputs: clinical notes, the target symptom (<math alttext="S" class="ltx_Math" display="inline" id="Sx2.SSx3.SSSx2.p2.1.m1.1"><semantics id="Sx2.SSx3.SSSx2.p2.1.m1.1a"><mi id="Sx2.SSx3.SSSx2.p2.1.m1.1.1" xref="Sx2.SSx3.SSSx2.p2.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx3.SSSx2.p2.1.m1.1b"><ci id="Sx2.SSx3.SSSx2.p2.1.m1.1.1.cmml" xref="Sx2.SSx3.SSSx2.p2.1.m1.1.1">ùëÜ</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx3.SSSx2.p2.1.m1.1c">S</annotation><annotation encoding="application/x-llamapun" id="Sx2.SSx3.SSSx2.p2.1.m1.1d">italic_S</annotation></semantics></math>), the prompt, and model parameters. The initial prompt template is structured as follows:</p>
<blockquote class="ltx_quote" id="Sx2.SSx3.SSSx2.p2.2">
<p class="ltx_p" id="Sx2.SSx3.SSSx2.p2.2.1"><span class="ltx_text ltx_font_italic" id="Sx2.SSx3.SSSx2.p2.2.1.1">"Answer the following yes/no/idk question. Does the following clinical note mention the symptom of <math alttext="S" class="ltx_Math" display="inline" id="Sx2.SSx3.SSSx2.p2.2.1.1.m1.1"><semantics id="Sx2.SSx3.SSSx2.p2.2.1.1.m1.1a"><mi id="Sx2.SSx3.SSSx2.p2.2.1.1.m1.1.1" xref="Sx2.SSx3.SSSx2.p2.2.1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx3.SSSx2.p2.2.1.1.m1.1b"><ci id="Sx2.SSx3.SSSx2.p2.2.1.1.m1.1.1.cmml" xref="Sx2.SSx3.SSSx2.p2.2.1.1.m1.1.1">ùëÜ</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx3.SSSx2.p2.2.1.1.m1.1c">S</annotation><annotation encoding="application/x-llamapun" id="Sx2.SSx3.SSSx2.p2.2.1.1.m1.1d">italic_S</annotation></semantics></math>?"</span></p>
</blockquote>
<p class="ltx_p" id="Sx2.SSx3.SSSx2.p2.3">Using these inputs, the model processes each clinical note to extract and classify the target symptom as present (yes), negated (no), or unknown (idk). Crucially, the student model is also tasked with providing a reasoning for each classification, enhancing the interpretability of its outputs. This initial extraction serves as the baseline for subsequent refinement iterations.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx2.SSx3.SSSx2.p3">
<p class="ltx_p" id="Sx2.SSx3.SSSx2.p3.1"><span class="ltx_text ltx_font_bold" id="Sx2.SSx3.SSSx2.p3.1.1">2. The student is assessed:</span> Student-generated labels are evaluated to calculate performance scores such as accuracy, precision, recall, and F1 score.</p>
</div>
<figure class="ltx_figure" id="Sx2.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_align_center ltx_figure_panel ltx_align_center" id="Sx2.F2.1"><span class="ltx_text" id="Sx2.F2.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="35" id="Sx2.F2.1.1.g1" src="extracted/5782180/zephyr-phi3-comparison-header.png" width="538"/></span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_align_center ltx_figure_panel ltx_align_center" id="Sx2.F2.2"><span class="ltx_text" id="Sx2.F2.2.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="934" id="Sx2.F2.2.1.g1" src="x1.png" width="747"/></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Performance Comparison of Zephyr and Phi3 Models in Symptom Extraction. The line charts on the left-hand side represent the evolution of the Accuracy scores for different post-RT toxicity symptoms, with each line color-coded according to the 12 symptoms listed in the legend. The right-hand side line chart shows the average performance score across all toxicity symptoms at each time point, illustrating the difference in mean and standard deviation between the initial student model‚Äôs performance and the final refined model‚Äôs performance.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="Sx2.SSx3.SSSx2.p4">
<p class="ltx_p" id="Sx2.SSx3.SSSx2.p4.1"><span class="ltx_text ltx_font_bold" id="Sx2.SSx3.SSSx2.p4.1.1">3. The teacher attempts to refine the student:</span> The performance scores, along with the generated prompts and reasoning, are sent to the teacher model. The teacher model reviews this information, considering the history of previous interactions and actions taken. Based on this analysis, the teacher model determines the most appropriate action to improve the student‚Äôs performance.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx2.SSx3.SSSx2.p5">
<p class="ltx_p" id="Sx2.SSx3.SSSx2.p5.1"><span class="ltx_text ltx_font_bold" id="Sx2.SSx3.SSSx2.p5.1.1">4. The teacher selects an action:</span> The teacher model selects one of the following actions:</p>
<ul class="ltx_itemize" id="Sx2.I4">
<li class="ltx_item" id="Sx2.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx2.I4.i1.p1">
<p class="ltx_p" id="Sx2.I4.i1.p1.1"><span class="ltx_text ltx_font_bold" id="Sx2.I4.i1.p1.1.1">Prompt Refinement:</span> If this action is chosen, the teacher model generates a refined prompt and may add RAG examples to enhance the contextual understanding of the student.</p>
</div>
</li>
<li class="ltx_item" id="Sx2.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx2.I4.i2.p1">
<p class="ltx_p" id="Sx2.I4.i2.p1.1"><span class="ltx_text ltx_font_bold" id="Sx2.I4.i2.p1.1.1">Fine-Tuning:</span> If this action is chosen, the teacher model selects specific samples and sets hyperparameters for fine-tuning the student.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="Sx2.SSx3.SSSx2.p6">
<p class="ltx_p" id="Sx2.SSx3.SSSx2.p6.1"><span class="ltx_text ltx_font_bold" id="Sx2.SSx3.SSSx2.p6.1.1">5. The refined approach is applied and iterated:</span> The refined prompt or fine-tuning configuration is applied to the student model, and the next iteration begins. This iterative process continues, alternating between prompt refinement and fine-tuning (in the hybrid approach), with the goal of continually improving the student model‚Äôs performance.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx2.SSx3.SSSx2.p7">
<p class="ltx_p" id="Sx2.SSx3.SSSx2.p7.1"><span class="ltx_text ltx_font_bold" id="Sx2.SSx3.SSSx2.p7.1.1">6. Iterative Refinement:</span> The process is structured into epochs, each comprising 16 refinement rounds. In each round, the teacher model refines the prompt or fine-tunes the student model to improve symptom extraction. If performance improves, the epoch ends, and a new epoch begins with renewed refinement opportunities. The process terminates when no improvement is achieved across an entire epoch, indicating the student model‚Äôs peak performance within the framework‚Äôs constraints.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="Sx2.SSx4">
<h3 class="ltx_title ltx_title_subsection">Methods Investigated</h3>
<section class="ltx_subsubsection" id="Sx2.SSx4.SSSx1">
<h4 class="ltx_title ltx_title_subsubsection">Prompt Refinement Approach</h4>
<div class="ltx_para" id="Sx2.SSx4.SSSx1.p1">
<p class="ltx_p" id="Sx2.SSx4.SSSx1.p1.1">The prompt refinement approach is a key component of our iterative refinement process, focusing on optimizing the prompts used by the student models for symptom extraction. This approach consists of two main steps:</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx2.SSx4.SSSx1.p2">
<p class="ltx_p" id="Sx2.SSx4.SSSx1.p2.1"><span class="ltx_text ltx_font_bold" id="Sx2.SSx4.SSSx1.p2.1.1">1. Prompt Refinement:</span> When this action is selected, the teacher model (GPT-4o) is tasked with refining the prompt based on the student‚Äôs performance. The teacher is given the following instruction:</p>
<blockquote class="ltx_quote" id="Sx2.SSx4.SSSx1.p2.2">
<p class="ltx_p" id="Sx2.SSx4.SSSx1.p2.2.1"><span class="ltx_text ltx_font_italic" id="Sx2.SSx4.SSSx1.p2.2.1.1">"Your task is to prompt engineer another Large Language Model called LLM2. I would like LLM2 to score single clinical symptom by yes/no/idk in clinical notes based on the given target symptom. I am including the performance score of this extraction by LLM2 which is calculated based on ground truth labels and LLM2‚Äôs output labels for symptom extraction across all notes. Your duty is to change the prompt such that LLM2‚Äôs output gets improved by having more similar LLM2 output labels as the ground truth labels. More specifically, I will provide you with a Best Prompt and other samples that didn‚Äôt work as well as the Best Prompt. [‚Ä¶]"</span></p>
</blockquote>
<p class="ltx_p" id="Sx2.SSx4.SSSx1.p2.3">The teacher model analyzes the current performance and generates a refined prompt aimed at improving the student model‚Äôs symptom extraction capability.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx2.SSx4.SSSx1.p3">
<p class="ltx_p" id="Sx2.SSx4.SSSx1.p3.1"><span class="ltx_text ltx_font_bold" id="Sx2.SSx4.SSSx1.p3.1.1">2. RAG Example Generation:</span> Following prompt refinement, the process advances to RAG example creation. This phase begins by extracting semantically similar (<math alttext="C_{R}" class="ltx_Math" display="inline" id="Sx2.SSx4.SSSx1.p3.1.m1.1"><semantics id="Sx2.SSx4.SSSx1.p3.1.m1.1a"><msub id="Sx2.SSx4.SSSx1.p3.1.m1.1.1" xref="Sx2.SSx4.SSSx1.p3.1.m1.1.1.cmml"><mi id="Sx2.SSx4.SSSx1.p3.1.m1.1.1.2" xref="Sx2.SSx4.SSSx1.p3.1.m1.1.1.2.cmml">C</mi><mi id="Sx2.SSx4.SSSx1.p3.1.m1.1.1.3" xref="Sx2.SSx4.SSSx1.p3.1.m1.1.1.3.cmml">R</mi></msub><annotation-xml encoding="MathML-Content" id="Sx2.SSx4.SSSx1.p3.1.m1.1b"><apply id="Sx2.SSx4.SSSx1.p3.1.m1.1.1.cmml" xref="Sx2.SSx4.SSSx1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="Sx2.SSx4.SSSx1.p3.1.m1.1.1.1.cmml" xref="Sx2.SSx4.SSSx1.p3.1.m1.1.1">subscript</csymbol><ci id="Sx2.SSx4.SSSx1.p3.1.m1.1.1.2.cmml" xref="Sx2.SSx4.SSSx1.p3.1.m1.1.1.2">ùê∂</ci><ci id="Sx2.SSx4.SSSx1.p3.1.m1.1.1.3.cmml" xref="Sx2.SSx4.SSSx1.p3.1.m1.1.1.3">ùëÖ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx4.SSSx1.p3.1.m1.1c">C_{R}</annotation><annotation encoding="application/x-llamapun" id="Sx2.SSx4.SSSx1.p3.1.m1.1d">italic_C start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT</annotation></semantics></math>) pairs from a vector database. For each clinical note, we employ the same embedding model (<span class="ltx_text ltx_font_typewriter" id="Sx2.SSx4.SSSx1.p3.1.2">Bio_ClinicalBERT</span>) to generate embeddings and query the database for the three most similar notes. The associated context and reasoning pairs from these neighbors are then presented to the teacher model. Utilizing this contextual information alongside the refined prompt, the teacher model generates one to five RAG examples to enhance the student model‚Äôs understanding of the task and improve its performance in symptom extraction.</p>
<blockquote class="ltx_quote" id="Sx2.SSx4.SSSx1.p3.2">
<p class="ltx_p" id="Sx2.SSx4.SSSx1.p3.2.1">"Now that you have refined the prompt, I want you to add some examples in the prompt. You can generate 1 to 5 examples (you should decide yourself) to add after the prompt you just generated. The generation of examples should be influenced by the model‚Äôs performance and its connection with the refined prompt."</p>
</blockquote>
<p class="ltx_p" id="Sx2.SSx4.SSSx1.p3.3">Finally, the refined prompt and the generated RAG examples are concatenated, creating a comprehensive instruction set that combines refined task guidance with relevant, context-rich examples.</p>
</div>
</section>
<section class="ltx_subsubsection" id="Sx2.SSx4.SSSx2">
<h4 class="ltx_title ltx_title_subsubsection">Fine-Tuning Approach</h4>
<div class="ltx_para" id="Sx2.SSx4.SSSx2.p1">
<p class="ltx_p" id="Sx2.SSx4.SSSx2.p1.1">The fine-tuning approach aims to adapt the student model for enhanced performance in clinical symptom extraction. This process involves:</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx2.SSx4.SSSx2.p2">
<p class="ltx_p" id="Sx2.SSx4.SSSx2.p2.2"><span class="ltx_text ltx_font_bold" id="Sx2.SSx4.SSSx2.p2.2.1">1. Sample Selection:</span> The teacher model (GPT-4o) selects samples from both the clinical MMLU dataset <math alttext="M" class="ltx_Math" display="inline" id="Sx2.SSx4.SSSx2.p2.1.m1.1"><semantics id="Sx2.SSx4.SSSx2.p2.1.m1.1a"><mi id="Sx2.SSx4.SSSx2.p2.1.m1.1.1" xref="Sx2.SSx4.SSSx2.p2.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx4.SSSx2.p2.1.m1.1b"><ci id="Sx2.SSx4.SSSx2.p2.1.m1.1.1.cmml" xref="Sx2.SSx4.SSSx2.p2.1.m1.1.1">ùëÄ</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx4.SSSx2.p2.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="Sx2.SSx4.SSSx2.p2.1.m1.1d">italic_M</annotation></semantics></math> and the context-reasoning pairs <math alttext="C_{R}" class="ltx_Math" display="inline" id="Sx2.SSx4.SSSx2.p2.2.m2.1"><semantics id="Sx2.SSx4.SSSx2.p2.2.m2.1a"><msub id="Sx2.SSx4.SSSx2.p2.2.m2.1.1" xref="Sx2.SSx4.SSSx2.p2.2.m2.1.1.cmml"><mi id="Sx2.SSx4.SSSx2.p2.2.m2.1.1.2" xref="Sx2.SSx4.SSSx2.p2.2.m2.1.1.2.cmml">C</mi><mi id="Sx2.SSx4.SSSx2.p2.2.m2.1.1.3" xref="Sx2.SSx4.SSSx2.p2.2.m2.1.1.3.cmml">R</mi></msub><annotation-xml encoding="MathML-Content" id="Sx2.SSx4.SSSx2.p2.2.m2.1b"><apply id="Sx2.SSx4.SSSx2.p2.2.m2.1.1.cmml" xref="Sx2.SSx4.SSSx2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="Sx2.SSx4.SSSx2.p2.2.m2.1.1.1.cmml" xref="Sx2.SSx4.SSSx2.p2.2.m2.1.1">subscript</csymbol><ci id="Sx2.SSx4.SSSx2.p2.2.m2.1.1.2.cmml" xref="Sx2.SSx4.SSSx2.p2.2.m2.1.1.2">ùê∂</ci><ci id="Sx2.SSx4.SSSx2.p2.2.m2.1.1.3.cmml" xref="Sx2.SSx4.SSSx2.p2.2.m2.1.1.3">ùëÖ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx4.SSSx2.p2.2.m2.1c">C_{R}</annotation><annotation encoding="application/x-llamapun" id="Sx2.SSx4.SSSx2.p2.2.m2.1d">italic_C start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT</annotation></semantics></math> derived from our clinical notes. The selection is guided by the following prompt:</p>
<blockquote class="ltx_quote" id="Sx2.SSx4.SSSx2.p2.3">
<p class="ltx_p" id="Sx2.SSx4.SSSx2.p2.3.1"><span class="ltx_text ltx_font_italic" id="Sx2.SSx4.SSSx2.p2.3.1.1">"Select specific samples to fine-tune LLM2, focusing on improving its performance in clinical symptom extraction. Choose samples that address LLM2‚Äôs current weaknesses, especially cases where it has incorrectly labeled symptoms. Return a list of at least 10 indices from the provided datasets."</span></p>
</blockquote>
<p class="ltx_p" id="Sx2.SSx4.SSSx2.p2.4">This step ensures the selection of relevant samples that target the model‚Äôs shortcomings in symptom identification and classification.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx2.SSx4.SSSx2.p3">
<p class="ltx_p" id="Sx2.SSx4.SSSx2.p3.1"><span class="ltx_text ltx_font_bold" id="Sx2.SSx4.SSSx2.p3.1.1">2. Fine-Tuning Configuration:</span> The teacher model then determines the optimal hyperparameters for fine-tuning:</p>
<blockquote class="ltx_quote" id="Sx2.SSx4.SSSx2.p3.2">
<p class="ltx_p" id="Sx2.SSx4.SSSx2.p3.2.1"><span class="ltx_text ltx_font_italic" id="Sx2.SSx4.SSSx2.p3.2.1.1">"Provide hyperparameters for fine-tuning the student model on clinical symptom extraction. Consider the model‚Äôs current performance and the selected samples. Return a JSON object with parameters including learning rate, batch size, number of epochs, and LoRA-specific settings."</span></p>
</blockquote>
<p class="ltx_p" id="Sx2.SSx4.SSSx2.p3.3">Using the selected samples and specified hyperparameters (including learning rate, per-device train batch size, number of train epochs, gradient accumulation steps, LoRA-specific settings such as <span class="ltx_text ltx_font_italic" id="Sx2.SSx4.SSSx2.p3.3.1">lora_r</span>, <span class="ltx_text ltx_font_italic" id="Sx2.SSx4.SSSx2.p3.3.2">lora_alpha</span>, and <span class="ltx_text ltx_font_italic" id="Sx2.SSx4.SSSx2.p3.3.3">lora_dropout</span>, <span class="ltx_text ltx_font_italic" id="Sx2.SSx4.SSSx2.p3.3.4">max grad norm</span>, <span class="ltx_text ltx_font_italic" id="Sx2.SSx4.SSSx2.p3.3.5">weight decay</span>, <span class="ltx_text ltx_font_italic" id="Sx2.SSx4.SSSx2.p3.3.6">learning rate scheduler type</span>, <span class="ltx_text ltx_font_italic" id="Sx2.SSx4.SSSx2.p3.3.7">warmup ratio</span>, <span class="ltx_text ltx_font_italic" id="Sx2.SSx4.SSSx2.p3.3.8">optimizer</span>, and <span class="ltx_text ltx_font_italic" id="Sx2.SSx4.SSSx2.p3.3.9">target modules</span>), the student model undergoes fine-tuning. This process focuses on enhancing the model‚Äôs ability to accurately extract and classify symptoms from clinical notes.</p>
</div>
<figure class="ltx_figure" id="Sx2.F3">
<p class="ltx_p ltx_align_center ltx_align_center" id="Sx2.F3.1"><span class="ltx_text" id="Sx2.F3.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="426" id="Sx2.F3.1.1.g1" src="x2.png" width="1162"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The left panels display initial (brighter colors) and refined (darker colors) performance scores (blue and green bars) and associated costs (red bars) for the Phi-3 and Zephyr models across different refinement techniques: Hybrid, Finetuned, RAG, and GPT-4o. Hatched bars represent F1-macro scores, while smooth bars indicate accuracy. Averages and standard deviations are calculated across 12 toxicity symptoms. The right panel illustrates the average Performance-Cost Ratio for refined Phi-3 and Zephyr models, showing performance scores and associated costs.</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="Sx2.SSx4.SSSx3">
<h4 class="ltx_title ltx_title_subsubsection">Hybrid Approach</h4>
<div class="ltx_para" id="Sx2.SSx4.SSSx3.p1">
<p class="ltx_p" id="Sx2.SSx4.SSSx3.p1.1">The hybrid approach combines the strengths of both prompt refinement and fine-tuning, allowing for dynamic adaptation based on the model‚Äôs current performance and needs. In this approach, the teacher model acts as an intelligent agent, deciding between prompt refinement and fine-tuning at each iteration. The process is as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx2.SSx4.SSSx3.p2">
<p class="ltx_p" id="Sx2.SSx4.SSSx3.p2.1"><span class="ltx_text ltx_font_bold" id="Sx2.SSx4.SSSx3.p2.1.1">1. Action Selection:</span> The teacher model is presented with a comprehensive prompt that includes:</p>
<ul class="ltx_itemize" id="Sx2.I5">
<li class="ltx_item" id="Sx2.I5.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx2.I5.i1.p1">
<p class="ltx_p" id="Sx2.I5.i1.p1.1">The best-performing prompt so far</p>
</div>
</li>
<li class="ltx_item" id="Sx2.I5.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx2.I5.i2.p1">
<p class="ltx_p" id="Sx2.I5.i2.p1.1">Previous prompts that were less effective</p>
</div>
</li>
<li class="ltx_item" id="Sx2.I5.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx2.I5.i3.p1">
<p class="ltx_p" id="Sx2.I5.i3.p1.1">The student model‚Äôs performance across all notes, including ground truth labels, output labels, and reasoning</p>
</div>
</li>
<li class="ltx_item" id="Sx2.I5.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx2.I5.i4.p1">
<p class="ltx_p" id="Sx2.I5.i4.p1.1">A history of previous actions taken and their resulting performance metrics</p>
</div>
</li>
</ul>
<p class="ltx_p" id="Sx2.SSx4.SSSx3.p2.2">Based on this information, the teacher model is asked to choose between prompt refinement and fine-tuning. The decision prompt is structured as follows:</p>
<blockquote class="ltx_quote" id="Sx2.SSx4.SSSx3.p2.3">
<p class="ltx_p" id="Sx2.SSx4.SSSx3.p2.3.1"><span class="ltx_text ltx_font_italic" id="Sx2.SSx4.SSSx3.p2.3.1.1">"Your task is to act as an intelligent agent that can decide whether to perform prompt refinement or fine-tuning on another Large Language Model called LLM2. LLM2 scores single clinical symptoms as yes/no/idk in clinical notes based on a given target symptom. [‚Ä¶] Based on this information, you must make a decision between the following actions:
@prompt_refinement: Choose this if [‚Ä¶] @finetuning: Choose this if [‚Ä¶]
Pay special attention to the reasonings LLM2 has provided for its labelings when making your decision."</span></p>
</blockquote>
<p class="ltx_p" id="Sx2.SSx4.SSSx3.p2.4">The teacher model returns its decision as a JSON object, including the chosen action and a brief explanation for why it believes this action is the most effective next step.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx2.SSx4.SSSx3.p3">
<p class="ltx_p" id="Sx2.SSx4.SSSx3.p3.1"><span class="ltx_text ltx_font_bold" id="Sx2.SSx4.SSSx3.p3.1.1">2. Action Execution:</span> Based on the teacher‚Äôs decision:</p>
<ul class="ltx_itemize" id="Sx2.I6">
<li class="ltx_item" id="Sx2.I6.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx2.I6.i1.p1">
<p class="ltx_p" id="Sx2.I6.i1.p1.1">If prompt refinement is chosen, the process proceeds as described in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#Sx2.SSx4.SSSx1" title="Prompt Refinement Approach ‚Ä£ Methods Investigated ‚Ä£ Experiments ‚Ä£ Hybrid Student-Teacher Large Language Model Refinement for Cancer Toxicity Symptom Extraction"><span class="ltx_text ltx_ref_title">Prompt Refinement Approach</span></a>.</p>
</div>
</li>
<li class="ltx_item" id="Sx2.I6.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Sx2.I6.i2.p1">
<p class="ltx_p" id="Sx2.I6.i2.p1.1">If fine-tuning is chosen, the process proceeds as described in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#Sx2.SSx4.SSSx2" title="Fine-Tuning Approach ‚Ä£ Methods Investigated ‚Ä£ Experiments ‚Ä£ Hybrid Student-Teacher Large Language Model Refinement for Cancer Toxicity Symptom Extraction"><span class="ltx_text ltx_ref_title">Fine-Tuning Approach</span></a>.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="Sx2.SSx4.SSSx3.p3.2">This hybrid approach allows for a flexible and adaptive optimization strategy, leveraging the strengths of both prompt refinement and fine-tuning based on the specific needs and performance of the model at each stage of the process.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="Sx2.SSx5">
<h3 class="ltx_title ltx_title_subsection">LLM Hyperparameter Selection for Text Generation</h3>
<div class="ltx_para" id="Sx2.SSx5.p1">
<p class="ltx_p" id="Sx2.SSx5.p1.1">The hyperparameters for the student and teacher models were selected to balance reproducibility in the student model with creative problem-solving in the teacher model. For the student model, we set the <span class="ltx_text ltx_font_italic" id="Sx2.SSx5.p1.1.1">temperature</span> to 0.2, <span class="ltx_text ltx_font_italic" id="Sx2.SSx5.p1.1.2">top-p</span> to 0.1, <span class="ltx_text ltx_font_italic" id="Sx2.SSx5.p1.1.3">top-k</span> to 1, expected output length to 500 tokens, epochs to 5, and rounds per epoch to 16. These settings ensure deterministic outputs, minimizing randomness and enhancing reproducibility. For the teacher model, we set the <span class="ltx_text ltx_font_italic" id="Sx2.SSx5.p1.1.4">temperature</span> to 1.9, <span class="ltx_text ltx_font_italic" id="Sx2.SSx5.p1.1.5">top-p</span> to 0.9, <span class="ltx_text ltx_font_italic" id="Sx2.SSx5.p1.1.6">top-k</span> to 50, and expected output length to 500 tokens. These values were chosen to allow for a diverse and exploratory generation of outputs, facilitating effective problem-solving and prompt refinement. These hyperparameters were chosen based on established guidelines for token selection and temperature settings in LLMs to optimize performance for our specific application.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx2.SSx6">
<h3 class="ltx_title ltx_title_subsection">Student and Teacher Evaluation Metrics</h3>
<div class="ltx_para" id="Sx2.SSx6.p1">
<p class="ltx_p" id="Sx2.SSx6.p1.1">In this study, we evaluate our student models by measuring accuracy and F1 macro scores after each symptom annotation in the training dataset. Additionally, the computational cost is assessed based on the prompt length and model weights. Costs are calculated using a function that determines the expenses of processing input and output tokens with GPT-4o, priced at $5.00 and $15.00 per million tokens respectively, reflecting the API‚Äôs current rates at the time of writing. Energy consumption is also evaluated by tracking the power usage during model inference, translating this into kilowatt-hours and then into monetary costs, using the average U.S. electricity rate of 16.88 cents per kilowatt-hour. This methodical approach ensures a comprehensive understanding of both the clinical efficacy and operational efficiency of the deployed student models in realistic healthcare settings.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Sx3">
<h2 class="ltx_title ltx_title_section">Results</h2>
<div class="ltx_para" id="Sx3.p1">
<p class="ltx_p" id="Sx3.p1.1">The performance evaluation of the Zephyr-7b-beta and Phi3-mini-128 models in extracting symptoms from clinical notes is presented across three refinement techniques: RAG, fine-tuning, and the hybrid method. These results, shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#Sx2.F2" title="Figure 2 ‚Ä£ Iterative Refinement Process ‚Ä£ Iterative Refinement in the Student-Teacher Framework ‚Ä£ Experiments ‚Ä£ Hybrid Student-Teacher Large Language Model Refinement for Cancer Toxicity Symptom Extraction"><span class="ltx_text ltx_ref_tag">2</span></a>, highlight the improvement in symptom extraction accuracy over five epochs during the iterative refinement process of prompts, RAG examples, and model weights.</p>
</div>
<div class="ltx_para" id="Sx3.p2">
<p class="ltx_p" id="Sx3.p2.1">For the Zephyr-7b-beta model using the RAG method, the average score increased from 0.32 ¬± 0.20 to 0.73 ¬± 0.15, demonstrating a significant lift in performance with a mean increase of 0.41 and a standard deviation decrease of 0.05. Notable improvements were observed in symptoms like Urothelial Carcinoma, which increased from 0 to 1 in two epochs, and Proctitis, which rose from 0.1 to 0.9 in three epochs. In the fine-tuning approach, the average score improved to 0.46 ¬± 0.23, with a smaller increase in mean performance. The most improved symptom was Cystitis, which increased from 0.3 to approximately 0.8. The hybrid method achieved an average score of 0.69 ¬± 0.20, showing similar but slightly less improvement compared to RAG. Symptoms like Erectile Dysfunction showed more improvement in the hybrid method than in RAG, and Stricture improved from 0.1 to approximately 0.85, compared to 0.65 in RAG.</p>
</div>
<div class="ltx_para" id="Sx3.p3">
<p class="ltx_p" id="Sx3.p3.1">For the Phi3-mini-128 model, the RAG approach resulted in the highest improvement, with the average score increasing from 0.40 ¬± 0.20 to 0.87 ¬± 0.09, showing a substantial lift of 0.46 in the mean and a decrease in standard deviation by 0.11. Fine-tuning showed limited improvements, with an average score of 0.42 ¬± 0.20, primarily in symptoms like Urinary Obstruction and Incontinence. The hybrid method for Phi3-mini-128 achieved a mean score of 0.80 ¬± 0.14, with a decrease in standard deviation by 0.05. Noteworthy improvements were seen in symptoms such as Nocturia, which increased to 0.9 in just one iteration, indicating faster convergence compared to the RAG method.</p>
</div>
<div class="ltx_para" id="Sx3.p4">
<p class="ltx_p" id="Sx3.p4.4">The results in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#Sx2.F3" title="Figure 3 ‚Ä£ Fine-Tuning Approach ‚Ä£ Methods Investigated ‚Ä£ Experiments ‚Ä£ Hybrid Student-Teacher Large Language Model Refinement for Cancer Toxicity Symptom Extraction"><span class="ltx_text ltx_ref_tag">3</span></a> present the performance of Phi-3 across different refinement techniques on the test set for all toxicity symptoms, showing both accuracy and F1-macro scores along with associated average costs per test note. The initial accuracy for Phi-3 with the base prompt and weights was 0.48 across all methods. After refinement, the Hybrid approach showed the highest improvement with an accuracy of 0.67, closely followed by RAG at 0.65, while fine-tuning yielded minimal improvement to 0.50. For F1-macro scores, the initial performance was 0.35, with the Hybrid method achieving the highest refined score of 0.54, followed by RAG at 0.49, while fine-tuning showed no improvement. GPT-4o, tested with both the initial Phi-3 prompt and the refined Hybrid prompt (selected as it performed best in both accuracy and F1-macro), demonstrated initial accuracy and F1-macro scores of 0.67 and 0.49 respectively, improving to 0.90 and 0.77 with the refined prompt. Notably, the average costs per test note varied significantly: GPT-4o was the most expensive at $<math alttext="7.11\times 10^{-2}" class="ltx_Math" display="inline" id="Sx3.p4.1.m1.1"><semantics id="Sx3.p4.1.m1.1a"><mrow id="Sx3.p4.1.m1.1.1" xref="Sx3.p4.1.m1.1.1.cmml"><mn id="Sx3.p4.1.m1.1.1.2" xref="Sx3.p4.1.m1.1.1.2.cmml">7.11</mn><mo id="Sx3.p4.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="Sx3.p4.1.m1.1.1.1.cmml">√ó</mo><msup id="Sx3.p4.1.m1.1.1.3" xref="Sx3.p4.1.m1.1.1.3.cmml"><mn id="Sx3.p4.1.m1.1.1.3.2" xref="Sx3.p4.1.m1.1.1.3.2.cmml">10</mn><mrow id="Sx3.p4.1.m1.1.1.3.3" xref="Sx3.p4.1.m1.1.1.3.3.cmml"><mo id="Sx3.p4.1.m1.1.1.3.3a" xref="Sx3.p4.1.m1.1.1.3.3.cmml">‚àí</mo><mn id="Sx3.p4.1.m1.1.1.3.3.2" xref="Sx3.p4.1.m1.1.1.3.3.2.cmml">2</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Sx3.p4.1.m1.1b"><apply id="Sx3.p4.1.m1.1.1.cmml" xref="Sx3.p4.1.m1.1.1"><times id="Sx3.p4.1.m1.1.1.1.cmml" xref="Sx3.p4.1.m1.1.1.1"></times><cn id="Sx3.p4.1.m1.1.1.2.cmml" type="float" xref="Sx3.p4.1.m1.1.1.2">7.11</cn><apply id="Sx3.p4.1.m1.1.1.3.cmml" xref="Sx3.p4.1.m1.1.1.3"><csymbol cd="ambiguous" id="Sx3.p4.1.m1.1.1.3.1.cmml" xref="Sx3.p4.1.m1.1.1.3">superscript</csymbol><cn id="Sx3.p4.1.m1.1.1.3.2.cmml" type="integer" xref="Sx3.p4.1.m1.1.1.3.2">10</cn><apply id="Sx3.p4.1.m1.1.1.3.3.cmml" xref="Sx3.p4.1.m1.1.1.3.3"><minus id="Sx3.p4.1.m1.1.1.3.3.1.cmml" xref="Sx3.p4.1.m1.1.1.3.3"></minus><cn id="Sx3.p4.1.m1.1.1.3.3.2.cmml" type="integer" xref="Sx3.p4.1.m1.1.1.3.3.2">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.p4.1.m1.1c">7.11\times 10^{-2}</annotation><annotation encoding="application/x-llamapun" id="Sx3.p4.1.m1.1d">7.11 √ó 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT</annotation></semantics></math>, followed by fine-tuning at $<math alttext="2.2\times 10^{-3}" class="ltx_Math" display="inline" id="Sx3.p4.2.m2.1"><semantics id="Sx3.p4.2.m2.1a"><mrow id="Sx3.p4.2.m2.1.1" xref="Sx3.p4.2.m2.1.1.cmml"><mn id="Sx3.p4.2.m2.1.1.2" xref="Sx3.p4.2.m2.1.1.2.cmml">2.2</mn><mo id="Sx3.p4.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="Sx3.p4.2.m2.1.1.1.cmml">√ó</mo><msup id="Sx3.p4.2.m2.1.1.3" xref="Sx3.p4.2.m2.1.1.3.cmml"><mn id="Sx3.p4.2.m2.1.1.3.2" xref="Sx3.p4.2.m2.1.1.3.2.cmml">10</mn><mrow id="Sx3.p4.2.m2.1.1.3.3" xref="Sx3.p4.2.m2.1.1.3.3.cmml"><mo id="Sx3.p4.2.m2.1.1.3.3a" xref="Sx3.p4.2.m2.1.1.3.3.cmml">‚àí</mo><mn id="Sx3.p4.2.m2.1.1.3.3.2" xref="Sx3.p4.2.m2.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Sx3.p4.2.m2.1b"><apply id="Sx3.p4.2.m2.1.1.cmml" xref="Sx3.p4.2.m2.1.1"><times id="Sx3.p4.2.m2.1.1.1.cmml" xref="Sx3.p4.2.m2.1.1.1"></times><cn id="Sx3.p4.2.m2.1.1.2.cmml" type="float" xref="Sx3.p4.2.m2.1.1.2">2.2</cn><apply id="Sx3.p4.2.m2.1.1.3.cmml" xref="Sx3.p4.2.m2.1.1.3"><csymbol cd="ambiguous" id="Sx3.p4.2.m2.1.1.3.1.cmml" xref="Sx3.p4.2.m2.1.1.3">superscript</csymbol><cn id="Sx3.p4.2.m2.1.1.3.2.cmml" type="integer" xref="Sx3.p4.2.m2.1.1.3.2">10</cn><apply id="Sx3.p4.2.m2.1.1.3.3.cmml" xref="Sx3.p4.2.m2.1.1.3.3"><minus id="Sx3.p4.2.m2.1.1.3.3.1.cmml" xref="Sx3.p4.2.m2.1.1.3.3"></minus><cn id="Sx3.p4.2.m2.1.1.3.3.2.cmml" type="integer" xref="Sx3.p4.2.m2.1.1.3.3.2">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.p4.2.m2.1c">2.2\times 10^{-3}</annotation><annotation encoding="application/x-llamapun" id="Sx3.p4.2.m2.1d">2.2 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT</annotation></semantics></math>, Hybrid at $<math alttext="9.0\times 10^{-4}" class="ltx_Math" display="inline" id="Sx3.p4.3.m3.1"><semantics id="Sx3.p4.3.m3.1a"><mrow id="Sx3.p4.3.m3.1.1" xref="Sx3.p4.3.m3.1.1.cmml"><mn id="Sx3.p4.3.m3.1.1.2" xref="Sx3.p4.3.m3.1.1.2.cmml">9.0</mn><mo id="Sx3.p4.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="Sx3.p4.3.m3.1.1.1.cmml">√ó</mo><msup id="Sx3.p4.3.m3.1.1.3" xref="Sx3.p4.3.m3.1.1.3.cmml"><mn id="Sx3.p4.3.m3.1.1.3.2" xref="Sx3.p4.3.m3.1.1.3.2.cmml">10</mn><mrow id="Sx3.p4.3.m3.1.1.3.3" xref="Sx3.p4.3.m3.1.1.3.3.cmml"><mo id="Sx3.p4.3.m3.1.1.3.3a" xref="Sx3.p4.3.m3.1.1.3.3.cmml">‚àí</mo><mn id="Sx3.p4.3.m3.1.1.3.3.2" xref="Sx3.p4.3.m3.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Sx3.p4.3.m3.1b"><apply id="Sx3.p4.3.m3.1.1.cmml" xref="Sx3.p4.3.m3.1.1"><times id="Sx3.p4.3.m3.1.1.1.cmml" xref="Sx3.p4.3.m3.1.1.1"></times><cn id="Sx3.p4.3.m3.1.1.2.cmml" type="float" xref="Sx3.p4.3.m3.1.1.2">9.0</cn><apply id="Sx3.p4.3.m3.1.1.3.cmml" xref="Sx3.p4.3.m3.1.1.3"><csymbol cd="ambiguous" id="Sx3.p4.3.m3.1.1.3.1.cmml" xref="Sx3.p4.3.m3.1.1.3">superscript</csymbol><cn id="Sx3.p4.3.m3.1.1.3.2.cmml" type="integer" xref="Sx3.p4.3.m3.1.1.3.2">10</cn><apply id="Sx3.p4.3.m3.1.1.3.3.cmml" xref="Sx3.p4.3.m3.1.1.3.3"><minus id="Sx3.p4.3.m3.1.1.3.3.1.cmml" xref="Sx3.p4.3.m3.1.1.3.3"></minus><cn id="Sx3.p4.3.m3.1.1.3.3.2.cmml" type="integer" xref="Sx3.p4.3.m3.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.p4.3.m3.1c">9.0\times 10^{-4}</annotation><annotation encoding="application/x-llamapun" id="Sx3.p4.3.m3.1d">9.0 √ó 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math>, and RAG being the most cost-effective at $<math alttext="8.0\times 10^{-4}" class="ltx_Math" display="inline" id="Sx3.p4.4.m4.1"><semantics id="Sx3.p4.4.m4.1a"><mrow id="Sx3.p4.4.m4.1.1" xref="Sx3.p4.4.m4.1.1.cmml"><mn id="Sx3.p4.4.m4.1.1.2" xref="Sx3.p4.4.m4.1.1.2.cmml">8.0</mn><mo id="Sx3.p4.4.m4.1.1.1" lspace="0.222em" rspace="0.222em" xref="Sx3.p4.4.m4.1.1.1.cmml">√ó</mo><msup id="Sx3.p4.4.m4.1.1.3" xref="Sx3.p4.4.m4.1.1.3.cmml"><mn id="Sx3.p4.4.m4.1.1.3.2" xref="Sx3.p4.4.m4.1.1.3.2.cmml">10</mn><mrow id="Sx3.p4.4.m4.1.1.3.3" xref="Sx3.p4.4.m4.1.1.3.3.cmml"><mo id="Sx3.p4.4.m4.1.1.3.3a" xref="Sx3.p4.4.m4.1.1.3.3.cmml">‚àí</mo><mn id="Sx3.p4.4.m4.1.1.3.3.2" xref="Sx3.p4.4.m4.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Sx3.p4.4.m4.1b"><apply id="Sx3.p4.4.m4.1.1.cmml" xref="Sx3.p4.4.m4.1.1"><times id="Sx3.p4.4.m4.1.1.1.cmml" xref="Sx3.p4.4.m4.1.1.1"></times><cn id="Sx3.p4.4.m4.1.1.2.cmml" type="float" xref="Sx3.p4.4.m4.1.1.2">8.0</cn><apply id="Sx3.p4.4.m4.1.1.3.cmml" xref="Sx3.p4.4.m4.1.1.3"><csymbol cd="ambiguous" id="Sx3.p4.4.m4.1.1.3.1.cmml" xref="Sx3.p4.4.m4.1.1.3">superscript</csymbol><cn id="Sx3.p4.4.m4.1.1.3.2.cmml" type="integer" xref="Sx3.p4.4.m4.1.1.3.2">10</cn><apply id="Sx3.p4.4.m4.1.1.3.3.cmml" xref="Sx3.p4.4.m4.1.1.3.3"><minus id="Sx3.p4.4.m4.1.1.3.3.1.cmml" xref="Sx3.p4.4.m4.1.1.3.3"></minus><cn id="Sx3.p4.4.m4.1.1.3.3.2.cmml" type="integer" xref="Sx3.p4.4.m4.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.p4.4.m4.1c">8.0\times 10^{-4}</annotation><annotation encoding="application/x-llamapun" id="Sx3.p4.4.m4.1d">8.0 √ó 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="Sx3.p5">
<p class="ltx_p" id="Sx3.p5.4">The results for the Zephyr model, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#Sx2.F3" title="Figure 3 ‚Ä£ Fine-Tuning Approach ‚Ä£ Methods Investigated ‚Ä£ Experiments ‚Ä£ Hybrid Student-Teacher Large Language Model Refinement for Cancer Toxicity Symptom Extraction"><span class="ltx_text ltx_ref_tag">3</span></a>, illustrate performance across various refinement techniques on the test set for all toxicity symptoms, presenting accuracy and F1-macro scores alongside average costs per test note. The initial accuracy for Zephyr with the base prompt and weights was 0.30 across all methods. Post-refinement, the RAG approach demonstrated the highest improvement with an accuracy of 0.53, followed by the Hybrid method at 0.48, while fine-tuning showed minimal improvement to 0.33. For F1-macro scores, the initial performance was 0.17, with RAG achieving the highest refined score of 0.39, followed by Hybrid at 0.35, and fine-tuning showing no substantial improvement at 0.17. GPT-4o, evaluated using both the initial Zephyr prompt and the refined RAG prompt (chosen for its superior performance in both accuracy and F1-macro), showed initial accuracy and F1-macro scores of 0.65 and 0.48 respectively, improving to 0.78 and 0.65 with the refined prompt. The average costs per test note varied considerably: GPT-4o was the most expensive at $<math alttext="5.90\times 10^{-2}" class="ltx_Math" display="inline" id="Sx3.p5.1.m1.1"><semantics id="Sx3.p5.1.m1.1a"><mrow id="Sx3.p5.1.m1.1.1" xref="Sx3.p5.1.m1.1.1.cmml"><mn id="Sx3.p5.1.m1.1.1.2" xref="Sx3.p5.1.m1.1.1.2.cmml">5.90</mn><mo id="Sx3.p5.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="Sx3.p5.1.m1.1.1.1.cmml">√ó</mo><msup id="Sx3.p5.1.m1.1.1.3" xref="Sx3.p5.1.m1.1.1.3.cmml"><mn id="Sx3.p5.1.m1.1.1.3.2" xref="Sx3.p5.1.m1.1.1.3.2.cmml">10</mn><mrow id="Sx3.p5.1.m1.1.1.3.3" xref="Sx3.p5.1.m1.1.1.3.3.cmml"><mo id="Sx3.p5.1.m1.1.1.3.3a" xref="Sx3.p5.1.m1.1.1.3.3.cmml">‚àí</mo><mn id="Sx3.p5.1.m1.1.1.3.3.2" xref="Sx3.p5.1.m1.1.1.3.3.2.cmml">2</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Sx3.p5.1.m1.1b"><apply id="Sx3.p5.1.m1.1.1.cmml" xref="Sx3.p5.1.m1.1.1"><times id="Sx3.p5.1.m1.1.1.1.cmml" xref="Sx3.p5.1.m1.1.1.1"></times><cn id="Sx3.p5.1.m1.1.1.2.cmml" type="float" xref="Sx3.p5.1.m1.1.1.2">5.90</cn><apply id="Sx3.p5.1.m1.1.1.3.cmml" xref="Sx3.p5.1.m1.1.1.3"><csymbol cd="ambiguous" id="Sx3.p5.1.m1.1.1.3.1.cmml" xref="Sx3.p5.1.m1.1.1.3">superscript</csymbol><cn id="Sx3.p5.1.m1.1.1.3.2.cmml" type="integer" xref="Sx3.p5.1.m1.1.1.3.2">10</cn><apply id="Sx3.p5.1.m1.1.1.3.3.cmml" xref="Sx3.p5.1.m1.1.1.3.3"><minus id="Sx3.p5.1.m1.1.1.3.3.1.cmml" xref="Sx3.p5.1.m1.1.1.3.3"></minus><cn id="Sx3.p5.1.m1.1.1.3.3.2.cmml" type="integer" xref="Sx3.p5.1.m1.1.1.3.3.2">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.p5.1.m1.1c">5.90\times 10^{-2}</annotation><annotation encoding="application/x-llamapun" id="Sx3.p5.1.m1.1d">5.90 √ó 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT</annotation></semantics></math>, followed by fine-tuning at $<math alttext="2.7\times 10^{-3}" class="ltx_Math" display="inline" id="Sx3.p5.2.m2.1"><semantics id="Sx3.p5.2.m2.1a"><mrow id="Sx3.p5.2.m2.1.1" xref="Sx3.p5.2.m2.1.1.cmml"><mn id="Sx3.p5.2.m2.1.1.2" xref="Sx3.p5.2.m2.1.1.2.cmml">2.7</mn><mo id="Sx3.p5.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="Sx3.p5.2.m2.1.1.1.cmml">√ó</mo><msup id="Sx3.p5.2.m2.1.1.3" xref="Sx3.p5.2.m2.1.1.3.cmml"><mn id="Sx3.p5.2.m2.1.1.3.2" xref="Sx3.p5.2.m2.1.1.3.2.cmml">10</mn><mrow id="Sx3.p5.2.m2.1.1.3.3" xref="Sx3.p5.2.m2.1.1.3.3.cmml"><mo id="Sx3.p5.2.m2.1.1.3.3a" xref="Sx3.p5.2.m2.1.1.3.3.cmml">‚àí</mo><mn id="Sx3.p5.2.m2.1.1.3.3.2" xref="Sx3.p5.2.m2.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Sx3.p5.2.m2.1b"><apply id="Sx3.p5.2.m2.1.1.cmml" xref="Sx3.p5.2.m2.1.1"><times id="Sx3.p5.2.m2.1.1.1.cmml" xref="Sx3.p5.2.m2.1.1.1"></times><cn id="Sx3.p5.2.m2.1.1.2.cmml" type="float" xref="Sx3.p5.2.m2.1.1.2">2.7</cn><apply id="Sx3.p5.2.m2.1.1.3.cmml" xref="Sx3.p5.2.m2.1.1.3"><csymbol cd="ambiguous" id="Sx3.p5.2.m2.1.1.3.1.cmml" xref="Sx3.p5.2.m2.1.1.3">superscript</csymbol><cn id="Sx3.p5.2.m2.1.1.3.2.cmml" type="integer" xref="Sx3.p5.2.m2.1.1.3.2">10</cn><apply id="Sx3.p5.2.m2.1.1.3.3.cmml" xref="Sx3.p5.2.m2.1.1.3.3"><minus id="Sx3.p5.2.m2.1.1.3.3.1.cmml" xref="Sx3.p5.2.m2.1.1.3.3"></minus><cn id="Sx3.p5.2.m2.1.1.3.3.2.cmml" type="integer" xref="Sx3.p5.2.m2.1.1.3.3.2">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.p5.2.m2.1c">2.7\times 10^{-3}</annotation><annotation encoding="application/x-llamapun" id="Sx3.p5.2.m2.1d">2.7 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT</annotation></semantics></math>, Hybrid at $<math alttext="1.4\times 10^{-3}" class="ltx_Math" display="inline" id="Sx3.p5.3.m3.1"><semantics id="Sx3.p5.3.m3.1a"><mrow id="Sx3.p5.3.m3.1.1" xref="Sx3.p5.3.m3.1.1.cmml"><mn id="Sx3.p5.3.m3.1.1.2" xref="Sx3.p5.3.m3.1.1.2.cmml">1.4</mn><mo id="Sx3.p5.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="Sx3.p5.3.m3.1.1.1.cmml">√ó</mo><msup id="Sx3.p5.3.m3.1.1.3" xref="Sx3.p5.3.m3.1.1.3.cmml"><mn id="Sx3.p5.3.m3.1.1.3.2" xref="Sx3.p5.3.m3.1.1.3.2.cmml">10</mn><mrow id="Sx3.p5.3.m3.1.1.3.3" xref="Sx3.p5.3.m3.1.1.3.3.cmml"><mo id="Sx3.p5.3.m3.1.1.3.3a" xref="Sx3.p5.3.m3.1.1.3.3.cmml">‚àí</mo><mn id="Sx3.p5.3.m3.1.1.3.3.2" xref="Sx3.p5.3.m3.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Sx3.p5.3.m3.1b"><apply id="Sx3.p5.3.m3.1.1.cmml" xref="Sx3.p5.3.m3.1.1"><times id="Sx3.p5.3.m3.1.1.1.cmml" xref="Sx3.p5.3.m3.1.1.1"></times><cn id="Sx3.p5.3.m3.1.1.2.cmml" type="float" xref="Sx3.p5.3.m3.1.1.2">1.4</cn><apply id="Sx3.p5.3.m3.1.1.3.cmml" xref="Sx3.p5.3.m3.1.1.3"><csymbol cd="ambiguous" id="Sx3.p5.3.m3.1.1.3.1.cmml" xref="Sx3.p5.3.m3.1.1.3">superscript</csymbol><cn id="Sx3.p5.3.m3.1.1.3.2.cmml" type="integer" xref="Sx3.p5.3.m3.1.1.3.2">10</cn><apply id="Sx3.p5.3.m3.1.1.3.3.cmml" xref="Sx3.p5.3.m3.1.1.3.3"><minus id="Sx3.p5.3.m3.1.1.3.3.1.cmml" xref="Sx3.p5.3.m3.1.1.3.3"></minus><cn id="Sx3.p5.3.m3.1.1.3.3.2.cmml" type="integer" xref="Sx3.p5.3.m3.1.1.3.3.2">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.p5.3.m3.1c">1.4\times 10^{-3}</annotation><annotation encoding="application/x-llamapun" id="Sx3.p5.3.m3.1d">1.4 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT</annotation></semantics></math>, and RAG being the most cost-effective at $<math alttext="1.3\times 10^{-3}" class="ltx_Math" display="inline" id="Sx3.p5.4.m4.1"><semantics id="Sx3.p5.4.m4.1a"><mrow id="Sx3.p5.4.m4.1.1" xref="Sx3.p5.4.m4.1.1.cmml"><mn id="Sx3.p5.4.m4.1.1.2" xref="Sx3.p5.4.m4.1.1.2.cmml">1.3</mn><mo id="Sx3.p5.4.m4.1.1.1" lspace="0.222em" rspace="0.222em" xref="Sx3.p5.4.m4.1.1.1.cmml">√ó</mo><msup id="Sx3.p5.4.m4.1.1.3" xref="Sx3.p5.4.m4.1.1.3.cmml"><mn id="Sx3.p5.4.m4.1.1.3.2" xref="Sx3.p5.4.m4.1.1.3.2.cmml">10</mn><mrow id="Sx3.p5.4.m4.1.1.3.3" xref="Sx3.p5.4.m4.1.1.3.3.cmml"><mo id="Sx3.p5.4.m4.1.1.3.3a" xref="Sx3.p5.4.m4.1.1.3.3.cmml">‚àí</mo><mn id="Sx3.p5.4.m4.1.1.3.3.2" xref="Sx3.p5.4.m4.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Sx3.p5.4.m4.1b"><apply id="Sx3.p5.4.m4.1.1.cmml" xref="Sx3.p5.4.m4.1.1"><times id="Sx3.p5.4.m4.1.1.1.cmml" xref="Sx3.p5.4.m4.1.1.1"></times><cn id="Sx3.p5.4.m4.1.1.2.cmml" type="float" xref="Sx3.p5.4.m4.1.1.2">1.3</cn><apply id="Sx3.p5.4.m4.1.1.3.cmml" xref="Sx3.p5.4.m4.1.1.3"><csymbol cd="ambiguous" id="Sx3.p5.4.m4.1.1.3.1.cmml" xref="Sx3.p5.4.m4.1.1.3">superscript</csymbol><cn id="Sx3.p5.4.m4.1.1.3.2.cmml" type="integer" xref="Sx3.p5.4.m4.1.1.3.2">10</cn><apply id="Sx3.p5.4.m4.1.1.3.3.cmml" xref="Sx3.p5.4.m4.1.1.3.3"><minus id="Sx3.p5.4.m4.1.1.3.3.1.cmml" xref="Sx3.p5.4.m4.1.1.3.3"></minus><cn id="Sx3.p5.4.m4.1.1.3.3.2.cmml" type="integer" xref="Sx3.p5.4.m4.1.1.3.3.2">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.p5.4.m4.1c">1.3\times 10^{-3}</annotation><annotation encoding="application/x-llamapun" id="Sx3.p5.4.m4.1d">1.3 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="Sx3.p6">
<p class="ltx_p" id="Sx3.p6.1">The right panel in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04775v1#Sx2.F3" title="Figure 3 ‚Ä£ Fine-Tuning Approach ‚Ä£ Methods Investigated ‚Ä£ Experiments ‚Ä£ Hybrid Student-Teacher Large Language Model Refinement for Cancer Toxicity Symptom Extraction"><span class="ltx_text ltx_ref_tag">3</span></a> presents the average PCR for refined Phi-3 and Zephyr models across the 12 toxicity symptoms, with error bars indicating standard deviation across symptoms. For accuracy-based PCR, Phi-3 consistently outperformed Zephyr across all methods. The Hybrid approach yielded the highest PCR for Phi-3 at 813, followed closely by RAG at 740, while Zephyr achieved 647 for RAG and 609 for Hybrid. Fine-tuning showed identical modest PCR values of 104 for both models. GPT-4o, despite its high performance, had the lowest PCR (14 for Phi-3, 13 for Zephyr) due to its significantly higher cost. F1-based PCR values showed a slightly different pattern, with Phi-3 achieving 719 for Hybrid and 560 for RAG, while Zephyr scored 587 for RAG and 489 for Hybrid. Fine-tuning showed lower F1-based PCR at 65 for Phi-3 and 63 for Zephyr. These results underscore the efficiency of the Hybrid and RAG approaches in balancing performance and cost, with Phi-3 demonstrating superior cost-effectiveness across most methods, particularly in the Hybrid approach for F1-based metrics.</p>
</div>
</section>
<section class="ltx_section" id="Sx4">
<h2 class="ltx_title ltx_title_section">Conclusion and Discussion</h2>
<div class="ltx_para" id="Sx4.p1">
<p class="ltx_p" id="Sx4.p1.1">This study explored iterative refinement techniques to optimize compact, locally deployable LLMs for clinical settings, aiming to balance data privacy, computational constraints, and operational costs. Using a student-teacher architecture with Zephyr-7b-beta and Phi3-mini-128 as student models and GPT-4o as the teacher, we evaluated prompt refinement with RAG, fine-tuning, and a hybrid method.</p>
</div>
<div class="ltx_para" id="Sx4.p2">
<p class="ltx_p" id="Sx4.p2.1">Our findings revealed that the RAG method provided significant performance improvements and cost-efficiency. This approach substantially enhanced accuracy and F1-macro scores while maintaining low operational costs, making it a practical solution for clinical applications. Fine-tuning, on the other hand, was less effective when used alone, suggesting its role is best as a complementary technique rather than a standalone solution. The hybrid method, which combines RAG and fine-tuning, demonstrated the best overall performance in Phi3-mini-128 and outperformed other approaches in various scenarios. This method effectively harnessed the strengths of both RAG and fine-tuning, particularly for specific symptoms where combined strategies were essential.</p>
</div>
<div class="ltx_para" id="Sx4.p3">
<p class="ltx_p" id="Sx4.p3.1">Interestingly, our results showed that the smaller Phi3-mini-128, with approximately half the parameters of Zephyr-7b-beta, generally outperformed Zephyr in the task of clinical symptom extraction. This outcome suggests that model size alone does not determine effectiveness; rather, the refinement technique plays a crucial role in performance optimization.</p>
</div>
<div class="ltx_para" id="Sx4.p4">
<p class="ltx_p" id="Sx4.p4.1">The test results underscored the substantial cost implications associated with different models. Although GPT-4o delivered the highest absolute performance, its significantly higher expenses‚Äî45 times those of Zephyr and 79 times those of Phi-3‚Äîled to the lowest PCR. This finding underscores the importance of cost-effectiveness in practical applications, particularly in resource-constrained clinical environments.</p>
</div>
<div class="ltx_para" id="Sx4.p5">
<p class="ltx_p" id="Sx4.p5.1">In summary, our study demonstrates the effectiveness of iterative refinement techniques, particularly hybrid and RAG methods, in enhancing compact LLMs for clinical symptom extraction. These approaches balance performance and cost, offering viable alternatives to larger models. Our findings highlight the potential of advanced refinement techniques in improving LLM capabilities in data-sparse, specialized domains like healthcare. These methods effectively address performance needs and resource constraints, with potential applications beyond healthcare.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
X.¬†Meng, X.¬†Yan, K.¬†Zhang, D.¬†Liu, X.¬†Cui, Y.¬†Yang, M.¬†Zhang, C.¬†Cao, J.¬†Wang, X.¬†Wang, J.¬†Gao, Y.-G.-S. Wang, J.¬†ming Ji, Z.¬†Qiu, M.¬†Li, C.¬†Qian, T.¬†Guo, S.¬†Ma, Z.¬†Wang, Z.¬†Guo, Y.¬†Lei, C.¬†Shao, W.¬†Wang, H.¬†Fan, and Y.-D. Tang, ‚ÄúThe application of large language models in medicine: A scoping review,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">iScience</em>, vol.¬†27, no.¬†5, p. 109713, 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.sciencedirect.com/science/article/pii/S2589004224009350" title="">https://www.sciencedirect.com/science/article/pii/S2589004224009350</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
J.¬†Ong, S.¬†Y.-H. Chang, W.¬†Wasswa, A.¬†Butte, N.¬†Shah, L.¬†Chew, N.¬†Liu, F.¬†Doshi-Velez, W.¬†Lu, J.¬†Savulescu, and D.¬†Ting, ‚ÄúEthical and regulatory challenges of large language models in medicine,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">The Lancet Digital Health</em>, vol.¬†6, 04 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Y.¬†Chen and P.¬†Esmaeilzadeh, ‚ÄúGenerative ai in medical practice: In-depth exploration of privacy and security challenges,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Journal of medical Internet research</em>, vol.¬†26, p. e53008, 03 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
N.¬†H. Shah, D.¬†Entwistle, and M.¬†A. Pfeffer, ‚ÄúCreation and adoption of large language models in medicine,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">JAMA</em>, vol. 330, no.¬†9, pp. 866‚Äì869, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1001/jama.2023.14217" title="">https://doi.org/10.1001/jama.2023.14217</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
X.-Y. Fu, M.¬†T.¬†R. Laskar, E.¬†Khasanova, C.¬†Chen, and S.¬†B. TN, ‚ÄúTiny titans: Can smaller large language models punch above their weight in the real world for meeting summarization?‚Äù 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2402.00841" title="">https://arxiv.org/abs/2402.00841</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
C.¬†Wu, W.¬†Lin, X.¬†Zhang, Y.¬†Zhang, W.¬†Xie, and Y.¬†Wang, ‚ÄúPmc-llama: Toward building open-source language models for medicine,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Journal of the American Medical Informatics Association</em>, April 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1093/jamia/ocae045" title="">https://doi.org/10.1093/jamia/ocae045</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
M.¬†Musser, ‚ÄúA cost analysis of generative language models and influence operations,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">ArXiv</em>, vol. abs/2308.03740, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:260682501" title="">https://api.semanticscholar.org/CorpusID:260682501</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
‚ÄúLarge language models in medicine: The potentials and pitfalls,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Annals of Internal Medicine</em>, vol. 177, no.¬†2, pp. 210‚Äì220, 2024, pMID: 38285984. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.7326/M23-2772" title="">https://doi.org/10.7326/M23-2772</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
M.¬†Mahbub, G.¬†M. Dams, S.¬†Srinivasan, C.¬†Rizy, I.¬†Danciu, J.¬†Trafton, and K.¬†Knight, ‚ÄúLeveraging large language models to extract information on substance use disorder severity from clinical notes: A zero-shot learning approach,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">ArXiv</em>, vol. abs/2403.12297, 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:268531240" title="">https://api.semanticscholar.org/CorpusID:268531240</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
J.¬†T. Reese, D.¬†Danis, J.¬†H. Caufield, T.¬†Groza, E.¬†Casiraghi, G.¬†Valentini, C.¬†J. Mungall, and P.¬†N. Robinson, ‚ÄúOn the limitations of large language models in clinical diagnosis,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">medRxiv</em>, Feb. 2024, preprint. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1101/2023.07.13.23292613" title="">https://doi.org/10.1101/2023.07.13.23292613</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
C.¬†Shyr, Y.¬†Hu, L.¬†Bastarache, A.¬†Cheng, R.¬†Hamid, P.¬†Harris, and H.¬†Xu, ‚ÄúIdentifying and extracting rare diseases and their phenotypes with large language models,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Journal of Healthcare Informatics Research</em>, vol.¬†8, no.¬†2, pp. 438‚Äì461, 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s41666-023-00155-0" title="">https://doi.org/10.1007/s41666-023-00155-0</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
M.¬†Guevara, S.¬†Chen, S.¬†A. Thomas, T.¬†L. Chaunzwa, I.¬†Franco, B.¬†H. Kann, S.¬†Moningi, J.¬†M. Qian, M.¬†H. Goldstein, S.¬†M. Harper, H.¬†J. Aerts, G.¬†K. Savova, R.¬†H. Mak, and D.¬†S. Bitterman, ‚ÄúLarge language models to identify social determinants of health in electronic health records,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">NPJ Digital Medicine</em>, vol.¬†7, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:260887020" title="">https://api.semanticscholar.org/CorpusID:260887020</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
P.¬†Chen, Z.¬†Guo, B.¬†Haddow, and K.¬†Heafield, ‚ÄúIterative translation refinement with large language models,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">ArXiv</em>, vol. abs/2306.03856, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:259088848" title="">https://api.semanticscholar.org/CorpusID:259088848</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
W.¬†Xiong, Y.¬†Song, X.¬†Zhao, W.¬†Wu, X.¬†Wang, K.¬†Wang, C.¬†Li, W.¬†Peng, and S.¬†Li, ‚ÄúWatch every step! llm agent learning via iterative step-level process refinement,‚Äù 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:270558898" title="">https://api.semanticscholar.org/CorpusID:270558898</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
A.¬†Madaan, N.¬†Tandon, P.¬†Gupta, S.¬†Hallinan, L.¬†Gao, S.¬†Wiegreffe, U.¬†Alon, N.¬†Dziri, S.¬†Prabhumoye, Y.¬†Yang <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">et¬†al.</em>, ‚ÄúSelf-refine: Iterative refinement with self-feedback,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib15.2.2">Advances in Neural Information Processing Systems</em>, vol.¬†36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
T.¬†Yan and T.¬†Xu, ‚ÄúRefining the responses of llms by themselves,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">ArXiv</em>, vol. abs/2305.04039, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:258556861" title="">https://api.semanticscholar.org/CorpusID:258556861</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Y.¬†Chen, J.¬†Gao, M.¬†Petruc, R.¬†D. Hammer, M.¬†Popescu, and D.¬†Xu, ‚ÄúIterative prompt refinement for mining gene relationships from chatgpt,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">bioRxiv</em>, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:266562033" title="">https://api.semanticscholar.org/CorpusID:266562033</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
N.¬†Lee, T.¬†Wattanawong, S.¬†Kim, K.¬†Mangalam, S.¬†Shen, G.¬†Anumanchipali, M.¬†W. Mahoney, K.¬†Keutzer, and A.¬†Gholami, ‚ÄúLlm2llm: Boosting llms with novel iterative data enhancement,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">ArXiv</em>, vol. abs/2403.15042, 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:268666980" title="">https://api.semanticscholar.org/CorpusID:268666980</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
C.¬†Zhang, C.¬†Tang, D.¬†Chong, K.¬†Shi, G.¬†Tang, F.¬†Jiang, and H.¬†Li, ‚ÄúTs-align: A teacher-student collaborative framework for scalable iterative finetuning of large language models,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">ArXiv</em>, vol. abs/2405.20215, 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:270123022" title="">https://api.semanticscholar.org/CorpusID:270123022</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
S.¬†Saha, P.¬†Hase, and M.¬†Bansal, ‚ÄúCan language models teach weaker agents? teacher explanations improve students via personalization,‚Äù 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:265157967" title="">https://api.semanticscholar.org/CorpusID:265157967</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
S.¬†Yuan, J.¬†Cheng, L.¬†Qiu, and D.¬†Yang, ‚ÄúBoosting scientific concepts understanding: Can analogy from teacher models empower student models?‚Äù 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:270558998" title="">https://api.semanticscholar.org/CorpusID:270558998</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
R.¬†Khanmohammadi, A.¬†I. Ghanem, K.¬†Verdecchia, R.¬†Hall, M.¬†Elshaikh, B.¬†Movsas, H.¬†Bagher-Ebadian, I.¬†Chetty, M.¬†M. Ghassemi, and K.¬†Thind, ‚ÄúIterative prompt refinement for radiation oncology symptom extraction using teacher-student large language models,‚Äù 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2402.04075" title="">https://arxiv.org/abs/2402.04075</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Y.¬†Ke, L.¬†Jin, K.¬†Elangovan, H.¬†R. Abdullah, N.¬†Liu, A.¬†T.¬†H. Sia, C.¬†R. Soh, J.¬†Y.¬†M. Tung, J.¬†C.¬†L. Ong, and D.¬†S.¬†W. Ting, ‚ÄúDevelopment and testing of retrieval augmented generation in large language models ‚Äì a case study report,‚Äù 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2402.01733" title="">https://arxiv.org/abs/2402.01733</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
D.¬†Hendrycks, C.¬†Burns, S.¬†Basart, A.¬†Zou, M.¬†Mazeika, D.¬†Song, and J.¬†Steinhardt, ‚ÄúMeasuring massive multitask language understanding,‚Äù 2021. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2009.03300" title="">https://arxiv.org/abs/2009.03300</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
C.¬†Zhou, P.¬†Liu, P.¬†Xu, S.¬†Iyer, J.¬†Sun, Y.¬†Mao, X.¬†Ma, A.¬†Efrat, P.¬†Yu, L.¬†YU, S.¬†Zhang, G.¬†Ghosh, M.¬†Lewis, L.¬†Zettlemoyer, and O.¬†Levy, ‚ÄúLima: Less is more for alignment,‚Äù in <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Advances in Neural Information Processing Systems</em>, A.¬†Oh, T.¬†Naumann, A.¬†Globerson, K.¬†Saenko, M.¬†Hardt, and S.¬†Levine, Eds., vol.¬†36.¬†¬†¬†Curran Associates, Inc., 2023, pp. 55‚Äâ006‚Äì55‚Äâ021. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/ac662d74829e4407ce1d126477f4a03a-Paper-Conference.pdf" title="">https://proceedings.neurips.cc/paper_files/paper/2023/file/ac662d74829e4407ce1d126477f4a03a-Paper-Conference.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
M.¬†Abdin, S.¬†A. Jacobs, A.¬†A. Awan, J.¬†Aneja, A.¬†Awadallah, H.¬†Awadalla, N.¬†Bach, A.¬†Bahree, A.¬†Bakhtiari, J.¬†Bao, H.¬†Behl, A.¬†Benhaim, M.¬†Bilenko, J.¬†Bjorck, S.¬†Bubeck, Q.¬†Cai, M.¬†Cai, C.¬†C.¬†T. Mendes, W.¬†Chen, V.¬†Chaudhary, D.¬†Chen, D.¬†Chen, Y.-C. Chen, Y.-L. Chen, P.¬†Chopra, X.¬†Dai, A.¬†D. Giorno, G.¬†de¬†Rosa, M.¬†Dixon, R.¬†Eldan, V.¬†Fragoso, D.¬†Iter, M.¬†Gao, M.¬†Gao, J.¬†Gao, A.¬†Garg, A.¬†Goswami, S.¬†Gunasekar, E.¬†Haider, J.¬†Hao, R.¬†J. Hewett, J.¬†Huynh, M.¬†Javaheripi, X.¬†Jin, P.¬†Kauffmann, N.¬†Karampatziakis, D.¬†Kim, M.¬†Khademi, L.¬†Kurilenko, J.¬†R. Lee, Y.¬†T. Lee, Y.¬†Li, Y.¬†Li, C.¬†Liang, L.¬†Liden, C.¬†Liu, M.¬†Liu, W.¬†Liu, E.¬†Lin, Z.¬†Lin, C.¬†Luo, P.¬†Madan, M.¬†Mazzola, A.¬†Mitra, H.¬†Modi, A.¬†Nguyen, B.¬†Norick, B.¬†Patra, D.¬†Perez-Becker, T.¬†Portet, R.¬†Pryzant, H.¬†Qin, M.¬†Radmilac, C.¬†Rosset, S.¬†Roy, O.¬†Ruwase, O.¬†Saarikivi, A.¬†Saied, A.¬†Salim, M.¬†Santacroce, S.¬†Shah, N.¬†Shang, H.¬†Sharma, S.¬†Shukla, X.¬†Song, M.¬†Tanaka, A.¬†Tupini, X.¬†Wang, L.¬†Wang, C.¬†Wang, Y.¬†Wang, R.¬†Ward, G.¬†Wang, P.¬†Witte, H.¬†Wu, M.¬†Wyatt, B.¬†Xiao,
C.¬†Xu, J.¬†Xu, W.¬†Xu, S.¬†Yadav, F.¬†Yang, J.¬†Yang, Z.¬†Yang, Y.¬†Yang, D.¬†Yu, L.¬†Yuan, C.¬†Zhang, C.¬†Zhang, J.¬†Zhang, L.¬†L. Zhang, Y.¬†Zhang, Y.¬†Zhang, Y.¬†Zhang, and X.¬†Zhou, ‚ÄúPhi-3 technical report: A highly capable language model locally on your phone,‚Äù 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2404.14219" title="">https://arxiv.org/abs/2404.14219</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
L.¬†Tunstall, E.¬†Beeching, N.¬†Lambert, N.¬†Rajani, K.¬†Rasul, Y.¬†Belkada, S.¬†Huang, L.¬†von Werra, C.¬†Fourrier, N.¬†Habib, N.¬†Sarrazin, O.¬†Sanseviero, A.¬†M. Rush, and T.¬†Wolf, ‚ÄúZephyr: Direct distillation of lm alignment,‚Äù 2023.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Aug  8 22:14:15 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
