<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2306.14123] Privacy and Fairness in Federated Learning: on the Perspective of Trade-off</title><meta property="og:description" content="Federated learning (FL) has been a hot topic in recent years. Ever since it was introduced, researchers have endeavored to devise FL systems that protect privacy or ensure fair results, with most research focusing on o…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Privacy and Fairness in Federated Learning: on the Perspective of Trade-off">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Privacy and Fairness in Federated Learning: on the Perspective of Trade-off">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2306.14123">

<!--Generated on Wed Feb 28 22:18:47 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Federated learning,  data privacy,  model fairness">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Privacy and Fairness in Federated Learning: on the Perspective of Trade-off</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Huiqiang Chen, Tianqing Zhu*, Tao Zhang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:huiqiang.chen,%20tao.zhang-3@student.uts.edu.au,%20tianqing.zhu@uts.edu.au">huiqiang.chen, tao.zhang-3@student.uts.edu.au, tianqing.zhu@uts.edu.au</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">University of Technology Sydney</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_streetaddress">PO Box 123 Broadway</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_city">Sydney</span><span id="id4.4.id4" class="ltx_text ltx_affiliation_state">NSW</span><span id="id5.5.id5" class="ltx_text ltx_affiliation_country">Australia</span><span id="id6.6.id6" class="ltx_text ltx_affiliation_postcode">2007</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Wanlei Zhou
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:wlzhou@cityu.edu.mo">wlzhou@cityu.edu.mo</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_affiliation_institution">City University of Macau</span><span id="id8.2.id2" class="ltx_text ltx_affiliation_streetaddress">Avenida Padre Tomás Pereira Taipa</span><span id="id9.3.id3" class="ltx_text ltx_affiliation_city">Macau</span><span id="id10.4.id4" class="ltx_text ltx_affiliation_country">China</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Philip S. Yu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:psyu@uic.edu">psyu@uic.edu</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id11.1.id1" class="ltx_text ltx_affiliation_institution">University of Illinois at Chicago</span><span id="id12.2.id2" class="ltx_text ltx_affiliation_streetaddress">851 S. Morgan St., Rm 1138 SEO, Chicago, IL 60607</span><span id="id13.3.id3" class="ltx_text ltx_affiliation_city">Chicago</span><span id="id14.4.id4" class="ltx_text ltx_affiliation_country">US</span>
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id15.id1" class="ltx_p">Federated learning (FL) has been a hot topic in recent years. Ever since it was introduced, researchers have endeavored to devise FL systems that protect privacy or ensure fair results, with most research focusing on one or the other. As two crucial ethical notions, the interactions between privacy and fairness are comparatively less studied. However, since privacy and fairness compete, considering each in isolation will inevitably come at the cost of the other. To provide a broad view of these two critical topics, we presented a detailed literature review of privacy and fairness issues, highlighting unique challenges posed by FL and solutions in federated settings. We further systematically surveyed different interactions between privacy and fairness, trying to reveal how privacy and fairness could affect each other and point out new research directions in fair and private FL.</p>
</div>
<div class="ltx_keywords">Federated learning, data privacy, model fairness
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>General and reference Surveys and overviews</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Machine learning</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Machine learning has changed our lives and will undoubtedly bring us more excitement. However, its success is closely tied to the availability of large-scale training data, and as new learning models keep emerging, the demand for more data persists relentlessly. One worrisome issue with collecting massive amounts of data is the risks that present to privacy. FL <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib130" title="" class="ltx_ref">2017</a>)</cite> has emerged as an attractive learning paradigm to meet privacy requirements.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Unlike traditional centralized machine learning, FL trains models in a distributed and parallel way such that different clients collectively train a model with their training data. This technique offers two enormous benefits. First, it saves companies the costly process of collecting large-scale data because the clients provide their local data. Second, it preserves the client’s privacy by keeping data locally. With such benefits, it is no surprise that the industry has already leaped to put FL into practice, such as Gboard <cite class="ltx_cite ltx_citemacro_citep">(Hard et al<span class="ltx_text">.</span>, <a href="#bib.bib73" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1. </span>Privacy and Fairness in FL</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">Great achievements have been made with FL. However, the paradigm of FL still suffers from ethical issues surrounding data use. One of those ethical issues is privacy. Although raw data never leave the device, the uploaded gradients/parameters still carry local information. Therefore, a trained model could hold the client’s data distribution. Consequently, an adversary can infer information about what data are included in the training set <cite class="ltx_cite ltx_citemacro_citep">(Hitaj
et al<span class="ltx_text">.</span>, <a href="#bib.bib76" title="" class="ltx_ref">2017</a>; Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib220" title="" class="ltx_ref">2020e</a>)</cite> or, even worse, reconstruct the training data <cite class="ltx_cite ltx_citemacro_citep">(Geiping et al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2020</a>)</cite>. As such, the research community is endeavoring to identify all potential privacy risks by launching different privacy attacks <cite class="ltx_cite ltx_citemacro_citep">(Nasr
et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2019</a>)</cite>. Accordingly, defenses for all these attacks are also being proposed to secure private data <cite class="ltx_cite ltx_citemacro_citep">(Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib191" title="" class="ltx_ref">2020a</a>)</cite>. This wargaming between attack and defense is leading us to more private FL environments.</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">Another ethical issue in FL is fairness, which refers to reducing the model’s bias towards disadvantaged groups, such as ethnic minorities, women, or the aged. Fairness in FL is defined at two different levels. The first pertains to <span id="S1.SS1.p2.1.1" class="ltx_text ltx_font_italic">algorithmic fairness</span> <cite class="ltx_cite ltx_citemacro_citep">(Mehrabi et al<span class="ltx_text">.</span>, <a href="#bib.bib132" title="" class="ltx_ref">2021</a>; Chouldechova and
Roth, <a href="#bib.bib32" title="" class="ltx_ref">2018</a>)</cite>, where model output should not skew towards disadvantaged groups defined by some sensitive attributes. The second pertains to <span id="S1.SS1.p2.1.2" class="ltx_text ltx_font_italic">client fairness</span> <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2019b</a>; Mohri
et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2019</a>)</cite>. In vanilla FL <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib130" title="" class="ltx_ref">2017</a>)</cite>, models trained on the larger dataset are given higher importance during aggregation. Hence, the global model will be optimized to capture the data distributions of clients with a larger dataset. Therefore the model performance will vary significantly among clients, which imposes unfairness at the client level.</p>
</div>
<div id="S1.SS1.p3" class="ltx_para">
<p id="S1.SS1.p3.1" class="ltx_p">Privacy and fairness are two crucial ethical notions, and violating either of them is unacceptable. However, to date, the research community has primarily considered these two issues separately, yet they are inextricably entwined. For example, it is well known that privacy comes at the cost of accuracy. What is surprising is that the cost is not consistent across all groups as expected, where disadvantaged groups often suffer more of an accuracy decrease than the other groups due to data scarcity <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2019</a>; Kuppam et al<span class="ltx_text">.</span>, <a href="#bib.bib106" title="" class="ltx_ref">2020</a>)</cite>. In other words, ensuring privacy can exacerbate the inequities between groups. Fairness, in turn, may negatively affect privacy. For example, to ensure a classification model is fair, the server usually needs to know the underlying distribution of the training dataset to eliminate bias existing in either the training data <cite class="ltx_cite ltx_citemacro_citep">(Feldman et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2015</a>; Kamiran and
Calders, <a href="#bib.bib93" title="" class="ltx_ref">2012</a>, <a href="#bib.bib92" title="" class="ltx_ref">2010</a>)</cite> or the model <cite class="ltx_cite ltx_citemacro_citep">(Zafar
et al<span class="ltx_text">.</span>, <a href="#bib.bib212" title="" class="ltx_ref">2017</a>; Goh
et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2016</a>; Zemel
et al<span class="ltx_text">.</span>, <a href="#bib.bib213" title="" class="ltx_ref">2013</a>)</cite>. This means the client will share more data with the server, increasing the privacy risk.</p>
</div>
<div id="S1.SS1.p4" class="ltx_para">
<p id="S1.SS1.p4.1" class="ltx_p">Therefore, in addition to reviewing privacy and fairness issues in FL, another motivation of this survey is to explore the possible interactions between privacy and fairness and to discuss the relationships between fairness and privacy. It is worth noting that the issue of client fairness adds an extra layer of complexity to the federated setting. To the best of our knowledge, this survey is the first attempt to examine the relationships between privacy and fairness in the federated setting.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Comparison to Related Surveys on Privacy or Fairness in FL</figcaption>
<table id="S1.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S1.T1.1.1.1" class="ltx_tr">
<td id="S1.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S1.T1.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Reference</span></td>
<td id="S1.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S1.T1.1.1.1.2.1" class="ltx_text" style="font-size:90%;">Privacy-preserving</span></td>
<td id="S1.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S1.T1.1.1.1.3.1" class="ltx_text" style="font-size:90%;">Fairness-aware</span></td>
<td id="S1.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S1.T1.1.1.1.4.1" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.1.1.1.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.1.1.1.4.1.1.1" class="ltx_tr">
<span id="S1.T1.1.1.1.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Interactions</span></span>
<span id="S1.T1.1.1.1.4.1.1.2" class="ltx_tr">
<span id="S1.T1.1.1.1.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">between privacy</span></span>
<span id="S1.T1.1.1.1.4.1.1.3" class="ltx_tr">
<span id="S1.T1.1.1.1.4.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">and fairness</span></span>
</span></span></td>
</tr>
<tr id="S1.T1.1.2.2" class="ltx_tr">
<td id="S1.T1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t">
<table id="S1.T1.1.2.2.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.1.2.2.1.1.1" class="ltx_tr">
<td id="S1.T1.1.2.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.1.2.2.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Privacy</span></td>
</tr>
<tr id="S1.T1.1.2.2.1.1.2" class="ltx_tr">
<td id="S1.T1.1.2.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.1.2.2.1.1.2.1.1" class="ltx_text" style="font-size:90%;">attack</span></td>
</tr>
</table>
</td>
<td id="S1.T1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.2.2.2.1" class="ltx_text" style="font-size:90%;">Defense</span></td>
<td id="S1.T1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">
<table id="S1.T1.1.2.2.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.1.2.2.3.1.1" class="ltx_tr">
<td id="S1.T1.1.2.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.1.2.2.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Algorithmic</span></td>
</tr>
<tr id="S1.T1.1.2.2.3.1.2" class="ltx_tr">
<td id="S1.T1.1.2.2.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.1.2.2.3.1.2.1.1" class="ltx_text" style="font-size:90%;">fairness</span></td>
</tr>
</table>
</td>
<td id="S1.T1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">
<table id="S1.T1.1.2.2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.1.2.2.4.1.1" class="ltx_tr">
<td id="S1.T1.1.2.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.1.2.2.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Client</span></td>
</tr>
<tr id="S1.T1.1.2.2.4.1.2" class="ltx_tr">
<td id="S1.T1.1.2.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.1.2.2.4.1.2.1.1" class="ltx_text" style="font-size:90%;">fairness</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S1.T1.1.3.3" class="ltx_tr">
<td id="S1.T1.1.3.3.1" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S1.T1.1.3.3.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Yang
et al<span class="ltx_text">.</span><span id="S1.T1.1.3.3.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib201" title="" class="ltx_ref">2019b</a><span id="S1.T1.1.3.3.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S1.T1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.3.3.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S1.T1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.3.3.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S1.T1.1.3.3.4" class="ltx_td ltx_border_t"></td>
<td id="S1.T1.1.3.3.5" class="ltx_td ltx_border_t"></td>
<td id="S1.T1.1.3.3.6" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S1.T1.1.4.4" class="ltx_tr">
<td id="S1.T1.1.4.4.1" class="ltx_td ltx_align_center"><cite class="ltx_cite ltx_citemacro_citep"><span id="S1.T1.1.4.4.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Yin et al<span class="ltx_text">.</span><span id="S1.T1.1.4.4.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib209" title="" class="ltx_ref">2021b</a><span id="S1.T1.1.4.4.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S1.T1.1.4.4.2" class="ltx_td ltx_align_center"><span id="S1.T1.1.4.4.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S1.T1.1.4.4.3" class="ltx_td ltx_align_center"><span id="S1.T1.1.4.4.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S1.T1.1.4.4.4" class="ltx_td"></td>
<td id="S1.T1.1.4.4.5" class="ltx_td"></td>
<td id="S1.T1.1.4.4.6" class="ltx_td"></td>
</tr>
<tr id="S1.T1.1.5.5" class="ltx_tr">
<td id="S1.T1.1.5.5.1" class="ltx_td ltx_align_center"><cite class="ltx_cite ltx_citemacro_citep"><span id="S1.T1.1.5.5.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Lyu et al<span class="ltx_text">.</span><span id="S1.T1.1.5.5.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib125" title="" class="ltx_ref">2020</a><span id="S1.T1.1.5.5.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S1.T1.1.5.5.2" class="ltx_td ltx_align_center"><span id="S1.T1.1.5.5.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S1.T1.1.5.5.3" class="ltx_td ltx_align_center"><span id="S1.T1.1.5.5.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S1.T1.1.5.5.4" class="ltx_td"></td>
<td id="S1.T1.1.5.5.5" class="ltx_td"></td>
<td id="S1.T1.1.5.5.6" class="ltx_td"></td>
</tr>
<tr id="S1.T1.1.6.6" class="ltx_tr">
<td id="S1.T1.1.6.6.1" class="ltx_td ltx_align_center"><cite class="ltx_cite ltx_citemacro_citep"><span id="S1.T1.1.6.6.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Kairouz
et al<span class="ltx_text">.</span><span id="S1.T1.1.6.6.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib90" title="" class="ltx_ref">2019</a><span id="S1.T1.1.6.6.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S1.T1.1.6.6.2" class="ltx_td ltx_align_center"><span id="S1.T1.1.6.6.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S1.T1.1.6.6.3" class="ltx_td ltx_align_center"><span id="S1.T1.1.6.6.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S1.T1.1.6.6.4" class="ltx_td ltx_align_center"><span id="S1.T1.1.6.6.4.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S1.T1.1.6.6.5" class="ltx_td ltx_align_center"><span id="S1.T1.1.6.6.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S1.T1.1.6.6.6" class="ltx_td"></td>
</tr>
<tr id="S1.T1.1.7.7" class="ltx_tr">
<td id="S1.T1.1.7.7.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.1.7.7.1.1" class="ltx_text" style="font-size:90%;">Our work</span></td>
<td id="S1.T1.1.7.7.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.1.7.7.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S1.T1.1.7.7.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.1.7.7.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S1.T1.1.7.7.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.1.7.7.4.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S1.T1.1.7.7.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.1.7.7.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S1.T1.1.7.7.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.1.7.7.6.1" class="ltx_text" style="font-size:90%;">✓</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2. </span>Main Contribution</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p">This survey provides a broad view of privacy and fairness issues in FL. We first illustrated that FL is not as private as it claimed to be. Adversarial clients and server have several new attack vectors at their disposal, and we outlined several techniques for preserving privacy against these attacks. Turning to fairness, we explained the two lines of fairness notions adopted in FL and the corresponding debiasing strategies. Lastly, we discussed interactions between privacy and fairness. Our contributions are as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">This is the first survey that provides a comprehensive overview of privacy, fairness, and the interactions between the two.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We present a detailed survey of privacy attacks and defenses in FL, discuss how these privacy attacks could damage privacy in FL and highlight the assumptions and principle methods of these attack strategies.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Following a rigorous enumeration of the sources of bias in the FL pipeline, we discuss the fairness notions adopted in FL and summarize fairness-aware FL approaches.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">We point out several future research directions toward training private and fair FL models.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Background Knowledge</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Definition of FL</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.8" class="ltx_p">The goal of FL is to train a global model in a distributed way. The objective function is formulated as:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.2" class="ltx_Math" alttext="\mathop{\min}\limits_{w}f\left(w\right)=\sum\limits_{k=1}^{m}{{p_{k}}{F_{k}}\left(w\right)}" display="block"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.3" xref="S2.E1.m1.2.3.cmml"><mrow id="S2.E1.m1.2.3.2" xref="S2.E1.m1.2.3.2.cmml"><munder id="S2.E1.m1.2.3.2.1" xref="S2.E1.m1.2.3.2.1.cmml"><mo movablelimits="false" id="S2.E1.m1.2.3.2.1.2" xref="S2.E1.m1.2.3.2.1.2.cmml">min</mo><mi id="S2.E1.m1.2.3.2.1.3" xref="S2.E1.m1.2.3.2.1.3.cmml">w</mi></munder><mrow id="S2.E1.m1.2.3.2.2" xref="S2.E1.m1.2.3.2.2.cmml"><mi id="S2.E1.m1.2.3.2.2.2" xref="S2.E1.m1.2.3.2.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.3.2.2.1" xref="S2.E1.m1.2.3.2.2.1.cmml">​</mo><mrow id="S2.E1.m1.2.3.2.2.3.2" xref="S2.E1.m1.2.3.2.2.cmml"><mo id="S2.E1.m1.2.3.2.2.3.2.1" xref="S2.E1.m1.2.3.2.2.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">w</mi><mo id="S2.E1.m1.2.3.2.2.3.2.2" xref="S2.E1.m1.2.3.2.2.cmml">)</mo></mrow></mrow></mrow><mo rspace="0.111em" id="S2.E1.m1.2.3.1" xref="S2.E1.m1.2.3.1.cmml">=</mo><mrow id="S2.E1.m1.2.3.3" xref="S2.E1.m1.2.3.3.cmml"><munderover id="S2.E1.m1.2.3.3.1" xref="S2.E1.m1.2.3.3.1.cmml"><mo movablelimits="false" id="S2.E1.m1.2.3.3.1.2.2" xref="S2.E1.m1.2.3.3.1.2.2.cmml">∑</mo><mrow id="S2.E1.m1.2.3.3.1.2.3" xref="S2.E1.m1.2.3.3.1.2.3.cmml"><mi id="S2.E1.m1.2.3.3.1.2.3.2" xref="S2.E1.m1.2.3.3.1.2.3.2.cmml">k</mi><mo id="S2.E1.m1.2.3.3.1.2.3.1" xref="S2.E1.m1.2.3.3.1.2.3.1.cmml">=</mo><mn id="S2.E1.m1.2.3.3.1.2.3.3" xref="S2.E1.m1.2.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.E1.m1.2.3.3.1.3" xref="S2.E1.m1.2.3.3.1.3.cmml">m</mi></munderover><mrow id="S2.E1.m1.2.3.3.2" xref="S2.E1.m1.2.3.3.2.cmml"><msub id="S2.E1.m1.2.3.3.2.2" xref="S2.E1.m1.2.3.3.2.2.cmml"><mi id="S2.E1.m1.2.3.3.2.2.2" xref="S2.E1.m1.2.3.3.2.2.2.cmml">p</mi><mi id="S2.E1.m1.2.3.3.2.2.3" xref="S2.E1.m1.2.3.3.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.3.3.2.1" xref="S2.E1.m1.2.3.3.2.1.cmml">​</mo><msub id="S2.E1.m1.2.3.3.2.3" xref="S2.E1.m1.2.3.3.2.3.cmml"><mi id="S2.E1.m1.2.3.3.2.3.2" xref="S2.E1.m1.2.3.3.2.3.2.cmml">F</mi><mi id="S2.E1.m1.2.3.3.2.3.3" xref="S2.E1.m1.2.3.3.2.3.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.3.3.2.1a" xref="S2.E1.m1.2.3.3.2.1.cmml">​</mo><mrow id="S2.E1.m1.2.3.3.2.4.2" xref="S2.E1.m1.2.3.3.2.cmml"><mo id="S2.E1.m1.2.3.3.2.4.2.1" xref="S2.E1.m1.2.3.3.2.cmml">(</mo><mi id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">w</mi><mo id="S2.E1.m1.2.3.3.2.4.2.2" xref="S2.E1.m1.2.3.3.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.3.cmml" xref="S2.E1.m1.2.3"><eq id="S2.E1.m1.2.3.1.cmml" xref="S2.E1.m1.2.3.1"></eq><apply id="S2.E1.m1.2.3.2.cmml" xref="S2.E1.m1.2.3.2"><apply id="S2.E1.m1.2.3.2.1.cmml" xref="S2.E1.m1.2.3.2.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.3.2.1.1.cmml" xref="S2.E1.m1.2.3.2.1">subscript</csymbol><min id="S2.E1.m1.2.3.2.1.2.cmml" xref="S2.E1.m1.2.3.2.1.2"></min><ci id="S2.E1.m1.2.3.2.1.3.cmml" xref="S2.E1.m1.2.3.2.1.3">𝑤</ci></apply><apply id="S2.E1.m1.2.3.2.2.cmml" xref="S2.E1.m1.2.3.2.2"><times id="S2.E1.m1.2.3.2.2.1.cmml" xref="S2.E1.m1.2.3.2.2.1"></times><ci id="S2.E1.m1.2.3.2.2.2.cmml" xref="S2.E1.m1.2.3.2.2.2">𝑓</ci><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">𝑤</ci></apply></apply><apply id="S2.E1.m1.2.3.3.cmml" xref="S2.E1.m1.2.3.3"><apply id="S2.E1.m1.2.3.3.1.cmml" xref="S2.E1.m1.2.3.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.3.3.1.1.cmml" xref="S2.E1.m1.2.3.3.1">superscript</csymbol><apply id="S2.E1.m1.2.3.3.1.2.cmml" xref="S2.E1.m1.2.3.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.3.3.1.2.1.cmml" xref="S2.E1.m1.2.3.3.1">subscript</csymbol><sum id="S2.E1.m1.2.3.3.1.2.2.cmml" xref="S2.E1.m1.2.3.3.1.2.2"></sum><apply id="S2.E1.m1.2.3.3.1.2.3.cmml" xref="S2.E1.m1.2.3.3.1.2.3"><eq id="S2.E1.m1.2.3.3.1.2.3.1.cmml" xref="S2.E1.m1.2.3.3.1.2.3.1"></eq><ci id="S2.E1.m1.2.3.3.1.2.3.2.cmml" xref="S2.E1.m1.2.3.3.1.2.3.2">𝑘</ci><cn type="integer" id="S2.E1.m1.2.3.3.1.2.3.3.cmml" xref="S2.E1.m1.2.3.3.1.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.2.3.3.1.3.cmml" xref="S2.E1.m1.2.3.3.1.3">𝑚</ci></apply><apply id="S2.E1.m1.2.3.3.2.cmml" xref="S2.E1.m1.2.3.3.2"><times id="S2.E1.m1.2.3.3.2.1.cmml" xref="S2.E1.m1.2.3.3.2.1"></times><apply id="S2.E1.m1.2.3.3.2.2.cmml" xref="S2.E1.m1.2.3.3.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.3.3.2.2.1.cmml" xref="S2.E1.m1.2.3.3.2.2">subscript</csymbol><ci id="S2.E1.m1.2.3.3.2.2.2.cmml" xref="S2.E1.m1.2.3.3.2.2.2">𝑝</ci><ci id="S2.E1.m1.2.3.3.2.2.3.cmml" xref="S2.E1.m1.2.3.3.2.2.3">𝑘</ci></apply><apply id="S2.E1.m1.2.3.3.2.3.cmml" xref="S2.E1.m1.2.3.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.3.3.2.3.1.cmml" xref="S2.E1.m1.2.3.3.2.3">subscript</csymbol><ci id="S2.E1.m1.2.3.3.2.3.2.cmml" xref="S2.E1.m1.2.3.3.2.3.2">𝐹</ci><ci id="S2.E1.m1.2.3.3.2.3.3.cmml" xref="S2.E1.m1.2.3.3.2.3.3">𝑘</ci></apply><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">𝑤</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">\mathop{\min}\limits_{w}f\left(w\right)=\sum\limits_{k=1}^{m}{{p_{k}}{F_{k}}\left(w\right)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.SS1.p1.7" class="ltx_p">where <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mi id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">m</annotation></semantics></math> is the number of clients, <math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="p_{k}&gt;0" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><mrow id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml"><msub id="S2.SS1.p1.2.m2.1.1.2" xref="S2.SS1.p1.2.m2.1.1.2.cmml"><mi id="S2.SS1.p1.2.m2.1.1.2.2" xref="S2.SS1.p1.2.m2.1.1.2.2.cmml">p</mi><mi id="S2.SS1.p1.2.m2.1.1.2.3" xref="S2.SS1.p1.2.m2.1.1.2.3.cmml">k</mi></msub><mo id="S2.SS1.p1.2.m2.1.1.1" xref="S2.SS1.p1.2.m2.1.1.1.cmml">&gt;</mo><mn id="S2.SS1.p1.2.m2.1.1.3" xref="S2.SS1.p1.2.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><apply id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1"><gt id="S2.SS1.p1.2.m2.1.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1.1"></gt><apply id="S2.SS1.p1.2.m2.1.1.2.cmml" xref="S2.SS1.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.1.1.2.1.cmml" xref="S2.SS1.p1.2.m2.1.1.2">subscript</csymbol><ci id="S2.SS1.p1.2.m2.1.1.2.2.cmml" xref="S2.SS1.p1.2.m2.1.1.2.2">𝑝</ci><ci id="S2.SS1.p1.2.m2.1.1.2.3.cmml" xref="S2.SS1.p1.2.m2.1.1.2.3">𝑘</ci></apply><cn type="integer" id="S2.SS1.p1.2.m2.1.1.3.cmml" xref="S2.SS1.p1.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">p_{k}&gt;0</annotation></semantics></math> is the aggregating weight of client <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><mi id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">k</annotation></semantics></math>, satisfying <math id="S2.SS1.p1.4.m4.1" class="ltx_Math" alttext="\sum_{k}p_{k}=1" display="inline"><semantics id="S2.SS1.p1.4.m4.1a"><mrow id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml"><mrow id="S2.SS1.p1.4.m4.1.1.2" xref="S2.SS1.p1.4.m4.1.1.2.cmml"><msub id="S2.SS1.p1.4.m4.1.1.2.1" xref="S2.SS1.p1.4.m4.1.1.2.1.cmml"><mo id="S2.SS1.p1.4.m4.1.1.2.1.2" xref="S2.SS1.p1.4.m4.1.1.2.1.2.cmml">∑</mo><mi id="S2.SS1.p1.4.m4.1.1.2.1.3" xref="S2.SS1.p1.4.m4.1.1.2.1.3.cmml">k</mi></msub><msub id="S2.SS1.p1.4.m4.1.1.2.2" xref="S2.SS1.p1.4.m4.1.1.2.2.cmml"><mi id="S2.SS1.p1.4.m4.1.1.2.2.2" xref="S2.SS1.p1.4.m4.1.1.2.2.2.cmml">p</mi><mi id="S2.SS1.p1.4.m4.1.1.2.2.3" xref="S2.SS1.p1.4.m4.1.1.2.2.3.cmml">k</mi></msub></mrow><mo id="S2.SS1.p1.4.m4.1.1.1" xref="S2.SS1.p1.4.m4.1.1.1.cmml">=</mo><mn id="S2.SS1.p1.4.m4.1.1.3" xref="S2.SS1.p1.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><apply id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1"><eq id="S2.SS1.p1.4.m4.1.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1.1"></eq><apply id="S2.SS1.p1.4.m4.1.1.2.cmml" xref="S2.SS1.p1.4.m4.1.1.2"><apply id="S2.SS1.p1.4.m4.1.1.2.1.cmml" xref="S2.SS1.p1.4.m4.1.1.2.1"><csymbol cd="ambiguous" id="S2.SS1.p1.4.m4.1.1.2.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1.2.1">subscript</csymbol><sum id="S2.SS1.p1.4.m4.1.1.2.1.2.cmml" xref="S2.SS1.p1.4.m4.1.1.2.1.2"></sum><ci id="S2.SS1.p1.4.m4.1.1.2.1.3.cmml" xref="S2.SS1.p1.4.m4.1.1.2.1.3">𝑘</ci></apply><apply id="S2.SS1.p1.4.m4.1.1.2.2.cmml" xref="S2.SS1.p1.4.m4.1.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.4.m4.1.1.2.2.1.cmml" xref="S2.SS1.p1.4.m4.1.1.2.2">subscript</csymbol><ci id="S2.SS1.p1.4.m4.1.1.2.2.2.cmml" xref="S2.SS1.p1.4.m4.1.1.2.2.2">𝑝</ci><ci id="S2.SS1.p1.4.m4.1.1.2.2.3.cmml" xref="S2.SS1.p1.4.m4.1.1.2.2.3">𝑘</ci></apply></apply><cn type="integer" id="S2.SS1.p1.4.m4.1.1.3.cmml" xref="S2.SS1.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">\sum_{k}p_{k}=1</annotation></semantics></math>. <math id="S2.SS1.p1.5.m5.1" class="ltx_Math" alttext="F_{k}(w)" display="inline"><semantics id="S2.SS1.p1.5.m5.1a"><mrow id="S2.SS1.p1.5.m5.1.2" xref="S2.SS1.p1.5.m5.1.2.cmml"><msub id="S2.SS1.p1.5.m5.1.2.2" xref="S2.SS1.p1.5.m5.1.2.2.cmml"><mi id="S2.SS1.p1.5.m5.1.2.2.2" xref="S2.SS1.p1.5.m5.1.2.2.2.cmml">F</mi><mi id="S2.SS1.p1.5.m5.1.2.2.3" xref="S2.SS1.p1.5.m5.1.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p1.5.m5.1.2.1" xref="S2.SS1.p1.5.m5.1.2.1.cmml">​</mo><mrow id="S2.SS1.p1.5.m5.1.2.3.2" xref="S2.SS1.p1.5.m5.1.2.cmml"><mo stretchy="false" id="S2.SS1.p1.5.m5.1.2.3.2.1" xref="S2.SS1.p1.5.m5.1.2.cmml">(</mo><mi id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml">w</mi><mo stretchy="false" id="S2.SS1.p1.5.m5.1.2.3.2.2" xref="S2.SS1.p1.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><apply id="S2.SS1.p1.5.m5.1.2.cmml" xref="S2.SS1.p1.5.m5.1.2"><times id="S2.SS1.p1.5.m5.1.2.1.cmml" xref="S2.SS1.p1.5.m5.1.2.1"></times><apply id="S2.SS1.p1.5.m5.1.2.2.cmml" xref="S2.SS1.p1.5.m5.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.1.2.2.1.cmml" xref="S2.SS1.p1.5.m5.1.2.2">subscript</csymbol><ci id="S2.SS1.p1.5.m5.1.2.2.2.cmml" xref="S2.SS1.p1.5.m5.1.2.2.2">𝐹</ci><ci id="S2.SS1.p1.5.m5.1.2.2.3.cmml" xref="S2.SS1.p1.5.m5.1.2.2.3">𝑘</ci></apply><ci id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">F_{k}(w)</annotation></semantics></math> is the empirical risk on client <math id="S2.SS1.p1.6.m6.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS1.p1.6.m6.1a"><mi id="S2.SS1.p1.6.m6.1.1" xref="S2.SS1.p1.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.1b"><ci id="S2.SS1.p1.6.m6.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.1c">k</annotation></semantics></math>’s data. In a trivial setting, <math id="S2.SS1.p1.7.m7.1" class="ltx_Math" alttext="p_{k}" display="inline"><semantics id="S2.SS1.p1.7.m7.1a"><msub id="S2.SS1.p1.7.m7.1.1" xref="S2.SS1.p1.7.m7.1.1.cmml"><mi id="S2.SS1.p1.7.m7.1.1.2" xref="S2.SS1.p1.7.m7.1.1.2.cmml">p</mi><mi id="S2.SS1.p1.7.m7.1.1.3" xref="S2.SS1.p1.7.m7.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m7.1b"><apply id="S2.SS1.p1.7.m7.1.1.cmml" xref="S2.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.1.1.1.cmml" xref="S2.SS1.p1.7.m7.1.1">subscript</csymbol><ci id="S2.SS1.p1.7.m7.1.1.2.cmml" xref="S2.SS1.p1.7.m7.1.1.2">𝑝</ci><ci id="S2.SS1.p1.7.m7.1.1.3.cmml" xref="S2.SS1.p1.7.m7.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m7.1c">p_{k}</annotation></semantics></math> is the ratio of local samples to total samples of all clients. The process of FL consists of two stages: the training and inference stages. Three actors are involved: 1) clients, each of which has a local dataset and will use it to contribute to the global model’s training by uploading local gradients/parameters, noting that each client’s dataset may vary from the others; 2) a server that coordinates the learning process; and 3) users, who will use the final well-trained model.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">In each iteration of FL, selected clients download the global model and perform learning algorithms locally. They communicate their updates to the server for aggregation and model updating. This interaction between clients and the server repeats until the model converges. At the inference stage, a well-trained model is deployed to users, where users can infer the model via black-box access. This step is no different from a traditional data center approach.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Privacy Disclosure in FL</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Recent research verified the privacy risk of FL. Adversaries can glean the participants’ training data. For example, Zhu et al. <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib232" title="" class="ltx_ref">2019</a>)</cite> fully reconstructed training data from the victim client through the uploaded gradients as shown in Fig.<a href="#S2.F1.sf1" title="In Figure 1 ‣ 2.2. Privacy Disclosure in FL ‣ 2. Background Knowledge ‣ Privacy and Fairness in Federated Learning: on the Perspective of Trade-off" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a>. In the course of the FL pipeline, several attack interfaces exist for an adversary, who could be the server or a client in FL. The attack could occur during the training or inference stage, within or outside the FL. The attack targets include membership, property, class representative, and the raw data <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib209" title="" class="ltx_ref">2021b</a>)</cite>.</p>
</div>
<figure id="S2.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S2.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.14123/assets/Reconstruction_Attack.png" id="S2.F1.sf1.g1" class="ltx_graphics ltx_img_landscape" width="689" height="444" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.sf1.4.2.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S2.F1.sf1.2.1" class="ltx_text" style="font-size:80%;">Overview of reconstruction attack in FL. An adversary iterative optimizes generated sample by matching gradients <math id="S2.F1.sf1.2.1.m1.1" class="ltx_Math" alttext="\nabla W" display="inline"><semantics id="S2.F1.sf1.2.1.m1.1b"><mrow id="S2.F1.sf1.2.1.m1.1.1" xref="S2.F1.sf1.2.1.m1.1.1.cmml"><mo rspace="0.167em" id="S2.F1.sf1.2.1.m1.1.1.1" xref="S2.F1.sf1.2.1.m1.1.1.1.cmml">∇</mo><mi id="S2.F1.sf1.2.1.m1.1.1.2" xref="S2.F1.sf1.2.1.m1.1.1.2.cmml">W</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.F1.sf1.2.1.m1.1c"><apply id="S2.F1.sf1.2.1.m1.1.1.cmml" xref="S2.F1.sf1.2.1.m1.1.1"><ci id="S2.F1.sf1.2.1.m1.1.1.1.cmml" xref="S2.F1.sf1.2.1.m1.1.1.1">∇</ci><ci id="S2.F1.sf1.2.1.m1.1.1.2.cmml" xref="S2.F1.sf1.2.1.m1.1.1.2">𝑊</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.sf1.2.1.m1.1d">\nabla W</annotation></semantics></math>.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S2.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.14123/assets/DLG_Attack_Result.png" id="S2.F1.sf2.g1" class="ltx_graphics ltx_img_landscape" width="391" height="227" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S2.F1.sf2.3.2" class="ltx_text" style="font-size:80%;">Attack results on MNIST, CIFAR-100, SVHN and LFW. The adversary is able to reconstruct the private images of other clients truthfully (reproduced from <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib232" title="" class="ltx_ref">2019</a>)</cite>).</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Reconstruction attack in FL.</figcaption>
</figure>
<section id="S2.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.1. </span>Membership Inference Attacks</h4>

<div id="S2.SS2.SSS1.p1" class="ltx_para">
<p id="S2.SS2.SSS1.p1.5" class="ltx_p">Membership Inference Attacks (MIA) aim to identify whether a given sample was used to train the target model. These types of attacks can pose privacy risks to individuals. For example, confirming a patient’s clinical record was used to train a model associated with a particular disease would reveal that patient’s health condition. MIA was initially investigated by Shokri et al. <cite class="ltx_cite ltx_citemacro_citep">(Shokri
et al<span class="ltx_text">.</span>, <a href="#bib.bib167" title="" class="ltx_ref">2017</a>)</cite>. The attack models are essentially binary classifiers. Given an instance <math id="S2.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\boldsymbol{X}" display="inline"><semantics id="S2.SS2.SSS1.p1.1.m1.1a"><mi id="S2.SS2.SSS1.p1.1.m1.1.1" xref="S2.SS2.SSS1.p1.1.m1.1.1.cmml">𝑿</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.1.m1.1b"><ci id="S2.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1">𝑿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.1.m1.1c">\boldsymbol{X}</annotation></semantics></math> and a target model <math id="S2.SS2.SSS1.p1.2.m2.1" class="ltx_Math" alttext="F_{t}" display="inline"><semantics id="S2.SS2.SSS1.p1.2.m2.1a"><msub id="S2.SS2.SSS1.p1.2.m2.1.1" xref="S2.SS2.SSS1.p1.2.m2.1.1.cmml"><mi id="S2.SS2.SSS1.p1.2.m2.1.1.2" xref="S2.SS2.SSS1.p1.2.m2.1.1.2.cmml">F</mi><mi id="S2.SS2.SSS1.p1.2.m2.1.1.3" xref="S2.SS2.SSS1.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.2.m2.1b"><apply id="S2.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p1.2.m2.1.1.1.cmml" xref="S2.SS2.SSS1.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS2.SSS1.p1.2.m2.1.1.2.cmml" xref="S2.SS2.SSS1.p1.2.m2.1.1.2">𝐹</ci><ci id="S2.SS2.SSS1.p1.2.m2.1.1.3.cmml" xref="S2.SS2.SSS1.p1.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.2.m2.1c">F_{t}</annotation></semantics></math>, the goal of the MIA model is to identify whether or not <math id="S2.SS2.SSS1.p1.3.m3.1" class="ltx_Math" alttext="\boldsymbol{X}" display="inline"><semantics id="S2.SS2.SSS1.p1.3.m3.1a"><mi id="S2.SS2.SSS1.p1.3.m3.1.1" xref="S2.SS2.SSS1.p1.3.m3.1.1.cmml">𝑿</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.3.m3.1b"><ci id="S2.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS1.p1.3.m3.1.1">𝑿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.3.m3.1c">\boldsymbol{X}</annotation></semantics></math> is contained within the training dataset <math id="S2.SS2.SSS1.p1.4.m4.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.SS2.SSS1.p1.4.m4.1a"><mi id="S2.SS2.SSS1.p1.4.m4.1.1" xref="S2.SS2.SSS1.p1.4.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.4.m4.1b"><ci id="S2.SS2.SSS1.p1.4.m4.1.1.cmml" xref="S2.SS2.SSS1.p1.4.m4.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.4.m4.1c">D</annotation></semantics></math> of the target model <math id="S2.SS2.SSS1.p1.5.m5.1" class="ltx_Math" alttext="F_{t}" display="inline"><semantics id="S2.SS2.SSS1.p1.5.m5.1a"><msub id="S2.SS2.SSS1.p1.5.m5.1.1" xref="S2.SS2.SSS1.p1.5.m5.1.1.cmml"><mi id="S2.SS2.SSS1.p1.5.m5.1.1.2" xref="S2.SS2.SSS1.p1.5.m5.1.1.2.cmml">F</mi><mi id="S2.SS2.SSS1.p1.5.m5.1.1.3" xref="S2.SS2.SSS1.p1.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.5.m5.1b"><apply id="S2.SS2.SSS1.p1.5.m5.1.1.cmml" xref="S2.SS2.SSS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p1.5.m5.1.1.1.cmml" xref="S2.SS2.SSS1.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS2.SSS1.p1.5.m5.1.1.2.cmml" xref="S2.SS2.SSS1.p1.5.m5.1.1.2">𝐹</ci><ci id="S2.SS2.SSS1.p1.5.m5.1.1.3.cmml" xref="S2.SS2.SSS1.p1.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.5.m5.1c">F_{t}</annotation></semantics></math>.</p>
</div>
</section>
<section id="S2.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.2. </span>Property Inference Attacks</h4>

<div id="S2.SS2.SSS2.p1" class="ltx_para">
<p id="S2.SS2.SSS2.p1.1" class="ltx_p">Property inference attacks aim to recover some property of the training set, which may be irrelevant to the main tasks. Such as the property of ”wearing glasses” against a gender classifier or the composition of the training dataset. This kind of attack also leads to privacy issues. With proper prior knowledge, the adversary can infer the presence of a specific sample in the training set.</p>
</div>
</section>
<section id="S2.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.3. </span>Model Inversion Attacks</h4>

<div id="S2.SS2.SSS3.p1" class="ltx_para">
<p id="S2.SS2.SSS3.p1.1" class="ltx_p">Model inversion attacks aim to recover class-specific features or construct class representatives by accessing the target model and other possible auxiliary information. The recovered data is a representing sample (usually a synthetic sample) that only reflects some aspects of the training data and is not a member of the training set.</p>
</div>
</section>
<section id="S2.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.4. </span>Reconstruction Attacks</h4>

<div id="S2.SS2.SSS4.p1" class="ltx_para">
<p id="S2.SS2.SSS4.p1.1" class="ltx_p">Reconstruction attacks <cite class="ltx_cite ltx_citemacro_citep">(Dinur and Nissim, <a href="#bib.bib40" title="" class="ltx_ref">2003</a>)</cite> aim to reconstruct a probabilistic version of samples in the training set. Success in a reconstruction attack is measured by comparing the reconstruction with the original data. If the two are similar, the attack has been successful. Fig.<a href="#S2.F1.sf2" title="In Figure 1 ‣ 2.2. Privacy Disclosure in FL ‣ 2. Background Knowledge ‣ Privacy and Fairness in Federated Learning: on the Perspective of Trade-off" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a> <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib232" title="" class="ltx_ref">2019</a>)</cite> shows an example. Unlike the model inversion attacks, the recovered data here is almost the same as the training dataset at the pixel level and belongs to the training dataset.</p>
</div>
</section>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Privacy-preserving Techniques</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">In the realm of FL, plenty of studies have shown how to break the basic privacy assurances, such as determining a client’s membership in the training set <cite class="ltx_cite ltx_citemacro_citep">(Nasr
et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2019</a>)</cite>, ascertaining the class representations of the client’s training data <cite class="ltx_cite ltx_citemacro_citep">(Hitaj
et al<span class="ltx_text">.</span>, <a href="#bib.bib76" title="" class="ltx_ref">2017</a>; Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib190" title="" class="ltx_ref">2019a</a>; Song et al<span class="ltx_text">.</span>, <a href="#bib.bib172" title="" class="ltx_ref">2020</a>)</cite>, and, the worst case of all, procuring the raw training data <cite class="ltx_cite ltx_citemacro_citep">(Geiping et al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2020</a>)</cite>. Several privacy-preserving techniques can help stop these privacy leakages, including cryptographic techniques and the perturbation approach.</p>
</div>
<section id="S2.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1. </span>Cryptographic Approach</h4>

<div id="S2.SS3.SSS1.p1" class="ltx_para">
<p id="S2.SS3.SSS1.p1.1" class="ltx_p">Secure computation is a cryptographic technique in which functions are evaluated based on a set of distributed inputs without revealing additional information, e.g., the parties’ inputs or intermediate results. Secure multi-party computation, homomorphic encryption, and secret sharing are the most common choices for a secure computing platform.</p>
</div>
<div id="S2.SS3.SSS1.p2" class="ltx_para">
<p id="S2.SS3.SSS1.p2.6" class="ltx_p">Multi-party computation <cite class="ltx_cite ltx_citemacro_citep">(Yao, <a href="#bib.bib205" title="" class="ltx_ref">1982</a>)</cite> was first introduced to secure the private inputs of multiple participants while they jointly compute an agreed-upon model or function. Formally, <math id="S2.SS3.SSS1.p2.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.SS3.SSS1.p2.1.m1.1a"><mi id="S2.SS3.SSS1.p2.1.m1.1.1" xref="S2.SS3.SSS1.p2.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS1.p2.1.m1.1b"><ci id="S2.SS3.SSS1.p2.1.m1.1.1.cmml" xref="S2.SS3.SSS1.p2.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS1.p2.1.m1.1c">n</annotation></semantics></math> participants <math id="S2.SS3.SSS1.p2.2.m2.3" class="ltx_Math" alttext="p_{1},p_{2},…" display="inline"><semantics id="S2.SS3.SSS1.p2.2.m2.3a"><mrow id="S2.SS3.SSS1.p2.2.m2.3.3.2" xref="S2.SS3.SSS1.p2.2.m2.3.3.3.cmml"><msub id="S2.SS3.SSS1.p2.2.m2.2.2.1.1" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.cmml"><mi id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.2" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.2.cmml">p</mi><mn id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.3" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S2.SS3.SSS1.p2.2.m2.3.3.2.3" xref="S2.SS3.SSS1.p2.2.m2.3.3.3.cmml">,</mo><msub id="S2.SS3.SSS1.p2.2.m2.3.3.2.2" xref="S2.SS3.SSS1.p2.2.m2.3.3.2.2.cmml"><mi id="S2.SS3.SSS1.p2.2.m2.3.3.2.2.2" xref="S2.SS3.SSS1.p2.2.m2.3.3.2.2.2.cmml">p</mi><mn id="S2.SS3.SSS1.p2.2.m2.3.3.2.2.3" xref="S2.SS3.SSS1.p2.2.m2.3.3.2.2.3.cmml">2</mn></msub><mo id="S2.SS3.SSS1.p2.2.m2.3.3.2.4" xref="S2.SS3.SSS1.p2.2.m2.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S2.SS3.SSS1.p2.2.m2.1.1" xref="S2.SS3.SSS1.p2.2.m2.1.1.cmml">…</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS1.p2.2.m2.3b"><list id="S2.SS3.SSS1.p2.2.m2.3.3.3.cmml" xref="S2.SS3.SSS1.p2.2.m2.3.3.2"><apply id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.1.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1">subscript</csymbol><ci id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.2.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.2">𝑝</ci><cn type="integer" id="S2.SS3.SSS1.p2.2.m2.2.2.1.1.3.cmml" xref="S2.SS3.SSS1.p2.2.m2.2.2.1.1.3">1</cn></apply><apply id="S2.SS3.SSS1.p2.2.m2.3.3.2.2.cmml" xref="S2.SS3.SSS1.p2.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS3.SSS1.p2.2.m2.3.3.2.2.1.cmml" xref="S2.SS3.SSS1.p2.2.m2.3.3.2.2">subscript</csymbol><ci id="S2.SS3.SSS1.p2.2.m2.3.3.2.2.2.cmml" xref="S2.SS3.SSS1.p2.2.m2.3.3.2.2.2">𝑝</ci><cn type="integer" id="S2.SS3.SSS1.p2.2.m2.3.3.2.2.3.cmml" xref="S2.SS3.SSS1.p2.2.m2.3.3.2.2.3">2</cn></apply><ci id="S2.SS3.SSS1.p2.2.m2.1.1.cmml" xref="S2.SS3.SSS1.p2.2.m2.1.1">…</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS1.p2.2.m2.3c">p_{1},p_{2},…</annotation></semantics></math>, and <math id="S2.SS3.SSS1.p2.3.m3.1" class="ltx_Math" alttext="p_{n}" display="inline"><semantics id="S2.SS3.SSS1.p2.3.m3.1a"><msub id="S2.SS3.SSS1.p2.3.m3.1.1" xref="S2.SS3.SSS1.p2.3.m3.1.1.cmml"><mi id="S2.SS3.SSS1.p2.3.m3.1.1.2" xref="S2.SS3.SSS1.p2.3.m3.1.1.2.cmml">p</mi><mi id="S2.SS3.SSS1.p2.3.m3.1.1.3" xref="S2.SS3.SSS1.p2.3.m3.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS1.p2.3.m3.1b"><apply id="S2.SS3.SSS1.p2.3.m3.1.1.cmml" xref="S2.SS3.SSS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS1.p2.3.m3.1.1.1.cmml" xref="S2.SS3.SSS1.p2.3.m3.1.1">subscript</csymbol><ci id="S2.SS3.SSS1.p2.3.m3.1.1.2.cmml" xref="S2.SS3.SSS1.p2.3.m3.1.1.2">𝑝</ci><ci id="S2.SS3.SSS1.p2.3.m3.1.1.3.cmml" xref="S2.SS3.SSS1.p2.3.m3.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS1.p2.3.m3.1c">p_{n}</annotation></semantics></math> can collaboratively compute <math id="S2.SS3.SSS1.p2.4.m4.3" class="ltx_Math" alttext="y=f\left(x_{1},…,x_{n}\right)" display="inline"><semantics id="S2.SS3.SSS1.p2.4.m4.3a"><mrow id="S2.SS3.SSS1.p2.4.m4.3.3" xref="S2.SS3.SSS1.p2.4.m4.3.3.cmml"><mi id="S2.SS3.SSS1.p2.4.m4.3.3.4" xref="S2.SS3.SSS1.p2.4.m4.3.3.4.cmml">y</mi><mo id="S2.SS3.SSS1.p2.4.m4.3.3.3" xref="S2.SS3.SSS1.p2.4.m4.3.3.3.cmml">=</mo><mrow id="S2.SS3.SSS1.p2.4.m4.3.3.2" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.cmml"><mi id="S2.SS3.SSS1.p2.4.m4.3.3.2.4" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS1.p2.4.m4.3.3.2.3" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.3.cmml">​</mo><mrow id="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.2.3.cmml"><mo id="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.3" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.2.3.cmml">(</mo><msub id="S2.SS3.SSS1.p2.4.m4.2.2.1.1.1.1" xref="S2.SS3.SSS1.p2.4.m4.2.2.1.1.1.1.cmml"><mi id="S2.SS3.SSS1.p2.4.m4.2.2.1.1.1.1.2" xref="S2.SS3.SSS1.p2.4.m4.2.2.1.1.1.1.2.cmml">x</mi><mn id="S2.SS3.SSS1.p2.4.m4.2.2.1.1.1.1.3" xref="S2.SS3.SSS1.p2.4.m4.2.2.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.4" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.2.3.cmml">,</mo><mi mathvariant="normal" id="S2.SS3.SSS1.p2.4.m4.1.1" xref="S2.SS3.SSS1.p2.4.m4.1.1.cmml">…</mi><mo id="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.5" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.2.3.cmml">,</mo><msub id="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.2" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.2.cmml"><mi id="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.2.2" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.2.2.cmml">x</mi><mi id="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.2.3" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.2.3.cmml">n</mi></msub><mo id="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.6" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS1.p2.4.m4.3b"><apply id="S2.SS3.SSS1.p2.4.m4.3.3.cmml" xref="S2.SS3.SSS1.p2.4.m4.3.3"><eq id="S2.SS3.SSS1.p2.4.m4.3.3.3.cmml" xref="S2.SS3.SSS1.p2.4.m4.3.3.3"></eq><ci id="S2.SS3.SSS1.p2.4.m4.3.3.4.cmml" xref="S2.SS3.SSS1.p2.4.m4.3.3.4">𝑦</ci><apply id="S2.SS3.SSS1.p2.4.m4.3.3.2.cmml" xref="S2.SS3.SSS1.p2.4.m4.3.3.2"><times id="S2.SS3.SSS1.p2.4.m4.3.3.2.3.cmml" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.3"></times><ci id="S2.SS3.SSS1.p2.4.m4.3.3.2.4.cmml" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.4">𝑓</ci><vector id="S2.SS3.SSS1.p2.4.m4.3.3.2.2.3.cmml" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2"><apply id="S2.SS3.SSS1.p2.4.m4.2.2.1.1.1.1.cmml" xref="S2.SS3.SSS1.p2.4.m4.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS1.p2.4.m4.2.2.1.1.1.1.1.cmml" xref="S2.SS3.SSS1.p2.4.m4.2.2.1.1.1.1">subscript</csymbol><ci id="S2.SS3.SSS1.p2.4.m4.2.2.1.1.1.1.2.cmml" xref="S2.SS3.SSS1.p2.4.m4.2.2.1.1.1.1.2">𝑥</ci><cn type="integer" id="S2.SS3.SSS1.p2.4.m4.2.2.1.1.1.1.3.cmml" xref="S2.SS3.SSS1.p2.4.m4.2.2.1.1.1.1.3">1</cn></apply><ci id="S2.SS3.SSS1.p2.4.m4.1.1.cmml" xref="S2.SS3.SSS1.p2.4.m4.1.1">…</ci><apply id="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.2.cmml" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.2.1.cmml" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.2">subscript</csymbol><ci id="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.2.2.cmml" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.2.2">𝑥</ci><ci id="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.2.3.cmml" xref="S2.SS3.SSS1.p2.4.m4.3.3.2.2.2.2.3">𝑛</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS1.p2.4.m4.3c">y=f\left(x_{1},…,x_{n}\right)</annotation></semantics></math>, where <math id="S2.SS3.SSS1.p2.5.m5.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S2.SS3.SSS1.p2.5.m5.1a"><msub id="S2.SS3.SSS1.p2.5.m5.1.1" xref="S2.SS3.SSS1.p2.5.m5.1.1.cmml"><mi id="S2.SS3.SSS1.p2.5.m5.1.1.2" xref="S2.SS3.SSS1.p2.5.m5.1.1.2.cmml">x</mi><mi id="S2.SS3.SSS1.p2.5.m5.1.1.3" xref="S2.SS3.SSS1.p2.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS1.p2.5.m5.1b"><apply id="S2.SS3.SSS1.p2.5.m5.1.1.cmml" xref="S2.SS3.SSS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS1.p2.5.m5.1.1.1.cmml" xref="S2.SS3.SSS1.p2.5.m5.1.1">subscript</csymbol><ci id="S2.SS3.SSS1.p2.5.m5.1.1.2.cmml" xref="S2.SS3.SSS1.p2.5.m5.1.1.2">𝑥</ci><ci id="S2.SS3.SSS1.p2.5.m5.1.1.3.cmml" xref="S2.SS3.SSS1.p2.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS1.p2.5.m5.1c">x_{i}</annotation></semantics></math> is a secret input that belongs to participants <math id="S2.SS3.SSS1.p2.6.m6.1" class="ltx_Math" alttext="p_{i}" display="inline"><semantics id="S2.SS3.SSS1.p2.6.m6.1a"><msub id="S2.SS3.SSS1.p2.6.m6.1.1" xref="S2.SS3.SSS1.p2.6.m6.1.1.cmml"><mi id="S2.SS3.SSS1.p2.6.m6.1.1.2" xref="S2.SS3.SSS1.p2.6.m6.1.1.2.cmml">p</mi><mi id="S2.SS3.SSS1.p2.6.m6.1.1.3" xref="S2.SS3.SSS1.p2.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS1.p2.6.m6.1b"><apply id="S2.SS3.SSS1.p2.6.m6.1.1.cmml" xref="S2.SS3.SSS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS1.p2.6.m6.1.1.1.cmml" xref="S2.SS3.SSS1.p2.6.m6.1.1">subscript</csymbol><ci id="S2.SS3.SSS1.p2.6.m6.1.1.2.cmml" xref="S2.SS3.SSS1.p2.6.m6.1.1.2">𝑝</ci><ci id="S2.SS3.SSS1.p2.6.m6.1.1.3.cmml" xref="S2.SS3.SSS1.p2.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS1.p2.6.m6.1c">p_{i}</annotation></semantics></math>, This form of secure computing offers both correctness and privacy. After all, no participant learns anything about the others’ data other than the final result.</p>
</div>
<div id="S2.SS3.SSS1.p3" class="ltx_para">
<p id="S2.SS3.SSS1.p3.1" class="ltx_p">Homomorphic encryption <cite class="ltx_cite ltx_citemacro_citep">(Yi
et al<span class="ltx_text">.</span>, <a href="#bib.bib207" title="" class="ltx_ref">2014</a>)</cite> allows certain mathematical operations, such as addition and multiplication, to be performed directly on ciphertexts. These can then be used as the basis for more complex arbitrary functions.</p>
</div>
</section>
<section id="S2.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.2. </span>Perturbation Approach</h4>

<div id="S2.SS3.SSS2.p1" class="ltx_para">
<p id="S2.SS3.SSS2.p1.1" class="ltx_p">With privacy concerns in mind, one needs to be cautious of how much information about a participating client is revealed during training. The perturbation approach arises as a natural way of preventing information leaks. By injecting the proper amount of artificial noise into the original data, the statistical information calculated from the perturbed data will be statistically indistinguishable from the original data.</p>
</div>
<div id="S2.SS3.SSS2.p2" class="ltx_para">
<p id="S2.SS3.SSS2.p2.6" class="ltx_p">There are three types of widely used perturbation techniques: differential privacy (DP), additive perturbation, and multiplicative perturbation. DP proposed by Dwork <cite class="ltx_cite ltx_citemacro_citep">(Dwork
et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2006</a>)</cite>, is the gold standard. The intuition behind DP is to mask the contribution of any individual user by a sufficient level of uncertainty. A randomized mechanism <math id="S2.SS3.SSS2.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S2.SS3.SSS2.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.SSS2.p2.1.m1.1.1" xref="S2.SS3.SSS2.p2.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p2.1.m1.1b"><ci id="S2.SS3.SSS2.p2.1.m1.1.1.cmml" xref="S2.SS3.SSS2.p2.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p2.1.m1.1c">\mathcal{M}</annotation></semantics></math> is said to be <math id="S2.SS3.SSS2.p2.2.m2.2" class="ltx_Math" alttext="\left(\epsilon,\delta\right)" display="inline"><semantics id="S2.SS3.SSS2.p2.2.m2.2a"><mrow id="S2.SS3.SSS2.p2.2.m2.2.3.2" xref="S2.SS3.SSS2.p2.2.m2.2.3.1.cmml"><mo id="S2.SS3.SSS2.p2.2.m2.2.3.2.1" xref="S2.SS3.SSS2.p2.2.m2.2.3.1.cmml">(</mo><mi id="S2.SS3.SSS2.p2.2.m2.1.1" xref="S2.SS3.SSS2.p2.2.m2.1.1.cmml">ϵ</mi><mo id="S2.SS3.SSS2.p2.2.m2.2.3.2.2" xref="S2.SS3.SSS2.p2.2.m2.2.3.1.cmml">,</mo><mi id="S2.SS3.SSS2.p2.2.m2.2.2" xref="S2.SS3.SSS2.p2.2.m2.2.2.cmml">δ</mi><mo id="S2.SS3.SSS2.p2.2.m2.2.3.2.3" xref="S2.SS3.SSS2.p2.2.m2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p2.2.m2.2b"><interval closure="open" id="S2.SS3.SSS2.p2.2.m2.2.3.1.cmml" xref="S2.SS3.SSS2.p2.2.m2.2.3.2"><ci id="S2.SS3.SSS2.p2.2.m2.1.1.cmml" xref="S2.SS3.SSS2.p2.2.m2.1.1">italic-ϵ</ci><ci id="S2.SS3.SSS2.p2.2.m2.2.2.cmml" xref="S2.SS3.SSS2.p2.2.m2.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p2.2.m2.2c">\left(\epsilon,\delta\right)</annotation></semantics></math>-differentially private if, for any pair of neighboring datasets <math id="S2.SS3.SSS2.p2.3.m3.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S2.SS3.SSS2.p2.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.SSS2.p2.3.m3.1.1" xref="S2.SS3.SSS2.p2.3.m3.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p2.3.m3.1b"><ci id="S2.SS3.SSS2.p2.3.m3.1.1.cmml" xref="S2.SS3.SSS2.p2.3.m3.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p2.3.m3.1c">\mathcal{D}</annotation></semantics></math> and <math id="S2.SS3.SSS2.p2.4.m4.1" class="ltx_Math" alttext="\mathcal{D^{\prime}}" display="inline"><semantics id="S2.SS3.SSS2.p2.4.m4.1a"><msup id="S2.SS3.SSS2.p2.4.m4.1.1" xref="S2.SS3.SSS2.p2.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.SSS2.p2.4.m4.1.1.2" xref="S2.SS3.SSS2.p2.4.m4.1.1.2.cmml">𝒟</mi><mo id="S2.SS3.SSS2.p2.4.m4.1.1.3" xref="S2.SS3.SSS2.p2.4.m4.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p2.4.m4.1b"><apply id="S2.SS3.SSS2.p2.4.m4.1.1.cmml" xref="S2.SS3.SSS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS2.p2.4.m4.1.1.1.cmml" xref="S2.SS3.SSS2.p2.4.m4.1.1">superscript</csymbol><ci id="S2.SS3.SSS2.p2.4.m4.1.1.2.cmml" xref="S2.SS3.SSS2.p2.4.m4.1.1.2">𝒟</ci><ci id="S2.SS3.SSS2.p2.4.m4.1.1.3.cmml" xref="S2.SS3.SSS2.p2.4.m4.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p2.4.m4.1c">\mathcal{D^{\prime}}</annotation></semantics></math>, and for every set of <math id="S2.SS3.SSS2.p2.5.m5.1" class="ltx_Math" alttext="S\subseteq Range\left(\mathcal{M}\right)" display="inline"><semantics id="S2.SS3.SSS2.p2.5.m5.1a"><mrow id="S2.SS3.SSS2.p2.5.m5.1.2" xref="S2.SS3.SSS2.p2.5.m5.1.2.cmml"><mi id="S2.SS3.SSS2.p2.5.m5.1.2.2" xref="S2.SS3.SSS2.p2.5.m5.1.2.2.cmml">S</mi><mo id="S2.SS3.SSS2.p2.5.m5.1.2.1" xref="S2.SS3.SSS2.p2.5.m5.1.2.1.cmml">⊆</mo><mrow id="S2.SS3.SSS2.p2.5.m5.1.2.3" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.cmml"><mi id="S2.SS3.SSS2.p2.5.m5.1.2.3.2" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS2.p2.5.m5.1.2.3.1" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.1.cmml">​</mo><mi id="S2.SS3.SSS2.p2.5.m5.1.2.3.3" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS2.p2.5.m5.1.2.3.1a" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.1.cmml">​</mo><mi id="S2.SS3.SSS2.p2.5.m5.1.2.3.4" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS2.p2.5.m5.1.2.3.1b" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.1.cmml">​</mo><mi id="S2.SS3.SSS2.p2.5.m5.1.2.3.5" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS2.p2.5.m5.1.2.3.1c" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.1.cmml">​</mo><mi id="S2.SS3.SSS2.p2.5.m5.1.2.3.6" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.SS3.SSS2.p2.5.m5.1.2.3.1d" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.1.cmml">​</mo><mrow id="S2.SS3.SSS2.p2.5.m5.1.2.3.7.2" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.cmml"><mo id="S2.SS3.SSS2.p2.5.m5.1.2.3.7.2.1" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS3.SSS2.p2.5.m5.1.1" xref="S2.SS3.SSS2.p2.5.m5.1.1.cmml">ℳ</mi><mo id="S2.SS3.SSS2.p2.5.m5.1.2.3.7.2.2" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p2.5.m5.1b"><apply id="S2.SS3.SSS2.p2.5.m5.1.2.cmml" xref="S2.SS3.SSS2.p2.5.m5.1.2"><subset id="S2.SS3.SSS2.p2.5.m5.1.2.1.cmml" xref="S2.SS3.SSS2.p2.5.m5.1.2.1"></subset><ci id="S2.SS3.SSS2.p2.5.m5.1.2.2.cmml" xref="S2.SS3.SSS2.p2.5.m5.1.2.2">𝑆</ci><apply id="S2.SS3.SSS2.p2.5.m5.1.2.3.cmml" xref="S2.SS3.SSS2.p2.5.m5.1.2.3"><times id="S2.SS3.SSS2.p2.5.m5.1.2.3.1.cmml" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.1"></times><ci id="S2.SS3.SSS2.p2.5.m5.1.2.3.2.cmml" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.2">𝑅</ci><ci id="S2.SS3.SSS2.p2.5.m5.1.2.3.3.cmml" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.3">𝑎</ci><ci id="S2.SS3.SSS2.p2.5.m5.1.2.3.4.cmml" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.4">𝑛</ci><ci id="S2.SS3.SSS2.p2.5.m5.1.2.3.5.cmml" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.5">𝑔</ci><ci id="S2.SS3.SSS2.p2.5.m5.1.2.3.6.cmml" xref="S2.SS3.SSS2.p2.5.m5.1.2.3.6">𝑒</ci><ci id="S2.SS3.SSS2.p2.5.m5.1.1.cmml" xref="S2.SS3.SSS2.p2.5.m5.1.1">ℳ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p2.5.m5.1c">S\subseteq Range\left(\mathcal{M}\right)</annotation></semantics></math>, if <math id="S2.SS3.SSS2.p2.6.m6.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S2.SS3.SSS2.p2.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.SSS2.p2.6.m6.1.1" xref="S2.SS3.SSS2.p2.6.m6.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p2.6.m6.1b"><ci id="S2.SS3.SSS2.p2.6.m6.1.1.cmml" xref="S2.SS3.SSS2.p2.6.m6.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p2.6.m6.1c">\mathcal{M}</annotation></semantics></math> satisfies:</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.7" class="ltx_Math" alttext="{\Pr\left[{\mathcal{M}\left(\mathcal{D}\right)\in S}\right]\leq\exp\left(\varepsilon\right)\cdot\Pr\left[{\mathcal{M}\left(\mathcal{D^{\prime}}\right)\in S}\right]+\delta}" display="block"><semantics id="S2.E2.m1.7a"><mrow id="S2.E2.m1.7.7" xref="S2.E2.m1.7.7.cmml"><mrow id="S2.E2.m1.6.6.1.1" xref="S2.E2.m1.6.6.1.2.cmml"><mi id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml">Pr</mi><mo id="S2.E2.m1.6.6.1.1a" xref="S2.E2.m1.6.6.1.2.cmml">⁡</mo><mrow id="S2.E2.m1.6.6.1.1.1" xref="S2.E2.m1.6.6.1.2.cmml"><mo id="S2.E2.m1.6.6.1.1.1.2" xref="S2.E2.m1.6.6.1.2.cmml">[</mo><mrow id="S2.E2.m1.6.6.1.1.1.1" xref="S2.E2.m1.6.6.1.1.1.1.cmml"><mrow id="S2.E2.m1.6.6.1.1.1.1.2" xref="S2.E2.m1.6.6.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.6.6.1.1.1.1.2.2" xref="S2.E2.m1.6.6.1.1.1.1.2.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.6.6.1.1.1.1.2.1" xref="S2.E2.m1.6.6.1.1.1.1.2.1.cmml">​</mo><mrow id="S2.E2.m1.6.6.1.1.1.1.2.3.2" xref="S2.E2.m1.6.6.1.1.1.1.2.cmml"><mo id="S2.E2.m1.6.6.1.1.1.1.2.3.2.1" xref="S2.E2.m1.6.6.1.1.1.1.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml">𝒟</mi><mo id="S2.E2.m1.6.6.1.1.1.1.2.3.2.2" xref="S2.E2.m1.6.6.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.6.6.1.1.1.1.1" xref="S2.E2.m1.6.6.1.1.1.1.1.cmml">∈</mo><mi id="S2.E2.m1.6.6.1.1.1.1.3" xref="S2.E2.m1.6.6.1.1.1.1.3.cmml">S</mi></mrow><mo id="S2.E2.m1.6.6.1.1.1.3" xref="S2.E2.m1.6.6.1.2.cmml">]</mo></mrow></mrow><mo id="S2.E2.m1.7.7.3" xref="S2.E2.m1.7.7.3.cmml">≤</mo><mrow id="S2.E2.m1.7.7.2" xref="S2.E2.m1.7.7.2.cmml"><mrow id="S2.E2.m1.7.7.2.1" xref="S2.E2.m1.7.7.2.1.cmml"><mrow id="S2.E2.m1.7.7.2.1.3.2" xref="S2.E2.m1.7.7.2.1.3.1.cmml"><mi id="S2.E2.m1.3.3" xref="S2.E2.m1.3.3.cmml">exp</mi><mo id="S2.E2.m1.7.7.2.1.3.2a" xref="S2.E2.m1.7.7.2.1.3.1.cmml">⁡</mo><mrow id="S2.E2.m1.7.7.2.1.3.2.1" xref="S2.E2.m1.7.7.2.1.3.1.cmml"><mo id="S2.E2.m1.7.7.2.1.3.2.1.1" xref="S2.E2.m1.7.7.2.1.3.1.cmml">(</mo><mi id="S2.E2.m1.4.4" xref="S2.E2.m1.4.4.cmml">ε</mi><mo rspace="0.055em" id="S2.E2.m1.7.7.2.1.3.2.1.2" xref="S2.E2.m1.7.7.2.1.3.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S2.E2.m1.7.7.2.1.2" xref="S2.E2.m1.7.7.2.1.2.cmml">⋅</mo><mrow id="S2.E2.m1.7.7.2.1.1.1" xref="S2.E2.m1.7.7.2.1.1.2.cmml"><mi id="S2.E2.m1.5.5" xref="S2.E2.m1.5.5.cmml">Pr</mi><mo id="S2.E2.m1.7.7.2.1.1.1a" xref="S2.E2.m1.7.7.2.1.1.2.cmml">⁡</mo><mrow id="S2.E2.m1.7.7.2.1.1.1.1" xref="S2.E2.m1.7.7.2.1.1.2.cmml"><mo id="S2.E2.m1.7.7.2.1.1.1.1.2" xref="S2.E2.m1.7.7.2.1.1.2.cmml">[</mo><mrow id="S2.E2.m1.7.7.2.1.1.1.1.1" xref="S2.E2.m1.7.7.2.1.1.1.1.1.cmml"><mrow id="S2.E2.m1.7.7.2.1.1.1.1.1.1" xref="S2.E2.m1.7.7.2.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.7.7.2.1.1.1.1.1.1.3" xref="S2.E2.m1.7.7.2.1.1.1.1.1.1.3.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.7.7.2.1.1.1.1.1.1.2" xref="S2.E2.m1.7.7.2.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1" xref="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1.1.2.cmml">𝒟</mi><mo id="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1.1.3.cmml">′</mo></msup><mo id="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.7.7.2.1.1.1.1.1.2" xref="S2.E2.m1.7.7.2.1.1.1.1.1.2.cmml">∈</mo><mi id="S2.E2.m1.7.7.2.1.1.1.1.1.3" xref="S2.E2.m1.7.7.2.1.1.1.1.1.3.cmml">S</mi></mrow><mo id="S2.E2.m1.7.7.2.1.1.1.1.3" xref="S2.E2.m1.7.7.2.1.1.2.cmml">]</mo></mrow></mrow></mrow><mo id="S2.E2.m1.7.7.2.2" xref="S2.E2.m1.7.7.2.2.cmml">+</mo><mi id="S2.E2.m1.7.7.2.3" xref="S2.E2.m1.7.7.2.3.cmml">δ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.7b"><apply id="S2.E2.m1.7.7.cmml" xref="S2.E2.m1.7.7"><leq id="S2.E2.m1.7.7.3.cmml" xref="S2.E2.m1.7.7.3"></leq><apply id="S2.E2.m1.6.6.1.2.cmml" xref="S2.E2.m1.6.6.1.1"><ci id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2">Pr</ci><apply id="S2.E2.m1.6.6.1.1.1.1.cmml" xref="S2.E2.m1.6.6.1.1.1.1"><in id="S2.E2.m1.6.6.1.1.1.1.1.cmml" xref="S2.E2.m1.6.6.1.1.1.1.1"></in><apply id="S2.E2.m1.6.6.1.1.1.1.2.cmml" xref="S2.E2.m1.6.6.1.1.1.1.2"><times id="S2.E2.m1.6.6.1.1.1.1.2.1.cmml" xref="S2.E2.m1.6.6.1.1.1.1.2.1"></times><ci id="S2.E2.m1.6.6.1.1.1.1.2.2.cmml" xref="S2.E2.m1.6.6.1.1.1.1.2.2">ℳ</ci><ci id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1">𝒟</ci></apply><ci id="S2.E2.m1.6.6.1.1.1.1.3.cmml" xref="S2.E2.m1.6.6.1.1.1.1.3">𝑆</ci></apply></apply><apply id="S2.E2.m1.7.7.2.cmml" xref="S2.E2.m1.7.7.2"><plus id="S2.E2.m1.7.7.2.2.cmml" xref="S2.E2.m1.7.7.2.2"></plus><apply id="S2.E2.m1.7.7.2.1.cmml" xref="S2.E2.m1.7.7.2.1"><ci id="S2.E2.m1.7.7.2.1.2.cmml" xref="S2.E2.m1.7.7.2.1.2">⋅</ci><apply id="S2.E2.m1.7.7.2.1.3.1.cmml" xref="S2.E2.m1.7.7.2.1.3.2"><exp id="S2.E2.m1.3.3.cmml" xref="S2.E2.m1.3.3"></exp><ci id="S2.E2.m1.4.4.cmml" xref="S2.E2.m1.4.4">𝜀</ci></apply><apply id="S2.E2.m1.7.7.2.1.1.2.cmml" xref="S2.E2.m1.7.7.2.1.1.1"><ci id="S2.E2.m1.5.5.cmml" xref="S2.E2.m1.5.5">Pr</ci><apply id="S2.E2.m1.7.7.2.1.1.1.1.1.cmml" xref="S2.E2.m1.7.7.2.1.1.1.1.1"><in id="S2.E2.m1.7.7.2.1.1.1.1.1.2.cmml" xref="S2.E2.m1.7.7.2.1.1.1.1.1.2"></in><apply id="S2.E2.m1.7.7.2.1.1.1.1.1.1.cmml" xref="S2.E2.m1.7.7.2.1.1.1.1.1.1"><times id="S2.E2.m1.7.7.2.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.7.7.2.1.1.1.1.1.1.2"></times><ci id="S2.E2.m1.7.7.2.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.7.7.2.1.1.1.1.1.1.3">ℳ</ci><apply id="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1.1.2">𝒟</ci><ci id="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.7.7.2.1.1.1.1.1.1.1.1.1.3">′</ci></apply></apply><ci id="S2.E2.m1.7.7.2.1.1.1.1.1.3.cmml" xref="S2.E2.m1.7.7.2.1.1.1.1.1.3">𝑆</ci></apply></apply></apply><ci id="S2.E2.m1.7.7.2.3.cmml" xref="S2.E2.m1.7.7.2.3">𝛿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.7c">{\Pr\left[{\mathcal{M}\left(\mathcal{D}\right)\in S}\right]\leq\exp\left(\varepsilon\right)\cdot\Pr\left[{\mathcal{M}\left(\mathcal{D^{\prime}}\right)\in S}\right]+\delta}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.SS3.SSS2.p2.13" class="ltx_p">The parameter <math id="S2.SS3.SSS2.p2.7.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S2.SS3.SSS2.p2.7.m1.1a"><mi id="S2.SS3.SSS2.p2.7.m1.1.1" xref="S2.SS3.SSS2.p2.7.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p2.7.m1.1b"><ci id="S2.SS3.SSS2.p2.7.m1.1.1.cmml" xref="S2.SS3.SSS2.p2.7.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p2.7.m1.1c">\epsilon</annotation></semantics></math> is defined as privacy budget, which measures how alike the two adjacent datasets <math id="S2.SS3.SSS2.p2.8.m2.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S2.SS3.SSS2.p2.8.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.SSS2.p2.8.m2.1.1" xref="S2.SS3.SSS2.p2.8.m2.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p2.8.m2.1b"><ci id="S2.SS3.SSS2.p2.8.m2.1.1.cmml" xref="S2.SS3.SSS2.p2.8.m2.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p2.8.m2.1c">\mathcal{D}</annotation></semantics></math> and <math id="S2.SS3.SSS2.p2.9.m3.1" class="ltx_Math" alttext="\mathcal{D^{\prime}}" display="inline"><semantics id="S2.SS3.SSS2.p2.9.m3.1a"><msup id="S2.SS3.SSS2.p2.9.m3.1.1" xref="S2.SS3.SSS2.p2.9.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.SSS2.p2.9.m3.1.1.2" xref="S2.SS3.SSS2.p2.9.m3.1.1.2.cmml">𝒟</mi><mo id="S2.SS3.SSS2.p2.9.m3.1.1.3" xref="S2.SS3.SSS2.p2.9.m3.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p2.9.m3.1b"><apply id="S2.SS3.SSS2.p2.9.m3.1.1.cmml" xref="S2.SS3.SSS2.p2.9.m3.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS2.p2.9.m3.1.1.1.cmml" xref="S2.SS3.SSS2.p2.9.m3.1.1">superscript</csymbol><ci id="S2.SS3.SSS2.p2.9.m3.1.1.2.cmml" xref="S2.SS3.SSS2.p2.9.m3.1.1.2">𝒟</ci><ci id="S2.SS3.SSS2.p2.9.m3.1.1.3.cmml" xref="S2.SS3.SSS2.p2.9.m3.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p2.9.m3.1c">\mathcal{D^{\prime}}</annotation></semantics></math> are to each other. A smaller <math id="S2.SS3.SSS2.p2.10.m4.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S2.SS3.SSS2.p2.10.m4.1a"><mi id="S2.SS3.SSS2.p2.10.m4.1.1" xref="S2.SS3.SSS2.p2.10.m4.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p2.10.m4.1b"><ci id="S2.SS3.SSS2.p2.10.m4.1.1.cmml" xref="S2.SS3.SSS2.p2.10.m4.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p2.10.m4.1c">\epsilon</annotation></semantics></math> indicates a stronger privacy guarantee.
If <math id="S2.SS3.SSS2.p2.11.m5.1" class="ltx_Math" alttext="\delta=0" display="inline"><semantics id="S2.SS3.SSS2.p2.11.m5.1a"><mrow id="S2.SS3.SSS2.p2.11.m5.1.1" xref="S2.SS3.SSS2.p2.11.m5.1.1.cmml"><mi id="S2.SS3.SSS2.p2.11.m5.1.1.2" xref="S2.SS3.SSS2.p2.11.m5.1.1.2.cmml">δ</mi><mo id="S2.SS3.SSS2.p2.11.m5.1.1.1" xref="S2.SS3.SSS2.p2.11.m5.1.1.1.cmml">=</mo><mn id="S2.SS3.SSS2.p2.11.m5.1.1.3" xref="S2.SS3.SSS2.p2.11.m5.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p2.11.m5.1b"><apply id="S2.SS3.SSS2.p2.11.m5.1.1.cmml" xref="S2.SS3.SSS2.p2.11.m5.1.1"><eq id="S2.SS3.SSS2.p2.11.m5.1.1.1.cmml" xref="S2.SS3.SSS2.p2.11.m5.1.1.1"></eq><ci id="S2.SS3.SSS2.p2.11.m5.1.1.2.cmml" xref="S2.SS3.SSS2.p2.11.m5.1.1.2">𝛿</ci><cn type="integer" id="S2.SS3.SSS2.p2.11.m5.1.1.3.cmml" xref="S2.SS3.SSS2.p2.11.m5.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p2.11.m5.1c">\delta=0</annotation></semantics></math>, then the randomized mechanism <math id="S2.SS3.SSS2.p2.12.m6.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S2.SS3.SSS2.p2.12.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.SSS2.p2.12.m6.1.1" xref="S2.SS3.SSS2.p2.12.m6.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p2.12.m6.1b"><ci id="S2.SS3.SSS2.p2.12.m6.1.1.cmml" xref="S2.SS3.SSS2.p2.12.m6.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p2.12.m6.1c">\mathcal{M}</annotation></semantics></math> is degraded into <math id="S2.SS3.SSS2.p2.13.m7.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S2.SS3.SSS2.p2.13.m7.1a"><mi id="S2.SS3.SSS2.p2.13.m7.1.1" xref="S2.SS3.SSS2.p2.13.m7.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p2.13.m7.1b"><ci id="S2.SS3.SSS2.p2.13.m7.1.1.cmml" xref="S2.SS3.SSS2.p2.13.m7.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p2.13.m7.1c">\epsilon</annotation></semantics></math>- DP.</p>
</div>
</section>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4. </span>Fairness in FL</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">Algorithms are widely used to assist in making recommendations, assessing loan applications, etc. Several studies have identified the unfairness in different algorithmic scenarios <cite class="ltx_cite ltx_citemacro_citep">(Mehrabi et al<span class="ltx_text">.</span>, <a href="#bib.bib132" title="" class="ltx_ref">2021</a>)</cite>. One example is the hate speech detector designed to rate the toxicity score of the given phrases to help companies like Twitter recognize harmful speech. The detector relies on a tool called <span id="S2.SS4.p1.1.1" class="ltx_text ltx_font_italic">Perspective</span>, which is trained on labeled data. The detector behaves differently towards phrases written in African American English in a racially biased way, as Fig. <a href="#S2.F2" title="Figure 2 ‣ 2.4. Fairness in FL ‣ 2. Background Knowledge ‣ Privacy and Fairness in Federated Learning: on the Perspective of Trade-off" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows <cite class="ltx_cite ltx_citemacro_citep">(Sap
et al<span class="ltx_text">.</span>, <a href="#bib.bib158" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2306.14123/assets/Hate_Speech_Detector.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="314" height="200" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Racial disparities in classifier predictions on tweets written in African-American English and in Standard American English (reproduced from <cite class="ltx_cite ltx_citemacro_citep">(Sap
et al<span class="ltx_text">.</span>, <a href="#bib.bib158" title="" class="ltx_ref">2019</a>)</cite>)</figcaption>
</figure>
<section id="S2.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.1. </span>Bias in FL</h4>

<div id="S2.SS4.SSS1.p1" class="ltx_para">
<p id="S2.SS4.SSS1.p1.1" class="ltx_p">Fairness can be eroded by bias. According to Olteanu et al. <cite class="ltx_cite ltx_citemacro_citep">(Olteanu et al<span class="ltx_text">.</span>, <a href="#bib.bib144" title="" class="ltx_ref">2019</a>)</cite>, bias can slip into data flows from generation to collection to processing <cite class="ltx_cite ltx_citemacro_citep">(Olteanu et al<span class="ltx_text">.</span>, <a href="#bib.bib144" title="" class="ltx_ref">2019</a>)</cite>.
The distributed learning paradigm of FL brings new and unique challenges to our efforts to build fair models. One challenge is that the independent and identical distribution (i.i.d.) assumption no longer holds <cite class="ltx_cite ltx_citemacro_citep">(Kairouz
et al<span class="ltx_text">.</span>, <a href="#bib.bib90" title="" class="ltx_ref">2019</a>)</cite>. In FL, bias can also be introduced by either the client or the server.</p>
</div>
<div id="S2.SS4.SSS1.p2" class="ltx_para">
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Client-introduced bias</span>. Clients can introduce bias in several ways. First, bias exists in a client’s local data – prejudice, underestimation, negative legacies, etc. <cite class="ltx_cite ltx_citemacro_citep">(Kamishima
et al<span class="ltx_text">.</span>, <a href="#bib.bib94" title="" class="ltx_ref">2012</a>)</cite>. This bias is then integrated into the global model through client and server interactions. Second, bias can strike when clients are dropped out of the federated setting due to device shutdowns or communication limitations. In these cases, the global model will find it hard to fit the clients’ data properly. The massively distributed data also incurs bias. In this case, the client does not have enough data to capture an underlying distribution, and moreover, the underlying distributions of different clients are probably not the same. <cite class="ltx_cite ltx_citemacro_citep">(Zhao
et al<span class="ltx_text">.</span>, <a href="#bib.bib229" title="" class="ltx_ref">2018a</a>; Briggs
et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2020</a>; Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib112" title="" class="ltx_ref">2021</a>)</cite></p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Server-introduced bias</span>. The server can also add bias. As the coordinator of the learning scheme, the server will sample clients in each round to train a global model with their local data <cite class="ltx_cite ltx_citemacro_citep">(Nagalapatti and
Narayanam, <a href="#bib.bib140" title="" class="ltx_ref">2021</a>)</cite>. However, the sampling process is prone to producing bias if it is not done with careful consideration. First, in terms of efficiency, only a fraction of clients are selected in each round <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib130" title="" class="ltx_ref">2017</a>)</cite>. Yet the data distribution of only a few selected clients forms an inadequate representation of the actual population distribution. Second, the sampling may be skewed toward certain clients. For instance, to speed up convergence, the server prefers clients that meet specific criteria <cite class="ltx_cite ltx_citemacro_citep">(Nishio and
Yonetani, <a href="#bib.bib143" title="" class="ltx_ref">2019</a>; Cho
et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.2. </span>Fairness Notions in FL</h4>

<div id="S2.SS4.SSS2.p1" class="ltx_para">
<p id="S2.SS4.SSS2.p1.1" class="ltx_p">To date, researchers have proposed several definitions of fairness, see, e.g., <cite class="ltx_cite ltx_citemacro_citep">(Verma and Rubin, <a href="#bib.bib183" title="" class="ltx_ref">2018</a>; Mehrabi et al<span class="ltx_text">.</span>, <a href="#bib.bib132" title="" class="ltx_ref">2021</a>)</cite>. These definitions vary from scenario to scenario, and it is unlikely that there will ever be one particular definition of fairness that fits all circumstances. Table <a href="#S2.T2" title="Table 2 ‣ 2.4.2. Fairness Notions in FL ‣ 2.4. Fairness in FL ‣ 2. Background Knowledge ‣ Privacy and Fairness in Federated Learning: on the Perspective of Trade-off" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> lists common algorithmic fairness notions adopted in centralized machine learning. At a high level, two families of definitions exist the <span id="S2.SS4.SSS2.p1.1.1" class="ltx_text ltx_font_italic">individual</span> notion and <span id="S2.SS4.SSS2.p1.1.2" class="ltx_text ltx_font_italic">statistical</span> notion <cite class="ltx_cite ltx_citemacro_citep">(Chouldechova and
Roth, <a href="#bib.bib32" title="" class="ltx_ref">2018</a>)</cite>.</p>
<ul id="S2.I2" class="ltx_itemize">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.6" class="ltx_p"><span id="S2.I2.i1.p1.6.1" class="ltx_text ltx_font_bold">Individual notion</span>. The individual notions ensure fairness between specific pairs of individuals: <span id="S2.I2.i1.p1.6.2" class="ltx_text ltx_font_italic">”Give similar predictions to similar individuals.”</span> <cite class="ltx_cite ltx_citemacro_citep">(Dwork et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2012</a>)</cite>. Formally, for a set of samples <math id="S2.I2.i1.p1.1.m1.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S2.I2.i1.p1.1.m1.1a"><mi id="S2.I2.i1.p1.1.m1.1.1" xref="S2.I2.i1.p1.1.m1.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S2.I2.i1.p1.1.m1.1b"><ci id="S2.I2.i1.p1.1.m1.1.1.cmml" xref="S2.I2.i1.p1.1.m1.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i1.p1.1.m1.1c">V</annotation></semantics></math>, a distance metric is defined as <math id="S2.I2.i1.p1.2.m2.1" class="ltx_Math" alttext="d:V\times V\to R" display="inline"><semantics id="S2.I2.i1.p1.2.m2.1a"><mrow id="S2.I2.i1.p1.2.m2.1.1" xref="S2.I2.i1.p1.2.m2.1.1.cmml"><mi id="S2.I2.i1.p1.2.m2.1.1.2" xref="S2.I2.i1.p1.2.m2.1.1.2.cmml">d</mi><mo lspace="0.278em" rspace="0.278em" id="S2.I2.i1.p1.2.m2.1.1.1" xref="S2.I2.i1.p1.2.m2.1.1.1.cmml">:</mo><mrow id="S2.I2.i1.p1.2.m2.1.1.3" xref="S2.I2.i1.p1.2.m2.1.1.3.cmml"><mrow id="S2.I2.i1.p1.2.m2.1.1.3.2" xref="S2.I2.i1.p1.2.m2.1.1.3.2.cmml"><mi id="S2.I2.i1.p1.2.m2.1.1.3.2.2" xref="S2.I2.i1.p1.2.m2.1.1.3.2.2.cmml">V</mi><mo lspace="0.222em" rspace="0.222em" id="S2.I2.i1.p1.2.m2.1.1.3.2.1" xref="S2.I2.i1.p1.2.m2.1.1.3.2.1.cmml">×</mo><mi id="S2.I2.i1.p1.2.m2.1.1.3.2.3" xref="S2.I2.i1.p1.2.m2.1.1.3.2.3.cmml">V</mi></mrow><mo stretchy="false" id="S2.I2.i1.p1.2.m2.1.1.3.1" xref="S2.I2.i1.p1.2.m2.1.1.3.1.cmml">→</mo><mi id="S2.I2.i1.p1.2.m2.1.1.3.3" xref="S2.I2.i1.p1.2.m2.1.1.3.3.cmml">R</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I2.i1.p1.2.m2.1b"><apply id="S2.I2.i1.p1.2.m2.1.1.cmml" xref="S2.I2.i1.p1.2.m2.1.1"><ci id="S2.I2.i1.p1.2.m2.1.1.1.cmml" xref="S2.I2.i1.p1.2.m2.1.1.1">:</ci><ci id="S2.I2.i1.p1.2.m2.1.1.2.cmml" xref="S2.I2.i1.p1.2.m2.1.1.2">𝑑</ci><apply id="S2.I2.i1.p1.2.m2.1.1.3.cmml" xref="S2.I2.i1.p1.2.m2.1.1.3"><ci id="S2.I2.i1.p1.2.m2.1.1.3.1.cmml" xref="S2.I2.i1.p1.2.m2.1.1.3.1">→</ci><apply id="S2.I2.i1.p1.2.m2.1.1.3.2.cmml" xref="S2.I2.i1.p1.2.m2.1.1.3.2"><times id="S2.I2.i1.p1.2.m2.1.1.3.2.1.cmml" xref="S2.I2.i1.p1.2.m2.1.1.3.2.1"></times><ci id="S2.I2.i1.p1.2.m2.1.1.3.2.2.cmml" xref="S2.I2.i1.p1.2.m2.1.1.3.2.2">𝑉</ci><ci id="S2.I2.i1.p1.2.m2.1.1.3.2.3.cmml" xref="S2.I2.i1.p1.2.m2.1.1.3.2.3">𝑉</ci></apply><ci id="S2.I2.i1.p1.2.m2.1.1.3.3.cmml" xref="S2.I2.i1.p1.2.m2.1.1.3.3">𝑅</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i1.p1.2.m2.1c">d:V\times V\to R</annotation></semantics></math> to measure the similarity. A function <math id="S2.I2.i1.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{M}:V\to\Delta A" display="inline"><semantics id="S2.I2.i1.p1.3.m3.1a"><mrow id="S2.I2.i1.p1.3.m3.1.1" xref="S2.I2.i1.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I2.i1.p1.3.m3.1.1.2" xref="S2.I2.i1.p1.3.m3.1.1.2.cmml">ℳ</mi><mo lspace="0.278em" rspace="0.278em" id="S2.I2.i1.p1.3.m3.1.1.1" xref="S2.I2.i1.p1.3.m3.1.1.1.cmml">:</mo><mrow id="S2.I2.i1.p1.3.m3.1.1.3" xref="S2.I2.i1.p1.3.m3.1.1.3.cmml"><mi id="S2.I2.i1.p1.3.m3.1.1.3.2" xref="S2.I2.i1.p1.3.m3.1.1.3.2.cmml">V</mi><mo stretchy="false" id="S2.I2.i1.p1.3.m3.1.1.3.1" xref="S2.I2.i1.p1.3.m3.1.1.3.1.cmml">→</mo><mrow id="S2.I2.i1.p1.3.m3.1.1.3.3" xref="S2.I2.i1.p1.3.m3.1.1.3.3.cmml"><mi mathvariant="normal" id="S2.I2.i1.p1.3.m3.1.1.3.3.2" xref="S2.I2.i1.p1.3.m3.1.1.3.3.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S2.I2.i1.p1.3.m3.1.1.3.3.1" xref="S2.I2.i1.p1.3.m3.1.1.3.3.1.cmml">​</mo><mi id="S2.I2.i1.p1.3.m3.1.1.3.3.3" xref="S2.I2.i1.p1.3.m3.1.1.3.3.3.cmml">A</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I2.i1.p1.3.m3.1b"><apply id="S2.I2.i1.p1.3.m3.1.1.cmml" xref="S2.I2.i1.p1.3.m3.1.1"><ci id="S2.I2.i1.p1.3.m3.1.1.1.cmml" xref="S2.I2.i1.p1.3.m3.1.1.1">:</ci><ci id="S2.I2.i1.p1.3.m3.1.1.2.cmml" xref="S2.I2.i1.p1.3.m3.1.1.2">ℳ</ci><apply id="S2.I2.i1.p1.3.m3.1.1.3.cmml" xref="S2.I2.i1.p1.3.m3.1.1.3"><ci id="S2.I2.i1.p1.3.m3.1.1.3.1.cmml" xref="S2.I2.i1.p1.3.m3.1.1.3.1">→</ci><ci id="S2.I2.i1.p1.3.m3.1.1.3.2.cmml" xref="S2.I2.i1.p1.3.m3.1.1.3.2">𝑉</ci><apply id="S2.I2.i1.p1.3.m3.1.1.3.3.cmml" xref="S2.I2.i1.p1.3.m3.1.1.3.3"><times id="S2.I2.i1.p1.3.m3.1.1.3.3.1.cmml" xref="S2.I2.i1.p1.3.m3.1.1.3.3.1"></times><ci id="S2.I2.i1.p1.3.m3.1.1.3.3.2.cmml" xref="S2.I2.i1.p1.3.m3.1.1.3.3.2">Δ</ci><ci id="S2.I2.i1.p1.3.m3.1.1.3.3.3.cmml" xref="S2.I2.i1.p1.3.m3.1.1.3.3.3">𝐴</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i1.p1.3.m3.1c">\mathcal{M}:V\to\Delta A</annotation></semantics></math> maps the samples <math id="S2.I2.i1.p1.4.m4.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S2.I2.i1.p1.4.m4.1a"><mi id="S2.I2.i1.p1.4.m4.1.1" xref="S2.I2.i1.p1.4.m4.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S2.I2.i1.p1.4.m4.1b"><ci id="S2.I2.i1.p1.4.m4.1.1.cmml" xref="S2.I2.i1.p1.4.m4.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i1.p1.4.m4.1c">V</annotation></semantics></math> to the probability distributions over outcomes, and another distance <math id="S2.I2.i1.p1.5.m5.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.I2.i1.p1.5.m5.1a"><mi id="S2.I2.i1.p1.5.m5.1.1" xref="S2.I2.i1.p1.5.m5.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.I2.i1.p1.5.m5.1b"><ci id="S2.I2.i1.p1.5.m5.1.1.cmml" xref="S2.I2.i1.p1.5.m5.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i1.p1.5.m5.1c">D</annotation></semantics></math> metric measures the distance between the distributions of outputs. Fairness is achieved if and only if <math id="S2.I2.i1.p1.6.m6.6" class="ltx_Math" alttext="D\left(\mathcal{M}\left(x\right),\mathcal{M}\left(y\right)\right)\leq d\left(x,y\right)" display="inline"><semantics id="S2.I2.i1.p1.6.m6.6a"><mrow id="S2.I2.i1.p1.6.m6.6.6" xref="S2.I2.i1.p1.6.m6.6.6.cmml"><mrow id="S2.I2.i1.p1.6.m6.6.6.2" xref="S2.I2.i1.p1.6.m6.6.6.2.cmml"><mi id="S2.I2.i1.p1.6.m6.6.6.2.4" xref="S2.I2.i1.p1.6.m6.6.6.2.4.cmml">D</mi><mo lspace="0em" rspace="0em" id="S2.I2.i1.p1.6.m6.6.6.2.3" xref="S2.I2.i1.p1.6.m6.6.6.2.3.cmml">​</mo><mrow id="S2.I2.i1.p1.6.m6.6.6.2.2.2" xref="S2.I2.i1.p1.6.m6.6.6.2.2.3.cmml"><mo id="S2.I2.i1.p1.6.m6.6.6.2.2.2.3" xref="S2.I2.i1.p1.6.m6.6.6.2.2.3.cmml">(</mo><mrow id="S2.I2.i1.p1.6.m6.5.5.1.1.1.1" xref="S2.I2.i1.p1.6.m6.5.5.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I2.i1.p1.6.m6.5.5.1.1.1.1.2" xref="S2.I2.i1.p1.6.m6.5.5.1.1.1.1.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S2.I2.i1.p1.6.m6.5.5.1.1.1.1.1" xref="S2.I2.i1.p1.6.m6.5.5.1.1.1.1.1.cmml">​</mo><mrow id="S2.I2.i1.p1.6.m6.5.5.1.1.1.1.3.2" xref="S2.I2.i1.p1.6.m6.5.5.1.1.1.1.cmml"><mo id="S2.I2.i1.p1.6.m6.5.5.1.1.1.1.3.2.1" xref="S2.I2.i1.p1.6.m6.5.5.1.1.1.1.cmml">(</mo><mi id="S2.I2.i1.p1.6.m6.1.1" xref="S2.I2.i1.p1.6.m6.1.1.cmml">x</mi><mo id="S2.I2.i1.p1.6.m6.5.5.1.1.1.1.3.2.2" xref="S2.I2.i1.p1.6.m6.5.5.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.I2.i1.p1.6.m6.6.6.2.2.2.4" xref="S2.I2.i1.p1.6.m6.6.6.2.2.3.cmml">,</mo><mrow id="S2.I2.i1.p1.6.m6.6.6.2.2.2.2" xref="S2.I2.i1.p1.6.m6.6.6.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I2.i1.p1.6.m6.6.6.2.2.2.2.2" xref="S2.I2.i1.p1.6.m6.6.6.2.2.2.2.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S2.I2.i1.p1.6.m6.6.6.2.2.2.2.1" xref="S2.I2.i1.p1.6.m6.6.6.2.2.2.2.1.cmml">​</mo><mrow id="S2.I2.i1.p1.6.m6.6.6.2.2.2.2.3.2" xref="S2.I2.i1.p1.6.m6.6.6.2.2.2.2.cmml"><mo id="S2.I2.i1.p1.6.m6.6.6.2.2.2.2.3.2.1" xref="S2.I2.i1.p1.6.m6.6.6.2.2.2.2.cmml">(</mo><mi id="S2.I2.i1.p1.6.m6.2.2" xref="S2.I2.i1.p1.6.m6.2.2.cmml">y</mi><mo id="S2.I2.i1.p1.6.m6.6.6.2.2.2.2.3.2.2" xref="S2.I2.i1.p1.6.m6.6.6.2.2.2.2.cmml">)</mo></mrow></mrow><mo id="S2.I2.i1.p1.6.m6.6.6.2.2.2.5" xref="S2.I2.i1.p1.6.m6.6.6.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.I2.i1.p1.6.m6.6.6.3" xref="S2.I2.i1.p1.6.m6.6.6.3.cmml">≤</mo><mrow id="S2.I2.i1.p1.6.m6.6.6.4" xref="S2.I2.i1.p1.6.m6.6.6.4.cmml"><mi id="S2.I2.i1.p1.6.m6.6.6.4.2" xref="S2.I2.i1.p1.6.m6.6.6.4.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.I2.i1.p1.6.m6.6.6.4.1" xref="S2.I2.i1.p1.6.m6.6.6.4.1.cmml">​</mo><mrow id="S2.I2.i1.p1.6.m6.6.6.4.3.2" xref="S2.I2.i1.p1.6.m6.6.6.4.3.1.cmml"><mo id="S2.I2.i1.p1.6.m6.6.6.4.3.2.1" xref="S2.I2.i1.p1.6.m6.6.6.4.3.1.cmml">(</mo><mi id="S2.I2.i1.p1.6.m6.3.3" xref="S2.I2.i1.p1.6.m6.3.3.cmml">x</mi><mo id="S2.I2.i1.p1.6.m6.6.6.4.3.2.2" xref="S2.I2.i1.p1.6.m6.6.6.4.3.1.cmml">,</mo><mi id="S2.I2.i1.p1.6.m6.4.4" xref="S2.I2.i1.p1.6.m6.4.4.cmml">y</mi><mo id="S2.I2.i1.p1.6.m6.6.6.4.3.2.3" xref="S2.I2.i1.p1.6.m6.6.6.4.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I2.i1.p1.6.m6.6b"><apply id="S2.I2.i1.p1.6.m6.6.6.cmml" xref="S2.I2.i1.p1.6.m6.6.6"><leq id="S2.I2.i1.p1.6.m6.6.6.3.cmml" xref="S2.I2.i1.p1.6.m6.6.6.3"></leq><apply id="S2.I2.i1.p1.6.m6.6.6.2.cmml" xref="S2.I2.i1.p1.6.m6.6.6.2"><times id="S2.I2.i1.p1.6.m6.6.6.2.3.cmml" xref="S2.I2.i1.p1.6.m6.6.6.2.3"></times><ci id="S2.I2.i1.p1.6.m6.6.6.2.4.cmml" xref="S2.I2.i1.p1.6.m6.6.6.2.4">𝐷</ci><interval closure="open" id="S2.I2.i1.p1.6.m6.6.6.2.2.3.cmml" xref="S2.I2.i1.p1.6.m6.6.6.2.2.2"><apply id="S2.I2.i1.p1.6.m6.5.5.1.1.1.1.cmml" xref="S2.I2.i1.p1.6.m6.5.5.1.1.1.1"><times id="S2.I2.i1.p1.6.m6.5.5.1.1.1.1.1.cmml" xref="S2.I2.i1.p1.6.m6.5.5.1.1.1.1.1"></times><ci id="S2.I2.i1.p1.6.m6.5.5.1.1.1.1.2.cmml" xref="S2.I2.i1.p1.6.m6.5.5.1.1.1.1.2">ℳ</ci><ci id="S2.I2.i1.p1.6.m6.1.1.cmml" xref="S2.I2.i1.p1.6.m6.1.1">𝑥</ci></apply><apply id="S2.I2.i1.p1.6.m6.6.6.2.2.2.2.cmml" xref="S2.I2.i1.p1.6.m6.6.6.2.2.2.2"><times id="S2.I2.i1.p1.6.m6.6.6.2.2.2.2.1.cmml" xref="S2.I2.i1.p1.6.m6.6.6.2.2.2.2.1"></times><ci id="S2.I2.i1.p1.6.m6.6.6.2.2.2.2.2.cmml" xref="S2.I2.i1.p1.6.m6.6.6.2.2.2.2.2">ℳ</ci><ci id="S2.I2.i1.p1.6.m6.2.2.cmml" xref="S2.I2.i1.p1.6.m6.2.2">𝑦</ci></apply></interval></apply><apply id="S2.I2.i1.p1.6.m6.6.6.4.cmml" xref="S2.I2.i1.p1.6.m6.6.6.4"><times id="S2.I2.i1.p1.6.m6.6.6.4.1.cmml" xref="S2.I2.i1.p1.6.m6.6.6.4.1"></times><ci id="S2.I2.i1.p1.6.m6.6.6.4.2.cmml" xref="S2.I2.i1.p1.6.m6.6.6.4.2">𝑑</ci><interval closure="open" id="S2.I2.i1.p1.6.m6.6.6.4.3.1.cmml" xref="S2.I2.i1.p1.6.m6.6.6.4.3.2"><ci id="S2.I2.i1.p1.6.m6.3.3.cmml" xref="S2.I2.i1.p1.6.m6.3.3">𝑥</ci><ci id="S2.I2.i1.p1.6.m6.4.4.cmml" xref="S2.I2.i1.p1.6.m6.4.4">𝑦</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i1.p1.6.m6.6c">D\left(\mathcal{M}\left(x\right),\mathcal{M}\left(y\right)\right)\leq d\left(x,y\right)</annotation></semantics></math>. This family of definitions provides a meaningful guarantee. However, they are at the cost of making significant assumptions, some of which are non-trivial problems in fairness.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p"><span id="S2.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Statistical notion</span>. The statistical notions provide fairness assurance at a statistical level. For the protected demographic groups <math id="S2.I2.i2.p1.1.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.I2.i2.p1.1.m1.1a"><mi id="S2.I2.i2.p1.1.m1.1.1" xref="S2.I2.i2.p1.1.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.I2.i2.p1.1.m1.1b"><ci id="S2.I2.i2.p1.1.m1.1.1.cmml" xref="S2.I2.i2.p1.1.m1.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i2.p1.1.m1.1c">G</annotation></semantics></math> (such as racial minorities), some statistical measures are required to be equal across all of these groups. These statistical measures include positive classification rates <cite class="ltx_cite ltx_citemacro_citep">(Kamishima
et al<span class="ltx_text">.</span>, <a href="#bib.bib95" title="" class="ltx_ref">2011</a>; Calders and
Verwer, <a href="#bib.bib21" title="" class="ltx_ref">2010</a>; Dwork et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2012</a>)</cite>, false positive and false negative rates <cite class="ltx_cite ltx_citemacro_citep">(Hardt
et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2016</a>; Kleinberg et al<span class="ltx_text">.</span>, <a href="#bib.bib104" title="" class="ltx_ref">2017</a>)</cite>, and positive predictive value <cite class="ltx_cite ltx_citemacro_citep">(Zafar
et al<span class="ltx_text">.</span>, <a href="#bib.bib212" title="" class="ltx_ref">2017</a>; Chouldechova, <a href="#bib.bib31" title="" class="ltx_ref">2017</a>)</cite>. Detailed enumeration can be found in <cite class="ltx_cite ltx_citemacro_citep">(Berk
et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2021a</a>; Verma and Rubin, <a href="#bib.bib183" title="" class="ltx_ref">2018</a>)</cite>. This family of definitions requires no assumption over data and can be easily verified. However, statistical notions are insufficient as a fairness constraint, which does not give meaningful guarantees to individuals or structured subgroups of the protected demographic groups. Jiang et al. <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al<span class="ltx_text">.</span>, <a href="#bib.bib86" title="" class="ltx_ref">2022</a>)</cite> generalized the demographic parity <cite class="ltx_cite ltx_citemacro_citep">(Kusner
et al<span class="ltx_text">.</span>, <a href="#bib.bib107" title="" class="ltx_ref">2018</a>)</cite> to continuous sensitive attribute.</p>
</div>
</li>
</ul>
</div>
<figure id="S2.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2. </span>Definitions of Algorithmic Fairness Notions</figcaption>
<table id="S2.T2.6" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T2.6.7.1" class="ltx_tr">
<td id="S2.T2.6.7.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S2.T2.6.7.1.1.1" class="ltx_text ltx_font_bold">Fairness notion</span></td>
<td id="S2.T2.6.7.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S2.T2.6.7.1.2.1" class="ltx_text ltx_font_bold">Definition</span></td>
<td id="S2.T2.6.7.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S2.T2.6.7.1.3.1" class="ltx_text ltx_font_bold">Explanation</span></td>
</tr>
<tr id="S2.T2.1.1" class="ltx_tr">
<td id="S2.T2.1.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S2.T2.1.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.1.1.2.1.1" class="ltx_tr">
<td id="S2.T2.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Individual Fairness</td>
</tr>
<tr id="S2.T2.1.1.2.1.2" class="ltx_tr">
<td id="S2.T2.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Dwork et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2012</a>)</cite></td>
</tr>
</table>
</td>
<td id="S2.T2.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><math id="S2.T2.1.1.1.m1.6" class="ltx_Math" alttext="D(M(x),M(y))\leq d(x,y)" display="inline"><semantics id="S2.T2.1.1.1.m1.6a"><mrow id="S2.T2.1.1.1.m1.6.6" xref="S2.T2.1.1.1.m1.6.6.cmml"><mrow id="S2.T2.1.1.1.m1.6.6.2" xref="S2.T2.1.1.1.m1.6.6.2.cmml"><mi id="S2.T2.1.1.1.m1.6.6.2.4" xref="S2.T2.1.1.1.m1.6.6.2.4.cmml">D</mi><mo lspace="0em" rspace="0em" id="S2.T2.1.1.1.m1.6.6.2.3" xref="S2.T2.1.1.1.m1.6.6.2.3.cmml">​</mo><mrow id="S2.T2.1.1.1.m1.6.6.2.2.2" xref="S2.T2.1.1.1.m1.6.6.2.2.3.cmml"><mo stretchy="false" id="S2.T2.1.1.1.m1.6.6.2.2.2.3" xref="S2.T2.1.1.1.m1.6.6.2.2.3.cmml">(</mo><mrow id="S2.T2.1.1.1.m1.5.5.1.1.1.1" xref="S2.T2.1.1.1.m1.5.5.1.1.1.1.cmml"><mi id="S2.T2.1.1.1.m1.5.5.1.1.1.1.2" xref="S2.T2.1.1.1.m1.5.5.1.1.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.T2.1.1.1.m1.5.5.1.1.1.1.1" xref="S2.T2.1.1.1.m1.5.5.1.1.1.1.1.cmml">​</mo><mrow id="S2.T2.1.1.1.m1.5.5.1.1.1.1.3.2" xref="S2.T2.1.1.1.m1.5.5.1.1.1.1.cmml"><mo stretchy="false" id="S2.T2.1.1.1.m1.5.5.1.1.1.1.3.2.1" xref="S2.T2.1.1.1.m1.5.5.1.1.1.1.cmml">(</mo><mi id="S2.T2.1.1.1.m1.1.1" xref="S2.T2.1.1.1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S2.T2.1.1.1.m1.5.5.1.1.1.1.3.2.2" xref="S2.T2.1.1.1.m1.5.5.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.T2.1.1.1.m1.6.6.2.2.2.4" xref="S2.T2.1.1.1.m1.6.6.2.2.3.cmml">,</mo><mrow id="S2.T2.1.1.1.m1.6.6.2.2.2.2" xref="S2.T2.1.1.1.m1.6.6.2.2.2.2.cmml"><mi id="S2.T2.1.1.1.m1.6.6.2.2.2.2.2" xref="S2.T2.1.1.1.m1.6.6.2.2.2.2.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.T2.1.1.1.m1.6.6.2.2.2.2.1" xref="S2.T2.1.1.1.m1.6.6.2.2.2.2.1.cmml">​</mo><mrow id="S2.T2.1.1.1.m1.6.6.2.2.2.2.3.2" xref="S2.T2.1.1.1.m1.6.6.2.2.2.2.cmml"><mo stretchy="false" id="S2.T2.1.1.1.m1.6.6.2.2.2.2.3.2.1" xref="S2.T2.1.1.1.m1.6.6.2.2.2.2.cmml">(</mo><mi id="S2.T2.1.1.1.m1.2.2" xref="S2.T2.1.1.1.m1.2.2.cmml">y</mi><mo stretchy="false" id="S2.T2.1.1.1.m1.6.6.2.2.2.2.3.2.2" xref="S2.T2.1.1.1.m1.6.6.2.2.2.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.T2.1.1.1.m1.6.6.2.2.2.5" xref="S2.T2.1.1.1.m1.6.6.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.T2.1.1.1.m1.6.6.3" xref="S2.T2.1.1.1.m1.6.6.3.cmml">≤</mo><mrow id="S2.T2.1.1.1.m1.6.6.4" xref="S2.T2.1.1.1.m1.6.6.4.cmml"><mi id="S2.T2.1.1.1.m1.6.6.4.2" xref="S2.T2.1.1.1.m1.6.6.4.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.T2.1.1.1.m1.6.6.4.1" xref="S2.T2.1.1.1.m1.6.6.4.1.cmml">​</mo><mrow id="S2.T2.1.1.1.m1.6.6.4.3.2" xref="S2.T2.1.1.1.m1.6.6.4.3.1.cmml"><mo stretchy="false" id="S2.T2.1.1.1.m1.6.6.4.3.2.1" xref="S2.T2.1.1.1.m1.6.6.4.3.1.cmml">(</mo><mi id="S2.T2.1.1.1.m1.3.3" xref="S2.T2.1.1.1.m1.3.3.cmml">x</mi><mo id="S2.T2.1.1.1.m1.6.6.4.3.2.2" xref="S2.T2.1.1.1.m1.6.6.4.3.1.cmml">,</mo><mi id="S2.T2.1.1.1.m1.4.4" xref="S2.T2.1.1.1.m1.4.4.cmml">y</mi><mo stretchy="false" id="S2.T2.1.1.1.m1.6.6.4.3.2.3" xref="S2.T2.1.1.1.m1.6.6.4.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.1.1.1.m1.6b"><apply id="S2.T2.1.1.1.m1.6.6.cmml" xref="S2.T2.1.1.1.m1.6.6"><leq id="S2.T2.1.1.1.m1.6.6.3.cmml" xref="S2.T2.1.1.1.m1.6.6.3"></leq><apply id="S2.T2.1.1.1.m1.6.6.2.cmml" xref="S2.T2.1.1.1.m1.6.6.2"><times id="S2.T2.1.1.1.m1.6.6.2.3.cmml" xref="S2.T2.1.1.1.m1.6.6.2.3"></times><ci id="S2.T2.1.1.1.m1.6.6.2.4.cmml" xref="S2.T2.1.1.1.m1.6.6.2.4">𝐷</ci><interval closure="open" id="S2.T2.1.1.1.m1.6.6.2.2.3.cmml" xref="S2.T2.1.1.1.m1.6.6.2.2.2"><apply id="S2.T2.1.1.1.m1.5.5.1.1.1.1.cmml" xref="S2.T2.1.1.1.m1.5.5.1.1.1.1"><times id="S2.T2.1.1.1.m1.5.5.1.1.1.1.1.cmml" xref="S2.T2.1.1.1.m1.5.5.1.1.1.1.1"></times><ci id="S2.T2.1.1.1.m1.5.5.1.1.1.1.2.cmml" xref="S2.T2.1.1.1.m1.5.5.1.1.1.1.2">𝑀</ci><ci id="S2.T2.1.1.1.m1.1.1.cmml" xref="S2.T2.1.1.1.m1.1.1">𝑥</ci></apply><apply id="S2.T2.1.1.1.m1.6.6.2.2.2.2.cmml" xref="S2.T2.1.1.1.m1.6.6.2.2.2.2"><times id="S2.T2.1.1.1.m1.6.6.2.2.2.2.1.cmml" xref="S2.T2.1.1.1.m1.6.6.2.2.2.2.1"></times><ci id="S2.T2.1.1.1.m1.6.6.2.2.2.2.2.cmml" xref="S2.T2.1.1.1.m1.6.6.2.2.2.2.2">𝑀</ci><ci id="S2.T2.1.1.1.m1.2.2.cmml" xref="S2.T2.1.1.1.m1.2.2">𝑦</ci></apply></interval></apply><apply id="S2.T2.1.1.1.m1.6.6.4.cmml" xref="S2.T2.1.1.1.m1.6.6.4"><times id="S2.T2.1.1.1.m1.6.6.4.1.cmml" xref="S2.T2.1.1.1.m1.6.6.4.1"></times><ci id="S2.T2.1.1.1.m1.6.6.4.2.cmml" xref="S2.T2.1.1.1.m1.6.6.4.2">𝑑</ci><interval closure="open" id="S2.T2.1.1.1.m1.6.6.4.3.1.cmml" xref="S2.T2.1.1.1.m1.6.6.4.3.2"><ci id="S2.T2.1.1.1.m1.3.3.cmml" xref="S2.T2.1.1.1.m1.3.3">𝑥</ci><ci id="S2.T2.1.1.1.m1.4.4.cmml" xref="S2.T2.1.1.1.m1.4.4">𝑦</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.1.1.1.m1.6c">D(M(x),M(y))\leq d(x,y)</annotation></semantics></math></td>
<td id="S2.T2.1.1.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S2.T2.1.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.1.1.3.1.1" class="ltx_tr">
<td id="S2.T2.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Similar samples receive</td>
</tr>
<tr id="S2.T2.1.1.3.1.2" class="ltx_tr">
<td id="S2.T2.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">similar treatment</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.2.2" class="ltx_tr">
<td id="S2.T2.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S2.T2.2.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.2.2.2.1.1" class="ltx_tr">
<td id="S2.T2.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Eqal Opportunity</td>
</tr>
<tr id="S2.T2.2.2.2.1.2" class="ltx_tr">
<td id="S2.T2.2.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Hardt
et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2016</a>)</cite></td>
</tr>
</table>
</td>
<td id="S2.T2.2.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><math id="S2.T2.2.2.1.m1.6" class="ltx_Math" alttext="\Pr[\hat{Y}=1|A=0,Y=1]=\Pr[\hat{Y}=1|A=1,Y=1]" display="inline"><semantics id="S2.T2.2.2.1.m1.6a"><mrow id="S2.T2.2.2.1.m1.6.6" xref="S2.T2.2.2.1.m1.6.6.cmml"><mrow id="S2.T2.2.2.1.m1.4.4.2.2" xref="S2.T2.2.2.1.m1.4.4.2.3.cmml"><mi id="S2.T2.2.2.1.m1.1.1" xref="S2.T2.2.2.1.m1.1.1.cmml">Pr</mi><mo id="S2.T2.2.2.1.m1.4.4.2.2a" xref="S2.T2.2.2.1.m1.4.4.2.3.cmml">⁡</mo><mrow id="S2.T2.2.2.1.m1.4.4.2.2.2" xref="S2.T2.2.2.1.m1.4.4.2.3.cmml"><mo stretchy="false" id="S2.T2.2.2.1.m1.4.4.2.2.2.3" xref="S2.T2.2.2.1.m1.4.4.2.3.cmml">[</mo><mrow id="S2.T2.2.2.1.m1.3.3.1.1.1.1" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.cmml"><mover accent="true" id="S2.T2.2.2.1.m1.3.3.1.1.1.1.2" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.2.cmml"><mi id="S2.T2.2.2.1.m1.3.3.1.1.1.1.2.2" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.2.2.cmml">Y</mi><mo id="S2.T2.2.2.1.m1.3.3.1.1.1.1.2.1" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.2.1.cmml">^</mo></mover><mo id="S2.T2.2.2.1.m1.3.3.1.1.1.1.3" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.3.cmml">=</mo><mrow id="S2.T2.2.2.1.m1.3.3.1.1.1.1.4" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.4.cmml"><mn id="S2.T2.2.2.1.m1.3.3.1.1.1.1.4.2" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.4.2.cmml">1</mn><mo fence="false" id="S2.T2.2.2.1.m1.3.3.1.1.1.1.4.1" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.4.1.cmml">|</mo><mi id="S2.T2.2.2.1.m1.3.3.1.1.1.1.4.3" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.4.3.cmml">A</mi></mrow><mo id="S2.T2.2.2.1.m1.3.3.1.1.1.1.5" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.5.cmml">=</mo><mn id="S2.T2.2.2.1.m1.3.3.1.1.1.1.6" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.6.cmml">0</mn></mrow><mo id="S2.T2.2.2.1.m1.4.4.2.2.2.4" xref="S2.T2.2.2.1.m1.4.4.2.3.cmml">,</mo><mrow id="S2.T2.2.2.1.m1.4.4.2.2.2.2" xref="S2.T2.2.2.1.m1.4.4.2.2.2.2.cmml"><mi id="S2.T2.2.2.1.m1.4.4.2.2.2.2.2" xref="S2.T2.2.2.1.m1.4.4.2.2.2.2.2.cmml">Y</mi><mo id="S2.T2.2.2.1.m1.4.4.2.2.2.2.1" xref="S2.T2.2.2.1.m1.4.4.2.2.2.2.1.cmml">=</mo><mn id="S2.T2.2.2.1.m1.4.4.2.2.2.2.3" xref="S2.T2.2.2.1.m1.4.4.2.2.2.2.3.cmml">1</mn></mrow><mo stretchy="false" id="S2.T2.2.2.1.m1.4.4.2.2.2.5" xref="S2.T2.2.2.1.m1.4.4.2.3.cmml">]</mo></mrow></mrow><mo id="S2.T2.2.2.1.m1.6.6.5" xref="S2.T2.2.2.1.m1.6.6.5.cmml">=</mo><mrow id="S2.T2.2.2.1.m1.6.6.4.2" xref="S2.T2.2.2.1.m1.6.6.4.3.cmml"><mi id="S2.T2.2.2.1.m1.2.2" xref="S2.T2.2.2.1.m1.2.2.cmml">Pr</mi><mo id="S2.T2.2.2.1.m1.6.6.4.2a" xref="S2.T2.2.2.1.m1.6.6.4.3.cmml">⁡</mo><mrow id="S2.T2.2.2.1.m1.6.6.4.2.2" xref="S2.T2.2.2.1.m1.6.6.4.3.cmml"><mo stretchy="false" id="S2.T2.2.2.1.m1.6.6.4.2.2.3" xref="S2.T2.2.2.1.m1.6.6.4.3.cmml">[</mo><mrow id="S2.T2.2.2.1.m1.5.5.3.1.1.1" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.cmml"><mover accent="true" id="S2.T2.2.2.1.m1.5.5.3.1.1.1.2" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.2.cmml"><mi id="S2.T2.2.2.1.m1.5.5.3.1.1.1.2.2" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.2.2.cmml">Y</mi><mo id="S2.T2.2.2.1.m1.5.5.3.1.1.1.2.1" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.2.1.cmml">^</mo></mover><mo id="S2.T2.2.2.1.m1.5.5.3.1.1.1.3" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.3.cmml">=</mo><mrow id="S2.T2.2.2.1.m1.5.5.3.1.1.1.4" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.4.cmml"><mn id="S2.T2.2.2.1.m1.5.5.3.1.1.1.4.2" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.4.2.cmml">1</mn><mo fence="false" id="S2.T2.2.2.1.m1.5.5.3.1.1.1.4.1" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.4.1.cmml">|</mo><mi id="S2.T2.2.2.1.m1.5.5.3.1.1.1.4.3" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.4.3.cmml">A</mi></mrow><mo id="S2.T2.2.2.1.m1.5.5.3.1.1.1.5" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.5.cmml">=</mo><mn id="S2.T2.2.2.1.m1.5.5.3.1.1.1.6" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.6.cmml">1</mn></mrow><mo id="S2.T2.2.2.1.m1.6.6.4.2.2.4" xref="S2.T2.2.2.1.m1.6.6.4.3.cmml">,</mo><mrow id="S2.T2.2.2.1.m1.6.6.4.2.2.2" xref="S2.T2.2.2.1.m1.6.6.4.2.2.2.cmml"><mi id="S2.T2.2.2.1.m1.6.6.4.2.2.2.2" xref="S2.T2.2.2.1.m1.6.6.4.2.2.2.2.cmml">Y</mi><mo id="S2.T2.2.2.1.m1.6.6.4.2.2.2.1" xref="S2.T2.2.2.1.m1.6.6.4.2.2.2.1.cmml">=</mo><mn id="S2.T2.2.2.1.m1.6.6.4.2.2.2.3" xref="S2.T2.2.2.1.m1.6.6.4.2.2.2.3.cmml">1</mn></mrow><mo stretchy="false" id="S2.T2.2.2.1.m1.6.6.4.2.2.5" xref="S2.T2.2.2.1.m1.6.6.4.3.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.2.2.1.m1.6b"><apply id="S2.T2.2.2.1.m1.6.6.cmml" xref="S2.T2.2.2.1.m1.6.6"><eq id="S2.T2.2.2.1.m1.6.6.5.cmml" xref="S2.T2.2.2.1.m1.6.6.5"></eq><apply id="S2.T2.2.2.1.m1.4.4.2.3.cmml" xref="S2.T2.2.2.1.m1.4.4.2.2"><ci id="S2.T2.2.2.1.m1.1.1.cmml" xref="S2.T2.2.2.1.m1.1.1">Pr</ci><apply id="S2.T2.2.2.1.m1.3.3.1.1.1.1.cmml" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1"><and id="S2.T2.2.2.1.m1.3.3.1.1.1.1a.cmml" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1"></and><apply id="S2.T2.2.2.1.m1.3.3.1.1.1.1b.cmml" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1"><eq id="S2.T2.2.2.1.m1.3.3.1.1.1.1.3.cmml" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.3"></eq><apply id="S2.T2.2.2.1.m1.3.3.1.1.1.1.2.cmml" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.2"><ci id="S2.T2.2.2.1.m1.3.3.1.1.1.1.2.1.cmml" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.2.1">^</ci><ci id="S2.T2.2.2.1.m1.3.3.1.1.1.1.2.2.cmml" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.2.2">𝑌</ci></apply><apply id="S2.T2.2.2.1.m1.3.3.1.1.1.1.4.cmml" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.4"><csymbol cd="latexml" id="S2.T2.2.2.1.m1.3.3.1.1.1.1.4.1.cmml" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.4.1">conditional</csymbol><cn type="integer" id="S2.T2.2.2.1.m1.3.3.1.1.1.1.4.2.cmml" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.4.2">1</cn><ci id="S2.T2.2.2.1.m1.3.3.1.1.1.1.4.3.cmml" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.4.3">𝐴</ci></apply></apply><apply id="S2.T2.2.2.1.m1.3.3.1.1.1.1c.cmml" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1"><eq id="S2.T2.2.2.1.m1.3.3.1.1.1.1.5.cmml" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.5"></eq><share href="#S2.T2.2.2.1.m1.3.3.1.1.1.1.4.cmml" id="S2.T2.2.2.1.m1.3.3.1.1.1.1d.cmml" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1"></share><cn type="integer" id="S2.T2.2.2.1.m1.3.3.1.1.1.1.6.cmml" xref="S2.T2.2.2.1.m1.3.3.1.1.1.1.6">0</cn></apply></apply><apply id="S2.T2.2.2.1.m1.4.4.2.2.2.2.cmml" xref="S2.T2.2.2.1.m1.4.4.2.2.2.2"><eq id="S2.T2.2.2.1.m1.4.4.2.2.2.2.1.cmml" xref="S2.T2.2.2.1.m1.4.4.2.2.2.2.1"></eq><ci id="S2.T2.2.2.1.m1.4.4.2.2.2.2.2.cmml" xref="S2.T2.2.2.1.m1.4.4.2.2.2.2.2">𝑌</ci><cn type="integer" id="S2.T2.2.2.1.m1.4.4.2.2.2.2.3.cmml" xref="S2.T2.2.2.1.m1.4.4.2.2.2.2.3">1</cn></apply></apply><apply id="S2.T2.2.2.1.m1.6.6.4.3.cmml" xref="S2.T2.2.2.1.m1.6.6.4.2"><ci id="S2.T2.2.2.1.m1.2.2.cmml" xref="S2.T2.2.2.1.m1.2.2">Pr</ci><apply id="S2.T2.2.2.1.m1.5.5.3.1.1.1.cmml" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1"><and id="S2.T2.2.2.1.m1.5.5.3.1.1.1a.cmml" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1"></and><apply id="S2.T2.2.2.1.m1.5.5.3.1.1.1b.cmml" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1"><eq id="S2.T2.2.2.1.m1.5.5.3.1.1.1.3.cmml" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.3"></eq><apply id="S2.T2.2.2.1.m1.5.5.3.1.1.1.2.cmml" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.2"><ci id="S2.T2.2.2.1.m1.5.5.3.1.1.1.2.1.cmml" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.2.1">^</ci><ci id="S2.T2.2.2.1.m1.5.5.3.1.1.1.2.2.cmml" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.2.2">𝑌</ci></apply><apply id="S2.T2.2.2.1.m1.5.5.3.1.1.1.4.cmml" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.4"><csymbol cd="latexml" id="S2.T2.2.2.1.m1.5.5.3.1.1.1.4.1.cmml" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.4.1">conditional</csymbol><cn type="integer" id="S2.T2.2.2.1.m1.5.5.3.1.1.1.4.2.cmml" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.4.2">1</cn><ci id="S2.T2.2.2.1.m1.5.5.3.1.1.1.4.3.cmml" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.4.3">𝐴</ci></apply></apply><apply id="S2.T2.2.2.1.m1.5.5.3.1.1.1c.cmml" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1"><eq id="S2.T2.2.2.1.m1.5.5.3.1.1.1.5.cmml" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.5"></eq><share href="#S2.T2.2.2.1.m1.5.5.3.1.1.1.4.cmml" id="S2.T2.2.2.1.m1.5.5.3.1.1.1d.cmml" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1"></share><cn type="integer" id="S2.T2.2.2.1.m1.5.5.3.1.1.1.6.cmml" xref="S2.T2.2.2.1.m1.5.5.3.1.1.1.6">1</cn></apply></apply><apply id="S2.T2.2.2.1.m1.6.6.4.2.2.2.cmml" xref="S2.T2.2.2.1.m1.6.6.4.2.2.2"><eq id="S2.T2.2.2.1.m1.6.6.4.2.2.2.1.cmml" xref="S2.T2.2.2.1.m1.6.6.4.2.2.2.1"></eq><ci id="S2.T2.2.2.1.m1.6.6.4.2.2.2.2.cmml" xref="S2.T2.2.2.1.m1.6.6.4.2.2.2.2">𝑌</ci><cn type="integer" id="S2.T2.2.2.1.m1.6.6.4.2.2.2.3.cmml" xref="S2.T2.2.2.1.m1.6.6.4.2.2.2.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.2.2.1.m1.6c">\Pr[\hat{Y}=1|A=0,Y=1]=\Pr[\hat{Y}=1|A=1,Y=1]</annotation></semantics></math></td>
<td id="S2.T2.2.2.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S2.T2.2.2.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.2.2.3.1.1" class="ltx_tr">
<td id="S2.T2.2.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Equal true positive rates</td>
</tr>
<tr id="S2.T2.2.2.3.1.2" class="ltx_tr">
<td id="S2.T2.2.2.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">for protected/unprotected</td>
</tr>
<tr id="S2.T2.2.2.3.1.3" class="ltx_tr">
<td id="S2.T2.2.2.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">groups</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.3.3" class="ltx_tr">
<td id="S2.T2.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S2.T2.3.3.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.3.3.2.1.1" class="ltx_tr">
<td id="S2.T2.3.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Equal Accuracy</td>
</tr>
<tr id="S2.T2.3.3.2.1.2" class="ltx_tr">
<td id="S2.T2.3.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Berk
et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021b</a>)</cite></td>
</tr>
</table>
</td>
<td id="S2.T2.3.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><math id="S2.T2.3.3.1.m1.4" class="ltx_Math" alttext="\Pr[\hat{Y}=Y|A=0]=\Pr[\hat{Y}=Y|A=1]" display="inline"><semantics id="S2.T2.3.3.1.m1.4a"><mrow id="S2.T2.3.3.1.m1.4.4" xref="S2.T2.3.3.1.m1.4.4.cmml"><mrow id="S2.T2.3.3.1.m1.3.3.1.1" xref="S2.T2.3.3.1.m1.3.3.1.2.cmml"><mi id="S2.T2.3.3.1.m1.1.1" xref="S2.T2.3.3.1.m1.1.1.cmml">Pr</mi><mo id="S2.T2.3.3.1.m1.3.3.1.1a" xref="S2.T2.3.3.1.m1.3.3.1.2.cmml">⁡</mo><mrow id="S2.T2.3.3.1.m1.3.3.1.1.1" xref="S2.T2.3.3.1.m1.3.3.1.2.cmml"><mo stretchy="false" id="S2.T2.3.3.1.m1.3.3.1.1.1.2" xref="S2.T2.3.3.1.m1.3.3.1.2.cmml">[</mo><mrow id="S2.T2.3.3.1.m1.3.3.1.1.1.1" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.cmml"><mover accent="true" id="S2.T2.3.3.1.m1.3.3.1.1.1.1.2" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.2.cmml"><mi id="S2.T2.3.3.1.m1.3.3.1.1.1.1.2.2" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.2.2.cmml">Y</mi><mo id="S2.T2.3.3.1.m1.3.3.1.1.1.1.2.1" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.2.1.cmml">^</mo></mover><mo id="S2.T2.3.3.1.m1.3.3.1.1.1.1.3" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.3.cmml">=</mo><mrow id="S2.T2.3.3.1.m1.3.3.1.1.1.1.4" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.4.cmml"><mi id="S2.T2.3.3.1.m1.3.3.1.1.1.1.4.2" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.4.2.cmml">Y</mi><mo fence="false" id="S2.T2.3.3.1.m1.3.3.1.1.1.1.4.1" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.4.1.cmml">|</mo><mi id="S2.T2.3.3.1.m1.3.3.1.1.1.1.4.3" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.4.3.cmml">A</mi></mrow><mo id="S2.T2.3.3.1.m1.3.3.1.1.1.1.5" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.5.cmml">=</mo><mn id="S2.T2.3.3.1.m1.3.3.1.1.1.1.6" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.6.cmml">0</mn></mrow><mo stretchy="false" id="S2.T2.3.3.1.m1.3.3.1.1.1.3" xref="S2.T2.3.3.1.m1.3.3.1.2.cmml">]</mo></mrow></mrow><mo id="S2.T2.3.3.1.m1.4.4.3" xref="S2.T2.3.3.1.m1.4.4.3.cmml">=</mo><mrow id="S2.T2.3.3.1.m1.4.4.2.1" xref="S2.T2.3.3.1.m1.4.4.2.2.cmml"><mi id="S2.T2.3.3.1.m1.2.2" xref="S2.T2.3.3.1.m1.2.2.cmml">Pr</mi><mo id="S2.T2.3.3.1.m1.4.4.2.1a" xref="S2.T2.3.3.1.m1.4.4.2.2.cmml">⁡</mo><mrow id="S2.T2.3.3.1.m1.4.4.2.1.1" xref="S2.T2.3.3.1.m1.4.4.2.2.cmml"><mo stretchy="false" id="S2.T2.3.3.1.m1.4.4.2.1.1.2" xref="S2.T2.3.3.1.m1.4.4.2.2.cmml">[</mo><mrow id="S2.T2.3.3.1.m1.4.4.2.1.1.1" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.cmml"><mover accent="true" id="S2.T2.3.3.1.m1.4.4.2.1.1.1.2" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.2.cmml"><mi id="S2.T2.3.3.1.m1.4.4.2.1.1.1.2.2" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.2.2.cmml">Y</mi><mo id="S2.T2.3.3.1.m1.4.4.2.1.1.1.2.1" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.2.1.cmml">^</mo></mover><mo id="S2.T2.3.3.1.m1.4.4.2.1.1.1.3" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.3.cmml">=</mo><mrow id="S2.T2.3.3.1.m1.4.4.2.1.1.1.4" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.4.cmml"><mi id="S2.T2.3.3.1.m1.4.4.2.1.1.1.4.2" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.4.2.cmml">Y</mi><mo fence="false" id="S2.T2.3.3.1.m1.4.4.2.1.1.1.4.1" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.4.1.cmml">|</mo><mi id="S2.T2.3.3.1.m1.4.4.2.1.1.1.4.3" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.4.3.cmml">A</mi></mrow><mo id="S2.T2.3.3.1.m1.4.4.2.1.1.1.5" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.5.cmml">=</mo><mn id="S2.T2.3.3.1.m1.4.4.2.1.1.1.6" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.6.cmml">1</mn></mrow><mo stretchy="false" id="S2.T2.3.3.1.m1.4.4.2.1.1.3" xref="S2.T2.3.3.1.m1.4.4.2.2.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.3.3.1.m1.4b"><apply id="S2.T2.3.3.1.m1.4.4.cmml" xref="S2.T2.3.3.1.m1.4.4"><eq id="S2.T2.3.3.1.m1.4.4.3.cmml" xref="S2.T2.3.3.1.m1.4.4.3"></eq><apply id="S2.T2.3.3.1.m1.3.3.1.2.cmml" xref="S2.T2.3.3.1.m1.3.3.1.1"><ci id="S2.T2.3.3.1.m1.1.1.cmml" xref="S2.T2.3.3.1.m1.1.1">Pr</ci><apply id="S2.T2.3.3.1.m1.3.3.1.1.1.1.cmml" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1"><and id="S2.T2.3.3.1.m1.3.3.1.1.1.1a.cmml" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1"></and><apply id="S2.T2.3.3.1.m1.3.3.1.1.1.1b.cmml" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1"><eq id="S2.T2.3.3.1.m1.3.3.1.1.1.1.3.cmml" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.3"></eq><apply id="S2.T2.3.3.1.m1.3.3.1.1.1.1.2.cmml" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.2"><ci id="S2.T2.3.3.1.m1.3.3.1.1.1.1.2.1.cmml" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.2.1">^</ci><ci id="S2.T2.3.3.1.m1.3.3.1.1.1.1.2.2.cmml" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.2.2">𝑌</ci></apply><apply id="S2.T2.3.3.1.m1.3.3.1.1.1.1.4.cmml" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.4"><csymbol cd="latexml" id="S2.T2.3.3.1.m1.3.3.1.1.1.1.4.1.cmml" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.4.1">conditional</csymbol><ci id="S2.T2.3.3.1.m1.3.3.1.1.1.1.4.2.cmml" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.4.2">𝑌</ci><ci id="S2.T2.3.3.1.m1.3.3.1.1.1.1.4.3.cmml" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.4.3">𝐴</ci></apply></apply><apply id="S2.T2.3.3.1.m1.3.3.1.1.1.1c.cmml" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1"><eq id="S2.T2.3.3.1.m1.3.3.1.1.1.1.5.cmml" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.5"></eq><share href="#S2.T2.3.3.1.m1.3.3.1.1.1.1.4.cmml" id="S2.T2.3.3.1.m1.3.3.1.1.1.1d.cmml" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1"></share><cn type="integer" id="S2.T2.3.3.1.m1.3.3.1.1.1.1.6.cmml" xref="S2.T2.3.3.1.m1.3.3.1.1.1.1.6">0</cn></apply></apply></apply><apply id="S2.T2.3.3.1.m1.4.4.2.2.cmml" xref="S2.T2.3.3.1.m1.4.4.2.1"><ci id="S2.T2.3.3.1.m1.2.2.cmml" xref="S2.T2.3.3.1.m1.2.2">Pr</ci><apply id="S2.T2.3.3.1.m1.4.4.2.1.1.1.cmml" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1"><and id="S2.T2.3.3.1.m1.4.4.2.1.1.1a.cmml" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1"></and><apply id="S2.T2.3.3.1.m1.4.4.2.1.1.1b.cmml" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1"><eq id="S2.T2.3.3.1.m1.4.4.2.1.1.1.3.cmml" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.3"></eq><apply id="S2.T2.3.3.1.m1.4.4.2.1.1.1.2.cmml" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.2"><ci id="S2.T2.3.3.1.m1.4.4.2.1.1.1.2.1.cmml" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.2.1">^</ci><ci id="S2.T2.3.3.1.m1.4.4.2.1.1.1.2.2.cmml" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.2.2">𝑌</ci></apply><apply id="S2.T2.3.3.1.m1.4.4.2.1.1.1.4.cmml" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.4"><csymbol cd="latexml" id="S2.T2.3.3.1.m1.4.4.2.1.1.1.4.1.cmml" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.4.1">conditional</csymbol><ci id="S2.T2.3.3.1.m1.4.4.2.1.1.1.4.2.cmml" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.4.2">𝑌</ci><ci id="S2.T2.3.3.1.m1.4.4.2.1.1.1.4.3.cmml" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.4.3">𝐴</ci></apply></apply><apply id="S2.T2.3.3.1.m1.4.4.2.1.1.1c.cmml" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1"><eq id="S2.T2.3.3.1.m1.4.4.2.1.1.1.5.cmml" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.5"></eq><share href="#S2.T2.3.3.1.m1.4.4.2.1.1.1.4.cmml" id="S2.T2.3.3.1.m1.4.4.2.1.1.1d.cmml" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1"></share><cn type="integer" id="S2.T2.3.3.1.m1.4.4.2.1.1.1.6.cmml" xref="S2.T2.3.3.1.m1.4.4.2.1.1.1.6">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.3.3.1.m1.4c">\Pr[\hat{Y}=Y|A=0]=\Pr[\hat{Y}=Y|A=1]</annotation></semantics></math></td>
<td id="S2.T2.3.3.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S2.T2.3.3.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.3.3.3.1.1" class="ltx_tr">
<td id="S2.T2.3.3.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Equal prediction accuracy</td>
</tr>
<tr id="S2.T2.3.3.3.1.2" class="ltx_tr">
<td id="S2.T2.3.3.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">for protected/unprotected</td>
</tr>
<tr id="S2.T2.3.3.3.1.3" class="ltx_tr">
<td id="S2.T2.3.3.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">groups</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.5.5" class="ltx_tr">
<td id="S2.T2.5.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S2.T2.5.5.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.5.5.3.1.1" class="ltx_tr">
<td id="S2.T2.5.5.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Equalized Odds</td>
</tr>
<tr id="S2.T2.5.5.3.1.2" class="ltx_tr">
<td id="S2.T2.5.5.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Hardt
et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2016</a>)</cite></td>
</tr>
</table>
</td>
<td id="S2.T2.5.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S2.T2.5.5.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.4.1.1.1" class="ltx_tr">
<td id="S2.T2.4.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><math id="S2.T2.4.4.1.1.1.1.m1.3" class="ltx_Math" alttext="\Pr[\hat{Y}=1|A=1,Y=y]=\Pr[\hat{Y}=1|A=0,Y=y]," display="inline"><semantics id="S2.T2.4.4.1.1.1.1.m1.3a"><mrow id="S2.T2.4.4.1.1.1.1.m1.3.3.1" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.cmml"><mrow id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.cmml"><mrow id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.3.cmml"><mi id="S2.T2.4.4.1.1.1.1.m1.1.1" xref="S2.T2.4.4.1.1.1.1.m1.1.1.cmml">Pr</mi><mo id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2a" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.3.cmml">⁡</mo><mrow id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.3.cmml"><mo stretchy="false" id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.3" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.3.cmml">[</mo><mrow id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.cmml"><mover accent="true" id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.2" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.2.cmml"><mi id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.2.2" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.2.2.cmml">Y</mi><mo id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.2.1" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.2.1.cmml">^</mo></mover><mo id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.3" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.3.cmml">=</mo><mrow id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.4" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.4.cmml"><mn id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.4.2" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.4.2.cmml">1</mn><mo fence="false" id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.4.1" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.4.1.cmml">|</mo><mi id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.4.3" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.4.3.cmml">A</mi></mrow><mo id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.5" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.5.cmml">=</mo><mn id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.6" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.6.cmml">1</mn></mrow><mo id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.4" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.3.cmml">,</mo><mrow id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.2" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.2.cmml"><mi id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.2.2" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.2.2.cmml">Y</mi><mo id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.2.1" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.2.1.cmml">=</mo><mi id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.2.3" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.2.3.cmml">y</mi></mrow><mo stretchy="false" id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.5" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.3.cmml">]</mo></mrow></mrow><mo id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.5" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.5.cmml">=</mo><mrow id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.3.cmml"><mi id="S2.T2.4.4.1.1.1.1.m1.2.2" xref="S2.T2.4.4.1.1.1.1.m1.2.2.cmml">Pr</mi><mo id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2a" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.3.cmml">⁡</mo><mrow id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.3.cmml"><mo stretchy="false" id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.3" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.3.cmml">[</mo><mrow id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.cmml"><mover accent="true" id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.2" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.2.cmml"><mi id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.2.2" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.2.2.cmml">Y</mi><mo id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.2.1" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.2.1.cmml">^</mo></mover><mo id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.3" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.3.cmml">=</mo><mrow id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.4" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.4.cmml"><mn id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.4.2" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.4.2.cmml">1</mn><mo fence="false" id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.4.1" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.4.1.cmml">|</mo><mi id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.4.3" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.4.3.cmml">A</mi></mrow><mo id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.5" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.5.cmml">=</mo><mn id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.6" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.6.cmml">0</mn></mrow><mo id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.4" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.3.cmml">,</mo><mrow id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.2" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.2.cmml"><mi id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.2.2" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.2.2.cmml">Y</mi><mo id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.2.1" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.2.1.cmml">=</mo><mi id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.2.3" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.2.3.cmml">y</mi></mrow><mo stretchy="false" id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.5" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.3.cmml">]</mo></mrow></mrow></mrow><mo id="S2.T2.4.4.1.1.1.1.m1.3.3.1.2" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.4.4.1.1.1.1.m1.3b"><apply id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1"><eq id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.5.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.5"></eq><apply id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.3.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2"><ci id="S2.T2.4.4.1.1.1.1.m1.1.1.cmml" xref="S2.T2.4.4.1.1.1.1.m1.1.1">Pr</ci><apply id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1"><and id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1a.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1"></and><apply id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1b.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1"><eq id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.3"></eq><apply id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.2"><ci id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.2.1.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.2.1">^</ci><ci id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.2.2.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.2.2">𝑌</ci></apply><apply id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.4.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.4"><csymbol cd="latexml" id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.4.1.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.4.1">conditional</csymbol><cn type="integer" id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.4.2.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.4.2">1</cn><ci id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.4.3.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.4.3">𝐴</ci></apply></apply><apply id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1c.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1"><eq id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.5.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.5"></eq><share href="#S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.4.cmml" id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1d.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1"></share><cn type="integer" id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.6.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.1.1.1.1.6">1</cn></apply></apply><apply id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.2.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.2"><eq id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.2.1.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.2.1"></eq><ci id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.2.2.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.2.2">𝑌</ci><ci id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.2.3.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.2.2.2.2.3">𝑦</ci></apply></apply><apply id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.3.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2"><ci id="S2.T2.4.4.1.1.1.1.m1.2.2.cmml" xref="S2.T2.4.4.1.1.1.1.m1.2.2">Pr</ci><apply id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1"><and id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1a.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1"></and><apply id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1b.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1"><eq id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.3.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.3"></eq><apply id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.2.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.2"><ci id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.2.1.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.2.1">^</ci><ci id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.2.2.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.2.2">𝑌</ci></apply><apply id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.4.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.4"><csymbol cd="latexml" id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.4.1.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.4.1">conditional</csymbol><cn type="integer" id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.4.2.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.4.2">1</cn><ci id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.4.3.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.4.3">𝐴</ci></apply></apply><apply id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1c.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1"><eq id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.5.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.5"></eq><share href="#S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.4.cmml" id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1d.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1"></share><cn type="integer" id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.6.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.3.1.1.1.6">0</cn></apply></apply><apply id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.2.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.2"><eq id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.2.1.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.2.1"></eq><ci id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.2.2.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.2.2">𝑌</ci><ci id="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.2.3.cmml" xref="S2.T2.4.4.1.1.1.1.m1.3.3.1.1.4.2.2.2.3">𝑦</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.4.4.1.1.1.1.m1.3c">\Pr[\hat{Y}=1|A=1,Y=y]=\Pr[\hat{Y}=1|A=0,Y=y],</annotation></semantics></math></td>
</tr>
<tr id="S2.T2.5.5.2.2.2" class="ltx_tr">
<td id="S2.T2.5.5.2.2.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><math id="S2.T2.5.5.2.2.2.1.m1.2" class="ltx_Math" alttext="y\in\{0,1\}" display="inline"><semantics id="S2.T2.5.5.2.2.2.1.m1.2a"><mrow id="S2.T2.5.5.2.2.2.1.m1.2.3" xref="S2.T2.5.5.2.2.2.1.m1.2.3.cmml"><mi id="S2.T2.5.5.2.2.2.1.m1.2.3.2" xref="S2.T2.5.5.2.2.2.1.m1.2.3.2.cmml">y</mi><mo id="S2.T2.5.5.2.2.2.1.m1.2.3.1" xref="S2.T2.5.5.2.2.2.1.m1.2.3.1.cmml">∈</mo><mrow id="S2.T2.5.5.2.2.2.1.m1.2.3.3.2" xref="S2.T2.5.5.2.2.2.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S2.T2.5.5.2.2.2.1.m1.2.3.3.2.1" xref="S2.T2.5.5.2.2.2.1.m1.2.3.3.1.cmml">{</mo><mn id="S2.T2.5.5.2.2.2.1.m1.1.1" xref="S2.T2.5.5.2.2.2.1.m1.1.1.cmml">0</mn><mo id="S2.T2.5.5.2.2.2.1.m1.2.3.3.2.2" xref="S2.T2.5.5.2.2.2.1.m1.2.3.3.1.cmml">,</mo><mn id="S2.T2.5.5.2.2.2.1.m1.2.2" xref="S2.T2.5.5.2.2.2.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S2.T2.5.5.2.2.2.1.m1.2.3.3.2.3" xref="S2.T2.5.5.2.2.2.1.m1.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.5.5.2.2.2.1.m1.2b"><apply id="S2.T2.5.5.2.2.2.1.m1.2.3.cmml" xref="S2.T2.5.5.2.2.2.1.m1.2.3"><in id="S2.T2.5.5.2.2.2.1.m1.2.3.1.cmml" xref="S2.T2.5.5.2.2.2.1.m1.2.3.1"></in><ci id="S2.T2.5.5.2.2.2.1.m1.2.3.2.cmml" xref="S2.T2.5.5.2.2.2.1.m1.2.3.2">𝑦</ci><set id="S2.T2.5.5.2.2.2.1.m1.2.3.3.1.cmml" xref="S2.T2.5.5.2.2.2.1.m1.2.3.3.2"><cn type="integer" id="S2.T2.5.5.2.2.2.1.m1.1.1.cmml" xref="S2.T2.5.5.2.2.2.1.m1.1.1">0</cn><cn type="integer" id="S2.T2.5.5.2.2.2.1.m1.2.2.cmml" xref="S2.T2.5.5.2.2.2.1.m1.2.2">1</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.5.5.2.2.2.1.m1.2c">y\in\{0,1\}</annotation></semantics></math></td>
</tr>
</table>
</td>
<td id="S2.T2.5.5.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S2.T2.5.5.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.5.5.4.1.1" class="ltx_tr">
<td id="S2.T2.5.5.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Equal positive rates for</td>
</tr>
<tr id="S2.T2.5.5.4.1.2" class="ltx_tr">
<td id="S2.T2.5.5.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">protected/unprotected</td>
</tr>
<tr id="S2.T2.5.5.4.1.3" class="ltx_tr">
<td id="S2.T2.5.5.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">groups</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.6.8.2" class="ltx_tr">
<td id="S2.T2.6.8.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S2.T2.6.8.2.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.6.8.2.1.1.1" class="ltx_tr">
<td id="S2.T2.6.8.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Treatment Equality</td>
</tr>
<tr id="S2.T2.6.8.2.1.1.2" class="ltx_tr">
<td id="S2.T2.6.8.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Berk
et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021b</a>)</cite></td>
</tr>
</table>
</td>
<td id="S2.T2.6.8.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="2">
<table id="S2.T2.6.8.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.6.8.2.2.1.1" class="ltx_tr">
<td id="S2.T2.6.8.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Equal false negatives and fase positives for protected/unprotected groups</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.6.6" class="ltx_tr">
<td id="S2.T2.6.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S2.T2.6.6.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.6.6.2.1.1" class="ltx_tr">
<td id="S2.T2.6.6.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Demographic Parity</td>
</tr>
<tr id="S2.T2.6.6.2.1.2" class="ltx_tr">
<td id="S2.T2.6.6.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Kusner
et al<span class="ltx_text">.</span>, <a href="#bib.bib107" title="" class="ltx_ref">2018</a>)</cite></td>
</tr>
</table>
</td>
<td id="S2.T2.6.6.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><math id="S2.T2.6.6.1.m1.4" class="ltx_Math" alttext="\Pr[\hat{Y}|A=0]=\Pr[\hat{Y}|A=1]" display="inline"><semantics id="S2.T2.6.6.1.m1.4a"><mrow id="S2.T2.6.6.1.m1.4.4" xref="S2.T2.6.6.1.m1.4.4.cmml"><mrow id="S2.T2.6.6.1.m1.3.3.1.1" xref="S2.T2.6.6.1.m1.3.3.1.2.cmml"><mi id="S2.T2.6.6.1.m1.1.1" xref="S2.T2.6.6.1.m1.1.1.cmml">Pr</mi><mo id="S2.T2.6.6.1.m1.3.3.1.1a" xref="S2.T2.6.6.1.m1.3.3.1.2.cmml">⁡</mo><mrow id="S2.T2.6.6.1.m1.3.3.1.1.1" xref="S2.T2.6.6.1.m1.3.3.1.2.cmml"><mo stretchy="false" id="S2.T2.6.6.1.m1.3.3.1.1.1.2" xref="S2.T2.6.6.1.m1.3.3.1.2.cmml">[</mo><mrow id="S2.T2.6.6.1.m1.3.3.1.1.1.1" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1.cmml"><mrow id="S2.T2.6.6.1.m1.3.3.1.1.1.1.2" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.cmml"><mover accent="true" id="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.2" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.2.cmml"><mi id="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.2.2" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.2.2.cmml">Y</mi><mo id="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.2.1" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.2.1.cmml">^</mo></mover><mo fence="false" id="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.1" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.1.cmml">|</mo><mi id="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.3" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.3.cmml">A</mi></mrow><mo id="S2.T2.6.6.1.m1.3.3.1.1.1.1.1" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1.1.cmml">=</mo><mn id="S2.T2.6.6.1.m1.3.3.1.1.1.1.3" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1.3.cmml">0</mn></mrow><mo stretchy="false" id="S2.T2.6.6.1.m1.3.3.1.1.1.3" xref="S2.T2.6.6.1.m1.3.3.1.2.cmml">]</mo></mrow></mrow><mo id="S2.T2.6.6.1.m1.4.4.3" xref="S2.T2.6.6.1.m1.4.4.3.cmml">=</mo><mrow id="S2.T2.6.6.1.m1.4.4.2.1" xref="S2.T2.6.6.1.m1.4.4.2.2.cmml"><mi id="S2.T2.6.6.1.m1.2.2" xref="S2.T2.6.6.1.m1.2.2.cmml">Pr</mi><mo id="S2.T2.6.6.1.m1.4.4.2.1a" xref="S2.T2.6.6.1.m1.4.4.2.2.cmml">⁡</mo><mrow id="S2.T2.6.6.1.m1.4.4.2.1.1" xref="S2.T2.6.6.1.m1.4.4.2.2.cmml"><mo stretchy="false" id="S2.T2.6.6.1.m1.4.4.2.1.1.2" xref="S2.T2.6.6.1.m1.4.4.2.2.cmml">[</mo><mrow id="S2.T2.6.6.1.m1.4.4.2.1.1.1" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1.cmml"><mrow id="S2.T2.6.6.1.m1.4.4.2.1.1.1.2" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.cmml"><mover accent="true" id="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.2" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.2.cmml"><mi id="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.2.2" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.2.2.cmml">Y</mi><mo id="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.2.1" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.2.1.cmml">^</mo></mover><mo fence="false" id="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.1" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.1.cmml">|</mo><mi id="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.3" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.3.cmml">A</mi></mrow><mo id="S2.T2.6.6.1.m1.4.4.2.1.1.1.1" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1.1.cmml">=</mo><mn id="S2.T2.6.6.1.m1.4.4.2.1.1.1.3" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S2.T2.6.6.1.m1.4.4.2.1.1.3" xref="S2.T2.6.6.1.m1.4.4.2.2.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.6.6.1.m1.4b"><apply id="S2.T2.6.6.1.m1.4.4.cmml" xref="S2.T2.6.6.1.m1.4.4"><eq id="S2.T2.6.6.1.m1.4.4.3.cmml" xref="S2.T2.6.6.1.m1.4.4.3"></eq><apply id="S2.T2.6.6.1.m1.3.3.1.2.cmml" xref="S2.T2.6.6.1.m1.3.3.1.1"><ci id="S2.T2.6.6.1.m1.1.1.cmml" xref="S2.T2.6.6.1.m1.1.1">Pr</ci><apply id="S2.T2.6.6.1.m1.3.3.1.1.1.1.cmml" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1"><eq id="S2.T2.6.6.1.m1.3.3.1.1.1.1.1.cmml" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1.1"></eq><apply id="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.cmml" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1.2"><csymbol cd="latexml" id="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.1.cmml" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.1">conditional</csymbol><apply id="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.2.cmml" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.2"><ci id="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.2.1.cmml" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.2.1">^</ci><ci id="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.2.2.cmml" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.2.2">𝑌</ci></apply><ci id="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.3.cmml" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1.2.3">𝐴</ci></apply><cn type="integer" id="S2.T2.6.6.1.m1.3.3.1.1.1.1.3.cmml" xref="S2.T2.6.6.1.m1.3.3.1.1.1.1.3">0</cn></apply></apply><apply id="S2.T2.6.6.1.m1.4.4.2.2.cmml" xref="S2.T2.6.6.1.m1.4.4.2.1"><ci id="S2.T2.6.6.1.m1.2.2.cmml" xref="S2.T2.6.6.1.m1.2.2">Pr</ci><apply id="S2.T2.6.6.1.m1.4.4.2.1.1.1.cmml" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1"><eq id="S2.T2.6.6.1.m1.4.4.2.1.1.1.1.cmml" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1.1"></eq><apply id="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.cmml" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1.2"><csymbol cd="latexml" id="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.1.cmml" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.1">conditional</csymbol><apply id="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.2.cmml" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.2"><ci id="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.2.1.cmml" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.2.1">^</ci><ci id="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.2.2.cmml" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.2.2">𝑌</ci></apply><ci id="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.3.cmml" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1.2.3">𝐴</ci></apply><cn type="integer" id="S2.T2.6.6.1.m1.4.4.2.1.1.1.3.cmml" xref="S2.T2.6.6.1.m1.4.4.2.1.1.1.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.6.6.1.m1.4c">\Pr[\hat{Y}|A=0]=\Pr[\hat{Y}|A=1]</annotation></semantics></math></td>
<td id="S2.T2.6.6.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S2.T2.6.6.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.6.6.3.1.1" class="ltx_tr">
<td id="S2.T2.6.6.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Outcome is independent</td>
</tr>
<tr id="S2.T2.6.6.3.1.2" class="ltx_tr">
<td id="S2.T2.6.6.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">of the protected attribute</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S2.SS4.SSS2.p2" class="ltx_para">
<p id="S2.SS4.SSS2.p2.1" class="ltx_p">Apart from algorithmic fairness, which is measured on sensitive attributes, fairness in FL can also be made from a client’s view since clients are naturally grouped by attributes like geographic location, gender and income <cite class="ltx_cite ltx_citemacro_citep">(Du
et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2021</a>)</cite>. At a client level, fairness can be evaluated by different metrics.</p>
</div>
<div id="S2.Thmtheorem1" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_font_italic ltx_title_theorem">Definition 0 (Good-intent fairness <cite class="ltx_cite ltx_citemacro_citep">(Mohri
et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2019</a>)</cite>).</h6>
<div id="S2.Thmtheorem1.p1" class="ltx_para">
<p id="S2.Thmtheorem1.p1.1" class="ltx_p">The training procedure does not overfit a model to any device at the expense of other clients in FL.</p>
</div>
</div>
<div id="S2.SS4.SSS2.p3" class="ltx_para">
<p id="S2.SS4.SSS2.p3.1" class="ltx_p">This metric improves the worst-case performance. Li et al. <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2019b</a>)</cite> took a further step. They tried to ensure a fair FL model for all clients by producing a more uniform model performance across all clients. Fairness is defined as the uniformity of the accuracy distribution across clients in FL.</p>
</div>
<div id="S2.Thmtheorem2" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_font_italic ltx_title_theorem">Definition 0 (Accuracy parity <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2019b</a>)</cite>).</h6>
<div id="S2.Thmtheorem2.p1" class="ltx_para">
<p id="S2.Thmtheorem2.p1.2" class="ltx_p">Consider two trained models, <math id="S2.Thmtheorem2.p1.1.m1.1" class="ltx_Math" alttext="f(w)" display="inline"><semantics id="S2.Thmtheorem2.p1.1.m1.1a"><mrow id="S2.Thmtheorem2.p1.1.m1.1.2" xref="S2.Thmtheorem2.p1.1.m1.1.2.cmml"><mi id="S2.Thmtheorem2.p1.1.m1.1.2.2" xref="S2.Thmtheorem2.p1.1.m1.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.Thmtheorem2.p1.1.m1.1.2.1" xref="S2.Thmtheorem2.p1.1.m1.1.2.1.cmml">​</mo><mrow id="S2.Thmtheorem2.p1.1.m1.1.2.3.2" xref="S2.Thmtheorem2.p1.1.m1.1.2.cmml"><mo stretchy="false" id="S2.Thmtheorem2.p1.1.m1.1.2.3.2.1" xref="S2.Thmtheorem2.p1.1.m1.1.2.cmml">(</mo><mi id="S2.Thmtheorem2.p1.1.m1.1.1" xref="S2.Thmtheorem2.p1.1.m1.1.1.cmml">w</mi><mo stretchy="false" id="S2.Thmtheorem2.p1.1.m1.1.2.3.2.2" xref="S2.Thmtheorem2.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Thmtheorem2.p1.1.m1.1b"><apply id="S2.Thmtheorem2.p1.1.m1.1.2.cmml" xref="S2.Thmtheorem2.p1.1.m1.1.2"><times id="S2.Thmtheorem2.p1.1.m1.1.2.1.cmml" xref="S2.Thmtheorem2.p1.1.m1.1.2.1"></times><ci id="S2.Thmtheorem2.p1.1.m1.1.2.2.cmml" xref="S2.Thmtheorem2.p1.1.m1.1.2.2">𝑓</ci><ci id="S2.Thmtheorem2.p1.1.m1.1.1.cmml" xref="S2.Thmtheorem2.p1.1.m1.1.1">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Thmtheorem2.p1.1.m1.1c">f(w)</annotation></semantics></math> and <math id="S2.Thmtheorem2.p1.2.m2.1" class="ltx_Math" alttext="f(\tilde{w})" display="inline"><semantics id="S2.Thmtheorem2.p1.2.m2.1a"><mrow id="S2.Thmtheorem2.p1.2.m2.1.2" xref="S2.Thmtheorem2.p1.2.m2.1.2.cmml"><mi id="S2.Thmtheorem2.p1.2.m2.1.2.2" xref="S2.Thmtheorem2.p1.2.m2.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.Thmtheorem2.p1.2.m2.1.2.1" xref="S2.Thmtheorem2.p1.2.m2.1.2.1.cmml">​</mo><mrow id="S2.Thmtheorem2.p1.2.m2.1.2.3.2" xref="S2.Thmtheorem2.p1.2.m2.1.1.cmml"><mo stretchy="false" id="S2.Thmtheorem2.p1.2.m2.1.2.3.2.1" xref="S2.Thmtheorem2.p1.2.m2.1.1.cmml">(</mo><mover accent="true" id="S2.Thmtheorem2.p1.2.m2.1.1" xref="S2.Thmtheorem2.p1.2.m2.1.1.cmml"><mi id="S2.Thmtheorem2.p1.2.m2.1.1.2" xref="S2.Thmtheorem2.p1.2.m2.1.1.2.cmml">w</mi><mo id="S2.Thmtheorem2.p1.2.m2.1.1.1" xref="S2.Thmtheorem2.p1.2.m2.1.1.1.cmml">~</mo></mover><mo stretchy="false" id="S2.Thmtheorem2.p1.2.m2.1.2.3.2.2" xref="S2.Thmtheorem2.p1.2.m2.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Thmtheorem2.p1.2.m2.1b"><apply id="S2.Thmtheorem2.p1.2.m2.1.2.cmml" xref="S2.Thmtheorem2.p1.2.m2.1.2"><times id="S2.Thmtheorem2.p1.2.m2.1.2.1.cmml" xref="S2.Thmtheorem2.p1.2.m2.1.2.1"></times><ci id="S2.Thmtheorem2.p1.2.m2.1.2.2.cmml" xref="S2.Thmtheorem2.p1.2.m2.1.2.2">𝑓</ci><apply id="S2.Thmtheorem2.p1.2.m2.1.1.cmml" xref="S2.Thmtheorem2.p1.2.m2.1.2.3.2"><ci id="S2.Thmtheorem2.p1.2.m2.1.1.1.cmml" xref="S2.Thmtheorem2.p1.2.m2.1.1.1">~</ci><ci id="S2.Thmtheorem2.p1.2.m2.1.1.2.cmml" xref="S2.Thmtheorem2.p1.2.m2.1.1.2">𝑤</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Thmtheorem2.p1.2.m2.1c">f(\tilde{w})</annotation></semantics></math>. The model that provides the most uniform performance across all clients will also provide the fairest solution to the FL objective in Eq. (<a href="#S2.E1" title="In 2.1. Definition of FL ‣ 2. Background Knowledge ‣ Privacy and Fairness in Federated Learning: on the Perspective of Trade-off" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
</div>
</section>
</section>
<section id="S2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5. </span>Interactions between Privacy and Fairness</h3>

<div id="S2.SS5.p1" class="ltx_para">
<p id="S2.SS5.p1.1" class="ltx_p">Both fairness and privacy are important ethical notions in machine learning and have been extensively studied. However, the majority of current studies in the research community consider fairness and privacy separately. However, the interactions between privacy and fairness are bilateral.</p>
<ul id="S2.I3" class="ltx_itemize">
<li id="S2.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i1.p1" class="ltx_para">
<p id="S2.I3.i1.p1.1" class="ltx_p"><span id="S2.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">Privacy degrades fairness</span>. Several works have observed inconsistent reductions in accuracy caused by private mechanisms on classification <cite class="ltx_cite ltx_citemacro_citep">(Farrand et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite> and generative tasks <cite class="ltx_cite ltx_citemacro_citep">(Ganev
et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2022</a>)</cite>. It turns out that privacy mechanisms affect the underrepresented group more than other groups.</p>
</div>
</li>
<li id="S2.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i2.p1" class="ltx_para">
<p id="S2.I3.i2.p1.1" class="ltx_p"><span id="S2.I3.i2.p1.1.1" class="ltx_text ltx_font_bold">Fairness increases privacy risk</span>. Fairness comes at the cost of privacy. To ensure fairness, a model is trained to perform equally on data from different groups, even though the underrepresented group didn’t have enough data in the training set, which incurs overfit and increases the privacy risk <cite class="ltx_cite ltx_citemacro_citep">(Chang and Shokri, <a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Privacy in FL</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">With the advent of FL, many claims that user data are now secure. However, even sharing a small fraction of gradients <cite class="ltx_cite ltx_citemacro_citep">(Shokri and
Shmatikov, <a href="#bib.bib166" title="" class="ltx_ref">2015</a>; Aono et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2017</a>)</cite> with a server would raise privacy concerns. In FL, there are several unexplored types of privacy attacks: <span id="S3.p1.1.1" class="ltx_text ltx_font_italic">membership inference attacks</span>, <span id="S3.p1.1.2" class="ltx_text ltx_font_italic">property inference attacks</span>, <span id="S3.p1.1.3" class="ltx_text ltx_font_italic">model inversion attacks</span>, and <span id="S3.p1.1.4" class="ltx_text ltx_font_italic">reconstruction attacks</span>. This section will outline these attacks before moving on to mitigation techniques and discussions.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Membership Inference Attacks</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The adversary’s goal in FL is to determine whether a given sample belongs to a single client’s private training data or of any participants <cite class="ltx_cite ltx_citemacro_citep">(Yang
et al<span class="ltx_text">.</span>, <a href="#bib.bib200" title="" class="ltx_ref">2020b</a>)</cite>. MIAs take occur in different ways in FL.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1. </span>White-box and Black-box MIAs</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p">Based on the access granted to the adversary, MIAs can be divided into black-box and white-box <cite class="ltx_cite ltx_citemacro_citep">(Nasr
et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2019</a>)</cite>. In the black-box setting, the adversary can only obtain a prediction vector computed by the target model while the internal parameters remain secret. MIAs in this setting exploit the statistical differences between a model’s predictions on its training set versus unseen data <cite class="ltx_cite ltx_citemacro_citep">(Shokri
et al<span class="ltx_text">.</span>, <a href="#bib.bib167" title="" class="ltx_ref">2017</a>)</cite>. Truex et al. <cite class="ltx_cite ltx_citemacro_citep">(Truex
et al<span class="ltx_text">.</span>, <a href="#bib.bib180" title="" class="ltx_ref">2019b</a>)</cite> described a systematic approach to constructing a black-box MIA model and the general formulation of each component in the attack model.</p>
</div>
<div id="S3.SS1.SSS1.p2" class="ltx_para">
<p id="S3.SS1.SSS1.p2.1" class="ltx_p">However, since the global model is shared with all participants for local training, it is often assumed that an adversary has white-box access in FL. The white-box access renders much more information to the adversary, such as the internal parameters of each layer. This enables the adversary to calculate the outputs of each layer. Nasr et al. <cite class="ltx_cite ltx_citemacro_citep">(Nasr
et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2019</a>)</cite> designed a deep learning attack model that separately processes the gradients extracted from different layers of the target model and combines this information to compute the membership probability of a target data point.</p>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2. </span>Training and Inference MIAs</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">MIAs can be launched during the training stage or once the model is complete in the inference stage in FL.</p>
</div>
<div id="S3.SS1.SSS2.p2" class="ltx_para">
<p id="S3.SS1.SSS2.p2.1" class="ltx_p">In the training stage, the adversary could be the server or any client participating in the training. Both characters have white-box access to the global model and can easily save the snapshots of the global model at each iteration during training. In this way, the adversary obtains multiple versions of the target model over time and acquires the updated information to infer private data <cite class="ltx_cite ltx_citemacro_citep">(Phuong
et al<span class="ltx_text">.</span>, <a href="#bib.bib151" title="" class="ltx_ref">2019</a>)</cite>. In addition to passively collecting the updated information, the adversary may further modify the information to allure the victim clients to reveal more information.</p>
</div>
<div id="S3.SS1.SSS2.p3" class="ltx_para">
<p id="S3.SS1.SSS2.p3.1" class="ltx_p">In the inference phase, the FL model is well-trained and fixed. The adversary can only perform an inference attack passively. In this case, MIA in FL resembles that in a centralized setting. The attack’s success largely depends on the information that is revealed to the adversary. Melis et al. <cite class="ltx_cite ltx_citemacro_citep">(Melis et al<span class="ltx_text">.</span>, <a href="#bib.bib133" title="" class="ltx_ref">2019</a>)</cite> investigated privacy leaks concerning membership during the inference phase and showed that positions of words in a batch could be revealed from a deep learning model.</p>
</div>
</section>
<section id="S3.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3. </span>Active and Passive MIAs</h4>

<div id="S3.SS1.SSS3.p1" class="ltx_para">
<p id="S3.SS1.SSS3.p1.1" class="ltx_p">The adversary can conduct MIAs against the FL model actively or passively. For instance, the server can either adaptively modify the aggregate parameters or honestly calculate the global model and passively conduct MIAs <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib221" title="" class="ltx_ref">2020f</a>)</cite>.</p>
</div>
<div id="S3.SS1.SSS3.p2" class="ltx_para">
<p id="S3.SS1.SSS3.p2.2" class="ltx_p">Melis et al. <cite class="ltx_cite ltx_citemacro_citep">(Melis et al<span class="ltx_text">.</span>, <a href="#bib.bib133" title="" class="ltx_ref">2019</a>)</cite> designed MIAs against models operating on non-numerical data (e.g., natural-language text). An embedding layer is equipped for the target model, transforming the inputs into a lower-dimensional vector representation. The adversary passively saves a snapshot of the joint model parameters <math id="S3.SS1.SSS3.p2.1.m1.1" class="ltx_Math" alttext="{w_{t}}" display="inline"><semantics id="S3.SS1.SSS3.p2.1.m1.1a"><msub id="S3.SS1.SSS3.p2.1.m1.1.1" xref="S3.SS1.SSS3.p2.1.m1.1.1.cmml"><mi id="S3.SS1.SSS3.p2.1.m1.1.1.2" xref="S3.SS1.SSS3.p2.1.m1.1.1.2.cmml">w</mi><mi id="S3.SS1.SSS3.p2.1.m1.1.1.3" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p2.1.m1.1b"><apply id="S3.SS1.SSS3.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p2.1.m1.1.1.1.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS3.p2.1.m1.1.1.2.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.2">𝑤</ci><ci id="S3.SS1.SSS3.p2.1.m1.1.1.3.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p2.1.m1.1c">{w_{t}}</annotation></semantics></math>. The difference between the consecutive snapshots <math id="S3.SS1.SSS3.p2.2.m2.1" class="ltx_Math" alttext="\Delta{w_{t}}={w_{t}}-{w_{t-1}}={\Sigma_{k}}\Delta w_{t}^{k}" display="inline"><semantics id="S3.SS1.SSS3.p2.2.m2.1a"><mrow id="S3.SS1.SSS3.p2.2.m2.1.1" xref="S3.SS1.SSS3.p2.2.m2.1.1.cmml"><mrow id="S3.SS1.SSS3.p2.2.m2.1.1.2" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.cmml"><mi mathvariant="normal" id="S3.SS1.SSS3.p2.2.m2.1.1.2.2" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS3.p2.2.m2.1.1.2.1" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.1.cmml">​</mo><msub id="S3.SS1.SSS3.p2.2.m2.1.1.2.3" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.3.cmml"><mi id="S3.SS1.SSS3.p2.2.m2.1.1.2.3.2" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.3.2.cmml">w</mi><mi id="S3.SS1.SSS3.p2.2.m2.1.1.2.3.3" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.3.3.cmml">t</mi></msub></mrow><mo id="S3.SS1.SSS3.p2.2.m2.1.1.3" xref="S3.SS1.SSS3.p2.2.m2.1.1.3.cmml">=</mo><mrow id="S3.SS1.SSS3.p2.2.m2.1.1.4" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.cmml"><msub id="S3.SS1.SSS3.p2.2.m2.1.1.4.2" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.2.cmml"><mi id="S3.SS1.SSS3.p2.2.m2.1.1.4.2.2" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.2.2.cmml">w</mi><mi id="S3.SS1.SSS3.p2.2.m2.1.1.4.2.3" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.2.3.cmml">t</mi></msub><mo id="S3.SS1.SSS3.p2.2.m2.1.1.4.1" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.1.cmml">−</mo><msub id="S3.SS1.SSS3.p2.2.m2.1.1.4.3" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.3.cmml"><mi id="S3.SS1.SSS3.p2.2.m2.1.1.4.3.2" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.3.2.cmml">w</mi><mrow id="S3.SS1.SSS3.p2.2.m2.1.1.4.3.3" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.3.3.cmml"><mi id="S3.SS1.SSS3.p2.2.m2.1.1.4.3.3.2" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.3.3.2.cmml">t</mi><mo id="S3.SS1.SSS3.p2.2.m2.1.1.4.3.3.1" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.3.3.1.cmml">−</mo><mn id="S3.SS1.SSS3.p2.2.m2.1.1.4.3.3.3" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="S3.SS1.SSS3.p2.2.m2.1.1.5" xref="S3.SS1.SSS3.p2.2.m2.1.1.5.cmml">=</mo><mrow id="S3.SS1.SSS3.p2.2.m2.1.1.6" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.cmml"><msub id="S3.SS1.SSS3.p2.2.m2.1.1.6.2" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.2.cmml"><mi mathvariant="normal" id="S3.SS1.SSS3.p2.2.m2.1.1.6.2.2" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.2.2.cmml">Σ</mi><mi id="S3.SS1.SSS3.p2.2.m2.1.1.6.2.3" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS1.SSS3.p2.2.m2.1.1.6.1" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.1.cmml">​</mo><mi mathvariant="normal" id="S3.SS1.SSS3.p2.2.m2.1.1.6.3" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.3.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS3.p2.2.m2.1.1.6.1a" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.1.cmml">​</mo><msubsup id="S3.SS1.SSS3.p2.2.m2.1.1.6.4" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.4.cmml"><mi id="S3.SS1.SSS3.p2.2.m2.1.1.6.4.2.2" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.4.2.2.cmml">w</mi><mi id="S3.SS1.SSS3.p2.2.m2.1.1.6.4.2.3" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.4.2.3.cmml">t</mi><mi id="S3.SS1.SSS3.p2.2.m2.1.1.6.4.3" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.4.3.cmml">k</mi></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p2.2.m2.1b"><apply id="S3.SS1.SSS3.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1"><and id="S3.SS1.SSS3.p2.2.m2.1.1a.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1"></and><apply id="S3.SS1.SSS3.p2.2.m2.1.1b.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1"><eq id="S3.SS1.SSS3.p2.2.m2.1.1.3.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.3"></eq><apply id="S3.SS1.SSS3.p2.2.m2.1.1.2.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.2"><times id="S3.SS1.SSS3.p2.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.1"></times><ci id="S3.SS1.SSS3.p2.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.2">Δ</ci><apply id="S3.SS1.SSS3.p2.2.m2.1.1.2.3.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.3"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p2.2.m2.1.1.2.3.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.3">subscript</csymbol><ci id="S3.SS1.SSS3.p2.2.m2.1.1.2.3.2.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.3.2">𝑤</ci><ci id="S3.SS1.SSS3.p2.2.m2.1.1.2.3.3.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.3.3">𝑡</ci></apply></apply><apply id="S3.SS1.SSS3.p2.2.m2.1.1.4.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.4"><minus id="S3.SS1.SSS3.p2.2.m2.1.1.4.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.1"></minus><apply id="S3.SS1.SSS3.p2.2.m2.1.1.4.2.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.2"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p2.2.m2.1.1.4.2.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.2">subscript</csymbol><ci id="S3.SS1.SSS3.p2.2.m2.1.1.4.2.2.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.2.2">𝑤</ci><ci id="S3.SS1.SSS3.p2.2.m2.1.1.4.2.3.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.2.3">𝑡</ci></apply><apply id="S3.SS1.SSS3.p2.2.m2.1.1.4.3.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.3"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p2.2.m2.1.1.4.3.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.3">subscript</csymbol><ci id="S3.SS1.SSS3.p2.2.m2.1.1.4.3.2.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.3.2">𝑤</ci><apply id="S3.SS1.SSS3.p2.2.m2.1.1.4.3.3.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.3.3"><minus id="S3.SS1.SSS3.p2.2.m2.1.1.4.3.3.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.3.3.1"></minus><ci id="S3.SS1.SSS3.p2.2.m2.1.1.4.3.3.2.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.3.3.2">𝑡</ci><cn type="integer" id="S3.SS1.SSS3.p2.2.m2.1.1.4.3.3.3.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.4.3.3.3">1</cn></apply></apply></apply></apply><apply id="S3.SS1.SSS3.p2.2.m2.1.1c.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1"><eq id="S3.SS1.SSS3.p2.2.m2.1.1.5.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.5"></eq><share href="#S3.SS1.SSS3.p2.2.m2.1.1.4.cmml" id="S3.SS1.SSS3.p2.2.m2.1.1d.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1"></share><apply id="S3.SS1.SSS3.p2.2.m2.1.1.6.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.6"><times id="S3.SS1.SSS3.p2.2.m2.1.1.6.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.1"></times><apply id="S3.SS1.SSS3.p2.2.m2.1.1.6.2.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.2"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p2.2.m2.1.1.6.2.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.2">subscript</csymbol><ci id="S3.SS1.SSS3.p2.2.m2.1.1.6.2.2.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.2.2">Σ</ci><ci id="S3.SS1.SSS3.p2.2.m2.1.1.6.2.3.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.2.3">𝑘</ci></apply><ci id="S3.SS1.SSS3.p2.2.m2.1.1.6.3.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.3">Δ</ci><apply id="S3.SS1.SSS3.p2.2.m2.1.1.6.4.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.4"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p2.2.m2.1.1.6.4.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.4">superscript</csymbol><apply id="S3.SS1.SSS3.p2.2.m2.1.1.6.4.2.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.4"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p2.2.m2.1.1.6.4.2.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.4">subscript</csymbol><ci id="S3.SS1.SSS3.p2.2.m2.1.1.6.4.2.2.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.4.2.2">𝑤</ci><ci id="S3.SS1.SSS3.p2.2.m2.1.1.6.4.2.3.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.4.2.3">𝑡</ci></apply><ci id="S3.SS1.SSS3.p2.2.m2.1.1.6.4.3.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.6.4.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p2.2.m2.1c">\Delta{w_{t}}={w_{t}}-{w_{t-1}}={\Sigma_{k}}\Delta w_{t}^{k}</annotation></semantics></math> reveals the aggregated updates from all participants and hence reveals the membership.</p>
</div>
<div id="S3.SS1.SSS3.p3" class="ltx_para">
<p id="S3.SS1.SSS3.p3.1" class="ltx_p">Nasr et al. <cite class="ltx_cite ltx_citemacro_citep">(Nasr
et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2019</a>)</cite> performed active MIAs on FL models by reversing the stochastic gradient descent algorithm and extracting membership information. If the target data point belongs to the training dataset, the attacker’s modifications will be nullified since the target model will descend the model’s gradient for training samples. However, if the target data sample is not used during the training, the target model will not respond to the attacker’s modification. Thus, membership can be deduced. In <cite class="ltx_cite ltx_citemacro_citep">(Hitaj
et al<span class="ltx_text">.</span>, <a href="#bib.bib76" title="" class="ltx_ref">2017</a>)</cite>, a malicious client actively mislabels the training sample to fool the victim into releasing private information.</p>
</div>
</section>
<section id="S3.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.4. </span>Insider and Outsider MIAs</h4>

<div id="S3.SS1.SSS4.p1" class="ltx_para">
<p id="S3.SS1.SSS4.p1.1" class="ltx_p">FL involves two types of actors who can access model information: internal actors (participating clients and the server) and external actors (model consumers and eavesdroppers). Therefore, FL systems must withstand potential adversaries within and outside the protocol.</p>
</div>
<div id="S3.SS1.SSS4.p2" class="ltx_para">
<p id="S3.SS1.SSS4.p2.1" class="ltx_p">The inner adversary could be a client or a server. Clients are picked at random to participate in a training round. When training with hundreds or millions of clients, malicious clients are highly likely involved, who will attempt to deduce the sensitive information of others <cite class="ltx_cite ltx_citemacro_citep">(Hitaj
et al<span class="ltx_text">.</span>, <a href="#bib.bib76" title="" class="ltx_ref">2017</a>)</cite>. The real-time nature of FL added to the inner attacker’s strength. For example, Zhang et al. <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib221" title="" class="ltx_ref">2020f</a>)</cite> trained a GAN as a malicious client during training to infer the data of other clients in FL.
A malicious central server poses a greater threat than a malicious client. Because it can manipulate the global model supplied to victims and obtain more information. Nasr et al. <cite class="ltx_cite ltx_citemacro_citep">(Nasr
et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2019</a>)</cite> launched MIAs from both the client and server sides and witnessed a higher inference accuracy as a curious central server than as a malicious client.</p>
</div>
<div id="S3.SS1.SSS4.p3" class="ltx_para">
<p id="S3.SS1.SSS4.p3.1" class="ltx_p">In addition to internal threats, FL also faces potential attacks from adversaries outside the system. Once the FL training is finished and the model is deployed to users, these users may conduct both black- and white-box attacks depending on their access.</p>
</div>
</section>
<section id="S3.SS1.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.5. </span>Discussion</h4>

<div id="S3.SS1.SSS5.p1" class="ltx_para">
<p id="S3.SS1.SSS5.p1.1" class="ltx_p">The attacks mentioned above demonstrate the vulnerability of FL to privacy attacks, and these privacy risks stem from two assumptions made within the FL protocols: 1) <span id="S3.SS1.SSS5.p1.1.1" class="ltx_text ltx_font_italic">The server is trustworthy</span>. FL gives the server access to each participant’s updates in the form of gradients or model parameters containing clients’ private information. The server can even purposefully send a modified model to steal information. 2) <span id="S3.SS1.SSS5.p1.1.2" class="ltx_text ltx_font_italic">Clients are honest</span>. A malicious client can collect several copies of the global model from the rounds it participates in. In this way, inference phase attacks on data privacy are also plausible during the learning phase. Additionally, adversarial clients may influence and shift the bounds of the model during development rather than just abusing the boundaries of a model’s service while it is in production.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Property Inference Attacks</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The adversary in property inference attacks attempts to infer the specific property of the subset of the training dataset. The target property may be irrelevant to the classification task (e.g., ”wearing glasses” in a gender classification task) and do not characterize the whole class. The attack is made at the population level as opposed to a single sample in MIA. In terms of when the attack is launched, property inference attacks can be classified as <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">static</span> or <span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_italic">dynamic</span> attacks. The static attack is applied after the training phase has concluded and the target training set is fixed. The dynamic attack typically occurs during the training phase in FL. In this instance, the training set is changing dynamically.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1. </span>Static Attacks</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">The research of property inference attacks dates back to <cite class="ltx_cite ltx_citemacro_citep">(Ateniese et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2013</a>)</cite>. Ateniese et al. performed a property inference attack against Hidden Markov Models and Support Vector Machine based on a meta-classifier. A set of shadow classifiers were trained on a dataset similar to the target model except for the target property. The meta-classifier is trained with shadow classifiers as the input to find the classifiers trained on the dataset with the target property. Ganju et al. <cite class="ltx_cite ltx_citemacro_citep">(Ganju
et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2018</a>)</cite> extended this attack to a fully connected neural network case. They shared a similar idea, using the gradient of shadow classifiers to train a meta-classifier. Different from <cite class="ltx_cite ltx_citemacro_citep">(Ateniese et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2013</a>)</cite>, their research focuses on improving the attack efficiency by taking permutation invariance into account.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2. </span>Dynamic Attacks</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">In every communication round of FL, clients are selected at random. This means the training data is dynamically changing, which weakens the property inference attack because the target property appears unpredictable, thereby diminishing the distinguishability of model updates <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib189" title="" class="ltx_ref">2022</a>)</cite>. Wang et al. <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib186" title="" class="ltx_ref">2019b</a>)</cite> explored property inference attacks within the FL framework. Inspired by the relationship between the changing of neuron weights in the output layer and the sample label, the authors proposed three attacks as an eavesdropper to infer the labels’ quantity composition proportion. Recently, Wang et al. <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib189" title="" class="ltx_ref">2022</a>)</cite> presented a poisoning-assisted property inference attack in FL from the client’s viewpoint, aiming at inferring if and when a sensitive property emerges. The authors built their attacks around the realization that regular model updates reflect the shift in data distribution and, in particular. A binary classifier is trained to make predictions based on these periodic model updates. A property-specific poisoning attack is proposed to distort the decision boundary of the shared model on target attribute data. Thus, model updates have a better discerning ability to infer target property.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3. </span>Discussion</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">The MIAs and reconstruction attacks represent two ends of a spectrum of privacy invasion. Property inference attacks locate in the middle and seek to determine if the attackers’ target property is present in the training samples. This type of attack is more complex than MIA since the target property doesn’t always match the attributes that characterize the classes of the FL model. Nonetheless, a property inference attack poses a greater threat than MIA. Using the real-time nature of FL, the adversary can even infer when the target property appears.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Model Inversion Attacks</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.5" class="ltx_p">Fredrikson et al. <cite class="ltx_cite ltx_citemacro_citep">(Fredrikson et al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2014</a>)</cite> initiated model inversion attacks on tabular data. A subsequent work <cite class="ltx_cite ltx_citemacro_citep">(Fredrikson
et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2015</a>)</cite> extended it to the image data. The attack is formulated as an optimization problem to synthesize the input for a given label: <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="y:{\max_{x}}\log{T_{y}}\left(x\right)" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.2" xref="S3.SS3.p1.1.m1.1.2.cmml"><mi id="S3.SS3.p1.1.m1.1.2.2" xref="S3.SS3.p1.1.m1.1.2.2.cmml">y</mi><mo lspace="0.278em" rspace="0.278em" id="S3.SS3.p1.1.m1.1.2.1" xref="S3.SS3.p1.1.m1.1.2.1.cmml">:</mo><mrow id="S3.SS3.p1.1.m1.1.2.3" xref="S3.SS3.p1.1.m1.1.2.3.cmml"><mrow id="S3.SS3.p1.1.m1.1.2.3.2" xref="S3.SS3.p1.1.m1.1.2.3.2.cmml"><msub id="S3.SS3.p1.1.m1.1.2.3.2.1" xref="S3.SS3.p1.1.m1.1.2.3.2.1.cmml"><mi id="S3.SS3.p1.1.m1.1.2.3.2.1.2" xref="S3.SS3.p1.1.m1.1.2.3.2.1.2.cmml">max</mi><mi id="S3.SS3.p1.1.m1.1.2.3.2.1.3" xref="S3.SS3.p1.1.m1.1.2.3.2.1.3.cmml">x</mi></msub><mo lspace="0.167em" id="S3.SS3.p1.1.m1.1.2.3.2a" xref="S3.SS3.p1.1.m1.1.2.3.2.cmml">⁡</mo><mrow id="S3.SS3.p1.1.m1.1.2.3.2.2" xref="S3.SS3.p1.1.m1.1.2.3.2.2.cmml"><mi id="S3.SS3.p1.1.m1.1.2.3.2.2.1" xref="S3.SS3.p1.1.m1.1.2.3.2.2.1.cmml">log</mi><mo lspace="0.167em" id="S3.SS3.p1.1.m1.1.2.3.2.2a" xref="S3.SS3.p1.1.m1.1.2.3.2.2.cmml">⁡</mo><msub id="S3.SS3.p1.1.m1.1.2.3.2.2.2" xref="S3.SS3.p1.1.m1.1.2.3.2.2.2.cmml"><mi id="S3.SS3.p1.1.m1.1.2.3.2.2.2.2" xref="S3.SS3.p1.1.m1.1.2.3.2.2.2.2.cmml">T</mi><mi id="S3.SS3.p1.1.m1.1.2.3.2.2.2.3" xref="S3.SS3.p1.1.m1.1.2.3.2.2.2.3.cmml">y</mi></msub></mrow></mrow><mo lspace="0em" rspace="0em" id="S3.SS3.p1.1.m1.1.2.3.1" xref="S3.SS3.p1.1.m1.1.2.3.1.cmml">​</mo><mrow id="S3.SS3.p1.1.m1.1.2.3.3.2" xref="S3.SS3.p1.1.m1.1.2.3.cmml"><mo id="S3.SS3.p1.1.m1.1.2.3.3.2.1" xref="S3.SS3.p1.1.m1.1.2.3.cmml">(</mo><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">x</mi><mo id="S3.SS3.p1.1.m1.1.2.3.3.2.2" xref="S3.SS3.p1.1.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.2"><ci id="S3.SS3.p1.1.m1.1.2.1.cmml" xref="S3.SS3.p1.1.m1.1.2.1">:</ci><ci id="S3.SS3.p1.1.m1.1.2.2.cmml" xref="S3.SS3.p1.1.m1.1.2.2">𝑦</ci><apply id="S3.SS3.p1.1.m1.1.2.3.cmml" xref="S3.SS3.p1.1.m1.1.2.3"><times id="S3.SS3.p1.1.m1.1.2.3.1.cmml" xref="S3.SS3.p1.1.m1.1.2.3.1"></times><apply id="S3.SS3.p1.1.m1.1.2.3.2.cmml" xref="S3.SS3.p1.1.m1.1.2.3.2"><apply id="S3.SS3.p1.1.m1.1.2.3.2.1.cmml" xref="S3.SS3.p1.1.m1.1.2.3.2.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.2.3.2.1.1.cmml" xref="S3.SS3.p1.1.m1.1.2.3.2.1">subscript</csymbol><max id="S3.SS3.p1.1.m1.1.2.3.2.1.2.cmml" xref="S3.SS3.p1.1.m1.1.2.3.2.1.2"></max><ci id="S3.SS3.p1.1.m1.1.2.3.2.1.3.cmml" xref="S3.SS3.p1.1.m1.1.2.3.2.1.3">𝑥</ci></apply><apply id="S3.SS3.p1.1.m1.1.2.3.2.2.cmml" xref="S3.SS3.p1.1.m1.1.2.3.2.2"><log id="S3.SS3.p1.1.m1.1.2.3.2.2.1.cmml" xref="S3.SS3.p1.1.m1.1.2.3.2.2.1"></log><apply id="S3.SS3.p1.1.m1.1.2.3.2.2.2.cmml" xref="S3.SS3.p1.1.m1.1.2.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.2.3.2.2.2.1.cmml" xref="S3.SS3.p1.1.m1.1.2.3.2.2.2">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.2.3.2.2.2.2.cmml" xref="S3.SS3.p1.1.m1.1.2.3.2.2.2.2">𝑇</ci><ci id="S3.SS3.p1.1.m1.1.2.3.2.2.2.3.cmml" xref="S3.SS3.p1.1.m1.1.2.3.2.2.2.3">𝑦</ci></apply></apply></apply><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">y:{\max_{x}}\log{T_{y}}\left(x\right)</annotation></semantics></math>, where <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="{T_{y}}\left(x\right)" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mrow id="S3.SS3.p1.2.m2.1.2" xref="S3.SS3.p1.2.m2.1.2.cmml"><msub id="S3.SS3.p1.2.m2.1.2.2" xref="S3.SS3.p1.2.m2.1.2.2.cmml"><mi id="S3.SS3.p1.2.m2.1.2.2.2" xref="S3.SS3.p1.2.m2.1.2.2.2.cmml">T</mi><mi id="S3.SS3.p1.2.m2.1.2.2.3" xref="S3.SS3.p1.2.m2.1.2.2.3.cmml">y</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS3.p1.2.m2.1.2.1" xref="S3.SS3.p1.2.m2.1.2.1.cmml">​</mo><mrow id="S3.SS3.p1.2.m2.1.2.3.2" xref="S3.SS3.p1.2.m2.1.2.cmml"><mo id="S3.SS3.p1.2.m2.1.2.3.2.1" xref="S3.SS3.p1.2.m2.1.2.cmml">(</mo><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">x</mi><mo id="S3.SS3.p1.2.m2.1.2.3.2.2" xref="S3.SS3.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.2.cmml" xref="S3.SS3.p1.2.m2.1.2"><times id="S3.SS3.p1.2.m2.1.2.1.cmml" xref="S3.SS3.p1.2.m2.1.2.1"></times><apply id="S3.SS3.p1.2.m2.1.2.2.cmml" xref="S3.SS3.p1.2.m2.1.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.2.2.1.cmml" xref="S3.SS3.p1.2.m2.1.2.2">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.2.2.2.cmml" xref="S3.SS3.p1.2.m2.1.2.2.2">𝑇</ci><ci id="S3.SS3.p1.2.m2.1.2.2.3.cmml" xref="S3.SS3.p1.2.m2.1.2.2.3">𝑦</ci></apply><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">{T_{y}}\left(x\right)</annotation></semantics></math> is the probability of the model <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mi id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">T</annotation></semantics></math> outputs label <math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><mi id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><ci id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">y</annotation></semantics></math> for input <math id="S3.SS3.p1.5.m5.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS3.p1.5.m5.1a"><mi id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.1b"><ci id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.1c">x</annotation></semantics></math>. The access could be black-box <cite class="ltx_cite ltx_citemacro_citep">(Fredrikson
et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2015</a>)</cite> or white-box <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib226" title="" class="ltx_ref">2020a</a>; Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2020a</a>)</cite>.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1. </span>Black-box Attacks</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">In the black-box setting, the attacker can only make prediction queries to the model. Fredrikson et al. <cite class="ltx_cite ltx_citemacro_citep">(Fredrikson
et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2015</a>)</cite> built attack algorithms following the maximum a posterior principle. Their attack recovered a recognizable image of a person given only API access to a facial recognition system and a specific name of a target person. Yang et al. <cite class="ltx_cite ltx_citemacro_citep">(Yang
et al<span class="ltx_text">.</span>, <a href="#bib.bib204" title="" class="ltx_ref">2019a</a>)</cite> engineered an inversion model a perform the inversion attacks. The adversary composed an auxiliary set assumed generic enough to retain meaningful information to regularize the ill-posed inversion problem <cite class="ltx_cite ltx_citemacro_citep">(Salem et al<span class="ltx_text">.</span>, <a href="#bib.bib155" title="" class="ltx_ref">2020</a>)</cite>. However, the target model is usually assumed to be simple networks, and the generalization to complex models is not trivial. The inversion problem of a neural network is non-convex, and the optimization suffers minimal local problems, which leads to poor attack performance.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2. </span>White-box Attacks</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">n the white-box setting, the attacker has complete knowledge of the model. Zhang et al. <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib226" title="" class="ltx_ref">2020a</a>)</cite> sketched a generative model to learn an informative prior from the public dataset. This prior is then used to regulate the inversion problem. Benefiting from this, the authors revealed private training data of DNNs with high fidelity. Chen et al. <cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2020a</a>)</cite> boosted <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib226" title="" class="ltx_ref">2020a</a>)</cite>’s methods. They leveraged the target model to label a public dataset, and a GAN model was trained to distinguish not only
real and synthesized samples but also labels. They also modeled the private data distribution to reconstruct representative data points better. The success of model inversion attack benefits from an informative prior.</p>
</div>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.3. </span>Discussion</h4>

<div id="S3.SS3.SSS3.p1" class="ltx_para">
<p id="S3.SS3.SSS3.p1.1" class="ltx_p">MIAs can be performed with either black-box access or white-box access. When given black-box access, the attack’s success heavily relies on the auxiliary dataset, which is assumed to share the same generic features as the private target dataset. Furthermore, the target models in this category are usually simple due to limited access. In the white-box case, the target models extend to DNNs. Most attacks implement GAN to synthesize samples to mimic the private samples regarding the soft labels. This kind of attack is less common compared with reconstruction attacks in FL.</p>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>Reconstruction Attacks</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Unlike MIAs, reconstruction attacks attempt to retrieve training data and pose a much more severe threat to privacy. As demonstrated by Aono et al. <cite class="ltx_cite ltx_citemacro_citep">(Aono et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2017</a>)</cite>, the gradient of the weights is proportional to that of the bias in the first layer of the model, and their ratio approximates the training input. Geiping et al. <cite class="ltx_cite ltx_citemacro_citep">(Geiping et al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2020</a>)</cite> demonstrated that it is possible to faithfully reconstruct images at high resolution given knowledge of the parameter gradients. Such a privacy break is possible even for deep neural networks. Huang et al. <cite class="ltx_cite ltx_citemacro_citep">(Huang
et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2021</a>)</cite> evaluated existing reconstruction attacks and defenses. Gupta et al. <cite class="ltx_cite ltx_citemacro_citep">(Gupta
et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022</a>)</cite> extended this attack to text data and successfully reconstructed single sentences with high fidelity for large batch sizes. To date, we know of two kinds of reconstruction attacks, namely <span id="S3.SS4.p1.1.1" class="ltx_text ltx_font_italic">optimization-based attacks</span> (Opt-based) and <span id="S3.SS4.p1.1.2" class="ltx_text ltx_font_italic">closed-form attacks</span>.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3. </span>Comparison between two reconstruction attack categories</figcaption>
<table id="S3.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T3.1.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1.1" class="ltx_td ltx_border_t" style="padding:1.15pt 2.0pt;"></td>
<th id="S3.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:1.15pt 2.0pt;">
<table id="S3.T3.1.1.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T3.1.1.1.2.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.1.1.2.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Theoretical</span></td>
</tr>
<tr id="S3.T3.1.1.1.2.1.2" class="ltx_tr">
<td id="S3.T3.1.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.1.1.2.1.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">guarantee</span></td>
</tr>
</table>
</th>
<th id="S3.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Convergence</span></th>
<th id="S3.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:1.15pt 2.0pt;">
<table id="S3.T3.1.1.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T3.1.1.1.4.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.1.1.4.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Running</span></td>
</tr>
<tr id="S3.T3.1.1.1.4.1.2" class="ltx_tr">
<td id="S3.T3.1.1.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.1.1.4.1.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">time</span></td>
</tr>
</table>
</th>
<th id="S3.T3.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:1.15pt 2.0pt;">
<table id="S3.T3.1.1.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T3.1.1.1.5.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.1.1.5.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Recovered</span></td>
</tr>
<tr id="S3.T3.1.1.1.5.1.2" class="ltx_tr">
<td id="S3.T3.1.1.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.1.1.5.1.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">image</span></td>
</tr>
</table>
</th>
<th id="S3.T3.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.1.1.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Applicability</span></th>
<th id="S3.T3.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.1.1.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Insight</span></th>
</tr>
<tr id="S3.T3.1.2.2" class="ltx_tr">
<td id="S3.T3.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.2.2.1.1" class="ltx_text" style="font-size:90%;">Opt-based</span></td>
<td id="S3.T3.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.2.2.2.1" class="ltx_text" style="font-size:90%;">No</span></td>
<td id="S3.T3.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.2.2.3.1" class="ltx_text" style="font-size:90%;">Local optimal</span></td>
<td id="S3.T3.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.2.2.4.1" class="ltx_text" style="font-size:90%;">Slow</span></td>
<td id="S3.T3.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.2.2.5.1" class="ltx_text" style="font-size:90%;">With artifacts</span></td>
<td id="S3.T3.1.2.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.2.2.6.1" class="ltx_text" style="font-size:90%;">No limitation</span></td>
<td id="S3.T3.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.2.2.7.1" class="ltx_text" style="font-size:90%;">No</span></td>
</tr>
<tr id="S3.T3.1.3.3" class="ltx_tr">
<td id="S3.T3.1.3.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.3.3.1.1" class="ltx_text" style="font-size:90%;">Closed-form</span></td>
<td id="S3.T3.1.3.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.3.3.2.1" class="ltx_text" style="font-size:90%;">Yes</span></td>
<td id="S3.T3.1.3.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.3.3.3.1" class="ltx_text" style="font-size:90%;">/</span></td>
<td id="S3.T3.1.3.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.3.3.4.1" class="ltx_text" style="font-size:90%;">Fast</span></td>
<td id="S3.T3.1.3.3.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.3.3.5.1" class="ltx_text" style="font-size:90%;">Original</span></td>
<td id="S3.T3.1.3.3.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.3.3.6.1" class="ltx_text" style="font-size:90%;">Limited</span></td>
<td id="S3.T3.1.3.3.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:1.15pt 2.0pt;"><span id="S3.T3.1.3.3.7.1" class="ltx_text" style="font-size:90%;">Yes</span></td>
</tr>
</tbody>
</table>
</figure>
<section id="S3.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.1. </span>Optimization-based Attack</h4>

<div id="S3.SS4.SSS1.p1" class="ltx_para">
<p id="S3.SS4.SSS1.p1.6" class="ltx_p">Raw data can be reconstructed from gradients by solving an optimization problem. Given a machine learning model <math id="S3.SS4.SSS1.p1.1.m1.1" class="ltx_Math" alttext="f(w)" display="inline"><semantics id="S3.SS4.SSS1.p1.1.m1.1a"><mrow id="S3.SS4.SSS1.p1.1.m1.1.2" xref="S3.SS4.SSS1.p1.1.m1.1.2.cmml"><mi id="S3.SS4.SSS1.p1.1.m1.1.2.2" xref="S3.SS4.SSS1.p1.1.m1.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.SS4.SSS1.p1.1.m1.1.2.1" xref="S3.SS4.SSS1.p1.1.m1.1.2.1.cmml">​</mo><mrow id="S3.SS4.SSS1.p1.1.m1.1.2.3.2" xref="S3.SS4.SSS1.p1.1.m1.1.2.cmml"><mo stretchy="false" id="S3.SS4.SSS1.p1.1.m1.1.2.3.2.1" xref="S3.SS4.SSS1.p1.1.m1.1.2.cmml">(</mo><mi id="S3.SS4.SSS1.p1.1.m1.1.1" xref="S3.SS4.SSS1.p1.1.m1.1.1.cmml">w</mi><mo stretchy="false" id="S3.SS4.SSS1.p1.1.m1.1.2.3.2.2" xref="S3.SS4.SSS1.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p1.1.m1.1b"><apply id="S3.SS4.SSS1.p1.1.m1.1.2.cmml" xref="S3.SS4.SSS1.p1.1.m1.1.2"><times id="S3.SS4.SSS1.p1.1.m1.1.2.1.cmml" xref="S3.SS4.SSS1.p1.1.m1.1.2.1"></times><ci id="S3.SS4.SSS1.p1.1.m1.1.2.2.cmml" xref="S3.SS4.SSS1.p1.1.m1.1.2.2">𝑓</ci><ci id="S3.SS4.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS4.SSS1.p1.1.m1.1.1">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p1.1.m1.1c">f(w)</annotation></semantics></math> and the gradient <math id="S3.SS4.SSS1.p1.2.m2.2" class="ltx_Math" alttext="g=\frac{1}{b}\sum\nolimits_{j=1}^{b}{{\nabla_{w}}{L_{w}}\left({x_{j}^{*},y_{j}^{*}}\right)}" display="inline"><semantics id="S3.SS4.SSS1.p1.2.m2.2a"><mrow id="S3.SS4.SSS1.p1.2.m2.2.2" xref="S3.SS4.SSS1.p1.2.m2.2.2.cmml"><mi id="S3.SS4.SSS1.p1.2.m2.2.2.4" xref="S3.SS4.SSS1.p1.2.m2.2.2.4.cmml">g</mi><mo id="S3.SS4.SSS1.p1.2.m2.2.2.3" xref="S3.SS4.SSS1.p1.2.m2.2.2.3.cmml">=</mo><mrow id="S3.SS4.SSS1.p1.2.m2.2.2.2" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.cmml"><mfrac id="S3.SS4.SSS1.p1.2.m2.2.2.2.4" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.4.cmml"><mn id="S3.SS4.SSS1.p1.2.m2.2.2.2.4.2" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.4.2.cmml">1</mn><mi id="S3.SS4.SSS1.p1.2.m2.2.2.2.4.3" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.4.3.cmml">b</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.SS4.SSS1.p1.2.m2.2.2.2.3" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.3.cmml">​</mo><mrow id="S3.SS4.SSS1.p1.2.m2.2.2.2.2" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.cmml"><msubsup id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.cmml"><mo id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.2" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.2.cmml">∑</mo><mrow id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.3" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.3.cmml"><mi id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.3.2" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.3.2.cmml">j</mi><mo id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.3.1" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.3.1.cmml">=</mo><mn id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.3.3" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.3" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.3.cmml">b</mi></msubsup><mrow id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.cmml"><mrow id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.cmml"><msub id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.1" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.1.cmml"><mo rspace="0.167em" id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.1.2" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.1.2.cmml">∇</mo><mi id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.1.3" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.1.3.cmml">w</mi></msub><msub id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.2" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.2.cmml"><mi id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.2.2" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.2.2.cmml">L</mi><mi id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.2.3" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.2.3.cmml">w</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.3" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.3.cmml">​</mo><mrow id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.3.cmml"><mo id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.3" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.3.cmml">(</mo><msubsup id="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1" xref="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1.2.2" xref="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1.2.3" xref="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1.2.3.cmml">j</mi><mo id="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1.3" xref="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1.3.cmml">∗</mo></msubsup><mo id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.4" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.3.cmml">,</mo><msubsup id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2.cmml"><mi id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2.2.2" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2.2.2.cmml">y</mi><mi id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2.2.3" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2.2.3.cmml">j</mi><mo id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2.3" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2.3.cmml">∗</mo></msubsup><mo id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.5" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p1.2.m2.2b"><apply id="S3.SS4.SSS1.p1.2.m2.2.2.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2"><eq id="S3.SS4.SSS1.p1.2.m2.2.2.3.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.3"></eq><ci id="S3.SS4.SSS1.p1.2.m2.2.2.4.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.4">𝑔</ci><apply id="S3.SS4.SSS1.p1.2.m2.2.2.2.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2"><times id="S3.SS4.SSS1.p1.2.m2.2.2.2.3.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.3"></times><apply id="S3.SS4.SSS1.p1.2.m2.2.2.2.4.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.4"><divide id="S3.SS4.SSS1.p1.2.m2.2.2.2.4.1.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.4"></divide><cn type="integer" id="S3.SS4.SSS1.p1.2.m2.2.2.2.4.2.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.4.2">1</cn><ci id="S3.SS4.SSS1.p1.2.m2.2.2.2.4.3.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.4.3">𝑏</ci></apply><apply id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2"><apply id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.1.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3">superscript</csymbol><apply id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.1.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3">subscript</csymbol><sum id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.2.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.2"></sum><apply id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.3.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.3"><eq id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.3.1.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.3.1"></eq><ci id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.3.2.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.3.2">𝑗</ci><cn type="integer" id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.3.3.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.2.3.3">1</cn></apply></apply><ci id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.3.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.3.3">𝑏</ci></apply><apply id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2"><times id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.3.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.3"></times><apply id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4"><apply id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.1.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.1"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.1.1.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.1">subscript</csymbol><ci id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.1.2.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.1.2">∇</ci><ci id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.1.3.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.1.3">𝑤</ci></apply><apply id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.2.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.2"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.2.1.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.2">subscript</csymbol><ci id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.2.2.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.2.2">𝐿</ci><ci id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.2.3.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.4.2.3">𝑤</ci></apply></apply><interval closure="open" id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.3.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2"><apply id="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1.2.3">𝑗</ci></apply><times id="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS4.SSS1.p1.2.m2.1.1.1.1.1.1.1.1.3"></times></apply><apply id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2.1.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2">superscript</csymbol><apply id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2.2.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2.2.1.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2.2.2.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2.2.2">𝑦</ci><ci id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2.2.3.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2.2.3">𝑗</ci></apply><times id="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2.3.cmml" xref="S3.SS4.SSS1.p1.2.m2.2.2.2.2.2.2.2.2.3"></times></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p1.2.m2.2c">g=\frac{1}{b}\sum\nolimits_{j=1}^{b}{{\nabla_{w}}{L_{w}}\left({x_{j}^{*},y_{j}^{*}}\right)}</annotation></semantics></math> computed on a private batch <math id="S3.SS4.SSS1.p1.3.m3.2" class="ltx_Math" alttext="\left(x^{*},y^{*}\right)\in\mathbb{R}^{b\times d}\times\mathbb{R}^{b}" display="inline"><semantics id="S3.SS4.SSS1.p1.3.m3.2a"><mrow id="S3.SS4.SSS1.p1.3.m3.2.2" xref="S3.SS4.SSS1.p1.3.m3.2.2.cmml"><mrow id="S3.SS4.SSS1.p1.3.m3.2.2.2.2" xref="S3.SS4.SSS1.p1.3.m3.2.2.2.3.cmml"><mo id="S3.SS4.SSS1.p1.3.m3.2.2.2.2.3" xref="S3.SS4.SSS1.p1.3.m3.2.2.2.3.cmml">(</mo><msup id="S3.SS4.SSS1.p1.3.m3.1.1.1.1.1" xref="S3.SS4.SSS1.p1.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS4.SSS1.p1.3.m3.1.1.1.1.1.2" xref="S3.SS4.SSS1.p1.3.m3.1.1.1.1.1.2.cmml">x</mi><mo id="S3.SS4.SSS1.p1.3.m3.1.1.1.1.1.3" xref="S3.SS4.SSS1.p1.3.m3.1.1.1.1.1.3.cmml">∗</mo></msup><mo id="S3.SS4.SSS1.p1.3.m3.2.2.2.2.4" xref="S3.SS4.SSS1.p1.3.m3.2.2.2.3.cmml">,</mo><msup id="S3.SS4.SSS1.p1.3.m3.2.2.2.2.2" xref="S3.SS4.SSS1.p1.3.m3.2.2.2.2.2.cmml"><mi id="S3.SS4.SSS1.p1.3.m3.2.2.2.2.2.2" xref="S3.SS4.SSS1.p1.3.m3.2.2.2.2.2.2.cmml">y</mi><mo id="S3.SS4.SSS1.p1.3.m3.2.2.2.2.2.3" xref="S3.SS4.SSS1.p1.3.m3.2.2.2.2.2.3.cmml">∗</mo></msup><mo id="S3.SS4.SSS1.p1.3.m3.2.2.2.2.5" xref="S3.SS4.SSS1.p1.3.m3.2.2.2.3.cmml">)</mo></mrow><mo id="S3.SS4.SSS1.p1.3.m3.2.2.3" xref="S3.SS4.SSS1.p1.3.m3.2.2.3.cmml">∈</mo><mrow id="S3.SS4.SSS1.p1.3.m3.2.2.4" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.cmml"><msup id="S3.SS4.SSS1.p1.3.m3.2.2.4.2" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.2.cmml"><mi id="S3.SS4.SSS1.p1.3.m3.2.2.4.2.2" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.2.2.cmml">ℝ</mi><mrow id="S3.SS4.SSS1.p1.3.m3.2.2.4.2.3" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.2.3.cmml"><mi id="S3.SS4.SSS1.p1.3.m3.2.2.4.2.3.2" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.2.3.2.cmml">b</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS4.SSS1.p1.3.m3.2.2.4.2.3.1" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.2.3.1.cmml">×</mo><mi id="S3.SS4.SSS1.p1.3.m3.2.2.4.2.3.3" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.2.3.3.cmml">d</mi></mrow></msup><mo lspace="0.222em" rspace="0.222em" id="S3.SS4.SSS1.p1.3.m3.2.2.4.1" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.1.cmml">×</mo><msup id="S3.SS4.SSS1.p1.3.m3.2.2.4.3" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.3.cmml"><mi id="S3.SS4.SSS1.p1.3.m3.2.2.4.3.2" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.3.2.cmml">ℝ</mi><mi id="S3.SS4.SSS1.p1.3.m3.2.2.4.3.3" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.3.3.cmml">b</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p1.3.m3.2b"><apply id="S3.SS4.SSS1.p1.3.m3.2.2.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2"><in id="S3.SS4.SSS1.p1.3.m3.2.2.3.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.3"></in><interval closure="open" id="S3.SS4.SSS1.p1.3.m3.2.2.2.3.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.2.2"><apply id="S3.SS4.SSS1.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS4.SSS1.p1.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p1.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS4.SSS1.p1.3.m3.1.1.1.1.1">superscript</csymbol><ci id="S3.SS4.SSS1.p1.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS4.SSS1.p1.3.m3.1.1.1.1.1.2">𝑥</ci><times id="S3.SS4.SSS1.p1.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS4.SSS1.p1.3.m3.1.1.1.1.1.3"></times></apply><apply id="S3.SS4.SSS1.p1.3.m3.2.2.2.2.2.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p1.3.m3.2.2.2.2.2.1.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.2.2.2">superscript</csymbol><ci id="S3.SS4.SSS1.p1.3.m3.2.2.2.2.2.2.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.2.2.2.2">𝑦</ci><times id="S3.SS4.SSS1.p1.3.m3.2.2.2.2.2.3.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.2.2.2.3"></times></apply></interval><apply id="S3.SS4.SSS1.p1.3.m3.2.2.4.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.4"><times id="S3.SS4.SSS1.p1.3.m3.2.2.4.1.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.1"></times><apply id="S3.SS4.SSS1.p1.3.m3.2.2.4.2.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.2"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p1.3.m3.2.2.4.2.1.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.2">superscript</csymbol><ci id="S3.SS4.SSS1.p1.3.m3.2.2.4.2.2.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.2.2">ℝ</ci><apply id="S3.SS4.SSS1.p1.3.m3.2.2.4.2.3.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.2.3"><times id="S3.SS4.SSS1.p1.3.m3.2.2.4.2.3.1.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.2.3.1"></times><ci id="S3.SS4.SSS1.p1.3.m3.2.2.4.2.3.2.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.2.3.2">𝑏</ci><ci id="S3.SS4.SSS1.p1.3.m3.2.2.4.2.3.3.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.2.3.3">𝑑</ci></apply></apply><apply id="S3.SS4.SSS1.p1.3.m3.2.2.4.3.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.3"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p1.3.m3.2.2.4.3.1.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.3">superscript</csymbol><ci id="S3.SS4.SSS1.p1.3.m3.2.2.4.3.2.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.3.2">ℝ</ci><ci id="S3.SS4.SSS1.p1.3.m3.2.2.4.3.3.cmml" xref="S3.SS4.SSS1.p1.3.m3.2.2.4.3.3">𝑏</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p1.3.m3.2c">\left(x^{*},y^{*}\right)\in\mathbb{R}^{b\times d}\times\mathbb{R}^{b}</annotation></semantics></math> with bath size <math id="S3.SS4.SSS1.p1.4.m4.1" class="ltx_Math" alttext="b" display="inline"><semantics id="S3.SS4.SSS1.p1.4.m4.1a"><mi id="S3.SS4.SSS1.p1.4.m4.1.1" xref="S3.SS4.SSS1.p1.4.m4.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p1.4.m4.1b"><ci id="S3.SS4.SSS1.p1.4.m4.1.1.cmml" xref="S3.SS4.SSS1.p1.4.m4.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p1.4.m4.1c">b</annotation></semantics></math>. The adversary tries to reconstruct <math id="S3.SS4.SSS1.p1.5.m5.1" class="ltx_Math" alttext="x\in\mathbb{R}^{b\times d}" display="inline"><semantics id="S3.SS4.SSS1.p1.5.m5.1a"><mrow id="S3.SS4.SSS1.p1.5.m5.1.1" xref="S3.SS4.SSS1.p1.5.m5.1.1.cmml"><mi id="S3.SS4.SSS1.p1.5.m5.1.1.2" xref="S3.SS4.SSS1.p1.5.m5.1.1.2.cmml">x</mi><mo id="S3.SS4.SSS1.p1.5.m5.1.1.1" xref="S3.SS4.SSS1.p1.5.m5.1.1.1.cmml">∈</mo><msup id="S3.SS4.SSS1.p1.5.m5.1.1.3" xref="S3.SS4.SSS1.p1.5.m5.1.1.3.cmml"><mi id="S3.SS4.SSS1.p1.5.m5.1.1.3.2" xref="S3.SS4.SSS1.p1.5.m5.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS4.SSS1.p1.5.m5.1.1.3.3" xref="S3.SS4.SSS1.p1.5.m5.1.1.3.3.cmml"><mi id="S3.SS4.SSS1.p1.5.m5.1.1.3.3.2" xref="S3.SS4.SSS1.p1.5.m5.1.1.3.3.2.cmml">b</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS4.SSS1.p1.5.m5.1.1.3.3.1" xref="S3.SS4.SSS1.p1.5.m5.1.1.3.3.1.cmml">×</mo><mi id="S3.SS4.SSS1.p1.5.m5.1.1.3.3.3" xref="S3.SS4.SSS1.p1.5.m5.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p1.5.m5.1b"><apply id="S3.SS4.SSS1.p1.5.m5.1.1.cmml" xref="S3.SS4.SSS1.p1.5.m5.1.1"><in id="S3.SS4.SSS1.p1.5.m5.1.1.1.cmml" xref="S3.SS4.SSS1.p1.5.m5.1.1.1"></in><ci id="S3.SS4.SSS1.p1.5.m5.1.1.2.cmml" xref="S3.SS4.SSS1.p1.5.m5.1.1.2">𝑥</ci><apply id="S3.SS4.SSS1.p1.5.m5.1.1.3.cmml" xref="S3.SS4.SSS1.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p1.5.m5.1.1.3.1.cmml" xref="S3.SS4.SSS1.p1.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS4.SSS1.p1.5.m5.1.1.3.2.cmml" xref="S3.SS4.SSS1.p1.5.m5.1.1.3.2">ℝ</ci><apply id="S3.SS4.SSS1.p1.5.m5.1.1.3.3.cmml" xref="S3.SS4.SSS1.p1.5.m5.1.1.3.3"><times id="S3.SS4.SSS1.p1.5.m5.1.1.3.3.1.cmml" xref="S3.SS4.SSS1.p1.5.m5.1.1.3.3.1"></times><ci id="S3.SS4.SSS1.p1.5.m5.1.1.3.3.2.cmml" xref="S3.SS4.SSS1.p1.5.m5.1.1.3.3.2">𝑏</ci><ci id="S3.SS4.SSS1.p1.5.m5.1.1.3.3.3.cmml" xref="S3.SS4.SSS1.p1.5.m5.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p1.5.m5.1c">x\in\mathbb{R}^{b\times d}</annotation></semantics></math> as an approximation of the true data <math id="S3.SS4.SSS1.p1.6.m6.1" class="ltx_Math" alttext="{x^{*}}" display="inline"><semantics id="S3.SS4.SSS1.p1.6.m6.1a"><msup id="S3.SS4.SSS1.p1.6.m6.1.1" xref="S3.SS4.SSS1.p1.6.m6.1.1.cmml"><mi id="S3.SS4.SSS1.p1.6.m6.1.1.2" xref="S3.SS4.SSS1.p1.6.m6.1.1.2.cmml">x</mi><mo id="S3.SS4.SSS1.p1.6.m6.1.1.3" xref="S3.SS4.SSS1.p1.6.m6.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p1.6.m6.1b"><apply id="S3.SS4.SSS1.p1.6.m6.1.1.cmml" xref="S3.SS4.SSS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p1.6.m6.1.1.1.cmml" xref="S3.SS4.SSS1.p1.6.m6.1.1">superscript</csymbol><ci id="S3.SS4.SSS1.p1.6.m6.1.1.2.cmml" xref="S3.SS4.SSS1.p1.6.m6.1.1.2">𝑥</ci><times id="S3.SS4.SSS1.p1.6.m6.1.1.3.cmml" xref="S3.SS4.SSS1.p1.6.m6.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p1.6.m6.1c">{x^{*}}</annotation></semantics></math> by solving the following optimization problem:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.4" class="ltx_Math" alttext="\arg\mathop{\min}\limits_{x}{\mathcal{L}_{grad}}\left(x;w,g\right)+\alpha{\mathcal{R}_{aux}}\left(x\right)" display="block"><semantics id="S3.E3.m1.4a"><mrow id="S3.E3.m1.4.5" xref="S3.E3.m1.4.5.cmml"><mrow id="S3.E3.m1.4.5.2" xref="S3.E3.m1.4.5.2.cmml"><mi id="S3.E3.m1.4.5.2.2" xref="S3.E3.m1.4.5.2.2.cmml">arg</mi><mo lspace="0.167em" rspace="0em" id="S3.E3.m1.4.5.2.1" xref="S3.E3.m1.4.5.2.1.cmml">​</mo><mrow id="S3.E3.m1.4.5.2.3" xref="S3.E3.m1.4.5.2.3.cmml"><munder id="S3.E3.m1.4.5.2.3.1" xref="S3.E3.m1.4.5.2.3.1.cmml"><mo movablelimits="false" rspace="0.167em" id="S3.E3.m1.4.5.2.3.1.2" xref="S3.E3.m1.4.5.2.3.1.2.cmml">min</mo><mi id="S3.E3.m1.4.5.2.3.1.3" xref="S3.E3.m1.4.5.2.3.1.3.cmml">x</mi></munder><mrow id="S3.E3.m1.4.5.2.3.2" xref="S3.E3.m1.4.5.2.3.2.cmml"><msub id="S3.E3.m1.4.5.2.3.2.2" xref="S3.E3.m1.4.5.2.3.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.4.5.2.3.2.2.2" xref="S3.E3.m1.4.5.2.3.2.2.2.cmml">ℒ</mi><mrow id="S3.E3.m1.4.5.2.3.2.2.3" xref="S3.E3.m1.4.5.2.3.2.2.3.cmml"><mi id="S3.E3.m1.4.5.2.3.2.2.3.2" xref="S3.E3.m1.4.5.2.3.2.2.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.5.2.3.2.2.3.1" xref="S3.E3.m1.4.5.2.3.2.2.3.1.cmml">​</mo><mi id="S3.E3.m1.4.5.2.3.2.2.3.3" xref="S3.E3.m1.4.5.2.3.2.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.5.2.3.2.2.3.1a" xref="S3.E3.m1.4.5.2.3.2.2.3.1.cmml">​</mo><mi id="S3.E3.m1.4.5.2.3.2.2.3.4" xref="S3.E3.m1.4.5.2.3.2.2.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.5.2.3.2.2.3.1b" xref="S3.E3.m1.4.5.2.3.2.2.3.1.cmml">​</mo><mi id="S3.E3.m1.4.5.2.3.2.2.3.5" xref="S3.E3.m1.4.5.2.3.2.2.3.5.cmml">d</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.5.2.3.2.1" xref="S3.E3.m1.4.5.2.3.2.1.cmml">​</mo><mrow id="S3.E3.m1.4.5.2.3.2.3.2" xref="S3.E3.m1.4.5.2.3.2.3.1.cmml"><mo id="S3.E3.m1.4.5.2.3.2.3.2.1" xref="S3.E3.m1.4.5.2.3.2.3.1.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">x</mi><mo id="S3.E3.m1.4.5.2.3.2.3.2.2" xref="S3.E3.m1.4.5.2.3.2.3.1.cmml">;</mo><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">w</mi><mo id="S3.E3.m1.4.5.2.3.2.3.2.3" xref="S3.E3.m1.4.5.2.3.2.3.1.cmml">,</mo><mi id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml">g</mi><mo id="S3.E3.m1.4.5.2.3.2.3.2.4" xref="S3.E3.m1.4.5.2.3.2.3.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E3.m1.4.5.1" xref="S3.E3.m1.4.5.1.cmml">+</mo><mrow id="S3.E3.m1.4.5.3" xref="S3.E3.m1.4.5.3.cmml"><mi id="S3.E3.m1.4.5.3.2" xref="S3.E3.m1.4.5.3.2.cmml">α</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.5.3.1" xref="S3.E3.m1.4.5.3.1.cmml">​</mo><msub id="S3.E3.m1.4.5.3.3" xref="S3.E3.m1.4.5.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.4.5.3.3.2" xref="S3.E3.m1.4.5.3.3.2.cmml">ℛ</mi><mrow id="S3.E3.m1.4.5.3.3.3" xref="S3.E3.m1.4.5.3.3.3.cmml"><mi id="S3.E3.m1.4.5.3.3.3.2" xref="S3.E3.m1.4.5.3.3.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.5.3.3.3.1" xref="S3.E3.m1.4.5.3.3.3.1.cmml">​</mo><mi id="S3.E3.m1.4.5.3.3.3.3" xref="S3.E3.m1.4.5.3.3.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.5.3.3.3.1a" xref="S3.E3.m1.4.5.3.3.3.1.cmml">​</mo><mi id="S3.E3.m1.4.5.3.3.3.4" xref="S3.E3.m1.4.5.3.3.3.4.cmml">x</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.5.3.1a" xref="S3.E3.m1.4.5.3.1.cmml">​</mo><mrow id="S3.E3.m1.4.5.3.4.2" xref="S3.E3.m1.4.5.3.cmml"><mo id="S3.E3.m1.4.5.3.4.2.1" xref="S3.E3.m1.4.5.3.cmml">(</mo><mi id="S3.E3.m1.4.4" xref="S3.E3.m1.4.4.cmml">x</mi><mo id="S3.E3.m1.4.5.3.4.2.2" xref="S3.E3.m1.4.5.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.4b"><apply id="S3.E3.m1.4.5.cmml" xref="S3.E3.m1.4.5"><plus id="S3.E3.m1.4.5.1.cmml" xref="S3.E3.m1.4.5.1"></plus><apply id="S3.E3.m1.4.5.2.cmml" xref="S3.E3.m1.4.5.2"><times id="S3.E3.m1.4.5.2.1.cmml" xref="S3.E3.m1.4.5.2.1"></times><arg id="S3.E3.m1.4.5.2.2.cmml" xref="S3.E3.m1.4.5.2.2"></arg><apply id="S3.E3.m1.4.5.2.3.cmml" xref="S3.E3.m1.4.5.2.3"><apply id="S3.E3.m1.4.5.2.3.1.cmml" xref="S3.E3.m1.4.5.2.3.1"><csymbol cd="ambiguous" id="S3.E3.m1.4.5.2.3.1.1.cmml" xref="S3.E3.m1.4.5.2.3.1">subscript</csymbol><min id="S3.E3.m1.4.5.2.3.1.2.cmml" xref="S3.E3.m1.4.5.2.3.1.2"></min><ci id="S3.E3.m1.4.5.2.3.1.3.cmml" xref="S3.E3.m1.4.5.2.3.1.3">𝑥</ci></apply><apply id="S3.E3.m1.4.5.2.3.2.cmml" xref="S3.E3.m1.4.5.2.3.2"><times id="S3.E3.m1.4.5.2.3.2.1.cmml" xref="S3.E3.m1.4.5.2.3.2.1"></times><apply id="S3.E3.m1.4.5.2.3.2.2.cmml" xref="S3.E3.m1.4.5.2.3.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.4.5.2.3.2.2.1.cmml" xref="S3.E3.m1.4.5.2.3.2.2">subscript</csymbol><ci id="S3.E3.m1.4.5.2.3.2.2.2.cmml" xref="S3.E3.m1.4.5.2.3.2.2.2">ℒ</ci><apply id="S3.E3.m1.4.5.2.3.2.2.3.cmml" xref="S3.E3.m1.4.5.2.3.2.2.3"><times id="S3.E3.m1.4.5.2.3.2.2.3.1.cmml" xref="S3.E3.m1.4.5.2.3.2.2.3.1"></times><ci id="S3.E3.m1.4.5.2.3.2.2.3.2.cmml" xref="S3.E3.m1.4.5.2.3.2.2.3.2">𝑔</ci><ci id="S3.E3.m1.4.5.2.3.2.2.3.3.cmml" xref="S3.E3.m1.4.5.2.3.2.2.3.3">𝑟</ci><ci id="S3.E3.m1.4.5.2.3.2.2.3.4.cmml" xref="S3.E3.m1.4.5.2.3.2.2.3.4">𝑎</ci><ci id="S3.E3.m1.4.5.2.3.2.2.3.5.cmml" xref="S3.E3.m1.4.5.2.3.2.2.3.5">𝑑</ci></apply></apply><list id="S3.E3.m1.4.5.2.3.2.3.1.cmml" xref="S3.E3.m1.4.5.2.3.2.3.2"><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">𝑥</ci><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">𝑤</ci><ci id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3">𝑔</ci></list></apply></apply></apply><apply id="S3.E3.m1.4.5.3.cmml" xref="S3.E3.m1.4.5.3"><times id="S3.E3.m1.4.5.3.1.cmml" xref="S3.E3.m1.4.5.3.1"></times><ci id="S3.E3.m1.4.5.3.2.cmml" xref="S3.E3.m1.4.5.3.2">𝛼</ci><apply id="S3.E3.m1.4.5.3.3.cmml" xref="S3.E3.m1.4.5.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.4.5.3.3.1.cmml" xref="S3.E3.m1.4.5.3.3">subscript</csymbol><ci id="S3.E3.m1.4.5.3.3.2.cmml" xref="S3.E3.m1.4.5.3.3.2">ℛ</ci><apply id="S3.E3.m1.4.5.3.3.3.cmml" xref="S3.E3.m1.4.5.3.3.3"><times id="S3.E3.m1.4.5.3.3.3.1.cmml" xref="S3.E3.m1.4.5.3.3.3.1"></times><ci id="S3.E3.m1.4.5.3.3.3.2.cmml" xref="S3.E3.m1.4.5.3.3.3.2">𝑎</ci><ci id="S3.E3.m1.4.5.3.3.3.3.cmml" xref="S3.E3.m1.4.5.3.3.3.3">𝑢</ci><ci id="S3.E3.m1.4.5.3.3.3.4.cmml" xref="S3.E3.m1.4.5.3.3.3.4">𝑥</ci></apply></apply><ci id="S3.E3.m1.4.4.cmml" xref="S3.E3.m1.4.4">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.4c">\arg\mathop{\min}\limits_{x}{\mathcal{L}_{grad}}\left(x;w,g\right)+\alpha{\mathcal{R}_{aux}}\left(x\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS4.SSS1.p1.8" class="ltx_p">The first part of Eq. <a href="#S3.E3" title="In 3.4.1. Optimization-based Attack ‣ 3.4. Reconstruction Attacks ‣ 3. Privacy in FL ‣ Privacy and Fairness in Federated Learning: on the Perspective of Trade-off" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> pushes the recovered gradients towards the true gradients <math id="S3.SS4.SSS1.p1.7.m1.1" class="ltx_Math" alttext="g" display="inline"><semantics id="S3.SS4.SSS1.p1.7.m1.1a"><mi id="S3.SS4.SSS1.p1.7.m1.1.1" xref="S3.SS4.SSS1.p1.7.m1.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p1.7.m1.1b"><ci id="S3.SS4.SSS1.p1.7.m1.1.1.cmml" xref="S3.SS4.SSS1.p1.7.m1.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p1.7.m1.1c">g</annotation></semantics></math>, hence deducing a better approximation. The regularization term <math id="S3.SS4.SSS1.p1.8.m2.1" class="ltx_Math" alttext="{\mathcal{R}_{aux}}\left(x\right)" display="inline"><semantics id="S3.SS4.SSS1.p1.8.m2.1a"><mrow id="S3.SS4.SSS1.p1.8.m2.1.2" xref="S3.SS4.SSS1.p1.8.m2.1.2.cmml"><msub id="S3.SS4.SSS1.p1.8.m2.1.2.2" xref="S3.SS4.SSS1.p1.8.m2.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.SSS1.p1.8.m2.1.2.2.2" xref="S3.SS4.SSS1.p1.8.m2.1.2.2.2.cmml">ℛ</mi><mrow id="S3.SS4.SSS1.p1.8.m2.1.2.2.3" xref="S3.SS4.SSS1.p1.8.m2.1.2.2.3.cmml"><mi id="S3.SS4.SSS1.p1.8.m2.1.2.2.3.2" xref="S3.SS4.SSS1.p1.8.m2.1.2.2.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS4.SSS1.p1.8.m2.1.2.2.3.1" xref="S3.SS4.SSS1.p1.8.m2.1.2.2.3.1.cmml">​</mo><mi id="S3.SS4.SSS1.p1.8.m2.1.2.2.3.3" xref="S3.SS4.SSS1.p1.8.m2.1.2.2.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS4.SSS1.p1.8.m2.1.2.2.3.1a" xref="S3.SS4.SSS1.p1.8.m2.1.2.2.3.1.cmml">​</mo><mi id="S3.SS4.SSS1.p1.8.m2.1.2.2.3.4" xref="S3.SS4.SSS1.p1.8.m2.1.2.2.3.4.cmml">x</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.SS4.SSS1.p1.8.m2.1.2.1" xref="S3.SS4.SSS1.p1.8.m2.1.2.1.cmml">​</mo><mrow id="S3.SS4.SSS1.p1.8.m2.1.2.3.2" xref="S3.SS4.SSS1.p1.8.m2.1.2.cmml"><mo id="S3.SS4.SSS1.p1.8.m2.1.2.3.2.1" xref="S3.SS4.SSS1.p1.8.m2.1.2.cmml">(</mo><mi id="S3.SS4.SSS1.p1.8.m2.1.1" xref="S3.SS4.SSS1.p1.8.m2.1.1.cmml">x</mi><mo id="S3.SS4.SSS1.p1.8.m2.1.2.3.2.2" xref="S3.SS4.SSS1.p1.8.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p1.8.m2.1b"><apply id="S3.SS4.SSS1.p1.8.m2.1.2.cmml" xref="S3.SS4.SSS1.p1.8.m2.1.2"><times id="S3.SS4.SSS1.p1.8.m2.1.2.1.cmml" xref="S3.SS4.SSS1.p1.8.m2.1.2.1"></times><apply id="S3.SS4.SSS1.p1.8.m2.1.2.2.cmml" xref="S3.SS4.SSS1.p1.8.m2.1.2.2"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p1.8.m2.1.2.2.1.cmml" xref="S3.SS4.SSS1.p1.8.m2.1.2.2">subscript</csymbol><ci id="S3.SS4.SSS1.p1.8.m2.1.2.2.2.cmml" xref="S3.SS4.SSS1.p1.8.m2.1.2.2.2">ℛ</ci><apply id="S3.SS4.SSS1.p1.8.m2.1.2.2.3.cmml" xref="S3.SS4.SSS1.p1.8.m2.1.2.2.3"><times id="S3.SS4.SSS1.p1.8.m2.1.2.2.3.1.cmml" xref="S3.SS4.SSS1.p1.8.m2.1.2.2.3.1"></times><ci id="S3.SS4.SSS1.p1.8.m2.1.2.2.3.2.cmml" xref="S3.SS4.SSS1.p1.8.m2.1.2.2.3.2">𝑎</ci><ci id="S3.SS4.SSS1.p1.8.m2.1.2.2.3.3.cmml" xref="S3.SS4.SSS1.p1.8.m2.1.2.2.3.3">𝑢</ci><ci id="S3.SS4.SSS1.p1.8.m2.1.2.2.3.4.cmml" xref="S3.SS4.SSS1.p1.8.m2.1.2.2.3.4">𝑥</ci></apply></apply><ci id="S3.SS4.SSS1.p1.8.m2.1.1.cmml" xref="S3.SS4.SSS1.p1.8.m2.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p1.8.m2.1c">{\mathcal{R}_{aux}}\left(x\right)</annotation></semantics></math> is used to incorporate the prior knowledge to further improve reconstruction.</p>
</div>
<div id="S3.SS4.SSS1.p2" class="ltx_para">
<p id="S3.SS4.SSS1.p2.2" class="ltx_p">Zhu and Han <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib232" title="" class="ltx_ref">2019</a>)</cite> proposed <span id="S3.SS4.SSS1.p2.2.1" class="ltx_text ltx_font_italic">DLG</span> attack with <math id="S3.SS4.SSS1.p2.1.m1.1" class="ltx_Math" alttext="l_{2}" display="inline"><semantics id="S3.SS4.SSS1.p2.1.m1.1a"><msub id="S3.SS4.SSS1.p2.1.m1.1.1" xref="S3.SS4.SSS1.p2.1.m1.1.1.cmml"><mi id="S3.SS4.SSS1.p2.1.m1.1.1.2" xref="S3.SS4.SSS1.p2.1.m1.1.1.2.cmml">l</mi><mn id="S3.SS4.SSS1.p2.1.m1.1.1.3" xref="S3.SS4.SSS1.p2.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p2.1.m1.1b"><apply id="S3.SS4.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS4.SSS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p2.1.m1.1.1.1.cmml" xref="S3.SS4.SSS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.SSS1.p2.1.m1.1.1.2.cmml" xref="S3.SS4.SSS1.p2.1.m1.1.1.2">𝑙</ci><cn type="integer" id="S3.SS4.SSS1.p2.1.m1.1.1.3.cmml" xref="S3.SS4.SSS1.p2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p2.1.m1.1c">l_{2}</annotation></semantics></math> distance as the reconstruction loss <math id="S3.SS4.SSS1.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{grad}" display="inline"><semantics id="S3.SS4.SSS1.p2.2.m2.1a"><msub id="S3.SS4.SSS1.p2.2.m2.1.1" xref="S3.SS4.SSS1.p2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.SSS1.p2.2.m2.1.1.2" xref="S3.SS4.SSS1.p2.2.m2.1.1.2.cmml">ℒ</mi><mrow id="S3.SS4.SSS1.p2.2.m2.1.1.3" xref="S3.SS4.SSS1.p2.2.m2.1.1.3.cmml"><mi id="S3.SS4.SSS1.p2.2.m2.1.1.3.2" xref="S3.SS4.SSS1.p2.2.m2.1.1.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS4.SSS1.p2.2.m2.1.1.3.1" xref="S3.SS4.SSS1.p2.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS4.SSS1.p2.2.m2.1.1.3.3" xref="S3.SS4.SSS1.p2.2.m2.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS4.SSS1.p2.2.m2.1.1.3.1a" xref="S3.SS4.SSS1.p2.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS4.SSS1.p2.2.m2.1.1.3.4" xref="S3.SS4.SSS1.p2.2.m2.1.1.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS4.SSS1.p2.2.m2.1.1.3.1b" xref="S3.SS4.SSS1.p2.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS4.SSS1.p2.2.m2.1.1.3.5" xref="S3.SS4.SSS1.p2.2.m2.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p2.2.m2.1b"><apply id="S3.SS4.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS4.SSS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p2.2.m2.1.1.1.cmml" xref="S3.SS4.SSS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.SSS1.p2.2.m2.1.1.2.cmml" xref="S3.SS4.SSS1.p2.2.m2.1.1.2">ℒ</ci><apply id="S3.SS4.SSS1.p2.2.m2.1.1.3.cmml" xref="S3.SS4.SSS1.p2.2.m2.1.1.3"><times id="S3.SS4.SSS1.p2.2.m2.1.1.3.1.cmml" xref="S3.SS4.SSS1.p2.2.m2.1.1.3.1"></times><ci id="S3.SS4.SSS1.p2.2.m2.1.1.3.2.cmml" xref="S3.SS4.SSS1.p2.2.m2.1.1.3.2">𝑔</ci><ci id="S3.SS4.SSS1.p2.2.m2.1.1.3.3.cmml" xref="S3.SS4.SSS1.p2.2.m2.1.1.3.3">𝑟</ci><ci id="S3.SS4.SSS1.p2.2.m2.1.1.3.4.cmml" xref="S3.SS4.SSS1.p2.2.m2.1.1.3.4">𝑎</ci><ci id="S3.SS4.SSS1.p2.2.m2.1.1.3.5.cmml" xref="S3.SS4.SSS1.p2.2.m2.1.1.3.5">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p2.2.m2.1c">\mathcal{L}_{grad}</annotation></semantics></math>. <span id="S3.SS4.SSS1.p2.2.2" class="ltx_text ltx_font_italic">DLG</span> starts with randomly generated dummy samples and then iteratively optimizes the dummy samples and labels until they converge. Finally, <span id="S3.SS4.SSS1.p2.2.3" class="ltx_text ltx_font_italic">DLG</span> achieves pixel-wise recovery accuracy for image classification and token-wise recovery accuracy for a masked language model. Zhao et al. <cite class="ltx_cite ltx_citemacro_citep">(Zhao
et al<span class="ltx_text">.</span>, <a href="#bib.bib227" title="" class="ltx_ref">2020</a>)</cite> improved Zhu and Han’s work <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib232" title="" class="ltx_ref">2019</a>)</cite> on convergence speed and reconstruction fidelity by leveraging the relationship between the ground-truth labels and the signs of the gradients.</p>
</div>
<div id="S3.SS4.SSS1.p3" class="ltx_para">
<p id="S3.SS4.SSS1.p3.2" class="ltx_p">The optimization problem Eq. <a href="#S3.E3" title="In 3.4.1. Optimization-based Attack ‣ 3.4. Reconstruction Attacks ‣ 3. Privacy in FL ‣ Privacy and Fairness in Federated Learning: on the Perspective of Trade-off" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> is often under-determined <cite class="ltx_cite ltx_citemacro_citep">(Jeon
et al<span class="ltx_text">.</span>, <a href="#bib.bib83" title="" class="ltx_ref">2021</a>)</cite>, as the information in the gradients <math id="S3.SS4.SSS1.p3.1.m1.1" class="ltx_Math" alttext="g" display="inline"><semantics id="S3.SS4.SSS1.p3.1.m1.1a"><mi id="S3.SS4.SSS1.p3.1.m1.1.1" xref="S3.SS4.SSS1.p3.1.m1.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p3.1.m1.1b"><ci id="S3.SS4.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS4.SSS1.p3.1.m1.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p3.1.m1.1c">g</annotation></semantics></math> is usually insufficient to recover the training data <math id="S3.SS4.SSS1.p3.2.m2.1" class="ltx_Math" alttext="{x^{*}}" display="inline"><semantics id="S3.SS4.SSS1.p3.2.m2.1a"><msup id="S3.SS4.SSS1.p3.2.m2.1.1" xref="S3.SS4.SSS1.p3.2.m2.1.1.cmml"><mi id="S3.SS4.SSS1.p3.2.m2.1.1.2" xref="S3.SS4.SSS1.p3.2.m2.1.1.2.cmml">x</mi><mo id="S3.SS4.SSS1.p3.2.m2.1.1.3" xref="S3.SS4.SSS1.p3.2.m2.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p3.2.m2.1b"><apply id="S3.SS4.SSS1.p3.2.m2.1.1.cmml" xref="S3.SS4.SSS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p3.2.m2.1.1.1.cmml" xref="S3.SS4.SSS1.p3.2.m2.1.1">superscript</csymbol><ci id="S3.SS4.SSS1.p3.2.m2.1.1.2.cmml" xref="S3.SS4.SSS1.p3.2.m2.1.1.2">𝑥</ci><times id="S3.SS4.SSS1.p3.2.m2.1.1.3.cmml" xref="S3.SS4.SSS1.p3.2.m2.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p3.2.m2.1c">{x^{*}}</annotation></semantics></math>. Even when the gradient size is substantially bigger than the input data dimension. As demonstrated by Zhu and Blaschko <cite class="ltx_cite ltx_citemacro_citep">(Zhu and Blaschko, <a href="#bib.bib231" title="" class="ltx_ref">2020</a>)</cite>, when the learning model is huge, there may be a pair of separate data sharing the same gradient.</p>
</div>
<div id="S3.SS4.SSS1.p4" class="ltx_para">
<p id="S3.SS4.SSS1.p4.1" class="ltx_p">In response to this, one may introduce prior knowledge as a regularization term to narrow the search space, making it more consistent with the underlying distribution of training data. Yin et al. <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib208" title="" class="ltx_ref">2021a</a>)</cite> utilized the local batch norm as the regularization term since adjacent pixels in natural photographs are likely to have comparable values. They achieved precise recovery of the high-resolution images on complex datasets, deep networks, and large batch sizes. Hatamizadeh et al. <cite class="ltx_cite ltx_citemacro_citep">(Hatamizadeh et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2022</a>)</cite> extended <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib208" title="" class="ltx_ref">2021a</a>)</cite>’s approach to vision transformers and discovered that, because of the attention mechanism, vision transformers are substantially more sensitive than previously researched CNNs. In the image domain, total variance is another choice <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib190" title="" class="ltx_ref">2019a</a>; Geiping et al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S3.SS4.SSS1.p5" class="ltx_para">
<p id="S3.SS4.SSS1.p5.1" class="ltx_p">Selecting a proper loss function can also contribute to attack efficiency. By combining mean square error and Wasserstein distance <cite class="ltx_cite ltx_citemacro_citep">(Arjovsky
et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2017</a>)</cite>, Ren et al. <cite class="ltx_cite ltx_citemacro_citep">(Ren et al<span class="ltx_text">.</span>, <a href="#bib.bib154" title="" class="ltx_ref">2022</a>)</cite> achieved a better reconstruction result than <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib232" title="" class="ltx_ref">2019</a>; Zhao
et al<span class="ltx_text">.</span>, <a href="#bib.bib227" title="" class="ltx_ref">2020</a>)</cite> in terms of batch size and reconstruction fidelity. Geiping et al. <cite class="ltx_cite ltx_citemacro_citep">(Geiping et al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2020</a>)</cite> adopted cosine distances to better capture the observation that the angle between two data points quantifies the change in prediction. With this method, they rebuilt a single high-resolution image and a series of low-resolution photos with a maximum batch size of 100. Jeon et al. <cite class="ltx_cite ltx_citemacro_citep">(Jeon
et al<span class="ltx_text">.</span>, <a href="#bib.bib83" title="" class="ltx_ref">2021</a>)</cite> systematically investigated ways to best utilize gradients, including using them to extract prior information. Wei et al. <cite class="ltx_cite ltx_citemacro_citep">(Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib193" title="" class="ltx_ref">2020b</a>)</cite> conducted a thorough analysis of how different hyper-parameter setups and settings for attack algorithms influence the effectiveness of the attack and its cost. In an effort to investigate the worst-case attack and evaluate the effectiveness of defense methods for reconstruction attacks, Balunovic et al. <cite class="ltx_cite ltx_citemacro_citep">(Balunović et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2021</a>)</cite> formulated the gradient leakage problem in a Bayesian framework and analyzed the condition for a Bayes optimal adversary.</p>
</div>
</section>
<section id="S3.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.2. </span>Closed-form Attack</h4>

<div id="S3.SS4.SSS2.p1" class="ltx_para">
<p id="S3.SS4.SSS2.p1.1" class="ltx_p">In an attempt to provide a theoretical understanding of how and when gradients lead to the remarkable recovery of original data, several studies investigated the possibility of recovering the input of a learnable affine function from gradients <cite class="ltx_cite ltx_citemacro_citep">(Aono et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2017</a>; Qian and Hansen, <a href="#bib.bib153" title="" class="ltx_ref">2020</a>; Fan
et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2020</a>)</cite>. Aono et al. <cite class="ltx_cite ltx_citemacro_citep">(Aono et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2017</a>)</cite> initiated the closed-form attack based on gradients. In certain circumstances, an honest-but-curious server could directly calculate individual data from the gradients uploaded by clients <cite class="ltx_cite ltx_citemacro_citep">(Aono et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2017</a>; Zhu and Blaschko, <a href="#bib.bib231" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S3.SS4.SSS2.p2" class="ltx_para">
<p id="S3.SS4.SSS2.p2.10" class="ltx_p">Consider a fully connected layer <math id="S3.SS4.SSS2.p2.1.m1.1" class="ltx_Math" alttext="Wx+b=z" display="inline"><semantics id="S3.SS4.SSS2.p2.1.m1.1a"><mrow id="S3.SS4.SSS2.p2.1.m1.1.1" xref="S3.SS4.SSS2.p2.1.m1.1.1.cmml"><mrow id="S3.SS4.SSS2.p2.1.m1.1.1.2" xref="S3.SS4.SSS2.p2.1.m1.1.1.2.cmml"><mrow id="S3.SS4.SSS2.p2.1.m1.1.1.2.2" xref="S3.SS4.SSS2.p2.1.m1.1.1.2.2.cmml"><mi id="S3.SS4.SSS2.p2.1.m1.1.1.2.2.2" xref="S3.SS4.SSS2.p2.1.m1.1.1.2.2.2.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.SS4.SSS2.p2.1.m1.1.1.2.2.1" xref="S3.SS4.SSS2.p2.1.m1.1.1.2.2.1.cmml">​</mo><mi id="S3.SS4.SSS2.p2.1.m1.1.1.2.2.3" xref="S3.SS4.SSS2.p2.1.m1.1.1.2.2.3.cmml">x</mi></mrow><mo id="S3.SS4.SSS2.p2.1.m1.1.1.2.1" xref="S3.SS4.SSS2.p2.1.m1.1.1.2.1.cmml">+</mo><mi id="S3.SS4.SSS2.p2.1.m1.1.1.2.3" xref="S3.SS4.SSS2.p2.1.m1.1.1.2.3.cmml">b</mi></mrow><mo id="S3.SS4.SSS2.p2.1.m1.1.1.1" xref="S3.SS4.SSS2.p2.1.m1.1.1.1.cmml">=</mo><mi id="S3.SS4.SSS2.p2.1.m1.1.1.3" xref="S3.SS4.SSS2.p2.1.m1.1.1.3.cmml">z</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS2.p2.1.m1.1b"><apply id="S3.SS4.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS4.SSS2.p2.1.m1.1.1"><eq id="S3.SS4.SSS2.p2.1.m1.1.1.1.cmml" xref="S3.SS4.SSS2.p2.1.m1.1.1.1"></eq><apply id="S3.SS4.SSS2.p2.1.m1.1.1.2.cmml" xref="S3.SS4.SSS2.p2.1.m1.1.1.2"><plus id="S3.SS4.SSS2.p2.1.m1.1.1.2.1.cmml" xref="S3.SS4.SSS2.p2.1.m1.1.1.2.1"></plus><apply id="S3.SS4.SSS2.p2.1.m1.1.1.2.2.cmml" xref="S3.SS4.SSS2.p2.1.m1.1.1.2.2"><times id="S3.SS4.SSS2.p2.1.m1.1.1.2.2.1.cmml" xref="S3.SS4.SSS2.p2.1.m1.1.1.2.2.1"></times><ci id="S3.SS4.SSS2.p2.1.m1.1.1.2.2.2.cmml" xref="S3.SS4.SSS2.p2.1.m1.1.1.2.2.2">𝑊</ci><ci id="S3.SS4.SSS2.p2.1.m1.1.1.2.2.3.cmml" xref="S3.SS4.SSS2.p2.1.m1.1.1.2.2.3">𝑥</ci></apply><ci id="S3.SS4.SSS2.p2.1.m1.1.1.2.3.cmml" xref="S3.SS4.SSS2.p2.1.m1.1.1.2.3">𝑏</ci></apply><ci id="S3.SS4.SSS2.p2.1.m1.1.1.3.cmml" xref="S3.SS4.SSS2.p2.1.m1.1.1.3">𝑧</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS2.p2.1.m1.1c">Wx+b=z</annotation></semantics></math> with <math id="S3.SS4.SSS2.p2.2.m2.3" class="ltx_Math" alttext="l=l(f(x),y)" display="inline"><semantics id="S3.SS4.SSS2.p2.2.m2.3a"><mrow id="S3.SS4.SSS2.p2.2.m2.3.3" xref="S3.SS4.SSS2.p2.2.m2.3.3.cmml"><mi id="S3.SS4.SSS2.p2.2.m2.3.3.3" xref="S3.SS4.SSS2.p2.2.m2.3.3.3.cmml">l</mi><mo id="S3.SS4.SSS2.p2.2.m2.3.3.2" xref="S3.SS4.SSS2.p2.2.m2.3.3.2.cmml">=</mo><mrow id="S3.SS4.SSS2.p2.2.m2.3.3.1" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.cmml"><mi id="S3.SS4.SSS2.p2.2.m2.3.3.1.3" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS4.SSS2.p2.2.m2.3.3.1.2" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.2.cmml">​</mo><mrow id="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.1.2.cmml"><mo stretchy="false" id="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.2" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.1.2.cmml">(</mo><mrow id="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1.cmml"><mi id="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1.2" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1.1" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1.1.cmml">​</mo><mrow id="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1.3.2" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1.3.2.1" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1.cmml">(</mo><mi id="S3.SS4.SSS2.p2.2.m2.1.1" xref="S3.SS4.SSS2.p2.2.m2.1.1.cmml">x</mi><mo stretchy="false" id="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1.3.2.2" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.3" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.1.2.cmml">,</mo><mi id="S3.SS4.SSS2.p2.2.m2.2.2" xref="S3.SS4.SSS2.p2.2.m2.2.2.cmml">y</mi><mo stretchy="false" id="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.4" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS2.p2.2.m2.3b"><apply id="S3.SS4.SSS2.p2.2.m2.3.3.cmml" xref="S3.SS4.SSS2.p2.2.m2.3.3"><eq id="S3.SS4.SSS2.p2.2.m2.3.3.2.cmml" xref="S3.SS4.SSS2.p2.2.m2.3.3.2"></eq><ci id="S3.SS4.SSS2.p2.2.m2.3.3.3.cmml" xref="S3.SS4.SSS2.p2.2.m2.3.3.3">𝑙</ci><apply id="S3.SS4.SSS2.p2.2.m2.3.3.1.cmml" xref="S3.SS4.SSS2.p2.2.m2.3.3.1"><times id="S3.SS4.SSS2.p2.2.m2.3.3.1.2.cmml" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.2"></times><ci id="S3.SS4.SSS2.p2.2.m2.3.3.1.3.cmml" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.3">𝑙</ci><interval closure="open" id="S3.SS4.SSS2.p2.2.m2.3.3.1.1.2.cmml" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1"><apply id="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1.cmml" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1"><times id="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1.1.cmml" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1.1"></times><ci id="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1.2.cmml" xref="S3.SS4.SSS2.p2.2.m2.3.3.1.1.1.1.2">𝑓</ci><ci id="S3.SS4.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS4.SSS2.p2.2.m2.1.1">𝑥</ci></apply><ci id="S3.SS4.SSS2.p2.2.m2.2.2.cmml" xref="S3.SS4.SSS2.p2.2.m2.2.2">𝑦</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS2.p2.2.m2.3c">l=l(f(x),y)</annotation></semantics></math> as the loss function, where <math id="S3.SS4.SSS2.p2.3.m3.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS4.SSS2.p2.3.m3.1a"><mi id="S3.SS4.SSS2.p2.3.m3.1.1" xref="S3.SS4.SSS2.p2.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS2.p2.3.m3.1b"><ci id="S3.SS4.SSS2.p2.3.m3.1.1.cmml" xref="S3.SS4.SSS2.p2.3.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS2.p2.3.m3.1c">x</annotation></semantics></math> and <math id="S3.SS4.SSS2.p2.4.m4.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS4.SSS2.p2.4.m4.1a"><mi id="S3.SS4.SSS2.p2.4.m4.1.1" xref="S3.SS4.SSS2.p2.4.m4.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS2.p2.4.m4.1b"><ci id="S3.SS4.SSS2.p2.4.m4.1.1.cmml" xref="S3.SS4.SSS2.p2.4.m4.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS2.p2.4.m4.1c">z</annotation></semantics></math> are the input and output vectors, respectively. Private data <math id="S3.SS4.SSS2.p2.5.m5.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS4.SSS2.p2.5.m5.1a"><mi id="S3.SS4.SSS2.p2.5.m5.1.1" xref="S3.SS4.SSS2.p2.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS2.p2.5.m5.1b"><ci id="S3.SS4.SSS2.p2.5.m5.1.1.cmml" xref="S3.SS4.SSS2.p2.5.m5.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS2.p2.5.m5.1c">x</annotation></semantics></math> can be derived from <math id="S3.SS4.SSS2.p2.6.m6.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S3.SS4.SSS2.p2.6.m6.1a"><mi id="S3.SS4.SSS2.p2.6.m6.1.1" xref="S3.SS4.SSS2.p2.6.m6.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS2.p2.6.m6.1b"><ci id="S3.SS4.SSS2.p2.6.m6.1.1.cmml" xref="S3.SS4.SSS2.p2.6.m6.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS2.p2.6.m6.1c">l</annotation></semantics></math>’s gradients w.r.t <math id="S3.SS4.SSS2.p2.7.m7.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS4.SSS2.p2.7.m7.1a"><mi id="S3.SS4.SSS2.p2.7.m7.1.1" xref="S3.SS4.SSS2.p2.7.m7.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS2.p2.7.m7.1b"><ci id="S3.SS4.SSS2.p2.7.m7.1.1.cmml" xref="S3.SS4.SSS2.p2.7.m7.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS2.p2.7.m7.1c">W</annotation></semantics></math> and <math id="S3.SS4.SSS2.p2.8.m8.1" class="ltx_Math" alttext="b" display="inline"><semantics id="S3.SS4.SSS2.p2.8.m8.1a"><mi id="S3.SS4.SSS2.p2.8.m8.1.1" xref="S3.SS4.SSS2.p2.8.m8.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS2.p2.8.m8.1b"><ci id="S3.SS4.SSS2.p2.8.m8.1.1.cmml" xref="S3.SS4.SSS2.p2.8.m8.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS2.p2.8.m8.1c">b</annotation></semantics></math>, i.e.,: <math id="S3.SS4.SSS2.p2.9.m9.1" class="ltx_Math" alttext="{x^{T}}=\frac{{\partial l}}{{\partial W}}\oslash\frac{{\partial l}}{{\partial b}}" display="inline"><semantics id="S3.SS4.SSS2.p2.9.m9.1a"><mrow id="S3.SS4.SSS2.p2.9.m9.1.1" xref="S3.SS4.SSS2.p2.9.m9.1.1.cmml"><msup id="S3.SS4.SSS2.p2.9.m9.1.1.2" xref="S3.SS4.SSS2.p2.9.m9.1.1.2.cmml"><mi id="S3.SS4.SSS2.p2.9.m9.1.1.2.2" xref="S3.SS4.SSS2.p2.9.m9.1.1.2.2.cmml">x</mi><mi id="S3.SS4.SSS2.p2.9.m9.1.1.2.3" xref="S3.SS4.SSS2.p2.9.m9.1.1.2.3.cmml">T</mi></msup><mo id="S3.SS4.SSS2.p2.9.m9.1.1.1" xref="S3.SS4.SSS2.p2.9.m9.1.1.1.cmml">=</mo><mrow id="S3.SS4.SSS2.p2.9.m9.1.1.3" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.cmml"><mfrac id="S3.SS4.SSS2.p2.9.m9.1.1.3.2" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.2.cmml"><mrow id="S3.SS4.SSS2.p2.9.m9.1.1.3.2.2" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.2.2.cmml"><mo rspace="0em" id="S3.SS4.SSS2.p2.9.m9.1.1.3.2.2.1" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.2.2.1.cmml">∂</mo><mi id="S3.SS4.SSS2.p2.9.m9.1.1.3.2.2.2" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.2.2.2.cmml">l</mi></mrow><mrow id="S3.SS4.SSS2.p2.9.m9.1.1.3.2.3" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.2.3.cmml"><mo rspace="0em" id="S3.SS4.SSS2.p2.9.m9.1.1.3.2.3.1" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.2.3.1.cmml">∂</mo><mi id="S3.SS4.SSS2.p2.9.m9.1.1.3.2.3.2" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.2.3.2.cmml">W</mi></mrow></mfrac><mo id="S3.SS4.SSS2.p2.9.m9.1.1.3.1" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.1.cmml">⊘</mo><mfrac id="S3.SS4.SSS2.p2.9.m9.1.1.3.3" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.3.cmml"><mrow id="S3.SS4.SSS2.p2.9.m9.1.1.3.3.2" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.3.2.cmml"><mo rspace="0em" id="S3.SS4.SSS2.p2.9.m9.1.1.3.3.2.1" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.3.2.1.cmml">∂</mo><mi id="S3.SS4.SSS2.p2.9.m9.1.1.3.3.2.2" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.3.2.2.cmml">l</mi></mrow><mrow id="S3.SS4.SSS2.p2.9.m9.1.1.3.3.3" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.3.3.cmml"><mo rspace="0em" id="S3.SS4.SSS2.p2.9.m9.1.1.3.3.3.1" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.3.3.1.cmml">∂</mo><mi id="S3.SS4.SSS2.p2.9.m9.1.1.3.3.3.2" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.3.3.2.cmml">b</mi></mrow></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS2.p2.9.m9.1b"><apply id="S3.SS4.SSS2.p2.9.m9.1.1.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1"><eq id="S3.SS4.SSS2.p2.9.m9.1.1.1.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.1"></eq><apply id="S3.SS4.SSS2.p2.9.m9.1.1.2.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.SSS2.p2.9.m9.1.1.2.1.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.2">superscript</csymbol><ci id="S3.SS4.SSS2.p2.9.m9.1.1.2.2.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.2.2">𝑥</ci><ci id="S3.SS4.SSS2.p2.9.m9.1.1.2.3.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.2.3">𝑇</ci></apply><apply id="S3.SS4.SSS2.p2.9.m9.1.1.3.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3"><ci id="S3.SS4.SSS2.p2.9.m9.1.1.3.1.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.1">⊘</ci><apply id="S3.SS4.SSS2.p2.9.m9.1.1.3.2.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.2"><divide id="S3.SS4.SSS2.p2.9.m9.1.1.3.2.1.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.2"></divide><apply id="S3.SS4.SSS2.p2.9.m9.1.1.3.2.2.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.2.2"><partialdiff id="S3.SS4.SSS2.p2.9.m9.1.1.3.2.2.1.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.2.2.1"></partialdiff><ci id="S3.SS4.SSS2.p2.9.m9.1.1.3.2.2.2.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.2.2.2">𝑙</ci></apply><apply id="S3.SS4.SSS2.p2.9.m9.1.1.3.2.3.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.2.3"><partialdiff id="S3.SS4.SSS2.p2.9.m9.1.1.3.2.3.1.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.2.3.1"></partialdiff><ci id="S3.SS4.SSS2.p2.9.m9.1.1.3.2.3.2.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.2.3.2">𝑊</ci></apply></apply><apply id="S3.SS4.SSS2.p2.9.m9.1.1.3.3.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.3"><divide id="S3.SS4.SSS2.p2.9.m9.1.1.3.3.1.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.3"></divide><apply id="S3.SS4.SSS2.p2.9.m9.1.1.3.3.2.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.3.2"><partialdiff id="S3.SS4.SSS2.p2.9.m9.1.1.3.3.2.1.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.3.2.1"></partialdiff><ci id="S3.SS4.SSS2.p2.9.m9.1.1.3.3.2.2.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.3.2.2">𝑙</ci></apply><apply id="S3.SS4.SSS2.p2.9.m9.1.1.3.3.3.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.3.3"><partialdiff id="S3.SS4.SSS2.p2.9.m9.1.1.3.3.3.1.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.3.3.1"></partialdiff><ci id="S3.SS4.SSS2.p2.9.m9.1.1.3.3.3.2.cmml" xref="S3.SS4.SSS2.p2.9.m9.1.1.3.3.3.2">𝑏</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS2.p2.9.m9.1c">{x^{T}}=\frac{{\partial l}}{{\partial W}}\oslash\frac{{\partial l}}{{\partial b}}</annotation></semantics></math>. Here <math id="S3.SS4.SSS2.p2.10.m10.1" class="ltx_Math" alttext="\oslash" display="inline"><semantics id="S3.SS4.SSS2.p2.10.m10.1a"><mo id="S3.SS4.SSS2.p2.10.m10.1.1" xref="S3.SS4.SSS2.p2.10.m10.1.1.cmml">⊘</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS2.p2.10.m10.1b"><ci id="S3.SS4.SSS2.p2.10.m10.1.1.cmml" xref="S3.SS4.SSS2.p2.10.m10.1.1">⊘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS2.p2.10.m10.1c">\oslash</annotation></semantics></math> denotes entry-wise division. The assumption of a fully connected layer holds for the last prediction layers in many popular architectures. As a result, the prediction modules’ input, which is the output of the preceding layers, can be rebuilt. These outputs typically include some information about the training data, making them vulnerable to attackers. In this light, the ability to recover ground truth label information from the gradients of the final fully-connected layer, as stated in Zhao et al. <cite class="ltx_cite ltx_citemacro_citep">(Zhao
et al<span class="ltx_text">.</span>, <a href="#bib.bib227" title="" class="ltx_ref">2020</a>)</cite>, is very intriguing.</p>
</div>
<div id="S3.SS4.SSS2.p3" class="ltx_para">
<p id="S3.SS4.SSS2.p3.4" class="ltx_p">Despite its inspiring nature, Aono et al.’s work <cite class="ltx_cite ltx_citemacro_citep">(Aono et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2017</a>)</cite> has some limitations. First, it does not apply to convolutional neural networks due to a mismatch in dimensions. Second, it cannot deal with batch inputs. For the batch input <math id="S3.SS4.SSS2.p3.1.m1.1" class="ltx_Math" alttext="\left\{x_{j}\right\}_{j=1}^{b}" display="inline"><semantics id="S3.SS4.SSS2.p3.1.m1.1a"><msubsup id="S3.SS4.SSS2.p3.1.m1.1.1" xref="S3.SS4.SSS2.p3.1.m1.1.1.cmml"><mrow id="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.1.2.cmml"><mo id="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1.2" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.1.2.cmml">{</mo><msub id="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1.1" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1.1.cmml"><mi id="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1.1.2" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1.1.3" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1.3" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS4.SSS2.p3.1.m1.1.1.1.3" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.3.cmml"><mi id="S3.SS4.SSS2.p3.1.m1.1.1.1.3.2" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.3.2.cmml">j</mi><mo id="S3.SS4.SSS2.p3.1.m1.1.1.1.3.1" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.3.1.cmml">=</mo><mn id="S3.SS4.SSS2.p3.1.m1.1.1.1.3.3" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.SS4.SSS2.p3.1.m1.1.1.3" xref="S3.SS4.SSS2.p3.1.m1.1.1.3.cmml">b</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS2.p3.1.m1.1b"><apply id="S3.SS4.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS4.SSS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS2.p3.1.m1.1.1.2.cmml" xref="S3.SS4.SSS2.p3.1.m1.1.1">superscript</csymbol><apply id="S3.SS4.SSS2.p3.1.m1.1.1.1.cmml" xref="S3.SS4.SSS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS2.p3.1.m1.1.1.1.2.cmml" xref="S3.SS4.SSS2.p3.1.m1.1.1">subscript</csymbol><set id="S3.SS4.SSS2.p3.1.m1.1.1.1.1.2.cmml" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1"><apply id="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.1.1.1.3">𝑗</ci></apply></set><apply id="S3.SS4.SSS2.p3.1.m1.1.1.1.3.cmml" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.3"><eq id="S3.SS4.SSS2.p3.1.m1.1.1.1.3.1.cmml" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.3.1"></eq><ci id="S3.SS4.SSS2.p3.1.m1.1.1.1.3.2.cmml" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.3.2">𝑗</ci><cn type="integer" id="S3.SS4.SSS2.p3.1.m1.1.1.1.3.3.cmml" xref="S3.SS4.SSS2.p3.1.m1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.SS4.SSS2.p3.1.m1.1.1.3.cmml" xref="S3.SS4.SSS2.p3.1.m1.1.1.3">𝑏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS2.p3.1.m1.1c">\left\{x_{j}\right\}_{j=1}^{b}</annotation></semantics></math>, all derivatives are summed over the batch dimension <math id="S3.SS4.SSS2.p3.2.m2.1" class="ltx_Math" alttext="b" display="inline"><semantics id="S3.SS4.SSS2.p3.2.m2.1a"><mi id="S3.SS4.SSS2.p3.2.m2.1.1" xref="S3.SS4.SSS2.p3.2.m2.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS2.p3.2.m2.1b"><ci id="S3.SS4.SSS2.p3.2.m2.1.1.cmml" xref="S3.SS4.SSS2.p3.2.m2.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS2.p3.2.m2.1c">b</annotation></semantics></math> and the recovered <math id="S3.SS4.SSS2.p3.3.m3.1" class="ltx_Math" alttext="\bar{x}" display="inline"><semantics id="S3.SS4.SSS2.p3.3.m3.1a"><mover accent="true" id="S3.SS4.SSS2.p3.3.m3.1.1" xref="S3.SS4.SSS2.p3.3.m3.1.1.cmml"><mi id="S3.SS4.SSS2.p3.3.m3.1.1.2" xref="S3.SS4.SSS2.p3.3.m3.1.1.2.cmml">x</mi><mo id="S3.SS4.SSS2.p3.3.m3.1.1.1" xref="S3.SS4.SSS2.p3.3.m3.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS2.p3.3.m3.1b"><apply id="S3.SS4.SSS2.p3.3.m3.1.1.cmml" xref="S3.SS4.SSS2.p3.3.m3.1.1"><ci id="S3.SS4.SSS2.p3.3.m3.1.1.1.cmml" xref="S3.SS4.SSS2.p3.3.m3.1.1.1">¯</ci><ci id="S3.SS4.SSS2.p3.3.m3.1.1.2.cmml" xref="S3.SS4.SSS2.p3.3.m3.1.1.2">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS2.p3.3.m3.1c">\bar{x}</annotation></semantics></math> is merely proportional to the average of batch inputs <math id="S3.SS4.SSS2.p3.4.m4.1" class="ltx_Math" alttext="\sum\nolimits_{j=1}^{b}{{x_{j}}}" display="inline"><semantics id="S3.SS4.SSS2.p3.4.m4.1a"><mrow id="S3.SS4.SSS2.p3.4.m4.1.1" xref="S3.SS4.SSS2.p3.4.m4.1.1.cmml"><msubsup id="S3.SS4.SSS2.p3.4.m4.1.1.1" xref="S3.SS4.SSS2.p3.4.m4.1.1.1.cmml"><mo id="S3.SS4.SSS2.p3.4.m4.1.1.1.2.2" xref="S3.SS4.SSS2.p3.4.m4.1.1.1.2.2.cmml">∑</mo><mrow id="S3.SS4.SSS2.p3.4.m4.1.1.1.2.3" xref="S3.SS4.SSS2.p3.4.m4.1.1.1.2.3.cmml"><mi id="S3.SS4.SSS2.p3.4.m4.1.1.1.2.3.2" xref="S3.SS4.SSS2.p3.4.m4.1.1.1.2.3.2.cmml">j</mi><mo id="S3.SS4.SSS2.p3.4.m4.1.1.1.2.3.1" xref="S3.SS4.SSS2.p3.4.m4.1.1.1.2.3.1.cmml">=</mo><mn id="S3.SS4.SSS2.p3.4.m4.1.1.1.2.3.3" xref="S3.SS4.SSS2.p3.4.m4.1.1.1.2.3.3.cmml">1</mn></mrow><mi id="S3.SS4.SSS2.p3.4.m4.1.1.1.3" xref="S3.SS4.SSS2.p3.4.m4.1.1.1.3.cmml">b</mi></msubsup><msub id="S3.SS4.SSS2.p3.4.m4.1.1.2" xref="S3.SS4.SSS2.p3.4.m4.1.1.2.cmml"><mi id="S3.SS4.SSS2.p3.4.m4.1.1.2.2" xref="S3.SS4.SSS2.p3.4.m4.1.1.2.2.cmml">x</mi><mi id="S3.SS4.SSS2.p3.4.m4.1.1.2.3" xref="S3.SS4.SSS2.p3.4.m4.1.1.2.3.cmml">j</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS2.p3.4.m4.1b"><apply id="S3.SS4.SSS2.p3.4.m4.1.1.cmml" xref="S3.SS4.SSS2.p3.4.m4.1.1"><apply id="S3.SS4.SSS2.p3.4.m4.1.1.1.cmml" xref="S3.SS4.SSS2.p3.4.m4.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS2.p3.4.m4.1.1.1.1.cmml" xref="S3.SS4.SSS2.p3.4.m4.1.1.1">superscript</csymbol><apply id="S3.SS4.SSS2.p3.4.m4.1.1.1.2.cmml" xref="S3.SS4.SSS2.p3.4.m4.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS2.p3.4.m4.1.1.1.2.1.cmml" xref="S3.SS4.SSS2.p3.4.m4.1.1.1">subscript</csymbol><sum id="S3.SS4.SSS2.p3.4.m4.1.1.1.2.2.cmml" xref="S3.SS4.SSS2.p3.4.m4.1.1.1.2.2"></sum><apply id="S3.SS4.SSS2.p3.4.m4.1.1.1.2.3.cmml" xref="S3.SS4.SSS2.p3.4.m4.1.1.1.2.3"><eq id="S3.SS4.SSS2.p3.4.m4.1.1.1.2.3.1.cmml" xref="S3.SS4.SSS2.p3.4.m4.1.1.1.2.3.1"></eq><ci id="S3.SS4.SSS2.p3.4.m4.1.1.1.2.3.2.cmml" xref="S3.SS4.SSS2.p3.4.m4.1.1.1.2.3.2">𝑗</ci><cn type="integer" id="S3.SS4.SSS2.p3.4.m4.1.1.1.2.3.3.cmml" xref="S3.SS4.SSS2.p3.4.m4.1.1.1.2.3.3">1</cn></apply></apply><ci id="S3.SS4.SSS2.p3.4.m4.1.1.1.3.cmml" xref="S3.SS4.SSS2.p3.4.m4.1.1.1.3">𝑏</ci></apply><apply id="S3.SS4.SSS2.p3.4.m4.1.1.2.cmml" xref="S3.SS4.SSS2.p3.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.SSS2.p3.4.m4.1.1.2.1.cmml" xref="S3.SS4.SSS2.p3.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS4.SSS2.p3.4.m4.1.1.2.2.cmml" xref="S3.SS4.SSS2.p3.4.m4.1.1.2.2">𝑥</ci><ci id="S3.SS4.SSS2.p3.4.m4.1.1.2.3.cmml" xref="S3.SS4.SSS2.p3.4.m4.1.1.2.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS2.p3.4.m4.1c">\sum\nolimits_{j=1}^{b}{{x_{j}}}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS4.SSS2.p4" class="ltx_para">
<p id="S3.SS4.SSS2.p4.1" class="ltx_p">To fix the dimension mismatch issue, Zhu and Blaschko <cite class="ltx_cite ltx_citemacro_citep">(Zhu and Blaschko, <a href="#bib.bib231" title="" class="ltx_ref">2020</a>)</cite> converted the convolutional layer into a fully connected layer using circulant matrix representation <cite class="ltx_cite ltx_citemacro_citep">(Golub and
Van Loan, <a href="#bib.bib64" title="" class="ltx_ref">2013</a>)</cite> of the convolutional kernel <cite class="ltx_cite ltx_citemacro_citep">(Fan
et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2020</a>)</cite>. The gradients of each layer were interpreted as the <span id="S3.SS4.SSS2.p4.1.1" class="ltx_text ltx_font_italic">gradient constraints</span>. Finally, they recursively reconstructed the layer-wise input. However, their implementation can only recover low-resolution images in settings where the batch size equals 1. For the batch input, the algorithm returns a linear combination of the training data.</p>
</div>
<div id="S3.SS4.SSS2.p5" class="ltx_para">
<p id="S3.SS4.SSS2.p5.2" class="ltx_p">To address these difficulties with the batch size, Fowl et al. <cite class="ltx_cite ltx_citemacro_citep">(Fowl et al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2021</a>)</cite> suggested making minor but malicious changes to the global model to reconstruct the client’s data from a batch of gradient updates. The key idea is to separate the batch data by some quantity <math id="S3.SS4.SSS2.p5.1.m1.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S3.SS4.SSS2.p5.1.m1.1a"><mi id="S3.SS4.SSS2.p5.1.m1.1.1" xref="S3.SS4.SSS2.p5.1.m1.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS2.p5.1.m1.1b"><ci id="S3.SS4.SSS2.p5.1.m1.1.1.cmml" xref="S3.SS4.SSS2.p5.1.m1.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS2.p5.1.m1.1c">h</annotation></semantics></math>, such as image brightness. To this end, an imprint module is added to the global model, which acts as a filter that separates a batch of samples based on quantity <math id="S3.SS4.SSS2.p5.2.m2.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S3.SS4.SSS2.p5.2.m2.1a"><mi id="S3.SS4.SSS2.p5.2.m2.1.1" xref="S3.SS4.SSS2.p5.2.m2.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS2.p5.2.m2.1b"><ci id="S3.SS4.SSS2.p5.2.m2.1.1.cmml" xref="S3.SS4.SSS2.p5.2.m2.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS2.p5.2.m2.1c">h</annotation></semantics></math>. Qian and Hansen <cite class="ltx_cite ltx_citemacro_citep">(Qian and Hansen, <a href="#bib.bib153" title="" class="ltx_ref">2020</a>)</cite> found bias term in the output layer is the key to the success of reconstruction. A fully-connected neural network requires just one node in one hidden layer for single-input reconstruction. In contrast, mini-batch reconstruction requires that the hidden units exceed the input size. Pan et al. <cite class="ltx_cite ltx_citemacro_citep">(Pan
et al<span class="ltx_text">.</span>, <a href="#bib.bib146" title="" class="ltx_ref">2020</a>)</cite> conducted an analytic investigation of the security boundary of the reconstruction attacks. Given a batch input, the secure/insecure boundary of the reconstruction attack was characterized by the number of Exclusively Activated Neurons (ExANs), where the more ExANs, the more likely the attack’s success.</p>
</div>
<figure id="S3.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4. </span>Comparison of reconstruction attacks in FL</figcaption>
<table id="S3.T4.11" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T4.11.12.1" class="ltx_tr">
<td id="S3.T4.11.12.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;" rowspan="2"><span id="S3.T4.11.12.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Method</span></td>
<td id="S3.T4.11.12.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;" colspan="2"><span id="S3.T4.11.12.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Objective function</span></td>
<td id="S3.T4.11.12.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;" rowspan="2"><span id="S3.T4.11.12.1.3.1" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.11.12.1.3.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.11.12.1.3.1.1.1" class="ltx_tr">
<span id="S3.T4.11.12.1.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.12.1.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Maximal</span></span></span>
<span id="S3.T4.11.12.1.3.1.1.2" class="ltx_tr">
<span id="S3.T4.11.12.1.3.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.12.1.3.1.1.2.1.1" class="ltx_text ltx_font_bold">batch size</span></span></span>
</span></span></td>
<td id="S3.T4.11.12.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;" rowspan="2"><span id="S3.T4.11.12.1.4.1" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.11.12.1.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.11.12.1.4.1.1.1" class="ltx_tr">
<span id="S3.T4.11.12.1.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.12.1.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Opt-based/</span></span></span>
<span id="S3.T4.11.12.1.4.1.1.2" class="ltx_tr">
<span id="S3.T4.11.12.1.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.12.1.4.1.1.2.1.1" class="ltx_text ltx_font_bold">Closed-form</span></span></span>
</span></span></td>
<td id="S3.T4.11.12.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;" rowspan="2"><span id="S3.T4.11.12.1.5.1" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.11.12.1.5.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.11.12.1.5.1.1.1" class="ltx_tr">
<span id="S3.T4.11.12.1.5.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.12.1.5.1.1.1.1.1" class="ltx_text ltx_font_bold">Theoretical</span></span></span>
<span id="S3.T4.11.12.1.5.1.1.2" class="ltx_tr">
<span id="S3.T4.11.12.1.5.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.12.1.5.1.1.2.1.1" class="ltx_text ltx_font_bold">guarantee</span></span></span>
</span></span></td>
<td id="S3.T4.11.12.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;" rowspan="2"><span id="S3.T4.11.12.1.6.1" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.11.12.1.6.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.11.12.1.6.1.1.1" class="ltx_tr">
<span id="S3.T4.11.12.1.6.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.12.1.6.1.1.1.1.1" class="ltx_text ltx_font_bold">Additional</span></span></span>
<span id="S3.T4.11.12.1.6.1.1.2" class="ltx_tr">
<span id="S3.T4.11.12.1.6.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.12.1.6.1.1.2.1.1" class="ltx_text ltx_font_bold">information</span></span></span>
</span></span></td>
<td id="S3.T4.11.12.1.7" class="ltx_td ltx_border_t" style="padding:0.9pt 2.0pt;"></td>
</tr>
<tr id="S3.T4.2.2" class="ltx_tr">
<td id="S3.T4.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><math id="S3.T4.1.1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{grad}" display="inline"><semantics id="S3.T4.1.1.1.m1.1a"><msub id="S3.T4.1.1.1.m1.1.1" xref="S3.T4.1.1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S3.T4.1.1.1.m1.1.1.2" xref="S3.T4.1.1.1.m1.1.1.2.cmml">ℒ</mi><mrow id="S3.T4.1.1.1.m1.1.1.3" xref="S3.T4.1.1.1.m1.1.1.3.cmml"><mi mathsize="90%" id="S3.T4.1.1.1.m1.1.1.3.2" xref="S3.T4.1.1.1.m1.1.1.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.T4.1.1.1.m1.1.1.3.1" xref="S3.T4.1.1.1.m1.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S3.T4.1.1.1.m1.1.1.3.3" xref="S3.T4.1.1.1.m1.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.T4.1.1.1.m1.1.1.3.1a" xref="S3.T4.1.1.1.m1.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S3.T4.1.1.1.m1.1.1.3.4" xref="S3.T4.1.1.1.m1.1.1.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.T4.1.1.1.m1.1.1.3.1b" xref="S3.T4.1.1.1.m1.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S3.T4.1.1.1.m1.1.1.3.5" xref="S3.T4.1.1.1.m1.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.T4.1.1.1.m1.1b"><apply id="S3.T4.1.1.1.m1.1.1.cmml" xref="S3.T4.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T4.1.1.1.m1.1.1.1.cmml" xref="S3.T4.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.T4.1.1.1.m1.1.1.2.cmml" xref="S3.T4.1.1.1.m1.1.1.2">ℒ</ci><apply id="S3.T4.1.1.1.m1.1.1.3.cmml" xref="S3.T4.1.1.1.m1.1.1.3"><times id="S3.T4.1.1.1.m1.1.1.3.1.cmml" xref="S3.T4.1.1.1.m1.1.1.3.1"></times><ci id="S3.T4.1.1.1.m1.1.1.3.2.cmml" xref="S3.T4.1.1.1.m1.1.1.3.2">𝑔</ci><ci id="S3.T4.1.1.1.m1.1.1.3.3.cmml" xref="S3.T4.1.1.1.m1.1.1.3.3">𝑟</ci><ci id="S3.T4.1.1.1.m1.1.1.3.4.cmml" xref="S3.T4.1.1.1.m1.1.1.3.4">𝑎</ci><ci id="S3.T4.1.1.1.m1.1.1.3.5.cmml" xref="S3.T4.1.1.1.m1.1.1.3.5">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.1.1.1.m1.1c">\mathcal{L}_{grad}</annotation></semantics></math></td>
<td id="S3.T4.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><math id="S3.T4.2.2.2.m1.1" class="ltx_Math" alttext="\mathcal{R}_{aux}" display="inline"><semantics id="S3.T4.2.2.2.m1.1a"><msub id="S3.T4.2.2.2.m1.1.1" xref="S3.T4.2.2.2.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S3.T4.2.2.2.m1.1.1.2" xref="S3.T4.2.2.2.m1.1.1.2.cmml">ℛ</mi><mrow id="S3.T4.2.2.2.m1.1.1.3" xref="S3.T4.2.2.2.m1.1.1.3.cmml"><mi mathsize="90%" id="S3.T4.2.2.2.m1.1.1.3.2" xref="S3.T4.2.2.2.m1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.T4.2.2.2.m1.1.1.3.1" xref="S3.T4.2.2.2.m1.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S3.T4.2.2.2.m1.1.1.3.3" xref="S3.T4.2.2.2.m1.1.1.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.T4.2.2.2.m1.1.1.3.1a" xref="S3.T4.2.2.2.m1.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S3.T4.2.2.2.m1.1.1.3.4" xref="S3.T4.2.2.2.m1.1.1.3.4.cmml">x</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.T4.2.2.2.m1.1b"><apply id="S3.T4.2.2.2.m1.1.1.cmml" xref="S3.T4.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S3.T4.2.2.2.m1.1.1.1.cmml" xref="S3.T4.2.2.2.m1.1.1">subscript</csymbol><ci id="S3.T4.2.2.2.m1.1.1.2.cmml" xref="S3.T4.2.2.2.m1.1.1.2">ℛ</ci><apply id="S3.T4.2.2.2.m1.1.1.3.cmml" xref="S3.T4.2.2.2.m1.1.1.3"><times id="S3.T4.2.2.2.m1.1.1.3.1.cmml" xref="S3.T4.2.2.2.m1.1.1.3.1"></times><ci id="S3.T4.2.2.2.m1.1.1.3.2.cmml" xref="S3.T4.2.2.2.m1.1.1.3.2">𝑎</ci><ci id="S3.T4.2.2.2.m1.1.1.3.3.cmml" xref="S3.T4.2.2.2.m1.1.1.3.3">𝑢</ci><ci id="S3.T4.2.2.2.m1.1.1.3.4.cmml" xref="S3.T4.2.2.2.m1.1.1.3.4">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.2.2.2.m1.1c">\mathcal{R}_{aux}</annotation></semantics></math></td>
<td id="S3.T4.2.2.3" class="ltx_td" style="padding:0.9pt 2.0pt;"></td>
</tr>
<tr id="S3.T4.3.3" class="ltx_tr">
<td id="S3.T4.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<span id="S3.T4.3.3.2.1" class="ltx_text" style="font-size:90%;">iDLG </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T4.3.3.2.2.1" class="ltx_text" style="font-size:90%;">(</span>Zhao
et al<span class="ltx_text">.</span><span id="S3.T4.3.3.2.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib227" title="" class="ltx_ref">2020</a><span id="S3.T4.3.3.2.4.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T4.3.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<math id="S3.T4.3.3.1.m1.1" class="ltx_Math" alttext="l_{2}" display="inline"><semantics id="S3.T4.3.3.1.m1.1a"><msub id="S3.T4.3.3.1.m1.1.1" xref="S3.T4.3.3.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.T4.3.3.1.m1.1.1.2" xref="S3.T4.3.3.1.m1.1.1.2.cmml">l</mi><mn mathsize="90%" id="S3.T4.3.3.1.m1.1.1.3" xref="S3.T4.3.3.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T4.3.3.1.m1.1b"><apply id="S3.T4.3.3.1.m1.1.1.cmml" xref="S3.T4.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T4.3.3.1.m1.1.1.1.cmml" xref="S3.T4.3.3.1.m1.1.1">subscript</csymbol><ci id="S3.T4.3.3.1.m1.1.1.2.cmml" xref="S3.T4.3.3.1.m1.1.1.2">𝑙</ci><cn type="integer" id="S3.T4.3.3.1.m1.1.1.3.cmml" xref="S3.T4.3.3.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.3.3.1.m1.1c">l_{2}</annotation></semantics></math><span id="S3.T4.3.3.1.1" class="ltx_text" style="font-size:90%;"> distance</span>
</td>
<td id="S3.T4.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.3.3.3.1" class="ltx_text" style="font-size:90%;">/</span></td>
<td id="S3.T4.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.3.3.4.1" class="ltx_text" style="font-size:90%;">8</span></td>
<td id="S3.T4.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.3.3.5.1" class="ltx_text" style="font-size:90%;">Opt-based</span></td>
<td id="S3.T4.3.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.3.3.6.1" class="ltx_text" style="font-size:90%;">No</span></td>
<td id="S3.T4.3.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.3.3.7.1" class="ltx_text" style="font-size:90%;">No</span></td>
<td id="S3.T4.3.3.8" class="ltx_td ltx_border_t" style="padding:0.9pt 2.0pt;"></td>
</tr>
<tr id="S3.T4.4.4" class="ltx_tr">
<td id="S3.T4.4.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<span id="S3.T4.4.4.2.1" class="ltx_text" style="font-size:90%;">DLG </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T4.4.4.2.2.1" class="ltx_text" style="font-size:90%;">(</span>Zhu et al<span class="ltx_text">.</span><span id="S3.T4.4.4.2.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib232" title="" class="ltx_ref">2019</a><span id="S3.T4.4.4.2.4.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T4.4.4.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<math id="S3.T4.4.4.1.m1.1" class="ltx_Math" alttext="l_{2}" display="inline"><semantics id="S3.T4.4.4.1.m1.1a"><msub id="S3.T4.4.4.1.m1.1.1" xref="S3.T4.4.4.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.T4.4.4.1.m1.1.1.2" xref="S3.T4.4.4.1.m1.1.1.2.cmml">l</mi><mn mathsize="90%" id="S3.T4.4.4.1.m1.1.1.3" xref="S3.T4.4.4.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T4.4.4.1.m1.1b"><apply id="S3.T4.4.4.1.m1.1.1.cmml" xref="S3.T4.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T4.4.4.1.m1.1.1.1.cmml" xref="S3.T4.4.4.1.m1.1.1">subscript</csymbol><ci id="S3.T4.4.4.1.m1.1.1.2.cmml" xref="S3.T4.4.4.1.m1.1.1.2">𝑙</ci><cn type="integer" id="S3.T4.4.4.1.m1.1.1.3.cmml" xref="S3.T4.4.4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.4.4.1.m1.1c">l_{2}</annotation></semantics></math><span id="S3.T4.4.4.1.1" class="ltx_text" style="font-size:90%;"> distance</span>
</td>
<td id="S3.T4.4.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.4.4.3.1" class="ltx_text" style="font-size:90%;">/</span></td>
<td id="S3.T4.4.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.4.4.4.1" class="ltx_text" style="font-size:90%;">8</span></td>
<td id="S3.T4.4.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.4.4.5.1" class="ltx_text" style="font-size:90%;">Opt-based</span></td>
<td id="S3.T4.4.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.4.4.6.1" class="ltx_text" style="font-size:90%;">Yes</span></td>
<td id="S3.T4.4.4.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.4.4.7.1" class="ltx_text" style="font-size:90%;">No</span></td>
<td id="S3.T4.4.4.8" class="ltx_td ltx_border_t" style="padding:0.9pt 2.0pt;"></td>
</tr>
<tr id="S3.T4.11.13.2" class="ltx_tr">
<td id="S3.T4.11.13.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<table id="S3.T4.11.13.2.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.11.13.2.1.1.1" class="ltx_tr">
<td id="S3.T4.11.13.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.13.2.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Inverting</span></td>
</tr>
<tr id="S3.T4.11.13.2.1.1.2" class="ltx_tr">
<td id="S3.T4.11.13.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;">
<span id="S3.T4.11.13.2.1.1.2.1.1" class="ltx_text" style="font-size:90%;">gradients</span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T4.11.13.2.1.1.2.1.2.1" class="ltx_text" style="font-size:90%;">(</span>Geiping et al<span class="ltx_text">.</span><span id="S3.T4.11.13.2.1.1.2.1.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib60" title="" class="ltx_ref">2020</a><span id="S3.T4.11.13.2.1.1.2.1.4.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
</tr>
</table>
</td>
<td id="S3.T4.11.13.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<table id="S3.T4.11.13.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.11.13.2.2.1.1" class="ltx_tr">
<td id="S3.T4.11.13.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.13.2.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Cosine</span></td>
</tr>
<tr id="S3.T4.11.13.2.2.1.2" class="ltx_tr">
<td id="S3.T4.11.13.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.13.2.2.1.2.1.1" class="ltx_text" style="font-size:90%;">similarity</span></td>
</tr>
</table>
</td>
<td id="S3.T4.11.13.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.13.2.3.1" class="ltx_text" style="font-size:90%;">Total variance</span></td>
<td id="S3.T4.11.13.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.13.2.4.1" class="ltx_text" style="font-size:90%;">100</span></td>
<td id="S3.T4.11.13.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.13.2.5.1" class="ltx_text" style="font-size:90%;">Opt-based</span></td>
<td id="S3.T4.11.13.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.13.2.6.1" class="ltx_text" style="font-size:90%;">Yes</span></td>
<td id="S3.T4.11.13.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<table id="S3.T4.11.13.2.7.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.11.13.2.7.1.1" class="ltx_tr">
<td id="S3.T4.11.13.2.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.13.2.7.1.1.1.1" class="ltx_text" style="font-size:90%;">Local updates;</span></td>
</tr>
<tr id="S3.T4.11.13.2.7.1.2" class="ltx_tr">
<td id="S3.T4.11.13.2.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.13.2.7.1.2.1.1" class="ltx_text" style="font-size:90%;">BN statistcs</span></td>
</tr>
</table>
</td>
<td id="S3.T4.11.13.2.8" class="ltx_td ltx_border_t" style="padding:0.9pt 2.0pt;"></td>
</tr>
<tr id="S3.T4.5.5" class="ltx_tr">
<td id="S3.T4.5.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T4.5.5.2.1.1" class="ltx_text" style="font-size:90%;">(</span>Wei et al<span class="ltx_text">.</span><span id="S3.T4.5.5.2.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib193" title="" class="ltx_ref">2020b</a><span id="S3.T4.5.5.2.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S3.T4.5.5.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<math id="S3.T4.5.5.1.m1.1" class="ltx_Math" alttext="l_{2}" display="inline"><semantics id="S3.T4.5.5.1.m1.1a"><msub id="S3.T4.5.5.1.m1.1.1" xref="S3.T4.5.5.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.T4.5.5.1.m1.1.1.2" xref="S3.T4.5.5.1.m1.1.1.2.cmml">l</mi><mn mathsize="90%" id="S3.T4.5.5.1.m1.1.1.3" xref="S3.T4.5.5.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T4.5.5.1.m1.1b"><apply id="S3.T4.5.5.1.m1.1.1.cmml" xref="S3.T4.5.5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T4.5.5.1.m1.1.1.1.cmml" xref="S3.T4.5.5.1.m1.1.1">subscript</csymbol><ci id="S3.T4.5.5.1.m1.1.1.2.cmml" xref="S3.T4.5.5.1.m1.1.1.2">𝑙</ci><cn type="integer" id="S3.T4.5.5.1.m1.1.1.3.cmml" xref="S3.T4.5.5.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.5.5.1.m1.1c">l_{2}</annotation></semantics></math><span id="S3.T4.5.5.1.1" class="ltx_text" style="font-size:90%;"> distance</span>
</td>
<td id="S3.T4.5.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<table id="S3.T4.5.5.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.5.5.3.1.1" class="ltx_tr">
<td id="S3.T4.5.5.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.5.5.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Label-based</span></td>
</tr>
<tr id="S3.T4.5.5.3.1.2" class="ltx_tr">
<td id="S3.T4.5.5.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.5.5.3.1.2.1.1" class="ltx_text" style="font-size:90%;">regularizer</span></td>
</tr>
</table>
</td>
<td id="S3.T4.5.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.5.5.4.1" class="ltx_text" style="font-size:90%;">8</span></td>
<td id="S3.T4.5.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.5.5.5.1" class="ltx_text" style="font-size:90%;">Opt-based</span></td>
<td id="S3.T4.5.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.5.5.6.1" class="ltx_text" style="font-size:90%;">Yes</span></td>
<td id="S3.T4.5.5.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.5.5.7.1" class="ltx_text" style="font-size:90%;">No</span></td>
<td id="S3.T4.5.5.8" class="ltx_td ltx_border_t" style="padding:0.9pt 2.0pt;"></td>
</tr>
<tr id="S3.T4.11.14.3" class="ltx_tr">
<td id="S3.T4.11.14.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<span id="S3.T4.11.14.3.1.1" class="ltx_text" style="font-size:90%;">SAPAG </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T4.11.14.3.1.2.1" class="ltx_text" style="font-size:90%;">(</span>Wang et al<span class="ltx_text">.</span><span id="S3.T4.11.14.3.1.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib188" title="" class="ltx_ref">2020a</a><span id="S3.T4.11.14.3.1.4.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T4.11.14.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<table id="S3.T4.11.14.3.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.11.14.3.2.1.1" class="ltx_tr">
<td id="S3.T4.11.14.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.14.3.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Gaussian</span></td>
</tr>
<tr id="S3.T4.11.14.3.2.1.2" class="ltx_tr">
<td id="S3.T4.11.14.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.14.3.2.1.2.1.1" class="ltx_text" style="font-size:90%;">kerneal</span></td>
</tr>
<tr id="S3.T4.11.14.3.2.1.3" class="ltx_tr">
<td id="S3.T4.11.14.3.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.14.3.2.1.3.1.1" class="ltx_text" style="font-size:90%;">based function</span></td>
</tr>
</table>
</td>
<td id="S3.T4.11.14.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.14.3.3.1" class="ltx_text" style="font-size:90%;">/</span></td>
<td id="S3.T4.11.14.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.14.3.4.1" class="ltx_text" style="font-size:90%;">8</span></td>
<td id="S3.T4.11.14.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.14.3.5.1" class="ltx_text" style="font-size:90%;">Opt-based</span></td>
<td id="S3.T4.11.14.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.14.3.6.1" class="ltx_text" style="font-size:90%;">No</span></td>
<td id="S3.T4.11.14.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.14.3.7.1" class="ltx_text" style="font-size:90%;">No</span></td>
<td id="S3.T4.11.14.3.8" class="ltx_td ltx_border_t" style="padding:0.9pt 2.0pt;"></td>
</tr>
<tr id="S3.T4.11.15.4" class="ltx_tr">
<td id="S3.T4.11.15.4.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<span id="S3.T4.11.15.4.1.1" class="ltx_text" style="font-size:90%;">R-GAP </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T4.11.15.4.1.2.1" class="ltx_text" style="font-size:90%;">(</span>Zhu and Blaschko<span id="S3.T4.11.15.4.1.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib231" title="" class="ltx_ref">2020</a><span id="S3.T4.11.15.4.1.4.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T4.11.15.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<table id="S3.T4.11.15.4.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.11.15.4.2.1.1" class="ltx_tr">
<td id="S3.T4.11.15.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.15.4.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Recursive</span></td>
</tr>
<tr id="S3.T4.11.15.4.2.1.2" class="ltx_tr">
<td id="S3.T4.11.15.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.15.4.2.1.2.1.1" class="ltx_text" style="font-size:90%;">gradients</span></td>
</tr>
</table>
</td>
<td id="S3.T4.11.15.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.15.4.3.1" class="ltx_text" style="font-size:90%;">/</span></td>
<td id="S3.T4.11.15.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.15.4.4.1" class="ltx_text" style="font-size:90%;">5</span></td>
<td id="S3.T4.11.15.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.15.4.5.1" class="ltx_text" style="font-size:90%;">Closed-form</span></td>
<td id="S3.T4.11.15.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.15.4.6.1" class="ltx_text" style="font-size:90%;">No</span></td>
<td id="S3.T4.11.15.4.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.15.4.7.1" class="ltx_text" style="font-size:90%;">No</span></td>
<td id="S3.T4.11.15.4.8" class="ltx_td ltx_border_t" style="padding:0.9pt 2.0pt;"></td>
</tr>
<tr id="S3.T4.7.7" class="ltx_tr">
<td id="S3.T4.7.7.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<table id="S3.T4.7.7.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.7.7.3.1.1" class="ltx_tr">
<td id="S3.T4.7.7.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.7.7.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Theory-</span></td>
</tr>
<tr id="S3.T4.7.7.3.1.2" class="ltx_tr">
<td id="S3.T4.7.7.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;">
<span id="S3.T4.7.7.3.1.2.1.1" class="ltx_text" style="font-size:90%;">oriented </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T4.7.7.3.1.2.1.2.1" class="ltx_text" style="font-size:90%;">(</span>Pan
et al<span class="ltx_text">.</span><span id="S3.T4.7.7.3.1.2.1.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib146" title="" class="ltx_ref">2020</a><span id="S3.T4.7.7.3.1.2.1.4.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
</tr>
</table>
</td>
<td id="S3.T4.6.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<math id="S3.T4.6.6.1.m1.1" class="ltx_Math" alttext="l_{2}" display="inline"><semantics id="S3.T4.6.6.1.m1.1a"><msub id="S3.T4.6.6.1.m1.1.1" xref="S3.T4.6.6.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.T4.6.6.1.m1.1.1.2" xref="S3.T4.6.6.1.m1.1.1.2.cmml">l</mi><mn mathsize="90%" id="S3.T4.6.6.1.m1.1.1.3" xref="S3.T4.6.6.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T4.6.6.1.m1.1b"><apply id="S3.T4.6.6.1.m1.1.1.cmml" xref="S3.T4.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T4.6.6.1.m1.1.1.1.cmml" xref="S3.T4.6.6.1.m1.1.1">subscript</csymbol><ci id="S3.T4.6.6.1.m1.1.1.2.cmml" xref="S3.T4.6.6.1.m1.1.1.2">𝑙</ci><cn type="integer" id="S3.T4.6.6.1.m1.1.1.3.cmml" xref="S3.T4.6.6.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.6.6.1.m1.1c">l_{2}</annotation></semantics></math><span id="S3.T4.6.6.1.1" class="ltx_text" style="font-size:90%;"> distance</span>
</td>
<td id="S3.T4.7.7.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<table id="S3.T4.7.7.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.7.7.2.1.1" class="ltx_tr">
<td id="S3.T4.7.7.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;">
<math id="S3.T4.7.7.2.1.1.1.m1.1" class="ltx_Math" alttext="l_{1}" display="inline"><semantics id="S3.T4.7.7.2.1.1.1.m1.1a"><msub id="S3.T4.7.7.2.1.1.1.m1.1.1" xref="S3.T4.7.7.2.1.1.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.T4.7.7.2.1.1.1.m1.1.1.2" xref="S3.T4.7.7.2.1.1.1.m1.1.1.2.cmml">l</mi><mn mathsize="90%" id="S3.T4.7.7.2.1.1.1.m1.1.1.3" xref="S3.T4.7.7.2.1.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T4.7.7.2.1.1.1.m1.1b"><apply id="S3.T4.7.7.2.1.1.1.m1.1.1.cmml" xref="S3.T4.7.7.2.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T4.7.7.2.1.1.1.m1.1.1.1.cmml" xref="S3.T4.7.7.2.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.T4.7.7.2.1.1.1.m1.1.1.2.cmml" xref="S3.T4.7.7.2.1.1.1.m1.1.1.2">𝑙</ci><cn type="integer" id="S3.T4.7.7.2.1.1.1.m1.1.1.3.cmml" xref="S3.T4.7.7.2.1.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.7.7.2.1.1.1.m1.1c">l_{1}</annotation></semantics></math><span id="S3.T4.7.7.2.1.1.1.1" class="ltx_text" style="font-size:90%;"> distance of</span>
</td>
</tr>
<tr id="S3.T4.7.7.2.1.2" class="ltx_tr">
<td id="S3.T4.7.7.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.7.7.2.1.2.1.1" class="ltx_text" style="font-size:90%;">feature map</span></td>
</tr>
</table>
</td>
<td id="S3.T4.7.7.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.7.7.4.1" class="ltx_text" style="font-size:90%;">32</span></td>
<td id="S3.T4.7.7.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.7.7.5.1" class="ltx_text" style="font-size:90%;">Closed-form</span></td>
<td id="S3.T4.7.7.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.7.7.6.1" class="ltx_text" style="font-size:90%;">Yes</span></td>
<td id="S3.T4.7.7.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<table id="S3.T4.7.7.7.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.7.7.7.1.1" class="ltx_tr">
<td id="S3.T4.7.7.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.7.7.7.1.1.1.1" class="ltx_text" style="font-size:90%;">Exclusive</span></td>
</tr>
<tr id="S3.T4.7.7.7.1.2" class="ltx_tr">
<td id="S3.T4.7.7.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.7.7.7.1.2.1.1" class="ltx_text" style="font-size:90%;">activated</span></td>
</tr>
<tr id="S3.T4.7.7.7.1.3" class="ltx_tr">
<td id="S3.T4.7.7.7.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.7.7.7.1.3.1.1" class="ltx_text" style="font-size:90%;">neurons</span></td>
</tr>
</table>
</td>
<td id="S3.T4.7.7.8" class="ltx_td ltx_border_t" style="padding:0.9pt 2.0pt;"></td>
</tr>
<tr id="S3.T4.8.8" class="ltx_tr">
<td id="S3.T4.8.8.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<table id="S3.T4.8.8.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.8.8.2.1.1" class="ltx_tr">
<td id="S3.T4.8.8.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.8.8.2.1.1.1.1" class="ltx_text" style="font-size:90%;">GradInversion</span></td>
</tr>
<tr id="S3.T4.8.8.2.1.2" class="ltx_tr">
<td id="S3.T4.8.8.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T4.8.8.2.1.2.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Yin et al<span class="ltx_text">.</span><span id="S3.T4.8.8.2.1.2.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib208" title="" class="ltx_ref">2021a</a><span id="S3.T4.8.8.2.1.2.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
</tr>
</table>
</td>
<td id="S3.T4.8.8.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<math id="S3.T4.8.8.1.m1.1" class="ltx_Math" alttext="l_{2}" display="inline"><semantics id="S3.T4.8.8.1.m1.1a"><msub id="S3.T4.8.8.1.m1.1.1" xref="S3.T4.8.8.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.T4.8.8.1.m1.1.1.2" xref="S3.T4.8.8.1.m1.1.1.2.cmml">l</mi><mn mathsize="90%" id="S3.T4.8.8.1.m1.1.1.3" xref="S3.T4.8.8.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T4.8.8.1.m1.1b"><apply id="S3.T4.8.8.1.m1.1.1.cmml" xref="S3.T4.8.8.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T4.8.8.1.m1.1.1.1.cmml" xref="S3.T4.8.8.1.m1.1.1">subscript</csymbol><ci id="S3.T4.8.8.1.m1.1.1.2.cmml" xref="S3.T4.8.8.1.m1.1.1.2">𝑙</ci><cn type="integer" id="S3.T4.8.8.1.m1.1.1.3.cmml" xref="S3.T4.8.8.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.8.8.1.m1.1c">l_{2}</annotation></semantics></math><span id="S3.T4.8.8.1.1" class="ltx_text" style="font-size:90%;"> distance</span>
</td>
<td id="S3.T4.8.8.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<table id="S3.T4.8.8.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.8.8.3.1.1" class="ltx_tr">
<td id="S3.T4.8.8.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.8.8.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Group</span></td>
</tr>
<tr id="S3.T4.8.8.3.1.2" class="ltx_tr">
<td id="S3.T4.8.8.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.8.8.3.1.2.1.1" class="ltx_text" style="font-size:90%;">consistency</span></td>
</tr>
</table>
</td>
<td id="S3.T4.8.8.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.8.8.4.1" class="ltx_text" style="font-size:90%;">48</span></td>
<td id="S3.T4.8.8.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.8.8.5.1" class="ltx_text" style="font-size:90%;">Opt-based</span></td>
<td id="S3.T4.8.8.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.8.8.6.1" class="ltx_text" style="font-size:90%;">No</span></td>
<td id="S3.T4.8.8.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.8.8.7.1" class="ltx_text" style="font-size:90%;">BN statistcs</span></td>
<td id="S3.T4.8.8.8" class="ltx_td ltx_border_t" style="padding:0.9pt 2.0pt;"></td>
</tr>
<tr id="S3.T4.9.9" class="ltx_tr">
<td id="S3.T4.9.9.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<span id="S3.T4.9.9.2.1" class="ltx_text" style="font-size:90%;">CAFÉ </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T4.9.9.2.2.1" class="ltx_text" style="font-size:90%;">(</span>Jin
et al<span class="ltx_text">.</span><span id="S3.T4.9.9.2.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib88" title="" class="ltx_ref">2021</a><span id="S3.T4.9.9.2.4.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T4.9.9.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<math id="S3.T4.9.9.1.m1.1" class="ltx_Math" alttext="l_{2}" display="inline"><semantics id="S3.T4.9.9.1.m1.1a"><msub id="S3.T4.9.9.1.m1.1.1" xref="S3.T4.9.9.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.T4.9.9.1.m1.1.1.2" xref="S3.T4.9.9.1.m1.1.1.2.cmml">l</mi><mn mathsize="90%" id="S3.T4.9.9.1.m1.1.1.3" xref="S3.T4.9.9.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T4.9.9.1.m1.1b"><apply id="S3.T4.9.9.1.m1.1.1.cmml" xref="S3.T4.9.9.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T4.9.9.1.m1.1.1.1.cmml" xref="S3.T4.9.9.1.m1.1.1">subscript</csymbol><ci id="S3.T4.9.9.1.m1.1.1.2.cmml" xref="S3.T4.9.9.1.m1.1.1.2">𝑙</ci><cn type="integer" id="S3.T4.9.9.1.m1.1.1.3.cmml" xref="S3.T4.9.9.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.9.9.1.m1.1c">l_{2}</annotation></semantics></math><span id="S3.T4.9.9.1.1" class="ltx_text" style="font-size:90%;"> distance</span>
</td>
<td id="S3.T4.9.9.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.9.9.3.1" class="ltx_text" style="font-size:90%;">Total variance</span></td>
<td id="S3.T4.9.9.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.9.9.4.1" class="ltx_text" style="font-size:90%;">100</span></td>
<td id="S3.T4.9.9.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.9.9.5.1" class="ltx_text" style="font-size:90%;">Opt-based</span></td>
<td id="S3.T4.9.9.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.9.9.6.1" class="ltx_text" style="font-size:90%;">Yes</span></td>
<td id="S3.T4.9.9.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.9.9.7.1" class="ltx_text" style="font-size:90%;">Batch indices</span></td>
<td id="S3.T4.9.9.8" class="ltx_td ltx_border_t" style="padding:0.9pt 2.0pt;"></td>
</tr>
<tr id="S3.T4.10.10" class="ltx_tr">
<td id="S3.T4.10.10.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<span id="S3.T4.10.10.2.1" class="ltx_text" style="font-size:90%;">GIAS&amp;GIM </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T4.10.10.2.2.1" class="ltx_text" style="font-size:90%;">(</span>Jeon
et al<span class="ltx_text">.</span><span id="S3.T4.10.10.2.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib83" title="" class="ltx_ref">2021</a><span id="S3.T4.10.10.2.4.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T4.10.10.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<table id="S3.T4.10.10.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.10.10.3.1.1" class="ltx_tr">
<td id="S3.T4.10.10.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.10.10.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Negative</span></td>
</tr>
<tr id="S3.T4.10.10.3.1.2" class="ltx_tr">
<td id="S3.T4.10.10.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.10.10.3.1.2.1.1" class="ltx_text" style="font-size:90%;">cosine</span></td>
</tr>
</table>
</td>
<td id="S3.T4.10.10.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<table id="S3.T4.10.10.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.10.10.1.1.1" class="ltx_tr">
<td id="S3.T4.10.10.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;">
<math id="S3.T4.10.10.1.1.1.1.m1.1" class="ltx_Math" alttext="l_{2}" display="inline"><semantics id="S3.T4.10.10.1.1.1.1.m1.1a"><msub id="S3.T4.10.10.1.1.1.1.m1.1.1" xref="S3.T4.10.10.1.1.1.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.T4.10.10.1.1.1.1.m1.1.1.2" xref="S3.T4.10.10.1.1.1.1.m1.1.1.2.cmml">l</mi><mn mathsize="90%" id="S3.T4.10.10.1.1.1.1.m1.1.1.3" xref="S3.T4.10.10.1.1.1.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T4.10.10.1.1.1.1.m1.1b"><apply id="S3.T4.10.10.1.1.1.1.m1.1.1.cmml" xref="S3.T4.10.10.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T4.10.10.1.1.1.1.m1.1.1.1.cmml" xref="S3.T4.10.10.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.T4.10.10.1.1.1.1.m1.1.1.2.cmml" xref="S3.T4.10.10.1.1.1.1.m1.1.1.2">𝑙</ci><cn type="integer" id="S3.T4.10.10.1.1.1.1.m1.1.1.3.cmml" xref="S3.T4.10.10.1.1.1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.10.10.1.1.1.1.m1.1c">l_{2}</annotation></semantics></math><span id="S3.T4.10.10.1.1.1.1.1" class="ltx_text" style="font-size:90%;"> distance in</span>
</td>
</tr>
<tr id="S3.T4.10.10.1.1.2" class="ltx_tr">
<td id="S3.T4.10.10.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.10.10.1.1.2.1.1" class="ltx_text" style="font-size:90%;">latent space</span></td>
</tr>
</table>
</td>
<td id="S3.T4.10.10.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.10.10.4.1" class="ltx_text" style="font-size:90%;">4</span></td>
<td id="S3.T4.10.10.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.10.10.5.1" class="ltx_text" style="font-size:90%;">Opt-based</span></td>
<td id="S3.T4.10.10.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.10.10.6.1" class="ltx_text" style="font-size:90%;">No</span></td>
<td id="S3.T4.10.10.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.10.10.7.1" class="ltx_text" style="font-size:90%;">No</span></td>
<td id="S3.T4.10.10.8" class="ltx_td ltx_border_t" style="padding:0.9pt 2.0pt;"></td>
</tr>
<tr id="S3.T4.11.16.5" class="ltx_tr">
<td id="S3.T4.11.16.5.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<table id="S3.T4.11.16.5.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.11.16.5.1.1.1" class="ltx_tr">
<td id="S3.T4.11.16.5.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.16.5.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Imprint</span></td>
</tr>
<tr id="S3.T4.11.16.5.1.1.2" class="ltx_tr">
<td id="S3.T4.11.16.5.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;">
<span id="S3.T4.11.16.5.1.1.2.1.1" class="ltx_text" style="font-size:90%;">module </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T4.11.16.5.1.1.2.1.2.1" class="ltx_text" style="font-size:90%;">(</span>Fowl et al<span class="ltx_text">.</span><span id="S3.T4.11.16.5.1.1.2.1.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib54" title="" class="ltx_ref">2021</a><span id="S3.T4.11.16.5.1.1.2.1.4.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
</tr>
</table>
</td>
<td id="S3.T4.11.16.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;">
<table id="S3.T4.11.16.5.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.11.16.5.2.1.1" class="ltx_tr">
<td id="S3.T4.11.16.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.16.5.2.1.1.1.1" class="ltx_text" style="font-size:90%;">One-shot</span></td>
</tr>
<tr id="S3.T4.11.16.5.2.1.2" class="ltx_tr">
<td id="S3.T4.11.16.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.16.5.2.1.2.1.1" class="ltx_text" style="font-size:90%;">mechanism</span></td>
</tr>
</table>
</td>
<td id="S3.T4.11.16.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.16.5.3.1" class="ltx_text" style="font-size:90%;">/</span></td>
<td id="S3.T4.11.16.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.16.5.4.1" class="ltx_text" style="font-size:90%;">16384</span></td>
<td id="S3.T4.11.16.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.16.5.5.1" class="ltx_text" style="font-size:90%;">Closed-form</span></td>
<td id="S3.T4.11.16.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.16.5.6.1" class="ltx_text" style="font-size:90%;">Yes</span></td>
<td id="S3.T4.11.16.5.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.16.5.7.1" class="ltx_text" style="font-size:90%;">CDF</span></td>
<td id="S3.T4.11.16.5.8" class="ltx_td ltx_border_t" style="padding:0.9pt 2.0pt;"></td>
</tr>
<tr id="S3.T4.11.11" class="ltx_tr">
<td id="S3.T4.11.11.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:0.9pt 2.0pt;">
<span id="S3.T4.11.11.2.1" class="ltx_text" style="font-size:90%;">GradViT </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T4.11.11.2.2.1" class="ltx_text" style="font-size:90%;">(</span>Hatamizadeh et al<span class="ltx_text">.</span><span id="S3.T4.11.11.2.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib75" title="" class="ltx_ref">2022</a><span id="S3.T4.11.11.2.4.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T4.11.11.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:0.9pt 2.0pt;">
<math id="S3.T4.11.11.1.m1.1" class="ltx_Math" alttext="l_{2}" display="inline"><semantics id="S3.T4.11.11.1.m1.1a"><msub id="S3.T4.11.11.1.m1.1.1" xref="S3.T4.11.11.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.T4.11.11.1.m1.1.1.2" xref="S3.T4.11.11.1.m1.1.1.2.cmml">l</mi><mn mathsize="90%" id="S3.T4.11.11.1.m1.1.1.3" xref="S3.T4.11.11.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T4.11.11.1.m1.1b"><apply id="S3.T4.11.11.1.m1.1.1.cmml" xref="S3.T4.11.11.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T4.11.11.1.m1.1.1.1.cmml" xref="S3.T4.11.11.1.m1.1.1">subscript</csymbol><ci id="S3.T4.11.11.1.m1.1.1.2.cmml" xref="S3.T4.11.11.1.m1.1.1.2">𝑙</ci><cn type="integer" id="S3.T4.11.11.1.m1.1.1.3.cmml" xref="S3.T4.11.11.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.11.11.1.m1.1c">l_{2}</annotation></semantics></math><span id="S3.T4.11.11.1.1" class="ltx_text" style="font-size:90%;"> distance</span>
</td>
<td id="S3.T4.11.11.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:0.9pt 2.0pt;">
<table id="S3.T4.11.11.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.11.11.3.1.1" class="ltx_tr">
<td id="S3.T4.11.11.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.11.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Image prior;</span></td>
</tr>
<tr id="S3.T4.11.11.3.1.2" class="ltx_tr">
<td id="S3.T4.11.11.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.11.3.1.2.1.1" class="ltx_text" style="font-size:90%;">Auxiliary</span></td>
</tr>
<tr id="S3.T4.11.11.3.1.3" class="ltx_tr">
<td id="S3.T4.11.11.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.11.3.1.3.1.1" class="ltx_text" style="font-size:90%;">Regularization</span></td>
</tr>
</table>
</td>
<td id="S3.T4.11.11.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.11.4.1" class="ltx_text" style="font-size:90%;">64</span></td>
<td id="S3.T4.11.11.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.11.5.1" class="ltx_text" style="font-size:90%;">Opt-based</span></td>
<td id="S3.T4.11.11.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.11.6.1" class="ltx_text" style="font-size:90%;">No</span></td>
<td id="S3.T4.11.11.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:0.9pt 2.0pt;">
<table id="S3.T4.11.11.7.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.11.11.7.1.1" class="ltx_tr">
<td id="S3.T4.11.11.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.11.7.1.1.1.1" class="ltx_text" style="font-size:90%;">Auxiliary</span></td>
</tr>
<tr id="S3.T4.11.11.7.1.2" class="ltx_tr">
<td id="S3.T4.11.11.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.9pt 2.0pt;"><span id="S3.T4.11.11.7.1.2.1.1" class="ltx_text" style="font-size:90%;">networks</span></td>
</tr>
</table>
</td>
<td id="S3.T4.11.11.8" class="ltx_td ltx_border_b ltx_border_t" style="padding:0.9pt 2.0pt;"></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.3. </span>Discussion</h4>

<div id="S3.SS4.SSS3.p1" class="ltx_para">
<p id="S3.SS4.SSS3.p1.1" class="ltx_p">The closed-form attacks outperform optimization-based attacks in several aspects. First, the closed-form attacks provide a theoretical guarantee of convergence. In contrast optimization-based attacks suffer from the local optimum problem since a non-convex optimization may not always converge to a correct solution <cite class="ltx_cite ltx_citemacro_citep">(Geiping et al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2020</a>)</cite>. Further, optimization-based attacks are sensitive to initialization <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib232" title="" class="ltx_ref">2019</a>)</cite>, whereas closed-form attacks do not. Second, the deterministic algorithms run by closed-form attacks are faster than optimization-based attacks. Third, closed-form attacks recover the data more accurately, while optimization-based methods, like GradInversion <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib208" title="" class="ltx_ref">2021a</a>)</cite>, recover data with artifacts. Jin et al. <cite class="ltx_cite ltx_citemacro_citep">(Jin
et al<span class="ltx_text">.</span>, <a href="#bib.bib88" title="" class="ltx_ref">2021</a>)</cite> made a good comparison between different reconstruction attacks in FL. Table <a href="#S3.T4" title="Table 4 ‣ 3.4.2. Closed-form Attack ‣ 3.4. Reconstruction Attacks ‣ 3. Privacy in FL ‣ Privacy and Fairness in Federated Learning: on the Perspective of Trade-off" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> summarizes their finding and includes some additional results from this study.</p>
</div>
</section>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5. </span>Privacy-preserving Techniques</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">Privacy-preserving machine learning approaches can be roughly classified as cryptographic approaches and perturbation approaches. Cryptographic approaches enable computation over encrypted data and provide rigorous privacy guarantees in the training process. However, they come at a high computational cost compared to the non-encryption alternatives <cite class="ltx_cite ltx_citemacro_citep">(Xu
et al<span class="ltx_text">.</span>, <a href="#bib.bib199" title="" class="ltx_ref">2021a</a>)</cite>. This computation overhead limits their application in some learning scenarios, particularly in deep neural networks with huge amounts of parameters. As a result, most state-of-the-art privacy-preserving methods are perturbation-based. The perturbation can be accomplished by adding artifact noise into the dataset, such as DP mechanism <cite class="ltx_cite ltx_citemacro_citep">(Geyer
et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2017</a>; Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib191" title="" class="ltx_ref">2020a</a>)</cite>. Or by representing the raw dataset with a surrogate dataset <cite class="ltx_cite ltx_citemacro_citep">(Wu
et al<span class="ltx_text">.</span>, <a href="#bib.bib194" title="" class="ltx_ref">2021</a>; Scheliga
et al<span class="ltx_text">.</span>, <a href="#bib.bib160" title="" class="ltx_ref">2022</a>)</cite> or abstracting the dataset via sketch techniques <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib113" title="" class="ltx_ref">2019a</a>; Haddadpour
et al<span class="ltx_text">.</span>, <a href="#bib.bib70" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<section id="S3.SS5.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.5.1. </span>Cryptographic Approaches</h4>

<div id="S3.SS5.SSS1.p1" class="ltx_para">
<p id="S3.SS5.SSS1.p1.1" class="ltx_p">Secure multi-party computation is a sub-field of cryptography that executes calculations on data dispersed among multiple parties in such a way that the computation results are only revealed to the participants <cite class="ltx_cite ltx_citemacro_citep">(Yao, <a href="#bib.bib205" title="" class="ltx_ref">1982</a>)</cite>. It can take the form of homomorphic encryption (HE) or secret sharing.</p>
</div>
<div id="S3.SS5.SSS1.p2" class="ltx_para">
<p id="S3.SS5.SSS1.p2.3" class="ltx_p">As one of the defacto privacy-preserving solutions, homomorphic encryption (HE) provides perfect privacy protection in the face of a malicious server. It allows clients to encrypt their updates in such a way that the server may directly aggregate ciphertexts without divulging anything about the plain text underneath. The downside is that encryption followed by decryption will inevitably impose both a computation and a communications overhead. Phong et al. <cite class="ltx_cite ltx_citemacro_citep">(Phong
et al<span class="ltx_text">.</span>, <a href="#bib.bib150" title="" class="ltx_ref">2018</a>)</cite> used <span id="S3.SS5.SSS1.p2.3.1" class="ltx_text ltx_font_italic">additively homomorphic encryption</span> to ensure no information was leaked to a malicious server. The encrypted aggregation was formulated as follows:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(4)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.3" class="ltx_Math" alttext="\bf{E}(W_{global}):=\bf{E}(W_{global})+\bf{E}(-\alpha\cdot G_{local})" display="block"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3" xref="S3.E4.m1.3.3.cmml"><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.3" xref="S3.E4.m1.1.1.1.3.cmml">𝐄</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.2.cmml">​</mo><mrow id="S3.E4.m1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.2.cmml">𝐖</mi><mi id="S3.E4.m1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.3.cmml">𝐠𝐥𝐨𝐛𝐚𝐥</mi></msub><mo rspace="0.278em" stretchy="false" id="S3.E4.m1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.278em" id="S3.E4.m1.3.3.4" xref="S3.E4.m1.3.3.4.cmml">:=</mo><mrow id="S3.E4.m1.3.3.3" xref="S3.E4.m1.3.3.3.cmml"><mrow id="S3.E4.m1.2.2.2.1" xref="S3.E4.m1.2.2.2.1.cmml"><mi id="S3.E4.m1.2.2.2.1.3" xref="S3.E4.m1.2.2.2.1.3.cmml">𝐄</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.1.2" xref="S3.E4.m1.2.2.2.1.2.cmml">​</mo><mrow id="S3.E4.m1.2.2.2.1.1.1" xref="S3.E4.m1.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.2.2.2.1.1.1.2" xref="S3.E4.m1.2.2.2.1.1.1.1.cmml">(</mo><msub id="S3.E4.m1.2.2.2.1.1.1.1" xref="S3.E4.m1.2.2.2.1.1.1.1.cmml"><mi id="S3.E4.m1.2.2.2.1.1.1.1.2" xref="S3.E4.m1.2.2.2.1.1.1.1.2.cmml">𝐖</mi><mi id="S3.E4.m1.2.2.2.1.1.1.1.3" xref="S3.E4.m1.2.2.2.1.1.1.1.3.cmml">𝐠𝐥𝐨𝐛𝐚𝐥</mi></msub><mo stretchy="false" id="S3.E4.m1.2.2.2.1.1.1.3" xref="S3.E4.m1.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.3.3.3.3" xref="S3.E4.m1.3.3.3.3.cmml">+</mo><mrow id="S3.E4.m1.3.3.3.2" xref="S3.E4.m1.3.3.3.2.cmml"><mi id="S3.E4.m1.3.3.3.2.3" xref="S3.E4.m1.3.3.3.2.3.cmml">𝐄</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.3.2.2" xref="S3.E4.m1.3.3.3.2.2.cmml">​</mo><mrow id="S3.E4.m1.3.3.3.2.1.1" xref="S3.E4.m1.3.3.3.2.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.3.2.1.1.2" xref="S3.E4.m1.3.3.3.2.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.3.3.3.2.1.1.1" xref="S3.E4.m1.3.3.3.2.1.1.1.cmml"><mo id="S3.E4.m1.3.3.3.2.1.1.1a" xref="S3.E4.m1.3.3.3.2.1.1.1.cmml">−</mo><mrow id="S3.E4.m1.3.3.3.2.1.1.1.2" xref="S3.E4.m1.3.3.3.2.1.1.1.2.cmml"><mi id="S3.E4.m1.3.3.3.2.1.1.1.2.2" xref="S3.E4.m1.3.3.3.2.1.1.1.2.2.cmml">α</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.3.3.3.2.1.1.1.2.1" xref="S3.E4.m1.3.3.3.2.1.1.1.2.1.cmml">⋅</mo><msub id="S3.E4.m1.3.3.3.2.1.1.1.2.3" xref="S3.E4.m1.3.3.3.2.1.1.1.2.3.cmml"><mi id="S3.E4.m1.3.3.3.2.1.1.1.2.3.2" xref="S3.E4.m1.3.3.3.2.1.1.1.2.3.2.cmml">𝐆</mi><mi id="S3.E4.m1.3.3.3.2.1.1.1.2.3.3" xref="S3.E4.m1.3.3.3.2.1.1.1.2.3.3.cmml">𝐥𝐨𝐜𝐚𝐥</mi></msub></mrow></mrow><mo stretchy="false" id="S3.E4.m1.3.3.3.2.1.1.3" xref="S3.E4.m1.3.3.3.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.cmml" xref="S3.E4.m1.3.3"><csymbol cd="latexml" id="S3.E4.m1.3.3.4.cmml" xref="S3.E4.m1.3.3.4">assign</csymbol><apply id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><times id="S3.E4.m1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.2"></times><ci id="S3.E4.m1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.3">𝐄</ci><apply id="S3.E4.m1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2">𝐖</ci><ci id="S3.E4.m1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3">𝐠𝐥𝐨𝐛𝐚𝐥</ci></apply></apply><apply id="S3.E4.m1.3.3.3.cmml" xref="S3.E4.m1.3.3.3"><plus id="S3.E4.m1.3.3.3.3.cmml" xref="S3.E4.m1.3.3.3.3"></plus><apply id="S3.E4.m1.2.2.2.1.cmml" xref="S3.E4.m1.2.2.2.1"><times id="S3.E4.m1.2.2.2.1.2.cmml" xref="S3.E4.m1.2.2.2.1.2"></times><ci id="S3.E4.m1.2.2.2.1.3.cmml" xref="S3.E4.m1.2.2.2.1.3">𝐄</ci><apply id="S3.E4.m1.2.2.2.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.1.1.1">subscript</csymbol><ci id="S3.E4.m1.2.2.2.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.2">𝐖</ci><ci id="S3.E4.m1.2.2.2.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.3">𝐠𝐥𝐨𝐛𝐚𝐥</ci></apply></apply><apply id="S3.E4.m1.3.3.3.2.cmml" xref="S3.E4.m1.3.3.3.2"><times id="S3.E4.m1.3.3.3.2.2.cmml" xref="S3.E4.m1.3.3.3.2.2"></times><ci id="S3.E4.m1.3.3.3.2.3.cmml" xref="S3.E4.m1.3.3.3.2.3">𝐄</ci><apply id="S3.E4.m1.3.3.3.2.1.1.1.cmml" xref="S3.E4.m1.3.3.3.2.1.1"><minus id="S3.E4.m1.3.3.3.2.1.1.1.1.cmml" xref="S3.E4.m1.3.3.3.2.1.1"></minus><apply id="S3.E4.m1.3.3.3.2.1.1.1.2.cmml" xref="S3.E4.m1.3.3.3.2.1.1.1.2"><ci id="S3.E4.m1.3.3.3.2.1.1.1.2.1.cmml" xref="S3.E4.m1.3.3.3.2.1.1.1.2.1">⋅</ci><ci id="S3.E4.m1.3.3.3.2.1.1.1.2.2.cmml" xref="S3.E4.m1.3.3.3.2.1.1.1.2.2">𝛼</ci><apply id="S3.E4.m1.3.3.3.2.1.1.1.2.3.cmml" xref="S3.E4.m1.3.3.3.2.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.3.2.1.1.1.2.3.1.cmml" xref="S3.E4.m1.3.3.3.2.1.1.1.2.3">subscript</csymbol><ci id="S3.E4.m1.3.3.3.2.1.1.1.2.3.2.cmml" xref="S3.E4.m1.3.3.3.2.1.1.1.2.3.2">𝐆</ci><ci id="S3.E4.m1.3.3.3.2.1.1.1.2.3.3.cmml" xref="S3.E4.m1.3.3.3.2.1.1.1.2.3.3">𝐥𝐨𝐜𝐚𝐥</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">\bf{E}(W_{global}):=\bf{E}(W_{global})+\bf{E}(-\alpha\cdot G_{local})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS5.SSS1.p2.2" class="ltx_p">where <span id="S3.SS5.SSS1.p2.2.1" class="ltx_text ltx_font_bold">E</span> is a homomorphic encryption operator that supports addition over ciphertexts, <math id="S3.SS5.SSS1.p2.1.m1.1" class="ltx_Math" alttext="\bf{G_{local}}" display="inline"><semantics id="S3.SS5.SSS1.p2.1.m1.1a"><msub id="S3.SS5.SSS1.p2.1.m1.1.1" xref="S3.SS5.SSS1.p2.1.m1.1.1.cmml"><mi id="S3.SS5.SSS1.p2.1.m1.1.1.2" xref="S3.SS5.SSS1.p2.1.m1.1.1.2.cmml">𝐆</mi><mi id="S3.SS5.SSS1.p2.1.m1.1.1.3" xref="S3.SS5.SSS1.p2.1.m1.1.1.3.cmml">𝐥𝐨𝐜𝐚𝐥</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p2.1.m1.1b"><apply id="S3.SS5.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS5.SSS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.p2.1.m1.1.1.1.cmml" xref="S3.SS5.SSS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.p2.1.m1.1.1.2.cmml" xref="S3.SS5.SSS1.p2.1.m1.1.1.2">𝐆</ci><ci id="S3.SS5.SSS1.p2.1.m1.1.1.3.cmml" xref="S3.SS5.SSS1.p2.1.m1.1.1.3">𝐥𝐨𝐜𝐚𝐥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p2.1.m1.1c">\bf{G_{local}}</annotation></semantics></math> is the aggregated gradient. The decryption key is public to the clients and private to the server, and thus, the client’s information is secured. Due to the additively homomorphic property of <span id="S3.SS5.SSS1.p2.2.2" class="ltx_text ltx_font_bold">E</span>, each client is still able to receive the correct updated model <math id="S3.SS5.SSS1.p2.2.m2.1" class="ltx_Math" alttext="W_{global}" display="inline"><semantics id="S3.SS5.SSS1.p2.2.m2.1a"><msub id="S3.SS5.SSS1.p2.2.m2.1.1" xref="S3.SS5.SSS1.p2.2.m2.1.1.cmml"><mi id="S3.SS5.SSS1.p2.2.m2.1.1.2" xref="S3.SS5.SSS1.p2.2.m2.1.1.2.cmml">W</mi><mrow id="S3.SS5.SSS1.p2.2.m2.1.1.3" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.cmml"><mi id="S3.SS5.SSS1.p2.2.m2.1.1.3.2" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS1.p2.2.m2.1.1.3.1" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS5.SSS1.p2.2.m2.1.1.3.3" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS1.p2.2.m2.1.1.3.1a" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS5.SSS1.p2.2.m2.1.1.3.4" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS1.p2.2.m2.1.1.3.1b" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS5.SSS1.p2.2.m2.1.1.3.5" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS1.p2.2.m2.1.1.3.1c" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS5.SSS1.p2.2.m2.1.1.3.6" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS1.p2.2.m2.1.1.3.1d" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS5.SSS1.p2.2.m2.1.1.3.7" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.7.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p2.2.m2.1b"><apply id="S3.SS5.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS5.SSS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.p2.2.m2.1.1.1.cmml" xref="S3.SS5.SSS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.p2.2.m2.1.1.2.cmml" xref="S3.SS5.SSS1.p2.2.m2.1.1.2">𝑊</ci><apply id="S3.SS5.SSS1.p2.2.m2.1.1.3.cmml" xref="S3.SS5.SSS1.p2.2.m2.1.1.3"><times id="S3.SS5.SSS1.p2.2.m2.1.1.3.1.cmml" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.1"></times><ci id="S3.SS5.SSS1.p2.2.m2.1.1.3.2.cmml" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.2">𝑔</ci><ci id="S3.SS5.SSS1.p2.2.m2.1.1.3.3.cmml" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.3">𝑙</ci><ci id="S3.SS5.SSS1.p2.2.m2.1.1.3.4.cmml" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.4">𝑜</ci><ci id="S3.SS5.SSS1.p2.2.m2.1.1.3.5.cmml" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.5">𝑏</ci><ci id="S3.SS5.SSS1.p2.2.m2.1.1.3.6.cmml" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.6">𝑎</ci><ci id="S3.SS5.SSS1.p2.2.m2.1.1.3.7.cmml" xref="S3.SS5.SSS1.p2.2.m2.1.1.3.7">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p2.2.m2.1c">W_{global}</annotation></semantics></math> via decryption.</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(5)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.3" class="ltx_Math" alttext="\bf{E}(W_{global})+\bf{E}(-\alpha\cdot G_{local})=\bf{E}(W_{global}-\alpha\cdot G_{local})" display="block"><semantics id="S3.E5.m1.3a"><mrow id="S3.E5.m1.3.3" xref="S3.E5.m1.3.3.cmml"><mrow id="S3.E5.m1.2.2.2" xref="S3.E5.m1.2.2.2.cmml"><mrow id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><mi id="S3.E5.m1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.3.cmml">𝐄</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E5.m1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E5.m1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.1.2.cmml">𝐖</mi><mi id="S3.E5.m1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.3.cmml">𝐠𝐥𝐨𝐛𝐚𝐥</mi></msub><mo stretchy="false" id="S3.E5.m1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.2.2.2.3" xref="S3.E5.m1.2.2.2.3.cmml">+</mo><mrow id="S3.E5.m1.2.2.2.2" xref="S3.E5.m1.2.2.2.2.cmml"><mi id="S3.E5.m1.2.2.2.2.3" xref="S3.E5.m1.2.2.2.2.3.cmml">𝐄</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.2.2.2" xref="S3.E5.m1.2.2.2.2.2.cmml">​</mo><mrow id="S3.E5.m1.2.2.2.2.1.1" xref="S3.E5.m1.2.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.2.2.2.2.1.1.2" xref="S3.E5.m1.2.2.2.2.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.2.2.2.2.1.1.1" xref="S3.E5.m1.2.2.2.2.1.1.1.cmml"><mo id="S3.E5.m1.2.2.2.2.1.1.1a" xref="S3.E5.m1.2.2.2.2.1.1.1.cmml">−</mo><mrow id="S3.E5.m1.2.2.2.2.1.1.1.2" xref="S3.E5.m1.2.2.2.2.1.1.1.2.cmml"><mi id="S3.E5.m1.2.2.2.2.1.1.1.2.2" xref="S3.E5.m1.2.2.2.2.1.1.1.2.2.cmml">α</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.2.2.2.2.1.1.1.2.1" xref="S3.E5.m1.2.2.2.2.1.1.1.2.1.cmml">⋅</mo><msub id="S3.E5.m1.2.2.2.2.1.1.1.2.3" xref="S3.E5.m1.2.2.2.2.1.1.1.2.3.cmml"><mi id="S3.E5.m1.2.2.2.2.1.1.1.2.3.2" xref="S3.E5.m1.2.2.2.2.1.1.1.2.3.2.cmml">𝐆</mi><mi id="S3.E5.m1.2.2.2.2.1.1.1.2.3.3" xref="S3.E5.m1.2.2.2.2.1.1.1.2.3.3.cmml">𝐥𝐨𝐜𝐚𝐥</mi></msub></mrow></mrow><mo stretchy="false" id="S3.E5.m1.2.2.2.2.1.1.3" xref="S3.E5.m1.2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E5.m1.3.3.4" xref="S3.E5.m1.3.3.4.cmml">=</mo><mrow id="S3.E5.m1.3.3.3" xref="S3.E5.m1.3.3.3.cmml"><mi id="S3.E5.m1.3.3.3.3" xref="S3.E5.m1.3.3.3.3.cmml">𝐄</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.3.3.3.2" xref="S3.E5.m1.3.3.3.2.cmml">​</mo><mrow id="S3.E5.m1.3.3.3.1.1" xref="S3.E5.m1.3.3.3.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.3.3.3.1.1.2" xref="S3.E5.m1.3.3.3.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.3.3.3.1.1.1" xref="S3.E5.m1.3.3.3.1.1.1.cmml"><msub id="S3.E5.m1.3.3.3.1.1.1.2" xref="S3.E5.m1.3.3.3.1.1.1.2.cmml"><mi id="S3.E5.m1.3.3.3.1.1.1.2.2" xref="S3.E5.m1.3.3.3.1.1.1.2.2.cmml">𝐖</mi><mi id="S3.E5.m1.3.3.3.1.1.1.2.3" xref="S3.E5.m1.3.3.3.1.1.1.2.3.cmml">𝐠𝐥𝐨𝐛𝐚𝐥</mi></msub><mo id="S3.E5.m1.3.3.3.1.1.1.1" xref="S3.E5.m1.3.3.3.1.1.1.1.cmml">−</mo><mrow id="S3.E5.m1.3.3.3.1.1.1.3" xref="S3.E5.m1.3.3.3.1.1.1.3.cmml"><mi id="S3.E5.m1.3.3.3.1.1.1.3.2" xref="S3.E5.m1.3.3.3.1.1.1.3.2.cmml">α</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.3.3.3.1.1.1.3.1" xref="S3.E5.m1.3.3.3.1.1.1.3.1.cmml">⋅</mo><msub id="S3.E5.m1.3.3.3.1.1.1.3.3" xref="S3.E5.m1.3.3.3.1.1.1.3.3.cmml"><mi id="S3.E5.m1.3.3.3.1.1.1.3.3.2" xref="S3.E5.m1.3.3.3.1.1.1.3.3.2.cmml">𝐆</mi><mi id="S3.E5.m1.3.3.3.1.1.1.3.3.3" xref="S3.E5.m1.3.3.3.1.1.1.3.3.3.cmml">𝐥𝐨𝐜𝐚𝐥</mi></msub></mrow></mrow><mo stretchy="false" id="S3.E5.m1.3.3.3.1.1.3" xref="S3.E5.m1.3.3.3.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.3b"><apply id="S3.E5.m1.3.3.cmml" xref="S3.E5.m1.3.3"><eq id="S3.E5.m1.3.3.4.cmml" xref="S3.E5.m1.3.3.4"></eq><apply id="S3.E5.m1.2.2.2.cmml" xref="S3.E5.m1.2.2.2"><plus id="S3.E5.m1.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.3"></plus><apply id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1"><times id="S3.E5.m1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.2"></times><ci id="S3.E5.m1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.3">𝐄</ci><apply id="S3.E5.m1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.2">𝐖</ci><ci id="S3.E5.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.3">𝐠𝐥𝐨𝐛𝐚𝐥</ci></apply></apply><apply id="S3.E5.m1.2.2.2.2.cmml" xref="S3.E5.m1.2.2.2.2"><times id="S3.E5.m1.2.2.2.2.2.cmml" xref="S3.E5.m1.2.2.2.2.2"></times><ci id="S3.E5.m1.2.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.2.3">𝐄</ci><apply id="S3.E5.m1.2.2.2.2.1.1.1.cmml" xref="S3.E5.m1.2.2.2.2.1.1"><minus id="S3.E5.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.E5.m1.2.2.2.2.1.1"></minus><apply id="S3.E5.m1.2.2.2.2.1.1.1.2.cmml" xref="S3.E5.m1.2.2.2.2.1.1.1.2"><ci id="S3.E5.m1.2.2.2.2.1.1.1.2.1.cmml" xref="S3.E5.m1.2.2.2.2.1.1.1.2.1">⋅</ci><ci id="S3.E5.m1.2.2.2.2.1.1.1.2.2.cmml" xref="S3.E5.m1.2.2.2.2.1.1.1.2.2">𝛼</ci><apply id="S3.E5.m1.2.2.2.2.1.1.1.2.3.cmml" xref="S3.E5.m1.2.2.2.2.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.2.2.1.1.1.2.3.1.cmml" xref="S3.E5.m1.2.2.2.2.1.1.1.2.3">subscript</csymbol><ci id="S3.E5.m1.2.2.2.2.1.1.1.2.3.2.cmml" xref="S3.E5.m1.2.2.2.2.1.1.1.2.3.2">𝐆</ci><ci id="S3.E5.m1.2.2.2.2.1.1.1.2.3.3.cmml" xref="S3.E5.m1.2.2.2.2.1.1.1.2.3.3">𝐥𝐨𝐜𝐚𝐥</ci></apply></apply></apply></apply></apply><apply id="S3.E5.m1.3.3.3.cmml" xref="S3.E5.m1.3.3.3"><times id="S3.E5.m1.3.3.3.2.cmml" xref="S3.E5.m1.3.3.3.2"></times><ci id="S3.E5.m1.3.3.3.3.cmml" xref="S3.E5.m1.3.3.3.3">𝐄</ci><apply id="S3.E5.m1.3.3.3.1.1.1.cmml" xref="S3.E5.m1.3.3.3.1.1"><minus id="S3.E5.m1.3.3.3.1.1.1.1.cmml" xref="S3.E5.m1.3.3.3.1.1.1.1"></minus><apply id="S3.E5.m1.3.3.3.1.1.1.2.cmml" xref="S3.E5.m1.3.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.3.1.1.1.2.1.cmml" xref="S3.E5.m1.3.3.3.1.1.1.2">subscript</csymbol><ci id="S3.E5.m1.3.3.3.1.1.1.2.2.cmml" xref="S3.E5.m1.3.3.3.1.1.1.2.2">𝐖</ci><ci id="S3.E5.m1.3.3.3.1.1.1.2.3.cmml" xref="S3.E5.m1.3.3.3.1.1.1.2.3">𝐠𝐥𝐨𝐛𝐚𝐥</ci></apply><apply id="S3.E5.m1.3.3.3.1.1.1.3.cmml" xref="S3.E5.m1.3.3.3.1.1.1.3"><ci id="S3.E5.m1.3.3.3.1.1.1.3.1.cmml" xref="S3.E5.m1.3.3.3.1.1.1.3.1">⋅</ci><ci id="S3.E5.m1.3.3.3.1.1.1.3.2.cmml" xref="S3.E5.m1.3.3.3.1.1.1.3.2">𝛼</ci><apply id="S3.E5.m1.3.3.3.1.1.1.3.3.cmml" xref="S3.E5.m1.3.3.3.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.3.1.1.1.3.3.1.cmml" xref="S3.E5.m1.3.3.3.1.1.1.3.3">subscript</csymbol><ci id="S3.E5.m1.3.3.3.1.1.1.3.3.2.cmml" xref="S3.E5.m1.3.3.3.1.1.1.3.3.2">𝐆</ci><ci id="S3.E5.m1.3.3.3.1.1.1.3.3.3.cmml" xref="S3.E5.m1.3.3.3.1.1.1.3.3.3">𝐥𝐨𝐜𝐚𝐥</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.3c">\bf{E}(W_{global})+\bf{E}(-\alpha\cdot G_{local})=\bf{E}(W_{global}-\alpha\cdot G_{local})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS5.SSS1.p2.4" class="ltx_p">However, the amount of data transferred between clients and the server is inflated by two orders of magnitude over the vanilla setting <cite class="ltx_cite ltx_citemacro_citep">(Phong
et al<span class="ltx_text">.</span>, <a href="#bib.bib150" title="" class="ltx_ref">2018</a>)</cite>. To reduce the communication load, Zhang et al. <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib218" title="" class="ltx_ref">2019a</a>)</cite> chose a distributed selective stochastic gradient descent (DSSGD) method in the local training phase to achieve distributed encryption and reduce the computation costs. Zhang et al. <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib216" title="" class="ltx_ref">2020c</a>)</cite> presented a BatchCrypt as a simple batch encryption technique. Clients first quantize their local gradients and then encode a batch of quantized updates into a long integer. As a result, the communication overhead is reduced by up to 101 times. Jiang et al. <cite class="ltx_cite ltx_citemacro_citep">(Jiang
et al<span class="ltx_text">.</span>, <a href="#bib.bib87" title="" class="ltx_ref">2021</a>)</cite> further reduced communication overhead by sending only a sparse subset of local states to the server.</p>
</div>
<div id="S3.SS5.SSS1.p3" class="ltx_para">
<p id="S3.SS5.SSS1.p3.1" class="ltx_p">Another drawback is that all participants share the same private key for decryption since homomorphic operations require all values to be encrypted with the same public kewhich degrades privacy protection in the face of malicious clients. To counter this problem, Park and Lim <cite class="ltx_cite ltx_citemacro_citep">(Park and Lim, <a href="#bib.bib149" title="" class="ltx_ref">2022</a>)</cite> sketched a privacy-preserving FL scheme based on a distributed homomorphic cryptosystem that allows clients to have their own unique private key for the homomorphic encryption scheme.</p>
</div>
<div id="S3.SS5.SSS1.p4" class="ltx_para">
<p id="S3.SS5.SSS1.p4.8" class="ltx_p">Secret sharing <cite class="ltx_cite ltx_citemacro_citep">(Shamir, <a href="#bib.bib161" title="" class="ltx_ref">1979</a>)</cite> is another kind of cryptographic technique. It splits a secret data <math id="S3.SS5.SSS1.p4.1.m1.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.SS5.SSS1.p4.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.SSS1.p4.1.m1.1.1" xref="S3.SS5.SSS1.p4.1.m1.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p4.1.m1.1b"><ci id="S3.SS5.SSS1.p4.1.m1.1.1.cmml" xref="S3.SS5.SSS1.p4.1.m1.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p4.1.m1.1c">\mathcal{D}</annotation></semantics></math> into <math id="S3.SS5.SSS1.p4.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS5.SSS1.p4.2.m2.1a"><mi id="S3.SS5.SSS1.p4.2.m2.1.1" xref="S3.SS5.SSS1.p4.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p4.2.m2.1b"><ci id="S3.SS5.SSS1.p4.2.m2.1.1.cmml" xref="S3.SS5.SSS1.p4.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p4.2.m2.1c">n</annotation></semantics></math> pieces such that the secret <math id="S3.SS5.SSS1.p4.3.m3.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.SS5.SSS1.p4.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.SSS1.p4.3.m3.1.1" xref="S3.SS5.SSS1.p4.3.m3.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p4.3.m3.1b"><ci id="S3.SS5.SSS1.p4.3.m3.1.1.cmml" xref="S3.SS5.SSS1.p4.3.m3.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p4.3.m3.1c">\mathcal{D}</annotation></semantics></math> can be easily reconstructed with at least <math id="S3.SS5.SSS1.p4.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS5.SSS1.p4.4.m4.1a"><mi id="S3.SS5.SSS1.p4.4.m4.1.1" xref="S3.SS5.SSS1.p4.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p4.4.m4.1b"><ci id="S3.SS5.SSS1.p4.4.m4.1.1.cmml" xref="S3.SS5.SSS1.p4.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p4.4.m4.1c">k</annotation></semantics></math> pieces. However, any set containing less than <math id="S3.SS5.SSS1.p4.5.m5.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS5.SSS1.p4.5.m5.1a"><mi id="S3.SS5.SSS1.p4.5.m5.1.1" xref="S3.SS5.SSS1.p4.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p4.5.m5.1b"><ci id="S3.SS5.SSS1.p4.5.m5.1.1.cmml" xref="S3.SS5.SSS1.p4.5.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p4.5.m5.1c">k</annotation></semantics></math> piece reveals no information about <math id="S3.SS5.SSS1.p4.6.m6.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.SS5.SSS1.p4.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.SSS1.p4.6.m6.1.1" xref="S3.SS5.SSS1.p4.6.m6.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p4.6.m6.1b"><ci id="S3.SS5.SSS1.p4.6.m6.1.1.cmml" xref="S3.SS5.SSS1.p4.6.m6.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p4.6.m6.1c">\mathcal{D}</annotation></semantics></math>. It enables the server to aggregate at least a certain number of clients’ updates without disclosing any individual client’s contribution. Bonawitz et al. <cite class="ltx_cite ltx_citemacro_citep">(Bonawitz et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2017</a>; Mondal et al<span class="ltx_text">.</span>, <a href="#bib.bib138" title="" class="ltx_ref">2022</a>)</cite> proposed a secure aggregation method for FL based on <math id="S3.SS5.SSS1.p4.7.m7.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS5.SSS1.p4.7.m7.1a"><mi id="S3.SS5.SSS1.p4.7.m7.1.1" xref="S3.SS5.SSS1.p4.7.m7.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p4.7.m7.1b"><ci id="S3.SS5.SSS1.p4.7.m7.1.1.cmml" xref="S3.SS5.SSS1.p4.7.m7.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p4.7.m7.1c">t</annotation></semantics></math>-out-of-<math id="S3.SS5.SSS1.p4.8.m8.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS5.SSS1.p4.8.m8.1a"><mi id="S3.SS5.SSS1.p4.8.m8.1.1" xref="S3.SS5.SSS1.p4.8.m8.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p4.8.m8.1b"><ci id="S3.SS5.SSS1.p4.8.m8.1.1.cmml" xref="S3.SS5.SSS1.p4.8.m8.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p4.8.m8.1c">n</annotation></semantics></math> secret sharing. The key idea is to mask the raw data in a symmetric way. Thus, when aggregated by the server, the introduced noise will be nullified. Liu et al. <cite class="ltx_cite ltx_citemacro_citep">(Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib120" title="" class="ltx_ref">2020</a>)</cite> incorporated secure sharing into their federated transfer learning framework to protect privacy. Based on an investigation of how secure aggregation parameters influence communication efficiency, Bonawitz et al. <cite class="ltx_cite ltx_citemacro_citep">(Bonawitz et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2019</a>)</cite> used quantization to build a communication-efficient secure aggregation scheme. So et al. <cite class="ltx_cite ltx_citemacro_citep">(So
et al<span class="ltx_text">.</span>, <a href="#bib.bib170" title="" class="ltx_ref">2021</a>)</cite> designed Turbo-Aggregate that leverages additive secret sharing and Lagrange coding to reduce the secure aggregation overhead. Shao et al. <cite class="ltx_cite ltx_citemacro_citep">(Shao
et al<span class="ltx_text">.</span>, <a href="#bib.bib162" title="" class="ltx_ref">2022</a>)</cite> shared a similar ideal, utilizing Lagrange coding to secretly share private datasets among clients.</p>
</div>
<div id="S3.SS5.SSS1.p5" class="ltx_para">
<p id="S3.SS5.SSS1.p5.1" class="ltx_p">Even though FL based on a homomorphic encryption scheme can prevent privacy leaks during training, it remains vulnerable to attacks in the inference stage. The trained model embodies the distribution of training data to a certain extent and the privacy risk still exists. Model inversion attack gives such an example. Given the white-box access to a trained model, Zhang et al. <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib226" title="" class="ltx_ref">2020a</a>)</cite> successfully discovered the sensitive features <span id="S3.SS5.SSS1.p5.1.1" class="ltx_text ltx_font_italic">x</span> associated with a specific label <span id="S3.SS5.SSS1.p5.1.2" class="ltx_text ltx_font_italic">y</span>.</p>
</div>
</section>
<section id="S3.SS5.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.5.2. </span>Perturbation Methods</h4>

<div id="S3.SS5.SSS2.p1" class="ltx_para">
<p id="S3.SS5.SSS2.p1.1" class="ltx_p">Due to its theoretical guarantee of privacy protection and its low computational and communication complexity, the DP technique <cite class="ltx_cite ltx_citemacro_citep">(Dwork, <a href="#bib.bib43" title="" class="ltx_ref">2008</a>)</cite> has emerged as the most popular choice for privacy protection among a variety of options. In differential privacy, a proper amount of noise is added to the raw data <cite class="ltx_cite ltx_citemacro_citep">(Gupta and Raskar, <a href="#bib.bib68" title="" class="ltx_ref">2018</a>)</cite>, the model <cite class="ltx_cite ltx_citemacro_citep">(Liu and Meng, <a href="#bib.bib119" title="" class="ltx_ref">2020</a>; Geyer
et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2017</a>)</cite>, the output <cite class="ltx_cite ltx_citemacro_citep">(Chaudhuri
et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2011</a>)</cite>, or the gradients <cite class="ltx_cite ltx_citemacro_citep">(Song
et al<span class="ltx_text">.</span>, <a href="#bib.bib173" title="" class="ltx_ref">2013</a>)</cite> to protect privacy.</p>
</div>
<div id="S3.SS5.SSS2.p2" class="ltx_para">
<p id="S3.SS5.SSS2.p2.1" class="ltx_p">Geyer et al. <cite class="ltx_cite ltx_citemacro_citep">(Geyer
et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2017</a>)</cite> applied a differentially private mechanism to the FL scenario, where they approximated the averaging operations with a randomized mechanism that provided client-level privacy. Truex et al. <cite class="ltx_cite ltx_citemacro_citep">(Truex et al<span class="ltx_text">.</span>, <a href="#bib.bib179" title="" class="ltx_ref">2019a</a>)</cite> presented an alternative approach that draws on both DP and secure multi-party computation. The clients and the server communicate through a secure channel. Upon receiving a request from the server, the clients upload their answers following the principles of DP. Xu et al. <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a href="#bib.bib196" title="" class="ltx_ref">2019a</a>)</cite> took a different approach. They approximated the objective function of a regression problem via polynomial representation and then added Laplace noise to the polynomial coefficients to protect privacy. Khalili et al. <cite class="ltx_cite ltx_citemacro_citep">(Khalili
et al<span class="ltx_text">.</span>, <a href="#bib.bib99" title="" class="ltx_ref">2021</a>)</cite> exploited an exponential mechanism <cite class="ltx_cite ltx_citemacro_citep">(McSherry and
Talwar, <a href="#bib.bib131" title="" class="ltx_ref">2007</a>)</cite> to privately select applicants based on the qualification scores predicted by a pre-trained model.</p>
</div>
<div id="S3.SS5.SSS2.p3" class="ltx_para">
<p id="S3.SS5.SSS2.p3.1" class="ltx_p">One concern with perturbation techniques is the trade-off between privacy, accuracy and convergence. A significant noise perfectly protects privacy at the cost of accuracy and convergence. Conversely, a weak noise is futile to privacy attacks <cite class="ltx_cite ltx_citemacro_citep">(Hitaj
et al<span class="ltx_text">.</span>, <a href="#bib.bib76" title="" class="ltx_ref">2017</a>)</cite>. Wei et al. <cite class="ltx_cite ltx_citemacro_citep">(Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib191" title="" class="ltx_ref">2020a</a>)</cite> conducted a theoretical analysis of the convergence behavior of FL with DP and identified the trade-off between convergence performance and privacy protection levels.</p>
</div>
<div id="S3.SS5.SSS2.p4" class="ltx_para">
<p id="S3.SS5.SSS2.p4.1" class="ltx_p">Many studies have been published on ways to deal with this trade-off <cite class="ltx_cite ltx_citemacro_citep">(Fan
et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2020</a>; Zhang and Wang, <a href="#bib.bib224" title="" class="ltx_ref">2021</a>; Shokri and
Shmatikov, <a href="#bib.bib166" title="" class="ltx_ref">2015</a>)</cite>. Shokri and Shmatikov <cite class="ltx_cite ltx_citemacro_citep">(Shokri and
Shmatikov, <a href="#bib.bib166" title="" class="ltx_ref">2015</a>)</cite> suggested randomly selecting and sharing a small fraction of gradient elements (those with large magnitudes) to reduce privacy loss. Fan et al. <cite class="ltx_cite ltx_citemacro_citep">(Fan
et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2020</a>)</cite> leveraged element-wise adaptive gradient perturbations to defeat reconstruction attacks and maintain high model accuracy. In a similar manner, Wei and Liu <cite class="ltx_cite ltx_citemacro_citep">(Wei and Liu, <a href="#bib.bib192" title="" class="ltx_ref">2021</a>)</cite> used dynamic privacy parameters. Introducing noise with a greater variance at the beginning of training and progressively decreasing the amount of noise and variance as training progresses.</p>
</div>
<div id="S3.SS5.SSS2.p5" class="ltx_para">
<p id="S3.SS5.SSS2.p5.1" class="ltx_p">Huang et al. <cite class="ltx_cite ltx_citemacro_citep">(Huang
et al<span class="ltx_text">.</span>, <a href="#bib.bib80" title="" class="ltx_ref">2020b</a>)</cite> proposed <span id="S3.SS5.SSS2.p5.1.1" class="ltx_text ltx_font_italic">InstaHide</span>, a combination of cryptographic and perturbation approaches to provide rigorous privacy protection at the cost of minor effects on accuracy. <span id="S3.SS5.SSS2.p5.1.2" class="ltx_text ltx_font_italic">InstaHide</span> encrypts the raw image by mixing it with multiple random images from a large public dataset. After that, it randomly flips the signs of the pixels before using it to train the model.</p>
</div>
<div id="S3.SS5.SSS2.p6" class="ltx_para">
<p id="S3.SS5.SSS2.p6.1" class="ltx_p">Yang created et al. <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib202" title="" class="ltx_ref">2021</a>)</cite> NISS to avoid the trade-off between accuracy and privacy by permitting clients to collaborate on reducing the total amount of injected noise. In particular, each client’s noise is neutralized and distributed to other clients. Theoretically, if all clients are trustworthy, the locally introduced noise can be perfectly offset by the server’s aggregation, completely avoiding the privacy accuracy trade-off. A similar idea can be found in Yang et al. <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib203" title="" class="ltx_ref">2020a</a>)</cite>.</p>
</div>
</section>
<section id="S3.SS5.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.5.3. </span>Trusted Execution Environment</h4>

<div id="S3.SS5.SSS3.p1" class="ltx_para">
<p id="S3.SS5.SSS3.p1.1" class="ltx_p">Some researchers use Trusted Execution Contexts (TEEs) like Intel SGX and ARM TrustZone to secure ML training in untrusted environments <cite class="ltx_cite ltx_citemacro_citep">(Tramer and Boneh, <a href="#bib.bib176" title="" class="ltx_ref">2018</a>; Mo et al<span class="ltx_text">.</span>, <a href="#bib.bib135" title="" class="ltx_ref">2020</a>; Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2019</a>)</cite>. With hardware and software safeguards, TEEs secure critical code from other programs. Compared with purely cryptography methods, TEEs provide much better performance since it only requires extra operations to create the trusted environment and communicate between trusted and untrusted components. Gu et al. <cite class="ltx_cite ltx_citemacro_citep">(Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2019</a>)</cite> partitioned DNN models and solely encased the first layers in an SGX-powered TEE to protect input information. Hynes et al. <cite class="ltx_cite ltx_citemacro_citep">(Hynes
et al<span class="ltx_text">.</span>, <a href="#bib.bib81" title="" class="ltx_ref">2018</a>)</cite> investigated speeding up the training using Graphics Processing Units (GPU). Tramer et al. <cite class="ltx_cite ltx_citemacro_citep">(Tramer and Boneh, <a href="#bib.bib176" title="" class="ltx_ref">2018</a>)</cite> shared the same concept and offered effective privacy-preserving neural network inference utilizing trusted hardware that delegated matrix multiplication to an untrusted GPU. However, this work does not translate well to FL due to the possible adversary server and limited computation power of the client device. To remedy this, Mo et al. <cite class="ltx_cite ltx_citemacro_citep">(Mo et al<span class="ltx_text">.</span>, <a href="#bib.bib135" title="" class="ltx_ref">2020</a>)</cite> advocated using the TEE of client devices in tandem with model partitioning to defend against MIA. The model is divided into two halves, and the final layers are calculated within TEE. Kato et al. <cite class="ltx_cite ltx_citemacro_citep">(Kato
et al<span class="ltx_text">.</span>, <a href="#bib.bib98" title="" class="ltx_ref">2022</a>)</cite> proposed to combine DP with TEE in FL in the presence of an untrusted server. The models are aggregated within the TEE of the server’s device. <cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2020b</a>)</cite></p>
</div>
</section>
<section id="S3.SS5.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.5.4. </span>Discussion</h4>

<div id="S3.SS5.SSS4.p1" class="ltx_para">
<p id="S3.SS5.SSS4.p1.1" class="ltx_p">Table <a href="#S3.T5" title="Table 5 ‣ 3.5.4. Discussion ‣ 3.5. Privacy-preserving Techniques ‣ 3. Privacy in FL ‣ Privacy and Fairness in Federated Learning: on the Perspective of Trade-off" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> summarized and compared the existing defense techniques. Cryptographic approaches preserve privacy to a great extent while suffering from computational complexity and are less feasible. The perturbation approaches trade-off privacy for model performance. Several inspiring works demonstrate that it may be possible to avoid that trade-off through either client collaborations to neutralize locally added noise on the server side or by using a surrogate dataset to protect the raw data without adding noise. The cryptographic approaches only ensure that no information will leak during training. They do not protect privacy during the inference stage. In contrast, the perturbation approaches (e.g., DP) protect privacy in both the training and inference stages. One may combine cryptographic and perturbation approaches to obtain better privacy protection throughout the machine learning pipeline.</p>
</div>
<figure id="S3.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5. </span>Privacy-preserving methods in FL</figcaption>
<div id="S3.T5.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:230pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-176.2pt,93.2pt) scale(0.551730913107349,0.551730913107349) ;">
<table id="S3.T5.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T5.1.1.1.1" class="ltx_tr">
<td id="S3.T5.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Attack</span></td>
<td id="S3.T5.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.1.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.1.1.2.1.1" class="ltx_tr">
<td id="S3.T5.1.1.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.1.1.2.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Defense</span></td>
</tr>
<tr id="S3.T5.1.1.1.1.2.1.2" class="ltx_tr">
<td id="S3.T5.1.1.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.1.1.2.1.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">method</span></td>
</tr>
</table>
</td>
<td id="S3.T5.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Rationale</span></td>
<td id="S3.T5.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Advantage</span></td>
<td id="S3.T5.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.1.1.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Disadvantage</span></td>
</tr>
<tr id="S3.T5.1.1.2.2" class="ltx_tr">
<td id="S3.T5.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="4"><span id="S3.T5.1.1.2.2.1.1" class="ltx_text" style="font-size:90%;">RA</span></td>
<td id="S3.T5.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.2.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.2.2.2.1.1" class="ltx_tr">
<td id="S3.T5.1.1.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.2.2.2.1.1.1.1" class="ltx_text" style="font-size:90%;">HE</span></td>
</tr>
<tr id="S3.T5.1.1.2.2.2.1.2" class="ltx_tr">
<td id="S3.T5.1.1.2.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T5.1.1.2.2.2.1.2.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Aono et al<span class="ltx_text">.</span><span id="S3.T5.1.1.2.2.2.1.2.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib6" title="" class="ltx_ref">2017</a>; Shin
et al<span class="ltx_text">.</span><span id="S3.T5.1.1.2.2.2.1.2.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib164" title="" class="ltx_ref">2021</a>; Jiang
et al<span class="ltx_text">.</span><span id="S3.T5.1.1.2.2.2.1.2.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib87" title="" class="ltx_ref">2021</a><span id="S3.T5.1.1.2.2.2.1.2.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
</tr>
</table>
</td>
<td id="S3.T5.1.1.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.2.2.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.2.2.3.1.1" class="ltx_tr">
<td id="S3.T5.1.1.2.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.2.2.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Gradients are encrypted</span></td>
</tr>
</table>
</td>
<td id="S3.T5.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.2.2.4.1" class="ltx_text" style="font-size:90%;">Accurate</span></td>
<td id="S3.T5.1.1.2.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.2.2.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.2.2.5.1.1" class="ltx_tr">
<td id="S3.T5.1.1.2.2.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.2.2.5.1.1.1.1" class="ltx_text" style="font-size:90%;">1. Vulnerable if there are</span></td>
</tr>
<tr id="S3.T5.1.1.2.2.5.1.2" class="ltx_tr">
<td id="S3.T5.1.1.2.2.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.2.2.5.1.2.1.1" class="ltx_text" style="font-size:90%;">multiple colluding entities;</span></td>
</tr>
<tr id="S3.T5.1.1.2.2.5.1.3" class="ltx_tr">
<td id="S3.T5.1.1.2.2.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.2.2.5.1.3.1.1" class="ltx_text" style="font-size:90%;">2. Ineffective at inference</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T5.1.1.3.3" class="ltx_tr">
<td id="S3.T5.1.1.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.3.3.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.3.3.1.1.1" class="ltx_tr">
<td id="S3.T5.1.1.3.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.3.3.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Secret sharing</span></td>
</tr>
<tr id="S3.T5.1.1.3.3.1.1.2" class="ltx_tr">
<td id="S3.T5.1.1.3.3.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T5.1.1.3.3.1.1.2.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Bonawitz et al<span class="ltx_text">.</span><span id="S3.T5.1.1.3.3.1.1.2.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib16" title="" class="ltx_ref">2017</a>; Mondal et al<span class="ltx_text">.</span><span id="S3.T5.1.1.3.3.1.1.2.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib138" title="" class="ltx_ref">2022</a>; Shao
et al<span class="ltx_text">.</span><span id="S3.T5.1.1.3.3.1.1.2.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib162" title="" class="ltx_ref">2022</a><span id="S3.T5.1.1.3.3.1.1.2.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
</tr>
</table>
</td>
<td id="S3.T5.1.1.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.3.3.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.3.3.2.1.1" class="ltx_tr">
<td id="S3.T5.1.1.3.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.3.3.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Hiding information about</span></td>
</tr>
<tr id="S3.T5.1.1.3.3.2.1.2" class="ltx_tr">
<td id="S3.T5.1.1.3.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.3.3.2.1.2.1.1" class="ltx_text" style="font-size:90%;">clients’ individual update,</span></td>
</tr>
<tr id="S3.T5.1.1.3.3.2.1.3" class="ltx_tr">
<td id="S3.T5.1.1.3.3.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.3.3.2.1.3.1.1" class="ltx_text" style="font-size:90%;">except for their sum</span></td>
</tr>
</table>
</td>
<td id="S3.T5.1.1.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.3.3.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.3.3.3.1.1" class="ltx_tr">
<td id="S3.T5.1.1.3.3.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.3.3.3.1.1.1.1" class="ltx_text" style="font-size:90%;">1. Accurate; 2. Robust to</span></td>
</tr>
<tr id="S3.T5.1.1.3.3.3.1.2" class="ltx_tr">
<td id="S3.T5.1.1.3.3.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.3.3.3.1.2.1.1" class="ltx_text" style="font-size:90%;">users dropping out</span></td>
</tr>
</table>
</td>
<td id="S3.T5.1.1.3.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.3.3.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.3.3.4.1.1" class="ltx_tr">
<td id="S3.T5.1.1.3.3.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.3.3.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Ineffective at inference</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T5.1.1.4.4" class="ltx_tr">
<td id="S3.T5.1.1.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.4.4.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.4.4.1.1.1" class="ltx_tr">
<td id="S3.T5.1.1.4.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.4.4.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Variational</span></td>
</tr>
<tr id="S3.T5.1.1.4.4.1.1.2" class="ltx_tr">
<td id="S3.T5.1.1.4.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.4.4.1.1.2.1.1" class="ltx_text" style="font-size:90%;">bottleneck</span></td>
</tr>
<tr id="S3.T5.1.1.4.4.1.1.3" class="ltx_tr">
<td id="S3.T5.1.1.4.4.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T5.1.1.4.4.1.1.3.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Scheliga
et al<span class="ltx_text">.</span><span id="S3.T5.1.1.4.4.1.1.3.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib160" title="" class="ltx_ref">2022</a><span id="S3.T5.1.1.4.4.1.1.3.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
</tr>
</table>
</td>
<td id="S3.T5.1.1.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.4.4.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.4.4.2.1.1" class="ltx_tr">
<td id="S3.T5.1.1.4.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.4.4.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Using surrogate gradient</span></td>
</tr>
<tr id="S3.T5.1.1.4.4.2.1.2" class="ltx_tr">
<td id="S3.T5.1.1.4.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.4.4.2.1.2.1.1" class="ltx_text" style="font-size:90%;">to protect privacy.</span></td>
</tr>
</table>
</td>
<td id="S3.T5.1.1.4.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.4.4.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.4.4.3.1.1" class="ltx_tr">
<td id="S3.T5.1.1.4.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.4.4.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Keep training process</span></td>
</tr>
<tr id="S3.T5.1.1.4.4.3.1.2" class="ltx_tr">
<td id="S3.T5.1.1.4.4.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.4.4.3.1.2.1.1" class="ltx_text" style="font-size:90%;">and performance intact</span></td>
</tr>
</table>
</td>
<td id="S3.T5.1.1.4.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.4.4.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.4.4.4.1.1" class="ltx_tr">
<td id="S3.T5.1.1.4.4.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.4.4.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Limit to optimization-based</span></td>
</tr>
<tr id="S3.T5.1.1.4.4.4.1.2" class="ltx_tr">
<td id="S3.T5.1.1.4.4.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.4.4.4.1.2.1.1" class="ltx_text" style="font-size:90%;">attack</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T5.1.1.5.5" class="ltx_tr">
<td id="S3.T5.1.1.5.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.5.5.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.5.5.1.1.1" class="ltx_tr">
<td id="S3.T5.1.1.5.5.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.5.5.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Gradient</span></td>
</tr>
<tr id="S3.T5.1.1.5.5.1.1.2" class="ltx_tr">
<td id="S3.T5.1.1.5.5.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.5.5.1.1.2.1.1" class="ltx_text" style="font-size:90%;">compression</span></td>
</tr>
<tr id="S3.T5.1.1.5.5.1.1.3" class="ltx_tr">
<td id="S3.T5.1.1.5.5.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T5.1.1.5.5.1.1.3.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Sun
et al<span class="ltx_text">.</span><span id="S3.T5.1.1.5.5.1.1.3.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib174" title="" class="ltx_ref">2020</a>; Zhu et al<span class="ltx_text">.</span><span id="S3.T5.1.1.5.5.1.1.3.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib232" title="" class="ltx_ref">2019</a>; Li
et al<span class="ltx_text">.</span><span id="S3.T5.1.1.5.5.1.1.3.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib116" title="" class="ltx_ref">2022</a><span id="S3.T5.1.1.5.5.1.1.3.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
</tr>
</table>
</td>
<td id="S3.T5.1.1.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.5.5.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.5.5.2.1.1" class="ltx_tr">
<td id="S3.T5.1.1.5.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.5.5.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Compressing gradients to</span></td>
</tr>
<tr id="S3.T5.1.1.5.5.2.1.2" class="ltx_tr">
<td id="S3.T5.1.1.5.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.5.5.2.1.2.1.1" class="ltx_text" style="font-size:90%;">prevent reconstruct private</span></td>
</tr>
<tr id="S3.T5.1.1.5.5.2.1.3" class="ltx_tr">
<td id="S3.T5.1.1.5.5.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.5.5.2.1.3.1.1" class="ltx_text" style="font-size:90%;">data by matching gradients</span></td>
</tr>
</table>
</td>
<td id="S3.T5.1.1.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.5.5.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.5.5.3.1.1" class="ltx_tr">
<td id="S3.T5.1.1.5.5.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.5.5.3.1.1.1.1" class="ltx_text" style="font-size:90%;">1. Easy to implement;</span></td>
</tr>
<tr id="S3.T5.1.1.5.5.3.1.2" class="ltx_tr">
<td id="S3.T5.1.1.5.5.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.5.5.3.1.2.1.1" class="ltx_text" style="font-size:90%;">2. Reduce communication</span></td>
</tr>
</table>
</td>
<td id="S3.T5.1.1.5.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="2"><span id="S3.T5.1.1.5.5.4.1" class="ltx_text" style="font-size:90%;">
<span id="S3.T5.1.1.5.5.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T5.1.1.5.5.4.1.1.1" class="ltx_tr">
<span id="S3.T5.1.1.5.5.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">Requires considerable noise,</span></span>
<span id="S3.T5.1.1.5.5.4.1.1.2" class="ltx_tr">
<span id="S3.T5.1.1.5.5.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">degrades model performance,</span></span>
<span id="S3.T5.1.1.5.5.4.1.1.3" class="ltx_tr">
<span id="S3.T5.1.1.5.5.4.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">and increases convergence</span></span>
<span id="S3.T5.1.1.5.5.4.1.1.4" class="ltx_tr">
<span id="S3.T5.1.1.5.5.4.1.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">time</span></span>
</span></span></td>
</tr>
<tr id="S3.T5.1.1.6.6" class="ltx_tr">
<td id="S3.T5.1.1.6.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="2"><span id="S3.T5.1.1.6.6.1.1" class="ltx_text" style="font-size:90%;">
<span id="S3.T5.1.1.6.6.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T5.1.1.6.6.1.1.1.1" class="ltx_tr">
<span id="S3.T5.1.1.6.6.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">RA,</span></span>
<span id="S3.T5.1.1.6.6.1.1.1.2" class="ltx_tr">
<span id="S3.T5.1.1.6.6.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">MIA,</span></span>
<span id="S3.T5.1.1.6.6.1.1.1.3" class="ltx_tr">
<span id="S3.T5.1.1.6.6.1.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">and PIA</span></span>
</span></span></td>
<td id="S3.T5.1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.6.6.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.6.6.2.1.1" class="ltx_tr">
<td id="S3.T5.1.1.6.6.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.6.6.2.1.1.1.1" class="ltx_text" style="font-size:90%;">DP</span></td>
</tr>
<tr id="S3.T5.1.1.6.6.2.1.2" class="ltx_tr">
<td id="S3.T5.1.1.6.6.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T5.1.1.6.6.2.1.2.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Wei et al<span class="ltx_text">.</span><span id="S3.T5.1.1.6.6.2.1.2.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib193" title="" class="ltx_ref">2020b</a>; Chen
et al<span class="ltx_text">.</span><span id="S3.T5.1.1.6.6.2.1.2.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib27" title="" class="ltx_ref">2020c</a>; Ma
et al<span class="ltx_text">.</span><span id="S3.T5.1.1.6.6.2.1.2.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib126" title="" class="ltx_ref">2021</a><span id="S3.T5.1.1.6.6.2.1.2.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
</tr>
</table>
</td>
<td id="S3.T5.1.1.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.6.6.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.6.6.3.1.1" class="ltx_tr">
<td id="S3.T5.1.1.6.6.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.6.6.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Hiding private information</span></td>
</tr>
<tr id="S3.T5.1.1.6.6.3.1.2" class="ltx_tr">
<td id="S3.T5.1.1.6.6.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.6.6.3.1.2.1.1" class="ltx_text" style="font-size:90%;">by injecting noise to the</span></td>
</tr>
<tr id="S3.T5.1.1.6.6.3.1.3" class="ltx_tr">
<td id="S3.T5.1.1.6.6.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.6.6.3.1.3.1.1" class="ltx_text" style="font-size:90%;">raw data, model, or output</span></td>
</tr>
</table>
</td>
<td id="S3.T5.1.1.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.6.6.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.6.6.4.1.1" class="ltx_tr">
<td id="S3.T5.1.1.6.6.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.6.6.4.1.1.1.1" class="ltx_text" style="font-size:90%;">1. Easy to implement;</span></td>
</tr>
<tr id="S3.T5.1.1.6.6.4.1.2" class="ltx_tr">
<td id="S3.T5.1.1.6.6.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.6.6.4.1.2.1.1" class="ltx_text" style="font-size:90%;">2. Long-term protection</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T5.1.1.7.7" class="ltx_tr">
<td id="S3.T5.1.1.7.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.7.7.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.7.7.1.1.1" class="ltx_tr">
<td id="S3.T5.1.1.7.7.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.7.7.1.1.1.1.1" class="ltx_text" style="font-size:90%;">TEEs</span></td>
</tr>
<tr id="S3.T5.1.1.7.7.1.1.2" class="ltx_tr">
<td id="S3.T5.1.1.7.7.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T5.1.1.7.7.1.1.2.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Mo et al<span class="ltx_text">.</span><span id="S3.T5.1.1.7.7.1.1.2.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib135" title="" class="ltx_ref">2020</a>; Kato
et al<span class="ltx_text">.</span><span id="S3.T5.1.1.7.7.1.1.2.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib98" title="" class="ltx_ref">2022</a><span id="S3.T5.1.1.7.7.1.1.2.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
</tr>
</table>
</td>
<td id="S3.T5.1.1.7.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T5.1.1.7.7.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T5.1.1.7.7.2.1.1" class="ltx_tr">
<td id="S3.T5.1.1.7.7.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.7.7.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Isolating part of networks</span></td>
</tr>
<tr id="S3.T5.1.1.7.7.2.1.2" class="ltx_tr">
<td id="S3.T5.1.1.7.7.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.7.7.2.1.2.1.1" class="ltx_text" style="font-size:90%;">from the untrusted</span></td>
</tr>
<tr id="S3.T5.1.1.7.7.2.1.3" class="ltx_tr">
<td id="S3.T5.1.1.7.7.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.7.7.2.1.3.1.1" class="ltx_text" style="font-size:90%;">environments</span></td>
</tr>
</table>
</td>
<td id="S3.T5.1.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.7.7.3.1" class="ltx_text" style="font-size:90%;">Reduce computation</span></td>
<td id="S3.T5.1.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T5.1.1.7.7.4.1" class="ltx_text" style="font-size:90%;">Limited memory space</span></td>
</tr>
<tr id="S3.T5.1.1.8.8" class="ltx_tr">
<td id="S3.T5.1.1.8.8.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="5"><span id="S3.T5.1.1.8.8.1.1" class="ltx_text" style="font-size:90%;">RA: Reconstruction attack; MIA: Membership inference attack; PIA: Property inference attack.</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S3.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6. </span>Comparison of privacy attacks in FL</figcaption>
<table id="S3.T6.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T6.1.1.1" class="ltx_tr">
<td id="S3.T6.1.1.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Attack</span></td>
<td id="S3.T6.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Ref.</span></td>
<td id="S3.T6.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Access</span></td>
<td id="S3.T6.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.1.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.1.1.4.1.1" class="ltx_tr">
<td id="S3.T6.1.1.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.1.1.4.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Attack</span></td>
</tr>
<tr id="S3.T6.1.1.1.4.1.2" class="ltx_tr">
<td id="S3.T6.1.1.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.1.1.4.1.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">interface</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.1.1.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Assumptions</span></td>
<td id="S3.T6.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.1.1.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Key technique</span></td>
</tr>
<tr id="S3.T6.1.2.2" class="ltx_tr">
<td id="S3.T6.1.2.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="2"><span id="S3.T6.1.2.2.1.1" class="ltx_text" style="font-size:90%;">
<span id="S3.T6.1.2.2.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:36.0pt;height:70pt;vertical-align:-17.0pt;"><span class="ltx_transformed_inner" style="width:70.0pt;transform:translate(-17.01pt,0pt) rotate(-90deg) ;">
<span id="S3.T6.1.2.2.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T6.1.2.2.1.1.1.1.1" class="ltx_tr">
<span id="S3.T6.1.2.2.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Membership</span></span>
<span id="S3.T6.1.2.2.1.1.1.1.2" class="ltx_tr">
<span id="S3.T6.1.2.2.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Inference Attack</span></span>
</span>
</span></span></span></td>
<td id="S3.T6.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T6.1.2.2.2.1.1" class="ltx_text" style="font-size:90%;">(</span>Shokri
et al<span class="ltx_text">.</span><span id="S3.T6.1.2.2.2.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib167" title="" class="ltx_ref">2017</a><span id="S3.T6.1.2.2.2.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S3.T6.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.2.2.3.1" class="ltx_text" style="font-size:90%;">BB</span></td>
<td id="S3.T6.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.2.2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.2.2.4.1.1" class="ltx_tr">
<td id="S3.T6.1.2.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.2.2.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Confidence</span></td>
</tr>
<tr id="S3.T6.1.2.2.4.1.2" class="ltx_tr">
<td id="S3.T6.1.2.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.2.2.4.1.2.1.1" class="ltx_text" style="font-size:90%;">vector</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.2.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.2.2.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.2.2.5.1.1" class="ltx_tr">
<td id="S3.T6.1.2.2.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.2.2.5.1.1.1.1" class="ltx_text" style="font-size:90%;">Knowledge about population</span></td>
</tr>
<tr id="S3.T6.1.2.2.5.1.2" class="ltx_tr">
<td id="S3.T6.1.2.2.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.2.2.5.1.2.1.1" class="ltx_text" style="font-size:90%;">data</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.2.2.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.2.2.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.2.2.6.1.1" class="ltx_tr">
<td id="S3.T6.1.2.2.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.2.2.6.1.1.1.1" class="ltx_text" style="font-size:90%;">Inferring from the discrepancies of</span></td>
</tr>
<tr id="S3.T6.1.2.2.6.1.2" class="ltx_tr">
<td id="S3.T6.1.2.2.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.2.2.6.1.2.1.1" class="ltx_text" style="font-size:90%;">predictions on training set versus</span></td>
</tr>
<tr id="S3.T6.1.2.2.6.1.3" class="ltx_tr">
<td id="S3.T6.1.2.2.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.2.2.6.1.3.1.1" class="ltx_text" style="font-size:90%;">unseen data</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T6.1.3.3" class="ltx_tr">
<td id="S3.T6.1.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T6.1.3.3.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Nasr
et al<span class="ltx_text">.</span><span id="S3.T6.1.3.3.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib141" title="" class="ltx_ref">2019</a><span id="S3.T6.1.3.3.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S3.T6.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.3.3.2.1" class="ltx_text" style="font-size:90%;">WB</span></td>
<td id="S3.T6.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.3.3.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.3.3.3.1.1" class="ltx_tr">
<td id="S3.T6.1.3.3.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.3.3.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></td>
</tr>
<tr id="S3.T6.1.3.3.3.1.2" class="ltx_tr">
<td id="S3.T6.1.3.3.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.3.3.3.1.2.1.1" class="ltx_text" style="font-size:90%;">parameters</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.3.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.3.3.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.3.3.4.1.1" class="ltx_tr">
<td id="S3.T6.1.3.3.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.3.3.4.1.1.1.1" class="ltx_text" style="font-size:90%;">A significant portion of the</span></td>
</tr>
<tr id="S3.T6.1.3.3.4.1.2" class="ltx_tr">
<td id="S3.T6.1.3.3.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.3.3.4.1.2.1.1" class="ltx_text" style="font-size:90%;">training data</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.3.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.3.3.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.3.3.5.1.1" class="ltx_tr">
<td id="S3.T6.1.3.3.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.3.3.5.1.1.1.1" class="ltx_text" style="font-size:90%;">Reversing the SGD algorithm</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T6.1.4.4" class="ltx_tr">
<td id="S3.T6.1.4.4.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="S3.T6.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T6.1.4.4.2.1.1" class="ltx_text" style="font-size:90%;">(</span>Leino and
Fredrikson<span id="S3.T6.1.4.4.2.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib110" title="" class="ltx_ref">2020</a><span id="S3.T6.1.4.4.2.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S3.T6.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.4.4.3.1" class="ltx_text" style="font-size:90%;">WB</span></td>
<td id="S3.T6.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.4.4.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.4.4.4.1.1" class="ltx_tr">
<td id="S3.T6.1.4.4.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.4.4.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></td>
</tr>
<tr id="S3.T6.1.4.4.4.1.2" class="ltx_tr">
<td id="S3.T6.1.4.4.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.4.4.4.1.2.1.1" class="ltx_text" style="font-size:90%;">parameters</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.4.4.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.4.4.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.4.4.5.1.1" class="ltx_tr">
<td id="S3.T6.1.4.4.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.4.4.5.1.1.1.1" class="ltx_text" style="font-size:90%;">A proxy dataset sampled from</span></td>
</tr>
<tr id="S3.T6.1.4.4.5.1.2" class="ltx_tr">
<td id="S3.T6.1.4.4.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.4.4.5.1.2.1.1" class="ltx_text" style="font-size:90%;">the ground-truth distribution</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.4.4.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.4.4.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.4.4.6.1.1" class="ltx_tr">
<td id="S3.T6.1.4.4.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.4.4.6.1.1.1.1" class="ltx_text" style="font-size:90%;">Inferring from parameter differences</span></td>
</tr>
<tr id="S3.T6.1.4.4.6.1.2" class="ltx_tr">
<td id="S3.T6.1.4.4.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.4.4.6.1.2.1.1" class="ltx_text" style="font-size:90%;">between the target and proxy model</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T6.1.5.5" class="ltx_tr">
<td id="S3.T6.1.5.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.5.5.1.1" class="ltx_text" style="font-size:90%;">
<span id="S3.T6.1.5.5.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:36.0pt;height:70pt;vertical-align:-17.0pt;"><span class="ltx_transformed_inner" style="width:70.0pt;transform:translate(-17.01pt,0pt) rotate(-90deg) ;">
<span id="S3.T6.1.5.5.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T6.1.5.5.1.1.1.1.1" class="ltx_tr">
<span id="S3.T6.1.5.5.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Property</span></span>
<span id="S3.T6.1.5.5.1.1.1.1.2" class="ltx_tr">
<span id="S3.T6.1.5.5.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Inference Attack</span></span>
</span>
</span></span></span></td>
<td id="S3.T6.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T6.1.5.5.2.1.1" class="ltx_text" style="font-size:90%;">(</span>Ateniese et al<span class="ltx_text">.</span><span id="S3.T6.1.5.5.2.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib8" title="" class="ltx_ref">2013</a><span id="S3.T6.1.5.5.2.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S3.T6.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.5.5.3.1" class="ltx_text" style="font-size:90%;">WB</span></td>
<td id="S3.T6.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.5.5.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.5.5.4.1.1" class="ltx_tr">
<td id="S3.T6.1.5.5.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.5.5.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></td>
</tr>
<tr id="S3.T6.1.5.5.4.1.2" class="ltx_tr">
<td id="S3.T6.1.5.5.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.5.5.4.1.2.1.1" class="ltx_text" style="font-size:90%;">parameters</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.5.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.5.5.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.5.5.5.1.1" class="ltx_tr">
<td id="S3.T6.1.5.5.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.5.5.5.1.1.1.1" class="ltx_text" style="font-size:90%;">1.Knowledge about training</span></td>
</tr>
<tr id="S3.T6.1.5.5.5.1.2" class="ltx_tr">
<td id="S3.T6.1.5.5.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.5.5.5.1.2.1.1" class="ltx_text" style="font-size:90%;">data structure; 2. Access to the</span></td>
</tr>
<tr id="S3.T6.1.5.5.5.1.3" class="ltx_tr">
<td id="S3.T6.1.5.5.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.5.5.5.1.3.1.1" class="ltx_text" style="font-size:90%;">ground-truth distribution</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.5.5.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.5.5.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.5.5.6.1.1" class="ltx_tr">
<td id="S3.T6.1.5.5.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.5.5.6.1.1.1.1" class="ltx_text" style="font-size:90%;">A meta-classifier to infer properties</span></td>
</tr>
<tr id="S3.T6.1.5.5.6.1.2" class="ltx_tr">
<td id="S3.T6.1.5.5.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.5.5.6.1.2.1.1" class="ltx_text" style="font-size:90%;">from multiple shadow classifier</span></td>
</tr>
<tr id="S3.T6.1.5.5.6.1.3" class="ltx_tr">
<td id="S3.T6.1.5.5.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.5.5.6.1.3.1.1" class="ltx_text" style="font-size:90%;">parameters</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T6.1.6.6" class="ltx_tr">
<td id="S3.T6.1.6.6.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="S3.T6.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T6.1.6.6.2.1.1" class="ltx_text" style="font-size:90%;">(</span>Wang
et al<span class="ltx_text">.</span><span id="S3.T6.1.6.6.2.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib189" title="" class="ltx_ref">2022</a><span id="S3.T6.1.6.6.2.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S3.T6.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.6.6.3.1" class="ltx_text" style="font-size:90%;">WB</span></td>
<td id="S3.T6.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.6.6.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.6.6.4.1.1" class="ltx_tr">
<td id="S3.T6.1.6.6.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.6.6.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></td>
</tr>
<tr id="S3.T6.1.6.6.4.1.2" class="ltx_tr">
<td id="S3.T6.1.6.6.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.6.6.4.1.2.1.1" class="ltx_text" style="font-size:90%;">updates</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.6.6.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.6.6.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.6.6.5.1.1" class="ltx_tr">
<td id="S3.T6.1.6.6.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.6.6.5.1.1.1.1" class="ltx_text" style="font-size:90%;">Adversary can manipulate</span></td>
</tr>
<tr id="S3.T6.1.6.6.5.1.2" class="ltx_tr">
<td id="S3.T6.1.6.6.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.6.6.5.1.2.1.1" class="ltx_text" style="font-size:90%;">more than one device in FL</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.6.6.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.6.6.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.6.6.6.1.1" class="ltx_tr">
<td id="S3.T6.1.6.6.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.6.6.6.1.1.1.1" class="ltx_text" style="font-size:90%;">Inferring other clients’ data from the</span></td>
</tr>
<tr id="S3.T6.1.6.6.6.1.2" class="ltx_tr">
<td id="S3.T6.1.6.6.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.6.6.6.1.2.1.1" class="ltx_text" style="font-size:90%;">periodic model updates</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T6.1.7.7" class="ltx_tr">
<td id="S3.T6.1.7.7.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="S3.T6.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T6.1.7.7.2.1.1" class="ltx_text" style="font-size:90%;">(</span>Wang
et al<span class="ltx_text">.</span><span id="S3.T6.1.7.7.2.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib186" title="" class="ltx_ref">2019b</a><span id="S3.T6.1.7.7.2.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S3.T6.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.7.7.3.1" class="ltx_text" style="font-size:90%;">WB</span></td>
<td id="S3.T6.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.7.7.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.7.7.4.1.1" class="ltx_tr">
<td id="S3.T6.1.7.7.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.7.7.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></td>
</tr>
<tr id="S3.T6.1.7.7.4.1.2" class="ltx_tr">
<td id="S3.T6.1.7.7.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.7.7.4.1.2.1.1" class="ltx_text" style="font-size:90%;">updates</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.7.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.7.7.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.7.7.5.1.1" class="ltx_tr">
<td id="S3.T6.1.7.7.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.7.7.5.1.1.1.1" class="ltx_text" style="font-size:90%;">1. Client’s average label count;</span></td>
</tr>
<tr id="S3.T6.1.7.7.5.1.2" class="ltx_tr">
<td id="S3.T6.1.7.7.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.7.7.5.1.2.1.1" class="ltx_text" style="font-size:90%;">2. Number of samples per label</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.7.7.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.7.7.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.7.7.6.1.1" class="ltx_tr">
<td id="S3.T6.1.7.7.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.7.7.6.1.1.1.1" class="ltx_text" style="font-size:90%;">Inferring from the layer neuron</span></td>
</tr>
<tr id="S3.T6.1.7.7.6.1.2" class="ltx_tr">
<td id="S3.T6.1.7.7.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.7.7.6.1.2.1.1" class="ltx_text" style="font-size:90%;">weight changes</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T6.1.8.8" class="ltx_tr">
<td id="S3.T6.1.8.8.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="3"><span id="S3.T6.1.8.8.1.1" class="ltx_text" style="font-size:90%;">
<span id="S3.T6.1.8.8.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.3pt;height:92.6pt;vertical-align:-43.2pt;"><span class="ltx_transformed_inner" style="width:92.6pt;transform:translate(-43.16pt,0pt) rotate(-90deg) ;">
<span id="S3.T6.1.8.8.1.1.1.1" class="ltx_p">Model Inversion Attack</span>
</span></span></span></td>
<td id="S3.T6.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T6.1.8.8.2.1.1" class="ltx_text" style="font-size:90%;">(</span>Fredrikson
et al<span class="ltx_text">.</span><span id="S3.T6.1.8.8.2.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib55" title="" class="ltx_ref">2015</a><span id="S3.T6.1.8.8.2.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S3.T6.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.8.8.3.1" class="ltx_text" style="font-size:90%;">BB/WB</span></td>
<td id="S3.T6.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.8.8.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.8.8.4.1.1" class="ltx_tr">
<td id="S3.T6.1.8.8.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.8.8.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Confidence</span></td>
</tr>
<tr id="S3.T6.1.8.8.4.1.2" class="ltx_tr">
<td id="S3.T6.1.8.8.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.8.8.4.1.2.1.1" class="ltx_text" style="font-size:90%;">vectors /</span></td>
</tr>
<tr id="S3.T6.1.8.8.4.1.3" class="ltx_tr">
<td id="S3.T6.1.8.8.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.8.8.4.1.3.1.1" class="ltx_text" style="font-size:90%;">Model</span></td>
</tr>
<tr id="S3.T6.1.8.8.4.1.4" class="ltx_tr">
<td id="S3.T6.1.8.8.4.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.8.8.4.1.4.1.1" class="ltx_text" style="font-size:90%;">parameters</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.8.8.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.8.8.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.8.8.5.1.1" class="ltx_tr">
<td id="S3.T6.1.8.8.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.8.8.5.1.1.1.1" class="ltx_text" style="font-size:90%;">1. Side information; 2. Simple</span></td>
</tr>
<tr id="S3.T6.1.8.8.5.1.2" class="ltx_tr">
<td id="S3.T6.1.8.8.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.8.8.5.1.2.1.1" class="ltx_text" style="font-size:90%;">networks</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.8.8.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.8.8.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.8.8.6.1.1" class="ltx_tr">
<td id="S3.T6.1.8.8.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.8.8.6.1.1.1.1" class="ltx_text" style="font-size:90%;">Optimizing the input to maximize</span></td>
</tr>
<tr id="S3.T6.1.8.8.6.1.2" class="ltx_tr">
<td id="S3.T6.1.8.8.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.8.8.6.1.2.1.1" class="ltx_text" style="font-size:90%;">confidence vectors subject to the</span></td>
</tr>
<tr id="S3.T6.1.8.8.6.1.3" class="ltx_tr">
<td id="S3.T6.1.8.8.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.8.8.6.1.3.1.1" class="ltx_text" style="font-size:90%;">classification matches the target</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T6.1.9.9" class="ltx_tr">
<td id="S3.T6.1.9.9.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T6.1.9.9.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Yang
et al<span class="ltx_text">.</span><span id="S3.T6.1.9.9.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib204" title="" class="ltx_ref">2019a</a><span id="S3.T6.1.9.9.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S3.T6.1.9.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.9.9.2.1" class="ltx_text" style="font-size:90%;">BB</span></td>
<td id="S3.T6.1.9.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.9.9.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.9.9.3.1.1" class="ltx_tr">
<td id="S3.T6.1.9.9.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.9.9.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Confidence</span></td>
</tr>
<tr id="S3.T6.1.9.9.3.1.2" class="ltx_tr">
<td id="S3.T6.1.9.9.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.9.9.3.1.2.1.1" class="ltx_text" style="font-size:90%;">vectors</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.9.9.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.9.9.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.9.9.4.1.1" class="ltx_tr">
<td id="S3.T6.1.9.9.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.9.9.4.1.1.1.1" class="ltx_text" style="font-size:90%;">1. Auxiliary dataset retains</span></td>
</tr>
<tr id="S3.T6.1.9.9.4.1.2" class="ltx_tr">
<td id="S3.T6.1.9.9.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.9.9.4.1.2.1.1" class="ltx_text" style="font-size:90%;">meaningful prior information;</span></td>
</tr>
<tr id="S3.T6.1.9.9.4.1.3" class="ltx_tr">
<td id="S3.T6.1.9.9.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.9.9.4.1.3.1.1" class="ltx_text" style="font-size:90%;">2. Simple networks</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.9.9.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.9.9.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.9.9.5.1.1" class="ltx_tr">
<td id="S3.T6.1.9.9.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.9.9.5.1.1.1.1" class="ltx_text" style="font-size:90%;">An inverse model approximates the</span></td>
</tr>
<tr id="S3.T6.1.9.9.5.1.2" class="ltx_tr">
<td id="S3.T6.1.9.9.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.9.9.5.1.2.1.1" class="ltx_text" style="font-size:90%;">mapping between predictions</span></td>
</tr>
<tr id="S3.T6.1.9.9.5.1.3" class="ltx_tr">
<td id="S3.T6.1.9.9.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.9.9.5.1.3.1.1" class="ltx_text" style="font-size:90%;">and images</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T6.1.10.10" class="ltx_tr">
<td id="S3.T6.1.10.10.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T6.1.10.10.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Zhang
et al<span class="ltx_text">.</span><span id="S3.T6.1.10.10.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib226" title="" class="ltx_ref">2020a</a><span id="S3.T6.1.10.10.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S3.T6.1.10.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.10.10.2.1" class="ltx_text" style="font-size:90%;">WB</span></td>
<td id="S3.T6.1.10.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.10.10.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.10.10.3.1.1" class="ltx_tr">
<td id="S3.T6.1.10.10.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.10.10.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Feature</span></td>
</tr>
<tr id="S3.T6.1.10.10.3.1.2" class="ltx_tr">
<td id="S3.T6.1.10.10.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.10.10.3.1.2.1.1" class="ltx_text" style="font-size:90%;">extractor</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.10.10.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.10.10.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.10.10.4.1.1" class="ltx_tr">
<td id="S3.T6.1.10.10.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.10.10.4.1.1.1.1" class="ltx_text" style="font-size:90%;">An auxiliary dataset retains</span></td>
</tr>
<tr id="S3.T6.1.10.10.4.1.2" class="ltx_tr">
<td id="S3.T6.1.10.10.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.10.10.4.1.2.1.1" class="ltx_text" style="font-size:90%;">meaningful prior information</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.10.10.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.10.10.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.10.10.5.1.1" class="ltx_tr">
<td id="S3.T6.1.10.10.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.10.10.5.1.1.1.1" class="ltx_text" style="font-size:90%;">1. Distilling prior knowledge from</span></td>
</tr>
<tr id="S3.T6.1.10.10.5.1.2" class="ltx_tr">
<td id="S3.T6.1.10.10.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.10.10.5.1.2.1.1" class="ltx_text" style="font-size:90%;">an auxiliary dataset via GAN;</span></td>
</tr>
<tr id="S3.T6.1.10.10.5.1.3" class="ltx_tr">
<td id="S3.T6.1.10.10.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.10.10.5.1.3.1.1" class="ltx_text" style="font-size:90%;">2. Optimizing the generate image to</span></td>
</tr>
<tr id="S3.T6.1.10.10.5.1.4" class="ltx_tr">
<td id="S3.T6.1.10.10.5.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.10.10.5.1.4.1.1" class="ltx_text" style="font-size:90%;">maximize likelihood</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T6.1.11.11" class="ltx_tr">
<td id="S3.T6.1.11.11.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="5"><span id="S3.T6.1.11.11.1.1" class="ltx_text" style="font-size:90%;">
<span id="S3.T6.1.11.11.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.3pt;height:88.7pt;vertical-align:-41.2pt;"><span class="ltx_transformed_inner" style="width:88.7pt;transform:translate(-41.23pt,0pt) rotate(-90deg) ;">
<span id="S3.T6.1.11.11.1.1.1.1" class="ltx_p">Reconstruction Attack</span>
</span></span></span></td>
<td id="S3.T6.1.11.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T6.1.11.11.2.1.1" class="ltx_text" style="font-size:90%;">(</span>Wang
et al<span class="ltx_text">.</span><span id="S3.T6.1.11.11.2.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib190" title="" class="ltx_ref">2019a</a><span id="S3.T6.1.11.11.2.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S3.T6.1.11.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.11.11.3.1" class="ltx_text" style="font-size:90%;">WB</span></td>
<td id="S3.T6.1.11.11.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.11.11.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.11.11.4.1.1" class="ltx_tr">
<td id="S3.T6.1.11.11.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.11.11.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Client</span></td>
</tr>
<tr id="S3.T6.1.11.11.4.1.2" class="ltx_tr">
<td id="S3.T6.1.11.11.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.11.11.4.1.2.1.1" class="ltx_text" style="font-size:90%;">updates</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.11.11.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.11.11.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.11.11.5.1.1" class="ltx_tr">
<td id="S3.T6.1.11.11.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.11.11.5.1.1.1.1" class="ltx_text" style="font-size:90%;">1. Shallow target model;</span></td>
</tr>
<tr id="S3.T6.1.11.11.5.1.2" class="ltx_tr">
<td id="S3.T6.1.11.11.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.11.11.5.1.2.1.1" class="ltx_text" style="font-size:90%;">2. Low-resolution image</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.11.11.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.11.11.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.11.11.6.1.1" class="ltx_tr">
<td id="S3.T6.1.11.11.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.11.11.6.1.1.1.1" class="ltx_text" style="font-size:90%;">A GAN with multi-task discriminator</span></td>
</tr>
<tr id="S3.T6.1.11.11.6.1.2" class="ltx_tr">
<td id="S3.T6.1.11.11.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.11.11.6.1.2.1.1" class="ltx_text" style="font-size:90%;">to enhance fidelity and identify client</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T6.1.12.12" class="ltx_tr">
<td id="S3.T6.1.12.12.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T6.1.12.12.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Geiping et al<span class="ltx_text">.</span><span id="S3.T6.1.12.12.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib60" title="" class="ltx_ref">2020</a><span id="S3.T6.1.12.12.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S3.T6.1.12.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.12.12.2.1" class="ltx_text" style="font-size:90%;">WB</span></td>
<td id="S3.T6.1.12.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.12.12.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.12.12.3.1.1" class="ltx_tr">
<td id="S3.T6.1.12.12.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.12.12.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Client</span></td>
</tr>
<tr id="S3.T6.1.12.12.3.1.2" class="ltx_tr">
<td id="S3.T6.1.12.12.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.12.12.3.1.2.1.1" class="ltx_text" style="font-size:90%;">updates</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.12.12.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.12.12.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.12.12.4.1.1" class="ltx_tr">
<td id="S3.T6.1.12.12.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.12.12.4.1.1.1.1" class="ltx_text" style="font-size:90%;">1. Honest-but-curious server in</span></td>
</tr>
<tr id="S3.T6.1.12.12.4.1.2" class="ltx_tr">
<td id="S3.T6.1.12.12.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.12.12.4.1.2.1.1" class="ltx_text" style="font-size:90%;">FL; 2. Small batches</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.12.12.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.12.12.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.12.12.5.1.1" class="ltx_tr">
<td id="S3.T6.1.12.12.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.12.12.5.1.1.1.1" class="ltx_text" style="font-size:90%;">Optimizing the image to get a similar</span></td>
</tr>
<tr id="S3.T6.1.12.12.5.1.2" class="ltx_tr">
<td id="S3.T6.1.12.12.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.12.12.5.1.2.1.1" class="ltx_text" style="font-size:90%;">change in model prediction as the</span></td>
</tr>
<tr id="S3.T6.1.12.12.5.1.3" class="ltx_tr">
<td id="S3.T6.1.12.12.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.12.12.5.1.3.1.1" class="ltx_text" style="font-size:90%;">target images</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T6.1.13.13" class="ltx_tr">
<td id="S3.T6.1.13.13.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T6.1.13.13.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Zhu et al<span class="ltx_text">.</span><span id="S3.T6.1.13.13.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib232" title="" class="ltx_ref">2019</a><span id="S3.T6.1.13.13.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S3.T6.1.13.13.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.13.13.2.1" class="ltx_text" style="font-size:90%;">WB</span></td>
<td id="S3.T6.1.13.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.13.13.3.1" class="ltx_text" style="font-size:90%;">Gradients</span></td>
<td id="S3.T6.1.13.13.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.13.13.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.13.13.4.1.1" class="ltx_tr">
<td id="S3.T6.1.13.13.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.13.13.4.1.1.1.1" class="ltx_text" style="font-size:90%;">1. Small image size; 2. Single</span></td>
</tr>
<tr id="S3.T6.1.13.13.4.1.2" class="ltx_tr">
<td id="S3.T6.1.13.13.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.13.13.4.1.2.1.1" class="ltx_text" style="font-size:90%;">batches; 3. Target model is</span></td>
</tr>
<tr id="S3.T6.1.13.13.4.1.3" class="ltx_tr">
<td id="S3.T6.1.13.13.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.13.13.4.1.3.1.1" class="ltx_text" style="font-size:90%;">twice differentiable</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.13.13.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.13.13.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.13.13.5.1.1" class="ltx_tr">
<td id="S3.T6.1.13.13.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.13.13.5.1.1.1.1" class="ltx_text" style="font-size:90%;">Jointly optimizing inputs and labels</span></td>
</tr>
<tr id="S3.T6.1.13.13.5.1.2" class="ltx_tr">
<td id="S3.T6.1.13.13.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.13.13.5.1.2.1.1" class="ltx_text" style="font-size:90%;">to match gradients</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T6.1.14.14" class="ltx_tr">
<td id="S3.T6.1.14.14.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T6.1.14.14.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Hatamizadeh et al<span class="ltx_text">.</span><span id="S3.T6.1.14.14.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib75" title="" class="ltx_ref">2022</a><span id="S3.T6.1.14.14.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S3.T6.1.14.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.14.14.2.1" class="ltx_text" style="font-size:90%;">WB</span></td>
<td id="S3.T6.1.14.14.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.14.14.3.1" class="ltx_text" style="font-size:90%;">Gradients</span></td>
<td id="S3.T6.1.14.14.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.14.14.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.14.14.4.1.1" class="ltx_tr">
<td id="S3.T6.1.14.14.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.14.14.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Auxiliary networks provide</span></td>
</tr>
<tr id="S3.T6.1.14.14.4.1.2" class="ltx_tr">
<td id="S3.T6.1.14.14.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.14.14.4.1.2.1.1" class="ltx_text" style="font-size:90%;">image prior</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.14.14.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.14.14.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.14.14.5.1.1" class="ltx_tr">
<td id="S3.T6.1.14.14.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.14.14.5.1.1.1.1" class="ltx_text" style="font-size:90%;">Optimizing inputs to match the target</span></td>
</tr>
<tr id="S3.T6.1.14.14.5.1.2" class="ltx_tr">
<td id="S3.T6.1.14.14.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.14.14.5.1.2.1.1" class="ltx_text" style="font-size:90%;">gradients with image prior and</span></td>
</tr>
<tr id="S3.T6.1.14.14.5.1.3" class="ltx_tr">
<td id="S3.T6.1.14.14.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.14.14.5.1.3.1.1" class="ltx_text" style="font-size:90%;">auxiliary regularizer</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T6.1.15.15" class="ltx_tr">
<td id="S3.T6.1.15.15.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T6.1.15.15.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Yin et al<span class="ltx_text">.</span><span id="S3.T6.1.15.15.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib208" title="" class="ltx_ref">2021a</a><span id="S3.T6.1.15.15.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S3.T6.1.15.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.15.15.2.1" class="ltx_text" style="font-size:90%;">WB</span></td>
<td id="S3.T6.1.15.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.15.15.3.1" class="ltx_text" style="font-size:90%;">BN layers</span></td>
<td id="S3.T6.1.15.15.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.15.15.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.15.15.4.1.1" class="ltx_tr">
<td id="S3.T6.1.15.15.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.15.15.4.1.1.1.1" class="ltx_text" style="font-size:90%;">1. BN layers in target model;</span></td>
</tr>
<tr id="S3.T6.1.15.15.4.1.2" class="ltx_tr">
<td id="S3.T6.1.15.15.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.15.15.4.1.2.1.1" class="ltx_text" style="font-size:90%;">2. No repeating labels in a</span></td>
</tr>
<tr id="S3.T6.1.15.15.4.1.3" class="ltx_tr">
<td id="S3.T6.1.15.15.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.15.15.4.1.3.1.1" class="ltx_text" style="font-size:90%;">batch.</span></td>
</tr>
</table>
</td>
<td id="S3.T6.1.15.15.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S3.T6.1.15.15.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.1.15.15.5.1.1" class="ltx_tr">
<td id="S3.T6.1.15.15.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.15.15.5.1.1.1.1" class="ltx_text" style="font-size:90%;">Optimizing the input to match the</span></td>
</tr>
<tr id="S3.T6.1.15.15.5.1.2" class="ltx_tr">
<td id="S3.T6.1.15.15.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.15.15.5.1.2.1.1" class="ltx_text" style="font-size:90%;">statistics of BN layers of the target</span></td>
</tr>
<tr id="S3.T6.1.15.15.5.1.3" class="ltx_tr">
<td id="S3.T6.1.15.15.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S3.T6.1.15.15.5.1.3.1.1" class="ltx_text" style="font-size:90%;">model</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T6.1.16.16" class="ltx_tr">
<td id="S3.T6.1.16.16.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="6"><span id="S3.T6.1.16.16.1.1" class="ltx_text" style="font-size:90%;">BB: black-box; WB: white-box</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S3.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.6. </span>Discussion of privacy attacks and defenses in FL</h3>

<div id="S3.SS6.p1" class="ltx_para">
<p id="S3.SS6.p1.1" class="ltx_p">This section reviews existing privacy attacks and defense approaches in FL. Table <a href="#S3.T6" title="Table 6 ‣ 3.5.4. Discussion ‣ 3.5. Privacy-preserving Techniques ‣ 3. Privacy in FL ‣ Privacy and Fairness in Federated Learning: on the Perspective of Trade-off" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> summarized the existing privacy attacks in FL. From the attacker’s perspective, FL differentiates from the centralized counterparts in sever aspects: 1) <span id="S3.SS6.p1.1.1" class="ltx_text ltx_font_italic">The active attacker in FL.</span> Due to the collaboration between clients and the server, an adversary could actively attack for victim’s private data. For example, the attacker may maliciously reverse the gradients <cite class="ltx_cite ltx_citemacro_citep">(Nasr
et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2019</a>)</cite> or mislabel the training sample <cite class="ltx_cite ltx_citemacro_citep">(Hitaj
et al<span class="ltx_text">.</span>, <a href="#bib.bib76" title="" class="ltx_ref">2017</a>)</cite> to neutralize the benign clients’ efforts and fool them into revealing more information about their private data. Hence making them more venerable compared to centralized machine learning. 2) <span id="S3.SS6.p1.1.2" class="ltx_text ltx_font_italic">The real-time nature of FL strengthens the attacker’s ability.</span> During the training process, the adversary could adaptive change their strategy to infer the victim’s private data. As a result, the adversary can even infer a specific clients’ data <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib190" title="" class="ltx_ref">2019a</a>)</cite> when the target features appear in FL <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib186" title="" class="ltx_ref">2019b</a>, <a href="#bib.bib189" title="" class="ltx_ref">2022</a>)</cite>, which is way more severe than centralized setting. 3) <span id="S3.SS6.p1.1.3" class="ltx_text ltx_font_italic">Gradients are shared between clients and server.</span> Unlike the centralized counterpart, where the adversary could at most access the white-box access to the target model. In FL, gradients are repeatedly shared between clients and the server. Which enables gradient-based privacy attacks. As shown by <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib232" title="" class="ltx_ref">2019</a>; Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib208" title="" class="ltx_ref">2021a</a>)</cite>, the malicious server can reconstruct clients’ training data at the pixel level by minimizing the distance to the target gradients.</p>
</div>
<div id="S3.SS6.p2" class="ltx_para">
<p id="S3.SS6.p2.1" class="ltx_p">From the defender’s perspective, protecting privacy in FL is also different from that in the centralized scenario. 1) <span id="S3.SS6.p2.1.1" class="ltx_text ltx_font_italic">Malicious could be the server or any client</span>. FL allows clients to keep private data local. A central server is designed to orchestrate the training process. Which complicated privacy protection. The adversary could be the server <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib190" title="" class="ltx_ref">2019a</a>; Ren et al<span class="ltx_text">.</span>, <a href="#bib.bib154" title="" class="ltx_ref">2022</a>; Geiping et al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2020</a>)</cite> or the client <cite class="ltx_cite ltx_citemacro_citep">(Hitaj
et al<span class="ltx_text">.</span>, <a href="#bib.bib76" title="" class="ltx_ref">2017</a>)</cite>. The malicious adversary is able to infer the target client’s privacy passively or actively. For example, sending the modified global model to the target client to probe private data <cite class="ltx_cite ltx_citemacro_citep">(Fowl et al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2021</a>)</cite>. This brings challenges to defending against potential privacy attacks. DP is a prevailing choice, but it degrades performance. The cryptographic approaches, like HE, and MPC, retain both privacy and performance at the cost of computation overhead, which is a more severe issue in FL since most clients’ devices are limited in computation power. 2) <span id="S3.SS6.p2.1.2" class="ltx_text ltx_font_italic">Training and inference stage privacy attacks.</span> Different from centralized machine learning, where the major privacy leakage happens at the inference stage, i.e., malicious users probe private training data by inferring the target model. In FL, the attacks could happen during or after the training. This requires the defenders to be aware of both possibilities. The cryptographic approaches proved provable privacy protection during the training stage. However, fail at the inference stage since training distribution is embedded in the trained model’s parameters. The perturbation approaches, e.g., DP, provides long-term protection and covers both the training and inference stage. One can hide sensitive information from adversaries by adding appropriate noise to the training data.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Fairness in FL</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Fairness, as discussed in the centralized setting, is mainly defined at either the group level <cite class="ltx_cite ltx_citemacro_citep">(Kusner
et al<span class="ltx_text">.</span>, <a href="#bib.bib107" title="" class="ltx_ref">2018</a>; Hardt
et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2016</a>)</cite> or the individual level <cite class="ltx_cite ltx_citemacro_citep">(Dwork et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2012</a>)</cite>. In the FL scenario, fairness has a broader definition. Beyond the long-established <span id="S4.p1.1.1" class="ltx_text ltx_font_italic">algorithmic fairness</span> <cite class="ltx_cite ltx_citemacro_citep">(Kusner
et al<span class="ltx_text">.</span>, <a href="#bib.bib107" title="" class="ltx_ref">2018</a>; Hardt
et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2016</a>)</cite>, <span id="S4.p1.1.2" class="ltx_text ltx_font_italic">client-level fairness</span> <cite class="ltx_cite ltx_citemacro_citep">(Yu et al<span class="ltx_text">.</span>, <a href="#bib.bib210" title="" class="ltx_ref">2020</a>; Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2019b</a>; Mohri
et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2019</a>; Martinez
et al<span class="ltx_text">.</span>, <a href="#bib.bib128" title="" class="ltx_ref">2020</a>)</cite> arises as a new challenge in FL.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Algorithmic Fairness</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Algorithmic fairness is commonly used to describe the discrepancies in algorithm decisions made across distinct groups as defined by a sensitive attribute. FL often involves a deep neural network with redundant parameters and is pruned to overfit the privileged groups. Various debiasing methods have been devised for different applications, including machine learning <cite class="ltx_cite ltx_citemacro_citep">(Zafar
et al<span class="ltx_text">.</span>, <a href="#bib.bib212" title="" class="ltx_ref">2017</a>; Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib222" title="" class="ltx_ref">2019b</a>; Berk et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2017</a>; Bolukbasi et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2016</a>; Brunet et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2019</a>)</cite>, representation learning <cite class="ltx_cite ltx_citemacro_citep">(Louizos et al<span class="ltx_text">.</span>, <a href="#bib.bib122" title="" class="ltx_ref">2016</a>; Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib214" title="" class="ltx_ref">2018a</a>)</cite>, and natural language processing <cite class="ltx_cite ltx_citemacro_citep">(Zhao
et al<span class="ltx_text">.</span>, <a href="#bib.bib228" title="" class="ltx_ref">2018b</a>; May
et al<span class="ltx_text">.</span>, <a href="#bib.bib129" title="" class="ltx_ref">2019</a>; Bordia and Bowman, <a href="#bib.bib18" title="" class="ltx_ref">2019</a>; Font and
Costa-jussà, <a href="#bib.bib53" title="" class="ltx_ref">2019</a>)</cite>. These methods vary in detail but share similar principles. Following the data flow, debiasing methods can be grouped into <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">pre-processing, in-processing</span> and <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_italic">post-processing</span> categories, which address the discriminate issues at three distinct stages of the data’s handling <cite class="ltx_cite ltx_citemacro_citep">(d’Alessandro et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1. </span>Pre-processing</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">Pre-processing tries to remove the underlying discrimination from the data typically by 1) altering the values of the sensitive attributes/class labels; 2) mapping the training data to a new space where the sensitive attributes and class labels are no longer relevant <cite class="ltx_cite ltx_citemacro_citep">(Feldman et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2015</a>; Kamiran and
Calders, <a href="#bib.bib93" title="" class="ltx_ref">2012</a>, <a href="#bib.bib92" title="" class="ltx_ref">2010</a>)</cite>; or 3) reweighting the samples in the training dataset to compensate for skewed treatment <cite class="ltx_cite ltx_citemacro_citep">(Kamiran and
Calders, <a href="#bib.bib93" title="" class="ltx_ref">2012</a>)</cite>.</p>
</div>
<div id="S4.SS1.SSS1.p2" class="ltx_para">
<p id="S4.SS1.SSS1.p2.1" class="ltx_p">Intuitively, by training a classifier on discrimination-free data, it is likely that the resulting predictions will be discrimination-free. Inspired by this idea, Kamiran and Calders <cite class="ltx_cite ltx_citemacro_citep">(Kamiran and
Calders, <a href="#bib.bib93" title="" class="ltx_ref">2012</a>)</cite> proposed three types of pre-processing solutions to learn a fair classification, <span id="S4.SS1.SSS1.p2.1.1" class="ltx_text ltx_font_italic">messaging, reweighing and sampling</span>. Feldman et al. <cite class="ltx_cite ltx_citemacro_citep">(Feldman et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2015</a>)</cite> investigated the problem of identifying and removing disparate impacts in the data. Xu et al. <cite class="ltx_cite ltx_citemacro_citep">(Xu
et al<span class="ltx_text">.</span>, <a href="#bib.bib198" title="" class="ltx_ref">2018</a>)</cite> proposed FairGAN, which generates fair data from the original training data and uses the generated data to train the model. Abay et al. <cite class="ltx_cite ltx_citemacro_citep">(Abay et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite> proposed two reweighting methods for the FL setting <cite class="ltx_cite ltx_citemacro_citep">(Kamiran and
Calders, <a href="#bib.bib93" title="" class="ltx_ref">2012</a>)</cite>, <span id="S4.SS1.SSS1.p2.1.2" class="ltx_text ltx_font_italic">local reweighing</span> and <span id="S4.SS1.SSS1.p2.1.3" class="ltx_text ltx_font_italic">global reweighing with DP</span>.</p>
</div>
<div id="S4.SS1.SSS1.p3" class="ltx_para">
<p id="S4.SS1.SSS1.p3.1" class="ltx_p">Notably, these pre-processing techniques require access to the training data, which violates the privacy principles of FL. As a result, these types of techniques can only be deployed locally on each client. However, in the presence of data heterogeneous among clients, local debiasing cannot provide fair performance for an entire population <cite class="ltx_cite ltx_citemacro_citep">(Cui
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2. </span>In-processing</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">In-processing modifies traditional learning algorithms to address discrimination <cite class="ltx_cite ltx_citemacro_citep">(Zafar
et al<span class="ltx_text">.</span>, <a href="#bib.bib212" title="" class="ltx_ref">2017</a>; Goh
et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2016</a>; Kamishima
et al<span class="ltx_text">.</span>, <a href="#bib.bib94" title="" class="ltx_ref">2012</a>; Berk et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2017</a>; Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib215" title="" class="ltx_ref">2018b</a>; Zemel
et al<span class="ltx_text">.</span>, <a href="#bib.bib213" title="" class="ltx_ref">2013</a>)</cite>. Such as adding a regularization term to the loss function. Berk et al. <cite class="ltx_cite ltx_citemacro_citep">(Berk et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2017</a>)</cite>, for example, incorporated a family of fairness regularizers into the objective function for regression problems. These regularizers span the range from notions of group fairness to individual fairness. They also create a trade-off between accuracy and fairness.</p>
</div>
<div id="S4.SS1.SSS2.p2" class="ltx_para">
<p id="S4.SS1.SSS2.p2.1" class="ltx_p">Another in-processing option is imposing constraints. Zhang et al. <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib215" title="" class="ltx_ref">2018b</a>)</cite> used a GAN to constrain the bias in a model trained on biased data. During training, the scheme simultaneously tries to maximize the accuracy of the predictor while minimizing the ability of the adversary to predict the protected variable. In FL, G’alvez et al. <cite class="ltx_cite ltx_citemacro_citep">(G’alvez et al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2021</a>)</cite> studied the notion of group fairness as an optimization problem with fairness constraints. Papadaki et al. <cite class="ltx_cite ltx_citemacro_citep">(Papadaki et al<span class="ltx_text">.</span>, <a href="#bib.bib147" title="" class="ltx_ref">2021</a>)</cite> formulated a min-max optimization problem to investigate group fairness in scenarios where population data were distributed across clients. Ezzeldin et al. <cite class="ltx_cite ltx_citemacro_citep">(Ezzeldin et al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2021</a>)</cite> replaced the aggregation protocol FedAvg with FairFed, which adaptively updates the aggregating weights in each round to improve group fairness. Clients whose local measurements match the global fairness measure are given preferential treatment. Khedr et al. <cite class="ltx_cite ltx_citemacro_citep">(Khedr and Shoukry, <a href="#bib.bib100" title="" class="ltx_ref">2022</a>)</cite> add a regularizer term to minimize the average loss in fairness across all training data.</p>
</div>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3. </span>Post-processing</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.1" class="ltx_p">Post-processing addresses discrimination issues after the model is trained and doesn’t need to change the training process. The general methodology of post-processing algorithms is to take a subset of samples and change their predicted labels to meet a group fairness requirement <cite class="ltx_cite ltx_citemacro_citep">(Calders and
Verwer, <a href="#bib.bib21" title="" class="ltx_ref">2010</a>; Hardt
et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2016</a>; Bolukbasi et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2016</a>; Pleiss et al<span class="ltx_text">.</span>, <a href="#bib.bib152" title="" class="ltx_ref">2017</a>; Canetti et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2019</a>; Lohia et al<span class="ltx_text">.</span>, <a href="#bib.bib121" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S4.SS1.SSS3.p2" class="ltx_para">
<p id="S4.SS1.SSS3.p2.7" class="ltx_p">Hardt et al. <cite class="ltx_cite ltx_citemacro_citep">(Hardt
et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2016</a>)</cite> proposed a post-processing technique to construct a non-discriminating predictor <math id="S4.SS1.SSS3.p2.1.m1.1" class="ltx_Math" alttext="\tilde{Y}" display="inline"><semantics id="S4.SS1.SSS3.p2.1.m1.1a"><mover accent="true" id="S4.SS1.SSS3.p2.1.m1.1.1" xref="S4.SS1.SSS3.p2.1.m1.1.1.cmml"><mi id="S4.SS1.SSS3.p2.1.m1.1.1.2" xref="S4.SS1.SSS3.p2.1.m1.1.1.2.cmml">Y</mi><mo id="S4.SS1.SSS3.p2.1.m1.1.1.1" xref="S4.SS1.SSS3.p2.1.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p2.1.m1.1b"><apply id="S4.SS1.SSS3.p2.1.m1.1.1.cmml" xref="S4.SS1.SSS3.p2.1.m1.1.1"><ci id="S4.SS1.SSS3.p2.1.m1.1.1.1.cmml" xref="S4.SS1.SSS3.p2.1.m1.1.1.1">~</ci><ci id="S4.SS1.SSS3.p2.1.m1.1.1.2.cmml" xref="S4.SS1.SSS3.p2.1.m1.1.1.2">𝑌</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p2.1.m1.1c">\tilde{Y}</annotation></semantics></math> from a learned discriminatory binary predictor <math id="S4.SS1.SSS3.p2.2.m2.1" class="ltx_Math" alttext="\hat{Y}" display="inline"><semantics id="S4.SS1.SSS3.p2.2.m2.1a"><mover accent="true" id="S4.SS1.SSS3.p2.2.m2.1.1" xref="S4.SS1.SSS3.p2.2.m2.1.1.cmml"><mi id="S4.SS1.SSS3.p2.2.m2.1.1.2" xref="S4.SS1.SSS3.p2.2.m2.1.1.2.cmml">Y</mi><mo id="S4.SS1.SSS3.p2.2.m2.1.1.1" xref="S4.SS1.SSS3.p2.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p2.2.m2.1b"><apply id="S4.SS1.SSS3.p2.2.m2.1.1.cmml" xref="S4.SS1.SSS3.p2.2.m2.1.1"><ci id="S4.SS1.SSS3.p2.2.m2.1.1.1.cmml" xref="S4.SS1.SSS3.p2.2.m2.1.1.1">^</ci><ci id="S4.SS1.SSS3.p2.2.m2.1.1.2.cmml" xref="S4.SS1.SSS3.p2.2.m2.1.1.2">𝑌</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p2.2.m2.1c">\hat{Y}</annotation></semantics></math>. Only access to the prediction <math id="S4.SS1.SSS3.p2.3.m3.1" class="ltx_Math" alttext="\hat{Y}" display="inline"><semantics id="S4.SS1.SSS3.p2.3.m3.1a"><mover accent="true" id="S4.SS1.SSS3.p2.3.m3.1.1" xref="S4.SS1.SSS3.p2.3.m3.1.1.cmml"><mi id="S4.SS1.SSS3.p2.3.m3.1.1.2" xref="S4.SS1.SSS3.p2.3.m3.1.1.2.cmml">Y</mi><mo id="S4.SS1.SSS3.p2.3.m3.1.1.1" xref="S4.SS1.SSS3.p2.3.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p2.3.m3.1b"><apply id="S4.SS1.SSS3.p2.3.m3.1.1.cmml" xref="S4.SS1.SSS3.p2.3.m3.1.1"><ci id="S4.SS1.SSS3.p2.3.m3.1.1.1.cmml" xref="S4.SS1.SSS3.p2.3.m3.1.1.1">^</ci><ci id="S4.SS1.SSS3.p2.3.m3.1.1.2.cmml" xref="S4.SS1.SSS3.p2.3.m3.1.1.2">𝑌</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p2.3.m3.1c">\hat{Y}</annotation></semantics></math>, the protected attribute <math id="S4.SS1.SSS3.p2.4.m4.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.SS1.SSS3.p2.4.m4.1a"><mi id="S4.SS1.SSS3.p2.4.m4.1.1" xref="S4.SS1.SSS3.p2.4.m4.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p2.4.m4.1b"><ci id="S4.SS1.SSS3.p2.4.m4.1.1.cmml" xref="S4.SS1.SSS3.p2.4.m4.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p2.4.m4.1c">A</annotation></semantics></math> and target label <math id="S4.SS1.SSS3.p2.5.m5.1" class="ltx_Math" alttext="Y" display="inline"><semantics id="S4.SS1.SSS3.p2.5.m5.1a"><mi id="S4.SS1.SSS3.p2.5.m5.1.1" xref="S4.SS1.SSS3.p2.5.m5.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p2.5.m5.1b"><ci id="S4.SS1.SSS3.p2.5.m5.1.1.cmml" xref="S4.SS1.SSS3.p2.5.m5.1.1">𝑌</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p2.5.m5.1c">Y</annotation></semantics></math> in the data are required, while details of the mapping of features <math id="S4.SS1.SSS3.p2.6.m6.1" class="ltx_Math" alttext="X" display="inline"><semantics id="S4.SS1.SSS3.p2.6.m6.1a"><mi id="S4.SS1.SSS3.p2.6.m6.1.1" xref="S4.SS1.SSS3.p2.6.m6.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p2.6.m6.1b"><ci id="S4.SS1.SSS3.p2.6.m6.1.1.cmml" xref="S4.SS1.SSS3.p2.6.m6.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p2.6.m6.1c">X</annotation></semantics></math> to prediction <math id="S4.SS1.SSS3.p2.7.m7.1" class="ltx_Math" alttext="\hat{Y}" display="inline"><semantics id="S4.SS1.SSS3.p2.7.m7.1a"><mover accent="true" id="S4.SS1.SSS3.p2.7.m7.1.1" xref="S4.SS1.SSS3.p2.7.m7.1.1.cmml"><mi id="S4.SS1.SSS3.p2.7.m7.1.1.2" xref="S4.SS1.SSS3.p2.7.m7.1.1.2.cmml">Y</mi><mo id="S4.SS1.SSS3.p2.7.m7.1.1.1" xref="S4.SS1.SSS3.p2.7.m7.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p2.7.m7.1b"><apply id="S4.SS1.SSS3.p2.7.m7.1.1.cmml" xref="S4.SS1.SSS3.p2.7.m7.1.1"><ci id="S4.SS1.SSS3.p2.7.m7.1.1.1.cmml" xref="S4.SS1.SSS3.p2.7.m7.1.1.1">^</ci><ci id="S4.SS1.SSS3.p2.7.m7.1.1.2.cmml" xref="S4.SS1.SSS3.p2.7.m7.1.1.2">𝑌</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p2.7.m7.1c">\hat{Y}</annotation></semantics></math> are not needed. Canetti et al. <cite class="ltx_cite ltx_citemacro_citep">(Canetti et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2019</a>)</cite> and Pleiss et al. <cite class="ltx_cite ltx_citemacro_citep">(Pleiss et al<span class="ltx_text">.</span>, <a href="#bib.bib152" title="" class="ltx_ref">2017</a>)</cite> shared the key characteristics as Hardt et al.’s <cite class="ltx_cite ltx_citemacro_citep">(Hardt
et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2016</a>)</cite> work. Lohia et al. <cite class="ltx_cite ltx_citemacro_citep">(Luo
et al<span class="ltx_text">.</span>, <a href="#bib.bib124" title="" class="ltx_ref">2021</a>)</cite> designed a post-processing method to increase both individual and group fairness. Salvador et al. <cite class="ltx_cite ltx_citemacro_citep">(Salvador et al<span class="ltx_text">.</span>, <a href="#bib.bib156" title="" class="ltx_ref">2021</a>)</cite> introduced a conditional calibration method for fair face verification. Their method clusters images into different sets and assigns distinct thresholds to different sets.</p>
</div>
</section>
<section id="S4.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.4. </span>Discussion</h4>

<div id="S4.SS1.SSS4.p1" class="ltx_para">
<p id="S4.SS1.SSS4.p1.1" class="ltx_p">Three different kinds of debiasing methods are at hand in centralized machine learning. However, solutions in the centralized setting cannot be applied directly in the FL scenario due to limitations with the training data. More specifically, in federated settings, the clients usually have limited amounts of data. Hence, a single client can’t accurately represent the true distribution over all clients. Consequently, debiasing data before training is not an option. Another limitation is that direct access to local data is prohibited on the server side. Nevertheless, canny researchers have found inspiration from and workarounds to these issues. Gálvez et al. <cite class="ltx_cite ltx_citemacro_citep">(G’alvez et al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2021</a>)</cite>, for example, bypassed this access restriction by using statistics to guide the model’s training instead of the raw data.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Client Fairness</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Client fairness in FL is another different fairness notion than algorithmic notions. Ideally, the models produced from FL should capture clients’ data distributions and generalize well when deployed on the client side. However, data distribution usually varies among clients. As a result, the global model has inconsistent performance on different clients’ dataset. At the client level, a FL protocol is considered to be fair if the performance fluctuates within a limited range, i.e., the variance in the model’s performance across clients falls under a predefined threshold. To this end, two lines of research exist to mitigate fairness issues in FL. These are the <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">single model approach</span> and the <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_italic">personalized models approach</span>.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1. </span>Single Model Approach</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">The single model approach trains a single global model for all clients as a standard FL scheme. Here, the focus is on solving any statistical heterogeneity during the training phase rather than smoothing the distribution difference.</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Data augmentation</span> is a straightforward solution to statistical heterogeneity. It increases data diversity on the client side. Several researchers have studied ways to enhance the statistical homogeneity of local data in FL <cite class="ltx_cite ltx_citemacro_citep">(Zhao
et al<span class="ltx_text">.</span>, <a href="#bib.bib229" title="" class="ltx_ref">2018a</a>; Jeong
et al<span class="ltx_text">.</span>, <a href="#bib.bib84" title="" class="ltx_ref">2018</a>; Hao et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2021</a>)</cite>. Zhao et al. <cite class="ltx_cite ltx_citemacro_citep">(Zhao
et al<span class="ltx_text">.</span>, <a href="#bib.bib229" title="" class="ltx_ref">2018a</a>)</cite> suggested a data share scheme, which creates a globally-shared dataset that is balanced by class. The experiment shows a 30% improvement on accuracy with only 5% globally shared data. Jeong et al. <cite class="ltx_cite ltx_citemacro_citep">(Jeong
et al<span class="ltx_text">.</span>, <a href="#bib.bib84" title="" class="ltx_ref">2018</a>)</cite> proposed <span id="S4.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">FAug</span>. Clients first collectively train a GAN model, which is then distributed to clients to augment their local data towards yielding an i.i.d dataset.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Client Selection</span> is another strategy that focuses on sampling data from a homogeneous distribution. Wang et al. <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib185" title="" class="ltx_ref">2020c</a>)</cite> proposed a control framework to actively select the best subset of clients in each training round. In Yang et al.’s <cite class="ltx_cite ltx_citemacro_citep">(Yang
et al<span class="ltx_text">.</span>, <a href="#bib.bib200" title="" class="ltx_ref">2020b</a>)</cite> method, the local data distribution is estimated first by comparing local updated gradients and gradients inferred from a balanced proxy dataset. The client selection algorithm based on a combinatorial multi-armed bandit was designed to minimize the effect of class imbalances.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Agnostic approach</span> trains a robust model against a possible unknown testing distribution. Mohri et al. <cite class="ltx_cite ltx_citemacro_citep">(Mohri
et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2019</a>)</cite> modeled testing distributions as an unknown mixture of all <math id="S4.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S4.I1.i3.p1.1.m1.1a"><mi id="S4.I1.i3.p1.1.m1.1.1" xref="S4.I1.i3.p1.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.1.m1.1b"><ci id="S4.I1.i3.p1.1.m1.1.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i3.p1.1.m1.1c">m</annotation></semantics></math> clients’ data. The global model is optimized for all possible target distributions. This makes the global model more robust to an unknown testing distribution. Du et al. <cite class="ltx_cite ltx_citemacro_citep">(Du
et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2021</a>)</cite> introduced a fairness constraint into Mohri et al.’s method <cite class="ltx_cite ltx_citemacro_citep">(Mohri
et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2019</a>)</cite> and proposed <span id="S4.I1.i3.p1.1.2" class="ltx_text ltx_font_italic">AgnosticFair</span>, a fairness-aware FL framework. Their method can provide both <em id="S4.I1.i3.p1.1.3" class="ltx_emph ltx_font_italic">Good-intent fairness</em> and <em id="S4.I1.i3.p1.1.4" class="ltx_emph ltx_font_italic">demographic parity</em></p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.4" class="ltx_p"><span id="S4.I1.i4.p1.4.1" class="ltx_text ltx_font_bold">Reweighting</span> tries to train a fair model by assigning suitable aggregating weights <math id="S4.I1.i4.p1.1.m1.1" class="ltx_Math" alttext="p_{k}" display="inline"><semantics id="S4.I1.i4.p1.1.m1.1a"><msub id="S4.I1.i4.p1.1.m1.1.1" xref="S4.I1.i4.p1.1.m1.1.1.cmml"><mi id="S4.I1.i4.p1.1.m1.1.1.2" xref="S4.I1.i4.p1.1.m1.1.1.2.cmml">p</mi><mi id="S4.I1.i4.p1.1.m1.1.1.3" xref="S4.I1.i4.p1.1.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.I1.i4.p1.1.m1.1b"><apply id="S4.I1.i4.p1.1.m1.1.1.cmml" xref="S4.I1.i4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.I1.i4.p1.1.m1.1.1.1.cmml" xref="S4.I1.i4.p1.1.m1.1.1">subscript</csymbol><ci id="S4.I1.i4.p1.1.m1.1.1.2.cmml" xref="S4.I1.i4.p1.1.m1.1.1.2">𝑝</ci><ci id="S4.I1.i4.p1.1.m1.1.1.3.cmml" xref="S4.I1.i4.p1.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i4.p1.1.m1.1c">p_{k}</annotation></semantics></math> in Eq. <a href="#S2.E1" title="In 2.1. Definition of FL ‣ 2. Background Knowledge ‣ Privacy and Fairness in Federated Learning: on the Perspective of Trade-off" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> to clients. Inspired by <math id="S4.I1.i4.p1.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.I1.i4.p1.2.m2.1a"><mi id="S4.I1.i4.p1.2.m2.1.1" xref="S4.I1.i4.p1.2.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i4.p1.2.m2.1b"><ci id="S4.I1.i4.p1.2.m2.1.1.cmml" xref="S4.I1.i4.p1.2.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i4.p1.2.m2.1c">\alpha</annotation></semantics></math>-fairness notions <cite class="ltx_cite ltx_citemacro_citep">(Lan
et al<span class="ltx_text">.</span>, <a href="#bib.bib109" title="" class="ltx_ref">2010</a>; Mo and Walrand, <a href="#bib.bib136" title="" class="ltx_ref">2000</a>)</cite>, Li et al. <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2019b</a>)</cite> sketched <math id="S4.I1.i4.p1.3.m3.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S4.I1.i4.p1.3.m3.1a"><mi id="S4.I1.i4.p1.3.m3.1.1" xref="S4.I1.i4.p1.3.m3.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i4.p1.3.m3.1b"><ci id="S4.I1.i4.p1.3.m3.1.1.cmml" xref="S4.I1.i4.p1.3.m3.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i4.p1.3.m3.1c">q</annotation></semantics></math><span id="S4.I1.i4.p1.4.2" class="ltx_text ltx_font_italic">-Fair FL</span> (<math id="S4.I1.i4.p1.4.m4.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S4.I1.i4.p1.4.m4.1a"><mi id="S4.I1.i4.p1.4.m4.1.1" xref="S4.I1.i4.p1.4.m4.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i4.p1.4.m4.1b"><ci id="S4.I1.i4.p1.4.m4.1.1.cmml" xref="S4.I1.i4.p1.4.m4.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i4.p1.4.m4.1c">q</annotation></semantics></math>-FFL) to foster fairer accuracy distribution across all clients by up-weighing clients with lower performance during aggregation. Huang et al. <cite class="ltx_cite ltx_citemacro_citep">(Huang
et al<span class="ltx_text">.</span>, <a href="#bib.bib78" title="" class="ltx_ref">2020a</a>)</cite> shared a similar idea where, for each round of aggregation, clients with lower accuracy or less training participant times are assigned higher aggregation weights.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2. </span>Personalized Models Approach</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">Instead of smoothing the statistical heterogeneity, in <span id="S4.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_italic">personalized FL</span>, multiple distinct models are trained for clients with different data distributions. A global model is first trained collaboratively and then personalized to clients using private data. In this way, clients can benefit from other clients’ data and solve the issue of statistical heterogeneity. Mansour et al. <cite class="ltx_cite ltx_citemacro_citep">(Mansour
et al<span class="ltx_text">.</span>, <a href="#bib.bib127" title="" class="ltx_ref">2020</a>)</cite> designed and analyzed three approaches to learning personalized models to learn personalized models. Kulkarni et al. <cite class="ltx_cite ltx_citemacro_citep">(Kulkarni
et al<span class="ltx_text">.</span>, <a href="#bib.bib105" title="" class="ltx_ref">2020</a>)</cite> conducted a brief overview of personalized FL. Chen et al. <cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2022</a>)</cite> provided a comprehensive benchmark of various personalized FL methods. Tan et al. <cite class="ltx_cite ltx_citemacro_citep">(Tan
et al<span class="ltx_text">.</span>, <a href="#bib.bib175" title="" class="ltx_ref">2021</a>)</cite> systematically reviewed this topic and classified personalized FL techniques in terms of data-based and model-based approaches. Here, we summarize their conclusions.</p>
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p"><span id="S4.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Multi-task learning</span> treats building models for each client as different tasks. Smith et al. <cite class="ltx_cite ltx_citemacro_citep">(Smith
et al<span class="ltx_text">.</span>, <a href="#bib.bib169" title="" class="ltx_ref">2017</a>)</cite> pioneered this approach and explored personalized FL via a multi-task learning framework. <cite class="ltx_cite ltx_citemacro_citep">(Agarwal
et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020</a>; Liang et al<span class="ltx_text">.</span>, <a href="#bib.bib117" title="" class="ltx_ref">2020</a>)</cite> followed this principle. Dinh et al. <cite class="ltx_cite ltx_citemacro_citep">(Dinh
et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2021</a>)</cite> proposed FedU, which incorporates a Laplacian regularization term into the optimization problem to leverage relationships between clients.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p"><span id="S4.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Model interpolation</span> trains local and global models simultaneously, where the global model is used for its generalization ability, and the local model is used to improve local performance. Hanzely and Richtárik <cite class="ltx_cite ltx_citemacro_citep">(Hanzely and
Richtárik, <a href="#bib.bib71" title="" class="ltx_ref">2021</a>)</cite> formulated an optimization problem that learns a mixture of the global and local models. The local model is trained solely on each client’s private data. Softly-enforced similarity from multi-task learning is borrowed to discourage the local model from departing too much from the mean model. Deng et al. <cite class="ltx_cite ltx_citemacro_citep">(Deng
et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2020</a>)</cite> and Mansour et al. <cite class="ltx_cite ltx_citemacro_citep">(Mansour
et al<span class="ltx_text">.</span>, <a href="#bib.bib127" title="" class="ltx_ref">2020</a>)</cite> adopt a similar formulation to determine the optimal interpolation of the local and global models. In Zhang et al.’s <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib223" title="" class="ltx_ref">2020d</a>)</cite> work, clients are given access to multiple models uploaded by other clients to evaluate how much they will benefit from these models. An optimal combination is then used as a personal update. Lin et al. <cite class="ltx_cite ltx_citemacro_citep">(Lin
et al<span class="ltx_text">.</span>, <a href="#bib.bib118" title="" class="ltx_ref">2022</a>)</cite> investigated the trade-offs between local and global models.</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p id="S4.I2.i3.p1.1" class="ltx_p"><span id="S4.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Parameter decoupling</span> learns local parameters as an independent task performed locally. The local model is designed to assist in personalizing the global model to local distributions. Liang et al. <cite class="ltx_cite ltx_citemacro_citep">(Liang et al<span class="ltx_text">.</span>, <a href="#bib.bib117" title="" class="ltx_ref">2020</a>)</cite> devised the local-global federated averaging algorithm, which jointly learns compact local representations for each client and a global model across all devices. Chen and Chao <cite class="ltx_cite ltx_citemacro_citep">(Chen and Chao, <a href="#bib.bib26" title="" class="ltx_ref">2021</a>)</cite> decomposed a FL model as a generic predictor, which is trained globally, along with a personalized predictor that is trained locally. The personalized predictor is formulated as a lightweight, adaptive module on top of the generic predictor.</p>
</div>
</li>
<li id="S4.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i4.p1" class="ltx_para">
<p id="S4.I2.i4.p1.1" class="ltx_p"><span id="S4.I2.i4.p1.1.1" class="ltx_text ltx_font_bold">Transfer learning</span> is a practical training paradigm that leverages knowledge from a source domain to help train a model in a target domain. The performance of transfer learning depends on the similarity between the two domains. Federated transfer learning was first introduced by Liu et al. <cite class="ltx_cite ltx_citemacro_citep">(Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib120" title="" class="ltx_ref">2020</a>)</cite>. Since clients in the same federation usually share the same domain, a FL scheme would make a suitable partner for transfer learning. Li and Wang <cite class="ltx_cite ltx_citemacro_citep">(Li and Wang, <a href="#bib.bib111" title="" class="ltx_ref">2019</a>)</cite> subsequently proposed FedMD, which combines transfer learning and knowledge distillation. Each client performs transfer learning by training a model to converge on a public dataset and subsequently fine-tune it on local data.</p>
</div>
</li>
<li id="S4.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i5.p1" class="ltx_para">
<p id="S4.I2.i5.p1.1" class="ltx_p"><span id="S4.I2.i5.p1.1.1" class="ltx_text ltx_font_bold">Clustering</span> arranges clients into different groups and trains a specific model for each group. Ghosh et al. <cite class="ltx_cite ltx_citemacro_citep">(Ghosh
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2020</a>)</cite> iteratively determines the membership of each client to a cluster and optimizes each of the cluster models via gradient descent in a distributed setting. Sattler et al. <cite class="ltx_cite ltx_citemacro_citep">(Sattler
et al<span class="ltx_text">.</span>, <a href="#bib.bib159" title="" class="ltx_ref">2020</a>)</cite> clusters clients according to the cosine similarity between the clients’ gradient updates. This allows clients with a similar distribution to profit from one another while minimizing detrimental interference from others. In Briggs et al.’s <cite class="ltx_cite ltx_citemacro_citep">(Briggs
et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2020</a>)</cite> method, a clustering step is periodically inserted into the training process to cluster clients based on their local updates. The clusters are then trained individually and in parallel on specialized models. Mansour et al. <cite class="ltx_cite ltx_citemacro_citep">(Mansour
et al<span class="ltx_text">.</span>, <a href="#bib.bib127" title="" class="ltx_ref">2020</a>)</cite> proposed hypothesis-based clustering, partitioning clients into <math id="S4.I2.i5.p1.1.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S4.I2.i5.p1.1.m1.1a"><mi id="S4.I2.i5.p1.1.m1.1.1" xref="S4.I2.i5.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S4.I2.i5.p1.1.m1.1b"><ci id="S4.I2.i5.p1.1.m1.1.1.cmml" xref="S4.I2.i5.p1.1.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i5.p1.1.m1.1c">q</annotation></semantics></math> clusters and finding the best hypothesis for each cluster.</p>
</div>
</li>
<li id="S4.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i6.p1" class="ltx_para">
<p id="S4.I2.i6.p1.1" class="ltx_p"><span id="S4.I2.i6.p1.1.1" class="ltx_text ltx_font_bold">Regularization</span> prevents overfitting when training models and has been used in several studies to remedy the weight divergence problem in FL settings. Li et al. <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib114" title="" class="ltx_ref">2020</a>)</cite> introduced a proximal term that considers the differences between global and local models to limit the effect of local updates. Yao et al. <cite class="ltx_cite ltx_citemacro_citep">(Yao and Sun, <a href="#bib.bib206" title="" class="ltx_ref">2020</a>)</cite> considered parameter importance in the regularised local loss function by using elastic weight consolidation <cite class="ltx_cite ltx_citemacro_citep">(Kirkpatrick et al<span class="ltx_text">.</span>, <a href="#bib.bib103" title="" class="ltx_ref">2017</a>)</cite>. In addition, a regularization term is introduced to penalize the deviation of the local model from the global model.</p>
</div>
</li>
<li id="S4.I2.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i7.p1" class="ltx_para">
<p id="S4.I2.i7.p1.1" class="ltx_p"><span id="S4.I2.i7.p1.1.1" class="ltx_text ltx_font_bold">Meta-learning</span> aims to leverage prior experience with other tasks to facilitate the learning process. The resulting models are highly-adaptable to new heterogeneous tasks <cite class="ltx_cite ltx_citemacro_citep">(Nichol
et al<span class="ltx_text">.</span>, <a href="#bib.bib142" title="" class="ltx_ref">2018</a>; Finn
et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2017</a>)</cite>. Fallah et al. <cite class="ltx_cite ltx_citemacro_citep">(Fallah
et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2020</a>)</cite> studied a personalized variant of FedAvg based on model-agnostic meta-learning formulation. The proposed Per-FedAvg algorithm looks for an initial model that performs well after one step of the local gradient update on each client’s data. Others have interpreted FedAvg as a meta-learning algorithm, breaking it into two stages of training and fine-tuning to optimize personalized performance and model convergence <cite class="ltx_cite ltx_citemacro_citep">(Jiang
et al<span class="ltx_text">.</span>, <a href="#bib.bib85" title="" class="ltx_ref">2019</a>; Khodak
et al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
</li>
</ul>
</div>
<figure id="S4.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7. </span>Summary of Fairness-aware FL</figcaption>
<table id="S4.T7.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T7.1.1.1" class="ltx_tr">
<th id="S4.T7.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Reference</span></th>
<th id="S4.T7.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<table id="S4.T7.1.1.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T7.1.1.1.2.1.1" class="ltx_tr">
<td id="S4.T7.1.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.1.1.2.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Single</span></td>
</tr>
<tr id="S4.T7.1.1.1.2.1.2" class="ltx_tr">
<td id="S4.T7.1.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.1.1.2.1.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Model</span></td>
</tr>
</table>
</th>
<th id="S4.T7.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<table id="S4.T7.1.1.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T7.1.1.1.3.1.1" class="ltx_tr">
<td id="S4.T7.1.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.1.1.3.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Personalized</span></td>
</tr>
<tr id="S4.T7.1.1.1.3.1.2" class="ltx_tr">
<td id="S4.T7.1.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.1.1.3.1.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Model</span></td>
</tr>
</table>
</th>
<th id="S4.T7.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<table id="S4.T7.1.1.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T7.1.1.1.4.1.1" class="ltx_tr">
<td id="S4.T7.1.1.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.1.1.4.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Algorithmic</span></td>
</tr>
<tr id="S4.T7.1.1.1.4.1.2" class="ltx_tr">
<td id="S4.T7.1.1.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.1.1.4.1.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Fairness</span></td>
</tr>
</table>
</th>
<th id="S4.T7.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<table id="S4.T7.1.1.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T7.1.1.1.5.1.1" class="ltx_tr">
<td id="S4.T7.1.1.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.1.1.5.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Client</span></td>
</tr>
<tr id="S4.T7.1.1.1.5.1.2" class="ltx_tr">
<td id="S4.T7.1.1.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.1.1.5.1.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Fairness</span></td>
</tr>
</table>
</th>
<th id="S4.T7.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.1.1.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Method</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T7.1.2.1" class="ltx_tr">
<th id="S4.T7.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T7.1.2.1.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Zhao
et al<span class="ltx_text">.</span><span id="S4.T7.1.2.1.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib229" title="" class="ltx_ref">2018a</a>; Jeong
et al<span class="ltx_text">.</span><span id="S4.T7.1.2.1.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib84" title="" class="ltx_ref">2018</a>; Hao et al<span class="ltx_text">.</span><span id="S4.T7.1.2.1.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib72" title="" class="ltx_ref">2021</a><span id="S4.T7.1.2.1.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S4.T7.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.2.1.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.2.1.3" class="ltx_td ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.2.1.4" class="ltx_td ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.2.1.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.2.1.6.1" class="ltx_text" style="font-size:90%;">Data Augmentation</span></td>
</tr>
<tr id="S4.T7.1.3.2" class="ltx_tr">
<th id="S4.T7.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T7.1.3.2.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Wang
et al<span class="ltx_text">.</span><span id="S4.T7.1.3.2.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib185" title="" class="ltx_ref">2020c</a>; Duan
et al<span class="ltx_text">.</span><span id="S4.T7.1.3.2.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib42" title="" class="ltx_ref">2021</a>; Yang
et al<span class="ltx_text">.</span><span id="S4.T7.1.3.2.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib200" title="" class="ltx_ref">2020b</a><span id="S4.T7.1.3.2.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S4.T7.1.3.2.2" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.3.2.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.3.2.3" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.3.2.4" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.3.2.5" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.3.2.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.3.2.6" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.3.2.6.1" class="ltx_text" style="font-size:90%;">Client Selection</span></td>
</tr>
<tr id="S4.T7.1.4.3" class="ltx_tr">
<th id="S4.T7.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T7.1.4.3.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Papadaki et al<span class="ltx_text">.</span><span id="S4.T7.1.4.3.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib147" title="" class="ltx_ref">2021</a><span id="S4.T7.1.4.3.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S4.T7.1.4.3.2" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.4.3.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.4.3.3" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.4.3.4" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.4.3.4.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.4.3.5" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.4.3.6" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.4.3.6.1" class="ltx_text" style="font-size:90%;">Agnostic approach</span></td>
</tr>
<tr id="S4.T7.1.5.4" class="ltx_tr">
<th id="S4.T7.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T7.1.5.4.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Du
et al<span class="ltx_text">.</span><span id="S4.T7.1.5.4.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib41" title="" class="ltx_ref">2021</a><span id="S4.T7.1.5.4.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S4.T7.1.5.4.2" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.5.4.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.5.4.3" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.5.4.4" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.5.4.4.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.5.4.5" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.5.4.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.5.4.6" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.5.4.6.1" class="ltx_text" style="font-size:90%;">Agnostic approach</span></td>
</tr>
<tr id="S4.T7.1.6.5" class="ltx_tr">
<th id="S4.T7.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T7.1.6.5.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Mohri
et al<span class="ltx_text">.</span><span id="S4.T7.1.6.5.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib137" title="" class="ltx_ref">2019</a>; Hu
et al<span class="ltx_text">.</span><span id="S4.T7.1.6.5.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib77" title="" class="ltx_ref">2020</a><span id="S4.T7.1.6.5.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S4.T7.1.6.5.2" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.6.5.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.6.5.3" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.6.5.4" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.6.5.5" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.6.5.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.6.5.6" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.6.5.6.1" class="ltx_text" style="font-size:90%;">Agnostic approach</span></td>
</tr>
<tr id="S4.T7.1.7.6" class="ltx_tr">
<th id="S4.T7.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T7.1.7.6.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Ezzeldin et al<span class="ltx_text">.</span><span id="S4.T7.1.7.6.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib47" title="" class="ltx_ref">2021</a><span id="S4.T7.1.7.6.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S4.T7.1.7.6.2" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.7.6.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.7.6.3" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.7.6.4" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.7.6.4.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.7.6.5" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.7.6.6" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.7.6.6.1" class="ltx_text" style="font-size:90%;">Reweight</span></td>
</tr>
<tr id="S4.T7.1.8.7" class="ltx_tr">
<th id="S4.T7.1.8.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T7.1.8.7.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Li
et al<span class="ltx_text">.</span><span id="S4.T7.1.8.7.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib115" title="" class="ltx_ref">2019b</a>; Huang
et al<span class="ltx_text">.</span><span id="S4.T7.1.8.7.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib78" title="" class="ltx_ref">2020a</a><span id="S4.T7.1.8.7.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S4.T7.1.8.7.2" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.8.7.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.8.7.3" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.8.7.4" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.8.7.5" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.8.7.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.8.7.6" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.8.7.6.1" class="ltx_text" style="font-size:90%;">Reweight</span></td>
</tr>
<tr id="S4.T7.1.9.8" class="ltx_tr">
<th id="S4.T7.1.9.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T7.1.9.8.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Kanaparthy et al<span class="ltx_text">.</span><span id="S4.T7.1.9.8.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib96" title="" class="ltx_ref">2022</a>; G’alvez et al<span class="ltx_text">.</span><span id="S4.T7.1.9.8.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib57" title="" class="ltx_ref">2021</a>; Yue
et al<span class="ltx_text">.</span><span id="S4.T7.1.9.8.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib211" title="" class="ltx_ref">2021</a><span id="S4.T7.1.9.8.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S4.T7.1.9.8.2" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.9.8.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.9.8.3" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.9.8.4" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.9.8.4.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.9.8.5" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.9.8.6" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.9.8.6.1" class="ltx_text" style="font-size:90%;">Regularization</span></td>
</tr>
<tr id="S4.T7.1.10.9" class="ltx_tr">
<th id="S4.T7.1.10.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T7.1.10.9.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Mansour
et al<span class="ltx_text">.</span><span id="S4.T7.1.10.9.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib127" title="" class="ltx_ref">2020</a>; Ghosh
et al<span class="ltx_text">.</span><span id="S4.T7.1.10.9.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib62" title="" class="ltx_ref">2020</a>; Sattler
et al<span class="ltx_text">.</span><span id="S4.T7.1.10.9.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib159" title="" class="ltx_ref">2020</a>; Briggs
et al<span class="ltx_text">.</span><span id="S4.T7.1.10.9.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib19" title="" class="ltx_ref">2020</a><span id="S4.T7.1.10.9.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S4.T7.1.10.9.2" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.10.9.3" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.10.9.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.10.9.4" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.10.9.5" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.10.9.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.10.9.6" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.10.9.6.1" class="ltx_text" style="font-size:90%;">Cluster</span></td>
</tr>
<tr id="S4.T7.1.11.10" class="ltx_tr">
<th id="S4.T7.1.11.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T7.1.11.10.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Mansour
et al<span class="ltx_text">.</span><span id="S4.T7.1.11.10.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib127" title="" class="ltx_ref">2020</a>; Hanzely and
Richtárik<span id="S4.T7.1.11.10.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib71" title="" class="ltx_ref">2021</a>; Deng
et al<span class="ltx_text">.</span><span id="S4.T7.1.11.10.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib37" title="" class="ltx_ref">2020</a>; Zhang et al<span class="ltx_text">.</span><span id="S4.T7.1.11.10.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib223" title="" class="ltx_ref">2020d</a><span id="S4.T7.1.11.10.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S4.T7.1.11.10.2" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.11.10.3" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.11.10.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.11.10.4" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.11.10.5" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.11.10.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.11.10.6" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.11.10.6.1" class="ltx_text" style="font-size:90%;">Model interpolation</span></td>
</tr>
<tr id="S4.T7.1.12.11" class="ltx_tr">
<th id="S4.T7.1.12.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T7.1.12.11.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Smith
et al<span class="ltx_text">.</span><span id="S4.T7.1.12.11.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib169" title="" class="ltx_ref">2017</a>; Agarwal
et al<span class="ltx_text">.</span><span id="S4.T7.1.12.11.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib4" title="" class="ltx_ref">2020</a>; Liang et al<span class="ltx_text">.</span><span id="S4.T7.1.12.11.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib117" title="" class="ltx_ref">2020</a>; Dinh
et al<span class="ltx_text">.</span><span id="S4.T7.1.12.11.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib39" title="" class="ltx_ref">2021</a><span id="S4.T7.1.12.11.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S4.T7.1.12.11.2" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.12.11.3" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.12.11.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.12.11.4" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.12.11.5" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.12.11.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.12.11.6" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.12.11.6.1" class="ltx_text" style="font-size:90%;">Multi-task learning</span></td>
</tr>
<tr id="S4.T7.1.13.12" class="ltx_tr">
<th id="S4.T7.1.13.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T7.1.13.12.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Liang et al<span class="ltx_text">.</span><span id="S4.T7.1.13.12.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib117" title="" class="ltx_ref">2020</a>; Chen and Chao<span id="S4.T7.1.13.12.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib26" title="" class="ltx_ref">2021</a><span id="S4.T7.1.13.12.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S4.T7.1.13.12.2" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.13.12.3" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.13.12.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.13.12.4" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.13.12.5" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.13.12.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.13.12.6" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.13.12.6.1" class="ltx_text" style="font-size:90%;">Parameter decoupling</span></td>
</tr>
<tr id="S4.T7.1.14.13" class="ltx_tr">
<th id="S4.T7.1.14.13.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T7.1.14.13.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Liu
et al<span class="ltx_text">.</span><span id="S4.T7.1.14.13.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib120" title="" class="ltx_ref">2020</a>; Li and Wang<span id="S4.T7.1.14.13.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib111" title="" class="ltx_ref">2019</a><span id="S4.T7.1.14.13.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S4.T7.1.14.13.2" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.14.13.3" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.14.13.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.14.13.4" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.14.13.5" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.14.13.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.14.13.6" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.14.13.6.1" class="ltx_text" style="font-size:90%;">Transfer learning</span></td>
</tr>
<tr id="S4.T7.1.15.14" class="ltx_tr">
<th id="S4.T7.1.15.14.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T7.1.15.14.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Li et al<span class="ltx_text">.</span><span id="S4.T7.1.15.14.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib114" title="" class="ltx_ref">2020</a>; Shoham et al<span class="ltx_text">.</span><span id="S4.T7.1.15.14.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib165" title="" class="ltx_ref">2019</a>; Yao and Sun<span id="S4.T7.1.15.14.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib206" title="" class="ltx_ref">2020</a><span id="S4.T7.1.15.14.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S4.T7.1.15.14.2" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.15.14.3" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.15.14.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.15.14.4" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.15.14.5" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.15.14.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.15.14.6" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.15.14.6.1" class="ltx_text" style="font-size:90%;">Regularization</span></td>
</tr>
<tr id="S4.T7.1.16.15" class="ltx_tr">
<th id="S4.T7.1.16.15.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T7.1.16.15.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Fallah
et al<span class="ltx_text">.</span><span id="S4.T7.1.16.15.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib48" title="" class="ltx_ref">2020</a>; Khodak
et al<span class="ltx_text">.</span><span id="S4.T7.1.16.15.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib101" title="" class="ltx_ref">2019</a>; Jiang
et al<span class="ltx_text">.</span><span id="S4.T7.1.16.15.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib85" title="" class="ltx_ref">2019</a>; Singhal et al<span class="ltx_text">.</span><span id="S4.T7.1.16.15.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib168" title="" class="ltx_ref">2021</a><span id="S4.T7.1.16.15.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S4.T7.1.16.15.2" class="ltx_td ltx_border_bb" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.16.15.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.16.15.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.16.15.4" class="ltx_td ltx_border_bb" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S4.T7.1.16.15.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.16.15.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S4.T7.1.16.15.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S4.T7.1.16.15.6.1" class="ltx_text" style="font-size:90%;">Meta-learning</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3. </span>Discussion</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.1" class="ltx_p">In addition to algorithmic fairness, client fairness is another concern in the FL community. Table <a href="#S4.T7" title="Table 7 ‣ 4.2.2. Personalized Models Approach ‣ 4.2. Client Fairness ‣ 4. Fairness in FL ‣ Privacy and Fairness in Federated Learning: on the Perspective of Trade-off" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> enumerated various works on these two topics. Regarding client fairness, the single model approach focuses on smoothing data heterogeneity, where it is easy to implement and can be added to the general FL paradigm since it only needs modest modification. On the downside, the single model approach is less effective than personalized approaches in terms of capturing local data distribution and may be insufficient when the data distributions vary significantly between clients. Additionally, the single-model approach does not allow clients to customize their models.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Discussion of fairness in FL</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">There are two definitions of fairness in FL, <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_italic">client fairness</span> and <span id="S4.SS3.p1.1.2" class="ltx_text ltx_font_italic">algorithmic fairness</span>. <span id="S4.SS3.p1.1.3" class="ltx_text ltx_font_italic">Algorithmic fairness</span> has been extensively studied in centralized machine learning. These algorithms presuppose centralized access to data, however, one virtue of FL is data never leaves the device. This means neither the server nor any client gains centralized access to the training data. Therefore, generalizing the fair learning algorithms to FL is not trivial. On the one hand, data is stored locally in FL. The server cannot directly access the local data of clients. Hence, server-side debiasing is not a viable solution. On the other hand, debiasing on the client side is ineffective due to the inadequate data, which can hardly represent the global data distribution <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib130" title="" class="ltx_ref">2017</a>)</cite>. There is no guarantee that model debiased with local data will generalize to the global distribution. The non-i.i.d data distributions further complicated this problem <cite class="ltx_cite ltx_citemacro_citep">(Kairouz
et al<span class="ltx_text">.</span>, <a href="#bib.bib90" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p"><span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_italic">Client fairness</span> is tailored to FL and stems from the non-i.i.d data. Each client sampled the training data from a distinct distribution. In this case, the vanilla FL protocol, <span id="S4.SS3.p2.1.2" class="ltx_text ltx_font_italic">FedAvg</span>, fails to train a model to fits clients’ data distribution. Various methods have been proposed to alleviate this. From the data aspect, <cite class="ltx_cite ltx_citemacro_citep">(Zhao
et al<span class="ltx_text">.</span>, <a href="#bib.bib229" title="" class="ltx_ref">2018a</a>; Jeong
et al<span class="ltx_text">.</span>, <a href="#bib.bib84" title="" class="ltx_ref">2018</a>; Hao et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2021</a>)</cite> proposed to augment client data to yield an i.i.d dataset. <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib185" title="" class="ltx_ref">2020c</a>; Yang
et al<span class="ltx_text">.</span>, <a href="#bib.bib200" title="" class="ltx_ref">2020b</a>; Duan
et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2021</a>)</cite> proposed to select participant clients to form a more homogeneous distribution. However, their methods did not consider the possible algorithmic fairness issues and may introduce bias to the model by choosing specific clients at a higher probability than others. From the model perspective, training different models for different clients seems a natural solution to the non-i.i.d. challenge. The core idea is to train global data collaboratively and then personalize it to local data distribution.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Interactions between Privacy and Fairness</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">As shown in Fig <a href="#S5.F3" title="Figure 3 ‣ 5. Interactions between Privacy and Fairness ‣ Privacy and Fairness in Federated Learning: on the Perspective of Trade-off" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, privacy and fairness are intertwined. On the one hand, <span id="S5.p1.1.1" class="ltx_text ltx_font_italic">fairness comes at the cost of privacy</span>. A fair model is trained to perform equally on data from different groups, which incurs overfit problems and consequently increases the privacy risk <cite class="ltx_cite ltx_citemacro_citep">(Chang and Shokri, <a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite>. On the other hand, <span id="S5.p1.1.2" class="ltx_text ltx_font_italic">privacy also harms fairness</span>. Several works <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2019</a>; Kuppam et al<span class="ltx_text">.</span>, <a href="#bib.bib106" title="" class="ltx_ref">2020</a>; Tran
et al<span class="ltx_text">.</span>, <a href="#bib.bib178" title="" class="ltx_ref">2021b</a>; Sanyal
et al<span class="ltx_text">.</span>, <a href="#bib.bib157" title="" class="ltx_ref">2022</a>)</cite> inconsistent reductions in accuracy caused by private mechanisms on classification <cite class="ltx_cite ltx_citemacro_citep">(Farrand et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite> and generative tasks <cite class="ltx_cite ltx_citemacro_citep">(Ganev
et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2022</a>)</cite>. Due to the tension between fairness and privacy, researchers often need to make trade-offs between these two notions. The trade-off could be increasing privacy protection at the expense of fairness, i.e., adopting relaxed fairness notions instead of exact notions or the opposite way. Table <a href="#S5.T8" title="Table 8 ‣ 5. Interactions between Privacy and Fairness ‣ Privacy and Fairness in Federated Learning: on the Perspective of Trade-off" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> gives various trade-offs between privacy and fairness. On the basis of the adopted privacy/fairness notions, the trade-offs can be divided into two categories. The first type sacrifices fairness for solid privacy protection, i.e. <math id="S5.p1.1.m1.1" class="ltx_Math" alttext="epsilon" display="inline"><semantics id="S5.p1.1.m1.1a"><mrow id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml"><mi id="S5.p1.1.m1.1.1.2" xref="S5.p1.1.m1.1.1.2.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.1" xref="S5.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.p1.1.m1.1.1.3" xref="S5.p1.1.m1.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.1a" xref="S5.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.p1.1.m1.1.1.4" xref="S5.p1.1.m1.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.1b" xref="S5.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.p1.1.m1.1.1.5" xref="S5.p1.1.m1.1.1.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.1c" xref="S5.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.p1.1.m1.1.1.6" xref="S5.p1.1.m1.1.1.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.1d" xref="S5.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.p1.1.m1.1.1.7" xref="S5.p1.1.m1.1.1.7.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.1e" xref="S5.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.p1.1.m1.1.1.8" xref="S5.p1.1.m1.1.1.8.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><apply id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1"><times id="S5.p1.1.m1.1.1.1.cmml" xref="S5.p1.1.m1.1.1.1"></times><ci id="S5.p1.1.m1.1.1.2.cmml" xref="S5.p1.1.m1.1.1.2">𝑒</ci><ci id="S5.p1.1.m1.1.1.3.cmml" xref="S5.p1.1.m1.1.1.3">𝑝</ci><ci id="S5.p1.1.m1.1.1.4.cmml" xref="S5.p1.1.m1.1.1.4">𝑠</ci><ci id="S5.p1.1.m1.1.1.5.cmml" xref="S5.p1.1.m1.1.1.5">𝑖</ci><ci id="S5.p1.1.m1.1.1.6.cmml" xref="S5.p1.1.m1.1.1.6">𝑙</ci><ci id="S5.p1.1.m1.1.1.7.cmml" xref="S5.p1.1.m1.1.1.7">𝑜</ci><ci id="S5.p1.1.m1.1.1.8.cmml" xref="S5.p1.1.m1.1.1.8">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">epsilon</annotation></semantics></math>-DP. The second form prioritizes fairness over privacy and employs relaxed DP in order to accommodate exact fairness.</p>
</div>
<figure id="S5.F3" class="ltx_figure"><img src="/html/2306.14123/assets/Privacy_Fairness_and_Accuracy_Trade-off.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="314" height="199" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Privacy, fairness, and accuracy trade-offs in deep learning: 1) privacy comes at the cost of accuracy; 2) fairness comes at the cost of accuracy; and 3) privacy interacts with fairness <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib225" title="" class="ltx_ref">2021</a>)</cite></figcaption>
</figure>
<figure id="S5.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8. </span>Private and Fair Learning</figcaption>
<table id="S5.T8.13" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T8.13.14.1" class="ltx_tr">
<td id="S5.T8.13.14.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;" rowspan="2"><span id="S5.T8.13.14.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Reference</span></td>
<td id="S5.T8.13.14.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;" rowspan="2"><span id="S5.T8.13.14.1.2.1" class="ltx_text" style="font-size:90%;">

<span id="S5.T8.13.14.1.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T8.13.14.1.2.1.1.1" class="ltx_tr">
<span id="S5.T8.13.14.1.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.14.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">Privacy</span></span></span>
<span id="S5.T8.13.14.1.2.1.1.2" class="ltx_tr">
<span id="S5.T8.13.14.1.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.14.1.2.1.1.2.1.1" class="ltx_text ltx_font_bold">notion</span></span></span>
</span></span></td>
<td id="S5.T8.13.14.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;" rowspan="2"><span id="S5.T8.13.14.1.3.1" class="ltx_text" style="font-size:90%;">

<span id="S5.T8.13.14.1.3.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T8.13.14.1.3.1.1.1" class="ltx_tr">
<span id="S5.T8.13.14.1.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.14.1.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Fairness</span></span></span>
<span id="S5.T8.13.14.1.3.1.1.2" class="ltx_tr">
<span id="S5.T8.13.14.1.3.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.14.1.3.1.1.2.1.1" class="ltx_text ltx_font_bold">notion</span></span></span>
</span></span></td>
<td id="S5.T8.13.14.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;" colspan="2"><span id="S5.T8.13.14.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Techniques to achieve</span></td>
<td id="S5.T8.13.14.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;" rowspan="2"><span id="S5.T8.13.14.1.5.1" class="ltx_text" style="font-size:90%;">
<span id="S5.T8.13.14.1.5.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T8.13.14.1.5.1.1.1" class="ltx_tr">
<span id="S5.T8.13.14.1.5.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.14.1.5.1.1.1.1.1" class="ltx_text ltx_font_bold">Trade-off</span></span></span>
<span id="S5.T8.13.14.1.5.1.1.2" class="ltx_tr">
<span id="S5.T8.13.14.1.5.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.14.1.5.1.1.2.1.1" class="ltx_text ltx_font_bold">type</span></span></span>
</span></span></td>
</tr>
<tr id="S5.T8.13.15.2" class="ltx_tr">
<td id="S5.T8.13.15.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.15.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Privacy</span></td>
<td id="S5.T8.13.15.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.15.2.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Fairness</span></td>
</tr>
<tr id="S5.T8.2.2" class="ltx_tr">
<td id="S5.T8.2.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T8.2.2.3.1.1" class="ltx_text" style="font-size:90%;">(</span>Cummings et al<span class="ltx_text">.</span><span id="S5.T8.2.2.3.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib35" title="" class="ltx_ref">2019</a><span id="S5.T8.2.2.3.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S5.T8.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<math id="S5.T8.1.1.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S5.T8.1.1.1.m1.1a"><mi mathsize="90%" id="S5.T8.1.1.1.m1.1.1" xref="S5.T8.1.1.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S5.T8.1.1.1.m1.1b"><ci id="S5.T8.1.1.1.m1.1.1.cmml" xref="S5.T8.1.1.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.1.1.1.m1.1c">\epsilon</annotation></semantics></math><span id="S5.T8.1.1.1.1" class="ltx_text" style="font-size:90%;">-DP</span>
</td>
<td id="S5.T8.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<math id="S5.T8.2.2.2.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.T8.2.2.2.m1.1a"><mi mathsize="90%" id="S5.T8.2.2.2.m1.1.1" xref="S5.T8.2.2.2.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.T8.2.2.2.m1.1b"><ci id="S5.T8.2.2.2.m1.1.1.cmml" xref="S5.T8.2.2.2.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.2.2.2.m1.1c">\alpha</annotation></semantics></math><span id="S5.T8.2.2.2.1" class="ltx_text" style="font-size:90%;">-Discrimination</span>
</td>
<td id="S5.T8.2.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<table id="S5.T8.2.2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.2.2.4.1.1" class="ltx_tr">
<td id="S5.T8.2.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.2.2.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Exponential</span></td>
</tr>
<tr id="S5.T8.2.2.4.1.2" class="ltx_tr">
<td id="S5.T8.2.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.2.2.4.1.2.1.1" class="ltx_text" style="font-size:90%;">mechanism</span></td>
</tr>
</table>
</td>
<td id="S5.T8.2.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<table id="S5.T8.2.2.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.2.2.5.1.1" class="ltx_tr">
<td id="S5.T8.2.2.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.2.2.5.1.1.1.1" class="ltx_text" style="font-size:90%;">Minimize</span></td>
</tr>
<tr id="S5.T8.2.2.5.1.2" class="ltx_tr">
<td id="S5.T8.2.2.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.2.2.5.1.2.1.1" class="ltx_text" style="font-size:90%;">discrimination scores</span></td>
</tr>
</table>
</td>
<td id="S5.T8.2.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.2.2.6.1" class="ltx_text" style="font-size:90%;">I</span></td>
</tr>
<tr id="S5.T8.3.3" class="ltx_tr">
<td id="S5.T8.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T8.3.3.2.1.1" class="ltx_text" style="font-size:90%;">(</span>Xu et al<span class="ltx_text">.</span><span id="S5.T8.3.3.2.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib197" title="" class="ltx_ref">2019b</a><span id="S5.T8.3.3.2.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S5.T8.3.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<math id="S5.T8.3.3.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S5.T8.3.3.1.m1.1a"><mi mathsize="90%" id="S5.T8.3.3.1.m1.1.1" xref="S5.T8.3.3.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S5.T8.3.3.1.m1.1b"><ci id="S5.T8.3.3.1.m1.1.1.cmml" xref="S5.T8.3.3.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.3.3.1.m1.1c">\epsilon</annotation></semantics></math><span id="S5.T8.3.3.1.1" class="ltx_text" style="font-size:90%;">-DP</span>
</td>
<td id="S5.T8.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<table id="S5.T8.3.3.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.3.3.3.1.1" class="ltx_tr">
<td id="S5.T8.3.3.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.3.3.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Decision boundary</span></td>
</tr>
<tr id="S5.T8.3.3.3.1.2" class="ltx_tr">
<td id="S5.T8.3.3.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.3.3.3.1.2.1.1" class="ltx_text" style="font-size:90%;">fairness</span></td>
</tr>
</table>
</td>
<td id="S5.T8.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<table id="S5.T8.3.3.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.3.3.4.1.1" class="ltx_tr">
<td id="S5.T8.3.3.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.3.3.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Functional</span></td>
</tr>
<tr id="S5.T8.3.3.4.1.2" class="ltx_tr">
<td id="S5.T8.3.3.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.3.3.4.1.2.1.1" class="ltx_text" style="font-size:90%;">mechanism</span></td>
</tr>
</table>
</td>
<td id="S5.T8.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.3.3.5.1" class="ltx_text" style="font-size:90%;">Fairness constraints</span></td>
<td id="S5.T8.3.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.3.3.6.1" class="ltx_text" style="font-size:90%;">I</span></td>
</tr>
<tr id="S5.T8.5.5" class="ltx_tr">
<td id="S5.T8.5.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T8.5.5.3.1.1" class="ltx_text" style="font-size:90%;">(</span>Mozannar
et al<span class="ltx_text">.</span><span id="S5.T8.5.5.3.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib139" title="" class="ltx_ref">2020</a><span id="S5.T8.5.5.3.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S5.T8.4.4.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<math id="S5.T8.4.4.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S5.T8.4.4.1.m1.1a"><mi mathsize="90%" id="S5.T8.4.4.1.m1.1.1" xref="S5.T8.4.4.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S5.T8.4.4.1.m1.1b"><ci id="S5.T8.4.4.1.m1.1.1.cmml" xref="S5.T8.4.4.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.4.4.1.m1.1c">\epsilon</annotation></semantics></math><span id="S5.T8.4.4.1.1" class="ltx_text" style="font-size:90%;">-DP</span>
</td>
<td id="S5.T8.5.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<math id="S5.T8.5.5.2.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.T8.5.5.2.m1.1a"><mi mathsize="90%" id="S5.T8.5.5.2.m1.1.1" xref="S5.T8.5.5.2.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.T8.5.5.2.m1.1b"><ci id="S5.T8.5.5.2.m1.1.1.cmml" xref="S5.T8.5.5.2.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.5.5.2.m1.1c">\alpha</annotation></semantics></math><span id="S5.T8.5.5.2.1" class="ltx_text" style="font-size:90%;">-Equal opportunity</span>
</td>
<td id="S5.T8.5.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.5.5.4.1" class="ltx_text" style="font-size:90%;">Local DP</span></td>
<td id="S5.T8.5.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<table id="S5.T8.5.5.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.5.5.5.1.1" class="ltx_tr">
<td id="S5.T8.5.5.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.5.5.5.1.1.1.1" class="ltx_text" style="font-size:90%;">Post-processing</span></td>
</tr>
</table>
</td>
<td id="S5.T8.5.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.5.5.6.1" class="ltx_text" style="font-size:90%;">I</span></td>
</tr>
<tr id="S5.T8.6.6" class="ltx_tr">
<td id="S5.T8.6.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T8.6.6.2.1.1" class="ltx_text" style="font-size:90%;">(</span>Lamy
et al<span class="ltx_text">.</span><span id="S5.T8.6.6.2.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib108" title="" class="ltx_ref">2019</a><span id="S5.T8.6.6.2.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S5.T8.6.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<math id="S5.T8.6.6.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S5.T8.6.6.1.m1.1a"><mi mathsize="90%" id="S5.T8.6.6.1.m1.1.1" xref="S5.T8.6.6.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S5.T8.6.6.1.m1.1b"><ci id="S5.T8.6.6.1.m1.1.1.cmml" xref="S5.T8.6.6.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.6.6.1.m1.1c">\epsilon</annotation></semantics></math><span id="S5.T8.6.6.1.1" class="ltx_text" style="font-size:90%;">-DP</span>
</td>
<td id="S5.T8.6.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<table id="S5.T8.6.6.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.6.6.3.1.1" class="ltx_tr">
<td id="S5.T8.6.6.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.6.6.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Equal odds &amp;</span></td>
</tr>
<tr id="S5.T8.6.6.3.1.2" class="ltx_tr">
<td id="S5.T8.6.6.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.6.6.3.1.2.1.1" class="ltx_text" style="font-size:90%;">Demographic parity</span></td>
</tr>
</table>
</td>
<td id="S5.T8.6.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<table id="S5.T8.6.6.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.6.6.4.1.1" class="ltx_tr">
<td id="S5.T8.6.6.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.6.6.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Class conditional</span></td>
</tr>
<tr id="S5.T8.6.6.4.1.2" class="ltx_tr">
<td id="S5.T8.6.6.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.6.6.4.1.2.1.1" class="ltx_text" style="font-size:90%;">noise</span></td>
</tr>
</table>
</td>
<td id="S5.T8.6.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.6.6.5.1" class="ltx_text" style="font-size:90%;">Fairness constraints</span></td>
<td id="S5.T8.6.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.6.6.6.1" class="ltx_text" style="font-size:90%;">I</span></td>
</tr>
<tr id="S5.T8.8.8" class="ltx_tr">
<td id="S5.T8.8.8.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T8.8.8.3.1.1" class="ltx_text" style="font-size:90%;">(</span>Ding
et al<span class="ltx_text">.</span><span id="S5.T8.8.8.3.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib38" title="" class="ltx_ref">2020</a><span id="S5.T8.8.8.3.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S5.T8.8.8.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<table id="S5.T8.8.8.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.7.7.1.1.1" class="ltx_tr">
<td id="S5.T8.7.7.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;">
<math id="S5.T8.7.7.1.1.1.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S5.T8.7.7.1.1.1.1.m1.1a"><mi mathsize="90%" id="S5.T8.7.7.1.1.1.1.m1.1.1" xref="S5.T8.7.7.1.1.1.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S5.T8.7.7.1.1.1.1.m1.1b"><ci id="S5.T8.7.7.1.1.1.1.m1.1.1.cmml" xref="S5.T8.7.7.1.1.1.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.7.7.1.1.1.1.m1.1c">\epsilon</annotation></semantics></math><span id="S5.T8.7.7.1.1.1.1.1" class="ltx_text" style="font-size:90%;">-DP &amp;</span>
</td>
</tr>
<tr id="S5.T8.8.8.2.2.2" class="ltx_tr">
<td id="S5.T8.8.8.2.2.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;">
<math id="S5.T8.8.8.2.2.2.1.m1.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S5.T8.8.8.2.2.2.1.m1.2a"><mrow id="S5.T8.8.8.2.2.2.1.m1.2.3.2" xref="S5.T8.8.8.2.2.2.1.m1.2.3.1.cmml"><mo maxsize="90%" minsize="90%" id="S5.T8.8.8.2.2.2.1.m1.2.3.2.1" xref="S5.T8.8.8.2.2.2.1.m1.2.3.1.cmml">(</mo><mi mathsize="90%" id="S5.T8.8.8.2.2.2.1.m1.1.1" xref="S5.T8.8.8.2.2.2.1.m1.1.1.cmml">ϵ</mi><mo mathsize="90%" id="S5.T8.8.8.2.2.2.1.m1.2.3.2.2" xref="S5.T8.8.8.2.2.2.1.m1.2.3.1.cmml">,</mo><mi mathsize="90%" id="S5.T8.8.8.2.2.2.1.m1.2.2" xref="S5.T8.8.8.2.2.2.1.m1.2.2.cmml">δ</mi><mo maxsize="90%" minsize="90%" id="S5.T8.8.8.2.2.2.1.m1.2.3.2.3" xref="S5.T8.8.8.2.2.2.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T8.8.8.2.2.2.1.m1.2b"><interval closure="open" id="S5.T8.8.8.2.2.2.1.m1.2.3.1.cmml" xref="S5.T8.8.8.2.2.2.1.m1.2.3.2"><ci id="S5.T8.8.8.2.2.2.1.m1.1.1.cmml" xref="S5.T8.8.8.2.2.2.1.m1.1.1">italic-ϵ</ci><ci id="S5.T8.8.8.2.2.2.1.m1.2.2.cmml" xref="S5.T8.8.8.2.2.2.1.m1.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.8.8.2.2.2.1.m1.2c">(\epsilon,\delta)</annotation></semantics></math><span id="S5.T8.8.8.2.2.2.1.1" class="ltx_text" style="font-size:90%;">-DP</span>
</td>
</tr>
</table>
</td>
<td id="S5.T8.8.8.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<table id="S5.T8.8.8.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.8.8.4.1.1" class="ltx_tr">
<td id="S5.T8.8.8.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.8.8.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Decision boundary</span></td>
</tr>
<tr id="S5.T8.8.8.4.1.2" class="ltx_tr">
<td id="S5.T8.8.8.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.8.8.4.1.2.1.1" class="ltx_text" style="font-size:90%;">fairness</span></td>
</tr>
</table>
</td>
<td id="S5.T8.8.8.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<table id="S5.T8.8.8.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.8.8.5.1.1" class="ltx_tr">
<td id="S5.T8.8.8.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.8.8.5.1.1.1.1" class="ltx_text" style="font-size:90%;">Functional</span></td>
</tr>
<tr id="S5.T8.8.8.5.1.2" class="ltx_tr">
<td id="S5.T8.8.8.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.8.8.5.1.2.1.1" class="ltx_text" style="font-size:90%;">mechanism</span></td>
</tr>
</table>
</td>
<td id="S5.T8.8.8.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.8.8.6.1" class="ltx_text" style="font-size:90%;">Fairness constraints</span></td>
<td id="S5.T8.8.8.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.8.8.7.1" class="ltx_text" style="font-size:90%;">I</span></td>
</tr>
<tr id="S5.T8.10.10" class="ltx_tr">
<td id="S5.T8.10.10.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T8.10.10.3.1.1" class="ltx_text" style="font-size:90%;">(</span>Jagielski et al<span class="ltx_text">.</span><span id="S5.T8.10.10.3.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib82" title="" class="ltx_ref">2019</a><span id="S5.T8.10.10.3.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S5.T8.9.9.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<math id="S5.T8.9.9.1.m1.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S5.T8.9.9.1.m1.2a"><mrow id="S5.T8.9.9.1.m1.2.3.2" xref="S5.T8.9.9.1.m1.2.3.1.cmml"><mo maxsize="90%" minsize="90%" id="S5.T8.9.9.1.m1.2.3.2.1" xref="S5.T8.9.9.1.m1.2.3.1.cmml">(</mo><mi mathsize="90%" id="S5.T8.9.9.1.m1.1.1" xref="S5.T8.9.9.1.m1.1.1.cmml">ϵ</mi><mo mathsize="90%" id="S5.T8.9.9.1.m1.2.3.2.2" xref="S5.T8.9.9.1.m1.2.3.1.cmml">,</mo><mi mathsize="90%" id="S5.T8.9.9.1.m1.2.2" xref="S5.T8.9.9.1.m1.2.2.cmml">δ</mi><mo maxsize="90%" minsize="90%" id="S5.T8.9.9.1.m1.2.3.2.3" xref="S5.T8.9.9.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T8.9.9.1.m1.2b"><interval closure="open" id="S5.T8.9.9.1.m1.2.3.1.cmml" xref="S5.T8.9.9.1.m1.2.3.2"><ci id="S5.T8.9.9.1.m1.1.1.cmml" xref="S5.T8.9.9.1.m1.1.1">italic-ϵ</ci><ci id="S5.T8.9.9.1.m1.2.2.cmml" xref="S5.T8.9.9.1.m1.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.9.9.1.m1.2c">(\epsilon,\delta)</annotation></semantics></math><span id="S5.T8.9.9.1.1" class="ltx_text" style="font-size:90%;">-DP</span>
</td>
<td id="S5.T8.10.10.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<math id="S5.T8.10.10.2.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.T8.10.10.2.m1.1a"><mi mathsize="90%" id="S5.T8.10.10.2.m1.1.1" xref="S5.T8.10.10.2.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.T8.10.10.2.m1.1b"><ci id="S5.T8.10.10.2.m1.1.1.cmml" xref="S5.T8.10.10.2.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.10.10.2.m1.1c">\alpha</annotation></semantics></math><span id="S5.T8.10.10.2.1" class="ltx_text" style="font-size:90%;">-Equal opportunity</span>
</td>
<td id="S5.T8.10.10.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<table id="S5.T8.10.10.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.10.10.4.1.1" class="ltx_tr">
<td id="S5.T8.10.10.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.10.10.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Exponential</span></td>
</tr>
<tr id="S5.T8.10.10.4.1.2" class="ltx_tr">
<td id="S5.T8.10.10.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.10.10.4.1.2.1.1" class="ltx_text" style="font-size:90%;">mechanism</span></td>
</tr>
<tr id="S5.T8.10.10.4.1.3" class="ltx_tr">
<td id="S5.T8.10.10.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.10.10.4.1.3.1.1" class="ltx_text" style="font-size:90%;">&amp; Laplace noise</span></td>
</tr>
</table>
</td>
<td id="S5.T8.10.10.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.10.10.5.1" class="ltx_text" style="font-size:90%;">Fairness constraints</span></td>
<td id="S5.T8.10.10.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.10.10.6.1" class="ltx_text" style="font-size:90%;">/</span></td>
</tr>
<tr id="S5.T8.11.11" class="ltx_tr">
<td id="S5.T8.11.11.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T8.11.11.2.1.1" class="ltx_text" style="font-size:90%;">(</span>Lowy
et al<span class="ltx_text">.</span><span id="S5.T8.11.11.2.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib123" title="" class="ltx_ref">2023</a><span id="S5.T8.11.11.2.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S5.T8.11.11.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<math id="S5.T8.11.11.1.m1.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S5.T8.11.11.1.m1.2a"><mrow id="S5.T8.11.11.1.m1.2.3.2" xref="S5.T8.11.11.1.m1.2.3.1.cmml"><mo maxsize="90%" minsize="90%" id="S5.T8.11.11.1.m1.2.3.2.1" xref="S5.T8.11.11.1.m1.2.3.1.cmml">(</mo><mi mathsize="90%" id="S5.T8.11.11.1.m1.1.1" xref="S5.T8.11.11.1.m1.1.1.cmml">ϵ</mi><mo mathsize="90%" id="S5.T8.11.11.1.m1.2.3.2.2" xref="S5.T8.11.11.1.m1.2.3.1.cmml">,</mo><mi mathsize="90%" id="S5.T8.11.11.1.m1.2.2" xref="S5.T8.11.11.1.m1.2.2.cmml">δ</mi><mo maxsize="90%" minsize="90%" id="S5.T8.11.11.1.m1.2.3.2.3" xref="S5.T8.11.11.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T8.11.11.1.m1.2b"><interval closure="open" id="S5.T8.11.11.1.m1.2.3.1.cmml" xref="S5.T8.11.11.1.m1.2.3.2"><ci id="S5.T8.11.11.1.m1.1.1.cmml" xref="S5.T8.11.11.1.m1.1.1">italic-ϵ</ci><ci id="S5.T8.11.11.1.m1.2.2.cmml" xref="S5.T8.11.11.1.m1.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.11.11.1.m1.2c">(\epsilon,\delta)</annotation></semantics></math><span id="S5.T8.11.11.1.1" class="ltx_text" style="font-size:90%;">-DP</span>
</td>
<td id="S5.T8.11.11.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<table id="S5.T8.11.11.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.11.11.3.1.1" class="ltx_tr">
<td id="S5.T8.11.11.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.11.11.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Equal odds &amp;</span></td>
</tr>
<tr id="S5.T8.11.11.3.1.2" class="ltx_tr">
<td id="S5.T8.11.11.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.11.11.3.1.2.1.1" class="ltx_text" style="font-size:90%;">Demographic parity</span></td>
</tr>
</table>
</td>
<td id="S5.T8.11.11.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.11.11.4.1" class="ltx_text" style="font-size:90%;">DP-SGDA</span></td>
<td id="S5.T8.11.11.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.11.11.5.1" class="ltx_text" style="font-size:90%;">ERMI regularizer</span></td>
<td id="S5.T8.11.11.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.11.11.6.1" class="ltx_text" style="font-size:90%;">II</span></td>
</tr>
<tr id="S5.T8.12.12" class="ltx_tr">
<td id="S5.T8.12.12.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T8.12.12.2.1.1" class="ltx_text" style="font-size:90%;">(</span>Esipova
et al<span class="ltx_text">.</span><span id="S5.T8.12.12.2.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib46" title="" class="ltx_ref">2022</a><span id="S5.T8.12.12.2.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S5.T8.12.12.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<math id="S5.T8.12.12.1.m1.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S5.T8.12.12.1.m1.2a"><mrow id="S5.T8.12.12.1.m1.2.3.2" xref="S5.T8.12.12.1.m1.2.3.1.cmml"><mo maxsize="90%" minsize="90%" id="S5.T8.12.12.1.m1.2.3.2.1" xref="S5.T8.12.12.1.m1.2.3.1.cmml">(</mo><mi mathsize="90%" id="S5.T8.12.12.1.m1.1.1" xref="S5.T8.12.12.1.m1.1.1.cmml">ϵ</mi><mo mathsize="90%" id="S5.T8.12.12.1.m1.2.3.2.2" xref="S5.T8.12.12.1.m1.2.3.1.cmml">,</mo><mi mathsize="90%" id="S5.T8.12.12.1.m1.2.2" xref="S5.T8.12.12.1.m1.2.2.cmml">δ</mi><mo maxsize="90%" minsize="90%" id="S5.T8.12.12.1.m1.2.3.2.3" xref="S5.T8.12.12.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T8.12.12.1.m1.2b"><interval closure="open" id="S5.T8.12.12.1.m1.2.3.1.cmml" xref="S5.T8.12.12.1.m1.2.3.2"><ci id="S5.T8.12.12.1.m1.1.1.cmml" xref="S5.T8.12.12.1.m1.1.1">italic-ϵ</ci><ci id="S5.T8.12.12.1.m1.2.2.cmml" xref="S5.T8.12.12.1.m1.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.12.12.1.m1.2c">(\epsilon,\delta)</annotation></semantics></math><span id="S5.T8.12.12.1.1" class="ltx_text" style="font-size:90%;">-DP</span>
</td>
<td id="S5.T8.12.12.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.12.12.3.1" class="ltx_text" style="font-size:90%;">Excessive risk gap</span></td>
<td id="S5.T8.12.12.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.12.12.4.1" class="ltx_text" style="font-size:90%;">DPSGD-Global-Adapt</span></td>
<td id="S5.T8.12.12.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.12.12.5.1" class="ltx_text" style="font-size:90%;">Gradient correction</span></td>
<td id="S5.T8.12.12.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.12.12.6.1" class="ltx_text" style="font-size:90%;">II</span></td>
</tr>
<tr id="S5.T8.13.13" class="ltx_tr">
<td id="S5.T8.13.13.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T8.13.13.2.1.1" class="ltx_text" style="font-size:90%;">(</span>Tran
et al<span class="ltx_text">.</span><span id="S5.T8.13.13.2.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib177" title="" class="ltx_ref">2021a</a><span id="S5.T8.13.13.2.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S5.T8.13.13.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<table id="S5.T8.13.13.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.13.13.1.1.1" class="ltx_tr">
<td id="S5.T8.13.13.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;">
<math id="S5.T8.13.13.1.1.1.1.m1.2" class="ltx_Math" alttext="(\alpha,\epsilon_{p})" display="inline"><semantics id="S5.T8.13.13.1.1.1.1.m1.2a"><mrow id="S5.T8.13.13.1.1.1.1.m1.2.2.1" xref="S5.T8.13.13.1.1.1.1.m1.2.2.2.cmml"><mo maxsize="90%" minsize="90%" id="S5.T8.13.13.1.1.1.1.m1.2.2.1.2" xref="S5.T8.13.13.1.1.1.1.m1.2.2.2.cmml">(</mo><mi mathsize="90%" id="S5.T8.13.13.1.1.1.1.m1.1.1" xref="S5.T8.13.13.1.1.1.1.m1.1.1.cmml">α</mi><mo mathsize="90%" id="S5.T8.13.13.1.1.1.1.m1.2.2.1.3" xref="S5.T8.13.13.1.1.1.1.m1.2.2.2.cmml">,</mo><msub id="S5.T8.13.13.1.1.1.1.m1.2.2.1.1" xref="S5.T8.13.13.1.1.1.1.m1.2.2.1.1.cmml"><mi mathsize="90%" id="S5.T8.13.13.1.1.1.1.m1.2.2.1.1.2" xref="S5.T8.13.13.1.1.1.1.m1.2.2.1.1.2.cmml">ϵ</mi><mi mathsize="90%" id="S5.T8.13.13.1.1.1.1.m1.2.2.1.1.3" xref="S5.T8.13.13.1.1.1.1.m1.2.2.1.1.3.cmml">p</mi></msub><mo maxsize="90%" minsize="90%" id="S5.T8.13.13.1.1.1.1.m1.2.2.1.4" xref="S5.T8.13.13.1.1.1.1.m1.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T8.13.13.1.1.1.1.m1.2b"><interval closure="open" id="S5.T8.13.13.1.1.1.1.m1.2.2.2.cmml" xref="S5.T8.13.13.1.1.1.1.m1.2.2.1"><ci id="S5.T8.13.13.1.1.1.1.m1.1.1.cmml" xref="S5.T8.13.13.1.1.1.1.m1.1.1">𝛼</ci><apply id="S5.T8.13.13.1.1.1.1.m1.2.2.1.1.cmml" xref="S5.T8.13.13.1.1.1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S5.T8.13.13.1.1.1.1.m1.2.2.1.1.1.cmml" xref="S5.T8.13.13.1.1.1.1.m1.2.2.1.1">subscript</csymbol><ci id="S5.T8.13.13.1.1.1.1.m1.2.2.1.1.2.cmml" xref="S5.T8.13.13.1.1.1.1.m1.2.2.1.1.2">italic-ϵ</ci><ci id="S5.T8.13.13.1.1.1.1.m1.2.2.1.1.3.cmml" xref="S5.T8.13.13.1.1.1.1.m1.2.2.1.1.3">𝑝</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.13.13.1.1.1.1.m1.2c">(\alpha,\epsilon_{p})</annotation></semantics></math><span id="S5.T8.13.13.1.1.1.1.1" class="ltx_text" style="font-size:90%;">-</span>
</td>
</tr>
<tr id="S5.T8.13.13.1.1.2" class="ltx_tr">
<td id="S5.T8.13.13.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.13.1.1.2.1.1" class="ltx_text" style="font-size:90%;">Rényi DP</span></td>
</tr>
</table>
</td>
<td id="S5.T8.13.13.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;">
<table id="S5.T8.13.13.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.13.13.3.1.1" class="ltx_tr">
<td id="S5.T8.13.13.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.13.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Equal odds,</span></td>
</tr>
<tr id="S5.T8.13.13.3.1.2" class="ltx_tr">
<td id="S5.T8.13.13.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.13.3.1.2.1.1" class="ltx_text" style="font-size:90%;">Accuracy parity</span></td>
</tr>
<tr id="S5.T8.13.13.3.1.3" class="ltx_tr">
<td id="S5.T8.13.13.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.13.3.1.3.1.1" class="ltx_text" style="font-size:90%;">&amp; Demographic parity</span></td>
</tr>
</table>
</td>
<td id="S5.T8.13.13.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.13.4.1" class="ltx_text" style="font-size:90%;">DP-SGD</span></td>
<td id="S5.T8.13.13.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.13.5.1" class="ltx_text" style="font-size:90%;">Fairness constraints</span></td>
<td id="S5.T8.13.13.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.13.6.1" class="ltx_text" style="font-size:90%;">II</span></td>
</tr>
<tr id="S5.T8.13.16.3" class="ltx_tr">
<td id="S5.T8.13.16.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T8.13.16.3.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Kilbertus et al<span class="ltx_text">.</span><span id="S5.T8.13.16.3.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib102" title="" class="ltx_ref">2018</a><span id="S5.T8.13.16.3.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S5.T8.13.16.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.16.3.2.1" class="ltx_text" style="font-size:90%;">/</span></td>
<td id="S5.T8.13.16.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.16.3.3.1" class="ltx_text" style="font-size:90%;">Equal accuracy</span></td>
<td id="S5.T8.13.16.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.16.3.4.1" class="ltx_text" style="font-size:90%;">MPC</span></td>
<td id="S5.T8.13.16.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.16.3.5.1" class="ltx_text" style="font-size:90%;">Fairness constraints</span></td>
<td id="S5.T8.13.16.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.16.3.6.1" class="ltx_text" style="font-size:90%;">II</span></td>
</tr>
<tr id="S5.T8.13.17.4" class="ltx_tr">
<td id="S5.T8.13.17.4.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T8.13.17.4.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Gupta
et al<span class="ltx_text">.</span><span id="S5.T8.13.17.4.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib67" title="" class="ltx_ref">2018</a><span id="S5.T8.13.17.4.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S5.T8.13.17.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.17.4.2.1" class="ltx_text" style="font-size:90%;">/</span></td>
<td id="S5.T8.13.17.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.17.4.3.1" class="ltx_text" style="font-size:90%;">Equal opportunity</span></td>
<td id="S5.T8.13.17.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.17.4.4.1" class="ltx_text" style="font-size:90%;">Proxy attribute</span></td>
<td id="S5.T8.13.17.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.17.4.5.1" class="ltx_text" style="font-size:90%;">Post-processing</span></td>
<td id="S5.T8.13.17.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.17.4.6.1" class="ltx_text" style="font-size:90%;">II</span></td>
</tr>
<tr id="S5.T8.13.18.5" class="ltx_tr">
<td id="S5.T8.13.18.5.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T8.13.18.5.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Wang et al<span class="ltx_text">.</span><span id="S5.T8.13.18.5.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib187" title="" class="ltx_ref">2020b</a><span id="S5.T8.13.18.5.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S5.T8.13.18.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.18.5.2.1" class="ltx_text" style="font-size:90%;">/</span></td>
<td id="S5.T8.13.18.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.18.5.3.1" class="ltx_text" style="font-size:90%;">Demographic parity</span></td>
<td id="S5.T8.13.18.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.18.5.4.1" class="ltx_text" style="font-size:90%;">Noisy attribute</span></td>
<td id="S5.T8.13.18.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.18.5.5.1" class="ltx_text" style="font-size:90%;">Fairness constraints</span></td>
<td id="S5.T8.13.18.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.18.5.6.1" class="ltx_text" style="font-size:90%;">II</span></td>
</tr>
<tr id="S5.T8.13.19.6" class="ltx_tr">
<td id="S5.T8.13.19.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T8.13.19.6.1.1.1" class="ltx_text" style="font-size:90%;">(</span>Awasthi et al<span class="ltx_text">.</span><span id="S5.T8.13.19.6.1.2.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib9" title="" class="ltx_ref">2020</a><span id="S5.T8.13.19.6.1.3.3" class="ltx_text" style="font-size:90%;">)</span></cite></td>
<td id="S5.T8.13.19.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.19.6.2.1" class="ltx_text" style="font-size:90%;">/</span></td>
<td id="S5.T8.13.19.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.19.6.3.1" class="ltx_text" style="font-size:90%;">Equal odds</span></td>
<td id="S5.T8.13.19.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.19.6.4.1" class="ltx_text" style="font-size:90%;">Noisy attribute</span></td>
<td id="S5.T8.13.19.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.19.6.5.1" class="ltx_text" style="font-size:90%;">Post-processing</span></td>
<td id="S5.T8.13.19.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.8pt 2.0pt;"><span id="S5.T8.13.19.6.6.1" class="ltx_text" style="font-size:90%;">II</span></td>
</tr>
<tr id="S5.T8.13.20.7" class="ltx_tr">
<td id="S5.T8.13.20.7.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.8pt 2.0pt;" colspan="6"><span id="S5.T8.13.20.7.1.1" class="ltx_text" style="font-size:90%;">I: Trade fairness for privacy. Relaxing fairness notions to achieve purely DP</span></td>
</tr>
<tr id="S5.T8.13.21.8" class="ltx_tr">
<td id="S5.T8.13.21.8.1" class="ltx_td ltx_align_left" style="padding:1.8pt 2.0pt;" colspan="6"><span id="S5.T8.13.21.8.1.1" class="ltx_text" style="font-size:90%;">II: Trade privacy for fairness. Adopting relaxed DP notion to accommodate exact fairness</span></td>
</tr>
</tbody>
</table>
</figure>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Privacy Degrades Fairness</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Currently, there are two approaches to privately train a fair model: the cryptography approach and the DP approach. In the first line of works, Veale et al. <cite class="ltx_cite ltx_citemacro_citep">(Veale and Binns, <a href="#bib.bib182" title="" class="ltx_ref">2017</a>)</cite> suggested storing protected characteristics in a trusted third party to protect privacy. The third-party will perform discrimination discovery and incorporate fairness constraints into model-building. Kilbertus et al. <cite class="ltx_cite ltx_citemacro_citep">(Kilbertus et al<span class="ltx_text">.</span>, <a href="#bib.bib102" title="" class="ltx_ref">2018</a>)</cite> relaxed the assumption of a trusted third party and proposed to train a fair model with encrypted sensitive attributes <cite class="ltx_cite ltx_citemacro_citep">(Mozannar
et al<span class="ltx_text">.</span>, <a href="#bib.bib139" title="" class="ltx_ref">2020</a>)</cite>. The cryptography approach is guaranteed to provide comparable performance as the non-private alternative at the cost of communication overhead. The trade-offs between privacy and efficiency are the main concern in this category.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">However, as argued by <cite class="ltx_cite ltx_citemacro_citep">(Jagielski et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2019</a>)</cite>, the cryptographic approach does not guarantee privacy at the inference stage. It only ensures the training data remain private during training and cannot prevent the adversary from inferring training samples from the neural network parameters <cite class="ltx_cite ltx_citemacro_citep">(Zhao
et al<span class="ltx_text">.</span>, <a href="#bib.bib227" title="" class="ltx_ref">2020</a>; Song
et al<span class="ltx_text">.</span>, <a href="#bib.bib171" title="" class="ltx_ref">2017</a>)</cite>. On the contrary, DP guarantees a fair model will not leak anything beyond what could be carried out from ”population level” correlations. As such, the majority of works focus on learning fair, and DP model <cite class="ltx_cite ltx_citemacro_citep">(Jagielski et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2019</a>; Cummings et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2019</a>; Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2019</a>; Xu et al<span class="ltx_text">.</span>, <a href="#bib.bib197" title="" class="ltx_ref">2019b</a>)</cite>. Thus, this subsection focus on DP as the privacy-preserving techniques.</p>
</div>
<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1. </span>Empirical Findings</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p id="S5.SS1.SSS1.p1.1" class="ltx_p">The impact of privacy on fairness was initially observed in empirical studies. Bagdasaryan et al. <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2019</a>)</cite> first observed that the reduction in accuracy caused by deep DP models negatively impacts underrepresented subgroups disproportionately. DP-SGD strengthens the model’s ”bias” toward the most prominent features of the distribution that is being learned. Kuppam et al. <cite class="ltx_cite ltx_citemacro_citep">(Kuppam et al<span class="ltx_text">.</span>, <a href="#bib.bib106" title="" class="ltx_ref">2020</a>)</cite> reached a similar conclusion when they examined the effects of DP on fairness in three real-world tasks involving sensitive public data. When the noise added by a private algorithm is negligible in relation to the underlying statistics, the costs of adopting a private technique may be minor. When stronger privacy is implemented or when a task entails a small population, significant disparities may emerge. Farrand et al. <cite class="ltx_cite ltx_citemacro_citep">(Farrand et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite> demonstrated that even minor differences and weak privacy protections could result in disparate outcomes. Ganev et al. <cite class="ltx_cite ltx_citemacro_citep">(Ganev
et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2022</a>)</cite> shifted the emphasis to generative models and tabular synthetic data. Three DP generative models PrivBayes <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib219" title="" class="ltx_ref">2017</a>)</cite>, DP-WGAN <cite class="ltx_cite ltx_citemacro_citep">(Alzantot and
Srivastava, <a href="#bib.bib5" title="" class="ltx_ref">[n.d.]</a>)</cite>, and PATE-GAN <cite class="ltx_cite ltx_citemacro_citep">(Jordon
et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2019</a>)</cite>, were involved. They witnessed a disparate effect on the accuracy of classifiers trained on synthetic data generated by all generative models. The losses are greater and/or more dispersed for underrepresented groups. Uniyal et al. <cite class="ltx_cite ltx_citemacro_citep">(Uniyal et al<span class="ltx_text">.</span>, <a href="#bib.bib181" title="" class="ltx_ref">2021</a>)</cite> compared DP-SGD and Private Aggregation of Teacher Ensembles (PATE) <cite class="ltx_cite ltx_citemacro_citep">(Papernot et al<span class="ltx_text">.</span>, <a href="#bib.bib148" title="" class="ltx_ref">2016</a>)</cite>, an alternative DP mechanism for discreetly training a deep neural network, in terms of fairness. They discovered that PATE has a disparate effect, but it is considerably less severe than DP-SGD.</p>
</div>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2. </span>Theoretical Explanations</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p id="S5.SS1.SSS2.p1.3" class="ltx_p">Several works have attempted to determine the mechanism underlying the well-known relationship between privacy and unfairness. Bagdasaryan et al. <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2019</a>)</cite> associated the impact with the gradient clipping operation in DP-SGD. During training, the model generates larger gradients for samples from underrepresented subgroups; consequently, clipping slows their learning rate. Therefore, the model learns less from the underrepresented subgroups, and its performance on those subgroups is negatively impacted more. Tran et al. <cite class="ltx_cite ltx_citemacro_citep">(Tran
et al<span class="ltx_text">.</span>, <a href="#bib.bib177" title="" class="ltx_ref">2021a</a>)</cite> conducted an in-depth study into this phenomenon with output perturbation <cite class="ltx_cite ltx_citemacro_citep">(Chaudhuri
et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2011</a>)</cite> and DP-SGD as the private mechanism. By measuring fairness with <span id="S5.SS1.SSS2.p1.3.1" class="ltx_text ltx_font_italic">excessive risk gap</span>, Tran et al. proved that output perturbation mechanisms incur unfairness when the local curvatures of the loss functions of different groups differ substantially. For DP-SGD, Tran et al. found that the clipping bound, the norm of inputs, and the group’s distance to the decision boundary collectively contributed to the unfairness raised by DP-SGD. Esipova et al. <cite class="ltx_cite ltx_citemacro_citep">(Esipova
et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2022</a>)</cite> examined the same issue from the gradient perspective. They proved that the gradient misalignment caused by DP-SGD is the main reason for unfairness. If the clipping operation disproportionately and sufficiently increases the direction error for group <math id="S5.SS1.SSS2.p1.1.m1.1" class="ltx_Math" alttext="a" display="inline"><semantics id="S5.SS1.SSS2.p1.1.m1.1a"><mi id="S5.SS1.SSS2.p1.1.m1.1.1" xref="S5.SS1.SSS2.p1.1.m1.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.1.m1.1b"><ci id="S5.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p1.1.m1.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.1.m1.1c">a</annotation></semantics></math> relative to group <math id="S5.SS1.SSS2.p1.2.m2.1" class="ltx_Math" alttext="b" display="inline"><semantics id="S5.SS1.SSS2.p1.2.m2.1a"><mi id="S5.SS1.SSS2.p1.2.m2.1.1" xref="S5.SS1.SSS2.p1.2.m2.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.2.m2.1b"><ci id="S5.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S5.SS1.SSS2.p1.2.m2.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.2.m2.1c">b</annotation></semantics></math>, then group <math id="S5.SS1.SSS2.p1.3.m3.1" class="ltx_Math" alttext="a" display="inline"><semantics id="S5.SS1.SSS2.p1.3.m3.1a"><mi id="S5.SS1.SSS2.p1.3.m3.1.1" xref="S5.SS1.SSS2.p1.3.m3.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.3.m3.1b"><ci id="S5.SS1.SSS2.p1.3.m3.1.1.cmml" xref="S5.SS1.SSS2.p1.3.m3.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.3.m3.1c">a</annotation></semantics></math> incurs larger excessive risk due to gradient misalignment.</p>
</div>
</section>
<section id="S5.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.3. </span>Mitigation Strategies</h4>

<div id="S5.SS1.SSS3.p1" class="ltx_para">
<p id="S5.SS1.SSS3.p1.4" class="ltx_p">Diverse methods have been proposed to mitigate the effect of private mechanisms on fairness. Xu et al. <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a href="#bib.bib195" title="" class="ltx_ref">2021b</a>)</cite> proposed DP-SGD-F, a variant of DP-SGD that reduces the divergent impact on different populations. By adaptively designating clipping bounds for each group, DP-SGD-F achieves a level of privacy proportional to each group’s utility-privacy trade-off. For the group whose clipping bias is greater (due to large gradients), a larger clipping bound is adopted to mitigate for their greater privacy cost. Tran et al. <cite class="ltx_cite ltx_citemacro_citep">(Tran
et al<span class="ltx_text">.</span>, <a href="#bib.bib177" title="" class="ltx_ref">2021a</a>)</cite> formulated a regularized optimization problem that minimizes empirical loss while satisfying two additional constraints. The first constraint equalizes the averaged non-private and private gradients, while the second constraint penalizes the difference between the local curvatures of distinct groups’ loss functions. Esipova et al. <cite class="ltx_cite ltx_citemacro_citep">(Esipova
et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2022</a>)</cite> modified DP-SGD and developed DP-SGD-Global-Adapt to preserve gradient direction. It is assumed that a hyperparameter <math id="S5.SS1.SSS3.p1.1.m1.1" class="ltx_Math" alttext="Z" display="inline"><semantics id="S5.SS1.SSS3.p1.1.m1.1a"><mi id="S5.SS1.SSS3.p1.1.m1.1.1" xref="S5.SS1.SSS3.p1.1.m1.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.1.m1.1b"><ci id="S5.SS1.SSS3.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS3.p1.1.m1.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.1.m1.1c">Z</annotation></semantics></math> is the upper bound for most gradients. Gradients less than <math id="S5.SS1.SSS3.p1.2.m2.1" class="ltx_Math" alttext="Z" display="inline"><semantics id="S5.SS1.SSS3.p1.2.m2.1a"><mi id="S5.SS1.SSS3.p1.2.m2.1.1" xref="S5.SS1.SSS3.p1.2.m2.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.2.m2.1b"><ci id="S5.SS1.SSS3.p1.2.m2.1.1.cmml" xref="S5.SS1.SSS3.p1.2.m2.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.2.m2.1c">Z</annotation></semantics></math> are uniformly scaled, whereas gradients greater than <math id="S5.SS1.SSS3.p1.3.m3.1" class="ltx_Math" alttext="Z" display="inline"><semantics id="S5.SS1.SSS3.p1.3.m3.1a"><mi id="S5.SS1.SSS3.p1.3.m3.1.1" xref="S5.SS1.SSS3.p1.3.m3.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.3.m3.1b"><ci id="S5.SS1.SSS3.p1.3.m3.1.1.cmml" xref="S5.SS1.SSS3.p1.3.m3.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.3.m3.1c">Z</annotation></semantics></math> are trimmed to <math id="S5.SS1.SSS3.p1.4.m4.1" class="ltx_Math" alttext="Z" display="inline"><semantics id="S5.SS1.SSS3.p1.4.m4.1a"><mi id="S5.SS1.SSS3.p1.4.m4.1.1" xref="S5.SS1.SSS3.p1.4.m4.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.4.m4.1b"><ci id="S5.SS1.SSS3.p1.4.m4.1.1.cmml" xref="S5.SS1.SSS3.p1.4.m4.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.4.m4.1c">Z</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Fairness Increases Privacy Risk</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Fairness in turn presents challenges for privacy mechanisms. Chang and Shokri <cite class="ltx_cite ltx_citemacro_citep">(Chang and Shokri, <a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite> observed an elevated privacy risk for underprivileged subgroups in a fair model. In order to ensure fairness, the model must perform equally well for all subgroups. However, limited data availability for underprivileged subgroups can lead to overfitting of the training data for unprivileged subgroups in a fair model, thereby increasing the privacy risk. Previous works on fairness-aware machine learning often assume that the sensitive features are reliable and accessible. This assumption unavoidably introduces privacy risks. However, achieving precise notions of fairness, such as demographic parity, becomes unattainable without access to sensitive attributes, specifically the membership information of sensitive groups. To address this issue, several techniques have been proposed to safeguard the privacy of sensitive attributes during the training of fair models.</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1. </span>Training Fair Models with Noisy Representation</h4>

<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.6" class="ltx_p">Researchers in this field train approximately fair models using noisy sensitive attributes to protect privacy. Gupta et al. <cite class="ltx_cite ltx_citemacro_citep">(Gupta
et al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2018</a>)</cite> substituted protected groups with proxy groups. To achieve fairness, the proxy groups need to align with the true positive group and even overlap with the ground-truth groups. Thus, the fairness guarantee comes at the cost of privacy. Several studies have explored fairness with imperfect group information. <cite class="ltx_cite ltx_citemacro_citep">(Kallus
et al<span class="ltx_text">.</span>, <a href="#bib.bib91" title="" class="ltx_ref">2020</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib187" title="" class="ltx_ref">2020b</a>; Lamy
et al<span class="ltx_text">.</span>, <a href="#bib.bib108" title="" class="ltx_ref">2019</a>; Awasthi et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite>. Lamy et al. <cite class="ltx_cite ltx_citemacro_citep">(Lamy
et al<span class="ltx_text">.</span>, <a href="#bib.bib108" title="" class="ltx_ref">2019</a>)</cite> introduced a mutual contaminated model to simulate a noisy distribution with corrupted attributes. Under this framework, they demonstrated that the fairness constraint on the clean distribution is equivalent to a scaled fairness constraint on the noisy distribution. To protect the privacy of sensitive attributes, they added class conditional noise to release the noisy dataset. Awasthi et al. <cite class="ltx_cite ltx_citemacro_citep">(Awasthi et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite> addressed the challenging problem of training a fair model with perturbed sensitive attribute values, where each attribute is independently flipped to its complementary value with probability <math id="S5.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S5.SS2.SSS1.p1.1.m1.1a"><mi id="S5.SS2.SSS1.p1.1.m1.1.1" xref="S5.SS2.SSS1.p1.1.m1.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.1.m1.1b"><ci id="S5.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.1.m1.1c">\gamma</annotation></semantics></math>. They identified conditions on the perturbation under which the classifier, denoted as <math id="S5.SS2.SSS1.p1.2.m2.1" class="ltx_Math" alttext="\hat{Y}" display="inline"><semantics id="S5.SS2.SSS1.p1.2.m2.1a"><mover accent="true" id="S5.SS2.SSS1.p1.2.m2.1.1" xref="S5.SS2.SSS1.p1.2.m2.1.1.cmml"><mi id="S5.SS2.SSS1.p1.2.m2.1.1.2" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.cmml">Y</mi><mo id="S5.SS2.SSS1.p1.2.m2.1.1.1" xref="S5.SS2.SSS1.p1.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.2.m2.1b"><apply id="S5.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1"><ci id="S5.SS2.SSS1.p1.2.m2.1.1.1.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.1">^</ci><ci id="S5.SS2.SSS1.p1.2.m2.1.1.2.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2">𝑌</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.2.m2.1c">\hat{Y}</annotation></semantics></math>, obtained by Hardt et al.’s method <cite class="ltx_cite ltx_citemacro_citep">(Hardt
et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2016</a>)</cite>, is fairer than the vanilla classifier, denoted as <math id="S5.SS2.SSS1.p1.3.m3.1" class="ltx_Math" alttext="\tilde{Y}" display="inline"><semantics id="S5.SS2.SSS1.p1.3.m3.1a"><mover accent="true" id="S5.SS2.SSS1.p1.3.m3.1.1" xref="S5.SS2.SSS1.p1.3.m3.1.1.cmml"><mi id="S5.SS2.SSS1.p1.3.m3.1.1.2" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.cmml">Y</mi><mo id="S5.SS2.SSS1.p1.3.m3.1.1.1" xref="S5.SS2.SSS1.p1.3.m3.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.3.m3.1b"><apply id="S5.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1"><ci id="S5.SS2.SSS1.p1.3.m3.1.1.1.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.1">~</ci><ci id="S5.SS2.SSS1.p1.3.m3.1.1.2.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.2">𝑌</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.3.m3.1c">\tilde{Y}</annotation></semantics></math>, trained on accurate attributes. They further provided a formal guarantee of effectiveness under the necessary conditions. Wang et al. <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib187" title="" class="ltx_ref">2020b</a>)</cite> trained a fair binary classifier based on a noisy label <math id="S5.SS2.SSS1.p1.4.m4.3" class="ltx_Math" alttext="\hat{G}\in\{1,...,\hat{m}\}" display="inline"><semantics id="S5.SS2.SSS1.p1.4.m4.3a"><mrow id="S5.SS2.SSS1.p1.4.m4.3.4" xref="S5.SS2.SSS1.p1.4.m4.3.4.cmml"><mover accent="true" id="S5.SS2.SSS1.p1.4.m4.3.4.2" xref="S5.SS2.SSS1.p1.4.m4.3.4.2.cmml"><mi id="S5.SS2.SSS1.p1.4.m4.3.4.2.2" xref="S5.SS2.SSS1.p1.4.m4.3.4.2.2.cmml">G</mi><mo id="S5.SS2.SSS1.p1.4.m4.3.4.2.1" xref="S5.SS2.SSS1.p1.4.m4.3.4.2.1.cmml">^</mo></mover><mo id="S5.SS2.SSS1.p1.4.m4.3.4.1" xref="S5.SS2.SSS1.p1.4.m4.3.4.1.cmml">∈</mo><mrow id="S5.SS2.SSS1.p1.4.m4.3.4.3.2" xref="S5.SS2.SSS1.p1.4.m4.3.4.3.1.cmml"><mo stretchy="false" id="S5.SS2.SSS1.p1.4.m4.3.4.3.2.1" xref="S5.SS2.SSS1.p1.4.m4.3.4.3.1.cmml">{</mo><mn id="S5.SS2.SSS1.p1.4.m4.1.1" xref="S5.SS2.SSS1.p1.4.m4.1.1.cmml">1</mn><mo id="S5.SS2.SSS1.p1.4.m4.3.4.3.2.2" xref="S5.SS2.SSS1.p1.4.m4.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="S5.SS2.SSS1.p1.4.m4.2.2" xref="S5.SS2.SSS1.p1.4.m4.2.2.cmml">…</mi><mo id="S5.SS2.SSS1.p1.4.m4.3.4.3.2.3" xref="S5.SS2.SSS1.p1.4.m4.3.4.3.1.cmml">,</mo><mover accent="true" id="S5.SS2.SSS1.p1.4.m4.3.3" xref="S5.SS2.SSS1.p1.4.m4.3.3.cmml"><mi id="S5.SS2.SSS1.p1.4.m4.3.3.2" xref="S5.SS2.SSS1.p1.4.m4.3.3.2.cmml">m</mi><mo id="S5.SS2.SSS1.p1.4.m4.3.3.1" xref="S5.SS2.SSS1.p1.4.m4.3.3.1.cmml">^</mo></mover><mo stretchy="false" id="S5.SS2.SSS1.p1.4.m4.3.4.3.2.4" xref="S5.SS2.SSS1.p1.4.m4.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.4.m4.3b"><apply id="S5.SS2.SSS1.p1.4.m4.3.4.cmml" xref="S5.SS2.SSS1.p1.4.m4.3.4"><in id="S5.SS2.SSS1.p1.4.m4.3.4.1.cmml" xref="S5.SS2.SSS1.p1.4.m4.3.4.1"></in><apply id="S5.SS2.SSS1.p1.4.m4.3.4.2.cmml" xref="S5.SS2.SSS1.p1.4.m4.3.4.2"><ci id="S5.SS2.SSS1.p1.4.m4.3.4.2.1.cmml" xref="S5.SS2.SSS1.p1.4.m4.3.4.2.1">^</ci><ci id="S5.SS2.SSS1.p1.4.m4.3.4.2.2.cmml" xref="S5.SS2.SSS1.p1.4.m4.3.4.2.2">𝐺</ci></apply><set id="S5.SS2.SSS1.p1.4.m4.3.4.3.1.cmml" xref="S5.SS2.SSS1.p1.4.m4.3.4.3.2"><cn type="integer" id="S5.SS2.SSS1.p1.4.m4.1.1.cmml" xref="S5.SS2.SSS1.p1.4.m4.1.1">1</cn><ci id="S5.SS2.SSS1.p1.4.m4.2.2.cmml" xref="S5.SS2.SSS1.p1.4.m4.2.2">…</ci><apply id="S5.SS2.SSS1.p1.4.m4.3.3.cmml" xref="S5.SS2.SSS1.p1.4.m4.3.3"><ci id="S5.SS2.SSS1.p1.4.m4.3.3.1.cmml" xref="S5.SS2.SSS1.p1.4.m4.3.3.1">^</ci><ci id="S5.SS2.SSS1.p1.4.m4.3.3.2.cmml" xref="S5.SS2.SSS1.p1.4.m4.3.3.2">𝑚</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.4.m4.3c">\hat{G}\in\{1,...,\hat{m}\}</annotation></semantics></math>, i.e., <math id="S5.SS2.SSS1.p1.5.m5.1" class="ltx_Math" alttext="\hat{G}" display="inline"><semantics id="S5.SS2.SSS1.p1.5.m5.1a"><mover accent="true" id="S5.SS2.SSS1.p1.5.m5.1.1" xref="S5.SS2.SSS1.p1.5.m5.1.1.cmml"><mi id="S5.SS2.SSS1.p1.5.m5.1.1.2" xref="S5.SS2.SSS1.p1.5.m5.1.1.2.cmml">G</mi><mo id="S5.SS2.SSS1.p1.5.m5.1.1.1" xref="S5.SS2.SSS1.p1.5.m5.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.5.m5.1b"><apply id="S5.SS2.SSS1.p1.5.m5.1.1.cmml" xref="S5.SS2.SSS1.p1.5.m5.1.1"><ci id="S5.SS2.SSS1.p1.5.m5.1.1.1.cmml" xref="S5.SS2.SSS1.p1.5.m5.1.1.1">^</ci><ci id="S5.SS2.SSS1.p1.5.m5.1.1.2.cmml" xref="S5.SS2.SSS1.p1.5.m5.1.1.2">𝐺</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.5.m5.1c">\hat{G}</annotation></semantics></math> could be <span id="S5.SS2.SSS1.p1.6.1" class="ltx_text ltx_font_italic">”country of residence”</span> as a noisy representation of the true group labels <math id="S5.SS2.SSS1.p1.6.m6.1" class="ltx_Math" alttext="G=" display="inline"><semantics id="S5.SS2.SSS1.p1.6.m6.1a"><mrow id="S5.SS2.SSS1.p1.6.m6.1.1" xref="S5.SS2.SSS1.p1.6.m6.1.1.cmml"><mi id="S5.SS2.SSS1.p1.6.m6.1.1.2" xref="S5.SS2.SSS1.p1.6.m6.1.1.2.cmml">G</mi><mo id="S5.SS2.SSS1.p1.6.m6.1.1.1" xref="S5.SS2.SSS1.p1.6.m6.1.1.1.cmml">=</mo><mi id="S5.SS2.SSS1.p1.6.m6.1.1.3" xref="S5.SS2.SSS1.p1.6.m6.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.6.m6.1b"><apply id="S5.SS2.SSS1.p1.6.m6.1.1.cmml" xref="S5.SS2.SSS1.p1.6.m6.1.1"><eq id="S5.SS2.SSS1.p1.6.m6.1.1.1.cmml" xref="S5.SS2.SSS1.p1.6.m6.1.1.1"></eq><ci id="S5.SS2.SSS1.p1.6.m6.1.1.2.cmml" xref="S5.SS2.SSS1.p1.6.m6.1.1.2">𝐺</ci><csymbol cd="latexml" id="S5.SS2.SSS1.p1.6.m6.1.1.3.cmml" xref="S5.SS2.SSS1.p1.6.m6.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.6.m6.1c">G=</annotation></semantics></math> <span id="S5.SS2.SSS1.p1.6.2" class="ltx_text ltx_font_italic">”language spoken at home”</span>.</p>
</div>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2. </span>Training Fair Models with DP</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.2" class="ltx_p">Works in this area protect privacy by adding noise to the private characteristic <cite class="ltx_cite ltx_citemacro_citep">(Tran
et al<span class="ltx_text">.</span>, <a href="#bib.bib177" title="" class="ltx_ref">2021a</a>)</cite>. The trade-off between privacy and fairness depends on the amount of noise added, with no noise and excessive noise representing the two extremes. In the case of no noise, the model’s performance remains unaffected but could lead to information breaches. Conversely, high levels of noise are effective in preserving privacy but can compromise the model’s utility. Tran et al. <cite class="ltx_cite ltx_citemacro_citep">(Tran
et al<span class="ltx_text">.</span>, <a href="#bib.bib177" title="" class="ltx_ref">2021a</a>)</cite> proposed a constrained optimization problem to address both private and fair learning tasks. Their framework ensures <math id="S5.SS2.SSS2.p1.1.m1.2" class="ltx_Math" alttext="(\alpha,\epsilon_{p})" display="inline"><semantics id="S5.SS2.SSS2.p1.1.m1.2a"><mrow id="S5.SS2.SSS2.p1.1.m1.2.2.1" xref="S5.SS2.SSS2.p1.1.m1.2.2.2.cmml"><mo stretchy="false" id="S5.SS2.SSS2.p1.1.m1.2.2.1.2" xref="S5.SS2.SSS2.p1.1.m1.2.2.2.cmml">(</mo><mi id="S5.SS2.SSS2.p1.1.m1.1.1" xref="S5.SS2.SSS2.p1.1.m1.1.1.cmml">α</mi><mo id="S5.SS2.SSS2.p1.1.m1.2.2.1.3" xref="S5.SS2.SSS2.p1.1.m1.2.2.2.cmml">,</mo><msub id="S5.SS2.SSS2.p1.1.m1.2.2.1.1" xref="S5.SS2.SSS2.p1.1.m1.2.2.1.1.cmml"><mi id="S5.SS2.SSS2.p1.1.m1.2.2.1.1.2" xref="S5.SS2.SSS2.p1.1.m1.2.2.1.1.2.cmml">ϵ</mi><mi id="S5.SS2.SSS2.p1.1.m1.2.2.1.1.3" xref="S5.SS2.SSS2.p1.1.m1.2.2.1.1.3.cmml">p</mi></msub><mo stretchy="false" id="S5.SS2.SSS2.p1.1.m1.2.2.1.4" xref="S5.SS2.SSS2.p1.1.m1.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p1.1.m1.2b"><interval closure="open" id="S5.SS2.SSS2.p1.1.m1.2.2.2.cmml" xref="S5.SS2.SSS2.p1.1.m1.2.2.1"><ci id="S5.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1">𝛼</ci><apply id="S5.SS2.SSS2.p1.1.m1.2.2.1.1.cmml" xref="S5.SS2.SSS2.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS2.p1.1.m1.2.2.1.1.1.cmml" xref="S5.SS2.SSS2.p1.1.m1.2.2.1.1">subscript</csymbol><ci id="S5.SS2.SSS2.p1.1.m1.2.2.1.1.2.cmml" xref="S5.SS2.SSS2.p1.1.m1.2.2.1.1.2">italic-ϵ</ci><ci id="S5.SS2.SSS2.p1.1.m1.2.2.1.1.3.cmml" xref="S5.SS2.SSS2.p1.1.m1.2.2.1.1.3">𝑝</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p1.1.m1.2c">(\alpha,\epsilon_{p})</annotation></semantics></math>-Rényi DP <cite class="ltx_cite ltx_citemacro_citep">(Mironov, <a href="#bib.bib134" title="" class="ltx_ref">2017</a>)</cite> for the sensitive attributes by solving the constrained problem with DP-SGD. Jagielski et al. <cite class="ltx_cite ltx_citemacro_citep">(Jagielski et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2019</a>)</cite> extended Agarwal et al.’s approach <cite class="ltx_cite ltx_citemacro_citep">(Agarwal et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2018</a>)</cite> by incorporating privacy considerations. They formulated a two-player zero-sum game, played between a ”learner” and an ”auditor,” to derive a fair classifier. Laplacian noise <cite class="ltx_cite ltx_citemacro_citep">(Dwork
et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2006</a>)</cite> and the exponential mechanism <cite class="ltx_cite ltx_citemacro_citep">(McSherry and
Talwar, <a href="#bib.bib131" title="" class="ltx_ref">2007</a>)</cite> were utilized separately for the ”learner” and the ”auditor”. As a result, the learned model satisfies <math id="S5.SS2.SSS2.p1.2.m2.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S5.SS2.SSS2.p1.2.m2.2a"><mrow id="S5.SS2.SSS2.p1.2.m2.2.3.2" xref="S5.SS2.SSS2.p1.2.m2.2.3.1.cmml"><mo stretchy="false" id="S5.SS2.SSS2.p1.2.m2.2.3.2.1" xref="S5.SS2.SSS2.p1.2.m2.2.3.1.cmml">(</mo><mi id="S5.SS2.SSS2.p1.2.m2.1.1" xref="S5.SS2.SSS2.p1.2.m2.1.1.cmml">ϵ</mi><mo id="S5.SS2.SSS2.p1.2.m2.2.3.2.2" xref="S5.SS2.SSS2.p1.2.m2.2.3.1.cmml">,</mo><mi id="S5.SS2.SSS2.p1.2.m2.2.2" xref="S5.SS2.SSS2.p1.2.m2.2.2.cmml">δ</mi><mo stretchy="false" id="S5.SS2.SSS2.p1.2.m2.2.3.2.3" xref="S5.SS2.SSS2.p1.2.m2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p1.2.m2.2b"><interval closure="open" id="S5.SS2.SSS2.p1.2.m2.2.3.1.cmml" xref="S5.SS2.SSS2.p1.2.m2.2.3.2"><ci id="S5.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS2.p1.2.m2.1.1">italic-ϵ</ci><ci id="S5.SS2.SSS2.p1.2.m2.2.2.cmml" xref="S5.SS2.SSS2.p1.2.m2.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p1.2.m2.2c">(\epsilon,\delta)</annotation></semantics></math>-DP and achieves equalized odds.</p>
</div>
</section>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>Fair and Private FL</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">In centralized machine learning, one entails centralized access to training data (either the true data or noisy data). However, this is invalid in FL, where neither the server nor clients have access to others’ data. Therefore, one cannot simply apply centralized fair learning algorithms in FL tasks. This raises a question: <span id="S5.SS3.p1.1.1" class="ltx_text ltx_font_italic">How can we promote algorithmic fairness in FL without accessing clients’ data in FL</span>? Several studies made progress in response to this challenge.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p"><span id="S5.SS3.p2.1.1" class="ltx_text ltx_font_bold">Using a surrogate model to preserve privacy</span>. Padala et al. <cite class="ltx_cite ltx_citemacro_citep">(Padala
et al<span class="ltx_text">.</span>, <a href="#bib.bib145" title="" class="ltx_ref">2021</a>)</cite> tried to satisfy both <math id="S5.SS3.p2.1.m1.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S5.SS3.p2.1.m1.2a"><mrow id="S5.SS3.p2.1.m1.2.3.2" xref="S5.SS3.p2.1.m1.2.3.1.cmml"><mo stretchy="false" id="S5.SS3.p2.1.m1.2.3.2.1" xref="S5.SS3.p2.1.m1.2.3.1.cmml">(</mo><mi id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml">ϵ</mi><mo id="S5.SS3.p2.1.m1.2.3.2.2" xref="S5.SS3.p2.1.m1.2.3.1.cmml">,</mo><mi id="S5.SS3.p2.1.m1.2.2" xref="S5.SS3.p2.1.m1.2.2.cmml">δ</mi><mo stretchy="false" id="S5.SS3.p2.1.m1.2.3.2.3" xref="S5.SS3.p2.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.2b"><interval closure="open" id="S5.SS3.p2.1.m1.2.3.1.cmml" xref="S5.SS3.p2.1.m1.2.3.2"><ci id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1">italic-ϵ</ci><ci id="S5.SS3.p2.1.m1.2.2.cmml" xref="S5.SS3.p2.1.m1.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.2c">(\epsilon,\delta)</annotation></semantics></math>-local DP and demographic fairness through a fair and private FL framework. To circumvent the access restriction, they decomposed the learning into two phases. First, each client learns a fair and accurate model on a local dataset, where the fairness constraint acts as a regularization term in the loss function. Then, every client trains a surrogate model to match the fair predictions from the first model with a DP guarantee. Finally, only the surrogate model is communicated to the server.</p>
</div>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p"><span id="S5.SS3.p3.1.1" class="ltx_text ltx_font_bold">Privacy through secure aggregation</span>. Zhang et al. <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib217" title="" class="ltx_ref">2020b</a>)</cite> investigated classification problems in FL through multiple goal optimization problems with privacy constraints. The objective is to minimize the accuracy loss and the discrimination risk. To this end, a team Markov game was designed to select participating clients at each communication round. In each round, clients decide whether or not to participate based on the global model’s state, which is characterized by bias level and accuracy. Further, a secure aggregation protocol is designed to estimate the global model’s status based on polynomial interpolation <cite class="ltx_cite ltx_citemacro_citep">(Karnin
et al<span class="ltx_text">.</span>, <a href="#bib.bib97" title="" class="ltx_ref">1983</a>)</cite> for privacy concerns. Under this protocol, the server is able to calculate the discrimination status without accessing the local data.</p>
</div>
<div id="S5.SS3.p4" class="ltx_para">
<p id="S5.SS3.p4.1" class="ltx_p"><span id="S5.SS3.p4.1.1" class="ltx_text ltx_font_bold">Achieve fairness based on statistics</span>. Gálvez et al. <cite class="ltx_cite ltx_citemacro_citep">(G’alvez et al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2021</a>)</cite> formulated a constrained optimization problem that is solved by the differential multiplier. Local statistics are provided to the server for debiasing the global model. To further protect privacy, client updates are clipped and perturbed by Gaussian noise before being sent to the server. Finally, their solution is able to provide the approximate group fairness notion over multiple attributes and <math id="S5.SS3.p4.1.m1.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S5.SS3.p4.1.m1.2a"><mrow id="S5.SS3.p4.1.m1.2.3.2" xref="S5.SS3.p4.1.m1.2.3.1.cmml"><mo stretchy="false" id="S5.SS3.p4.1.m1.2.3.2.1" xref="S5.SS3.p4.1.m1.2.3.1.cmml">(</mo><mi id="S5.SS3.p4.1.m1.1.1" xref="S5.SS3.p4.1.m1.1.1.cmml">ϵ</mi><mo id="S5.SS3.p4.1.m1.2.3.2.2" xref="S5.SS3.p4.1.m1.2.3.1.cmml">,</mo><mi id="S5.SS3.p4.1.m1.2.2" xref="S5.SS3.p4.1.m1.2.2.cmml">δ</mi><mo stretchy="false" id="S5.SS3.p4.1.m1.2.3.2.3" xref="S5.SS3.p4.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.1.m1.2b"><interval closure="open" id="S5.SS3.p4.1.m1.2.3.1.cmml" xref="S5.SS3.p4.1.m1.2.3.2"><ci id="S5.SS3.p4.1.m1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1">italic-ϵ</ci><ci id="S5.SS3.p4.1.m1.2.2.cmml" xref="S5.SS3.p4.1.m1.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.1.m1.2c">(\epsilon,\delta)</annotation></semantics></math>-DP.</p>
</div>
<div id="S5.SS3.p5" class="ltx_para">
<p id="S5.SS3.p5.1" class="ltx_p"><span id="S5.SS3.p5.1.1" class="ltx_text ltx_font_bold">Fairness through agnostic learning</span>. Shifts in distribution is one source of bias in FL. The global model is trained on the data of all clients (source distribution), but each client’s local data distribution (target distribution) may differ. When deployed to the client, unfavorable outcomes occur. Du et al. <cite class="ltx_cite ltx_citemacro_citep">(Du
et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2021</a>)</cite> proposed treating the client data distribution in an agnostic way. An adversary generates any possible unknown local data distribution to maximize the loss, while the learner aims to optimize the accuracy and fairness.</p>
</div>
<div id="S5.SS3.p6" class="ltx_para">
<p id="S5.SS3.p6.1" class="ltx_p"><span id="S5.SS3.p6.1.1" class="ltx_text ltx_font_bold">Calculate fairness violations locally</span>. Chu et al. <cite class="ltx_cite ltx_citemacro_citep">(Chu
et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2021</a>)</cite> formulated a constraint optimization problem to learn a fair and private model in FL. Each client locally calculates fairness violations to avoid impinging on the data privacy of any client. Chu et al. <cite class="ltx_cite ltx_citemacro_citep">(Chu
et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2021</a>)</cite> further optimized this method by aggregating fairness constraints to better estimate the true fairness violation for all data.</p>
</div>
<div id="S5.SS3.p7" class="ltx_para">
<p id="S5.SS3.p7.1" class="ltx_p">Although some fair FL algorithms do not directly access the training data <cite class="ltx_cite ltx_citemacro_citep">(Du
et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2021</a>; Chu
et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2021</a>)</cite>, faithfully sharing the model/gradients in FL could incur privacy leakage risks. The privacy breach could happen during the training or inference stage. The attack could be carried out by either the server or the clients <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib209" title="" class="ltx_ref">2021b</a>)</cite>. For example, an honest-but-curious server can lunch a reconstruction attack <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib232" title="" class="ltx_ref">2019</a>)</cite> to recover the private data from the gradients uploaded by the victim client. However, the main challenge to training a fair model in FL is restricted data access, e.g., data never leaving local devices, which is an under-investigated topic in FL literature. In the case of the adversary clients/server in FL, some privacy-preserving techniques, such as DP, can be combined with the aforementioned fair FL approaches to prevent privacy leakage.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4. </span>Discussion of Privacy and Fairness Interactions</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">The complex interactions between privacy and fairness have been thoroughly examined and documented in various studies. These investigations highlight the intricate trade-offs and challenges that arise when attempting to simultaneously address both privacy and fairness objectives <cite class="ltx_cite ltx_citemacro_citep">(Cummings et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<p id="S5.SS4.p2.1" class="ltx_p">The impact of privacy and fairness on each other is indeed bilateral. In one scenario, privacy measures can degrade fairness. For instance, in widely-used privacy mechanisms like DP-SGD, to protect privacy, the algorithm clips and adds noise to the gradients. However, due to the scarcity of data for certain groups, these modifications can disproportionately affect underrepresented groups, exacerbating unfairness. Therefore, the implementation of DP can inadvertently worsen existing unfairness by disproportionately impacting certain groups.</p>
</div>
<div id="S5.SS4.p3" class="ltx_para">
<p id="S5.SS4.p3.1" class="ltx_p">In another case, fairness can increase privacy risks. To achieve fairness, it may be necessary to collect additional demographic information about users, even if it is irrelevant to the task at hand. This data collection is aimed at guiding modifications to the model, such as addressing inconsistent responses or removing discrimination in statistical models <cite class="ltx_cite ltx_citemacro_citep">(Voigt and Von dem
Bussche, <a href="#bib.bib184" title="" class="ltx_ref">2017</a>; Goodman, <a href="#bib.bib65" title="" class="ltx_ref">2016</a>; Žliobaitė and
Custers, <a href="#bib.bib233" title="" class="ltx_ref">2016</a>)</cite>. However, the collection of such sensitive information raises privacy concerns, as it expands the scope of data being collected and potentially increases the risk of privacy breaches.</p>
</div>
<div id="S5.SS4.p4" class="ltx_para">
<p id="S5.SS4.p4.1" class="ltx_p">In the context of Federated Learning (FL), the cooperative game between clients and the server adds complexity to the privacy and fairness challenges. FL introduces new privacy attack surfaces, as discussed in Section 3, where potential malicious participants can actively or passively infer the private data of other clients. Consequently, securing private information in FL requires even stronger privacy protection measures compared to the centralized setting. Merely protecting group membership is insufficient to address the privacy risks in FL. Furthermore, the non-i.i.d. (non-independent and identically distributed) nature of FL poses another challenge. In a typical FL system, clients’ data are sampled from different distributions, leading to data heterogeneity. A model that achieves fairness within the local distribution of each client is not guaranteed to perform unbiasedly on a global scale. The non-i.i.d. issue also introduces potential fairness concerns at the client level, as the performance of the model can vary significantly among clients. It is crucial to address this variation and ensure fairness across all participating clients in FL. The challenge lies in training a fair model in FL without violating the data access restrictions imposed by each client. Finding methods to mitigate the fairness issues arising from the non-i.i.d. nature of the data while respecting the privacy and data access constraints in FL remains a challenging task.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Open Research Directions</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">The research community has made fruitful progress in privacy and fairness in FL. However, throughout this survey, we found this field still faces several challenges that need to be solved.</p>
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p"><span id="S6.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Trade-offs between Privacy and Fairness</span>. The interaction between privacy and fairness is an under-studied topic. Existing works have focused on exploring the two notions in isolation, either focused on privacy-preserving machine learning <cite class="ltx_cite ltx_citemacro_citep">(Xu
et al<span class="ltx_text">.</span>, <a href="#bib.bib199" title="" class="ltx_ref">2021a</a>)</cite> or on paradigms that respect fairness <cite class="ltx_cite ltx_citemacro_citep">(Shi et al<span class="ltx_text">.</span>, <a href="#bib.bib163" title="" class="ltx_ref">2021</a>)</cite>. However, as demonstrated by several studies <cite class="ltx_cite ltx_citemacro_citep">(Chang and Shokri, <a href="#bib.bib23" title="" class="ltx_ref">2021</a>; Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2019</a>; Kuppam et al<span class="ltx_text">.</span>, <a href="#bib.bib106" title="" class="ltx_ref">2020</a>)</cite>, privacy and fairness may compete with each other. In the realm of FL, challenges and opportunities coexist. On the one hand, restricted information and non-i.i.d distribution complicate the problem settings. On the other hand, the flexibility of the FL paradigm may enable more possible solutions. For instance, the personalized model <cite class="ltx_cite ltx_citemacro_citep">(Kulkarni
et al<span class="ltx_text">.</span>, <a href="#bib.bib105" title="" class="ltx_ref">2020</a>; Tan
et al<span class="ltx_text">.</span>, <a href="#bib.bib175" title="" class="ltx_ref">2021</a>; Zhu
et al<span class="ltx_text">.</span>, <a href="#bib.bib230" title="" class="ltx_ref">2021</a>)</cite> has been widely used in FL to address statistical challenges by assigning clients personalized models. We may combine privacy and personalized models to achieve a better trade-off between privacy, fairness, and utility. Thus, we believe it is worth examining the trade-offs between privacy and fairness in FL.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p"><span id="S6.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">The Compatibility of Fairness and DP</span>. We believe it would be worth investigating techniques that simultaneously accommodate fairness and DP. As pointed out in Dwork et al.’s <cite class="ltx_cite ltx_citemacro_citep">(Dwork et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2012</a>)</cite> work, given a carefully designed distance metric, it is possible to achieve individual fairness through <math id="S6.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S6.I1.i2.p1.1.m1.1a"><mi id="S6.I1.i2.p1.1.m1.1.1" xref="S6.I1.i2.p1.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S6.I1.i2.p1.1.m1.1b"><ci id="S6.I1.i2.p1.1.m1.1.1.cmml" xref="S6.I1.i2.p1.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.I1.i2.p1.1.m1.1c">\epsilon</annotation></semantics></math>-DP. Two characteristics of FL make individual fairness a superior choice over group fairness: 1) Data distribution in FL may vary significantly between clients, and individual fairness is more suitable in such cases. Since it is defined at the sample level, thus, it generates better than group notions when addressing new samples which may be distinct from those in the training set; 2) The restricted access to information in FL lends itself more to individual fairness because individual fairness relies on a Lipschitz continual prediction model and does not require access to demographic data. This perfectly fits the FL setting.</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p"><span id="S6.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">How can one satisfy fairness at both the algorithm and client levels in FL?</span> The majority of studies on fairness in FL focus on promoting fairness at the client level. However, client-level fairness does not necessarily imply algorithmic fairness. Consider a scenario where multiple companies (clients) collaborate to train a credit card approval model. Consumer demographic compositions vary between each company. Although a federated model trained subject to client-level fairness constraints might handle the different companies fairly, the model could still be biased towards sensitive attributes (such as race or educational background). This raises a question: <span id="S6.I1.i3.p1.1.2" class="ltx_text ltx_font_italic">How can one satisfy fairness at both the algorithm and the client levels while preserving privacy in FL?</span>.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this article, we conducted a detailed survey of data privacy and model fairness issues in FL. Uniquely, we also documented the interactions between privacy and fairness from the perspective of trade-offs. In terms of privacy in FL, we first reviewed privacy attacks in FL. Then, we presented three kinds of privacy-preserving techniques. Regarding fairness, we first analyzed the possible sources of bias and how bias can be introduced on both the client and server sides. Following a review of the notions of fairness adopted in machine learning and those originating from FL, a discussion of the various fairness-aware FL algorithms is presented. The last part of the survey focused on the interactions between privacy and fairness. We identified three relations in the general context and further listed possible solutions to achieve both fair and private FL.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
This paper is supported by the Australian Research Council Discovery DP200100946 and DP230100246, and NSF under grants III-1763325, III-1909323,III-2106758, and SaTC-1930941.

</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abay et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Annie Abay, Yi Zhou,
Nathalie Baracaldo, Shashank Rajamoni,
Ebube Chuba, and Heiko Ludwig.
2020.

</span>
<span class="ltx_bibblock">Mitigating bias in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.02447</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agarwal et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Alekh Agarwal, Alina
Beygelzimer, Miroslav Dudík, John
Langford, and Hanna Wallach.
2018.

</span>
<span class="ltx_bibblock">A reductions approach to fair classification. In
<em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.
PMLR, 60–69.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agarwal
et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Alekh Agarwal, John
Langford, and Chen-Yu Wei.
2020.

</span>
<span class="ltx_bibblock">Federated residual learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.12880</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alzantot and
Srivastava ([n.d.])</span>
<span class="ltx_bibblock">
Moustafa Alzantot and
Mani Srivastava. [n.d.].

</span>
<span class="ltx_bibblock">Differential Privacy Synthetic Data Generation
using WGANs, 2019.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">URL https://github.
com/nesl/nist_differential_privacy_ synthetic_data_challenge</em>
([n. d.]).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aono et al<span id="bib.bib6.3.3.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Yoshinori Aono, Takuya
Hayashi, Lihua Wang, Shiho Moriai,
et al<span id="bib.bib6.4.1" class="ltx_text">.</span> 2017.

</span>
<span class="ltx_bibblock">Privacy-preserving deep learning: Revisited and
enhanced. In <em id="bib.bib6.5.1" class="ltx_emph ltx_font_italic">International Conference on
Applications and Techniques in Information Security</em>. Springer,
100–110.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arjovsky
et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Martin Arjovsky, Soumith
Chintala, and Léon Bottou.
2017.

</span>
<span class="ltx_bibblock">Wasserstein generative adversarial networks. In
<em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>.
PMLR, 214–223.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ateniese et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Giuseppe Ateniese,
Giovanni Felici, Luigi V. Mancini,
Angelo Spognardi, Antonio Villani, and
Domenico Vitali. 2013.

</span>
<span class="ltx_bibblock">Hacking Smart Machines with Smarter Ones: How to
Extract Meaningful Data from Machine Learning Classifiers.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/ARXIV.1306.4447" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/ARXIV.1306.4447</a>

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Awasthi et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Pranjal Awasthi,
Matthäus Kleindessner, and Jamie
Morgenstern. 2020.

</span>
<span class="ltx_bibblock">Equalized odds postprocessing under imperfect group
information. In <em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">International conference on
artificial intelligence and statistics</em>. PMLR, 1770–1780.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bagdasaryan et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Eugene Bagdasaryan, Omid
Poursaeed, and Vitaly Shmatikov.
2019.

</span>
<span class="ltx_bibblock">Differential privacy has disparate impact on model
accuracy.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 32 (2019),
15479–15488.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Balunović et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Mislav Balunović,
Dimitar I Dimitrov, Robin Staab, and
Martin Vechev. 2021.

</span>
<span class="ltx_bibblock">Bayesian framework for gradient leakage.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2111.04706</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berk et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Richard Berk, Hoda
Heidari, Shahin Jabbari, Matthew Joseph,
Michael Kearns, Jamie Morgenstern,
Seth Neel, and Aaron Roth.
2017.

</span>
<span class="ltx_bibblock">A convex framework for fair regression.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1706.02409</em>
(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berk
et al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Richard Berk, Hoda
Heidari, Shahin Jabbari, Michael Kearns,
and Aaron Roth. 2021a.

</span>
<span class="ltx_bibblock">Fairness in Criminal Justice Risk Assessments: The
State of the Art.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.3.1" class="ltx_emph ltx_font_italic">Sociological Methods &amp; Research</em>
50, 1 (2021),
3–44.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1177/0049124118782533" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1177/0049124118782533</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berk
et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Richard Berk, Hoda
Heidari, Shahin Jabbari, Michael Kearns,
and Aaron Roth. 2021b.

</span>
<span class="ltx_bibblock">Fairness in criminal justice risk assessments: The
state of the art.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">Sociological Methods &amp; Research</em>
50, 1 (2021),
3–44.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bolukbasi et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Tolga Bolukbasi, Kai-Wei
Chang, James Y Zou, Venkatesh Saligrama,
and Adam T Kalai. 2016.

</span>
<span class="ltx_bibblock">Man is to computer programmer as woman is to
homemaker? debiasing word embeddings.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">Advances in neural information processing
systems</em> 29 (2016),
4349–4357.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Keith Bonawitz, Vladimir
Ivanov, Ben Kreuter, Antonio Marcedone,
H Brendan McMahan, Sarvar Patel,
Daniel Ramage, Aaron Segal, and
Karn Seth. 2017.

</span>
<span class="ltx_bibblock">Practical secure aggregation for privacy-preserving
machine learning. In <em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">proceedings of the 2017 ACM
SIGSAC Conference on Computer and Communications Security</em>.
1175–1191.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Keith Bonawitz, Fariborz
Salehi, Jakub Konečnỳ, Brendan
McMahan, and Marco Gruteser.
2019.

</span>
<span class="ltx_bibblock">Federated learning with autotuned
communication-efficient secure aggregation. In
<em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">2019 53rd Asilomar Conference on Signals, Systems,
and Computers</em>. IEEE, 1222–1226.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bordia and Bowman (2019)</span>
<span class="ltx_bibblock">
Shikha Bordia and
Samuel R Bowman. 2019.

</span>
<span class="ltx_bibblock">Identifying and reducing gender bias in word-level
language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1904.03035</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Briggs
et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Christopher Briggs, Zhong
Fan, and Péter András.
2020.

</span>
<span class="ltx_bibblock">Federated learning with hierarchical clustering of
local updates to improve training on non-IID data.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">2020 International Joint Conference on Neural
Networks (IJCNN)</em> (2020), 1–9.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brunet et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Marc-Etienne Brunet,
Colleen Alkalay-Houlihan, Ashton
Anderson, and Richard Zemel.
2019.

</span>
<span class="ltx_bibblock">Understanding the origins of bias in word
embeddings. In <em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">International Conference on Machine
Learning</em>. PMLR, 803–811.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Calders and
Verwer (2010)</span>
<span class="ltx_bibblock">
Toon Calders and Sicco
Verwer. 2010.

</span>
<span class="ltx_bibblock">Three naive bayes approaches for
discrimination-free classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Data mining and knowledge discovery</em>
21, 2 (2010),
277–292.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Canetti et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Ran Canetti, Aloni Cohen,
Nishanth Dikkala, Govind Ramnarayan,
Sarah Scheffler, and Adam Smith.
2019.

</span>
<span class="ltx_bibblock">From Soft Classifiers to Hard Decisions: How fair can
we be?

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1810.02003 [cs.LG]

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang and Shokri (2021)</span>
<span class="ltx_bibblock">
Hongyan Chang and Reza
Shokri. 2021.

</span>
<span class="ltx_bibblock">On the privacy risks of algorithmic fairness. In
<em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">2021 IEEE European Symposium on Security and
Privacy (EuroS&amp;P)</em>. IEEE, 292–303.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chaudhuri
et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2011)</span>
<span class="ltx_bibblock">
Kamalika Chaudhuri, Claire
Monteleoni, and Anand D Sarwate.
2011.

</span>
<span class="ltx_bibblock">Differentially private empirical risk
minimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>
12, 3 (2011).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen
et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Daoyuan Chen, Dawei Gao,
Weirui Kuang, Yaliang Li, and
Bolin Ding. 2022.

</span>
<span class="ltx_bibblock">pFL-Bench: A Comprehensive Benchmark for
Personalized Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.03655</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Chao (2021)</span>
<span class="ltx_bibblock">
Hong-You Chen and
Wei-Lun Chao. 2021.

</span>
<span class="ltx_bibblock">On Bridging Generic and Personalized Federated
Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.00778</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen
et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2020c)</span>
<span class="ltx_bibblock">
Junjie Chen, Wendy Hui
Wang, and Xinghua Shi.
2020c.

</span>
<span class="ltx_bibblock">Differential privacy protection against membership
inference attack on machine learning for genomic data. In
<em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">BIOCOMPUTING 2021: Proceedings of the Pacific
Symposium</em>. World Scientific, 26–37.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen
et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Si Chen, Ruoxi Jia, and
Guo-Jun Qi. 2020a.

</span>
<span class="ltx_bibblock">Improved Techniques for Model Inversion Attacks.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.04092</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen
et al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Yu Chen, Fang Luo,
Tong Li, Tao Xiang,
Zheli Liu, and Jin Li.
2020b.

</span>
<span class="ltx_bibblock">A training-integrity privacy-preserving federated
learning scheme with trusted execution environment.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.3.1" class="ltx_emph ltx_font_italic">Information Sciences</em> 522
(2020), 69–79.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho
et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yae Jee Cho, Jianyu Wang,
and Gauri Joshi. 2020.

</span>
<span class="ltx_bibblock">Client selection in federated learning: Convergence
analysis and power-of-choice selection strategies.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.01243</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chouldechova (2017)</span>
<span class="ltx_bibblock">
Alexandra Chouldechova.
2017.

</span>
<span class="ltx_bibblock">Fair prediction with disparate impact: A study of
bias in recidivism prediction instruments.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Big data</em> 5,
2 (2017), 153–163.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chouldechova and
Roth (2018)</span>
<span class="ltx_bibblock">
Alexandra Chouldechova and
Aaron Roth. 2018.

</span>
<span class="ltx_bibblock">The frontiers of fairness in machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1810.08810</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chu
et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Lingyang Chu, Lanjun
Wang, Yanjie Dong, Jian Pei,
Zirui Zhou, and Yong Zhang.
2021.

</span>
<span class="ltx_bibblock">FedFair: Training Fair Models In Cross-Silo
Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/2109.05662
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui
et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Sen Cui, Weishen Pan,
Jian Liang, Changshui Zhang, and
Fei Wang. 2021.

</span>
<span class="ltx_bibblock">Addressing algorithmic disparity and performance
inconsistency in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 34 (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cummings et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Rachel Cummings, Varun
Gupta, Dhamma Kimpara, and Jamie
Morgenstern. 2019.

</span>
<span class="ltx_bibblock">On the compatibility of privacy and fairness. In
<em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">Adjunct Publication of the 27th Conference on User
Modeling, Adaptation and Personalization</em>. 309–315.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">d’Alessandro et al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Brian d’Alessandro, Cathy
O’Neil, and Tom LaGatta.
2017.

</span>
<span class="ltx_bibblock">Conscientious classification: A data scientist’s
guide to discrimination-aware classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.3.1" class="ltx_emph ltx_font_italic">Big data</em> 5,
2 (2017), 120–134.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng
et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yuyang Deng,
Mohammad Mahdi Kamani, and Mehrdad
Mahdavi. 2020.

</span>
<span class="ltx_bibblock">Adaptive personalized federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.13461</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding
et al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jiahao Ding, Xinyue
Zhang, Xiaohuan Li, Junyi Wang,
Rong Yu, and Miao Pan.
2020.

</span>
<span class="ltx_bibblock">Differentially private and fair classification via
calibrated functional mechanism. In <em id="bib.bib38.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the AAAI Conference on Artificial Intelligence</em>, Vol. 34.
622–629.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dinh
et al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Canh T Dinh, Tung T Vu,
Nguyen H Tran, Minh N Dao, and
Hongyu Zhang. 2021.

</span>
<span class="ltx_bibblock">FedU: A Unified Framework for Federated Multi-Task
Learning with Laplacian Regularization.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2102.07148</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dinur and Nissim (2003)</span>
<span class="ltx_bibblock">
Irit Dinur and Kobbi
Nissim. 2003.

</span>
<span class="ltx_bibblock">Revealing information while preserving privacy. In
<em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Proceedings of the twenty-second ACM
SIGMOD-SIGACT-SIGART symposium on Principles of database systems</em>.
202–210.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du
et al<span id="bib.bib41.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Wei Du, Depeng Xu,
Xintao Wu, and Hanghang Tong.
2021.

</span>
<span class="ltx_bibblock">Fairness-aware Agnostic Federated Learning. In
<em id="bib.bib41.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 SIAM International
Conference on Data Mining (SDM)</em>. SIAM, 181–189.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duan
et al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
M. Duan, D. Liu,
X. Chen, R. Liu, Y.
Tan, and L. Liang. 2021.

</span>
<span class="ltx_bibblock">Self-Balancing Federated Learning With Global
Imbalanced Data in Mobile Systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel &amp; Distributed
Systems</em> 32, 01 (2021),
59–71.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TPDS.2020.3009406" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TPDS.2020.3009406</a>

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork (2008)</span>
<span class="ltx_bibblock">
Cynthia Dwork.
2008.

</span>
<span class="ltx_bibblock">Differential privacy: A survey of results. In
<em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">International conference on theory and applications
of models of computation</em>. Springer, 1–19.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork et al<span id="bib.bib44.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Cynthia Dwork, Moritz
Hardt, Toniann Pitassi, Omer Reingold,
and Richard Zemel. 2012.

</span>
<span class="ltx_bibblock">Fairness through awareness. In
<em id="bib.bib44.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 3rd innovations in theoretical
computer science conference</em>. 214–226.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork
et al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2006)</span>
<span class="ltx_bibblock">
Cynthia Dwork, Frank
McSherry, Kobbi Nissim, and Adam
Smith. 2006.

</span>
<span class="ltx_bibblock">Calibrating Noise to Sensitivity in Private Data
Analysis. In <em id="bib.bib45.3.1" class="ltx_emph ltx_font_italic">Theory of Cryptography</em>,
Shai Halevi and Tal
Rabin (Eds.). Springer Berlin Heidelberg,
Berlin, Heidelberg, 265–284.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Esipova
et al<span id="bib.bib46.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Maria S Esipova,
Atiyeh Ashari Ghomi, Yaqiao Luo, and
Jesse C Cresswell. 2022.

</span>
<span class="ltx_bibblock">Disparate Impact in Differential Privacy from
Gradient Misalignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.07737</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ezzeldin et al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yahya H Ezzeldin, Shen
Yan, Chaoyang He, Emilio Ferrara, and
Salman Avestimehr. 2021.

</span>
<span class="ltx_bibblock">Fairfed: Enabling group fairness in federated
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.00857</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fallah
et al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Alireza Fallah, Aryan
Mokhtari, and Asuman Ozdaglar.
2020.

</span>
<span class="ltx_bibblock">Personalized Federated Learning with Theoretical
Guarantees: A Model-Agnostic Meta-Learning Approach. In
<em id="bib.bib48.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em>, Vol. 33. 3557–3568.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan
et al<span id="bib.bib49.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Lixin Fan, Kam Woh Ng,
Ce Ju, Tianyu Zhang,
Chang Liu, Chee Seng Chan, and
Qiang Yang. 2020.

</span>
<span class="ltx_bibblock">Rethinking privacy preserving deep learning: How to
evaluate and thwart privacy attacks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib49.3.1" class="ltx_emph ltx_font_italic">Federated Learning</em>.
Springer, 32–50.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Farrand et al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tom Farrand, Fatemehsadat
Mireshghallah, Sahib Singh, and Andrew
Trask. 2020.

</span>
<span class="ltx_bibblock">Neither private nor fair: Impact of data imbalance
on utility and fairness in differential privacy. In
<em id="bib.bib50.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 workshop on
privacy-preserving machine learning in practice</em>. 15–19.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feldman et al<span id="bib.bib51.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Michael Feldman, Sorelle A
Friedler, John Moeller, Carlos
Scheidegger, and Suresh Venkatasubramanian.
2015.

</span>
<span class="ltx_bibblock">Certifying and removing disparate impact. In
<em id="bib.bib51.3.1" class="ltx_emph ltx_font_italic">proceedings of the 21th ACM SIGKDD international
conference on knowledge discovery and data mining</em>.
259–268.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Finn
et al<span id="bib.bib52.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Chelsea Finn, Pieter
Abbeel, and Sergey Levine.
2017.

</span>
<span class="ltx_bibblock">Model-agnostic meta-learning for fast adaptation of
deep networks. In <em id="bib.bib52.3.1" class="ltx_emph ltx_font_italic">International Conference on
Machine Learning</em>. PMLR, 1126–1135.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Font and
Costa-jussà (2019)</span>
<span class="ltx_bibblock">
Joel Escudé Font and
Marta R Costa-jussà. 2019.

</span>
<span class="ltx_bibblock">Equalizing Gender Bias in Neural Machine
Translation with Word Embeddings Techniques. In
<em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Proceedings of the First Workshop on Gender Bias in
Natural Language Processing</em>. 147–154.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fowl et al<span id="bib.bib54.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Liam Fowl, Jonas Geiping,
Wojtek Czaja, Micah Goldblum, and
Tom Goldstein. 2021.

</span>
<span class="ltx_bibblock">Robbing the Fed: Directly Obtaining Private Data in
Federated Learning with Modified Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.13057</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fredrikson
et al<span id="bib.bib55.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Matt Fredrikson, Somesh
Jha, and Thomas Ristenpart.
2015.

</span>
<span class="ltx_bibblock">Model inversion attacks that exploit confidence
information and basic countermeasures. In
<em id="bib.bib55.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 22nd ACM SIGSAC conference on
computer and communications security</em>. 1322–1333.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fredrikson et al<span id="bib.bib56.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Matthew Fredrikson, Eric
Lantz, Somesh Jha, Simon Lin,
David Page, and Thomas Ristenpart.
2014.

</span>
<span class="ltx_bibblock">Privacy in Pharmacogenetics: An End-to-End Case
Study of Personalized Warfarin Dosing. In <em id="bib.bib56.3.1" class="ltx_emph ltx_font_italic">23rd
USENIX Security Symposium (USENIX Security 14)</em>.
USENIX Association, San Diego, CA,
17–32.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/fredrikson_matthew" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/fredrikson_matthew</a>

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">G’alvez et al<span id="bib.bib57.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Borja Rodr’iguez G’alvez,
Filip Granqvist, Rogier C. van Dalen,
and Matthew Stephen Seigel.
2021.

</span>
<span class="ltx_bibblock">Enforcing fairness in private federated learning
via the modified method of differential multipliers.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/2109.08604
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ganev
et al<span id="bib.bib58.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Georgi Ganev, Bristena
Oprisanu, and Emiliano De Cristofaro.
2022.

</span>
<span class="ltx_bibblock">Robin Hood and Matthew Effects: Differential
Privacy Has Disparate Impact on Synthetic Data. In
<em id="bib.bib58.3.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.
PMLR, 6944–6959.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ganju
et al<span id="bib.bib59.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Karan Ganju, Qi Wang,
Wei Yang, Carl A. Gunter, and
Nikita Borisov. 2018.

</span>
<span class="ltx_bibblock">Property Inference Attacks on Fully Connected
Neural Networks Using Permutation Invariant Representations. In
<em id="bib.bib59.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 ACM SIGSAC Conference on
Computer and Communications Security</em> (Toronto, Canada)
<em id="bib.bib59.4.2" class="ltx_emph ltx_font_italic">(CCS ’18)</em>. Association for
Computing Machinery, New York, NY, USA,
619–633.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3243734.3243834" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3243734.3243834</a>

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geiping et al<span id="bib.bib60.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jonas Geiping, Hartmut
Bauermeister, Hannah Dröge, and
Michael Moeller. 2020.

</span>
<span class="ltx_bibblock">Inverting Gradients–How easy is it to break
privacy in federated learning?

</span>
<span class="ltx_bibblock"><em id="bib.bib60.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.14053</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geyer
et al<span id="bib.bib61.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Robin C Geyer, Tassilo
Klein, and Moin Nabi. 2017.

</span>
<span class="ltx_bibblock">Differentially private federated learning: A client
level perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1712.07557</em>
(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghosh
et al<span id="bib.bib62.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Avishek Ghosh, Jichan
Chung, Dong Yin, and Kannan
Ramchandran. 2020.

</span>
<span class="ltx_bibblock">An Efficient Framework for Clustered Federated
Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 33 (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goh
et al<span id="bib.bib63.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Gabriel Goh, Andrew
Cotter, Maya Gupta, and Michael P
Friedlander. 2016.

</span>
<span class="ltx_bibblock">Satisfying real-world goals with dataset
constraints. In <em id="bib.bib63.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information
Processing Systems</em>. 2415–2423.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Golub and
Van Loan (2013)</span>
<span class="ltx_bibblock">
Gene H Golub and
Charles F Van Loan. 2013.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">Matrix computations</em>.

</span>
<span class="ltx_bibblock">JHU press.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodman (2016)</span>
<span class="ltx_bibblock">
Bryce W Goodman.
2016.

</span>
<span class="ltx_bibblock">A step towards accountable algorithms?: Algorithmic
discrimination and the European Union general data protection. In
<em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">29th Conference on Neural Information Processing
Systems (NIPS 2016), Barcelona. NIPS Foundation</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al<span id="bib.bib66.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Zhongshu Gu, Heqing
Huang, Jialong Zhang, Dong Su,
Hani Jamjoom, Ankita Lamba,
Dimitrios Pendarakis, and Ian Molloy.
2019.

</span>
<span class="ltx_bibblock">Yerbabuena: Securing deep learning inference data
via enclave-based ternary model partitioning.

</span>
<span class="ltx_bibblock">(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta
et al<span id="bib.bib67.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Maya Gupta, Andrew
Cotter, Mahdi Milani Fard, and Serena
Wang. 2018.

</span>
<span class="ltx_bibblock">Proxy Fairness.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1806.11212 [cs.LG]

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta and Raskar (2018)</span>
<span class="ltx_bibblock">
Otkrist Gupta and Ramesh
Raskar. 2018.

</span>
<span class="ltx_bibblock">Distributed learning of deep neural network over
multiple agents.

</span>
<span class="ltx_bibblock"><em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">Journal of Network and Computer
Applications</em> 116 (2018),
1–8.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta
et al<span id="bib.bib69.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Samyak Gupta, Yangsibo
Huang, Zexuan Zhong, Tianyu Gao,
Kai Li, and Danqi Chen.
2022.

</span>
<span class="ltx_bibblock">Recovering private text in federated learning of
language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib69.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.08514</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Haddadpour
et al<span id="bib.bib70.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Farzin Haddadpour, Belhal
Karimi, Ping Li, and Xiaoyun Li.
2020.

</span>
<span class="ltx_bibblock">Fedsketch: Communication-efficient and private
federated learning via sketching.

</span>
<span class="ltx_bibblock"><em id="bib.bib70.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2008.04975</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hanzely and
Richtárik (2021)</span>
<span class="ltx_bibblock">
Filip Hanzely and Peter
Richtárik. 2021.

</span>
<span class="ltx_bibblock">Federated Learning of a Mixture of Global and Local
Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2002.05516 [cs.LG]

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hao et al<span id="bib.bib72.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Weituo Hao, Mostafa
El-Khamy, Jungwon Lee, Jianyi Zhang,
Kevin J Liang, Changyou Chen, and
Lawrence Carin Duke. 2021.

</span>
<span class="ltx_bibblock">Towards Fair Federated Learning With Zero-Shot Data
Augmentation. In <em id="bib.bib72.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em>.
3310–3319.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hard et al<span id="bib.bib73.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Andrew Hard, Kanishka
Rao, Rajiv Mathews, Swaroop Ramaswamy,
Françoise Beaufays, Sean
Augenstein, Hubert Eichner, Chloé
Kiddon, and Daniel Ramage.
2018.

</span>
<span class="ltx_bibblock">Federated learning for mobile keyboard prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib73.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.03604</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hardt
et al<span id="bib.bib74.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Moritz Hardt, Eric Price,
and Nati Srebro. 2016.

</span>
<span class="ltx_bibblock">Equality of opportunity in supervised learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib74.3.1" class="ltx_emph ltx_font_italic">Advances in neural information processing
systems</em> 29 (2016),
3315–3323.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hatamizadeh et al<span id="bib.bib75.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Ali Hatamizadeh, Hongxu
Yin, Holger R Roth, Wenqi Li,
Jan Kautz, Daguang Xu, and
Pavlo Molchanov. 2022.

</span>
<span class="ltx_bibblock">Gradvit: Gradient inversion of vision
transformers. In <em id="bib.bib75.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition</em>.
10021–10030.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hitaj
et al<span id="bib.bib76.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Briland Hitaj, Giuseppe
Ateniese, and Fernando Perez-Cruz.
2017.

</span>
<span class="ltx_bibblock">Deep models under the GAN: information leakage from
collaborative deep learning. In <em id="bib.bib76.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
2017 ACM SIGSAC Conference on Computer and Communications Security</em>.
603–618.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu
et al<span id="bib.bib77.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Zeou Hu, Kiarash
Shaloudegi, Guojun Zhang, and Yaoliang
Yu. 2020.

</span>
<span class="ltx_bibblock">FedMGDA+: Federated Learning meets Multi-objective
Optimization.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2006.11489 [cs.LG]

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang
et al<span id="bib.bib78.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Wei Huang, Tianrui Li,
Dexian Wang, Shengdong Du, and
Junbo Zhang. 2020a.

</span>
<span class="ltx_bibblock">Fairness and Accuracy in Federated Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2012.10069 [cs.LG]

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang
et al<span id="bib.bib79.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yangsibo Huang, Samyak
Gupta, Zhao Song, Kai Li, and
Sanjeev Arora. 2021.

</span>
<span class="ltx_bibblock">Evaluating gradient inversion attacks and defenses
in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib79.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 34 (2021),
7232–7241.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang
et al<span id="bib.bib80.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Yangsibo Huang, Zhao
Song, Kai Li, and Sanjeev Arora.
2020b.

</span>
<span class="ltx_bibblock">Instahide: Instance-hiding schemes for private
distributed learning. In <em id="bib.bib80.3.1" class="ltx_emph ltx_font_italic">International conference
on machine learning</em>. PMLR, 4507–4518.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hynes
et al<span id="bib.bib81.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Nick Hynes, Raymond
Cheng, and Dawn Song. 2018.

</span>
<span class="ltx_bibblock">Efficient deep learning on multi-source private
data.

</span>
<span class="ltx_bibblock"><em id="bib.bib81.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1807.06689</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jagielski et al<span id="bib.bib82.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Matthew Jagielski, Michael
Kearns, Jieming Mao, Alina Oprea,
Aaron Roth, Saeed Sharifi-Malvajerdi,
and Jonathan Ullman. 2019.

</span>
<span class="ltx_bibblock">Differentially private fair learning. In
<em id="bib.bib82.3.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.
PMLR, 3000–3008.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jeon
et al<span id="bib.bib83.3.3.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Jiwnoo Jeon, Kangwook
Lee, Sewoong Oh, Jungseul Ok,
et al<span id="bib.bib83.4.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">Gradient Inversion with Generative Image Prior.

</span>
<span class="ltx_bibblock"><em id="bib.bib83.5.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 34 (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jeong
et al<span id="bib.bib84.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Eunjeong Jeong, Seungeun
Oh, Hyesung Kim, Jihong Park,
Mehdi Bennis, and Seong-Lyun Kim.
2018.

</span>
<span class="ltx_bibblock">Communication-Efficient On-Device Machine Learning:
Federated Distillation and Augmentation under Non-IID Private Data.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1811.11479 [cs.LG]

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang
et al<span id="bib.bib85.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Yihan Jiang, Jakub
Konečný, Keith Rush, and Sreeram
Kannan. 2019.

</span>
<span class="ltx_bibblock">Improving Federated Learning Personalization via
Model Agnostic Meta Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1909.12488 [cs.LG]

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al<span id="bib.bib86.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Zhimeng Jiang, Xiaotian
Han, Chao Fan, Fan Yang,
Ali Mostafavi, and Xia Hu.
2022.

</span>
<span class="ltx_bibblock">Generalized demographic parity for group fairness.
In <em id="bib.bib86.3.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang
et al<span id="bib.bib87.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Zhifeng Jiang, Wei Wang,
and Yang Liu. 2021.

</span>
<span class="ltx_bibblock">FLASHE: Additively Symmetric Homomorphic Encryption
for Cross-Silo Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib87.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.00675</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin
et al<span id="bib.bib88.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Xiao Jin, Pin-Yu Chen,
Chia-Yi Hsu, Chia-Mu Yu, and
Tianyi Chen. 2021.

</span>
<span class="ltx_bibblock">Catastrophic Data Leakage in Vertical Federated
Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib88.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 34 (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jordon
et al<span id="bib.bib89.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
James Jordon, Jinsung
Yoon, and Mihaela Van Der Schaar.
2019.

</span>
<span class="ltx_bibblock">PATE-GAN: Generating synthetic data with
differential privacy guarantees. In <em id="bib.bib89.3.1" class="ltx_emph ltx_font_italic">International
conference on learning representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz
et al<span id="bib.bib90.3.3.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Peter Kairouz, H Brendan
McMahan, Brendan Avent, Aurélien
Bellet, Mehdi Bennis, Arjun Nitin
Bhagoji, Kallista Bonawitz, Zachary
Charles, Graham Cormode, Rachel
Cummings, et al<span id="bib.bib90.4.1" class="ltx_text">.</span> 2019.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib90.5.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.04977</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kallus
et al<span id="bib.bib91.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Nathan Kallus, Xiaojie
Mao, and Angela Zhou. 2020.

</span>
<span class="ltx_bibblock">Assessing Algorithmic Fairness with Unobserved
Protected Class Using Data Combination.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1906.00285 [stat.ML]

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kamiran and
Calders (2010)</span>
<span class="ltx_bibblock">
Faisal Kamiran and Toon
Calders. 2010.

</span>
<span class="ltx_bibblock">Classification with no discrimination by
preferential sampling. In <em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">Proc. 19th Machine
Learning Conf. Belgium and The Netherlands</em>. Citeseer,
1–6.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kamiran and
Calders (2012)</span>
<span class="ltx_bibblock">
Faisal Kamiran and Toon
Calders. 2012.

</span>
<span class="ltx_bibblock">Data preprocessing techniques for classification
without discrimination.

</span>
<span class="ltx_bibblock"><em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">Knowledge and information systems</em>
33, 1 (2012),
1–33.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kamishima
et al<span id="bib.bib94.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Toshihiro Kamishima,
Shotaro Akaho, Hideki Asoh, and
Jun Sakuma. 2012.

</span>
<span class="ltx_bibblock">Fairness-aware classifier with prejudice remover
regularizer. In <em id="bib.bib94.3.1" class="ltx_emph ltx_font_italic">Joint European conference on
machine learning and knowledge discovery in databases</em>. Springer,
35–50.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kamishima
et al<span id="bib.bib95.2.2.1" class="ltx_text">.</span> (2011)</span>
<span class="ltx_bibblock">
Toshihiro Kamishima,
Shotaro Akaho, and Jun Sakuma.
2011.

</span>
<span class="ltx_bibblock">Fairness-aware Learning through Regularization
Approach. In <em id="bib.bib95.3.1" class="ltx_emph ltx_font_italic">2011 IEEE 11th International
Conference on Data Mining Workshops</em>. 643–650.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ICDMW.2011.83" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICDMW.2011.83</a>

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kanaparthy et al<span id="bib.bib96.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Samhita Kanaparthy,
Manisha Padala, Sankarshan Damle, and
Sujit Gujar. 2022.

</span>
<span class="ltx_bibblock">Fair Federated Learning for Heterogeneous Data. In
<em id="bib.bib96.3.1" class="ltx_emph ltx_font_italic">5th Joint International Conference on Data Science
&amp;amp; Management of Data (9th ACM IKDD CODS and 27th COMAD)</em> (Bangalore,
India) <em id="bib.bib96.4.2" class="ltx_emph ltx_font_italic">(CODS-COMAD 2022)</em>.
Association for Computing Machinery,
New York, NY, USA, 298–299.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3493700.3493750" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3493700.3493750</a>

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karnin
et al<span id="bib.bib97.2.2.1" class="ltx_text">.</span> (1983)</span>
<span class="ltx_bibblock">
Ehud Karnin, Jonathan
Greene, and Martin Hellman.
1983.

</span>
<span class="ltx_bibblock">On secret sharing systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib97.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Theory</em>
29, 1 (1983),
35–41.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kato
et al<span id="bib.bib98.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Fumiyuki Kato, Yang Cao,
and Masatoshi Yoshikawa.
2022.

</span>
<span class="ltx_bibblock">OLIVE: Oblivious and Differentially Private
Federated Learning on Trusted Execution Environment.

</span>
<span class="ltx_bibblock"><em id="bib.bib98.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2202.07165</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khalili
et al<span id="bib.bib99.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Mohammad Mahdi Khalili,
Xueru Zhang, Mahed Abroshan, and
Somayeh Sojoudi. 2021.

</span>
<span class="ltx_bibblock">Improving Fairness and Privacy in Selection
Problems. In <em id="bib.bib99.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on
Artificial Intelligence</em>, Vol. 35.
8092–8100.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khedr and Shoukry (2022)</span>
<span class="ltx_bibblock">
Haitham Khedr and Yasser
Shoukry. 2022.

</span>
<span class="ltx_bibblock">Certifair: A framework for certified global
fairness of neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.09927</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khodak
et al<span id="bib.bib101.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Mikhail Khodak,
Maria-Florina F Balcan, and Ameet S
Talwalkar. 2019.

</span>
<span class="ltx_bibblock">Adaptive Gradient-Based Meta-Learning Methods.

</span>
<span class="ltx_bibblock"><em id="bib.bib101.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 32 (2019),
5917–5928.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kilbertus et al<span id="bib.bib102.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Niki Kilbertus, Adrià
Gascón, Matt Kusner, Michael Veale,
Krishna Gummadi, and Adrian Weller.
2018.

</span>
<span class="ltx_bibblock">Blind justice: Fairness with encrypted sensitive
attributes. In <em id="bib.bib102.3.1" class="ltx_emph ltx_font_italic">International Conference on Machine
Learning</em>. PMLR, 2630–2639.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirkpatrick et al<span id="bib.bib103.3.3.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
James Kirkpatrick, Razvan
Pascanu, Neil Rabinowitz, Joel Veness,
Guillaume Desjardins, Andrei A Rusu,
Kieran Milan, John Quan,
Tiago Ramalho, Agnieszka
Grabska-Barwinska, et al<span id="bib.bib103.4.1" class="ltx_text">.</span> 2017.

</span>
<span class="ltx_bibblock">Overcoming catastrophic forgetting in neural
networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib103.5.1" class="ltx_emph ltx_font_italic">Proceedings of the national academy of
sciences</em> 114, 13
(2017), 3521–3526.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kleinberg et al<span id="bib.bib104.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Jon Kleinberg, Sendhil
Mullainathan, and Manish Raghavan.
2017.

</span>
<span class="ltx_bibblock">Inherent Trade-Offs in the Fair Determination of
Risk Scores. In <em id="bib.bib104.3.1" class="ltx_emph ltx_font_italic">8th Innovations in Theoretical
Computer Science Conference (ITCS 2017)</em>. Schloss Dagstuhl-Leibniz-Zentrum
fuer Informatik.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kulkarni
et al<span id="bib.bib105.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Viraj Kulkarni, Milind
Kulkarni, and Aniruddha Pant.
2020.

</span>
<span class="ltx_bibblock">Survey of personalization techniques for federated
learning. In <em id="bib.bib105.3.1" class="ltx_emph ltx_font_italic">2020 Fourth World Conference on Smart
Trends in Systems, Security and Sustainability (WorldS4)</em>. IEEE,
794–797.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kuppam et al<span id="bib.bib106.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Satya Kuppam, Ryan
McKenna, David Pujol, Michael Hay,
Ashwin Machanavajjhala, and Gerome
Miklau. 2020.

</span>
<span class="ltx_bibblock">Fair decision making using privacy-protected data.

</span>
<span class="ltx_bibblock"><em id="bib.bib106.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on
Fairness, Accountability, and Transparency</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kusner
et al<span id="bib.bib107.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Matt J. Kusner, Joshua R.
Loftus, Chris Russell, and Ricardo
Silva. 2018.

</span>
<span class="ltx_bibblock">Counterfactual Fairness.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1703.06856 [stat.ML]

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lamy
et al<span id="bib.bib108.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Alex Lamy, Ziyuan Zhong,
Aditya K Menon, and Nakul Verma.
2019.

</span>
<span class="ltx_bibblock">Noise-tolerant fair classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib108.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 32 (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lan
et al<span id="bib.bib109.2.2.1" class="ltx_text">.</span> (2010)</span>
<span class="ltx_bibblock">
Tian Lan, David Kao,
Mung Chiang, and Ashutosh Sabharwal.
2010.

</span>
<span class="ltx_bibblock"><em id="bib.bib109.3.1" class="ltx_emph ltx_font_italic">An axiomatic theory of fairness in network
resource allocation</em>.

</span>
<span class="ltx_bibblock">IEEE.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Leino and
Fredrikson (2020)</span>
<span class="ltx_bibblock">
Klas Leino and Matt
Fredrikson. 2020.

</span>
<span class="ltx_bibblock">Stolen Memories: Leveraging Model Memorization for
Calibrated <math id="bib.bib110.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib110.1.m1.1a"><mo stretchy="false" id="bib.bib110.1.m1.1.1" xref="bib.bib110.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib110.1.m1.1b"><ci id="bib.bib110.1.m1.1.1.cmml" xref="bib.bib110.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib110.1.m1.1c">\{</annotation></semantics></math>White-Box<math id="bib.bib110.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib110.2.m2.1a"><mo stretchy="false" id="bib.bib110.2.m2.1.1" xref="bib.bib110.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib110.2.m2.1b"><ci id="bib.bib110.2.m2.1.1.cmml" xref="bib.bib110.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib110.2.m2.1c">\}</annotation></semantics></math> Membership Inference. In
<em id="bib.bib110.3.1" class="ltx_emph ltx_font_italic">29th USENIX security symposium (USENIX Security
20)</em>. 1605–1622.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Wang (2019)</span>
<span class="ltx_bibblock">
Daliang Li and Junpu
Wang. 2019.

</span>
<span class="ltx_bibblock">Fedmd: Heterogenous federated learning via model
distillation.

</span>
<span class="ltx_bibblock"><em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.03581</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span id="bib.bib112.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Tian Li, Shengyuan Hu,
Ahmad Beirami, and Virginia Smith.
2021.

</span>
<span class="ltx_bibblock">Ditto: Fair and Robust Federated Learning Through
Personalization. In <em id="bib.bib112.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 38th
International Conference on Machine Learning</em>
<em id="bib.bib112.4.2" class="ltx_emph ltx_font_italic">(Proceedings of Machine Learning Research,
Vol. 139)</em>, Marina
Meila and Tong Zhang (Eds.). PMLR,
6357–6368.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.mlr.press/v139/li21h.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v139/li21h.html</a>

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span id="bib.bib113.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Tian Li, Zaoxing Liu,
Vyas Sekar, and Virginia Smith.
2019a.

</span>
<span class="ltx_bibblock">Privacy for free: Communication-efficient learning
with differential privacy using sketches.

</span>
<span class="ltx_bibblock"><em id="bib.bib113.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.00972</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib114.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu,
Manzil Zaheer, Maziar Sanjabi,
Ameet Talwalkar, and Virginia Smith.
2020.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib114.3.1" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning and Systems</em>
2 (2020), 429–450.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span id="bib.bib115.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Tian Li, Maziar Sanjabi,
Ahmad Beirami, and Virginia Smith.
2019b.

</span>
<span class="ltx_bibblock">Fair resource allocation in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib115.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1905.10497</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span id="bib.bib116.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Zhize Li, Haoyu Zhao,
Boyue Li, and Yuejie Chi.
2022.

</span>
<span class="ltx_bibblock">SoteriaFL: A unified framework for private
federated learning with communication compression.

</span>
<span class="ltx_bibblock"><em id="bib.bib116.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.09888</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al<span id="bib.bib117.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Paul Pu Liang, Terrance
Liu, Liu Ziyin, Nicholas B. Allen,
Randy P. Auerbach, David Brent,
Ruslan Salakhutdinov, and Louis-Philippe
Morency. 2020.

</span>
<span class="ltx_bibblock">Think Locally, Act Globally: Federated Learning with
Local and Global Representations.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2001.01523 [cs.LG]

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin
et al<span id="bib.bib118.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Shiyun Lin, Yuze Han,
Xiang Li, and Zhihua Zhang.
2022.

</span>
<span class="ltx_bibblock">Personalized Federated Learning towards
Communication Efficiency, Robustness and Fairness.

</span>
<span class="ltx_bibblock"><em id="bib.bib118.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu and Meng (2020)</span>
<span class="ltx_bibblock">
Junxu Liu and Xiaofeng
Meng. 2020.

</span>
<span class="ltx_bibblock">Survey on privacy-preserving machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib119.1.1" class="ltx_emph ltx_font_italic">Journal of Computer Research and
Development</em> 57, 2
(2020), 346.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu
et al<span id="bib.bib120.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yang Liu, Yan Kang,
Chaoping Xing, Tianjian Chen, and
Qiang Yang. 2020.

</span>
<span class="ltx_bibblock">A secure federated transfer learning framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib120.3.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em>
35, 4 (2020),
70–82.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lohia et al<span id="bib.bib121.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Pranay K. Lohia,
Karthikeyan Natesan Ramamurthy, Manish
Bhide, Diptikalyan Saha, Kush R.
Varshney, and Ruchir Puri.
2019.

</span>
<span class="ltx_bibblock">Bias Mitigation Post-processing for Individual and
Group Fairness. In <em id="bib.bib121.3.1" class="ltx_emph ltx_font_italic">ICASSP 2019 - 2019 IEEE
International Conference on Acoustics, Speech and Signal Processing
(ICASSP)</em>. 2847–2851.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ICASSP.2019.8682620" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICASSP.2019.8682620</a>

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Louizos et al<span id="bib.bib122.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Christos Louizos, Kevin
Swersky, Yujia Li, Max Welling, and
Richard S Zemel. 2016.

</span>
<span class="ltx_bibblock">The Variational Fair Autoencoder. In
<em id="bib.bib122.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lowy
et al<span id="bib.bib123.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Andrew Lowy, Devansh
Gupta, and Meisam Razaviyayn.
2023.

</span>
<span class="ltx_bibblock">Stochastic Differentially Private and Fair
Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib123.3.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo
et al<span id="bib.bib124.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Mi Luo, Fei Chen,
Dapeng Hu, Yifan Zhang,
Jian Liang, and Jiashi Feng.
2021.

</span>
<span class="ltx_bibblock">No Fear of Heterogeneity: Classifier Calibration
for Federated Learning with Non-IID Data. In
<em id="bib.bib124.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em>, A. Beygelzimer,
Y. Dauphin, P. Liang, and
J. Wortman Vaughan (Eds.).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://openreview.net/forum?id=AFiH_CNnVhS" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=AFiH_CNnVhS</a>

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu et al<span id="bib.bib125.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Lingjuan Lyu, Han Yu,
and Qiang Yang. 2020.

</span>
<span class="ltx_bibblock">Threats to federated learning: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib125.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.02133</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma
et al<span id="bib.bib126.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Xindi Ma, Baopu Li,
Qi Jiang, Yimin Chen,
Sheng Gao, and Jianfeng Ma.
2021.

</span>
<span class="ltx_bibblock">NOSnoop: An effective collaborative meta-learning
scheme against property inference attack.

</span>
<span class="ltx_bibblock"><em id="bib.bib126.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>
9, 9 (2021),
6778–6789.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mansour
et al<span id="bib.bib127.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yishay Mansour, Mehryar
Mohri, Jae Ro, and Ananda Theertha
Suresh. 2020.

</span>
<span class="ltx_bibblock">Three approaches for personalization with
applications to federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib127.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.10619</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Martinez
et al<span id="bib.bib128.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Natalia Martinez, Martin
Bertran, and Guillermo Sapiro.
2020.

</span>
<span class="ltx_bibblock">Minimax Pareto Fairness: A Multi Objective
Perspective. In <em id="bib.bib128.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 37th
International Conference on Machine Learning</em>
<em id="bib.bib128.4.2" class="ltx_emph ltx_font_italic">(Proceedings of Machine Learning Research,
Vol. 119)</em>, Hal Daumé
III and Aarti Singh (Eds.). PMLR,
6755–6764.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">May
et al<span id="bib.bib129.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Chandler May, Alex Wang,
Shikha Bordia, Samuel R Bowman, and
Rachel Rudinger. 2019.

</span>
<span class="ltx_bibblock">On measuring social biases in sentence encoders.

</span>
<span class="ltx_bibblock"><em id="bib.bib129.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1903.10561</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al<span id="bib.bib130.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider
Moore, Daniel Ramage, Seth Hampson,
and Blaise Aguera y Arcas.
2017.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks
from decentralized data. In <em id="bib.bib130.3.1" class="ltx_emph ltx_font_italic">Artificial
intelligence and statistics</em>. PMLR, 1273–1282.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McSherry and
Talwar (2007)</span>
<span class="ltx_bibblock">
Frank McSherry and Kunal
Talwar. 2007.

</span>
<span class="ltx_bibblock">Mechanism design via differential privacy. In
<em id="bib.bib131.1.1" class="ltx_emph ltx_font_italic">48th Annual IEEE Symposium on Foundations of
Computer Science (FOCS’07)</em>. IEEE, 94–103.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mehrabi et al<span id="bib.bib132.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Ninareh Mehrabi, Fred
Morstatter, Nripsuta Saxena, Kristina
Lerman, and Aram Galstyan.
2021.

</span>
<span class="ltx_bibblock">A survey on bias and fairness in machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib132.3.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys (CSUR)</em>
54, 6 (2021),
1–35.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Melis et al<span id="bib.bib133.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Luca Melis, Congzheng
Song, Emiliano De Cristofaro, and
Vitaly Shmatikov. 2019.

</span>
<span class="ltx_bibblock">Exploiting unintended feature leakage in
collaborative learning. In <em id="bib.bib133.3.1" class="ltx_emph ltx_font_italic">2019 IEEE Symposium on
Security and Privacy (SP)</em>. IEEE, 691–706.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mironov (2017)</span>
<span class="ltx_bibblock">
Ilya Mironov.
2017.

</span>
<span class="ltx_bibblock">Rényi differential privacy. In
<em id="bib.bib134.1.1" class="ltx_emph ltx_font_italic">2017 IEEE 30th computer security foundations
symposium (CSF)</em>. IEEE, 263–275.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo et al<span id="bib.bib135.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Fan Mo, Ali Shahin
Shamsabadi, Kleomenis Katevas, Soteris
Demetriou, Ilias Leontiadis, Andrea
Cavallaro, and Hamed Haddadi.
2020.

</span>
<span class="ltx_bibblock">DarkneTZ: towards model privacy at the edge using
trusted execution environments. In <em id="bib.bib135.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 18th International Conference on Mobile Systems, Applications, and
Services</em>. 161–174.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo and Walrand (2000)</span>
<span class="ltx_bibblock">
Jeonghoon Mo and Jean
Walrand. 2000.

</span>
<span class="ltx_bibblock">Fair end-to-end window-based congestion control.

</span>
<span class="ltx_bibblock"><em id="bib.bib136.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on networking</em>
8, 5 (2000),
556–567.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mohri
et al<span id="bib.bib137.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Mehryar Mohri, Gary
Sivek, and Ananda Theertha Suresh.
2019.

</span>
<span class="ltx_bibblock">Agnostic federated learning. In
<em id="bib.bib137.3.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.
PMLR, 4615–4625.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mondal et al<span id="bib.bib138.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Arup Mondal, Yash More,
Prashanthi Ramachandran, Priyam Panda,
Harpreet Virk, and Debayan Gupta.
2022.

</span>
<span class="ltx_bibblock">Scotch: an efficient secure computation framework
for secure aggregation.

</span>
<span class="ltx_bibblock"><em id="bib.bib138.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2201.07730</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mozannar
et al<span id="bib.bib139.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Hussein Mozannar, Mesrob
Ohannessian, and Nathan Srebro.
2020.

</span>
<span class="ltx_bibblock">Fair learning with private demographic data. In
<em id="bib.bib139.3.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.
PMLR, 7066–7075.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nagalapatti and
Narayanam (2021)</span>
<span class="ltx_bibblock">
Lokesh Nagalapatti and
Ramasuri Narayanam. 2021.

</span>
<span class="ltx_bibblock">Game of Gradients: Mitigating Irrelevant Clients in
Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib140.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on
Artificial Intelligence</em> 35, 10
(5 2021), 9046–9054.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://ojs.aaai.org/index.php/AAAI/article/view/17093" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://ojs.aaai.org/index.php/AAAI/article/view/17093</a>

</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nasr
et al<span id="bib.bib141.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Milad Nasr, Reza Shokri,
and Amir Houmansadr. 2019.

</span>
<span class="ltx_bibblock">Comprehensive Privacy Analysis of Deep Learning:
Passive and Active White-box Inference Attacks against Centralized and
Federated Learning. In <em id="bib.bib141.3.1" class="ltx_emph ltx_font_italic">2019 IEEE Symposium on
Security and Privacy (SP)</em>. 739–753.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/SP.2019.00065" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/SP.2019.00065</a>

</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nichol
et al<span id="bib.bib142.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Alex Nichol, Joshua
Achiam, and John Schulman.
2018.

</span>
<span class="ltx_bibblock">On First-Order Meta-Learning Algorithms.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1803.02999 [cs.LG]

</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nishio and
Yonetani (2019)</span>
<span class="ltx_bibblock">
Takayuki Nishio and Ryo
Yonetani. 2019.

</span>
<span class="ltx_bibblock">Client selection for federated learning with
heterogeneous resources in mobile edge. In <em id="bib.bib143.1.1" class="ltx_emph ltx_font_italic">ICC
2019-2019 IEEE international conference on communications (ICC)</em>. IEEE,
1–7.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Olteanu et al<span id="bib.bib144.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Alexandra Olteanu, Carlos
Castillo, Fernando Diaz, and Emre
Kıcıman. 2019.

</span>
<span class="ltx_bibblock">Social data: Biases, methodological pitfalls, and
ethical boundaries.

</span>
<span class="ltx_bibblock"><em id="bib.bib144.3.1" class="ltx_emph ltx_font_italic">Frontiers in Big Data</em> 2
(2019), 13.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Padala
et al<span id="bib.bib145.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Manisha Padala, Sankarshan
Damle, and Sujit Gujar.
2021.

</span>
<span class="ltx_bibblock">Federated Learning Meets Fairness and Differential
Privacy. In <em id="bib.bib145.3.1" class="ltx_emph ltx_font_italic">International Conference on Neural
Information Processing</em>. Springer, 692–699.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan
et al<span id="bib.bib146.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Xudong Pan, Mi Zhang,
Yifan Yan, Jiaming Zhu, and
Min Yang. 2020.

</span>
<span class="ltx_bibblock">Exploring the Security Boundary of Data
Reconstruction via Neuron Exclusivity Analysis.

</span>
<span class="ltx_bibblock"><em id="bib.bib146.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.13356</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papadaki et al<span id="bib.bib147.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Afroditi Papadaki, Natalia
Martinez, Martin Bertran, Guillermo
Sapiro, and Miguel Rodrigues.
2021.

</span>
<span class="ltx_bibblock">Federating for Learning Group Fair Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2110.01999 [cs.LG]

</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papernot et al<span id="bib.bib148.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Nicolas Papernot,
Martín Abadi, Ulfar Erlingsson,
Ian Goodfellow, and Kunal Talwar.
2016.

</span>
<span class="ltx_bibblock">Semi-supervised knowledge transfer for deep
learning from private training data.

</span>
<span class="ltx_bibblock"><em id="bib.bib148.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.05755</em>
(2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park and Lim (2022)</span>
<span class="ltx_bibblock">
Jaehyoung Park and Hyuk
Lim. 2022.

</span>
<span class="ltx_bibblock">Privacy-Preserving Federated Learning Using
Homomorphic Encryption.

</span>
<span class="ltx_bibblock"><em id="bib.bib149.1.1" class="ltx_emph ltx_font_italic">Applied Sciences</em> 12,
2 (2022), 734.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Phong
et al<span id="bib.bib150.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Le Trieu Phong, Yoshinori
Aono, Takuya Hayashi, Lihua Wang, and
Shiho Moriai. 2018.

</span>
<span class="ltx_bibblock">Privacy-Preserving Deep Learning via Additively
Homomorphic Encryption.

</span>
<span class="ltx_bibblock"><em id="bib.bib150.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics
and Security</em> 13 (2018),
1333–1345.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Phuong
et al<span id="bib.bib151.3.3.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Tran Thi Phuong et al<span id="bib.bib151.4.1" class="ltx_text">.</span>
2019.

</span>
<span class="ltx_bibblock">Privacy-preserving deep learning via weight
transmission.

</span>
<span class="ltx_bibblock"><em id="bib.bib151.5.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics
and Security</em> 14, 11
(2019), 3003–3015.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pleiss et al<span id="bib.bib152.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Geoff Pleiss, Manish
Raghavan, Felix Wu, Jon Kleinberg, and
Kilian Q Weinberger. 2017.

</span>
<span class="ltx_bibblock">On Fairness and Calibration. In
<em id="bib.bib152.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em>, I. Guyon,
U. V. Luxburg, S. Bengio,
H. Wallach, R. Fergus,
S. Vishwanathan, and R. Garnett
(Eds.), Vol. 30. Curran Associates,
Inc.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.neurips.cc/paper/2017/file/b8b9c74ac526fffbeb2d39ab038d1cd7-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2017/file/b8b9c74ac526fffbeb2d39ab038d1cd7-Paper.pdf</a>

</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qian and Hansen (2020)</span>
<span class="ltx_bibblock">
Jia Qian and Lars Kai
Hansen. 2020.

</span>
<span class="ltx_bibblock">What can we learn from gradients?

</span>
<span class="ltx_bibblock">(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren et al<span id="bib.bib154.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Hanchi Ren, Jingjing
Deng, and Xianghua Xie.
2022.

</span>
<span class="ltx_bibblock">GRNN: Generative Regression Neural Network - A Data
Leakage Attack for Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib154.3.1" class="ltx_emph ltx_font_italic">ACM Trans. Intell. Syst. Technol.</em>
(12 2022).

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3510032" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3510032</a>

</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salem et al<span id="bib.bib155.4.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Ahmed Salem, Apratim
Bhattacharya, Michael Backes, Mario
Fritz, and Yang Zhang. 2020.

</span>
<span class="ltx_bibblock"><math id="bib.bib155.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib155.1.m1.1a"><mo stretchy="false" id="bib.bib155.1.m1.1.1" xref="bib.bib155.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib155.1.m1.1b"><ci id="bib.bib155.1.m1.1.1.cmml" xref="bib.bib155.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib155.1.m1.1c">\{</annotation></semantics></math>Updates-Leak<math id="bib.bib155.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib155.2.m2.1a"><mo stretchy="false" id="bib.bib155.2.m2.1.1" xref="bib.bib155.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib155.2.m2.1b"><ci id="bib.bib155.2.m2.1.1.cmml" xref="bib.bib155.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib155.2.m2.1c">\}</annotation></semantics></math>: Data Set Inference and
Reconstruction Attacks in Online Learning. In <em id="bib.bib155.5.1" class="ltx_emph ltx_font_italic">29th
USENIX security symposium (USENIX Security 20)</em>.
1291–1308.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib156" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salvador et al<span id="bib.bib156.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Tiago Salvador, Stephanie
Cairns, Vikram Voleti, Noah Marshall,
and Adam Oberman. 2021.

</span>
<span class="ltx_bibblock">Faircal: Fairness calibration for face
verification.

</span>
<span class="ltx_bibblock"><em id="bib.bib156.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.03761</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib157" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanyal
et al<span id="bib.bib157.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Amartya Sanyal, Yaxi Hu,
and Fanny Yang. 2022.

</span>
<span class="ltx_bibblock">How unfair is private learning?. In
<em id="bib.bib157.3.1" class="ltx_emph ltx_font_italic">Uncertainty in Artificial Intelligence</em>. PMLR,
1738–1748.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib158" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sap
et al<span id="bib.bib158.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Maarten Sap, Dallas Card,
Saadia Gabriel, Yejin Choi, and
Noah A Smith. 2019.

</span>
<span class="ltx_bibblock">The risk of racial bias in hate speech detection.
In <em id="bib.bib158.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th annual meeting of the
association for computational linguistics</em>. 1668–1678.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib159" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sattler
et al<span id="bib.bib159.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Felix Sattler,
Klaus-Robert Müller, and Wojciech
Samek. 2020.

</span>
<span class="ltx_bibblock">Clustered federated learning: Model-agnostic
distributed multitask optimization under privacy constraints.

</span>
<span class="ltx_bibblock"><em id="bib.bib159.3.1" class="ltx_emph ltx_font_italic">IEEE transactions on neural networks and
learning systems</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib160" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scheliga
et al<span id="bib.bib160.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Daniel Scheliga, Patrick
Mäder, and Marco Seeland.
2022.

</span>
<span class="ltx_bibblock">PRECODE-A Generic Model Extension to Prevent Deep
Gradient Leakage. In <em id="bib.bib160.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF
Winter Conference on Applications of Computer Vision</em>.
1849–1858.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib161" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shamir (1979)</span>
<span class="ltx_bibblock">
Adi Shamir.
1979.

</span>
<span class="ltx_bibblock">How to share a secret.

</span>
<span class="ltx_bibblock"><em id="bib.bib161.1.1" class="ltx_emph ltx_font_italic">Commun. ACM</em> 22,
11 (1979), 612–613.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib162" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shao
et al<span id="bib.bib162.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jiawei Shao, Yuchang Sun,
Songze Li, and Jun Zhang.
2022.

</span>
<span class="ltx_bibblock">Dres-fl: Dropout-resilient secure federated
learning for non-iid clients via secret data sharing.

</span>
<span class="ltx_bibblock"><em id="bib.bib162.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.02680</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib163" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al<span id="bib.bib163.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yuxin Shi, Han Yu, and
Cyril Leung. 2021.

</span>
<span class="ltx_bibblock">A Survey of Fairness-Aware Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib163.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2111.01872</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib164" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shin
et al<span id="bib.bib164.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Jinmyeong Shin, Seok-Hwan
Choi, and Yoon-Ho Choi.
2021.

</span>
<span class="ltx_bibblock">Is Homomorphic Encryption-Based Deep Learning
Secure Enough?

</span>
<span class="ltx_bibblock"><em id="bib.bib164.3.1" class="ltx_emph ltx_font_italic">Sensors</em> 21,
23 (2021), 7806.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib165" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shoham et al<span id="bib.bib165.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Neta Shoham, Tomer
Avidor, Aviv Keren, Nadav Israel,
Daniel Benditkis, Liron Mor-Yosef, and
Itai Zeitak. 2019.

</span>
<span class="ltx_bibblock">Overcoming forgetting in federated learning on
non-iid data.

</span>
<span class="ltx_bibblock"><em id="bib.bib165.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.07796</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib166" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shokri and
Shmatikov (2015)</span>
<span class="ltx_bibblock">
Reza Shokri and Vitaly
Shmatikov. 2015.

</span>
<span class="ltx_bibblock">Privacy-preserving deep learning. In
<em id="bib.bib166.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 22nd ACM SIGSAC conference on
computer and communications security</em>. 1310–1321.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib167" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shokri
et al<span id="bib.bib167.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Reza Shokri, Marco
Stronati, Congzheng Song, and Vitaly
Shmatikov. 2017.

</span>
<span class="ltx_bibblock">Membership inference attacks against machine
learning models. In <em id="bib.bib167.3.1" class="ltx_emph ltx_font_italic">2017 IEEE Symposium on
Security and Privacy (SP)</em>. IEEE, 3–18.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib168" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singhal et al<span id="bib.bib168.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Karan Singhal, Hakim
Sidahmed, Zachary Garrett, Shanshan Wu,
Keith Rush, and Sushant Prakash.
2021.

</span>
<span class="ltx_bibblock">Federated Reconstruction: Partially Local Federated
Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2102.03448 [cs.LG]

</span>
</li>
<li id="bib.bib169" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith
et al<span id="bib.bib169.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Virginia Smith, Chao-Kai
Chiang, Maziar Sanjabi, and Ameet S
Talwalkar. 2017.

</span>
<span class="ltx_bibblock">Federated Multi-Task Learning. In
<em id="bib.bib169.3.1" class="ltx_emph ltx_font_italic">NIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib170" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">So
et al<span id="bib.bib170.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Jinhyun So, Başak
Güler, and A Salman Avestimehr.
2021.

</span>
<span class="ltx_bibblock">Turbo-aggregate: Breaking the quadratic aggregation
barrier in secure federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib170.3.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in Information
Theory</em> 2, 1 (2021),
479–489.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib171" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song
et al<span id="bib.bib171.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Congzheng Song, Thomas
Ristenpart, and Vitaly Shmatikov.
2017.

</span>
<span class="ltx_bibblock">Machine learning models that remember too much. In
<em id="bib.bib171.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 ACM SIGSAC Conference on
computer and communications security</em>. 587–601.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib172" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et al<span id="bib.bib172.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Mengkai Song, Zhibo Wang,
Zhifei Zhang, Yang Song,
Qian Wang, Ju Ren, and
Hairong Qi. 2020.

</span>
<span class="ltx_bibblock">Analyzing user-level privacy attack against
federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib172.3.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in
Communications</em> 38, 10
(2020), 2430–2444.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib173" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song
et al<span id="bib.bib173.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Shuang Song, Kamalika
Chaudhuri, and Anand D Sarwate.
2013.

</span>
<span class="ltx_bibblock">Stochastic gradient descent with differentially
private updates. In <em id="bib.bib173.3.1" class="ltx_emph ltx_font_italic">2013 IEEE Global Conference on
Signal and Information Processing</em>. IEEE, 245–248.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib174" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun
et al<span id="bib.bib174.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Ruoyu Sun, Tiantian Fang,
and Alex Schwing. 2020.

</span>
<span class="ltx_bibblock">Towards a Better Global Loss Landscape of GANs.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/ARXIV.2011.04926" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/ARXIV.2011.04926</a>

</span>
</li>
<li id="bib.bib175" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan
et al<span id="bib.bib175.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Alysa Ziying Tan, Han Yu,
Lizhen Cui, and Qiang Yang.
2021.

</span>
<span class="ltx_bibblock">Towards personalized federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib175.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2103.00710</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib176" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tramer and Boneh (2018)</span>
<span class="ltx_bibblock">
Florian Tramer and Dan
Boneh. 2018.

</span>
<span class="ltx_bibblock">Slalom: Fast, verifiable and private execution of
neural networks in trusted hardware.

</span>
<span class="ltx_bibblock"><em id="bib.bib176.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.03287</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib177" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tran
et al<span id="bib.bib177.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Cuong Tran, Ferdinando
Fioretto, and Pascal Van Hentenryck.
2021a.

</span>
<span class="ltx_bibblock">Differentially private and fair deep learning: A
lagrangian dual approach. In <em id="bib.bib177.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
AAAI Conference on Artificial Intelligence</em>, Vol. 35.
9932–9939.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib178" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tran
et al<span id="bib.bib178.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Cuong Tran, Ferdinando
Fioretto, Pascal Van Hentenryck, and
Zhiyan Yao. 2021b.

</span>
<span class="ltx_bibblock">Decision making with differential privacy under a
fairness lens. In <em id="bib.bib178.3.1" class="ltx_emph ltx_font_italic">Proceedings of the International
Joint Conference on Artificial Intelligence (IJCAI)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib179" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Truex et al<span id="bib.bib179.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Stacey Truex, Nathalie
Baracaldo, Ali Anwar, Thomas Steinke,
Heiko Ludwig, Rui Zhang, and
Yi Zhou. 2019a.

</span>
<span class="ltx_bibblock">A hybrid approach to privacy-preserving federated
learning. In <em id="bib.bib179.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th ACM workshop
on artificial intelligence and security</em>. 1–11.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib180" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Truex
et al<span id="bib.bib180.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Stacey Truex, Ling Liu,
Mehmet Emre Gursoy, Lei Yu, and
Wenqi Wei. 2019b.

</span>
<span class="ltx_bibblock">Demystifying Membership Inference Attacks in
Machine Learning as a Service.

</span>
<span class="ltx_bibblock"><em id="bib.bib180.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Services Computing</em>
(2019), 1–1.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TSC.2019.2897554" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TSC.2019.2897554</a>

</span>
</li>
<li id="bib.bib181" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Uniyal et al<span id="bib.bib181.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Archit Uniyal, Rakshit
Naidu, Sasikanth Kotti, Sahib Singh,
Patrik Joslin Kenfack, Fatemehsadat
Mireshghallah, and Andrew Trask.
2021.

</span>
<span class="ltx_bibblock">Dp-sgd vs pate: Which has less disparate impact on
model accuracy?

</span>
<span class="ltx_bibblock"><em id="bib.bib181.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.12576</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib182" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Veale and Binns (2017)</span>
<span class="ltx_bibblock">
Michael Veale and Reuben
Binns. 2017.

</span>
<span class="ltx_bibblock">Fairer machine learning in the real world:
Mitigating discrimination without collecting sensitive data.

</span>
<span class="ltx_bibblock"><em id="bib.bib182.1.1" class="ltx_emph ltx_font_italic">Big Data &amp; Society</em> 4,
2 (2017),
2053951717743530.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib183" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Verma and Rubin (2018)</span>
<span class="ltx_bibblock">
Sahil Verma and Julia
Rubin. 2018.

</span>
<span class="ltx_bibblock">Fairness Definitions Explained. In
<em id="bib.bib183.1.1" class="ltx_emph ltx_font_italic">Proceedings of the International Workshop on
Software Fairness</em> (Gothenburg, Sweden) <em id="bib.bib183.2.2" class="ltx_emph ltx_font_italic">(FairWare
’18)</em>. Association for Computing Machinery,
New York, NY, USA, 1–7.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3194770.3194776" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3194770.3194776</a>

</span>
</li>
<li id="bib.bib184" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Voigt and Von dem
Bussche (2017)</span>
<span class="ltx_bibblock">
Paul Voigt and Axel
Von dem Bussche. 2017.

</span>
<span class="ltx_bibblock">The eu general data protection regulation (gdpr).

</span>
<span class="ltx_bibblock"><em id="bib.bib184.1.1" class="ltx_emph ltx_font_italic">A Practical Guide, 1st Ed., Cham: Springer
International Publishing</em> 10 (2017),
3152676.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib185" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span id="bib.bib185.2.2.1" class="ltx_text">.</span> (2020c)</span>
<span class="ltx_bibblock">
Hao Wang, Zakhary Kaplan,
Di Niu, and Baochun Li.
2020c.

</span>
<span class="ltx_bibblock">Optimizing Federated Learning on Non-IID Data with
Reinforcement Learning. In <em id="bib.bib185.3.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM 2020 -
IEEE Conference on Computer Communications</em>. 1698–1707.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/INFOCOM41043.2020.9155494" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/INFOCOM41043.2020.9155494</a>

</span>
</li>
<li id="bib.bib186" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span id="bib.bib186.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Lixu Wang, Shichao Xu,
Xiao Wang, and Qi Zhu.
2019b.

</span>
<span class="ltx_bibblock">Eavesdrop the Composition Proportion of Training
Labels in Federated Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/ARXIV.1910.06044" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/ARXIV.1910.06044</a>

</span>
</li>
<li id="bib.bib187" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib187.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Serena Wang, Wenshuo Guo,
Harikrishna Narasimhan, Andrew Cotter,
Maya Gupta, and Michael Jordan.
2020b.

</span>
<span class="ltx_bibblock">Robust optimization for fairness with noisy
protected groups.

</span>
<span class="ltx_bibblock"><em id="bib.bib187.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 33 (2020),
5190–5203.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib188" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib188.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Yijue Wang, Jieren Deng,
Dan Guo, Chenghong Wang,
Xianrui Meng, Hang Liu,
Caiwen Ding, and Sanguthevar
Rajasekaran. 2020a.

</span>
<span class="ltx_bibblock">Sapag: A self-adaptive privacy attack from
gradients.

</span>
<span class="ltx_bibblock"><em id="bib.bib188.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.06228</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib189" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span id="bib.bib189.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Zhibo Wang, Yuting Huang,
Mengkai Song, Libing Wu,
Feng Xue, and Kui Ren.
2022.

</span>
<span class="ltx_bibblock">Poisoning-assisted property inference attack
against federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib189.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Dependable and Secure
Computing</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib190" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span id="bib.bib190.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Zhibo Wang, Mengkai Song,
Zhifei Zhang, Yang Song,
Qian Wang, and Hairong Qi.
2019a.

</span>
<span class="ltx_bibblock">Beyond inferring class representatives: User-level
privacy leakage from federated learning. In <em id="bib.bib190.3.1" class="ltx_emph ltx_font_italic">IEEE
INFOCOM 2019-IEEE Conference on Computer Communications</em>. IEEE,
2512–2520.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib191" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al<span id="bib.bib191.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Kang Wei, Jun Li,
Ming Ding, Chuan Ma,
Howard H Yang, Farhad Farokhi,
Shi Jin, Tony QS Quek, and
H Vincent Poor. 2020a.

</span>
<span class="ltx_bibblock">Federated learning with differential privacy:
Algorithms and performance analysis.

</span>
<span class="ltx_bibblock"><em id="bib.bib191.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics
and Security</em> 15 (2020),
3454–3469.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib192" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei and Liu (2021)</span>
<span class="ltx_bibblock">
Wenqi Wei and Ling
Liu. 2021.

</span>
<span class="ltx_bibblock">Gradient Leakage Attack Resilient Deep Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib192.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics
and Security</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib193" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al<span id="bib.bib193.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Wenqi Wei, Ling Liu,
Margaret Loper, Ka-Ho Chow,
Mehmet Emre Gursoy, Stacey Truex, and
Yanzhao Wu. 2020b.

</span>
<span class="ltx_bibblock">A framework for evaluating gradient leakage attacks
in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib193.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.10397</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib194" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu
et al<span id="bib.bib194.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yuezhou Wu, Yan Kang,
Jiahuan Luo, Yuanqin He, and
Qiang Yang. 2021.

</span>
<span class="ltx_bibblock">FedCG: Leverage Conditional GAN for Protecting
Privacy and Maintaining Competitive Performance in Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib194.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2111.08211</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib195" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span id="bib.bib195.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Depeng Xu, Wei Du, and
Xintao Wu. 2021b.

</span>
<span class="ltx_bibblock">Removing Disparate Impact on Model Accuracy in
Differentially Private Stochastic Gradient Descent. In
<em id="bib.bib195.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th ACM SIGKDD Conference on
Knowledge Discovery and Data Mining</em> (Virtual Event, Singapore)
<em id="bib.bib195.4.2" class="ltx_emph ltx_font_italic">(KDD ’21)</em>. Association for
Computing Machinery, New York, NY, USA,
1924–1932.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3447548.3467268" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3447548.3467268</a>

</span>
</li>
<li id="bib.bib196" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span id="bib.bib196.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Depeng Xu, Shuhan Yuan,
and Xintao Wu. 2019a.

</span>
<span class="ltx_bibblock">Achieving Differential Privacy and Fairness in
Logistic Regression. In <em id="bib.bib196.3.1" class="ltx_emph ltx_font_italic">Companion Proceedings of
The 2019 World Wide Web Conference</em> (San Francisco, USA)
<em id="bib.bib196.4.2" class="ltx_emph ltx_font_italic">(WWW ’19)</em>. Association for
Computing Machinery, New York, NY, USA,
594–599.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3308560.3317584" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3308560.3317584</a>

</span>
</li>
<li id="bib.bib197" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span id="bib.bib197.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Depeng Xu, Shuhan Yuan,
and Xintao Wu. 2019b.

</span>
<span class="ltx_bibblock">Achieving differential privacy and fairness in
logistic regression. In <em id="bib.bib197.3.1" class="ltx_emph ltx_font_italic">Companion proceedings of
The 2019 world wide web conference</em>. 594–599.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib198" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu
et al<span id="bib.bib198.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Depeng Xu, Shuhan Yuan,
Lu Zhang, and Xintao Wu.
2018.

</span>
<span class="ltx_bibblock">Fairgan: Fairness-aware generative adversarial
networks. In <em id="bib.bib198.3.1" class="ltx_emph ltx_font_italic">2018 IEEE International Conference on
Big Data (Big Data)</em>. IEEE, 570–575.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib199" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu
et al<span id="bib.bib199.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Runhua Xu, Nathalie
Baracaldo, and James Joshi.
2021a.

</span>
<span class="ltx_bibblock">Privacy-Preserving Machine Learning: Methods,
Challenges and Directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib199.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2108.04417</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib200" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang
et al<span id="bib.bib200.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Miao Yang, Akitanoshou
Wong, Hongbin Zhu, Haifeng Wang, and
Hua Qian. 2020b.

</span>
<span class="ltx_bibblock">Federated learning with class imbalance reduction.

</span>
<span class="ltx_bibblock"><em id="bib.bib200.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.11266</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib201" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang
et al<span id="bib.bib201.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu,
Tianjian Chen, and Yongxin Tong.
2019b.

</span>
<span class="ltx_bibblock">Federated machine learning: Concept and
applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib201.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and
Technology (TIST)</em> 10, 2
(2019), 1–19.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib202" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib202.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Wenzhuo Yang, Yipeng
Zhou, Miao Hu, Di Wu,
Xi Zheng, Jessie Hui Wang,
Song Guo, and Chao Li.
2021.

</span>
<span class="ltx_bibblock">Gain without Pain: Offsetting DP-injected Nosies
Stealthily in Cross-device Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib202.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib203" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib203.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Xue Yang, Yan Feng,
Weijun Fang, Jun Shao,
Xiaohu Tang, Shu-Tao Xia, and
Rongxing Lu. 2020a.

</span>
<span class="ltx_bibblock">An Accuracy-Lossless Perturbation Method for
Defending Privacy Attacks in Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib203.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.09843</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib204" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang
et al<span id="bib.bib204.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Ziqi Yang, Ee-Chien
Chang, and Zhenkai Liang.
2019a.

</span>
<span class="ltx_bibblock">Adversarial neural network inversion via auxiliary
knowledge alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib204.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1902.08552</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib205" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao (1982)</span>
<span class="ltx_bibblock">
Andrew C Yao.
1982.

</span>
<span class="ltx_bibblock">Protocols for secure computations. In
<em id="bib.bib205.1.1" class="ltx_emph ltx_font_italic">23rd annual symposium on foundations of computer
science (sfcs 1982)</em>. IEEE, 160–164.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib206" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao and Sun (2020)</span>
<span class="ltx_bibblock">
Xin Yao and Lifeng
Sun. 2020.

</span>
<span class="ltx_bibblock">Continual local training for better initialization
of federated models. In <em id="bib.bib206.1.1" class="ltx_emph ltx_font_italic">2020 IEEE International
Conference on Image Processing (ICIP)</em>. IEEE, 1736–1740.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib207" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yi
et al<span id="bib.bib207.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Xun Yi, Russell Paulet,
and Elisa Bertino. 2014.

</span>
<span class="ltx_bibblock">Homomorphic encryption.

</span>
<span class="ltx_bibblock">In <em id="bib.bib207.3.1" class="ltx_emph ltx_font_italic">Homomorphic encryption and
applications</em>. Springer, 27–46.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib208" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al<span id="bib.bib208.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Hongxu Yin, Arun Mallya,
Arash Vahdat, Jose M Alvarez,
Jan Kautz, and Pavlo Molchanov.
2021a.

</span>
<span class="ltx_bibblock">See through gradients: Image batch recovery via
gradinversion. In <em id="bib.bib208.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition</em>.
16337–16346.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib209" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al<span id="bib.bib209.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Xuefei Yin, Yanming Zhu,
and Jiankun Hu. 2021b.

</span>
<span class="ltx_bibblock">A comprehensive survey of privacy-preserving
federated learning: A taxonomy, review, and future directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib209.3.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys (CSUR)</em>
54, 6 (2021),
1–36.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib210" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al<span id="bib.bib210.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Han Yu, Zelei Liu,
Yang Liu, Tianjian Chen,
Mingshu Cong, Xi Weng,
Dusit Niyato, and Qiang Yang.
2020.

</span>
<span class="ltx_bibblock">A fairness-aware incentive scheme for federated
learning. In <em id="bib.bib210.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI/ACM
Conference on AI, Ethics, and Society</em>. 393–399.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib211" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yue
et al<span id="bib.bib211.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Xubo Yue, Maher Nouiehed,
and Raed Al Kontar. 2021.

</span>
<span class="ltx_bibblock">GIFAIR-FL: An Approach for Group and Individual
Fairness in Federated Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2108.02741 [cs.LG]

</span>
</li>
<li id="bib.bib212" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zafar
et al<span id="bib.bib212.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Muhammad Bilal Zafar,
Isabel Valera, Manuel Gomez Rogriguez,
and Krishna P Gummadi. 2017.

</span>
<span class="ltx_bibblock">Fairness constraints: Mechanisms for fair
classification. In <em id="bib.bib212.3.1" class="ltx_emph ltx_font_italic">Artificial Intelligence and
Statistics</em>. PMLR, 962–970.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib213" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zemel
et al<span id="bib.bib213.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Rich Zemel, Yu Wu,
Kevin Swersky, Toni Pitassi, and
Cynthia Dwork. 2013.

</span>
<span class="ltx_bibblock">Learning fair representations. In
<em id="bib.bib213.3.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>.
PMLR, 325–333.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib214" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib214.2.2.1" class="ltx_text">.</span> (2018a)</span>
<span class="ltx_bibblock">
Brian Hu Zhang, Blake
Lemoine, and Margaret Mitchell.
2018a.

</span>
<span class="ltx_bibblock">Mitigating unwanted biases with adversarial
learning. In <em id="bib.bib214.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 AAAI/ACM
Conference on AI, Ethics, and Society</em>. 335–340.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib215" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib215.2.2.1" class="ltx_text">.</span> (2018b)</span>
<span class="ltx_bibblock">
Brian Hu Zhang, Blake
Lemoine, and Margaret Mitchell.
2018b.

</span>
<span class="ltx_bibblock">Mitigating Unwanted Biases with Adversarial
Learning. In <em id="bib.bib215.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 AAAI/ACM
Conference on AI, Ethics, and Society</em> (New Orleans, LA, USA)
<em id="bib.bib215.4.2" class="ltx_emph ltx_font_italic">(AIES ’18)</em>. Association for
Computing Machinery, New York, NY, USA,
335–340.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3278721.3278779" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3278721.3278779</a>

</span>
</li>
<li id="bib.bib216" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib216.6.2.1" class="ltx_text">.</span> (2020c)</span>
<span class="ltx_bibblock">
Chengliang Zhang, Suyi
Li, Junzhe Xia, Wei Wang,
Feng Yan, and Yang Liu.
2020c.

</span>
<span class="ltx_bibblock"><math id="bib.bib216.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib216.1.m1.1a"><mo stretchy="false" id="bib.bib216.1.m1.1.1" xref="bib.bib216.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib216.1.m1.1b"><ci id="bib.bib216.1.m1.1.1.cmml" xref="bib.bib216.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib216.1.m1.1c">\{</annotation></semantics></math>BatchCrypt<math id="bib.bib216.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib216.2.m2.1a"><mo stretchy="false" id="bib.bib216.2.m2.1.1" xref="bib.bib216.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib216.2.m2.1b"><ci id="bib.bib216.2.m2.1.1.cmml" xref="bib.bib216.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib216.2.m2.1c">\}</annotation></semantics></math>: Efficient Homomorphic
Encryption for <math id="bib.bib216.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib216.3.m3.1a"><mo stretchy="false" id="bib.bib216.3.m3.1.1" xref="bib.bib216.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib216.3.m3.1b"><ci id="bib.bib216.3.m3.1.1.cmml" xref="bib.bib216.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib216.3.m3.1c">\{</annotation></semantics></math>Cross-Silo<math id="bib.bib216.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib216.4.m4.1a"><mo stretchy="false" id="bib.bib216.4.m4.1.1" xref="bib.bib216.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib216.4.m4.1b"><ci id="bib.bib216.4.m4.1.1.cmml" xref="bib.bib216.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib216.4.m4.1c">\}</annotation></semantics></math> Federated Learning. In
<em id="bib.bib216.7.1" class="ltx_emph ltx_font_italic">2020 USENIX Annual Technical Conference (USENIX ATC
20)</em>. 493–506.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib217" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib217.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Daniel Yue Zhang, Ziyi
Kou, and Dong Wang. 2020b.

</span>
<span class="ltx_bibblock">Fairfl: A fair federated learning approach to
reducing demographic bias in privacy-sensitive classification models. In
<em id="bib.bib217.3.1" class="ltx_emph ltx_font_italic">2020 IEEE International Conference on Big Data (Big
Data)</em>. IEEE, 1051–1060.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib218" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib218.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Jiale Zhang, Bing Chen,
Shui Yu, and Hai Deng.
2019a.

</span>
<span class="ltx_bibblock">PEFL: A privacy-enhanced federated learning scheme
for big data analytics. In <em id="bib.bib218.3.1" class="ltx_emph ltx_font_italic">2019 IEEE Global
Communications Conference (GLOBECOM)</em>. IEEE, 1–6.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib219" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib219.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Jun Zhang, Graham
Cormode, Cecilia M Procopiuc, Divesh
Srivastava, and Xiaokui Xiao.
2017.

</span>
<span class="ltx_bibblock">Privbayes: Private data release via bayesian
networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib219.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Database Systems (TODS)</em>
42, 4 (2017),
1–41.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib220" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib220.2.2.1" class="ltx_text">.</span> (2020e)</span>
<span class="ltx_bibblock">
Jingwen Zhang, Jiale
Zhang, Junjun Chen, and Shui Yu.
2020e.

</span>
<span class="ltx_bibblock">GAN Enhanced Membership Inference: A Passive Local
Attack in Federated Learning. In <em id="bib.bib220.3.1" class="ltx_emph ltx_font_italic">ICC 2020 - 2020
IEEE International Conference on Communications (ICC)</em>.
1–6.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ICC40277.2020.9148790" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICC40277.2020.9148790</a>

</span>
</li>
<li id="bib.bib221" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib221.2.2.1" class="ltx_text">.</span> (2020f)</span>
<span class="ltx_bibblock">
Jingwen Zhang, Jiale
Zhang, Junjun Chen, and Shui Yu.
2020f.

</span>
<span class="ltx_bibblock">Gan enhanced membership inference: A passive local
attack in federated learning. In <em id="bib.bib221.3.1" class="ltx_emph ltx_font_italic">ICC 2020-2020
IEEE International Conference on Communications (ICC)</em>. IEEE,
1–6.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib222" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib222.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
L Zhang, Y Wu, and
X Wu. 2019b.

</span>
<span class="ltx_bibblock">Fairness-aware classification: Criterion convexity
and bounds. In <em id="bib.bib222.3.1" class="ltx_emph ltx_font_italic">AAAI</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib223" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib223.2.2.1" class="ltx_text">.</span> (2020d)</span>
<span class="ltx_bibblock">
Michael Zhang, Karan
Sapra, Sanja Fidler, Serena Yeung, and
Jose M Alvarez. 2020d.

</span>
<span class="ltx_bibblock">Personalized Federated Learning with First Order
Model Optimization. In <em id="bib.bib223.3.1" class="ltx_emph ltx_font_italic">International Conference on
Learning Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib224" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Wang (2021)</span>
<span class="ltx_bibblock">
Mengjiao Zhang and
Shusen Wang. 2021.

</span>
<span class="ltx_bibblock">Matrix sketching for secure collaborative machine
learning. In <em id="bib.bib224.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine
Learning</em>. PMLR, 12589–12599.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib225" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib225.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Tao Zhang, Tianqing Zhu,
Kun Gao, Wanlei Zhou, and
S Yu Philip. 2021.

</span>
<span class="ltx_bibblock">Balancing Learning Model Privacy, Fairness, and
Accuracy With Early Stopping Criteria.

</span>
<span class="ltx_bibblock"><em id="bib.bib225.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and
Learning Systems</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib226" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib226.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Yuheng Zhang, Ruoxi Jia,
Hengzhi Pei, Wenxiao Wang,
Bo Li, and Dawn Song.
2020a.

</span>
<span class="ltx_bibblock">The Secret Revealer: Generative Model-Inversion
Attacks Against Deep Neural Networks.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1911.07135 [cs.LG]

</span>
</li>
<li id="bib.bib227" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao
et al<span id="bib.bib227.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Bo Zhao, Konda Reddy
Mopuri, and Hakan Bilen.
2020.

</span>
<span class="ltx_bibblock">idlg: Improved deep leakage from gradients.

</span>
<span class="ltx_bibblock"><em id="bib.bib227.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.02610</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib228" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao
et al<span id="bib.bib228.2.2.1" class="ltx_text">.</span> (2018b)</span>
<span class="ltx_bibblock">
Jieyu Zhao, Tianlu Wang,
Mark Yatskar, Vicente Ordonez, and
Kai-Wei Chang. 2018b.

</span>
<span class="ltx_bibblock">Gender bias in coreference resolution: Evaluation
and debiasing methods.

</span>
<span class="ltx_bibblock"><em id="bib.bib228.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1804.06876</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib229" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao
et al<span id="bib.bib229.2.2.1" class="ltx_text">.</span> (2018a)</span>
<span class="ltx_bibblock">
Yue Zhao, Meng Li,
Liangzhen Lai, Naveen Suda,
Damon Civin, and Vikas Chandra.
2018a.

</span>
<span class="ltx_bibblock">Federated learning with non-iid data.

</span>
<span class="ltx_bibblock"><em id="bib.bib229.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.00582</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib230" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu
et al<span id="bib.bib230.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Hangyu Zhu, Jinjin Xu,
Shiqing Liu, and Yaochu Jin.
2021.

</span>
<span class="ltx_bibblock">Federated learning on non-IID data: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib230.3.1" class="ltx_emph ltx_font_italic">Neurocomputing</em> 465
(2021), 371–390.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib231" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu and Blaschko (2020)</span>
<span class="ltx_bibblock">
Junyi Zhu and Matthew
Blaschko. 2020.

</span>
<span class="ltx_bibblock">R-gap: Recursive gradient attack on privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib231.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.07733</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib232" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al<span id="bib.bib232.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Ligeng Zhu, Zhijian Liu,
and Song Han. 2019.

</span>
<span class="ltx_bibblock">Deep leakage from gradients.

</span>
<span class="ltx_bibblock"><em id="bib.bib232.3.1" class="ltx_emph ltx_font_italic">Advances in neural information processing
systems</em> 32 (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib233" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Žliobaitė and
Custers (2016)</span>
<span class="ltx_bibblock">
Indrė Žliobaitė and
B. H. M. Custers. 2016.

</span>
<span class="ltx_bibblock">Using sensitive personal data may be necessary for
avoiding discrimination in data-driven decision models.

</span>
<span class="ltx_bibblock"><em id="bib.bib233.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence and Law</em>
24 (2016), 183–201.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2306.14122" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2306.14123" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2306.14123">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2306.14123" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2306.14124" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 22:18:47 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
