<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2309.09381] Federated Learning in Temporal Heterogeneity</title><meta property="og:description" content="In this work, we explored federated learning in temporal heterogeneity across clients. We observed that global model obtained by FedAvg trained with fixed-length sequences shows faster convergence than varying-length sâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning in Temporal Heterogeneity">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning in Temporal Heterogeneity">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2309.09381">

<!--Generated on Wed Feb 28 03:31:37 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Federated Learning in Temporal Heterogeneity</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Junghwan Lee 
<br class="ltx_break">H. Milton Stewart School of Industrial and Systems Engineering
<br class="ltx_break">Georgia Institute of Technology
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">jlee3541@gatech.edu</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">In this work, we explored federated learning in temporal heterogeneity across clients. We observed that global model obtained by <span id="id2.id1.1" class="ltx_text ltx_font_typewriter">FedAvg</span> trained with fixed-length sequences shows faster convergence than varying-length sequences. We proposed methods to mitigate temporal heterogeneity for efficient federated learning based on the empirical observation.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">Federated learning is distributed learning framework where data are used locally (i.e., local devices or local institutions) instead of sharing or storing data through centralized serverÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. Existing studies in federated learning have shown that learning good global model from local models is possible without sharing or storing the entire data. Therefore, federated learning can effectively address privacy concerns related to training deep learning models on large datasets, which gained attention to federated learning.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">One of major challenges in federated learning is heterogeneity among local clients. Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> showed that simply averaging local models often fail to obtain good global model with heterogeneous clients. Numerous studies have been conducted to address the challenge of various types of heterogeneity in federated learning. For example, FedBNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> used batch normalization to mitigate heterogeneity of label distribution and FedProx Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> used <math id="S1.p2.1.m1.1" class="ltx_Math" alttext="l_{2}" display="inline"><semantics id="S1.p2.1.m1.1a"><msub id="S1.p2.1.m1.1.1" xref="S1.p2.1.m1.1.1.cmml"><mi id="S1.p2.1.m1.1.1.2" xref="S1.p2.1.m1.1.1.2.cmml">l</mi><mn id="S1.p2.1.m1.1.1.3" xref="S1.p2.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><apply id="S1.p2.1.m1.1.1.cmml" xref="S1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S1.p2.1.m1.1.1.1.cmml" xref="S1.p2.1.m1.1.1">subscript</csymbol><ci id="S1.p2.1.m1.1.1.2.cmml" xref="S1.p2.1.m1.1.1.2">ğ‘™</ci><cn type="integer" id="S1.p2.1.m1.1.1.3.cmml" xref="S1.p2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">l_{2}</annotation></semantics></math> regularization to control deviance of heterogeneous local models from global model.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">The recent success of machine learning in various domains is largely attributed to the use of sequential data containing temporal information. For example, large language models heavily rely on the training on the massive natural language data and disease prediction models require a large number of electronic health records. While sequential data contain innate non-iidness due to varying-length, there have been lack of studies that seek to explore using sequential data. In this paper, we discussed the effect of temporal heterogeneity in sequential data on federated learning. We made the following contributions:</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para ltx_noindent">
<p id="S1.I1.i1.p1.1" class="ltx_p">We observed that averaging local models where each local model was trained with the same length of sequences quickly converges than local models with varying-length sequences.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para ltx_noindent">
<p id="S1.I1.i2.p1.1" class="ltx_p">We proposed approaches to mitigate temporal heterogeneity due to varying-length sequences based on the observation.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Problem Formulation</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.11" class="ltx_p">We assume <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="N\in\mathbb{N}" display="inline"><semantics id="S2.p1.1.m1.1a"><mrow id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml"><mi id="S2.p1.1.m1.1.1.2" xref="S2.p1.1.m1.1.1.2.cmml">N</mi><mo id="S2.p1.1.m1.1.1.1" xref="S2.p1.1.m1.1.1.1.cmml">âˆˆ</mo><mi id="S2.p1.1.m1.1.1.3" xref="S2.p1.1.m1.1.1.3.cmml">â„•</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><apply id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1"><in id="S2.p1.1.m1.1.1.1.cmml" xref="S2.p1.1.m1.1.1.1"></in><ci id="S2.p1.1.m1.1.1.2.cmml" xref="S2.p1.1.m1.1.1.2">ğ‘</ci><ci id="S2.p1.1.m1.1.1.3.cmml" xref="S2.p1.1.m1.1.1.3">â„•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">N\in\mathbb{N}</annotation></semantics></math> clients are trained for <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="E\in\mathbb{N}" display="inline"><semantics id="S2.p1.2.m2.1a"><mrow id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml"><mi id="S2.p1.2.m2.1.1.2" xref="S2.p1.2.m2.1.1.2.cmml">E</mi><mo id="S2.p1.2.m2.1.1.1" xref="S2.p1.2.m2.1.1.1.cmml">âˆˆ</mo><mi id="S2.p1.2.m2.1.1.3" xref="S2.p1.2.m2.1.1.3.cmml">â„•</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><apply id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1"><in id="S2.p1.2.m2.1.1.1.cmml" xref="S2.p1.2.m2.1.1.1"></in><ci id="S2.p1.2.m2.1.1.2.cmml" xref="S2.p1.2.m2.1.1.2">ğ¸</ci><ci id="S2.p1.2.m2.1.1.3.cmml" xref="S2.p1.2.m2.1.1.3">â„•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">E\in\mathbb{N}</annotation></semantics></math> epochs and communicate with global model after <math id="S2.p1.3.m3.1" class="ltx_Math" alttext="K\in\mathbb{N}" display="inline"><semantics id="S2.p1.3.m3.1a"><mrow id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml"><mi id="S2.p1.3.m3.1.1.2" xref="S2.p1.3.m3.1.1.2.cmml">K</mi><mo id="S2.p1.3.m3.1.1.1" xref="S2.p1.3.m3.1.1.1.cmml">âˆˆ</mo><mi id="S2.p1.3.m3.1.1.3" xref="S2.p1.3.m3.1.1.3.cmml">â„•</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><apply id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1"><in id="S2.p1.3.m3.1.1.1.cmml" xref="S2.p1.3.m3.1.1.1"></in><ci id="S2.p1.3.m3.1.1.2.cmml" xref="S2.p1.3.m3.1.1.2">ğ¾</ci><ci id="S2.p1.3.m3.1.1.3.cmml" xref="S2.p1.3.m3.1.1.3">â„•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">K\in\mathbb{N}</annotation></semantics></math> iterations. Each client <math id="S2.p1.4.m4.1" class="ltx_Math" alttext="i\in[N]" display="inline"><semantics id="S2.p1.4.m4.1a"><mrow id="S2.p1.4.m4.1.2" xref="S2.p1.4.m4.1.2.cmml"><mi id="S2.p1.4.m4.1.2.2" xref="S2.p1.4.m4.1.2.2.cmml">i</mi><mo id="S2.p1.4.m4.1.2.1" xref="S2.p1.4.m4.1.2.1.cmml">âˆˆ</mo><mrow id="S2.p1.4.m4.1.2.3.2" xref="S2.p1.4.m4.1.2.3.1.cmml"><mo stretchy="false" id="S2.p1.4.m4.1.2.3.2.1" xref="S2.p1.4.m4.1.2.3.1.1.cmml">[</mo><mi id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml">N</mi><mo stretchy="false" id="S2.p1.4.m4.1.2.3.2.2" xref="S2.p1.4.m4.1.2.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><apply id="S2.p1.4.m4.1.2.cmml" xref="S2.p1.4.m4.1.2"><in id="S2.p1.4.m4.1.2.1.cmml" xref="S2.p1.4.m4.1.2.1"></in><ci id="S2.p1.4.m4.1.2.2.cmml" xref="S2.p1.4.m4.1.2.2">ğ‘–</ci><apply id="S2.p1.4.m4.1.2.3.1.cmml" xref="S2.p1.4.m4.1.2.3.2"><csymbol cd="latexml" id="S2.p1.4.m4.1.2.3.1.1.cmml" xref="S2.p1.4.m4.1.2.3.2.1">delimited-[]</csymbol><ci id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">i\in[N]</annotation></semantics></math> has <math id="S2.p1.5.m5.1" class="ltx_Math" alttext="m_{i}\in\mathbb{N}" display="inline"><semantics id="S2.p1.5.m5.1a"><mrow id="S2.p1.5.m5.1.1" xref="S2.p1.5.m5.1.1.cmml"><msub id="S2.p1.5.m5.1.1.2" xref="S2.p1.5.m5.1.1.2.cmml"><mi id="S2.p1.5.m5.1.1.2.2" xref="S2.p1.5.m5.1.1.2.2.cmml">m</mi><mi id="S2.p1.5.m5.1.1.2.3" xref="S2.p1.5.m5.1.1.2.3.cmml">i</mi></msub><mo id="S2.p1.5.m5.1.1.1" xref="S2.p1.5.m5.1.1.1.cmml">âˆˆ</mo><mi id="S2.p1.5.m5.1.1.3" xref="S2.p1.5.m5.1.1.3.cmml">â„•</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.5.m5.1b"><apply id="S2.p1.5.m5.1.1.cmml" xref="S2.p1.5.m5.1.1"><in id="S2.p1.5.m5.1.1.1.cmml" xref="S2.p1.5.m5.1.1.1"></in><apply id="S2.p1.5.m5.1.1.2.cmml" xref="S2.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S2.p1.5.m5.1.1.2.1.cmml" xref="S2.p1.5.m5.1.1.2">subscript</csymbol><ci id="S2.p1.5.m5.1.1.2.2.cmml" xref="S2.p1.5.m5.1.1.2.2">ğ‘š</ci><ci id="S2.p1.5.m5.1.1.2.3.cmml" xref="S2.p1.5.m5.1.1.2.3">ğ‘–</ci></apply><ci id="S2.p1.5.m5.1.1.3.cmml" xref="S2.p1.5.m5.1.1.3">â„•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.5.m5.1c">m_{i}\in\mathbb{N}</annotation></semantics></math> training examples where each training example consists of <math id="S2.p1.6.m6.1" class="ltx_Math" alttext="l_{j}" display="inline"><semantics id="S2.p1.6.m6.1a"><msub id="S2.p1.6.m6.1.1" xref="S2.p1.6.m6.1.1.cmml"><mi id="S2.p1.6.m6.1.1.2" xref="S2.p1.6.m6.1.1.2.cmml">l</mi><mi id="S2.p1.6.m6.1.1.3" xref="S2.p1.6.m6.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.6.m6.1b"><apply id="S2.p1.6.m6.1.1.cmml" xref="S2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.p1.6.m6.1.1.1.cmml" xref="S2.p1.6.m6.1.1">subscript</csymbol><ci id="S2.p1.6.m6.1.1.2.cmml" xref="S2.p1.6.m6.1.1.2">ğ‘™</ci><ci id="S2.p1.6.m6.1.1.3.cmml" xref="S2.p1.6.m6.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.6.m6.1c">l_{j}</annotation></semantics></math>-length sequence of features in <math id="S2.p1.7.m7.1" class="ltx_Math" alttext="\mathbb{R}^{d}" display="inline"><semantics id="S2.p1.7.m7.1a"><msup id="S2.p1.7.m7.1.1" xref="S2.p1.7.m7.1.1.cmml"><mi id="S2.p1.7.m7.1.1.2" xref="S2.p1.7.m7.1.1.2.cmml">â„</mi><mi id="S2.p1.7.m7.1.1.3" xref="S2.p1.7.m7.1.1.3.cmml">d</mi></msup><annotation-xml encoding="MathML-Content" id="S2.p1.7.m7.1b"><apply id="S2.p1.7.m7.1.1.cmml" xref="S2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.p1.7.m7.1.1.1.cmml" xref="S2.p1.7.m7.1.1">superscript</csymbol><ci id="S2.p1.7.m7.1.1.2.cmml" xref="S2.p1.7.m7.1.1.2">â„</ci><ci id="S2.p1.7.m7.1.1.3.cmml" xref="S2.p1.7.m7.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.7.m7.1c">\mathbb{R}^{d}</annotation></semantics></math> with label <math id="S2.p1.8.m8.1" class="ltx_Math" alttext="y_{j}^{i}" display="inline"><semantics id="S2.p1.8.m8.1a"><msubsup id="S2.p1.8.m8.1.1" xref="S2.p1.8.m8.1.1.cmml"><mi id="S2.p1.8.m8.1.1.2.2" xref="S2.p1.8.m8.1.1.2.2.cmml">y</mi><mi id="S2.p1.8.m8.1.1.2.3" xref="S2.p1.8.m8.1.1.2.3.cmml">j</mi><mi id="S2.p1.8.m8.1.1.3" xref="S2.p1.8.m8.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.p1.8.m8.1b"><apply id="S2.p1.8.m8.1.1.cmml" xref="S2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.p1.8.m8.1.1.1.cmml" xref="S2.p1.8.m8.1.1">superscript</csymbol><apply id="S2.p1.8.m8.1.1.2.cmml" xref="S2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.p1.8.m8.1.1.2.1.cmml" xref="S2.p1.8.m8.1.1">subscript</csymbol><ci id="S2.p1.8.m8.1.1.2.2.cmml" xref="S2.p1.8.m8.1.1.2.2">ğ‘¦</ci><ci id="S2.p1.8.m8.1.1.2.3.cmml" xref="S2.p1.8.m8.1.1.2.3">ğ‘—</ci></apply><ci id="S2.p1.8.m8.1.1.3.cmml" xref="S2.p1.8.m8.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.8.m8.1c">y_{j}^{i}</annotation></semantics></math>: <math id="S2.p1.9.m9.10" class="ltx_Math" alttext="\{(x_{1,j}^{i},...,x_{l_{j},j}^{i})\in\mathbb{R}^{d\times l_{j}},(y_{j}^{i})\in\{0,1\}^{k}\ :j\in[M],l_{j}\in\mathbb{N}\}" display="inline"><semantics id="S2.p1.9.m9.10a"><mrow id="S2.p1.9.m9.10.10.2" xref="S2.p1.9.m9.10.10.3.cmml"><mo stretchy="false" id="S2.p1.9.m9.10.10.2.3" xref="S2.p1.9.m9.10.10.3.1.cmml">{</mo><mrow id="S2.p1.9.m9.9.9.1.1.2" xref="S2.p1.9.m9.9.9.1.1.3.cmml"><mrow id="S2.p1.9.m9.9.9.1.1.1.1" xref="S2.p1.9.m9.9.9.1.1.1.1.cmml"><mrow id="S2.p1.9.m9.9.9.1.1.1.1.2.2" xref="S2.p1.9.m9.9.9.1.1.1.1.2.3.cmml"><mo stretchy="false" id="S2.p1.9.m9.9.9.1.1.1.1.2.2.3" xref="S2.p1.9.m9.9.9.1.1.1.1.2.3.cmml">(</mo><msubsup id="S2.p1.9.m9.9.9.1.1.1.1.1.1.1" xref="S2.p1.9.m9.9.9.1.1.1.1.1.1.1.cmml"><mi id="S2.p1.9.m9.9.9.1.1.1.1.1.1.1.2.2" xref="S2.p1.9.m9.9.9.1.1.1.1.1.1.1.2.2.cmml">x</mi><mrow id="S2.p1.9.m9.2.2.2.4" xref="S2.p1.9.m9.2.2.2.3.cmml"><mn id="S2.p1.9.m9.1.1.1.1" xref="S2.p1.9.m9.1.1.1.1.cmml">1</mn><mo id="S2.p1.9.m9.2.2.2.4.1" xref="S2.p1.9.m9.2.2.2.3.cmml">,</mo><mi id="S2.p1.9.m9.2.2.2.2" xref="S2.p1.9.m9.2.2.2.2.cmml">j</mi></mrow><mi id="S2.p1.9.m9.9.9.1.1.1.1.1.1.1.3" xref="S2.p1.9.m9.9.9.1.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S2.p1.9.m9.9.9.1.1.1.1.2.2.4" xref="S2.p1.9.m9.9.9.1.1.1.1.2.3.cmml">,</mo><mi mathvariant="normal" id="S2.p1.9.m9.5.5" xref="S2.p1.9.m9.5.5.cmml">â€¦</mi><mo id="S2.p1.9.m9.9.9.1.1.1.1.2.2.5" xref="S2.p1.9.m9.9.9.1.1.1.1.2.3.cmml">,</mo><msubsup id="S2.p1.9.m9.9.9.1.1.1.1.2.2.2" xref="S2.p1.9.m9.9.9.1.1.1.1.2.2.2.cmml"><mi id="S2.p1.9.m9.9.9.1.1.1.1.2.2.2.2.2" xref="S2.p1.9.m9.9.9.1.1.1.1.2.2.2.2.2.cmml">x</mi><mrow id="S2.p1.9.m9.4.4.2.2" xref="S2.p1.9.m9.4.4.2.3.cmml"><msub id="S2.p1.9.m9.4.4.2.2.1" xref="S2.p1.9.m9.4.4.2.2.1.cmml"><mi id="S2.p1.9.m9.4.4.2.2.1.2" xref="S2.p1.9.m9.4.4.2.2.1.2.cmml">l</mi><mi id="S2.p1.9.m9.4.4.2.2.1.3" xref="S2.p1.9.m9.4.4.2.2.1.3.cmml">j</mi></msub><mo id="S2.p1.9.m9.4.4.2.2.2" xref="S2.p1.9.m9.4.4.2.3.cmml">,</mo><mi id="S2.p1.9.m9.3.3.1.1" xref="S2.p1.9.m9.3.3.1.1.cmml">j</mi></mrow><mi id="S2.p1.9.m9.9.9.1.1.1.1.2.2.2.3" xref="S2.p1.9.m9.9.9.1.1.1.1.2.2.2.3.cmml">i</mi></msubsup><mo stretchy="false" id="S2.p1.9.m9.9.9.1.1.1.1.2.2.6" xref="S2.p1.9.m9.9.9.1.1.1.1.2.3.cmml">)</mo></mrow><mo id="S2.p1.9.m9.9.9.1.1.1.1.3" xref="S2.p1.9.m9.9.9.1.1.1.1.3.cmml">âˆˆ</mo><msup id="S2.p1.9.m9.9.9.1.1.1.1.4" xref="S2.p1.9.m9.9.9.1.1.1.1.4.cmml"><mi id="S2.p1.9.m9.9.9.1.1.1.1.4.2" xref="S2.p1.9.m9.9.9.1.1.1.1.4.2.cmml">â„</mi><mrow id="S2.p1.9.m9.9.9.1.1.1.1.4.3" xref="S2.p1.9.m9.9.9.1.1.1.1.4.3.cmml"><mi id="S2.p1.9.m9.9.9.1.1.1.1.4.3.2" xref="S2.p1.9.m9.9.9.1.1.1.1.4.3.2.cmml">d</mi><mo lspace="0.222em" rspace="0.222em" id="S2.p1.9.m9.9.9.1.1.1.1.4.3.1" xref="S2.p1.9.m9.9.9.1.1.1.1.4.3.1.cmml">Ã—</mo><msub id="S2.p1.9.m9.9.9.1.1.1.1.4.3.3" xref="S2.p1.9.m9.9.9.1.1.1.1.4.3.3.cmml"><mi id="S2.p1.9.m9.9.9.1.1.1.1.4.3.3.2" xref="S2.p1.9.m9.9.9.1.1.1.1.4.3.3.2.cmml">l</mi><mi id="S2.p1.9.m9.9.9.1.1.1.1.4.3.3.3" xref="S2.p1.9.m9.9.9.1.1.1.1.4.3.3.3.cmml">j</mi></msub></mrow></msup></mrow><mo id="S2.p1.9.m9.9.9.1.1.2.3" xref="S2.p1.9.m9.9.9.1.1.3a.cmml">,</mo><mrow id="S2.p1.9.m9.9.9.1.1.2.2" xref="S2.p1.9.m9.9.9.1.1.2.2.cmml"><mrow id="S2.p1.9.m9.9.9.1.1.2.2.1.1" xref="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.p1.9.m9.9.9.1.1.2.2.1.1.2" xref="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.cmml">(</mo><msubsup id="S2.p1.9.m9.9.9.1.1.2.2.1.1.1" xref="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.cmml"><mi id="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.2.2" xref="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.2.2.cmml">y</mi><mi id="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.2.3" xref="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.2.3.cmml">j</mi><mi id="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.3" xref="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.3.cmml">i</mi></msubsup><mo stretchy="false" id="S2.p1.9.m9.9.9.1.1.2.2.1.1.3" xref="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.cmml">)</mo></mrow><mo id="S2.p1.9.m9.9.9.1.1.2.2.2" xref="S2.p1.9.m9.9.9.1.1.2.2.2.cmml">âˆˆ</mo><msup id="S2.p1.9.m9.9.9.1.1.2.2.3" xref="S2.p1.9.m9.9.9.1.1.2.2.3.cmml"><mrow id="S2.p1.9.m9.9.9.1.1.2.2.3.2.2" xref="S2.p1.9.m9.9.9.1.1.2.2.3.2.1.cmml"><mo stretchy="false" id="S2.p1.9.m9.9.9.1.1.2.2.3.2.2.1" xref="S2.p1.9.m9.9.9.1.1.2.2.3.2.1.cmml">{</mo><mn id="S2.p1.9.m9.6.6" xref="S2.p1.9.m9.6.6.cmml">0</mn><mo id="S2.p1.9.m9.9.9.1.1.2.2.3.2.2.2" xref="S2.p1.9.m9.9.9.1.1.2.2.3.2.1.cmml">,</mo><mn id="S2.p1.9.m9.7.7" xref="S2.p1.9.m9.7.7.cmml">1</mn><mo rspace="0.278em" stretchy="false" id="S2.p1.9.m9.9.9.1.1.2.2.3.2.2.3" xref="S2.p1.9.m9.9.9.1.1.2.2.3.2.1.cmml">}</mo></mrow><mi id="S2.p1.9.m9.9.9.1.1.2.2.3.3" xref="S2.p1.9.m9.9.9.1.1.2.2.3.3.cmml">k</mi></msup></mrow></mrow><mo rspace="0.278em" id="S2.p1.9.m9.10.10.2.4" xref="S2.p1.9.m9.10.10.3.1.cmml">:</mo><mrow id="S2.p1.9.m9.10.10.2.2.2" xref="S2.p1.9.m9.10.10.2.2.3.cmml"><mrow id="S2.p1.9.m9.10.10.2.2.1.1" xref="S2.p1.9.m9.10.10.2.2.1.1.cmml"><mi id="S2.p1.9.m9.10.10.2.2.1.1.2" xref="S2.p1.9.m9.10.10.2.2.1.1.2.cmml">j</mi><mo id="S2.p1.9.m9.10.10.2.2.1.1.1" xref="S2.p1.9.m9.10.10.2.2.1.1.1.cmml">âˆˆ</mo><mrow id="S2.p1.9.m9.10.10.2.2.1.1.3.2" xref="S2.p1.9.m9.10.10.2.2.1.1.3.1.cmml"><mo stretchy="false" id="S2.p1.9.m9.10.10.2.2.1.1.3.2.1" xref="S2.p1.9.m9.10.10.2.2.1.1.3.1.1.cmml">[</mo><mi id="S2.p1.9.m9.8.8" xref="S2.p1.9.m9.8.8.cmml">M</mi><mo stretchy="false" id="S2.p1.9.m9.10.10.2.2.1.1.3.2.2" xref="S2.p1.9.m9.10.10.2.2.1.1.3.1.1.cmml">]</mo></mrow></mrow><mo id="S2.p1.9.m9.10.10.2.2.2.3" xref="S2.p1.9.m9.10.10.2.2.3a.cmml">,</mo><mrow id="S2.p1.9.m9.10.10.2.2.2.2" xref="S2.p1.9.m9.10.10.2.2.2.2.cmml"><msub id="S2.p1.9.m9.10.10.2.2.2.2.2" xref="S2.p1.9.m9.10.10.2.2.2.2.2.cmml"><mi id="S2.p1.9.m9.10.10.2.2.2.2.2.2" xref="S2.p1.9.m9.10.10.2.2.2.2.2.2.cmml">l</mi><mi id="S2.p1.9.m9.10.10.2.2.2.2.2.3" xref="S2.p1.9.m9.10.10.2.2.2.2.2.3.cmml">j</mi></msub><mo id="S2.p1.9.m9.10.10.2.2.2.2.1" xref="S2.p1.9.m9.10.10.2.2.2.2.1.cmml">âˆˆ</mo><mi id="S2.p1.9.m9.10.10.2.2.2.2.3" xref="S2.p1.9.m9.10.10.2.2.2.2.3.cmml">â„•</mi></mrow></mrow><mo stretchy="false" id="S2.p1.9.m9.10.10.2.5" xref="S2.p1.9.m9.10.10.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.9.m9.10b"><apply id="S2.p1.9.m9.10.10.3.cmml" xref="S2.p1.9.m9.10.10.2"><csymbol cd="latexml" id="S2.p1.9.m9.10.10.3.1.cmml" xref="S2.p1.9.m9.10.10.2.3">conditional-set</csymbol><apply id="S2.p1.9.m9.9.9.1.1.3.cmml" xref="S2.p1.9.m9.9.9.1.1.2"><csymbol cd="ambiguous" id="S2.p1.9.m9.9.9.1.1.3a.cmml" xref="S2.p1.9.m9.9.9.1.1.2.3">formulae-sequence</csymbol><apply id="S2.p1.9.m9.9.9.1.1.1.1.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1"><in id="S2.p1.9.m9.9.9.1.1.1.1.3.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.3"></in><vector id="S2.p1.9.m9.9.9.1.1.1.1.2.3.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.2.2"><apply id="S2.p1.9.m9.9.9.1.1.1.1.1.1.1.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p1.9.m9.9.9.1.1.1.1.1.1.1.1.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.p1.9.m9.9.9.1.1.1.1.1.1.1.2.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p1.9.m9.9.9.1.1.1.1.1.1.1.2.1.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p1.9.m9.9.9.1.1.1.1.1.1.1.2.2.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.1.1.1.2.2">ğ‘¥</ci><list id="S2.p1.9.m9.2.2.2.3.cmml" xref="S2.p1.9.m9.2.2.2.4"><cn type="integer" id="S2.p1.9.m9.1.1.1.1.cmml" xref="S2.p1.9.m9.1.1.1.1">1</cn><ci id="S2.p1.9.m9.2.2.2.2.cmml" xref="S2.p1.9.m9.2.2.2.2">ğ‘—</ci></list></apply><ci id="S2.p1.9.m9.9.9.1.1.1.1.1.1.1.3.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><ci id="S2.p1.9.m9.5.5.cmml" xref="S2.p1.9.m9.5.5">â€¦</ci><apply id="S2.p1.9.m9.9.9.1.1.1.1.2.2.2.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.p1.9.m9.9.9.1.1.1.1.2.2.2.1.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.2.2.2">superscript</csymbol><apply id="S2.p1.9.m9.9.9.1.1.1.1.2.2.2.2.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.p1.9.m9.9.9.1.1.1.1.2.2.2.2.1.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.p1.9.m9.9.9.1.1.1.1.2.2.2.2.2.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.2.2.2.2.2">ğ‘¥</ci><list id="S2.p1.9.m9.4.4.2.3.cmml" xref="S2.p1.9.m9.4.4.2.2"><apply id="S2.p1.9.m9.4.4.2.2.1.cmml" xref="S2.p1.9.m9.4.4.2.2.1"><csymbol cd="ambiguous" id="S2.p1.9.m9.4.4.2.2.1.1.cmml" xref="S2.p1.9.m9.4.4.2.2.1">subscript</csymbol><ci id="S2.p1.9.m9.4.4.2.2.1.2.cmml" xref="S2.p1.9.m9.4.4.2.2.1.2">ğ‘™</ci><ci id="S2.p1.9.m9.4.4.2.2.1.3.cmml" xref="S2.p1.9.m9.4.4.2.2.1.3">ğ‘—</ci></apply><ci id="S2.p1.9.m9.3.3.1.1.cmml" xref="S2.p1.9.m9.3.3.1.1">ğ‘—</ci></list></apply><ci id="S2.p1.9.m9.9.9.1.1.1.1.2.2.2.3.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.2.2.2.3">ğ‘–</ci></apply></vector><apply id="S2.p1.9.m9.9.9.1.1.1.1.4.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.p1.9.m9.9.9.1.1.1.1.4.1.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.4">superscript</csymbol><ci id="S2.p1.9.m9.9.9.1.1.1.1.4.2.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.4.2">â„</ci><apply id="S2.p1.9.m9.9.9.1.1.1.1.4.3.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.4.3"><times id="S2.p1.9.m9.9.9.1.1.1.1.4.3.1.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.4.3.1"></times><ci id="S2.p1.9.m9.9.9.1.1.1.1.4.3.2.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.4.3.2">ğ‘‘</ci><apply id="S2.p1.9.m9.9.9.1.1.1.1.4.3.3.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.4.3.3"><csymbol cd="ambiguous" id="S2.p1.9.m9.9.9.1.1.1.1.4.3.3.1.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.4.3.3">subscript</csymbol><ci id="S2.p1.9.m9.9.9.1.1.1.1.4.3.3.2.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.4.3.3.2">ğ‘™</ci><ci id="S2.p1.9.m9.9.9.1.1.1.1.4.3.3.3.cmml" xref="S2.p1.9.m9.9.9.1.1.1.1.4.3.3.3">ğ‘—</ci></apply></apply></apply></apply><apply id="S2.p1.9.m9.9.9.1.1.2.2.cmml" xref="S2.p1.9.m9.9.9.1.1.2.2"><in id="S2.p1.9.m9.9.9.1.1.2.2.2.cmml" xref="S2.p1.9.m9.9.9.1.1.2.2.2"></in><apply id="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.cmml" xref="S2.p1.9.m9.9.9.1.1.2.2.1.1"><csymbol cd="ambiguous" id="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.1.cmml" xref="S2.p1.9.m9.9.9.1.1.2.2.1.1">superscript</csymbol><apply id="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.2.cmml" xref="S2.p1.9.m9.9.9.1.1.2.2.1.1"><csymbol cd="ambiguous" id="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.2.1.cmml" xref="S2.p1.9.m9.9.9.1.1.2.2.1.1">subscript</csymbol><ci id="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.2.2.cmml" xref="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.2.2">ğ‘¦</ci><ci id="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.2.3.cmml" xref="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.2.3">ğ‘—</ci></apply><ci id="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.3.cmml" xref="S2.p1.9.m9.9.9.1.1.2.2.1.1.1.3">ğ‘–</ci></apply><apply id="S2.p1.9.m9.9.9.1.1.2.2.3.cmml" xref="S2.p1.9.m9.9.9.1.1.2.2.3"><csymbol cd="ambiguous" id="S2.p1.9.m9.9.9.1.1.2.2.3.1.cmml" xref="S2.p1.9.m9.9.9.1.1.2.2.3">superscript</csymbol><set id="S2.p1.9.m9.9.9.1.1.2.2.3.2.1.cmml" xref="S2.p1.9.m9.9.9.1.1.2.2.3.2.2"><cn type="integer" id="S2.p1.9.m9.6.6.cmml" xref="S2.p1.9.m9.6.6">0</cn><cn type="integer" id="S2.p1.9.m9.7.7.cmml" xref="S2.p1.9.m9.7.7">1</cn></set><ci id="S2.p1.9.m9.9.9.1.1.2.2.3.3.cmml" xref="S2.p1.9.m9.9.9.1.1.2.2.3.3">ğ‘˜</ci></apply></apply></apply><apply id="S2.p1.9.m9.10.10.2.2.3.cmml" xref="S2.p1.9.m9.10.10.2.2.2"><csymbol cd="ambiguous" id="S2.p1.9.m9.10.10.2.2.3a.cmml" xref="S2.p1.9.m9.10.10.2.2.2.3">formulae-sequence</csymbol><apply id="S2.p1.9.m9.10.10.2.2.1.1.cmml" xref="S2.p1.9.m9.10.10.2.2.1.1"><in id="S2.p1.9.m9.10.10.2.2.1.1.1.cmml" xref="S2.p1.9.m9.10.10.2.2.1.1.1"></in><ci id="S2.p1.9.m9.10.10.2.2.1.1.2.cmml" xref="S2.p1.9.m9.10.10.2.2.1.1.2">ğ‘—</ci><apply id="S2.p1.9.m9.10.10.2.2.1.1.3.1.cmml" xref="S2.p1.9.m9.10.10.2.2.1.1.3.2"><csymbol cd="latexml" id="S2.p1.9.m9.10.10.2.2.1.1.3.1.1.cmml" xref="S2.p1.9.m9.10.10.2.2.1.1.3.2.1">delimited-[]</csymbol><ci id="S2.p1.9.m9.8.8.cmml" xref="S2.p1.9.m9.8.8">ğ‘€</ci></apply></apply><apply id="S2.p1.9.m9.10.10.2.2.2.2.cmml" xref="S2.p1.9.m9.10.10.2.2.2.2"><in id="S2.p1.9.m9.10.10.2.2.2.2.1.cmml" xref="S2.p1.9.m9.10.10.2.2.2.2.1"></in><apply id="S2.p1.9.m9.10.10.2.2.2.2.2.cmml" xref="S2.p1.9.m9.10.10.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.p1.9.m9.10.10.2.2.2.2.2.1.cmml" xref="S2.p1.9.m9.10.10.2.2.2.2.2">subscript</csymbol><ci id="S2.p1.9.m9.10.10.2.2.2.2.2.2.cmml" xref="S2.p1.9.m9.10.10.2.2.2.2.2.2">ğ‘™</ci><ci id="S2.p1.9.m9.10.10.2.2.2.2.2.3.cmml" xref="S2.p1.9.m9.10.10.2.2.2.2.2.3">ğ‘—</ci></apply><ci id="S2.p1.9.m9.10.10.2.2.2.2.3.cmml" xref="S2.p1.9.m9.10.10.2.2.2.2.3">â„•</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.9.m9.10c">\{(x_{1,j}^{i},...,x_{l_{j},j}^{i})\in\mathbb{R}^{d\times l_{j}},(y_{j}^{i})\in\{0,1\}^{k}\ :j\in[M],l_{j}\in\mathbb{N}\}</annotation></semantics></math>. Our aim is to train a global model <math id="S2.p1.10.m10.1" class="ltx_Math" alttext="f^{*}" display="inline"><semantics id="S2.p1.10.m10.1a"><msup id="S2.p1.10.m10.1.1" xref="S2.p1.10.m10.1.1.cmml"><mi id="S2.p1.10.m10.1.1.2" xref="S2.p1.10.m10.1.1.2.cmml">f</mi><mo id="S2.p1.10.m10.1.1.3" xref="S2.p1.10.m10.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S2.p1.10.m10.1b"><apply id="S2.p1.10.m10.1.1.cmml" xref="S2.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S2.p1.10.m10.1.1.1.cmml" xref="S2.p1.10.m10.1.1">superscript</csymbol><ci id="S2.p1.10.m10.1.1.2.cmml" xref="S2.p1.10.m10.1.1.2">ğ‘“</ci><times id="S2.p1.10.m10.1.1.3.cmml" xref="S2.p1.10.m10.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.10.m10.1c">f^{*}</annotation></semantics></math> from local models <math id="S2.p1.11.m11.1" class="ltx_Math" alttext="f_{i}" display="inline"><semantics id="S2.p1.11.m11.1a"><msub id="S2.p1.11.m11.1.1" xref="S2.p1.11.m11.1.1.cmml"><mi id="S2.p1.11.m11.1.1.2" xref="S2.p1.11.m11.1.1.2.cmml">f</mi><mi id="S2.p1.11.m11.1.1.3" xref="S2.p1.11.m11.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.11.m11.1b"><apply id="S2.p1.11.m11.1.1.cmml" xref="S2.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S2.p1.11.m11.1.1.1.cmml" xref="S2.p1.11.m11.1.1">subscript</csymbol><ci id="S2.p1.11.m11.1.1.2.cmml" xref="S2.p1.11.m11.1.1.2">ğ‘“</ci><ci id="S2.p1.11.m11.1.1.3.cmml" xref="S2.p1.11.m11.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.11.m11.1c">f_{i}</annotation></semantics></math> under temporal heterogeneity. Temporal heterogeneity can be defined as how the length of sequences are unequally distributed (e.g., entropy difference between the empirical distribution and uniform distribution).</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiment</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">In this section, we conducted experiments using two datasets: sequential MNIST (sMNIST) and eICU. sMNIST can be considered synthetically manipulated dataset to have temporal heterogenety. eICU dataset has temporal heterogeneity in nature.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Setup</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p">The two most commonly used deep learning architecture for sequential data are Recurrent Neural Networks (RNN) and TransformerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. We used Gated Recurrent Unit (GRU)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> and stacked Transformer encodersÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> for our experiments, which are representative model in each architecture, respectively. We used Adam for optimization with learning rate 0.01.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p">For federated learning framework, we used FedAvgÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, the simplest and the most widely used framework in federated learning. We assumed full participation of all clients for all rounds in our experiments. Local training epochs were set to 1 and communication to the global model was conducted after the training of all local models (i.e., full participation) and batch size was set to 32.</p>
</div>
<figure id="S3.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F1.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2309.09381/assets/x1.png" id="S3.F1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="346" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F1.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2309.09381/assets/x2.png" id="S3.F1.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="346" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>(<span id="S3.F1.5.1" class="ltx_text ltx_font_bold">Left</span>) Test accuracy of FedAvg trained with batches of varying-length (FedAvg-VL) and fixed-length (FedAvg-FL). (<span id="S3.F1.6.2" class="ltx_text ltx_font_bold">Right</span>) Average training loss of local models with batches of varying-length (FedAvg-VL) and fixed-length (FedAvg-FL)</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Sequential MNIST</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p">Sequential MNIST (sMNIST) is used to learn long-term dependencyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. In sMNIST, original MNIST images were flattened in scanline order (i.e., starting from the top left to the bottom right) where 784 pixels are represented in a single sequence. We constructed two different datasets to explore the effect of temporal heterogeneity.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p">For the first dataset, we divided MNIST into five subsets where each subset has the same label distribution and the number of images. Then the images in each subset were randomly re-sized into one of <math id="S3.SS2.p2.1.m1.5" class="ltx_Math" alttext="[14\times 14,17\times 17,21\times 21,24\times 24,28\times 28]" display="inline"><semantics id="S3.SS2.p2.1.m1.5a"><mrow id="S3.SS2.p2.1.m1.5.5.5" xref="S3.SS2.p2.1.m1.5.5.6.cmml"><mo stretchy="false" id="S3.SS2.p2.1.m1.5.5.5.6" xref="S3.SS2.p2.1.m1.5.5.6.cmml">[</mo><mrow id="S3.SS2.p2.1.m1.1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.1.cmml"><mn id="S3.SS2.p2.1.m1.1.1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.1.1.2.cmml">14</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.1.m1.1.1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.1.1.cmml">Ã—</mo><mn id="S3.SS2.p2.1.m1.1.1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.1.1.3.cmml">14</mn></mrow><mo id="S3.SS2.p2.1.m1.5.5.5.7" xref="S3.SS2.p2.1.m1.5.5.6.cmml">,</mo><mrow id="S3.SS2.p2.1.m1.2.2.2.2" xref="S3.SS2.p2.1.m1.2.2.2.2.cmml"><mn id="S3.SS2.p2.1.m1.2.2.2.2.2" xref="S3.SS2.p2.1.m1.2.2.2.2.2.cmml">17</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.1.m1.2.2.2.2.1" xref="S3.SS2.p2.1.m1.2.2.2.2.1.cmml">Ã—</mo><mn id="S3.SS2.p2.1.m1.2.2.2.2.3" xref="S3.SS2.p2.1.m1.2.2.2.2.3.cmml">17</mn></mrow><mo id="S3.SS2.p2.1.m1.5.5.5.8" xref="S3.SS2.p2.1.m1.5.5.6.cmml">,</mo><mrow id="S3.SS2.p2.1.m1.3.3.3.3" xref="S3.SS2.p2.1.m1.3.3.3.3.cmml"><mn id="S3.SS2.p2.1.m1.3.3.3.3.2" xref="S3.SS2.p2.1.m1.3.3.3.3.2.cmml">21</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.1.m1.3.3.3.3.1" xref="S3.SS2.p2.1.m1.3.3.3.3.1.cmml">Ã—</mo><mn id="S3.SS2.p2.1.m1.3.3.3.3.3" xref="S3.SS2.p2.1.m1.3.3.3.3.3.cmml">21</mn></mrow><mo id="S3.SS2.p2.1.m1.5.5.5.9" xref="S3.SS2.p2.1.m1.5.5.6.cmml">,</mo><mrow id="S3.SS2.p2.1.m1.4.4.4.4" xref="S3.SS2.p2.1.m1.4.4.4.4.cmml"><mn id="S3.SS2.p2.1.m1.4.4.4.4.2" xref="S3.SS2.p2.1.m1.4.4.4.4.2.cmml">24</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.1.m1.4.4.4.4.1" xref="S3.SS2.p2.1.m1.4.4.4.4.1.cmml">Ã—</mo><mn id="S3.SS2.p2.1.m1.4.4.4.4.3" xref="S3.SS2.p2.1.m1.4.4.4.4.3.cmml">24</mn></mrow><mo id="S3.SS2.p2.1.m1.5.5.5.10" xref="S3.SS2.p2.1.m1.5.5.6.cmml">,</mo><mrow id="S3.SS2.p2.1.m1.5.5.5.5" xref="S3.SS2.p2.1.m1.5.5.5.5.cmml"><mn id="S3.SS2.p2.1.m1.5.5.5.5.2" xref="S3.SS2.p2.1.m1.5.5.5.5.2.cmml">28</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.1.m1.5.5.5.5.1" xref="S3.SS2.p2.1.m1.5.5.5.5.1.cmml">Ã—</mo><mn id="S3.SS2.p2.1.m1.5.5.5.5.3" xref="S3.SS2.p2.1.m1.5.5.5.5.3.cmml">28</mn></mrow><mo stretchy="false" id="S3.SS2.p2.1.m1.5.5.5.11" xref="S3.SS2.p2.1.m1.5.5.6.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.5b"><list id="S3.SS2.p2.1.m1.5.5.6.cmml" xref="S3.SS2.p2.1.m1.5.5.5"><apply id="S3.SS2.p2.1.m1.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1"><times id="S3.SS2.p2.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1"></times><cn type="integer" id="S3.SS2.p2.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.2">14</cn><cn type="integer" id="S3.SS2.p2.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.3">14</cn></apply><apply id="S3.SS2.p2.1.m1.2.2.2.2.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2"><times id="S3.SS2.p2.1.m1.2.2.2.2.1.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2.1"></times><cn type="integer" id="S3.SS2.p2.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2.2">17</cn><cn type="integer" id="S3.SS2.p2.1.m1.2.2.2.2.3.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2.3">17</cn></apply><apply id="S3.SS2.p2.1.m1.3.3.3.3.cmml" xref="S3.SS2.p2.1.m1.3.3.3.3"><times id="S3.SS2.p2.1.m1.3.3.3.3.1.cmml" xref="S3.SS2.p2.1.m1.3.3.3.3.1"></times><cn type="integer" id="S3.SS2.p2.1.m1.3.3.3.3.2.cmml" xref="S3.SS2.p2.1.m1.3.3.3.3.2">21</cn><cn type="integer" id="S3.SS2.p2.1.m1.3.3.3.3.3.cmml" xref="S3.SS2.p2.1.m1.3.3.3.3.3">21</cn></apply><apply id="S3.SS2.p2.1.m1.4.4.4.4.cmml" xref="S3.SS2.p2.1.m1.4.4.4.4"><times id="S3.SS2.p2.1.m1.4.4.4.4.1.cmml" xref="S3.SS2.p2.1.m1.4.4.4.4.1"></times><cn type="integer" id="S3.SS2.p2.1.m1.4.4.4.4.2.cmml" xref="S3.SS2.p2.1.m1.4.4.4.4.2">24</cn><cn type="integer" id="S3.SS2.p2.1.m1.4.4.4.4.3.cmml" xref="S3.SS2.p2.1.m1.4.4.4.4.3">24</cn></apply><apply id="S3.SS2.p2.1.m1.5.5.5.5.cmml" xref="S3.SS2.p2.1.m1.5.5.5.5"><times id="S3.SS2.p2.1.m1.5.5.5.5.1.cmml" xref="S3.SS2.p2.1.m1.5.5.5.5.1"></times><cn type="integer" id="S3.SS2.p2.1.m1.5.5.5.5.2.cmml" xref="S3.SS2.p2.1.m1.5.5.5.5.2">28</cn><cn type="integer" id="S3.SS2.p2.1.m1.5.5.5.5.3.cmml" xref="S3.SS2.p2.1.m1.5.5.5.5.3">28</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.5c">[14\times 14,17\times 17,21\times 21,24\times 24,28\times 28]</annotation></semantics></math>. This dataset contains both temporal heterogeneity within clients (varying-length of sequences in a sigle client) and between clients (different distribution of sequence lengths). We refer this dataset as varying-length dataset (VL dataset).</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.1" class="ltx_p">The second dataset also has the five subsets showing the same label distribution and the number of images, but all images in the same subset were re-sized into one of <math id="S3.SS2.p3.1.m1.5" class="ltx_Math" alttext="[14\times 14,17\times 17,21\times 21,24\times 24,28\times 28]" display="inline"><semantics id="S3.SS2.p3.1.m1.5a"><mrow id="S3.SS2.p3.1.m1.5.5.5" xref="S3.SS2.p3.1.m1.5.5.6.cmml"><mo stretchy="false" id="S3.SS2.p3.1.m1.5.5.5.6" xref="S3.SS2.p3.1.m1.5.5.6.cmml">[</mo><mrow id="S3.SS2.p3.1.m1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.cmml"><mn id="S3.SS2.p3.1.m1.1.1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.1.1.2.cmml">14</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.1.m1.1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.1.cmml">Ã—</mo><mn id="S3.SS2.p3.1.m1.1.1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.1.1.3.cmml">14</mn></mrow><mo id="S3.SS2.p3.1.m1.5.5.5.7" xref="S3.SS2.p3.1.m1.5.5.6.cmml">,</mo><mrow id="S3.SS2.p3.1.m1.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.2.cmml"><mn id="S3.SS2.p3.1.m1.2.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.2.2.cmml">17</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.1.m1.2.2.2.2.1" xref="S3.SS2.p3.1.m1.2.2.2.2.1.cmml">Ã—</mo><mn id="S3.SS2.p3.1.m1.2.2.2.2.3" xref="S3.SS2.p3.1.m1.2.2.2.2.3.cmml">17</mn></mrow><mo id="S3.SS2.p3.1.m1.5.5.5.8" xref="S3.SS2.p3.1.m1.5.5.6.cmml">,</mo><mrow id="S3.SS2.p3.1.m1.3.3.3.3" xref="S3.SS2.p3.1.m1.3.3.3.3.cmml"><mn id="S3.SS2.p3.1.m1.3.3.3.3.2" xref="S3.SS2.p3.1.m1.3.3.3.3.2.cmml">21</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.1.m1.3.3.3.3.1" xref="S3.SS2.p3.1.m1.3.3.3.3.1.cmml">Ã—</mo><mn id="S3.SS2.p3.1.m1.3.3.3.3.3" xref="S3.SS2.p3.1.m1.3.3.3.3.3.cmml">21</mn></mrow><mo id="S3.SS2.p3.1.m1.5.5.5.9" xref="S3.SS2.p3.1.m1.5.5.6.cmml">,</mo><mrow id="S3.SS2.p3.1.m1.4.4.4.4" xref="S3.SS2.p3.1.m1.4.4.4.4.cmml"><mn id="S3.SS2.p3.1.m1.4.4.4.4.2" xref="S3.SS2.p3.1.m1.4.4.4.4.2.cmml">24</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.1.m1.4.4.4.4.1" xref="S3.SS2.p3.1.m1.4.4.4.4.1.cmml">Ã—</mo><mn id="S3.SS2.p3.1.m1.4.4.4.4.3" xref="S3.SS2.p3.1.m1.4.4.4.4.3.cmml">24</mn></mrow><mo id="S3.SS2.p3.1.m1.5.5.5.10" xref="S3.SS2.p3.1.m1.5.5.6.cmml">,</mo><mrow id="S3.SS2.p3.1.m1.5.5.5.5" xref="S3.SS2.p3.1.m1.5.5.5.5.cmml"><mn id="S3.SS2.p3.1.m1.5.5.5.5.2" xref="S3.SS2.p3.1.m1.5.5.5.5.2.cmml">28</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.1.m1.5.5.5.5.1" xref="S3.SS2.p3.1.m1.5.5.5.5.1.cmml">Ã—</mo><mn id="S3.SS2.p3.1.m1.5.5.5.5.3" xref="S3.SS2.p3.1.m1.5.5.5.5.3.cmml">28</mn></mrow><mo stretchy="false" id="S3.SS2.p3.1.m1.5.5.5.11" xref="S3.SS2.p3.1.m1.5.5.6.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.5b"><list id="S3.SS2.p3.1.m1.5.5.6.cmml" xref="S3.SS2.p3.1.m1.5.5.5"><apply id="S3.SS2.p3.1.m1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1"><times id="S3.SS2.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1"></times><cn type="integer" id="S3.SS2.p3.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.2">14</cn><cn type="integer" id="S3.SS2.p3.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.3">14</cn></apply><apply id="S3.SS2.p3.1.m1.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2"><times id="S3.SS2.p3.1.m1.2.2.2.2.1.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.1"></times><cn type="integer" id="S3.SS2.p3.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2">17</cn><cn type="integer" id="S3.SS2.p3.1.m1.2.2.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.3">17</cn></apply><apply id="S3.SS2.p3.1.m1.3.3.3.3.cmml" xref="S3.SS2.p3.1.m1.3.3.3.3"><times id="S3.SS2.p3.1.m1.3.3.3.3.1.cmml" xref="S3.SS2.p3.1.m1.3.3.3.3.1"></times><cn type="integer" id="S3.SS2.p3.1.m1.3.3.3.3.2.cmml" xref="S3.SS2.p3.1.m1.3.3.3.3.2">21</cn><cn type="integer" id="S3.SS2.p3.1.m1.3.3.3.3.3.cmml" xref="S3.SS2.p3.1.m1.3.3.3.3.3">21</cn></apply><apply id="S3.SS2.p3.1.m1.4.4.4.4.cmml" xref="S3.SS2.p3.1.m1.4.4.4.4"><times id="S3.SS2.p3.1.m1.4.4.4.4.1.cmml" xref="S3.SS2.p3.1.m1.4.4.4.4.1"></times><cn type="integer" id="S3.SS2.p3.1.m1.4.4.4.4.2.cmml" xref="S3.SS2.p3.1.m1.4.4.4.4.2">24</cn><cn type="integer" id="S3.SS2.p3.1.m1.4.4.4.4.3.cmml" xref="S3.SS2.p3.1.m1.4.4.4.4.3">24</cn></apply><apply id="S3.SS2.p3.1.m1.5.5.5.5.cmml" xref="S3.SS2.p3.1.m1.5.5.5.5"><times id="S3.SS2.p3.1.m1.5.5.5.5.1.cmml" xref="S3.SS2.p3.1.m1.5.5.5.5.1"></times><cn type="integer" id="S3.SS2.p3.1.m1.5.5.5.5.2.cmml" xref="S3.SS2.p3.1.m1.5.5.5.5.2">28</cn><cn type="integer" id="S3.SS2.p3.1.m1.5.5.5.5.3.cmml" xref="S3.SS2.p3.1.m1.5.5.5.5.3">28</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.5c">[14\times 14,17\times 17,21\times 21,24\times 24,28\times 28]</annotation></semantics></math>. While temporal heterogeneity exists both inside and across clients in the first dataset, temporal heterogeneity only exists across clients in the second dataset. We refer the second dataset as fixed-length dataset (FL dataset).</p>
</div>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.p4.1" class="ltx_p">FigureÂ <a href="#S3.F1" title="Figure 1 â€£ 3.1 Setup â€£ 3 Experiment â€£ Federated Learning in Temporal Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows test accuracy and average training loss per communication round on VL dataset and FL dataset. We observed that FedAvg on FL dataset quickly converges than VL dataset. FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3.2 Sequential MNIST â€£ 3 Experiment â€£ Federated Learning in Temporal Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="l_{2}" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><msub id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml"><mi id="S3.SS2.p4.1.m1.1.1.2" xref="S3.SS2.p4.1.m1.1.1.2.cmml">l</mi><mn id="S3.SS2.p4.1.m1.1.1.3" xref="S3.SS2.p4.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><apply id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.1.1.2">ğ‘™</ci><cn type="integer" id="S3.SS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">l_{2}</annotation></semantics></math>-distance between each local model and global model in FedAvg on the two datasets. While FedAvg on VL dataset and FL dataset both shows convergence to the global model, FedAvg on FL dataset shows different behavior from FedAvg on VL dataset. As local model divergence behavior has crucial impact on the performance of global model especially in non-iid settingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, this warrants further investigation.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F2.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="" id="S3.F2.1.g1" class="ltx_graphics ltx_missing ltx_missing_image" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F2.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2309.09381/assets/x4.png" id="S3.F2.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="346" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>(Left) Test accuracy of FedAvg trained with batches of varying-length (FedAvg-VL) and fixed-length (FedAvg-FL). (Right) Average training loss of local models with batches of varying-length (FedAvg-VL) and fixed-length (FedAvg-FL)</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Intensive Care Unit Acuity Prediction</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.p1.1" class="ltx_p">This experiment will be added after theoretical justification based on the empirical observation using sMNIST.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Proposed Method</h2>

<figure id="S4.F3" class="ltx_figure ltx_align_center"><img src="/html/2309.09381/assets/x5.png" id="S4.F3.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="302" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Visual description of batch alignment. Color represents client membership of data. Solid box represents local training batch. Dashed lines represent communication round.</figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Batch Alignment</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p">FigureÂ <a href="#S4.F3" title="Figure 3 â€£ 4 Proposed Method â€£ Federated Learning in Temporal Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> depicts batch alignment for federated learning. As we observed that training with batches containing fixed-length sequences, batch alignment helps efficient convergence of global model by aligning the length of sequences in a batch for each local model.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Normalization</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.1" class="ltx_p">Previous research has shown that proper normalization is beneficial for global model convergence Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. However, application of normalization to recurrent neural networks or Transformer requires careful consideration due to various reasons (e.g., gradient flow)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Further investigation requires to justify the benefits of sequential normalization over normalization of the learned representation for the entire sequence.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Future Works</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">We admit that we did not conducted all planned experiments due to time limit. This works are purely based on empirical observation, therefore theoretical justification will be required. In order for theoretical analysis, we need clear mathematical definition of temporal heterogeneity. Neural Tangent KernelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> can be used for theoretical analysis (motivated by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>), which can be combined with empirical observation of the tracking of gradient w.r.t. the varying length of sequences.</p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.1" class="ltx_p">Additionally, we did not include the results using Transformer encoder, which is the most commonly used deep learning model for sequential data. Therefore, future works will also include the same experiments using Transformer encoder.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Kyunghyun Cho, Bart VanÂ MerriÃ«nboer, Caglar Gulcehre, Dzmitry Bahdanau,
Fethi Bougares, Holger Schwenk, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Learning phrase representations using rnn encoder-decoder for
statistical machine translation.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1406.1078</span>, 2014.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Tim Cooijmans, Nicolas Ballas, CÃ©sar Laurent, Ã‡aÄŸlar
GÃ¼lÃ§ehre, and Aaron Courville.

</span>
<span class="ltx_bibblock">Recurrent batch normalization.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1603.09025</span>, 2016.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language
understanding.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1810.04805</span>, 2018.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Arthur Jacot, Franck Gabriel, and ClÃ©ment Hongler.

</span>
<span class="ltx_bibblock">Neural tangent kernel: Convergence and generalization in neural
networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 31, 2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
CÃ©sar Laurent, Gabriel Pereyra, PhilÃ©mon Brakel, Ying Zhang, and Yoshua
Bengio.

</span>
<span class="ltx_bibblock">Batch normalized recurrent neural networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">2016 IEEE International Conference on Acoustics, Speech and
Signal Processing (ICASSP)</span>, pages 2657â€“2661. IEEE, 2016.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
QuocÂ V Le, Navdeep Jaitly, and GeoffreyÂ E Hinton.

</span>
<span class="ltx_bibblock">A simple way to initialize recurrent networks of rectified linear
units.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1504.00941</span>, 2015.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Tian Li, AnitÂ Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
Virginia Smith.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Proceedings of Machine learning and systems</span>, 2:429â€“450, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Xiaoxiao Li, Meirui Jiang, Xiaofei Zhang, Michael Kamp, and QiÂ Dou.

</span>
<span class="ltx_bibblock">Fedbn: Federated learning on non-iid features via local batch
normalization.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2102.07623</span>, 2021.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and BlaiseÂ Aguera
yÂ Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Artificial intelligence and statistics</span>, pages 1273â€“1282.
PMLR, 2017.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Sheng Shen, Zhewei Yao, Amir Gholami, Michael Mahoney, and Kurt Keutzer.

</span>
<span class="ltx_bibblock">Powernorm: Rethinking batch normalization in transformers.

</span>
<span class="ltx_bibblock">In <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
8741â€“8751. PMLR, 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
AidanÂ N Gomez, Åukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 30, 2017.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Seongjun Yang, Hyeonji Hwang, Daeyoung Kim, Radhika Dua, Jong-Yeup Kim, Eunho
Yang, and Edward Choi.

</span>
<span class="ltx_bibblock">Towards the practical utility of federated learning in the medical
domain.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2207.03075</span>, 2022.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Hangyu Zhu, Jinjin Xu, Shiqing Liu, and Yaochu Jin.

</span>
<span class="ltx_bibblock">Federated learning on non-iid data: A survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">Neurocomputing</span>, 465:371â€“390, 2021.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2309.09380" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2309.09381" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2309.09381">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2309.09381" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2309.09382" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 03:31:37 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
