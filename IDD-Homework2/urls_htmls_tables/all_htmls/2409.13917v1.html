<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making</title>
<!--Generated on Fri Sep 20 21:54:53 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Machine Learning Visualizations Trust Decision-Making." lang="en" name="keywords"/>
<base href="/html/2409.13917v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S1" title="In Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S2" title="In Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Works</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S3" title="In Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S4" title="In Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Task 1: Trust in Recommender Systems</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S4.SS1" title="In 4 Task 1: Trust in Recommender Systems ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Procedure</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S4.SS2" title="In 4 Task 1: Trust in Recommender Systems ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Results</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S5" title="In Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Task 2: Trust in Individual Recommendations</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S5.SS1" title="In 5 Task 2: Trust in Individual Recommendations ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Procedure</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S5.SS2" title="In 5 Task 2: Trust in Individual Recommendations ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Results</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S6" title="In Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Qualitative Tasks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S7" title="In Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Discussion and Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>University of South Florida, Tampa, FL 33620, USA
<span class="ltx_note ltx_role_email" id="id1.1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>bhavanadoppalapudi@gmail.com</span></span></span> </span></span></span><span class="ltx_note ltx_role_institutetext" id="id2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>University of Utah, Salt Lake City, UT 84112, USA
<br class="ltx_break"/><span class="ltx_note ltx_role_email" id="id2.1"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">email: </span>{dilshadur,prosen}@sci.utah.edu</span></span></span></span></span></span>
<h1 class="ltx_title ltx_title_document">Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Bhavana Doppalapudi
</span><span class="ltx_author_notes">11</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Md Dilshadur Rahman
</span><span class="ltx_author_notes">22</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Paul Rosen
</span><span class="ltx_author_notes">22</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">The accuracy of recommender systems influences their trust and decision-making when using them. Providing additional information, such as visualizations, offers context that would otherwise be lacking. However, the role of visualizations in influencing trust and decisions with recommender systems is under-explored. To bridge this gap, we conducted a two-part human-subject experiment to investigate the impact of scatterplots on recommender system decisions. Our first study focuses on high-level decisions, such as selecting which recommender system to use. The second study focuses on low-level decisions, such as agreeing or disagreeing with a specific recommendation. Our results show scatterplots accompanied by higher levels of accuracy influence decisions and that participants tended to trust the recommendations more when scatterplots were accompanied by descriptive accuracy (e.g., <span class="ltx_text ltx_font_italic" id="id1.id1.1">high</span>, <span class="ltx_text ltx_font_italic" id="id1.id1.2">medium</span>, or <span class="ltx_text ltx_font_italic" id="id1.id1.3">low</span>) instead of numeric accuracy (e.g., <span class="ltx_text ltx_font_italic" id="id1.id1.4">90%</span>). Furthermore, we observed scatterplots often assisted participants in validating their decisions. Based on the results, we believe that scatterplots and visualizations, in general, can aid in making informed decisions, validating decisions, and building trust in recommendation systems.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Machine Learning Visualizations Trust Decision-Making.
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recommender systems are ubiquitous in diverse contexts, from low-risk activities like traffic prediction <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib20" title="">20</a>]</cite> and movie suggestions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib13" title="">13</a>]</cite> to high-risk scenarios like delivering child care <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib7" title="">7</a>]</cite> and homeless services <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib22" title="">22</a>]</cite>. The widespread use of recommender systems highlights the need to understand the factors influencing users’ trust in these systems. Significant research has been dedicated to studying and improving trust by enhancing transparency and providing information such as accuracy and explanations for recommendations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib39" title="">39</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib24" title="">24</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">While providing accuracy offers insights into recommender system performance, research often overlooks the nuanced meaning of accuracy, which is context-specific (e.g., due to class imbalance, classifier type, i.e., binary vs. multiclass, etc.), and expecting the general population to possess this knowledge is unreasonable.
A simple scenario is to consider a condition that is observed only 10% of the time. A recommender system that always reports false would still exhibit a 90% accuracy! While experts possess the knowledge to employ additional metrics to illustrate this imbalance, the same cannot be expected from the general population,
highlighting the need to investigate the effects of providing additional context, such as visualizations, to assist people in decision-making.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The use of visualizations in understanding people’s trust in recommender systems has been relatively underexplored. Most of the current research focuses on interactive visualizations and tools <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib28" title="">28</a>]</cite> to explore, analyze, and validate the recommendations and performance of recommender systems. While offering tools for analysis and exploration proves advantageous for professionals and researchers, translating these to the general population seems unreasonable. Furthermore, there exists a lack of focus on how including simple visualizations that depict data and offer extra contextual information regarding the features utilized by the recommender system supports trust and decision-making.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">We describe the findings of a crowdsourced study on how the inclusion of visualization, scatterplots in particular, with accuracy, shapes people’s decisions and trust in recommender systems. Our first experimental task requires participants to consider the presented scatterplots along with accuracy and make a decision on selecting 1 of the 2 provided recommender systems, with the selection of 1 over the other serving as a proxy for trust. The second experimental task requires participants to consider the presented scatterplot and decide whether to agree or disagree with a recommendation made by the recommender system. Through these tasks, we focus on (1) how scatterplots presented with different accuracy influence people’s decisions and (2) how scatterplots accompanied by accuracy presented in different formats impact trust.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Our findings show that scatterplots paired with accuracy do influence people’s decisions and trust in recommendations. In addition, we found scatterplots accompanying descriptive accuracy (e.g., ‘high,’ ‘low,’ etc.) induced more trust. Finally, we observed that scatterplots not only assisted people in making decisions but also invalidating them. Taken together, the results provide new insights into how scatterplots assist in decision-making and trust in recommendations.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_italic" id="S2.p1.1.1">Trust and Transparency in Recommendations.</span>
It has been shown that people prefer human over algorithmic advice even if the algorithm performs better <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib9" title="">9</a>]</cite>. Additionally, mistakes made by automated systems result in a quicker loss of confidence than those made by humans <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib25" title="">25</a>]</cite>. However, transparent and open explanations positively influence decision-making processes with machine learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib24" title="">24</a>]</cite>, and precisely calibrating to transparency can significantly enhance user trust and the perceived quality of recommender systems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib23" title="">23</a>]</cite>. Various studies have investigated the role of transparency in decisions with machine learning models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib38" title="">38</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib29" title="">29</a>]</cite>, but, to the best of our knowledge, the role of visualization, particularly scatterplots, in providing transparency has not been thoroughly studied.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_italic" id="S2.p2.1.1">Visualizations in Machine Learning.</span>
Chatzimparmpas et al. present a state-of-the-art report on enhancing trust in machine learning models through interactive visualizations and outline research opportunities in their surveys <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib5" title="">5</a>]</cite>. Visualizations are crucial for deciphering black-box models by identifying key features and decoding complex behaviors. Tools such as the What If Tool <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib35" title="">35</a>]</cite> and SliceTeller <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib40" title="">40</a>]</cite> provide insights into model performance under various scenarios and identify data segments causing inaccuracies. Advances in interactive visualization techniques, such as RuleMatrix <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib26" title="">26</a>]</cite>, EnsembleMatrix <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib33" title="">33</a>]</cite>, and deep learning interpretation systems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib36" title="">36</a>]</cite>, have improved the comprehension, exploration, and validation of predictive models. Tools such as ModelTracker <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib2" title="">2</a>]</cite> and Squares <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib28" title="">28</a>]</cite> refine error analysis and debugging processes through interactive visualizations that display summary statistics and instance-level performance metrics. Additionally, ExplainExplore <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib8" title="">8</a>]</cite> and Melody <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib4" title="">4</a>]</cite> analyze and summarize explanations through interactive systems for better understanding. Tools such as Fairkit-learn <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib18" title="">18</a>]</cite>, FAIRVIS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib3" title="">3</a>]</cite>, and FairSight <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib1" title="">1</a>]</cite> help data scientists assess fairness, offering methods for subgroup analysis and fairness evaluation in algorithmic decisions. DiscriLens <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib34" title="">34</a>]</cite>, D-BIAS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib15" title="">15</a>]</cite>, and Visual Auditor <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib27" title="">27</a>]</cite> focus on uncovering bias, incorporating human insights, and providing analytical views on fairness issues. These efforts highlight a trend toward leveraging visual analytics for improved fairness and bias mitigation in machine learning, with less emphasis on improving general user trust in recommendations.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1"><span class="ltx_text ltx_font_italic" id="S2.p3.1.1">Visualization and Decision-Making.</span>
Visualizations guide users in making informed decisions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib41" title="">41</a>]</cite>, communicate critical information <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib30" title="">30</a>]</cite>, aid in predictions with uncertainty <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib17" title="">17</a>]</cite>, and help identify complex patterns <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib31" title="">31</a>]</cite>. Dimara et al. proposed an agenda to enhance decision-making through visualization research <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib11" title="">11</a>]</cite>. Limited work employs visualizations to investigate trust in recommendation system decision-making. Xiong et al. used map-based visualizations to study transparency and trust through factors like accuracy, clarity, disclosure, and thoroughness <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib37" title="">37</a>]</cite>. A study that closely relates to ours investigates how visual design impacts the perception of model bias, trust, and adoption <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib14" title="">14</a>]</cite>. Findings reveal that visualization design choices, such as explaining fairness and mentioning bias, significantly affect trust levels. While both studies use visualizations and examine model performance metrics like accuracy, our study investigates the influence of scatterplots and accuracy on trust and decision-making, whereas their study focuses on identifying fair models using various signals and visualization methods, making these studies complementary.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Study</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We now describe our study of how scatterplots depicting recommender system predictions influence general users’ trust and decision-making.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1"><span class="ltx_text ltx_font_italic" id="S3.p2.1.1">Procedure.</span>
The IRB-approved study was run on Amazon Mechanical Turk (AMT) using custom web pages and server built with Python.
First, participants received an overview of the study’s goals and provided consent. After demographic questions, they completed tutorial questions with a sample dataset</p>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S3.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F1.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="131" id="S3.F1.sf1.g1" src="x1.png" width="164"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F1.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="131" id="S3.F1.sf2.g1" src="x2.png" width="159"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F1.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="131" id="S3.F1.sf3.g1" src="x3.png" width="149"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Experimental plots: (a) reference plot of training data, (b) recommender plot of testing data, and (c) testing data with single recommendation in black.</figcaption>
</figure>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">to avoid learning effects. Participants then engaged in 2 types of task: (1) high-level decision-making tasks (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S4" title="4 Task 1: Trust in Recommender Systems ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">sec.</span> <span class="ltx_text ltx_ref_tag">4</span></a>)
and (2) low-level decision-making tasks (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S5" title="5 Task 2: Trust in Individual Recommendations ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">sec.</span> <span class="ltx_text ltx_ref_tag">5</span></a>).
An example experiment is at <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://shorturl.at/xEQR7</span>.</p>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.1"><span class="ltx_text ltx_font_italic" id="S3.p4.1.1">Visualizations.</span>
For all datasets, the 2 continuous attributes with the strongest correlation to the predicted value were selected to visualize. To reduce color bias, we generated the visualizations with 4 distinct color set orientations: Red/Blue, Blue/Red (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S3.F2" title="In 3 Study ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>), Purple/Dogerblue, and Dogerblue/Purple (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S4.F4" title="In 4.1 Procedure ‣ 4 Task 1: Trust in Recommender Systems ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>).
Experiments used 3 types of scatterplots: (1) reference scatterplots (i.e., ground truth from training data), where color represents the class data points actually belong to (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S3.F1.sf1" title="In Figure 1 ‣ 3 Study ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">1a</span></a>); (2) recommender scatterplots, where the color of the data points represents the class the system predicted they belong to (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S3.F1.sf2" title="In Figure 1 ‣ 3 Study ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">1b</span></a>); and
(3) single recommendation scatterplots, where recommender scatterplots had an extra data point, depicted in black, to represent the specific data point for which the recommendation was being made (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S3.F1.sf3" title="In Figure 1 ‣ 3 Study ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">1c</span></a>).</p>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S3.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F2.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="161" id="S3.F2.sf1.g1" src="x4.png" width="202"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Haberman</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F2.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="161" id="S3.F2.sf2.g1" src="x5.png" width="195"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Liver Disease</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F2.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="161" id="S3.F2.sf3.g1" src="x6.png" width="207"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>South German</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Datasets</figcaption>
</figure>
<div class="ltx_para" id="S3.p5">
<p class="ltx_p" id="S3.p5.1"><span class="ltx_text ltx_font_italic" id="S3.p5.1.1">Recommender Models.</span>
We did not want to compare multiple models, but we did want to provide diversity in the recommendations. Therefore, we used 4 popular binary classification models: Decision Tree, Random Forest, K-Nearest Neighbors, and Support Vector Machine.
As is the case with most real recommender systems, participants were not told which model they were being presented with during the experimental tasks.
All models were built by randomly partitioning each dataset into training and test
sets at a 75% to 25% ratio, respectively. Each resulted in similar levels of accuracy that are reported at <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://shorturl.at/xEQR7</span>.</p>
</div>
<div class="ltx_para" id="S3.p6">
<p class="ltx_p" id="S3.p6.1"><span class="ltx_text ltx_font_italic" id="S3.p6.1.1">Data Sets.</span>
For our study, we used 3 datasets
acquired from the UCI Machine Learning Repository <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#bib.bib16" title="">16</a>]</cite>. The datasets were chosen to showcase some variety in data densities while avoiding complications of overdraw.
<span class="ltx_text ltx_font_italic" id="S3.p6.1.2">Haberman’s Survival</span> (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S3.F2.sf1" title="In Figure 2 ‣ 3 Study ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">2a</span></a>) contains 306 instances of 3 attributes and deals with the survival of patients 5 years after undergoing surgery for cancer. <span class="ltx_text ltx_font_italic" id="S3.p6.1.3">Indian Liver Patient</span> (see
<a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S3.F2.sf2" title="In Figure 2 ‣ 3 Study ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">2b</span></a>) comprises 583 instances of 10 attributes about the health of individuals</p>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S3.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F3.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="185" id="S3.F3.sf1.g1" src="extracted/5869362/figs/age_gender.png" width="269"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Demographics</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F3.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="196" id="S3.F3.sf2.g1" src="extracted/5869362/figs/ML_VIS_experience.png" width="269"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Background</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>(a) Age and gender (female/blue and male/orange) and (b) experience in machine learning (vert.) and visualization (horiz.).</figcaption>
</figure>
<div class="ltx_para" id="S3.p7">
<p class="ltx_p" id="S3.p7.1">with and without liver disease. <span class="ltx_text ltx_font_italic" id="S3.p7.1.1">South German Credit</span> (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S3.F2.sf3" title="In Figure 2 ‣ 3 Study ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">2c</span></a>) consists of 1000 instances of 20 attributes with the credit quality of customers for a requested loan. Details of feature selection and feature visualizations are reported in the supplement (see <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://shorturl.at/xEQR7</span>).</p>
</div>
<div class="ltx_para" id="S3.p8">
<p class="ltx_p" id="S3.p8.1"><span class="ltx_text ltx_font_italic" id="S3.p8.1.1">Participants.</span>
120 subjects were paid $2 to participate in the study, which lasted about 15 minutes. We screened the participants for their location and only those in the US and Canada were considered for the study.
We analyzed the data of 71 participants (35 female and 36 male) who passed the following inclusion criteria: (1) answered all the experimental tasks without any omissions; and
(2) provided a correct response to at least 1 of 2 attention-checks. Demographics and self-reported experience with visualization and machine learning can be found in <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S3.F3" title="In 3 Study ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Task 1: Trust in Recommender Systems</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">The primary aim of these tasks was to investigate the impact of scatterplots presented with the accuracy information on individuals’ preferences for selecting a recommender system.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Procedure</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Each participant was presented with 3 visualizations: a reference scatterplot and 2 recommender scatterplots (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S3" title="3 Study ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">sec.</span> <span class="ltx_text ltx_ref_tag">3</span></a>). Their objective was to select a recommender system from the 2 available options. We designed 3 versions of the task. Each participant was presented with all 3 versions, making it a within-subject stimuli. The variations were:</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">The <span class="ltx_text ltx_font_italic" id="S4.I1.i1.p1.1.1">Visualization-Only</span> version presented a reference scatterplot and 2 recommender scatterplot visualizations (example in supplement).</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">The <span class="ltx_text ltx_font_italic" id="S4.I1.i2.p1.1.1">Visualization + Numeric Accuracy</span> version presented a reference scatterplot with 2 recommender scatterplots, each accompanied by numeric accuracy (e.g., <span class="ltx_text ltx_font_italic" id="S4.I1.i2.p1.1.2">91%</span>) for each of the recommender scatterplots (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S4.F4" title="In 4.1 Procedure ‣ 4 Task 1: Trust in Recommender Systems ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">The <span class="ltx_text ltx_font_italic" id="S4.I1.i3.p1.1.1">Visualization + Descriptive Accuracy</span> version followed a similar setup, with a reference scatterplot and 2 recommender scatterplots, each accompanied by descriptive accuracy labels (e.g., <span class="ltx_text ltx_font_italic" id="S4.I1.i3.p1.1.2">high</span>, <span class="ltx_text ltx_font_italic" id="S4.I1.i3.p1.1.3">medium</span>, or <span class="ltx_text ltx_font_italic" id="S4.I1.i3.p1.1.4">low</span>), instead of numeric accuracy values (example in supplement).</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.1">Recommender Systems Used.</span>
We employed all 4 recommender system models (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S3" title="3 Study ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">sec.</span> <span class="ltx_text ltx_ref_tag">3</span></a>). For every question, 2 models were chosen at random.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1"><span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.1">Accuracy.</span>
In the real-world, accuracy is often provided without significant context. We intentionally avoided providing participants with an explanation of</p>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="573" id="S4.F4.g1" src="x7.png" width="580"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span class="ltx_text ltx_font_italic" id="S4.F4.2.1">Visualization + Numeric Accuracy</span> version of the experiment 1 tasks.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.6">what the accuracy actually meant to determine better how participants naturally perceived it.
Further, we opted to ignore the model output accuracy and instead systematically generated an accuracy for each stimulus. For binary classifiers like those we used, 50% accuracy indicates that the algorithm is essentially guessing.
Using this value as a lower bound, we categorized accuracy into 3 tiers, aligning descriptive accuracy with numeric accuracy: <span class="ltx_text ltx_font_italic" id="S4.SS1.p4.6.1">high</span> <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS1.p4.1.m1.1"><semantics id="S4.SS1.p4.1.m1.1a"><mo id="S4.SS1.p4.1.m1.1.1" stretchy="false" xref="S4.SS1.p4.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><ci id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.1.m1.1d">→</annotation></semantics></math> <math alttext="[90\%,95\%]" class="ltx_Math" display="inline" id="S4.SS1.p4.2.m2.2"><semantics id="S4.SS1.p4.2.m2.2a"><mrow id="S4.SS1.p4.2.m2.2.2.2" xref="S4.SS1.p4.2.m2.2.2.3.cmml"><mo id="S4.SS1.p4.2.m2.2.2.2.3" stretchy="false" xref="S4.SS1.p4.2.m2.2.2.3.cmml">[</mo><mrow id="S4.SS1.p4.2.m2.1.1.1.1" xref="S4.SS1.p4.2.m2.1.1.1.1.cmml"><mn id="S4.SS1.p4.2.m2.1.1.1.1.2" xref="S4.SS1.p4.2.m2.1.1.1.1.2.cmml">90</mn><mo id="S4.SS1.p4.2.m2.1.1.1.1.1" xref="S4.SS1.p4.2.m2.1.1.1.1.1.cmml">%</mo></mrow><mo id="S4.SS1.p4.2.m2.2.2.2.4" xref="S4.SS1.p4.2.m2.2.2.3.cmml">,</mo><mrow id="S4.SS1.p4.2.m2.2.2.2.2" xref="S4.SS1.p4.2.m2.2.2.2.2.cmml"><mn id="S4.SS1.p4.2.m2.2.2.2.2.2" xref="S4.SS1.p4.2.m2.2.2.2.2.2.cmml">95</mn><mo id="S4.SS1.p4.2.m2.2.2.2.2.1" xref="S4.SS1.p4.2.m2.2.2.2.2.1.cmml">%</mo></mrow><mo id="S4.SS1.p4.2.m2.2.2.2.5" stretchy="false" xref="S4.SS1.p4.2.m2.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.2b"><interval closure="closed" id="S4.SS1.p4.2.m2.2.2.3.cmml" xref="S4.SS1.p4.2.m2.2.2.2"><apply id="S4.SS1.p4.2.m2.1.1.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1.1.1"><csymbol cd="latexml" id="S4.SS1.p4.2.m2.1.1.1.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1.1.1.1">percent</csymbol><cn id="S4.SS1.p4.2.m2.1.1.1.1.2.cmml" type="integer" xref="S4.SS1.p4.2.m2.1.1.1.1.2">90</cn></apply><apply id="S4.SS1.p4.2.m2.2.2.2.2.cmml" xref="S4.SS1.p4.2.m2.2.2.2.2"><csymbol cd="latexml" id="S4.SS1.p4.2.m2.2.2.2.2.1.cmml" xref="S4.SS1.p4.2.m2.2.2.2.2.1">percent</csymbol><cn id="S4.SS1.p4.2.m2.2.2.2.2.2.cmml" type="integer" xref="S4.SS1.p4.2.m2.2.2.2.2.2">95</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.2c">[90\%,95\%]</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.2.m2.2d">[ 90 % , 95 % ]</annotation></semantics></math>; <span class="ltx_text ltx_font_italic" id="S4.SS1.p4.6.2">medium</span> <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS1.p4.3.m3.1"><semantics id="S4.SS1.p4.3.m3.1a"><mo id="S4.SS1.p4.3.m3.1.1" stretchy="false" xref="S4.SS1.p4.3.m3.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.3.m3.1b"><ci id="S4.SS1.p4.3.m3.1.1.cmml" xref="S4.SS1.p4.3.m3.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.3.m3.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.3.m3.1d">→</annotation></semantics></math> <math alttext="[75\%,80\%]" class="ltx_Math" display="inline" id="S4.SS1.p4.4.m4.2"><semantics id="S4.SS1.p4.4.m4.2a"><mrow id="S4.SS1.p4.4.m4.2.2.2" xref="S4.SS1.p4.4.m4.2.2.3.cmml"><mo id="S4.SS1.p4.4.m4.2.2.2.3" stretchy="false" xref="S4.SS1.p4.4.m4.2.2.3.cmml">[</mo><mrow id="S4.SS1.p4.4.m4.1.1.1.1" xref="S4.SS1.p4.4.m4.1.1.1.1.cmml"><mn id="S4.SS1.p4.4.m4.1.1.1.1.2" xref="S4.SS1.p4.4.m4.1.1.1.1.2.cmml">75</mn><mo id="S4.SS1.p4.4.m4.1.1.1.1.1" xref="S4.SS1.p4.4.m4.1.1.1.1.1.cmml">%</mo></mrow><mo id="S4.SS1.p4.4.m4.2.2.2.4" xref="S4.SS1.p4.4.m4.2.2.3.cmml">,</mo><mrow id="S4.SS1.p4.4.m4.2.2.2.2" xref="S4.SS1.p4.4.m4.2.2.2.2.cmml"><mn id="S4.SS1.p4.4.m4.2.2.2.2.2" xref="S4.SS1.p4.4.m4.2.2.2.2.2.cmml">80</mn><mo id="S4.SS1.p4.4.m4.2.2.2.2.1" xref="S4.SS1.p4.4.m4.2.2.2.2.1.cmml">%</mo></mrow><mo id="S4.SS1.p4.4.m4.2.2.2.5" stretchy="false" xref="S4.SS1.p4.4.m4.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.4.m4.2b"><interval closure="closed" id="S4.SS1.p4.4.m4.2.2.3.cmml" xref="S4.SS1.p4.4.m4.2.2.2"><apply id="S4.SS1.p4.4.m4.1.1.1.1.cmml" xref="S4.SS1.p4.4.m4.1.1.1.1"><csymbol cd="latexml" id="S4.SS1.p4.4.m4.1.1.1.1.1.cmml" xref="S4.SS1.p4.4.m4.1.1.1.1.1">percent</csymbol><cn id="S4.SS1.p4.4.m4.1.1.1.1.2.cmml" type="integer" xref="S4.SS1.p4.4.m4.1.1.1.1.2">75</cn></apply><apply id="S4.SS1.p4.4.m4.2.2.2.2.cmml" xref="S4.SS1.p4.4.m4.2.2.2.2"><csymbol cd="latexml" id="S4.SS1.p4.4.m4.2.2.2.2.1.cmml" xref="S4.SS1.p4.4.m4.2.2.2.2.1">percent</csymbol><cn id="S4.SS1.p4.4.m4.2.2.2.2.2.cmml" type="integer" xref="S4.SS1.p4.4.m4.2.2.2.2.2">80</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.4.m4.2c">[75\%,80\%]</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.4.m4.2d">[ 75 % , 80 % ]</annotation></semantics></math>; and <span class="ltx_text ltx_font_italic" id="S4.SS1.p4.6.3">low</span> <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS1.p4.5.m5.1"><semantics id="S4.SS1.p4.5.m5.1a"><mo id="S4.SS1.p4.5.m5.1.1" stretchy="false" xref="S4.SS1.p4.5.m5.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.5.m5.1b"><ci id="S4.SS1.p4.5.m5.1.1.cmml" xref="S4.SS1.p4.5.m5.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.5.m5.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.5.m5.1d">→</annotation></semantics></math> <math alttext="[65\%,70\%]" class="ltx_Math" display="inline" id="S4.SS1.p4.6.m6.2"><semantics id="S4.SS1.p4.6.m6.2a"><mrow id="S4.SS1.p4.6.m6.2.2.2" xref="S4.SS1.p4.6.m6.2.2.3.cmml"><mo id="S4.SS1.p4.6.m6.2.2.2.3" stretchy="false" xref="S4.SS1.p4.6.m6.2.2.3.cmml">[</mo><mrow id="S4.SS1.p4.6.m6.1.1.1.1" xref="S4.SS1.p4.6.m6.1.1.1.1.cmml"><mn id="S4.SS1.p4.6.m6.1.1.1.1.2" xref="S4.SS1.p4.6.m6.1.1.1.1.2.cmml">65</mn><mo id="S4.SS1.p4.6.m6.1.1.1.1.1" xref="S4.SS1.p4.6.m6.1.1.1.1.1.cmml">%</mo></mrow><mo id="S4.SS1.p4.6.m6.2.2.2.4" xref="S4.SS1.p4.6.m6.2.2.3.cmml">,</mo><mrow id="S4.SS1.p4.6.m6.2.2.2.2" xref="S4.SS1.p4.6.m6.2.2.2.2.cmml"><mn id="S4.SS1.p4.6.m6.2.2.2.2.2" xref="S4.SS1.p4.6.m6.2.2.2.2.2.cmml">70</mn><mo id="S4.SS1.p4.6.m6.2.2.2.2.1" xref="S4.SS1.p4.6.m6.2.2.2.2.1.cmml">%</mo></mrow><mo id="S4.SS1.p4.6.m6.2.2.2.5" stretchy="false" xref="S4.SS1.p4.6.m6.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.6.m6.2b"><interval closure="closed" id="S4.SS1.p4.6.m6.2.2.3.cmml" xref="S4.SS1.p4.6.m6.2.2.2"><apply id="S4.SS1.p4.6.m6.1.1.1.1.cmml" xref="S4.SS1.p4.6.m6.1.1.1.1"><csymbol cd="latexml" id="S4.SS1.p4.6.m6.1.1.1.1.1.cmml" xref="S4.SS1.p4.6.m6.1.1.1.1.1">percent</csymbol><cn id="S4.SS1.p4.6.m6.1.1.1.1.2.cmml" type="integer" xref="S4.SS1.p4.6.m6.1.1.1.1.2">65</cn></apply><apply id="S4.SS1.p4.6.m6.2.2.2.2.cmml" xref="S4.SS1.p4.6.m6.2.2.2.2"><csymbol cd="latexml" id="S4.SS1.p4.6.m6.2.2.2.2.1.cmml" xref="S4.SS1.p4.6.m6.2.2.2.2.1">percent</csymbol><cn id="S4.SS1.p4.6.m6.2.2.2.2.2.cmml" type="integer" xref="S4.SS1.p4.6.m6.2.2.2.2.2">70</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.6.m6.2c">[65\%,70\%]</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.6.m6.2d">[ 65 % , 70 % ]</annotation></semantics></math>.
The precise numeric accuracy displayed for each question was chosen at random from within the designated range.</p>
</div>
<div class="ltx_para" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.1"><span class="ltx_text ltx_font_italic" id="S4.SS1.p5.1.1">Color.</span> Participants were randomly assigned to 1 of the 4 distinct color treatments (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S3" title="3 Study ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">sec.</span> <span class="ltx_text ltx_ref_tag">3</span></a>), and all of their stimuli used that color combination.</p>
</div>
<div class="ltx_para" id="S4.SS1.p6">
<p class="ltx_p" id="S4.SS1.p6.1"><span class="ltx_text ltx_font_italic" id="S4.SS1.p6.1.1">Tasks.</span> Each participant was assigned 9 tasks in random order, encompassing the 3 experimental conditions (i.e., Visualization-Only, Visualization + Numeric Accuracy, and Visualization + Descriptive Accuracy) across the 3 datasets (i.e., Haberman’s Survival, Indian Liver Patient, and South German Credit).</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Results</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We first evaluated whether there was any potential association (i.e., bias) for recommender system selection and task versions. We conducted a 2-way ANOVA that showed
no statistically significant interaction
(F(6,24) = 2.43, p=.057),
suggesting that participants did not have a preference for any specific recommender model but rather made decisions based on the information provided.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p ltx_minipage ltx_align_top" id="S4.SS2.p2.1" style="width:433.6pt;"><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">Hypothesis 1 [H1]:</span> <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.2">Scatterplots accompanied by higher accuracy correspond to a greater chance of selection compared to those accompanied by lower accuracy.</span></p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">We investigated the influence of scatterplots accompanied by higher accuracy (both numeric and descriptive) on the selection of recommender systems, as compared to scatterplots accompanied by lower accuracy. We used Shapiro-Wilk test to check for normality, and the results indicated the data deviated from a normal distribution (W=0.813, p&lt;.001). Thus, we conducted a Kruskal-Wallis non-parametric test, and the results of the test indicate that <span class="ltx_text ltx_font_italic" id="S4.SS2.p3.1.1">scatterplot visualizations presented with higher accuracy significantly impact the selection of recommender systems</span> (H(1, n=142)=161.19, p&lt;.001). For the post hoc analysis, we performed a Dunn’s test and compared the mean ranks. The results indicated a statistical significance for the selection of scatterplots that are accompanied by higher accuracy (Z(1, n=142)=12.69, p&lt;.001). The data was visualized to show the effects (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S4.F5.sf1" title="In Figure 5 ‣ 4.2 Results ‣ 4 Task 1: Trust in Recommender Systems ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">5a</span></a>). These findings are consistent with our hypothesis, leading us to reject the null hypothesis and <span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.2">accept H1</span>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p4">
<p class="ltx_p ltx_minipage ltx_align_center ltx_align_top" id="S4.SS2.p4.1" style="width:433.6pt;"><span class="ltx_text ltx_font_bold" id="S4.SS2.p4.1.1">Hypothesis 2 [H2]:</span> <span class="ltx_text ltx_font_italic" id="S4.SS2.p4.1.2">Scatterplots accompanied by numeric accuracy will have less influence on selection than those accompanied by descriptive accuracy.</span></p>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S4.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F5.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="240" id="S4.F5.sf1.g1" src="extracted/5869362/figs/H1_vis.png" width="252"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>High, Medium, and Low Accuracy</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F5.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="240" id="S4.F5.sf2.g1" src="extracted/5869362/figs/H2_vis.png" width="252"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Numeric and Descriptive Accuracy</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Selection of recommender systems: (a) presents the proportion of time the recommender with higher accuracy was selected, while (b) presents the selection of recommender systems for numeric and descriptive accuracy conditions.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p5">
<p class="ltx_p" id="S4.SS2.p5.1">For the subsequent analysis, we examined whether the method of presenting accuracy, specifically Numeric Accuracy (e.g., <span class="ltx_text ltx_font_italic" id="S4.SS2.p5.1.1">90%</span>) versus Descriptive Accuracy (e.g., <span class="ltx_text ltx_font_italic" id="S4.SS2.p5.1.2">high</span>), alongside scatterplot visualizations influenced the selection of recommender systems.
We used the Shapiro-Wilk test to check for normality, and the results indicated the data deviated from a normal distribution (W=0.698, p&lt;.001). Due to the non-normal distribution of data, we conducted a Wilcoxon test. The results revealed that the <span class="ltx_text ltx_font_italic" id="S4.SS2.p5.1.3">method of presenting accuracy metrics alongside scatterplot visualizations did not exhibit a statistically significant association with the selection of recommender systems</span> (W=276, p=.189) (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S4.F5.sf2" title="In Figure 5 ‣ 4.2 Results ‣ 4 Task 1: Trust in Recommender Systems ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">5b</span></a>). Therefore, we are unable to reject the null hypothesis and, therefore, <span class="ltx_text ltx_font_bold" id="S4.SS2.p5.1.4">reject H2</span>.</p>
</div>
<div class="ltx_para" id="S4.SS2.p6">
<p class="ltx_p" id="S4.SS2.p6.1"><span class="ltx_text ltx_font_italic" id="S4.SS2.p6.1.1">Discussion.</span> <span class="ltx_text ltx_font_bold" id="S4.SS2.p6.1.2">H1</span> validated that accuracy influences trust and decisions regarding the recommender system. On the other hand, we expected that the ambiguity associated with numeric accuracy would cause participants to “trust the visualization” less, as opposed to the less ambiguous descriptive accuracy. However, as <span class="ltx_text ltx_font_bold" id="S4.SS2.p6.1.3">H2</span> was rejected, we cannot support that claim in the situation.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Task 2: Trust in Individual Recommendations</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Building on the previous task, this task focuses on examining the way scatterplots, paired with accuracy, impact participants’ trust in individual recommendations generated by the recommender systems.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Procedure</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Participants were presented with information about the dataset, including what the recommender system is recommending in a single recommendation scatterplot (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S3.F1.sf3" title="In Figure 1 ‣ 3 Study ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">1c</span></a>) coupled with the recommender systems’ recommendation for the data point. They were then required to indicate if they would agree with the recommendation. The decision to agree with the recommendation was considered a proxy for trust in the recommendation.
Additionally, in order to investigate the behavior of the participant’s decision when additional information was given, we altered the sequence in which the information was provided.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<ul class="ltx_itemize" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1">The <span class="ltx_text ltx_font_italic" id="S5.I1.i1.p1.1.1">Visualization + Accuracy</span> condition provided all information at once and asked for agreement with the recommendation (example in supplement).</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1">The <span class="ltx_text ltx_font_italic" id="S5.I1.i2.p1.1.1">Visualization <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.I1.i2.p1.1.1.m1.1"><semantics id="S5.I1.i2.p1.1.1.m1.1a"><mo id="S5.I1.i2.p1.1.1.m1.1.1" stretchy="false" xref="S5.I1.i2.p1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.1.1.m1.1b"><ci id="S5.I1.i2.p1.1.1.m1.1.1.cmml" xref="S5.I1.i2.p1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i2.p1.1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.I1.i2.p1.1.1.m1.1d">→</annotation></semantics></math> Accuracy</span> condition first showed the recommendation and the single recommendation scatterplot and asked for agreement with the recommendation (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S5.F6.sf1" title="In Figure 6 ‣ 5.1 Procedure ‣ 5 Task 2: Trust in Individual Recommendations ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">6a</span></a>). Subsequently, accuracy information was provided, and participants were asked if they still agreed with the recommendation (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S5.F6.sf2" title="In Figure 6 ‣ 5.1 Procedure ‣ 5 Task 2: Trust in Individual Recommendations ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">6b</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i3.p1">
<p class="ltx_p" id="S5.I1.i3.p1.1">The <span class="ltx_text ltx_font_italic" id="S5.I1.i3.p1.1.1">Accuracy <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.I1.i3.p1.1.1.m1.1"><semantics id="S5.I1.i3.p1.1.1.m1.1a"><mo id="S5.I1.i3.p1.1.1.m1.1.1" stretchy="false" xref="S5.I1.i3.p1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.I1.i3.p1.1.1.m1.1b"><ci id="S5.I1.i3.p1.1.1.m1.1.1.cmml" xref="S5.I1.i3.p1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i3.p1.1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.I1.i3.p1.1.1.m1.1d">→</annotation></semantics></math> Visualization</span> condition initially presented the recommendation and the accuracy and asked for agreement with it. Subsequently, the single recommendation scatterplot was shown, and participants were asked if they still agreed with the recommendation (example in supplement).</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S5.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="S5.F6.sf1" style="width:377.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="462" id="S5.F6.sf1.g1" src="x8.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>First part of the task</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="S5.F6.sf2" style="width:377.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="462" id="S5.F6.sf2.g1" src="x9.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Second part of the task</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span class="ltx_text ltx_font_italic" id="S5.F6.2.1">Visualization <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.F6.2.1.m1.1"><semantics id="S5.F6.2.1.m1.1b"><mo id="S5.F6.2.1.m1.1.1" stretchy="false" xref="S5.F6.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.F6.2.1.m1.1c"><ci id="S5.F6.2.1.m1.1.1.cmml" xref="S5.F6.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.2.1.m1.1d">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.F6.2.1.m1.1e">→</annotation></semantics></math> Numeric Accuracy</span> version of task 2. (a) illustrates the initial decision of the task, while (b) the second step provides an opportunity to reconsider their decision. </figcaption>
</figure>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.2">Participants were randomly assigned to 1 of 12 distinct treatments in a <span class="ltx_text ltx_font_italic" id="S5.SS1.p3.2.3">4 * 3</span> design. As with Task 1, participants were randomly assigned to 1 of the 4 distinct color treatments (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S3" title="3 Study ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">sec.</span> <span class="ltx_text ltx_ref_tag">3</span></a>). All of their stimuli used that color combination, making it a between-subject stimuli. The task type (i.e., <span class="ltx_text ltx_font_italic" id="S5.SS1.p3.2.4">Visualization + Accuracy</span>, <span class="ltx_text ltx_font_italic" id="S5.SS1.p3.1.1">Visualization <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.p3.1.1.m1.1"><semantics id="S5.SS1.p3.1.1.m1.1a"><mo id="S5.SS1.p3.1.1.m1.1.1" stretchy="false" xref="S5.SS1.p3.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.1.m1.1b"><ci id="S5.SS1.p3.1.1.m1.1.1.cmml" xref="S5.SS1.p3.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p3.1.1.m1.1d">→</annotation></semantics></math> Accuracy</span>, and <span class="ltx_text ltx_font_italic" id="S5.SS1.p3.2.2">Accuracy <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.p3.2.2.m1.1"><semantics id="S5.SS1.p3.2.2.m1.1a"><mo id="S5.SS1.p3.2.2.m1.1.1" stretchy="false" xref="S5.SS1.p3.2.2.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.2.2.m1.1b"><ci id="S5.SS1.p3.2.2.m1.1.1.cmml" xref="S5.SS1.p3.2.2.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.2.2.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p3.2.2.m1.1d">→</annotation></semantics></math> Visualization</span>) was the second between subject stimuli. On the other hand, participants were presented with both the numeric (e.g., <span class="ltx_text ltx_font_italic" id="S5.SS1.p3.2.5">91%</span>) and descriptive (e.g., <span class="ltx_text ltx_font_italic" id="S5.SS1.p3.2.6">high</span>) conditions, making it a within-subject stimuli. Other variables, such as recommender systems’ recommendation and the accuracy shown, were randomly assigned to each participant for each task.</p>
</div>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.2"><span class="ltx_text ltx_font_italic" id="S5.SS1.p4.2.3">Task.</span> Participants were given information about the dataset, including what the recommendation system is recommending, a single recommendation scatterplot, and the systems’ recommendation of the data point and the accuracy. They were asked to record their agreement with the recommendation by selecting either <span class="ltx_text ltx_font_italic" id="S5.SS1.p4.2.4">Yes</span> or <span class="ltx_text ltx_font_italic" id="S5.SS1.p4.2.5">No</span> (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S5.F6.sf1" title="In Figure 6 ‣ 5.1 Procedure ‣ 5 Task 2: Trust in Individual Recommendations ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">6a</span></a>). For the <span class="ltx_text ltx_font_italic" id="S5.SS1.p4.1.1">Visualization <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.p4.1.1.m1.1"><semantics id="S5.SS1.p4.1.1.m1.1a"><mo id="S5.SS1.p4.1.1.m1.1.1" stretchy="false" xref="S5.SS1.p4.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.1.1.m1.1b"><ci id="S5.SS1.p4.1.1.m1.1.1.cmml" xref="S5.SS1.p4.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p4.1.1.m1.1d">→</annotation></semantics></math> Accuracy</span> and <span class="ltx_text ltx_font_italic" id="S5.SS1.p4.2.2">Accuracy <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.p4.2.2.m1.1"><semantics id="S5.SS1.p4.2.2.m1.1a"><mo id="S5.SS1.p4.2.2.m1.1.1" stretchy="false" xref="S5.SS1.p4.2.2.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.2.2.m1.1b"><ci id="S5.SS1.p4.2.2.m1.1.1.cmml" xref="S5.SS1.p4.2.2.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.2.2.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p4.2.2.m1.1d">→</annotation></semantics></math> Visualization</span> conditions, they were then shown additional information and asked the same question again (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S5.F6.sf2" title="In Figure 6 ‣ 5.1 Procedure ‣ 5 Task 2: Trust in Individual Recommendations ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">6b</span></a>). Each participant responded to a total of 6 tasks—3 datasets and 2 types of accuracy.</p>
</div>
<div class="ltx_para" id="S5.SS1.p5">
<p class="ltx_p" id="S5.SS1.p5.1"><span class="ltx_text ltx_font_italic" id="S5.SS1.p5.1.1">Recommender Systems and Recommendations.</span> We employed all 4 recommenders (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S3" title="3 Study ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">sec.</span> <span class="ltx_text ltx_ref_tag">3</span></a>). 3 data points, excluded from both training and test sets, were chosen from each dataset for recommendation. All 4 recommender systems yielded identical recommendations for the data points. We presented participants with either the actual recommendations made by the system or the inverted recommendations to balance the behavior toward stimuli and avoid bias. The recommendations were randomly assigned to participants, meaning while a participant was presented with the actual recommendation for 1 task, they might encounter the incorrect recommendation for the subsequent task.</p>
</div>
<div class="ltx_para" id="S5.SS1.p6">
<p class="ltx_p" id="S5.SS1.p6.1"><span class="ltx_text ltx_font_italic" id="S5.SS1.p6.1.1">Accuracy.</span> To assess the impact of varying accuracy, we ignored the output accuracy and systematically generated accuracy similar to Task 1.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Results</h3>
<div class="ltx_para ltx_noindent" id="S5.SS2.p1">
<p class="ltx_p ltx_minipage ltx_align_center ltx_align_top" id="S5.SS2.p1.1" style="width:433.6pt;"><span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.1">Hypothesis 3 [H3]</span>: <span class="ltx_text ltx_font_italic" id="S5.SS2.p1.1.2">Scatterplots accompanied by higher accuracy correspond to a greater chance of trusting the recommendation compared to scatterplots accompanied by lower accuracy.</span></p>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S5.F7">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F7.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="258" id="S5.F7.sf1.g1" src="extracted/5869362/figs/H3_vis.png" width="269"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Level of accuracy</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F7.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="262" id="S5.F7.sf2.g1" src="extracted/5869362/figs/H4_vis.png" width="269"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Num. or Desc.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Agreement with the recommendation: (a) across high, medium, and low accuracy and (b) when accuracy is presented as Numeric or Descriptive.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">We filtered the full data to test this hypothesis. Our initial analysis involved examining if the data satisfy the assumptions of a 1-way ANOVA. The results from the Shapiro-Wilk test (W=0.665, p&lt;0.001) indicated that data deviated significantly from a normal distribution. This led us to choose non parametric Kruskal-Wallis test. The Kruskal-Wallis analysis (H(2, n=280)=15.352, p&lt;.001) indicated the difference was statistically significant. This supported that <span class="ltx_text ltx_font_italic" id="S5.SS2.p2.1.1">scatterplots accompanied by higher accuracy correspond to a greater chance of building trust in the recommendation compared to scatterplots accompanied by lower accuracy</span>. The visualization of the corresponding data also supports this finding (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S5.F7.sf1" title="In Figure 7 ‣ 5.2 Results ‣ 5 Task 2: Trust in Individual Recommendations ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">7a</span></a>). This led us to reject the null hypothesis and <span class="ltx_text ltx_font_bold" id="S5.SS2.p2.1.2">accept H3</span>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p3">
<p class="ltx_p ltx_minipage ltx_align_center ltx_align_top" id="S5.SS2.p3.1" style="width:433.6pt;"><span class="ltx_text ltx_font_bold" id="S5.SS2.p3.1.1">Hypothesis 4 [H4]</span>: <span class="ltx_text ltx_font_italic" id="S5.SS2.p3.1.2">Scatterplots accompanied by Descriptive Accuracy correspond to a greater chance of trusting the recommendation compared to scatterplots accompanied by Numeric Accuracy.</span></p>
</div>
<div class="ltx_para" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1">We again filtered the data needed to test this hypothesis from the full data. As each participant was exposed to both scatterplots along with Numeric Accuracy and scatterplots along with Descriptive Accuracy an equal number of times, we decided to use a Paired Samples T-test. The Shapiro-Wilk test was used to test data normality, and the results (W=0.931, p&lt;.001) indicated the distribution of data deviated from normality. We selected a non parametric alternative, Wilcoxon sign test on paired samples to test our hypothesis. The results indicated (V=419, p=.008) that the median <span class="ltx_text ltx_font_italic" id="S5.SS2.p4.1.1">trust of scatterplots accompanied by Numeric Accuracy was less than that of scatterplots accompanied by Descriptive Accuracy</span>. The visualizations from the data also reflected a similar relation (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S5.F7.sf2" title="In Figure 7 ‣ 5.2 Results ‣ 5 Task 2: Trust in Individual Recommendations ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">7b</span></a>). This led us to reject null hypothesis and <span class="ltx_text ltx_font_bold" id="S5.SS2.p4.1.2">accept H4</span>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p5">
<p class="ltx_p ltx_minipage ltx_align_top" id="S5.SS2.p5.1" style="width:433.6pt;"><span class="ltx_text ltx_font_bold" id="S5.SS2.p5.1.1">Hypothesis 5 [H5]</span>: <span class="ltx_text ltx_font_italic" id="S5.SS2.p5.1.2">The order of presentation of scatterplots and accuracy of information influence the participant’s trust in the recommendation.</span></p>
</div>
<div class="ltx_para" id="S5.SS2.p6">
<p class="ltx_p" id="S5.SS2.p6.2">We utilized data for <span class="ltx_text ltx_font_italic" id="S5.SS2.p6.2.3">Visualization + Accuracy</span>, <span class="ltx_text ltx_font_italic" id="S5.SS2.p6.1.1">Visualization <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS2.p6.1.1.m1.1"><semantics id="S5.SS2.p6.1.1.m1.1a"><mo id="S5.SS2.p6.1.1.m1.1.1" stretchy="false" xref="S5.SS2.p6.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p6.1.1.m1.1b"><ci id="S5.SS2.p6.1.1.m1.1.1.cmml" xref="S5.SS2.p6.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p6.1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p6.1.1.m1.1d">→</annotation></semantics></math> Accuracy</span> and <span class="ltx_text ltx_font_italic" id="S5.SS2.p6.2.2">Accuracy <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS2.p6.2.2.m1.1"><semantics id="S5.SS2.p6.2.2.m1.1a"><mo id="S5.SS2.p6.2.2.m1.1.1" stretchy="false" xref="S5.SS2.p6.2.2.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p6.2.2.m1.1b"><ci id="S5.SS2.p6.2.2.m1.1.1.cmml" xref="S5.SS2.p6.2.2.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p6.2.2.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p6.2.2.m1.1d">→</annotation></semantics></math> Visualization</span> stimuli.
We used Shapiro-Wilk to test for normality, and the results (W=0.852, p&lt;.001) implied data deviated from a normal distribution. Therefore, we avoided 1-way ANOVA and instead used a non-parametric alternative, Kruskal-Wallis test. The Kruskal-Wallis test results (H (2, n=142)=1.005, p=.604) implied that <span class="ltx_text ltx_font_italic" id="S5.SS2.p6.2.4">no strong evidence exists to suggest that the order of presentation of scatterplots and accuracy influenced decisions</span>. Based on the results, we could not reject the null hypothesis and therefore <span class="ltx_text ltx_font_bold" id="S5.SS2.p6.2.5">reject H5</span>.</p>
</div>
<div class="ltx_para" id="S5.SS2.p7">
<p class="ltx_p" id="S5.SS2.p7.1"><span class="ltx_text ltx_font_italic" id="S5.SS2.p7.1.1">Discussion.</span> In this task, <span class="ltx_text ltx_font_bold" id="S5.SS2.p7.1.2">H3</span> showed that scatterplots accompanied by higher accuracy assist in making trustworthy decisions about a recommendation. Furthermore, unlike the previous experimental task, <span class="ltx_text ltx_font_bold" id="S5.SS2.p7.1.3">H4</span> validated that scatterplots accompanied by subjective information like Descriptive Accuracy aid in instilling trust in a recommendation compared to Numeric Accuracy. Although we expected the order of presenting information to sway the trust in recommendations, we did not find evidence of it in our experiment.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Qualitative Tasks</h2>
<figure class="ltx_figure ltx_align_floatright" id="S6.F8">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F8.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="188" id="S6.F8.sf1.g1" src="extracted/5869362/figs/likert_values.png" width="293"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Dependency levels</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F8.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="177" id="S6.F8.sf2.g1" src="extracted/5869362/figs/open_image.png" width="240"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Strategies</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>(a) Self-reported dependence on scatterplots for task 1 (T1) and task 2 (T2). (b) The outcomes derived from the post-experiment questionnaire, where <span class="ltx_text ltx_font_typewriter" id="S6.F8.3.1">OpenQuestion1</span> was for recommender systems, and <span class="ltx_text ltx_font_typewriter" id="S6.F8.4.2">OpenQuestion2</span> was for individual recommendations (AV: Accuracy-Validation, VA: Visualization-Validation).</figcaption>
</figure>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">We evaluated participants’ self-reported dependence on scatterplots and examine the decision-making strategies they used.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1"><span class="ltx_text ltx_font_italic" id="S6.p2.1.1">Role of Scatterplots.</span>
At the end of each experimental task version, participants recorded their level of dependence on scatterplots using a 5-point Likert Scale ranging from ‘Strongly Depend’ to ‘Strongly Does not Depend’.
Our analysis revealed that over 75% of participants indicated a significant level of dependence on the visualization, with many reporting either ‘Strongly Depend’ or ‘Depend’ on scatterplots for decision-making (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S6.F8.sf1" title="In Figure 8 ‣ 6 Qualitative Tasks ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">8a</span></a>).</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1"><span class="ltx_text ltx_font_italic" id="S6.p3.1.1">Post Experiment Questionnaire.</span>
After the experimental tasks, participants were asked 2 open-ended questions.
The first prompted them to record the approach employed in deciding to pick a recommender system when a scatterplot was coupled with accuracy (<span class="ltx_text ltx_font_typewriter" id="S6.p3.1.2">OpenQuestion1</span>), while the
second asked about the approach utilized in determining whether or not to trust an individual recommendation (<span class="ltx_text ltx_font_typewriter" id="S6.p3.1.3">OpenQuestion2</span>). The responses were reviewed and organized into 5 categories based on their decision strategies.
(1) <span class="ltx_text ltx_font_italic" id="S6.p3.1.4">Visualization-Based</span> included participants who expressed that decisions were based primarily on scatterplots. (2) <span class="ltx_text ltx_font_italic" id="S6.p3.1.5">Accuracy-Based</span> was assigned to participants who indicated accuracy as the primary determinant of their decisions.
(3) <span class="ltx_text ltx_font_italic" id="S6.p3.1.6">Visualization-Validation</span> was when the decisions were initially made using scatterplots and subsequently validated based on accuracy.
(4) <span class="ltx_text ltx_font_italic" id="S6.p3.1.7">Accuracy-Validation</span> first relied on accuracy to make decisions and then validated the decisions based on scatterplots.
(5) Participants whose decision-making strategy lacked specificity, often involving factors such as gut feeling and instinct, were categorized as <span class="ltx_text ltx_font_italic" id="S6.p3.1.8">Unclear</span>.
The results suggest that when faced with the choice between 2 recommender systems, participants tended to give slightly higher priority to accuracy over scatterplots (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13917v1#S6.F8.sf2" title="In Figure 8 ‣ 6 Qualitative Tasks ‣ Seeing is Believing: The Role of Scatterplots in Recommender System Trust and Decision-Making"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">8b</span></a>). However, our analysis revealed that when making a decision regarding their trust in individual recommendations, scatterplots played a slightly more significant role in influencing decisions.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Discussion and Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1"><span class="ltx_text ltx_font_italic" id="S7.p1.1.1">Discussion.</span>
We analyzed the way scatterplots presented, along with accuracy, influence trust in recommender systems. We observed that participants relied on the accuracy provided with the scatterplot to make decisions, and higher accuracy positively influenced both deciding on selecting a recommender system and trusting an individual recommendation. While the presentation of accuracy accompanying scatterplots as numeric and descriptive did not show a statistically significant difference in selecting a recommender system, Descriptive Accuracy exhibited a notable impact on trust in individual recommendations.
We believe the lack of influence on the selection of a recommender system could be due to the multiway comparison of the scatterplot and accuracy of both recommender systems.
Moreover, the findings also revealed that participants utilized scatterplots to validate their decisions when accuracy was higher, but they particularly relied on scatterplots to make decisions as accuracy values dropped.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1"><span class="ltx_text ltx_font_italic" id="S7.p2.1.1">Limitations and Future Work.</span>
While we primarily focused on scatterplot visualizations in our study, we plan to extend our research to examine the influence of additional visualization types on trust and decision-making. We visualized the relation between 2 attributes and aimed to explore how visualizing multiple attributes affects people’s decisions on recommendations.
We recognize that real-world datasets are often large, which can clutter visualizations and become difficult to interpret.
Finally, we acknowledge the subjective nature of trust and the challenges in measuring it. In our work, we primarily consider relative trust by focusing on participants’ selection of one option over another.</p>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.1"><span class="ltx_text ltx_font_italic" id="S7.p3.1.1">Conclusion.</span> The inspiration behind this research was to explore and comprehend the role of visualizations, especially scatterplots presented alongside accuracy, in influencing trust in recommender systems and individual recommendations. Our observations show participants did depend on scatterplots for making decisions and validating them. In particular, participants tended to trust high accuracy alone, but visualizations became increasingly more important with lower accuracy. We also saw that the presentation of the accuracy in a descriptive form, although vague, was easier to interpret than the numeric form, which also has contextualized meaning.
Based on our findings, we advocate for incorporating visualizations to enhance trust and decision-making in recommender systems. This approach helps mitigate the issues that arise from relying solely on accuracy metrics, thereby increasing the ability of the general population to make more informed decisions.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Ahn, Y., Lin, Y.R.: Fairsight: Visual analytics for fairness in decision
making. IEEE TVCG <span class="ltx_text ltx_font_bold" id="bib.bib1.1.1">26</span>(1), 1086–1095 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Amershi, S., Chickering, M., Drucker, S.M., Lee, B., Simard, P., Suh, J.:
Modeltracker: Redesigning performance analysis tools for machine learning.
In: ACM CHI. pp. 337–346 (2015)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Cabrera, Á., Epperson, W., et al.: Fairvis: Visual analytics for
discovering intersectional bias in machine learning. In: IEEE VAST. pp.
46–56 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Chan, G.Y.Y., Bertini, E., Nonato, L.G., Barr, B., Silva, C.T.: Melody:
Generating and visualizing machine learning model summary to understand data
and classifiers together. arXiv (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Chatzimparmpas, A., Martins, R.M., Jusufi, I., Kerren, A.: A survey of surveys
on the use of visualization for interpreting machine learning models.
Information Visualization <span class="ltx_text ltx_font_bold" id="bib.bib5.1.1">19</span>(3), 207–233 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Chatzimparmpas, A., Martins, R.M., Jusufi, I., Kucher, K., Rossi, F., Kerren,
A.: The state of the art in enhancing trust in machine learning models with
the use of visualizations. Computer Graphics Forum <span class="ltx_text ltx_font_bold" id="bib.bib6.1.1">39</span>(3), 713–756
(2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Chouldechova, A., Benavides-Prado, D., Fialko, O., Vaithianathan, R.: A case
study of algorithm-assisted decision making in child maltreatment hotline
screening decisions. In: ACM FAccT. pp. 134–148 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Collaris, D., van Wijk, J.J.: Explainexplore: Visual exploration of machine
learning explanations. In: IEEE PacificVis. pp. 26–35 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Dietvorst, B.J., Simmons, J.P., Massey, C.: Algorithm aversion: people
erroneously avoid algorithms after seeing them err. J. Exp. Psych.: General
<span class="ltx_text ltx_font_bold" id="bib.bib9.1.1">144</span>(1),  114 (2015)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Dimara, E., Bailly, G., Bezerianos, A., Franconeri, S.: Mitigating the
attraction effect with visualizations. IEEE TVCG <span class="ltx_text ltx_font_bold" id="bib.bib10.1.1">25</span>(1), 850–860
(2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Dimara, E., Stasko, J.: A critical reflection on visualization research: Where
do decision making tasks hide? IEEE TVCG <span class="ltx_text ltx_font_bold" id="bib.bib11.1.1">28</span>(1), 1128–1138 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Dua, D., Graff, C.: UCI machine learning repository (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Furtado, F., Singh, A.: Movie recommendation system using machine learning
algorithms. International Journal of Research in Engineering and Technology
(2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Gaba, A., Kaufman, Z., Cheung, J., Shvakel, M., Hall, K.W., Brun, Y.,
Bearfield, C.X.: My model is unfair, do people even care? visual design
affects trust and perceived bias in machine learning. IEEE TVCG
<span class="ltx_text ltx_font_bold" id="bib.bib14.1.1">30</span>(1), 327–337 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Ghai, B., Mueller, K.: D-bias: a causality-based human-in-the-loop system for
tackling algorithmic bias. IEEE TVCG <span class="ltx_text ltx_font_bold" id="bib.bib15.1.1">29</span>(1), 473–482 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Groemping, U.: South german credit data: Correcting a widely used data set.
Rep. Math., Phys. Chem., Berlin, Germany, Tech. Rep <span class="ltx_text ltx_font_bold" id="bib.bib16.1.1">4</span>,  2019 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Guo, S., Du, F., Malik, S., Koh, E., Kim, S., Liu, Z., Kim, D., Zha, H., Cao,
N.: Visualizing uncertainty and alternatives in event sequence predictions.
In: ACM CHI. pp. 1–12 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Johnson, B., Bartola, J., Angell, R., Witty, S., Giguere, S., Brun, Y.:
Fairkit, fairkit, on the wall, who’s the fairest of them all? supporting
fairness-related decision-making. EURO Journal on Decision Processes
<span class="ltx_text ltx_font_bold" id="bib.bib18.1.1">11</span>, 100031 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Kahng, M., Andrews, P.Y., Kalro, A., Chau, D.H.: Activis: Visual exploration of
industry-scale deep neural network models. IEEE TVCG <span class="ltx_text ltx_font_bold" id="bib.bib19.1.1">24</span>(1), 88–97
(2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Kay, M., Kola, T., Hullman, J.R., Munson, S.A.: When (ish) is my bus?
user-centered visualizations of uncertainty in everyday, mobile predictive
systems. In: ACM CHI. pp. 5092–5103 (2016)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Kizilcec, R.F.: How much information? effects of transparency on trust in an
algorithmic interface. In: ACM CHI. pp. 2390–2395 (2016)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Kube, A., Das, S., Fowler, P.J.: Allocating interventions based on predicted
outcomes: A case study on homelessness services. AAAI <span class="ltx_text ltx_font_bold" id="bib.bib22.1.1">33</span>(01),
622–629 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Kunkel, J., Donkers, T., et al.: Let me explain: Impact of personal and
impersonal explanations on trust in recommender systems. In: ACM CHI. pp.
1–12 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Lai, V., Tan, C.: On human predictions with explanations and predictions of
machine learning models. In: ACM FAccT. pp. 29–38 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Mahmud, H., Islam, A.N., Ahmed, S.I., Smolander, K.: What influences
algorithmic decision-making? a systematic literature review on algorithm
aversion. Technological Forecasting and Social Change <span class="ltx_text ltx_font_bold" id="bib.bib25.1.1">175</span>, 121390
(2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Ming, Y., Qu, H., Bertini, E.: Rulematrix: Visualizing and understanding
classifiers with rules. IEEE TVCG <span class="ltx_text ltx_font_bold" id="bib.bib26.1.1">25</span>(1), 342–352 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Munechika, D., Wang, Z., Reidy, J., et al.: Visual auditor: Interactive
visualization for detection and summarization of model biases. In: IEEE VIS.
pp. 45–49 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Ren, D., Amershi, S., Lee, B., Suh, J., Williams, J.D.: Squares: Supporting
interactive performance analysis for multiclass classifiers. IEEE TVCG
(2016)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Ribeiro, M.T., Singh, S., Guestrin, C.: " why should i trust you?" explaining
the predictions of any classifier. In: ACM KDD. pp. 1135–1144 (2016)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Savikhin, A., Maciejewski, R., Ebert, D.S.: Applied visual analytics for
economic decision-making. In: IEEE VAST. pp. 107–114 (2008)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Scheepens, R., Michels, S., van de Wetering, H., van Wijk, J.J.: Rationale
visualization for safety and security. In: Computer Graphics Forum. pp.
191–200 (2015)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Suresh, H., Lao, N., Liccardi, I.: Misplaced trust: Measuring the interference
of machine learning in human decision-making. In: ACM Web Science (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Talbot, J., Lee, B., et al.: Ensemblematrix: interactive visualization to
support machine learning with multiple classifiers. In: ACM CHI. pp.
1283–1292 (2009)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Wang, Q., Xu, Z., Chen, Z., Wang, Y., Liu, S., Qu, H.: Visual analysis of
discrimination in machine learning. IEEE TVCG <span class="ltx_text ltx_font_bold" id="bib.bib34.1.1">27</span>(2), 1470–1480
(2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Wexler, J., Pushkarna, M., Bolukbasi, T., Wattenberg, M., et al.: The what-if
tool: Interactive probing of machine learning models. IEEE TVCG
<span class="ltx_text ltx_font_bold" id="bib.bib35.1.1">26</span>(1), 56–65 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Wu, C., Qian, A., et al.: Feature-oriented design of visual analytics system
for interpretable deep learning based intrusion detection. In: TASE. pp.
73–80 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Xiong, C., Padilla, L., Grayson, K., Franconeri, S.: Examining the components
of trust in map-based visualizations. In: TrustVis Workshop. pp. 19–23
(2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Yang, F., Huang, Z., Scholtz, J., Arendt, D.L.: How do visual explanations
foster end users’ appropriate trust in machine learning? In: ACM IUI. pp.
189–201 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Yin, M., Wortman Vaughan, J., Wallach, H.: Understanding the effect of accuracy
on trust in machine learning models. In: ACM CHI. pp. 1–12 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Zhang, X., Ono, J.P., Song, H., Gou, L., et al.: Sliceteller: A data
slice-driven approach for machine learning model validation. IEEE TVCG
<span class="ltx_text ltx_font_bold" id="bib.bib40.1.1">29</span>(1), 842–852 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Zhang, Y., Bellamy, R.K., Kellogg, W.A.: Designing information for remediating
cognitive biases in decision-making. In: ACM CHI. pp. 2211–2220 (2015)

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Sep 20 21:54:53 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
