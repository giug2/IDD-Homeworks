<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2307.10655] A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency</title><meta property="og:description" content="Federated learning (FL) has emerged as a highly effective paradigm for privacy-preserving collaborative training among different parties.
Unlike traditional centralized learning, which requires collecting data from eac…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2307.10655">

<!--Generated on Wed Feb 28 16:35:04 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated learning,  privacy leakage,  communication efficiency,  defense mechanism,  literature survey.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Jiawei Shao<sup id="id4.4.id1" class="ltx_sup"><span id="id4.4.id1.1" class="ltx_text ltx_font_italic">∗</span></sup>,  Zijian Li<sup id="id5.5.id2" class="ltx_sup"><span id="id5.5.id2.1" class="ltx_text ltx_font_italic">∗</span></sup>,  Wenqiang Sun<sup id="id6.6.id3" class="ltx_sup"><span id="id6.6.id3.1" class="ltx_text ltx_font_italic">∗</span></sup>, 
Tailin Zhou, 
Yuchang Sun, 
Lumin Liu, 
Zehong Lin, 
Jun Zhang
</span><span class="ltx_author_notes">The authors are with the Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong (E-mail: {jiawei.shao, zijian.li, wsunap, tailin.zhou, yuchang.sun, lliubb}@connect.ust.hk, {eezhlin, eejzhang}@ust.hk).
The corresponding author is J. Zhang. The asterisk denotes equal contributions.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id7.id1" class="ltx_p">Federated learning (FL) has emerged as a highly effective paradigm for privacy-preserving collaborative training among different parties.
Unlike traditional centralized learning, which requires collecting data from each party, FL allows clients to share <em id="id7.id1.1" class="ltx_emph ltx_font_italic">privacy-preserving information</em> without exposing private datasets.
This approach not only guarantees enhanced privacy protection but also facilitates more efficient and secure collaboration among multiple participants.
Therefore, FL has gained considerable attention from researchers, promoting numerous surveys to summarize the related works.
However, the majority of these surveys concentrate on methods sharing model parameters during the training process, while overlooking the potential of sharing other forms of local information.
In this paper, we present a systematic survey from a new perspective, i.e., <em id="id7.id1.2" class="ltx_emph ltx_font_italic">what to share</em> in FL, with an emphasis on the model utility, privacy leakage, and communication efficiency.
This survey differs from previous ones due to four distinct contributions.
First, we present a new taxonomy of FL methods in terms of the sharing methods, which includes three categories of shared information: model sharing, synthetic data sharing, and knowledge sharing.
Second, we analyze the vulnerability of different sharing methods to privacy attacks and review the defense mechanisms that provide certain privacy guarantees.
Third, we conduct extensive experiments to compare the performance and communication overhead of various sharing methods in FL.
Besides, we assess the potential privacy leakage through model inversion and membership inference attacks, while comparing the effectiveness of various defense approaches.
Finally, we discuss potential deficiencies in current methods and outline future directions for improvement.
</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated learning, privacy leakage, communication efficiency, defense mechanism, literature survey.

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Artificial intelligence (AI) has been successfully integrated into a wide variety of applications, such as natural language processing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, computer vision <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, and speech recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, resulting in remarkable performance enhancements.
The success of AI systems depends on two key ingredients: massive datasets and powerful computing capabilities.
Conventionally, centralized training is used for building high-performing models, where all data are consolidated in a central server.
However, this approach strongly relies on data collection, which poses several challenges, including data availability and data privacy.
On one hand, due to the competitive industry landscape, data generally exist in the form of isolated islands, which makes it expensive and time-consuming to break down the barriers between data sources.
On the other hand, with the growing emphasis on data security and user privacy, regulations like the General Data Protection Regulation (GDPR) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and California Consumer Privacy Act (CCPA) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> have been enforced to restrict data collection and storage.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S1.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2307.10655/assets/x1.png" id="S1.F1.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="143" height="154" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S1.F1.sf1.3.2" class="ltx_text" style="font-size:80%;">Model sharing</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S1.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2307.10655/assets/x2.png" id="S1.F1.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="142" height="153" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S1.F1.sf2.3.2" class="ltx_text" style="font-size:80%;">Synthetic data sharing</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S1.F1.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2307.10655/assets/x3.png" id="S1.F1.sf3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="143" height="154" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf3.2.1.1" class="ltx_text" style="font-size:80%;">(c)</span> </span><span id="S1.F1.sf3.3.2" class="ltx_text" style="font-size:80%;">Knowledge sharing</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An overview of different sharing methods in FL.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To address the above challenges, federated learning (FL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> has emerged as a promising solution by enabling distributed learning without the need for raw data sharing.
Specifically, FL relies on a central server to coordinate distributed model learning across multiple clients, ensuring that raw data remain locally on the client, thereby mitigating privacy concerns.
During the training process, clients iteratively optimize their local models using their respective datasets while sharing <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">privacy-preserving information</em> among themselves.
The compilation of this information represents the collective expertise gained from the private datasets, which contributes to the model performance in FL.
In the literature, the shared information can be categorized into three main types: model parameters, synthetic data, and knowledge, as depicted in Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Accordingly, there are three sharing methods described as follows.</p>
</div>
<div id="S1.p3" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Model sharing.</span>
The most commonly used method is sharing the local model parameters or updates <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
In this method, the clients upload their local models to the server for aggregation.
The resulting aggregated model is then sent back to the clients for further optimization based on their local samples.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Synthetic data sharing.</span>
Rather than sharing the raw samples, some methods generate and share synthetic data in FL.
Commonly used methods include training a generative adversarial network (GAN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> and performing dataset condensation (DC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Knowledge sharing.</span>
In addition to sharing model and synthetic data, sharing <em id="S1.I1.i3.p1.1.2" class="ltx_emph ltx_font_italic">knowledge</em> is an alternative method, which typically refers to the exchange of layer activations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
One popular approach is sharing feature statistics of local data to impose regularization in local training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.
Another approach is federated distillation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, which relies on a proxy dataset to transfer knowledge among clients. Specifically, the clients share the predictions on the proxy samples with the server to leverage the averaged predictions for knowledge distillation.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In recent years, FL has gained significant attention and its efficacy has been validated in various domains, such as healthcare <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, financial services <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, and smart cities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. Despite its success, FL still faces three primary challenges:</p>
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p"><span id="S1.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Data heterogeneity.</span> The basic assumption in AI algorithms is that the training samples are independent and identically distributed (IID).
This assumption, however, is not true in the context of FL, as clients possess their own local datasets. Therefore, it is impractical to guarantee that these datasets follow the same distribution in FL.
This mismatch in data distributions gives rise to heterogeneity, which, in turn, exacerbates the issue of local divergence. Consequently, the model alignment by exchanging local information becomes more challenging, leading to poor convergence or a slower learning process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p"><span id="S1.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Privacy leakage.</span> Although FL relies on clients sharing local information instead of raw data, recent studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> have demonstrated that FL is still vulnerable to privacy attacks. This is because the shared information often contains privacy-sensitive details about the local dataset.
For instance, model sharing methods require the model parameters to be uploaded to a server for aggregation.
These parameters, however, can be exploited by a server, to reconstruct the private data and infer the properties of the local dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>.</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p id="S1.I2.i3.p1.1" class="ltx_p"><span id="S1.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Communication overhead.</span>
Unlike centralized training, which involves collecting raw data from clients only once before training begins, FL requires frequent sharing of local information from clients, resulting in considerable communication overhead <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.
Such an issue is particularly challenging when collaboratively training large language models (LLMs) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> by sharing the model parameters.
This is because the model contains billions of parameters, which are significantly larger in size than the local text datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">As discussed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, there exists a tradeoff between utility (i.e., model performance), privacy, and efficiency in FL.
Note that the sharing methods critically affect these three factors.
For example, sharing knowledge can significantly reduce communication overhead and protect the local models against white-box attacks.
Nonetheless, this method may not achieve the desired model performance, especially when the data is highly non-IID.
Moreover, when sharing synthetic samples, there is an inherent tradeoff between the model utility and the potential breach of privacy.
If the synthetic samples preserve more information from the original samples, there can be a more significant improvement in model performance.
This, however, also increases the risk of privacy breaches.
Recently, many efforts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> have been made to improve the model utility in FL while providing high privacy guarantees and reducing communication costs.
In this survey, we will take a closer look at these endeavors and provide a systematic analysis of <em id="S1.p5.1.1" class="ltx_emph ltx_font_italic">what to share</em> in FL.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span><span id="S1.SS1.1.1" class="ltx_text ltx_font_italic">Related Surveys</span>
</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">The pioneering work of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> provided a comprehensive introduction to the basics and key concepts of FL.
Subsequently, researchers such as Li et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> delved deeper into the unique properties of FL compared with distributed computation and privacy-preserving learning approaches.
In addition, the studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> summarized FL methods from a system-level perspective and provided an in-depth analysis of the hardware platforms and communication protocols.</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">Despite the rising popularity of FL, Kairouz et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> have identified a collection of open problems that need to be addressed, including non-IID data, privacy risks, and limited communication bandwidth.
To address these challenges, researchers have published several survey papers that examine different aspects of the problems.
For instance, Zhu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> provided a comprehensive review of existing solutions that tackle the non-IID issue in FL.
Furthermore, the surveys conducted by Lyu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> and Yin et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> primarily focused on security and privacy concerns in FL schemes.
In addition, Rodriguez et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> presented experimental results that evaluate the performance of various attack approaches.
Moreover, the papers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> further considered the communication challenges in FL and reviewed potential solutions to reduce communication costs.
Nonetheless, the majority of these surveys primarily concentrated on the exchange of model parameters during federated training.
The sharing of other forms of information, such as data and knowledge, has been substantially overlooked.</p>
</div>
<div id="S1.SS1.p3" class="ltx_para">
<p id="S1.SS1.p3.1" class="ltx_p">Recently, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> conducted a review of data sharing, data enhancement, and data selection schemes that aim at mitigating the non-IID problem.
Moreover, Wu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> made the first attempt to provide a comprehensive survey on federated knowledge distillation, which investigates the application of knowledge distillation (KD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> in FL.
The authors discussed the benefits of this technique in addressing the challenges related to resources, personalization, and network environments.</p>
</div>
<div id="S1.SS1.p4" class="ltx_para">
<p id="S1.SS1.p4.1" class="ltx_p">Table <a href="#S1.T1" title="TABLE I ‣ 1.1 Related Surveys ‣ 1 Introduction ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> presents a comparison of the main focuses across these surveys.
Note that none of these works explicitly specified the privacy risks associated with each of the three sharing methods, and lacked a thorough experimental study.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Overview of Related Surveys</figcaption>
<div id="S1.T1.54" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:305pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(12.1pt,-8.5pt) scale(1.05904267680686,1.05904267680686) ;">
<table id="S1.T1.54.54" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S1.T1.54.54.55.1" class="ltx_tr">
<td id="S1.T1.54.54.55.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="2"><span id="S1.T1.54.54.55.1.1.1" class="ltx_text">Ref.</span></td>
<td id="S1.T1.54.54.55.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="3">What to share</td>
<td id="S1.T1.54.54.55.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="2"><span id="S1.T1.54.54.55.1.3.1" class="ltx_text">
<span id="S1.T1.54.54.55.1.3.1.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.54.54.55.1.3.1.1.1" class="ltx_tr">
<span id="S1.T1.54.54.55.1.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">Model</span></span>
<span id="S1.T1.54.54.55.1.3.1.1.2" class="ltx_tr">
<span id="S1.T1.54.54.55.1.3.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">utility</span></span>
</span></span></td>
<td id="S1.T1.54.54.55.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="2"><span id="S1.T1.54.54.55.1.4.1" class="ltx_text">
<span id="S1.T1.54.54.55.1.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.54.54.55.1.4.1.1.1" class="ltx_tr">
<span id="S1.T1.54.54.55.1.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">Privacy</span></span>
<span id="S1.T1.54.54.55.1.4.1.1.2" class="ltx_tr">
<span id="S1.T1.54.54.55.1.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">leakage</span></span>
</span></span></td>
<td id="S1.T1.54.54.55.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="2"><span id="S1.T1.54.54.55.1.5.1" class="ltx_text">
<span id="S1.T1.54.54.55.1.5.1.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.54.54.55.1.5.1.1.1" class="ltx_tr">
<span id="S1.T1.54.54.55.1.5.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">Commun.</span></span>
<span id="S1.T1.54.54.55.1.5.1.1.2" class="ltx_tr">
<span id="S1.T1.54.54.55.1.5.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">efficiency</span></span>
</span></span></td>
<td id="S1.T1.54.54.55.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="2"><span id="S1.T1.54.54.55.1.6.1" class="ltx_text">
<span id="S1.T1.54.54.55.1.6.1.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.54.54.55.1.6.1.1.1" class="ltx_tr">
<span id="S1.T1.54.54.55.1.6.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">Empirical</span></span>
<span id="S1.T1.54.54.55.1.6.1.1.2" class="ltx_tr">
<span id="S1.T1.54.54.55.1.6.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">results</span></span>
</span></span></td>
</tr>
<tr id="S1.T1.54.54.56.2" class="ltx_tr">
<td id="S1.T1.54.54.56.2.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">Model</td>
<td id="S1.T1.54.54.56.2.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">Data</td>
<td id="S1.T1.54.54.56.2.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">Knowl.</td>
</tr>
<tr id="S1.T1.3.3.3" class="ltx_tr">
<td id="S1.T1.3.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite></td>
<td id="S1.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.1.1.1.1.m1.1a"><mi mathvariant="normal" id="S1.T1.1.1.1.1.m1.1.1" xref="S1.T1.1.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.1.1.1.1.m1.1b"><ci id="S1.T1.1.1.1.1.m1.1.1.cmml" xref="S1.T1.1.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.1.1.1.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.3.3.3.5" class="ltx_td ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.3.3.3.6" class="ltx_td ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.2.2.2.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.2.2.2.2.m1.1a"><mi mathvariant="normal" id="S1.T1.2.2.2.2.m1.1.1" xref="S1.T1.2.2.2.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.2.2.2.2.m1.1b"><ci id="S1.T1.2.2.2.2.m1.1.1.cmml" xref="S1.T1.2.2.2.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.2.2.2.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.3.3.3.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.3.3.3.3.m1.1a"><mi mathvariant="normal" id="S1.T1.3.3.3.3.m1.1.1" xref="S1.T1.3.3.3.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.3.3.3.3.m1.1b"><ci id="S1.T1.3.3.3.3.m1.1.1.cmml" xref="S1.T1.3.3.3.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.3.3.3.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.3.3.3.7" class="ltx_td ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.3.3.3.8" class="ltx_td ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
</tr>
<tr id="S1.T1.7.7.7" class="ltx_tr">
<td id="S1.T1.7.7.7.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite></td>
<td id="S1.T1.4.4.4.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.4.4.4.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.4.4.4.1.m1.1a"><mi mathvariant="normal" id="S1.T1.4.4.4.1.m1.1.1" xref="S1.T1.4.4.4.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.4.4.4.1.m1.1b"><ci id="S1.T1.4.4.4.1.m1.1.1.cmml" xref="S1.T1.4.4.4.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.4.4.4.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.7.7.7.6" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.7.7.7.7" class="ltx_td ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.5.5.5.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.5.5.5.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.5.5.5.2.m1.1a"><mi mathvariant="normal" id="S1.T1.5.5.5.2.m1.1.1" xref="S1.T1.5.5.5.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.5.5.5.2.m1.1b"><ci id="S1.T1.5.5.5.2.m1.1.1.cmml" xref="S1.T1.5.5.5.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.5.5.5.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.6.6.6.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.6.6.6.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.6.6.6.3.m1.1a"><mi mathvariant="normal" id="S1.T1.6.6.6.3.m1.1.1" xref="S1.T1.6.6.6.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.6.6.6.3.m1.1b"><ci id="S1.T1.6.6.6.3.m1.1.1.cmml" xref="S1.T1.6.6.6.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.6.6.6.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.7.7.7.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.7.7.7.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.7.7.7.4.m1.1a"><mi mathvariant="normal" id="S1.T1.7.7.7.4.m1.1.1" xref="S1.T1.7.7.7.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.7.7.7.4.m1.1b"><ci id="S1.T1.7.7.7.4.m1.1.1.cmml" xref="S1.T1.7.7.7.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.7.7.7.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.7.7.7.8" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
</tr>
<tr id="S1.T1.11.11.11" class="ltx_tr">
<td id="S1.T1.11.11.11.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite></td>
<td id="S1.T1.8.8.8.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.8.8.8.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.8.8.8.1.m1.1a"><mi mathvariant="normal" id="S1.T1.8.8.8.1.m1.1.1" xref="S1.T1.8.8.8.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.8.8.8.1.m1.1b"><ci id="S1.T1.8.8.8.1.m1.1.1.cmml" xref="S1.T1.8.8.8.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.8.8.8.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.11.11.11.6" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.11.11.11.7" class="ltx_td ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.9.9.9.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.9.9.9.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.9.9.9.2.m1.1a"><mi mathvariant="normal" id="S1.T1.9.9.9.2.m1.1.1" xref="S1.T1.9.9.9.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.9.9.9.2.m1.1b"><ci id="S1.T1.9.9.9.2.m1.1.1.cmml" xref="S1.T1.9.9.9.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.9.9.9.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.10.10.10.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.10.10.10.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.10.10.10.3.m1.1a"><mi mathvariant="normal" id="S1.T1.10.10.10.3.m1.1.1" xref="S1.T1.10.10.10.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.10.10.10.3.m1.1b"><ci id="S1.T1.10.10.10.3.m1.1.1.cmml" xref="S1.T1.10.10.10.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.10.10.10.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.11.11.11.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.11.11.11.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.11.11.11.4.m1.1a"><mi mathvariant="normal" id="S1.T1.11.11.11.4.m1.1.1" xref="S1.T1.11.11.11.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.11.11.11.4.m1.1b"><ci id="S1.T1.11.11.11.4.m1.1.1.cmml" xref="S1.T1.11.11.11.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.11.11.11.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.11.11.11.8" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
</tr>
<tr id="S1.T1.15.15.15" class="ltx_tr">
<td id="S1.T1.15.15.15.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite></td>
<td id="S1.T1.12.12.12.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.12.12.12.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.12.12.12.1.m1.1a"><mi mathvariant="normal" id="S1.T1.12.12.12.1.m1.1.1" xref="S1.T1.12.12.12.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.12.12.12.1.m1.1b"><ci id="S1.T1.12.12.12.1.m1.1.1.cmml" xref="S1.T1.12.12.12.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.12.12.12.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.15.15.15.6" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.15.15.15.7" class="ltx_td ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.13.13.13.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.13.13.13.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.13.13.13.2.m1.1a"><mi mathvariant="normal" id="S1.T1.13.13.13.2.m1.1.1" xref="S1.T1.13.13.13.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.13.13.13.2.m1.1b"><ci id="S1.T1.13.13.13.2.m1.1.1.cmml" xref="S1.T1.13.13.13.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.13.13.13.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.14.14.14.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.14.14.14.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.14.14.14.3.m1.1a"><mi mathvariant="normal" id="S1.T1.14.14.14.3.m1.1.1" xref="S1.T1.14.14.14.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.14.14.14.3.m1.1b"><ci id="S1.T1.14.14.14.3.m1.1.1.cmml" xref="S1.T1.14.14.14.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.14.14.14.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.15.15.15.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.15.15.15.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.15.15.15.4.m1.1a"><mi mathvariant="normal" id="S1.T1.15.15.15.4.m1.1.1" xref="S1.T1.15.15.15.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.15.15.15.4.m1.1b"><ci id="S1.T1.15.15.15.4.m1.1.1.cmml" xref="S1.T1.15.15.15.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.15.15.15.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.15.15.15.8" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
</tr>
<tr id="S1.T1.19.19.19" class="ltx_tr">
<td id="S1.T1.19.19.19.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite></td>
<td id="S1.T1.16.16.16.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.16.16.16.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.16.16.16.1.m1.1a"><mi mathvariant="normal" id="S1.T1.16.16.16.1.m1.1.1" xref="S1.T1.16.16.16.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.16.16.16.1.m1.1b"><ci id="S1.T1.16.16.16.1.m1.1.1.cmml" xref="S1.T1.16.16.16.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.16.16.16.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.19.19.19.6" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.19.19.19.7" class="ltx_td ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.17.17.17.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.17.17.17.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.17.17.17.2.m1.1a"><mi mathvariant="normal" id="S1.T1.17.17.17.2.m1.1.1" xref="S1.T1.17.17.17.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.17.17.17.2.m1.1b"><ci id="S1.T1.17.17.17.2.m1.1.1.cmml" xref="S1.T1.17.17.17.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.17.17.17.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.18.18.18.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.18.18.18.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.18.18.18.3.m1.1a"><mi mathvariant="normal" id="S1.T1.18.18.18.3.m1.1.1" xref="S1.T1.18.18.18.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.18.18.18.3.m1.1b"><ci id="S1.T1.18.18.18.3.m1.1.1.cmml" xref="S1.T1.18.18.18.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.18.18.18.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.19.19.19.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.19.19.19.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.19.19.19.4.m1.1a"><mi mathvariant="normal" id="S1.T1.19.19.19.4.m1.1.1" xref="S1.T1.19.19.19.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.19.19.19.4.m1.1b"><ci id="S1.T1.19.19.19.4.m1.1.1.cmml" xref="S1.T1.19.19.19.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.19.19.19.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.19.19.19.8" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
</tr>
<tr id="S1.T1.23.23.23" class="ltx_tr">
<td id="S1.T1.23.23.23.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite></td>
<td id="S1.T1.20.20.20.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.20.20.20.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.20.20.20.1.m1.1a"><mi mathvariant="normal" id="S1.T1.20.20.20.1.m1.1.1" xref="S1.T1.20.20.20.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.20.20.20.1.m1.1b"><ci id="S1.T1.20.20.20.1.m1.1.1.cmml" xref="S1.T1.20.20.20.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.20.20.20.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.21.21.21.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.21.21.21.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.21.21.21.2.m1.1a"><mi mathvariant="normal" id="S1.T1.21.21.21.2.m1.1.1" xref="S1.T1.21.21.21.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.21.21.21.2.m1.1b"><ci id="S1.T1.21.21.21.2.m1.1.1.cmml" xref="S1.T1.21.21.21.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.21.21.21.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.22.22.22.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.22.22.22.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.22.22.22.3.m1.1a"><mi mathvariant="normal" id="S1.T1.22.22.22.3.m1.1.1" xref="S1.T1.22.22.22.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.22.22.22.3.m1.1b"><ci id="S1.T1.22.22.22.3.m1.1.1.cmml" xref="S1.T1.22.22.22.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.22.22.22.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.23.23.23.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.23.23.23.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.23.23.23.4.m1.1a"><mi mathvariant="normal" id="S1.T1.23.23.23.4.m1.1.1" xref="S1.T1.23.23.23.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.23.23.23.4.m1.1b"><ci id="S1.T1.23.23.23.4.m1.1.1.cmml" xref="S1.T1.23.23.23.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.23.23.23.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.23.23.23.6" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.23.23.23.7" class="ltx_td ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.23.23.23.8" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
</tr>
<tr id="S1.T1.25.25.25" class="ltx_tr">
<td id="S1.T1.25.25.25.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite></td>
<td id="S1.T1.24.24.24.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.24.24.24.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.24.24.24.1.m1.1a"><mi mathvariant="normal" id="S1.T1.24.24.24.1.m1.1.1" xref="S1.T1.24.24.24.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.24.24.24.1.m1.1b"><ci id="S1.T1.24.24.24.1.m1.1.1.cmml" xref="S1.T1.24.24.24.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.24.24.24.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.25.25.25.4" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.25.25.25.5" class="ltx_td ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.25.25.25.6" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.25.25.25.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.25.25.25.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.25.25.25.2.m1.1a"><mi mathvariant="normal" id="S1.T1.25.25.25.2.m1.1.1" xref="S1.T1.25.25.25.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.25.25.25.2.m1.1b"><ci id="S1.T1.25.25.25.2.m1.1.1.cmml" xref="S1.T1.25.25.25.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.25.25.25.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.25.25.25.7" class="ltx_td ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.25.25.25.8" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
</tr>
<tr id="S1.T1.27.27.27" class="ltx_tr">
<td id="S1.T1.27.27.27.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite></td>
<td id="S1.T1.26.26.26.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.26.26.26.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.26.26.26.1.m1.1a"><mi mathvariant="normal" id="S1.T1.26.26.26.1.m1.1.1" xref="S1.T1.26.26.26.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.26.26.26.1.m1.1b"><ci id="S1.T1.26.26.26.1.m1.1.1.cmml" xref="S1.T1.26.26.26.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.26.26.26.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.27.27.27.4" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.27.27.27.5" class="ltx_td ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.27.27.27.6" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.27.27.27.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.27.27.27.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.27.27.27.2.m1.1a"><mi mathvariant="normal" id="S1.T1.27.27.27.2.m1.1.1" xref="S1.T1.27.27.27.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.27.27.27.2.m1.1b"><ci id="S1.T1.27.27.27.2.m1.1.1.cmml" xref="S1.T1.27.27.27.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.27.27.27.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.27.27.27.7" class="ltx_td ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.27.27.27.8" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
</tr>
<tr id="S1.T1.31.31.31" class="ltx_tr">
<td id="S1.T1.31.31.31.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite></td>
<td id="S1.T1.28.28.28.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.28.28.28.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.28.28.28.1.m1.1a"><mi mathvariant="normal" id="S1.T1.28.28.28.1.m1.1.1" xref="S1.T1.28.28.28.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.28.28.28.1.m1.1b"><ci id="S1.T1.28.28.28.1.m1.1.1.cmml" xref="S1.T1.28.28.28.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.28.28.28.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.31.31.31.6" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.31.31.31.7" class="ltx_td ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.29.29.29.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.29.29.29.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.29.29.29.2.m1.1a"><mi mathvariant="normal" id="S1.T1.29.29.29.2.m1.1.1" xref="S1.T1.29.29.29.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.29.29.29.2.m1.1b"><ci id="S1.T1.29.29.29.2.m1.1.1.cmml" xref="S1.T1.29.29.29.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.29.29.29.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.30.30.30.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.30.30.30.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.30.30.30.3.m1.1a"><mi mathvariant="normal" id="S1.T1.30.30.30.3.m1.1.1" xref="S1.T1.30.30.30.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.30.30.30.3.m1.1b"><ci id="S1.T1.30.30.30.3.m1.1.1.cmml" xref="S1.T1.30.30.30.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.30.30.30.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.31.31.31.8" class="ltx_td ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.31.31.31.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.31.31.31.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.31.31.31.4.m1.1a"><mi mathvariant="normal" id="S1.T1.31.31.31.4.m1.1.1" xref="S1.T1.31.31.31.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.31.31.31.4.m1.1b"><ci id="S1.T1.31.31.31.4.m1.1.1.cmml" xref="S1.T1.31.31.31.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.31.31.31.4.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S1.T1.35.35.35" class="ltx_tr">
<td id="S1.T1.35.35.35.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite></td>
<td id="S1.T1.32.32.32.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.32.32.32.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.32.32.32.1.m1.1a"><mi mathvariant="normal" id="S1.T1.32.32.32.1.m1.1.1" xref="S1.T1.32.32.32.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.32.32.32.1.m1.1b"><ci id="S1.T1.32.32.32.1.m1.1.1.cmml" xref="S1.T1.32.32.32.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.32.32.32.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.35.35.35.6" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.35.35.35.7" class="ltx_td ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.33.33.33.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.33.33.33.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.33.33.33.2.m1.1a"><mi mathvariant="normal" id="S1.T1.33.33.33.2.m1.1.1" xref="S1.T1.33.33.33.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.33.33.33.2.m1.1b"><ci id="S1.T1.33.33.33.2.m1.1.1.cmml" xref="S1.T1.33.33.33.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.33.33.33.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.34.34.34.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.34.34.34.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.34.34.34.3.m1.1a"><mi mathvariant="normal" id="S1.T1.34.34.34.3.m1.1.1" xref="S1.T1.34.34.34.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.34.34.34.3.m1.1b"><ci id="S1.T1.34.34.34.3.m1.1.1.cmml" xref="S1.T1.34.34.34.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.34.34.34.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.35.35.35.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.35.35.35.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.35.35.35.4.m1.1a"><mi mathvariant="normal" id="S1.T1.35.35.35.4.m1.1.1" xref="S1.T1.35.35.35.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.35.35.35.4.m1.1b"><ci id="S1.T1.35.35.35.4.m1.1.1.cmml" xref="S1.T1.35.35.35.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.35.35.35.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.35.35.35.8" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
</tr>
<tr id="S1.T1.39.39.39" class="ltx_tr">
<td id="S1.T1.39.39.39.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite></td>
<td id="S1.T1.36.36.36.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.36.36.36.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.36.36.36.1.m1.1a"><mi mathvariant="normal" id="S1.T1.36.36.36.1.m1.1.1" xref="S1.T1.36.36.36.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.36.36.36.1.m1.1b"><ci id="S1.T1.36.36.36.1.m1.1.1.cmml" xref="S1.T1.36.36.36.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.36.36.36.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.39.39.39.6" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.39.39.39.7" class="ltx_td ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.37.37.37.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.37.37.37.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.37.37.37.2.m1.1a"><mi mathvariant="normal" id="S1.T1.37.37.37.2.m1.1.1" xref="S1.T1.37.37.37.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.37.37.37.2.m1.1b"><ci id="S1.T1.37.37.37.2.m1.1.1.cmml" xref="S1.T1.37.37.37.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.37.37.37.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.38.38.38.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.38.38.38.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.38.38.38.3.m1.1a"><mi mathvariant="normal" id="S1.T1.38.38.38.3.m1.1.1" xref="S1.T1.38.38.38.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.38.38.38.3.m1.1b"><ci id="S1.T1.38.38.38.3.m1.1.1.cmml" xref="S1.T1.38.38.38.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.38.38.38.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.39.39.39.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.39.39.39.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.39.39.39.4.m1.1a"><mi mathvariant="normal" id="S1.T1.39.39.39.4.m1.1.1" xref="S1.T1.39.39.39.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.39.39.39.4.m1.1b"><ci id="S1.T1.39.39.39.4.m1.1.1.cmml" xref="S1.T1.39.39.39.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.39.39.39.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.39.39.39.8" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
</tr>
<tr id="S1.T1.44.44.44" class="ltx_tr">
<td id="S1.T1.44.44.44.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite></td>
<td id="S1.T1.40.40.40.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.40.40.40.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.40.40.40.1.m1.1a"><mi mathvariant="normal" id="S1.T1.40.40.40.1.m1.1.1" xref="S1.T1.40.40.40.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.40.40.40.1.m1.1b"><ci id="S1.T1.40.40.40.1.m1.1.1.cmml" xref="S1.T1.40.40.40.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.40.40.40.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.41.41.41.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.41.41.41.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.41.41.41.2.m1.1a"><mi mathvariant="normal" id="S1.T1.41.41.41.2.m1.1.1" xref="S1.T1.41.41.41.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.41.41.41.2.m1.1b"><ci id="S1.T1.41.41.41.2.m1.1.1.cmml" xref="S1.T1.41.41.41.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.41.41.41.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.44.44.44.7" class="ltx_td ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.42.42.42.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.42.42.42.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.42.42.42.3.m1.1a"><mi mathvariant="normal" id="S1.T1.42.42.42.3.m1.1.1" xref="S1.T1.42.42.42.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.42.42.42.3.m1.1b"><ci id="S1.T1.42.42.42.3.m1.1.1.cmml" xref="S1.T1.42.42.42.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.42.42.42.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.43.43.43.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.43.43.43.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.43.43.43.4.m1.1a"><mi mathvariant="normal" id="S1.T1.43.43.43.4.m1.1.1" xref="S1.T1.43.43.43.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.43.43.43.4.m1.1b"><ci id="S1.T1.43.43.43.4.m1.1.1.cmml" xref="S1.T1.43.43.43.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.43.43.43.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.44.44.44.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.44.44.44.5.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.44.44.44.5.m1.1a"><mi mathvariant="normal" id="S1.T1.44.44.44.5.m1.1.1" xref="S1.T1.44.44.44.5.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.44.44.44.5.m1.1b"><ci id="S1.T1.44.44.44.5.m1.1.1.cmml" xref="S1.T1.44.44.44.5.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.44.44.44.5.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.44.44.44.8" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
</tr>
<tr id="S1.T1.47.47.47" class="ltx_tr">
<td id="S1.T1.47.47.47.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite></td>
<td id="S1.T1.47.47.47.5" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.47.47.47.6" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.45.45.45.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.45.45.45.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.45.45.45.1.m1.1a"><mi mathvariant="normal" id="S1.T1.45.45.45.1.m1.1.1" xref="S1.T1.45.45.45.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.45.45.45.1.m1.1b"><ci id="S1.T1.45.45.45.1.m1.1.1.cmml" xref="S1.T1.45.45.45.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.45.45.45.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.46.46.46.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.46.46.46.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.46.46.46.2.m1.1a"><mi mathvariant="normal" id="S1.T1.46.46.46.2.m1.1.1" xref="S1.T1.46.46.46.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.46.46.46.2.m1.1b"><ci id="S1.T1.46.46.46.2.m1.1.1.cmml" xref="S1.T1.46.46.46.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.46.46.46.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.47.47.47.7" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="S1.T1.47.47.47.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.47.47.47.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.47.47.47.3.m1.1a"><mi mathvariant="normal" id="S1.T1.47.47.47.3.m1.1.1" xref="S1.T1.47.47.47.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.47.47.47.3.m1.1b"><ci id="S1.T1.47.47.47.3.m1.1.1.cmml" xref="S1.T1.47.47.47.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.47.47.47.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.47.47.47.8" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
</tr>
<tr id="S1.T1.54.54.54" class="ltx_tr">
<td id="S1.T1.54.54.54.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Ours</td>
<td id="S1.T1.48.48.48.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.48.48.48.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.48.48.48.1.m1.1a"><mi mathvariant="normal" id="S1.T1.48.48.48.1.m1.1.1" xref="S1.T1.48.48.48.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.48.48.48.1.m1.1b"><ci id="S1.T1.48.48.48.1.m1.1.1.cmml" xref="S1.T1.48.48.48.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.48.48.48.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.49.49.49.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.49.49.49.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.49.49.49.2.m1.1a"><mi mathvariant="normal" id="S1.T1.49.49.49.2.m1.1.1" xref="S1.T1.49.49.49.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.49.49.49.2.m1.1b"><ci id="S1.T1.49.49.49.2.m1.1.1.cmml" xref="S1.T1.49.49.49.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.49.49.49.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.50.50.50.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.50.50.50.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.50.50.50.3.m1.1a"><mi mathvariant="normal" id="S1.T1.50.50.50.3.m1.1.1" xref="S1.T1.50.50.50.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.50.50.50.3.m1.1b"><ci id="S1.T1.50.50.50.3.m1.1.1.cmml" xref="S1.T1.50.50.50.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.50.50.50.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.51.51.51.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.51.51.51.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.51.51.51.4.m1.1a"><mi mathvariant="normal" id="S1.T1.51.51.51.4.m1.1.1" xref="S1.T1.51.51.51.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.51.51.51.4.m1.1b"><ci id="S1.T1.51.51.51.4.m1.1.1.cmml" xref="S1.T1.51.51.51.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.51.51.51.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.52.52.52.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.52.52.52.5.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.52.52.52.5.m1.1a"><mi mathvariant="normal" id="S1.T1.52.52.52.5.m1.1.1" xref="S1.T1.52.52.52.5.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.52.52.52.5.m1.1b"><ci id="S1.T1.52.52.52.5.m1.1.1.cmml" xref="S1.T1.52.52.52.5.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.52.52.52.5.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.53.53.53.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.53.53.53.6.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.53.53.53.6.m1.1a"><mi mathvariant="normal" id="S1.T1.53.53.53.6.m1.1.1" xref="S1.T1.53.53.53.6.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.53.53.53.6.m1.1b"><ci id="S1.T1.53.53.53.6.m1.1.1.cmml" xref="S1.T1.53.53.53.6.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.53.53.53.6.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S1.T1.54.54.54.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S1.T1.54.54.54.7.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S1.T1.54.54.54.7.m1.1a"><mi mathvariant="normal" id="S1.T1.54.54.54.7.m1.1.1" xref="S1.T1.54.54.54.7.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S1.T1.54.54.54.7.m1.1b"><ci id="S1.T1.54.54.54.7.m1.1.1.cmml" xref="S1.T1.54.54.54.7.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.54.54.54.7.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span><span id="S1.SS2.1.1" class="ltx_text ltx_font_italic">Contributions</span>
</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p">In this paper, we present a new survey of what to share in FL, with an emphasis on the model utility, privacy leakage, and communication efficiency.
Compared with prior studies, this paper makes the following contributions:</p>
</div>
<div id="S1.SS2.p2" class="ltx_para">
<ul id="S1.I3" class="ltx_itemize">
<li id="S1.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i1.p1" class="ltx_para">
<p id="S1.I3.i1.p1.1" class="ltx_p">We introduce a new taxonomy that classifies FL methods, based on their shared information, into three categories: model sharing, synthetic data sharing, and knowledge sharing. By summarizing the current state-of-the-art FL methods into these three categories, we provide a comprehensive overview of what to share in FL.</p>
</div>
</li>
<li id="S1.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i2.p1" class="ltx_para">
<p id="S1.I3.i2.p1.1" class="ltx_p">We delve into an in-depth exploration of the potential privacy risks associated with FL, and analyze the vulnerability of different sharing methods to privacy attacks.
Moreover, we provide a thorough review of the defense methods that can mitigate these risks.</p>
</div>
</li>
<li id="S1.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i3.p1" class="ltx_para">
<p id="S1.I3.i3.p1.1" class="ltx_p">We conduct extensive experiments to compare the performance and communication overhead of various sharing methods in FL.
Furthermore, we assess the susceptibility of these methods to privacy breaches caused by model inversion and membership inference attacks, and evaluate the effectiveness of different defense methods in mitigating the attacks.</p>
</div>
</li>
<li id="S1.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i4.p1" class="ltx_para">
<p id="S1.I3.i4.p1.1" class="ltx_p">We provide a set of valuable insights and lessons learned from our literature review and empirical results.
These findings shed light on promising directions for enhancing the development of high-performance, privacy-preserving, and communication-efficient FL systems.</p>
</div>
</li>
</ul>
</div>
<div id="S1.SS2.p3" class="ltx_para">
<p id="S1.SS2.p3.1" class="ltx_p">The rest of the paper is organized as follows.
Section <a href="#S2" title="2 Preliminary ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> introduces the basic concepts of FL and privacy threats.
Section <a href="#S3" title="3 Sharing methods in FL ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and Section <a href="#S4" title="4 Privacy Attacks ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> present the taxonomies of sharing methods and privacy attacks in FL, respectively.
Section <a href="#S5" title="5 Defense against Privacy Attacks ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> reviews the defense methods against privacy attacks.
In Section <a href="#S6" title="6 Experiments ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we conduct experimental studies to compare the performance of representative methods.
Section <a href="#S7" title="7 Discussions and Future Works ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> discusses potential deficiencies in current methods and outlines several future directions for improvement.
Finally, Section <a href="#S8" title="8 Conclusions ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> concludes this survey.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Preliminary</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">To gain a comprehensive understanding of the concepts presented in this survey, it is essential to have a foundational knowledge of the principles of FL and the potential privacy risks it poses.
Therefore, this section will provide an overview of the fundamental concepts of FL and its associated privacy threats.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span><span id="S2.SS1.1.1" class="ltx_text ltx_font_italic">An Overview of Federated Learning</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">As depicted in Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, a typical FL framework consists of a central server and multiple distributed clients. Each client possesses a local model and a private dataset that comprises features and labels. For instance, in an image classification task, the features represent the raw image, while the label denotes the class. In this paper, we focus on the horizontal federated learning (HFL) framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, where all clients have the same feature and label spaces. However, the data distribution across clients may not be independent or identically distributed (non-IID), which poses significant challenges to model convergence.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">To overcome data heterogeneity, FL algorithms need to rely on information exchange among clients. The training process of FL can be divided into two main phases: the local training phase and the information sharing phase.
In the local training phase, the clients optimize their own local models based on the data available locally.
In the information sharing phase, under the coordination of the central server, the clients share privacy-preserving information among themselves to calibrate the local models and improve the FL convergence.
These two phases are repeated multiple times until the local models converge.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">The specific types of shared information used in the training process may differ depending on the FL method employed. For example, FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> involves clients uploading their local models to a central server, which aggregates the local models to form a global model that mitigates the local divergence caused by non-IID data.
The resulting global model is then sent back to the clients for the next round of training.
Another example is FedMD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, where the clients transmit the logits of proxy samples as knowledge to the server.
The server averages these logits and sends them back to the clients for knowledge distillation.
In addition, certain methods for computer vision tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> promote the sharing of synthetic samples among clients to alleviate the non-IID problem.
These synthetic samples are visually dissimilar from raw data to preserve privacy but retain the essential patterns for model training.</p>
</div>
<figure id="S2.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S2.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2307.10655/assets/x4.png" id="S2.F2.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="129" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S2.F2.sf1.3.2" class="ltx_text" style="font-size:80%;">Passive attack</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S2.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2307.10655/assets/x5.png" id="S2.F2.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="155" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S2.F2.sf2.3.2" class="ltx_text" style="font-size:80%;">Active attack</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Two types of privacy attacks in FL: (a) passive attack and (b) active attack.</figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span><span id="S2.SS2.1.1" class="ltx_text ltx_font_italic">Privacy Threat Model</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Deep learning models are vulnerable to privacy breaches since they can unintentionally memorize specific details about the training data.
The privacy attackers can construct the private samples <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> or infer the properties of dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> by accessing the model parameters or querying the black-box models.
FL, as a type of deep learning approach, faces equal or even higher privacy risks since sharing local information during the training process could inadvertently reveal more sensitive data.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Fig. <a href="#S2.F2" title="Figure 2 ‣ 2.1 An Overview of Federated Learning ‣ 2 Preliminary ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates two typical privacy attacks in FL: passive and active attacks, which are categorized based on the actions taken by the attacker.
In a passive attack, the clients and the server participating in FL are semi-honest.
They follow the FL protocols without compromising performance but try to infer private information about local datasets from the information exchanged during the training process.
If an attacker takes control of a client, it can leverage the access to execute privacy attacks by exploiting the information provided by the server.
Additionally, if the server is the attacker, it can exploit the individual information sent by the clients to perform more severe privacy breaches.
In contrast, in an active attack, the attackers are malicious participants who intentionally deviate from the FL protocols by altering messages.
This enables them to deceive clients into releasing more private information on local data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>.
Fortunately, numerous studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> have developed defense mechanisms to identify such attackers by monitoring the shared information.
Our work primarily focuses on passive attacks in FL.
We recommend readers interested in active attacks to refer to the surveys <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> for a more comprehensive summary.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Sharing methods in FL</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">By sharing privacy-preserving information among clients, FL enables collaborative model training on decentralized data while preserving user privacy.
However, the effectiveness of FL depends heavily on the sharing methods employed.
To facilitate a more thorough evaluation of existing FL approaches, we propose a new taxonomy based on the sharing methods.
In this section, we will provide a comprehensive overview of three types of sharing methods: model sharing, synthetic data sharing, and knowledge sharing.
Table <a href="#S3.T2" title="TABLE II ‣ 3 Sharing methods in FL ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> summarizes the taxonomy of sharing methods in FL.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Taxonomy of sharing methods in federated learning</figcaption>
<div id="S3.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:429.3pt;height:151.9pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-137.8pt,48.6pt) scale(0.609020822159227,0.609020822159227) ;">
<table id="S3.T2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.1.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding-left:0.2pt;padding-right:0.2pt;">Ref.</th>
<th id="S3.T2.1.1.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:0.2pt;padding-right:0.2pt;">
<table id="S3.T2.1.1.1.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T2.1.1.1.1.2.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1.1.2.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">Model</td>
</tr>
<tr id="S3.T2.1.1.1.1.2.1.2" class="ltx_tr">
<td id="S3.T2.1.1.1.1.2.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">sharing</td>
</tr>
</table>
</th>
<th id="S3.T2.1.1.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:0.2pt;padding-right:0.2pt;">
<table id="S3.T2.1.1.1.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T2.1.1.1.1.3.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1.1.3.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">Data</td>
</tr>
<tr id="S3.T2.1.1.1.1.3.1.2" class="ltx_tr">
<td id="S3.T2.1.1.1.1.3.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">sharing</td>
</tr>
</table>
</th>
<th id="S3.T2.1.1.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:0.2pt;padding-right:0.2pt;">
<table id="S3.T2.1.1.1.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T2.1.1.1.1.4.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1.1.4.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">Knowledge</td>
</tr>
<tr id="S3.T2.1.1.1.1.4.1.2" class="ltx_tr">
<td id="S3.T2.1.1.1.1.4.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">sharing</td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.1.1.2.1" class="ltx_tr">
<th id="S3.T2.1.1.2.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:0.2pt;padding-right:0.2pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>, <a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite></th>
<td id="S3.T2.1.1.2.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.2pt;padding-right:0.2pt;">Full model</td>
<td id="S3.T2.1.1.2.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
<td id="S3.T2.1.1.2.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
</tr>
<tr id="S3.T2.1.1.3.2" class="ltx_tr">
<th id="S3.T2.1.1.3.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:0.2pt;padding-right:0.2pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite></th>
<td id="S3.T2.1.1.3.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">Quantized model</td>
<td id="S3.T2.1.1.3.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
<td id="S3.T2.1.1.3.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
</tr>
<tr id="S3.T2.1.1.4.3" class="ltx_tr">
<th id="S3.T2.1.1.4.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:0.2pt;padding-right:0.2pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite></th>
<td id="S3.T2.1.1.4.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">Sparsified model</td>
<td id="S3.T2.1.1.4.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
<td id="S3.T2.1.1.4.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
</tr>
<tr id="S3.T2.1.1.5.4" class="ltx_tr">
<th id="S3.T2.1.1.5.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:0.2pt;padding-right:0.2pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>, <a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite></th>
<td id="S3.T2.1.1.5.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
<td id="S3.T2.1.1.5.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">Synthetic samples</td>
<td id="S3.T2.1.1.5.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
</tr>
<tr id="S3.T2.1.1.6.5" class="ltx_tr">
<th id="S3.T2.1.1.6.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:0.2pt;padding-right:0.2pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite></th>
<td id="S3.T2.1.1.6.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">Full model</td>
<td id="S3.T2.1.1.6.5.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">Synthetic samples</td>
<td id="S3.T2.1.1.6.5.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
</tr>
<tr id="S3.T2.1.1.7.6" class="ltx_tr">
<th id="S3.T2.1.1.7.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:0.2pt;padding-right:0.2pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>, <a href="#bib.bib70" title="" class="ltx_ref">70</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite></th>
<td id="S3.T2.1.1.7.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">Full model</td>
<td id="S3.T2.1.1.7.6.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">Coded samples</td>
<td id="S3.T2.1.1.7.6.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
</tr>
<tr id="S3.T2.1.1.8.7" class="ltx_tr">
<th id="S3.T2.1.1.8.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:0.2pt;padding-right:0.2pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>, <a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite></th>
<td id="S3.T2.1.1.8.7.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">Full model</td>
<td id="S3.T2.1.1.8.7.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">Raw samples</td>
<td id="S3.T2.1.1.8.7.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
</tr>
<tr id="S3.T2.1.1.9.8" class="ltx_tr">
<th id="S3.T2.1.1.9.8.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:0.2pt;padding-right:0.2pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite></th>
<td id="S3.T2.1.1.9.8.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
<td id="S3.T2.1.1.9.8.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
<td id="S3.T2.1.1.9.8.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">Statistics</td>
</tr>
<tr id="S3.T2.1.1.10.9" class="ltx_tr">
<th id="S3.T2.1.1.10.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:0.2pt;padding-right:0.2pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib76" title="" class="ltx_ref">76</a>, <a href="#bib.bib77" title="" class="ltx_ref">77</a>, <a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite></th>
<td id="S3.T2.1.1.10.9.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
<td id="S3.T2.1.1.10.9.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
<td id="S3.T2.1.1.10.9.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">Predictions</td>
</tr>
<tr id="S3.T2.1.1.11.10" class="ltx_tr">
<th id="S3.T2.1.1.11.10.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:0.2pt;padding-right:0.2pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>, <a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite></th>
<td id="S3.T2.1.1.11.10.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
<td id="S3.T2.1.1.11.10.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
<td id="S3.T2.1.1.11.10.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.2pt;padding-right:0.2pt;">Predictions &amp; features</td>
</tr>
<tr id="S3.T2.1.1.12.11" class="ltx_tr">
<th id="S3.T2.1.1.12.11.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r" style="padding-left:0.2pt;padding-right:0.2pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>, <a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite></th>
<td id="S3.T2.1.1.12.11.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:0.2pt;padding-right:0.2pt;">Full model</td>
<td id="S3.T2.1.1.12.11.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:0.2pt;padding-right:0.2pt;">–</td>
<td id="S3.T2.1.1.12.11.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:0.2pt;padding-right:0.2pt;">Statistics</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span><span id="S3.SS1.1.1" class="ltx_text ltx_font_italic">Model Sharing</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Model sharing is the most widely used method in FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
During the training process, participating clients train a local model using their private data and send the resulting model updates or parameters to the server for aggregation.
The aggregated model, referred to as the global model, is then sent back to the clients as the starting point for their next round of local model training.
This iterative process is repeated multiple rounds until the models converge.
However, deep learning models usually consist of a large number of parameters, and the frequent transmission of these models between clients and the server results in significant latency.
Moreover, the data and system heterogeneity in FL can cause the global model to converge slowly or even diverge, leading to an increase in communication rounds.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">To reduce the communication overhead, many research works have focused on improving the training efficiency. Early FL research introduced a regularization term to the local training loss, with the goal of mitigating model divergence issues that arise from data heterogeneity and improving the convergence rate <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib83" title="" class="ltx_ref">83</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>, <a href="#bib.bib84" title="" class="ltx_ref">84</a>, <a href="#bib.bib85" title="" class="ltx_ref">85</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>.
For instance, FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> adopts an <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi mathvariant="normal" id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">ℓ</mi><mn id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">ℓ</ci><cn type="integer" id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\ell_{2}</annotation></semantics></math> regularization term to penalize local models that are far away from the global model.
SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite> introduces a control variate to correct drifts in local training.
FedDyn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> employs a novel dynamic regularization method for FL, where the local loss is dynamically updated to ensure the asymptotic consistency of client optima with stationary points of the global empirical loss.
Another line of studies improved the performance of the global model via aggregation optimization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>, <a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>.
The standard aggregation method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> averages the local models based on weight coordinates.
However, the weight permutation invariance principle <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>, <a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite> points out that this coordinate-based aggregation is suboptimal, as the neurons in some layers may be mismatched.
To address this issue, Yurochkin et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite> developed probabilistic federated neural matching (PFNM) based on the posterior of a Beta-Bernoulli process (BBP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite> to match the weights among local models.
Nonetheless, PFNM is only effective on simple architectures like fully-connected layers.
To achieve the weight alignment goal, Wang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> proposed FedMA, which searches for the best permutation matrices using the Hungarian matching algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite>.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">Besides improving the training efficiency, model compression methods have been shown to be effective in reducing the communication overhead.
In particular, these methods can minimize the model size for each round, thereby reducing the amount of data transmitted among clients.
For instance, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> employed a stochastic quantization method, namely QSGD, to quantize local updates for more efficient transmission.
Jhunjhunwala et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> proposed an adaptive quantization algorithm called AdaQuantFL to dynamically adjust the quantization level during the training process, effectively reducing both communication costs and quantization distortion.
Apart from quantization, sparsification methods have also been widely used for model compression in FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>. These methods transform a full gradient into a sparse one by selecting a subset of important elements and setting other insignificant coordinates to zero.
One popular sparsification technique is top-k sparsification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>, which removes a significant portion of gradients without affecting model convergence.
In addition, Han et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> proposed an adaptive sparsification method, which determines the degree of sparsity automatically based on the model performance.
Furthermore, Hu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> integrated random sparsification with gradient perturbation on each client to amplify the privacy guarantee while improving communication efficiency.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">Although model sharing methods retain private datasets locally, the shared model parameters and updates may implicitly contain private information.
This poses a potential risk for privacy breaches and information leakage if attackers gain access to either the clients’ local model or the aggregated model.
A detailed discussion on privacy attacks will be provided in Section <a href="#S4" title="4 Privacy Attacks ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span><span id="S3.SS2.1.1" class="ltx_text ltx_font_italic">Synthetic Data Sharing</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Besides the model sharing methods, sharing a portion of raw data is another intuitive yet effective approach to tackle the data heterogeneity among clients and improve the federated utility.
In this research line, Yoshida et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite> proposed a hybrid learning framework that assumes a small portion of clients is willing to share their raw data with others, while Tian et al.
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite> developed a pre-shared data training strategy to collect local data from a random set of clients.
Empirical results from these studies demonstrated that sharing limited raw data can significantly improve overall performance.
However, it is important to note that directly sharing raw data in FL poses a serious threat to privacy.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">To tackle the privacy concerns, a variety of methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>, <a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> generated synthetic data by processing the private datasets and shared them to mitigate the data heterogeneity issue.
Specifically, Mix2FLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>, which builds upon the Mixup technique <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>, allows clients to share mixup samples with the server and adopts an inverse engineer to generate inversely-mixup samples for federated distillation. This approach involves generating mixup samples by linearly combining multiple raw samples into one sample, which effectively masks details from each individual raw sample.
Similarly, Shin et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> developed an XOR-based mixup data augmentation technique to produce synthetic-but-realistic samples.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">In addition to processing raw data, various deep-learning-based methods have been developed for data generation in FL, such as dataset distillation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite> and dataset condensation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>. The key idea behind these methods is to synthesize a small yet informative set of samples by learning from the large raw dataset, allowing models trained on the synthetic data to achieve comparable performance to those trained on the raw data. By generating a small synthetic dataset locally with these methods, each client in FL can share it with the server in one shot <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>, <a href="#bib.bib94" title="" class="ltx_ref">94</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> to significantly reduce the communication costs. This approach can be further extended to iteratively optimize the local synthetic datasets using the updated global model and share them with the server <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>. The iterative optimization process allows the synthetic datasets to be continuously refined, resulting in improved model performance.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">Recently, many works combined the model sharing and data sharing methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib96" title="" class="ltx_ref">96</a>, <a href="#bib.bib97" title="" class="ltx_ref">97</a>, <a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite> to further enhance the FL performance.
For instance, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> proposed a mean augmented federated learning (MAFL) framework that shares model updates and averaged local data to approximate the loss function of global mixup.
Moreover, FedDPGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite> and FedGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite> allow clients to collaboratively train a global generator in a federated framework, where the local datasets can be supplemented with synthetic data to improve model training.
SDA-FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>, on the other hand, allows each client to individually train a generator, which provides synthetic data for all the clients and mitigates the data heterogeneity among clients during the subsequent FL training.
Alternatively, VHL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite> conducts FL with a virtual homogeneous dataset to calibrate the features from the heterogeneous clients, which can be generated from pure noise shared across clients without any private information.
In addition, some works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>, <a href="#bib.bib70" title="" class="ltx_ref">70</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite> employed cryptographic primitives to encrypt private samples.
For example, the code dataset can be distributed among clients or sent to the server for improving the training efficiency.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span><span id="S3.SS3.1.1" class="ltx_text ltx_font_italic">Knowledge Sharing</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In addition to model sharing and synthetic data sharing methods, knowledge distillation (KD) is an effective technique that enables the transfer of knowledge among models.
Federated distillation (FD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite> is an extension of KD that is tailored to the FL framework.
Typical knowledge exchanged among clients include statistics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, model outputs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>, and intermediate features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>, <a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">The studies in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> introduced a pioneering method named FKD, where the clients periodically transmit the average logits for each label in their respective private datasets to the server.
The server then aggregates these logits to produce global logits, which are sent back to the clients to calibrate the local training.
Although FKD offers remarkable communication efficiency compared with traditional model sharing methods, it can result in significant performance drops.
To tackle this issue, Wang et al. proposed a predicted logits selection (PLS) algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite> that updates the per-label global logits by scheduling appropriate local predicted logits, thereby reducing the impact of misleading logits on the convergence of local models.
However, the performance of PLS deteriorates significantly when the data distributions across clients are highly heterogeneous.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">Mainstream knowledge sharing methods typically rely on a proxy dataset to facilitate the knowledge transfer among clients.
Specifically, clients compute the local logits on the proxy samples, and the server aggregates them to produce the global logits for local distillation.
For example, FedMD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> adopts a labeled proxy dataset to perform initial pertaining and knowledge distillation.
The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite> proposed an entropy reduction aggregation (ERA) scheme to modify the aggregation step.
The empirical evidence showed that using a small temperature coefficient when applying softmax to the aggregated logits reduces the entropy of global logits and improves convergence.
Moreover, the Cronus method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite> aggregates the logits at the server following the robust mean estimation algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite> to enhance robustness.
To further reduce the communication overhead, compressed federated distillation (CFD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite> develops a quantization mechanism and a delta coding method to compress the logits.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.1" class="ltx_p">Besides sharing logits, some methods select features for knowledge sharing.
For instance, the FedAD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite> method employs class-specific attention maps to capture the knowledge of local models. The diversity of attention maps across local clients is then exploited to calibrate local models for seeking a consensus among them.
Moreover, FedGKT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite> reformulates FL as a group knowledge transfer training algorithm.
Specifically, the server adopts the intermediate feature maps of clients, along with the corresponding logits, to train a global model.
The discrepancy between the local and global logits is incorporated as a regularization term within the local loss function to facilitate consistency.</p>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<p id="S3.SS3.p5.1" class="ltx_p">Moreover, there are some methods that combine knowledge sharing and model sharing to enhance FL performance.
One such approach is FedFTG <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>, which leverages knowledge distillation to refine the global model on the server side. In this method, the server trains a generator model by incorporating information from the local label distribution and the local models.
Another approach is FedGen <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>, which learns a lightweight server-side generator, based on the local label counters and parameters, to ensemble client information in a data-free manner.
This generator is then broadcasted to clients and regulates local training by providing learned knowledge as an inductive bias.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Privacy Attacks</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">While FL is viewed as a privacy-preserving distributed learning paradigm by keeping private data locally, the shared information actually exposes a broad attack surface.
For instance, the private data can be reconstructed from the shared model by observing its input-output pairs.
Besides, the shared synthetic data can be utilized for membership inference attacks based on density estimation, which determines whether a specific real sample is used for training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>.
For knowledge sharing methods, the model distillation process can inadvertently compromise privacy by leaking information about the mapping between samples and predictions, which allows attackers to infer data membership.
In this section, we discuss two types of attacks in FL that differ in their objectives: the first type aims to reconstruct private data  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>, <a href="#bib.bib102" title="" class="ltx_ref">102</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite>, while the second one focuses on inferring unexpected features of the private dataset  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>, <a href="#bib.bib105" title="" class="ltx_ref">105</a>, <a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite>.
Table <a href="#S4.T3" title="TABLE III ‣ 4 Privacy Attacks ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> provides a summary of the taxonomy of privacy attacks.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Taxonomy of privacy attacks.</figcaption>
<table id="S4.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">Ref.</th>
<th id="S4.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Attack by using</th>
<th id="S4.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Type</th>
<th id="S4.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Target</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.2.1" class="ltx_tr">
<th id="S4.T3.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>, <a href="#bib.bib102" title="" class="ltx_ref">102</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite></th>
<td id="S4.T3.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Gradients</td>
<td id="S4.T3.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Gradient inversion attack</td>
<td id="S4.T3.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T3.1.2.1.4.1" class="ltx_text">
<span id="S4.T3.1.2.1.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.1.2.1.4.1.1.1" class="ltx_tr">
<span id="S4.T3.1.2.1.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Recover the private</span></span>
<span id="S4.T3.1.2.1.4.1.1.2" class="ltx_tr">
<span id="S4.T3.1.2.1.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">training data.</span></span>
</span></span></td>
</tr>
<tr id="S4.T3.1.3.2" class="ltx_tr">
<th id="S4.T3.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>, <a href="#bib.bib108" title="" class="ltx_ref">108</a>, <a href="#bib.bib109" title="" class="ltx_ref">109</a>, <a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite></th>
<td id="S4.T3.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Model parameters</td>
<td id="S4.T3.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T3.1.3.2.3.1" class="ltx_text">Model inversion attack</span></td>
</tr>
<tr id="S4.T3.1.4.3" class="ltx_tr">
<th id="S4.T3.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>, <a href="#bib.bib112" title="" class="ltx_ref">112</a>, <a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite></th>
<td id="S4.T3.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Model outputs</td>
</tr>
<tr id="S4.T3.1.5.4" class="ltx_tr">
<th id="S4.T3.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>, <a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite></th>
<td id="S4.T3.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Model parameters</td>
<td id="S4.T3.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T3.1.5.4.3.1" class="ltx_text">Membership inference attack</span></td>
<td id="S4.T3.1.5.4.4" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T3.1.5.4.4.1" class="ltx_text">
<span id="S4.T3.1.5.4.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.1.5.4.4.1.1.1" class="ltx_tr">
<span id="S4.T3.1.5.4.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Determine whether a data sample</span></span>
<span id="S4.T3.1.5.4.4.1.1.2" class="ltx_tr">
<span id="S4.T3.1.5.4.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">was used in the training or not.</span></span>
</span></span></td>
</tr>
<tr id="S4.T3.1.6.5" class="ltx_tr">
<th id="S4.T3.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>, <a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite></th>
<td id="S4.T3.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Model outputs</td>
</tr>
<tr id="S4.T3.1.7.6" class="ltx_tr">
<th id="S4.T3.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>, <a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite></th>
<td id="S4.T3.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Model parameters</td>
<td id="S4.T3.1.7.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T3.1.7.6.3.1" class="ltx_text">Property inference attack</span></td>
<td id="S4.T3.1.7.6.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" rowspan="2"><span id="S4.T3.1.7.6.4.1" class="ltx_text">
<span id="S4.T3.1.7.6.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.1.7.6.4.1.1.1" class="ltx_tr">
<span id="S4.T3.1.7.6.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Infer sensitive information</span></span>
<span id="S4.T3.1.7.6.4.1.1.2" class="ltx_tr">
<span id="S4.T3.1.7.6.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">of the training set.</span></span>
</span></span></td>
</tr>
<tr id="S4.T3.1.8.7" class="ltx_tr">
<th id="S4.T3.1.8.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite></th>
<td id="S4.T3.1.8.7.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Model outputs</td>
</tr>
</tbody>
</table>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span><span id="S4.SS1.1.1" class="ltx_text ltx_font_italic">Reconstruct Private Data</span>
</h3>

<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Gradient Inversion Attack</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">Gradient inversion attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>, <a href="#bib.bib102" title="" class="ltx_ref">102</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite> attempt to reconstruct the original training data from updated gradients.
For instance, deep leakage from gradients (DLG) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite> is the first algorithm to exploit the private information contained in the gradients.
Specifically, DLG first randomly generates a pair of dummy inputs and labels and calculates the resulting dummy gradients through forward and backward operations.
The algorithm then optimizes the dummy inputs and labels to minimize the distance between dummy gradients and target gradients.
Later, Zhao et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite> further improved DLG by incorporating the signs of gradients to reveal the ground-truth labels.
Yin et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite> proposed GradInversion to reconstruct more realistic images by introducing batch label restoration.
Moreover, Deng et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite> developed the first gradient leakage mechanism, namely TAG, to attack Transformer-based models.
LAMP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>]</cite> is a novel attack tailored to textual data, which combines cosine similarity and embedding regularization terms with the gradient matching loss.
Furthermore, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite> illustrated
the feasibility of recovering multiple sentences from gradients based on beam search and token reordering policies.</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>Model Inversion Attack</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">Model inversion attacks are designed to reconstruct private data when given access to a deep learning model.
Early research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> first pointed out that linear models are vulnerable to these attacks.
Subsequently, Fredrikson et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> applied the Maximum a Posterior (MAP) principle to model the inversion process as an optimization problem, with the objective of reconstructing the most likely examples corresponding to a specific target label.
In addition, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite> proposed a novel GAB-based attack technique called the generative model-inversion (GMI) attack.
Unlike other techniques, the GMI attack utilizes a public dataset to learn a distributional prior for guiding the inversion process, instead of reconstructing private data from scratch.
In certain scenarios, attackers may not have access to the model parameters, but they can still obtain private information by querying the target model.
To address this issue, Yang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite> trained an inversion model solely based on the black-box accesses to the target model.
To train this inversion model, they assumed the existence of a public dataset and leveraged it as background knowledge.
In addition, they designed a truncation-based technique to align the generator to inverse the target model.
A more recent work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite> introduced the IDEAL framework, which aims to enable efficient learning from black-box model APIs through iterative performance data generation and knowledge distillation. After the training process, the generator is capable of producing samples that closely resemble the training data of the target model.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span><span id="S4.SS2.1.1" class="ltx_text ltx_font_italic">Infer Features of Private Datasets</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Besides reconstructing data from the deep learning models, the shared information could reveal unexpected features of the private datasets.
In recent years, many studies have explored the potential for membership inference attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib115" title="" class="ltx_ref">115</a>, <a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite> and property inference attacks
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>, <a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite> to exploit these vulnerabilities.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Membership Inference Attack</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">Deep learning models are susceptible to memorizing and overfitting the training dataset, leading to different behavior on the training data (members) and test data (non-members).
This vulnerability enables the attacker to determine the membership status of a data record.
Previous research mainly focused on the black-box setting, where attackers can only access the output of deep learning models for a given input sample.
Two major types of attacks are metric-based <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>, <a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite> and classifier-based approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>, <a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>.
Metric-based methods determine membership status by calculating a specific metric on the output of the target model.
Potential metrics include accuracy, prediction loss, confidence scores, and output entropy.
The attacker infers the membership based on whether the calculated result exceeds or falls below the pre-defined threshold.
Classifier-based methods involve training a binary classifier to distinguish the behavior of a deep neural network on its training members from non-members.
The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite> trained such a classifier in a supervised manner, assuming the availability of a dataset with ground-truth labels of both member and non-member data.
However, in most cases, an attacker may not have access to the private training dataset.
Therefore, many studies have resorted to unsupervised learning to tackle this challenge.
The first unsupervised membership inference attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite> created multiple shadow models to mimic the behavior of the target model.
The attacker gains access to the training and test datasets of these shadow models, enabling them to create a new dataset containing features and ground truth of membership.
This dataset can then be utilized to train a membership classifier.
Recently, with the development of FL, many studies are paying more attention to inferring privacy by exploiting white-box models at different training epochs.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>, the author analyzed the model’s idiosyncratic use of features for white-box membership inference.
Similarly, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib126" title="" class="ltx_ref">126</a>]</cite> proposed a passive membership inference attack based on the predictions of local models at different epochs.
In addition to analyzing features and predictions, Melis et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite> identified membership leakage by exploiting gradients.
When using FL for training a word embedding function, a deterministic function is used to map each word to a high-dimensional vector.
By calculating the gradients of a training batch, words with non-zero gradients are used in the training process.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Property Inference Attack</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">The objective of a property inference attack (PIA) is to infer sensitive global properties of the training dataset that may not be relevant to the target tasks, such as the data’s production environment and the proportion of data from a particular class.
The first work was formulated by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite>, which involoved training a meta-classifier to determine if a model possesses a particular property.
The attacker generates a set of shadow models that are trained on the same task using datasets with or without the target property.
The parameters of these shadow models are then used to train the meta-classifier.
This approach has been proven effective for classifiers such as hidden Markov models and support vector machine models.
Later, Ganju et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite> extended the PIA to fully-connected neural networks.
They arranged the neural networks into a canonical form and represented each neural network layer as a set, reducing the complexity of the meta-classifier.
Concurrently, Melis et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite> proposed a binary batch property classifier that leverages the snapshots of the global model to generate aggregated updates based on the data with and without a specific property.
Later, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite> proposed three new types of attacks to exploit valuable information contained in the training data.
These attacks include Class Sniffing, Quantity Inference, and Whole Determination, which can infer label quantity composition proportion of a single training round or the entire training process.
The attacker downloads the aggregated model and optimizes it by using data with different labels.
By analyzing gradients, the attacker can estimate the quantity proportion of different classes.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref">127</a>]</cite>, the attacker trains a CycleGAN during collaborative learning to generate a gradient for subject-level privacy inference.
In addition, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite> studied the PIA attacks when only black-box access to the model is available to the attacker.
They found that a few hundred queries to the black-box model are sufficient to infer population-level properties in datasets.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Defense against Privacy Attacks</span>
</h2>

<figure id="S5.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2307.10655/assets/x6.png" id="S5.F3.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="346" height="251" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S5.F3.sf1.3.2" class="ltx_text" style="font-size:80%;">Cryptography-based technique</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2307.10655/assets/x7.png" id="S5.F3.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="345" height="154" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S5.F3.sf2.3.2" class="ltx_text" style="font-size:80%;">Perturbation method</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Defense methods against privacy attacks in FL: (a) cryptography-based technique and (b) perturbation method.</figcaption>
</figure>
<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">As discussed in the previous section, the information exchanged during FL has the potential to compromise the privacy of local datasets.
This highlights the crucial need to develop client-side defenses to provide a stronger privacy guarantee.
In this section, we discuss two main defense approaches: cryptography-based techniques and perturbation methods, as depicted in Fig. <a href="#S5.F3" title="Figure 3 ‣ 5 Defense against Privacy Attacks ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
A summary of these defense methods is available in Table <a href="#S5.T4" title="TABLE IV ‣ 5.1 Cryptography-based Techniques ‣ 5 Defense against Privacy Attacks ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span><span id="S5.SS1.1.1" class="ltx_text ltx_font_italic">Cryptography-based Techniques</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Cryptography-based techniques allow users to encrypt data and perform algebraic operations on the ciphertext.
Homomorphic encryption (HE) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib128" title="" class="ltx_ref">128</a>]</cite> is a key component of cryptography-based techniques, as it provides cryptographic primitives that allow computations on encrypted data without the need for decryption.
The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref">129</a>]</cite> implemented HE to solve binary classification problems by utilizing polynomials for approximating the objective functions.
Building upon this concept, the studies in<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib130" title="" class="ltx_ref">130</a>, <a href="#bib.bib131" title="" class="ltx_ref">131</a>]</cite> proposed approximate HE schemes to perform logistic regression on homomorphic encrypted data.
Later, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>, <a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite> trained neural networks on encrypted data, while the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib134" title="" class="ltx_ref">134</a>, <a href="#bib.bib135" title="" class="ltx_ref">135</a>]</cite> performed distillation based on the encrypted samples.
In addition, the studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib136" title="" class="ltx_ref">136</a>, <a href="#bib.bib137" title="" class="ltx_ref">137</a>]</cite> adopted HE techniques to encrypt the local model updates for secure aggregation in FL.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">Secret sharing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>, <a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite> is a subfield of cryptography that enables multiple parties to collaboratively compute a function over their inputs while keeping the inputs private.
This technique is widely used in federated aggregation, and the primary goal is to protect the privacy of individual clients’ data while allowing model updates to be shared and aggregated.
In this approach, the server only receives the aggregation of the clients’ information, while the masks have an additive structure that allows them to be removed when aggregated at the central server.
The first secure aggregation work to average uploaded models from multiple clients was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite>.
The key idea is to adopt pairwise masks to conceal the raw data, and the masks have an additive structure that allows their cancellation when added in aggregation.
Later, Bonawitz et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib141" title="" class="ltx_ref">141</a>]</cite> proposed an aggressive quantization approach to develop a communication-efficient secure aggregation scheme.
The studies in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib142" title="" class="ltx_ref">142</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> employed the Lagrange coding for secret sharing in FL.
Jahani et al. proposed two novel secure aggregation protocols, namely SwiftAgg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib143" title="" class="ltx_ref">143</a>]</cite> and SwiftAgg+ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib144" title="" class="ltx_ref">144</a>]</cite>, to reduce the communication overhead and enhance the robustness against straggling clients.
Moreover, Liu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib145" title="" class="ltx_ref">145</a>]</cite> combined homomorphic encryption and secret sharing to enable secure federated transfer learning.
A similar approach has been used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>, <a href="#bib.bib147" title="" class="ltx_ref">147</a>]</cite> for aggregating the knowledge uploaded by clients.</p>
</div>
<figure id="S5.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>Taxonomy of defense approaches for different sharing methods. HE, SS, and DP represent homomorphic encryption, secret sharing, and differential privacy, respectively.</figcaption>
<div id="S5.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:25.7pt;vertical-align:-0.2pt;"><span class="ltx_transformed_inner" style="transform:translate(-705.9pt,41.5pt) scale(0.234963686888265,0.234963686888265) ;">
<table id="S5.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T4.1.1.1.1" class="ltx_tr">
<th id="S5.T4.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="2"><span id="S5.T4.1.1.1.1.1.1" class="ltx_text">
<span id="S5.T4.1.1.1.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T4.1.1.1.1.1.1.1.1" class="ltx_tr">
<span id="S5.T4.1.1.1.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">What to</span></span>
<span id="S5.T4.1.1.1.1.1.1.1.2" class="ltx_tr">
<span id="S5.T4.1.1.1.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">share</span></span>
</span></span></th>
<td id="S5.T4.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="2">Cryptography</td>
<td id="S5.T4.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="2">Perturbation</td>
</tr>
<tr id="S5.T4.1.1.2.2" class="ltx_tr">
<td id="S5.T4.1.1.2.2.1" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">HE</td>
<td id="S5.T4.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">SS</td>
<td id="S5.T4.1.1.2.2.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">DP</td>
<td id="S5.T4.1.1.2.2.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Others</td>
</tr>
<tr id="S5.T4.1.1.3.3" class="ltx_tr">
<th id="S5.T4.1.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Model</th>
<td id="S5.T4.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib136" title="" class="ltx_ref">136</a>, <a href="#bib.bib137" title="" class="ltx_ref">137</a>, <a href="#bib.bib145" title="" class="ltx_ref">145</a>]</cite></td>
<td id="S5.T4.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib140" title="" class="ltx_ref">140</a>, <a href="#bib.bib141" title="" class="ltx_ref">141</a>, <a href="#bib.bib142" title="" class="ltx_ref">142</a>, <a href="#bib.bib143" title="" class="ltx_ref">143</a>, <a href="#bib.bib144" title="" class="ltx_ref">144</a>]</cite></td>
<td id="S5.T4.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>, <a href="#bib.bib149" title="" class="ltx_ref">149</a>, <a href="#bib.bib150" title="" class="ltx_ref">150</a>, <a href="#bib.bib151" title="" class="ltx_ref">151</a>, <a href="#bib.bib152" title="" class="ltx_ref">152</a>, <a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite></td>
<td id="S5.T4.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>, <a href="#bib.bib154" title="" class="ltx_ref">154</a>, <a href="#bib.bib155" title="" class="ltx_ref">155</a>, <a href="#bib.bib156" title="" class="ltx_ref">156</a>, <a href="#bib.bib157" title="" class="ltx_ref">157</a>, <a href="#bib.bib158" title="" class="ltx_ref">158</a>]</cite></td>
</tr>
<tr id="S5.T4.1.1.4.4" class="ltx_tr">
<th id="S5.T4.1.1.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">Data</th>
<td id="S5.T4.1.1.4.4.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref">129</a>, <a href="#bib.bib130" title="" class="ltx_ref">130</a>, <a href="#bib.bib131" title="" class="ltx_ref">131</a>, <a href="#bib.bib132" title="" class="ltx_ref">132</a>, <a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite></td>
<td id="S5.T4.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite></td>
<td id="S5.T4.1.1.4.4.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>, <a href="#bib.bib97" title="" class="ltx_ref">97</a>, <a href="#bib.bib96" title="" class="ltx_ref">96</a>, <a href="#bib.bib70" title="" class="ltx_ref">70</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite></td>
<td id="S5.T4.1.1.4.4.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib159" title="" class="ltx_ref">159</a>]</cite></td>
</tr>
<tr id="S5.T4.1.1.5.5" class="ltx_tr">
<th id="S5.T4.1.1.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">Knowl.</th>
<td id="S5.T4.1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib134" title="" class="ltx_ref">134</a>, <a href="#bib.bib135" title="" class="ltx_ref">135</a>]</cite></td>
<td id="S5.T4.1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>, <a href="#bib.bib147" title="" class="ltx_ref">147</a>]</cite></td>
<td id="S5.T4.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib160" title="" class="ltx_ref">160</a>, <a href="#bib.bib161" title="" class="ltx_ref">161</a>, <a href="#bib.bib162" title="" class="ltx_ref">162</a>, <a href="#bib.bib163" title="" class="ltx_ref">163</a>, <a href="#bib.bib164" title="" class="ltx_ref">164</a>]</cite></td>
<td id="S5.T4.1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib165" title="" class="ltx_ref">165</a>, <a href="#bib.bib166" title="" class="ltx_ref">166</a>]</cite></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span><span id="S5.SS2.1.1" class="ltx_text ltx_font_italic">Perturbation Methods</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Although the aforementioned methods are capable of partially concealing the individual uploaded information, it is still possible for attackers to reveal private information from the computation results, e.g., the aggregation.
To address this issue, some perturbation methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>, <a href="#bib.bib150" title="" class="ltx_ref">150</a>, <a href="#bib.bib149" title="" class="ltx_ref">149</a>, <a href="#bib.bib154" title="" class="ltx_ref">154</a>, <a href="#bib.bib155" title="" class="ltx_ref">155</a>, <a href="#bib.bib156" title="" class="ltx_ref">156</a>]</cite> were proposed to provide a stronger privacy guarantee.
Among these methods, differential privacy (DP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib167" title="" class="ltx_ref">167</a>]</cite> enables an untrusted central collector to perform privacy-preserving data analytics.
The differentially private SGD algorithm proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>]</cite> is the main client-side defense method, which adopts a privacy accountant to constrain the total privacy loss.
Subsequently, several studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib150" title="" class="ltx_ref">150</a>, <a href="#bib.bib149" title="" class="ltx_ref">149</a>, <a href="#bib.bib151" title="" class="ltx_ref">151</a>, <a href="#bib.bib152" title="" class="ltx_ref">152</a>, <a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite> have employed DP in FL to protect local models against privacy attacks.
For example, Yadav et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib151" title="" class="ltx_ref">151</a>]</cite> used Gaussian and Laplace mechanisms to secure updated gradients in each communication round. Hao et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib152" title="" class="ltx_ref">152</a>]</cite> integrated additively homomorphic encryption <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib128" title="" class="ltx_ref">128</a>]</cite> with differential privacy to enhance privacy protection. In addition, Wei et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite> proposed a dynamic decay noise-injection policy to further improve the accuracy and resiliency.
Moreover, the DP mechanism has also been leveraged to protect the knowledge distillation process by adding noise to the model outputs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib160" title="" class="ltx_ref">160</a>, <a href="#bib.bib161" title="" class="ltx_ref">161</a>, <a href="#bib.bib162" title="" class="ltx_ref">162</a>, <a href="#bib.bib163" title="" class="ltx_ref">163</a>, <a href="#bib.bib164" title="" class="ltx_ref">164</a>]</cite>.
For instance, a noisy voting mechanism was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib163" title="" class="ltx_ref">163</a>]</cite> to secure the individual model output.
The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib161" title="" class="ltx_ref">161</a>]</cite> proposed a selective and interactive mechanism to add less DP noise in aggregation.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">In addition to the DP mechanism, there are various alternative approaches to secure shared information.
For instance, Zhu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite> proposed a compression-based method to prune the gradients with small magnitudes to zero, while Fan et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib154" title="" class="ltx_ref">154</a>]</cite> developed a secret polarization network to add adaptive noise to the gradients.
These two methods make it difficult for attackers to match the gradients when reconstructing private data.
Moreover, perturbing the training dataset can improve the robustness of the model against privacy attacks.
In this regard, Sun et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib155" title="" class="ltx_ref">155</a>]</cite> proposed a defense called Soteria against model inversion attack by learning a <em id="S5.SS2.p2.1.1" class="ltx_emph ltx_font_italic">defended layer</em> to perturb data.
Lee et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib157" title="" class="ltx_ref">157</a>]</cite> developed a digestive neural network that modifies input data to digested data batches.
These batches are expected to have a maximum distance from the original mini-batch to mitigate privacy attacks while maintaining desired classification accuracy.
In addition, numerous studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib156" title="" class="ltx_ref">156</a>, <a href="#bib.bib158" title="" class="ltx_ref">158</a>]</cite> have endeavored to perturb the model for a better privacy guarantee.
The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib156" title="" class="ltx_ref">156</a>]</cite> introduced a double-blind collaborative learning framework to apply random matrix sketching to model parameters.
Yang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib158" title="" class="ltx_ref">158</a>]</cite> proposed an accuracy-lossless perturbation method that allows clients to add arbitrarily large random noise to local models, while enabling the server to eliminate the noise during aggregation.
In federated knowledge distillation, Li et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib165" title="" class="ltx_ref">165</a>]</cite> developed a swing distillation technique to adaptively adjust the temperature coefficient based on the degree of private information contained in the data.
Gong et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib166" title="" class="ltx_ref">166</a>]</cite> proposed a one-shot offline knowledge distillation framework, which utilizes the quantized and noisy ensemble of local predictions to enable privacy-preserving knowledge transfer.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Experiments</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">The objective of the experimental study is to analyze the performance of different sharing methods in FL in terms of accuracy and communication overhead.
In addition, we analyze privacy leakage under various attacks and evaluate the effectiveness of the defense methods.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span><span id="S6.SS1.1.1" class="ltx_text ltx_font_italic">Setup</span>
</h3>

<section id="S6.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.1 </span>Datasets</h4>

<div id="S6.SS1.SSS1.p1" class="ltx_para">
<p id="S6.SS1.SSS1.p1.2" class="ltx_p">We select two benchmark datasets to conduct the experiments: SVHN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib168" title="" class="ltx_ref">168</a>]</cite> and CIFAR-10 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib169" title="" class="ltx_ref">169</a>]</cite>.
The SVHN dataset comprises real-world images of street view house numbers, consisting of 73,257 digits for training and 26,032 digits for testing.
On the other hand, the CIFAR-10 dataset comprises 60,000 <math id="S6.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="32\times 32" display="inline"><semantics id="S6.SS1.SSS1.p1.1.m1.1a"><mrow id="S6.SS1.SSS1.p1.1.m1.1.1" xref="S6.SS1.SSS1.p1.1.m1.1.1.cmml"><mn id="S6.SS1.SSS1.p1.1.m1.1.1.2" xref="S6.SS1.SSS1.p1.1.m1.1.1.2.cmml">32</mn><mo lspace="0.222em" rspace="0.222em" id="S6.SS1.SSS1.p1.1.m1.1.1.1" xref="S6.SS1.SSS1.p1.1.m1.1.1.1.cmml">×</mo><mn id="S6.SS1.SSS1.p1.1.m1.1.1.3" xref="S6.SS1.SSS1.p1.1.m1.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.p1.1.m1.1b"><apply id="S6.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S6.SS1.SSS1.p1.1.m1.1.1"><times id="S6.SS1.SSS1.p1.1.m1.1.1.1.cmml" xref="S6.SS1.SSS1.p1.1.m1.1.1.1"></times><cn type="integer" id="S6.SS1.SSS1.p1.1.m1.1.1.2.cmml" xref="S6.SS1.SSS1.p1.1.m1.1.1.2">32</cn><cn type="integer" id="S6.SS1.SSS1.p1.1.m1.1.1.3.cmml" xref="S6.SS1.SSS1.p1.1.m1.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS1.p1.1.m1.1c">32\times 32</annotation></semantics></math> color images, which are divided into 10 classes, with each class containing 6,000 images.
In this dataset, 50,000 images are used for training, and the remaining 10,000 images are reserved for testing.
To simulate the non-IID distribution, we set the number of clients in the FL system to 10 and adopt the Dirichlet distribution to shuffle the training data.
Specifically, the parameter <math id="S6.SS1.SSS1.p1.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S6.SS1.SSS1.p1.2.m2.1a"><mi id="S6.SS1.SSS1.p1.2.m2.1.1" xref="S6.SS1.SSS1.p1.2.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.p1.2.m2.1b"><ci id="S6.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S6.SS1.SSS1.p1.2.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS1.p1.2.m2.1c">\alpha</annotation></semantics></math> of the Dirichlet distribution controls the data heterogeneity, which is set to 0.01 and 0.1 on SVHN and 0.05 and 0.1 on CIFAR-10, respectively.</p>
</div>
</section>
<section id="S6.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.2 </span>FL Methods</h4>

<div id="S6.SS1.SSS2.p1" class="ltx_para">
<p id="S6.SS1.SSS2.p1.1" class="ltx_p">Based on the taxonomy of various sharing schemes, we choose the following representative methods from each category for our experimental analysis.</p>
</div>
<div id="S6.SS1.SSS2.p2" class="ltx_para">
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p"><span id="S6.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Model sharing</span>:
In the experiments, we evaluate the performance of three model sharing methods, namely FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, and FedPAQ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>.
FedAvg is the first attempt and the most widely used FL algorithm that allows clients to perform local training and upload the updated weights to the server for aggregation.
FedProx is a generalized version of FedAvg with an additional regularized loss in local training to mitigate the local overfitting caused by the non-IID data.
Considering the frequent exchange of model updates between clients and the server, FedPAQ aims at reducing communication overhead by employing quantization techniques for these updates.
Specifically, we quantize every floating-point value in the model updates to a 4-bit representation.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p"><span id="S6.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Synthetic data sharing</span>:
Sharing synthetic data among clients helps to mitigate data heterogeneity without heavily compromising privacy.
In our experiments, we evaluate two synthetic data sharing methods: dataset condensation (DC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite> and Mixup <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>.
The DC method condenses a large dataset into a small set of informative synthetic samples, while Mixup performs a linear interpolation between local samples.</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p"><span id="S6.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Knowledge sharing</span>: We evaluate FedMD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, FedED <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, and FKD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> in the experiments.
FedMD and FedED rely on a proxy dataset to transfer knowledge.
Specifically, the clients in FedMD upload their local predictions of the proxy samples to the server for aggregation, and then the ensemble predictions are sent back to the clients for knowledge distillation.
In contrast, FedED directly trains a student model at the server using the proxy samples and the local predictions.
We leverage the samples from MNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib170" title="" class="ltx_ref">170</a>]</cite> and Tiny ImageNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib171" title="" class="ltx_ref">171</a>]</cite> datasets to transfer knowledge in the SVHN and CIFAR-10 classification tasks, respectively.
On the other hand, FKD is a data-free knowledge distillation method that introduces a distillation regularizer to penalize the gap between the clients’ class-wise predictions and the ensemble predictions.
In FKD, each client shares its class-wise average predictions calculated by its local dataset.
The server then averages these predictions to obtain the ensemble result and sends it back to the clients.</p>
</div>
</li>
</ul>
</div>
<div id="S6.SS1.SSS2.p3" class="ltx_para">
<p id="S6.SS1.SSS2.p3.1" class="ltx_p">In addition, we also evaluate the performance of FedMix <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>, which combines the sharing of model parameters and the utilization of synthetic data through Mixup during the training phase.
Moreover, we present two performance benchmarks for comparison.
Firstly, we report the average accuracy of local models by independently training on their respective local datasets (referred to as IndepTrain), which serves as the lower bound for performance.
Secondly, we report the performance achieved by centralized training, which represents the performance upper bound.
Table <a href="#S6.T5" title="TABLE V ‣ 6.1.2 FL Methods ‣ 6.1 Setup ‣ 6 Experiments ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> provides a summary of these methods for ease of reference.</p>
</div>
<figure id="S6.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE V: </span>Representative methods selected in the experiments.</figcaption>
<table id="S6.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T5.1.1.1" class="ltx_tr">
<th id="S6.T5.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="S6.T5.1.1.1.1.1" class="ltx_text">Method</span></th>
<td id="S6.T5.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S6.T5.1.1.1.2.1" class="ltx_text">Type</span></td>
<td id="S6.T5.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t" colspan="2">Privacy attacks</td>
</tr>
<tr id="S6.T5.1.2.2" class="ltx_tr">
<td id="S6.T5.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t">Model inversion attack</td>
<td id="S6.T5.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">Membership inference attack</td>
</tr>
<tr id="S6.T5.1.3.3" class="ltx_tr">
<th id="S6.T5.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>
</th>
<td id="S6.T5.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t">Model sharing</td>
<td id="S6.T5.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t">White-box</td>
<td id="S6.T5.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t">White-box</td>
</tr>
<tr id="S6.T5.1.4.4" class="ltx_tr">
<th id="S6.T5.1.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</th>
<td id="S6.T5.1.4.4.2" class="ltx_td ltx_align_center">Model sharing</td>
<td id="S6.T5.1.4.4.3" class="ltx_td ltx_align_center">White-box</td>
<td id="S6.T5.1.4.4.4" class="ltx_td ltx_align_center">White-box</td>
</tr>
<tr id="S6.T5.1.5.5" class="ltx_tr">
<th id="S6.T5.1.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">FedPAQ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>
</th>
<td id="S6.T5.1.5.5.2" class="ltx_td ltx_align_center">Model sharing</td>
<td id="S6.T5.1.5.5.3" class="ltx_td ltx_align_center">White-box</td>
<td id="S6.T5.1.5.5.4" class="ltx_td ltx_align_center">White-box</td>
</tr>
<tr id="S6.T5.1.6.6" class="ltx_tr">
<th id="S6.T5.1.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">FedMix <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>
</th>
<td id="S6.T5.1.6.6.2" class="ltx_td ltx_align_center">Model &amp; Synthetic data sharing</td>
<td id="S6.T5.1.6.6.3" class="ltx_td ltx_align_center">White-box</td>
<td id="S6.T5.1.6.6.4" class="ltx_td ltx_align_center">White-box</td>
</tr>
<tr id="S6.T5.1.7.7" class="ltx_tr">
<th id="S6.T5.1.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">DC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>
</th>
<td id="S6.T5.1.7.7.2" class="ltx_td ltx_align_center">Synthetic data sharing</td>
<td id="S6.T5.1.7.7.3" class="ltx_td ltx_align_center">–</td>
<td id="S6.T5.1.7.7.4" class="ltx_td ltx_align_center">–</td>
</tr>
<tr id="S6.T5.1.8.8" class="ltx_tr">
<th id="S6.T5.1.8.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Mixup <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>
</th>
<td id="S6.T5.1.8.8.2" class="ltx_td ltx_align_center">Synthetic data sharing</td>
<td id="S6.T5.1.8.8.3" class="ltx_td ltx_align_center">–</td>
<td id="S6.T5.1.8.8.4" class="ltx_td ltx_align_center">–</td>
</tr>
<tr id="S6.T5.1.9.9" class="ltx_tr">
<th id="S6.T5.1.9.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">FedMD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>
</th>
<td id="S6.T5.1.9.9.2" class="ltx_td ltx_align_center">Knowledge sharing</td>
<td id="S6.T5.1.9.9.3" class="ltx_td ltx_align_center">Black-box</td>
<td id="S6.T5.1.9.9.4" class="ltx_td ltx_align_center">Black-box</td>
</tr>
<tr id="S6.T5.1.10.10" class="ltx_tr">
<th id="S6.T5.1.10.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">FedED <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</th>
<td id="S6.T5.1.10.10.2" class="ltx_td ltx_align_center">Knowledge sharing</td>
<td id="S6.T5.1.10.10.3" class="ltx_td ltx_align_center">Black-box</td>
<td id="S6.T5.1.10.10.4" class="ltx_td ltx_align_center">Black-box</td>
</tr>
<tr id="S6.T5.1.11.11" class="ltx_tr">
<th id="S6.T5.1.11.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">FKD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>
</th>
<td id="S6.T5.1.11.11.2" class="ltx_td ltx_align_center">Knowledge sharing</td>
<td id="S6.T5.1.11.11.3" class="ltx_td ltx_align_center">–</td>
<td id="S6.T5.1.11.11.4" class="ltx_td ltx_align_center">–</td>
</tr>
<tr id="S6.T5.1.12.12" class="ltx_tr">
<th id="S6.T5.1.12.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">IndepTrain</th>
<td id="S6.T5.1.12.12.2" class="ltx_td ltx_align_center ltx_border_t">–</td>
<td id="S6.T5.1.12.12.3" class="ltx_td ltx_align_center ltx_border_t">–</td>
<td id="S6.T5.1.12.12.4" class="ltx_td ltx_align_center ltx_border_t">–</td>
</tr>
<tr id="S6.T5.1.13.13" class="ltx_tr">
<th id="S6.T5.1.13.13.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">Centralized</th>
<td id="S6.T5.1.13.13.2" class="ltx_td ltx_align_center ltx_border_b">Raw data sharing</td>
<td id="S6.T5.1.13.13.3" class="ltx_td ltx_align_center ltx_border_b">–</td>
<td id="S6.T5.1.13.13.4" class="ltx_td ltx_align_center ltx_border_b">–</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S6.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.3 </span>Privacy Attacks</h4>

<div id="S6.SS1.SSS3.p1" class="ltx_para">
<p id="S6.SS1.SSS3.p1.1" class="ltx_p">While the taxonomy of attacks presented on the model is broad, our analysis primarily focuses on the most commonly used ones in the literature, including model inversion attacks and membership inference attacks.
In particular, we pay close attention to server-side attacks, as the server can acquire more information than individual clients, thereby posing the most significant threat to privacy.</p>
</div>
<div id="S6.SS1.SSS3.p2" class="ltx_para">
<ul id="S6.I2" class="ltx_itemize">
<li id="S6.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i1.p1" class="ltx_para">
<p id="S6.I2.i1.p1.1" class="ltx_p"><span id="S6.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Model inversion attack</span>:
Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>, <a href="#bib.bib110" title="" class="ltx_ref">110</a>, <a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite>, we employ a generative adversarial model (GAN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib172" title="" class="ltx_ref">172</a>]</cite> to extract knowledge from the shared information.
For the model sharing methods, the attacker can obtain the local model and directly use it as the discriminator to train the generator in this GAN.
For knowledge sharing methods where the attacker can only access the models’ output, we implement the IDEAL approach <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite> to reconstruct private data in a black-box setting.
In the experiments, we evaluate model inversion attacks using the Frechet inception distance (FID) score <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib173" title="" class="ltx_ref">173</a>]</cite> as a metric, which compares the distribution of the reconstructed images and the real images, with a lower FID value indicating better image quality and diversity.</p>
</div>
</li>
<li id="S6.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i2.p1" class="ltx_para">
<p id="S6.I2.i2.p1.1" class="ltx_p"><span id="S6.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Membership inference attack</span>:
The attacker employs a neural-based binary classifier to determine the membership of samples.
Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite>, we provide the attacker with more advantages than previous works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>, <a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite>.
Specifically, for the knowledge sharing methods, we assume the attacker can query the model, own a training dataset with the membership status, and observe the shared information during training.
The input of the classifier includes the inference results of some models during the training epochs.
In addition, for the model sharing methods, the attacker can further utilize the intermediate features and gradients for membership inference.
To evaluate the performance of membership inference, we create a membership dataset that comprises 10,000 member and non-member samples randomly selected from the local datasets and the test dataset, respectively, and use binary classification accuracy as the performance metric.</p>
</div>
</li>
</ul>
</div>
<div id="S6.SS1.SSS3.p3" class="ltx_para">
<p id="S6.SS1.SSS3.p3.1" class="ltx_p">To the best of our knowledge, no prior research has been conducted on performing model inversion attacks solely using shared data or class-wise predictions.
Thus, we assume that the attackers randomly guess the results when performing membership inference attacks.
In addition, when conducting model inversion attacks on (1) DC and Mixup, and (2) FKD and IndepTrain, we regard the shared data and random noise as the reconstructed samples, respectively.</p>
</div>
</section>
<section id="S6.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.4 </span>Neural Network Architecture</h4>

<div id="S6.SS1.SSS4.p1" class="ltx_para">
<p id="S6.SS1.SSS4.p1.2" class="ltx_p">For the image classification task on SVHN and CIFAR-10 datasets, we employ a convolutional neural network (CNN) that comprises two convolutional layers with a kernel size of <math id="S6.SS1.SSS4.p1.1.m1.1" class="ltx_Math" alttext="5\times 5" display="inline"><semantics id="S6.SS1.SSS4.p1.1.m1.1a"><mrow id="S6.SS1.SSS4.p1.1.m1.1.1" xref="S6.SS1.SSS4.p1.1.m1.1.1.cmml"><mn id="S6.SS1.SSS4.p1.1.m1.1.1.2" xref="S6.SS1.SSS4.p1.1.m1.1.1.2.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S6.SS1.SSS4.p1.1.m1.1.1.1" xref="S6.SS1.SSS4.p1.1.m1.1.1.1.cmml">×</mo><mn id="S6.SS1.SSS4.p1.1.m1.1.1.3" xref="S6.SS1.SSS4.p1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS4.p1.1.m1.1b"><apply id="S6.SS1.SSS4.p1.1.m1.1.1.cmml" xref="S6.SS1.SSS4.p1.1.m1.1.1"><times id="S6.SS1.SSS4.p1.1.m1.1.1.1.cmml" xref="S6.SS1.SSS4.p1.1.m1.1.1.1"></times><cn type="integer" id="S6.SS1.SSS4.p1.1.m1.1.1.2.cmml" xref="S6.SS1.SSS4.p1.1.m1.1.1.2">5</cn><cn type="integer" id="S6.SS1.SSS4.p1.1.m1.1.1.3.cmml" xref="S6.SS1.SSS4.p1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS4.p1.1.m1.1c">5\times 5</annotation></semantics></math>, two max-pooling layers with a kernel size of <math id="S6.SS1.SSS4.p1.2.m2.1" class="ltx_Math" alttext="2\times 2" display="inline"><semantics id="S6.SS1.SSS4.p1.2.m2.1a"><mrow id="S6.SS1.SSS4.p1.2.m2.1.1" xref="S6.SS1.SSS4.p1.2.m2.1.1.cmml"><mn id="S6.SS1.SSS4.p1.2.m2.1.1.2" xref="S6.SS1.SSS4.p1.2.m2.1.1.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S6.SS1.SSS4.p1.2.m2.1.1.1" xref="S6.SS1.SSS4.p1.2.m2.1.1.1.cmml">×</mo><mn id="S6.SS1.SSS4.p1.2.m2.1.1.3" xref="S6.SS1.SSS4.p1.2.m2.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS4.p1.2.m2.1b"><apply id="S6.SS1.SSS4.p1.2.m2.1.1.cmml" xref="S6.SS1.SSS4.p1.2.m2.1.1"><times id="S6.SS1.SSS4.p1.2.m2.1.1.1.cmml" xref="S6.SS1.SSS4.p1.2.m2.1.1.1"></times><cn type="integer" id="S6.SS1.SSS4.p1.2.m2.1.1.2.cmml" xref="S6.SS1.SSS4.p1.2.m2.1.1.2">2</cn><cn type="integer" id="S6.SS1.SSS4.p1.2.m2.1.1.3.cmml" xref="S6.SS1.SSS4.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS4.p1.2.m2.1c">2\times 2</annotation></semantics></math>, and two fully-connected layers.
The output channels in the convolutional layers are 64 and 128, respectively.
The input neurons of the fully-connected layers are 1600 and 512, respectively.
The generator in GAN for reconstructing the private data has two fully-connected layers and two transposed convolution layers.
The binary classifier for inferring membership comprises two fully-connected layers, where the number of hidden neurons is 128.</p>
</div>
</section>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span><span id="S6.SS2.1.1" class="ltx_text ltx_font_italic">Privacy-Utility Tradeoff</span>
</h3>

<figure id="S6.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2307.10655/assets/x8.png" id="S6.F4.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="452" height="150" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F4.sf1.4.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><math id="S6.F4.sf1.2.m1.1" class="ltx_Math" alttext="\alpha=0.01" display="inline"><semantics id="S6.F4.sf1.2.m1.1b"><mrow id="S6.F4.sf1.2.m1.1.1" xref="S6.F4.sf1.2.m1.1.1.cmml"><mi mathsize="80%" id="S6.F4.sf1.2.m1.1.1.2" xref="S6.F4.sf1.2.m1.1.1.2.cmml">α</mi><mo mathsize="80%" id="S6.F4.sf1.2.m1.1.1.1" xref="S6.F4.sf1.2.m1.1.1.1.cmml">=</mo><mn mathsize="80%" id="S6.F4.sf1.2.m1.1.1.3" xref="S6.F4.sf1.2.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F4.sf1.2.m1.1c"><apply id="S6.F4.sf1.2.m1.1.1.cmml" xref="S6.F4.sf1.2.m1.1.1"><eq id="S6.F4.sf1.2.m1.1.1.1.cmml" xref="S6.F4.sf1.2.m1.1.1.1"></eq><ci id="S6.F4.sf1.2.m1.1.1.2.cmml" xref="S6.F4.sf1.2.m1.1.1.2">𝛼</ci><cn type="float" id="S6.F4.sf1.2.m1.1.1.3.cmml" xref="S6.F4.sf1.2.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F4.sf1.2.m1.1d">\alpha=0.01</annotation></semantics></math></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2307.10655/assets/x9.png" id="S6.F4.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="452" height="150" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F4.sf2.4.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><math id="S6.F4.sf2.2.m1.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S6.F4.sf2.2.m1.1b"><mrow id="S6.F4.sf2.2.m1.1.1" xref="S6.F4.sf2.2.m1.1.1.cmml"><mi mathsize="80%" id="S6.F4.sf2.2.m1.1.1.2" xref="S6.F4.sf2.2.m1.1.1.2.cmml">α</mi><mo mathsize="80%" id="S6.F4.sf2.2.m1.1.1.1" xref="S6.F4.sf2.2.m1.1.1.1.cmml">=</mo><mn mathsize="80%" id="S6.F4.sf2.2.m1.1.1.3" xref="S6.F4.sf2.2.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F4.sf2.2.m1.1c"><apply id="S6.F4.sf2.2.m1.1.1.cmml" xref="S6.F4.sf2.2.m1.1.1"><eq id="S6.F4.sf2.2.m1.1.1.1.cmml" xref="S6.F4.sf2.2.m1.1.1.1"></eq><ci id="S6.F4.sf2.2.m1.1.1.2.cmml" xref="S6.F4.sf2.2.m1.1.1.2">𝛼</ci><cn type="float" id="S6.F4.sf2.2.m1.1.1.3.cmml" xref="S6.F4.sf2.2.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F4.sf2.2.m1.1d">\alpha=0.1</annotation></semantics></math></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Accuracy and privacy leakage in SVHN image classification task. Local datasets follow Dirichlet distribution with (a) <math id="S6.F4.3.m1.1" class="ltx_Math" alttext="\alpha=0.01" display="inline"><semantics id="S6.F4.3.m1.1b"><mrow id="S6.F4.3.m1.1.1" xref="S6.F4.3.m1.1.1.cmml"><mi id="S6.F4.3.m1.1.1.2" xref="S6.F4.3.m1.1.1.2.cmml">α</mi><mo id="S6.F4.3.m1.1.1.1" xref="S6.F4.3.m1.1.1.1.cmml">=</mo><mn id="S6.F4.3.m1.1.1.3" xref="S6.F4.3.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F4.3.m1.1c"><apply id="S6.F4.3.m1.1.1.cmml" xref="S6.F4.3.m1.1.1"><eq id="S6.F4.3.m1.1.1.1.cmml" xref="S6.F4.3.m1.1.1.1"></eq><ci id="S6.F4.3.m1.1.1.2.cmml" xref="S6.F4.3.m1.1.1.2">𝛼</ci><cn type="float" id="S6.F4.3.m1.1.1.3.cmml" xref="S6.F4.3.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F4.3.m1.1d">\alpha=0.01</annotation></semantics></math> and (b) <math id="S6.F4.4.m2.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S6.F4.4.m2.1b"><mrow id="S6.F4.4.m2.1.1" xref="S6.F4.4.m2.1.1.cmml"><mi id="S6.F4.4.m2.1.1.2" xref="S6.F4.4.m2.1.1.2.cmml">α</mi><mo id="S6.F4.4.m2.1.1.1" xref="S6.F4.4.m2.1.1.1.cmml">=</mo><mn id="S6.F4.4.m2.1.1.3" xref="S6.F4.4.m2.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F4.4.m2.1c"><apply id="S6.F4.4.m2.1.1.cmml" xref="S6.F4.4.m2.1.1"><eq id="S6.F4.4.m2.1.1.1.cmml" xref="S6.F4.4.m2.1.1.1"></eq><ci id="S6.F4.4.m2.1.1.2.cmml" xref="S6.F4.4.m2.1.1.2">𝛼</ci><cn type="float" id="S6.F4.4.m2.1.1.3.cmml" xref="S6.F4.4.m2.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F4.4.m2.1d">\alpha=0.1</annotation></semantics></math>.</figcaption>
</figure>
<figure id="S6.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2307.10655/assets/x10.png" id="S6.F5.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="452" height="150" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F5.sf1.4.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><math id="S6.F5.sf1.2.m1.1" class="ltx_Math" alttext="\alpha=0.05" display="inline"><semantics id="S6.F5.sf1.2.m1.1b"><mrow id="S6.F5.sf1.2.m1.1.1" xref="S6.F5.sf1.2.m1.1.1.cmml"><mi mathsize="80%" id="S6.F5.sf1.2.m1.1.1.2" xref="S6.F5.sf1.2.m1.1.1.2.cmml">α</mi><mo mathsize="80%" id="S6.F5.sf1.2.m1.1.1.1" xref="S6.F5.sf1.2.m1.1.1.1.cmml">=</mo><mn mathsize="80%" id="S6.F5.sf1.2.m1.1.1.3" xref="S6.F5.sf1.2.m1.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F5.sf1.2.m1.1c"><apply id="S6.F5.sf1.2.m1.1.1.cmml" xref="S6.F5.sf1.2.m1.1.1"><eq id="S6.F5.sf1.2.m1.1.1.1.cmml" xref="S6.F5.sf1.2.m1.1.1.1"></eq><ci id="S6.F5.sf1.2.m1.1.1.2.cmml" xref="S6.F5.sf1.2.m1.1.1.2">𝛼</ci><cn type="float" id="S6.F5.sf1.2.m1.1.1.3.cmml" xref="S6.F5.sf1.2.m1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F5.sf1.2.m1.1d">\alpha=0.05</annotation></semantics></math></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2307.10655/assets/x11.png" id="S6.F5.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="452" height="150" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F5.sf2.4.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><math id="S6.F5.sf2.2.m1.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S6.F5.sf2.2.m1.1b"><mrow id="S6.F5.sf2.2.m1.1.1" xref="S6.F5.sf2.2.m1.1.1.cmml"><mi mathsize="80%" id="S6.F5.sf2.2.m1.1.1.2" xref="S6.F5.sf2.2.m1.1.1.2.cmml">α</mi><mo mathsize="80%" id="S6.F5.sf2.2.m1.1.1.1" xref="S6.F5.sf2.2.m1.1.1.1.cmml">=</mo><mn mathsize="80%" id="S6.F5.sf2.2.m1.1.1.3" xref="S6.F5.sf2.2.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F5.sf2.2.m1.1c"><apply id="S6.F5.sf2.2.m1.1.1.cmml" xref="S6.F5.sf2.2.m1.1.1"><eq id="S6.F5.sf2.2.m1.1.1.1.cmml" xref="S6.F5.sf2.2.m1.1.1.1"></eq><ci id="S6.F5.sf2.2.m1.1.1.2.cmml" xref="S6.F5.sf2.2.m1.1.1.2">𝛼</ci><cn type="float" id="S6.F5.sf2.2.m1.1.1.3.cmml" xref="S6.F5.sf2.2.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F5.sf2.2.m1.1d">\alpha=0.1</annotation></semantics></math></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Accuracy and privacy leakage in CIFAR-10 image classification task. Local datasets follow Dirichlet distribution with (a) <math id="S6.F5.3.m1.1" class="ltx_Math" alttext="\alpha=0.05" display="inline"><semantics id="S6.F5.3.m1.1b"><mrow id="S6.F5.3.m1.1.1" xref="S6.F5.3.m1.1.1.cmml"><mi id="S6.F5.3.m1.1.1.2" xref="S6.F5.3.m1.1.1.2.cmml">α</mi><mo id="S6.F5.3.m1.1.1.1" xref="S6.F5.3.m1.1.1.1.cmml">=</mo><mn id="S6.F5.3.m1.1.1.3" xref="S6.F5.3.m1.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F5.3.m1.1c"><apply id="S6.F5.3.m1.1.1.cmml" xref="S6.F5.3.m1.1.1"><eq id="S6.F5.3.m1.1.1.1.cmml" xref="S6.F5.3.m1.1.1.1"></eq><ci id="S6.F5.3.m1.1.1.2.cmml" xref="S6.F5.3.m1.1.1.2">𝛼</ci><cn type="float" id="S6.F5.3.m1.1.1.3.cmml" xref="S6.F5.3.m1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F5.3.m1.1d">\alpha=0.05</annotation></semantics></math> and (b) <math id="S6.F5.4.m2.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S6.F5.4.m2.1b"><mrow id="S6.F5.4.m2.1.1" xref="S6.F5.4.m2.1.1.cmml"><mi id="S6.F5.4.m2.1.1.2" xref="S6.F5.4.m2.1.1.2.cmml">α</mi><mo id="S6.F5.4.m2.1.1.1" xref="S6.F5.4.m2.1.1.1.cmml">=</mo><mn id="S6.F5.4.m2.1.1.3" xref="S6.F5.4.m2.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F5.4.m2.1c"><apply id="S6.F5.4.m2.1.1.cmml" xref="S6.F5.4.m2.1.1"><eq id="S6.F5.4.m2.1.1.1.cmml" xref="S6.F5.4.m2.1.1.1"></eq><ci id="S6.F5.4.m2.1.1.2.cmml" xref="S6.F5.4.m2.1.1.2">𝛼</ci><cn type="float" id="S6.F5.4.m2.1.1.3.cmml" xref="S6.F5.4.m2.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F5.4.m2.1d">\alpha=0.1</annotation></semantics></math>.</figcaption>
</figure>
<figure id="S6.F6" class="ltx_figure"><img src="/html/2307.10655/assets/x12.png" id="S6.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="185" height="106" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Visualization of shared data by the DC, FedMix, and centralized training methods in the CIFAR-10 classification task.</figcaption>
</figure>
<figure id="S6.F7" class="ltx_figure"><img src="/html/2307.10655/assets/x13.png" id="S6.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="452" height="150" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Communication overhead during the training process.</figcaption>
</figure>
<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">In this subsection, we evaluate the effectiveness of various methods and investigate their privacy leakage.
We assume that the semi-honest server conducts privacy attacks by utilizing the shared information from clients.
We set the number of communication rounds to 1,000, with each round consisting of 10 local training steps.
For knowledge sharing methods, we set the distillation steps per communication round to 50.
The empirical results are presented in Fig. <a href="#S6.F4" title="Figure 4 ‣ 6.2 Privacy-Utility Tradeoff ‣ 6 Experiments ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and Fig. <a href="#S6.F5" title="Figure 5 ‣ 6.2 Privacy-Utility Tradeoff ‣ 6 Experiments ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, which report the classification accuracy, membership inference accuracy, and FID value of each method on the privacy-utility planes. Moreover, we plot the Pareto optimal curve to depict the tradeoff between performance and privacy leakage.
It is observed that with the increase of the classification accuracy, the membership inference accuracy approaches 100%, and the FID value approaches zero.
In other words, achieving high performance often comes at the expense of compromising privacy.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p">The performance achieved by centralized training serves as an upper bound for comparison.
However, it breaches the privacy requirement of FL since it requires the direct collection of local datasets from clients.
Among various FL baselines, model sharing methods achieve satisfactory performance.
In particular, the FedPAQ method quantizes the local model updates before uploading, resulting in lower performance and privacy leakage compared with other model sharing methods.
This may be attributed to the quantization process, which reduces the amount of information sent to the server, thereby providing stronger privacy guarantees.
Furthermore, FedMix achieves additional performance gains by sharing synthetic data.
However, this method also leads to relatively high privacy leakage due to increased exposure of clients’ information.</p>
</div>
<div id="S6.SS2.p3" class="ltx_para">
<p id="S6.SS2.p3.1" class="ltx_p">The synthetic data sharing methods, DC and Mixup, achieve poor performance in terms of both utility and privacy guarantees.
While their FID values are comparable to or even smaller than those of model sharing methods, indicating high privacy leakage, their test accuracy is approximately the same as that of IndepTrain.
Fig. <a href="#S6.F6" title="Figure 6 ‣ 6.2 Privacy-Utility Tradeoff ‣ 6 Experiments ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> presents a visualization of the shared samples in different methods.
The synthetic samples appear visually dissimilar to the raw data, which could be the reason that negatively influences the performance.
The Mixup method generates new training examples by linearly interpolating input samples and their corresponding labels.
However, when the relationship between input samples and their labels is non-linear, Mixup may not capture this relationship.
Moreover, as pointed out in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, dataset condensation may contain numerous task-irrelevant features, potentially leading to a degradation in model performance.</p>
</div>
<div id="S6.SS2.p4" class="ltx_para">
<p id="S6.SS2.p4.1" class="ltx_p">The knowledge sharing methods offer much stronger privacy guarantees compared with the model sharing methods. By keeping the model parameters locally, the local model is protected from white-box privacy attacks, resulting in lower accuracy of membership inference and larger FID value.
Moreover, the data-based knowledge sharing methods, such as FedMD and FedED, outperform the data-free knowledge sharing method, FKD, in terms of test accuracy.
This is because the knowledge shared in a data-free manner could be misleading and ambiguous, resulting in performance degradation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib174" title="" class="ltx_ref">174</a>, <a href="#bib.bib175" title="" class="ltx_ref">175</a>]</cite>.
On the other hand, FKD demonstrates greater robustness against privacy attacks compared with both FedMD and FedED due to the reduced exposure of information during the training process.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span><span id="S6.SS3.1.1" class="ltx_text ltx_font_italic">Communication Overhead</span>
</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">In this subsection, we compare the communication overhead of different sharing methods.
Fig. <a href="#S6.F7" title="Figure 7 ‣ 6.2 Privacy-Utility Tradeoff ‣ 6 Experiments ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows the total communication overhead for each client during the training process.
Although the model sharing methods achieve satisfactory test accuracy, as verified in Section <a href="#S6.F7" title="Figure 7 ‣ 6.2 Privacy-Utility Tradeoff ‣ 6 Experiments ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, they result in a higher communication overhead than data sharing and knowledge sharing methods.
This is mainly because the local models contain a large number of parameters.
Note that FedPAQ provides a tradeoff between communication overhead and performance.
By quantizing the model updates, it reduces communication costs, but this leads to a reduction in the model utility.
The communication overhead associated with data sharing methods is proportional to the size of the shared data.
Similarly, for data-based knowledge sharing methods, such as FedMD and FedED, the communication costs are dictated by the number of proxy samples utilized for knowledge transfer.
In the experiments, we utilize the MNIST dataset and Tiny ImageNet dataset to transfer knowledge for the SVHN and CIFAR-10 classification tasks, respectively.
Since the gray-scale digits from MNIST are smaller in size than the RGB images from Tiny ImageNet, we see that the communication overhead of both FedMD and FedED methods for the SVHN classification task is lower than that for the CIFAR-10 classification task.
Moreover, FKD has the lowest communication overhead since it only shares class-wise predictions among clients without relying on proxy samples.</p>
</div>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span><span id="S6.SS4.1.1" class="ltx_text ltx_font_italic">Effectiveness of Defense Methods</span>
</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.1" class="ltx_p">Finally, we evaluate the effectiveness of the defense methods in enhancing privacy protection against potential attacks.
Two techniques are selected in the experiments, including differential privacy (DP) and data perturbation.</p>
</div>
<section id="S6.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.4.1 </span>Differential Privacy</h4>

<div id="S6.SS4.SSS1.p1" class="ltx_para">
<p id="S6.SS4.SSS1.p1.1" class="ltx_p">We employ the differentially-private stochastic gradient descent (DP-SGD) algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>, <a href="#bib.bib176" title="" class="ltx_ref">176</a>]</cite> and the Opacus package <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib177" title="" class="ltx_ref">177</a>]</cite> to optimize local models in four FL methods: FedAvg, FedPAQ, FedMD, and FedED.
The maximum norm of the gradient is set to 1, and the noise multiplier is set to 0.01.
The performance of the classifier and the privacy attacks is shown in Table <a href="#S6.T6" title="TABLE VI ‣ 6.4.1 Differential Privacy ‣ 6.4 Effectiveness of Defense Methods ‣ 6 Experiments ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>.
It is observed that the DP mechanism effectively protects the model against the membership inference attack but at the cost of reduced test accuracy.
This is due to the fact that the addition of DP noise to the models makes it challenging for both the clients and the attacker to distinguish between signal and random fluctuations.
However, the DP mechanism provides limited defense against the model inversion attack.
The empirical results presented in Table <a href="#S6.T6" title="TABLE VI ‣ 6.4.1 Differential Privacy ‣ 6.4 Effectiveness of Defense Methods ‣ 6 Experiments ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a> are consistent with the findings in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite>, where the FID value may not increase after introducing the DP noise.
The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite> attributed these results to the fact that DP is mainly designed to protect the presence of a single data sample and not explicitly to protect attribute privacy.</p>
</div>
<figure id="S6.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VI: </span>Test accuracy, membership inference (MEM) accuracy, and FID value of representative methods with and without DP protection.
The symbols <math id="S6.T6.5.m1.1" class="ltx_Math" alttext="\Uparrow" display="inline"><semantics id="S6.T6.5.m1.1b"><mo stretchy="false" id="S6.T6.5.m1.1.1" xref="S6.T6.5.m1.1.1.cmml">⇑</mo><annotation-xml encoding="MathML-Content" id="S6.T6.5.m1.1c"><ci id="S6.T6.5.m1.1.1.cmml" xref="S6.T6.5.m1.1.1">⇑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.5.m1.1d">\Uparrow</annotation></semantics></math> and <math id="S6.T6.6.m2.1" class="ltx_Math" alttext="\Downarrow" display="inline"><semantics id="S6.T6.6.m2.1b"><mo stretchy="false" id="S6.T6.6.m2.1.1" xref="S6.T6.6.m2.1.1.cmml">⇓</mo><annotation-xml encoding="MathML-Content" id="S6.T6.6.m2.1c"><ci id="S6.T6.6.m2.1.1.cmml" xref="S6.T6.6.m2.1.1">⇓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.6.m2.1d">\Downarrow</annotation></semantics></math> respectively denote higher and lower values as desirable qualities.
The symbols <math id="S6.T6.7.m3.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T6.7.m3.1b"><mo mathcolor="#00FF00" stretchy="false" id="S6.T6.7.m3.1.1" xref="S6.T6.7.m3.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T6.7.m3.1c"><ci id="S6.T6.7.m3.1.1.cmml" xref="S6.T6.7.m3.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.7.m3.1d">\uparrow</annotation></semantics></math> and <math id="S6.T6.8.m4.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T6.8.m4.1b"><mo mathcolor="#FF0000" stretchy="false" id="S6.T6.8.m4.1.1" xref="S6.T6.8.m4.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T6.8.m4.1c"><ci id="S6.T6.8.m4.1.1.cmml" xref="S6.T6.8.m4.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.8.m4.1d">\downarrow</annotation></semantics></math> represent the increase or decrease in values compared to cases where differential privacy protection is not applied.
</figcaption>
<table id="S6.T6.23" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T6.23.16.1" class="ltx_tr">
<th id="S6.T6.23.16.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" rowspan="2"></th>
<th id="S6.T6.23.16.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">FedAvg</th>
<th id="S6.T6.23.16.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">FedPAQ</th>
<th id="S6.T6.23.16.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">FedMD</th>
<th id="S6.T6.23.16.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">FedED</th>
</tr>
<tr id="S6.T6.23.17.2" class="ltx_tr">
<th id="S6.T6.23.17.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">w/o DP</th>
<th id="S6.T6.23.17.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">w/ DP</th>
<th id="S6.T6.23.17.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">w/o DP</th>
<th id="S6.T6.23.17.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">w/ DP</th>
<th id="S6.T6.23.17.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">w/o DP</th>
<th id="S6.T6.23.17.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">w/ DP</th>
<th id="S6.T6.23.17.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">w/o DP</th>
<th id="S6.T6.23.17.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">w/ DP</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T6.13.5" class="ltx_tr">
<th id="S6.T6.9.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Test <math id="S6.T6.9.1.1.m1.1" class="ltx_Math" alttext="\Uparrow" display="inline"><semantics id="S6.T6.9.1.1.m1.1a"><mo stretchy="false" id="S6.T6.9.1.1.m1.1.1" xref="S6.T6.9.1.1.m1.1.1.cmml">⇑</mo><annotation-xml encoding="MathML-Content" id="S6.T6.9.1.1.m1.1b"><ci id="S6.T6.9.1.1.m1.1.1.cmml" xref="S6.T6.9.1.1.m1.1.1">⇑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.9.1.1.m1.1c">\Uparrow</annotation></semantics></math>
</th>
<td id="S6.T6.13.5.6" class="ltx_td ltx_align_center ltx_border_t">66.81</td>
<td id="S6.T6.10.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">61.19 <math id="S6.T6.10.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T6.10.2.2.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T6.10.2.2.m1.1.1" xref="S6.T6.10.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T6.10.2.2.m1.1b"><ci id="S6.T6.10.2.2.m1.1.1.cmml" xref="S6.T6.10.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.10.2.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T6.13.5.7" class="ltx_td ltx_align_center ltx_border_t">58.82</td>
<td id="S6.T6.11.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56.66 <math id="S6.T6.11.3.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T6.11.3.3.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T6.11.3.3.m1.1.1" xref="S6.T6.11.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T6.11.3.3.m1.1b"><ci id="S6.T6.11.3.3.m1.1.1.cmml" xref="S6.T6.11.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.11.3.3.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T6.13.5.8" class="ltx_td ltx_align_center ltx_border_t">47.51</td>
<td id="S6.T6.12.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">38.91 <math id="S6.T6.12.4.4.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T6.12.4.4.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T6.12.4.4.m1.1.1" xref="S6.T6.12.4.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T6.12.4.4.m1.1b"><ci id="S6.T6.12.4.4.m1.1.1.cmml" xref="S6.T6.12.4.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.12.4.4.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T6.13.5.9" class="ltx_td ltx_align_center ltx_border_t">43.35</td>
<td id="S6.T6.13.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">35.93 <math id="S6.T6.13.5.5.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T6.13.5.5.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T6.13.5.5.m1.1.1" xref="S6.T6.13.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T6.13.5.5.m1.1b"><ci id="S6.T6.13.5.5.m1.1.1.cmml" xref="S6.T6.13.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.13.5.5.m1.1c">\downarrow</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T6.18.10" class="ltx_tr">
<th id="S6.T6.14.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">MEM <math id="S6.T6.14.6.1.m1.1" class="ltx_Math" alttext="\Downarrow" display="inline"><semantics id="S6.T6.14.6.1.m1.1a"><mo stretchy="false" id="S6.T6.14.6.1.m1.1.1" xref="S6.T6.14.6.1.m1.1.1.cmml">⇓</mo><annotation-xml encoding="MathML-Content" id="S6.T6.14.6.1.m1.1b"><ci id="S6.T6.14.6.1.m1.1.1.cmml" xref="S6.T6.14.6.1.m1.1.1">⇓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.14.6.1.m1.1c">\Downarrow</annotation></semantics></math>
</th>
<td id="S6.T6.18.10.6" class="ltx_td ltx_align_center">65.50</td>
<td id="S6.T6.15.7.2" class="ltx_td ltx_align_center ltx_border_r">52.11 <math id="S6.T6.15.7.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T6.15.7.2.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T6.15.7.2.m1.1.1" xref="S6.T6.15.7.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T6.15.7.2.m1.1b"><ci id="S6.T6.15.7.2.m1.1.1.cmml" xref="S6.T6.15.7.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.15.7.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T6.18.10.7" class="ltx_td ltx_align_center">57.13</td>
<td id="S6.T6.16.8.3" class="ltx_td ltx_align_center ltx_border_r">51.30 <math id="S6.T6.16.8.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T6.16.8.3.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T6.16.8.3.m1.1.1" xref="S6.T6.16.8.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T6.16.8.3.m1.1b"><ci id="S6.T6.16.8.3.m1.1.1.cmml" xref="S6.T6.16.8.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.16.8.3.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T6.18.10.8" class="ltx_td ltx_align_center">51.75</td>
<td id="S6.T6.17.9.4" class="ltx_td ltx_align_center ltx_border_r">50.78 <math id="S6.T6.17.9.4.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T6.17.9.4.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T6.17.9.4.m1.1.1" xref="S6.T6.17.9.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T6.17.9.4.m1.1b"><ci id="S6.T6.17.9.4.m1.1.1.cmml" xref="S6.T6.17.9.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.17.9.4.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T6.18.10.9" class="ltx_td ltx_align_center">50.80</td>
<td id="S6.T6.18.10.5" class="ltx_td ltx_align_center ltx_border_r">50.68 <math id="S6.T6.18.10.5.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T6.18.10.5.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T6.18.10.5.m1.1.1" xref="S6.T6.18.10.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T6.18.10.5.m1.1b"><ci id="S6.T6.18.10.5.m1.1.1.cmml" xref="S6.T6.18.10.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.18.10.5.m1.1c">\downarrow</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T6.23.15" class="ltx_tr">
<th id="S6.T6.19.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">FID <math id="S6.T6.19.11.1.m1.1" class="ltx_Math" alttext="\Uparrow" display="inline"><semantics id="S6.T6.19.11.1.m1.1a"><mo stretchy="false" id="S6.T6.19.11.1.m1.1.1" xref="S6.T6.19.11.1.m1.1.1.cmml">⇑</mo><annotation-xml encoding="MathML-Content" id="S6.T6.19.11.1.m1.1b"><ci id="S6.T6.19.11.1.m1.1.1.cmml" xref="S6.T6.19.11.1.m1.1.1">⇑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.19.11.1.m1.1c">\Uparrow</annotation></semantics></math>
</th>
<td id="S6.T6.23.15.6" class="ltx_td ltx_align_center ltx_border_b">238.38</td>
<td id="S6.T6.20.12.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">249.20 <math id="S6.T6.20.12.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T6.20.12.2.m1.1a"><mo mathcolor="#00FF00" stretchy="false" id="S6.T6.20.12.2.m1.1.1" xref="S6.T6.20.12.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T6.20.12.2.m1.1b"><ci id="S6.T6.20.12.2.m1.1.1.cmml" xref="S6.T6.20.12.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.20.12.2.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S6.T6.23.15.7" class="ltx_td ltx_align_center ltx_border_b">278.74</td>
<td id="S6.T6.21.13.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">272.40 <math id="S6.T6.21.13.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T6.21.13.3.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T6.21.13.3.m1.1.1" xref="S6.T6.21.13.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T6.21.13.3.m1.1b"><ci id="S6.T6.21.13.3.m1.1.1.cmml" xref="S6.T6.21.13.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.21.13.3.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T6.23.15.8" class="ltx_td ltx_align_center ltx_border_b">362.38</td>
<td id="S6.T6.22.14.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">344.00 <math id="S6.T6.22.14.4.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T6.22.14.4.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T6.22.14.4.m1.1.1" xref="S6.T6.22.14.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T6.22.14.4.m1.1b"><ci id="S6.T6.22.14.4.m1.1.1.cmml" xref="S6.T6.22.14.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.22.14.4.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T6.23.15.9" class="ltx_td ltx_align_center ltx_border_b">354.99</td>
<td id="S6.T6.23.15.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">379.70 <math id="S6.T6.23.15.5.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T6.23.15.5.m1.1a"><mo mathcolor="#00FF00" stretchy="false" id="S6.T6.23.15.5.m1.1.1" xref="S6.T6.23.15.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T6.23.15.5.m1.1b"><ci id="S6.T6.23.15.5.m1.1.1.cmml" xref="S6.T6.23.15.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.23.15.5.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S6.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VII: </span>
Test accuracy and membership inference (MEM) accuracy of representative methods with data perturbation.
The symbols <math id="S6.T7.5.m1.1" class="ltx_Math" alttext="\Uparrow" display="inline"><semantics id="S6.T7.5.m1.1b"><mo stretchy="false" id="S6.T7.5.m1.1.1" xref="S6.T7.5.m1.1.1.cmml">⇑</mo><annotation-xml encoding="MathML-Content" id="S6.T7.5.m1.1c"><ci id="S6.T7.5.m1.1.1.cmml" xref="S6.T7.5.m1.1.1">⇑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.5.m1.1d">\Uparrow</annotation></semantics></math> and <math id="S6.T7.6.m2.1" class="ltx_Math" alttext="\Downarrow" display="inline"><semantics id="S6.T7.6.m2.1b"><mo stretchy="false" id="S6.T7.6.m2.1.1" xref="S6.T7.6.m2.1.1.cmml">⇓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.6.m2.1c"><ci id="S6.T7.6.m2.1.1.cmml" xref="S6.T7.6.m2.1.1">⇓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.6.m2.1d">\Downarrow</annotation></semantics></math> respectively denote higher and lower values as desirable qualities.
The symbols <math id="S6.T7.7.m3.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T7.7.m3.1b"><mo mathcolor="#00FF00" stretchy="false" id="S6.T7.7.m3.1.1" xref="S6.T7.7.m3.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T7.7.m3.1c"><ci id="S6.T7.7.m3.1.1.cmml" xref="S6.T7.7.m3.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.7.m3.1d">\uparrow</annotation></semantics></math> and <math id="S6.T7.8.m4.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.8.m4.1b"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.8.m4.1.1" xref="S6.T7.8.m4.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.8.m4.1c"><ci id="S6.T7.8.m4.1.1.cmml" xref="S6.T7.8.m4.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.8.m4.1d">\downarrow</annotation></semantics></math> represent the increase or decrease in values compared to the baseline.
</figcaption>
<div id="S6.T7.36" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:424.9pt;height:91.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-122.6pt,26.3pt) scale(0.634035917322568,0.634035917322568) ;">
<table id="S6.T7.36.28" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T7.36.28.29.1" class="ltx_tr">
<th id="S6.T7.36.28.29.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S6.T7.36.28.29.1.1.1" class="ltx_text">Accuracy</span></th>
<th id="S6.T7.36.28.29.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="4">FedAvg</th>
<th id="S6.T7.36.28.29.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="4">FedPAQ</th>
</tr>
<tr id="S6.T7.36.28.30.2" class="ltx_tr">
<th id="S6.T7.36.28.30.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Baseline</th>
<th id="S6.T7.36.28.30.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Gaussian Augmentation</th>
<th id="S6.T7.36.28.30.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">RandomCrop</th>
<th id="S6.T7.36.28.30.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">RandomFlip</th>
<th id="S6.T7.36.28.30.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Baseline</th>
<th id="S6.T7.36.28.30.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Gaussian Augmentation</th>
<th id="S6.T7.36.28.30.2.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">RandomCrop</th>
<th id="S6.T7.36.28.30.2.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">RandomFlip</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T7.15.7.7" class="ltx_tr">
<th id="S6.T7.9.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Test <math id="S6.T7.9.1.1.1.m1.1" class="ltx_Math" alttext="\Uparrow" display="inline"><semantics id="S6.T7.9.1.1.1.m1.1a"><mo stretchy="false" id="S6.T7.9.1.1.1.m1.1.1" xref="S6.T7.9.1.1.1.m1.1.1.cmml">⇑</mo><annotation-xml encoding="MathML-Content" id="S6.T7.9.1.1.1.m1.1b"><ci id="S6.T7.9.1.1.1.m1.1.1.cmml" xref="S6.T7.9.1.1.1.m1.1.1">⇑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.9.1.1.1.m1.1c">\Uparrow</annotation></semantics></math>
</th>
<td id="S6.T7.15.7.7.8" class="ltx_td ltx_align_center ltx_border_t">66.81</td>
<td id="S6.T7.10.2.2.2" class="ltx_td ltx_align_center ltx_border_t">59.72 <math id="S6.T7.10.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.10.2.2.2.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.10.2.2.2.m1.1.1" xref="S6.T7.10.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.10.2.2.2.m1.1b"><ci id="S6.T7.10.2.2.2.m1.1.1.cmml" xref="S6.T7.10.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.10.2.2.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T7.11.3.3.3" class="ltx_td ltx_align_center ltx_border_t">73.15 <math id="S6.T7.11.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T7.11.3.3.3.m1.1a"><mo mathcolor="#00FF00" stretchy="false" id="S6.T7.11.3.3.3.m1.1.1" xref="S6.T7.11.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T7.11.3.3.3.m1.1b"><ci id="S6.T7.11.3.3.3.m1.1.1.cmml" xref="S6.T7.11.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.11.3.3.3.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S6.T7.12.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">70.45 <math id="S6.T7.12.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T7.12.4.4.4.m1.1a"><mo mathcolor="#00FF00" stretchy="false" id="S6.T7.12.4.4.4.m1.1.1" xref="S6.T7.12.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T7.12.4.4.4.m1.1b"><ci id="S6.T7.12.4.4.4.m1.1.1.cmml" xref="S6.T7.12.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.12.4.4.4.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S6.T7.15.7.7.9" class="ltx_td ltx_align_center ltx_border_t">58.82</td>
<td id="S6.T7.13.5.5.5" class="ltx_td ltx_align_center ltx_border_t">47.31 <math id="S6.T7.13.5.5.5.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.13.5.5.5.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.13.5.5.5.m1.1.1" xref="S6.T7.13.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.13.5.5.5.m1.1b"><ci id="S6.T7.13.5.5.5.m1.1.1.cmml" xref="S6.T7.13.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.13.5.5.5.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T7.14.6.6.6" class="ltx_td ltx_align_center ltx_border_t">61.25 <math id="S6.T7.14.6.6.6.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T7.14.6.6.6.m1.1a"><mo mathcolor="#00FF00" stretchy="false" id="S6.T7.14.6.6.6.m1.1.1" xref="S6.T7.14.6.6.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T7.14.6.6.6.m1.1b"><ci id="S6.T7.14.6.6.6.m1.1.1.cmml" xref="S6.T7.14.6.6.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.14.6.6.6.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S6.T7.15.7.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">61.45 <math id="S6.T7.15.7.7.7.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T7.15.7.7.7.m1.1a"><mo mathcolor="#00FF00" stretchy="false" id="S6.T7.15.7.7.7.m1.1.1" xref="S6.T7.15.7.7.7.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T7.15.7.7.7.m1.1b"><ci id="S6.T7.15.7.7.7.m1.1.1.cmml" xref="S6.T7.15.7.7.7.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.15.7.7.7.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T7.22.14.14" class="ltx_tr">
<th id="S6.T7.16.8.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">MEM <math id="S6.T7.16.8.8.1.m1.1" class="ltx_Math" alttext="\Downarrow" display="inline"><semantics id="S6.T7.16.8.8.1.m1.1a"><mo stretchy="false" id="S6.T7.16.8.8.1.m1.1.1" xref="S6.T7.16.8.8.1.m1.1.1.cmml">⇓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.16.8.8.1.m1.1b"><ci id="S6.T7.16.8.8.1.m1.1.1.cmml" xref="S6.T7.16.8.8.1.m1.1.1">⇓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.16.8.8.1.m1.1c">\Downarrow</annotation></semantics></math>
</th>
<td id="S6.T7.22.14.14.8" class="ltx_td ltx_align_center">65.50</td>
<td id="S6.T7.17.9.9.2" class="ltx_td ltx_align_center">63.72 <math id="S6.T7.17.9.9.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.17.9.9.2.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.17.9.9.2.m1.1.1" xref="S6.T7.17.9.9.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.17.9.9.2.m1.1b"><ci id="S6.T7.17.9.9.2.m1.1.1.cmml" xref="S6.T7.17.9.9.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.17.9.9.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T7.18.10.10.3" class="ltx_td ltx_align_center">53.45 <math id="S6.T7.18.10.10.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.18.10.10.3.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.18.10.10.3.m1.1.1" xref="S6.T7.18.10.10.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.18.10.10.3.m1.1b"><ci id="S6.T7.18.10.10.3.m1.1.1.cmml" xref="S6.T7.18.10.10.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.18.10.10.3.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T7.19.11.11.4" class="ltx_td ltx_align_center ltx_border_r">62.06 <math id="S6.T7.19.11.11.4.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.19.11.11.4.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.19.11.11.4.m1.1.1" xref="S6.T7.19.11.11.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.19.11.11.4.m1.1b"><ci id="S6.T7.19.11.11.4.m1.1.1.cmml" xref="S6.T7.19.11.11.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.19.11.11.4.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T7.22.14.14.9" class="ltx_td ltx_align_center">57.13</td>
<td id="S6.T7.20.12.12.5" class="ltx_td ltx_align_center">52.02 <math id="S6.T7.20.12.12.5.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.20.12.12.5.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.20.12.12.5.m1.1.1" xref="S6.T7.20.12.12.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.20.12.12.5.m1.1b"><ci id="S6.T7.20.12.12.5.m1.1.1.cmml" xref="S6.T7.20.12.12.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.20.12.12.5.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T7.21.13.13.6" class="ltx_td ltx_align_center">51.27 <math id="S6.T7.21.13.13.6.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.21.13.13.6.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.21.13.13.6.m1.1.1" xref="S6.T7.21.13.13.6.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.21.13.13.6.m1.1b"><ci id="S6.T7.21.13.13.6.m1.1.1.cmml" xref="S6.T7.21.13.13.6.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.21.13.13.6.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T7.22.14.14.7" class="ltx_td ltx_align_center ltx_border_r">52.54 <math id="S6.T7.22.14.14.7.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.22.14.14.7.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.22.14.14.7.m1.1.1" xref="S6.T7.22.14.14.7.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.22.14.14.7.m1.1b"><ci id="S6.T7.22.14.14.7.m1.1.1.cmml" xref="S6.T7.22.14.14.7.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.22.14.14.7.m1.1c">\downarrow</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T7.36.28.31.1" class="ltx_tr">
<th id="S6.T7.36.28.31.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_tt" rowspan="2"><span id="S6.T7.36.28.31.1.1.1" class="ltx_text">Accuracy</span></th>
<th id="S6.T7.36.28.31.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="4">FedMD</th>
<th id="S6.T7.36.28.31.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="4">FedED</th>
</tr>
<tr id="S6.T7.36.28.32.2" class="ltx_tr">
<th id="S6.T7.36.28.32.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Baseline</th>
<th id="S6.T7.36.28.32.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Gaussian Augmentation</th>
<th id="S6.T7.36.28.32.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">RandomCrop</th>
<th id="S6.T7.36.28.32.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">RandomFlip</th>
<th id="S6.T7.36.28.32.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Baseline</th>
<th id="S6.T7.36.28.32.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Gaussian Augmentation</th>
<th id="S6.T7.36.28.32.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">RandomCrop</th>
<th id="S6.T7.36.28.32.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">RandomFlip</th>
</tr>
<tr id="S6.T7.29.21.21" class="ltx_tr">
<th id="S6.T7.23.15.15.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Test <math id="S6.T7.23.15.15.1.m1.1" class="ltx_Math" alttext="\Uparrow" display="inline"><semantics id="S6.T7.23.15.15.1.m1.1a"><mo stretchy="false" id="S6.T7.23.15.15.1.m1.1.1" xref="S6.T7.23.15.15.1.m1.1.1.cmml">⇑</mo><annotation-xml encoding="MathML-Content" id="S6.T7.23.15.15.1.m1.1b"><ci id="S6.T7.23.15.15.1.m1.1.1.cmml" xref="S6.T7.23.15.15.1.m1.1.1">⇑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.23.15.15.1.m1.1c">\Uparrow</annotation></semantics></math>
</th>
<td id="S6.T7.29.21.21.8" class="ltx_td ltx_align_center ltx_border_t">47.51</td>
<td id="S6.T7.24.16.16.2" class="ltx_td ltx_align_center ltx_border_t">31.76 <math id="S6.T7.24.16.16.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.24.16.16.2.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.24.16.16.2.m1.1.1" xref="S6.T7.24.16.16.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.24.16.16.2.m1.1b"><ci id="S6.T7.24.16.16.2.m1.1.1.cmml" xref="S6.T7.24.16.16.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.24.16.16.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T7.25.17.17.3" class="ltx_td ltx_align_center ltx_border_t">48.66 <math id="S6.T7.25.17.17.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T7.25.17.17.3.m1.1a"><mo mathcolor="#00FF00" stretchy="false" id="S6.T7.25.17.17.3.m1.1.1" xref="S6.T7.25.17.17.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T7.25.17.17.3.m1.1b"><ci id="S6.T7.25.17.17.3.m1.1.1.cmml" xref="S6.T7.25.17.17.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.25.17.17.3.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S6.T7.26.18.18.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">48.29 <math id="S6.T7.26.18.18.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T7.26.18.18.4.m1.1a"><mo mathcolor="#00FF00" stretchy="false" id="S6.T7.26.18.18.4.m1.1.1" xref="S6.T7.26.18.18.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T7.26.18.18.4.m1.1b"><ci id="S6.T7.26.18.18.4.m1.1.1.cmml" xref="S6.T7.26.18.18.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.26.18.18.4.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S6.T7.29.21.21.9" class="ltx_td ltx_align_center ltx_border_t">43.35</td>
<td id="S6.T7.27.19.19.5" class="ltx_td ltx_align_center ltx_border_t">36.90 <math id="S6.T7.27.19.19.5.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.27.19.19.5.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.27.19.19.5.m1.1.1" xref="S6.T7.27.19.19.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.27.19.19.5.m1.1b"><ci id="S6.T7.27.19.19.5.m1.1.1.cmml" xref="S6.T7.27.19.19.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.27.19.19.5.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T7.28.20.20.6" class="ltx_td ltx_align_center ltx_border_t">42.98 <math id="S6.T7.28.20.20.6.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.28.20.20.6.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.28.20.20.6.m1.1.1" xref="S6.T7.28.20.20.6.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.28.20.20.6.m1.1b"><ci id="S6.T7.28.20.20.6.m1.1.1.cmml" xref="S6.T7.28.20.20.6.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.28.20.20.6.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T7.29.21.21.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.79 <math id="S6.T7.29.21.21.7.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T7.29.21.21.7.m1.1a"><mo mathcolor="#00FF00" stretchy="false" id="S6.T7.29.21.21.7.m1.1.1" xref="S6.T7.29.21.21.7.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T7.29.21.21.7.m1.1b"><ci id="S6.T7.29.21.21.7.m1.1.1.cmml" xref="S6.T7.29.21.21.7.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.29.21.21.7.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T7.36.28.28" class="ltx_tr">
<th id="S6.T7.30.22.22.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">MEM <math id="S6.T7.30.22.22.1.m1.1" class="ltx_Math" alttext="\Downarrow" display="inline"><semantics id="S6.T7.30.22.22.1.m1.1a"><mo stretchy="false" id="S6.T7.30.22.22.1.m1.1.1" xref="S6.T7.30.22.22.1.m1.1.1.cmml">⇓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.30.22.22.1.m1.1b"><ci id="S6.T7.30.22.22.1.m1.1.1.cmml" xref="S6.T7.30.22.22.1.m1.1.1">⇓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.30.22.22.1.m1.1c">\Downarrow</annotation></semantics></math>
</th>
<td id="S6.T7.36.28.28.8" class="ltx_td ltx_align_center ltx_border_b">51.75</td>
<td id="S6.T7.31.23.23.2" class="ltx_td ltx_align_center ltx_border_b">50.61 <math id="S6.T7.31.23.23.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.31.23.23.2.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.31.23.23.2.m1.1.1" xref="S6.T7.31.23.23.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.31.23.23.2.m1.1b"><ci id="S6.T7.31.23.23.2.m1.1.1.cmml" xref="S6.T7.31.23.23.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.31.23.23.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T7.32.24.24.3" class="ltx_td ltx_align_center ltx_border_b">50.49 <math id="S6.T7.32.24.24.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.32.24.24.3.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.32.24.24.3.m1.1.1" xref="S6.T7.32.24.24.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.32.24.24.3.m1.1b"><ci id="S6.T7.32.24.24.3.m1.1.1.cmml" xref="S6.T7.32.24.24.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.32.24.24.3.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T7.33.25.25.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">50.68 <math id="S6.T7.33.25.25.4.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.33.25.25.4.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.33.25.25.4.m1.1.1" xref="S6.T7.33.25.25.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.33.25.25.4.m1.1b"><ci id="S6.T7.33.25.25.4.m1.1.1.cmml" xref="S6.T7.33.25.25.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.33.25.25.4.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T7.36.28.28.9" class="ltx_td ltx_align_center ltx_border_b">50.80</td>
<td id="S6.T7.34.26.26.5" class="ltx_td ltx_align_center ltx_border_b">50.38 <math id="S6.T7.34.26.26.5.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.34.26.26.5.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.34.26.26.5.m1.1.1" xref="S6.T7.34.26.26.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.34.26.26.5.m1.1b"><ci id="S6.T7.34.26.26.5.m1.1.1.cmml" xref="S6.T7.34.26.26.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.34.26.26.5.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T7.35.27.27.6" class="ltx_td ltx_align_center ltx_border_b">50.14 <math id="S6.T7.35.27.27.6.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.35.27.27.6.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.35.27.27.6.m1.1.1" xref="S6.T7.35.27.27.6.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.35.27.27.6.m1.1b"><ci id="S6.T7.35.27.27.6.m1.1.1.cmml" xref="S6.T7.35.27.27.6.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.35.27.27.6.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T7.36.28.28.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">50.31 <math id="S6.T7.36.28.28.7.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T7.36.28.28.7.m1.1a"><mo mathcolor="#FF0000" stretchy="false" id="S6.T7.36.28.28.7.m1.1.1" xref="S6.T7.36.28.28.7.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T7.36.28.28.7.m1.1b"><ci id="S6.T7.36.28.28.7.m1.1.1.cmml" xref="S6.T7.36.28.28.7.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.36.28.28.7.m1.1c">\downarrow</annotation></semantics></math>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S6.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.4.2 </span>Data Perturbation</h4>

<div id="S6.SS4.SSS2.p1" class="ltx_para">
<p id="S6.SS4.SSS2.p1.1" class="ltx_p">To present effective defense methods against privacy attacks while avoiding negative impacts on the utility, recent studies have adopted data perturbation and augmentation to defend against the membership inference attacks by mitigating the overfitting effect of local training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib178" title="" class="ltx_ref">178</a>, <a href="#bib.bib179" title="" class="ltx_ref">179</a>]</cite>.
In this part, we choose three representative methods for evaluation, including Gaussian augmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib180" title="" class="ltx_ref">180</a>]</cite>, RandomCrop <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib181" title="" class="ltx_ref">181</a>]</cite>, and RandomFlip <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib181" title="" class="ltx_ref">181</a>]</cite>.
Specifically, Gaussian augmentation incorporates the Gaussian noise into the input data for randomized smoothing.
RandomCrop crops the images at a random location, while RandomFlip randomly flips the input image horizontally or vertically.
Table <a href="#S6.T7" title="TABLE VII ‣ 6.4.1 Differential Privacy ‣ 6.4 Effectiveness of Defense Methods ‣ 6 Experiments ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VII</span></a> presents the test accuracy and membership inference accuracy of the four FL methods with or without data perturbation. We see that all the three data perturbation methods provide better privacy guarantees against membership inference attacks.
This is because all these technologies modify the training samples and thus reduce the overfitting impact on local models.
However, Gaussian augmentation results in a decrease in test accuracy, since it introduces Gaussian noise into the real samples.
In contrast, commonly used data augmentation technologies, such as RandomCrop and RandomFlip, have the potential to improve model utility.
Specifically, RandomCrop provides a wider range of variations in object positions and scales, and RandomFlip augments the input data by flipping them in different directions, both of which enhance the generalization ability of the models and thus improve the model performance.</p>
</div>
<figure id="S6.F8" class="ltx_figure"><img src="/html/2307.10655/assets/radar_chart_cifar10.png" id="S6.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="466" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>The accuracy, communication cost, and privacy leakage of different FL methods in the CIFAR-10 classification task with <math id="S6.F8.2.m1.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S6.F8.2.m1.1b"><mrow id="S6.F8.2.m1.1.1" xref="S6.F8.2.m1.1.1.cmml"><mi id="S6.F8.2.m1.1.1.2" xref="S6.F8.2.m1.1.1.2.cmml">α</mi><mo id="S6.F8.2.m1.1.1.1" xref="S6.F8.2.m1.1.1.1.cmml">=</mo><mn id="S6.F8.2.m1.1.1.3" xref="S6.F8.2.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F8.2.m1.1c"><apply id="S6.F8.2.m1.1.1.cmml" xref="S6.F8.2.m1.1.1"><eq id="S6.F8.2.m1.1.1.1.cmml" xref="S6.F8.2.m1.1.1.1"></eq><ci id="S6.F8.2.m1.1.1.2.cmml" xref="S6.F8.2.m1.1.1.2">𝛼</ci><cn type="float" id="S6.F8.2.m1.1.1.3.cmml" xref="S6.F8.2.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.2.m1.1d">\alpha=0.1</annotation></semantics></math>. The communication costs are normalized by the logarithmic scale.
The normalized privacy leakage is a weighted sum of the membership inference accuracy and the FID value.</figcaption>
</figure>
</section>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Discussions and Future Works</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">After conducting a comprehensive review of the shared information in FL and analyzing extensive experimental results of representative methods, we have made several important observations and valuable findings.
In this section, we will consolidate this wealth of information into a series of meaningful insights and highlight promising directions for future research.</p>
</div>
<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span><span id="S7.SS1.1.1" class="ltx_text ltx_font_italic">What to Share in FL</span>
</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p">In FL, sharing different types of information strikes a tradeoff between model utility, privacy leakage, and communication efficiency.
Fig. <a href="#S6.F8" title="Figure 8 ‣ 6.4.2 Data Perturbation ‣ 6.4 Effectiveness of Defense Methods ‣ 6 Experiments ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> presents a comparative analysis of representative methods.
The centralized training scheme achieves the highest accuracy, but it does not provide any privacy protection for client data.
In contrast, the model sharing method can achieve comparable accuracy to the centralized training scheme with relatively low privacy leakage, but it incurs high communication overhead.
The knowledge sharing method strikes a balance between accuracy, privacy leakage, and communication overhead.
Although its accuracy is lower than the model sharing method, it has less communication overhead and privacy leakage.
On the other hand, the performance of synthetic data sharing is very poor.
Compared with the knowledge sharing method, it has a greater degree of privacy leakage and a reduced level of accuracy.
Notably, its performance is even inferior to that of IndepTrain.
Therefore, how to effectively generate high-quality synthetic data that enhance training performance in FL while upholding robust privacy guarantees is a challenge for future research endeavors.</p>
</div>
<div id="S7.SS1.p2" class="ltx_para">
<p id="S7.SS1.p2.1" class="ltx_p">Attaining high training performance and efficiency holds significant practical value.
While each client’s private data is not shared with other participants, semi-honest participants can still potentially reconstruct private information by observing shared model information.
As a result, the primary objective of privacy preservation is to ensure that the potential privacy leakage remains below an acceptable level.
Formulating a tradeoff between model utility, privacy leakage, and efficiency is crucial to guide the choice of sharing methods in practice.
Therefore, explicitly quantifying the informativeness and privacy leakage of shared information is a crucial avenue for future research.</p>
</div>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span><span id="S7.SS2.1.1" class="ltx_text ltx_font_italic">Tradeoff in Defense</span>
</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">As verified in the experimental results, the implementation of defense mechanisms in FL often comes at the cost of performance degradation and increased overhead.
In this subsection, we will delve into the additional expenses incurred by the defense methods.</p>
</div>
<div id="S7.SS2.p2" class="ltx_para">
<p id="S7.SS2.p2.1" class="ltx_p">Cryptography-based techniques are frequently utilized to enhance privacy preservation in FL.
However, this approach may lead to a significant increase in communication overhead due to the use of encrypted messages or masks.
As noted in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite>, the overhead associated with secure aggregation protocol increases dramatically with the number of clients.
Moreover, another key challenge is the availability of clients, since clients can drop at any stage in FL.
Therefore, the cryptographic protocols need to be robust in such environments.</p>
</div>
<div id="S7.SS2.p3" class="ltx_para">
<p id="S7.SS2.p3.1" class="ltx_p">In addition, perturbation methods are often employed to safeguard private samples by introducing noise in the training process.
However, these methods inevitably reduce training performance.
For instance, defense techniques based on DP generally add a substantial amount of noise to ensure data privacy, which significantly impairs model performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>.
Moreover, DP may not provide full protection to local models against model inversion attacks.
Empirical results presented in Table <a href="#S6.T6" title="TABLE VI ‣ 6.4.1 Differential Privacy ‣ 6.4 Effectiveness of Defense Methods ‣ 6 Experiments ‣ A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a> revealed that the FID value may not increase with the use of DP protection.
The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite> offered an explanation for these findings: DP only conceals the presence of a single instance in the training set, while model inversion attacks aim to infer generic features.
Consequently, limiting the learning of individual training instances by the DP mechanism can facilitate the inference for generic features.</p>
</div>
<div id="S7.SS2.p4" class="ltx_para">
<p id="S7.SS2.p4.1" class="ltx_p">In summary, explicitly quantifying the level of privacy guarantee in FL is of utmost importance.
Precise measurement and assessment of potential risks of data breaches are essential to devise targeted solutions that offer enhanced protection to participants against privacy attacks.
Moreover, considering the system heterogeneity and dynamic channel conditions in the training process,
it is necessary but challenging to develop more efficient defense methods.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span><span id="S8.1.1" class="ltx_text ltx_font_smallcaps">Conclusions</span>
</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">FL has emerged as an innovative solution to address the privacy-preserving requirements of cutting-edge AI techniques.
Despite its numerous advantages, this novel learning paradigm still faces several challenges, including data heterogeneity, vulnerability to privacy attacks, and high communication overhead.
While recent survey articles have summarized the state-of-the-art works in FL, most of these studies primarily focused on sharing model parameters during the training process and overlooked other sharing methods.
To fill this gap, our survey presented a new taxonomy that classifies FL methods into three categories based on the type of shared information, including model sharing, synthetic data sharing, and knowledge sharing.
We provided a comprehensive review of different sharing methods, analyzing their model utility, privacy leakage, and communication efficiency.
Moreover, we conducted extensive experiments to compare the performance of these methods, which yielded valuable insights and lessons.
There are still numerous avenues to be explored with the aim of enhancing training performance while minimizing privacy risks and communication overhead.
This survey aims to serve as a comprehensive guide for researchers, facilitating their understanding of the current state-of-the-art and inspiring future studies.</p>
</div>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span><span id="S9.1.1" class="ltx_text ltx_font_smallcaps">Acknowledgement</span>
</h2>

<div id="S9.p1" class="ltx_para">
<p id="S9.p1.1" class="ltx_p">This work was supported by the Hong Kong Research Grants Council under the Areas of Excellence scheme grant AoE/E-601/22-R and NSFC/RGC Collaborative Research Scheme grant CRS_HKUST603/22.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
K. Chowdhary and K. Chowdhary, “Natural language processing,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Fundam.
Artif. Intell.</em>, pp. 603–649, Apr. 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
A. Voulodimos <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Deep learning for computer vision: A brief
review,” <em id="bib.bib2.2.2" class="ltx_emph ltx_font_italic">Comput. Intell. Neurosci.</em>, vol. 2018, Feb. 2018.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Z. Zhang, J. Geiger, J. Pohjalainen, A. E.-D. Mousa, W. Jin, and B. Schuller,
“Deep learning for environmentally robust speech recognition: An overview of
recent developments,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">ACM Trans. Intell. Syst. Technol. (TIST)</em>,
vol. 9, no. 5, pp. 1–28, Apr. 2018.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
P. Voigt and A. Von dem Bussche, <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">The EU general data protection
regulation (GDPR)</em>.   Springer, 2017.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
S. L. Pardau, “The California consumer privacy act: Towards a
European-style privacy regime in the United States?” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">J.
Technol Law Policy</em>, vol. 23, Jun. 2018.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Artif. Intell. Statist. (AISTATS)</em>, Ft.
Lauderdale, FL, USA, Apr. 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith,
“Federated optimization in heterogeneous networks,” in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proc. Mach.
Learn. Syst. (MLSys)</em>, Austin, TX, USA, Mar. 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,
A. Courville, and Y. Bengio, “Generative adversarial networks,”
<em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Commun. ACM</em>, vol. 63, no. 11, pp. 139–144, Nov. 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
S. Lee, S. Chun, S. Jung, S. Yun, and S. Yoon, “Dataset condensation with
contrastive signals,” in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Mach. Learn. (ICML)</em>,
Baltimore, MD, USA, Jul. 2022, pp. 12 352–12 364.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
E. Jeong, S. Oh, H. Kim, J. Park, M. Bennis, and S.-L. Kim,
“Communication-efficient on-device machine learning: Federated distillation
and augmentation under non-IID private data,” [Online]. Available:
<a target="_blank" href="https://arxiv.org/pdf/1811.11479.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/1811.11479.pdf</a>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
H. Seo, J. Park, S. Oh, M. Bennis, and S.-L. Kim, “Federated knowledge
distillation,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Mach. Learn. Wireless Commun.</em>, pp. 457–485, Jun.
2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Y. Tan <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “FedProto: Federated prototype learning across
heterogeneous clients,” in <em id="bib.bib12.2.2" class="ltx_emph ltx_font_italic">Proc. AAAI Conf. Artif. Intell. (AAAI)</em>,
Feb. 2022, pp. 8432–8440.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
T. Zhou, J. Zhang, and D. Tsang, “FedFA: Federated learning with feature
anchors to align feature and classifier for heterogeneous data,” [Online].
Available: <a target="_blank" href="https://arxiv.org/pdf/2211.09299.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/2211.09299.pdf</a>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
D. Li and J. Wang, “FedMD: Heterogenous federated learning via model
distillation,” [Online]. Available:
<a target="_blank" href="https://arxiv.org/abs/1910.03581.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1910.03581.pdf</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
D. Sui, Y. Chen, J. Zhao, Y. Jia, Y. Xie, and W. Sun, “FedED: Federated
learning via ensemble distillation for medical relation extraction,” in
<em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proc. 2020 Conf. Empirical Methods Natural Lang. Process. (EMNLP)</em>,
Nov. 2020, pp. 2118–2128.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
J. Xu, B. S. Glicksberg, C. Su, P. Walker, J. Bian, and F. Wang, “Federated
learning for healthcare informatics,” <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">J. Healthcare Inform. Res.</em>,
vol. 5, pp. 1–19, Oct. 2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
G. Long, Y. Tan, J. Jiang, and C. Zhang, “Federated learning for open
banking,” in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Federated Learning: Privacy and Incentive</em>, ser. Lecture
Notes in Computer Science.   Springer,
2020, vol. 12500, pp. 240–254.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
J. C. Jiang, B. Kantarci, S. Oktug, and T. Soyata, “Federated learning in
smart city sensing: Challenges and opportunities,” <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 20,
no. 21, p. 6230, Oct. 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Y. Zhao, M. Li, L. Lai, N. Suda, D. Civin, and V. Chandra, “Federated learning
with non-IID data,” [Online]. Available:
<a target="_blank" href="https://arxiv.org/pdf/1806.00582.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/1806.00582.pdf</a>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
J. Geiping, H. Bauermeister, H. Dröge, and M. Moeller, “Inverting
gradients-how easy is it to break privacy in federated learning?” in
<em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proc. 34th Conf. Adv. Neural Inf. Process. Syst. (NeurIPS)</em>, Dec.
2020, pp. 16 937–16 947.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
M. Fredrikson, S. Jha, and T. Ristenpart, “Model inversion attacks that
exploit confidence information and basic countermeasures,” in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proc.
22nd ACM SIGSAC Conf. Comput. Commun. Secur. (CCS)</em>, Denver, CO, USA, Oct.
2015, pp. 1322–1333.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Y. Sun, J. Shao, Y. Mao, J. H. Wang, and J. Zhang, “Semi-decentralized
federated edge learning for fast convergence on non-IID data,” in
<em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE Wireless Commun. Netw. Conf. (WCNC)</em>, Austin, TX, USA, Apr.
2022, pp. 1898–1903.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Y. Sun, J. Shao, Y. Mao, J. H. Wang, and J. Zhang, “Semi-decentralized
federated edge learning with data and device heterogeneity,” <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">IEEE
Trans. Netw. Serv. Manag.</em>, vol. 20, no. 2, pp. 1487–1501, Jun. 2023.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Y. Sun, J. Shao, Y. Mao, and J. Zhang, “Asynchronous semi-decentralized
federated edge learning for heterogeneous clients,” in <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE Int.
Conf. Commun. (ICC)</em>, Seoul, South Korea, May 2022, pp. 5196–5201.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
S. Bubeck <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Sparks of artificial general intelligence: Early
experiments with GPT-4,” [Online]. Available:
<a target="_blank" href="https://arxiv.org/pdf/2303.12712.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/2303.12712.pdf</a>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
E. Kasneci <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “ChatGPT for good? On opportunities and
challenges of large language models for education,” <em id="bib.bib26.2.2" class="ltx_emph ltx_font_italic">Learn. Individual
Differences</em>, vol. 103, p. 102274, Apr. 2023.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
A. Hilmkil, S. Callh, M. Barbieri, L. R. Sütfeld, E. L. Zec, and O. Mogren,
“Scaling federated learning for fine-tuning of large language models,” in
<em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Natural Lang. Process. Inf. Syst. (NLDB)</em>, Saarbrücken, Germany,
Jun. 2021, pp. 15–23.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
M. Chen, N. Shlezinger, H. V. Poor, Y. C. Eldar, and S. Cui,
“Communication-efficient federated learning,” <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proc. Nat. Acad. Sci.</em>,
vol. 118, no. 17, p. e2024789118, Apr. 2021.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
X. Zhang, Y. Kang, K. Chen, L. Fan, and Q. Yang, “Trading off privacy, utility
and efficiency in federated learning,” <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">ACM Trans. Intell. Syst.
Technol. (TIST)</em>, May 2023.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Z. Shen, J. Ye, A. Kang, H. Hassani, and R. Shokri, “Share your representation
only: Guaranteed improvement of the privacy-utility tradeoff in federated
learning,” in <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Learn. Repr. (ICLR)</em>, Apr. 2022.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
M. Kim, O. Günlü, and R. F. Schaefer, “Federated learning with local
differential privacy: Trade-offs between privacy, utility, and
communication,” in <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">IEEE Int. Conf. Acoust. Speech Signal Process.
(ICASSP)</em>, Toronto, ON, Canada, Jun. 2021, pp. 2650–2654.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Q. Yang, Y. Liu, T. Chen, and Y. Tong, “Federated machine learning: Concept
and applications,” <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">ACM Trans. Intell. Syst. Technol. (TIST)</em>,
vol. 10, no. 2, pp. 1–19, 2019.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, “Federated learning:
Challenges, methods, and future directions,” <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Process.
Mag.</em>, vol. 37, no. 3, pp. 50–60, May 2020.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Q. Li <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “A survey on federated learning systems: Vision, hype and
reality for data privacy and protection,” <em id="bib.bib34.2.2" class="ltx_emph ltx_font_italic">IEEE Trans. Knowl. and
Data Eng.</em>, vol. 35, no. 4, pp. 3347–3366, Apr. 2023.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
M. Aledhari, R. Razzak, R. M. Parizi, and F. Saeed, “Federated learning: A
survey on enabling technologies, protocols, and applications,” <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">IEEE
Access</em>, vol. 8, pp. 140 699–140 725, 2020.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
P. Kairouz <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Advances and open problems in federated learning,”
<em id="bib.bib36.2.2" class="ltx_emph ltx_font_italic">Found. Trends Mach. Learn.</em>, vol. 14, no. 1–2, pp. 1–210, 2021.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
H. Zhu, J. Xu, S. Liu, and Y. Jin, “Federated learning on non-IID data: A
survey,” <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Neurocomputing</em>, vol. 465, pp. 371–390, 2021.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
L. Lyu, H. Yu, and Q. Yang, “Threats to federated learning: A survey,”
[Online]. Available: <a target="_blank" href="https://arxiv.org/pdf/2003.02133.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/2003.02133.pdf</a>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
X. Yin, Y. Zhu, and J. Hu, “A comprehensive survey of privacy-preserving
federated learning: A taxonomy, review, and future directions,” <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">ACM
Comput. Surv. (CSUR)</em>, vol. 54, no. 6, pp. 1–36, Jul. 2021.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
N. Rodríguez-Barroso, D. Jiménez-López, M. V. Luzón,
F. Herrera, and E. Martínez-Cámara, “Survey on federated learning
threats: Concepts, taxonomy on attacks and defences, experimental study and
challenges,” <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Inf. Fusion</em>, vol. 90, pp. 148–173, 2023.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
O. A. Wahab, A. Mourad, H. Otrok, and T. Taleb, “Federated machine learning:
Survey, multi-level classification, desirable criteria and future directions
in communication and networking systems,” <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">IEEE Commun. Surveys
Tuts.</em>, vol. 23, no. 2, pp. 1342–1397, 2021.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
W. Y. B. Lim <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning in mobile edge networks: A
comprehensive survey,” <em id="bib.bib42.2.2" class="ltx_emph ltx_font_italic">IEEE Commun. Surveys Tuts.</em>, vol. 22, no. 3,
pp. 2031–2063, 3rd Quart. 2020.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
X. Ma, J. Zhu, Z. Lin, S. Chen, and Y. Qin, “A state-of-the-art survey on
solving non-IID data in federated learning,” <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Future Gener. Comput.
Syst.</em>, vol. 135, pp. 244–258, 2022.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Z. Wu, S. Sun, Y. Wang, M. Liu, X. Jiang, and R. Li, “Survey of knowledge
distillation in federated edge learning,” [Online]. Available:
<a target="_blank" href="https://arxiv.org/pdf/2301.05849.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/2301.05849.pdf</a>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
J. Gou, B. Yu, S. J. Maybank, and D. Tao, “Knowledge distillation: A survey,”
<em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Int. J. Comput. Vision</em>, vol. 129, no. 6, pp. 1789–1819, Jun. 2021.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
T. Yoon, S. Shin, S. J. Hwang, and E. Yang, “FedMix: Approximation of mixup
under mean augmented federated learning,” in <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Learn.
Representations (ICLR)</em>, May 2021.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
S. Hu, J. Goetz, K. Malik, H. Zhan, Z. Liu, and Y. Liu, “Fedsynth: Gradient
compression via synthetic data in federated learning,” in <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Workshop
Federated Learn. Recent Adv. New Challenges (Conjunction NeurIPS)</em>, 2022.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
S. Rezaei and X. Liu, “On the difficulty of membership inference attacks,” in
<em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE/CVF Conf. Comput. Vision Pattern Recognit. (CVPR)</em>, June
2021, pp. 7892–7900.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
B. Hitaj, G. Ateniese, and F. Perez-Cruz, “Deep models under the GAN:
Information leakage from collaborative deep learning,” in <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Proc. ACM
SIGSAC Conf. Comput. Commun. Secur. (CCS)</em>, Dallas, TX, USA, Oct. 2017, pp.
603–618.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
V. Shejwalkar and A. Houmansadr, “Manipulating the byzantine: Optimizing model
poisoning attacks and defenses for federated learning,” in <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Netw.
Distrib. Syst. Secur. Symp. (NDSS)</em>, Feb. 2021.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
M. Fang, X. Cao, J. Jia, and N. Z. Gong, “Local model poisoning attacks to
byzantine-robust federated learning,” in <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proc. USENIX Conf. Secur.
Symp.</em>, 2020, pp. 1623–1640.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
S. P. Karimireddy, S. Kale, M. Mohri, S. Reddi, S. Stich, and A. T. Suresh,
“SCAFFOLD: Stochastic controlled averaging for federated learning,” in
<em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Mach. Learn. (ICML)</em>, Jul. 2020, pp. 5132–5143.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Q. Li, B. He, and D. Song, “Model-contrastive federated learning,” in
<em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE/CVF Conf. Comput. Vision Pattern Recognit. (CVPR)</em>, Jun.
2021, pp. 10 713–10 722.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
D. A. E. Acar, Y. Zhao, R. M. Navarro, M. Mattina, P. N. Whatmough, and
V. Saligrama, “Federated learning based on dynamic regularization,” in
<em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Learn. Representations (ICLR)</em>, May 2021.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
M. Yurochkin, M. Agarwal, S. Ghosh, K. Greenewald, N. Hoang, and Y. Khazaeni,
“Bayesian nonparametric federated learning of neural networks,” in
<em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Mach. Learn. (ICML)</em>, vol. 97, Jun. 2019, pp.
7252–7261.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
H. Wang, M. Yurochkin, Y. Sun, D. Papailiopoulos, and Y. Khazaeni, “Federated
learning with matched averaging,” in <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Learn.
Representations (ICLR)</em>, Apr. 2020.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
D. Alistarh, D. Grubic, J. Li, R. Tomioka, and M. Vojnovic, “QSGD:
Communication-efficient SGD via gradient quantization and encoding,” in
<em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">Proc. Adv. Neural Inf. Process. Syst. (NeurIPS)</em>, vol. 30, Dec. 2017.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
A. Reisizadeh, A. Mokhtari, H. Hassani, A. Jadbabaie, and R. Pedarsani,
“FedPAQ: A communication-efficient federated learning method with periodic
averaging and quantization,” in <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">Proc. of Int. Conf. Artif. Intell.
Statist. (AISTATS)</em>, Aug. 2020, pp. 2021–2031.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
D. Jhunjhunwala, A. Gadhikar, G. Joshi, and Y. C. Eldar, “Adaptive
quantization of model updates for communication-efficient federated
learning,” in <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE Int. Conf. Acoust. Speech Signal Process.
(ICASSP)</em>, Toronto, ON, Canada, Jun. 2021, pp. 3110–3114.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
S. Shi <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “A distributed synchronous SGD algorithm with global
top-k sparsification for low bandwidth networks,” in <em id="bib.bib60.2.2" class="ltx_emph ltx_font_italic">IEEE Int. Conf.
Distrib. Comput. Syst. (ICDCS)</em>, Dallas, TX, USA, Jul. 2019, pp. 2238–2247.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
P. Han, S. Wang, and K. K. Leung, “Adaptive gradient sparsification for
efficient federated learning: An online learning approach,” in <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">IEEE
Int. Conf. Distrib. Comput. Syst. (ICDCS)</em>, Singap., Jul. 2020, pp. 300–310.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
R. Hu, Y. Gong, and Y. Guo, “Federated learning with sparsification-amplified
privacy and adaptive optimization,” in <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Joint Conf. Artif.
Intell. (IJCAI)</em>, Montreal, QC, Canada, Aug. 2021, pp. 1463–1469.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
P. Liu, X. Yu, and J. T. Zhou, “Meta knowledge condensation for federated
learning,” [Online]. Available: <a target="_blank" href="https://arxiv.org/pdf/2209.14851.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/2209.14851.pdf</a>.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
S.-W. Kim and D.-W. Choi, “Stable federated learning with dataset
condensation.” <em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">J. Comput. Sci. Eng.</em>, vol. 16, no. 1, pp. 52–62, Mar.
2022.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
S. Oh, J. Park, E. Jeong, H. Kim, M. Bennis, and S.-L. Kim, “Mix2FLD:
Downlink federated learning after uplink federated distillation with two-way
mixup,” <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">IEEE Commun. Lett.</em>, vol. 24, no. 10, pp. 2211–2215, Jun.
2020.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
M. Shin, C. Hwang, J. Kim, J. Park, M. Bennis, and S.-L. Kim, “Xor mixup:
Privacy-preserving data augmentation for one-shot federated learning,”
[Online]. Available: <a target="_blank" href="https://arxiv.org/pdf/2006.05148.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/2006.05148.pdf</a>.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Z. Li, J. Shao, Y. Mao, J. H. Wang, and J. Zhang, “Federated learning with
GAN-based data synthesis for non-IID clients,” in <em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">Int. Workshop
Trustworthy Federated Learn.</em>, Mar. 2022, pp. 17–32.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
J. Shao, Y. Sun, S. Li, and J. Zhang, “DReS-FL: Dropout-resilient secure
federated learning for non-iid clients via secret data sharing,” in
<em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">Proc. Adv. Neural Inf. Process. Syst. (NeurIPS)</em>, vol. 35, Dec. 2022,
pp. 10 533–10 545.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
J. So, B. Guler, and S. Avestimehr, “A scalable approach for
privacy-preserving collaborative machine learning,” <em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">Proc. Adv. Neural
Inf. Process. Syst. (NeurIPS)</em>, vol. 33, pp. 8054–8066, Dec. 2020.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Y. Sun, J. Shao, S. Li, Y. Mao, and J. Zhang, “Stochastic coded federated
learning with convergence and privacy guarantees,” in <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">IEEE Int. Symp.
Inf. Theory (ISIT)</em>, Espoo, Finland, Aug. 2022, pp. 2028–2033.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Y. Sun, J. Shao, Y. Mao, S. Li, and J. Zhang, “Stochastic coded federated
learning: Theoretical analysis and incentive mechanism design,” [Online].
Available: <a target="_blank" href="https://arxiv.org/pdf/2211.04132.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/2211.04132.pdf</a>.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
N. Yoshida, T. Nishio, M. Morikura, K. Yamamoto, and R. Yonetani, “Hybrid-FL
for wireless networks: Cooperative learning mechanism using non-IID data,”
in <em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE Int. Conf. Commun. (ICC)</em>, 2020, pp. 1–7.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
P. Tian, Z. Chen, W. Yu, and W. Liao, “Towards asynchronous federated learning
based threat detection: A dc-adam approach,” <em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">Computers &amp; Security</em>,
vol. 108, p. 102344, Jun. 2021.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
A. Mora, I. Tenison, P. Bellavista, and I. Rish, “Knowledge distillation for
federated learning: a practical guide,” [Online]. Available:
<a target="_blank" href="https://arxiv.org/pdf/2211.04742.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/2211.04742.pdf</a>.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
D. Wang, N. Zhang, M. Tao, and X. Chen, “Knowledge selection and local
updating optimization for federated knowledge distillation with heterogeneous
models,” <em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">IEEE J. Sel. Areas Commun.</em>, vol. 17, no. 1, pp. 82–97,
Jan. 2023.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
H. Chang, V. Shejwalkar, R. Shokri, and A. Houmansadr, “Cronus: Robust and
heterogeneous collaborative learning with black-box knowledge transfer,”
[Online]. Available: <a target="_blank" href="https://arxiv.org/pdf/1912.11279.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/1912.11279.pdf</a>.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
S. Itahara, T. Nishio, Y. Koda, M. Morikura, and K. Yamamoto,
“Distillation-based semi-supervised federated learning for
communication-efficient collaborative training with non-iid private data,”
<em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Mobile Comput.</em>, vol. 22, no. 1, pp. 191–205, Mar. 2021.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
F. Sattler, A. Marban, R. Rischke, and W. Samek, “CFD:
Communication-efficient federated distillation via soft-label quantization
and delta coding,” <em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Netw. Sci. Eng.</em>, vol. 9, no. 4, pp.
2025–2038, May 2021.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
X. Gong <em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Ensemble attention distillation for privacy-preserving
federated learning,” in <em id="bib.bib79.2.2" class="ltx_emph ltx_font_italic">Proc. IEEE/CVF Int. Conf. Comput. Vision
(CVPR)</em>, Montreal, QC, Canada, Oct. 2021, pp. 15 076–15 086.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
C. He, M. Annavaram, and S. Avestimehr, “Group knowledge transfer: Federated
learning of large cnns at the edge,” in <em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">Proc. Adv. Neural Inf.
Process. Syst. (NeurIPS)</em>, vol. 33, Dec. 2022, pp. 14 068–14 080.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
L. Zhang, L. Shen, L. Ding, D. Tao, and L.-Y. Duan, “Fine-tuning global model
via data-free knowledge distillation for non-iid federated learning,” in
<em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE/CVF Conf. Comput. Vision Pattern Recognit. (CVPR)</em>, New
Orleans, Louisiana, Jun. 2022, pp. 10 174–10 183.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
Z. Zhu, J. Hong, and J. Zhou, “Data-free knowledge distillation for
heterogeneous federated learning,” in <em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Mach. Learn.
(ICML)</em>, Jul. 2021, pp. 12 878–12 889.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
S. P. Karimireddy, S. Kale, M. Mohri, S. Reddi, S. Stich, and A. T. Suresh,
“SCAFFOLD: Stochastic controlled averaging for federated learning,” in
<em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Mach. Learn. (ICML)</em>, Jul. 2020, pp. 5132–5143.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
H. T. Nguyen, V. Sehwag, S. Hosseinalipour, C. G. Brinton, M. Chiang, and H. V.
Poor, “Fast-convergent federated learning,” <em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">IEEE J. Sel. Areas
Commun.</em>, vol. 39, no. 1, pp. 201–218, 2020.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
L. Gao, H. Fu, L. Li, Y. Chen, M. Xu, and C.-Z. Xu, “Feddc: Federated learning
with non-IID data via local drift decoupling and correction,” in
<em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE/CVF Conf. Comput. Vision and Pattern Recognit. (CVPR)</em>,
New Orleans, Louisiana, Jun. 2022, pp. 10 112–10 121.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
R. Entezari, H. Sedghi, O. Saukh, and B. Neyshabur, “The role of permutation
invariance in linear mode connectivity of neural networks,” in <em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">Proc.
Int. Conf. Learn. Representations (ICLR)</em>, Apr. 2022.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
X.-C. Li <em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning with position-aware neurons,” in
<em id="bib.bib87.2.2" class="ltx_emph ltx_font_italic">Proc. IEEE/CVF Conf. Comput. Vision Pattern Recognit. (CVPR)</em>, New
Orleans, Louisiana, Jun. 2022, pp. 10 082–10 091.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
R. Thibaux and M. I. Jordan, “Hierarchical Beta processes and the indian
buffet process,” in <em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Artif. Intell. Statist.
(AISTATS)</em>, San Juan, Puerto Rico, Mar. 2007, pp. 564–571.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
H. Kuhn, “The Hungarian method for the assignment problem,” <em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">Naval
Res. logistics Quart.</em>, vol. 2, no. 1-2, pp. 83–97, 1955.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
H. Zhang, M. Cisse, Y. N. Dauphin, and D. Lopez-Paz, “Mixup: Beyond
empirical risk minimization,” in <em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Learn.
Representations (ICLR)</em>, Vancouver, BC, Canada, Apr. 2018.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
T. Wang, J.-Y. Zhu, A. Torralba, and A. A. Efros, “Dataset distillation,”
[Online]. Available: <a target="_blank" href="https://arxiv.org/pdf/1811.10959.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/1811.10959.pdf</a>.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
B. Zhao, K. R. Mopuri, and H. Bilen, “Dataset condensation with gradient
matching,” [Online]. Available: <a target="_blank" href="https://arxiv.org/pdf/2006.05929.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/2006.05929.pdf</a>.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
Y. Zhou, G. Pu, X. Ma, X. Li, and D. Wu, “Distilled one-shot federated
learning,” [Online]. Available: <a target="_blank" href="https://arxiv.org/pdf/2009.07999.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/2009.07999.pdf</a>.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
R. Song <em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning via decentralized dataset
distillation in resource-constrained edge environments,” [Online].
Available: <a target="_blank" href="https://arxiv.org/pdf/2208.11311.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/2208.11311.pdf</a>.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
Y. Xiong, R. Wang, M. Cheng, F. Yu, and C.-J. Hsieh, “FedDM: Iterative
distribution matching for communication-efficient federated learning,” in
<em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE/ACM Comput. Vision Pattern Recognit. (CVPR)</em>, New Orleans,
LA, USA, Jun. 2023, pp. 16 323–16 332.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
L. Zhang, B. Shen, A. Barnawi, S. Xi, N. Kumar, and Y. Wu, “FedDPGAN:
Federated differentially private generative adversarial networks framework
for the detection of COVID-19 pneumonia,” <em id="bib.bib96.1.1" class="ltx_emph ltx_font_italic">Inf. Syst. Frontiers</em>,
vol. 23, no. 6, pp. 1403–1415, Jun. 2021.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
D. C. Nguyen, M. Ding, P. N. Pathirana, A. Seneviratne, and A. Y. Zomaya,
“Federated learning for COVID-19 detection with generative adversarial
networks in edge cloud computing,” <em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">IEEE Internet Things J.</em>, vol. 9,
no. 12, pp. 10 257–10 271, Oct. 2021.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
Z. Tang, Y. Zhang, S. Shi, X. He, B. Han, and X. Chu, “Virtual homogeneity
learning: Defending against data heterogeneity in federated learning,” in
<em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. on Mach. Learn. (ICML)</em>, Baltimore, MD, USA, Jul.
2022, pp. 21 111–21 132.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
I. Diakonikolas, G. Kamath, D. M. Kane, J. Li, A. Moitra, and A. Stewart,
“Being robust (in high dimensions) can be practical,” in <em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">Proc. Int.
Conf. Mach. Learn. (ICML)</em>, Sydney, NSW, Australia, Aug. 2017, pp. 999–1008.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
B. van Breugel, H. Sun, Z. Qian, and M. van der Schaar, “Membership inference
attacks against synthetic data through overfitting detection,” in
<em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Artif. Intell. Statist. (AISTATS)</em>, Palau de
Congressos, Valencia, Spain, Apr. 2023, pp. 3493–3514.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
L. Zhu, Z. Liu, and S. Han, “Deep leakage from gradients,” in <em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">Proc.
33rd Conf. Adv. Neural Inf. Process. Syst. (NeurIPS)</em>, Vancouver, BC,
Canada, Dec. 2019.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
B. Zhao, K. R. Mopuri, and H. Bilen, “iDLG: Improved deep leakage from
gradients,” [Online]. Available <a target="_blank" href="https://arxiv.org/pdf/2001.02610.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/2001.02610.pdf</a>.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
H. Yin, A. Mallya, A. Vahdat, J. M. Alvarez, J. Kautz, and P. Molchanov, “See
through gradients: Image batch recovery via gradinversion,” in <em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">Proc.
IEEE/ACM Comput. Vision Pattern Recognit. (CVPR)</em>, Jun. 2021, pp.
16 337–16 346.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
L. Melis, C. Song, E. De Cristofaro, and V. Shmatikov, “Exploiting unintended
feature leakage in collaborative learning,” in <em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE Symp. Secur.
Privacy (SP)</em>, San Francisco, CA, USA, May 2019, pp. 691–706.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
G. Ateniese, L. V. Mancini, A. Spognardi, A. Villani, D. Vitali, and G. Felici,
“Hacking smart machines with smarter ones: How to extract meaningful data
from machine learning classifiers,” <em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">Int. J. Secur. Netw.</em>, vol. 10,
no. 3, pp. 137–150, Sept. 2015.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
K. Ganju, Q. Wang, W. Yang, C. A. Gunter, and N. Borisov, “Property inference
attacks on fully connected neural networks using permutation invariant
representations,” in <em id="bib.bib106.1.1" class="ltx_emph ltx_font_italic">Proc. ACM SIGSAC Conf. Comput. Commun. Secur.
(CCS)</em>, Toronto, CA, Canada, Oct. 2018, pp. 619–633.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
H. Chen <em id="bib.bib107.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Data-free learning of student networks,” in
<em id="bib.bib107.2.2" class="ltx_emph ltx_font_italic">Proc. IEEE/CVF Int. Conf. Comput. Vision (ICCV)</em>, Seoul, Korea,
Oct.–Nov. 2019, pp. 3514–3522.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
M. Fredrikson, E. Lantz, S. Jha, S. Lin, D. Page, and T. Ristenpart, “Privacy
in pharmacogenetics: An end-to-end case study of personalized warfarin
dosing,” in <em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">USENIX Secur. Symp.</em>, San Diego, CA, USA, Aug. 2014, pp.
17–32.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
Y. Zhang, R. Jia, H. Pei, W. Wang, B. Li, and D. Song, “The secret revealer:
Generative model-inversion attacks against deep neural networks,” in
<em id="bib.bib109.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE/ACM Comput. Vision Pattern Recognit. (CVPR)</em>, Seattle, WA,
USA, 2020, pp. 253–261.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
S. Chen, M. Kahla, R. Jia, and G.-J. Qi, “Knowledge-enriched distributional
model inversion attacks,” in <em id="bib.bib110.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE/CVF Int. Conf. Comput. Vision
(ICCV)</em>, Montreal, QC, Canada, Oct. 2021, pp. 16 178–16 187.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
Z. Yang, E.-C. Chang, and Z. Liang, “Adversarial neural network inversion via
auxiliary knowledge alignment,” [Online]. Available:
<a target="_blank" href="https://arxiv.org/pdf/1902.08552.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/1902.08552.pdf</a>.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
A. Dionysiou, V. Vassiliades, and E. Athanasopoulos, “Exploring model
inversion attacks in the black-box setting,” <em id="bib.bib112.1.1" class="ltx_emph ltx_font_italic">Proc. Privacy Enhancing
Technol.</em>, vol. 1, pp. 190–206, 2023.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
J. Zhang, C. Chen, and L. Lyu, “Ideal: Query-efficient data-free learning from
black-box models,” in <em id="bib.bib113.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Learn. Representations (ICLR)</em>,
Kigali Rwanda, May 2023.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
M. Nasr, R. Shokri, and A. Houmansadr, “Comprehensive privacy analysis of deep
learning: Passive and active white-box inference attacks against centralized
and federated learning,” in <em id="bib.bib114.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE Symp. Secur. Privacy (SP)</em>, San
Francisco, CA, USA, May 2019, pp. 739–753.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
R. Shokri, M. Stronati, C. Song, and V. Shmatikov, “Membership inference
attacks against machine learning models,” in <em id="bib.bib115.1.1" class="ltx_emph ltx_font_italic">Proc. 2017 IEEE Symp.
Secur. Privacy (SP)</em>, San Jose, CA, USA, May 2017, pp. 3–18.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
A. Salem, Y. Zhang, M. Humbert, P. Berrang, M. Fritz, and M. Backes,
“ML-leaks: Model and data independent membership inference attacks and
defenses on machine learning models,” in <em id="bib.bib116.1.1" class="ltx_emph ltx_font_italic">Proc. Netw. Distrib. Syst.
Secur. (NDSS) Symp.</em>, San Diego, CA, USA, Feb. 2019.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
L. Wang, S. Xu, X. Wang, and Q. Zhu, “Eavesdrop the composition proportion of
training labels in federated learning,” [Online]. Available:
<a target="_blank" href="https://arxiv.org/pdf/1910.06044.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/1910.06044.pdf</a>.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
W. Zhang, S. Tople, and O. Ohrimenko, “Leakage of dataset properties in
multi-party machine learning.” in <em id="bib.bib118.1.1" class="ltx_emph ltx_font_italic">USENIX Secur. Symp.</em>, Jun. 2021, pp.
2687–2704.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
J. Deng <em id="bib.bib119.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “TAG: Gradient attack on transformer-based language
models,” in <em id="bib.bib119.2.2" class="ltx_emph ltx_font_italic">Findings Assoc. Comput. Linguistics (EMNLP)</em>, Punta Cana,
Dominican Republic, Nov, 2021, pp. 3600–3610.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
M. Balunovic, D. Dimitrov, N. Jovanović, and M. Vechev, “LAMP:
Extracting text from gradients with language model priors,” in <em id="bib.bib120.1.1" class="ltx_emph ltx_font_italic">Proc.
35th Conf. Adv. Neural Inf. Process. Syst. (NeurIPS)</em>, LA, CA, USA, Nov.
2022, pp. 7641–7654.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
S. Gupta, Y. Huang, Z. Zhong, T. Gao, K. Li, and D. Chen, “Recovering private
text in federated learning of language models,” in <em id="bib.bib121.1.1" class="ltx_emph ltx_font_italic">Proc. 35th Conf.
Adv. Neural Inf. Process. Syst. (NeurIPS)</em>, LA, CA, USA, Nov. 2022, pp.
8130–8143.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
H. Hu, Z. Salcic, L. Sun, G. Dobbie, P. S. Yu, and X. Zhang, “Membership
inference attacks on machine learning: A survey,” <em id="bib.bib122.1.1" class="ltx_emph ltx_font_italic">ACM Comput. Surveys
(CSUR)</em>, vol. 54, no. 11s, pp. 1–37, 2022.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
L. Song and P. Mittal, “Systematic evaluation of privacy risks of machine
learning models,” in <em id="bib.bib123.1.1" class="ltx_emph ltx_font_italic">USENIX Secur. Symp.</em>, vol. 1, no. 2, Aug. 2021,
p. 4.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
S. Yeom, I. Giacomelli, M. Fredrikson, and S. Jha, “Privacy risk in machine
learning: Analyzing the connection to overfitting,” in <em id="bib.bib124.1.1" class="ltx_emph ltx_font_italic">IEEE 31st
Comput. Secur. Found. Symp. (CSF)</em>, Oxford, UK, July 2018, pp. 268–282.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock">
K. Leino and M. Fredrikson, “Stolen memories: Leveraging model memorization
for calibrated white-box membership inference,” in <em id="bib.bib125.1.1" class="ltx_emph ltx_font_italic">29th USENIX Secur.
Symp.</em>, Aug. 2020, pp. 1605–1622.

</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[126]</span>
<span class="ltx_bibblock">
O. Zari, C. Xu, and G. Neglia, “Efficient passive membership inference attack
in federated learning,” in <em id="bib.bib126.1.1" class="ltx_emph ltx_font_italic">Proc. Conf. Adv. Neural Inf. Process. Syst.
(NeurIPS) PriML 2021-Workshop Privacy Mach. Learn.</em>, Dec. 2021.

</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[127]</span>
<span class="ltx_bibblock">
M. Xu and X. Li, “Subject property inference attack in collaborative
learning,” in <em id="bib.bib127.1.1" class="ltx_emph ltx_font_italic">Proc. 12th Int. Conf. Intell. Human-Machine Syst.
Cybern. (IHMSC)</em>, Hangzhou, China, Aug. 2020, pp. 227–231.

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[128]</span>
<span class="ltx_bibblock">
C. Fontaine and F. Galand, “A survey of homomorphic encryption for
nonspecialists,” <em id="bib.bib128.1.1" class="ltx_emph ltx_font_italic">EURASIP J. Inf. Secur.</em>, vol. 2007, pp. 1–10, Oct.
2007.

</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[129]</span>
<span class="ltx_bibblock">
T. Graepel, K. Lauter, and M. Naehrig, “Ml confidential: Machine learning on
encrypted data,” in <em id="bib.bib129.1.1" class="ltx_emph ltx_font_italic">Proc. Inf. Secur. Cryptology</em>, Seoul, Korea, Nov.
2013, pp. 1–21.

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[130]</span>
<span class="ltx_bibblock">
A. Kim, Y. Song, M. Kim, K. Lee, and J. H. Cheon, “Logistic regression model
training based on the approximate homomorphic encryption,” <em id="bib.bib130.1.1" class="ltx_emph ltx_font_italic">BMC Med.
Genomics</em>, vol. 11, no. 4, pp. 23–31, Oct. 2018.

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[131]</span>
<span class="ltx_bibblock">
K. Han, S. Hong, J. H. Cheon, and D. Park, “Logistic regression on homomorphic
encrypted data at scale,” in <em id="bib.bib131.1.1" class="ltx_emph ltx_font_italic">Proc. AAAI Conf. Artif. Intell. (AAAI)</em>,
vol. 33, no. 01, Honolulu, HI, USA, Jan. 2019, pp. 9466–9471.

</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[132]</span>
<span class="ltx_bibblock">
E. Hesamifard, H. Takabi, and M. Ghasemi, “Cryptodl: Deep neural networks over
encrypted data,” [Online]. Available:
<a target="_blank" href="https://arxiv.org/abs/1711.05189" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1711.05189</a>.

</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[133]</span>
<span class="ltx_bibblock">
R. Gilad-Bachrach, N. Dowlin, K. Laine, K. Lauter, M. Naehrig, and J. Wernsing,
“Cryptonets: Applying neural networks to encrypted data with high throughput
and accuracy,” in <em id="bib.bib133.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Mach. Learn. (ICML)</em>, New York, NY,
USA, Jun. 2016, pp. 201–210.

</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[134]</span>
<span class="ltx_bibblock">
N. Tastan and K. Nandakumar, “Capride learning: Confidential and private
decentralized learning based on encryption-friendly distillation loss,” in
<em id="bib.bib134.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE/CVF Conf. Comput. Vision Pattern Recognit. (CVPR)</em>,
Vancouver, BC, Canada, Jun. 2023, pp. 8084–8092.

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[135]</span>
<span class="ltx_bibblock">
A. Afonin and S. P. Karimireddy, “Towards model agnostic federated learning
using knowledge distillation,” in <em id="bib.bib135.1.1" class="ltx_emph ltx_font_italic">Int. Conf. Learn. Representations
(ICLR)</em>, May 2021.

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[136]</span>
<span class="ltx_bibblock">
W. Jin <em id="bib.bib136.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “FedML-HE: An efficient homomorphic-encryption-based
privacy-preserving federated learning system,” [Online]. Available:
<a target="_blank" href="https://arxiv.org/pdf/2303.10837.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/2303.10837.pdf</a>.

</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[137]</span>
<span class="ltx_bibblock">
F. Wibawa, F. O. Catak, M. Kuzlu, S. Sarp, and U. Cali, “Homomorphic
encryption and federated learning based privacy-preserving cnn training:
Covid-19 detection use-case,” in <em id="bib.bib137.1.1" class="ltx_emph ltx_font_italic">Proc. 2022 Eur. Interdisciplinary
Cybersecurity Conf.</em>, New York, NY, USA, Jun. 2022, pp. 85–90.

</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[138]</span>
<span class="ltx_bibblock">
J. Hur, “Improving security and efficiency in attribute-based data sharing,”
<em id="bib.bib138.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Knowl. Data Eng.</em>, vol. 25, no. 10, pp. 2271–2282, Apr.
2011.

</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[139]</span>
<span class="ltx_bibblock">
M. Ali <em id="bib.bib139.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “SeDaSC: secure data sharing in clouds,” <em id="bib.bib139.2.2" class="ltx_emph ltx_font_italic">IEEE
Syst. J.</em>, vol. 11, no. 2, pp. 395–404, Jun. 2015.

</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[140]</span>
<span class="ltx_bibblock">
K. Bonawitz <em id="bib.bib140.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Practical secure aggregation for
privacy-preserving machine learning,” in <em id="bib.bib140.2.2" class="ltx_emph ltx_font_italic">Proc. ACM SIGSAC Conf.
Comput. Commun. Secur. (CCS)</em>, Dallas, TX, USA, Oct. 2017, pp. 1175–1191.

</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[141]</span>
<span class="ltx_bibblock">
K. Bonawitz, F. Salehi, J. Konečnỳ, B. McMahan, and M. Gruteser,
“Federated learning with autotuned communication-efficient secure
aggregation,” in <em id="bib.bib141.1.1" class="ltx_emph ltx_font_italic">Proc. Asilomar Conf. Signals Syst. Comput.</em>, Pacific
Grove, CA, USA, Nov. 2019, pp. 1222–1226.

</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[142]</span>
<span class="ltx_bibblock">
J. So, B. Güler, and A. S. Avestimehr, “Turbo-aggregate: Breaking the
quadratic aggregation barrier in secure federated learning,” <em id="bib.bib142.1.1" class="ltx_emph ltx_font_italic">IEEE J.
Sel. Areas Inf. Theory</em>, vol. 2, no. 1, pp. 479–489, Jan. 2021.

</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[143]</span>
<span class="ltx_bibblock">
T. Jahani-Nezhad, M. A. Maddah-Ali, S. Li, and G. Caire, “SwiftAgg:
Communication-efficient and dropout-resistant secure aggregation for
federated learning with worst-case security guarantees,” in <em id="bib.bib143.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE
Int. Symp. Inf. Theory (ISIT)</em>, Espoo, Finland, Feb. 2022, pp. 103–108.

</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[144]</span>
<span class="ltx_bibblock">
T. Jahani-Nezhad, M. A. Maddah-Ali, S. Li, and G. Caire, “SwiftAgg+:
Achieving asymptotically optimal communication loads in secure aggregation
for federated learning,” <em id="bib.bib144.1.1" class="ltx_emph ltx_font_italic">IEEE J. Sel. Areas Commun.</em>, vol. 41, no. 4,
pp. 977–989, Mar. 2023.

</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[145]</span>
<span class="ltx_bibblock">
Y. Liu, Y. Kang, C. Xing, T. Chen, and Q. Yang, “A secure federated transfer
learning framework,” <em id="bib.bib145.1.1" class="ltx_emph ltx_font_italic">IEEE Intell. Syst.</em>, vol. 35, no. 4, pp. 70–82,
Apr. 2020.

</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[146]</span>
<span class="ltx_bibblock">
T. Liu, J. Xia, Z. Ling, X. Fu, S. Yu, and M. Chen, “Efficient federated
learning for AIoT applications using knowledge distillation,” <em id="bib.bib146.1.1" class="ltx_emph ltx_font_italic">IEEE
Internet Things J.</em>, vol. 10, no. 8, pp. 7229–7243, Dec. 2022.

</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[147]</span>
<span class="ltx_bibblock">
S. Zhao, Q. Zhao, C. Zhao, H. Jiang, and Q. Xu, “Privacy-enhancing machine
learning framework with private aggregation of teacher ensembles,”
<em id="bib.bib147.1.1" class="ltx_emph ltx_font_italic">Int. J. Intell. Syst.</em>, vol. 37, no. 11, pp. 9904–9920, Sept. 2022.

</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[148]</span>
<span class="ltx_bibblock">
M. Abadi <em id="bib.bib148.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Deep learning with differential privacy,” in
<em id="bib.bib148.2.2" class="ltx_emph ltx_font_italic">Proc. ACM SIGSAC Conf. Comput. Commun. Secur. (CCS)</em>, Vienna, Austria,
Oct. 2016, pp. 308–318.

</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[149]</span>
<span class="ltx_bibblock">
Z. Bu, J. Dong, Q. Long, and W. J. Su, “Deep learning with gaussian
differential privacy,” <em id="bib.bib149.1.1" class="ltx_emph ltx_font_italic">Harvard Data Sci. Rev.</em>, vol. 2020, no. 23, pp.
10–1162, Nov. 2020.

</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[150]</span>
<span class="ltx_bibblock">
Q. Zheng, S. Chen, Q. Long, and W. Su, “Federated f-differential privacy,” in
<em id="bib.bib150.1.1" class="ltx_emph ltx_font_italic">Int. Conf. Artif. Intell. Statist. (AISTATS)</em>, Apr. 2021, pp.
2251–2259.

</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[151]</span>
<span class="ltx_bibblock">
K. Yadav, B. B. Gupta, K. T. Chui, and K. Psannis, “Differential privacy
approach to solve gradient leakage attack in a federated machine learning
environment,” in <em id="bib.bib151.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Comput. Data Social Netw.</em>, Dallas,
TX, USA, Dec. 2020, pp. 378–385.

</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[152]</span>
<span class="ltx_bibblock">
M. Hao, H. Li, G. Xu, S. Liu, and H. Yang, “Towards efficient and
privacy-preserving federated deep learning,” in <em id="bib.bib152.1.1" class="ltx_emph ltx_font_italic">IEEE Int. Conf.
Commun. (ICC)</em>, Shanghai, China, May 2019.

</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[153]</span>
<span class="ltx_bibblock">
W. Wei, L. Liu, Y. Wut, G. Su, and A. Iyengar, “Gradient-leakage resilient
federated learning,” in <em id="bib.bib153.1.1" class="ltx_emph ltx_font_italic">IEEE Int. Conf. Distrib. Comput. Syst.
(ICDCS)</em>, Jul. 2021, pp. 797–807.

</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[154]</span>
<span class="ltx_bibblock">
L. Fan <em id="bib.bib154.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Rethinking privacy preserving deep learning: How to
evaluate and thwart privacy attacks,” <em id="bib.bib154.2.2" class="ltx_emph ltx_font_italic">Federated Learn. Privacy
Incentive</em>, pp. 32–50, Nov. 2020.

</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[155]</span>
<span class="ltx_bibblock">
J. Sun, A. Li, B. Wang, H. Yang, H. Li, and Y. Chen, “Soteria: Provable
defense against privacy leakage in federated learning from representation
perspective,” in <em id="bib.bib155.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE/ACM Comput. Vision Pattern Recognit.
(CVPR)</em>, Jun. 2021, pp. 9311–9319.

</span>
</li>
<li id="bib.bib156" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[156]</span>
<span class="ltx_bibblock">
M. Zhang and S. Wang, “Matrix sketching for secure collaborative machine
learning,” in <em id="bib.bib156.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Mach. Learn. (ICML)</em>, Jul. 2021, pp.
12 589–12 599.

</span>
</li>
<li id="bib.bib157" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[157]</span>
<span class="ltx_bibblock">
X. Cao, J. Jia, and N. Z. Gong, “Data poisoning attacks to local differential
privacy protocols,” in <em id="bib.bib157.1.1" class="ltx_emph ltx_font_italic">USENIX Secur. Symp.</em>, Aug. 2021.

</span>
</li>
<li id="bib.bib158" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[158]</span>
<span class="ltx_bibblock">
X. Yang <em id="bib.bib158.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “An accuracy-lossless perturbation method for defending
privacy attacks in federated learning,” in <em id="bib.bib158.2.2" class="ltx_emph ltx_font_italic">Proc. ACM Web Conf.</em>, Lyon,
France, Apr. 2022, pp. 732–742.

</span>
</li>
<li id="bib.bib159" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[159]</span>
<span class="ltx_bibblock">
S.-W. Kim and D.-W. Choi, “Stable federated learning with dataset
condensation,” <em id="bib.bib159.1.1" class="ltx_emph ltx_font_italic">J. Comput. Sci. Eng.</em>, vol. 16, no. 1, pp. 52–62, Mar.
2022.

</span>
</li>
<li id="bib.bib160" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[160]</span>
<span class="ltx_bibblock">
N. Papernot, M. Abadi, Ú. Erlingsson, I. Goodfellow, and K. Talwar,
“Semi-supervised knowledge transfer for deep learning from private training
data,” in <em id="bib.bib160.1.1" class="ltx_emph ltx_font_italic">Int. Conf. Learn. Representations (ICLR)</em>, Toulon, France,
Apr. 2017.

</span>
</li>
<li id="bib.bib161" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[161]</span>
<span class="ltx_bibblock">
N. Papernot, S. Song, I. Mironov, A. Raghunathan, K. Talwar, and U. Erlingsson,
“Scalable private learning with pate,” in <em id="bib.bib161.1.1" class="ltx_emph ltx_font_italic">Int. Conf. Learn.
Representations (ICLR)</em>, Vancouver, BC, Canada, Apr. 2018.

</span>
</li>
<li id="bib.bib162" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[162]</span>
<span class="ltx_bibblock">
Y. Zhu, X. Yu, M. Chandraker, and Y.-X. Wang, “Private-knn: Practical
differential privacy for computer vision,” in <em id="bib.bib162.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE/CVF Conf.
Comput. Vision Pattern Recognit. (CVPR)</em>, Jun. 2020, pp. 11 854–11 862.

</span>
</li>
<li id="bib.bib163" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[163]</span>
<span class="ltx_bibblock">
Y. Zhu <em id="bib.bib163.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Voting-based approaches for differentially private
federated learning,” in <em id="bib.bib163.2.2" class="ltx_emph ltx_font_italic">Workshop Federated Learn. Recent Adv. and New
Challenges Conjunction NeurIPS</em>, New Orleans, LA, USA, Nov. 2020.

</span>
</li>
<li id="bib.bib164" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[164]</span>
<span class="ltx_bibblock">
L. Sun and L. Lyu, “Federated model distillation with noise-free differential
privacy,” in <em id="bib.bib164.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Joint Conf Artif. Intell (IJCAI)</em>, Aug.
2021, pp. 1563–1570.

</span>
</li>
<li id="bib.bib165" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[165]</span>
<span class="ltx_bibblock">
J. Li, X. Wu, W. Dong, S. Wu, C. Bian, and D. Xiong, “Swing distillation: A
privacy-preserving knowledge distillation framework,” [Online]. Available:
<a target="_blank" href="https://arxiv.org/abs/2212.08349" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2212.08349</a>.

</span>
</li>
<li id="bib.bib166" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[166]</span>
<span class="ltx_bibblock">
X. Gong <em id="bib.bib166.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Preserving privacy in federated learning with ensemble
cross-domain knowledge distillation,” in <em id="bib.bib166.2.2" class="ltx_emph ltx_font_italic">Proc. AAAI Conf. Artif.
Intell. (AAAI)</em>, vol. 36, no. 11, Feb. 2022, pp. 11 891–11 899.

</span>
</li>
<li id="bib.bib167" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[167]</span>
<span class="ltx_bibblock">
C. Dwork, “Differential privacy,” in <em id="bib.bib167.1.1" class="ltx_emph ltx_font_italic">Proc. Automata, Languages Program.
Int. Colloq.</em>, Venice, Italy, Jul. 2006, pp. 1–12.

</span>
</li>
<li id="bib.bib168" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[168]</span>
<span class="ltx_bibblock">
Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and A. Y. Ng, “Reading
digits in natural images with unsupervised feature learning,” [Online].
Available: <a target="_blank" href="https://research.google/pubs/pub37648/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://research.google/pubs/pub37648/</a>.

</span>
</li>
<li id="bib.bib169" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[169]</span>
<span class="ltx_bibblock">
A. Krizhevsky, “Learning multiple layers of features from tiny images,”
[Online]. Available:
<a target="_blank" href="https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf</a>.

</span>
</li>
<li id="bib.bib170" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[170]</span>
<span class="ltx_bibblock">
A. Baldominos, Y. Saez, and P. Isasi, “A survey of handwritten character
recognition with mnist and emnist,” <em id="bib.bib170.1.1" class="ltx_emph ltx_font_italic">Appl. Sci.</em>, vol. 9, no. 15, p.
3169, Aug. 2019.

</span>
</li>
<li id="bib.bib171" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[171]</span>
<span class="ltx_bibblock">
Y. Le and X. Yang, “Tiny imagenet visual recognition challenge,” [Online].
Available:
<a target="_blank" href="http://cs231n.stanford.edu/reports/2015/pdfs/yle_project.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://cs231n.stanford.edu/reports/2015/pdfs/yle_project.pdf</a>.

</span>
</li>
<li id="bib.bib172" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[172]</span>
<span class="ltx_bibblock">
A. Creswell, T. White, V. Dumoulin, K. Arulkumaran, B. Sengupta, and A. A.
Bharath, “Generative adversarial networks: An overview,” <em id="bib.bib172.1.1" class="ltx_emph ltx_font_italic">IEEE Signal
process. Mag.</em>, vol. 35, no. 1, pp. 53–65, Jan. 2018.

</span>
</li>
<li id="bib.bib173" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[173]</span>
<span class="ltx_bibblock">
M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter, “GANs
trained by a two time-scale update rule converge to a local nash
equilibrium,” in <em id="bib.bib173.1.1" class="ltx_emph ltx_font_italic">Proc. Adv. Neural Inf. Process. Syst. (NeurIPS)</em>,
Long Beach, CA, USA, Dec. 2017.

</span>
</li>
<li id="bib.bib174" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[174]</span>
<span class="ltx_bibblock">
D. Wang, N. Zhang, M. Tao, and X. Chen, “Knowledge selection and local
updating optimization for federated knowledge distillation with heterogeneous
models,” <em id="bib.bib174.1.1" class="ltx_emph ltx_font_italic">IEEE J. Sel. Topics Signal Process.</em>, vol. 17, no. 1, pp.
82–97, Nov. 2022.

</span>
</li>
<li id="bib.bib175" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[175]</span>
<span class="ltx_bibblock">
J. Shao, F. Wu, and J. Zhang, “Selective knowledge sharing for
privacy-preserving federated distillation without a good teacher,” [Online].
Available: <a target="_blank" href="https://arxiv.org/abs/2304.01731.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2304.01731.pdf</a>.

</span>
</li>
<li id="bib.bib176" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[176]</span>
<span class="ltx_bibblock">
I. Mironov, “Rényi differential privacy,” in <em id="bib.bib176.1.1" class="ltx_emph ltx_font_italic">IEEE Comput. Secur.
Found. Symp (CSF)</em>, Santa Barbara, CA, USA, Aug. 2017, pp. 263–275.

</span>
</li>
<li id="bib.bib177" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[177]</span>
<span class="ltx_bibblock">
A. Yousefpour <em id="bib.bib177.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Opacus: User-friendly differential privacy
library in pytorch,” [Online]. Available:
<a target="_blank" href="https://arxiv.org/abs/2109.12298" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2109.12298</a>.

</span>
</li>
<li id="bib.bib178" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[178]</span>
<span class="ltx_bibblock">
A. Sablayrolles, M. Douze, C. Schmid, Y. Ollivier, and H. Jégou,
“White-box vs black-box: Bayes optimal strategies for membership
inference,” in <em id="bib.bib178.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Mach. Learn. (ICML)</em>, Long Beach, CA,
USA, Jul. 2019, pp. 5558–5567.

</span>
</li>
<li id="bib.bib179" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[179]</span>
<span class="ltx_bibblock">
Y. Kaya and T. Dumitras, “When does data augmentation help with membership
inference attacks?” in <em id="bib.bib179.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Mach. Learn. (ICML)</em>, Jul.
2021, pp. 5345–5355.

</span>
</li>
<li id="bib.bib180" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[180]</span>
<span class="ltx_bibblock">
J. Cohen, E. Rosenfeld, and Z. Kolter, “Certified adversarial robustness via
randomized smoothing,” in <em id="bib.bib180.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Mach. Learn. (ICML)</em>, Long
Beach, CA, USA, Jul. 2019, pp. 1310–1320.

</span>
</li>
<li id="bib.bib181" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[181]</span>
<span class="ltx_bibblock">
K. Simonyan and A. Zisserman, “Very deep convolutional networks for
large-scale image recognition,” in <em id="bib.bib181.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Learn.
Representations (ICLR)</em>, San Diego, CA, USA, May 2015.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2307.10654" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2307.10655" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2307.10655">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2307.10655" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2307.10656" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 16:35:04 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
