<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2305.12954] Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?</title><meta property="og:description" content="Diffusion models have recently achieved astonishing performance in generating high-fidelity photo-realistic images. Given their huge success, it is still unclear whether synthetic images are applicable for knowledge diâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2305.12954">

<!--Generated on Thu Feb 29 06:06:20 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Zheng Li <sup id="id1.1.id1" class="ltx_sup">1</sup> ,
Yuxuan Li <sup id="id2.2.id2" class="ltx_sup">1</sup><span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span> ,
Penghai Zhao <sup id="id3.3.id3" class="ltx_sup">1</sup>,
Renjie Song <sup id="id4.4.id4" class="ltx_sup">2</sup>,
Xiang Li <sup id="id5.5.id5" class="ltx_sup">1</sup> ,
Jian Yang <sup id="id6.6.id6" class="ltx_sup">1</sup><span id="footnotex2" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">2</span></span></span></span>
<br class="ltx_break">
<br class="ltx_break"><sup id="id7.7.id7" class="ltx_sup">1</sup> Nankai University,
<sup id="id8.8.id8" class="ltx_sup">2</sup> Megvii Technology 
<br class="ltx_break">
<br class="ltx_break"><span id="id9.9.id9" class="ltx_text ltx_font_typewriter">{zhengli97, zhaopenghai}@mail.nankai.edu.cn, yuxuan.li.17@ucl.ac.uk</span> 
<br class="ltx_break"><span id="id10.10.id10" class="ltx_text ltx_font_typewriter">songrenjie@megvii.com, {xiang.li.implus, csjyang}@nankai.edu.cn</span>
</span><span class="ltx_author_notes">Equal contributions.Corresponding author.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id11.id1" class="ltx_p">Diffusion models have recently achieved astonishing performance in generating high-fidelity photo-realistic images. Given their huge success, it is still unclear whether synthetic images are applicable for knowledge distillation when real images are unavailable. In this paper, we extensively study whether and how synthetic images produced from state-of-the-art diffusion models can be used for knowledge distillation without access to real images, and obtain three key conclusions: (1) synthetic data from diffusion models can easily lead to state-of-the-art performance among existing synthesis-based distillation methods, (2) low-fidelity synthetic images are better teaching materials, and (3) relatively weak classifiers are better teachers. Code is available at <a target="_blank" href="https://github.com/zhengli97/DM-KD" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/zhengli97/DM-KD</a>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Knowledge distillationÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">hinton2015distilling</span> </a></cite> aims to train a lightweight student model on a target dataset under the supervision of a pre-trained teacher model. Various formsÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">romero2014fitnets</span> </a>; <a href="#bib.bib65" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">zagoruyko2016paying</span> </a>; <a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">kim2018paraphrasing</span> </a>; <a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">chen2021distilling</span> </a>; <a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">chen2022improved</span> </a>; <a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">li2022curriculum</span> </a></cite> and paradigmsÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib68" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">zhang2018deep</span> </a>; <a href="#bib.bib70" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">zhu2018knowledge</span> </a>; <a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">zhang2019your</span> </a>; <a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">chen2020online</span> </a>; <a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">kim2021self</span> </a>; <a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">qian2022switchable</span> </a></cite> have been proposed to improve the efficiency of distillation.
However, training datasets might not always be available due to security and privacy concerns, which makes existing data-dependent distillation methods no longer applicable.
To address this issue, several synthesis-based distillation methods are proposed. These methods utilize either white-box teacher statisticsÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">lopes2017data</span> </a>; <a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">chen2019data</span> </a>; <a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">yin2020dreaming</span> </a>; <a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">fang2022up</span> </a></cite> or data augmentation techniquesÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">asano2023the</span> </a></cite> to generate synthetic samples that serve as proxy training datasets for distillation. By training on such synthetic data, the student model can successfully learn from the teacher model without access to real training data.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Recently, diffusion modelsÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">ho2020denoising</span> </a>; <a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">saharia2022imagen</span> </a>; <a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">ramesh2021zero</span> </a>; <a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">ramesh2022hierarchical</span> </a></cite> are attracting increasing attention in image generation tasks. Several high-performance diffusion models, including GLIDEÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">nichol2021glide</span> </a></cite>, Stable DiffusionÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">rombach2022high</span> </a></cite>, and DiTÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">peebles2022scalable</span> </a></cite>, have demonstrated impressive abilities to generate high-fidelity photo-realistic images at high resolutions. This leads to a natural question: Can these synthetic images be used for downstream tasks?
He et al.Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">he2023is</span> </a></cite> made the first attempt using synthetic data to improve the zero-shot and few-shot recognition performance of a classifier. Azizi et al.Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">azizi2023synthetic</span> </a></cite> utilized the diffusion model as a generative data augmentation method to increase the scale of existing datasets.
However, to our best knowledge, few works have explored the impact of diffusion generative models on knowledge distillation.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this paper, we aim to investigate whether and how synthetic images generated from state-of-the-art diffusion models can be utilized for knowledge distillation without access to real images. Through our research, we have identified three key findings, which are outlined below:</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p"><span id="S1.p4.1.1" class="ltx_text ltx_font_bold">(1) Synthetic data from diffusion models can easily lead to state-of-the-art performance among existing synthesis-based distillation methods.</span>
Our proposed approach differs from previous synthesis-based distillation methods by eliminating the need to design complex and precise generative methods based on the white-box teacher model or the careful selection of a single datum. Instead, we leverage publicly available state-of-the-art diffusion models to generate a proxy dataset for distillation, even when the teacher model is a black box.
As a result, our method achieves state-of-the-art performance across multiple datasets, including ImageNet-1K, ImageNet-100, CIFAR-100, and Flowers-102 datasets. Notably, our method can effectively transfer knowledge in the target dataset from the teacher model to the student model, even when there is no intersection of categories between the synthetic dataset and the target dataset.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.4" class="ltx_p"><span id="S1.p5.4.1" class="ltx_text ltx_font_bold">(2) Low-fidelity synthetic images are better teaching materials.</span>
While existing diffusion models have demonstrated an impressive ability to generate high-fidelity and realistic images, our experiments suggest that higher image fidelity does not necessarily lead to better distillation performance. On the contrary, our experimental results indicate that relatively low-fidelity images, as assessed by the ImageReward scoreÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">xu2023imagereward</span> </a></cite>, are better learning materials for students during the distillation process.
Specifically, for conditional diffusion models, our experiments suggest that the relatively <em id="S1.p5.4.2" class="ltx_emph ltx_font_italic">small</em> guidance scaling factorÂ (<math id="S1.p5.1.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S1.p5.1.m1.1a"><mi id="S1.p5.1.m1.1.1" xref="S1.p5.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S1.p5.1.m1.1b"><ci id="S1.p5.1.m1.1.1.cmml" xref="S1.p5.1.m1.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.1.m1.1c">s</annotation></semantics></math>) and sampling time stepÂ (<math id="S1.p5.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S1.p5.2.m2.1a"><mi id="S1.p5.2.m2.1.1" xref="S1.p5.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S1.p5.2.m2.1b"><ci id="S1.p5.2.m2.1.1.cmml" xref="S1.p5.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.2.m2.1c">T</annotation></semantics></math>) are better synthetic dataset generators for knowledge distillation, despite the fact that larger <math id="S1.p5.3.m3.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S1.p5.3.m3.1a"><mi id="S1.p5.3.m3.1.1" xref="S1.p5.3.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S1.p5.3.m3.1b"><ci id="S1.p5.3.m3.1.1.cmml" xref="S1.p5.3.m3.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.3.m3.1c">s</annotation></semantics></math> and <math id="S1.p5.4.m4.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S1.p5.4.m4.1a"><mi id="S1.p5.4.m4.1.1" xref="S1.p5.4.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S1.p5.4.m4.1b"><ci id="S1.p5.4.m4.1.1.cmml" xref="S1.p5.4.m4.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.4.m4.1c">T</annotation></semantics></math> can result in higher ImageReward scores and visually appealing/appropriate images.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p"><span id="S1.p6.1.1" class="ltx_text ltx_font_bold">(3) Relatively weak classifiers are better teachers.</span> On real datasets, knowledge distillation is typically achieved by distilling a larger teacher modelÂ (e.g., ResNet34) to a smaller student modelÂ (e.g., ResNet18). However, on synthetic datasets, we observe the opposite phenomenon, where relatively weak classifiers tend to perform better than strong classifiers.
Specifically, when training ResNet34 on the synthetic dataset, using ResNet18 as the teacher model leads to a 3% improvement in performance compared to using ResNet50 as the teacher model.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Conditional Diffusion Models.</span>
Diffusion modelÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">sohl2015deep</span> </a>; <a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">ho2020denoising</span> </a>; <a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">nichol2021improved</span> </a></cite> is a type of generative model that learns to model the probability distribution of a dataset by gradually adding sampled Gaussian noise to the data to "diffuse" the data and then trying to recover the original data by denoising the noise step by step until high-quality images are obtained. Conditional diffusion models is a type of diffusion model that is conditioned on some additional information, such as a text promptÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">saharia2022imagen</span> </a>; <a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">nichol2021glide</span> </a>; <a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">rombach2022high</span> </a>; <a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">ramesh2022hierarchical</span> </a></cite> or a class labelÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">ho2022cascaded</span> </a>; <a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">peebles2022scalable</span> </a></cite>. The conditioning signal is used to guide the denoising process so that the model can generate samples conditioned on a specific input.
Recent text-to-image generation models based on diffusion, such as ImagenÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">saharia2022imagen</span> </a></cite>, GLIDEÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">nichol2021glide</span> </a></cite>, SDÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">rombach2022high</span> </a></cite>, and class label conditional model DiTÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">peebles2022scalable</span> </a></cite>, have demonstrated the ability to generate highly realistic and visually stunning images, highlighting the potential power of diffusion models in generative modeling. Its outstanding performance makes it a popular choice for a variety of low-level image processing tasks, such as super-resolutionÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">li2022srdiff</span> </a>; <a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">saharia2022image</span> </a></cite>, image inpaintingÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">song2020score</span> </a>; <a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">lugmayr2022repaint</span> </a>; <a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">alt2022learning</span> </a></cite>, and dehazingÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">ozdenizci2023restoring</span> </a></cite>. However, the extent to which generative diffusion models can contribute to high-level tasks has yet to be well explored.
Several recent studies utilize well-trained open vocabulary text-to-image diffusion models as synthetic data generators for classification tasks. For example, He et al.Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">he2022synthetic</span> </a></cite> show that synthetic data generated by diffusion models can improve model pre-training, as well as zero-shot and few-shot image classification performance. Trabucco et al.Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">trabucco2023effective</span> </a></cite> augment images by editing them using a pre-trained text-to-image diffusion model to bring more semantic attribute diversity, leading to improvements in few-shot settings. Additionally, Azizi et al.Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">azizi2023synthetic</span> </a></cite> demonstrate that finetuned class-label conditional diffusion models can produce high-quality, in-distribution synthetic data that, when trained alongside real data, can achieve state-of-the-art classification performance.
However, to our best knowledge, few works have explored the impact of diffusion generation models on knowledge distillation.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Synthesis-based Knowledge Distillation.</span>
In recent years, knowledge distillationÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">hinton2015distilling</span> </a></cite> has received increasing attention from the research community, and it has been widely utilized in various vision tasksÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">liu2019structured</span> </a>; <a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">wang2020intra</span> </a>; <a href="#bib.bib66" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">zhang2019fast</span> </a>; <a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">li2021online</span> </a>; <a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">chen2022improved</span> </a>; <a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">yang2022vitkd</span> </a></cite>.
Conventional distillation methodsÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">park2019relational</span> </a>; <a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">chen2020online</span> </a>; <a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">li2020online</span> </a>; <a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">yang2021knowledge</span> </a>; <a href="#bib.bib69" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">zhao2022decoupled</span> </a>; <a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">li2022curriculum</span> </a></cite> require labeled training sets to train the student model by transferring knowledge from a large pre-trained teacher model. However, the original training dataset might not always be available due to privacy and safety concerns, making existing data-dependent methods hard to apply to data-scarce scenarios. Synthetic-based distillation methodsÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">lopes2017data</span> </a>; <a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">chen2019data</span> </a>; <a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">yin2020dreaming</span> </a>; <a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">luo2020large</span> </a>; <a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">haroush2020knowledge</span> </a>; <a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">binici2022robust</span> </a>; <a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">fang2022up</span> </a>; <a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">asano2023the</span> </a></cite> are proposed to solve the data-dependent problem. It typically follows a distilling-by-generating paradigmÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">fang2022up</span> </a></cite> wherein a proxy dataset will be synthesized by utilizing different generative methods. Lopes et al.Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">lopes2017data</span> </a></cite> first proposes to reconstruct the dataset from the metadataÂ (e.g., activation statistics). DeepInversionÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">yin2020dreaming</span> </a></cite> further optimizes the metadata-based synthesis method by introducing a feature regularization term. FastDFKDÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">fang2022up</span> </a></cite> proposes to speed up the generation process by using common features.
In contrast to previous GAN- and inversion-based distillation methods, One-Image-DistillÂ (OID)Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">asano2023the</span> </a></cite> utilizes data augmentation to construct a proxy dataset based on a single real image.
Our method stands out from previous approaches that rely on complex generative processes that are based on white-box teachers or require careful selection of the individual real image. These methods are often time-consuming and require a significant amount of effort. In contrast, our approach is simpler, more efficient, and more effective. It only requires the use of publicly available diffusion models for data synthesis.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<figure id="S3.F1" class="ltx_figure"><img src="/html/2305.12954/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="119" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An overview of our proposed synthetic data Knowledge Distillation approach based on Diffusion ModelsÂ (DM-KD). We propose to use the diffusion model to synthesize images given the target label space when the real dataset is not available. The student model is optimized to minimize the prediction discrepancy between itself and the teacher model on the synthetic dataset.</figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.6" class="ltx_p"><span id="S3.p1.6.1" class="ltx_text ltx_font_bold">Data Generation from Diffusion Model.</span>
In recent years, diffusion models have been demonstrated to produce images of higher quality, more realistic textures, and lower FIDÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">dhariwal2021diffusion</span> </a>; <a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">rombach2022high</span> </a>; <a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">nichol2021glide</span> </a></cite> than traditional GANÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">goodfellow2020generative</span> </a></cite> models.
It gradually adds sampled Gaussian noise to an image by:

</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.4" class="ltx_Math" alttext="q(x_{t}|x_{t-1})=\mathcal{N}(x_{t};\sqrt{\bar{a}_{t}}x_{t-1},(1-\bar{a}_{t})\mathbf{I})\vspace{-2pt}" display="block"><semantics id="S3.E1.m1.4a"><mrow id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.3.cmml">q</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.E1.m1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.2.cmml">x</mi><mrow id="S3.E1.m1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.3.2.cmml">t</mi><mo id="S3.E1.m1.1.1.1.1.1.1.3.3.1" xref="S3.E1.m1.1.1.1.1.1.1.3.3.1.cmml">âˆ’</mo><mn id="S3.E1.m1.1.1.1.1.1.1.3.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msub></mrow><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.4.4.5" xref="S3.E1.m1.4.4.5.cmml">=</mo><mrow id="S3.E1.m1.4.4.4" xref="S3.E1.m1.4.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.4.4.4.5" xref="S3.E1.m1.4.4.4.5.cmml">ğ’©</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.4.4" xref="S3.E1.m1.4.4.4.4.cmml">â€‹</mo><mrow id="S3.E1.m1.4.4.4.3.3" xref="S3.E1.m1.4.4.4.3.4.cmml"><mo stretchy="false" id="S3.E1.m1.4.4.4.3.3.4" xref="S3.E1.m1.4.4.4.3.4.cmml">(</mo><msub id="S3.E1.m1.2.2.2.1.1.1" xref="S3.E1.m1.2.2.2.1.1.1.cmml"><mi id="S3.E1.m1.2.2.2.1.1.1.2" xref="S3.E1.m1.2.2.2.1.1.1.2.cmml">x</mi><mi id="S3.E1.m1.2.2.2.1.1.1.3" xref="S3.E1.m1.2.2.2.1.1.1.3.cmml">t</mi></msub><mo id="S3.E1.m1.4.4.4.3.3.5" xref="S3.E1.m1.4.4.4.3.4.cmml">;</mo><mrow id="S3.E1.m1.3.3.3.2.2.2" xref="S3.E1.m1.3.3.3.2.2.2.cmml"><msqrt id="S3.E1.m1.3.3.3.2.2.2.2" xref="S3.E1.m1.3.3.3.2.2.2.2.cmml"><msub id="S3.E1.m1.3.3.3.2.2.2.2.2" xref="S3.E1.m1.3.3.3.2.2.2.2.2.cmml"><mover accent="true" id="S3.E1.m1.3.3.3.2.2.2.2.2.2" xref="S3.E1.m1.3.3.3.2.2.2.2.2.2.cmml"><mi id="S3.E1.m1.3.3.3.2.2.2.2.2.2.2" xref="S3.E1.m1.3.3.3.2.2.2.2.2.2.2.cmml">a</mi><mo id="S3.E1.m1.3.3.3.2.2.2.2.2.2.1" xref="S3.E1.m1.3.3.3.2.2.2.2.2.2.1.cmml">Â¯</mo></mover><mi id="S3.E1.m1.3.3.3.2.2.2.2.2.3" xref="S3.E1.m1.3.3.3.2.2.2.2.2.3.cmml">t</mi></msub></msqrt><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.3.2.2.2.1" xref="S3.E1.m1.3.3.3.2.2.2.1.cmml">â€‹</mo><msub id="S3.E1.m1.3.3.3.2.2.2.3" xref="S3.E1.m1.3.3.3.2.2.2.3.cmml"><mi id="S3.E1.m1.3.3.3.2.2.2.3.2" xref="S3.E1.m1.3.3.3.2.2.2.3.2.cmml">x</mi><mrow id="S3.E1.m1.3.3.3.2.2.2.3.3" xref="S3.E1.m1.3.3.3.2.2.2.3.3.cmml"><mi id="S3.E1.m1.3.3.3.2.2.2.3.3.2" xref="S3.E1.m1.3.3.3.2.2.2.3.3.2.cmml">t</mi><mo id="S3.E1.m1.3.3.3.2.2.2.3.3.1" xref="S3.E1.m1.3.3.3.2.2.2.3.3.1.cmml">âˆ’</mo><mn id="S3.E1.m1.3.3.3.2.2.2.3.3.3" xref="S3.E1.m1.3.3.3.2.2.2.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="S3.E1.m1.4.4.4.3.3.6" xref="S3.E1.m1.4.4.4.3.4.cmml">,</mo><mrow id="S3.E1.m1.4.4.4.3.3.3" xref="S3.E1.m1.4.4.4.3.3.3.cmml"><mrow id="S3.E1.m1.4.4.4.3.3.3.1.1" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.4.4.4.3.3.3.1.1.2" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.4.4.4.3.3.3.1.1.1" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.cmml"><mn id="S3.E1.m1.4.4.4.3.3.3.1.1.1.2" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.2.cmml">1</mn><mo id="S3.E1.m1.4.4.4.3.3.3.1.1.1.1" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.1.cmml">âˆ’</mo><msub id="S3.E1.m1.4.4.4.3.3.3.1.1.1.3" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.cmml"><mover accent="true" id="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.2" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.2.cmml"><mi id="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.2.2" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.2.2.cmml">a</mi><mo id="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.2.1" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.2.1.cmml">Â¯</mo></mover><mi id="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.3" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S3.E1.m1.4.4.4.3.3.3.1.1.3" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.4.3.3.3.2" xref="S3.E1.m1.4.4.4.3.3.3.2.cmml">â€‹</mo><mi id="S3.E1.m1.4.4.4.3.3.3.3" xref="S3.E1.m1.4.4.4.3.3.3.3.cmml">ğˆ</mi></mrow><mo stretchy="false" id="S3.E1.m1.4.4.4.3.3.7" xref="S3.E1.m1.4.4.4.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><apply id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4"><eq id="S3.E1.m1.4.4.5.cmml" xref="S3.E1.m1.4.4.5"></eq><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><times id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.2"></times><ci id="S3.E1.m1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.3">ğ‘</ci><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.E1.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3">ğ‘¡</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2">ğ‘¥</ci><apply id="S3.E1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3"><minus id="S3.E1.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.1"></minus><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.2">ğ‘¡</ci><cn type="integer" id="S3.E1.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3">1</cn></apply></apply></apply></apply><apply id="S3.E1.m1.4.4.4.cmml" xref="S3.E1.m1.4.4.4"><times id="S3.E1.m1.4.4.4.4.cmml" xref="S3.E1.m1.4.4.4.4"></times><ci id="S3.E1.m1.4.4.4.5.cmml" xref="S3.E1.m1.4.4.4.5">ğ’©</ci><list id="S3.E1.m1.4.4.4.3.4.cmml" xref="S3.E1.m1.4.4.4.3.3"><apply id="S3.E1.m1.2.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.2.1.1.1.2.cmml" xref="S3.E1.m1.2.2.2.1.1.1.2">ğ‘¥</ci><ci id="S3.E1.m1.2.2.2.1.1.1.3.cmml" xref="S3.E1.m1.2.2.2.1.1.1.3">ğ‘¡</ci></apply><apply id="S3.E1.m1.3.3.3.2.2.2.cmml" xref="S3.E1.m1.3.3.3.2.2.2"><times id="S3.E1.m1.3.3.3.2.2.2.1.cmml" xref="S3.E1.m1.3.3.3.2.2.2.1"></times><apply id="S3.E1.m1.3.3.3.2.2.2.2.cmml" xref="S3.E1.m1.3.3.3.2.2.2.2"><root id="S3.E1.m1.3.3.3.2.2.2.2a.cmml" xref="S3.E1.m1.3.3.3.2.2.2.2"></root><apply id="S3.E1.m1.3.3.3.2.2.2.2.2.cmml" xref="S3.E1.m1.3.3.3.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.2.2.2.2.2.1.cmml" xref="S3.E1.m1.3.3.3.2.2.2.2.2">subscript</csymbol><apply id="S3.E1.m1.3.3.3.2.2.2.2.2.2.cmml" xref="S3.E1.m1.3.3.3.2.2.2.2.2.2"><ci id="S3.E1.m1.3.3.3.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.3.3.3.2.2.2.2.2.2.1">Â¯</ci><ci id="S3.E1.m1.3.3.3.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.3.3.3.2.2.2.2.2.2.2">ğ‘</ci></apply><ci id="S3.E1.m1.3.3.3.2.2.2.2.2.3.cmml" xref="S3.E1.m1.3.3.3.2.2.2.2.2.3">ğ‘¡</ci></apply></apply><apply id="S3.E1.m1.3.3.3.2.2.2.3.cmml" xref="S3.E1.m1.3.3.3.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.2.2.2.3.1.cmml" xref="S3.E1.m1.3.3.3.2.2.2.3">subscript</csymbol><ci id="S3.E1.m1.3.3.3.2.2.2.3.2.cmml" xref="S3.E1.m1.3.3.3.2.2.2.3.2">ğ‘¥</ci><apply id="S3.E1.m1.3.3.3.2.2.2.3.3.cmml" xref="S3.E1.m1.3.3.3.2.2.2.3.3"><minus id="S3.E1.m1.3.3.3.2.2.2.3.3.1.cmml" xref="S3.E1.m1.3.3.3.2.2.2.3.3.1"></minus><ci id="S3.E1.m1.3.3.3.2.2.2.3.3.2.cmml" xref="S3.E1.m1.3.3.3.2.2.2.3.3.2">ğ‘¡</ci><cn type="integer" id="S3.E1.m1.3.3.3.2.2.2.3.3.3.cmml" xref="S3.E1.m1.3.3.3.2.2.2.3.3.3">1</cn></apply></apply></apply><apply id="S3.E1.m1.4.4.4.3.3.3.cmml" xref="S3.E1.m1.4.4.4.3.3.3"><times id="S3.E1.m1.4.4.4.3.3.3.2.cmml" xref="S3.E1.m1.4.4.4.3.3.3.2"></times><apply id="S3.E1.m1.4.4.4.3.3.3.1.1.1.cmml" xref="S3.E1.m1.4.4.4.3.3.3.1.1"><minus id="S3.E1.m1.4.4.4.3.3.3.1.1.1.1.cmml" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.1"></minus><cn type="integer" id="S3.E1.m1.4.4.4.3.3.3.1.1.1.2.cmml" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.2">1</cn><apply id="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.cmml" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.1.cmml" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.3">subscript</csymbol><apply id="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.2.cmml" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.2"><ci id="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.2.1.cmml" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.2.1">Â¯</ci><ci id="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.2.2.cmml" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.2.2">ğ‘</ci></apply><ci id="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.3.cmml" xref="S3.E1.m1.4.4.4.3.3.3.1.1.1.3.3">ğ‘¡</ci></apply></apply><ci id="S3.E1.m1.4.4.4.3.3.3.3.cmml" xref="S3.E1.m1.4.4.4.3.3.3.3">ğˆ</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">q(x_{t}|x_{t-1})=\mathcal{N}(x_{t};\sqrt{\bar{a}_{t}}x_{t-1},(1-\bar{a}_{t})\mathbf{I})\vspace{-2pt}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.p1.5" class="ltx_p">where <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="\bar{a}_{t}" display="inline"><semantics id="S3.p1.1.m1.1a"><msub id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mover accent="true" id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml"><mi id="S3.p1.1.m1.1.1.2.2" xref="S3.p1.1.m1.1.1.2.2.cmml">a</mi><mo id="S3.p1.1.m1.1.1.2.1" xref="S3.p1.1.m1.1.1.2.1.cmml">Â¯</mo></mover><mi id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1">subscript</csymbol><apply id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2"><ci id="S3.p1.1.m1.1.1.2.1.cmml" xref="S3.p1.1.m1.1.1.2.1">Â¯</ci><ci id="S3.p1.1.m1.1.1.2.2.cmml" xref="S3.p1.1.m1.1.1.2.2">ğ‘</ci></apply><ci id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">\bar{a}_{t}</annotation></semantics></math> is a hyperparameter and <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="x_{t}" display="inline"><semantics id="S3.p1.2.m2.1a"><msub id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><mi id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">x</mi><mi id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2">ğ‘¥</ci><ci id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">x_{t}</annotation></semantics></math> is the noised image at timestep <math id="S3.p1.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.p1.3.m3.1a"><mi id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><ci id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">t</annotation></semantics></math>.
When generating an image, the model <math id="S3.p1.4.m4.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.p1.4.m4.1a"><mi id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">\theta</annotation></semantics></math> carries out the denoising process over a given number of <math id="S3.p1.5.m5.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.p1.5.m5.1a"><mi id="S3.p1.5.m5.1.1" xref="S3.p1.5.m5.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.1b"><ci id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.5.m5.1c">T</annotation></semantics></math> timesteps. At each timestep, the model attempts to predict the sampled Gaussian noise with the following equation:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.3" class="ltx_Math" alttext="p_{\theta}(x_{t-1}|x_{t})=\mathcal{N}(\mu_{\theta}(x_{t}),\Sigma_{\theta}(x_{t}))\vspace{-4pt}" display="block"><semantics id="S3.E2.m1.3a"><mrow id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.3.cmml"><mi id="S3.E2.m1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.3.2.cmml">p</mi><mi id="S3.E2.m1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.1.1.2.2.cmml">x</mi><mrow id="S3.E2.m1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2.3.2" xref="S3.E2.m1.1.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S3.E2.m1.1.1.1.1.1.1.2.3.1" xref="S3.E2.m1.1.1.1.1.1.1.2.3.1.cmml">âˆ’</mo><mn id="S3.E2.m1.1.1.1.1.1.1.2.3.3" xref="S3.E2.m1.1.1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo fence="false" id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.cmml">x</mi><mi id="S3.E2.m1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S3.E2.m1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.4" xref="S3.E2.m1.3.3.4.cmml">=</mo><mrow id="S3.E2.m1.3.3.3" xref="S3.E2.m1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.3.3.3.4" xref="S3.E2.m1.3.3.3.4.cmml">ğ’©</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.3.3.3" xref="S3.E2.m1.3.3.3.3.cmml">â€‹</mo><mrow id="S3.E2.m1.3.3.3.2.2" xref="S3.E2.m1.3.3.3.2.3.cmml"><mo stretchy="false" id="S3.E2.m1.3.3.3.2.2.3" xref="S3.E2.m1.3.3.3.2.3.cmml">(</mo><mrow id="S3.E2.m1.2.2.2.1.1.1" xref="S3.E2.m1.2.2.2.1.1.1.cmml"><msub id="S3.E2.m1.2.2.2.1.1.1.3" xref="S3.E2.m1.2.2.2.1.1.1.3.cmml"><mi id="S3.E2.m1.2.2.2.1.1.1.3.2" xref="S3.E2.m1.2.2.2.1.1.1.3.2.cmml">Î¼</mi><mi id="S3.E2.m1.2.2.2.1.1.1.3.3" xref="S3.E2.m1.2.2.2.1.1.1.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.1.1.1.2" xref="S3.E2.m1.2.2.2.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E2.m1.2.2.2.1.1.1.1.1" xref="S3.E2.m1.2.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.2.1.1.1.1.1.2" xref="S3.E2.m1.2.2.2.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E2.m1.2.2.2.1.1.1.1.1.1" xref="S3.E2.m1.2.2.2.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.2.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.2.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E2.m1.2.2.2.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.2.1.1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S3.E2.m1.2.2.2.1.1.1.1.1.3" xref="S3.E2.m1.2.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.3.2.2.4" xref="S3.E2.m1.3.3.3.2.3.cmml">,</mo><mrow id="S3.E2.m1.3.3.3.2.2.2" xref="S3.E2.m1.3.3.3.2.2.2.cmml"><msub id="S3.E2.m1.3.3.3.2.2.2.3" xref="S3.E2.m1.3.3.3.2.2.2.3.cmml"><mi mathvariant="normal" id="S3.E2.m1.3.3.3.2.2.2.3.2" xref="S3.E2.m1.3.3.3.2.2.2.3.2.cmml">Î£</mi><mi id="S3.E2.m1.3.3.3.2.2.2.3.3" xref="S3.E2.m1.3.3.3.2.2.2.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.3.3.2.2.2.2" xref="S3.E2.m1.3.3.3.2.2.2.2.cmml">â€‹</mo><mrow id="S3.E2.m1.3.3.3.2.2.2.1.1" xref="S3.E2.m1.3.3.3.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.3.3.3.2.2.2.1.1.2" xref="S3.E2.m1.3.3.3.2.2.2.1.1.1.cmml">(</mo><msub id="S3.E2.m1.3.3.3.2.2.2.1.1.1" xref="S3.E2.m1.3.3.3.2.2.2.1.1.1.cmml"><mi id="S3.E2.m1.3.3.3.2.2.2.1.1.1.2" xref="S3.E2.m1.3.3.3.2.2.2.1.1.1.2.cmml">x</mi><mi id="S3.E2.m1.3.3.3.2.2.2.1.1.1.3" xref="S3.E2.m1.3.3.3.2.2.2.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S3.E2.m1.3.3.3.2.2.2.1.1.3" xref="S3.E2.m1.3.3.3.2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E2.m1.3.3.3.2.2.5" xref="S3.E2.m1.3.3.3.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.3b"><apply id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3"><eq id="S3.E2.m1.3.3.4.cmml" xref="S3.E2.m1.3.3.4"></eq><apply id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><times id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.2"></times><apply id="S3.E2.m1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.3.2">ğ‘</ci><ci id="S3.E2.m1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2">ğ‘¥</ci><apply id="S3.E2.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.3"><minus id="S3.E2.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.3.1"></minus><ci id="S3.E2.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.3.2">ğ‘¡</ci><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2">ğ‘¥</ci><ci id="S3.E2.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply></apply><apply id="S3.E2.m1.3.3.3.cmml" xref="S3.E2.m1.3.3.3"><times id="S3.E2.m1.3.3.3.3.cmml" xref="S3.E2.m1.3.3.3.3"></times><ci id="S3.E2.m1.3.3.3.4.cmml" xref="S3.E2.m1.3.3.3.4">ğ’©</ci><interval closure="open" id="S3.E2.m1.3.3.3.2.3.cmml" xref="S3.E2.m1.3.3.3.2.2"><apply id="S3.E2.m1.2.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1"><times id="S3.E2.m1.2.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2"></times><apply id="S3.E2.m1.2.2.2.1.1.1.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.1.1.1.3.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.2.2.2.1.1.1.3.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.3.2">ğœ‡</ci><ci id="S3.E2.m1.2.2.2.1.1.1.3.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E2.m1.2.2.2.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.2.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.E2.m1.2.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.1.1.3">ğ‘¡</ci></apply></apply><apply id="S3.E2.m1.3.3.3.2.2.2.cmml" xref="S3.E2.m1.3.3.3.2.2.2"><times id="S3.E2.m1.3.3.3.2.2.2.2.cmml" xref="S3.E2.m1.3.3.3.2.2.2.2"></times><apply id="S3.E2.m1.3.3.3.2.2.2.3.cmml" xref="S3.E2.m1.3.3.3.2.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.3.2.2.2.3.1.cmml" xref="S3.E2.m1.3.3.3.2.2.2.3">subscript</csymbol><ci id="S3.E2.m1.3.3.3.2.2.2.3.2.cmml" xref="S3.E2.m1.3.3.3.2.2.2.3.2">Î£</ci><ci id="S3.E2.m1.3.3.3.2.2.2.3.3.cmml" xref="S3.E2.m1.3.3.3.2.2.2.3.3">ğœƒ</ci></apply><apply id="S3.E2.m1.3.3.3.2.2.2.1.1.1.cmml" xref="S3.E2.m1.3.3.3.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.3.2.2.2.1.1.1.1.cmml" xref="S3.E2.m1.3.3.3.2.2.2.1.1">subscript</csymbol><ci id="S3.E2.m1.3.3.3.2.2.2.1.1.1.2.cmml" xref="S3.E2.m1.3.3.3.2.2.2.1.1.1.2">ğ‘¥</ci><ci id="S3.E2.m1.3.3.3.2.2.2.1.1.1.3.cmml" xref="S3.E2.m1.3.3.3.2.2.2.1.1.1.3">ğ‘¡</ci></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.3c">p_{\theta}(x_{t-1}|x_{t})=\mathcal{N}(\mu_{\theta}(x_{t}),\Sigma_{\theta}(x_{t}))\vspace{-4pt}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.2" class="ltx_p">In this paper, our study is mainly based on three popular conditional diffusion models, i.e. DiTÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">peebles2022scalable</span> </a></cite>, GLIDEÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">nichol2021glide</span> </a></cite> and Stable DiffusionÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">rombach2022high</span> </a></cite>, for synthetic data generation.
These models incorporate a conditioning input <math id="S3.p2.1.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.p2.1.m1.1a"><mi id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">c</annotation></semantics></math>, which allows for the noise prediction to be conditioned on <math id="S3.p2.2.m2.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.p2.2.m2.1a"><mi id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><ci id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">c</annotation></semantics></math> such as:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.4" class="ltx_Math" alttext="p_{\theta}(x_{t-1}|x_{t},c)=\mathcal{N}(\mu_{\theta}(x_{t}|c),\Sigma_{\theta}(x_{t}|c))\vspace{-4pt}" display="block"><semantics id="S3.E3.m1.4a"><mrow id="S3.E3.m1.4.4" xref="S3.E3.m1.4.4.cmml"><mrow id="S3.E3.m1.2.2.1" xref="S3.E3.m1.2.2.1.cmml"><msub id="S3.E3.m1.2.2.1.3" xref="S3.E3.m1.2.2.1.3.cmml"><mi id="S3.E3.m1.2.2.1.3.2" xref="S3.E3.m1.2.2.1.3.2.cmml">p</mi><mi id="S3.E3.m1.2.2.1.3.3" xref="S3.E3.m1.2.2.1.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.2" xref="S3.E3.m1.2.2.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.2.2.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.2.2.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.cmml"><msub id="S3.E3.m1.2.2.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.3.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.3.2" xref="S3.E3.m1.2.2.1.1.1.1.3.2.cmml">x</mi><mrow id="S3.E3.m1.2.2.1.1.1.1.3.3" xref="S3.E3.m1.2.2.1.1.1.1.3.3.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.3.3.2" xref="S3.E3.m1.2.2.1.1.1.1.3.3.2.cmml">t</mi><mo id="S3.E3.m1.2.2.1.1.1.1.3.3.1" xref="S3.E3.m1.2.2.1.1.1.1.3.3.1.cmml">âˆ’</mo><mn id="S3.E3.m1.2.2.1.1.1.1.3.3.3" xref="S3.E3.m1.2.2.1.1.1.1.3.3.3.cmml">1</mn></mrow></msub><mo fence="false" id="S3.E3.m1.2.2.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.2.cmml">|</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml"><msub id="S3.E3.m1.2.2.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E3.m1.2.2.1.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">c</mi></mrow></mrow><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.4.4.4" xref="S3.E3.m1.4.4.4.cmml">=</mo><mrow id="S3.E3.m1.4.4.3" xref="S3.E3.m1.4.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.4.4.3.4" xref="S3.E3.m1.4.4.3.4.cmml">ğ’©</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.3.3" xref="S3.E3.m1.4.4.3.3.cmml">â€‹</mo><mrow id="S3.E3.m1.4.4.3.2.2" xref="S3.E3.m1.4.4.3.2.3.cmml"><mo stretchy="false" id="S3.E3.m1.4.4.3.2.2.3" xref="S3.E3.m1.4.4.3.2.3.cmml">(</mo><mrow id="S3.E3.m1.3.3.2.1.1.1" xref="S3.E3.m1.3.3.2.1.1.1.cmml"><msub id="S3.E3.m1.3.3.2.1.1.1.3" xref="S3.E3.m1.3.3.2.1.1.1.3.cmml"><mi id="S3.E3.m1.3.3.2.1.1.1.3.2" xref="S3.E3.m1.3.3.2.1.1.1.3.2.cmml">Î¼</mi><mi id="S3.E3.m1.3.3.2.1.1.1.3.3" xref="S3.E3.m1.3.3.2.1.1.1.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.2.1.1.1.2" xref="S3.E3.m1.3.3.2.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.3.3.2.1.1.1.1.1" xref="S3.E3.m1.3.3.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.3.3.2.1.1.1.1.1.2" xref="S3.E3.m1.3.3.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.3.3.2.1.1.1.1.1.1" xref="S3.E3.m1.3.3.2.1.1.1.1.1.1.cmml"><msub id="S3.E3.m1.3.3.2.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.2.1.1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.3.3.2.1.1.1.1.1.1.2.2" xref="S3.E3.m1.3.3.2.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.E3.m1.3.3.2.1.1.1.1.1.1.2.3" xref="S3.E3.m1.3.3.2.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.E3.m1.3.3.2.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.2.1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.E3.m1.3.3.2.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.2.1.1.1.1.1.1.3.cmml">c</mi></mrow><mo stretchy="false" id="S3.E3.m1.3.3.2.1.1.1.1.1.3" xref="S3.E3.m1.3.3.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.4.4.3.2.2.4" xref="S3.E3.m1.4.4.3.2.3.cmml">,</mo><mrow id="S3.E3.m1.4.4.3.2.2.2" xref="S3.E3.m1.4.4.3.2.2.2.cmml"><msub id="S3.E3.m1.4.4.3.2.2.2.3" xref="S3.E3.m1.4.4.3.2.2.2.3.cmml"><mi mathvariant="normal" id="S3.E3.m1.4.4.3.2.2.2.3.2" xref="S3.E3.m1.4.4.3.2.2.2.3.2.cmml">Î£</mi><mi id="S3.E3.m1.4.4.3.2.2.2.3.3" xref="S3.E3.m1.4.4.3.2.2.2.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.3.2.2.2.2" xref="S3.E3.m1.4.4.3.2.2.2.2.cmml">â€‹</mo><mrow id="S3.E3.m1.4.4.3.2.2.2.1.1" xref="S3.E3.m1.4.4.3.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.4.4.3.2.2.2.1.1.2" xref="S3.E3.m1.4.4.3.2.2.2.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.4.4.3.2.2.2.1.1.1" xref="S3.E3.m1.4.4.3.2.2.2.1.1.1.cmml"><msub id="S3.E3.m1.4.4.3.2.2.2.1.1.1.2" xref="S3.E3.m1.4.4.3.2.2.2.1.1.1.2.cmml"><mi id="S3.E3.m1.4.4.3.2.2.2.1.1.1.2.2" xref="S3.E3.m1.4.4.3.2.2.2.1.1.1.2.2.cmml">x</mi><mi id="S3.E3.m1.4.4.3.2.2.2.1.1.1.2.3" xref="S3.E3.m1.4.4.3.2.2.2.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.E3.m1.4.4.3.2.2.2.1.1.1.1" xref="S3.E3.m1.4.4.3.2.2.2.1.1.1.1.cmml">|</mo><mi id="S3.E3.m1.4.4.3.2.2.2.1.1.1.3" xref="S3.E3.m1.4.4.3.2.2.2.1.1.1.3.cmml">c</mi></mrow><mo stretchy="false" id="S3.E3.m1.4.4.3.2.2.2.1.1.3" xref="S3.E3.m1.4.4.3.2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E3.m1.4.4.3.2.2.5" xref="S3.E3.m1.4.4.3.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.4b"><apply id="S3.E3.m1.4.4.cmml" xref="S3.E3.m1.4.4"><eq id="S3.E3.m1.4.4.4.cmml" xref="S3.E3.m1.4.4.4"></eq><apply id="S3.E3.m1.2.2.1.cmml" xref="S3.E3.m1.2.2.1"><times id="S3.E3.m1.2.2.1.2.cmml" xref="S3.E3.m1.2.2.1.2"></times><apply id="S3.E3.m1.2.2.1.3.cmml" xref="S3.E3.m1.2.2.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.3.1.cmml" xref="S3.E3.m1.2.2.1.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.3.2.cmml" xref="S3.E3.m1.2.2.1.3.2">ğ‘</ci><ci id="S3.E3.m1.2.2.1.3.3.cmml" xref="S3.E3.m1.2.2.1.3.3">ğœƒ</ci></apply><apply id="S3.E3.m1.2.2.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.2.2.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2">conditional</csymbol><apply id="S3.E3.m1.2.2.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.3.2">ğ‘¥</ci><apply id="S3.E3.m1.2.2.1.1.1.1.3.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.3.3"><minus id="S3.E3.m1.2.2.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.3.3.1"></minus><ci id="S3.E3.m1.2.2.1.1.1.1.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.3.3.2">ğ‘¡</ci><cn type="integer" id="S3.E3.m1.2.2.1.1.1.1.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.3.3.3">1</cn></apply></apply><list id="S3.E3.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1"><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">ğ‘</ci></list></apply></apply><apply id="S3.E3.m1.4.4.3.cmml" xref="S3.E3.m1.4.4.3"><times id="S3.E3.m1.4.4.3.3.cmml" xref="S3.E3.m1.4.4.3.3"></times><ci id="S3.E3.m1.4.4.3.4.cmml" xref="S3.E3.m1.4.4.3.4">ğ’©</ci><interval closure="open" id="S3.E3.m1.4.4.3.2.3.cmml" xref="S3.E3.m1.4.4.3.2.2"><apply id="S3.E3.m1.3.3.2.1.1.1.cmml" xref="S3.E3.m1.3.3.2.1.1.1"><times id="S3.E3.m1.3.3.2.1.1.1.2.cmml" xref="S3.E3.m1.3.3.2.1.1.1.2"></times><apply id="S3.E3.m1.3.3.2.1.1.1.3.cmml" xref="S3.E3.m1.3.3.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.2.1.1.1.3.1.cmml" xref="S3.E3.m1.3.3.2.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.3.3.2.1.1.1.3.2.cmml" xref="S3.E3.m1.3.3.2.1.1.1.3.2">ğœ‡</ci><ci id="S3.E3.m1.3.3.2.1.1.1.3.3.cmml" xref="S3.E3.m1.3.3.2.1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E3.m1.3.3.2.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.2.1.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.3.3.2.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.2.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.E3.m1.3.3.2.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.3.3.2.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E3.m1.3.3.2.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.3.3.2.1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.E3.m1.3.3.2.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.3.3.2.1.1.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.E3.m1.3.3.2.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.2.1.1.1.1.1.1.3">ğ‘</ci></apply></apply><apply id="S3.E3.m1.4.4.3.2.2.2.cmml" xref="S3.E3.m1.4.4.3.2.2.2"><times id="S3.E3.m1.4.4.3.2.2.2.2.cmml" xref="S3.E3.m1.4.4.3.2.2.2.2"></times><apply id="S3.E3.m1.4.4.3.2.2.2.3.cmml" xref="S3.E3.m1.4.4.3.2.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.3.2.2.2.3.1.cmml" xref="S3.E3.m1.4.4.3.2.2.2.3">subscript</csymbol><ci id="S3.E3.m1.4.4.3.2.2.2.3.2.cmml" xref="S3.E3.m1.4.4.3.2.2.2.3.2">Î£</ci><ci id="S3.E3.m1.4.4.3.2.2.2.3.3.cmml" xref="S3.E3.m1.4.4.3.2.2.2.3.3">ğœƒ</ci></apply><apply id="S3.E3.m1.4.4.3.2.2.2.1.1.1.cmml" xref="S3.E3.m1.4.4.3.2.2.2.1.1"><csymbol cd="latexml" id="S3.E3.m1.4.4.3.2.2.2.1.1.1.1.cmml" xref="S3.E3.m1.4.4.3.2.2.2.1.1.1.1">conditional</csymbol><apply id="S3.E3.m1.4.4.3.2.2.2.1.1.1.2.cmml" xref="S3.E3.m1.4.4.3.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.3.2.2.2.1.1.1.2.1.cmml" xref="S3.E3.m1.4.4.3.2.2.2.1.1.1.2">subscript</csymbol><ci id="S3.E3.m1.4.4.3.2.2.2.1.1.1.2.2.cmml" xref="S3.E3.m1.4.4.3.2.2.2.1.1.1.2.2">ğ‘¥</ci><ci id="S3.E3.m1.4.4.3.2.2.2.1.1.1.2.3.cmml" xref="S3.E3.m1.4.4.3.2.2.2.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.E3.m1.4.4.3.2.2.2.1.1.1.3.cmml" xref="S3.E3.m1.4.4.3.2.2.2.1.1.1.3">ğ‘</ci></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.4c">p_{\theta}(x_{t-1}|x_{t},c)=\mathcal{N}(\mu_{\theta}(x_{t}|c),\Sigma_{\theta}(x_{t}|c))\vspace{-4pt}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.2" class="ltx_p">By introducing a noise prediction network <math id="S3.p3.1.m1.1" class="ltx_Math" alttext="\epsilon_{\theta}" display="inline"><semantics id="S3.p3.1.m1.1a"><msub id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml"><mi id="S3.p3.1.m1.1.1.2" xref="S3.p3.1.m1.1.1.2.cmml">Ïµ</mi><mi id="S3.p3.1.m1.1.1.3" xref="S3.p3.1.m1.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><apply id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p3.1.m1.1.1.1.cmml" xref="S3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.p3.1.m1.1.1.2.cmml" xref="S3.p3.1.m1.1.1.2">italic-Ïµ</ci><ci id="S3.p3.1.m1.1.1.3.cmml" xref="S3.p3.1.m1.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">\epsilon_{\theta}</annotation></semantics></math> to model <math id="S3.p3.2.m2.1" class="ltx_Math" alttext="\mu_{\theta}" display="inline"><semantics id="S3.p3.2.m2.1a"><msub id="S3.p3.2.m2.1.1" xref="S3.p3.2.m2.1.1.cmml"><mi id="S3.p3.2.m2.1.1.2" xref="S3.p3.2.m2.1.1.2.cmml">Î¼</mi><mi id="S3.p3.2.m2.1.1.3" xref="S3.p3.2.m2.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p3.2.m2.1b"><apply id="S3.p3.2.m2.1.1.cmml" xref="S3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p3.2.m2.1.1.1.cmml" xref="S3.p3.2.m2.1.1">subscript</csymbol><ci id="S3.p3.2.m2.1.1.2.cmml" xref="S3.p3.2.m2.1.1.2">ğœ‡</ci><ci id="S3.p3.2.m2.1.1.3.cmml" xref="S3.p3.2.m2.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.2.m2.1c">\mu_{\theta}</annotation></semantics></math>, a simple mean squared error loss function is used for training the model:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.3" class="ltx_Math" alttext="\mathcal{L}_{simple}(\theta)=MSE(\epsilon_{\theta}(x_{t}),\epsilon_{t})\vspace{-2pt}" display="block"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3" xref="S3.E4.m1.3.3.cmml"><mrow id="S3.E4.m1.3.3.4" xref="S3.E4.m1.3.3.4.cmml"><msub id="S3.E4.m1.3.3.4.2" xref="S3.E4.m1.3.3.4.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.3.3.4.2.2" xref="S3.E4.m1.3.3.4.2.2.cmml">â„’</mi><mrow id="S3.E4.m1.3.3.4.2.3" xref="S3.E4.m1.3.3.4.2.3.cmml"><mi id="S3.E4.m1.3.3.4.2.3.2" xref="S3.E4.m1.3.3.4.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.4.2.3.1" xref="S3.E4.m1.3.3.4.2.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.3.3.4.2.3.3" xref="S3.E4.m1.3.3.4.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.4.2.3.1a" xref="S3.E4.m1.3.3.4.2.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.3.3.4.2.3.4" xref="S3.E4.m1.3.3.4.2.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.4.2.3.1b" xref="S3.E4.m1.3.3.4.2.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.3.3.4.2.3.5" xref="S3.E4.m1.3.3.4.2.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.4.2.3.1c" xref="S3.E4.m1.3.3.4.2.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.3.3.4.2.3.6" xref="S3.E4.m1.3.3.4.2.3.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.4.2.3.1d" xref="S3.E4.m1.3.3.4.2.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.3.3.4.2.3.7" xref="S3.E4.m1.3.3.4.2.3.7.cmml">e</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.4.1" xref="S3.E4.m1.3.3.4.1.cmml">â€‹</mo><mrow id="S3.E4.m1.3.3.4.3.2" xref="S3.E4.m1.3.3.4.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.4.3.2.1" xref="S3.E4.m1.3.3.4.cmml">(</mo><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">Î¸</mi><mo stretchy="false" id="S3.E4.m1.3.3.4.3.2.2" xref="S3.E4.m1.3.3.4.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.3.3.3" xref="S3.E4.m1.3.3.3.cmml">=</mo><mrow id="S3.E4.m1.3.3.2" xref="S3.E4.m1.3.3.2.cmml"><mi id="S3.E4.m1.3.3.2.4" xref="S3.E4.m1.3.3.2.4.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.2.3" xref="S3.E4.m1.3.3.2.3.cmml">â€‹</mo><mi id="S3.E4.m1.3.3.2.5" xref="S3.E4.m1.3.3.2.5.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.2.3a" xref="S3.E4.m1.3.3.2.3.cmml">â€‹</mo><mi id="S3.E4.m1.3.3.2.6" xref="S3.E4.m1.3.3.2.6.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.2.3b" xref="S3.E4.m1.3.3.2.3.cmml">â€‹</mo><mrow id="S3.E4.m1.3.3.2.2.2" xref="S3.E4.m1.3.3.2.2.3.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.2.2.2.3" xref="S3.E4.m1.3.3.2.2.3.cmml">(</mo><mrow id="S3.E4.m1.2.2.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.cmml"><msub id="S3.E4.m1.2.2.1.1.1.1.3" xref="S3.E4.m1.2.2.1.1.1.1.3.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.3.2" xref="S3.E4.m1.2.2.1.1.1.1.3.2.cmml">Ïµ</mi><mi id="S3.E4.m1.2.2.1.1.1.1.3.3" xref="S3.E4.m1.2.2.1.1.1.1.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.1.1.1.1.2" xref="S3.E4.m1.2.2.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E4.m1.2.2.1.1.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.2.2.1.1.1.1.1.1.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E4.m1.2.2.1.1.1.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S3.E4.m1.2.2.1.1.1.1.1.1.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.3.3.2.2.2.4" xref="S3.E4.m1.3.3.2.2.3.cmml">,</mo><msub id="S3.E4.m1.3.3.2.2.2.2" xref="S3.E4.m1.3.3.2.2.2.2.cmml"><mi id="S3.E4.m1.3.3.2.2.2.2.2" xref="S3.E4.m1.3.3.2.2.2.2.2.cmml">Ïµ</mi><mi id="S3.E4.m1.3.3.2.2.2.2.3" xref="S3.E4.m1.3.3.2.2.2.2.3.cmml">t</mi></msub><mo stretchy="false" id="S3.E4.m1.3.3.2.2.2.5" xref="S3.E4.m1.3.3.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.cmml" xref="S3.E4.m1.3.3"><eq id="S3.E4.m1.3.3.3.cmml" xref="S3.E4.m1.3.3.3"></eq><apply id="S3.E4.m1.3.3.4.cmml" xref="S3.E4.m1.3.3.4"><times id="S3.E4.m1.3.3.4.1.cmml" xref="S3.E4.m1.3.3.4.1"></times><apply id="S3.E4.m1.3.3.4.2.cmml" xref="S3.E4.m1.3.3.4.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.4.2.1.cmml" xref="S3.E4.m1.3.3.4.2">subscript</csymbol><ci id="S3.E4.m1.3.3.4.2.2.cmml" xref="S3.E4.m1.3.3.4.2.2">â„’</ci><apply id="S3.E4.m1.3.3.4.2.3.cmml" xref="S3.E4.m1.3.3.4.2.3"><times id="S3.E4.m1.3.3.4.2.3.1.cmml" xref="S3.E4.m1.3.3.4.2.3.1"></times><ci id="S3.E4.m1.3.3.4.2.3.2.cmml" xref="S3.E4.m1.3.3.4.2.3.2">ğ‘ </ci><ci id="S3.E4.m1.3.3.4.2.3.3.cmml" xref="S3.E4.m1.3.3.4.2.3.3">ğ‘–</ci><ci id="S3.E4.m1.3.3.4.2.3.4.cmml" xref="S3.E4.m1.3.3.4.2.3.4">ğ‘š</ci><ci id="S3.E4.m1.3.3.4.2.3.5.cmml" xref="S3.E4.m1.3.3.4.2.3.5">ğ‘</ci><ci id="S3.E4.m1.3.3.4.2.3.6.cmml" xref="S3.E4.m1.3.3.4.2.3.6">ğ‘™</ci><ci id="S3.E4.m1.3.3.4.2.3.7.cmml" xref="S3.E4.m1.3.3.4.2.3.7">ğ‘’</ci></apply></apply><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">ğœƒ</ci></apply><apply id="S3.E4.m1.3.3.2.cmml" xref="S3.E4.m1.3.3.2"><times id="S3.E4.m1.3.3.2.3.cmml" xref="S3.E4.m1.3.3.2.3"></times><ci id="S3.E4.m1.3.3.2.4.cmml" xref="S3.E4.m1.3.3.2.4">ğ‘€</ci><ci id="S3.E4.m1.3.3.2.5.cmml" xref="S3.E4.m1.3.3.2.5">ğ‘†</ci><ci id="S3.E4.m1.3.3.2.6.cmml" xref="S3.E4.m1.3.3.2.6">ğ¸</ci><interval closure="open" id="S3.E4.m1.3.3.2.2.3.cmml" xref="S3.E4.m1.3.3.2.2.2"><apply id="S3.E4.m1.2.2.1.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1"><times id="S3.E4.m1.2.2.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.2"></times><apply id="S3.E4.m1.2.2.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.2">italic-Ïµ</ci><ci id="S3.E4.m1.2.2.1.1.1.1.3.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply></apply><apply id="S3.E4.m1.3.3.2.2.2.2.cmml" xref="S3.E4.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.2.2.2.2.1.cmml" xref="S3.E4.m1.3.3.2.2.2.2">subscript</csymbol><ci id="S3.E4.m1.3.3.2.2.2.2.2.cmml" xref="S3.E4.m1.3.3.2.2.2.2.2">italic-Ïµ</ci><ci id="S3.E4.m1.3.3.2.2.2.2.3.cmml" xref="S3.E4.m1.3.3.2.2.2.2.3">ğ‘¡</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">\mathcal{L}_{simple}(\theta)=MSE(\epsilon_{\theta}(x_{t}),\epsilon_{t})\vspace{-2pt}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.p3.4" class="ltx_p">The objective is to minimize the distance between the predicted noise <math id="S3.p3.3.m1.1" class="ltx_Math" alttext="\epsilon_{\theta}(x_{t})" display="inline"><semantics id="S3.p3.3.m1.1a"><mrow id="S3.p3.3.m1.1.1" xref="S3.p3.3.m1.1.1.cmml"><msub id="S3.p3.3.m1.1.1.3" xref="S3.p3.3.m1.1.1.3.cmml"><mi id="S3.p3.3.m1.1.1.3.2" xref="S3.p3.3.m1.1.1.3.2.cmml">Ïµ</mi><mi id="S3.p3.3.m1.1.1.3.3" xref="S3.p3.3.m1.1.1.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.p3.3.m1.1.1.2" xref="S3.p3.3.m1.1.1.2.cmml">â€‹</mo><mrow id="S3.p3.3.m1.1.1.1.1" xref="S3.p3.3.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.p3.3.m1.1.1.1.1.2" xref="S3.p3.3.m1.1.1.1.1.1.cmml">(</mo><msub id="S3.p3.3.m1.1.1.1.1.1" xref="S3.p3.3.m1.1.1.1.1.1.cmml"><mi id="S3.p3.3.m1.1.1.1.1.1.2" xref="S3.p3.3.m1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.p3.3.m1.1.1.1.1.1.3" xref="S3.p3.3.m1.1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S3.p3.3.m1.1.1.1.1.3" xref="S3.p3.3.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.3.m1.1b"><apply id="S3.p3.3.m1.1.1.cmml" xref="S3.p3.3.m1.1.1"><times id="S3.p3.3.m1.1.1.2.cmml" xref="S3.p3.3.m1.1.1.2"></times><apply id="S3.p3.3.m1.1.1.3.cmml" xref="S3.p3.3.m1.1.1.3"><csymbol cd="ambiguous" id="S3.p3.3.m1.1.1.3.1.cmml" xref="S3.p3.3.m1.1.1.3">subscript</csymbol><ci id="S3.p3.3.m1.1.1.3.2.cmml" xref="S3.p3.3.m1.1.1.3.2">italic-Ïµ</ci><ci id="S3.p3.3.m1.1.1.3.3.cmml" xref="S3.p3.3.m1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.p3.3.m1.1.1.1.1.1.cmml" xref="S3.p3.3.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p3.3.m1.1.1.1.1.1.1.cmml" xref="S3.p3.3.m1.1.1.1.1">subscript</csymbol><ci id="S3.p3.3.m1.1.1.1.1.1.2.cmml" xref="S3.p3.3.m1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.p3.3.m1.1.1.1.1.1.3.cmml" xref="S3.p3.3.m1.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.3.m1.1c">\epsilon_{\theta}(x_{t})</annotation></semantics></math> and the GT noise <math id="S3.p3.4.m2.1" class="ltx_Math" alttext="\epsilon_{t}" display="inline"><semantics id="S3.p3.4.m2.1a"><msub id="S3.p3.4.m2.1.1" xref="S3.p3.4.m2.1.1.cmml"><mi id="S3.p3.4.m2.1.1.2" xref="S3.p3.4.m2.1.1.2.cmml">Ïµ</mi><mi id="S3.p3.4.m2.1.1.3" xref="S3.p3.4.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p3.4.m2.1b"><apply id="S3.p3.4.m2.1.1.cmml" xref="S3.p3.4.m2.1.1"><csymbol cd="ambiguous" id="S3.p3.4.m2.1.1.1.cmml" xref="S3.p3.4.m2.1.1">subscript</csymbol><ci id="S3.p3.4.m2.1.1.2.cmml" xref="S3.p3.4.m2.1.1.2">italic-Ïµ</ci><ci id="S3.p3.4.m2.1.1.3.cmml" xref="S3.p3.4.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.4.m2.1c">\epsilon_{t}</annotation></semantics></math>.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.4" class="ltx_p">More specifically, to generate images with more distinctive features related to the given conditions, a classifier-free sampling strategy is employed, which encourages a high value of <math id="S3.p4.1.m1.1" class="ltx_Math" alttext="p(c|x_{t})" display="inline"><semantics id="S3.p4.1.m1.1a"><mrow id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml"><mi id="S3.p4.1.m1.1.1.3" xref="S3.p4.1.m1.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.p4.1.m1.1.1.2" xref="S3.p4.1.m1.1.1.2.cmml">â€‹</mo><mrow id="S3.p4.1.m1.1.1.1.1" xref="S3.p4.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.p4.1.m1.1.1.1.1.2" xref="S3.p4.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.p4.1.m1.1.1.1.1.1" xref="S3.p4.1.m1.1.1.1.1.1.cmml"><mi id="S3.p4.1.m1.1.1.1.1.1.2" xref="S3.p4.1.m1.1.1.1.1.1.2.cmml">c</mi><mo fence="false" id="S3.p4.1.m1.1.1.1.1.1.1" xref="S3.p4.1.m1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.p4.1.m1.1.1.1.1.1.3" xref="S3.p4.1.m1.1.1.1.1.1.3.cmml"><mi id="S3.p4.1.m1.1.1.1.1.1.3.2" xref="S3.p4.1.m1.1.1.1.1.1.3.2.cmml">x</mi><mi id="S3.p4.1.m1.1.1.1.1.1.3.3" xref="S3.p4.1.m1.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S3.p4.1.m1.1.1.1.1.3" xref="S3.p4.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><apply id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1"><times id="S3.p4.1.m1.1.1.2.cmml" xref="S3.p4.1.m1.1.1.2"></times><ci id="S3.p4.1.m1.1.1.3.cmml" xref="S3.p4.1.m1.1.1.3">ğ‘</ci><apply id="S3.p4.1.m1.1.1.1.1.1.cmml" xref="S3.p4.1.m1.1.1.1.1"><csymbol cd="latexml" id="S3.p4.1.m1.1.1.1.1.1.1.cmml" xref="S3.p4.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.p4.1.m1.1.1.1.1.1.2.cmml" xref="S3.p4.1.m1.1.1.1.1.1.2">ğ‘</ci><apply id="S3.p4.1.m1.1.1.1.1.1.3.cmml" xref="S3.p4.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.p4.1.m1.1.1.1.1.1.3.1.cmml" xref="S3.p4.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.p4.1.m1.1.1.1.1.1.3.2.cmml" xref="S3.p4.1.m1.1.1.1.1.1.3.2">ğ‘¥</ci><ci id="S3.p4.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.p4.1.m1.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">p(c|x_{t})</annotation></semantics></math>.
<math id="S3.p4.2.m2.1" class="ltx_Math" alttext="p(c|x_{t})" display="inline"><semantics id="S3.p4.2.m2.1a"><mrow id="S3.p4.2.m2.1.1" xref="S3.p4.2.m2.1.1.cmml"><mi id="S3.p4.2.m2.1.1.3" xref="S3.p4.2.m2.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.p4.2.m2.1.1.2" xref="S3.p4.2.m2.1.1.2.cmml">â€‹</mo><mrow id="S3.p4.2.m2.1.1.1.1" xref="S3.p4.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.p4.2.m2.1.1.1.1.2" xref="S3.p4.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S3.p4.2.m2.1.1.1.1.1" xref="S3.p4.2.m2.1.1.1.1.1.cmml"><mi id="S3.p4.2.m2.1.1.1.1.1.2" xref="S3.p4.2.m2.1.1.1.1.1.2.cmml">c</mi><mo fence="false" id="S3.p4.2.m2.1.1.1.1.1.1" xref="S3.p4.2.m2.1.1.1.1.1.1.cmml">|</mo><msub id="S3.p4.2.m2.1.1.1.1.1.3" xref="S3.p4.2.m2.1.1.1.1.1.3.cmml"><mi id="S3.p4.2.m2.1.1.1.1.1.3.2" xref="S3.p4.2.m2.1.1.1.1.1.3.2.cmml">x</mi><mi id="S3.p4.2.m2.1.1.1.1.1.3.3" xref="S3.p4.2.m2.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S3.p4.2.m2.1.1.1.1.3" xref="S3.p4.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.2.m2.1b"><apply id="S3.p4.2.m2.1.1.cmml" xref="S3.p4.2.m2.1.1"><times id="S3.p4.2.m2.1.1.2.cmml" xref="S3.p4.2.m2.1.1.2"></times><ci id="S3.p4.2.m2.1.1.3.cmml" xref="S3.p4.2.m2.1.1.3">ğ‘</ci><apply id="S3.p4.2.m2.1.1.1.1.1.cmml" xref="S3.p4.2.m2.1.1.1.1"><csymbol cd="latexml" id="S3.p4.2.m2.1.1.1.1.1.1.cmml" xref="S3.p4.2.m2.1.1.1.1.1.1">conditional</csymbol><ci id="S3.p4.2.m2.1.1.1.1.1.2.cmml" xref="S3.p4.2.m2.1.1.1.1.1.2">ğ‘</ci><apply id="S3.p4.2.m2.1.1.1.1.1.3.cmml" xref="S3.p4.2.m2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.p4.2.m2.1.1.1.1.1.3.1.cmml" xref="S3.p4.2.m2.1.1.1.1.1.3">subscript</csymbol><ci id="S3.p4.2.m2.1.1.1.1.1.3.2.cmml" xref="S3.p4.2.m2.1.1.1.1.1.3.2">ğ‘¥</ci><ci id="S3.p4.2.m2.1.1.1.1.1.3.3.cmml" xref="S3.p4.2.m2.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.2.m2.1c">p(c|x_{t})</annotation></semantics></math> can be represented in terms of <math id="S3.p4.3.m3.1" class="ltx_Math" alttext="p(x_{t}|c)" display="inline"><semantics id="S3.p4.3.m3.1a"><mrow id="S3.p4.3.m3.1.1" xref="S3.p4.3.m3.1.1.cmml"><mi id="S3.p4.3.m3.1.1.3" xref="S3.p4.3.m3.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.p4.3.m3.1.1.2" xref="S3.p4.3.m3.1.1.2.cmml">â€‹</mo><mrow id="S3.p4.3.m3.1.1.1.1" xref="S3.p4.3.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.p4.3.m3.1.1.1.1.2" xref="S3.p4.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S3.p4.3.m3.1.1.1.1.1" xref="S3.p4.3.m3.1.1.1.1.1.cmml"><msub id="S3.p4.3.m3.1.1.1.1.1.2" xref="S3.p4.3.m3.1.1.1.1.1.2.cmml"><mi id="S3.p4.3.m3.1.1.1.1.1.2.2" xref="S3.p4.3.m3.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.p4.3.m3.1.1.1.1.1.2.3" xref="S3.p4.3.m3.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.p4.3.m3.1.1.1.1.1.1" xref="S3.p4.3.m3.1.1.1.1.1.1.cmml">|</mo><mi id="S3.p4.3.m3.1.1.1.1.1.3" xref="S3.p4.3.m3.1.1.1.1.1.3.cmml">c</mi></mrow><mo stretchy="false" id="S3.p4.3.m3.1.1.1.1.3" xref="S3.p4.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.3.m3.1b"><apply id="S3.p4.3.m3.1.1.cmml" xref="S3.p4.3.m3.1.1"><times id="S3.p4.3.m3.1.1.2.cmml" xref="S3.p4.3.m3.1.1.2"></times><ci id="S3.p4.3.m3.1.1.3.cmml" xref="S3.p4.3.m3.1.1.3">ğ‘</ci><apply id="S3.p4.3.m3.1.1.1.1.1.cmml" xref="S3.p4.3.m3.1.1.1.1"><csymbol cd="latexml" id="S3.p4.3.m3.1.1.1.1.1.1.cmml" xref="S3.p4.3.m3.1.1.1.1.1.1">conditional</csymbol><apply id="S3.p4.3.m3.1.1.1.1.1.2.cmml" xref="S3.p4.3.m3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.p4.3.m3.1.1.1.1.1.2.1.cmml" xref="S3.p4.3.m3.1.1.1.1.1.2">subscript</csymbol><ci id="S3.p4.3.m3.1.1.1.1.1.2.2.cmml" xref="S3.p4.3.m3.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.p4.3.m3.1.1.1.1.1.2.3.cmml" xref="S3.p4.3.m3.1.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.p4.3.m3.1.1.1.1.1.3.cmml" xref="S3.p4.3.m3.1.1.1.1.1.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.3.m3.1c">p(x_{t}|c)</annotation></semantics></math> and <math id="S3.p4.4.m4.1" class="ltx_Math" alttext="p(x_{t})" display="inline"><semantics id="S3.p4.4.m4.1a"><mrow id="S3.p4.4.m4.1.1" xref="S3.p4.4.m4.1.1.cmml"><mi id="S3.p4.4.m4.1.1.3" xref="S3.p4.4.m4.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.p4.4.m4.1.1.2" xref="S3.p4.4.m4.1.1.2.cmml">â€‹</mo><mrow id="S3.p4.4.m4.1.1.1.1" xref="S3.p4.4.m4.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.p4.4.m4.1.1.1.1.2" xref="S3.p4.4.m4.1.1.1.1.1.cmml">(</mo><msub id="S3.p4.4.m4.1.1.1.1.1" xref="S3.p4.4.m4.1.1.1.1.1.cmml"><mi id="S3.p4.4.m4.1.1.1.1.1.2" xref="S3.p4.4.m4.1.1.1.1.1.2.cmml">x</mi><mi id="S3.p4.4.m4.1.1.1.1.1.3" xref="S3.p4.4.m4.1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S3.p4.4.m4.1.1.1.1.3" xref="S3.p4.4.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.4.m4.1b"><apply id="S3.p4.4.m4.1.1.cmml" xref="S3.p4.4.m4.1.1"><times id="S3.p4.4.m4.1.1.2.cmml" xref="S3.p4.4.m4.1.1.2"></times><ci id="S3.p4.4.m4.1.1.3.cmml" xref="S3.p4.4.m4.1.1.3">ğ‘</ci><apply id="S3.p4.4.m4.1.1.1.1.1.cmml" xref="S3.p4.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.p4.4.m4.1.1.1.1.1.1.cmml" xref="S3.p4.4.m4.1.1.1.1">subscript</csymbol><ci id="S3.p4.4.m4.1.1.1.1.1.2.cmml" xref="S3.p4.4.m4.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.p4.4.m4.1.1.1.1.1.3.cmml" xref="S3.p4.4.m4.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.4.m4.1c">p(x_{t})</annotation></semantics></math> by using Bayesâ€™ Rule as:</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.4" class="ltx_Math" alttext="p(c|x_{t})=\frac{p(x_{t}|c)\cdot p(c)}{p(x_{t})}\vspace{-2pt}" display="block"><semantics id="S3.E5.m1.4a"><mrow id="S3.E5.m1.4.4" xref="S3.E5.m1.4.4.cmml"><mrow id="S3.E5.m1.4.4.1" xref="S3.E5.m1.4.4.1.cmml"><mi id="S3.E5.m1.4.4.1.3" xref="S3.E5.m1.4.4.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.4.1.2" xref="S3.E5.m1.4.4.1.2.cmml">â€‹</mo><mrow id="S3.E5.m1.4.4.1.1.1" xref="S3.E5.m1.4.4.1.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.4.4.1.1.1.2" xref="S3.E5.m1.4.4.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.4.4.1.1.1.1" xref="S3.E5.m1.4.4.1.1.1.1.cmml"><mi id="S3.E5.m1.4.4.1.1.1.1.2" xref="S3.E5.m1.4.4.1.1.1.1.2.cmml">c</mi><mo fence="false" id="S3.E5.m1.4.4.1.1.1.1.1" xref="S3.E5.m1.4.4.1.1.1.1.1.cmml">|</mo><msub id="S3.E5.m1.4.4.1.1.1.1.3" xref="S3.E5.m1.4.4.1.1.1.1.3.cmml"><mi id="S3.E5.m1.4.4.1.1.1.1.3.2" xref="S3.E5.m1.4.4.1.1.1.1.3.2.cmml">x</mi><mi id="S3.E5.m1.4.4.1.1.1.1.3.3" xref="S3.E5.m1.4.4.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S3.E5.m1.4.4.1.1.1.3" xref="S3.E5.m1.4.4.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.4.4.2" xref="S3.E5.m1.4.4.2.cmml">=</mo><mfrac id="S3.E5.m1.3.3" xref="S3.E5.m1.3.3.cmml"><mrow id="S3.E5.m1.2.2.2" xref="S3.E5.m1.2.2.2.cmml"><mrow id="S3.E5.m1.2.2.2.2" xref="S3.E5.m1.2.2.2.2.cmml"><mrow id="S3.E5.m1.2.2.2.2.1" xref="S3.E5.m1.2.2.2.2.1.cmml"><mi id="S3.E5.m1.2.2.2.2.1.3" xref="S3.E5.m1.2.2.2.2.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.2.2.1.2" xref="S3.E5.m1.2.2.2.2.1.2.cmml">â€‹</mo><mrow id="S3.E5.m1.2.2.2.2.1.1.1" xref="S3.E5.m1.2.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.2.2.2.2.1.1.1.2" xref="S3.E5.m1.2.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.2.2.2.2.1.1.1.1" xref="S3.E5.m1.2.2.2.2.1.1.1.1.cmml"><msub id="S3.E5.m1.2.2.2.2.1.1.1.1.2" xref="S3.E5.m1.2.2.2.2.1.1.1.1.2.cmml"><mi id="S3.E5.m1.2.2.2.2.1.1.1.1.2.2" xref="S3.E5.m1.2.2.2.2.1.1.1.1.2.2.cmml">x</mi><mi id="S3.E5.m1.2.2.2.2.1.1.1.1.2.3" xref="S3.E5.m1.2.2.2.2.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.E5.m1.2.2.2.2.1.1.1.1.1" xref="S3.E5.m1.2.2.2.2.1.1.1.1.1.cmml">|</mo><mi id="S3.E5.m1.2.2.2.2.1.1.1.1.3" xref="S3.E5.m1.2.2.2.2.1.1.1.1.3.cmml">c</mi></mrow><mo rspace="0.055em" stretchy="false" id="S3.E5.m1.2.2.2.2.1.1.1.3" xref="S3.E5.m1.2.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S3.E5.m1.2.2.2.2.2" xref="S3.E5.m1.2.2.2.2.2.cmml">â‹…</mo><mi id="S3.E5.m1.2.2.2.2.3" xref="S3.E5.m1.2.2.2.2.3.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.2.3" xref="S3.E5.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E5.m1.2.2.2.4.2" xref="S3.E5.m1.2.2.2.cmml"><mo stretchy="false" id="S3.E5.m1.2.2.2.4.2.1" xref="S3.E5.m1.2.2.2.cmml">(</mo><mi id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml">c</mi><mo stretchy="false" id="S3.E5.m1.2.2.2.4.2.2" xref="S3.E5.m1.2.2.2.cmml">)</mo></mrow></mrow><mrow id="S3.E5.m1.3.3.3" xref="S3.E5.m1.3.3.3.cmml"><mi id="S3.E5.m1.3.3.3.3" xref="S3.E5.m1.3.3.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.3.3.3.2" xref="S3.E5.m1.3.3.3.2.cmml">â€‹</mo><mrow id="S3.E5.m1.3.3.3.1.1" xref="S3.E5.m1.3.3.3.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.3.3.3.1.1.2" xref="S3.E5.m1.3.3.3.1.1.1.cmml">(</mo><msub id="S3.E5.m1.3.3.3.1.1.1" xref="S3.E5.m1.3.3.3.1.1.1.cmml"><mi id="S3.E5.m1.3.3.3.1.1.1.2" xref="S3.E5.m1.3.3.3.1.1.1.2.cmml">x</mi><mi id="S3.E5.m1.3.3.3.1.1.1.3" xref="S3.E5.m1.3.3.3.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S3.E5.m1.3.3.3.1.1.3" xref="S3.E5.m1.3.3.3.1.1.1.cmml">)</mo></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.4b"><apply id="S3.E5.m1.4.4.cmml" xref="S3.E5.m1.4.4"><eq id="S3.E5.m1.4.4.2.cmml" xref="S3.E5.m1.4.4.2"></eq><apply id="S3.E5.m1.4.4.1.cmml" xref="S3.E5.m1.4.4.1"><times id="S3.E5.m1.4.4.1.2.cmml" xref="S3.E5.m1.4.4.1.2"></times><ci id="S3.E5.m1.4.4.1.3.cmml" xref="S3.E5.m1.4.4.1.3">ğ‘</ci><apply id="S3.E5.m1.4.4.1.1.1.1.cmml" xref="S3.E5.m1.4.4.1.1.1"><csymbol cd="latexml" id="S3.E5.m1.4.4.1.1.1.1.1.cmml" xref="S3.E5.m1.4.4.1.1.1.1.1">conditional</csymbol><ci id="S3.E5.m1.4.4.1.1.1.1.2.cmml" xref="S3.E5.m1.4.4.1.1.1.1.2">ğ‘</ci><apply id="S3.E5.m1.4.4.1.1.1.1.3.cmml" xref="S3.E5.m1.4.4.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.1.1.1.1.3.1.cmml" xref="S3.E5.m1.4.4.1.1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.4.4.1.1.1.1.3.2.cmml" xref="S3.E5.m1.4.4.1.1.1.1.3.2">ğ‘¥</ci><ci id="S3.E5.m1.4.4.1.1.1.1.3.3.cmml" xref="S3.E5.m1.4.4.1.1.1.1.3.3">ğ‘¡</ci></apply></apply></apply><apply id="S3.E5.m1.3.3.cmml" xref="S3.E5.m1.3.3"><divide id="S3.E5.m1.3.3.4.cmml" xref="S3.E5.m1.3.3"></divide><apply id="S3.E5.m1.2.2.2.cmml" xref="S3.E5.m1.2.2.2"><times id="S3.E5.m1.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.3"></times><apply id="S3.E5.m1.2.2.2.2.cmml" xref="S3.E5.m1.2.2.2.2"><ci id="S3.E5.m1.2.2.2.2.2.cmml" xref="S3.E5.m1.2.2.2.2.2">â‹…</ci><apply id="S3.E5.m1.2.2.2.2.1.cmml" xref="S3.E5.m1.2.2.2.2.1"><times id="S3.E5.m1.2.2.2.2.1.2.cmml" xref="S3.E5.m1.2.2.2.2.1.2"></times><ci id="S3.E5.m1.2.2.2.2.1.3.cmml" xref="S3.E5.m1.2.2.2.2.1.3">ğ‘</ci><apply id="S3.E5.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.E5.m1.2.2.2.2.1.1.1"><csymbol cd="latexml" id="S3.E5.m1.2.2.2.2.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.2.2.1.1.1.1.1">conditional</csymbol><apply id="S3.E5.m1.2.2.2.2.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.2.2.1.1.1.1.2.1.cmml" xref="S3.E5.m1.2.2.2.2.1.1.1.1.2">subscript</csymbol><ci id="S3.E5.m1.2.2.2.2.1.1.1.1.2.2.cmml" xref="S3.E5.m1.2.2.2.2.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.E5.m1.2.2.2.2.1.1.1.1.2.3.cmml" xref="S3.E5.m1.2.2.2.2.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.E5.m1.2.2.2.2.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.2.2.1.1.1.1.3">ğ‘</ci></apply></apply><ci id="S3.E5.m1.2.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.2.3">ğ‘</ci></apply><ci id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1">ğ‘</ci></apply><apply id="S3.E5.m1.3.3.3.cmml" xref="S3.E5.m1.3.3.3"><times id="S3.E5.m1.3.3.3.2.cmml" xref="S3.E5.m1.3.3.3.2"></times><ci id="S3.E5.m1.3.3.3.3.cmml" xref="S3.E5.m1.3.3.3.3">ğ‘</ci><apply id="S3.E5.m1.3.3.3.1.1.1.cmml" xref="S3.E5.m1.3.3.3.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.3.1.1.1.1.cmml" xref="S3.E5.m1.3.3.3.1.1">subscript</csymbol><ci id="S3.E5.m1.3.3.3.1.1.1.2.cmml" xref="S3.E5.m1.3.3.3.1.1.1.2">ğ‘¥</ci><ci id="S3.E5.m1.3.3.3.1.1.1.3.cmml" xref="S3.E5.m1.3.3.3.1.1.1.3">ğ‘¡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.4c">p(c|x_{t})=\frac{p(x_{t}|c)\cdot p(c)}{p(x_{t})}\vspace{-2pt}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.p4.5" class="ltx_p">By taking the logarithm and derivative on <math id="S3.p4.5.m1.1" class="ltx_Math" alttext="x_{t}" display="inline"><semantics id="S3.p4.5.m1.1a"><msub id="S3.p4.5.m1.1.1" xref="S3.p4.5.m1.1.1.cmml"><mi id="S3.p4.5.m1.1.1.2" xref="S3.p4.5.m1.1.1.2.cmml">x</mi><mi id="S3.p4.5.m1.1.1.3" xref="S3.p4.5.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p4.5.m1.1b"><apply id="S3.p4.5.m1.1.1.cmml" xref="S3.p4.5.m1.1.1"><csymbol cd="ambiguous" id="S3.p4.5.m1.1.1.1.cmml" xref="S3.p4.5.m1.1.1">subscript</csymbol><ci id="S3.p4.5.m1.1.1.2.cmml" xref="S3.p4.5.m1.1.1.2">ğ‘¥</ci><ci id="S3.p4.5.m1.1.1.3.cmml" xref="S3.p4.5.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.5.m1.1c">x_{t}</annotation></semantics></math>, the following equation is obtained:</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.3" class="ltx_Math" alttext="\nabla_{x_{t}}\log p(c|x_{t})\propto\nabla_{x_{t}}\log p(x_{t}|c)-\nabla_{x_{t}}\log p(x_{t})\vspace{-2pt}" display="block"><semantics id="S3.E6.m1.3a"><mrow id="S3.E6.m1.3.3" xref="S3.E6.m1.3.3.cmml"><mrow id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.cmml"><mrow id="S3.E6.m1.1.1.1.3" xref="S3.E6.m1.1.1.1.3.cmml"><mrow id="S3.E6.m1.1.1.1.3.1" xref="S3.E6.m1.1.1.1.3.1.cmml"><msub id="S3.E6.m1.1.1.1.3.1.1" xref="S3.E6.m1.1.1.1.3.1.1.cmml"><mo id="S3.E6.m1.1.1.1.3.1.1.2" xref="S3.E6.m1.1.1.1.3.1.1.2.cmml">âˆ‡</mo><msub id="S3.E6.m1.1.1.1.3.1.1.3" xref="S3.E6.m1.1.1.1.3.1.1.3.cmml"><mi id="S3.E6.m1.1.1.1.3.1.1.3.2" xref="S3.E6.m1.1.1.1.3.1.1.3.2.cmml">x</mi><mi id="S3.E6.m1.1.1.1.3.1.1.3.3" xref="S3.E6.m1.1.1.1.3.1.1.3.3.cmml">t</mi></msub></msub><mi id="S3.E6.m1.1.1.1.3.1.2" xref="S3.E6.m1.1.1.1.3.1.2.cmml">log</mi></mrow><mo lspace="0.167em" id="S3.E6.m1.1.1.1.3a" xref="S3.E6.m1.1.1.1.3.cmml">â¡</mo><mi id="S3.E6.m1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.3.2.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.2" xref="S3.E6.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E6.m1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E6.m1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.2.cmml">c</mi><mo fence="false" id="S3.E6.m1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.E6.m1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.1.1.1.3.2.cmml">x</mi><mi id="S3.E6.m1.1.1.1.1.1.1.3.3" xref="S3.E6.m1.1.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.3.3.4" xref="S3.E6.m1.3.3.4.cmml">âˆ</mo><mrow id="S3.E6.m1.3.3.3" xref="S3.E6.m1.3.3.3.cmml"><mrow id="S3.E6.m1.2.2.2.1" xref="S3.E6.m1.2.2.2.1.cmml"><mrow id="S3.E6.m1.2.2.2.1.3" xref="S3.E6.m1.2.2.2.1.3.cmml"><mrow id="S3.E6.m1.2.2.2.1.3.1" xref="S3.E6.m1.2.2.2.1.3.1.cmml"><msub id="S3.E6.m1.2.2.2.1.3.1.1" xref="S3.E6.m1.2.2.2.1.3.1.1.cmml"><mo rspace="0.167em" id="S3.E6.m1.2.2.2.1.3.1.1.2" xref="S3.E6.m1.2.2.2.1.3.1.1.2.cmml">âˆ‡</mo><msub id="S3.E6.m1.2.2.2.1.3.1.1.3" xref="S3.E6.m1.2.2.2.1.3.1.1.3.cmml"><mi id="S3.E6.m1.2.2.2.1.3.1.1.3.2" xref="S3.E6.m1.2.2.2.1.3.1.1.3.2.cmml">x</mi><mi id="S3.E6.m1.2.2.2.1.3.1.1.3.3" xref="S3.E6.m1.2.2.2.1.3.1.1.3.3.cmml">t</mi></msub></msub><mi id="S3.E6.m1.2.2.2.1.3.1.2" xref="S3.E6.m1.2.2.2.1.3.1.2.cmml">log</mi></mrow><mo lspace="0.167em" id="S3.E6.m1.2.2.2.1.3a" xref="S3.E6.m1.2.2.2.1.3.cmml">â¡</mo><mi id="S3.E6.m1.2.2.2.1.3.2" xref="S3.E6.m1.2.2.2.1.3.2.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.2.1.2" xref="S3.E6.m1.2.2.2.1.2.cmml">â€‹</mo><mrow id="S3.E6.m1.2.2.2.1.1.1" xref="S3.E6.m1.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.E6.m1.2.2.2.1.1.1.2" xref="S3.E6.m1.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E6.m1.2.2.2.1.1.1.1" xref="S3.E6.m1.2.2.2.1.1.1.1.cmml"><msub id="S3.E6.m1.2.2.2.1.1.1.1.2" xref="S3.E6.m1.2.2.2.1.1.1.1.2.cmml"><mi id="S3.E6.m1.2.2.2.1.1.1.1.2.2" xref="S3.E6.m1.2.2.2.1.1.1.1.2.2.cmml">x</mi><mi id="S3.E6.m1.2.2.2.1.1.1.1.2.3" xref="S3.E6.m1.2.2.2.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.E6.m1.2.2.2.1.1.1.1.1" xref="S3.E6.m1.2.2.2.1.1.1.1.1.cmml">|</mo><mi id="S3.E6.m1.2.2.2.1.1.1.1.3" xref="S3.E6.m1.2.2.2.1.1.1.1.3.cmml">c</mi></mrow><mo stretchy="false" id="S3.E6.m1.2.2.2.1.1.1.3" xref="S3.E6.m1.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.3.3.3.3" xref="S3.E6.m1.3.3.3.3.cmml">âˆ’</mo><mrow id="S3.E6.m1.3.3.3.2" xref="S3.E6.m1.3.3.3.2.cmml"><mrow id="S3.E6.m1.3.3.3.2.3" xref="S3.E6.m1.3.3.3.2.3.cmml"><mrow id="S3.E6.m1.3.3.3.2.3.1" xref="S3.E6.m1.3.3.3.2.3.1.cmml"><msub id="S3.E6.m1.3.3.3.2.3.1.1" xref="S3.E6.m1.3.3.3.2.3.1.1.cmml"><mo rspace="0.167em" id="S3.E6.m1.3.3.3.2.3.1.1.2" xref="S3.E6.m1.3.3.3.2.3.1.1.2.cmml">âˆ‡</mo><msub id="S3.E6.m1.3.3.3.2.3.1.1.3" xref="S3.E6.m1.3.3.3.2.3.1.1.3.cmml"><mi id="S3.E6.m1.3.3.3.2.3.1.1.3.2" xref="S3.E6.m1.3.3.3.2.3.1.1.3.2.cmml">x</mi><mi id="S3.E6.m1.3.3.3.2.3.1.1.3.3" xref="S3.E6.m1.3.3.3.2.3.1.1.3.3.cmml">t</mi></msub></msub><mi id="S3.E6.m1.3.3.3.2.3.1.2" xref="S3.E6.m1.3.3.3.2.3.1.2.cmml">log</mi></mrow><mo lspace="0.167em" id="S3.E6.m1.3.3.3.2.3a" xref="S3.E6.m1.3.3.3.2.3.cmml">â¡</mo><mi id="S3.E6.m1.3.3.3.2.3.2" xref="S3.E6.m1.3.3.3.2.3.2.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.3.2.2" xref="S3.E6.m1.3.3.3.2.2.cmml">â€‹</mo><mrow id="S3.E6.m1.3.3.3.2.1.1" xref="S3.E6.m1.3.3.3.2.1.1.1.cmml"><mo stretchy="false" id="S3.E6.m1.3.3.3.2.1.1.2" xref="S3.E6.m1.3.3.3.2.1.1.1.cmml">(</mo><msub id="S3.E6.m1.3.3.3.2.1.1.1" xref="S3.E6.m1.3.3.3.2.1.1.1.cmml"><mi id="S3.E6.m1.3.3.3.2.1.1.1.2" xref="S3.E6.m1.3.3.3.2.1.1.1.2.cmml">x</mi><mi id="S3.E6.m1.3.3.3.2.1.1.1.3" xref="S3.E6.m1.3.3.3.2.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S3.E6.m1.3.3.3.2.1.1.3" xref="S3.E6.m1.3.3.3.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.3b"><apply id="S3.E6.m1.3.3.cmml" xref="S3.E6.m1.3.3"><csymbol cd="latexml" id="S3.E6.m1.3.3.4.cmml" xref="S3.E6.m1.3.3.4">proportional-to</csymbol><apply id="S3.E6.m1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"><times id="S3.E6.m1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.2"></times><apply id="S3.E6.m1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.3"><apply id="S3.E6.m1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.3.1"><apply id="S3.E6.m1.1.1.1.3.1.1.cmml" xref="S3.E6.m1.1.1.1.3.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.3.1.1.1.cmml" xref="S3.E6.m1.1.1.1.3.1.1">subscript</csymbol><ci id="S3.E6.m1.1.1.1.3.1.1.2.cmml" xref="S3.E6.m1.1.1.1.3.1.1.2">âˆ‡</ci><apply id="S3.E6.m1.1.1.1.3.1.1.3.cmml" xref="S3.E6.m1.1.1.1.3.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.3.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.3.1.1.3">subscript</csymbol><ci id="S3.E6.m1.1.1.1.3.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.3.1.1.3.2">ğ‘¥</ci><ci id="S3.E6.m1.1.1.1.3.1.1.3.3.cmml" xref="S3.E6.m1.1.1.1.3.1.1.3.3">ğ‘¡</ci></apply></apply><log id="S3.E6.m1.1.1.1.3.1.2.cmml" xref="S3.E6.m1.1.1.1.3.1.2"></log></apply><ci id="S3.E6.m1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.3.2">ğ‘</ci></apply><apply id="S3.E6.m1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E6.m1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.E6.m1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.2">ğ‘</ci><apply id="S3.E6.m1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.3.2">ğ‘¥</ci><ci id="S3.E6.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply></apply><apply id="S3.E6.m1.3.3.3.cmml" xref="S3.E6.m1.3.3.3"><minus id="S3.E6.m1.3.3.3.3.cmml" xref="S3.E6.m1.3.3.3.3"></minus><apply id="S3.E6.m1.2.2.2.1.cmml" xref="S3.E6.m1.2.2.2.1"><times id="S3.E6.m1.2.2.2.1.2.cmml" xref="S3.E6.m1.2.2.2.1.2"></times><apply id="S3.E6.m1.2.2.2.1.3.cmml" xref="S3.E6.m1.2.2.2.1.3"><apply id="S3.E6.m1.2.2.2.1.3.1.cmml" xref="S3.E6.m1.2.2.2.1.3.1"><apply id="S3.E6.m1.2.2.2.1.3.1.1.cmml" xref="S3.E6.m1.2.2.2.1.3.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.1.3.1.1.1.cmml" xref="S3.E6.m1.2.2.2.1.3.1.1">subscript</csymbol><ci id="S3.E6.m1.2.2.2.1.3.1.1.2.cmml" xref="S3.E6.m1.2.2.2.1.3.1.1.2">âˆ‡</ci><apply id="S3.E6.m1.2.2.2.1.3.1.1.3.cmml" xref="S3.E6.m1.2.2.2.1.3.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.1.3.1.1.3.1.cmml" xref="S3.E6.m1.2.2.2.1.3.1.1.3">subscript</csymbol><ci id="S3.E6.m1.2.2.2.1.3.1.1.3.2.cmml" xref="S3.E6.m1.2.2.2.1.3.1.1.3.2">ğ‘¥</ci><ci id="S3.E6.m1.2.2.2.1.3.1.1.3.3.cmml" xref="S3.E6.m1.2.2.2.1.3.1.1.3.3">ğ‘¡</ci></apply></apply><log id="S3.E6.m1.2.2.2.1.3.1.2.cmml" xref="S3.E6.m1.2.2.2.1.3.1.2"></log></apply><ci id="S3.E6.m1.2.2.2.1.3.2.cmml" xref="S3.E6.m1.2.2.2.1.3.2">ğ‘</ci></apply><apply id="S3.E6.m1.2.2.2.1.1.1.1.cmml" xref="S3.E6.m1.2.2.2.1.1.1"><csymbol cd="latexml" id="S3.E6.m1.2.2.2.1.1.1.1.1.cmml" xref="S3.E6.m1.2.2.2.1.1.1.1.1">conditional</csymbol><apply id="S3.E6.m1.2.2.2.1.1.1.1.2.cmml" xref="S3.E6.m1.2.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.1.1.1.1.2.1.cmml" xref="S3.E6.m1.2.2.2.1.1.1.1.2">subscript</csymbol><ci id="S3.E6.m1.2.2.2.1.1.1.1.2.2.cmml" xref="S3.E6.m1.2.2.2.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.E6.m1.2.2.2.1.1.1.1.2.3.cmml" xref="S3.E6.m1.2.2.2.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.E6.m1.2.2.2.1.1.1.1.3.cmml" xref="S3.E6.m1.2.2.2.1.1.1.1.3">ğ‘</ci></apply></apply><apply id="S3.E6.m1.3.3.3.2.cmml" xref="S3.E6.m1.3.3.3.2"><times id="S3.E6.m1.3.3.3.2.2.cmml" xref="S3.E6.m1.3.3.3.2.2"></times><apply id="S3.E6.m1.3.3.3.2.3.cmml" xref="S3.E6.m1.3.3.3.2.3"><apply id="S3.E6.m1.3.3.3.2.3.1.cmml" xref="S3.E6.m1.3.3.3.2.3.1"><apply id="S3.E6.m1.3.3.3.2.3.1.1.cmml" xref="S3.E6.m1.3.3.3.2.3.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.3.2.3.1.1.1.cmml" xref="S3.E6.m1.3.3.3.2.3.1.1">subscript</csymbol><ci id="S3.E6.m1.3.3.3.2.3.1.1.2.cmml" xref="S3.E6.m1.3.3.3.2.3.1.1.2">âˆ‡</ci><apply id="S3.E6.m1.3.3.3.2.3.1.1.3.cmml" xref="S3.E6.m1.3.3.3.2.3.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.3.2.3.1.1.3.1.cmml" xref="S3.E6.m1.3.3.3.2.3.1.1.3">subscript</csymbol><ci id="S3.E6.m1.3.3.3.2.3.1.1.3.2.cmml" xref="S3.E6.m1.3.3.3.2.3.1.1.3.2">ğ‘¥</ci><ci id="S3.E6.m1.3.3.3.2.3.1.1.3.3.cmml" xref="S3.E6.m1.3.3.3.2.3.1.1.3.3">ğ‘¡</ci></apply></apply><log id="S3.E6.m1.3.3.3.2.3.1.2.cmml" xref="S3.E6.m1.3.3.3.2.3.1.2"></log></apply><ci id="S3.E6.m1.3.3.3.2.3.2.cmml" xref="S3.E6.m1.3.3.3.2.3.2">ğ‘</ci></apply><apply id="S3.E6.m1.3.3.3.2.1.1.1.cmml" xref="S3.E6.m1.3.3.3.2.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.3.2.1.1.1.1.cmml" xref="S3.E6.m1.3.3.3.2.1.1">subscript</csymbol><ci id="S3.E6.m1.3.3.3.2.1.1.1.2.cmml" xref="S3.E6.m1.3.3.3.2.1.1.1.2">ğ‘¥</ci><ci id="S3.E6.m1.3.3.3.2.1.1.1.3.cmml" xref="S3.E6.m1.3.3.3.2.1.1.1.3">ğ‘¡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.3c">\nabla_{x_{t}}\log p(c|x_{t})\propto\nabla_{x_{t}}\log p(x_{t}|c)-\nabla_{x_{t}}\log p(x_{t})\vspace{-2pt}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.p4.6" class="ltx_p">Therefore, the denoising process can be directed towards removing the conditional noise by interpreting the predicted noise from the models <math id="S3.p4.6.m1.1" class="ltx_Math" alttext="\epsilon_{\theta}" display="inline"><semantics id="S3.p4.6.m1.1a"><msub id="S3.p4.6.m1.1.1" xref="S3.p4.6.m1.1.1.cmml"><mi id="S3.p4.6.m1.1.1.2" xref="S3.p4.6.m1.1.1.2.cmml">Ïµ</mi><mi id="S3.p4.6.m1.1.1.3" xref="S3.p4.6.m1.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p4.6.m1.1b"><apply id="S3.p4.6.m1.1.1.cmml" xref="S3.p4.6.m1.1.1"><csymbol cd="ambiguous" id="S3.p4.6.m1.1.1.1.cmml" xref="S3.p4.6.m1.1.1">subscript</csymbol><ci id="S3.p4.6.m1.1.1.2.cmml" xref="S3.p4.6.m1.1.1.2">italic-Ïµ</ci><ci id="S3.p4.6.m1.1.1.3.cmml" xref="S3.p4.6.m1.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.6.m1.1c">\epsilon_{\theta}</annotation></semantics></math> as the score function:</p>
<table id="S3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.5" class="ltx_Math" alttext="\hat{\epsilon}_{\theta}(x_{t}|c)=\epsilon_{\theta}(x_{t}|\emptyset)-s\cdot(\sigma_{t}\nabla_{x_{t}}\log p(c|x_{t}))\propto\epsilon_{\theta}(x_{t}|\emptyset)+s\cdot(\epsilon_{\theta}(x_{t}|c)-\epsilon_{\theta}(x_{t}|\emptyset))\vspace{-1pt}" display="block"><semantics id="S3.E7.m1.5a"><mrow id="S3.E7.m1.5.5" xref="S3.E7.m1.5.5.cmml"><mrow id="S3.E7.m1.1.1.1" xref="S3.E7.m1.1.1.1.cmml"><msub id="S3.E7.m1.1.1.1.3" xref="S3.E7.m1.1.1.1.3.cmml"><mover accent="true" id="S3.E7.m1.1.1.1.3.2" xref="S3.E7.m1.1.1.1.3.2.cmml"><mi id="S3.E7.m1.1.1.1.3.2.2" xref="S3.E7.m1.1.1.1.3.2.2.cmml">Ïµ</mi><mo id="S3.E7.m1.1.1.1.3.2.1" xref="S3.E7.m1.1.1.1.3.2.1.cmml">^</mo></mover><mi id="S3.E7.m1.1.1.1.3.3" xref="S3.E7.m1.1.1.1.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.2" xref="S3.E7.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E7.m1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E7.m1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E7.m1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.cmml"><msub id="S3.E7.m1.1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.2.2" xref="S3.E7.m1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.E7.m1.1.1.1.1.1.1.2.3" xref="S3.E7.m1.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.E7.m1.1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.E7.m1.1.1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.1.1.3.cmml">c</mi></mrow><mo stretchy="false" id="S3.E7.m1.1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E7.m1.5.5.7" xref="S3.E7.m1.5.5.7.cmml">=</mo><mrow id="S3.E7.m1.3.3.3" xref="S3.E7.m1.3.3.3.cmml"><mrow id="S3.E7.m1.2.2.2.1" xref="S3.E7.m1.2.2.2.1.cmml"><msub id="S3.E7.m1.2.2.2.1.3" xref="S3.E7.m1.2.2.2.1.3.cmml"><mi id="S3.E7.m1.2.2.2.1.3.2" xref="S3.E7.m1.2.2.2.1.3.2.cmml">Ïµ</mi><mi id="S3.E7.m1.2.2.2.1.3.3" xref="S3.E7.m1.2.2.2.1.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.E7.m1.2.2.2.1.2" xref="S3.E7.m1.2.2.2.1.2.cmml">â€‹</mo><mrow id="S3.E7.m1.2.2.2.1.1.1" xref="S3.E7.m1.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.E7.m1.2.2.2.1.1.1.2" xref="S3.E7.m1.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E7.m1.2.2.2.1.1.1.1" xref="S3.E7.m1.2.2.2.1.1.1.1.cmml"><msub id="S3.E7.m1.2.2.2.1.1.1.1.2" xref="S3.E7.m1.2.2.2.1.1.1.1.2.cmml"><mi id="S3.E7.m1.2.2.2.1.1.1.1.2.2" xref="S3.E7.m1.2.2.2.1.1.1.1.2.2.cmml">x</mi><mi id="S3.E7.m1.2.2.2.1.1.1.1.2.3" xref="S3.E7.m1.2.2.2.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.E7.m1.2.2.2.1.1.1.1.1" xref="S3.E7.m1.2.2.2.1.1.1.1.1.cmml">|</mo><mi mathvariant="normal" id="S3.E7.m1.2.2.2.1.1.1.1.3" xref="S3.E7.m1.2.2.2.1.1.1.1.3.cmml">âˆ…</mi></mrow><mo stretchy="false" id="S3.E7.m1.2.2.2.1.1.1.3" xref="S3.E7.m1.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E7.m1.3.3.3.3" xref="S3.E7.m1.3.3.3.3.cmml">âˆ’</mo><mrow id="S3.E7.m1.3.3.3.2" xref="S3.E7.m1.3.3.3.2.cmml"><mi id="S3.E7.m1.3.3.3.2.3" xref="S3.E7.m1.3.3.3.2.3.cmml">s</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E7.m1.3.3.3.2.2" xref="S3.E7.m1.3.3.3.2.2.cmml">â‹…</mo><mrow id="S3.E7.m1.3.3.3.2.1.1" xref="S3.E7.m1.3.3.3.2.1.1.1.cmml"><mo stretchy="false" id="S3.E7.m1.3.3.3.2.1.1.2" xref="S3.E7.m1.3.3.3.2.1.1.1.cmml">(</mo><mrow id="S3.E7.m1.3.3.3.2.1.1.1" xref="S3.E7.m1.3.3.3.2.1.1.1.cmml"><msub id="S3.E7.m1.3.3.3.2.1.1.1.3" xref="S3.E7.m1.3.3.3.2.1.1.1.3.cmml"><mi id="S3.E7.m1.3.3.3.2.1.1.1.3.2" xref="S3.E7.m1.3.3.3.2.1.1.1.3.2.cmml">Ïƒ</mi><mi id="S3.E7.m1.3.3.3.2.1.1.1.3.3" xref="S3.E7.m1.3.3.3.2.1.1.1.3.3.cmml">t</mi></msub><mo lspace="0.167em" rspace="0em" id="S3.E7.m1.3.3.3.2.1.1.1.2" xref="S3.E7.m1.3.3.3.2.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E7.m1.3.3.3.2.1.1.1.4" xref="S3.E7.m1.3.3.3.2.1.1.1.4.cmml"><mrow id="S3.E7.m1.3.3.3.2.1.1.1.4.1" xref="S3.E7.m1.3.3.3.2.1.1.1.4.1.cmml"><msub id="S3.E7.m1.3.3.3.2.1.1.1.4.1.1" xref="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.cmml"><mo rspace="0.167em" id="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.2" xref="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.2.cmml">âˆ‡</mo><msub id="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.3" xref="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.3.cmml"><mi id="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.3.2" xref="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.3.2.cmml">x</mi><mi id="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.3.3" xref="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.3.3.cmml">t</mi></msub></msub><mi id="S3.E7.m1.3.3.3.2.1.1.1.4.1.2" xref="S3.E7.m1.3.3.3.2.1.1.1.4.1.2.cmml">log</mi></mrow><mo lspace="0.167em" id="S3.E7.m1.3.3.3.2.1.1.1.4a" xref="S3.E7.m1.3.3.3.2.1.1.1.4.cmml">â¡</mo><mi id="S3.E7.m1.3.3.3.2.1.1.1.4.2" xref="S3.E7.m1.3.3.3.2.1.1.1.4.2.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E7.m1.3.3.3.2.1.1.1.2a" xref="S3.E7.m1.3.3.3.2.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E7.m1.3.3.3.2.1.1.1.1.1" xref="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E7.m1.3.3.3.2.1.1.1.1.1.2" xref="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E7.m1.3.3.3.2.1.1.1.1.1.1" xref="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.cmml"><mi id="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.2" xref="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.2.cmml">c</mi><mo fence="false" id="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.1" xref="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.3" xref="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.3.cmml"><mi id="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.3.2" xref="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.3.2.cmml">x</mi><mi id="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.3.3" xref="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S3.E7.m1.3.3.3.2.1.1.1.1.1.3" xref="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E7.m1.3.3.3.2.1.1.3" xref="S3.E7.m1.3.3.3.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E7.m1.5.5.8" xref="S3.E7.m1.5.5.8.cmml">âˆ</mo><mrow id="S3.E7.m1.5.5.5" xref="S3.E7.m1.5.5.5.cmml"><mrow id="S3.E7.m1.4.4.4.1" xref="S3.E7.m1.4.4.4.1.cmml"><msub id="S3.E7.m1.4.4.4.1.3" xref="S3.E7.m1.4.4.4.1.3.cmml"><mi id="S3.E7.m1.4.4.4.1.3.2" xref="S3.E7.m1.4.4.4.1.3.2.cmml">Ïµ</mi><mi id="S3.E7.m1.4.4.4.1.3.3" xref="S3.E7.m1.4.4.4.1.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.E7.m1.4.4.4.1.2" xref="S3.E7.m1.4.4.4.1.2.cmml">â€‹</mo><mrow id="S3.E7.m1.4.4.4.1.1.1" xref="S3.E7.m1.4.4.4.1.1.1.1.cmml"><mo stretchy="false" id="S3.E7.m1.4.4.4.1.1.1.2" xref="S3.E7.m1.4.4.4.1.1.1.1.cmml">(</mo><mrow id="S3.E7.m1.4.4.4.1.1.1.1" xref="S3.E7.m1.4.4.4.1.1.1.1.cmml"><msub id="S3.E7.m1.4.4.4.1.1.1.1.2" xref="S3.E7.m1.4.4.4.1.1.1.1.2.cmml"><mi id="S3.E7.m1.4.4.4.1.1.1.1.2.2" xref="S3.E7.m1.4.4.4.1.1.1.1.2.2.cmml">x</mi><mi id="S3.E7.m1.4.4.4.1.1.1.1.2.3" xref="S3.E7.m1.4.4.4.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.E7.m1.4.4.4.1.1.1.1.1" xref="S3.E7.m1.4.4.4.1.1.1.1.1.cmml">|</mo><mi mathvariant="normal" id="S3.E7.m1.4.4.4.1.1.1.1.3" xref="S3.E7.m1.4.4.4.1.1.1.1.3.cmml">âˆ…</mi></mrow><mo stretchy="false" id="S3.E7.m1.4.4.4.1.1.1.3" xref="S3.E7.m1.4.4.4.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E7.m1.5.5.5.3" xref="S3.E7.m1.5.5.5.3.cmml">+</mo><mrow id="S3.E7.m1.5.5.5.2" xref="S3.E7.m1.5.5.5.2.cmml"><mi id="S3.E7.m1.5.5.5.2.3" xref="S3.E7.m1.5.5.5.2.3.cmml">s</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E7.m1.5.5.5.2.2" xref="S3.E7.m1.5.5.5.2.2.cmml">â‹…</mo><mrow id="S3.E7.m1.5.5.5.2.1.1" xref="S3.E7.m1.5.5.5.2.1.1.1.cmml"><mo stretchy="false" id="S3.E7.m1.5.5.5.2.1.1.2" xref="S3.E7.m1.5.5.5.2.1.1.1.cmml">(</mo><mrow id="S3.E7.m1.5.5.5.2.1.1.1" xref="S3.E7.m1.5.5.5.2.1.1.1.cmml"><mrow id="S3.E7.m1.5.5.5.2.1.1.1.1" xref="S3.E7.m1.5.5.5.2.1.1.1.1.cmml"><msub id="S3.E7.m1.5.5.5.2.1.1.1.1.3" xref="S3.E7.m1.5.5.5.2.1.1.1.1.3.cmml"><mi id="S3.E7.m1.5.5.5.2.1.1.1.1.3.2" xref="S3.E7.m1.5.5.5.2.1.1.1.1.3.2.cmml">Ïµ</mi><mi id="S3.E7.m1.5.5.5.2.1.1.1.1.3.3" xref="S3.E7.m1.5.5.5.2.1.1.1.1.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.E7.m1.5.5.5.2.1.1.1.1.2" xref="S3.E7.m1.5.5.5.2.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E7.m1.5.5.5.2.1.1.1.1.1.1" xref="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.2" xref="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1" xref="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.cmml"><msub id="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.2" xref="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.2.2" xref="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.2.3" xref="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.1" xref="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.3" xref="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.3.cmml">c</mi></mrow><mo stretchy="false" id="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.3" xref="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E7.m1.5.5.5.2.1.1.1.3" xref="S3.E7.m1.5.5.5.2.1.1.1.3.cmml">âˆ’</mo><mrow id="S3.E7.m1.5.5.5.2.1.1.1.2" xref="S3.E7.m1.5.5.5.2.1.1.1.2.cmml"><msub id="S3.E7.m1.5.5.5.2.1.1.1.2.3" xref="S3.E7.m1.5.5.5.2.1.1.1.2.3.cmml"><mi id="S3.E7.m1.5.5.5.2.1.1.1.2.3.2" xref="S3.E7.m1.5.5.5.2.1.1.1.2.3.2.cmml">Ïµ</mi><mi id="S3.E7.m1.5.5.5.2.1.1.1.2.3.3" xref="S3.E7.m1.5.5.5.2.1.1.1.2.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.E7.m1.5.5.5.2.1.1.1.2.2" xref="S3.E7.m1.5.5.5.2.1.1.1.2.2.cmml">â€‹</mo><mrow id="S3.E7.m1.5.5.5.2.1.1.1.2.1.1" xref="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.cmml"><mo stretchy="false" id="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.2" xref="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.cmml">(</mo><mrow id="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1" xref="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.cmml"><msub id="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.2" xref="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.2.cmml"><mi id="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.2.2" xref="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.2.2.cmml">x</mi><mi id="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.2.3" xref="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.1" xref="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.1.cmml">|</mo><mi mathvariant="normal" id="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.3" xref="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.3.cmml">âˆ…</mi></mrow><mo stretchy="false" id="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.3" xref="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.E7.m1.5.5.5.2.1.1.3" xref="S3.E7.m1.5.5.5.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.5b"><apply id="S3.E7.m1.5.5.cmml" xref="S3.E7.m1.5.5"><and id="S3.E7.m1.5.5a.cmml" xref="S3.E7.m1.5.5"></and><apply id="S3.E7.m1.5.5b.cmml" xref="S3.E7.m1.5.5"><eq id="S3.E7.m1.5.5.7.cmml" xref="S3.E7.m1.5.5.7"></eq><apply id="S3.E7.m1.1.1.1.cmml" xref="S3.E7.m1.1.1.1"><times id="S3.E7.m1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.2"></times><apply id="S3.E7.m1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.1.3">subscript</csymbol><apply id="S3.E7.m1.1.1.1.3.2.cmml" xref="S3.E7.m1.1.1.1.3.2"><ci id="S3.E7.m1.1.1.1.3.2.1.cmml" xref="S3.E7.m1.1.1.1.3.2.1">^</ci><ci id="S3.E7.m1.1.1.1.3.2.2.cmml" xref="S3.E7.m1.1.1.1.3.2.2">italic-Ïµ</ci></apply><ci id="S3.E7.m1.1.1.1.3.3.cmml" xref="S3.E7.m1.1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E7.m1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E7.m1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.E7.m1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.E7.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.E7.m1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3">ğ‘</ci></apply></apply><apply id="S3.E7.m1.3.3.3.cmml" xref="S3.E7.m1.3.3.3"><minus id="S3.E7.m1.3.3.3.3.cmml" xref="S3.E7.m1.3.3.3.3"></minus><apply id="S3.E7.m1.2.2.2.1.cmml" xref="S3.E7.m1.2.2.2.1"><times id="S3.E7.m1.2.2.2.1.2.cmml" xref="S3.E7.m1.2.2.2.1.2"></times><apply id="S3.E7.m1.2.2.2.1.3.cmml" xref="S3.E7.m1.2.2.2.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.2.1.3.1.cmml" xref="S3.E7.m1.2.2.2.1.3">subscript</csymbol><ci id="S3.E7.m1.2.2.2.1.3.2.cmml" xref="S3.E7.m1.2.2.2.1.3.2">italic-Ïµ</ci><ci id="S3.E7.m1.2.2.2.1.3.3.cmml" xref="S3.E7.m1.2.2.2.1.3.3">ğœƒ</ci></apply><apply id="S3.E7.m1.2.2.2.1.1.1.1.cmml" xref="S3.E7.m1.2.2.2.1.1.1"><csymbol cd="latexml" id="S3.E7.m1.2.2.2.1.1.1.1.1.cmml" xref="S3.E7.m1.2.2.2.1.1.1.1.1">conditional</csymbol><apply id="S3.E7.m1.2.2.2.1.1.1.1.2.cmml" xref="S3.E7.m1.2.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.2.1.1.1.1.2.1.cmml" xref="S3.E7.m1.2.2.2.1.1.1.1.2">subscript</csymbol><ci id="S3.E7.m1.2.2.2.1.1.1.1.2.2.cmml" xref="S3.E7.m1.2.2.2.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.E7.m1.2.2.2.1.1.1.1.2.3.cmml" xref="S3.E7.m1.2.2.2.1.1.1.1.2.3">ğ‘¡</ci></apply><emptyset id="S3.E7.m1.2.2.2.1.1.1.1.3.cmml" xref="S3.E7.m1.2.2.2.1.1.1.1.3"></emptyset></apply></apply><apply id="S3.E7.m1.3.3.3.2.cmml" xref="S3.E7.m1.3.3.3.2"><ci id="S3.E7.m1.3.3.3.2.2.cmml" xref="S3.E7.m1.3.3.3.2.2">â‹…</ci><ci id="S3.E7.m1.3.3.3.2.3.cmml" xref="S3.E7.m1.3.3.3.2.3">ğ‘ </ci><apply id="S3.E7.m1.3.3.3.2.1.1.1.cmml" xref="S3.E7.m1.3.3.3.2.1.1"><times id="S3.E7.m1.3.3.3.2.1.1.1.2.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.2"></times><apply id="S3.E7.m1.3.3.3.2.1.1.1.3.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.3.3.3.2.1.1.1.3.1.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.3">subscript</csymbol><ci id="S3.E7.m1.3.3.3.2.1.1.1.3.2.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.3.2">ğœ</ci><ci id="S3.E7.m1.3.3.3.2.1.1.1.3.3.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.E7.m1.3.3.3.2.1.1.1.4.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.4"><apply id="S3.E7.m1.3.3.3.2.1.1.1.4.1.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.4.1"><apply id="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.4.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.1.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.4.1.1">subscript</csymbol><ci id="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.2.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.2">âˆ‡</ci><apply id="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.3.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.3.1.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.3">subscript</csymbol><ci id="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.3.2.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.3.2">ğ‘¥</ci><ci id="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.3.3.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.4.1.1.3.3">ğ‘¡</ci></apply></apply><log id="S3.E7.m1.3.3.3.2.1.1.1.4.1.2.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.4.1.2"></log></apply><ci id="S3.E7.m1.3.3.3.2.1.1.1.4.2.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.4.2">ğ‘</ci></apply><apply id="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.1.1"><csymbol cd="latexml" id="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.2">ğ‘</ci><apply id="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.3.1.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.3.2.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.3.2">ğ‘¥</ci><ci id="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.3.3.cmml" xref="S3.E7.m1.3.3.3.2.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply></apply></apply></apply></apply><apply id="S3.E7.m1.5.5c.cmml" xref="S3.E7.m1.5.5"><csymbol cd="latexml" id="S3.E7.m1.5.5.8.cmml" xref="S3.E7.m1.5.5.8">proportional-to</csymbol><share href="#S3.E7.m1.3.3.3.cmml" id="S3.E7.m1.5.5d.cmml" xref="S3.E7.m1.5.5"></share><apply id="S3.E7.m1.5.5.5.cmml" xref="S3.E7.m1.5.5.5"><plus id="S3.E7.m1.5.5.5.3.cmml" xref="S3.E7.m1.5.5.5.3"></plus><apply id="S3.E7.m1.4.4.4.1.cmml" xref="S3.E7.m1.4.4.4.1"><times id="S3.E7.m1.4.4.4.1.2.cmml" xref="S3.E7.m1.4.4.4.1.2"></times><apply id="S3.E7.m1.4.4.4.1.3.cmml" xref="S3.E7.m1.4.4.4.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.4.1.3.1.cmml" xref="S3.E7.m1.4.4.4.1.3">subscript</csymbol><ci id="S3.E7.m1.4.4.4.1.3.2.cmml" xref="S3.E7.m1.4.4.4.1.3.2">italic-Ïµ</ci><ci id="S3.E7.m1.4.4.4.1.3.3.cmml" xref="S3.E7.m1.4.4.4.1.3.3">ğœƒ</ci></apply><apply id="S3.E7.m1.4.4.4.1.1.1.1.cmml" xref="S3.E7.m1.4.4.4.1.1.1"><csymbol cd="latexml" id="S3.E7.m1.4.4.4.1.1.1.1.1.cmml" xref="S3.E7.m1.4.4.4.1.1.1.1.1">conditional</csymbol><apply id="S3.E7.m1.4.4.4.1.1.1.1.2.cmml" xref="S3.E7.m1.4.4.4.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.4.1.1.1.1.2.1.cmml" xref="S3.E7.m1.4.4.4.1.1.1.1.2">subscript</csymbol><ci id="S3.E7.m1.4.4.4.1.1.1.1.2.2.cmml" xref="S3.E7.m1.4.4.4.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.E7.m1.4.4.4.1.1.1.1.2.3.cmml" xref="S3.E7.m1.4.4.4.1.1.1.1.2.3">ğ‘¡</ci></apply><emptyset id="S3.E7.m1.4.4.4.1.1.1.1.3.cmml" xref="S3.E7.m1.4.4.4.1.1.1.1.3"></emptyset></apply></apply><apply id="S3.E7.m1.5.5.5.2.cmml" xref="S3.E7.m1.5.5.5.2"><ci id="S3.E7.m1.5.5.5.2.2.cmml" xref="S3.E7.m1.5.5.5.2.2">â‹…</ci><ci id="S3.E7.m1.5.5.5.2.3.cmml" xref="S3.E7.m1.5.5.5.2.3">ğ‘ </ci><apply id="S3.E7.m1.5.5.5.2.1.1.1.cmml" xref="S3.E7.m1.5.5.5.2.1.1"><minus id="S3.E7.m1.5.5.5.2.1.1.1.3.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.3"></minus><apply id="S3.E7.m1.5.5.5.2.1.1.1.1.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.1"><times id="S3.E7.m1.5.5.5.2.1.1.1.1.2.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.1.2"></times><apply id="S3.E7.m1.5.5.5.2.1.1.1.1.3.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.5.5.5.2.1.1.1.1.3.1.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.1.3">subscript</csymbol><ci id="S3.E7.m1.5.5.5.2.1.1.1.1.3.2.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.1.3.2">italic-Ïµ</ci><ci id="S3.E7.m1.5.5.5.2.1.1.1.1.3.3.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.1.1.1.1.3">ğ‘</ci></apply></apply><apply id="S3.E7.m1.5.5.5.2.1.1.1.2.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.2"><times id="S3.E7.m1.5.5.5.2.1.1.1.2.2.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.2.2"></times><apply id="S3.E7.m1.5.5.5.2.1.1.1.2.3.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.5.5.5.2.1.1.1.2.3.1.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.2.3">subscript</csymbol><ci id="S3.E7.m1.5.5.5.2.1.1.1.2.3.2.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.2.3.2">italic-Ïµ</ci><ci id="S3.E7.m1.5.5.5.2.1.1.1.2.3.3.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.2.3.3">ğœƒ</ci></apply><apply id="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.2.1.1"><csymbol cd="latexml" id="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.1.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.1">conditional</csymbol><apply id="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.2.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.2.1.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.2">subscript</csymbol><ci id="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.2.2.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.2.2">ğ‘¥</ci><ci id="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.2.3.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.2.3">ğ‘¡</ci></apply><emptyset id="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.3.cmml" xref="S3.E7.m1.5.5.5.2.1.1.1.2.1.1.1.3"></emptyset></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.5c">\hat{\epsilon}_{\theta}(x_{t}|c)=\epsilon_{\theta}(x_{t}|\emptyset)-s\cdot(\sigma_{t}\nabla_{x_{t}}\log p(c|x_{t}))\propto\epsilon_{\theta}(x_{t}|\emptyset)+s\cdot(\epsilon_{\theta}(x_{t}|c)-\epsilon_{\theta}(x_{t}|\emptyset))\vspace{-1pt}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S3.p4.13" class="ltx_p">where <math id="S3.p4.7.m1.1" class="ltx_Math" alttext="\epsilon_{\theta}(x_{t}|c)" display="inline"><semantics id="S3.p4.7.m1.1a"><mrow id="S3.p4.7.m1.1.1" xref="S3.p4.7.m1.1.1.cmml"><msub id="S3.p4.7.m1.1.1.3" xref="S3.p4.7.m1.1.1.3.cmml"><mi id="S3.p4.7.m1.1.1.3.2" xref="S3.p4.7.m1.1.1.3.2.cmml">Ïµ</mi><mi id="S3.p4.7.m1.1.1.3.3" xref="S3.p4.7.m1.1.1.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.p4.7.m1.1.1.2" xref="S3.p4.7.m1.1.1.2.cmml">â€‹</mo><mrow id="S3.p4.7.m1.1.1.1.1" xref="S3.p4.7.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.p4.7.m1.1.1.1.1.2" xref="S3.p4.7.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.p4.7.m1.1.1.1.1.1" xref="S3.p4.7.m1.1.1.1.1.1.cmml"><msub id="S3.p4.7.m1.1.1.1.1.1.2" xref="S3.p4.7.m1.1.1.1.1.1.2.cmml"><mi id="S3.p4.7.m1.1.1.1.1.1.2.2" xref="S3.p4.7.m1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.p4.7.m1.1.1.1.1.1.2.3" xref="S3.p4.7.m1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.p4.7.m1.1.1.1.1.1.1" xref="S3.p4.7.m1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.p4.7.m1.1.1.1.1.1.3" xref="S3.p4.7.m1.1.1.1.1.1.3.cmml">c</mi></mrow><mo stretchy="false" id="S3.p4.7.m1.1.1.1.1.3" xref="S3.p4.7.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.7.m1.1b"><apply id="S3.p4.7.m1.1.1.cmml" xref="S3.p4.7.m1.1.1"><times id="S3.p4.7.m1.1.1.2.cmml" xref="S3.p4.7.m1.1.1.2"></times><apply id="S3.p4.7.m1.1.1.3.cmml" xref="S3.p4.7.m1.1.1.3"><csymbol cd="ambiguous" id="S3.p4.7.m1.1.1.3.1.cmml" xref="S3.p4.7.m1.1.1.3">subscript</csymbol><ci id="S3.p4.7.m1.1.1.3.2.cmml" xref="S3.p4.7.m1.1.1.3.2">italic-Ïµ</ci><ci id="S3.p4.7.m1.1.1.3.3.cmml" xref="S3.p4.7.m1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.p4.7.m1.1.1.1.1.1.cmml" xref="S3.p4.7.m1.1.1.1.1"><csymbol cd="latexml" id="S3.p4.7.m1.1.1.1.1.1.1.cmml" xref="S3.p4.7.m1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.p4.7.m1.1.1.1.1.1.2.cmml" xref="S3.p4.7.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.p4.7.m1.1.1.1.1.1.2.1.cmml" xref="S3.p4.7.m1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.p4.7.m1.1.1.1.1.1.2.2.cmml" xref="S3.p4.7.m1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.p4.7.m1.1.1.1.1.1.2.3.cmml" xref="S3.p4.7.m1.1.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.p4.7.m1.1.1.1.1.1.3.cmml" xref="S3.p4.7.m1.1.1.1.1.1.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.7.m1.1c">\epsilon_{\theta}(x_{t}|c)</annotation></semantics></math> is the sampled noise predicted at timestep <math id="S3.p4.8.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.p4.8.m2.1a"><mi id="S3.p4.8.m2.1.1" xref="S3.p4.8.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.p4.8.m2.1b"><ci id="S3.p4.8.m2.1.1.cmml" xref="S3.p4.8.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.8.m2.1c">t</annotation></semantics></math> with condition <math id="S3.p4.9.m3.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.p4.9.m3.1a"><mi id="S3.p4.9.m3.1.1" xref="S3.p4.9.m3.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.p4.9.m3.1b"><ci id="S3.p4.9.m3.1.1.cmml" xref="S3.p4.9.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.9.m3.1c">c</annotation></semantics></math>, and <math id="S3.p4.10.m4.1" class="ltx_Math" alttext="\epsilon_{\theta}(x_{t}|\emptyset)" display="inline"><semantics id="S3.p4.10.m4.1a"><mrow id="S3.p4.10.m4.1.1" xref="S3.p4.10.m4.1.1.cmml"><msub id="S3.p4.10.m4.1.1.3" xref="S3.p4.10.m4.1.1.3.cmml"><mi id="S3.p4.10.m4.1.1.3.2" xref="S3.p4.10.m4.1.1.3.2.cmml">Ïµ</mi><mi id="S3.p4.10.m4.1.1.3.3" xref="S3.p4.10.m4.1.1.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.p4.10.m4.1.1.2" xref="S3.p4.10.m4.1.1.2.cmml">â€‹</mo><mrow id="S3.p4.10.m4.1.1.1.1" xref="S3.p4.10.m4.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.p4.10.m4.1.1.1.1.2" xref="S3.p4.10.m4.1.1.1.1.1.cmml">(</mo><mrow id="S3.p4.10.m4.1.1.1.1.1" xref="S3.p4.10.m4.1.1.1.1.1.cmml"><msub id="S3.p4.10.m4.1.1.1.1.1.2" xref="S3.p4.10.m4.1.1.1.1.1.2.cmml"><mi id="S3.p4.10.m4.1.1.1.1.1.2.2" xref="S3.p4.10.m4.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.p4.10.m4.1.1.1.1.1.2.3" xref="S3.p4.10.m4.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.p4.10.m4.1.1.1.1.1.1" xref="S3.p4.10.m4.1.1.1.1.1.1.cmml">|</mo><mi mathvariant="normal" id="S3.p4.10.m4.1.1.1.1.1.3" xref="S3.p4.10.m4.1.1.1.1.1.3.cmml">âˆ…</mi></mrow><mo stretchy="false" id="S3.p4.10.m4.1.1.1.1.3" xref="S3.p4.10.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.10.m4.1b"><apply id="S3.p4.10.m4.1.1.cmml" xref="S3.p4.10.m4.1.1"><times id="S3.p4.10.m4.1.1.2.cmml" xref="S3.p4.10.m4.1.1.2"></times><apply id="S3.p4.10.m4.1.1.3.cmml" xref="S3.p4.10.m4.1.1.3"><csymbol cd="ambiguous" id="S3.p4.10.m4.1.1.3.1.cmml" xref="S3.p4.10.m4.1.1.3">subscript</csymbol><ci id="S3.p4.10.m4.1.1.3.2.cmml" xref="S3.p4.10.m4.1.1.3.2">italic-Ïµ</ci><ci id="S3.p4.10.m4.1.1.3.3.cmml" xref="S3.p4.10.m4.1.1.3.3">ğœƒ</ci></apply><apply id="S3.p4.10.m4.1.1.1.1.1.cmml" xref="S3.p4.10.m4.1.1.1.1"><csymbol cd="latexml" id="S3.p4.10.m4.1.1.1.1.1.1.cmml" xref="S3.p4.10.m4.1.1.1.1.1.1">conditional</csymbol><apply id="S3.p4.10.m4.1.1.1.1.1.2.cmml" xref="S3.p4.10.m4.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.p4.10.m4.1.1.1.1.1.2.1.cmml" xref="S3.p4.10.m4.1.1.1.1.1.2">subscript</csymbol><ci id="S3.p4.10.m4.1.1.1.1.1.2.2.cmml" xref="S3.p4.10.m4.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.p4.10.m4.1.1.1.1.1.2.3.cmml" xref="S3.p4.10.m4.1.1.1.1.1.2.3">ğ‘¡</ci></apply><emptyset id="S3.p4.10.m4.1.1.1.1.1.3.cmml" xref="S3.p4.10.m4.1.1.1.1.1.3"></emptyset></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.10.m4.1c">\epsilon_{\theta}(x_{t}|\emptyset)</annotation></semantics></math> is the unconditional predicted noise.
Here, the hyperparameter <math id="S3.p4.11.m5.1" class="ltx_Math" alttext="s\geq 1" display="inline"><semantics id="S3.p4.11.m5.1a"><mrow id="S3.p4.11.m5.1.1" xref="S3.p4.11.m5.1.1.cmml"><mi id="S3.p4.11.m5.1.1.2" xref="S3.p4.11.m5.1.1.2.cmml">s</mi><mo id="S3.p4.11.m5.1.1.1" xref="S3.p4.11.m5.1.1.1.cmml">â‰¥</mo><mn id="S3.p4.11.m5.1.1.3" xref="S3.p4.11.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.11.m5.1b"><apply id="S3.p4.11.m5.1.1.cmml" xref="S3.p4.11.m5.1.1"><geq id="S3.p4.11.m5.1.1.1.cmml" xref="S3.p4.11.m5.1.1.1"></geq><ci id="S3.p4.11.m5.1.1.2.cmml" xref="S3.p4.11.m5.1.1.2">ğ‘ </ci><cn type="integer" id="S3.p4.11.m5.1.1.3.cmml" xref="S3.p4.11.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.11.m5.1c">s\geq 1</annotation></semantics></math> is used to adjust the scale of the guidance, with <math id="S3.p4.12.m6.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.p4.12.m6.1a"><mi id="S3.p4.12.m6.1.1" xref="S3.p4.12.m6.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.p4.12.m6.1b"><ci id="S3.p4.12.m6.1.1.cmml" xref="S3.p4.12.m6.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.12.m6.1c">s</annotation></semantics></math>=1 indicating that no classifier-free guidance is employed. Additionally, <math id="S3.p4.13.m7.1" class="ltx_Math" alttext="\emptyset" display="inline"><semantics id="S3.p4.13.m7.1a"><mi mathvariant="normal" id="S3.p4.13.m7.1.1" xref="S3.p4.13.m7.1.1.cmml">âˆ…</mi><annotation-xml encoding="MathML-Content" id="S3.p4.13.m7.1b"><emptyset id="S3.p4.13.m7.1.1.cmml" xref="S3.p4.13.m7.1.1"></emptyset></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.13.m7.1c">\emptyset</annotation></semantics></math> represents a trainable "null" condition.
Based on the performance comparison between DiT, Glide, and SD in TableÂ <a href="#S3.T1" title="Table 1 â€£ 3 Method â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we default to use DiT as our synthetic data generator for knowledge distillation in this study. Data generation and student training details are presented in the supplementary material.</p>
</div>
<figure id="S3.T1" class="ltx_table ltx_align_floatright">
<div id="S3.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:385.9pt;height:69.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-24.2pt,4.3pt) scale(0.888663800535122,0.888663800535122) ;">
<table id="S3.T1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_t">Method</td>
<td id="S3.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t">#Syn Images</td>
<td id="S3.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">Epoch</td>
<td id="S3.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">AccÂ (%)</td>
</tr>
<tr id="S3.T1.1.1.2" class="ltx_tr">
<td id="S3.T1.1.1.2.1" class="ltx_td ltx_align_left ltx_border_t">GLIDEÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">nichol2021glide</span> </a></cite>
</td>
<td id="S3.T1.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t">200K</td>
<td id="S3.T1.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t">100</td>
<td id="S3.T1.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t">44.58</td>
</tr>
<tr id="S3.T1.1.1.3" class="ltx_tr">
<td id="S3.T1.1.1.3.1" class="ltx_td ltx_align_left">SDÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">rombach2022high</span> </a></cite>
</td>
<td id="S3.T1.1.1.3.2" class="ltx_td ltx_align_center">200K</td>
<td id="S3.T1.1.1.3.3" class="ltx_td ltx_align_center">100</td>
<td id="S3.T1.1.1.3.4" class="ltx_td ltx_align_center">39.95</td>
</tr>
<tr id="S3.T1.1.1.4" class="ltx_tr">
<td id="S3.T1.1.1.4.1" class="ltx_td ltx_align_left ltx_border_b">DiTÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">peebles2022scalable</span> </a></cite>
</td>
<td id="S3.T1.1.1.4.2" class="ltx_td ltx_align_center ltx_border_b">200K</td>
<td id="S3.T1.1.1.4.3" class="ltx_td ltx_align_center ltx_border_b">100</td>
<td id="S3.T1.1.1.4.4" class="ltx_td ltx_align_center ltx_border_b">54.64</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparison of three state-of-the-art diffusion models on ImageNet-1K using their default hyper-parameters to generate synthetic images. "#Syn Images" represents the total number of synthetic images. We use the pre-trained ResNet18 as the teacher to train the vanilla ResNet18 student model.</figcaption>
</figure>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.5" class="ltx_p"><span id="S3.p5.5.1" class="ltx_text ltx_font_bold">Knowledge Distillation.</span>
Originally proposed by Hinton et al.Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">hinton2015distilling</span> </a></cite>, knowledge distillation aims to transfer the knowledge of a pretrained heavy teacher model to a lightweight student model.
After the distillation, the student can master the expertise of the teacher and be used for final deployment. Specifically, the Kullback-LeiblerÂ (KL) divergence loss is utilized to match the output distribution of two models, which can be simply formulated as follows:</p>
<table id="S3.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E8.m1.1" class="ltx_Math" alttext="L_{kd}(q^{t},q^{s})=\tau^{2}KL(\sigma(q^{t}/\tau),\sigma(q^{s}/\tau)),\vspace{-1pt}" display="block"><semantics id="S3.E8.m1.1a"><mrow id="S3.E8.m1.1.1.1" xref="S3.E8.m1.1.1.1.1.cmml"><mrow id="S3.E8.m1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.cmml"><mrow id="S3.E8.m1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.2.cmml"><msub id="S3.E8.m1.1.1.1.1.2.4" xref="S3.E8.m1.1.1.1.1.2.4.cmml"><mi id="S3.E8.m1.1.1.1.1.2.4.2" xref="S3.E8.m1.1.1.1.1.2.4.2.cmml">L</mi><mrow id="S3.E8.m1.1.1.1.1.2.4.3" xref="S3.E8.m1.1.1.1.1.2.4.3.cmml"><mi id="S3.E8.m1.1.1.1.1.2.4.3.2" xref="S3.E8.m1.1.1.1.1.2.4.3.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.2.4.3.1" xref="S3.E8.m1.1.1.1.1.2.4.3.1.cmml">â€‹</mo><mi id="S3.E8.m1.1.1.1.1.2.4.3.3" xref="S3.E8.m1.1.1.1.1.2.4.3.3.cmml">d</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.2.3" xref="S3.E8.m1.1.1.1.1.2.3.cmml">â€‹</mo><mrow id="S3.E8.m1.1.1.1.1.2.2.2" xref="S3.E8.m1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S3.E8.m1.1.1.1.1.2.2.2.3" xref="S3.E8.m1.1.1.1.1.2.2.3.cmml">(</mo><msup id="S3.E8.m1.1.1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.2.cmml">q</mi><mi id="S3.E8.m1.1.1.1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msup><mo id="S3.E8.m1.1.1.1.1.2.2.2.4" xref="S3.E8.m1.1.1.1.1.2.2.3.cmml">,</mo><msup id="S3.E8.m1.1.1.1.1.2.2.2.2" xref="S3.E8.m1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E8.m1.1.1.1.1.2.2.2.2.2" xref="S3.E8.m1.1.1.1.1.2.2.2.2.2.cmml">q</mi><mi id="S3.E8.m1.1.1.1.1.2.2.2.2.3" xref="S3.E8.m1.1.1.1.1.2.2.2.2.3.cmml">s</mi></msup><mo stretchy="false" id="S3.E8.m1.1.1.1.1.2.2.2.5" xref="S3.E8.m1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E8.m1.1.1.1.1.5" xref="S3.E8.m1.1.1.1.1.5.cmml">=</mo><mrow id="S3.E8.m1.1.1.1.1.4" xref="S3.E8.m1.1.1.1.1.4.cmml"><msup id="S3.E8.m1.1.1.1.1.4.4" xref="S3.E8.m1.1.1.1.1.4.4.cmml"><mi id="S3.E8.m1.1.1.1.1.4.4.2" xref="S3.E8.m1.1.1.1.1.4.4.2.cmml">Ï„</mi><mn id="S3.E8.m1.1.1.1.1.4.4.3" xref="S3.E8.m1.1.1.1.1.4.4.3.cmml">2</mn></msup><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.4.3" xref="S3.E8.m1.1.1.1.1.4.3.cmml">â€‹</mo><mi id="S3.E8.m1.1.1.1.1.4.5" xref="S3.E8.m1.1.1.1.1.4.5.cmml">K</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.4.3a" xref="S3.E8.m1.1.1.1.1.4.3.cmml">â€‹</mo><mi id="S3.E8.m1.1.1.1.1.4.6" xref="S3.E8.m1.1.1.1.1.4.6.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.4.3b" xref="S3.E8.m1.1.1.1.1.4.3.cmml">â€‹</mo><mrow id="S3.E8.m1.1.1.1.1.4.2.2" xref="S3.E8.m1.1.1.1.1.4.2.3.cmml"><mo stretchy="false" id="S3.E8.m1.1.1.1.1.4.2.2.3" xref="S3.E8.m1.1.1.1.1.4.2.3.cmml">(</mo><mrow id="S3.E8.m1.1.1.1.1.3.1.1.1" xref="S3.E8.m1.1.1.1.1.3.1.1.1.cmml"><mi id="S3.E8.m1.1.1.1.1.3.1.1.1.3" xref="S3.E8.m1.1.1.1.1.3.1.1.1.3.cmml">Ïƒ</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.3.1.1.1.2" xref="S3.E8.m1.1.1.1.1.3.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E8.m1.1.1.1.1.3.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.cmml"><msup id="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.2.cmml"><mi id="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.2.2" xref="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.2.2.cmml">q</mi><mi id="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.2.3" xref="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.2.3.cmml">t</mi></msup><mo id="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.1.cmml">/</mo><mi id="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.3.cmml">Ï„</mi></mrow><mo stretchy="false" id="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E8.m1.1.1.1.1.4.2.2.4" xref="S3.E8.m1.1.1.1.1.4.2.3.cmml">,</mo><mrow id="S3.E8.m1.1.1.1.1.4.2.2.2" xref="S3.E8.m1.1.1.1.1.4.2.2.2.cmml"><mi id="S3.E8.m1.1.1.1.1.4.2.2.2.3" xref="S3.E8.m1.1.1.1.1.4.2.2.2.3.cmml">Ïƒ</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.4.2.2.2.2" xref="S3.E8.m1.1.1.1.1.4.2.2.2.2.cmml">â€‹</mo><mrow id="S3.E8.m1.1.1.1.1.4.2.2.2.1.1" xref="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.2" xref="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.cmml">(</mo><mrow id="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1" xref="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.cmml"><msup id="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.2" xref="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.2.cmml"><mi id="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.2.2" xref="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.2.2.cmml">q</mi><mi id="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.2.3" xref="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.2.3.cmml">s</mi></msup><mo id="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.1" xref="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.1.cmml">/</mo><mi id="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.3" xref="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.3.cmml">Ï„</mi></mrow><mo stretchy="false" id="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.3" xref="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E8.m1.1.1.1.1.4.2.2.5" xref="S3.E8.m1.1.1.1.1.4.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E8.m1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.1b"><apply id="S3.E8.m1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1"><eq id="S3.E8.m1.1.1.1.1.5.cmml" xref="S3.E8.m1.1.1.1.1.5"></eq><apply id="S3.E8.m1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.2"><times id="S3.E8.m1.1.1.1.1.2.3.cmml" xref="S3.E8.m1.1.1.1.1.2.3"></times><apply id="S3.E8.m1.1.1.1.1.2.4.cmml" xref="S3.E8.m1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.2.4.1.cmml" xref="S3.E8.m1.1.1.1.1.2.4">subscript</csymbol><ci id="S3.E8.m1.1.1.1.1.2.4.2.cmml" xref="S3.E8.m1.1.1.1.1.2.4.2">ğ¿</ci><apply id="S3.E8.m1.1.1.1.1.2.4.3.cmml" xref="S3.E8.m1.1.1.1.1.2.4.3"><times id="S3.E8.m1.1.1.1.1.2.4.3.1.cmml" xref="S3.E8.m1.1.1.1.1.2.4.3.1"></times><ci id="S3.E8.m1.1.1.1.1.2.4.3.2.cmml" xref="S3.E8.m1.1.1.1.1.2.4.3.2">ğ‘˜</ci><ci id="S3.E8.m1.1.1.1.1.2.4.3.3.cmml" xref="S3.E8.m1.1.1.1.1.2.4.3.3">ğ‘‘</ci></apply></apply><interval closure="open" id="S3.E8.m1.1.1.1.1.2.2.3.cmml" xref="S3.E8.m1.1.1.1.1.2.2.2"><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.2">ğ‘</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S3.E8.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E8.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E8.m1.1.1.1.1.2.2.2.2">superscript</csymbol><ci id="S3.E8.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E8.m1.1.1.1.1.2.2.2.2.2">ğ‘</ci><ci id="S3.E8.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E8.m1.1.1.1.1.2.2.2.2.3">ğ‘ </ci></apply></interval></apply><apply id="S3.E8.m1.1.1.1.1.4.cmml" xref="S3.E8.m1.1.1.1.1.4"><times id="S3.E8.m1.1.1.1.1.4.3.cmml" xref="S3.E8.m1.1.1.1.1.4.3"></times><apply id="S3.E8.m1.1.1.1.1.4.4.cmml" xref="S3.E8.m1.1.1.1.1.4.4"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.4.4.1.cmml" xref="S3.E8.m1.1.1.1.1.4.4">superscript</csymbol><ci id="S3.E8.m1.1.1.1.1.4.4.2.cmml" xref="S3.E8.m1.1.1.1.1.4.4.2">ğœ</ci><cn type="integer" id="S3.E8.m1.1.1.1.1.4.4.3.cmml" xref="S3.E8.m1.1.1.1.1.4.4.3">2</cn></apply><ci id="S3.E8.m1.1.1.1.1.4.5.cmml" xref="S3.E8.m1.1.1.1.1.4.5">ğ¾</ci><ci id="S3.E8.m1.1.1.1.1.4.6.cmml" xref="S3.E8.m1.1.1.1.1.4.6">ğ¿</ci><interval closure="open" id="S3.E8.m1.1.1.1.1.4.2.3.cmml" xref="S3.E8.m1.1.1.1.1.4.2.2"><apply id="S3.E8.m1.1.1.1.1.3.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.3.1.1.1"><times id="S3.E8.m1.1.1.1.1.3.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.3.1.1.1.2"></times><ci id="S3.E8.m1.1.1.1.1.3.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.3.1.1.1.3">ğœ</ci><apply id="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.3.1.1.1.1.1"><divide id="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.1"></divide><apply id="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.2.1.cmml" xref="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.2">superscript</csymbol><ci id="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.2.2.cmml" xref="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.2.2">ğ‘</ci><ci id="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.2.3.cmml" xref="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.3.1.1.1.1.1.1.3">ğœ</ci></apply></apply><apply id="S3.E8.m1.1.1.1.1.4.2.2.2.cmml" xref="S3.E8.m1.1.1.1.1.4.2.2.2"><times id="S3.E8.m1.1.1.1.1.4.2.2.2.2.cmml" xref="S3.E8.m1.1.1.1.1.4.2.2.2.2"></times><ci id="S3.E8.m1.1.1.1.1.4.2.2.2.3.cmml" xref="S3.E8.m1.1.1.1.1.4.2.2.2.3">ğœ</ci><apply id="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.4.2.2.2.1.1"><divide id="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.1"></divide><apply id="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.2.1.cmml" xref="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.2">superscript</csymbol><ci id="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.2.2.cmml" xref="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.2.2">ğ‘</ci><ci id="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.2.3.cmml" xref="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.2.3">ğ‘ </ci></apply><ci id="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.4.2.2.2.1.1.1.3">ğœ</ci></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.1c">L_{kd}(q^{t},q^{s})=\tau^{2}KL(\sigma(q^{t}/\tau),\sigma(q^{s}/\tau)),\vspace{-1pt}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p id="S3.p5.4" class="ltx_p">where <math id="S3.p5.1.m1.1" class="ltx_Math" alttext="q^{t}" display="inline"><semantics id="S3.p5.1.m1.1a"><msup id="S3.p5.1.m1.1.1" xref="S3.p5.1.m1.1.1.cmml"><mi id="S3.p5.1.m1.1.1.2" xref="S3.p5.1.m1.1.1.2.cmml">q</mi><mi id="S3.p5.1.m1.1.1.3" xref="S3.p5.1.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S3.p5.1.m1.1b"><apply id="S3.p5.1.m1.1.1.cmml" xref="S3.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p5.1.m1.1.1.1.cmml" xref="S3.p5.1.m1.1.1">superscript</csymbol><ci id="S3.p5.1.m1.1.1.2.cmml" xref="S3.p5.1.m1.1.1.2">ğ‘</ci><ci id="S3.p5.1.m1.1.1.3.cmml" xref="S3.p5.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.1.m1.1c">q^{t}</annotation></semantics></math> and <math id="S3.p5.2.m2.1" class="ltx_Math" alttext="q^{s}" display="inline"><semantics id="S3.p5.2.m2.1a"><msup id="S3.p5.2.m2.1.1" xref="S3.p5.2.m2.1.1.cmml"><mi id="S3.p5.2.m2.1.1.2" xref="S3.p5.2.m2.1.1.2.cmml">q</mi><mi id="S3.p5.2.m2.1.1.3" xref="S3.p5.2.m2.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S3.p5.2.m2.1b"><apply id="S3.p5.2.m2.1.1.cmml" xref="S3.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p5.2.m2.1.1.1.cmml" xref="S3.p5.2.m2.1.1">superscript</csymbol><ci id="S3.p5.2.m2.1.1.2.cmml" xref="S3.p5.2.m2.1.1.2">ğ‘</ci><ci id="S3.p5.2.m2.1.1.3.cmml" xref="S3.p5.2.m2.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.2.m2.1c">q^{s}</annotation></semantics></math> denote the logits predicted by the teacher and student. <math id="S3.p5.3.m3.1" class="ltx_Math" alttext="\sigma(\cdot)" display="inline"><semantics id="S3.p5.3.m3.1a"><mrow id="S3.p5.3.m3.1.2" xref="S3.p5.3.m3.1.2.cmml"><mi id="S3.p5.3.m3.1.2.2" xref="S3.p5.3.m3.1.2.2.cmml">Ïƒ</mi><mo lspace="0em" rspace="0em" id="S3.p5.3.m3.1.2.1" xref="S3.p5.3.m3.1.2.1.cmml">â€‹</mo><mrow id="S3.p5.3.m3.1.2.3.2" xref="S3.p5.3.m3.1.2.cmml"><mo stretchy="false" id="S3.p5.3.m3.1.2.3.2.1" xref="S3.p5.3.m3.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.p5.3.m3.1.1" xref="S3.p5.3.m3.1.1.cmml">â‹…</mo><mo stretchy="false" id="S3.p5.3.m3.1.2.3.2.2" xref="S3.p5.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p5.3.m3.1b"><apply id="S3.p5.3.m3.1.2.cmml" xref="S3.p5.3.m3.1.2"><times id="S3.p5.3.m3.1.2.1.cmml" xref="S3.p5.3.m3.1.2.1"></times><ci id="S3.p5.3.m3.1.2.2.cmml" xref="S3.p5.3.m3.1.2.2">ğœ</ci><ci id="S3.p5.3.m3.1.1.cmml" xref="S3.p5.3.m3.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.3.m3.1c">\sigma(\cdot)</annotation></semantics></math> is the softmax function and <math id="S3.p5.4.m4.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S3.p5.4.m4.1a"><mi id="S3.p5.4.m4.1.1" xref="S3.p5.4.m4.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S3.p5.4.m4.1b"><ci id="S3.p5.4.m4.1.1.cmml" xref="S3.p5.4.m4.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.4.m4.1c">\tau</annotation></semantics></math> is the temperature hyperparameter which controls the softness of probability distribution.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.2" class="ltx_p"><span id="S3.p6.2.1" class="ltx_text ltx_font_bold">Synthetic Data Knowledge Distillation Based on Diffusion ModelsÂ (DM-KD).</span>
An overview of our proposed method is illustrated in Fig.Â <a href="#S3.F1" title="Figure 1 â€£ 3 Method â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The framework consists of three models: the publicly available diffusion model, the pre-trained teacher model, and the untrained target student model.
The diffusion model is responsible for generating specified synthetic images, denoted as <math id="S3.p6.1.m1.1" class="ltx_Math" alttext="x^{n}" display="inline"><semantics id="S3.p6.1.m1.1a"><msup id="S3.p6.1.m1.1.1" xref="S3.p6.1.m1.1.1.cmml"><mi id="S3.p6.1.m1.1.1.2" xref="S3.p6.1.m1.1.1.2.cmml">x</mi><mi id="S3.p6.1.m1.1.1.3" xref="S3.p6.1.m1.1.1.3.cmml">n</mi></msup><annotation-xml encoding="MathML-Content" id="S3.p6.1.m1.1b"><apply id="S3.p6.1.m1.1.1.cmml" xref="S3.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p6.1.m1.1.1.1.cmml" xref="S3.p6.1.m1.1.1">superscript</csymbol><ci id="S3.p6.1.m1.1.1.2.cmml" xref="S3.p6.1.m1.1.1.2">ğ‘¥</ci><ci id="S3.p6.1.m1.1.1.3.cmml" xref="S3.p6.1.m1.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.1.m1.1c">x^{n}</annotation></semantics></math>, based on given conditions, such as class labels or text. After synthesis, we aim to distill the teacherâ€™s knowledge to the student on the synthetic dataset.
Given the unlabeled synthetic training dataset <math id="S3.p6.2.m2.1" class="ltx_Math" alttext="D=\{x^{n}\}_{n=1}^{N}" display="inline"><semantics id="S3.p6.2.m2.1a"><mrow id="S3.p6.2.m2.1.1" xref="S3.p6.2.m2.1.1.cmml"><mi id="S3.p6.2.m2.1.1.3" xref="S3.p6.2.m2.1.1.3.cmml">D</mi><mo id="S3.p6.2.m2.1.1.2" xref="S3.p6.2.m2.1.1.2.cmml">=</mo><msubsup id="S3.p6.2.m2.1.1.1" xref="S3.p6.2.m2.1.1.1.cmml"><mrow id="S3.p6.2.m2.1.1.1.1.1.1" xref="S3.p6.2.m2.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.p6.2.m2.1.1.1.1.1.1.2" xref="S3.p6.2.m2.1.1.1.1.1.2.cmml">{</mo><msup id="S3.p6.2.m2.1.1.1.1.1.1.1" xref="S3.p6.2.m2.1.1.1.1.1.1.1.cmml"><mi id="S3.p6.2.m2.1.1.1.1.1.1.1.2" xref="S3.p6.2.m2.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.p6.2.m2.1.1.1.1.1.1.1.3" xref="S3.p6.2.m2.1.1.1.1.1.1.1.3.cmml">n</mi></msup><mo stretchy="false" id="S3.p6.2.m2.1.1.1.1.1.1.3" xref="S3.p6.2.m2.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.p6.2.m2.1.1.1.1.3" xref="S3.p6.2.m2.1.1.1.1.3.cmml"><mi id="S3.p6.2.m2.1.1.1.1.3.2" xref="S3.p6.2.m2.1.1.1.1.3.2.cmml">n</mi><mo id="S3.p6.2.m2.1.1.1.1.3.1" xref="S3.p6.2.m2.1.1.1.1.3.1.cmml">=</mo><mn id="S3.p6.2.m2.1.1.1.1.3.3" xref="S3.p6.2.m2.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.p6.2.m2.1.1.1.3" xref="S3.p6.2.m2.1.1.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.p6.2.m2.1b"><apply id="S3.p6.2.m2.1.1.cmml" xref="S3.p6.2.m2.1.1"><eq id="S3.p6.2.m2.1.1.2.cmml" xref="S3.p6.2.m2.1.1.2"></eq><ci id="S3.p6.2.m2.1.1.3.cmml" xref="S3.p6.2.m2.1.1.3">ğ·</ci><apply id="S3.p6.2.m2.1.1.1.cmml" xref="S3.p6.2.m2.1.1.1"><csymbol cd="ambiguous" id="S3.p6.2.m2.1.1.1.2.cmml" xref="S3.p6.2.m2.1.1.1">superscript</csymbol><apply id="S3.p6.2.m2.1.1.1.1.cmml" xref="S3.p6.2.m2.1.1.1"><csymbol cd="ambiguous" id="S3.p6.2.m2.1.1.1.1.2.cmml" xref="S3.p6.2.m2.1.1.1">subscript</csymbol><set id="S3.p6.2.m2.1.1.1.1.1.2.cmml" xref="S3.p6.2.m2.1.1.1.1.1.1"><apply id="S3.p6.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.p6.2.m2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p6.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.p6.2.m2.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.p6.2.m2.1.1.1.1.1.1.1.2.cmml" xref="S3.p6.2.m2.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.p6.2.m2.1.1.1.1.1.1.1.3.cmml" xref="S3.p6.2.m2.1.1.1.1.1.1.1.3">ğ‘›</ci></apply></set><apply id="S3.p6.2.m2.1.1.1.1.3.cmml" xref="S3.p6.2.m2.1.1.1.1.3"><eq id="S3.p6.2.m2.1.1.1.1.3.1.cmml" xref="S3.p6.2.m2.1.1.1.1.3.1"></eq><ci id="S3.p6.2.m2.1.1.1.1.3.2.cmml" xref="S3.p6.2.m2.1.1.1.1.3.2">ğ‘›</ci><cn type="integer" id="S3.p6.2.m2.1.1.1.1.3.3.cmml" xref="S3.p6.2.m2.1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.p6.2.m2.1.1.1.3.cmml" xref="S3.p6.2.m2.1.1.1.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.2.m2.1c">D=\{x^{n}\}_{n=1}^{N}</annotation></semantics></math> generated by the diffusion model, we minimize the distillation loss between teacher and student models:</p>
<table id="S3.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E9.m1.1" class="ltx_Math" alttext="L_{stu}=\sum_{n}^{N}L_{kd}(f_{t}(x^{n}),f_{s}(x^{n})).\vspace{-2pt}" display="block"><semantics id="S3.E9.m1.1a"><mrow id="S3.E9.m1.1.1.1" xref="S3.E9.m1.1.1.1.1.cmml"><mrow id="S3.E9.m1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.cmml"><msub id="S3.E9.m1.1.1.1.1.4" xref="S3.E9.m1.1.1.1.1.4.cmml"><mi id="S3.E9.m1.1.1.1.1.4.2" xref="S3.E9.m1.1.1.1.1.4.2.cmml">L</mi><mrow id="S3.E9.m1.1.1.1.1.4.3" xref="S3.E9.m1.1.1.1.1.4.3.cmml"><mi id="S3.E9.m1.1.1.1.1.4.3.2" xref="S3.E9.m1.1.1.1.1.4.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.1.1.1.1.4.3.1" xref="S3.E9.m1.1.1.1.1.4.3.1.cmml">â€‹</mo><mi id="S3.E9.m1.1.1.1.1.4.3.3" xref="S3.E9.m1.1.1.1.1.4.3.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.1.1.1.1.4.3.1a" xref="S3.E9.m1.1.1.1.1.4.3.1.cmml">â€‹</mo><mi id="S3.E9.m1.1.1.1.1.4.3.4" xref="S3.E9.m1.1.1.1.1.4.3.4.cmml">u</mi></mrow></msub><mo rspace="0.111em" id="S3.E9.m1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.3.cmml">=</mo><mrow id="S3.E9.m1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.2.cmml"><munderover id="S3.E9.m1.1.1.1.1.2.3" xref="S3.E9.m1.1.1.1.1.2.3.cmml"><mo movablelimits="false" id="S3.E9.m1.1.1.1.1.2.3.2.2" xref="S3.E9.m1.1.1.1.1.2.3.2.2.cmml">âˆ‘</mo><mi id="S3.E9.m1.1.1.1.1.2.3.2.3" xref="S3.E9.m1.1.1.1.1.2.3.2.3.cmml">n</mi><mi id="S3.E9.m1.1.1.1.1.2.3.3" xref="S3.E9.m1.1.1.1.1.2.3.3.cmml">N</mi></munderover><mrow id="S3.E9.m1.1.1.1.1.2.2" xref="S3.E9.m1.1.1.1.1.2.2.cmml"><msub id="S3.E9.m1.1.1.1.1.2.2.4" xref="S3.E9.m1.1.1.1.1.2.2.4.cmml"><mi id="S3.E9.m1.1.1.1.1.2.2.4.2" xref="S3.E9.m1.1.1.1.1.2.2.4.2.cmml">L</mi><mrow id="S3.E9.m1.1.1.1.1.2.2.4.3" xref="S3.E9.m1.1.1.1.1.2.2.4.3.cmml"><mi id="S3.E9.m1.1.1.1.1.2.2.4.3.2" xref="S3.E9.m1.1.1.1.1.2.2.4.3.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.1.1.1.1.2.2.4.3.1" xref="S3.E9.m1.1.1.1.1.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E9.m1.1.1.1.1.2.2.4.3.3" xref="S3.E9.m1.1.1.1.1.2.2.4.3.3.cmml">d</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E9.m1.1.1.1.1.2.2.3" xref="S3.E9.m1.1.1.1.1.2.2.3.cmml">â€‹</mo><mrow id="S3.E9.m1.1.1.1.1.2.2.2.2" xref="S3.E9.m1.1.1.1.1.2.2.2.3.cmml"><mo stretchy="false" id="S3.E9.m1.1.1.1.1.2.2.2.2.3" xref="S3.E9.m1.1.1.1.1.2.2.2.3.cmml">(</mo><mrow id="S3.E9.m1.1.1.1.1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2.cmml">f</mi><mi id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">n</mi></msup><mo stretchy="false" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E9.m1.1.1.1.1.2.2.2.2.4" xref="S3.E9.m1.1.1.1.1.2.2.2.3.cmml">,</mo><mrow id="S3.E9.m1.1.1.1.1.2.2.2.2.2" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.cmml"><msub id="S3.E9.m1.1.1.1.1.2.2.2.2.2.3" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.3.cmml"><mi id="S3.E9.m1.1.1.1.1.2.2.2.2.2.3.2" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.3.2.cmml">f</mi><mi id="S3.E9.m1.1.1.1.1.2.2.2.2.2.3.3" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.3.3.cmml">s</mi></msub><mo lspace="0em" rspace="0em" id="S3.E9.m1.1.1.1.1.2.2.2.2.2.2" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.2.cmml">â€‹</mo><mrow id="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1.2" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1.1.cmml">(</mo><msup id="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1.1" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1.1.cmml"><mi id="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1.1.2" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.cmml">x</mi><mi id="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1.1.3" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1.1.3.cmml">n</mi></msup><mo stretchy="false" id="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1.3" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E9.m1.1.1.1.1.2.2.2.2.5" xref="S3.E9.m1.1.1.1.1.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E9.m1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E9.m1.1b"><apply id="S3.E9.m1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1"><eq id="S3.E9.m1.1.1.1.1.3.cmml" xref="S3.E9.m1.1.1.1.1.3"></eq><apply id="S3.E9.m1.1.1.1.1.4.cmml" xref="S3.E9.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.4.1.cmml" xref="S3.E9.m1.1.1.1.1.4">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.4.2.cmml" xref="S3.E9.m1.1.1.1.1.4.2">ğ¿</ci><apply id="S3.E9.m1.1.1.1.1.4.3.cmml" xref="S3.E9.m1.1.1.1.1.4.3"><times id="S3.E9.m1.1.1.1.1.4.3.1.cmml" xref="S3.E9.m1.1.1.1.1.4.3.1"></times><ci id="S3.E9.m1.1.1.1.1.4.3.2.cmml" xref="S3.E9.m1.1.1.1.1.4.3.2">ğ‘ </ci><ci id="S3.E9.m1.1.1.1.1.4.3.3.cmml" xref="S3.E9.m1.1.1.1.1.4.3.3">ğ‘¡</ci><ci id="S3.E9.m1.1.1.1.1.4.3.4.cmml" xref="S3.E9.m1.1.1.1.1.4.3.4">ğ‘¢</ci></apply></apply><apply id="S3.E9.m1.1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.2"><apply id="S3.E9.m1.1.1.1.1.2.3.cmml" xref="S3.E9.m1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.2.3.1.cmml" xref="S3.E9.m1.1.1.1.1.2.3">superscript</csymbol><apply id="S3.E9.m1.1.1.1.1.2.3.2.cmml" xref="S3.E9.m1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.2.3.2.1.cmml" xref="S3.E9.m1.1.1.1.1.2.3">subscript</csymbol><sum id="S3.E9.m1.1.1.1.1.2.3.2.2.cmml" xref="S3.E9.m1.1.1.1.1.2.3.2.2"></sum><ci id="S3.E9.m1.1.1.1.1.2.3.2.3.cmml" xref="S3.E9.m1.1.1.1.1.2.3.2.3">ğ‘›</ci></apply><ci id="S3.E9.m1.1.1.1.1.2.3.3.cmml" xref="S3.E9.m1.1.1.1.1.2.3.3">ğ‘</ci></apply><apply id="S3.E9.m1.1.1.1.1.2.2.cmml" xref="S3.E9.m1.1.1.1.1.2.2"><times id="S3.E9.m1.1.1.1.1.2.2.3.cmml" xref="S3.E9.m1.1.1.1.1.2.2.3"></times><apply id="S3.E9.m1.1.1.1.1.2.2.4.cmml" xref="S3.E9.m1.1.1.1.1.2.2.4"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.2.2.4.1.cmml" xref="S3.E9.m1.1.1.1.1.2.2.4">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.2.2.4.2.cmml" xref="S3.E9.m1.1.1.1.1.2.2.4.2">ğ¿</ci><apply id="S3.E9.m1.1.1.1.1.2.2.4.3.cmml" xref="S3.E9.m1.1.1.1.1.2.2.4.3"><times id="S3.E9.m1.1.1.1.1.2.2.4.3.1.cmml" xref="S3.E9.m1.1.1.1.1.2.2.4.3.1"></times><ci id="S3.E9.m1.1.1.1.1.2.2.4.3.2.cmml" xref="S3.E9.m1.1.1.1.1.2.2.4.3.2">ğ‘˜</ci><ci id="S3.E9.m1.1.1.1.1.2.2.4.3.3.cmml" xref="S3.E9.m1.1.1.1.1.2.2.4.3.3">ğ‘‘</ci></apply></apply><interval closure="open" id="S3.E9.m1.1.1.1.1.2.2.2.3.cmml" xref="S3.E9.m1.1.1.1.1.2.2.2.2"><apply id="S3.E9.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1"><times id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2">ğ‘“</ci><ci id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘›</ci></apply></apply><apply id="S3.E9.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2"><times id="S3.E9.m1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.2"></times><apply id="S3.E9.m1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.2.2.2.2.2.3.1.cmml" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.3">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.2.2.2.2.2.3.2.cmml" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.3.2">ğ‘“</ci><ci id="S3.E9.m1.1.1.1.1.2.2.2.2.2.3.3.cmml" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.3.3">ğ‘ </ci></apply><apply id="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1">superscript</csymbol><ci id="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1.1.2">ğ‘¥</ci><ci id="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1.1.3.cmml" xref="S3.E9.m1.1.1.1.1.2.2.2.2.2.1.1.1.3">ğ‘›</ci></apply></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E9.m1.1c">L_{stu}=\sum_{n}^{N}L_{kd}(f_{t}(x^{n}),f_{s}(x^{n})).\vspace{-2pt}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
<p id="S3.p6.4" class="ltx_p">where <math id="S3.p6.3.m1.1" class="ltx_Math" alttext="f_{t}" display="inline"><semantics id="S3.p6.3.m1.1a"><msub id="S3.p6.3.m1.1.1" xref="S3.p6.3.m1.1.1.cmml"><mi id="S3.p6.3.m1.1.1.2" xref="S3.p6.3.m1.1.1.2.cmml">f</mi><mi id="S3.p6.3.m1.1.1.3" xref="S3.p6.3.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p6.3.m1.1b"><apply id="S3.p6.3.m1.1.1.cmml" xref="S3.p6.3.m1.1.1"><csymbol cd="ambiguous" id="S3.p6.3.m1.1.1.1.cmml" xref="S3.p6.3.m1.1.1">subscript</csymbol><ci id="S3.p6.3.m1.1.1.2.cmml" xref="S3.p6.3.m1.1.1.2">ğ‘“</ci><ci id="S3.p6.3.m1.1.1.3.cmml" xref="S3.p6.3.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.3.m1.1c">f_{t}</annotation></semantics></math> and <math id="S3.p6.4.m2.1" class="ltx_Math" alttext="f_{s}" display="inline"><semantics id="S3.p6.4.m2.1a"><msub id="S3.p6.4.m2.1.1" xref="S3.p6.4.m2.1.1.cmml"><mi id="S3.p6.4.m2.1.1.2" xref="S3.p6.4.m2.1.1.2.cmml">f</mi><mi id="S3.p6.4.m2.1.1.3" xref="S3.p6.4.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p6.4.m2.1b"><apply id="S3.p6.4.m2.1.1.cmml" xref="S3.p6.4.m2.1.1"><csymbol cd="ambiguous" id="S3.p6.4.m2.1.1.1.cmml" xref="S3.p6.4.m2.1.1">subscript</csymbol><ci id="S3.p6.4.m2.1.1.2.cmml" xref="S3.p6.4.m2.1.1.2">ğ‘“</ci><ci id="S3.p6.4.m2.1.1.3.cmml" xref="S3.p6.4.m2.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.4.m2.1c">f_{s}</annotation></semantics></math> represent the function of teacher and student, respectively.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiment</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Settings.</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">Dataset.</span>
The CIFAR-100Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">krizhevsky2009learning</span> </a></cite> dataset consists of colored natural images with <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="32\times 32" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mn id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">32</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p1.1.m1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.cmml">Ã—</mo><mn id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><times id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1"></times><cn type="integer" id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">32</cn><cn type="integer" id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">32\times 32</annotation></semantics></math> pixels. The train and test sets have 50K images and 10K images respectively.
ImageNet-1KÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">deng2009imagenet</span> </a></cite> contains 1.28M images for training, and 50K for validation, from 1K classes.
We also extend our method to other datasets, including ImageNet-100Â (100 category), and Flowers-102Â (102 category)Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">nilsback2006visual</span> </a></cite>.
We use the synthetic dataset to train our student model and the real validation set to evaluate the performance.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.3" class="ltx_p"><span id="S4.SS1.p2.3.1" class="ltx_text ltx_font_bold">Data generation.</span> We select the 1K classes from ImageNet-1K as the default conditions for our data synthesis.
Each category generates an equal number of images, all of which have a size of <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="256\times 256" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mrow id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mn id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">256</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p2.1.m1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.cmml">Ã—</mo><mn id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><times id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1"></times><cn type="integer" id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">256</cn><cn type="integer" id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">256\times 256</annotation></semantics></math>. For instance, in a synthesized dataset of 200K images, every category contains 200 images.
To conduct our knowledge distillation experiments on ImageNet-1K, ImageNet-100, and Flowers-102 datasets, we resize the synthetic dataset to <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mrow id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><mn id="S4.SS1.p2.2.m2.1.1.2" xref="S4.SS1.p2.2.m2.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p2.2.m2.1.1.1" xref="S4.SS1.p2.2.m2.1.1.1.cmml">Ã—</mo><mn id="S4.SS1.p2.2.m2.1.1.3" xref="S4.SS1.p2.2.m2.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><times id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1.1"></times><cn type="integer" id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2">224</cn><cn type="integer" id="S4.SS1.p2.2.m2.1.1.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">224\times 224</annotation></semantics></math>. For CIFAR-100, the synthetic training dataset contains 50K images that are resized to <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="32\times 32" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><mrow id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml"><mn id="S4.SS1.p2.3.m3.1.1.2" xref="S4.SS1.p2.3.m3.1.1.2.cmml">32</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p2.3.m3.1.1.1" xref="S4.SS1.p2.3.m3.1.1.1.cmml">Ã—</mo><mn id="S4.SS1.p2.3.m3.1.1.3" xref="S4.SS1.p2.3.m3.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><apply id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1"><times id="S4.SS1.p2.3.m3.1.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1.1"></times><cn type="integer" id="S4.SS1.p2.3.m3.1.1.2.cmml" xref="S4.SS1.p2.3.m3.1.1.2">32</cn><cn type="integer" id="S4.SS1.p2.3.m3.1.1.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">32\times 32</annotation></semantics></math>.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Implementation details.</span>
All of the experiments are implemented by PytorchÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">paszke2019pytorch</span> </a></cite> and conducted on a server containing eight NVIDIA RTX 2080Ti GPUs.
We follow the same training schedule as previous knowledge distillation methodsÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">tian2019contrastive</span> </a>; <a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">chen2021distilling</span> </a></cite>.
We use the stochastic gradient descentsÂ (SGD) as the optimizer with momentum 0.9 and weight decay 5e-4.
For CIFAR-100, the initial learning rate is 0.05 and divided by 10 at 150, 180, and 210 epochs, for a total of 240 epochs. The mini-batch size is 64.
For ImageNet-1K, the weight decay is 1e-4 and the batch size is 256. The initial learning rate is set to 0.1 and divided by 10 at 30, 60, and 90 epochs, for a total of 100 epochs. We set the temperature <math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mi id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><ci id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">\tau</annotation></semantics></math> to 10 by default. For each dataset, we report the Top-1 classification accuracy. The results are averaged over 3 runs. More training details are presented in the supplementary material.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Comparison to existing synthesis-based distillation methods.</h3>

<figure id="S4.T2" class="ltx_table">
<div id="S4.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:135.2pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-121.5pt,37.7pt) scale(0.640846176053621,0.640846176053621) ;">
<table id="S4.T2.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.1.1.1" class="ltx_tr">
<td id="S4.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T2.1.1.1.1.1" class="ltx_text">Method</span></td>
<td id="S4.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T2.1.1.1.2.1" class="ltx_text">Syn Method</span></td>
<td id="S4.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">T:ResNet34</td>
<td id="S4.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">T:VGG11</td>
<td id="S4.T2.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t">T:WRN40-2</td>
<td id="S4.T2.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t">T:WRN40-2</td>
<td id="S4.T2.1.1.1.7" class="ltx_td ltx_align_center ltx_border_t">T:WRN40-2</td>
</tr>
<tr id="S4.T2.1.1.2" class="ltx_tr">
<td id="S4.T2.1.1.2.1" class="ltx_td ltx_align_center">S:ResNet18</td>
<td id="S4.T2.1.1.2.2" class="ltx_td ltx_align_center">S:ResNet18</td>
<td id="S4.T2.1.1.2.3" class="ltx_td ltx_align_center">S:WRN16-1</td>
<td id="S4.T2.1.1.2.4" class="ltx_td ltx_align_center">S:WRN40-1</td>
<td id="S4.T2.1.1.2.5" class="ltx_td ltx_align_center">S:WRN16-2</td>
</tr>
<tr id="S4.T2.1.1.3" class="ltx_tr">
<td id="S4.T2.1.1.3.1" class="ltx_td ltx_align_center ltx_border_t">Teacher</td>
<td id="S4.T2.1.1.3.2" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S4.T2.1.1.3.3" class="ltx_td ltx_align_center ltx_border_t">78.05</td>
<td id="S4.T2.1.1.3.4" class="ltx_td ltx_align_center ltx_border_t">71.32</td>
<td id="S4.T2.1.1.3.5" class="ltx_td ltx_align_center ltx_border_t">75.83</td>
<td id="S4.T2.1.1.3.6" class="ltx_td ltx_align_center ltx_border_t">75.83</td>
<td id="S4.T2.1.1.3.7" class="ltx_td ltx_align_center ltx_border_t">75.83</td>
</tr>
<tr id="S4.T2.1.1.4" class="ltx_tr">
<td id="S4.T2.1.1.4.1" class="ltx_td ltx_align_center">Student</td>
<td id="S4.T2.1.1.4.2" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.4.3" class="ltx_td ltx_align_center">77.10</td>
<td id="S4.T2.1.1.4.4" class="ltx_td ltx_align_center">77.10</td>
<td id="S4.T2.1.1.4.5" class="ltx_td ltx_align_center">65.31</td>
<td id="S4.T2.1.1.4.6" class="ltx_td ltx_align_center">72.19</td>
<td id="S4.T2.1.1.4.7" class="ltx_td ltx_align_center">73.56</td>
</tr>
<tr id="S4.T2.1.1.5" class="ltx_tr">
<td id="S4.T2.1.1.5.1" class="ltx_td ltx_align_center">KD</td>
<td id="S4.T2.1.1.5.2" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.1.1.5.3" class="ltx_td ltx_align_center">77.87</td>
<td id="S4.T2.1.1.5.4" class="ltx_td ltx_align_center">75.07</td>
<td id="S4.T2.1.1.5.5" class="ltx_td ltx_align_center">64.06</td>
<td id="S4.T2.1.1.5.6" class="ltx_td ltx_align_center">68.58</td>
<td id="S4.T2.1.1.5.7" class="ltx_td ltx_align_center">70.79</td>
</tr>
<tr id="S4.T2.1.1.6" class="ltx_tr">
<td id="S4.T2.1.1.6.1" class="ltx_td ltx_align_center ltx_border_t">DeepInvÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">yin2020dreaming</span> </a></cite>
</td>
<td id="S4.T2.1.1.6.2" class="ltx_td ltx_align_center ltx_border_t">Inversion</td>
<td id="S4.T2.1.1.6.3" class="ltx_td ltx_align_center ltx_border_t">61.32</td>
<td id="S4.T2.1.1.6.4" class="ltx_td ltx_align_center ltx_border_t">54.13</td>
<td id="S4.T2.1.1.6.5" class="ltx_td ltx_align_center ltx_border_t">53.77</td>
<td id="S4.T2.1.1.6.6" class="ltx_td ltx_align_center ltx_border_t">61.33</td>
<td id="S4.T2.1.1.6.7" class="ltx_td ltx_align_center ltx_border_t">61.34</td>
</tr>
<tr id="S4.T2.1.1.7" class="ltx_tr">
<td id="S4.T2.1.1.7.1" class="ltx_td ltx_align_center">DAFLÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">chen2019data</span> </a></cite>
</td>
<td id="S4.T2.1.1.7.2" class="ltx_td ltx_align_center">Inversion</td>
<td id="S4.T2.1.1.7.3" class="ltx_td ltx_align_center">74.47</td>
<td id="S4.T2.1.1.7.4" class="ltx_td ltx_align_center">54.16</td>
<td id="S4.T2.1.1.7.5" class="ltx_td ltx_align_center">20.88</td>
<td id="S4.T2.1.1.7.6" class="ltx_td ltx_align_center">42.83</td>
<td id="S4.T2.1.1.7.7" class="ltx_td ltx_align_center">43.70</td>
</tr>
<tr id="S4.T2.1.1.8" class="ltx_tr">
<td id="S4.T2.1.1.8.1" class="ltx_td ltx_align_center">DFQÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">choi2020data</span> </a></cite>
</td>
<td id="S4.T2.1.1.8.2" class="ltx_td ltx_align_center">Inversion</td>
<td id="S4.T2.1.1.8.3" class="ltx_td ltx_align_center">77.01</td>
<td id="S4.T2.1.1.8.4" class="ltx_td ltx_align_center">66.21</td>
<td id="S4.T2.1.1.8.5" class="ltx_td ltx_align_center">51.27</td>
<td id="S4.T2.1.1.8.6" class="ltx_td ltx_align_center">54.43</td>
<td id="S4.T2.1.1.8.7" class="ltx_td ltx_align_center">64.79</td>
</tr>
<tr id="S4.T2.1.1.9" class="ltx_tr">
<td id="S4.T2.1.1.9.1" class="ltx_td ltx_align_center">FastDFKDÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">fang2022up</span> </a></cite>
</td>
<td id="S4.T2.1.1.9.2" class="ltx_td ltx_align_center">Inversion</td>
<td id="S4.T2.1.1.9.3" class="ltx_td ltx_align_center">74.34</td>
<td id="S4.T2.1.1.9.4" class="ltx_td ltx_align_center">67.44</td>
<td id="S4.T2.1.1.9.5" class="ltx_td ltx_align_center">54.02</td>
<td id="S4.T2.1.1.9.6" class="ltx_td ltx_align_center">63.91</td>
<td id="S4.T2.1.1.9.7" class="ltx_td ltx_align_center">65.12</td>
</tr>
<tr id="S4.T2.1.1.10" class="ltx_tr">
<td id="S4.T2.1.1.10.1" class="ltx_td ltx_align_center ltx_border_t">One-ImageÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">asano2023the</span> </a></cite>
</td>
<td id="S4.T2.1.1.10.2" class="ltx_td ltx_align_center ltx_border_t">Augmentation</td>
<td id="S4.T2.1.1.10.3" class="ltx_td ltx_align_center ltx_border_t">74.56</td>
<td id="S4.T2.1.1.10.4" class="ltx_td ltx_align_center ltx_border_t">68.51</td>
<td id="S4.T2.1.1.10.5" class="ltx_td ltx_align_center ltx_border_t">34.62</td>
<td id="S4.T2.1.1.10.6" class="ltx_td ltx_align_center ltx_border_t">52.39</td>
<td id="S4.T2.1.1.10.7" class="ltx_td ltx_align_center ltx_border_t">54.71</td>
</tr>
<tr id="S4.T2.1.1.11" class="ltx_tr">
<td id="S4.T2.1.1.11.1" class="ltx_td ltx_align_center ltx_border_b">DM-KDÂ (Ours)</td>
<td id="S4.T2.1.1.11.2" class="ltx_td ltx_align_center ltx_border_b">Diffusion</td>
<td id="S4.T2.1.1.11.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T2.1.1.11.3.1" class="ltx_text ltx_font_bold">76.58</span></td>
<td id="S4.T2.1.1.11.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T2.1.1.11.4.1" class="ltx_text ltx_font_bold">70.83</span></td>
<td id="S4.T2.1.1.11.5" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T2.1.1.11.5.1" class="ltx_text ltx_font_bold">56.29</span></td>
<td id="S4.T2.1.1.11.6" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T2.1.1.11.6.1" class="ltx_text ltx_font_bold">65.01</span></td>
<td id="S4.T2.1.1.11.7" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T2.1.1.11.7.1" class="ltx_text ltx_font_bold">66.89</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Student accuracy on CIFAR-100 validation set. </figcaption>
</figure>
<figure id="S4.T3" class="ltx_table">
<div id="S4.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:390.3pt;height:119.4pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-120.2pt,36.6pt) scale(0.618854851436865,0.618854851436865) ;">
<table id="S4.T3.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<td id="S4.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T3.1.1.1.1.1" class="ltx_text">Method</span></td>
<td id="S4.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T3.1.1.1.2.1" class="ltx_text">Syn Method</span></td>
<td id="S4.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T3.1.1.1.3.1" class="ltx_text">Data Amount</span></td>
<td id="S4.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T3.1.1.1.4.1" class="ltx_text">Epoch</span></td>
<td id="S4.T3.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t">T: ResNet50/18</td>
<td id="S4.T3.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t">T: ResNet50/18</td>
</tr>
<tr id="S4.T3.1.1.2" class="ltx_tr">
<td id="S4.T3.1.1.2.1" class="ltx_td ltx_align_center">S: ResNet50</td>
<td id="S4.T3.1.1.2.2" class="ltx_td ltx_align_center">S: ResNet18</td>
</tr>
<tr id="S4.T3.1.1.3" class="ltx_tr">
<td id="S4.T3.1.1.3.1" class="ltx_td ltx_align_center ltx_border_t">Places365+KD</td>
<td id="S4.T3.1.1.3.2" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S4.T3.1.1.3.3" class="ltx_td ltx_align_center ltx_border_t">1.8M</td>
<td id="S4.T3.1.1.3.4" class="ltx_td ltx_align_center ltx_border_t">200</td>
<td id="S4.T3.1.1.3.5" class="ltx_td ltx_align_center ltx_border_t">55.74</td>
<td id="S4.T3.1.1.3.6" class="ltx_td ltx_align_center ltx_border_t">45.53</td>
</tr>
<tr id="S4.T3.1.1.4" class="ltx_tr">
<td id="S4.T3.1.1.4.1" class="ltx_td ltx_align_center">BigGANÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">brock2018large</span> </a></cite>
</td>
<td id="S4.T3.1.1.4.2" class="ltx_td ltx_align_center">GAN</td>
<td id="S4.T3.1.1.4.3" class="ltx_td ltx_align_center">215K</td>
<td id="S4.T3.1.1.4.4" class="ltx_td ltx_align_center">90</td>
<td id="S4.T3.1.1.4.5" class="ltx_td ltx_align_center">64.00</td>
<td id="S4.T3.1.1.4.6" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T3.1.1.5" class="ltx_tr">
<td id="S4.T3.1.1.5.1" class="ltx_td ltx_align_center">DeepInvÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">yin2020dreaming</span> </a></cite>
</td>
<td id="S4.T3.1.1.5.2" class="ltx_td ltx_align_center">Inversion</td>
<td id="S4.T3.1.1.5.3" class="ltx_td ltx_align_center">140K</td>
<td id="S4.T3.1.1.5.4" class="ltx_td ltx_align_center">90</td>
<td id="S4.T3.1.1.5.5" class="ltx_td ltx_align_center">68.00</td>
<td id="S4.T3.1.1.5.6" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T3.1.1.6" class="ltx_tr">
<td id="S4.T3.1.1.6.1" class="ltx_td ltx_align_center">FastDFKDÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">fang2022up</span> </a></cite>
</td>
<td id="S4.T3.1.1.6.2" class="ltx_td ltx_align_center">Inversion</td>
<td id="S4.T3.1.1.6.3" class="ltx_td ltx_align_center">140K</td>
<td id="S4.T3.1.1.6.4" class="ltx_td ltx_align_center">200</td>
<td id="S4.T3.1.1.6.5" class="ltx_td ltx_align_center">68.61</td>
<td id="S4.T3.1.1.6.6" class="ltx_td ltx_align_center">53.45</td>
</tr>
<tr id="S4.T3.1.1.7" class="ltx_tr">
<td id="S4.T3.1.1.7.1" class="ltx_td ltx_align_center ltx_border_t">One-ImageÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">asano2023the</span> </a></cite>
</td>
<td id="S4.T3.1.1.7.2" class="ltx_td ltx_align_center ltx_border_t">Augmentation</td>
<td id="S4.T3.1.1.7.3" class="ltx_td ltx_align_center ltx_border_t">1.28M</td>
<td id="S4.T3.1.1.7.4" class="ltx_td ltx_align_center ltx_border_t">200</td>
<td id="S4.T3.1.1.7.5" class="ltx_td ltx_align_center ltx_border_t">66.20</td>
<td id="S4.T3.1.1.7.6" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S4.T3.1.1.8" class="ltx_tr">
<td id="S4.T3.1.1.8.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" rowspan="3"><span id="S4.T3.1.1.8.1.1" class="ltx_text">DM-KDÂ (Ours)</span></td>
<td id="S4.T3.1.1.8.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" rowspan="3"><span id="S4.T3.1.1.8.2.1" class="ltx_text">Diffusion</span></td>
<td id="S4.T3.1.1.8.3" class="ltx_td ltx_align_center ltx_border_t">140K</td>
<td id="S4.T3.1.1.8.4" class="ltx_td ltx_align_center ltx_border_t">200</td>
<td id="S4.T3.1.1.8.5" class="ltx_td ltx_align_center ltx_border_t">66.74</td>
<td id="S4.T3.1.1.8.6" class="ltx_td ltx_align_center ltx_border_t">60.10</td>
</tr>
<tr id="S4.T3.1.1.9" class="ltx_tr">
<td id="S4.T3.1.1.9.1" class="ltx_td ltx_align_center">200K</td>
<td id="S4.T3.1.1.9.2" class="ltx_td ltx_align_center">200</td>
<td id="S4.T3.1.1.9.3" class="ltx_td ltx_align_center">68.63</td>
<td id="S4.T3.1.1.9.4" class="ltx_td ltx_align_center">61.61</td>
</tr>
<tr id="S4.T3.1.1.10" class="ltx_tr">
<td id="S4.T3.1.1.10.1" class="ltx_td ltx_align_center ltx_border_b">1.28M</td>
<td id="S4.T3.1.1.10.2" class="ltx_td ltx_align_center ltx_border_b">200</td>
<td id="S4.T3.1.1.10.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T3.1.1.10.3.1" class="ltx_text ltx_font_bold">72.43</span></td>
<td id="S4.T3.1.1.10.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T3.1.1.10.4.1" class="ltx_text ltx_font_bold">68.25</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Student accuracy on ImageNet-1K validation set.
</figcaption>
</figure>
<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_bold">Data-free Distillation.</span>
Existing data-free distillation methods are all based on the white-box teacher model for distillation. These methods primarily utilize information within the white-box teacher model, such as layer statistics, to generate samples and construct training sets that approximate the original data for distillation.
Previous methods have three limitations. Firstly, it requires careful of design of the generative method, which is complex and time-consuming. Secondly, it becomes ineffective when the white-box teacher model is not available and only predictions through APIs are provided. Thirdly, current methods face difficulties in scaling with larger data volumes due to the limited diversity of synthetic dataÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">luo2020large</span> </a>; <a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">choi2020data</span> </a>; <a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">fang2021contrastive</span> </a></cite>.
Our method effectively solves the above problems. By adopting the publicly available advanced diffusion model, samples can also be generated when the teacher is a black-box model. At the same time, the large-scale diffusion model can easily generate a large number of diverse high-resolution samples for distillation.
In TablesÂ <a href="#S4.T2" title="Table 2 â€£ 4.2 Comparison to existing synthesis-based distillation methods. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> andÂ <a href="#S4.T3" title="Table 3 â€£ 4.2 Comparison to existing synthesis-based distillation methods. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we compare our method with mainstream data-free methods, and our method shows very competitive performance when trained on the same amount of synthetic data. By simply introducing more synthetic training samples, our method significantly improves the performance of data-free distillation by a large margin, as shown in TableÂ <a href="#S4.T3" title="Table 3 â€£ 4.2 Comparison to existing synthesis-based distillation methods. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">One Image Distillation.</span>
One-Image-DistillÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">asano2023the</span> </a></cite> first performs multiple random crops on a large imageÂ (i.e., <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="2560\times 1920" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mrow id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mn id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml">2560</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p2.1.m1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.1.cmml">Ã—</mo><mn id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3.cmml">1920</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><times id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1"></times><cn type="integer" id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2">2560</cn><cn type="integer" id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3">1920</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">2560\times 1920</annotation></semantics></math>), and then applies data augmentation techniques to the cropped images to create a synthetic image set. The synthetic dataset contains approximately 50K images for CIFAR-100 and 1.28M images for ImageNet-1K.
Itâ€™s critical to carefully select the source image for One-Image-Distill since sparse images will perform much worse than dense images as mentioned in the original paper. However, our method doesnâ€™t require such detailed selection operations. We can directly generate images through the diffusion model given the target label space.
As shown in TableÂ <a href="#S4.T2" title="Table 2 â€£ 4.2 Comparison to existing synthesis-based distillation methods. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and TableÂ <a href="#S4.T3" title="Table 3 â€£ 4.2 Comparison to existing synthesis-based distillation methods. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, our method shows better performance for the same or larger data volume.
Note that the results in TableÂ <a href="#S4.T2" title="Table 2 â€£ 4.2 Comparison to existing synthesis-based distillation methods. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> were not reported in the original paper, so we adopt the "Animals" image and reimplement the method based on the official code<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://github.com/yukimasano/single-img-extrapolating</span></span></span>.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p"><span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_bold">Extension to other datasets.</span>
Our synthetic dataset is generated based on the 1K classes of ImageNet-1K. To verify the generalizability of our method, we extended it to other datasets, including CIFAR-100Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">krizhevsky2009learning</span> </a></cite>, ImageNet-100Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">deng2009imagenet</span> </a></cite>, and Flowers-102Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">nilsback2006visual</span> </a></cite>. Specifically, the teacher pre-trains on the specified real dataset and then performs knowledge distillation based on our synthetic dataset. The results are reported in TablesÂ <a href="#S4.T2" title="Table 2 â€£ 4.2 Comparison to existing synthesis-based distillation methods. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> andÂ <a href="#S4.T4" title="Table 4 â€£ 4.2 Comparison to existing synthesis-based distillation methods. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, and the excellent performance on these three datasets indicates our method demonstrates good generalization to other datasets. Notably, it is surprising to find that our method achieved a great distillation performance on the fine-grained Flowers-102 dataset, even though the synthetic dataset categories do not intersect with the Flowers-102 dataset categories.
There are two possible reasons for such a good generalization. First, the 1K classes of the synthetic data contain most of the common classes, enabling students to learn robust general features during training. Second, in knowledge distillation, the influence of data domain shift on students can be effectively weakened by the supervision of the pretrained teacher model.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2305.12954/assets/x2.png" id="S4.F2.g1" class="ltx_graphics ltx_img_square" width="368" height="371" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Visualized fidelity of synthetic images with different scaling factors <math id="S4.F2.7.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.F2.7.m1.1b"><mi id="S4.F2.7.m1.1.1" xref="S4.F2.7.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.F2.7.m1.1c"><ci id="S4.F2.7.m1.1.1.cmml" xref="S4.F2.7.m1.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.7.m1.1d">s</annotation></semantics></math> and sampling steps <math id="S4.F2.8.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.F2.8.m2.1b"><mi id="S4.F2.8.m2.1.1" xref="S4.F2.8.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.F2.8.m2.1c"><ci id="S4.F2.8.m2.1.1.cmml" xref="S4.F2.8.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.8.m2.1d">T</annotation></semantics></math>. Increasing the value of <math id="S4.F2.9.m3.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.F2.9.m3.1b"><mi id="S4.F2.9.m3.1.1" xref="S4.F2.9.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.F2.9.m3.1c"><ci id="S4.F2.9.m3.1.1.cmml" xref="S4.F2.9.m3.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.9.m3.1d">s</annotation></semantics></math> or <math id="S4.F2.10.m4.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.F2.10.m4.1b"><mi id="S4.F2.10.m4.1.1" xref="S4.F2.10.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.F2.10.m4.1c"><ci id="S4.F2.10.m4.1.1.cmml" xref="S4.F2.10.m4.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.10.m4.1d">T</annotation></semantics></math> results in higher fidelity images. The example images generated with <math id="S4.F2.11.m5.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.F2.11.m5.1b"><mi id="S4.F2.11.m5.1.1" xref="S4.F2.11.m5.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.F2.11.m5.1c"><ci id="S4.F2.11.m5.1.1.cmml" xref="S4.F2.11.m5.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.11.m5.1d">s</annotation></semantics></math>=2 contain unrealistic elements, such as a dog with two heads or a church building that is unnaturally distorted, and their fidelity and coherence are much lower than those generated with <math id="S4.F2.12.m6.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.F2.12.m6.1b"><mi id="S4.F2.12.m6.1.1" xref="S4.F2.12.m6.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.F2.12.m6.1c"><ci id="S4.F2.12.m6.1.1.cmml" xref="S4.F2.12.m6.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.12.m6.1d">s</annotation></semantics></math>=4.</figcaption>
</figure>
<figure id="S4.T4" class="ltx_table">
<div id="S4.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:333.9pt;height:34.9pt;vertical-align:-0.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-225.2pt,23.3pt) scale(0.425733096840942,0.425733096840942) ;">
<table id="S4.T4.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.1.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T4.1.1.1.1.1" class="ltx_text">Datasets</span></td>
<td id="S4.T4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t">Categories</td>
<td id="S4.T4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">Teacher</td>
<td id="S4.T4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">One-ImageÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">asano2023the</span> </a></cite>
</td>
<td id="S4.T4.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t">Ours</td>
</tr>
<tr id="S4.T4.1.1.2" class="ltx_tr">
<td id="S4.T4.1.1.2.1" class="ltx_td ltx_align_center">(#Classes)</td>
<td id="S4.T4.1.1.2.2" class="ltx_td ltx_align_center">ResNet18</td>
<td id="S4.T4.1.1.2.3" class="ltx_td ltx_align_center">ResNet50</td>
<td id="S4.T4.1.1.2.4" class="ltx_td ltx_align_center">ResNet50</td>
</tr>
<tr id="S4.T4.1.1.3" class="ltx_tr">
<td id="S4.T4.1.1.3.1" class="ltx_td ltx_align_center ltx_border_t">ImageNet-100Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">deng2009imagenet</span> </a></cite>
</td>
<td id="S4.T4.1.1.3.2" class="ltx_td ltx_align_center ltx_border_t">ObjectsÂ (100)</td>
<td id="S4.T4.1.1.3.3" class="ltx_td ltx_align_center ltx_border_t">89.6</td>
<td id="S4.T4.1.1.3.4" class="ltx_td ltx_align_center ltx_border_t">84.4</td>
<td id="S4.T4.1.1.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.1.3.5.1" class="ltx_text ltx_font_bold">85.9</span></td>
</tr>
<tr id="S4.T4.1.1.4" class="ltx_tr">
<td id="S4.T4.1.1.4.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">Flowers-102Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">nilsback2006visual</span> </a></cite>
</td>
<td id="S4.T4.1.1.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">Flower typesÂ (102)</td>
<td id="S4.T4.1.1.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">87.9</td>
<td id="S4.T4.1.1.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">81.5</td>
<td id="S4.T4.1.1.4.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T4.1.1.4.5.1" class="ltx_text ltx_font_bold">85.4</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Student accuracy on ImageNet-100, and Flowers-102 datasets. Our DM-KD demonstrates good generalization to other datasets. Notably, even when there is no intersection of categories between the synthetic dataset and the Flowers-102 dataset, our method still achieves high performance.</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Low-fidelity synthetic images are better teaching materials.</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.10" class="ltx_p">When synthesizing images, two hyperparameters determine the overall fidelity of the synthetic images: the value of the classifier-free guidance scaling factor <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mi id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">s</annotation></semantics></math>, and the total number of sampling steps <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mi id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><ci id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">T</annotation></semantics></math>.
In general, the parameter <math id="S4.SS3.p1.3.m3.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS3.p1.3.m3.1a"><mi id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><ci id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">s</annotation></semantics></math> controls the strength of the injection of conditional distinction features.n A higher value of <math id="S4.SS3.p1.4.m4.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS3.p1.4.m4.1a"><mi id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><ci id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">s</annotation></semantics></math> produces an image with richer conditional features and higher image fidelity. Conversely, a lower value of <math id="S4.SS3.p1.5.m5.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS3.p1.5.m5.1a"><mi id="S4.SS3.p1.5.m5.1.1" xref="S4.SS3.p1.5.m5.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.5.m5.1b"><ci id="S4.SS3.p1.5.m5.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.5.m5.1c">s</annotation></semantics></math>Â (where <math id="S4.SS3.p1.6.m6.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS3.p1.6.m6.1a"><mi id="S4.SS3.p1.6.m6.1.1" xref="S4.SS3.p1.6.m6.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.6.m6.1b"><ci id="S4.SS3.p1.6.m6.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.6.m6.1c">s</annotation></semantics></math>=1 means no guidance) produces an image with lower fidelity, sometimes, even with image distortion and deformation.
Another parameter, <math id="S4.SS3.p1.7.m7.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p1.7.m7.1a"><mi id="S4.SS3.p1.7.m7.1.1" xref="S4.SS3.p1.7.m7.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.7.m7.1b"><ci id="S4.SS3.p1.7.m7.1.1.cmml" xref="S4.SS3.p1.7.m7.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.7.m7.1c">T</annotation></semantics></math>, determines the number of denoising timesteps carried out during image generation. Typically, a larger value of <math id="S4.SS3.p1.8.m8.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p1.8.m8.1a"><mi id="S4.SS3.p1.8.m8.1.1" xref="S4.SS3.p1.8.m8.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.8.m8.1b"><ci id="S4.SS3.p1.8.m8.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.8.m8.1c">T</annotation></semantics></math> results in a more detailed image with higher fidelity, but it also increases the generation time. DiT uses <math id="S4.SS3.p1.9.m9.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS3.p1.9.m9.1a"><mi id="S4.SS3.p1.9.m9.1.1" xref="S4.SS3.p1.9.m9.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.9.m9.1b"><ci id="S4.SS3.p1.9.m9.1.1.cmml" xref="S4.SS3.p1.9.m9.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.9.m9.1c">s</annotation></semantics></math>=4 and <math id="S4.SS3.p1.10.m10.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p1.10.m10.1a"><mi id="S4.SS3.p1.10.m10.1.1" xref="S4.SS3.p1.10.m10.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.10.m10.1b"><ci id="S4.SS3.p1.10.m10.1.1.cmml" xref="S4.SS3.p1.10.m10.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.10.m10.1c">T</annotation></semantics></math>=250 as its default parameters for high-fidelity image synthesis.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.4" class="ltx_p">To investigate the relationship between synthetic fidelity and distillation performance, datasets are synthesized using the DiT model with varying classifier-free guidance scaling factorsÂ (<math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mi id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><ci id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">s</annotation></semantics></math>) and sampling stepsÂ (<math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mi id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><ci id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">T</annotation></semantics></math>).
Examples of different categories from the synthesized datasets with different scaling factors <math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mi id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><ci id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">s</annotation></semantics></math> and sampling steps <math id="S4.SS3.p2.4.m4.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p2.4.m4.1a"><mi id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><ci id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">T</annotation></semantics></math> are visualized in Fig.Â <a href="#S4.F2" title="Figure 2 â€£ 4.2 Comparison to existing synthesis-based distillation methods. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
In this paper, the fidelity of the synthesized datasets is evaluated using the ImageRewardÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">xu2023imagereward</span> </a></cite> metric, which is the state-of-the-art in synthesis dataset evaluation. The ImageReward metric scores are presented in Table Â <a href="#S4.SS3" title="4.3 Low-fidelity synthetic images are better teaching materials. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>, where higher scores indicate higher fidelity and human preference. In this section, both teacher and student models adopt the ResNet18 model. For the teacher model, we use the pre-trained weights on torchvisionÂ <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://pytorch.org/vision/main/models.html</span></span></span>. The experiments are conducted on 200K synthetic datasets and the students are trained by 100 epochs for experimental efficiency.</p>
</div>
<div id="S4.SS3.12" class="ltx_logical-block ltx_minipage ltx_align_middle" style="width:433.6pt;">
<figure id="S4.SS3.6.6" class="ltx_figure ltx_minipage ltx_align_top" style="width:216.8pt;">
<div id="S4.SS3.2.2.2.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:407.6pt;height:184.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(74.5pt,-33.7pt) scale(1.57565894871155,1.57565894871155) ;">
<table id="S4.SS3.2.2.2.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S4.SS3.2.2.2.2.2.2" class="ltx_tr">
<td id="S4.SS3.1.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.SS3.1.1.1.1.1.1.1.1" class="ltx_text"><span id="S4.SS3.1.1.1.1.1.1.1.1.2" class="ltx_text"></span> <span id="S4.SS3.1.1.1.1.1.1.1.1.1" class="ltx_text">
<span id="S4.SS3.1.1.1.1.1.1.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.SS3.1.1.1.1.1.1.1.1.1.1.2" class="ltx_tr">
<span id="S4.SS3.1.1.1.1.1.1.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Scaling</span></span>
<span id="S4.SS3.1.1.1.1.1.1.1.1.1.1.1" class="ltx_tr">
<span id="S4.SS3.1.1.1.1.1.1.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Factor <math id="S4.SS3.1.1.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS3.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mi id="S4.SS3.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S4.SS3.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="S4.SS3.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.SS3.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">s</annotation></semantics></math></span></span>
</span></span> <span id="S4.SS3.1.1.1.1.1.1.1.1.3" class="ltx_text"></span></span></td>
<td id="S4.SS3.2.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t" colspan="5">Sampling Step <math id="S4.SS3.2.2.2.2.2.2.2.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.2.2.2.2.2.2.2.m1.1a"><mi id="S4.SS3.2.2.2.2.2.2.2.m1.1.1" xref="S4.SS3.2.2.2.2.2.2.2.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.2.2.2.2.2.2.2.m1.1b"><ci id="S4.SS3.2.2.2.2.2.2.2.m1.1.1.cmml" xref="S4.SS3.2.2.2.2.2.2.2.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.2.2.2.2.2.2.2.m1.1c">T</annotation></semantics></math>
</td>
</tr>
<tr id="S4.SS3.2.2.2.2.2.3" class="ltx_tr">
<td id="S4.SS3.2.2.2.2.2.3.1" class="ltx_td ltx_align_center">50</td>
<td id="S4.SS3.2.2.2.2.2.3.2" class="ltx_td ltx_align_center">100</td>
<td id="S4.SS3.2.2.2.2.2.3.3" class="ltx_td ltx_align_center">150</td>
<td id="S4.SS3.2.2.2.2.2.3.4" class="ltx_td ltx_align_center">200</td>
<td id="S4.SS3.2.2.2.2.2.3.5" class="ltx_td ltx_align_center">250</td>
</tr>
<tr id="S4.SS3.2.2.2.2.2.4" class="ltx_tr">
<td id="S4.SS3.2.2.2.2.2.4.1" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="S4.SS3.2.2.2.2.2.4.2" class="ltx_td ltx_align_center ltx_border_t">-1.087</td>
<td id="S4.SS3.2.2.2.2.2.4.3" class="ltx_td ltx_align_center ltx_border_t">-1.010</td>
<td id="S4.SS3.2.2.2.2.2.4.4" class="ltx_td ltx_align_center ltx_border_t">-0.984</td>
<td id="S4.SS3.2.2.2.2.2.4.5" class="ltx_td ltx_align_center ltx_border_t">-0.966</td>
<td id="S4.SS3.2.2.2.2.2.4.6" class="ltx_td ltx_align_center ltx_border_t">-0.948</td>
</tr>
<tr id="S4.SS3.2.2.2.2.2.5" class="ltx_tr">
<td id="S4.SS3.2.2.2.2.2.5.1" class="ltx_td ltx_align_center">2</td>
<td id="S4.SS3.2.2.2.2.2.5.2" class="ltx_td ltx_align_center" style="background-color:#ECECEC;"><span id="S4.SS3.2.2.2.2.2.5.2.1" class="ltx_text" style="background-color:#ECECEC;">-0.332</span></td>
<td id="S4.SS3.2.2.2.2.2.5.3" class="ltx_td ltx_align_center" style="background-color:#ECECEC;"><span id="S4.SS3.2.2.2.2.2.5.3.1" class="ltx_text" style="background-color:#ECECEC;">-0.292</span></td>
<td id="S4.SS3.2.2.2.2.2.5.4" class="ltx_td ltx_align_center" style="background-color:#ECECEC;"><span id="S4.SS3.2.2.2.2.2.5.4.1" class="ltx_text" style="background-color:#ECECEC;">-0.279</span></td>
<td id="S4.SS3.2.2.2.2.2.5.5" class="ltx_td ltx_align_center" style="background-color:#ECECEC;"><span id="S4.SS3.2.2.2.2.2.5.5.1" class="ltx_text" style="background-color:#ECECEC;">-0.270</span></td>
<td id="S4.SS3.2.2.2.2.2.5.6" class="ltx_td ltx_align_center" style="background-color:#ECECEC;"><span id="S4.SS3.2.2.2.2.2.5.6.1" class="ltx_text" style="background-color:#ECECEC;">-0.264</span></td>
</tr>
<tr id="S4.SS3.2.2.2.2.2.6" class="ltx_tr">
<td id="S4.SS3.2.2.2.2.2.6.1" class="ltx_td ltx_align_center">3</td>
<td id="S4.SS3.2.2.2.2.2.6.2" class="ltx_td ltx_align_center">-0.112</td>
<td id="S4.SS3.2.2.2.2.2.6.3" class="ltx_td ltx_align_center">-0.093</td>
<td id="S4.SS3.2.2.2.2.2.6.4" class="ltx_td ltx_align_center">-0.086</td>
<td id="S4.SS3.2.2.2.2.2.6.5" class="ltx_td ltx_align_center">-0.086</td>
<td id="S4.SS3.2.2.2.2.2.6.6" class="ltx_td ltx_align_center">-0.076</td>
</tr>
<tr id="S4.SS3.2.2.2.2.2.7" class="ltx_tr">
<td id="S4.SS3.2.2.2.2.2.7.1" class="ltx_td ltx_align_center ltx_border_b">4</td>
<td id="S4.SS3.2.2.2.2.2.7.2" class="ltx_td ltx_align_center ltx_border_b">-0.026</td>
<td id="S4.SS3.2.2.2.2.2.7.3" class="ltx_td ltx_align_center ltx_border_b">-0.016</td>
<td id="S4.SS3.2.2.2.2.2.7.4" class="ltx_td ltx_align_center ltx_border_b">-0.011</td>
<td id="S4.SS3.2.2.2.2.2.7.5" class="ltx_td ltx_align_center ltx_border_b">-0.007</td>
<td id="S4.SS3.2.2.2.2.2.7.6" class="ltx_td ltx_align_center ltx_border_b">-0.003</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Table 5: </span> ImageRewardÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">xu2023imagereward</span> </a></cite> with different classifier-free guidance scaling factors <math id="S4.SS3.5.5.5.5.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS3.5.5.5.5.m1.1b"><mi id="S4.SS3.5.5.5.5.m1.1.1" xref="S4.SS3.5.5.5.5.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.5.5.5.5.m1.1c"><ci id="S4.SS3.5.5.5.5.m1.1.1.cmml" xref="S4.SS3.5.5.5.5.m1.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.5.5.5.5.m1.1d">s</annotation></semantics></math> and sampling steps <math id="S4.SS3.6.6.6.6.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.6.6.6.6.m2.1b"><mi id="S4.SS3.6.6.6.6.m2.1.1" xref="S4.SS3.6.6.6.6.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.6.6.6.6.m2.1c"><ci id="S4.SS3.6.6.6.6.m2.1.1.cmml" xref="S4.SS3.6.6.6.6.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.6.6.6.6.m2.1d">T</annotation></semantics></math>. A larger value denotes higher image fidelity.</figcaption>
</figure>
<figure id="S4.SS3.12.12" class="ltx_figure ltx_minipage ltx_align_top" style="width:203.8pt;">
<div id="S4.SS3.8.8.2.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:407.6pt;height:197pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(82.8pt,-40.0pt) scale(1.68416572290086,1.68416572290086) ;">
<table id="S4.SS3.8.8.2.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S4.SS3.8.8.2.2.2.2" class="ltx_tr">
<td id="S4.SS3.7.7.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.SS3.7.7.1.1.1.1.1.1" class="ltx_text"><span id="S4.SS3.7.7.1.1.1.1.1.1.2" class="ltx_text"></span> <span id="S4.SS3.7.7.1.1.1.1.1.1.1" class="ltx_text">
<span id="S4.SS3.7.7.1.1.1.1.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.SS3.7.7.1.1.1.1.1.1.1.1.2" class="ltx_tr">
<span id="S4.SS3.7.7.1.1.1.1.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Scaling</span></span>
<span id="S4.SS3.7.7.1.1.1.1.1.1.1.1.1" class="ltx_tr">
<span id="S4.SS3.7.7.1.1.1.1.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Factor <math id="S4.SS3.7.7.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS3.7.7.1.1.1.1.1.1.1.1.1.1.m1.1a"><mi id="S4.SS3.7.7.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S4.SS3.7.7.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.7.7.1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="S4.SS3.7.7.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.SS3.7.7.1.1.1.1.1.1.1.1.1.1.m1.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.7.7.1.1.1.1.1.1.1.1.1.1.m1.1c">s</annotation></semantics></math></span></span>
</span></span> <span id="S4.SS3.7.7.1.1.1.1.1.1.3" class="ltx_text"></span></span></td>
<td id="S4.SS3.8.8.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t" colspan="5">Sampling Step <math id="S4.SS3.8.8.2.2.2.2.2.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.8.8.2.2.2.2.2.m1.1a"><mi id="S4.SS3.8.8.2.2.2.2.2.m1.1.1" xref="S4.SS3.8.8.2.2.2.2.2.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.8.8.2.2.2.2.2.m1.1b"><ci id="S4.SS3.8.8.2.2.2.2.2.m1.1.1.cmml" xref="S4.SS3.8.8.2.2.2.2.2.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.8.8.2.2.2.2.2.m1.1c">T</annotation></semantics></math>
</td>
</tr>
<tr id="S4.SS3.8.8.2.2.2.3" class="ltx_tr">
<td id="S4.SS3.8.8.2.2.2.3.1" class="ltx_td ltx_align_center">50</td>
<td id="S4.SS3.8.8.2.2.2.3.2" class="ltx_td ltx_align_center">100</td>
<td id="S4.SS3.8.8.2.2.2.3.3" class="ltx_td ltx_align_center">150</td>
<td id="S4.SS3.8.8.2.2.2.3.4" class="ltx_td ltx_align_center">200</td>
<td id="S4.SS3.8.8.2.2.2.3.5" class="ltx_td ltx_align_center">250</td>
</tr>
<tr id="S4.SS3.8.8.2.2.2.4" class="ltx_tr">
<td id="S4.SS3.8.8.2.2.2.4.1" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="S4.SS3.8.8.2.2.2.4.2" class="ltx_td ltx_align_center ltx_border_t">52.46</td>
<td id="S4.SS3.8.8.2.2.2.4.3" class="ltx_td ltx_align_center ltx_border_t">54.44</td>
<td id="S4.SS3.8.8.2.2.2.4.4" class="ltx_td ltx_align_center ltx_border_t">54.50</td>
<td id="S4.SS3.8.8.2.2.2.4.5" class="ltx_td ltx_align_center ltx_border_t">55.03</td>
<td id="S4.SS3.8.8.2.2.2.4.6" class="ltx_td ltx_align_center ltx_border_t">54.90</td>
</tr>
<tr id="S4.SS3.8.8.2.2.2.5" class="ltx_tr">
<td id="S4.SS3.8.8.2.2.2.5.1" class="ltx_td ltx_align_center">2</td>
<td id="S4.SS3.8.8.2.2.2.5.2" class="ltx_td ltx_align_center" style="background-color:#ECECEC;"><span id="S4.SS3.8.8.2.2.2.5.2.1" class="ltx_text" style="background-color:#ECECEC;">56.88</span></td>
<td id="S4.SS3.8.8.2.2.2.5.3" class="ltx_td ltx_align_center" style="background-color:#ECECEC;"><span id="S4.SS3.8.8.2.2.2.5.3.1" class="ltx_text ltx_font_bold" style="background-color:#ECECEC;">57.22</span></td>
<td id="S4.SS3.8.8.2.2.2.5.4" class="ltx_td ltx_align_center" style="background-color:#ECECEC;"><span id="S4.SS3.8.8.2.2.2.5.4.1" class="ltx_text" style="background-color:#ECECEC;">57.12</span></td>
<td id="S4.SS3.8.8.2.2.2.5.5" class="ltx_td ltx_align_center" style="background-color:#ECECEC;"><span id="S4.SS3.8.8.2.2.2.5.5.1" class="ltx_text" style="background-color:#ECECEC;">57.14</span></td>
<td id="S4.SS3.8.8.2.2.2.5.6" class="ltx_td ltx_align_center" style="background-color:#ECECEC;"><span id="S4.SS3.8.8.2.2.2.5.6.1" class="ltx_text" style="background-color:#ECECEC;">57.04</span></td>
</tr>
<tr id="S4.SS3.8.8.2.2.2.6" class="ltx_tr">
<td id="S4.SS3.8.8.2.2.2.6.1" class="ltx_td ltx_align_center">3</td>
<td id="S4.SS3.8.8.2.2.2.6.2" class="ltx_td ltx_align_center">56.02</td>
<td id="S4.SS3.8.8.2.2.2.6.3" class="ltx_td ltx_align_center">56.12</td>
<td id="S4.SS3.8.8.2.2.2.6.4" class="ltx_td ltx_align_center">56.28</td>
<td id="S4.SS3.8.8.2.2.2.6.5" class="ltx_td ltx_align_center">56.25</td>
<td id="S4.SS3.8.8.2.2.2.6.6" class="ltx_td ltx_align_center">56.09</td>
</tr>
<tr id="S4.SS3.8.8.2.2.2.7" class="ltx_tr">
<td id="S4.SS3.8.8.2.2.2.7.1" class="ltx_td ltx_align_center ltx_border_b">4</td>
<td id="S4.SS3.8.8.2.2.2.7.2" class="ltx_td ltx_align_center ltx_border_b">54.92</td>
<td id="S4.SS3.8.8.2.2.2.7.3" class="ltx_td ltx_align_center ltx_border_b">54.78</td>
<td id="S4.SS3.8.8.2.2.2.7.4" class="ltx_td ltx_align_center ltx_border_b">54.95</td>
<td id="S4.SS3.8.8.2.2.2.7.5" class="ltx_td ltx_align_center ltx_border_b">54.81</td>
<td id="S4.SS3.8.8.2.2.2.7.6" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.SS3.8.8.2.2.2.7.6.1" class="ltx_text ltx_framed ltx_framed_underline">54.64</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Table 6: </span> Student accuracy with different scaling factors <math id="S4.SS3.11.11.5.5.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS3.11.11.5.5.m1.1b"><mi id="S4.SS3.11.11.5.5.m1.1.1" xref="S4.SS3.11.11.5.5.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.11.11.5.5.m1.1c"><ci id="S4.SS3.11.11.5.5.m1.1.1.cmml" xref="S4.SS3.11.11.5.5.m1.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.11.11.5.5.m1.1d">s</annotation></semantics></math> and sampling steps <math id="S4.SS3.12.12.6.6.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.12.12.6.6.m2.1b"><mi id="S4.SS3.12.12.6.6.m2.1.1" xref="S4.SS3.12.12.6.6.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.12.12.6.6.m2.1c"><ci id="S4.SS3.12.12.6.6.m2.1.1.cmml" xref="S4.SS3.12.12.6.6.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.12.12.6.6.m2.1d">T</annotation></semantics></math>. Student models are trained for 100 epochs.</figcaption>
</figure>
</div>
<figure id="S4.T7" class="ltx_table">
<div id="S4.T7.4.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:390.3pt;height:80.9pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-38.7pt,7.9pt) scale(0.834570979051842,0.834570979051842) ;">
<table id="S4.T7.4.4.4" class="ltx_tabular ltx_align_middle">
<tr id="S4.T7.4.4.4.5" class="ltx_tr">
<td id="S4.T7.4.4.4.5.1" class="ltx_td ltx_align_center ltx_border_t">Teacher</td>
<td id="S4.T7.4.4.4.5.2" class="ltx_td ltx_align_center ltx_border_t">ResNet18</td>
<td id="S4.T7.4.4.4.5.3" class="ltx_td ltx_align_center ltx_border_t">ResNet34</td>
<td id="S4.T7.4.4.4.5.4" class="ltx_td ltx_align_center ltx_border_t">VGG16</td>
<td id="S4.T7.4.4.4.5.5" class="ltx_td ltx_align_center ltx_border_t">ResNet50</td>
<td id="S4.T7.4.4.4.5.6" class="ltx_td ltx_align_center ltx_border_t">ShuffleV2</td>
</tr>
<tr id="S4.T7.4.4.4.6" class="ltx_tr">
<td id="S4.T7.4.4.4.6.1" class="ltx_td ltx_align_center">Acc.Â (%)</td>
<td id="S4.T7.4.4.4.6.2" class="ltx_td ltx_align_center">69.75</td>
<td id="S4.T7.4.4.4.6.3" class="ltx_td ltx_align_center">73.31</td>
<td id="S4.T7.4.4.4.6.4" class="ltx_td ltx_align_center">73.36</td>
<td id="S4.T7.4.4.4.6.5" class="ltx_td ltx_align_center">76.13</td>
<td id="S4.T7.4.4.4.6.6" class="ltx_td ltx_align_center">69.36</td>
</tr>
<tr id="S4.T7.4.4.4.7" class="ltx_tr">
<td id="S4.T7.4.4.4.7.1" class="ltx_td ltx_align_center ltx_border_t">Student</td>
<td id="S4.T7.4.4.4.7.2" class="ltx_td ltx_align_center ltx_border_t">ResNet18</td>
<td id="S4.T7.4.4.4.7.3" class="ltx_td ltx_align_center ltx_border_t">ResNet18</td>
<td id="S4.T7.4.4.4.7.4" class="ltx_td ltx_align_center ltx_border_t">VGG11</td>
<td id="S4.T7.4.4.4.7.5" class="ltx_td ltx_align_center ltx_border_t">ResNet34</td>
<td id="S4.T7.4.4.4.7.6" class="ltx_td ltx_align_center ltx_border_t">ResNet50</td>
</tr>
<tr id="S4.T7.2.2.2.2" class="ltx_tr">
<td id="S4.T7.2.2.2.2.2" class="ltx_td ltx_align_center">Low FidelityÂ (<math id="S4.T7.1.1.1.1.1.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.T7.1.1.1.1.1.m1.1a"><mi id="S4.T7.1.1.1.1.1.m1.1.1" xref="S4.T7.1.1.1.1.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.T7.1.1.1.1.1.m1.1b"><ci id="S4.T7.1.1.1.1.1.m1.1.1.cmml" xref="S4.T7.1.1.1.1.1.m1.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.1.1.1.1.1.m1.1c">s</annotation></semantics></math>=2, <math id="S4.T7.2.2.2.2.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.T7.2.2.2.2.2.m2.1a"><mi id="S4.T7.2.2.2.2.2.m2.1.1" xref="S4.T7.2.2.2.2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.T7.2.2.2.2.2.m2.1b"><ci id="S4.T7.2.2.2.2.2.m2.1.1.cmml" xref="S4.T7.2.2.2.2.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.2.2.2.2.2.m2.1c">T</annotation></semantics></math>=100, reward=-0.292)</td>
<td id="S4.T7.2.2.2.2.3" class="ltx_td ltx_align_center">57.22</td>
<td id="S4.T7.2.2.2.2.4" class="ltx_td ltx_align_center">54.17</td>
<td id="S4.T7.2.2.2.2.5" class="ltx_td ltx_align_center">51.81</td>
<td id="S4.T7.2.2.2.2.6" class="ltx_td ltx_align_center">57.78</td>
<td id="S4.T7.2.2.2.2.7" class="ltx_td ltx_align_center">63.66</td>
</tr>
<tr id="S4.T7.4.4.4.4" class="ltx_tr">
<td id="S4.T7.4.4.4.4.2" class="ltx_td ltx_align_center ltx_border_b">High FidelityÂ (<math id="S4.T7.3.3.3.3.1.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.T7.3.3.3.3.1.m1.1a"><mi id="S4.T7.3.3.3.3.1.m1.1.1" xref="S4.T7.3.3.3.3.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.T7.3.3.3.3.1.m1.1b"><ci id="S4.T7.3.3.3.3.1.m1.1.1.cmml" xref="S4.T7.3.3.3.3.1.m1.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.3.3.3.3.1.m1.1c">s</annotation></semantics></math>=4, <math id="S4.T7.4.4.4.4.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.T7.4.4.4.4.2.m2.1a"><mi id="S4.T7.4.4.4.4.2.m2.1.1" xref="S4.T7.4.4.4.4.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.T7.4.4.4.4.2.m2.1b"><ci id="S4.T7.4.4.4.4.2.m2.1.1.cmml" xref="S4.T7.4.4.4.4.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.4.4.4.4.2.m2.1c">T</annotation></semantics></math>=250, reward=-0.003)</td>
<td id="S4.T7.4.4.4.4.3" class="ltx_td ltx_align_center ltx_border_b">56.19</td>
<td id="S4.T7.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_b">49.73</td>
<td id="S4.T7.4.4.4.4.5" class="ltx_td ltx_align_center ltx_border_b">47.51</td>
<td id="S4.T7.4.4.4.4.6" class="ltx_td ltx_align_center ltx_border_b">52.24</td>
<td id="S4.T7.4.4.4.4.7" class="ltx_td ltx_align_center ltx_border_b">56.20</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span>Distillation performance for different teacher-student pairs under low- and high-fidelity synthetic images. The low-fidelity images are more effective for various teacher-student pairs. </figcaption>
</figure>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.4" class="ltx_p"><span id="S4.SS3.p3.4.1" class="ltx_text ltx_font_bold">Results.</span>
For image classification tasks, it is commonly believed that classification models will demonstrate better generalization ability on real data when high-fidelity, photo-realistic synthesized images are utilized as the training dataset.
Existing data-free distillation methodsÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">chen2019data</span> </a>; <a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">yin2020dreaming</span> </a></cite> follow a similar idea by synthesizing realistic datasets for distillation.
However, we find that the distillation performance of images synthesized with default parameters is suboptimal.
To assess the distillation performance achieved with different synthetic datasets, we report the student accuracy in Table Â <a href="#S4.SS3" title="4.3 Low-fidelity synthetic images are better teaching materials. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a> and TableÂ <a href="#S4.T7" title="Table 7 â€£ 4.3 Low-fidelity synthetic images are better teaching materials. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, which correspond to the datasets in TableÂ <a href="#S4.SS3" title="4.3 Low-fidelity synthetic images are better teaching materials. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>.
Our study shows that high-fidelity images, as indicated by a high ImageRewardÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">xu2023imagereward</span> </a></cite> score, generated with default parameters, exhibit weaker distillation performance than low-fidelity ones. By progressively decreasing the values of both the scaling factor <math id="S4.SS3.p3.1.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS3.p3.1.m1.1a"><mi id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><ci id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">s</annotation></semantics></math> and sampling step <math id="S4.SS3.p3.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p3.2.m2.1a"><mi id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><ci id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">T</annotation></semantics></math>, a better distillation performance can be achieved. These findings suggest that low-fidelity images are more effective as learning materials for students during the distillation process.
In addition, when setting <math id="S4.SS3.p3.3.m3.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS3.p3.3.m3.1a"><mi id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.1b"><ci id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.1c">s</annotation></semantics></math>=1, which means that there is no classifier-free guidance in the image generation process, a significant drop in student performance is observed. This suggests that poor fidelity generated images may hinder the student modelâ€™s ability to learn effectively in logit representation.
Our experiments show that setting <math id="S4.SS3.p3.4.m4.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS3.p3.4.m4.1a"><mi id="S4.SS3.p3.4.m4.1.1" xref="S4.SS3.p3.4.m4.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.4.m4.1b"><ci id="S4.SS3.p3.4.m4.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.4.m4.1c">s</annotation></semantics></math>=2 and using a sampling step of 100 can generate images with relatively low fidelity, which results in the best performance for ImageNet-1K knowledge distillation (see in TableÂ <a href="#S4.SS3" title="4.3 Low-fidelity synthetic images are better teaching materials. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a> and TableÂ <a href="#S4.T7" title="Table 7 â€£ 4.3 Low-fidelity synthetic images are better teaching materials. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>).</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.2" class="ltx_p"><span id="S4.SS3.p4.2.1" class="ltx_text ltx_font_bold">Scaling with more synthetic data.</span>
Based on the above findings, we proceed to evaluate the distillation performance on large-scale data by generating synthetic images of varying data amounts, ranging from 100K to 2.0M. In the following experiments, we use a scaling factor of <math id="S4.SS3.p4.1.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS3.p4.1.m1.1a"><mi id="S4.SS3.p4.1.m1.1.1" xref="S4.SS3.p4.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.m1.1b"><ci id="S4.SS3.p4.1.m1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">s</annotation></semantics></math>=2 and sampling step <math id="S4.SS3.p4.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p4.2.m2.1a"><mi id="S4.SS3.p4.2.m2.1.1" xref="S4.SS3.p4.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.2.m2.1b"><ci id="S4.SS3.p4.2.m2.1.1.cmml" xref="S4.SS3.p4.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.2.m2.1c">T</annotation></semantics></math>=100 to construct the synthetic dataset, unless otherwise specified. Fig.Â <a href="#S4.F5" title="Figure 5 â€£ 4.4 Relatively weak classifiers are better teachers. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows that the performance continues to improve as the number of synthetic images increases up to 2.0M. As the data amount increases, we observe that the performance improvement begins to plateau.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2305.12954/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" width="147" height="120" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2305.12954/assets/x4.png" id="S4.F3.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" width="147" height="120" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2305.12954/assets/x5.png" id="S4.F3.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" width="147" height="120" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Top-1 classification accuracyÂ (%) of different teacher-student pairs on ImageNet dataset. Relatively weak classifiers bring better distillation performance. Student models are trained for 100 epochs.</figcaption>
</figure>
<figure id="S4.T8" class="ltx_table">
<div id="S4.T8.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:346.9pt;height:66.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-30.1pt,5.8pt) scale(0.85227545627177,0.85227545627177) ;">
<table id="S4.T8.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T8.1.1.1" class="ltx_tr">
<td id="S4.T8.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">Teacher</td>
<td id="S4.T8.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t">SNV2-0.5</td>
<td id="S4.T8.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">Res18</td>
<td id="S4.T8.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Res34</td>
<td id="S4.T8.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t">SNV2-0.5</td>
<td id="S4.T8.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t">Res18</td>
<td id="S4.T8.1.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Res34</td>
<td id="S4.T8.1.1.1.8" class="ltx_td ltx_align_center ltx_border_t">SNV2-0.5</td>
<td id="S4.T8.1.1.1.9" class="ltx_td ltx_align_center ltx_border_t">Res18</td>
</tr>
<tr id="S4.T8.1.1.2" class="ltx_tr">
<td id="S4.T8.1.1.2.1" class="ltx_td ltx_align_center">Acc.Â (%)</td>
<td id="S4.T8.1.1.2.2" class="ltx_td ltx_align_center">60.55</td>
<td id="S4.T8.1.1.2.3" class="ltx_td ltx_align_center">69.75</td>
<td id="S4.T8.1.1.2.4" class="ltx_td ltx_align_center ltx_border_r">73.31</td>
<td id="S4.T8.1.1.2.5" class="ltx_td ltx_align_center">60.55</td>
<td id="S4.T8.1.1.2.6" class="ltx_td ltx_align_center">69.75</td>
<td id="S4.T8.1.1.2.7" class="ltx_td ltx_align_center ltx_border_r">73.31</td>
<td id="S4.T8.1.1.2.8" class="ltx_td ltx_align_center">60.55</td>
<td id="S4.T8.1.1.2.9" class="ltx_td ltx_align_center">69.75</td>
</tr>
<tr id="S4.T8.1.1.3" class="ltx_tr">
<td id="S4.T8.1.1.3.1" class="ltx_td ltx_align_center ltx_border_t">Student</td>
<td id="S4.T8.1.1.3.2" class="ltx_td ltx_align_center ltx_border_t">Res18</td>
<td id="S4.T8.1.1.3.3" class="ltx_td ltx_align_center ltx_border_t">Res18</td>
<td id="S4.T8.1.1.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Res18</td>
<td id="S4.T8.1.1.3.5" class="ltx_td ltx_align_center ltx_border_t">Res34</td>
<td id="S4.T8.1.1.3.6" class="ltx_td ltx_align_center ltx_border_t">Res34</td>
<td id="S4.T8.1.1.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Res34</td>
<td id="S4.T8.1.1.3.8" class="ltx_td ltx_align_center ltx_border_t">Res50</td>
<td id="S4.T8.1.1.3.9" class="ltx_td ltx_align_center ltx_border_t">Res50</td>
</tr>
<tr id="S4.T8.1.1.4" class="ltx_tr">
<td id="S4.T8.1.1.4.1" class="ltx_td ltx_align_center ltx_border_b">SynKD</td>
<td id="S4.T8.1.1.4.2" class="ltx_td ltx_align_center ltx_border_b">54.03</td>
<td id="S4.T8.1.1.4.3" class="ltx_td ltx_align_center ltx_border_b">57.22</td>
<td id="S4.T8.1.1.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">54.17</td>
<td id="S4.T8.1.1.4.5" class="ltx_td ltx_align_center ltx_border_b">56.83</td>
<td id="S4.T8.1.1.4.6" class="ltx_td ltx_align_center ltx_border_b">61.11</td>
<td id="S4.T8.1.1.4.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">60.19</td>
<td id="S4.T8.1.1.4.8" class="ltx_td ltx_align_center ltx_border_b">58.11</td>
<td id="S4.T8.1.1.4.9" class="ltx_td ltx_align_center ltx_border_b">62.74</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8: </span>Knowledge distillation with large teacher-student capacity gaps. A relatively weak teacher with a small teacher-student gap generally leads to better performance.</figcaption>
</figure>
<figure id="S4.T9" class="ltx_table ltx_align_floatright">
<div id="S4.T9.1" class="ltx_inline-block ltx_transformed_outer" style="width:398.9pt;height:97.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(76.5pt,-18.7pt) scale(1.62202873129891,1.62202873129891) ;">
<table id="S4.T9.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T9.1.1.2" class="ltx_tr">
<td id="S4.T9.1.1.2.1" class="ltx_td ltx_align_center ltx_border_t">#Syn Images</td>
<td id="S4.T9.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t">50K</td>
<td id="S4.T9.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t">100K</td>
<td id="S4.T9.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t">200K</td>
<td id="S4.T9.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t">400K</td>
</tr>
<tr id="S4.T9.1.1.3" class="ltx_tr">
<td id="S4.T9.1.1.3.1" class="ltx_td ltx_align_center">Train Epoch</td>
<td id="S4.T9.1.1.3.2" class="ltx_td ltx_align_center">400</td>
<td id="S4.T9.1.1.3.3" class="ltx_td ltx_align_center">200</td>
<td id="S4.T9.1.1.3.4" class="ltx_td ltx_align_center">100</td>
<td id="S4.T9.1.1.3.5" class="ltx_td ltx_align_center">50</td>
</tr>
<tr id="S4.T9.1.1.1" class="ltx_tr">
<td id="S4.T9.1.1.1.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">ResNet18<math id="S4.T9.1.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T9.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T9.1.1.1.1.m1.1.1" xref="S4.T9.1.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.T9.1.1.1.1.m1.1b"><ci id="S4.T9.1.1.1.1.m1.1.1.cmml" xref="S4.T9.1.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.1.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>ResNet18</td>
<td id="S4.T9.1.1.1.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">54.84</td>
<td id="S4.T9.1.1.1.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">55.00</td>
<td id="S4.T9.1.1.1.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">57.22</td>
<td id="S4.T9.1.1.1.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T9.1.1.1.5.1" class="ltx_text ltx_font_bold">57.69</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 9: </span>Data diversity. Generating more data samples increases the diversity of the synthetic dataset, leading to better distillation performance.</figcaption>
</figure>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.1" class="ltx_p"><span id="S4.SS3.p5.1.1" class="ltx_text ltx_font_bold">Data diversity.</span>
In this experiment, we aim to validate whether generating more samples brings greater diversity to the dataset and thus leads to better distillation performance. To achieve this, we fix the number of total training iterations (i.e., Data Amount<math id="S4.SS3.p5.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS3.p5.1.m1.1a"><mo id="S4.SS3.p5.1.m1.1.1" xref="S4.SS3.p5.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.1.m1.1b"><times id="S4.SS3.p5.1.m1.1.1.cmml" xref="S4.SS3.p5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.1.m1.1c">\times</annotation></semantics></math>Train Epochs) and scale the training schedule based on the data volume. Our results, presented in TableÂ <a href="#S4.T9" title="Table 9 â€£ 4.3 Low-fidelity synthetic images are better teaching materials. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, demonstrate that generating more data increases the diversity in the synthetic dataset, resulting in improved performance.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Relatively weak classifiers are better teachers.</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p"><span id="S4.SS4.p1.1.1" class="ltx_text ltx_font_bold">Experiment setup.</span> To validate if relatively weak classifiers are better teachers, we carefully select multiple teacher-student model pairs with different architectures, including ResNetÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">he2016deep</span> </a></cite>, VGGÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">simonyan2014very</span> </a></cite>, and ShuffleNetV2Â (SNV2)Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">ma2018shufflenet</span> </a></cite>. The experiments are conducted on 200K synthetic datasets and the students are trained by 100 epochs.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p"><span id="S4.SS4.p2.1.1" class="ltx_text ltx_font_bold">Results.</span>
When training on real datasets, it is common to use a relatively large teacher model to train the student model, such as distilling ResNet34 to ResNet18. In general, smaller teacher models often fail to achieve satisfactory distillation performance compared to larger teacher models. However, when working with synthetic datasets, we observe the <span id="S4.SS4.p2.1.2" class="ltx_text ltx_font_bold">opposite</span> phenomenon: relatively weak teacher models can actually achieve better distillation performance than strong ones, as shown in Fig.Â <a href="#S4.F3" title="Figure 3 â€£ 4.3 Low-fidelity synthetic images are better teaching materials. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and Fig.Â <a href="#S4.F5" title="Figure 5 â€£ 4.4 Relatively weak classifiers are better teachers. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
Interestingly, we found that as the capacity of the teacher model increases, a significant drop in performance is observed.
Specifically, when training ResNet34 on the synthetic dataset, using ResNet18 as the teacher model leads to a 3% improvement in performance compared to using ResNet50 as the teacher model.
These results highlight the importance of carefully selecting a teacher model when performing knowledge distillation and suggest that using a smaller, weaker teacher model may be preferable when working with synthetic datasets.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p"><span id="S4.SS4.p3.1.1" class="ltx_text ltx_font_bold">Should teachers be as weak as possible?</span>
To answer this question, we conduct a series of experiments using three groups of teacher-student pairs with large capacity gaps, as shown in Table.Â <a href="#S4.T8" title="Table 8 â€£ 4.3 Low-fidelity synthetic images are better teaching materials. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.
We choose SNV2-0.5 as the teacher to test the effect that the teacher is obviously weaker than the student.
Our results show that when the teacher-student gap is large, it does not necessarily lead to better performance. In fact, our experiments suggest that using a relatively weak teacher model may be a better choice for optimizing knowledge transfer.</p>
</div>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F5.1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_top" style="width:199.5pt;"><img src="/html/2305.12954/assets/x6.png" id="S4.F5.1.g1" class="ltx_graphics ltx_img_landscape" width="387" height="294" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Top-1 classification accuracyÂ (%) on ImageNet dataset. Teachers and students are different architectures. Students are trained for 100 epochs.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F5.2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_top" style="width:225.5pt;"><img src="/html/2305.12954/assets/x7.png" id="S4.F5.2.g1" class="ltx_graphics ltx_img_landscape" width="415" height="265" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Improved classification accuracy of the student model with increasing numbers of synthetic images used for distillation. Student models are trained for 100 epochs.</figcaption>
</figure>
</div>
</div>
</figure>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Ablation Study</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.2" class="ltx_p"><span id="S4.SS5.p1.2.1" class="ltx_text ltx_font_bold">Temperature hyperparameter.</span>
As discussed in previous worksÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">hinton2015distilling</span> </a>; <a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">chandrasegaran2022revisiting</span> </a>; <a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">li2022curriculum</span> </a></cite>, the temperature parameter is a crucial factor in controlling the smoothness of probability distributions. It determines the level of difficulty involved in the process and is an essential component in achieving optimal results.
The temperature parameter <math id="S4.SS5.p1.1.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S4.SS5.p1.1.m1.1a"><mi id="S4.SS5.p1.1.m1.1.1" xref="S4.SS5.p1.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.1.m1.1b"><ci id="S4.SS5.p1.1.m1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.1.m1.1c">\tau</annotation></semantics></math> has been set to different values in previous works (e.g., 3 in DeepInvÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">yin2020dreaming</span> </a></cite>, 8 in One-ImageÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">asano2023the</span> </a></cite>, 20 in FastDFKDÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">fang2022up</span> </a></cite>). In Fig.Â <a href="#S4.F6" title="Figure 6 â€£ 4.5 Ablation Study â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we present the detailed distillation results obtained under different temperature values. The best result is obtained when we set <math id="S4.SS5.p1.2.m2.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S4.SS5.p1.2.m2.1a"><mi id="S4.SS5.p1.2.m2.1.1" xref="S4.SS5.p1.2.m2.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.2.m2.1b"><ci id="S4.SS5.p1.2.m2.1.1.cmml" xref="S4.SS5.p1.2.m2.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.2.m2.1c">\tau</annotation></semantics></math>=10.</p>
</div>
<figure id="S4.F6" class="ltx_figure ltx_align_floatright"><img src="/html/2305.12954/assets/x8.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="350" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Grid search for values of the temperature hyperparameter. The best performance is achieved when <math id="S4.F6.2.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S4.F6.2.m1.1b"><mi id="S4.F6.2.m1.1.1" xref="S4.F6.2.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S4.F6.2.m1.1c"><ci id="S4.F6.2.m1.1.1.cmml" xref="S4.F6.2.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.2.m1.1d">\tau</annotation></semantics></math>=10.</figcaption>
</figure>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p"><span id="S4.SS5.p2.1.1" class="ltx_text ltx_font_bold">Training with hard labels.</span>
The DiT model uses class labels as input to generate images, making it possible to use these labels as hard labels to supervise the modelâ€™s training. In order to investigate the potential benefits of hard label supervision for synthetic datasets, we conduct experiments as presented in TableÂ <a href="#S4.T10" title="Table 10 â€£ 4.5 Ablation Study â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>.
The experiments involved training the student model with soft labels only, hard labels only, and a combination of hard and soft labels.
For the joint hard label and soft label training, we follow the traditional distillation methodsÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">hinton2015distilling</span> </a>; <a href="#bib.bib68" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">zhang2018deep</span> </a>; <a href="#bib.bib69" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">zhao2022decoupled</span> </a></cite> to weights the two losses at a 1:1 ratio.
The results indicate that utilizing hard labels during training actually leads to worse performance compared to using only soft labels. This finding confirms the existence of a domain shift between the synthetic and real datasets, as mentioned inÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">he2022synthetic</span> </a></cite>. However, by using the distillation method, the impact of the domain shift is largely reduced.</p>
</div>
<figure id="S4.T10" class="ltx_table">
<div id="S4.T10.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:281.9pt;height:85.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-17.8pt,5.4pt) scale(0.887716460059727,0.887716460059727) ;">
<table id="S4.T10.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T10.1.1.1" class="ltx_tr">
<td id="S4.T10.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T10.1.1.1.1.1" class="ltx_text">Hard Label</span></td>
<td id="S4.T10.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T10.1.1.1.2.1" class="ltx_text">Soft Label</span></td>
<td id="S4.T10.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">T: ResNet18</td>
<td id="S4.T10.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">T: ResNet34</td>
<td id="S4.T10.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t">T: VGG16</td>
</tr>
<tr id="S4.T10.1.1.2" class="ltx_tr">
<td id="S4.T10.1.1.2.1" class="ltx_td ltx_align_center">S: ResNet18</td>
<td id="S4.T10.1.1.2.2" class="ltx_td ltx_align_center">S: ResNet18</td>
<td id="S4.T10.1.1.2.3" class="ltx_td ltx_align_center">S: VGG11</td>
</tr>
<tr id="S4.T10.1.1.3" class="ltx_tr">
<td id="S4.T10.1.1.3.1" class="ltx_td ltx_border_t"></td>
<td id="S4.T10.1.1.3.2" class="ltx_td ltx_align_center ltx_border_t">âœ“</td>
<td id="S4.T10.1.1.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T10.1.1.3.3.1" class="ltx_text ltx_font_bold">57.22</span></td>
<td id="S4.T10.1.1.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T10.1.1.3.4.1" class="ltx_text ltx_font_bold">54.17</span></td>
<td id="S4.T10.1.1.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T10.1.1.3.5.1" class="ltx_text ltx_font_bold">51.81</span></td>
</tr>
<tr id="S4.T10.1.1.4" class="ltx_tr">
<td id="S4.T10.1.1.4.1" class="ltx_td ltx_align_center">âœ“</td>
<td id="S4.T10.1.1.4.2" class="ltx_td"></td>
<td id="S4.T10.1.1.4.3" class="ltx_td ltx_align_center">42.40</td>
<td id="S4.T10.1.1.4.4" class="ltx_td ltx_align_center">42.58</td>
<td id="S4.T10.1.1.4.5" class="ltx_td ltx_align_center">41.10</td>
</tr>
<tr id="S4.T10.1.1.5" class="ltx_tr">
<td id="S4.T10.1.1.5.1" class="ltx_td ltx_align_center ltx_border_b">âœ“</td>
<td id="S4.T10.1.1.5.2" class="ltx_td ltx_align_center ltx_border_b">âœ“</td>
<td id="S4.T10.1.1.5.3" class="ltx_td ltx_align_center ltx_border_b">56.08</td>
<td id="S4.T10.1.1.5.4" class="ltx_td ltx_align_center ltx_border_b">53.61</td>
<td id="S4.T10.1.1.5.5" class="ltx_td ltx_align_center ltx_border_b">50.32</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 10: </span>Accuracy comparison of hard and soft labels. Soft labels work better than hard labels and both.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we systematically study whether and how synthetic images generated from state-of-the-art diffusion models can be used for knowledge distillation without access to real data.
Through our research, we have three key findings: (1)Â extensive experiments demonstrate that synthetic data from diffusion models can easily achieve state-of-the-art performance among existing synthesis-based distillation methods, (2)Â low-fidelity synthetic images are better teaching materials for knowledge distillation, and (3)Â relatively weak classifiers are better teachers.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Limitations and future work.</span>
Due to limited computing resources, we were not able to conduct experiments on large models (e.g., ViTÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">dosovitskiy2020image</span> </a></cite>, Swin TransformerÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">liu2021swin</span> </a></cite>) with larger data volumes.
Besides, this paper focuses on the original sampling manner of the considered diffusion models and does not discuss the influence of the advanced sampling manners, e.g., DPM-SolverÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">lu2022dpm</span> </a></cite>, DPM++Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">lu2022dpmplus</span> </a></cite>. We plan to discuss them in our future work.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Acknowledgement</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This work was supported by the Young Scientists Fund of the National Natural Science Foundation of ChinaÂ (Grant No.62206134) and the Tianjin Key Laboratory of Visual Computing and Intelligent Perception (VCIP). Computation is supported by the Supercomputing Center of Nankai University (NKSC).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.2.2.1" class="ltx_text" style="font-size:90%;">[1]</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.4.1" class="ltx_text" style="font-size:90%;">
Tobias Alt, Pascal Peter, and Joachim Weickert.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.5.1" class="ltx_text" style="font-size:90%;">Learning sparse masks for diffusion-based image inpainting.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib1.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Pattern Recognition and Image Analysis</span><span id="bib.bib1.8.3" class="ltx_text" style="font-size:90%;">, pages 528â€“539,
2022.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.2.2.1" class="ltx_text" style="font-size:90%;">[2]</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.4.1" class="ltx_text" style="font-size:90%;">
YukiÂ M Asano and Aaqib Saeed.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.5.1" class="ltx_text" style="font-size:90%;">The augmented image prior: Distilling 1000 classes by extrapolating
from a single image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib2.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICLR</span><span id="bib.bib2.8.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.2.2.1" class="ltx_text" style="font-size:90%;">[3]</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.4.1" class="ltx_text" style="font-size:90%;">
Shekoofeh Azizi, Simon Kornblith, Chitwan Saharia, Mohammad Norouzi, and
DavidÂ J Fleet.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.5.1" class="ltx_text" style="font-size:90%;">Synthetic data from diffusion models improves imagenet
classification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2304.08466</span><span id="bib.bib3.7.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.2.2.1" class="ltx_text" style="font-size:90%;">[4]</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.4.1" class="ltx_text" style="font-size:90%;">
Kuluhan Binici, Shivam Aggarwal, NamÂ Trung Pham, Karianto Leman, and Tulika
Mitra.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.5.1" class="ltx_text" style="font-size:90%;">Robust and resource-efficient data-free knowledge distillation by
generative pseudo replay.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI</span><span id="bib.bib4.8.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.2.2.1" class="ltx_text" style="font-size:90%;">[5]</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.4.1" class="ltx_text" style="font-size:90%;">
Andrew Brock, Jeff Donahue, and Karen Simonyan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.5.1" class="ltx_text" style="font-size:90%;">Large scale gan training for high fidelity natural image synthesis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1809.11096</span><span id="bib.bib5.7.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.2.2.1" class="ltx_text" style="font-size:90%;">[6]</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.4.1" class="ltx_text" style="font-size:90%;">
Keshigeyan Chandrasegaran, Ngoc-Trung Tran, Yunqing Zhao, and Ngai-Man Cheung.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.5.1" class="ltx_text" style="font-size:90%;">Revisiting label smoothing and knowledge distillation compatibility:
What was missing?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICML</span><span id="bib.bib6.8.3" class="ltx_text" style="font-size:90%;">, pages 2890â€“2916, 2022.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.2.2.1" class="ltx_text" style="font-size:90%;">[7]</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.4.1" class="ltx_text" style="font-size:90%;">
Defang Chen, Jian-Ping Mei, Can Wang, Yan Feng, and Chun Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.5.1" class="ltx_text" style="font-size:90%;">Online knowledge distillation with diverse peers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI</span><span id="bib.bib7.8.3" class="ltx_text" style="font-size:90%;">, pages 3430â€“3437, 2020.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.2.2.1" class="ltx_text" style="font-size:90%;">[8]</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.4.1" class="ltx_text" style="font-size:90%;">
Hanting Chen, Yunhe Wang, Chang Xu, Zhaohui Yang, Chuanjian Liu, Boxin Shi,
Chunjing Xu, Chao Xu, and QiÂ Tian.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.5.1" class="ltx_text" style="font-size:90%;">Data-free learning of student networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib8.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib8.8.3" class="ltx_text" style="font-size:90%;">, pages 3514â€“3522, 2019.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.2.2.1" class="ltx_text" style="font-size:90%;">[9]</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.4.1" class="ltx_text" style="font-size:90%;">
Pengguang Chen, Shu Liu, Hengshuang Zhao, and Jiaya Jia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.5.1" class="ltx_text" style="font-size:90%;">Distilling knowledge via knowledge review.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib9.8.3" class="ltx_text" style="font-size:90%;">, pages 5008â€“5017, 2021.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.2.2.1" class="ltx_text" style="font-size:90%;">[10]</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.4.1" class="ltx_text" style="font-size:90%;">
Yudong Chen, Sen Wang, Jiajun Liu, Xuwei Xu, Frank deÂ Hoog, and ZiÂ Huang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.5.1" class="ltx_text" style="font-size:90%;">Improved feature distillation via projector ensemble.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2210.15274</span><span id="bib.bib10.7.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.2.2.1" class="ltx_text" style="font-size:90%;">[11]</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.4.1" class="ltx_text" style="font-size:90%;">
Yoojin Choi, Jihwan Choi, Mostafa El-Khamy, and Jungwon Lee.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.5.1" class="ltx_text" style="font-size:90%;">Data-free network quantization with adversarial knowledge
distillation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR Workshops</span><span id="bib.bib11.8.3" class="ltx_text" style="font-size:90%;">, pages 710â€“711, 2020.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.2.2.1" class="ltx_text" style="font-size:90%;">[12]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.4.1" class="ltx_text" style="font-size:90%;">
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and LiÂ Fei-Fei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.5.1" class="ltx_text" style="font-size:90%;">Imagenet: A large-scale hierarchical image database.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib12.8.3" class="ltx_text" style="font-size:90%;">, pages 248â€“255, 2009.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.2.2.1" class="ltx_text" style="font-size:90%;">[13]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.4.1" class="ltx_text" style="font-size:90%;">
Prafulla Dhariwal and Alexander Nichol.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.5.1" class="ltx_text" style="font-size:90%;">Diffusion models beat gans on image synthesis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib13.7.2" class="ltx_text" style="font-size:90%;">, pages 8780â€“8794, 2021.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.2.2.1" class="ltx_text" style="font-size:90%;">[14]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.4.1" class="ltx_text" style="font-size:90%;">
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
Heigold, Sylvain Gelly, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.5.1" class="ltx_text" style="font-size:90%;">An image is worth 16x16 words: Transformers for image recognition at
scale.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2010.11929</span><span id="bib.bib14.7.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.2.2.1" class="ltx_text" style="font-size:90%;">[15]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.4.1" class="ltx_text" style="font-size:90%;">
Gongfan Fang, Kanya Mo, Xinchao Wang, Jie Song, Shitao Bei, Haofei Zhang, and
Mingli Song.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.5.1" class="ltx_text" style="font-size:90%;">Up to 100x faster data-free knowledge distillation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI</span><span id="bib.bib15.8.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.2.2.1" class="ltx_text" style="font-size:90%;">[16]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.4.1" class="ltx_text" style="font-size:90%;">
Gongfan Fang, Jie Song, Xinchao Wang, Chengchao Shen, Xingen Wang, and Mingli
Song.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.5.1" class="ltx_text" style="font-size:90%;">Contrastive model inversion for data-free knowledge distillation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2105.08584</span><span id="bib.bib16.7.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.2.2.1" class="ltx_text" style="font-size:90%;">[17]</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.4.1" class="ltx_text" style="font-size:90%;">
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.5.1" class="ltx_text" style="font-size:90%;">Generative adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Communications of the ACM</span><span id="bib.bib17.7.2" class="ltx_text" style="font-size:90%;">, pages 139â€“144, 2020.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.2.2.1" class="ltx_text" style="font-size:90%;">[18]</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.4.1" class="ltx_text" style="font-size:90%;">
Matan Haroush, Itay Hubara, Elad Hoffer, and Daniel Soudry.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.5.1" class="ltx_text" style="font-size:90%;">The knowledge within: Methods for data-free model compression.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib18.8.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.2.2.1" class="ltx_text" style="font-size:90%;">[19]</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.4.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.5.1" class="ltx_text" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib19.8.3" class="ltx_text" style="font-size:90%;">, pages 770â€“778, 2016.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.2.2.1" class="ltx_text" style="font-size:90%;">[20]</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.4.1" class="ltx_text" style="font-size:90%;">
Ruifei He, Shuyang Sun, Xin Yu, Chuhui Xue, Wenqing Zhang, Philip Torr, Song
Bai, and Xiaojuan Qi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.5.1" class="ltx_text" style="font-size:90%;">Is synthetic data from generative models ready for image recognition?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2210.07574</span><span id="bib.bib20.7.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.2.2.1" class="ltx_text" style="font-size:90%;">[21]</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.4.1" class="ltx_text" style="font-size:90%;">
Ruifei He, Shuyang Sun, Xin Yu, Chuhui Xue, Wenqing Zhang, Philip Torr, Song
Bai, and Xiaojuan Qi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.5.1" class="ltx_text" style="font-size:90%;">Is synthetic data from generative models ready for image recognition?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICLR</span><span id="bib.bib21.8.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.2.2.1" class="ltx_text" style="font-size:90%;">[22]</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.4.1" class="ltx_text" style="font-size:90%;">
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.5.1" class="ltx_text" style="font-size:90%;">Distilling the knowledge in a neural network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1503.02531</span><span id="bib.bib22.7.2" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.2.2.1" class="ltx_text" style="font-size:90%;">[23]</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.4.1" class="ltx_text" style="font-size:90%;">
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.5.1" class="ltx_text" style="font-size:90%;">Denoising diffusion probabilistic models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib23.7.2" class="ltx_text" style="font-size:90%;">, pages 6840â€“6851, 2020.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.2.2.1" class="ltx_text" style="font-size:90%;">[24]</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.4.1" class="ltx_text" style="font-size:90%;">
Jonathan Ho, Chitwan Saharia, William Chan, DavidÂ J Fleet, Mohammad Norouzi,
and Tim Salimans.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.5.1" class="ltx_text" style="font-size:90%;">Cascaded diffusion models for high fidelity image generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of Machine Learning Research</span><span id="bib.bib24.7.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.2.2.1" class="ltx_text" style="font-size:90%;">[25]</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.4.1" class="ltx_text" style="font-size:90%;">
Jangho Kim, SeoungUK Park, and Nojun Kwak.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.5.1" class="ltx_text" style="font-size:90%;">Paraphrasing complex network: Network compression via factor
transfer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1802.04977</span><span id="bib.bib25.7.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.2.2.1" class="ltx_text" style="font-size:90%;">[26]</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.4.1" class="ltx_text" style="font-size:90%;">
Kyungyul Kim, ByeongMoon Ji, Doyoung Yoon, and Sangheum Hwang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.5.1" class="ltx_text" style="font-size:90%;">Self-knowledge distillation with progressive refinement of targets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib26.8.3" class="ltx_text" style="font-size:90%;">, pages 6567â€“6576, 2021.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.2.2.1" class="ltx_text" style="font-size:90%;">[27]</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.4.1" class="ltx_text" style="font-size:90%;">
Alex Krizhevsky and Geoffrey Hinton.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.5.1" class="ltx_text" style="font-size:90%;">Learning multiple layers of features from tiny images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Technical Report</span><span id="bib.bib27.7.2" class="ltx_text" style="font-size:90%;">, 2009.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.2.2.1" class="ltx_text" style="font-size:90%;">[28]</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.4.1" class="ltx_text" style="font-size:90%;">
Haoying Li, Yifan Yang, Meng Chang, Shiqi Chen, Huajun Feng, Zhihai Xu, QiÂ Li,
and Yueting Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.5.1" class="ltx_text" style="font-size:90%;">Srdiff: Single image super-resolution with diffusion probabilistic
models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Neurocomputing</span><span id="bib.bib28.7.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.2.2.1" class="ltx_text" style="font-size:90%;">[29]</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.4.1" class="ltx_text" style="font-size:90%;">
Zheng Li, Ying Huang, Defang Chen, Tianren Luo, Ning Cai, and Zhigeng Pan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.5.1" class="ltx_text" style="font-size:90%;">Online knowledge distillation via multi-branch diversity enhancement.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib29.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ACCV</span><span id="bib.bib29.8.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.2.2.1" class="ltx_text" style="font-size:90%;">[30]</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.4.1" class="ltx_text" style="font-size:90%;">
Zheng Li, Xiang Li, Lingfeng Yang, Borui Zhao, Renjie Song, Lei Luo, Jun Li,
and Jian Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.5.1" class="ltx_text" style="font-size:90%;">Curriculum temperature for knowledge distillation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2211.16231</span><span id="bib.bib30.7.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.2.2.1" class="ltx_text" style="font-size:90%;">[31]</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.4.1" class="ltx_text" style="font-size:90%;">
Zheng Li, Jingwen Ye, Mingli Song, Ying Huang, and Zhigeng Pan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.5.1" class="ltx_text" style="font-size:90%;">Online knowledge distillation for efficient pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib31.8.3" class="ltx_text" style="font-size:90%;">, pages 11740â€“11750, 2021.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.2.2.1" class="ltx_text" style="font-size:90%;">[32]</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.4.1" class="ltx_text" style="font-size:90%;">
Yifan Liu, KeÂ Chen, Chris Liu, Zengchang Qin, Zhenbo Luo, and Jingdong Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.5.1" class="ltx_text" style="font-size:90%;">Structured knowledge distillation for semantic segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib32.8.3" class="ltx_text" style="font-size:90%;">, pages 2604â€“2613, 2019.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.2.2.1" class="ltx_text" style="font-size:90%;">[33]</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.4.1" class="ltx_text" style="font-size:90%;">
ZeÂ Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
Baining Guo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.5.1" class="ltx_text" style="font-size:90%;">Swin transformer: Hierarchical vision transformer using shifted
windows.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib33.8.3" class="ltx_text" style="font-size:90%;">, pages 10012â€“10022, 2021.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.2.2.1" class="ltx_text" style="font-size:90%;">[34]</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.4.1" class="ltx_text" style="font-size:90%;">
RaphaelÂ Gontijo Lopes, Stefano Fenu, and Thad Starner.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.5.1" class="ltx_text" style="font-size:90%;">Data-free knowledge distillation for deep neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1710.07535</span><span id="bib.bib34.7.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.2.2.1" class="ltx_text" style="font-size:90%;">[35]</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.4.1" class="ltx_text" style="font-size:90%;">
Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.5.1" class="ltx_text" style="font-size:90%;">Dpm-solver: A fast ode solver for diffusion probabilistic model
sampling in around 10 steps.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2206.00927</span><span id="bib.bib35.7.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.2.2.1" class="ltx_text" style="font-size:90%;">[36]</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.4.1" class="ltx_text" style="font-size:90%;">
Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.5.1" class="ltx_text" style="font-size:90%;">Dpm-solver++: Fast solver for guided sampling of diffusion
probabilistic models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2211.01095</span><span id="bib.bib36.7.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.2.2.1" class="ltx_text" style="font-size:90%;">[37]</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.4.1" class="ltx_text" style="font-size:90%;">
Andreas Lugmayr, Martin Danelljan, Andres Romero, Fisher Yu, Radu Timofte, and
Luc VanÂ Gool.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.5.1" class="ltx_text" style="font-size:90%;">Repaint: Inpainting using denoising diffusion probabilistic models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib37.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib37.8.3" class="ltx_text" style="font-size:90%;">, pages 11461â€“11471, 2022.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.2.2.1" class="ltx_text" style="font-size:90%;">[38]</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.4.1" class="ltx_text" style="font-size:90%;">
Liangchen Luo, Mark Sandler, ZiÂ Lin, Andrey Zhmoginov, and Andrew Howard.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.5.1" class="ltx_text" style="font-size:90%;">Large-scale generative data-free distillation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2012.05578</span><span id="bib.bib38.7.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.2.2.1" class="ltx_text" style="font-size:90%;">[39]</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.4.1" class="ltx_text" style="font-size:90%;">
Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.5.1" class="ltx_text" style="font-size:90%;">Shufflenet v2: Practical guidelines for efficient cnn architecture
design.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib39.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib39.8.3" class="ltx_text" style="font-size:90%;">, pages 116â€“131, 2018.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.2.2.1" class="ltx_text" style="font-size:90%;">[40]</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.4.1" class="ltx_text" style="font-size:90%;">
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin,
Bob McGrew, Ilya Sutskever, and Mark Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.5.1" class="ltx_text" style="font-size:90%;">Glide: Towards photorealistic image generation and editing with
text-guided diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2112.10741</span><span id="bib.bib40.7.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.2.2.1" class="ltx_text" style="font-size:90%;">[41]</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.4.1" class="ltx_text" style="font-size:90%;">
AlexanderÂ Quinn Nichol and Prafulla Dhariwal.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.5.1" class="ltx_text" style="font-size:90%;">Improved denoising diffusion probabilistic models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib41.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICML</span><span id="bib.bib41.8.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.2.2.1" class="ltx_text" style="font-size:90%;">[42]</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.4.1" class="ltx_text" style="font-size:90%;">
M-E Nilsback and Andrew Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.5.1" class="ltx_text" style="font-size:90%;">A visual vocabulary for flower classification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib42.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib42.8.3" class="ltx_text" style="font-size:90%;">, pages 1447â€“1454, 2006.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.2.2.1" class="ltx_text" style="font-size:90%;">[43]</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.4.1" class="ltx_text" style="font-size:90%;">
Ozan Ã–zdenizci and Robert Legenstein.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.5.1" class="ltx_text" style="font-size:90%;">Restoring vision in adverse weather conditions with patch-based
denoising diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">T-PAMI</span><span id="bib.bib43.7.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.2.2.1" class="ltx_text" style="font-size:90%;">[44]</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.4.1" class="ltx_text" style="font-size:90%;">
Wonpyo Park, Dongju Kim, Yan Lu, and Minsu Cho.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.5.1" class="ltx_text" style="font-size:90%;">Relational knowledge distillation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib44.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib44.8.3" class="ltx_text" style="font-size:90%;">, pages 3967â€“3976, 2019.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.2.2.1" class="ltx_text" style="font-size:90%;">[45]</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.4.1" class="ltx_text" style="font-size:90%;">
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.5.1" class="ltx_text" style="font-size:90%;">Pytorch: An imperative style, high-performance deep learning library.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib45.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib45.8.3" class="ltx_text" style="font-size:90%;">, pages 8026â€“8037, 2019.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.2.2.1" class="ltx_text" style="font-size:90%;">[46]</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.4.1" class="ltx_text" style="font-size:90%;">
William Peebles and Saining Xie.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.5.1" class="ltx_text" style="font-size:90%;">Scalable diffusion models with transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2212.09748</span><span id="bib.bib46.7.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.2.2.1" class="ltx_text" style="font-size:90%;">[47]</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.4.1" class="ltx_text" style="font-size:90%;">
Biao Qian, Yang Wang, Hongzhi Yin, Richang Hong, and Meng Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.5.1" class="ltx_text" style="font-size:90%;">Switchable online knowledge distillation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib47.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib47.8.3" class="ltx_text" style="font-size:90%;">, pages 449â€“466, 2022.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.2.2.1" class="ltx_text" style="font-size:90%;">[48]</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.4.1" class="ltx_text" style="font-size:90%;">
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.5.1" class="ltx_text" style="font-size:90%;">Hierarchical text-conditional image generation with clip latents.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2204.06125</span><span id="bib.bib48.7.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.2.2.1" class="ltx_text" style="font-size:90%;">[49]</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.4.1" class="ltx_text" style="font-size:90%;">
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec
Radford, Mark Chen, and Ilya Sutskever.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.5.1" class="ltx_text" style="font-size:90%;">Zero-shot text-to-image generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib49.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICML</span><span id="bib.bib49.8.3" class="ltx_text" style="font-size:90%;">, pages 8821â€“8831, 2021.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib50.2.2.1" class="ltx_text" style="font-size:90%;">[50]</span></span>
<span class="ltx_bibblock"><span id="bib.bib50.4.1" class="ltx_text" style="font-size:90%;">
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and BjÃ¶rn
Ommer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.5.1" class="ltx_text" style="font-size:90%;">High-resolution image synthesis with latent diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib50.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib50.8.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib51.2.2.1" class="ltx_text" style="font-size:90%;">[51]</span></span>
<span class="ltx_bibblock"><span id="bib.bib51.4.1" class="ltx_text" style="font-size:90%;">
Adriana Romero, Nicolas Ballas, SamiraÂ Ebrahimi Kahou, Antoine Chassang, Carlo
Gatta, and Yoshua Bengio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.5.1" class="ltx_text" style="font-size:90%;">Fitnets: Hints for thin deep nets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1412.6550</span><span id="bib.bib51.7.2" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib52.2.2.1" class="ltx_text" style="font-size:90%;">[52]</span></span>
<span class="ltx_bibblock"><span id="bib.bib52.4.1" class="ltx_text" style="font-size:90%;">
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, EmilyÂ L
Denton, Kamyar Ghasemipour, Raphael GontijoÂ Lopes, Burcu KaragolÂ Ayan, Tim
Salimans, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.5.1" class="ltx_text" style="font-size:90%;">Photorealistic text-to-image diffusion models with deep language
understanding.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib52.7.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib53.2.2.1" class="ltx_text" style="font-size:90%;">[53]</span></span>
<span class="ltx_bibblock"><span id="bib.bib53.4.1" class="ltx_text" style="font-size:90%;">
Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, DavidÂ J Fleet, and
Mohammad Norouzi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.5.1" class="ltx_text" style="font-size:90%;">Image super-resolution via iterative refinement.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">T-PAMI</span><span id="bib.bib53.7.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib54.2.2.1" class="ltx_text" style="font-size:90%;">[54]</span></span>
<span class="ltx_bibblock"><span id="bib.bib54.4.1" class="ltx_text" style="font-size:90%;">
Karen Simonyan and Andrew Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.5.1" class="ltx_text" style="font-size:90%;">Very deep convolutional networks for large-scale image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1409.1556</span><span id="bib.bib54.7.2" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib55.2.2.1" class="ltx_text" style="font-size:90%;">[55]</span></span>
<span class="ltx_bibblock"><span id="bib.bib55.4.1" class="ltx_text" style="font-size:90%;">
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.5.1" class="ltx_text" style="font-size:90%;">Deep unsupervised learning using nonequilibrium thermodynamics.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib55.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICML</span><span id="bib.bib55.8.3" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib56.2.2.1" class="ltx_text" style="font-size:90%;">[56]</span></span>
<span class="ltx_bibblock"><span id="bib.bib56.4.1" class="ltx_text" style="font-size:90%;">
Yang Song, Jascha Sohl-Dickstein, DiederikÂ P Kingma, Abhishek Kumar, Stefano
Ermon, and Ben Poole.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.5.1" class="ltx_text" style="font-size:90%;">Score-based generative modeling through stochastic differential
equations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2011.13456</span><span id="bib.bib56.7.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib57.2.2.1" class="ltx_text" style="font-size:90%;">[57]</span></span>
<span class="ltx_bibblock"><span id="bib.bib57.4.1" class="ltx_text" style="font-size:90%;">
Yonglong Tian, Dilip Krishnan, and Phillip Isola.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.5.1" class="ltx_text" style="font-size:90%;">Contrastive representation distillation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1910.10699</span><span id="bib.bib57.7.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib58.2.2.1" class="ltx_text" style="font-size:90%;">[58]</span></span>
<span class="ltx_bibblock"><span id="bib.bib58.4.1" class="ltx_text" style="font-size:90%;">
Brandon Trabucco, Kyle Doherty, Max Gurinas, and Ruslan Salakhutdinov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.5.1" class="ltx_text" style="font-size:90%;">Effective data augmentation with diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2302.07944</span><span id="bib.bib58.7.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib59.2.2.1" class="ltx_text" style="font-size:90%;">[59]</span></span>
<span class="ltx_bibblock"><span id="bib.bib59.4.1" class="ltx_text" style="font-size:90%;">
Yukang Wang, Wei Zhou, Tao Jiang, Xiang Bai, and Yongchao Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.5.1" class="ltx_text" style="font-size:90%;">Intra-class feature variation distillation for semantic segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib59.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib59.8.3" class="ltx_text" style="font-size:90%;">, pages 346â€“362, 2020.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib60.2.2.1" class="ltx_text" style="font-size:90%;">[60]</span></span>
<span class="ltx_bibblock"><span id="bib.bib60.4.1" class="ltx_text" style="font-size:90%;">
Jiazheng Xu, Xiao Liu, Yuchen Wu, Yuxuan Tong, Qinkai Li, Ming Ding, Jie Tang,
and Yuxiao Dong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.5.1" class="ltx_text" style="font-size:90%;">Imagereward: Learning and evaluating human preferences for
text-to-image generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2304.05977</span><span id="bib.bib60.7.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib61.2.2.1" class="ltx_text" style="font-size:90%;">[61]</span></span>
<span class="ltx_bibblock"><span id="bib.bib61.4.1" class="ltx_text" style="font-size:90%;">
Jing Yang, Brais Martinez, Adrian Bulat, Georgios Tzimiropoulos, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.5.1" class="ltx_text" style="font-size:90%;">Knowledge distillation via softmax regression representation
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib61.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICLR</span><span id="bib.bib61.8.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib62.2.2.1" class="ltx_text" style="font-size:90%;">[62]</span></span>
<span class="ltx_bibblock"><span id="bib.bib62.4.1" class="ltx_text" style="font-size:90%;">
Zhendong Yang, Zhe Li, Ailing Zeng, Zexian Li, Chun Yuan, and YuÂ Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.5.1" class="ltx_text" style="font-size:90%;">Vitkd: Practical guidelines for vit feature knowledge distillation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2209.02432</span><span id="bib.bib62.7.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib63.2.2.1" class="ltx_text" style="font-size:90%;">[63]</span></span>
<span class="ltx_bibblock"><span id="bib.bib63.4.1" class="ltx_text" style="font-size:90%;">
Hongxu Yin, Pavlo Molchanov, JoseÂ M Alvarez, Zhizhong Li, Arun Mallya, Derek
Hoiem, NirajÂ K Jha, and Jan Kautz.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.5.1" class="ltx_text" style="font-size:90%;">Dreaming to distill: Data-free knowledge transfer via deepinversion.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib63.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib63.8.3" class="ltx_text" style="font-size:90%;">, pages 8715â€“8724, 2020.
</span>
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib64.2.2.1" class="ltx_text" style="font-size:90%;">[64]</span></span>
<span class="ltx_bibblock"><span id="bib.bib64.4.1" class="ltx_text" style="font-size:90%;">
Sangdoo Yun, Dongyoon Han, SeongÂ Joon Oh, Sanghyuk Chun, Junsuk Choe, and
Youngjoon Yoo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.5.1" class="ltx_text" style="font-size:90%;">Cutmix: Regularization strategy to train strong classifiers with
localizable features.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib64.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib64.8.3" class="ltx_text" style="font-size:90%;">, pages 6023â€“6032, 2019.
</span>
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib65.2.2.1" class="ltx_text" style="font-size:90%;">[65]</span></span>
<span class="ltx_bibblock"><span id="bib.bib65.4.1" class="ltx_text" style="font-size:90%;">
Sergey Zagoruyko and Nikos Komodakis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.5.1" class="ltx_text" style="font-size:90%;">Paying more attention to attention: Improving the performance of
convolutional neural networks via attention transfer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1612.03928</span><span id="bib.bib65.7.2" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib66.2.2.1" class="ltx_text" style="font-size:90%;">[66]</span></span>
<span class="ltx_bibblock"><span id="bib.bib66.4.1" class="ltx_text" style="font-size:90%;">
Feng Zhang, Xiatian Zhu, and Mao Ye.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.5.1" class="ltx_text" style="font-size:90%;">Fast human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib66.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib66.8.3" class="ltx_text" style="font-size:90%;">, pages 3517â€“3526, 2019.
</span>
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib67.2.2.1" class="ltx_text" style="font-size:90%;">[67]</span></span>
<span class="ltx_bibblock"><span id="bib.bib67.4.1" class="ltx_text" style="font-size:90%;">
Linfeng Zhang, Jiebo Song, Anni Gao, Jingwei Chen, Chenglong Bao, and Kaisheng
Ma.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib67.5.1" class="ltx_text" style="font-size:90%;">Be your own teacher: Improve the performance of convolutional neural
networks via self distillation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib67.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib67.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib67.8.3" class="ltx_text" style="font-size:90%;">, pages 3713â€“3722, 2019.
</span>
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib68.2.2.1" class="ltx_text" style="font-size:90%;">[68]</span></span>
<span class="ltx_bibblock"><span id="bib.bib68.4.1" class="ltx_text" style="font-size:90%;">
Ying Zhang, Tao Xiang, TimothyÂ M Hospedales, and Huchuan Lu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib68.5.1" class="ltx_text" style="font-size:90%;">Deep mutual learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib68.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib68.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib68.8.3" class="ltx_text" style="font-size:90%;">, pages 4320â€“4328, 2018.
</span>
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib69.2.2.1" class="ltx_text" style="font-size:90%;">[69]</span></span>
<span class="ltx_bibblock"><span id="bib.bib69.4.1" class="ltx_text" style="font-size:90%;">
Borui Zhao, Quan Cui, Renjie Song, Yiyu Qiu, and Jiajun Liang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib69.5.1" class="ltx_text" style="font-size:90%;">Decoupled knowledge distillation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib69.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib69.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib69.8.3" class="ltx_text" style="font-size:90%;">, pages 11953â€“11962, 2022.
</span>
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib70.2.2.1" class="ltx_text" style="font-size:90%;">[70]</span></span>
<span class="ltx_bibblock"><span id="bib.bib70.4.1" class="ltx_text" style="font-size:90%;">
Xiatian Zhu, Shaogang Gong, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib70.5.1" class="ltx_text" style="font-size:90%;">Knowledge distillation by on-the-fly native ensemble.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib70.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib70.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib70.8.3" class="ltx_text" style="font-size:90%;">, pages 7517â€“7527, 2018.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Data generation.</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p id="A1.SS1.p1.1" class="ltx_p">To generate the desired images, we utilize off-the-shelf text-to-image diffusion models such as GLIDEÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">nichol2021glide</span> </a></cite> and Stable DiffusionÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">rombach2022high</span> </a></cite>. The text prompt used in these models has a fixed format of "A realistic photo of <span id="A1.SS1.p1.1.1" class="ltx_text ltx_font_italic">class</span>," where "<span id="A1.SS1.p1.1.2" class="ltx_text ltx_font_italic">class</span>" specifies the category of the target image.
When using GLIDE, we employ the official default settings for inference, which consist of a sampling step of 100 and a classifier-free guidance scale of 3.0. Similarly, for Stable Diffusion, we utilize the official settings of a sampling step of 50 and a classifier-free guidance scale of 7.5.</p>
</div>
<div id="A1.SS1.p2" class="ltx_para">
<p id="A1.SS1.p2.1" class="ltx_p">DiTÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">peebles2022scalable</span> </a></cite> differs from the text-to-image method in that it uses class labels as input to generate synthetic images. To generate an image corresponding to a specific class in the ImageNet-1K dataset, we input the index of that class. For example, to generate an image of a Pembroke Welsh Corgi, we would input index 263.</p>
</div>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Training details.</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p id="A1.SS2.p1.3" class="ltx_p"><span id="A1.SS2.p1.3.1" class="ltx_text ltx_font_bold">CIFAR-100.</span> We first resize the synthesized image of size <math id="A1.SS2.p1.1.m1.1" class="ltx_Math" alttext="256\times 256" display="inline"><semantics id="A1.SS2.p1.1.m1.1a"><mrow id="A1.SS2.p1.1.m1.1.1" xref="A1.SS2.p1.1.m1.1.1.cmml"><mn id="A1.SS2.p1.1.m1.1.1.2" xref="A1.SS2.p1.1.m1.1.1.2.cmml">256</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS2.p1.1.m1.1.1.1" xref="A1.SS2.p1.1.m1.1.1.1.cmml">Ã—</mo><mn id="A1.SS2.p1.1.m1.1.1.3" xref="A1.SS2.p1.1.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.1.m1.1b"><apply id="A1.SS2.p1.1.m1.1.1.cmml" xref="A1.SS2.p1.1.m1.1.1"><times id="A1.SS2.p1.1.m1.1.1.1.cmml" xref="A1.SS2.p1.1.m1.1.1.1"></times><cn type="integer" id="A1.SS2.p1.1.m1.1.1.2.cmml" xref="A1.SS2.p1.1.m1.1.1.2">256</cn><cn type="integer" id="A1.SS2.p1.1.m1.1.1.3.cmml" xref="A1.SS2.p1.1.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.1.m1.1c">256\times 256</annotation></semantics></math> to <math id="A1.SS2.p1.2.m2.1" class="ltx_Math" alttext="32\times 32" display="inline"><semantics id="A1.SS2.p1.2.m2.1a"><mrow id="A1.SS2.p1.2.m2.1.1" xref="A1.SS2.p1.2.m2.1.1.cmml"><mn id="A1.SS2.p1.2.m2.1.1.2" xref="A1.SS2.p1.2.m2.1.1.2.cmml">32</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS2.p1.2.m2.1.1.1" xref="A1.SS2.p1.2.m2.1.1.1.cmml">Ã—</mo><mn id="A1.SS2.p1.2.m2.1.1.3" xref="A1.SS2.p1.2.m2.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.2.m2.1b"><apply id="A1.SS2.p1.2.m2.1.1.cmml" xref="A1.SS2.p1.2.m2.1.1"><times id="A1.SS2.p1.2.m2.1.1.1.cmml" xref="A1.SS2.p1.2.m2.1.1.1"></times><cn type="integer" id="A1.SS2.p1.2.m2.1.1.2.cmml" xref="A1.SS2.p1.2.m2.1.1.2">32</cn><cn type="integer" id="A1.SS2.p1.2.m2.1.1.3.cmml" xref="A1.SS2.p1.2.m2.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.2.m2.1c">32\times 32</annotation></semantics></math>. In addition to applying the classic distillation data augmentation scheme, i.e., random cropping and horizontal flipping, we use the CutMixÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib64" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">yun2019cutmix</span> </a></cite> augmentation method during training, in order to align with the One-ImageÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">asano2023the</span> </a></cite> augmentation scheme. The temperature <math id="A1.SS2.p1.3.m3.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="A1.SS2.p1.3.m3.1a"><mi id="A1.SS2.p1.3.m3.1.1" xref="A1.SS2.p1.3.m3.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.3.m3.1b"><ci id="A1.SS2.p1.3.m3.1.1.cmml" xref="A1.SS2.p1.3.m3.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.3.m3.1c">\tau</annotation></semantics></math> is set to 10.</p>
</div>
<div id="A1.SS2.p2" class="ltx_para">
<p id="A1.SS2.p2.1" class="ltx_p"><span id="A1.SS2.p2.1.1" class="ltx_text ltx_font_bold">ImageNet-1K.</span> We have two training schedules in this paper. The first is the classic distillation training strategy, which is to train 100 epochs and divide the learning rate by 10 in the 30th, 60th, and 90th epochs. We use this as the default training strategy unless otherwise stated. In TableÂ <a href="#S4.T3" title="Table 3 â€£ 4.2 Comparison to existing synthesis-based distillation methods. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we adopted the second training strategy, which is the same as that of FastDFKDÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">fang2022up</span> </a></cite>. This involves training for 200 epochs, with the learning rate divided by 10 at the 120th, 150th, and 180th epochs.
Specifically, we choose the teacher model with the same structure as the student for distillation in TableÂ <a href="#S4.T3" title="Table 3 â€£ 4.2 Comparison to existing synthesis-based distillation methods. â€£ 4 Experiment â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. In the 5th column, we use ResNet50 as the teacher to train the student ResNet50, while in the 6th column, we use ResNet18 as the teacher to train the student ResNet18.
For data augmentation, following the setting of One-ImageÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">asano2023the</span> </a></cite>, we adopt the CutMix method during training.</p>
</div>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Analysis.</h3>

<div id="A1.SS3.p1" class="ltx_para">
<p id="A1.SS3.p1.1" class="ltx_p">When using DiT to generate images, due to the classifier-free guidance mechanism, the generated images will have a distinct appearance that aligns with the specific class. This allows the classifier to classify these generated images more easily than real images, resulting in higher class confidence, as shown in TableÂ <a href="#A1.T11" title="Table 11 â€£ A.3 Analysis. â€£ Appendix A Appendix â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>.
However, this high confidence in the synthesized images can also result in a sharp output distribution, making it challenging for knowledge distillation to effectively transfer knowledge of class similarity. A smooth target distribution would be more effective for knowledge transfer.</p>
</div>
<figure id="A1.T11" class="ltx_table">
<div id="A1.T11.2.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:216.8pt;height:103.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.5pt,6.9pt) scale(0.882136707765574,0.882136707765574) ;">
<table id="A1.T11.2.2.2" class="ltx_tabular ltx_align_middle">
<tr id="A1.T11.2.2.2.2" class="ltx_tr">
<td id="A1.T11.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="A1.T11.1.1.1.1.1.1" class="ltx_text"><span id="A1.T11.1.1.1.1.1.1.2" class="ltx_text"></span> <span id="A1.T11.1.1.1.1.1.1.1" class="ltx_text">
<span id="A1.T11.1.1.1.1.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T11.1.1.1.1.1.1.1.1.2" class="ltx_tr">
<span id="A1.T11.1.1.1.1.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Sampling</span></span>
<span id="A1.T11.1.1.1.1.1.1.1.1.1" class="ltx_tr">
<span id="A1.T11.1.1.1.1.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Factor <math id="A1.T11.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="A1.T11.1.1.1.1.1.1.1.1.1.1.m1.1a"><mi id="A1.T11.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="A1.T11.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="A1.T11.1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="A1.T11.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.T11.1.1.1.1.1.1.1.1.1.1.m1.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T11.1.1.1.1.1.1.1.1.1.1.m1.1c">s</annotation></semantics></math></span></span>
</span></span> <span id="A1.T11.1.1.1.1.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T11.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t" colspan="5">Sampling Step <math id="A1.T11.2.2.2.2.2.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="A1.T11.2.2.2.2.2.m1.1a"><mi id="A1.T11.2.2.2.2.2.m1.1.1" xref="A1.T11.2.2.2.2.2.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="A1.T11.2.2.2.2.2.m1.1b"><ci id="A1.T11.2.2.2.2.2.m1.1.1.cmml" xref="A1.T11.2.2.2.2.2.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T11.2.2.2.2.2.m1.1c">T</annotation></semantics></math>
</td>
</tr>
<tr id="A1.T11.2.2.2.3" class="ltx_tr">
<td id="A1.T11.2.2.2.3.1" class="ltx_td ltx_align_center">50</td>
<td id="A1.T11.2.2.2.3.2" class="ltx_td ltx_align_center">100</td>
<td id="A1.T11.2.2.2.3.3" class="ltx_td ltx_align_center">150</td>
<td id="A1.T11.2.2.2.3.4" class="ltx_td ltx_align_center">200</td>
<td id="A1.T11.2.2.2.3.5" class="ltx_td ltx_align_center">250</td>
</tr>
<tr id="A1.T11.2.2.2.4" class="ltx_tr">
<td id="A1.T11.2.2.2.4.1" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="A1.T11.2.2.2.4.2" class="ltx_td ltx_align_center ltx_border_t">44.68</td>
<td id="A1.T11.2.2.2.4.3" class="ltx_td ltx_align_center ltx_border_t">48.62</td>
<td id="A1.T11.2.2.2.4.4" class="ltx_td ltx_align_center ltx_border_t">50.53</td>
<td id="A1.T11.2.2.2.4.5" class="ltx_td ltx_align_center ltx_border_t">50.40</td>
<td id="A1.T11.2.2.2.4.6" class="ltx_td ltx_align_center ltx_border_t">50.83</td>
</tr>
<tr id="A1.T11.2.2.2.5" class="ltx_tr">
<td id="A1.T11.2.2.2.5.1" class="ltx_td ltx_align_center">2</td>
<td id="A1.T11.2.2.2.5.2" class="ltx_td ltx_align_center" style="background-color:#ECECEC;"><span id="A1.T11.2.2.2.5.2.1" class="ltx_text" style="background-color:#ECECEC;">80.31</span></td>
<td id="A1.T11.2.2.2.5.3" class="ltx_td ltx_align_center" style="background-color:#ECECEC;"><span id="A1.T11.2.2.2.5.3.1" class="ltx_text" style="background-color:#ECECEC;">81.45</span></td>
<td id="A1.T11.2.2.2.5.4" class="ltx_td ltx_align_center" style="background-color:#ECECEC;"><span id="A1.T11.2.2.2.5.4.1" class="ltx_text" style="background-color:#ECECEC;">81.72</span></td>
<td id="A1.T11.2.2.2.5.5" class="ltx_td ltx_align_center" style="background-color:#ECECEC;"><span id="A1.T11.2.2.2.5.5.1" class="ltx_text" style="background-color:#ECECEC;">82.07</span></td>
<td id="A1.T11.2.2.2.5.6" class="ltx_td ltx_align_center" style="background-color:#ECECEC;"><span id="A1.T11.2.2.2.5.6.1" class="ltx_text" style="background-color:#ECECEC;">81.90</span></td>
</tr>
<tr id="A1.T11.2.2.2.6" class="ltx_tr">
<td id="A1.T11.2.2.2.6.1" class="ltx_td ltx_align_center">3</td>
<td id="A1.T11.2.2.2.6.2" class="ltx_td ltx_align_center">87.56</td>
<td id="A1.T11.2.2.2.6.3" class="ltx_td ltx_align_center">87.73</td>
<td id="A1.T11.2.2.2.6.4" class="ltx_td ltx_align_center">87.46</td>
<td id="A1.T11.2.2.2.6.5" class="ltx_td ltx_align_center">87.53</td>
<td id="A1.T11.2.2.2.6.6" class="ltx_td ltx_align_center">87.53</td>
</tr>
<tr id="A1.T11.2.2.2.7" class="ltx_tr">
<td id="A1.T11.2.2.2.7.1" class="ltx_td ltx_align_center ltx_border_b">4</td>
<td id="A1.T11.2.2.2.7.2" class="ltx_td ltx_align_center ltx_border_b">88.96</td>
<td id="A1.T11.2.2.2.7.3" class="ltx_td ltx_align_center ltx_border_b">89.00</td>
<td id="A1.T11.2.2.2.7.4" class="ltx_td ltx_align_center ltx_border_b">88.72</td>
<td id="A1.T11.2.2.2.7.5" class="ltx_td ltx_align_center ltx_border_b">88.76</td>
<td id="A1.T11.2.2.2.7.6" class="ltx_td ltx_align_center ltx_border_b">88.71</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 11: </span>Pretrained ResNet18 teacher evaluated on synthetic dataset with different scaling factors <math id="A1.T11.7.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="A1.T11.7.m1.1b"><mi id="A1.T11.7.m1.1.1" xref="A1.T11.7.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="A1.T11.7.m1.1c"><ci id="A1.T11.7.m1.1.1.cmml" xref="A1.T11.7.m1.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T11.7.m1.1d">s</annotation></semantics></math> and sampling steps <math id="A1.T11.8.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="A1.T11.8.m2.1b"><mi id="A1.T11.8.m2.1.1" xref="A1.T11.8.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="A1.T11.8.m2.1c"><ci id="A1.T11.8.m2.1.1.cmml" xref="A1.T11.8.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T11.8.m2.1d">T</annotation></semantics></math>. When classifier-free guidance is usedÂ (i.e., <math id="A1.T11.9.m3.1" class="ltx_Math" alttext="s&gt;1" display="inline"><semantics id="A1.T11.9.m3.1b"><mrow id="A1.T11.9.m3.1.1" xref="A1.T11.9.m3.1.1.cmml"><mi id="A1.T11.9.m3.1.1.2" xref="A1.T11.9.m3.1.1.2.cmml">s</mi><mo id="A1.T11.9.m3.1.1.1" xref="A1.T11.9.m3.1.1.1.cmml">&gt;</mo><mn id="A1.T11.9.m3.1.1.3" xref="A1.T11.9.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T11.9.m3.1c"><apply id="A1.T11.9.m3.1.1.cmml" xref="A1.T11.9.m3.1.1"><gt id="A1.T11.9.m3.1.1.1.cmml" xref="A1.T11.9.m3.1.1.1"></gt><ci id="A1.T11.9.m3.1.1.2.cmml" xref="A1.T11.9.m3.1.1.2">ğ‘ </ci><cn type="integer" id="A1.T11.9.m3.1.1.3.cmml" xref="A1.T11.9.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T11.9.m3.1d">s&gt;1</annotation></semantics></math>), these results are significantly higher than the accuracy of 69.75% on the real ImageNet validation set. When <math id="A1.T11.10.m4.1" class="ltx_Math" alttext="s" display="inline"><semantics id="A1.T11.10.m4.1b"><mi id="A1.T11.10.m4.1.1" xref="A1.T11.10.m4.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="A1.T11.10.m4.1c"><ci id="A1.T11.10.m4.1.1.cmml" xref="A1.T11.10.m4.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T11.10.m4.1d">s</annotation></semantics></math>=1, we can observe that the accuracy of the pre-trained teacher is only around 50%. This implies that the teacher is unable to provide accurate soft labels for distillation.</figcaption>
</figure>
<div id="A1.SS3.p2" class="ltx_para">
<p id="A1.SS3.p2.3" class="ltx_p">Both our second and third findings in SectionÂ <a href="#S1" title="1 Introduction â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> are attempts to reduce the sharpness of the distribution and create a smooth learning target for distillation.
(1) The goal of creating low-fidelity samples is to increase the classification difficulty of the classifier and decrease its tendency to become overconfident in predicting a certain class.
As shown in TableÂ <a href="#A1.T12" title="Table 12 â€£ A.3 Analysis. â€£ Appendix A Appendix â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>, by gradually reducing the scaling factor <math id="A1.SS3.p2.1.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="A1.SS3.p2.1.m1.1a"><mi id="A1.SS3.p2.1.m1.1.1" xref="A1.SS3.p2.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="A1.SS3.p2.1.m1.1b"><ci id="A1.SS3.p2.1.m1.1.1.cmml" xref="A1.SS3.p2.1.m1.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p2.1.m1.1c">s</annotation></semantics></math>, the variance is gradually reduced, which means that the distribution generated by the teacher becomes smoother. The best performance is achieved when we set <math id="A1.SS3.p2.2.m2.1" class="ltx_Math" alttext="s" display="inline"><semantics id="A1.SS3.p2.2.m2.1a"><mi id="A1.SS3.p2.2.m2.1.1" xref="A1.SS3.p2.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="A1.SS3.p2.2.m2.1b"><ci id="A1.SS3.p2.2.m2.1.1.cmml" xref="A1.SS3.p2.2.m2.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p2.2.m2.1c">s</annotation></semantics></math>=2, which corresponds to the lowest scaling factor in the table.
(2) Weak classifiers are less discriminative compared to strong classifiers and tend to produce smoother outputs. In TableÂ <a href="#A1.T12" title="Table 12 â€£ A.3 Analysis. â€£ Appendix A Appendix â€£ Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>, we compare the output variance of pretrained ResNet18 and ResNet34 teachers on the synthetic dataset. Our results indicate that for different scaling factors <math id="A1.SS3.p2.3.m3.1" class="ltx_Math" alttext="s" display="inline"><semantics id="A1.SS3.p2.3.m3.1a"><mi id="A1.SS3.p2.3.m3.1.1" xref="A1.SS3.p2.3.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="A1.SS3.p2.3.m3.1b"><ci id="A1.SS3.p2.3.m3.1.1.cmml" xref="A1.SS3.p2.3.m3.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p2.3.m3.1c">s</annotation></semantics></math>, ResNet18 consistently achieves a lower variance than ResNet34. This shows that ResNet18 can produce smoother output for distillation.</p>
</div>
<figure id="A1.T12" class="ltx_table">
<div id="A1.T12.1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:173.4pt;height:60.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.9pt,-0.3pt) scale(1.01087047482636,1.01087047482636) ;">
<table id="A1.T12.1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="A1.T12.1.1.1.1" class="ltx_tr">
<td id="A1.T12.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">VarianceÂ (<math id="A1.T12.1.1.1.1.1.m1.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="A1.T12.1.1.1.1.1.m1.1a"><msup id="A1.T12.1.1.1.1.1.m1.1.1" xref="A1.T12.1.1.1.1.1.m1.1.1.cmml"><mn id="A1.T12.1.1.1.1.1.m1.1.1.2" xref="A1.T12.1.1.1.1.1.m1.1.1.2.cmml">10</mn><mrow id="A1.T12.1.1.1.1.1.m1.1.1.3" xref="A1.T12.1.1.1.1.1.m1.1.1.3.cmml"><mo id="A1.T12.1.1.1.1.1.m1.1.1.3a" xref="A1.T12.1.1.1.1.1.m1.1.1.3.cmml">âˆ’</mo><mn id="A1.T12.1.1.1.1.1.m1.1.1.3.2" xref="A1.T12.1.1.1.1.1.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="A1.T12.1.1.1.1.1.m1.1b"><apply id="A1.T12.1.1.1.1.1.m1.1.1.cmml" xref="A1.T12.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T12.1.1.1.1.1.m1.1.1.1.cmml" xref="A1.T12.1.1.1.1.1.m1.1.1">superscript</csymbol><cn type="integer" id="A1.T12.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.T12.1.1.1.1.1.m1.1.1.2">10</cn><apply id="A1.T12.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.T12.1.1.1.1.1.m1.1.1.3"><minus id="A1.T12.1.1.1.1.1.m1.1.1.3.1.cmml" xref="A1.T12.1.1.1.1.1.m1.1.1.3"></minus><cn type="integer" id="A1.T12.1.1.1.1.1.m1.1.1.3.2.cmml" xref="A1.T12.1.1.1.1.1.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T12.1.1.1.1.1.m1.1c">10^{-4}</annotation></semantics></math>)</td>
<td id="A1.T12.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t">s=2</td>
<td id="A1.T12.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">s=3</td>
<td id="A1.T12.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">s=4</td>
</tr>
<tr id="A1.T12.1.1.1.2" class="ltx_tr">
<td id="A1.T12.1.1.1.2.1" class="ltx_td ltx_align_center ltx_border_t">ResNet18</td>
<td id="A1.T12.1.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#ECECEC;"><span id="A1.T12.1.1.1.2.2.1" class="ltx_text" style="background-color:#ECECEC;">6.80</span></td>
<td id="A1.T12.1.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t">7.57</td>
<td id="A1.T12.1.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t">7.72</td>
</tr>
<tr id="A1.T12.1.1.1.3" class="ltx_tr">
<td id="A1.T12.1.1.1.3.1" class="ltx_td ltx_align_center ltx_border_b">ResNet34</td>
<td id="A1.T12.1.1.1.3.2" class="ltx_td ltx_align_center ltx_border_b" style="background-color:#ECECEC;"><span id="A1.T12.1.1.1.3.2.1" class="ltx_text" style="background-color:#ECECEC;">7.25</span></td>
<td id="A1.T12.1.1.1.3.3" class="ltx_td ltx_align_center ltx_border_b">7.95</td>
<td id="A1.T12.1.1.1.3.4" class="ltx_td ltx_align_center ltx_border_b">8.10</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 12: </span>The varianceÂ (<math id="A1.T12.3.m1.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="A1.T12.3.m1.1b"><msup id="A1.T12.3.m1.1.1" xref="A1.T12.3.m1.1.1.cmml"><mn id="A1.T12.3.m1.1.1.2" xref="A1.T12.3.m1.1.1.2.cmml">10</mn><mrow id="A1.T12.3.m1.1.1.3" xref="A1.T12.3.m1.1.1.3.cmml"><mo id="A1.T12.3.m1.1.1.3b" xref="A1.T12.3.m1.1.1.3.cmml">âˆ’</mo><mn id="A1.T12.3.m1.1.1.3.2" xref="A1.T12.3.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="A1.T12.3.m1.1c"><apply id="A1.T12.3.m1.1.1.cmml" xref="A1.T12.3.m1.1.1"><csymbol cd="ambiguous" id="A1.T12.3.m1.1.1.1.cmml" xref="A1.T12.3.m1.1.1">superscript</csymbol><cn type="integer" id="A1.T12.3.m1.1.1.2.cmml" xref="A1.T12.3.m1.1.1.2">10</cn><apply id="A1.T12.3.m1.1.1.3.cmml" xref="A1.T12.3.m1.1.1.3"><minus id="A1.T12.3.m1.1.1.3.1.cmml" xref="A1.T12.3.m1.1.1.3"></minus><cn type="integer" id="A1.T12.3.m1.1.1.3.2.cmml" xref="A1.T12.3.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T12.3.m1.1d">10^{-4}</annotation></semantics></math>) of the probability distribution output by the pretrained teacher model on the synthetic dataset. The sampling step is fixed to 100. Smaller variances represent smoother probability distributions.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2305.12953" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2305.12954" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2305.12954">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2305.12954" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2305.12955" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 06:06:20 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
