<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>JungleGPT: Designing and Optimizing Compound AI Systems for E-Commerce</title>
<!--Generated on Tue May 28 20:12:10 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2407.00038v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#S1" title="In JungleGPT: Designing and Optimizing Compound AI Systems for E-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#S2" title="In JungleGPT: Designing and Optimizing Compound AI Systems for E-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>JungleGPT: An E-Commerce AI Compound System</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#S2.SS0.SSS0.Px1" title="In 2 JungleGPT: An E-Commerce AI Compound System ‣ JungleGPT: Designing and Optimizing Compound AI Systems for E-Commerce"><span class="ltx_text ltx_ref_title">Design</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#S2.SS0.SSS0.Px2" title="In 2 JungleGPT: An E-Commerce AI Compound System ‣ JungleGPT: Designing and Optimizing Compound AI Systems for E-Commerce"><span class="ltx_text ltx_ref_title">Cost Optimization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#S2.SS0.SSS0.Px3" title="In 2 JungleGPT: An E-Commerce AI Compound System ‣ JungleGPT: Designing and Optimizing Compound AI Systems for E-Commerce"><span class="ltx_text ltx_ref_title">Conclusion</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">JungleGPT: Designing and Optimizing Compound AI Systems for E-Commerce</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sherry Ruan 
<br class="ltx_break"/>Stanford University 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">sruan@cs.stanford.edu</span>
<br class="ltx_break"/>Tian Zhao
<br class="ltx_break"/>Stanford University
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.2.id2">tianzhao@cs.stanford.edu</span>
<br class="ltx_break"/>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id3.id1">LLMs have significantly advanced the e-commerce industry by powering applications such as personalized recommendations and customer service. However, most current efforts focus solely on monolithic LLMs and fall short in addressing the complexity and scale of real-world e-commerce scenarios. In this work, we present JungleGPT, the first compound AI system tailored for real-world e-commerce applications. We outline the system’s design and the techniques used to optimize its performance for practical use cases, which have proven to reduce inference costs to less than 1% of what they would be with a powerful, monolithic LLM.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Global e-commerce sales are projected to reach $6.3 trillion in 2024 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib6" title="">6</a>]</cite>, accounting for 6% of the global gross domestic product (GDP) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib9" title="">9</a>]</cite>, underscoring the critical role of e-commerce in the world economy.
AI has been instrumental in accelerating the e-commerce industry by enhancing the online shopping experience through personalized recommendations and facilitating online sales with AI-powered tools such as creative content generation and automated customer service.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">With recent advancements in large language models (LLMs), significant progress has been made in e-commerce, including e-commerce-specific translations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib8" title="">8</a>]</cite>, product review analysis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib15" title="">15</a>]</cite>, and automatic product descriptions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib18" title="">18</a>]</cite>.
Furthermore, researchers have employed various LLM techniques to enhance the performance of LLMs on specific e-commerce tasks, including crafting instruction datasets tailored for e-commerce <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib13" title="">13</a>]</cite>, instruction tuning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib12" title="">12</a>]</cite>, and multi-aspect instruction following <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib16" title="">16</a>]</cite>. These methods have proven to surpass the capabilities of general LLMs within the e-commerce domain. However, existing work primarily focuses on improving the performance of monolithic LLMs on e-commerce datasets. Real-world e-commerce user patterns differ significantly from traditional enterprise AI in three key areas:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">Global Footprint</span>: Both e-commerce buyers and sellers are located globally, which requires <span class="ltx_text ltx_font_italic" id="S1.I1.i1.p1.1.2">efficient caching systems</span> to ensure seamless access to data.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">Read-Heavy Operations</span>: E-commerce user patterns generally involve more read operations than write operations. Therefore, it is essential to bring snapshots of data closer to users, such as <span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.2">within browser sessions or on edge networks</span>.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">Long-Tail Users</span>: Online sellers are predominantly small to medium-sized businesses (SMBs) (e.g., about 98% of Amazon sellers are SMBs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib14" title="">14</a>]</cite>). The ratio of their data size to their paying power is typically high, so LLM solutions need to be <span class="ltx_text ltx_font_italic" id="S1.I1.i3.p1.1.2">extremely cost-efficient</span>.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>JungleGPT: An E-Commerce AI Compound System</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">To address the limitations of monolithic LLMs described above, we designed and built <span class="ltx_text ltx_font_italic" id="S2.p1.1.1">JungleGPT</span>, the first compound AI system <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib17" title="">17</a>]</cite> tailored for e-commerce to meet the unique needs of this industry.</p>
</div>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h3 class="ltx_title ltx_title_paragraph">Design</h3>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="269" id="S2.F1.g1" src="extracted/5622508/JungleGPT.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>JungleGPT Compound AI System Design</figcaption>
</figure>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">The JungleGPT system encompasses three key components: <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px1.p1.1.1">JungleGPT Copilot</span>, <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px1.p1.1.2">JungleGPT Caching Nodes</span>, and <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px1.p1.1.3">JungleGPT LLM Nodes</span>. The components are connected with asynchronous updates to ensure prompt user interactions.</p>
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">JungleGPT Copilot</span>: JungleGPT Copilot sits on the critical path of user interaction loops. Conceptually, this is the “L1 cache” of the whole JungleGPT system - data storage and compute capacity are low and designed to support frequent read operations. The copilot runs fast, lightweight machine learning models using modern web technology, e.g., webGPU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib10" title="">10</a>]</cite> for analyzing user queries and returning responses with low latency. Furthermore, JungleGPT Copilot utilizes powerful parsers in modern web frameworks to clean up context for LLMs and prepare prompts. To ensure security, we design semantic caches specifically for sensitive user data, e.g., personal identification information. We implement these caches using browser-local session memories and do not share them with backend JungleGPT LLM nodes.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">JungleGPT Caching Nodes</span>: E-commerce users’ geographical locations are extremely global. To enable low-latency, distributed data access for users, we utilize modern caching systems deployed on edge networks - each user can access a snapshot of their data on edge nodes that are geographically closer to them, and these caches are updated lazily by the backend JungleGPT LLM nodes. In our evaluation, we typically find users able to access their snapshots within hundreds of milliseconds.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">JungleGPT LLM Nodes</span>: JungleGPT LLM nodes are detached from the main user interaction loop and periodically update JungleGPT Caching Nodes. The asynchronous design ensures that LLM inference latency does not sit on the critical path in user interaction.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h3 class="ltx_title ltx_title_paragraph">Cost Optimization</h3>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">Cost efficiency is a key consideration for e-commerce applications. Generally, e-commerce SaaS products have monthly fees capped at several hundred dollars. Assuming a computing budget of $100/month, a user can only generate 2.2M tokens with GPT4.5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib4" title="">4</a>]</cite>, which significantly falls short of compute needs. From our user interviews, we typically see users trying to analyze texts that are 1 to 2 orders of magnitude greater than 2.2M tokens. Furthermore, e-commerce users are often English-as-a-Second-Language (ESL) speakers and require LLMs to provide language-specific analysis. To meet these needs, we utilize an ensemble of small, cost-efficient LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.00038v1#bib.bib11" title="">11</a>]</cite> fine-tuned on common languages of our user base. To further improve analysis quality, we create lightweight rerankers fine-tuned for each language group. Combining small LLMs and rerankers fine-tuned for non-English use cases reduces our inference cost to less than <math alttext="1\%" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="S2.SS0.SSS0.Px2.p1.1.m1.1a"><mrow id="S2.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mn id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">1</mn><mo id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.1">percent</csymbol><cn id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" type="integer" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.1.m1.1c">1\%</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.1.m1.1d">1 %</annotation></semantics></math> of using a powerful and monolithic LLM endpoint.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h3 class="ltx_title ltx_title_paragraph">Conclusion</h3>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.1">We identify three quadrants: global footprint, read-heavy operations, and long-tail users where current monolithic LLMs for e-commerce fall short and a compound AI system can bring significant value to end users. JungleGPT, a compound AI system for e-commerce, is designed to address system requirements in these three quadrants. We hope this work inspires more research and industry efforts towards building effective compound AI to advance the e-commerce industry.</p>
</div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
CroissantLLMChat-v0.1 | Hugging Face.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/croissantllm/CroissantLLMChat-v0.1" title="">https://huggingface.co/croissantllm/CroissantLLMChat-v0.1</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-05-17.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
OpenHathi-7B-Hi-v0.1-Base | Hugging Face.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/sarvamai/OpenHathi-7B-Hi-v0.1-Base" title="">https://huggingface.co/sarvamai/OpenHathi-7B-Hi-v0.1-Base</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-05-17.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
OpenThaiGPT | Hugging Face.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/openthaigpt" title="">https://huggingface.co/openthaigpt</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-05-17.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Pricing | OpenAI.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/api/pricing" title="">https://openai.com/api/pricing</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-05-17.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Visualizing the $105 Trillion World Economy in One Chart.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.visual%5C%5C%0Acapitalist.com/visualizing-the-105-trillion-world-economy-in-one-chart" title="">https://www.visual
<br class="ltx_break"/>capitalist.com/visualizing-the-105-trillion-world-economy-in-one-chart</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-05-17.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Worldwide Retail Ecommerce Forecast 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.emarketer.com/content/worldwide-retail-ecommerce-forecast-2024" title="">https://www.emarketer.com/content/worldwide-retail-ecommerce-forecast-2024</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-05-17.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai, Chengqi Deng, Honghui Ding, Kai Dong, Qiushi Du, Zhe Fu, et al.

</span>
<span class="ltx_bibblock">Deepseek llm: Scaling open-source language models with longtermism.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2401.02954</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Kaidi Chen, Ben Chen, Dehong Gao, Huangyu Dai, Wen Jiang, Wei Ning, Shanqing Yu, Libin Yang, and Xiaoyan Cai.

</span>
<span class="ltx_bibblock">General2Specialized LLMs Translation for E-commerce.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">Companion Proceedings of the ACM on Web Conference 2024</span>, WWW ’24, page 670–673, New York, NY, USA, 2024. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
International Monetary Fund (IMF).

</span>
<span class="ltx_bibblock">World Economic Outlook.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.imf.org/external/datamapper/NGDPD@WEO/OEMDC/ADVEC/WEOWORLD" title="">https://www.imf.org/external/datamapper/NGDPD@WEO/OEMDC/ADVEC/WEOWORLD</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-05-17.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Benjamin Kenwright.

</span>
<span class="ltx_bibblock">Introduction to the WebGPU API.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">Acm siggraph 2022 courses</span>, pages 1–184. 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Hemanth Kumar.

</span>
<span class="ltx_bibblock">Tamil-Mistral-7B-Instruct-v0.1 | Hugging Face.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/Hemanth-thunder/Tamil-Mistral-7B-Instruct-v0.1" title="">https://huggingface.co/Hemanth-thunder/Tamil-Mistral-7B-Instruct-v0.1</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-05-17.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Yangning Li, Shirong Ma, Xiaobin Wang, Shen Huang, Chengyue Jiang, Hai-Tao Zheng, Pengjun Xie, Fei Huang, and Yong Jiang.

</span>
<span class="ltx_bibblock">EcomGPT: Instruction-Tuning Large Language Models with Chain-of-Task Tasks for E-commerce.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</span>, 38(17):18582–18590, Mar. 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Bo Peng, Xinyi Ling, Ziru Chen, Huan Sun, and Xia Ning.

</span>
<span class="ltx_bibblock">eCeLLM: Generalizing Large Language Models for E-commerce from Large-scale, High-quality Instruction Data, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Gitnux Marketdata Report.

</span>
<span class="ltx_bibblock">Must-Know Amazon Seller Statistics [Latest Report].

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://gitnux.org/amazon-seller-statistics" title="">https://gitnux.org/amazon-seller-statistics</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-05-17.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Konstantinos I. Roumeliotis, Nikolaos D. Tselikas, and Dimitrios K. Nasiopoulos.

</span>
<span class="ltx_bibblock">LLMs in e-commerce: A comparative analysis of GPT and LLaMA models in product review evaluation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">Natural Language Processing Journal</span>, 6:100056, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Kaize Shi, Xueyao Sun, Dingxian Wang, Yinlin Fu, Guandong Xu, and Qing Li.

</span>
<span class="ltx_bibblock">LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction Following, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Matei Zaharia, Omar Khattab, Lingjiao Chen, Jared Quincy Davis, Heather Miller, Chris Potts, James Zou, Michael Carbin, Jonathan Frankle, Naveen Rao, and Ali Ghodsi.

</span>
<span class="ltx_bibblock">The Shift from Models to Compound AI Systems.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/" title="">https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/</a>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Jianghong Zhou, Bo Liu, Jhalak Nilesh Acharya Yao Hong, Kuang-chih Lee, and Musen Wen.

</span>
<span class="ltx_bibblock">Leveraging large language models for enhanced product descriptions in ecommerce.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2310.18357</span>, 2023.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue May 28 20:12:10 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
