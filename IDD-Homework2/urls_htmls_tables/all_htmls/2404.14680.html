<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers</title>
<!--Generated on Tue Apr 30 21:43:53 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2404.14680v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S1" title="In Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S2" title="In Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S3" title="In Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S3.SS1" title="In 3 Results ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Translation Quality Metrics and Example Translations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S4" title="In Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Discussion and Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S5" title="In Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Acknowledgments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#A1" title="In Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Key Phrases Removed From GPT Output</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#A2" title="In Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Complete Translation Quality Measure and Timing Plots</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\addbibresource</span>
<p class="ltx_p" id="p1.2">main.bib







</p>
</div>
<h1 class="ltx_title ltx_title_document">Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Elijah Pelofske
</span><span class="ltx_author_notes">E-mail: elijah.pelofske@protonmail.com
<span class="ltx_contact ltx_role_affiliation">Sandia National Laboratories
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vincent Urias
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Sandia National Laboratories
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lorie M. Liebrock
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">New Mexico Cybersecurity Center of Excellence, New Mexico Tech
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id4.4">The task of accurate and efficient language translation is an extremely important information processing task. Machine learning enabled and automated translation that is accurate and fast is often a large topic of interest in the machine learning and data science communities. In this study, we examine using local Generative Pretrained Transformer (GPT) models to perform automated zero shot black-box, sentence wise, multi-natural-language translation into English text. We benchmark 16 different open-source GPT models, with no custom fine-tuning, from the Huggingface LLM repository for translating 50 different non-English languages into English using translated TED Talk transcripts as the reference dataset. These GPT model inference calls are performed strictly locally, on single A100 Nvidia GPUs. Benchmark metrics that are reported are language translation accuracy, using BLEU, GLEU, METEOR, and chrF text overlap measures, and wall-clock time for each sentence translation. The best overall performing GPT model for translating into English text for the BLEU metric is <span class="ltx_text ltx_font_typewriter" id="id4.4.1">ReMM-v2-L2-13B</span> with a mean score across all tested languages of <math alttext="0.152" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mn id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml">0.152</mn><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><cn id="id1.1.m1.1.1.cmml" type="float" xref="id1.1.m1.1.1">0.152</cn></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">0.152</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">0.152</annotation></semantics></math>, for the GLEU metric is <span class="ltx_text ltx_font_typewriter" id="id4.4.2">ReMM-v2-L2-13B</span> with a mean score across all tested languages of <math alttext="0.256" class="ltx_Math" display="inline" id="id2.2.m2.1"><semantics id="id2.2.m2.1a"><mn id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml">0.256</mn><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><cn id="id2.2.m2.1.1.cmml" type="float" xref="id2.2.m2.1.1">0.256</cn></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">0.256</annotation><annotation encoding="application/x-llamapun" id="id2.2.m2.1d">0.256</annotation></semantics></math>, for the chrF metric is <span class="ltx_text ltx_font_typewriter" id="id4.4.3">Llama2-chat-AYT-13B</span> with a mean score across all tested languages of <math alttext="0.448" class="ltx_Math" display="inline" id="id3.3.m3.1"><semantics id="id3.3.m3.1a"><mn id="id3.3.m3.1.1" xref="id3.3.m3.1.1.cmml">0.448</mn><annotation-xml encoding="MathML-Content" id="id3.3.m3.1b"><cn id="id3.3.m3.1.1.cmml" type="float" xref="id3.3.m3.1.1">0.448</cn></annotation-xml><annotation encoding="application/x-tex" id="id3.3.m3.1c">0.448</annotation><annotation encoding="application/x-llamapun" id="id3.3.m3.1d">0.448</annotation></semantics></math>, and for the METEOR metric is <span class="ltx_text ltx_font_typewriter" id="id4.4.4">ReMM-v2-L2-13B</span> with a mean score across all tested languages of <math alttext="0.438" class="ltx_Math" display="inline" id="id4.4.m4.1"><semantics id="id4.4.m4.1a"><mn id="id4.4.m4.1.1" xref="id4.4.m4.1.1.cmml">0.438</mn><annotation-xml encoding="MathML-Content" id="id4.4.m4.1b"><cn id="id4.4.m4.1.1.cmml" type="float" xref="id4.4.m4.1.1">0.438</cn></annotation-xml><annotation encoding="application/x-tex" id="id4.4.m4.1c">0.438</annotation><annotation encoding="application/x-llamapun" id="id4.4.m4.1d">0.438</annotation></semantics></math>.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large Language Models (LLMs), specifically transformer based architecture <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">vaswani2023attention</span>]</cite>, have been shown to be incredibly effective at learning tasks that require significant abstraction. Generative Pre-Trained Transformers (GPT) <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yenduri2023generative</span>]</cite> have been used to demonstrate numerous highly consequential learning and information processing tasks <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">openai2023gpt4</span>]</cite>, including code generation <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">narasimhan2021cgems</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhong2023chatgpt</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">olausson2023selfrepair</span>]</cite>, text summarization <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">goyal2023news</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2023abstractive</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">bajaj2021long</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">pu2023summarization</span>]</cite>, and chemistry experimental design <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">boiko2023autonomous</span>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">In this study, we examine the capabilities of GPT models for the task of translating natural language text in an automated black-box fashion. Multi-language translation using GPT models has been investigated before using OpenAI’s GPT models <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hendy2023good</span>]</cite>, and using deep learning <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">popel2020transforming</span>]</cite>. In this study, we evaluate 16 open source GPT models, run locally and offline in order to assess the effectiveness of black-box translation using current local GPT models. We consider the language translation task of going from <math alttext="50" class="ltx_Math" display="inline" id="S1.p2.1.m1.1"><semantics id="S1.p2.1.m1.1a"><mn id="S1.p2.1.m1.1.1" xref="S1.p2.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><cn id="S1.p2.1.m1.1.1.cmml" type="integer" xref="S1.p2.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">50</annotation><annotation encoding="application/x-llamapun" id="S1.p2.1.m1.1d">50</annotation></semantics></math> natural languages into English text, using the dataset of translated TED talk transcripts.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">This study is motivated by machine translation being of fundamental interest in computing and information sharing, and given the evident demonstrations of GPT model capabilities, it makes sense to evaluate how well current GPT models perform at this task. Many GPT chat models are available to users as cloud based resources. However, there are significant privacy and security concerns with this model of computation. Therefore, we are interested in using offline, entirely local, GPT inference calls. This also lets us quantify the scale of the computation required for a task such as automated multi-language machine translation - in this case we use single A100 GPU’s to perform the inference for each model. Lastly, we aim to evaluate the <em class="ltx_emph ltx_font_italic" id="S1.p3.1.1">automated</em> machine translation capabilities of the current GPT models - in particular we do not heavily optimize the inference hyperparameters, or the chat prompts. The goal is to measure a reasonably large and language agnostic (e.g., not prompt tuned for each language) benchmark of the translation capabilities of these models. The GPT translation quality is compared against the <span class="ltx_text ltx_font_typewriter" id="S1.p3.1.2">Google translate</span> API, in Python <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">python_google_translate</span>]</cite>.</p>
</div>
<figure class="ltx_table" id="S1.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S1.T1.3">
<tr class="ltx_tr" id="S1.T1.3.1">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt" id="S1.T1.3.1.1">Model name</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" id="S1.T1.3.1.2">Reference(s)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S1.T1.3.1.3">Context Length</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S1.T1.3.1.4">Architecture type</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S1.T1.3.1.5">Model Size</td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.2">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt ltx_border_t" id="S1.T1.3.2.1"><span class="ltx_text ltx_font_typewriter" id="S1.T1.3.2.1.1">zephyr-7b-alpha</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt ltx_border_t" id="S1.T1.3.2.2"> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">rafailov2023direct</span>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t" id="S1.T1.3.2.3">32768 Tokens</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t" id="S1.T1.3.2.4">mistral</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t" id="S1.T1.3.2.5">7.24B params</td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.3">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.3.3.1"><span class="ltx_text ltx_font_typewriter" id="S1.T1.3.3.1.1">zephyr-7b-beta</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.3.3.2"> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">rafailov2023direct</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tunstall2023zephyr</span>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.3.3">32768 Tokens</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.3.4">mistral</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.3.5">7.24B params</td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.4">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.3.4.1"><span class="ltx_text ltx_font_typewriter" id="S1.T1.3.4.1.1">Mistral-7B-Instruct-v0.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.3.4.2"> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">jiang2023mistral</span>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.4.3">32768 Tokens</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.4.4">mistral</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.4.5">7.24B params</td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.5">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.3.5.1"><span class="ltx_text ltx_font_typewriter" id="S1.T1.3.5.1.1">Turdus</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.3.5.2"> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">udk_dot_ai_turdus</span>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.5.3">32768 Tokens</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.5.4">mistral</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.5.5">7.24B params</td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.6">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.3.6.1"><span class="ltx_text ltx_font_typewriter" id="S1.T1.3.6.1.1">vicuna-7b-v1.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.3.6.2"> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zheng2023judging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">touvron2023llama</span>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.6.3">4096 Tokens</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.6.4">llama</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.6.5">7B params</td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.7">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.3.7.1"><span class="ltx_text ltx_font_typewriter" id="S1.T1.3.7.1.1">phi-2</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.3.7.2"> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">phi_2_huggingface</span>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.7.3">2048 Tokens</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.7.4">phi</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.7.5">2.78B params</td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.8">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.3.8.1"><span class="ltx_text ltx_font_typewriter" id="S1.T1.3.8.1.1">phi-1</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.3.8.2"> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gunasekar2023textbooks</span>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.8.3">2048 Tokens</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.8.4">phi</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.8.5">1.3B params</td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.9">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.3.9.1"><span class="ltx_text ltx_font_typewriter" id="S1.T1.3.9.1.1">phi-1_5</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.3.9.2"> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">textbooks2</span>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.9.3">2048 Tokens</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.9.4">phi</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.9.5">1.3B params</td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.10">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.3.10.1"><span class="ltx_text ltx_font_typewriter" id="S1.T1.3.10.1.1">ReMM-v2-L2-13B</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.3.10.2"> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ReMM-v2-L2-13B</span>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.10.3">4096 Tokens</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.10.4">llama</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.10.5">13B params</td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.11">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.3.11.1"><span class="ltx_text ltx_font_typewriter" id="S1.T1.3.11.1.1">wizardLM-7B-HF</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.3.11.2"> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2023wizardlm</span>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.11.3">2048 Tokens</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.11.4">llama</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.11.5">7B params</td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.12">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.3.12.1"><span class="ltx_text ltx_font_typewriter" id="S1.T1.3.12.1.1">wizardLM-13B-1.0-fp16</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.3.12.2"> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2023wizardlm</span>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.12.3">2048 Tokens</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.12.4">llama</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.12.5">13B params</td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.13">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.3.13.1"><span class="ltx_text ltx_font_typewriter" id="S1.T1.3.13.1.1">Llama-2-13b-chat-hf</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.3.13.2"> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">touvron2023llama</span>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.13.3">4096 Tokens</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.13.4">llama</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.13.5">13B params</td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.14">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.3.14.1"><span class="ltx_text ltx_font_typewriter" id="S1.T1.3.14.1.1">Llama2-chat-AYT-13B</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.3.14.2"> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mukherjee2023orca</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">touvron2023llama</span>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.14.3">4096 Tokens</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.14.4">llama</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.14.5">13B params</td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.15">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.3.15.1"><span class="ltx_text ltx_font_typewriter" id="S1.T1.3.15.1.1">TinyLlama-1.1B-Chat-v1.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.3.15.2"> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2024tinyllama</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lit-gpt</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">dao2023flashattention2</span>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.15.3">2048 Tokens</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.15.4">llama</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.15.5">1.1B params</td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.16">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.3.16.1"><span class="ltx_text ltx_font_typewriter" id="S1.T1.3.16.1.1">gpt4all-13b-snoozy</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.3.16.2"> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gpt4all</span>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.16.3">2048 Tokens</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.16.4">llama</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.16.5">13B params</td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.17">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.3.17.1"><span class="ltx_text ltx_font_typewriter" id="S1.T1.3.17.1.1">falcon-7b-instruct</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t" id="S1.T1.3.17.2"> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">refinedweb</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">falcon40b</span>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S1.T1.3.17.3">2048 Tokens</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S1.T1.3.17.4">falcon</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S1.T1.3.17.5">7B params</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Summary of the <math alttext="16" class="ltx_Math" display="inline" id="S1.T1.2.m1.1"><semantics id="S1.T1.2.m1.1b"><mn id="S1.T1.2.m1.1.1" xref="S1.T1.2.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S1.T1.2.m1.1c"><cn id="S1.T1.2.m1.1.1.cmml" type="integer" xref="S1.T1.2.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.2.m1.1d">16</annotation><annotation encoding="application/x-llamapun" id="S1.T1.2.m1.1e">16</annotation></semantics></math> Generative Pre-trained Transformers models used in this study</figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methods</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The GPT models used in this study are summarized in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S1.T1" title="Table 1 ‣ 1 Introduction ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">1</span></a> - the model weights were downloaded from huggingface <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wolf2020huggingfaces</span>]</cite>, where the trained model weights are open sourced. Each of these GPT models have been fine tuned, with varying levels of success, to be prompted in a chat-type mode. These models run using the PyTorch python library <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Paszke_PyTorch_An_Imperative_2019</span>]</cite>. The context window for the GPT models, summarized in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S1.T1" title="Table 1 ‣ 1 Introduction ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">1</span></a>, is not always clearly defined, but for several of the models the context window is given explicitly in the model weights repository. In other cases, the context window is in the metadata under the parameter <span class="ltx_text ltx_font_typewriter" id="S2.p1.1.1">max_position_embeddings</span>, <span class="ltx_text ltx_font_typewriter" id="S2.p1.1.2">n_embd</span>, or is not explicitly stated. No fine-tuning of the model weights is performed, all <math alttext="16" class="ltx_Math" display="inline" id="S2.p1.1.m1.1"><semantics id="S2.p1.1.m1.1a"><mn id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><cn id="S2.p1.1.m1.1.1.cmml" type="integer" xref="S2.p1.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">16</annotation><annotation encoding="application/x-llamapun" id="S2.p1.1.m1.1d">16</annotation></semantics></math> of these GPT models are evaluated as-is in this black-box benchmarking comparison for language translation. Importantly, the underlying architectures of all of these GPT models rely on a large number of remarkable machine learning developments in recent years, many of which are described in refs. <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">su2023roformer</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">dao2022flashattention</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">dao2023flashattention2</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">brown2020language</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">shazeer2019fast</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">openai2023gpt4</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">vaswani2023attention</span>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.11">The translation dataset is a set of Ted Talk transcripts aggregated by the study in ref. <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Ye2018WordEmbeddings</span>]</cite>. Specifically, for <math alttext="50" class="ltx_Math" display="inline" id="S2.p2.1.m1.1"><semantics id="S2.p2.1.m1.1a"><mn id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><cn id="S2.p2.1.m1.1.1.cmml" type="integer" xref="S2.p2.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">50</annotation><annotation encoding="application/x-llamapun" id="S2.p2.1.m1.1d">50</annotation></semantics></math> of the foreign languages in the transcript dataset, <math alttext="1,000" class="ltx_Math" display="inline" id="S2.p2.2.m2.2"><semantics id="S2.p2.2.m2.2a"><mrow id="S2.p2.2.m2.2.3.2" xref="S2.p2.2.m2.2.3.1.cmml"><mn id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">1</mn><mo id="S2.p2.2.m2.2.3.2.1" xref="S2.p2.2.m2.2.3.1.cmml">,</mo><mn id="S2.p2.2.m2.2.2" xref="S2.p2.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.2b"><list id="S2.p2.2.m2.2.3.1.cmml" xref="S2.p2.2.m2.2.3.2"><cn id="S2.p2.2.m2.1.1.cmml" type="integer" xref="S2.p2.2.m2.1.1">1</cn><cn id="S2.p2.2.m2.2.2.cmml" type="integer" xref="S2.p2.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.2c">1,000</annotation><annotation encoding="application/x-llamapun" id="S2.p2.2.m2.2d">1 , 000</annotation></semantics></math> of those sentences are translated into English. Due to the nature of the dataset, the same <math alttext="1,000" class="ltx_Math" display="inline" id="S2.p2.3.m3.2"><semantics id="S2.p2.3.m3.2a"><mrow id="S2.p2.3.m3.2.3.2" xref="S2.p2.3.m3.2.3.1.cmml"><mn id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml">1</mn><mo id="S2.p2.3.m3.2.3.2.1" xref="S2.p2.3.m3.2.3.1.cmml">,</mo><mn id="S2.p2.3.m3.2.2" xref="S2.p2.3.m3.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.2b"><list id="S2.p2.3.m3.2.3.1.cmml" xref="S2.p2.3.m3.2.3.2"><cn id="S2.p2.3.m3.1.1.cmml" type="integer" xref="S2.p2.3.m3.1.1">1</cn><cn id="S2.p2.3.m3.2.2.cmml" type="integer" xref="S2.p2.3.m3.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.2c">1,000</annotation><annotation encoding="application/x-llamapun" id="S2.p2.3.m3.2d">1 , 000</annotation></semantics></math> sentences are not necessarily translated across the <math alttext="50" class="ltx_Math" display="inline" id="S2.p2.4.m4.1"><semantics id="S2.p2.4.m4.1a"><mn id="S2.p2.4.m4.1.1" xref="S2.p2.4.m4.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S2.p2.4.m4.1b"><cn id="S2.p2.4.m4.1.1.cmml" type="integer" xref="S2.p2.4.m4.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.4.m4.1c">50</annotation><annotation encoding="application/x-llamapun" id="S2.p2.4.m4.1d">50</annotation></semantics></math> foreign languages (many of the transcript translations are incomplete). Then, those translated sentences are compared against the corresponding reference English sentence. This GPT translation is performed on a per-sentence basis because, as detailed in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S1.T1" title="Table 1 ‣ 1 Introduction ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">1</span></a>, each of these models have a maximum token context window that is relatively small compared to the size of a complete document (which could be comprised of tens or hundreds of thousands of tokens). Therefore, we apply the translations for each individual sentence primarily to mitigate the problems that arise if we attempt to generate text that has a longer token length than what the GPT model was designed to process. In order to assess the quality of the translations, four metrics are used; METEOR <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">banarjee2005</span>]</cite>, chrF (CHaRacter-level F-score) <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Popovic2015chrFCN</span>]</cite>, BLEU (Bilingual Evaluation Understudy) <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Papineni02bleu</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lin-och-2004-orange</span>]</cite>, GLEU (General Language Understanding Evaluation) <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mutton2007gleu</span>]</cite>. The METEOR, GLEU, BLEU, chrF and metrics are computed using NLTK <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bird2009natural</span>]</cite>, using all default hyper-parameters. The metrics are computed after the reference sentence and the translated sentence have been tokenized, all punctuation is removed, and all text is made lower case in order to strictly evaluate the words used for the translation. All four of these metrics are defined to be in between (or equal to) <math alttext="[0,1]" class="ltx_Math" display="inline" id="S2.p2.5.m5.2"><semantics id="S2.p2.5.m5.2a"><mrow id="S2.p2.5.m5.2.3.2" xref="S2.p2.5.m5.2.3.1.cmml"><mo id="S2.p2.5.m5.2.3.2.1" stretchy="false" xref="S2.p2.5.m5.2.3.1.cmml">[</mo><mn id="S2.p2.5.m5.1.1" xref="S2.p2.5.m5.1.1.cmml">0</mn><mo id="S2.p2.5.m5.2.3.2.2" xref="S2.p2.5.m5.2.3.1.cmml">,</mo><mn id="S2.p2.5.m5.2.2" xref="S2.p2.5.m5.2.2.cmml">1</mn><mo id="S2.p2.5.m5.2.3.2.3" stretchy="false" xref="S2.p2.5.m5.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.5.m5.2b"><interval closure="closed" id="S2.p2.5.m5.2.3.1.cmml" xref="S2.p2.5.m5.2.3.2"><cn id="S2.p2.5.m5.1.1.cmml" type="integer" xref="S2.p2.5.m5.1.1">0</cn><cn id="S2.p2.5.m5.2.2.cmml" type="integer" xref="S2.p2.5.m5.2.2">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.5.m5.2c">[0,1]</annotation><annotation encoding="application/x-llamapun" id="S2.p2.5.m5.2d">[ 0 , 1 ]</annotation></semantics></math>, where <math alttext="1" class="ltx_Math" display="inline" id="S2.p2.6.m6.1"><semantics id="S2.p2.6.m6.1a"><mn id="S2.p2.6.m6.1.1" xref="S2.p2.6.m6.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.p2.6.m6.1b"><cn id="S2.p2.6.m6.1.1.cmml" type="integer" xref="S2.p2.6.m6.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.6.m6.1c">1</annotation><annotation encoding="application/x-llamapun" id="S2.p2.6.m6.1d">1</annotation></semantics></math> indicates the translations completely agree and <math alttext="0" class="ltx_Math" display="inline" id="S2.p2.7.m7.1"><semantics id="S2.p2.7.m7.1a"><mn id="S2.p2.7.m7.1.1" xref="S2.p2.7.m7.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S2.p2.7.m7.1b"><cn id="S2.p2.7.m7.1.1.cmml" type="integer" xref="S2.p2.7.m7.1.1">0</cn></annotation-xml></semantics></math> indicates the translated document shares no overlap with the original reference document. Note that even high-quality human translations do not guarantee a score of <math alttext="1" class="ltx_Math" display="inline" id="S2.p2.8.m8.1"><semantics id="S2.p2.8.m8.1a"><mn id="S2.p2.8.m8.1.1" xref="S2.p2.8.m8.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.p2.8.m8.1b"><cn id="S2.p2.8.m8.1.1.cmml" type="integer" xref="S2.p2.8.m8.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.8.m8.1c">1</annotation><annotation encoding="application/x-llamapun" id="S2.p2.8.m8.1d">1</annotation></semantics></math> for all four metrics; generally, it is a difficult task to capture language translation quality <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2016googles</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">math11041006</span>]</cite>. Additionally, the multi-language dataset that is used in this study is a collection of TED Talk video transcripts, which themselves are not guaranteed to always be accurate. Therefore, when analyzing the translation quality metrics, we should not always expect to be able to reach scores of <math alttext="1" class="ltx_Math" display="inline" id="S2.p2.9.m9.1"><semantics id="S2.p2.9.m9.1a"><mn id="S2.p2.9.m9.1.1" xref="S2.p2.9.m9.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.p2.9.m9.1b"><cn id="S2.p2.9.m9.1.1.cmml" type="integer" xref="S2.p2.9.m9.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.9.m9.1c">1</annotation><annotation encoding="application/x-llamapun" id="S2.p2.9.m9.1d">1</annotation></semantics></math>, but rather we should be aiming to get closer to <math alttext="1" class="ltx_Math" display="inline" id="S2.p2.10.m10.1"><semantics id="S2.p2.10.m10.1a"><mn id="S2.p2.10.m10.1.1" xref="S2.p2.10.m10.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.p2.10.m10.1b"><cn id="S2.p2.10.m10.1.1.cmml" type="integer" xref="S2.p2.10.m10.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.10.m10.1c">1</annotation><annotation encoding="application/x-llamapun" id="S2.p2.10.m10.1d">1</annotation></semantics></math> than <math alttext="0" class="ltx_Math" display="inline" id="S2.p2.11.m11.1"><semantics id="S2.p2.11.m11.1a"><mn id="S2.p2.11.m11.1.1" xref="S2.p2.11.m11.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S2.p2.11.m11.1b"><cn id="S2.p2.11.m11.1.1.cmml" type="integer" xref="S2.p2.11.m11.1.1">0</cn></annotation-xml></semantics></math>.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Minimal GPT output postprocessing is applied in the form of removing language-agnostic key phrases from the beginning of the generated text, if it matches certain commonly used phrases that are not the actual content of the translation, such as <em class="ltx_emph ltx_font_italic" id="S2.p3.1.1">This translated text is</em>. The full list of removed phrases is given in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#A1" title="Appendix A Key Phrases Removed From GPT Output ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">For each sentence (regardless of the language of the text), the following text prompt is used in order to prompt the GPT model to translate the sentence into English text using a one-shot inference call.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p5">
<svg class="ltx_picture" height="56.46" id="S2.p5.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,56.46) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 50.56 C 0 53.82 2.64 56.46 5.91 56.46 L 594.09 56.46 C 597.36 56.46 600 53.82 600 50.56 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 50.56 C 1.97 52.73 3.73 54.49 5.91 54.49 L 594.09 54.49 C 596.27 54.49 598.03 52.73 598.03 50.56 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="28.9" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S2.p5.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="S2.p5.pic1.1.1.1.1.1.1">Translate the following sentence into clearly written English text. Respond only with the translated text; do not write explanations or justifications in your reply.</span>
<span class="ltx_p" id="S2.p5.pic1.1.1.1.1.1.2">Text to be translated</span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p" id="S2.p6.1">The text that we want translated is put where the phrase <span class="ltx_text ltx_font_typewriter" id="S2.p6.1.1">Text to be translated</span> is in the above prompt example. This prompt is not changed to instruct the GPT model on what the input language is – meaning that this automated translation method has the advantage of being entirely language agnostic, specifically meaning that language detection does not need to be applied so as to have the translation be performed correctly. Or more specifically, this is the prompting method that is applied to the GPT models with the aim of benchmarking how well they perform at the task of automated, and language agnostic, sentence-wise translation. All of the experimental results reported in this study use this fixed prompt so as to simplify the data analysis (and the total required compute time). This prompt was chosen based on minimal small experimentation with prompts that performed reasonably well - but better prompts could likely be found.</p>
</div>
<div class="ltx_para" id="S2.p7">
<p class="ltx_p" id="S2.p7.1">The GPT model inference is performed using the Python 3 module <em class="ltx_emph ltx_font_italic" id="S2.p7.1.1">transformers</em> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wolf2020huggingfaces</span>]</cite>, and each model inference call is performed on a single Nvidia A100 GPU <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">9361255</span>]</cite> with 82 Gigabytes of memory, with CUDA Version 12.4. The text generation calls are performed using the <span class="ltx_text ltx_font_typewriter" id="S2.p7.1.2">pipeline</span> method in <em class="ltx_emph ltx_font_italic" id="S2.p7.1.3">transformers</em> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wolf2020huggingfaces</span>]</cite> using all default parameters, except the inference temperature is set to <math alttext="0.01" class="ltx_Math" display="inline" id="S2.p7.1.m1.1"><semantics id="S2.p7.1.m1.1a"><mn id="S2.p7.1.m1.1.1" xref="S2.p7.1.m1.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="S2.p7.1.m1.1b"><cn id="S2.p7.1.m1.1.1.cmml" type="float" xref="S2.p7.1.m1.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p7.1.m1.1c">0.01</annotation><annotation encoding="application/x-llamapun" id="S2.p7.1.m1.1d">0.01</annotation></semantics></math> which results in nearly deterministic output where the chosen token at each step of the model is very likely to be the highest probability token. The timing of the inference calls is reported using wall-clock time to generate the translation of each sentence. Importantly, multiple inference calls were performed on several GPUs concurrently - although the computations were independent, the timing statistics that are reported may be slightly greater than what could be achieved on a completed isolated computing platform with no concurrent GPU computations.</p>
</div>
<div class="ltx_para" id="S2.p8">
<p class="ltx_p" id="S2.p8.1">Finally, the translation quality from the GPT models is compared against automated translation (performed by supplying only the target language of English) using <span class="ltx_text ltx_font_typewriter" id="S2.p8.1.1">Google translate</span>. This is performed using a python 3 library <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">python_google_translate</span>]</cite> that calls the <span class="ltx_text ltx_font_typewriter" id="S2.p8.1.2">Google translate</span> API. In cases where the output from the Google API is None, the “translated” text is set to an empty string (this happened for a couple of sentences, but was not very common).</p>
</div>
<figure class="ltx_figure" id="S2.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="S2.F1.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="S2.F1.7">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S2.F1.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S2.F1.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S2.F1.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S2.F1.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Spanish-to-English dataset per-sentence translation quality and timing statistics for each of the <math alttext="16" class="ltx_Math" display="inline" id="S2.F1.4.m1.1"><semantics id="S2.F1.4.m1.1b"><mn id="S2.F1.4.m1.1.1" xref="S2.F1.4.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S2.F1.4.m1.1c"><cn id="S2.F1.4.m1.1.1.cmml" type="integer" xref="S2.F1.4.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.4.m1.1d">16</annotation><annotation encoding="application/x-llamapun" id="S2.F1.4.m1.1e">16</annotation></semantics></math> GPT models. Timing is reported in the top sub-plot, on a log scale y-axis, using direct wall-clock compute time to produce the generated text per sentence. Datapoints which are smaller in the time plot mean that the GTP model output took less wall-clock time to generate. The bottom four sub-plots report the distribution of language quality metrics (one datapoint for each sentence), using the four different language quality measures. For all four of the language quality translation plots, scores closer to <math alttext="1" class="ltx_Math" display="inline" id="S2.F1.5.m2.1"><semantics id="S2.F1.5.m2.1b"><mn id="S2.F1.5.m2.1.1" xref="S2.F1.5.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.F1.5.m2.1c"><cn id="S2.F1.5.m2.1.1.cmml" type="integer" xref="S2.F1.5.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.5.m2.1d">1</annotation><annotation encoding="application/x-llamapun" id="S2.F1.5.m2.1e">1</annotation></semantics></math> indicate better translation quality, and scores near <math alttext="0" class="ltx_Math" display="inline" id="S2.F1.6.m3.1"><semantics id="S2.F1.6.m3.1b"><mn id="S2.F1.6.m3.1.1" xref="S2.F1.6.m3.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S2.F1.6.m3.1c"><cn id="S2.F1.6.m3.1.1.cmml" type="integer" xref="S2.F1.6.m3.1.1">0</cn></annotation-xml></semantics></math> indicate bad translation quality. All distributions are shown as box-plot representations, where the red dots indicate outlier points and the blue rectangles indicate the region between the first and third quartile’s, the orange line denotes the median. </figcaption>
</figure>
<figure class="ltx_figure" id="S2.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="S2.F2.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="S2.F2.7">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S2.F2.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S2.F2.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S2.F2.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S2.F2.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>French-to-English dataset per-sentence translation quality and timing statistics for each of the <math alttext="16" class="ltx_Math" display="inline" id="S2.F2.4.m1.1"><semantics id="S2.F2.4.m1.1b"><mn id="S2.F2.4.m1.1.1" xref="S2.F2.4.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S2.F2.4.m1.1c"><cn id="S2.F2.4.m1.1.1.cmml" type="integer" xref="S2.F2.4.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.4.m1.1d">16</annotation><annotation encoding="application/x-llamapun" id="S2.F2.4.m1.1e">16</annotation></semantics></math> GPT models. Timing is reported in the top sub-plot, on a log scale y-axis, using direct wall-clock compute time to produce the generated text per sentence. Datapoints which are smaller in the time plot mean that the GTP model output took less wall-clock time to generate. The bottom four sub-plots report the distribution of language quality metrics (one datapoint for each sentence), using the four different language quality measures. For all four of the language quality translation plots, scores closer to <math alttext="1" class="ltx_Math" display="inline" id="S2.F2.5.m2.1"><semantics id="S2.F2.5.m2.1b"><mn id="S2.F2.5.m2.1.1" xref="S2.F2.5.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.F2.5.m2.1c"><cn id="S2.F2.5.m2.1.1.cmml" type="integer" xref="S2.F2.5.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.5.m2.1d">1</annotation><annotation encoding="application/x-llamapun" id="S2.F2.5.m2.1e">1</annotation></semantics></math> indicate better translation quality, and scores near <math alttext="0" class="ltx_Math" display="inline" id="S2.F2.6.m3.1"><semantics id="S2.F2.6.m3.1b"><mn id="S2.F2.6.m3.1.1" xref="S2.F2.6.m3.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S2.F2.6.m3.1c"><cn id="S2.F2.6.m3.1.1.cmml" type="integer" xref="S2.F2.6.m3.1.1">0</cn></annotation-xml></semantics></math> indicate bad translation quality. All distributions are shown as box-plot representations, where the red dots indicate outlier points and the blue rectangles indicate the region between the first and third quartile’s, the orange line denotes the median. </figcaption>
</figure>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Results</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.3">Table <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S3.T2" title="Table 2 ‣ 3 Results ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">2</span></a> summarizes the best performing GPT models for translating <math alttext="50" class="ltx_Math" display="inline" id="S3.p1.1.m1.1"><semantics id="S3.p1.1.m1.1a"><mn id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><cn id="S3.p1.1.m1.1.1.cmml" type="integer" xref="S3.p1.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">50</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.1d">50</annotation></semantics></math> foreign languages, using the four different translation metrics. Table <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S3.T2" title="Table 2 ‣ 3 Results ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">2</span></a> reports the best mean translation quality per sentence which are given by the rounded value to <math alttext="3" class="ltx_Math" display="inline" id="S3.p1.2.m2.1"><semantics id="S3.p1.2.m2.1a"><mn id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><cn id="S3.p1.2.m2.1.1.cmml" type="integer" xref="S3.p1.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">3</annotation><annotation encoding="application/x-llamapun" id="S3.p1.2.m2.1d">3</annotation></semantics></math> decimal places. The final aggregate metric of the best performing GPT model across all languages, for each of the language quality metrics, is computed as the mean of the vector of all <math alttext="50" class="ltx_Math" display="inline" id="S3.p1.3.m3.1"><semantics id="S3.p1.3.m3.1a"><mn id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><cn id="S3.p1.3.m3.1.1.cmml" type="integer" xref="S3.p1.3.m3.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">50</annotation><annotation encoding="application/x-llamapun" id="S3.p1.3.m3.1d">50</annotation></semantics></math> language scores (this aggregate metric is not weighted by the different amounts of sentences that were translated in the language dataset).</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.2">Notably, of the <math alttext="16" class="ltx_Math" display="inline" id="S3.p2.1.m1.1"><semantics id="S3.p2.1.m1.1a"><mn id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><cn id="S3.p2.1.m1.1.1.cmml" type="integer" xref="S3.p2.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">16</annotation><annotation encoding="application/x-llamapun" id="S3.p2.1.m1.1d">16</annotation></semantics></math> GPT models, only a small subset of these was the best performing for any tuple of language and translation quality metric. Specifically, the models that had the best mean scores (for any combination of language and translation quality measure) were; <span class="ltx_text ltx_font_typewriter" id="S3.p2.2.1">ReMM-v2-L2-13B</span>, <span class="ltx_text ltx_font_typewriter" id="S3.p2.2.2">Turdus</span>, <span class="ltx_text ltx_font_typewriter" id="S3.p2.2.3">Llama2-chat-AYT-13B</span>, <span class="ltx_text ltx_font_typewriter" id="S3.p2.2.4">wizardLM-13B-1.0-fp16</span>, and <span class="ltx_text ltx_font_typewriter" id="S3.p2.2.5">zephyr-7b-alpha</span>. <span class="ltx_text ltx_font_typewriter" id="S3.p2.2.6">ReMM-v2-L2-13B</span> was the best performing model overall. Importantly, for each language, the translation scores shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S3.T2" title="Table 2 ‣ 3 Results ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">2</span></a> were computed on the exact same translated sentences, but the best performing GPT model was not always the same across the <math alttext="4" class="ltx_Math" display="inline" id="S3.p2.2.m2.1"><semantics id="S3.p2.2.m2.1a"><mn id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><cn id="S3.p2.2.m2.1.1.cmml" type="integer" xref="S3.p2.2.m2.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">4</annotation><annotation encoding="application/x-llamapun" id="S3.p2.2.m2.1d">4</annotation></semantics></math> translation quality metrics.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">On average, the best performing of the <math alttext="16" class="ltx_Math" display="inline" id="S3.p3.1.m1.1"><semantics id="S3.p3.1.m1.1a"><mn id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><cn id="S3.p3.1.m1.1.1.cmml" type="integer" xref="S3.p3.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">16</annotation><annotation encoding="application/x-llamapun" id="S3.p3.1.m1.1d">16</annotation></semantics></math> GPT models were not always able to generate good translations. The languages that the GPT models scored the lowest on were Mongolian, Burmese, Kazakh, Kurdish, Armenian, and Georgian.</p>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.1">Figures <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S2.F1" title="Figure 1 ‣ 2 Methods ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">1</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S2.F2" title="Figure 2 ‣ 2 Methods ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">2</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S3.F3" title="Figure 3 ‣ 3 Results ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S3.F4" title="Figure 4 ‣ 3 Results ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">4</span></a>, and <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S3.F5" title="Figure 5 ‣ 3 Results ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">5</span></a> shows detailed performance and wall-clock timing statistics for Spanish, French, Chinese, Arabic, and Hindi – which are the five most commonly spoken natural languages (besides English). These plots are representative of the expected language translation quality for the most commonly used languages. Figures <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S3.F6" title="Figure 6 ‣ 3 Results ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">6</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S3.F7" title="Figure 7 ‣ 3 Results ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">7</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S3.F8" title="Figure 8 ‣ 3 Results ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">8</span></a> show detailed per-GPT model performance for Mongolian, Kazakh, and Georgian, which were languages for which the GPT models were unable to produce good translations for, on average. The detailed per-GPT translation metrics and timing statistics for translating all of the other <math alttext="50" class="ltx_Math" display="inline" id="S3.p4.1.m1.1"><semantics id="S3.p4.1.m1.1a"><mn id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><cn id="S3.p4.1.m1.1.1.cmml" type="integer" xref="S3.p4.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">50</annotation><annotation encoding="application/x-llamapun" id="S3.p4.1.m1.1d">50</annotation></semantics></math> languages into English are enumerated in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#A2" title="Appendix B Complete Translation Quality Measure and Timing Plots ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
<div class="ltx_para" id="S3.p5">
<p class="ltx_p" id="S3.p5.1">There are a number of consistent trends seen in the translation quality box-plot figures - namely that the three <span class="ltx_text ltx_font_typewriter" id="S3.p5.1.1">phi</span> models generally have very low accuracy. <span class="ltx_text ltx_font_typewriter" id="S3.p5.1.2">Llama-2-13b-chat-hf</span>, notably, also consistently has very low translation accuracy, which is surprising because nearly all of the best performing models were fine-tuned from Llama-2 models. The mechanism that caused this low accuracy is not clear, but this behavior could be due to the particular prompt that was used and testing other prompts could improve the translation accuracy for future study.
In terms of translation speed, the slowest GPT models were <span class="ltx_text ltx_font_typewriter" id="S3.p5.1.3">phi-1</span>, <span class="ltx_text ltx_font_typewriter" id="S3.p5.1.4">phi-2</span>, <span class="ltx_text ltx_font_typewriter" id="S3.p5.1.5">phi-1_5</span>, <span class="ltx_text ltx_font_typewriter" id="S3.p5.1.6">zephyr-7b-beta</span>, and <span class="ltx_text ltx_font_typewriter" id="S3.p5.1.7">falcon-7b-instruct</span>.</p>
</div>
<div class="ltx_para" id="S3.p6">
<p class="ltx_p" id="S3.p6.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S3.T3" title="Table 3 ‣ 3 Results ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">3</span></a> shows the mean translation quality metrics, for the four language metrics, across all <math alttext="50" class="ltx_Math" display="inline" id="S3.p6.1.m1.1"><semantics id="S3.p6.1.m1.1a"><mn id="S3.p6.1.m1.1.1" xref="S3.p6.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S3.p6.1.m1.1b"><cn id="S3.p6.1.m1.1.1.cmml" type="integer" xref="S3.p6.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.1.m1.1c">50</annotation><annotation encoding="application/x-llamapun" id="S3.p6.1.m1.1d">50</annotation></semantics></math> languages being translated into English, using <span class="ltx_text ltx_font_typewriter" id="S3.p6.1.1">Google translate</span>. The same test sentences translated by the GPT models, for each language, were also translated using <span class="ltx_text ltx_font_typewriter" id="S3.p6.1.2">Google translate</span> - therefore the entries in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S3.T3" title="Table 3 ‣ 3 Results ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">3</span></a> should be compared against the best performing GPT models in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.14680v1#S3.T2" title="Table 2 ‣ 3 Results ‣ Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers"><span class="ltx_text ltx_ref_tag">2</span></a>. These results show the performance of <span class="ltx_text ltx_font_typewriter" id="S3.p6.1.3">Google translate</span>, using it as a reasonable performance benchmark for automated machine translation of languages. Interestingly, there were exactly two languages where, for at least one of the language metrics (although, in these cases it was for all four language quality metrics), the best performing GPT model had better mean sentence translation quality than google translate. These two languages were French and Chinese. For all other languages, either the best performing GPT model was definitively worse at translating, or was comparable to within a small margin. The languages for which the best performing GPT model and google translate performed marginally the same were German, Spanish, Italian, Russian, Korean, Serbian, Japanese, Ukrainian, Vietnamese, and Bosnian.</p>
</div>
<figure class="ltx_figure" id="S3.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="S3.F3.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="S3.F3.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F3.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F3.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F3.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F3.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Chinese-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="S3.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="S3.F4.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="S3.F4.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F4.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F4.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F4.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F4.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Arabic-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_table" id="S3.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T2.1" style="width:491.3pt;height:720.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-73.4pt,107.6pt) scale(0.77,0.77) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.1.1">
<tr class="ltx_tr" id="S3.T2.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_tt" id="S3.T2.1.1.1.1">Language</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.2">Best Mean GLEU</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.3">Best Mean BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.4">Best Mean chrF</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.5">Best Mean METEOR</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.2">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_tt" id="S3.T2.1.1.2.1">Arabic</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T2.1.1.2.2">ReMM-v2-L2-13B (0.271)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T2.1.1.2.3">ReMM-v2-L2-13B (0.157)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T2.1.1.2.4">Turdus (0.478)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T2.1.1.2.5">ReMM-v2-L2-13B (0.489)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.3">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.3.1">Azerbaijani</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.3.2">ReMM-v2-L2-13B (0.121)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.3.3">ReMM-v2-L2-13B (0.035)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.3.4">Turdus (0.316)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.3.5">Turdus (0.257)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.4">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.4.1">Belarusian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.4.2">ReMM-v2-L2-13B (0.2)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.4.3">ReMM-v2-L2-13B (0.093)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.4.4">Llama2-chat-AYT-13B (0.392)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.4.5">ReMM-v2-L2-13B (0.369)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.5">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.5.1">Bulgarian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.5.2">ReMM-v2-L2-13B (0.363)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.5.3">ReMM-v2-L2-13B (0.246)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.5.4">ReMM-v2-L2-13B (0.554)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.5.5">ReMM-v2-L2-13B (0.582)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.6">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.6.1">Bengali</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.6.2">ReMM-v2-L2-13B (0.121)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.6.3">ReMM-v2-L2-13B (0.028)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.6.4">Turdus (0.335)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.6.5">Turdus (0.282)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.7">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.7.1">Bosnian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.7.2">ReMM-v2-L2-13B (0.342)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.7.3">ReMM-v2-L2-13B (0.229)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.7.4">Llama2-chat-AYT-13B (0.546)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.7.5">ReMM-v2-L2-13B (0.559)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.8">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.8.1">Czech</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.8.2">ReMM-v2-L2-13B (0.326)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.8.3">ReMM-v2-L2-13B (0.207)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.8.4">Llama2-chat-AYT-13B (0.518)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.8.5">ReMM-v2-L2-13B (0.546)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.9">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.9.1">Danish</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.9.2">ReMM-v2-L2-13B (0.454)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.9.3">ReMM-v2-L2-13B (0.368)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.9.4">ReMM-v2-L2-13B (0.632)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.9.5">ReMM-v2-L2-13B (0.673)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.10">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.10.1">German</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.10.2">ReMM-v2-L2-13B (0.361)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.10.3">ReMM-v2-L2-13B (0.238)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.10.4">ReMM-v2-L2-13B (0.555)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.10.5">ReMM-v2-L2-13B (0.579)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.11">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.11.1">Greek</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.11.2">ReMM-v2-L2-13B (0.294)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.11.3">ReMM-v2-L2-13B (0.176)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.11.4">ReMM-v2-L2-13B (0.467)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.11.5">ReMM-v2-L2-13B (0.499)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.12">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.12.1">Spanish</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.12.2">ReMM-v2-L2-13B (0.443)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.12.3">ReMM-v2-L2-13B (0.331)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.12.4">ReMM-v2-L2-13B (0.624)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.12.5">ReMM-v2-L2-13B (0.658)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.13">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.13.1">Estonian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.13.2">ReMM-v2-L2-13B (0.134)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.13.3">Turdus (0.044)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.13.4">Turdus (0.349)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.13.5">Turdus (0.287)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.14">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.14.1">Persian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.14.2">ReMM-v2-L2-13B (0.226)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.14.3">ReMM-v2-L2-13B (0.112)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.14.4">Llama2-chat-AYT-13B (0.434)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.14.5">Llama2-chat-AYT-13B (0.428)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.15">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.15.1">Finnish</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.15.2">ReMM-v2-L2-13B (0.304)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.15.3">ReMM-v2-L2-13B (0.192)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.15.4">ReMM-v2-L2-13B (0.523)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.15.5">ReMM-v2-L2-13B (0.526)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.16">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.16.1">French</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.16.2">ReMM-v2-L2-13B (0.394)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.16.3">ReMM-v2-L2-13B (0.278)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.16.4">ReMM-v2-L2-13B (0.585)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.16.5">ReMM-v2-L2-13B (0.614)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.17">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.17.1">Galician</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.17.2">ReMM-v2-L2-13B (0.317)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.17.3">ReMM-v2-L2-13B (0.192)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.17.4">Llama2-chat-AYT-13B (0.53)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.17.5">Llama2-chat-AYT-13B (0.528)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.18">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.18.1">Hebrew</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.18.2">ReMM-v2-L2-13B (0.267)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.18.3">ReMM-v2-L2-13B (0.149)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.18.4">Turdus (0.463)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.18.5">ReMM-v2-L2-13B (0.477)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.19">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.19.1">Hindi</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.19.2">ReMM-v2-L2-13B (0.191)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.19.3">ReMM-v2-L2-13B (0.084)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.19.4">Llama2-chat-AYT-13B (0.396)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.19.5">ReMM-v2-L2-13B (0.379)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.20">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.20.1">Croatian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.20.2">ReMM-v2-L2-13B (0.345)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.20.3">ReMM-v2-L2-13B (0.237)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.20.4">ReMM-v2-L2-13B (0.541)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.20.5">ReMM-v2-L2-13B (0.561)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.21">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.21.1">Hungarian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.21.2">ReMM-v2-L2-13B (0.285)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.21.3">ReMM-v2-L2-13B (0.171)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.21.4">ReMM-v2-L2-13B (0.487)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.21.5">ReMM-v2-L2-13B (0.495)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.22">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.22.1">Armenian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.22.2">Turdus (0.096)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.22.3">Turdus (0.019)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.22.4">Turdus (0.294)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.22.5">Turdus (0.228)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.23">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.23.1">Indonesian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.23.2">ReMM-v2-L2-13B (0.29)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.23.3">ReMM-v2-L2-13B (0.166)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.23.4">Llama2-chat-AYT-13B (0.495)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.23.5">ReMM-v2-L2-13B (0.514)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.24">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.24.1">Italian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.24.2">ReMM-v2-L2-13B (0.375)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.24.3">ReMM-v2-L2-13B (0.262)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.24.4">ReMM-v2-L2-13B (0.561)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.24.5">ReMM-v2-L2-13B (0.59)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.25">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.25.1">Japanese</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.25.2">ReMM-v2-L2-13B (0.186)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.25.3">ReMM-v2-L2-13B (0.078)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.25.4">Llama2-chat-AYT-13B (0.403)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.25.5">Llama2-chat-AYT-13B (0.372)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.26">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.26.1">Georgian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.26.2">ReMM-v2-L2-13B (0.094)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.26.3">ReMM-v2-L2-13B (0.017)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.26.4">Turdus (0.292)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.26.5">Turdus (0.206)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.27">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.27.1">Kazakh</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.27.2">Turdus (0.053)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.27.3">Turdus (0.006)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.27.4">Turdus (0.237)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.27.5">Turdus (0.138)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.28">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.28.1">Korean</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.28.2">ReMM-v2-L2-13B (0.238)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.28.3">ReMM-v2-L2-13B (0.116)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.28.4">ReMM-v2-L2-13B (0.452)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.28.5">ReMM-v2-L2-13B (0.446)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.29">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.29.1">Kurdish</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.29.2">ReMM-v2-L2-13B (0.044)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.29.3">Turdus (0.002)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.29.4">Turdus (0.225)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.29.5">Llama2-chat-AYT-13B (0.12)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.30">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.30.1">Lithuanian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.30.2">Turdus (0.12)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.30.3">zephyr-7b-alpha (0.037)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.30.4">Turdus (0.328)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.30.5">Turdus (0.269)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.31">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.31.1">Macedonian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.31.2">ReMM-v2-L2-13B (0.276)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.31.3">ReMM-v2-L2-13B (0.152)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.31.4">Llama2-chat-AYT-13B (0.486)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.31.5">ReMM-v2-L2-13B (0.479)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.32">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.32.1">Mongolian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.32.2">ReMM-v2-L2-13B (0.038)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.32.3">wizardLM-13B-1.0-fp16 (0.002)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.32.4">Turdus (0.21)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.32.5">Turdus (0.095)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.33">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.33.1">Malay</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.33.2">ReMM-v2-L2-13B (0.271)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.33.3">ReMM-v2-L2-13B (0.157)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.33.4">ReMM-v2-L2-13B (0.472)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.33.5">ReMM-v2-L2-13B (0.486)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.34">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.34.1">Burmese</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.34.2">ReMM-v2-L2-13B (0.028)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.34.3">ReMM-v2-L2-13B (0.002)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.34.4">Turdus (0.228)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.34.5">Turdus (0.096)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.35">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.35.1">Norwegian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.35.2">ReMM-v2-L2-13B (0.413)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.35.3">ReMM-v2-L2-13B (0.299)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.35.4">ReMM-v2-L2-13B (0.597)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.35.5">ReMM-v2-L2-13B (0.629)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.36">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.36.1">Dutch</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.36.2">ReMM-v2-L2-13B (0.387)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.36.3">ReMM-v2-L2-13B (0.277)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.36.4">Llama2-chat-AYT-13B (0.561)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.36.5">ReMM-v2-L2-13B (0.59)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.37">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.37.1">Polish</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.37.2">ReMM-v2-L2-13B (0.292)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.37.3">ReMM-v2-L2-13B (0.177)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.37.4">Llama2-chat-AYT-13B (0.492)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.37.5">ReMM-v2-L2-13B (0.494)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.38">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.38.1">Portuguese</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.38.2">ReMM-v2-L2-13B (0.441)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.38.3">ReMM-v2-L2-13B (0.32)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.38.4">ReMM-v2-L2-13B (0.618)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.38.5">ReMM-v2-L2-13B (0.643)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.39">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.39.1">Romanian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.39.2">ReMM-v2-L2-13B (0.367)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.39.3">ReMM-v2-L2-13B (0.255)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.39.4">ReMM-v2-L2-13B (0.562)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.39.5">ReMM-v2-L2-13B (0.58)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.40">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.40.1">Russian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.40.2">ReMM-v2-L2-13B (0.305)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.40.3">ReMM-v2-L2-13B (0.182)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.40.4">ReMM-v2-L2-13B (0.501)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.40.5">ReMM-v2-L2-13B (0.516)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.41">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.41.1">Slovak</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.41.2">ReMM-v2-L2-13B (0.287)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.41.3">ReMM-v2-L2-13B (0.166)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.41.4">Llama2-chat-AYT-13B (0.493)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.41.5">ReMM-v2-L2-13B (0.506)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.42">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.42.1">Slovenian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.42.2">ReMM-v2-L2-13B (0.254)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.42.3">ReMM-v2-L2-13B (0.14)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.42.4">ReMM-v2-L2-13B (0.46)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.42.5">ReMM-v2-L2-13B (0.459)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.43">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.43.1">Albanian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.43.2">Turdus (0.122)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.43.3">Turdus (0.041)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.43.4">Turdus (0.329)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.43.5">Turdus (0.266)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.44">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.44.1">Serbian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.44.2">ReMM-v2-L2-13B (0.347)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.44.3">ReMM-v2-L2-13B (0.233)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.44.4">ReMM-v2-L2-13B (0.535)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.44.5">ReMM-v2-L2-13B (0.559)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.45">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.45.1">Swedish</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.45.2">ReMM-v2-L2-13B (0.408)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.45.3">ReMM-v2-L2-13B (0.294)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.45.4">ReMM-v2-L2-13B (0.583)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.45.5">ReMM-v2-L2-13B (0.619)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.46">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.46.1">Thai</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.46.2">ReMM-v2-L2-13B (0.151)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.46.3">ReMM-v2-L2-13B (0.051)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.46.4">Turdus (0.338)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.46.5">ReMM-v2-L2-13B (0.309)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.47">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.47.1">Turkish</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.47.2">ReMM-v2-L2-13B (0.236)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.47.3">ReMM-v2-L2-13B (0.118)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.47.4">Llama2-chat-AYT-13B (0.437)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.47.5">ReMM-v2-L2-13B (0.432)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.48">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.48.1">Ukrainian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.48.2">ReMM-v2-L2-13B (0.303)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.48.3">ReMM-v2-L2-13B (0.178)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.48.4">ReMM-v2-L2-13B (0.501)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.48.5">ReMM-v2-L2-13B (0.507)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.49">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.49.1">Urdu</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.49.2">ReMM-v2-L2-13B (0.197)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.49.3">ReMM-v2-L2-13B (0.085)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.49.4">Llama2-chat-AYT-13B (0.413)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.49.5">Llama2-chat-AYT-13B (0.385)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.50">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.50.1">Vietnamese</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.50.2">ReMM-v2-L2-13B (0.274)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.50.3">ReMM-v2-L2-13B (0.155)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.50.4">ReMM-v2-L2-13B (0.464)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.50.5">ReMM-v2-L2-13B (0.497)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.51">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T2.1.1.51.1">Chinese</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.51.2">ReMM-v2-L2-13B (0.186)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.51.3">ReMM-v2-L2-13B (0.068)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.51.4">Llama2-chat-AYT-13B (0.405)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.51.5">ReMM-v2-L2-13B (0.372)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.52">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_rr ltx_border_tt" id="S3.T2.1.1.52.1">All languages</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt" id="S3.T2.1.1.52.2">ReMM-v2-L2-13B (0.256)</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt" id="S3.T2.1.1.52.3">ReMM-v2-L2-13B (0.152)</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt" id="S3.T2.1.1.52.4">Llama2-chat-AYT-13B (0.448)</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt" id="S3.T2.1.1.52.5">ReMM-v2-L2-13B (0.438)</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Best GPT translation metrics for each language, computed by the best mean translation quality over all tested sentence</figcaption>
</figure>
<figure class="ltx_table" id="S3.T3">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T3.1">
<tr class="ltx_tr" id="S3.T3.1.1">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_tt" id="S3.T3.1.1.1">Language</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T3.1.1.2">Mean GLEU</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T3.1.1.3">Mean BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T3.1.1.4">Mean chrF</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T3.1.1.5">Mean METEOR</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.2">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_tt" id="S3.T3.1.2.1">Arabic</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T3.1.2.2">0.354</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T3.1.2.3">0.225</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T3.1.2.4">0.559</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T3.1.2.5">0.592</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.3">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.3.1">Azerbaijani</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.3.2">0.231</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.3.3">0.099</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.3.4">0.431</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.3.5">0.417</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.4">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.4.1">Belarusian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.4.2">0.289</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.4.3">0.169</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.4.4">0.484</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.4.5">0.486</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.5">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.5.1">Bulgarian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.5.2">0.396</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.5.3">0.273</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.5.4">0.584</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.5.5">0.619</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.6">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.6.1">Bengali</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.6.2">0.184</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.6.3">0.078</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.6.4">0.365</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.6.5">0.369</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.7">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.7.1">Bosnian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.7.2">0.381</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.7.3">0.26</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.7.4">0.58</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.7.5">0.611</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.8">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.8.1">Czech</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.8.2">0.372</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.8.3">0.238</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.8.4">0.559</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.8.5">0.607</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.9">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.9.1">Danish</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.9.2">0.527</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.9.3">0.438</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.9.4">0.689</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.9.5">0.744</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.10">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.10.1">German</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.10.2">0.367</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.10.3">0.235</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.10.4">0.557</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.10.5">0.588</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.11">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.11.1">Greek</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.11.2">0.379</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.11.3">0.25</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.11.4">0.559</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.11.5">0.602</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.12">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.12.1">Spanish</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.12.2">0.438</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.12.3">0.324</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.12.4">0.623</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.12.5">0.66</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.13">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.13.1">Estonian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.13.2">0.32</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.13.3">0.198</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.13.4">0.526</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.13.5">0.545</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.14">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.14.1">Persian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.14.2">0.301</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.14.3">0.188</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.14.4">0.494</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.14.5">0.52</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.15">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.15.1">Finnish</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.15.2">0.349</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.15.3">0.234</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.15.4">0.555</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.15.5">0.576</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.16">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.16.1">French</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.16.2">0.326</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.16.3">0.202</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.16.4">0.552</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.16.5">0.579</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.17">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.17.1">Galician</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.17.2">0.367</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.17.3">0.25</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.17.4">0.564</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.17.5">0.586</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.18">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.18.1">Hebrew</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.18.2">0.39</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.18.3">0.262</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.18.4">0.569</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.18.5">0.615</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.19">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.19.1">Hindi</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.19.2">0.234</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.19.3">0.113</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.19.4">0.437</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.19.5">0.445</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.20">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.20.1">Croatian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.20.2">0.413</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.20.3">0.282</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.20.4">0.599</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.20.5">0.637</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.21">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.21.1">Hungarian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.21.2">0.329</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.21.3">0.21</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.21.4">0.522</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.21.5">0.551</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.22">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.22.1">Armenian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.22.2">0.28</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.22.3">0.158</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.22.4">0.478</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.22.5">0.477</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.23">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.23.1">Indonesian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.23.2">0.327</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.23.3">0.2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.23.4">0.527</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.23.5">0.567</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.24">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.24.1">Italian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.24.2">0.372</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.24.3">0.255</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.24.4">0.568</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.24.5">0.601</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.25">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.25.1">Japanese</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.25.2">0.204</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.25.3">0.078</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.25.4">0.395</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.25.5">0.387</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.26">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.26.1">Georgian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.26.2">0.254</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.26.3">0.119</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.26.4">0.458</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.26.5">0.452</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.27">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.27.1">Kazakh</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.27.2">0.206</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.27.3">0.076</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.27.4">0.383</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.27.5">0.379</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.28">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.28.1">Korean</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.28.2">0.25</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.28.3">0.126</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.28.4">0.455</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.28.5">0.461</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.29">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.29.1">Kurdish</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.29.2">0.21</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.29.3">0.095</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.29.4">0.394</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.29.5">0.407</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.30">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.30.1">Lithuanian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.30.2">0.308</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.30.3">0.176</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.30.4">0.507</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.30.5">0.52</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.31">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.31.1">Macedonian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.31.2">0.369</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.31.3">0.245</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.31.4">0.571</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.31.5">0.597</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.32">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.32.1">Mongolian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.32.2">0.165</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.32.3">0.037</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.32.4">0.338</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.32.5">0.312</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.33">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.33.1">Malay</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.33.2">0.309</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.33.3">0.184</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.33.4">0.509</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.33.5">0.537</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.34">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.34.1">Burmese</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.34.2">0.078</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.34.3">0.012</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.34.4">0.195</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.34.5">0.152</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.35">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.35.1">Norwegian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.35.2">0.462</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.35.3">0.351</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.35.4">0.635</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.35.5">0.685</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.36">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.36.1">Dutch</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.36.2">0.409</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.36.3">0.292</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.36.4">0.589</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.36.5">0.621</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.37">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.37.1">Polish</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.37.2">0.313</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.37.3">0.187</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.37.4">0.507</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.37.5">0.521</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.38">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.38.1">Portuguese</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.38.2">0.459</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.38.3">0.335</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.38.4">0.64</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.38.5">0.672</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.39">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.39.1">Romanian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.39.2">0.389</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.39.3">0.268</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.39.4">0.581</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.39.5">0.612</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.40">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.40.1">Russian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.40.2">0.298</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.40.3">0.174</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.40.4">0.497</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.40.5">0.507</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.41">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.41.1">Slovak</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.41.2">0.361</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.41.3">0.229</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.41.4">0.561</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.41.5">0.594</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.42">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.42.1">Slovenian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.42.2">0.321</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.42.3">0.197</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.42.4">0.525</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.42.5">0.544</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.43">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.43.1">Albanian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.43.2">0.383</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.43.3">0.256</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.43.4">0.575</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.43.5">0.608</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.44">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.44.1">Serbian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.44.2">0.388</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.44.3">0.261</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.44.4">0.57</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.44.5">0.617</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.45">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.45.1">Swedish</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.45.2">0.446</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.45.3">0.329</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.45.4">0.618</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.45.5">0.666</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.46">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.46.1">Thai</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.46.2">0.189</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.46.3">0.067</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.46.4">0.36</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.46.5">0.361</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.47">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.47.1">Turkish</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.47.2">0.323</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.47.3">0.193</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.47.4">0.514</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.47.5">0.546</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.48">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.48.1">Ukrainian</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.48.2">0.305</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.48.3">0.17</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.48.4">0.502</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.48.5">0.513</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.49">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.49.1">Urdu</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.49.2">0.302</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.49.3">0.18</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.49.4">0.509</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.49.5">0.529</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.50">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.50.1">Vietnamese</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.50.2">0.292</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.50.3">0.173</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.50.4">0.483</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.50.5">0.526</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.51">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_rr ltx_border_t" id="S3.T3.1.51.1">Chinese</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T3.1.51.2">0.155</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T3.1.51.3">0.039</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T3.1.51.4">0.358</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T3.1.51.5">0.318</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Mean translation quality metrics from using the Google translate service, taken across all test sentences </figcaption>
</figure>
<figure class="ltx_figure" id="S3.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="S3.F5.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="S3.F5.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F5.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F5.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F5.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F5.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Hindi-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="S3.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="S3.F6.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="S3.F6.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F6.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F6.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F6.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F6.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Mongolian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="S3.F7">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="S3.F7.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="S3.F7.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F7.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F7.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F7.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F7.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Kazakh-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="S3.F8">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="S3.F8.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="S3.F8.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F8.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F8.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F8.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F8.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Georgian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Translation Quality Metrics and Example Translations</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.2">The following are some examples where the translations produced by the GPT models are reasonable, but the language quality scores are not very close to <math alttext="1" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mn id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><cn id="S3.SS1.p1.1.m1.1.1.cmml" type="integer" xref="S3.SS1.p1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">1</annotation></semantics></math>. These examples are shown with the aim of conveying that the overall translation quality for many of the GPT models is quite good even if the mean language quality scores are on average not incredibly close to <math alttext="1" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mn id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><cn id="S3.SS1.p1.2.m2.1.1.cmml" type="integer" xref="S3.SS1.p1.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">1</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">1</annotation></semantics></math>. Importantly, most of the reason for this is that the translation quality metrics are computed for individual sentences, not the entirety of the translated document - and this can lead to unstable measurements of translation quality. However, the mean of the sentence translation quality is a good representation of the overall translation quality – in particular the language quality metrics over the entire translated corpus are very similar (but not necessarily equal) to the mean of the translation metrics across all of the component sentences.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.4">This is an example sentence translation from Spanish into English from the TED talk dataset where the translated sentence has a GLEU score of <math alttext="0.435" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mn id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">0.435</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><cn id="S3.SS1.p2.1.m1.1.1.cmml" type="float" xref="S3.SS1.p2.1.m1.1.1">0.435</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">0.435</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">0.435</annotation></semantics></math>, a BLEU score of <math alttext="0.320" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mn id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">0.320</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><cn id="S3.SS1.p2.2.m2.1.1.cmml" type="float" xref="S3.SS1.p2.2.m2.1.1">0.320</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">0.320</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">0.320</annotation></semantics></math>, a chrF score of <math alttext="0.780" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><mn id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">0.780</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><cn id="S3.SS1.p2.3.m3.1.1.cmml" type="float" xref="S3.SS1.p2.3.m3.1.1">0.780</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">0.780</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">0.780</annotation></semantics></math>, and a METEOR score of <math alttext="0.864" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><mn id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">0.864</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><cn id="S3.SS1.p2.4.m4.1.1.cmml" type="float" xref="S3.SS1.p2.4.m4.1.1">0.864</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">0.864</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">0.864</annotation></semantics></math>. Note that both of these sentences have been tokenized before the score was computed and are shown in their tokenized form.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<svg class="ltx_picture" height="70.38" id="S3.SS1.p3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,70.38) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 64.47 C 0 67.73 2.64 70.38 5.91 70.38 L 594.09 70.38 C 597.36 70.38 600 67.73 600 64.47 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 64.47 C 1.97 66.65 3.73 68.41 5.91 68.41 L 594.09 68.41 C 596.27 68.41 598.03 66.65 598.03 64.47 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="42.82" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S3.SS1.p3.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="S3.SS1.p3.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.pic1.1.1.1.1.1.1.1">Reference English sentence:</span> this is a viking lander photograph of the surface of mars</span>
<span class="ltx_p" id="S3.SS1.p3.pic1.1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.pic1.1.1.1.1.1.2.1">GPT translated sentence from Spanish into English:</span> this is a photograph from the viking lander on the surface of mars</span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.4">This is another Spanish to English sentence translation where the translated sentence has a GLEU score of <math alttext="0.427" class="ltx_Math" display="inline" id="S3.SS1.p4.1.m1.1"><semantics id="S3.SS1.p4.1.m1.1a"><mn id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">0.427</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><cn id="S3.SS1.p4.1.m1.1.1.cmml" type="float" xref="S3.SS1.p4.1.m1.1.1">0.427</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">0.427</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.1.m1.1d">0.427</annotation></semantics></math>, a BLEU score of <math alttext="0.379" class="ltx_Math" display="inline" id="S3.SS1.p4.2.m2.1"><semantics id="S3.SS1.p4.2.m2.1a"><mn id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml">0.379</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><cn id="S3.SS1.p4.2.m2.1.1.cmml" type="float" xref="S3.SS1.p4.2.m2.1.1">0.379</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">0.379</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.2.m2.1d">0.379</annotation></semantics></math>, a chrF score of <math alttext="0.645" class="ltx_Math" display="inline" id="S3.SS1.p4.3.m3.1"><semantics id="S3.SS1.p4.3.m3.1a"><mn id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml">0.645</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><cn id="S3.SS1.p4.3.m3.1.1.cmml" type="float" xref="S3.SS1.p4.3.m3.1.1">0.645</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">0.645</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.3.m3.1d">0.645</annotation></semantics></math>, and a METEOR score of <math alttext="0.725" class="ltx_Math" display="inline" id="S3.SS1.p4.4.m4.1"><semantics id="S3.SS1.p4.4.m4.1a"><mn id="S3.SS1.p4.4.m4.1.1" xref="S3.SS1.p4.4.m4.1.1.cmml">0.725</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.1b"><cn id="S3.SS1.p4.4.m4.1.1.cmml" type="float" xref="S3.SS1.p4.4.m4.1.1">0.725</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.1c">0.725</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.4.m4.1d">0.725</annotation></semantics></math>:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p5">
<svg class="ltx_picture" height="89.67" id="S3.SS1.p5.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,89.67) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 83.77 C 0 87.03 2.64 89.67 5.91 89.67 L 594.09 89.67 C 597.36 89.67 600 87.03 600 83.77 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 83.77 C 1.97 85.94 3.73 87.7 5.91 87.7 L 594.09 87.7 C 596.27 87.7 598.03 85.94 598.03 83.77 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="62.11" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S3.SS1.p5.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="S3.SS1.p5.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1">Reference English sentence:</span> but there is intriguing evidence that suggests that the early history of mars there may have been rivers and fast flowing water</span>
<span class="ltx_p" id="S3.SS1.p5.pic1.1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.SS1.p5.pic1.1.1.1.1.1.2.1">GPT translated sentence from Spanish into English:</span> there is intriguing evidence suggesting that the early history of mars may have had rivers and streams of water</span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="S3.SS1.p6">
<p class="ltx_p" id="S3.SS1.p6.4">This is an example sentence translation from Spanish into English which had a GLEU score of <math alttext="0.481" class="ltx_Math" display="inline" id="S3.SS1.p6.1.m1.1"><semantics id="S3.SS1.p6.1.m1.1a"><mn id="S3.SS1.p6.1.m1.1.1" xref="S3.SS1.p6.1.m1.1.1.cmml">0.481</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.1.m1.1b"><cn id="S3.SS1.p6.1.m1.1.1.cmml" type="float" xref="S3.SS1.p6.1.m1.1.1">0.481</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.1.m1.1c">0.481</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p6.1.m1.1d">0.481</annotation></semantics></math>, a BLEU score of <math alttext="0.429" class="ltx_Math" display="inline" id="S3.SS1.p6.2.m2.1"><semantics id="S3.SS1.p6.2.m2.1a"><mn id="S3.SS1.p6.2.m2.1.1" xref="S3.SS1.p6.2.m2.1.1.cmml">0.429</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.2.m2.1b"><cn id="S3.SS1.p6.2.m2.1.1.cmml" type="float" xref="S3.SS1.p6.2.m2.1.1">0.429</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.2.m2.1c">0.429</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p6.2.m2.1d">0.429</annotation></semantics></math>, a chrf score of <math alttext="0.629" class="ltx_Math" display="inline" id="S3.SS1.p6.3.m3.1"><semantics id="S3.SS1.p6.3.m3.1a"><mn id="S3.SS1.p6.3.m3.1.1" xref="S3.SS1.p6.3.m3.1.1.cmml">0.629</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.3.m3.1b"><cn id="S3.SS1.p6.3.m3.1.1.cmml" type="float" xref="S3.SS1.p6.3.m3.1.1">0.629</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.3.m3.1c">0.629</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p6.3.m3.1d">0.629</annotation></semantics></math>, and a METEOR score of <math alttext="0.735" class="ltx_Math" display="inline" id="S3.SS1.p6.4.m4.1"><semantics id="S3.SS1.p6.4.m4.1a"><mn id="S3.SS1.p6.4.m4.1.1" xref="S3.SS1.p6.4.m4.1.1.cmml">0.735</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.4.m4.1b"><cn id="S3.SS1.p6.4.m4.1.1.cmml" type="float" xref="S3.SS1.p6.4.m4.1.1">0.735</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.4.m4.1c">0.735</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p6.4.m4.1d">0.735</annotation></semantics></math>:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p7">
<svg class="ltx_picture" height="73.07" id="S3.SS1.p7.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,73.07) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 67.16 C 0 70.42 2.64 73.07 5.91 73.07 L 594.09 73.07 C 597.36 73.07 600 70.42 600 67.16 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 67.16 C 1.97 69.34 3.73 71.1 5.91 71.1 L 594.09 71.1 C 596.27 71.1 598.03 69.34 598.03 67.16 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="45.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S3.SS1.p7.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="S3.SS1.p7.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p7.pic1.1.1.1.1.1.1.1">Reference English sentence:</span> the answer is no there is no liquid water on the surface of mars today</span>
<span class="ltx_p" id="S3.SS1.p7.pic1.1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.SS1.p7.pic1.1.1.1.1.1.2.1">GPT translated sentence from Spanish into English:</span> there is no water liquid on the surface of mars today</span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="S3.SS1.p8">
<p class="ltx_p" id="S3.SS1.p8.4">This is an example sentence translation from French into English which had a GLEU score of <math alttext="0.587" class="ltx_Math" display="inline" id="S3.SS1.p8.1.m1.1"><semantics id="S3.SS1.p8.1.m1.1a"><mn id="S3.SS1.p8.1.m1.1.1" xref="S3.SS1.p8.1.m1.1.1.cmml">0.587</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.1.m1.1b"><cn id="S3.SS1.p8.1.m1.1.1.cmml" type="float" xref="S3.SS1.p8.1.m1.1.1">0.587</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.1.m1.1c">0.587</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p8.1.m1.1d">0.587</annotation></semantics></math>, a BLEU score of <math alttext="0.556" class="ltx_Math" display="inline" id="S3.SS1.p8.2.m2.1"><semantics id="S3.SS1.p8.2.m2.1a"><mn id="S3.SS1.p8.2.m2.1.1" xref="S3.SS1.p8.2.m2.1.1.cmml">0.556</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.2.m2.1b"><cn id="S3.SS1.p8.2.m2.1.1.cmml" type="float" xref="S3.SS1.p8.2.m2.1.1">0.556</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.2.m2.1c">0.556</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p8.2.m2.1d">0.556</annotation></semantics></math>, a chrF score of <math alttext="0.718" class="ltx_Math" display="inline" id="S3.SS1.p8.3.m3.1"><semantics id="S3.SS1.p8.3.m3.1a"><mn id="S3.SS1.p8.3.m3.1.1" xref="S3.SS1.p8.3.m3.1.1.cmml">0.718</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.3.m3.1b"><cn id="S3.SS1.p8.3.m3.1.1.cmml" type="float" xref="S3.SS1.p8.3.m3.1.1">0.718</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.3.m3.1c">0.718</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p8.3.m3.1d">0.718</annotation></semantics></math>, and a METEOR score of <math alttext="0.825" class="ltx_Math" display="inline" id="S3.SS1.p8.4.m4.1"><semantics id="S3.SS1.p8.4.m4.1a"><mn id="S3.SS1.p8.4.m4.1.1" xref="S3.SS1.p8.4.m4.1.1.cmml">0.825</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.4.m4.1b"><cn id="S3.SS1.p8.4.m4.1.1.cmml" type="float" xref="S3.SS1.p8.4.m4.1.1">0.825</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.4.m4.1c">0.825</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p8.4.m4.1d">0.825</annotation></semantics></math>:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p9">
<svg class="ltx_picture" height="106.28" id="S3.SS1.p9.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,106.28) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 100.37 C 0 103.63 2.64 106.28 5.91 106.28 L 594.09 106.28 C 597.36 106.28 600 103.63 600 100.37 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 100.37 C 1.97 102.54 3.73 104.31 5.91 104.31 L 594.09 104.31 C 596.27 104.31 598.03 102.54 598.03 100.37 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="78.72" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S3.SS1.p9.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="S3.SS1.p9.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p9.pic1.1.1.1.1.1.1.1">Reference English sentence:</span> i want to talk to you about one of the biggest myths in medicine and that is the idea that all we need are more medical breakthroughs and then all of our problems will be solved</span>
<span class="ltx_p" id="S3.SS1.p9.pic1.1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.SS1.p9.pic1.1.1.1.1.1.2.1">GPT translated sentence from French into English:</span> i want to talk about one of the greatest myths of medicine and that is the idea that all we need are additional medical procedures and then all our problems will be solved</span>
</span></foreignobject></g></g></svg>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Discussion and Conclusion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.2">The translation quality provided by sentence-wise GPT translations showed a clear stratification of the capabilities of the evaluated <math alttext="16" class="ltx_Math" display="inline" id="S4.p1.1.m1.1"><semantics id="S4.p1.1.m1.1a"><mn id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><cn id="S4.p1.1.m1.1.1.cmml" type="integer" xref="S4.p1.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">16</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.m1.1d">16</annotation></semantics></math> GPT models. The best performing GPT models, across all <math alttext="50" class="ltx_Math" display="inline" id="S4.p1.2.m2.1"><semantics id="S4.p1.2.m2.1a"><mn id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><cn id="S4.p1.2.m2.1.1.cmml" type="integer" xref="S4.p1.2.m2.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">50</annotation><annotation encoding="application/x-llamapun" id="S4.p1.2.m2.1d">50</annotation></semantics></math> foreign languages, for translating into English is <span class="ltx_text ltx_font_typewriter" id="S4.p1.2.1">ReMM-v2-L2-13B</span> and <span class="ltx_text ltx_font_typewriter" id="S4.p1.2.2">Llama2-chat-AYT-13B</span>. This shows that language translation could serve as a clear, and very application-relevant, benchmark for GPT capabilities for processing natural language.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">The best performing GPT model translations compare very well against automated machine translation using the Google translate API, although typically Google translate has marginally better scores. Importantly, the GPT model computations offer the security advantage of performing the computations locally, meaning that locally run GPT model automated language translation may be a good alternative depending on the importance of the security and the privacy of handling the information.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">The GPT models do not uniformly perform well though – several of the tested models performed noticeably worse than other GPT models, and these trends are consistent across all of the <math alttext="50" class="ltx_Math" display="inline" id="S4.p3.1.m1.1"><semantics id="S4.p3.1.m1.1a"><mn id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><cn id="S4.p3.1.m1.1.1.cmml" type="integer" xref="S4.p3.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">50</annotation><annotation encoding="application/x-llamapun" id="S4.p3.1.m1.1d">50</annotation></semantics></math> tested languages. Interestingly, there were also some languages that were not able to be translated well by any of the GPT models, for example Mongolian, Kazakh, Burmese, Kurdish, Armenian, and Georgian. This could be due to these languages being relatively low-resource in the training data used when training these GPT models. Notably, there were several GPT models that were consistently the slowest across the different languages; <span class="ltx_text ltx_font_typewriter" id="S4.p3.1.1">phi-1</span>, <span class="ltx_text ltx_font_typewriter" id="S4.p3.1.2">phi-2</span>, <span class="ltx_text ltx_font_typewriter" id="S4.p3.1.3">phi-1_5</span>, <span class="ltx_text ltx_font_typewriter" id="S4.p3.1.4">zephyr-7b-beta</span>, and <span class="ltx_text ltx_font_typewriter" id="S4.p3.1.5">falcon-7b-instruct</span>.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Acknowledgments</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Sandia National Laboratories is a multi-mission laboratory managed and operated by National Technology &amp; Engineering Solutions of Sandia, LLC (NTESS), a wholly owned subsidiary of Honeywell International Inc., for the U.S. Department of Energy’s National Nuclear Security Administration (DOE/NNSA) under contract DE-NA0003525. This written work is authored by an employee of NTESS. The employee, not NTESS, owns the right, title and interest in and to the written work and is responsible for its contents. Any subjective views or opinions that might be expressed in the written work do not necessarily represent the views of the U.S. Government. The publisher acknowledges that the U.S. Government retains a non-exclusive, paid-up, irrevocable, world-wide license to publish or reproduce the published form of this written work or allow others to do so, for U.S. Government purposes. The DOE will provide public access to results of federally sponsored research in accordance with the DOE Public Access Plan.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para" id="S5.p2">
<span class="ltx_ERROR undefined" id="S5.p2.1">\printbibliography</span>
</div>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Key Phrases Removed From GPT Output</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">Any generated text that starts with any of the following strings has that text removed before the language quality metrics are computed. This list is not complete for the sake of space, but these serve as representative ancillary text that were commonly seen in the GPT model output.</p>
</div>
<div class="ltx_para" id="A1.p2">
<ul class="ltx_itemize" id="A1.I1">
<li class="ltx_item" id="A1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i1.p1">
<p class="ltx_p" id="A1.I1.i1.p1.1">Translated text:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i2.p1">
<p class="ltx_p" id="A1.I1.i2.p1.1">Translation:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i3.p1">
<p class="ltx_p" id="A1.I1.i3.p1.1">The translated text is:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i4.p1">
<p class="ltx_p" id="A1.I1.i4.p1.1">The sentence translates to:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i5.p1">
<p class="ltx_p" id="A1.I1.i5.p1.1">The translation is:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i6.p1">
<p class="ltx_p" id="A1.I1.i6.p1.1">The sentence should be translated to:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i7.p1">
<p class="ltx_p" id="A1.I1.i7.p1.1">The following sentence is translated into English text:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i8.p1">
<p class="ltx_p" id="A1.I1.i8.p1.1">Answer: The translation of the sentence is:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i9.p1">
<p class="ltx_p" id="A1.I1.i9.p1.1">This is the translated text:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i10" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i10.p1">
<p class="ltx_p" id="A1.I1.i10.p1.1">Clear English translation:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i11" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i11.p1">
<p class="ltx_p" id="A1.I1.i11.p1.1">You can translate this sentence into English as:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i12" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i12.p1">
<p class="ltx_p" id="A1.I1.i12.p1.1">This sentence translates to</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i13" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i13.p1">
<p class="ltx_p" id="A1.I1.i13.p1.1">Solution: The sentence is translated into clearly written English text as follows:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i14" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i14.p1">
<p class="ltx_p" id="A1.I1.i14.p1.1">The following sentence is translated into clearly written English text:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i15" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i15.p1">
<p class="ltx_p" id="A1.I1.i15.p1.1">This is a clear and accurate translation:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i16" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i16.p1">
<p class="ltx_p" id="A1.I1.i16.p1.1">The sentence has been translated into English as:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i17" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i17.p1">
<p class="ltx_p" id="A1.I1.i17.p1.1">The given sentence translates to:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i18" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i18.p1">
<p class="ltx_p" id="A1.I1.i18.p1.1">A clear English translation of the given sentence is:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i19" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i19.p1">
<p class="ltx_p" id="A1.I1.i19.p1.1">In English, this translates to:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i20" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i20.p1">
<p class="ltx_p" id="A1.I1.i20.p1.1">The following is the translated text:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i21" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i21.p1">
<p class="ltx_p" id="A1.I1.i21.p1.1">The correct translation is:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i22" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i22.p1">
<p class="ltx_p" id="A1.I1.i22.p1.1">This should be translated as:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i23" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i23.p1">
<p class="ltx_p" id="A1.I1.i23.p1.1">Here is the translation of the sentence:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i24" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i24.p1">
<p class="ltx_p" id="A1.I1.i24.p1.1">The text translates to:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i25" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i25.p1">
<p class="ltx_p" id="A1.I1.i25.p1.1">Here is my translation:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i26" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i26.p1">
<p class="ltx_p" id="A1.I1.i26.p1.1">You can translate the sentence as:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i27" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i27.p1">
<p class="ltx_p" id="A1.I1.i27.p1.1">The English translation of the given sentence is:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i28" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i28.p1">
<p class="ltx_p" id="A1.I1.i28.p1.1">This sentence can be translated as:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i29" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i29.p1">
<p class="ltx_p" id="A1.I1.i29.p1.1">This sentence can be translated into English as:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i30" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i30.p1">
<p class="ltx_p" id="A1.I1.i30.p1.1">The following is a clearly written English translation of the provided text:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i31" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i31.p1">
<p class="ltx_p" id="A1.I1.i31.p1.1">The following sentence is translated into English:</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i32" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i32.p1">
<p class="ltx_p" id="A1.I1.i32.p1.1">Translate the following sentence into clearly written English text. Respond only with the translated text; do not write explanations or justifications in your reply.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A1.p3">
<p class="ltx_p" id="A1.p3.1">Note that the last entry in the above list is actually just the input prompt; we found some of the GPT models would on occasion re-output the prompt before generating any further text, so this was included in the simple text removal post-processing.</p>
</div>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Complete Translation Quality Measure and Timing Plots</h2>
<figure class="ltx_figure" id="A2.F9">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F9.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F9.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F9.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F9.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F9.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F9.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Albanian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F10">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F10.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F10.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F10.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F10.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F10.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F10.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Armenian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F11">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F11.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F11.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F11.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F11.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F11.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F11.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Azerbaijani-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F12">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F12.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F12.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F12.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F12.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F12.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F12.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Belarusian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F13">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F13.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F13.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F13.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F13.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F13.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F13.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Bosnian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F14">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F14.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F14.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F14.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F14.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F14.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F14.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>Burmese-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F15">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F15.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F15.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F15.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F15.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F15.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F15.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 15: </span>Bengali-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F16">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F16.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F16.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F16.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F16.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F16.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F16.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 16: </span>Bulgarian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F17">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F17.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F17.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F17.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F17.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F17.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F17.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 17: </span>Croatian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F18">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F18.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F18.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F18.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F18.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F18.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F18.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 18: </span>Czech-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F19">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F19.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F19.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F19.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F19.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F19.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F19.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 19: </span>Dutch-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F20">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F20.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F20.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F20.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F20.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F20.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F20.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 20: </span>Danish-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F21">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F21.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F21.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F21.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F21.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F21.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F21.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 21: </span>Estonian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F22">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F22.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F22.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F22.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F22.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F22.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F22.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 22: </span>Finnish-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F23">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F23.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F23.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F23.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F23.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F23.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F23.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 23: </span>Galician-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F24">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F24.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F24.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F24.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F24.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F24.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F24.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 24: </span>Greek-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F25">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F25.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F25.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F25.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F25.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F25.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F25.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 25: </span>German-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F26">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F26.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F26.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F26.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F26.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F26.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F26.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 26: </span>Hebrew-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F27">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F27.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F27.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F27.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F27.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F27.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F27.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 27: </span>Hungarian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F28">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F28.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F28.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F28.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F28.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F28.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F28.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 28: </span>Indonesian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F29">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F29.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F29.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F29.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F29.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F29.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F29.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 29: </span>Italian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F30">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F30.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F30.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F30.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F30.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F30.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F30.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 30: </span>Japanese-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F31">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F31.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F31.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F31.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F31.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F31.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F31.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 31: </span>Korean-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F32">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F32.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F32.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F32.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F32.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F32.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F32.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 32: </span>Kurdish-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F33">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F33.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F33.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F33.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F33.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F33.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F33.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 33: </span>Lithuanian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F34">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F34.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F34.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F34.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F34.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F34.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F34.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 34: </span>Macedonian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F35">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F35.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F35.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F35.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F35.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F35.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F35.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 35: </span>Polish-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F36">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F36.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F36.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F36.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F36.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F36.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F36.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 36: </span>Swedish-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F37">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F37.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F37.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F37.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F37.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F37.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F37.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 37: </span>Turkish-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F38">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F38.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F38.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F38.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F38.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F38.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F38.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 38: </span>Norwegian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F39">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F39.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F39.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F39.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F39.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F39.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F39.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 39: </span>Ukranian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F40">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F40.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F40.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F40.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F40.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F40.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F40.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 40: </span>Malay-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F41">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F41.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F41.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F41.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F41.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F41.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F41.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 41: </span>Thai-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F42">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F42.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F42.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F42.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F42.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F42.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F42.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 42: </span>Portuguese-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F43">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F43.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F43.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F43.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F43.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F43.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F43.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 43: </span>Russian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F44">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F44.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F44.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F44.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F44.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F44.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F44.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 44: </span>Persian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F45">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F45.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F45.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F45.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F45.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F45.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F45.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 45: </span>Slovenian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F46">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F46.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F46.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F46.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F46.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F46.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F46.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 46: </span>Serbian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F47">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F47.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F47.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F47.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F47.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F47.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F47.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 47: </span>Urdu-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F48">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F48.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F48.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F48.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F48.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F48.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F48.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 48: </span>Slovak-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F49">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F49.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F49.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F49.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F49.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F49.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F49.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 49: </span>Romanian-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<figure class="ltx_figure" id="A2.F50">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_missing ltx_missing_image" id="A2.F50.g1" src=""/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="A2.F50.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F50.g2" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F50.g3" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F50.g4" src=""/><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F50.g5" src=""/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 50: </span>Vietnamese-to-English dataset per-sentence translation quality and timing statistics </figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Apr 30 21:43:53 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
