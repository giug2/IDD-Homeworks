<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>ARTAI: An Evaluation Platform to Assess Societal Risk of Recommender Algorithms</title>
<!--Generated on Thu Sep 19 01:23:12 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Recommender Algorithms,  Societal Risk Evaluation,  Simulation System" lang="en" name="keywords"/>
<base href="/html/2409.12396v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#S1" title="In ARTAI: An Evaluation Platform to Assess Societal Risk of Recommender Algorithms"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#S2" title="In ARTAI: An Evaluation Platform to Assess Societal Risk of Recommender Algorithms"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Evaluation Platform Design</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#S3" title="In ARTAI: An Evaluation Platform to Assess Societal Risk of Recommender Algorithms"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">ARTAI: An Evaluation Platform to Assess Societal Risk of Recommender Algorithms</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Qin Ruan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:qin.ruan@ucdconnect.ie">qin.ruan@ucdconnect.ie</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0001-5822-9260" title="ORCID identifier">0000-0001-5822-9260</a></span>
</span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jin Xu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:jin.xu@ucd.ie">jin.xu@ucd.ie</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-6644-8217" title="ORCID identifier">0000-0002-6644-8217</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_department" id="id1.1.id1">School of Computer Science and Insight SFI Research Centre for Data Analytics</span><span class="ltx_text ltx_affiliation_institution" id="id2.2.id2">University College Dublin</span><span class="ltx_text ltx_affiliation_city" id="id3.3.id3">Dublin</span><span class="ltx_text ltx_affiliation_country" id="id4.4.id4">Ireland</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ruihai Dong
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:ruihai.dong@ucd.ie">ruihai.dong@ucd.ie</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-2509-1370" title="ORCID identifier">0000-0002-2509-1370</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_department" id="id5.1.id1">School of Computer Science and Insight SFI Research Centre for Data Analytics</span><span class="ltx_text ltx_affiliation_institution" id="id6.2.id2">University College Dublin</span><span class="ltx_text ltx_affiliation_city" id="id7.3.id3">Dublin</span><span class="ltx_text ltx_affiliation_country" id="id8.4.id4">Ireland</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Arjumand Younus
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:arjumand.younus@ucd.ie">arjumand.younus@ucd.ie</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0001-7748-2050" title="ORCID identifier">0000-0001-7748-2050</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_department" id="id9.1.id1">School of Information and Communication</span><span class="ltx_text ltx_affiliation_institution" id="id10.2.id2">University College Dublin</span><span class="ltx_text ltx_affiliation_city" id="id11.3.id3">Dublin</span><span class="ltx_text ltx_affiliation_country" id="id12.4.id4">Ireland</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tai Tan Mai
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:tai.tanmai@dcu.ie">tai.tanmai@dcu.ie</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0001-6657-0872" title="ORCID identifier">0000-0001-6657-0872</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_department" id="id13.1.id1">School of Computing</span><span class="ltx_text ltx_affiliation_institution" id="id14.2.id2">Dublin City University</span><span class="ltx_text ltx_affiliation_city" id="id15.3.id3">Dublin</span><span class="ltx_text ltx_affiliation_country" id="id16.4.id4">Ireland</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Barry O’Sullivan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:b.osullivan@cs.ucc.ie">b.osullivan@cs.ucc.ie</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/" title="ORCID identifier"></a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_department" id="id17.1.id1">Insight SFI Research Centre for Data Analytics and School of Computer Science &amp; IT</span><span class="ltx_text ltx_affiliation_institution" id="id18.2.id2">University College Cork</span><span class="ltx_text ltx_affiliation_city" id="id19.3.id3">Cork</span><span class="ltx_text ltx_affiliation_country" id="id20.4.id4">Ireland</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Susan Leavy
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:susan.leavy@ucd.ie">susan.leavy@ucd.ie</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-3679-2279" title="ORCID identifier">0000-0002-3679-2279</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_department" id="id21.1.id1">Insight SFI Research Centre for Data Analytics</span><span class="ltx_text ltx_affiliation_institution" id="id22.2.id2">University College Dublin</span><span class="ltx_text ltx_affiliation_city" id="id23.3.id3">Dublin</span><span class="ltx_text ltx_affiliation_country" id="id24.4.id4">Ireland</span>
</span></span></span>
</div>
<div class="ltx_dates">(2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id25.id1">Societal risk emanating from how recommender algorithms disseminate content online is now well documented. Emergent regulation aims to mitigate this risk through ethical audits and enabling new research on the social impact of algorithms. However, there is currently a need for tools and methods that enable such evaluation. This paper presents ARTAI, an evaluation environment that enables large-scale assessments of recommender algorithms to identify harmful patterns in how content is distributed online and enables the implementation of new regulatory requirements for increased transparency in recommender systems.</p>
</div>
<div class="ltx_keywords">Recommender Algorithms, Societal Risk Evaluation, Simulation System
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>none</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>FAccTRec 2024: The 7th Workshop on Responsible Recommendation. In 18th ACM Conference on Recommender Systems; October 14–18, 2024; Bari, Italy</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Societal risks emanating from how content is disseminated by recommender algorithms in online platforms to increase engagement are now well documented <cite class="ltx_cite ltx_citemacro_citep">(Carroll et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#bib.bib5" title="">2022</a>; Milano et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#bib.bib10" title="">2020</a>; Baker et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#bib.bib4" title="">2024</a>)</cite>. The Digital Services Act (DSA)  <cite class="ltx_cite ltx_citemacro_citep">(eu2, <a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#bib.bib2" title="">2020</a>)</cite> currently being implemented across the European Union (EU) address these issues and mandates improved algorithmic transparency through third-party auditing. It also recognises the crucial role of research, granting access rights for independent researchers to evaluate the social impacts of digital platforms <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">GPAI24</span>)</cite>. Many countries are also introducing online safety legislation to ensure the protection of children using online platforms and mandating increased levels of transparency (e.g.<cite class="ltx_cite ltx_citemacro_citep">(Houses of the Oireachtas, <a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#bib.bib7" title="">2022</a>; Parliament of the United Kingdom, <a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#bib.bib13" title="">2023</a>)</cite>). To enable researchers and auditors to conduct risk assessments of recommender algorithms there is a need for the development of evaluation tools <cite class="ltx_cite ltx_citemacro_citep">(Mökander et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#bib.bib11" title="">2022</a>)</cite>. ARTAI (Assessing Risk for Trustworthy AI) is an evaluation platform to address this requirement to assess the social impact of recommender algorithms.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Current approaches to risk evaluation involve analysis of code, user surveys, data scraping, sock-puppet audits and crowd-sourcing. Code audits are increasingly infeasible given the use of deep learning and the dynamic nature of such systems in live environments. Approaches involving collecting data from users or setting up sample profiles in sock-puppet audits can have limitations in terms of scaling to very large samples <cite class="ltx_cite ltx_citemacro_citep">(Ada Lovelace Institute, <a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#bib.bib3" title="">2021</a>)</cite>. To overcome these limitations and provide scalable and comprehensive risk assessments this project developed a simulation environment. These environments allow researchers to systematically measure user engagement and assess the societal impact of recommender algorithms in a controlled setting. They can also address issues pertaining to user data in research through the generation of synthetic user data. Simulation frameworks such as Google’s RecSim <cite class="ltx_cite ltx_citemacro_citep">(Ie et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#bib.bib8" title="">2019</a>)</cite>, Alibaba’s Virtual-Taobao <cite class="ltx_cite ltx_citemacro_citep">(Shi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#bib.bib14" title="">2019</a>)</cite> and Microsoft’s MindSim <cite class="ltx_cite ltx_citemacro_citep">(Luo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#bib.bib9" title="">2022</a>)</cite> have been developed primarily for use by developers of recommendation algorithms to test and refine their systems. This project builds on this work developing a prototype simulation environment for auditors, researchers and industry to assess risk in recommender algorithms.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Evaluation Platform Design</h2>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="442" id="S2.F1.g1" src="x1.png" width="872"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>ARTAI Components</figcaption>
</figure>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">ARTAI is designed as a simulation platform for recommendation algorithms to impart transparency and enable large-scale evaluation of trends in what content is suggested to users online. The simulation environment is integrated within a user interface designed for platform regulators, third-party auditors and industry. It allows for sample profiles of users and different models of online interaction to be generated and interaction with the recommendation algorithm simulated. The output of the algorithms, the recommended content, is categorised and trends are compiled in an interpretable report which visualises what kind of content algorithms are recommended. This approach allows for the identification of both instances of harmful content and also potentially harmful content distribution trends. The overall aim is that societal risks, particularly risks to vulnerable groups may be identified before the negative consequences become evident in society, thus reflecting a core aim of the DSA which is to “foresee”, rather than witness societal risk.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">The platform comprises five main components: <span class="ltx_text ltx_font_italic" id="S2.p2.1.1">Pre-Processing and Analysis</span>, <span class="ltx_text ltx_font_italic" id="S2.p2.1.2">Content Classifiers</span>, <span class="ltx_text ltx_font_italic" id="S2.p2.1.3">Synthetic User Data Generation</span>, <span class="ltx_text ltx_font_italic" id="S2.p2.1.4">Simulation</span> and <span class="ltx_text ltx_font_italic" id="S2.p2.1.5">Risk Evaluation</span> (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#S2.F1" title="Figure 1 ‣ 2. Evaluation Platform Design ‣ ARTAI: An Evaluation Platform to Assess Societal Risk of Recommender Algorithms"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.p3.1.1">Pre-Processing and Analysis</span>: Given a large-scale dataset such as videos or text, along with profile and online behaviour data of users, this component provides a suite of tools to pre-process the data and uncover patterns and trends that can be used to generate data synthetically. For instance, user behaviour analysis tools track and analyse interactions across various dimensions such as engagement frequency and content preferences, to uncover behavioural trends. Content topic clustering solutions categorise and group content based on topics to reveal underlying structures within the data. These insights can then inform the generation of large-scale synthetic user data for simulations. In our work, we utilised a recently released large-scale dataset of short videos MicroLens <cite class="ltx_cite ltx_citemacro_citep">(Ni et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#bib.bib12" title="">2023</a>)</cite>. This dataset includes extensive user-item interaction data along with rich visual and textual information such as the original video content, comments and titles. These details enable a more fine-grained classification of the items and facilitate the learning of user preference distributions for data generation.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1"><span class="ltx_text ltx_font_bold" id="S2.p4.1.1">Content Classifiers</span>: This component includes a number of trained classifiers designed to identify various types of videos or text. The primary goal is to discern the kind of content being recommended, rather than merely identifying harmful content. The content classification tool developed by ARTAI incorporates advanced natural language processing (NLP) technologies to ensure that classification outcomes are both explainable and meaningful. This approach enhances the transparency and utility of the tool, enabling users to understand and trust the classification process. It also allows researchers studying the social impact of recommender algorithms to define and investigate new topics.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1"><span class="ltx_text ltx_font_bold" id="S2.p5.1.1">Synthetic User Data Generation</span>: This component involves example user groups that can be specified and synthetic data generated. Groups of users can be set up with different interest distributions. For instance, we may be interested in users who have the same interests but marginal differences in their browsing histories in relation to a particular topic. Setting up this interest distribution will allow for the simulation of recommender system outputs to capture the consequences of even marginal changes in online behaviour for user groups.</p>
</div>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p" id="S2.p6.1"><span class="ltx_text ltx_font_bold" id="S2.p6.1.1">Simulation</span>: The use of simulation is crucial for understanding how different recommendation strategies influence user behaviour and content dissemination over time. By creating a controlled environment, we can systematically analyse the impact of various factors and conditions on the outcomes of recommender systems. Multiple user choice models are represented in the platform <cite class="ltx_cite ltx_citemacro_citep">(Hazrati and Ricci, <a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#bib.bib6" title="">2022</a>)</cite> and this is used to simulate the interaction between users and recommendation algorithms. For example, in a position-based user choice model, users are most likely to select items recommended at the top of a personalised recommendation list. How actively a user interacts with recommender systems over time will also be included as part of the modelling.</p>
</div>
<div class="ltx_para" id="S2.p7">
<p class="ltx_p" id="S2.p7.1"><span class="ltx_text ltx_font_bold" id="S2.p7.1.1">Risk Evaluation</span>: The platform will develop reports based on collated patterns and trends of recommended content for synthetic user data, simulated interactions and the kind of personalised recommendations suggested to users over time. This component will highlight how certain user profiles and online behaviours give rise to different content recommendations. The content classifiers allow for the evaluation, not only of what conditions may lead to the recommendation of particular harmful content types, but also of the proportion of content categories that are recommended overall and how this changes over time.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Conclusion</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This paper presented ARTAI, a simulation environment for the evaluation of recommender algorithms for societal risk. The platform aims to address the lack of oversight into what kind of content is being recommended to different user groups, which is a particular issue concerning vulnerable groups such as children. ARTAI is designed primarily for use by auditors and vetted researchers to enable the implementation of the European Union DSA. While simulation environments have been used in industry (e.g. <cite class="ltx_cite ltx_citemacro_citep">(Ie et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#bib.bib8" title="">2019</a>; Shi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#bib.bib14" title="">2019</a>; Luo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12396v1#bib.bib9" title="">2022</a>)</cite>), they have been created with developers in mind and require advanced technical skill to implement and use. The ARTAI system is designed from the outset with the full range of stakeholders involved resulting in an accessible user interface. The goal of this project is to equip auditors with tools to conduct ethics evaluations and increase the scale at which researchers across disciplines can evaluate the social impact of online platforms.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
This publication has emanated from research conducted with the financial support of the EU Commission Recovery and Resilience Facility under the Science Foundation Ireland OurTech Challenge Grant Number 22/NCF/OT/11077 and with the financial support of Science Foundation Ireland 12/RC/2289_P2 at Insight the SFI Research Centre for Data Analytics at University College Dublin.

</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">eu2 (2020)</span>
<span class="ltx_bibblock">
2020.

</span>
<span class="ltx_bibblock">Proposal for a Regulation of the European Parliament and of the Council on a Single Market For Digital Services (Digital Services Act) 2000/31/EC.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=COM%3A2020%3A825%3AFIN" title="">https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=COM%3A2020%3A825%3AFIN</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ada Lovelace Institute (2021)</span>
<span class="ltx_bibblock">
Ada Lovelace Institute. 2021.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Technical Methods for Regulatory Inspection of Algorithmic Systems</em>.

</span>
<span class="ltx_bibblock">Technical Report. Ada Lovelace Institute, London, UK.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.adalovelaceinstitute.org/report/technical-methods-regulatory-inspection/" title="">https://www.adalovelaceinstitute.org/report/technical-methods-regulatory-inspection/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baker et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Catherine Baker, Debbie Ging, and Maja Brandt Andreasen. 2024.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">Recommending Toxicity: The role of algorithmic recommender functions on YouTube Shorts and TikTok in promoting male supremacist influencers</em>.

</span>
<span class="ltx_bibblock">Technical Report. Anti-Bullying Centre, Dublin City University.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carroll et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Micah D Carroll, Anca Dragan, Stuart Russell, and Dylan Hadfield-Menell. 2022.

</span>
<span class="ltx_bibblock">Estimating and penalizing induced preference shifts in recommender systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">International Conference on Machine Learning</em>. PMLR, 2686–2708.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hazrati and Ricci (2022)</span>
<span class="ltx_bibblock">
Naieme Hazrati and Francesco Ricci. 2022.

</span>
<span class="ltx_bibblock">Simulating users’ interactions with recommender systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Adjunct proceedings of the 30th acm conference on user modeling, adaptation and personalization</em>. 95–98.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Houses of the Oireachtas (2022)</span>
<span class="ltx_bibblock">
Houses of the Oireachtas. 2022.

</span>
<span class="ltx_bibblock">Online safety and media regulation Act 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.oireachtas.ie/en/bills/bill/2022/6" title="">https://www.oireachtas.ie/en/bills/bill/2022/6</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: 2024-8-7.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ie et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Eugene Ie, Chih-wei Hsu, Martin Mladenov, Vihan Jain, Sanmit Narvekar, Jing Wang, Rui Wu, and Craig Boutilier. 2019.

</span>
<span class="ltx_bibblock">Recsim: A configurable simulation platform for recommender systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">arXiv preprint arXiv:1909.04847</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Xufang Luo, Zheng Liu, Shitao Xiao, Xing Xie, and Dongsheng Li. 2022.

</span>
<span class="ltx_bibblock">Mindsim: user simulator for news recommenders. In <em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">Proceedings of the ACM Web Conference 2022</em>. 2067–2077.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Milano et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Silvia Milano, Mariarosaria Taddeo, and Luciano Floridi. 2020.

</span>
<span class="ltx_bibblock">Recommender systems and their ethical challenges.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">Ai &amp; Society</em> 35 (2020), 957–967.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mökander et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Jakob Mökander, Maria Axente, Federico Casolari, and Luciano Floridi. 2022.

</span>
<span class="ltx_bibblock">Conformity assessments and post-market monitoring: a guide to the role of auditing in the proposed European AI regulation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">Minds and Machines</em> 32, 2 (2022), 241–268.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ni et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yongxin Ni, Yu Cheng, Xiangyan Liu, Junchen Fu, Youhua Li, Xiangnan He, Yongfeng Zhang, and Fajie Yuan. 2023.

</span>
<span class="ltx_bibblock">A Content-Driven Micro-Video Recommendation Dataset at Scale.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">arXiv preprint arXiv:2309.15379</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parliament of the United Kingdom (2023)</span>
<span class="ltx_bibblock">
Parliament of the United Kingdom. 2023.

</span>
<span class="ltx_bibblock">Online Safety Act 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.legislation.gov.uk/ukpga/2023/50/pdfs/ukpga_20230050_en.pdf" title="">https://www.legislation.gov.uk/ukpga/2023/50/pdfs/ukpga_20230050_en.pdf</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: 2024-9-18.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Jing-Cheng Shi, Yang Yu, Qing Da, Shi-Yong Chen, and An-Xiang Zeng. 2019.

</span>
<span class="ltx_bibblock">Virtual-taobao: Virtualizing real-world online retail environment for reinforcement learning. In <em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, Vol. 33. 4902–4909.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Sep 19 01:23:12 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
