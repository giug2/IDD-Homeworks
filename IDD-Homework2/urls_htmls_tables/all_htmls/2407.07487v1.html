<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Review-LLM: Harnessing Large Language Models for Personalized Review Generation</title>
<!--Generated on Wed Jul 10 09:18:55 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2407.07487v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S1" title="In Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S2" title="In Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S2.SS1" title="In 2 Method ‣ Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Problem Formulation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S2.SS2" title="In 2 Method ‣ Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Review-LLM</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S3" title="In Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S3.SS1" title="In 3 Experiments ‣ Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Experimental Setting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S3.SS2" title="In 3 Experiments ‣ Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Baselines and Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S3.SS3" title="In 3 Experiments ‣ Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Overall Performance</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S3.SS4" title="In 3 Experiments ‣ Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Negative Review Performance</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S3.SS5" title="In 3 Experiments ‣ Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Human Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S3.SS6" title="In 3 Experiments ‣ Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.6 </span>Case Study</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S4" title="In Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S5" title="In Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Limitation</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Review-LLM: Harnessing Large Language Models 
<br class="ltx_break"/>for Personalized Review Generation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Qiyao Peng<sup class="ltx_sup" id="id1.1.id1">1</sup>, Hongtao Liu<sup class="ltx_sup" id="id2.2.id2">2</sup>,
Hongyan Xu<sup class="ltx_sup" id="id3.3.id3">3</sup>, Qing Yang<sup class="ltx_sup" id="id4.4.id4">2</sup>, Minglai Shao<sup class="ltx_sup" id="id5.5.id5">1</sup>,
Wenjun Wang<sup class="ltx_sup" id="id6.6.id6">3</sup>
<br class="ltx_break"/><sup class="ltx_sup" id="id7.7.id7">1</sup> School of New Media Communication, Tianjin University, China 
<br class="ltx_break"/><sup class="ltx_sup" id="id8.8.id8">2</sup> Du Xiaoman Financial, Beijing, China 
<br class="ltx_break"/><sup class="ltx_sup" id="id9.9.id9">3</sup> College of Intelligence and Computing, Tianjin University, China 
<br class="ltx_break"/><sup class="ltx_sup" id="id10.10.id10">1</sup><span class="ltx_text ltx_font_typewriter" id="id11.11.id11">{qypeng, shaoml}@tju.edu.cn</span>
<br class="ltx_break"/><sup class="ltx_sup" id="id12.12.id12">2</sup><span class="ltx_text ltx_font_typewriter" id="id13.13.id13">{liuhongtao01, yangqing}@duxiaoman.com</span>
<br class="ltx_break"/><sup class="ltx_sup" id="id14.14.id14">3</sup><span class="ltx_text ltx_font_typewriter" id="id15.15.id15">{hongyanxu, wjwang}@tju.edu.cn</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id16.id1">Product review generation is an important task in recommender systems, which could provide explanation and persuasiveness for the recommendation.
Recently, Large Language Models (LLMs, e.g., ChatGPT) have shown superior text modeling and generating ability, which could be applied in review generation.
However, directly applying the LLMs for generating reviews might be troubled by the “polite” phenomenon of the LLMs and could not generate personalized reviews (e.g., negative reviews).
In this paper, we propose Review-LLM that customizes LLMs for personalized review generation.
Firstly, we construct the prompt input by aggregating user historical behaviors, which include corresponding item titles and reviews.
This enables the LLMs to capture user interest features and review writing style.
Secondly, we incorporate ratings as indicators of satisfaction into the prompt, which could further improve the model’s understanding of user preferences and the sentiment tendency control of generated reviews.
Finally, we feed the prompt text into LLMs, and use Supervised Fine-Tuning (SFT) to make the model generate personalized reviews for the given user and target item.
Experimental results on the real-world dataset show that our fine-tuned model could achieve better review generation performance than existing close-source LLMs.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">Review-LLM: Harnessing Large Language Models 
<br class="ltx_break"/>for Personalized Review Generation</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_guessed_headers ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_thead">
<span class="ltx_tr" id="p1.1.2.1.1.1.1">
<span class="ltx_td ltx_align_center ltx_th ltx_th_column" id="p1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.1">
Qiyao Peng<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.1">1</sup>, Hongtao Liu<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.2">2</sup>,
Hongyan Xu<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.3">3</sup>, Qing Yang<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.4">2</sup>, Minglai Shao<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.5">1</sup>,
Wenjun Wang<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.6">3</sup></span></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.1.1.2.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.2.1.1"><sup class="ltx_sup" id="p1.1.2.1.1.2.1.1.1">1</sup> School of New Media Communication, Tianjin University, China</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.2.1"><sup class="ltx_sup" id="p1.1.2.1.1.3.2.1.1">2</sup> Du Xiaoman Financial, Beijing, China</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.4.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.4.3.1"><sup class="ltx_sup" id="p1.1.2.1.1.4.3.1.1">3</sup> College of Intelligence and Computing, Tianjin University, China</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.5.4">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.5.4.1"><sup class="ltx_sup" id="p1.1.2.1.1.5.4.1.1">1</sup><span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.5.4.1.2">{qypeng, shaoml}@tju.edu.cn</span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.6.5">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.6.5.1"><sup class="ltx_sup" id="p1.1.2.1.1.6.5.1.1">2</sup><span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.6.5.1.2">{liuhongtao01, yangqing}@duxiaoman.com</span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.7.6">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.7.6.1"><sup class="ltx_sup" id="p1.1.2.1.1.7.6.1.1">3</sup><span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.7.6.1.2">{hongyanxu, wjwang}@tju.edu.cn</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Online e-commerce platforms (e.g., Amazon.com) usually offer users opportunities to share reviews for items they have purchased <cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib16" title="">2020</a>)</cite>.
These reviews typically contain rich user preference information and detailed item attributes <cite class="ltx_cite ltx_citemacro_cite">McAuley and Leskovec (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib12" title="">2013</a>)</cite>, which can inform users about the item and improve recommendation accuracy.
However, many users only provide a rating for the item but no review after purchasing the item.
Therefore, review generation task has attracted more attentions <cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib10" title="">2018</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Most existing methods are based on the encoder-decoder neural network framework <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib7" title="">2019</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib6" title="">2020</a>); Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib5" title="">2020</a>)</cite>.
Earlier methods utilize discrete attribute information about users and items to generate reviews <cite class="ltx_cite ltx_citemacro_cite">Tang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib17" title="">2016</a>); Dong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib2" title="">2017</a>); Ni et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib13" title="">2017</a>); Zang and Wan (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib20" title="">2017</a>)</cite>.
For example, Tang et al. <cite class="ltx_cite ltx_citemacro_cite">Tang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib17" title="">2016</a>)</cite> utilize user/item IDs, and rating as input information, and use the RNN-based decoder for generating reviews.
Recent works consider using the text information to help generating reviews, such as item titles, and historical reviews of users/items, etc <cite class="ltx_cite ltx_citemacro_cite">Ni and McAuley (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib14" title="">2018</a>); Li and Tuzhilin (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib8" title="">2019</a>)</cite>.
Ni et al. <cite class="ltx_cite ltx_citemacro_cite">Ni and McAuley (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib14" title="">2018</a>)</cite> propose ExpansionNet,
which also integrates phrase information from item titles and review summaries into the encoder for generating reviews.
Li et al. <cite class="ltx_cite ltx_citemacro_cite">Li and Tuzhilin (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib8" title="">2019</a>)</cite> propose a RevGAN model to generate controllable and personalized reviews from item descriptions and sentiment labels.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Recently, owing to the strong reasoning and learning capabilities exhibited by Large Language Models (LLMs) <cite class="ltx_cite ltx_citemacro_cite">Achiam et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib1" title="">2023</a>); Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib18" title="">2023</a>)</cite>, many researchers are extending LLMs applications in other domains, such as Recommender Systems (RS) <cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib19" title="">2024</a>)</cite>.
Motivated by this, in this paper, we want to preliminary explore how to extend the LLMs (e.g., Llama-3) to the review generation.
Compared with other traditional generation tasks (such as poem generation), applying LLMs for the review generation in the e-commerce platforms is more challenging due to the lack of personalized information.
First, most existing large language models are usually pre-trained at the corpus-level and might not capture the review style and habits of the users.
This might cause the generated review to be inconsistent with user’s previous reviews.
Second, users are dissatisfied with many items and the corresponding reviews should be negative.
However, the generated text by the LLMs is usually “polite” <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib18" title="">2023</a>)</cite>, which might lead to the model generating positive reviews for the user’s dissatisfaction.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Hence, in this paper, we design a framework (Review-LLM) for harnessing the LLMs to generate personalized reviews.
Specifically, we re-construct the model input via aggregating the user behavior sequence, including the item titles and corresponding reviews.
In this way, the model could learn user interest features and review writing styles from semantically rich text information.
Furthermore, the user’s rating of the item can be used to indicate the user’s satisfaction with the item.
We integrate this information into the prompt input accordingly.
In this way, the large language model can better perceive whether users like different items, and may prevent the model from generating more “polite” reviews.
Finally, we feed the input prompt text into the LLMs (Llama-3), which is subsequently fine-tuned using Supervised Fine-Tuning (SFT) to output the review for target items.
For experiments, we design different difficulty levels review generation testing dataset to verify the effectiveness of different models.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Method</h2>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="312" id="S2.F1.g1" src="x1.png" width="796"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An example of input prompt for Review-LLM.</figcaption>
</figure>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Problem Formulation</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.18">Given the user <math alttext="u" class="ltx_Math" display="inline" id="S2.SS1.p1.1.m1.1"><semantics id="S2.SS1.p1.1.m1.1a"><mi id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">u</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.1.m1.1d">italic_u</annotation></semantics></math>, item <math alttext="v" class="ltx_Math" display="inline" id="S2.SS1.p1.2.m2.1"><semantics id="S2.SS1.p1.2.m2.1a"><mi id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">v</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.2.m2.1d">italic_v</annotation></semantics></math>, rating <math alttext="r" class="ltx_Math" display="inline" id="S2.SS1.p1.3.m3.1"><semantics id="S2.SS1.p1.3.m3.1a"><mi id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">r</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.3.m3.1d">italic_r</annotation></semantics></math>, and user’s historical interaction, review generation aims to automatically generate personalized reviews for the user <math alttext="u" class="ltx_Math" display="inline" id="S2.SS1.p1.4.m4.1"><semantics id="S2.SS1.p1.4.m4.1a"><mi id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><ci id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">u</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.4.m4.1d">italic_u</annotation></semantics></math> towards the target item <math alttext="v" class="ltx_Math" display="inline" id="S2.SS1.p1.5.m5.1"><semantics id="S2.SS1.p1.5.m5.1a"><mi id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><ci id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">v</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.5.m5.1d">italic_v</annotation></semantics></math>.
Especially, the user’s historical interaction is a sequence of items that the user purchased, which can be denoted as <math alttext="H^{u}=\{v_{1},v_{2},\cdots,v_{h}\}" class="ltx_Math" display="inline" id="S2.SS1.p1.6.m6.4"><semantics id="S2.SS1.p1.6.m6.4a"><mrow id="S2.SS1.p1.6.m6.4.4" xref="S2.SS1.p1.6.m6.4.4.cmml"><msup id="S2.SS1.p1.6.m6.4.4.5" xref="S2.SS1.p1.6.m6.4.4.5.cmml"><mi id="S2.SS1.p1.6.m6.4.4.5.2" xref="S2.SS1.p1.6.m6.4.4.5.2.cmml">H</mi><mi id="S2.SS1.p1.6.m6.4.4.5.3" xref="S2.SS1.p1.6.m6.4.4.5.3.cmml">u</mi></msup><mo id="S2.SS1.p1.6.m6.4.4.4" xref="S2.SS1.p1.6.m6.4.4.4.cmml">=</mo><mrow id="S2.SS1.p1.6.m6.4.4.3.3" xref="S2.SS1.p1.6.m6.4.4.3.4.cmml"><mo id="S2.SS1.p1.6.m6.4.4.3.3.4" stretchy="false" xref="S2.SS1.p1.6.m6.4.4.3.4.cmml">{</mo><msub id="S2.SS1.p1.6.m6.2.2.1.1.1" xref="S2.SS1.p1.6.m6.2.2.1.1.1.cmml"><mi id="S2.SS1.p1.6.m6.2.2.1.1.1.2" xref="S2.SS1.p1.6.m6.2.2.1.1.1.2.cmml">v</mi><mn id="S2.SS1.p1.6.m6.2.2.1.1.1.3" xref="S2.SS1.p1.6.m6.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p1.6.m6.4.4.3.3.5" xref="S2.SS1.p1.6.m6.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p1.6.m6.3.3.2.2.2" xref="S2.SS1.p1.6.m6.3.3.2.2.2.cmml"><mi id="S2.SS1.p1.6.m6.3.3.2.2.2.2" xref="S2.SS1.p1.6.m6.3.3.2.2.2.2.cmml">v</mi><mn id="S2.SS1.p1.6.m6.3.3.2.2.2.3" xref="S2.SS1.p1.6.m6.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.SS1.p1.6.m6.4.4.3.3.6" xref="S2.SS1.p1.6.m6.4.4.3.4.cmml">,</mo><mi id="S2.SS1.p1.6.m6.1.1" mathvariant="normal" xref="S2.SS1.p1.6.m6.1.1.cmml">⋯</mi><mo id="S2.SS1.p1.6.m6.4.4.3.3.7" xref="S2.SS1.p1.6.m6.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p1.6.m6.4.4.3.3.3" xref="S2.SS1.p1.6.m6.4.4.3.3.3.cmml"><mi id="S2.SS1.p1.6.m6.4.4.3.3.3.2" xref="S2.SS1.p1.6.m6.4.4.3.3.3.2.cmml">v</mi><mi id="S2.SS1.p1.6.m6.4.4.3.3.3.3" xref="S2.SS1.p1.6.m6.4.4.3.3.3.3.cmml">h</mi></msub><mo id="S2.SS1.p1.6.m6.4.4.3.3.8" stretchy="false" xref="S2.SS1.p1.6.m6.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.4b"><apply id="S2.SS1.p1.6.m6.4.4.cmml" xref="S2.SS1.p1.6.m6.4.4"><eq id="S2.SS1.p1.6.m6.4.4.4.cmml" xref="S2.SS1.p1.6.m6.4.4.4"></eq><apply id="S2.SS1.p1.6.m6.4.4.5.cmml" xref="S2.SS1.p1.6.m6.4.4.5"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m6.4.4.5.1.cmml" xref="S2.SS1.p1.6.m6.4.4.5">superscript</csymbol><ci id="S2.SS1.p1.6.m6.4.4.5.2.cmml" xref="S2.SS1.p1.6.m6.4.4.5.2">𝐻</ci><ci id="S2.SS1.p1.6.m6.4.4.5.3.cmml" xref="S2.SS1.p1.6.m6.4.4.5.3">𝑢</ci></apply><set id="S2.SS1.p1.6.m6.4.4.3.4.cmml" xref="S2.SS1.p1.6.m6.4.4.3.3"><apply id="S2.SS1.p1.6.m6.2.2.1.1.1.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m6.2.2.1.1.1.1.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.6.m6.2.2.1.1.1.2.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1.2">𝑣</ci><cn id="S2.SS1.p1.6.m6.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS1.p1.6.m6.2.2.1.1.1.3">1</cn></apply><apply id="S2.SS1.p1.6.m6.3.3.2.2.2.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m6.3.3.2.2.2.1.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2">subscript</csymbol><ci id="S2.SS1.p1.6.m6.3.3.2.2.2.2.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.2">𝑣</ci><cn id="S2.SS1.p1.6.m6.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS1.p1.6.m6.3.3.2.2.2.3">2</cn></apply><ci id="S2.SS1.p1.6.m6.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1">⋯</ci><apply id="S2.SS1.p1.6.m6.4.4.3.3.3.cmml" xref="S2.SS1.p1.6.m6.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m6.4.4.3.3.3.1.cmml" xref="S2.SS1.p1.6.m6.4.4.3.3.3">subscript</csymbol><ci id="S2.SS1.p1.6.m6.4.4.3.3.3.2.cmml" xref="S2.SS1.p1.6.m6.4.4.3.3.3.2">𝑣</ci><ci id="S2.SS1.p1.6.m6.4.4.3.3.3.3.cmml" xref="S2.SS1.p1.6.m6.4.4.3.3.3.3">ℎ</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.4c">H^{u}=\{v_{1},v_{2},\cdots,v_{h}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.6.m6.4d">italic_H start_POSTSUPERSCRIPT italic_u end_POSTSUPERSCRIPT = { italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ⋯ , italic_v start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT }</annotation></semantics></math>, where <math alttext="h" class="ltx_Math" display="inline" id="S2.SS1.p1.7.m7.1"><semantics id="S2.SS1.p1.7.m7.1a"><mi id="S2.SS1.p1.7.m7.1.1" xref="S2.SS1.p1.7.m7.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m7.1b"><ci id="S2.SS1.p1.7.m7.1.1.cmml" xref="S2.SS1.p1.7.m7.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m7.1c">h</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.7.m7.1d">italic_h</annotation></semantics></math> is the number of items.
And corresponding rating score sequence <math alttext="R^{u}=\{r_{1},r_{2},\cdots,r_{h}\}" class="ltx_Math" display="inline" id="S2.SS1.p1.8.m8.4"><semantics id="S2.SS1.p1.8.m8.4a"><mrow id="S2.SS1.p1.8.m8.4.4" xref="S2.SS1.p1.8.m8.4.4.cmml"><msup id="S2.SS1.p1.8.m8.4.4.5" xref="S2.SS1.p1.8.m8.4.4.5.cmml"><mi id="S2.SS1.p1.8.m8.4.4.5.2" xref="S2.SS1.p1.8.m8.4.4.5.2.cmml">R</mi><mi id="S2.SS1.p1.8.m8.4.4.5.3" xref="S2.SS1.p1.8.m8.4.4.5.3.cmml">u</mi></msup><mo id="S2.SS1.p1.8.m8.4.4.4" xref="S2.SS1.p1.8.m8.4.4.4.cmml">=</mo><mrow id="S2.SS1.p1.8.m8.4.4.3.3" xref="S2.SS1.p1.8.m8.4.4.3.4.cmml"><mo id="S2.SS1.p1.8.m8.4.4.3.3.4" stretchy="false" xref="S2.SS1.p1.8.m8.4.4.3.4.cmml">{</mo><msub id="S2.SS1.p1.8.m8.2.2.1.1.1" xref="S2.SS1.p1.8.m8.2.2.1.1.1.cmml"><mi id="S2.SS1.p1.8.m8.2.2.1.1.1.2" xref="S2.SS1.p1.8.m8.2.2.1.1.1.2.cmml">r</mi><mn id="S2.SS1.p1.8.m8.2.2.1.1.1.3" xref="S2.SS1.p1.8.m8.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p1.8.m8.4.4.3.3.5" xref="S2.SS1.p1.8.m8.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p1.8.m8.3.3.2.2.2" xref="S2.SS1.p1.8.m8.3.3.2.2.2.cmml"><mi id="S2.SS1.p1.8.m8.3.3.2.2.2.2" xref="S2.SS1.p1.8.m8.3.3.2.2.2.2.cmml">r</mi><mn id="S2.SS1.p1.8.m8.3.3.2.2.2.3" xref="S2.SS1.p1.8.m8.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.SS1.p1.8.m8.4.4.3.3.6" xref="S2.SS1.p1.8.m8.4.4.3.4.cmml">,</mo><mi id="S2.SS1.p1.8.m8.1.1" mathvariant="normal" xref="S2.SS1.p1.8.m8.1.1.cmml">⋯</mi><mo id="S2.SS1.p1.8.m8.4.4.3.3.7" xref="S2.SS1.p1.8.m8.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p1.8.m8.4.4.3.3.3" xref="S2.SS1.p1.8.m8.4.4.3.3.3.cmml"><mi id="S2.SS1.p1.8.m8.4.4.3.3.3.2" xref="S2.SS1.p1.8.m8.4.4.3.3.3.2.cmml">r</mi><mi id="S2.SS1.p1.8.m8.4.4.3.3.3.3" xref="S2.SS1.p1.8.m8.4.4.3.3.3.3.cmml">h</mi></msub><mo id="S2.SS1.p1.8.m8.4.4.3.3.8" stretchy="false" xref="S2.SS1.p1.8.m8.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.8.m8.4b"><apply id="S2.SS1.p1.8.m8.4.4.cmml" xref="S2.SS1.p1.8.m8.4.4"><eq id="S2.SS1.p1.8.m8.4.4.4.cmml" xref="S2.SS1.p1.8.m8.4.4.4"></eq><apply id="S2.SS1.p1.8.m8.4.4.5.cmml" xref="S2.SS1.p1.8.m8.4.4.5"><csymbol cd="ambiguous" id="S2.SS1.p1.8.m8.4.4.5.1.cmml" xref="S2.SS1.p1.8.m8.4.4.5">superscript</csymbol><ci id="S2.SS1.p1.8.m8.4.4.5.2.cmml" xref="S2.SS1.p1.8.m8.4.4.5.2">𝑅</ci><ci id="S2.SS1.p1.8.m8.4.4.5.3.cmml" xref="S2.SS1.p1.8.m8.4.4.5.3">𝑢</ci></apply><set id="S2.SS1.p1.8.m8.4.4.3.4.cmml" xref="S2.SS1.p1.8.m8.4.4.3.3"><apply id="S2.SS1.p1.8.m8.2.2.1.1.1.cmml" xref="S2.SS1.p1.8.m8.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.8.m8.2.2.1.1.1.1.cmml" xref="S2.SS1.p1.8.m8.2.2.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.8.m8.2.2.1.1.1.2.cmml" xref="S2.SS1.p1.8.m8.2.2.1.1.1.2">𝑟</ci><cn id="S2.SS1.p1.8.m8.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS1.p1.8.m8.2.2.1.1.1.3">1</cn></apply><apply id="S2.SS1.p1.8.m8.3.3.2.2.2.cmml" xref="S2.SS1.p1.8.m8.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.8.m8.3.3.2.2.2.1.cmml" xref="S2.SS1.p1.8.m8.3.3.2.2.2">subscript</csymbol><ci id="S2.SS1.p1.8.m8.3.3.2.2.2.2.cmml" xref="S2.SS1.p1.8.m8.3.3.2.2.2.2">𝑟</ci><cn id="S2.SS1.p1.8.m8.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS1.p1.8.m8.3.3.2.2.2.3">2</cn></apply><ci id="S2.SS1.p1.8.m8.1.1.cmml" xref="S2.SS1.p1.8.m8.1.1">⋯</ci><apply id="S2.SS1.p1.8.m8.4.4.3.3.3.cmml" xref="S2.SS1.p1.8.m8.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.p1.8.m8.4.4.3.3.3.1.cmml" xref="S2.SS1.p1.8.m8.4.4.3.3.3">subscript</csymbol><ci id="S2.SS1.p1.8.m8.4.4.3.3.3.2.cmml" xref="S2.SS1.p1.8.m8.4.4.3.3.3.2">𝑟</ci><ci id="S2.SS1.p1.8.m8.4.4.3.3.3.3.cmml" xref="S2.SS1.p1.8.m8.4.4.3.3.3.3">ℎ</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.8.m8.4c">R^{u}=\{r_{1},r_{2},\cdots,r_{h}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.8.m8.4d">italic_R start_POSTSUPERSCRIPT italic_u end_POSTSUPERSCRIPT = { italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ⋯ , italic_r start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT }</annotation></semantics></math>, where <math alttext="h" class="ltx_Math" display="inline" id="S2.SS1.p1.9.m9.1"><semantics id="S2.SS1.p1.9.m9.1a"><mi id="S2.SS1.p1.9.m9.1.1" xref="S2.SS1.p1.9.m9.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.9.m9.1b"><ci id="S2.SS1.p1.9.m9.1.1.cmml" xref="S2.SS1.p1.9.m9.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.9.m9.1c">h</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.9.m9.1d">italic_h</annotation></semantics></math> is the number of ratings.
The <math alttext="i" class="ltx_Math" display="inline" id="S2.SS1.p1.10.m10.1"><semantics id="S2.SS1.p1.10.m10.1a"><mi id="S2.SS1.p1.10.m10.1.1" xref="S2.SS1.p1.10.m10.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.10.m10.1b"><ci id="S2.SS1.p1.10.m10.1.1.cmml" xref="S2.SS1.p1.10.m10.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.10.m10.1c">i</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.10.m10.1d">italic_i</annotation></semantics></math>-th item title and corresponding review are denoted as: <math alttext="T^{u}_{i}=\{w_{1},w_{2},\cdots,w_{N}\}" class="ltx_Math" display="inline" id="S2.SS1.p1.11.m11.4"><semantics id="S2.SS1.p1.11.m11.4a"><mrow id="S2.SS1.p1.11.m11.4.4" xref="S2.SS1.p1.11.m11.4.4.cmml"><msubsup id="S2.SS1.p1.11.m11.4.4.5" xref="S2.SS1.p1.11.m11.4.4.5.cmml"><mi id="S2.SS1.p1.11.m11.4.4.5.2.2" xref="S2.SS1.p1.11.m11.4.4.5.2.2.cmml">T</mi><mi id="S2.SS1.p1.11.m11.4.4.5.3" xref="S2.SS1.p1.11.m11.4.4.5.3.cmml">i</mi><mi id="S2.SS1.p1.11.m11.4.4.5.2.3" xref="S2.SS1.p1.11.m11.4.4.5.2.3.cmml">u</mi></msubsup><mo id="S2.SS1.p1.11.m11.4.4.4" xref="S2.SS1.p1.11.m11.4.4.4.cmml">=</mo><mrow id="S2.SS1.p1.11.m11.4.4.3.3" xref="S2.SS1.p1.11.m11.4.4.3.4.cmml"><mo id="S2.SS1.p1.11.m11.4.4.3.3.4" stretchy="false" xref="S2.SS1.p1.11.m11.4.4.3.4.cmml">{</mo><msub id="S2.SS1.p1.11.m11.2.2.1.1.1" xref="S2.SS1.p1.11.m11.2.2.1.1.1.cmml"><mi id="S2.SS1.p1.11.m11.2.2.1.1.1.2" xref="S2.SS1.p1.11.m11.2.2.1.1.1.2.cmml">w</mi><mn id="S2.SS1.p1.11.m11.2.2.1.1.1.3" xref="S2.SS1.p1.11.m11.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p1.11.m11.4.4.3.3.5" xref="S2.SS1.p1.11.m11.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p1.11.m11.3.3.2.2.2" xref="S2.SS1.p1.11.m11.3.3.2.2.2.cmml"><mi id="S2.SS1.p1.11.m11.3.3.2.2.2.2" xref="S2.SS1.p1.11.m11.3.3.2.2.2.2.cmml">w</mi><mn id="S2.SS1.p1.11.m11.3.3.2.2.2.3" xref="S2.SS1.p1.11.m11.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.SS1.p1.11.m11.4.4.3.3.6" xref="S2.SS1.p1.11.m11.4.4.3.4.cmml">,</mo><mi id="S2.SS1.p1.11.m11.1.1" mathvariant="normal" xref="S2.SS1.p1.11.m11.1.1.cmml">⋯</mi><mo id="S2.SS1.p1.11.m11.4.4.3.3.7" xref="S2.SS1.p1.11.m11.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p1.11.m11.4.4.3.3.3" xref="S2.SS1.p1.11.m11.4.4.3.3.3.cmml"><mi id="S2.SS1.p1.11.m11.4.4.3.3.3.2" xref="S2.SS1.p1.11.m11.4.4.3.3.3.2.cmml">w</mi><mi id="S2.SS1.p1.11.m11.4.4.3.3.3.3" xref="S2.SS1.p1.11.m11.4.4.3.3.3.3.cmml">N</mi></msub><mo id="S2.SS1.p1.11.m11.4.4.3.3.8" stretchy="false" xref="S2.SS1.p1.11.m11.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.11.m11.4b"><apply id="S2.SS1.p1.11.m11.4.4.cmml" xref="S2.SS1.p1.11.m11.4.4"><eq id="S2.SS1.p1.11.m11.4.4.4.cmml" xref="S2.SS1.p1.11.m11.4.4.4"></eq><apply id="S2.SS1.p1.11.m11.4.4.5.cmml" xref="S2.SS1.p1.11.m11.4.4.5"><csymbol cd="ambiguous" id="S2.SS1.p1.11.m11.4.4.5.1.cmml" xref="S2.SS1.p1.11.m11.4.4.5">subscript</csymbol><apply id="S2.SS1.p1.11.m11.4.4.5.2.cmml" xref="S2.SS1.p1.11.m11.4.4.5"><csymbol cd="ambiguous" id="S2.SS1.p1.11.m11.4.4.5.2.1.cmml" xref="S2.SS1.p1.11.m11.4.4.5">superscript</csymbol><ci id="S2.SS1.p1.11.m11.4.4.5.2.2.cmml" xref="S2.SS1.p1.11.m11.4.4.5.2.2">𝑇</ci><ci id="S2.SS1.p1.11.m11.4.4.5.2.3.cmml" xref="S2.SS1.p1.11.m11.4.4.5.2.3">𝑢</ci></apply><ci id="S2.SS1.p1.11.m11.4.4.5.3.cmml" xref="S2.SS1.p1.11.m11.4.4.5.3">𝑖</ci></apply><set id="S2.SS1.p1.11.m11.4.4.3.4.cmml" xref="S2.SS1.p1.11.m11.4.4.3.3"><apply id="S2.SS1.p1.11.m11.2.2.1.1.1.cmml" xref="S2.SS1.p1.11.m11.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.11.m11.2.2.1.1.1.1.cmml" xref="S2.SS1.p1.11.m11.2.2.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.11.m11.2.2.1.1.1.2.cmml" xref="S2.SS1.p1.11.m11.2.2.1.1.1.2">𝑤</ci><cn id="S2.SS1.p1.11.m11.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS1.p1.11.m11.2.2.1.1.1.3">1</cn></apply><apply id="S2.SS1.p1.11.m11.3.3.2.2.2.cmml" xref="S2.SS1.p1.11.m11.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.11.m11.3.3.2.2.2.1.cmml" xref="S2.SS1.p1.11.m11.3.3.2.2.2">subscript</csymbol><ci id="S2.SS1.p1.11.m11.3.3.2.2.2.2.cmml" xref="S2.SS1.p1.11.m11.3.3.2.2.2.2">𝑤</ci><cn id="S2.SS1.p1.11.m11.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS1.p1.11.m11.3.3.2.2.2.3">2</cn></apply><ci id="S2.SS1.p1.11.m11.1.1.cmml" xref="S2.SS1.p1.11.m11.1.1">⋯</ci><apply id="S2.SS1.p1.11.m11.4.4.3.3.3.cmml" xref="S2.SS1.p1.11.m11.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.p1.11.m11.4.4.3.3.3.1.cmml" xref="S2.SS1.p1.11.m11.4.4.3.3.3">subscript</csymbol><ci id="S2.SS1.p1.11.m11.4.4.3.3.3.2.cmml" xref="S2.SS1.p1.11.m11.4.4.3.3.3.2">𝑤</ci><ci id="S2.SS1.p1.11.m11.4.4.3.3.3.3.cmml" xref="S2.SS1.p1.11.m11.4.4.3.3.3.3">𝑁</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.11.m11.4c">T^{u}_{i}=\{w_{1},w_{2},\cdots,w_{N}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.11.m11.4d">italic_T start_POSTSUPERSCRIPT italic_u end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = { italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_w start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ⋯ , italic_w start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT }</annotation></semantics></math> and <math alttext="E^{u}_{i}=\{w_{1},w_{2},\cdots,w_{M}\}" class="ltx_Math" display="inline" id="S2.SS1.p1.12.m12.4"><semantics id="S2.SS1.p1.12.m12.4a"><mrow id="S2.SS1.p1.12.m12.4.4" xref="S2.SS1.p1.12.m12.4.4.cmml"><msubsup id="S2.SS1.p1.12.m12.4.4.5" xref="S2.SS1.p1.12.m12.4.4.5.cmml"><mi id="S2.SS1.p1.12.m12.4.4.5.2.2" xref="S2.SS1.p1.12.m12.4.4.5.2.2.cmml">E</mi><mi id="S2.SS1.p1.12.m12.4.4.5.3" xref="S2.SS1.p1.12.m12.4.4.5.3.cmml">i</mi><mi id="S2.SS1.p1.12.m12.4.4.5.2.3" xref="S2.SS1.p1.12.m12.4.4.5.2.3.cmml">u</mi></msubsup><mo id="S2.SS1.p1.12.m12.4.4.4" xref="S2.SS1.p1.12.m12.4.4.4.cmml">=</mo><mrow id="S2.SS1.p1.12.m12.4.4.3.3" xref="S2.SS1.p1.12.m12.4.4.3.4.cmml"><mo id="S2.SS1.p1.12.m12.4.4.3.3.4" stretchy="false" xref="S2.SS1.p1.12.m12.4.4.3.4.cmml">{</mo><msub id="S2.SS1.p1.12.m12.2.2.1.1.1" xref="S2.SS1.p1.12.m12.2.2.1.1.1.cmml"><mi id="S2.SS1.p1.12.m12.2.2.1.1.1.2" xref="S2.SS1.p1.12.m12.2.2.1.1.1.2.cmml">w</mi><mn id="S2.SS1.p1.12.m12.2.2.1.1.1.3" xref="S2.SS1.p1.12.m12.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p1.12.m12.4.4.3.3.5" xref="S2.SS1.p1.12.m12.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p1.12.m12.3.3.2.2.2" xref="S2.SS1.p1.12.m12.3.3.2.2.2.cmml"><mi id="S2.SS1.p1.12.m12.3.3.2.2.2.2" xref="S2.SS1.p1.12.m12.3.3.2.2.2.2.cmml">w</mi><mn id="S2.SS1.p1.12.m12.3.3.2.2.2.3" xref="S2.SS1.p1.12.m12.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.SS1.p1.12.m12.4.4.3.3.6" xref="S2.SS1.p1.12.m12.4.4.3.4.cmml">,</mo><mi id="S2.SS1.p1.12.m12.1.1" mathvariant="normal" xref="S2.SS1.p1.12.m12.1.1.cmml">⋯</mi><mo id="S2.SS1.p1.12.m12.4.4.3.3.7" xref="S2.SS1.p1.12.m12.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p1.12.m12.4.4.3.3.3" xref="S2.SS1.p1.12.m12.4.4.3.3.3.cmml"><mi id="S2.SS1.p1.12.m12.4.4.3.3.3.2" xref="S2.SS1.p1.12.m12.4.4.3.3.3.2.cmml">w</mi><mi id="S2.SS1.p1.12.m12.4.4.3.3.3.3" xref="S2.SS1.p1.12.m12.4.4.3.3.3.3.cmml">M</mi></msub><mo id="S2.SS1.p1.12.m12.4.4.3.3.8" stretchy="false" xref="S2.SS1.p1.12.m12.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.12.m12.4b"><apply id="S2.SS1.p1.12.m12.4.4.cmml" xref="S2.SS1.p1.12.m12.4.4"><eq id="S2.SS1.p1.12.m12.4.4.4.cmml" xref="S2.SS1.p1.12.m12.4.4.4"></eq><apply id="S2.SS1.p1.12.m12.4.4.5.cmml" xref="S2.SS1.p1.12.m12.4.4.5"><csymbol cd="ambiguous" id="S2.SS1.p1.12.m12.4.4.5.1.cmml" xref="S2.SS1.p1.12.m12.4.4.5">subscript</csymbol><apply id="S2.SS1.p1.12.m12.4.4.5.2.cmml" xref="S2.SS1.p1.12.m12.4.4.5"><csymbol cd="ambiguous" id="S2.SS1.p1.12.m12.4.4.5.2.1.cmml" xref="S2.SS1.p1.12.m12.4.4.5">superscript</csymbol><ci id="S2.SS1.p1.12.m12.4.4.5.2.2.cmml" xref="S2.SS1.p1.12.m12.4.4.5.2.2">𝐸</ci><ci id="S2.SS1.p1.12.m12.4.4.5.2.3.cmml" xref="S2.SS1.p1.12.m12.4.4.5.2.3">𝑢</ci></apply><ci id="S2.SS1.p1.12.m12.4.4.5.3.cmml" xref="S2.SS1.p1.12.m12.4.4.5.3">𝑖</ci></apply><set id="S2.SS1.p1.12.m12.4.4.3.4.cmml" xref="S2.SS1.p1.12.m12.4.4.3.3"><apply id="S2.SS1.p1.12.m12.2.2.1.1.1.cmml" xref="S2.SS1.p1.12.m12.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.12.m12.2.2.1.1.1.1.cmml" xref="S2.SS1.p1.12.m12.2.2.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.12.m12.2.2.1.1.1.2.cmml" xref="S2.SS1.p1.12.m12.2.2.1.1.1.2">𝑤</ci><cn id="S2.SS1.p1.12.m12.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS1.p1.12.m12.2.2.1.1.1.3">1</cn></apply><apply id="S2.SS1.p1.12.m12.3.3.2.2.2.cmml" xref="S2.SS1.p1.12.m12.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.12.m12.3.3.2.2.2.1.cmml" xref="S2.SS1.p1.12.m12.3.3.2.2.2">subscript</csymbol><ci id="S2.SS1.p1.12.m12.3.3.2.2.2.2.cmml" xref="S2.SS1.p1.12.m12.3.3.2.2.2.2">𝑤</ci><cn id="S2.SS1.p1.12.m12.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS1.p1.12.m12.3.3.2.2.2.3">2</cn></apply><ci id="S2.SS1.p1.12.m12.1.1.cmml" xref="S2.SS1.p1.12.m12.1.1">⋯</ci><apply id="S2.SS1.p1.12.m12.4.4.3.3.3.cmml" xref="S2.SS1.p1.12.m12.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.p1.12.m12.4.4.3.3.3.1.cmml" xref="S2.SS1.p1.12.m12.4.4.3.3.3">subscript</csymbol><ci id="S2.SS1.p1.12.m12.4.4.3.3.3.2.cmml" xref="S2.SS1.p1.12.m12.4.4.3.3.3.2">𝑤</ci><ci id="S2.SS1.p1.12.m12.4.4.3.3.3.3.cmml" xref="S2.SS1.p1.12.m12.4.4.3.3.3.3">𝑀</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.12.m12.4c">E^{u}_{i}=\{w_{1},w_{2},\cdots,w_{M}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.12.m12.4d">italic_E start_POSTSUPERSCRIPT italic_u end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = { italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_w start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ⋯ , italic_w start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT }</annotation></semantics></math> respectively, where <math alttext="N" class="ltx_Math" display="inline" id="S2.SS1.p1.13.m13.1"><semantics id="S2.SS1.p1.13.m13.1a"><mi id="S2.SS1.p1.13.m13.1.1" xref="S2.SS1.p1.13.m13.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.13.m13.1b"><ci id="S2.SS1.p1.13.m13.1.1.cmml" xref="S2.SS1.p1.13.m13.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.13.m13.1c">N</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.13.m13.1d">italic_N</annotation></semantics></math> and <math alttext="M" class="ltx_Math" display="inline" id="S2.SS1.p1.14.m14.1"><semantics id="S2.SS1.p1.14.m14.1a"><mi id="S2.SS1.p1.14.m14.1.1" xref="S2.SS1.p1.14.m14.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.14.m14.1b"><ci id="S2.SS1.p1.14.m14.1.1.cmml" xref="S2.SS1.p1.14.m14.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.14.m14.1c">M</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.14.m14.1d">italic_M</annotation></semantics></math> are their lengths.
We denote the generated review as <math alttext="\hat{Y}=\{w_{1},w_{2},\cdots,w_{L}\}" class="ltx_Math" display="inline" id="S2.SS1.p1.15.m15.4"><semantics id="S2.SS1.p1.15.m15.4a"><mrow id="S2.SS1.p1.15.m15.4.4" xref="S2.SS1.p1.15.m15.4.4.cmml"><mover accent="true" id="S2.SS1.p1.15.m15.4.4.5" xref="S2.SS1.p1.15.m15.4.4.5.cmml"><mi id="S2.SS1.p1.15.m15.4.4.5.2" xref="S2.SS1.p1.15.m15.4.4.5.2.cmml">Y</mi><mo id="S2.SS1.p1.15.m15.4.4.5.1" xref="S2.SS1.p1.15.m15.4.4.5.1.cmml">^</mo></mover><mo id="S2.SS1.p1.15.m15.4.4.4" xref="S2.SS1.p1.15.m15.4.4.4.cmml">=</mo><mrow id="S2.SS1.p1.15.m15.4.4.3.3" xref="S2.SS1.p1.15.m15.4.4.3.4.cmml"><mo id="S2.SS1.p1.15.m15.4.4.3.3.4" stretchy="false" xref="S2.SS1.p1.15.m15.4.4.3.4.cmml">{</mo><msub id="S2.SS1.p1.15.m15.2.2.1.1.1" xref="S2.SS1.p1.15.m15.2.2.1.1.1.cmml"><mi id="S2.SS1.p1.15.m15.2.2.1.1.1.2" xref="S2.SS1.p1.15.m15.2.2.1.1.1.2.cmml">w</mi><mn id="S2.SS1.p1.15.m15.2.2.1.1.1.3" xref="S2.SS1.p1.15.m15.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p1.15.m15.4.4.3.3.5" xref="S2.SS1.p1.15.m15.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p1.15.m15.3.3.2.2.2" xref="S2.SS1.p1.15.m15.3.3.2.2.2.cmml"><mi id="S2.SS1.p1.15.m15.3.3.2.2.2.2" xref="S2.SS1.p1.15.m15.3.3.2.2.2.2.cmml">w</mi><mn id="S2.SS1.p1.15.m15.3.3.2.2.2.3" xref="S2.SS1.p1.15.m15.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.SS1.p1.15.m15.4.4.3.3.6" xref="S2.SS1.p1.15.m15.4.4.3.4.cmml">,</mo><mi id="S2.SS1.p1.15.m15.1.1" mathvariant="normal" xref="S2.SS1.p1.15.m15.1.1.cmml">⋯</mi><mo id="S2.SS1.p1.15.m15.4.4.3.3.7" xref="S2.SS1.p1.15.m15.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p1.15.m15.4.4.3.3.3" xref="S2.SS1.p1.15.m15.4.4.3.3.3.cmml"><mi id="S2.SS1.p1.15.m15.4.4.3.3.3.2" xref="S2.SS1.p1.15.m15.4.4.3.3.3.2.cmml">w</mi><mi id="S2.SS1.p1.15.m15.4.4.3.3.3.3" xref="S2.SS1.p1.15.m15.4.4.3.3.3.3.cmml">L</mi></msub><mo id="S2.SS1.p1.15.m15.4.4.3.3.8" stretchy="false" xref="S2.SS1.p1.15.m15.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.15.m15.4b"><apply id="S2.SS1.p1.15.m15.4.4.cmml" xref="S2.SS1.p1.15.m15.4.4"><eq id="S2.SS1.p1.15.m15.4.4.4.cmml" xref="S2.SS1.p1.15.m15.4.4.4"></eq><apply id="S2.SS1.p1.15.m15.4.4.5.cmml" xref="S2.SS1.p1.15.m15.4.4.5"><ci id="S2.SS1.p1.15.m15.4.4.5.1.cmml" xref="S2.SS1.p1.15.m15.4.4.5.1">^</ci><ci id="S2.SS1.p1.15.m15.4.4.5.2.cmml" xref="S2.SS1.p1.15.m15.4.4.5.2">𝑌</ci></apply><set id="S2.SS1.p1.15.m15.4.4.3.4.cmml" xref="S2.SS1.p1.15.m15.4.4.3.3"><apply id="S2.SS1.p1.15.m15.2.2.1.1.1.cmml" xref="S2.SS1.p1.15.m15.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.15.m15.2.2.1.1.1.1.cmml" xref="S2.SS1.p1.15.m15.2.2.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.15.m15.2.2.1.1.1.2.cmml" xref="S2.SS1.p1.15.m15.2.2.1.1.1.2">𝑤</ci><cn id="S2.SS1.p1.15.m15.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS1.p1.15.m15.2.2.1.1.1.3">1</cn></apply><apply id="S2.SS1.p1.15.m15.3.3.2.2.2.cmml" xref="S2.SS1.p1.15.m15.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.15.m15.3.3.2.2.2.1.cmml" xref="S2.SS1.p1.15.m15.3.3.2.2.2">subscript</csymbol><ci id="S2.SS1.p1.15.m15.3.3.2.2.2.2.cmml" xref="S2.SS1.p1.15.m15.3.3.2.2.2.2">𝑤</ci><cn id="S2.SS1.p1.15.m15.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS1.p1.15.m15.3.3.2.2.2.3">2</cn></apply><ci id="S2.SS1.p1.15.m15.1.1.cmml" xref="S2.SS1.p1.15.m15.1.1">⋯</ci><apply id="S2.SS1.p1.15.m15.4.4.3.3.3.cmml" xref="S2.SS1.p1.15.m15.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.p1.15.m15.4.4.3.3.3.1.cmml" xref="S2.SS1.p1.15.m15.4.4.3.3.3">subscript</csymbol><ci id="S2.SS1.p1.15.m15.4.4.3.3.3.2.cmml" xref="S2.SS1.p1.15.m15.4.4.3.3.3.2">𝑤</ci><ci id="S2.SS1.p1.15.m15.4.4.3.3.3.3.cmml" xref="S2.SS1.p1.15.m15.4.4.3.3.3.3">𝐿</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.15.m15.4c">\hat{Y}=\{w_{1},w_{2},\cdots,w_{L}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.15.m15.4d">over^ start_ARG italic_Y end_ARG = { italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_w start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ⋯ , italic_w start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT }</annotation></semantics></math> and <math alttext="L" class="ltx_Math" display="inline" id="S2.SS1.p1.16.m16.1"><semantics id="S2.SS1.p1.16.m16.1a"><mi id="S2.SS1.p1.16.m16.1.1" xref="S2.SS1.p1.16.m16.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.16.m16.1b"><ci id="S2.SS1.p1.16.m16.1.1.cmml" xref="S2.SS1.p1.16.m16.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.16.m16.1c">L</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.16.m16.1d">italic_L</annotation></semantics></math> is the length; the reference review is denoted as <math alttext="Y=\{w_{1},w_{2},\cdots,w_{L^{\prime}}\}" class="ltx_Math" display="inline" id="S2.SS1.p1.17.m17.4"><semantics id="S2.SS1.p1.17.m17.4a"><mrow id="S2.SS1.p1.17.m17.4.4" xref="S2.SS1.p1.17.m17.4.4.cmml"><mi id="S2.SS1.p1.17.m17.4.4.5" xref="S2.SS1.p1.17.m17.4.4.5.cmml">Y</mi><mo id="S2.SS1.p1.17.m17.4.4.4" xref="S2.SS1.p1.17.m17.4.4.4.cmml">=</mo><mrow id="S2.SS1.p1.17.m17.4.4.3.3" xref="S2.SS1.p1.17.m17.4.4.3.4.cmml"><mo id="S2.SS1.p1.17.m17.4.4.3.3.4" stretchy="false" xref="S2.SS1.p1.17.m17.4.4.3.4.cmml">{</mo><msub id="S2.SS1.p1.17.m17.2.2.1.1.1" xref="S2.SS1.p1.17.m17.2.2.1.1.1.cmml"><mi id="S2.SS1.p1.17.m17.2.2.1.1.1.2" xref="S2.SS1.p1.17.m17.2.2.1.1.1.2.cmml">w</mi><mn id="S2.SS1.p1.17.m17.2.2.1.1.1.3" xref="S2.SS1.p1.17.m17.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p1.17.m17.4.4.3.3.5" xref="S2.SS1.p1.17.m17.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p1.17.m17.3.3.2.2.2" xref="S2.SS1.p1.17.m17.3.3.2.2.2.cmml"><mi id="S2.SS1.p1.17.m17.3.3.2.2.2.2" xref="S2.SS1.p1.17.m17.3.3.2.2.2.2.cmml">w</mi><mn id="S2.SS1.p1.17.m17.3.3.2.2.2.3" xref="S2.SS1.p1.17.m17.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.SS1.p1.17.m17.4.4.3.3.6" xref="S2.SS1.p1.17.m17.4.4.3.4.cmml">,</mo><mi id="S2.SS1.p1.17.m17.1.1" mathvariant="normal" xref="S2.SS1.p1.17.m17.1.1.cmml">⋯</mi><mo id="S2.SS1.p1.17.m17.4.4.3.3.7" xref="S2.SS1.p1.17.m17.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p1.17.m17.4.4.3.3.3" xref="S2.SS1.p1.17.m17.4.4.3.3.3.cmml"><mi id="S2.SS1.p1.17.m17.4.4.3.3.3.2" xref="S2.SS1.p1.17.m17.4.4.3.3.3.2.cmml">w</mi><msup id="S2.SS1.p1.17.m17.4.4.3.3.3.3" xref="S2.SS1.p1.17.m17.4.4.3.3.3.3.cmml"><mi id="S2.SS1.p1.17.m17.4.4.3.3.3.3.2" xref="S2.SS1.p1.17.m17.4.4.3.3.3.3.2.cmml">L</mi><mo id="S2.SS1.p1.17.m17.4.4.3.3.3.3.3" xref="S2.SS1.p1.17.m17.4.4.3.3.3.3.3.cmml">′</mo></msup></msub><mo id="S2.SS1.p1.17.m17.4.4.3.3.8" stretchy="false" xref="S2.SS1.p1.17.m17.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.17.m17.4b"><apply id="S2.SS1.p1.17.m17.4.4.cmml" xref="S2.SS1.p1.17.m17.4.4"><eq id="S2.SS1.p1.17.m17.4.4.4.cmml" xref="S2.SS1.p1.17.m17.4.4.4"></eq><ci id="S2.SS1.p1.17.m17.4.4.5.cmml" xref="S2.SS1.p1.17.m17.4.4.5">𝑌</ci><set id="S2.SS1.p1.17.m17.4.4.3.4.cmml" xref="S2.SS1.p1.17.m17.4.4.3.3"><apply id="S2.SS1.p1.17.m17.2.2.1.1.1.cmml" xref="S2.SS1.p1.17.m17.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.17.m17.2.2.1.1.1.1.cmml" xref="S2.SS1.p1.17.m17.2.2.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.17.m17.2.2.1.1.1.2.cmml" xref="S2.SS1.p1.17.m17.2.2.1.1.1.2">𝑤</ci><cn id="S2.SS1.p1.17.m17.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS1.p1.17.m17.2.2.1.1.1.3">1</cn></apply><apply id="S2.SS1.p1.17.m17.3.3.2.2.2.cmml" xref="S2.SS1.p1.17.m17.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.17.m17.3.3.2.2.2.1.cmml" xref="S2.SS1.p1.17.m17.3.3.2.2.2">subscript</csymbol><ci id="S2.SS1.p1.17.m17.3.3.2.2.2.2.cmml" xref="S2.SS1.p1.17.m17.3.3.2.2.2.2">𝑤</ci><cn id="S2.SS1.p1.17.m17.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS1.p1.17.m17.3.3.2.2.2.3">2</cn></apply><ci id="S2.SS1.p1.17.m17.1.1.cmml" xref="S2.SS1.p1.17.m17.1.1">⋯</ci><apply id="S2.SS1.p1.17.m17.4.4.3.3.3.cmml" xref="S2.SS1.p1.17.m17.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.p1.17.m17.4.4.3.3.3.1.cmml" xref="S2.SS1.p1.17.m17.4.4.3.3.3">subscript</csymbol><ci id="S2.SS1.p1.17.m17.4.4.3.3.3.2.cmml" xref="S2.SS1.p1.17.m17.4.4.3.3.3.2">𝑤</ci><apply id="S2.SS1.p1.17.m17.4.4.3.3.3.3.cmml" xref="S2.SS1.p1.17.m17.4.4.3.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.p1.17.m17.4.4.3.3.3.3.1.cmml" xref="S2.SS1.p1.17.m17.4.4.3.3.3.3">superscript</csymbol><ci id="S2.SS1.p1.17.m17.4.4.3.3.3.3.2.cmml" xref="S2.SS1.p1.17.m17.4.4.3.3.3.3.2">𝐿</ci><ci id="S2.SS1.p1.17.m17.4.4.3.3.3.3.3.cmml" xref="S2.SS1.p1.17.m17.4.4.3.3.3.3.3">′</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.17.m17.4c">Y=\{w_{1},w_{2},\cdots,w_{L^{\prime}}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.17.m17.4d">italic_Y = { italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_w start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ⋯ , italic_w start_POSTSUBSCRIPT italic_L start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT }</annotation></semantics></math> and <math alttext="L^{\prime}" class="ltx_Math" display="inline" id="S2.SS1.p1.18.m18.1"><semantics id="S2.SS1.p1.18.m18.1a"><msup id="S2.SS1.p1.18.m18.1.1" xref="S2.SS1.p1.18.m18.1.1.cmml"><mi id="S2.SS1.p1.18.m18.1.1.2" xref="S2.SS1.p1.18.m18.1.1.2.cmml">L</mi><mo id="S2.SS1.p1.18.m18.1.1.3" xref="S2.SS1.p1.18.m18.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.18.m18.1b"><apply id="S2.SS1.p1.18.m18.1.1.cmml" xref="S2.SS1.p1.18.m18.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.18.m18.1.1.1.cmml" xref="S2.SS1.p1.18.m18.1.1">superscript</csymbol><ci id="S2.SS1.p1.18.m18.1.1.2.cmml" xref="S2.SS1.p1.18.m18.1.1.2">𝐿</ci><ci id="S2.SS1.p1.18.m18.1.1.3.cmml" xref="S2.SS1.p1.18.m18.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.18.m18.1c">L^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.18.m18.1d">italic_L start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> is the length.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Review-LLM</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">In this section, we introduce Review-LLM for generating reviews.
The key is to enhance the LLMs to learn more personalized user interest features and review writing styles based on the histories.
Specifically, we propose to construct a prompt text for training the LLM-based model using a supervised fine-tuning approach.
As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S2.F1" title="Figure 1 ‣ 2 Method ‣ Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_tag">1</span></a>, the prompt text composes of the following parts:</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p2.1.1">1) Generation Instruction</span>: Its role is to instruct the LLMs to consider both the user’s preference and historical behaviors to complete the generation task. The generation task is structured as an output of the review for the target item;
<span class="ltx_text ltx_font_bold" id="S2.SS2.p2.1.2">2) Input</span>: This contains the items the user has interacted with, including the item title, review, and rating;
<span class="ltx_text ltx_font_bold" id="S2.SS2.p2.1.3">3) The user purchased a new item</span>: This contains the target item title and the corresponding rating;
<span class="ltx_text ltx_font_bold" id="S2.SS2.p2.1.4">4) Response</span>: This is the generated review for the target item.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.5">Then, we use the following SFT training loss to train the LLM-based review generation model:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{sft}=-\sum_{i=1}^{L}logp(w_{i}|w_{&lt;i})," class="ltx_Math" display="block" id="S2.E1.m1.1"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><msub id="S2.E1.m1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.3.2.cmml">ℒ</mi><mrow id="S2.E1.m1.1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.1.3.3.cmml"><mi id="S2.E1.m1.1.1.1.1.3.3.2" xref="S2.E1.m1.1.1.1.1.3.3.2.cmml">s</mi><mo id="S2.E1.m1.1.1.1.1.3.3.1" xref="S2.E1.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S2.E1.m1.1.1.1.1.3.3.3" xref="S2.E1.m1.1.1.1.1.3.3.3.cmml">f</mi><mo id="S2.E1.m1.1.1.1.1.3.3.1a" xref="S2.E1.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S2.E1.m1.1.1.1.1.3.3.4" xref="S2.E1.m1.1.1.1.1.3.3.4.cmml">t</mi></mrow></msub><mo id="S2.E1.m1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.cmml">=</mo><mrow id="S2.E1.m1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.cmml"><mo id="S2.E1.m1.1.1.1.1.1a" xref="S2.E1.m1.1.1.1.1.1.cmml">−</mo><mrow id="S2.E1.m1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.cmml"><munderover id="S2.E1.m1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.2.cmml"><mo id="S2.E1.m1.1.1.1.1.1.1.2.2.2" movablelimits="false" xref="S2.E1.m1.1.1.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.2.2.3" xref="S2.E1.m1.1.1.1.1.1.1.2.2.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.2.2.3.2" xref="S2.E1.m1.1.1.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S2.E1.m1.1.1.1.1.1.1.2.2.3.1" xref="S2.E1.m1.1.1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S2.E1.m1.1.1.1.1.1.1.2.2.3.3" xref="S2.E1.m1.1.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S2.E1.m1.1.1.1.1.1.1.2.3" xref="S2.E1.m1.1.1.1.1.1.1.2.3.cmml">L</mi></munderover><mrow id="S2.E1.m1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.3.cmml">l</mi><mo id="S2.E1.m1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.4" xref="S2.E1.m1.1.1.1.1.1.1.1.4.cmml">o</mi><mo id="S2.E1.m1.1.1.1.1.1.1.1.2a" xref="S2.E1.m1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.5" xref="S2.E1.m1.1.1.1.1.1.1.1.5.cmml">g</mi><mo id="S2.E1.m1.1.1.1.1.1.1.1.2b" xref="S2.E1.m1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.6" xref="S2.E1.m1.1.1.1.1.1.1.1.6.cmml">p</mi><mo id="S2.E1.m1.1.1.1.1.1.1.1.2c" xref="S2.E1.m1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">w</mi><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">w</mi><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml"></mi><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml">&lt;</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml">i</mi></mrow></msub></mrow><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="S2.E1.m1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"><eq id="S2.E1.m1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2"></eq><apply id="S2.E1.m1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.3.2">ℒ</ci><apply id="S2.E1.m1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.3.3"><times id="S2.E1.m1.1.1.1.1.3.3.1.cmml" xref="S2.E1.m1.1.1.1.1.3.3.1"></times><ci id="S2.E1.m1.1.1.1.1.3.3.2.cmml" xref="S2.E1.m1.1.1.1.1.3.3.2">𝑠</ci><ci id="S2.E1.m1.1.1.1.1.3.3.3.cmml" xref="S2.E1.m1.1.1.1.1.3.3.3">𝑓</ci><ci id="S2.E1.m1.1.1.1.1.3.3.4.cmml" xref="S2.E1.m1.1.1.1.1.3.3.4">𝑡</ci></apply></apply><apply id="S2.E1.m1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1"><minus id="S2.E1.m1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1"></minus><apply id="S2.E1.m1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1"><apply id="S2.E1.m1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S2.E1.m1.1.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2">subscript</csymbol><sum id="S2.E1.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2.2.2"></sum><apply id="S2.E1.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2.2.3"><eq id="S2.E1.m1.1.1.1.1.1.1.2.2.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2.2.3.1"></eq><ci id="S2.E1.m1.1.1.1.1.1.1.2.2.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2.2.3.2">𝑖</ci><cn id="S2.E1.m1.1.1.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S2.E1.m1.1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.1.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2.3">𝐿</ci></apply><apply id="S2.E1.m1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1"><times id="S2.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.2"></times><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3">𝑙</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.4.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.4">𝑜</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.5.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.5">𝑔</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.6.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.6">𝑝</ci><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.2">𝑤</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.2">𝑤</ci><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3"><lt id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.1"></lt><csymbol cd="latexml" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.2">absent</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.3">𝑖</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\mathcal{L}_{sft}=-\sum_{i=1}^{L}logp(w_{i}|w_{&lt;i}),</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.1d">caligraphic_L start_POSTSUBSCRIPT italic_s italic_f italic_t end_POSTSUBSCRIPT = - ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT italic_l italic_o italic_g italic_p ( italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_w start_POSTSUBSCRIPT &lt; italic_i end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.p3.4">where <math alttext="w_{i}" class="ltx_Math" display="inline" id="S2.SS2.p3.1.m1.1"><semantics id="S2.SS2.p3.1.m1.1a"><msub id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml"><mi id="S2.SS2.p3.1.m1.1.1.2" xref="S2.SS2.p3.1.m1.1.1.2.cmml">w</mi><mi id="S2.SS2.p3.1.m1.1.1.3" xref="S2.SS2.p3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><apply id="S2.SS2.p3.1.m1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.1.m1.1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.p3.1.m1.1.1.2.cmml" xref="S2.SS2.p3.1.m1.1.1.2">𝑤</ci><ci id="S2.SS2.p3.1.m1.1.1.3.cmml" xref="S2.SS2.p3.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">w_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.1.m1.1d">italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the <math alttext="i" class="ltx_Math" display="inline" id="S2.SS2.p3.2.m2.1"><semantics id="S2.SS2.p3.2.m2.1a"><mi id="S2.SS2.p3.2.m2.1.1" xref="S2.SS2.p3.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.2.m2.1b"><ci id="S2.SS2.p3.2.m2.1.1.cmml" xref="S2.SS2.p3.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.2.m2.1d">italic_i</annotation></semantics></math>-th word in the generated review and <math alttext="L" class="ltx_Math" display="inline" id="S2.SS2.p3.3.m3.1"><semantics id="S2.SS2.p3.3.m3.1a"><mi id="S2.SS2.p3.3.m3.1.1" xref="S2.SS2.p3.3.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.3.m3.1b"><ci id="S2.SS2.p3.3.m3.1.1.cmml" xref="S2.SS2.p3.3.m3.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.3.m3.1c">L</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.3.m3.1d">italic_L</annotation></semantics></math> is the length of that.
The probability <math alttext="p(w_{i}|w_{&lt;i})" class="ltx_Math" display="inline" id="S2.SS2.p3.4.m4.1"><semantics id="S2.SS2.p3.4.m4.1a"><mrow id="S2.SS2.p3.4.m4.1.1" xref="S2.SS2.p3.4.m4.1.1.cmml"><mi id="S2.SS2.p3.4.m4.1.1.3" xref="S2.SS2.p3.4.m4.1.1.3.cmml">p</mi><mo id="S2.SS2.p3.4.m4.1.1.2" xref="S2.SS2.p3.4.m4.1.1.2.cmml">⁢</mo><mrow id="S2.SS2.p3.4.m4.1.1.1.1" xref="S2.SS2.p3.4.m4.1.1.1.1.1.cmml"><mo id="S2.SS2.p3.4.m4.1.1.1.1.2" stretchy="false" xref="S2.SS2.p3.4.m4.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS2.p3.4.m4.1.1.1.1.1" xref="S2.SS2.p3.4.m4.1.1.1.1.1.cmml"><msub id="S2.SS2.p3.4.m4.1.1.1.1.1.2" xref="S2.SS2.p3.4.m4.1.1.1.1.1.2.cmml"><mi id="S2.SS2.p3.4.m4.1.1.1.1.1.2.2" xref="S2.SS2.p3.4.m4.1.1.1.1.1.2.2.cmml">w</mi><mi id="S2.SS2.p3.4.m4.1.1.1.1.1.2.3" xref="S2.SS2.p3.4.m4.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S2.SS2.p3.4.m4.1.1.1.1.1.1" xref="S2.SS2.p3.4.m4.1.1.1.1.1.1.cmml">|</mo><msub id="S2.SS2.p3.4.m4.1.1.1.1.1.3" xref="S2.SS2.p3.4.m4.1.1.1.1.1.3.cmml"><mi id="S2.SS2.p3.4.m4.1.1.1.1.1.3.2" xref="S2.SS2.p3.4.m4.1.1.1.1.1.3.2.cmml">w</mi><mrow id="S2.SS2.p3.4.m4.1.1.1.1.1.3.3" xref="S2.SS2.p3.4.m4.1.1.1.1.1.3.3.cmml"><mi id="S2.SS2.p3.4.m4.1.1.1.1.1.3.3.2" xref="S2.SS2.p3.4.m4.1.1.1.1.1.3.3.2.cmml"></mi><mo id="S2.SS2.p3.4.m4.1.1.1.1.1.3.3.1" xref="S2.SS2.p3.4.m4.1.1.1.1.1.3.3.1.cmml">&lt;</mo><mi id="S2.SS2.p3.4.m4.1.1.1.1.1.3.3.3" xref="S2.SS2.p3.4.m4.1.1.1.1.1.3.3.3.cmml">i</mi></mrow></msub></mrow><mo id="S2.SS2.p3.4.m4.1.1.1.1.3" stretchy="false" xref="S2.SS2.p3.4.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.4.m4.1b"><apply id="S2.SS2.p3.4.m4.1.1.cmml" xref="S2.SS2.p3.4.m4.1.1"><times id="S2.SS2.p3.4.m4.1.1.2.cmml" xref="S2.SS2.p3.4.m4.1.1.2"></times><ci id="S2.SS2.p3.4.m4.1.1.3.cmml" xref="S2.SS2.p3.4.m4.1.1.3">𝑝</ci><apply id="S2.SS2.p3.4.m4.1.1.1.1.1.cmml" xref="S2.SS2.p3.4.m4.1.1.1.1"><csymbol cd="latexml" id="S2.SS2.p3.4.m4.1.1.1.1.1.1.cmml" xref="S2.SS2.p3.4.m4.1.1.1.1.1.1">conditional</csymbol><apply id="S2.SS2.p3.4.m4.1.1.1.1.1.2.cmml" xref="S2.SS2.p3.4.m4.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p3.4.m4.1.1.1.1.1.2.1.cmml" xref="S2.SS2.p3.4.m4.1.1.1.1.1.2">subscript</csymbol><ci id="S2.SS2.p3.4.m4.1.1.1.1.1.2.2.cmml" xref="S2.SS2.p3.4.m4.1.1.1.1.1.2.2">𝑤</ci><ci id="S2.SS2.p3.4.m4.1.1.1.1.1.2.3.cmml" xref="S2.SS2.p3.4.m4.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S2.SS2.p3.4.m4.1.1.1.1.1.3.cmml" xref="S2.SS2.p3.4.m4.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.p3.4.m4.1.1.1.1.1.3.1.cmml" xref="S2.SS2.p3.4.m4.1.1.1.1.1.3">subscript</csymbol><ci id="S2.SS2.p3.4.m4.1.1.1.1.1.3.2.cmml" xref="S2.SS2.p3.4.m4.1.1.1.1.1.3.2">𝑤</ci><apply id="S2.SS2.p3.4.m4.1.1.1.1.1.3.3.cmml" xref="S2.SS2.p3.4.m4.1.1.1.1.1.3.3"><lt id="S2.SS2.p3.4.m4.1.1.1.1.1.3.3.1.cmml" xref="S2.SS2.p3.4.m4.1.1.1.1.1.3.3.1"></lt><csymbol cd="latexml" id="S2.SS2.p3.4.m4.1.1.1.1.1.3.3.2.cmml" xref="S2.SS2.p3.4.m4.1.1.1.1.1.3.3.2">absent</csymbol><ci id="S2.SS2.p3.4.m4.1.1.1.1.1.3.3.3.cmml" xref="S2.SS2.p3.4.m4.1.1.1.1.1.3.3.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.4.m4.1c">p(w_{i}|w_{&lt;i})</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.4.m4.1d">italic_p ( italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_w start_POSTSUBSCRIPT &lt; italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> is calculated by the LLM model following the next-token prediction paradigm.
During the training process, we utilize the Low-Rank Adaptation (LoRA) <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib3" title="">2021</a>)</cite> for Parameter-Efficient Fine-Tuning (PEFT), which can greatly reduce the number of trainable parameters.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">During inference, we remove the review of the target item in the <span class="ltx_text ltx_font_bold" id="S2.SS2.p4.1.1">4) Response</span>.
Then we input this modified prompt into the large language model to generate the review for the target item.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Experimental Setting</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">In this paper, we select five open-source 5-core recommendation datasets from Amazon dataset <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cseweb.ucsd.edu/~jmcauley/datasets/amazon_v2/" title="">https://cseweb.ucsd.edu/~jmcauley/datasets/amazon_v2/</a></span></span></span>, including “Arts, Crafts and Sewing”, “Office items”, “Musical Instruments”, “Toys and Games” and “Video Games”.
We only remain users with more than 10 historical interactions and less than 30 historical interactions.
We timely sort user interactions, then employ the last review as the reference review, and treat others as historical interactions.
Then, we randomly select 1000 samples from each dataset as the training set and 200 samples as simple evaluation data from the remaining data.
Furthermore, we select 200 negative reviews from each dataset as hard evaluation data to test the model’s ability to generate negative reviews.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">We conduct experiments using a cluster composed of 4*A800 80GB GPUs.
We select Llama-3-8b <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://llama.meta.com/llama3/" title="">https://llama.meta.com/llama3/</a></span></span></span> as the base model.
And, we conduct the SFT training based on PyTorch and PEFT library <cite class="ltx_cite ltx_citemacro_cite">Mangrulkar et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib11" title="">2022</a>)</cite> and use the LoRA <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib3" title="">2021</a>)</cite> with a rank equal to 8.
In addition, we use the Adam optimizer with learning rate of 5e-6 and batch size of 1 for SFT, and we set gradient accumulation steps as 2.
We conduct each experiment independently and repeat it 5 times, and report the average results.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Baselines and Evaluation Metrics</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We compare Review-LLM with: (i) closed-source models such as GPT-3.5-Turbo, GPT-4o <cite class="ltx_cite ltx_citemacro_cite">Achiam et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib1" title="">2023</a>)</cite>; (ii) open-source models such as, Llama-3-8b <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib18" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">To evaluate the performance of different models, we select ROUGE-1/L <cite class="ltx_cite ltx_citemacro_cite">Lin (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib9" title="">2004</a>)</cite> and BERT <cite class="ltx_cite ltx_citemacro_cite">Kenton and Toutanova (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib4" title="">2019</a>)</cite> similar score (BertScore) as evaluation metrics.
ROUGE-n measures the n-gram similarity while BertScore measures the semantic similarity in the embedding space between the generated reviews and the reference reviews.
We use the sentence transformers <cite class="ltx_cite ltx_citemacro_cite">Reimers and Gurevych (<a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#bib.bib15" title="">2019</a>)</cite> to compute the BertScore.
Besides, we conduct a human evaluation experiment to test whether the generated reviews are semantically consistent with the reference reviews.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Simple evaluation. w/ rating means the prompt contains ratings and w/o rating is vice.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.1" style="width:182.1pt;height:85.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-82.5pt,38.8pt) scale(0.524734522024457,0.524734522024457) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T1.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<th class="ltx_td ltx_nopad ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S3.T1.1.1.1.1"><svg height="19.07" overflow="visible" version="1.1" width="93.78"><g transform="translate(0,19.07) scale(1,-1)"><path d="M 0,19.07 93.78,0" stroke="#000000" stroke-width="0.4"></path><g class="ltx_svg_fog" transform="translate(0,0)"><g transform="translate(0,9.61) scale(1, -1)"><foreignobject height="9.61" overflow="visible" width="46.89">
<span class="ltx_inline-block" id="S3.T1.1.1.1.1.pic1.1.1">
<span class="ltx_inline-block ltx_align_left" id="S3.T1.1.1.1.1.pic1.1.1.1">
<span class="ltx_p" id="S3.T1.1.1.1.1.pic1.1.1.1.1">Method</span>
</span>
</span></foreignobject></g></g><g class="ltx_svg_fog" transform="translate(54.15,9.61)"><g transform="translate(0,9.46) scale(1, -1)"><foreignobject height="9.46" overflow="visible" width="39.63">
<span class="ltx_inline-block" id="S3.T1.1.1.1.1.pic1.2.1">
<span class="ltx_inline-block ltx_align_right" id="S3.T1.1.1.1.1.pic1.2.1.1">
<span class="ltx_p" id="S3.T1.1.1.1.1.pic1.2.1.1.1">Metric</span>
</span>
</span></foreignobject></g></g></g></svg></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T1.1.1.1.2">ROUGE-1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T1.1.1.1.3">ROUGE-L</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.4">BertScore (mean)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.1.1.2.1.1">GPT-3.5-turbo (w/ rating)</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.1.2">15.99</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.1.3">9.84</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.1.4">41.52</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T1.1.1.3.2.1">GPT-3.5-turbo (w/o rating)</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.3.2.2">16.00</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.3.2.3">9.81</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.3.2.4">41.37</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T1.1.1.4.3.1">GPT-4o (w/ rating)</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.4.3.2">12.80</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.4.3.3">8.47</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.4.3.4">40.12</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.5.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T1.1.1.5.4.1">GPT-4o (w/o rating)</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.4.2">15.41</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.4.3">11.22</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.4.4">41.73</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.6.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T1.1.1.6.5.1">Llama-3-8b (w/ rating)</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.6.5.2">12.23</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.6.5.3">8.23</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.6.5.4">31.30</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.7.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T1.1.1.7.6.1">Llama-3-8b (w/o rating)</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.7.6.2">13.82</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.7.6.3">9.59</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.7.6.4">30.46</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.8.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T1.1.1.8.7.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.8.7.1.1">Review-LLM (w/ rating)</span></th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.8.7.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.8.7.2.1">31.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.8.7.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.8.7.3.1">26.88</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.8.7.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.8.7.4.1">49.52</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.9.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S3.T1.1.1.9.8.1">Review-LLM (w/o rating)</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.9.8.2">30.47</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.9.8.3">26.38</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.9.8.4">48.56</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Overall Performance</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S3.T1" title="Table 1 ‣ 3.2 Baselines and Evaluation Metrics ‣ 3 Experiments ‣ Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_tag">1</span></a> compares the performance of our method with several baselines and ablations.
It is noted that the GPT-3.5-Turbo and GPT-4o are always better than Llama-3-8b, the reason is that the GPT-series models have a larger number of parameters and are pre-trained on massive data, which could learn more general knowledge.
Besides, we find that some baselines without ratings perform better than with ratings, while our fine-tuning method is the opposite.
We argue that this is because the user rating information is further pre-trained in our method while baselines not.
Overall, our method Review-LLM outperforms all methods (including GPT-3.5-Turbo and GPT-4o) across all metrics, demonstrating the effectiveness of using the item title, review, and rating to personalized fine-tune.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Negative Review Performance</h3>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Hard evaluation. w/ rating means the prompt contains ratings and w/o rating is vice.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T2.1" style="width:182.1pt;height:85.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-82.5pt,38.8pt) scale(0.524734522024457,0.524734522024457) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T2.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.1.1.1">
<th class="ltx_td ltx_nopad ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.1"><svg height="19.07" overflow="visible" version="1.1" width="93.78"><g transform="translate(0,19.07) scale(1,-1)"><path d="M 0,19.07 93.78,0" stroke="#000000" stroke-width="0.4"></path><g class="ltx_svg_fog" transform="translate(0,0)"><g transform="translate(0,9.61) scale(1, -1)"><foreignobject height="9.61" overflow="visible" width="46.89">
<span class="ltx_inline-block" id="S3.T2.1.1.1.1.pic1.1.1">
<span class="ltx_inline-block ltx_align_left" id="S3.T2.1.1.1.1.pic1.1.1.1">
<span class="ltx_p" id="S3.T2.1.1.1.1.pic1.1.1.1.1">Method</span>
</span>
</span></foreignobject></g></g><g class="ltx_svg_fog" transform="translate(54.15,9.61)"><g transform="translate(0,9.46) scale(1, -1)"><foreignobject height="9.46" overflow="visible" width="39.63">
<span class="ltx_inline-block" id="S3.T2.1.1.1.1.pic1.2.1">
<span class="ltx_inline-block ltx_align_right" id="S3.T2.1.1.1.1.pic1.2.1.1">
<span class="ltx_p" id="S3.T2.1.1.1.1.pic1.2.1.1.1">Metric</span>
</span>
</span></foreignobject></g></g></g></svg></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.2">ROUGE-1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.3">ROUGE-L</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.4">BertScore (mean)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.1.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T2.1.1.2.1.1">GPT-3.5-turbo (w/ rating)</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.2.1.2">17.62</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.2.1.3">10.70</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.2.1.4">37.45</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T2.1.1.3.2.1">GPT-3.5-turbo (w/o rating)</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.1.3.2.2">16.07</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.1.3.2.3">9.89</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.3.2.4">37.25</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T2.1.1.4.3.1">GPT-4o (w/ rating)</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.1.4.3.2">16.66</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.1.4.3.3">9.86</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.3.4">39.21</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.5.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T2.1.1.5.4.1">GPT-4o (w/o rating)</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.1.5.4.2">14.51</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.1.5.4.3">8.73</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.5.4.4">38.64</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.6.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T2.1.1.6.5.1">Llama-3-8b (w/ rating)</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.1.6.5.2">13.47</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.1.6.5.3">8.05</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.6.5.4">28.38</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.7.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T2.1.1.7.6.1">Llama-3-8b (w/o rating)</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.1.7.6.2">13.11</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.1.7.6.3">7.89</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.7.6.4">26.96</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.8.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T2.1.1.8.7.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.8.7.1.1">Review-LLM (w/ rating)</span></th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.1.8.7.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.8.7.2.1">21.93</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.1.8.7.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.8.7.3.1">16.63</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.8.7.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.8.7.4.1">39.35</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.9.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S3.T2.1.1.9.8.1">Review-LLM (w/o rating)</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T2.1.1.9.8.2">17.82</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T2.1.1.9.8.3">13.50</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.9.8.4">35.89</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">In our method, we employ user rating information to strengthen the model’s understanding of user preferences for different items to achieve more personalized review generation.
In this part, we test the performance of the model on the constructed hard testing set.
The different model performance is shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S3.T2" title="Table 2 ‣ 3.4 Negative Review Performance ‣ 3 Experiments ‣ Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_tag">2</span></a>.
From the results, we can find that all model performance has decreased compared with Table <a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S3.T1" title="Table 1 ‣ 3.2 Baselines and Evaluation Metrics ‣ 3 Experiments ‣ Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_tag">1</span></a>.
In particular, using Llama3-8b for inference directly, BertScore is reduced to <math alttext="26.96" class="ltx_Math" display="inline" id="S3.SS4.p1.1.m1.1"><semantics id="S3.SS4.p1.1.m1.1a"><mn id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml">26.96</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><cn id="S3.SS4.p1.1.m1.1.1.cmml" type="float" xref="S3.SS4.p1.1.m1.1.1">26.96</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">26.96</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.1.m1.1d">26.96</annotation></semantics></math>.
We argue that this is because the LLMs might be polite, resulting in insufficient negative information captured during generating reviews.
Besides, methods with ratings outperform methods without ratings on semantic similarity, especially Review-LLM, which further confirms the necessity of fusing the rating information for personalized review generation.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Human Evaluation</h3>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="261" id="S3.F2.g1" src="x2.png" width="382"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Human Evaluation. The bar is the mean of the model performance, and the error bar represents the max and min accuracy of the model.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.3">In this part, we conduct the human evaluation to test the model performance of review generation.
Considering that the generated texts with rating information usually have higher semantic similarity than those without, we only compare the models with rating information here.
We randomly select 100 reference reviews and generated reviews from the simple testing set, and hire 10 Ph.D. students who are familiar with review/text generation to evaluate the similarity between generated reviews and reference reviews.
If the reference review is semantically similar to the generated reviews, it is marked as <math alttext="1" class="ltx_Math" display="inline" id="S3.SS5.p1.1.m1.1"><semantics id="S3.SS5.p1.1.m1.1a"><mn id="S3.SS5.p1.1.m1.1.1" xref="S3.SS5.p1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.1.m1.1b"><cn id="S3.SS5.p1.1.m1.1.1.cmml" type="integer" xref="S3.SS5.p1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.1.m1.1d">1</annotation></semantics></math>, otherwise it is marked as <math alttext="0" class="ltx_Math" display="inline" id="S3.SS5.p1.2.m2.1"><semantics id="S3.SS5.p1.2.m2.1a"><mn id="S3.SS5.p1.2.m2.1.1" xref="S3.SS5.p1.2.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.2.m2.1b"><cn id="S3.SS5.p1.2.m2.1.1.cmml" type="integer" xref="S3.SS5.p1.2.m2.1.1">0</cn></annotation-xml></semantics></math>.
Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S3.F2" title="Figure 2 ‣ 3.5 Human Evaluation ‣ 3 Experiments ‣ Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_tag">2</span></a> shows the percentage of generated reviews marked as <math alttext="1" class="ltx_Math" display="inline" id="S3.SS5.p1.3.m3.1"><semantics id="S3.SS5.p1.3.m3.1a"><mn id="S3.SS5.p1.3.m3.1.1" xref="S3.SS5.p1.3.m3.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.3.m3.1b"><cn id="S3.SS5.p1.3.m3.1.1.cmml" type="integer" xref="S3.SS5.p1.3.m3.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.3.m3.1c">1</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.3.m3.1d">1</annotation></semantics></math>.
From the results, we can see that the designed fine-tuning data and framework could improve the quality of generated reviews and increase their semantic similarity to the reference reviews.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.6 </span>Case Study</h3>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="405" id="S3.F3.g1" src="x3.png" width="365"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Case Study.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS6.p1">
<p class="ltx_p" id="S3.SS6.p1.1">To demonstrate the effect of Review-LLM on generating reviews more intuitively, we select the generated reviews (from Review-LLM, GPT-4o, GPT-3.5-Turbo) and the real review for visualization shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.07487v1#S3.F3" title="Figure 3 ‣ 3.6 Case Study ‣ 3 Experiments ‣ Review-LLM: Harnessing Large Language Models for Personalized Review Generation"><span class="ltx_text ltx_ref_tag">3</span></a>.
First, we can find the review generated by our model is semantically similar to the real review and brief.
In contrast, reviews derived by GPT-3.5-Turbo/GPT-4o are too long and may not be suitable for e-commerce platforms.
Second, the generated review of Review-LLM better reflects review writing styles and user sentiment towards the item (we marked those in blue font).
This demonstrates that our model could generate high-quality personalized reviews effectively by unifying rich user information with LLMs.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">This paper presents a framework that leverages Large Language Models (LLMs) for personalized review generation in recommender systems.
By aggregating user historical behaviors, including item titles, reviews, and ratings, we construct a comprehensive input prompt to capture user preferences and review writing style.
In this way, the model could mitigate the generation of overly polite reviews.
Then, we utilize the low-rank adaptation for parameter-efficient fine-tuning, enabling the LLMs to generate reviews for candidate items through supervised fine-tuning.
Experimental results show that our fine-tuning method outperforms GPT-3.5-Turbo and GPT-4o in review generation.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Limitation</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">(1) Different individuals may focus on different aspects of a product, such as price, quality, appearance, or durability. While the proposed framework leverages user historical behaviors to capture comprehensive user interest features, it may not fully capture the diversity of individual preferences.
(2) The framework primarily focuses on capturing user preferences from historical behaviors without considering the dynamics of user interactions over time. User preferences and writing styles can evolve, and incorporating temporal dynamics could potentially improve the accuracy and personalization of review generation.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et al. (2023)</span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2303.08774</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et al. (2017)</span>
<span class="ltx_bibblock">
Li Dong, Shaohan Huang, Furu Wei, Mirella Lapata, Ming Zhou, and Ke Xu. 2017.

</span>
<span class="ltx_bibblock">Learning to generate product reviews from attributes.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">ECAL</em>, pages 623–632.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2021)</span>
<span class="ltx_bibblock">
Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. 2021.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kenton and Toutanova (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of NAACL-HLT</em>, pages 4171–4186.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2020)</span>
<span class="ltx_bibblock">
Jihyeok Kim, Seungtaek Choi, Reinald Kim Amplayo, and Seung-won Hwang. 2020.

</span>
<span class="ltx_bibblock">Retrieval-augmented controllable review generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 28th International Conference on Computational Linguistics</em>, pages 2284–2295.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2020)</span>
<span class="ltx_bibblock">
Junyi Li, Siqing Li, Wayne Xin Zhao, Gaole He, Zhicheng Wei, Nicholas Jing Yuan, and Ji-Rong Wen. 2020.

</span>
<span class="ltx_bibblock">Knowledge-enhanced personalized review generation with capsule graph neural network.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">CIKM</em>, pages 735–744.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2019)</span>
<span class="ltx_bibblock">
Junyi Li, Wayne Xin Zhao, Ji-Rong Wen, and Yang Song. 2019.

</span>
<span class="ltx_bibblock">Generating long and informative reviews with aspect-aware coarse-to-fine decoding.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">ACL</em>, pages 1969–1979.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Tuzhilin (2019)</span>
<span class="ltx_bibblock">
Pan Li and Alexander Tuzhilin. 2019.

</span>
<span class="ltx_bibblock">Towards controllable and personalized review generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">EMNLP</em>, pages 3228–3236.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin (2004)</span>
<span class="ltx_bibblock">
Chin-Yew Lin. 2004.

</span>
<span class="ltx_bibblock">Rouge: A package for automatic evaluation of summaries.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Text summarization branches out</em>, pages 74–81.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2018)</span>
<span class="ltx_bibblock">
Yichao Lu, Ruihai Dong, and Barry Smyth. 2018.

</span>
<span class="ltx_bibblock">Why i like it: multi-task learning for recommendation and explanation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the 12th ACM Conference on Recommender Systems</em>, pages 4–12.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mangrulkar et al. (2022)</span>
<span class="ltx_bibblock">
Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, Sayak Paul, and Benjamin Bossan. 2022.

</span>
<span class="ltx_bibblock">Peft: State-of-the-art parameter-efficient fine-tuning methods.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/huggingface/peft" title="">https://github.com/huggingface/peft</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McAuley and Leskovec (2013)</span>
<span class="ltx_bibblock">
Julian McAuley and Jure Leskovec. 2013.

</span>
<span class="ltx_bibblock">Hidden factors and hidden topics: understanding rating dimensions with review text.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 7th ACM conference on Recommender systems</em>, pages 165–172.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ni et al. (2017)</span>
<span class="ltx_bibblock">
Jianmo Ni, Zachary C Lipton, Sharad Vikram, and Julian McAuley. 2017.

</span>
<span class="ltx_bibblock">Estimating reactions and recommending products with generative models of reviews.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">IJCNLP</em>, pages 783–791.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ni and McAuley (2018)</span>
<span class="ltx_bibblock">
Jianmo Ni and Julian McAuley. 2018.

</span>
<span class="ltx_bibblock">Personalized review generation by expanding phrases and attending on aspect-aware representations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">ACL</em>, pages 706–711.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reimers and Gurevych (2019)</span>
<span class="ltx_bibblock">
Nils Reimers and Iryna Gurevych. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/1908.10084" title="">Sentence-bert: Sentence embeddings using siamese bert-networks</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing</em>. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2020)</span>
<span class="ltx_bibblock">
Peijie Sun, Le Wu, Kun Zhang, Yanjie Fu, Richang Hong, and Meng Wang. 2020.

</span>
<span class="ltx_bibblock">Dual learning for explainable recommendation: Towards unifying user preference prediction and review generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of The Web Conference 2020</em>, pages 837–847.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al. (2016)</span>
<span class="ltx_bibblock">
Jian Tang, Yifan Yang, Sam Carton, Ming Zhang, and Qiaozhu Mei. 2016.

</span>
<span class="ltx_bibblock">Context-aware natural language generation with recurrent neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:1611.09900</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2302.13971</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2024)</span>
<span class="ltx_bibblock">
Lanling Xu, Junjie Zhang, Bingqian Li, Jinpeng Wang, Mingchen Cai, Wayne Xin Zhao, and Ji-Rong Wen. 2024.

</span>
<span class="ltx_bibblock">Prompting large language models for recommender systems: A comprehensive framework and empirical analysis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2401.04997</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zang and Wan (2017)</span>
<span class="ltx_bibblock">
Hongyu Zang and Xiaojun Wan. 2017.

</span>
<span class="ltx_bibblock">Towards automatic generation of product reviews from aspect-sentiment scores.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proceedings of the 10th International Conference on Natural Language Generation</em>, pages 168–177.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Jul 10 09:18:55 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
