<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[1807.09842] Understanding and representing the semantics of large structured documents</title><meta property="og:description" content="Understanding large, structured documents like scholarly articles, requests for proposals or business reports is a complex and difficult task. It involves discovering a document‚Äôs overall purpose and subject(s), unders‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Understanding and representing the semantics of large structured documents">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Understanding and representing the semantics of large structured documents">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/1807.09842">

<!--Generated on Sat Mar 16 17:08:08 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Document Ontology Deep Learning Semantic Annotation.">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span id="id1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>University of Maryland, Baltimore County, Baltimore MD 21250, USA 
<br class="ltx_break"><span id="id1.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>{mrahman1,finin}@umbc.edu</span></span></span></span></span></span>
<h1 class="ltx_title ltx_title_document">Understanding and representing the semantics
<br class="ltx_break">of large structured documents</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Muhammad Mahbubur Rahman 
</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tim Finin
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Understanding large, structured documents like scholarly articles, requests for proposals or business reports is a complex and difficult task. It involves discovering a document‚Äôs overall purpose and subject(s), understanding the function and meaning of its sections and subsections, and extracting low level entities and facts about them. In this research, we present a deep learning based document ontology to capture the general purpose semantic structure and domain specific semantic concepts from a large number of academic articles and business documents. The ontology is able to describe different functional parts of a document, which can be used to enhance semantic indexing for a better understanding by human beings and machines. We evaluate our models through extensive experiments on datasets of scholarly articles from <span id="id1.id1.1" class="ltx_text ltx_font_italic">arXiv</span> and <span id="id1.id1.2" class="ltx_text ltx_font_italic">Request for Proposal</span> documents.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Document Ontology Deep Learning Semantic Annotation.
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Understanding the semantic structure of large multi-themed documents is a challenging task because these documents are composed of a variety of functional sections discussing diverse topics. Some documents may have a table of contents, whereas others may not. Even if a table of contents is present, mapping it across the document is not a straightforward process. Section and subsection headers may or may not be present in the table of contents and if they are present, they are often inconsistent across documents even within the same vertical domain.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Identifying a semantic organization of sections, subsections and sub-subsections of documents across all vertical domains is not the same. For example, a business document has a completely different structure from a user manual. Scholarly research articles from different disciplines, such as computer science and social science, may have different structures. For example, social science articles usually have <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">methodology</span> sections whereas computer science articles often have <span id="S1.p2.1.2" class="ltx_text ltx_font_italic">approach</span> sections. Semantically these two section types share the same purpose and function, even though their details may be quite different.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Our objective is to develop and use a document ontology to describe different functional parts of academic and business documents. For example, the <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">introduction</span> section of a research paper describes the problem statement, scope and context by explaining the significance of the research challenge. The <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">results</span> section presents and illustrates research findings with the help of experiments, graphs and tables. Finally, the <span id="S1.p3.1.3" class="ltx_text ltx_font_italic">conclusion</span> section typically restates the paper‚Äôs contribution and the most important ideas that support the main argument of the paper.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Creating such an ontology involves significant human understanding and analysis of a large number of documents from any vertical domain. It is also requires a common understanding of the structure of information presented in those documents. The common concepts across all documents should be clearly visible to the ontology developers. The developers should also understand the hierarchy of the sections, subsection and sub-subsections of a document. Hence the process to get each relationship among different concepts of a document is time consuming. Moreover, some concepts may be overlooked while analyzing the documents.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">We have developed a deep learning based system to automatically determine ontology concepts and properties from a large number of documents of the same vertical domain. Our approaches are powerful, yet simple, to capture the most important semantic concepts from academic articles and <span id="S1.p5.1.1" class="ltx_text ltx_font_italic">request for proposal</span> (RFP) documents. In the course of out this work, we experimented with and evaluated several state of the art technologies, including Variational Autoencoders (VAE) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, Convolutional Autoencoders (CAE) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> and LDA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">The ontology can be used for annotating different sections of a document, which helps to understand its semantic structure. It can also be useful for comprehending and modeling types and subtypes of documents. The results can enable the reuse of domain knowledge along with text analysis, content based question answering and semantic document indexing.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Over the last few years, several ontologies have been developed to describe a document‚Äôs semantic structure and annotate it with a semantic label. Some of them were designed for academic articles and others deal with other type of documents.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Ciccarese et al. developed an Ontology of Rhetorical Blocks (ORB) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> to capture the coarse-grained rhetorical structure of a scientific article. ORB can be used to add semantics to a new article and to annotate an existing article. It divides a scientific article into three components: header, body and tail. The header captures meta-information about the article, such as it‚Äôs title, authors, affiliations, publishing venue, and abstract. The body adopts the IMRAD structure from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> and contains introduction, methods, results, and discussion. The tail provides additional meta-information about the paper, such as acknowledgments and references.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Peroni et al. introduced the Semantic Publishing and Referencing (SPAR) Ontologies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> to create comprehensive machine-readable RDF meta-data for the entire set of characteristics of a document from semantic publishing. It is used to describe different components of books and journal articles, such as citations and bibliographic records. It has eight ontologies to cover all of the components for the creation of RDF meta-data (DoCO, FaBiO, CiTO, PRO, PSO, C4O, BiRO and PWO). DoCO, the document components ontology <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, provides a general-purpose structured vocabulary of document elements to describe both structural and rhetorical document components in RDF. This ontology can be used to annotate and retrieve document components of an academic article based on its structure and content. Examples of DoCO classes are chapter, list, preface, table and figure. DoCO also inherits another two ontologies: Discourse Elements Ontology (Deo) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> and Document Structural Patterns Ontology <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">Shotton et al. developed the Deo ontology to study different corpora of scientific literature on different topics and publishers. It presents structured vocabulary for rhetorical elements within an academic document. The major classes of Deo are introduction, background, motivation, model, related work, methods, results, conclusion, and acknowledgements. This ontology is very intriguing and relevant to our semantic annotation.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">Monti et al. developed a system to reconstruct an electronic medical document with semantic annotation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. They divided the process into three steps. In the first, they classified documents in one of the categories specified in the Consolidated CDA (C-CDA) standard <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, using PDFBox <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> to extract text from CDA standard medical documents. Later, they split the document into paragraphs using the typographical features available in the PDF file. Finally, they identified key concepts from the document and mapped them to the most appropriate medical ontology. However, the paper lacks technical detail and an analysis of the results.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">A Contextual Long short-term memory (CLSTM) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> was used by Ghosh et al. for sentence topic prediction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. Lopyrev et al. trained an encoder-decoder RNN with LSTM for generating news headlines using the texts of news articles from the Gigaword dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. Srivastava et al. introduced a type of Deep Boltzmann Machine (DBM) for extracting distributed semantic representations from a large unstructured collection of documents <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. They used the Over-Replicated <math id="S2.p6.1.m1.1" class="ltx_Math" alttext="Softmax" display="inline"><semantics id="S2.p6.1.m1.1a"><mrow id="S2.p6.1.m1.1.1" xref="S2.p6.1.m1.1.1.cmml"><mi id="S2.p6.1.m1.1.1.2" xref="S2.p6.1.m1.1.1.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S2.p6.1.m1.1.1.1" xref="S2.p6.1.m1.1.1.1.cmml">‚Äã</mo><mi id="S2.p6.1.m1.1.1.3" xref="S2.p6.1.m1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.p6.1.m1.1.1.1a" xref="S2.p6.1.m1.1.1.1.cmml">‚Äã</mo><mi id="S2.p6.1.m1.1.1.4" xref="S2.p6.1.m1.1.1.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.p6.1.m1.1.1.1b" xref="S2.p6.1.m1.1.1.1.cmml">‚Äã</mo><mi id="S2.p6.1.m1.1.1.5" xref="S2.p6.1.m1.1.1.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.p6.1.m1.1.1.1c" xref="S2.p6.1.m1.1.1.1.cmml">‚Äã</mo><mi id="S2.p6.1.m1.1.1.6" xref="S2.p6.1.m1.1.1.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.p6.1.m1.1.1.1d" xref="S2.p6.1.m1.1.1.1.cmml">‚Äã</mo><mi id="S2.p6.1.m1.1.1.7" xref="S2.p6.1.m1.1.1.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.p6.1.m1.1.1.1e" xref="S2.p6.1.m1.1.1.1.cmml">‚Äã</mo><mi id="S2.p6.1.m1.1.1.8" xref="S2.p6.1.m1.1.1.8.cmml">x</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p6.1.m1.1b"><apply id="S2.p6.1.m1.1.1.cmml" xref="S2.p6.1.m1.1.1"><times id="S2.p6.1.m1.1.1.1.cmml" xref="S2.p6.1.m1.1.1.1"></times><ci id="S2.p6.1.m1.1.1.2.cmml" xref="S2.p6.1.m1.1.1.2">ùëÜ</ci><ci id="S2.p6.1.m1.1.1.3.cmml" xref="S2.p6.1.m1.1.1.3">ùëú</ci><ci id="S2.p6.1.m1.1.1.4.cmml" xref="S2.p6.1.m1.1.1.4">ùëì</ci><ci id="S2.p6.1.m1.1.1.5.cmml" xref="S2.p6.1.m1.1.1.5">ùë°</ci><ci id="S2.p6.1.m1.1.1.6.cmml" xref="S2.p6.1.m1.1.1.6">ùëö</ci><ci id="S2.p6.1.m1.1.1.7.cmml" xref="S2.p6.1.m1.1.1.7">ùëé</ci><ci id="S2.p6.1.m1.1.1.8.cmml" xref="S2.p6.1.m1.1.1.8">ùë•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.1.m1.1c">Softmax</annotation></semantics></math> model for document retrieval and classification.</p>
</div>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.1" class="ltx_p">Tuarob et al. described an algorithm to automatically build a semantic hierarchical structure of sections for a scholarly paper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. They defined a section as the pair of the section header and its textual content. They employed a rule-based approach to recognize sections from scholarly articles and applied a simple set of heuristics that built a hierarchy of sections from the extracted section headers.</p>
</div>
<div id="S2.p8" class="ltx_para">
<p id="S2.p8.1" class="ltx_p">Most of the ontologies mentioned above are developed either manually or do not provide any technical details.
Our ontology is an enhancement of Deo<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, developed using deep learning and embedding vector clustering to choose classes and the properties based on more than <math id="S2.p8.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S2.p8.1.m1.1a"><mn id="S2.p8.1.m1.1.1" xref="S2.p8.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.p8.1.m1.1b"><cn type="integer" id="S2.p8.1.m1.1.1.cmml" xref="S2.p8.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.1.m1.1c">1</annotation></semantics></math> million academic articles and a few hundred thousand business documents. Our approach is able to capture semantic meaning of different functional parts of a document by semantic annotation and semantic concept extraction, as described in our earlier research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Data Type and Document Category</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this research, we focus on extracting information from PDF documents. The motivation for focusing on PDF documents is the popularity and portability of PDF over different types of devices and operating systems. But automatic post-processing of a PDF document is not an easy task, since the objective of PDF rendering tools is not to support post-processing, but rather better visualization of the content. The rendering tools allow numerous equally valid ways of producing the same visual result and therefore no structure can reliably be derived from how the text operators are used. For experimental purposes, we choose PDF documents from academic articles and business documents, such as <span id="S3.p1.1.1" class="ltx_text ltx_font_italic">arXiv</span> and RFP domains. We use a dataset which contains <math id="S3.p1.1.m1.3" class="ltx_Math" alttext="1,121,363" display="inline"><semantics id="S3.p1.1.m1.3a"><mrow id="S3.p1.1.m1.3.4.2" xref="S3.p1.1.m1.3.4.1.cmml"><mn id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">1</mn><mo id="S3.p1.1.m1.3.4.2.1" xref="S3.p1.1.m1.3.4.1.cmml">,</mo><mn id="S3.p1.1.m1.2.2" xref="S3.p1.1.m1.2.2.cmml">121</mn><mo id="S3.p1.1.m1.3.4.2.2" xref="S3.p1.1.m1.3.4.1.cmml">,</mo><mn id="S3.p1.1.m1.3.3" xref="S3.p1.1.m1.3.3.cmml">363</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.3b"><list id="S3.p1.1.m1.3.4.1.cmml" xref="S3.p1.1.m1.3.4.2"><cn type="integer" id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">1</cn><cn type="integer" id="S3.p1.1.m1.2.2.cmml" xref="S3.p1.1.m1.2.2">121</cn><cn type="integer" id="S3.p1.1.m1.3.3.cmml" xref="S3.p1.1.m1.3.3">363</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.3c">1,121,363</annotation></semantics></math> <span id="S3.p1.1.2" class="ltx_text ltx_font_italic">arXiv</span> articles during or before 2016 released by Rahman et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>System Architecture and Technical Approach</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">This section describes the overall work flow of our system and the approach used for each of its parts.</p>
</div>
<figure id="S4.F1" class="ltx_figure"><img src="/html/1807.09842/assets/figures/pipe_line_ontology.jpg" id="S4.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="399" height="180" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F1.3.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S4.F1.4.2" class="ltx_text" style="font-size:90%;">Overall work flow of our system</span></figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>System Architecture</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The pipeline of our system is shown in Figure <a href="#S4.F1" title="Figure 1 ‚Ä£ 4 System Architecture and Technical Approach ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The top-level, subsection and sub-subsection headers are retrieved from all the <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">arXiv</span> articles released by Rahman et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. After preprocessing, the headers are passed into Autoencoder. The embedding vector is dumped from the Autoencoder, which is passed through a t-SNE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> dimensionality reduction. A k-mean <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> clustering algorithm is then applied on the reduced embedding vector. After preprocessing, a count based approach is also applied to retrieve all of the unique headers based on count. We also use our previous system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> to get semantic sections, which are passed through LDA topic models to get domain specific semantic terms or concepts for each of the individual sections.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Technical Approach</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In order to design a document ontology, we created a list of classes and properties by following the count-based and cluster-based approaches. In the count-based approach, we first took all section headers, including <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">top-level</span>, <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_italic">subsection</span> and <span id="S4.SS2.p1.1.3" class="ltx_text ltx_font_italic">sub-subsection</span> which are basically headers from the table of contents of all <span id="S4.SS2.p1.1.4" class="ltx_text ltx_font_italic">arXiv</span> articles. Then we removed numbers and dots from the beginning of each header, and generated the frequency for each header and sorted them. Based on a frequency threshold, we considered the section headers, which might be a class or concept for our ontology.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">For the cluster based approach, we generated all section headers from the table of contents of all <span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_italic">arXiv</span> articles and developed a Variational Autoencoder and Convolutional Autoencoder to represent each of the section headers in a sentence level embedding, which is termed ‚Äùheader embedding‚Äù in our system. We applied Autoencoder to learn the header embedding in an unsupervised fashion, in order to produce good quality clusters. We then dumped the embedding vector from the bottleneck layer. Since this vector has high dimensionality and clustering high-dimensioned data often does not work well, we applied the t-SNE dimensionality reduction technique to reduce the dimensions of the embedding vector to just two dimensions. After dimensionality reduction, we used k-means clustering on the embedding vector to cluster the header embedding into semantically meaningful groups. We analyzed all clusters and all section headers from the count-based approach and came up with the classes or general purpose semantic concepts to design our document ontology.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S4.T1.3.2" class="ltx_text" style="font-size:90%;">Classes for Ontology</span></figcaption>
<div id="S4.T1.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:100.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-38.5pt,9.0pt) scale(0.849216048243645,0.849216048243645) ;">
<table id="S4.T1.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.4.1.1.1" class="ltx_tr">
<th id="S4.T1.4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Document Type</span></th>
<th id="S4.T1.4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.4.1.1.1.2.1" class="ltx_text ltx_font_bold">Classes/Concepts</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.4.1.2.1" class="ltx_tr">
<th id="S4.T1.4.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.4.1.2.1.1.1" class="ltx_text ltx_font_bold">Academic Article</span></th>
<td id="S4.T1.4.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S4.T1.4.1.2.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.4.1.2.1.2.1.1" class="ltx_tr">
<td id="S4.T1.4.1.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Introduction, Conclusion, Discussion, References, Acknowledgments, Results, Abstract,</td>
</tr>
<tr id="S4.T1.4.1.2.1.2.1.2" class="ltx_tr">
<td id="S4.T1.4.1.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Appendix, Related Work, Experiments, Methodology, Proof of Theorem, Evaluation,</td>
</tr>
<tr id="S4.T1.4.1.2.1.2.1.3" class="ltx_tr">
<td id="S4.T1.4.1.2.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Future Work, Datasets, Contribution, Background, Implementation, Approach, Preliminary</td>
</tr>
</table>
</td>
</tr>
<tr id="S4.T1.4.1.3.2" class="ltx_tr">
<th id="S4.T1.4.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.4.1.3.2.1.1" class="ltx_text ltx_font_bold">RFP</span></th>
<td id="S4.T1.4.1.3.2.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">
<table id="S4.T1.4.1.3.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.4.1.3.2.2.1.1" class="ltx_tr">
<td id="S4.T1.4.1.3.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Introduction, Requirement, General Information, Conclusion, Statement of Work,</td>
</tr>
<tr id="S4.T1.4.1.3.2.2.1.2" class="ltx_tr">
<td id="S4.T1.4.1.3.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Contract Administration, Appendix, Background, Deliverable, Contract Clauses</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">We also applied a similar approach for section headers from RFP documents. To understand the sections of an RFP, we read <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> and discussed with experts from RedShred <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Table <a href="#S4.T1" title="Table 1 ‚Ä£ 4.2 Technical Approach ‚Ä£ 4 System Architecture and Technical Approach ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows classes from <span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_italic">arXiv</span> articles and RFPs, which were used to design a simple document ontology. The detailed descriptions are given below.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/1807.09842/assets/figures/vae_for_ontology.jpg" id="S4.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="399" height="150" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S4.F2.4.2" class="ltx_text" style="font-size:90%;">Variational Autoencoder for Ontology Class Selection</span></figcaption>
</figure>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Variational Autoencoder</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.3" class="ltx_p">A variational autoencoder is a type of autoencoder that learns latent variable models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> for the input data. Instead of learning an arbitrary function, the autoencoder learns the parameters of a probability distribution of the input data. The encoder turns the input data into two parameters in a latent space, which are noted as <math id="S4.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\bar{z}" display="inline"><semantics id="S4.SS2.SSS1.p1.1.m1.1a"><mover accent="true" id="S4.SS2.SSS1.p1.1.m1.1.1" xref="S4.SS2.SSS1.p1.1.m1.1.1.cmml"><mi id="S4.SS2.SSS1.p1.1.m1.1.1.2" xref="S4.SS2.SSS1.p1.1.m1.1.1.2.cmml">z</mi><mo id="S4.SS2.SSS1.p1.1.m1.1.1.1" xref="S4.SS2.SSS1.p1.1.m1.1.1.1.cmml">¬Ø</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.1.m1.1b"><apply id="S4.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1"><ci id="S4.SS2.SSS1.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1.1">¬Ø</ci><ci id="S4.SS2.SSS1.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1.2">ùëß</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.1.m1.1c">\bar{z}</annotation></semantics></math> and <math id="S4.SS2.SSS1.p1.2.m2.1" class="ltx_Math" alttext="z\log\sigma" display="inline"><semantics id="S4.SS2.SSS1.p1.2.m2.1a"><mrow id="S4.SS2.SSS1.p1.2.m2.1.1" xref="S4.SS2.SSS1.p1.2.m2.1.1.cmml"><mi id="S4.SS2.SSS1.p1.2.m2.1.1.2" xref="S4.SS2.SSS1.p1.2.m2.1.1.2.cmml">z</mi><mo lspace="0.167em" rspace="0em" id="S4.SS2.SSS1.p1.2.m2.1.1.1" xref="S4.SS2.SSS1.p1.2.m2.1.1.1.cmml">‚Äã</mo><mrow id="S4.SS2.SSS1.p1.2.m2.1.1.3" xref="S4.SS2.SSS1.p1.2.m2.1.1.3.cmml"><mi id="S4.SS2.SSS1.p1.2.m2.1.1.3.1" xref="S4.SS2.SSS1.p1.2.m2.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S4.SS2.SSS1.p1.2.m2.1.1.3a" xref="S4.SS2.SSS1.p1.2.m2.1.1.3.cmml">‚Å°</mo><mi id="S4.SS2.SSS1.p1.2.m2.1.1.3.2" xref="S4.SS2.SSS1.p1.2.m2.1.1.3.2.cmml">œÉ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.2.m2.1b"><apply id="S4.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1"><times id="S4.SS2.SSS1.p1.2.m2.1.1.1.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1.1"></times><ci id="S4.SS2.SSS1.p1.2.m2.1.1.2.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1.2">ùëß</ci><apply id="S4.SS2.SSS1.p1.2.m2.1.1.3.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1.3"><log id="S4.SS2.SSS1.p1.2.m2.1.1.3.1.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1.3.1"></log><ci id="S4.SS2.SSS1.p1.2.m2.1.1.3.2.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1.3.2">ùúé</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.2.m2.1c">z\log\sigma</annotation></semantics></math>. Then, randomly, a similar data point, <math id="S4.SS2.SSS1.p1.3.m3.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S4.SS2.SSS1.p1.3.m3.1a"><mi id="S4.SS2.SSS1.p1.3.m3.1.1" xref="S4.SS2.SSS1.p1.3.m3.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.3.m3.1b"><ci id="S4.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS1.p1.3.m3.1.1">ùëß</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.3.m3.1c">z</annotation></semantics></math> is selected from the latent normal distribution using Equation <a href="#S4.E1" title="In 4.2.1 Variational Autoencoder ‚Ä£ 4.2 Technical Approach ‚Ä£ 4 System Architecture and Technical Approach ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.1" class="ltx_Math" alttext="z=\bar{z}+e^{z\log\sigma}*\epsilon" display="block"><semantics id="S4.E1.m1.1a"><mrow id="S4.E1.m1.1.1" xref="S4.E1.m1.1.1.cmml"><mi id="S4.E1.m1.1.1.2" xref="S4.E1.m1.1.1.2.cmml">z</mi><mo id="S4.E1.m1.1.1.1" xref="S4.E1.m1.1.1.1.cmml">=</mo><mrow id="S4.E1.m1.1.1.3" xref="S4.E1.m1.1.1.3.cmml"><mover accent="true" id="S4.E1.m1.1.1.3.2" xref="S4.E1.m1.1.1.3.2.cmml"><mi id="S4.E1.m1.1.1.3.2.2" xref="S4.E1.m1.1.1.3.2.2.cmml">z</mi><mo id="S4.E1.m1.1.1.3.2.1" xref="S4.E1.m1.1.1.3.2.1.cmml">¬Ø</mo></mover><mo id="S4.E1.m1.1.1.3.1" xref="S4.E1.m1.1.1.3.1.cmml">+</mo><mrow id="S4.E1.m1.1.1.3.3" xref="S4.E1.m1.1.1.3.3.cmml"><msup id="S4.E1.m1.1.1.3.3.2" xref="S4.E1.m1.1.1.3.3.2.cmml"><mi id="S4.E1.m1.1.1.3.3.2.2" xref="S4.E1.m1.1.1.3.3.2.2.cmml">e</mi><mrow id="S4.E1.m1.1.1.3.3.2.3" xref="S4.E1.m1.1.1.3.3.2.3.cmml"><mi id="S4.E1.m1.1.1.3.3.2.3.2" xref="S4.E1.m1.1.1.3.3.2.3.2.cmml">z</mi><mo lspace="0.167em" rspace="0em" id="S4.E1.m1.1.1.3.3.2.3.1" xref="S4.E1.m1.1.1.3.3.2.3.1.cmml">‚Äã</mo><mrow id="S4.E1.m1.1.1.3.3.2.3.3" xref="S4.E1.m1.1.1.3.3.2.3.3.cmml"><mi id="S4.E1.m1.1.1.3.3.2.3.3.1" xref="S4.E1.m1.1.1.3.3.2.3.3.1.cmml">log</mi><mo lspace="0.167em" id="S4.E1.m1.1.1.3.3.2.3.3a" xref="S4.E1.m1.1.1.3.3.2.3.3.cmml">‚Å°</mo><mi id="S4.E1.m1.1.1.3.3.2.3.3.2" xref="S4.E1.m1.1.1.3.3.2.3.3.2.cmml">œÉ</mi></mrow></mrow></msup><mo lspace="0.222em" rspace="0.222em" id="S4.E1.m1.1.1.3.3.1" xref="S4.E1.m1.1.1.3.3.1.cmml">‚àó</mo><mi id="S4.E1.m1.1.1.3.3.3" xref="S4.E1.m1.1.1.3.3.3.cmml">œµ</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.1b"><apply id="S4.E1.m1.1.1.cmml" xref="S4.E1.m1.1.1"><eq id="S4.E1.m1.1.1.1.cmml" xref="S4.E1.m1.1.1.1"></eq><ci id="S4.E1.m1.1.1.2.cmml" xref="S4.E1.m1.1.1.2">ùëß</ci><apply id="S4.E1.m1.1.1.3.cmml" xref="S4.E1.m1.1.1.3"><plus id="S4.E1.m1.1.1.3.1.cmml" xref="S4.E1.m1.1.1.3.1"></plus><apply id="S4.E1.m1.1.1.3.2.cmml" xref="S4.E1.m1.1.1.3.2"><ci id="S4.E1.m1.1.1.3.2.1.cmml" xref="S4.E1.m1.1.1.3.2.1">¬Ø</ci><ci id="S4.E1.m1.1.1.3.2.2.cmml" xref="S4.E1.m1.1.1.3.2.2">ùëß</ci></apply><apply id="S4.E1.m1.1.1.3.3.cmml" xref="S4.E1.m1.1.1.3.3"><times id="S4.E1.m1.1.1.3.3.1.cmml" xref="S4.E1.m1.1.1.3.3.1"></times><apply id="S4.E1.m1.1.1.3.3.2.cmml" xref="S4.E1.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.3.3.2.1.cmml" xref="S4.E1.m1.1.1.3.3.2">superscript</csymbol><ci id="S4.E1.m1.1.1.3.3.2.2.cmml" xref="S4.E1.m1.1.1.3.3.2.2">ùëí</ci><apply id="S4.E1.m1.1.1.3.3.2.3.cmml" xref="S4.E1.m1.1.1.3.3.2.3"><times id="S4.E1.m1.1.1.3.3.2.3.1.cmml" xref="S4.E1.m1.1.1.3.3.2.3.1"></times><ci id="S4.E1.m1.1.1.3.3.2.3.2.cmml" xref="S4.E1.m1.1.1.3.3.2.3.2">ùëß</ci><apply id="S4.E1.m1.1.1.3.3.2.3.3.cmml" xref="S4.E1.m1.1.1.3.3.2.3.3"><log id="S4.E1.m1.1.1.3.3.2.3.3.1.cmml" xref="S4.E1.m1.1.1.3.3.2.3.3.1"></log><ci id="S4.E1.m1.1.1.3.3.2.3.3.2.cmml" xref="S4.E1.m1.1.1.3.3.2.3.3.2">ùúé</ci></apply></apply></apply><ci id="S4.E1.m1.1.1.3.3.3.cmml" xref="S4.E1.m1.1.1.3.3.3">italic-œµ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.1c">z=\bar{z}+e^{z\log\sigma}*\epsilon</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.SSS1.p1.4" class="ltx_p">A final decoder maps these latent space points back to the original input data. The architecture of our VAE is given in Figure <a href="#S4.F2" title="Figure 2 ‚Ä£ 4.2 Technical Approach ‚Ä£ 4 System Architecture and Technical Approach ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Convolutional Autoencoder</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">A convolutional autoencoder is an autoencoder that employs a convolutional network to learn the parameters in an unsupervised way. Since our input is text, we use a Conv1D layer for both convolutional and deconvolutional parts of the network. The input text is converted into a <span id="S4.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_italic">one-hot</span> encoding, which is passed into the embedding layer. Before encoding, we have Conv1D and MaxPooling1D layers with a <span id="S4.SS2.SSS2.p1.1.2" class="ltx_text ltx_font_italic">ReLu</span> activation function. The decoder starts with the deconvolution followed by an UpSampling1D layer. At the end, the decoder reproduces the original text. The architecture of the CAE is given in Figure <a href="#S4.F3" title="Figure 3 ‚Ä£ 4.2.2 Convolutional Autoencoder ‚Ä£ 4.2 Technical Approach ‚Ä£ 4 System Architecture and Technical Approach ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/1807.09842/assets/figures/Convolutional_Autoencoder.jpg" id="S4.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="160" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.4.2" class="ltx_text" style="font-size:90%;">Convolutional Autoencoder for Ontology Class Selection</span></figcaption>
</figure>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3 </span>Document Ontology</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.1" class="ltx_p">After getting the classes from an analysis of the count- and cluster-based approaches, we designed an ontology for our input documents. The classes represent general purpose semantic concepts in our ontology. We also analyzed cluster visualization to get properties and relations among classes. Detailed results are included in section <a href="#S5" title="5 Experiments and Results ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. Figure <a href="#S4.F4" title="Figure 4 ‚Ä£ 4.2.3 Document Ontology ‚Ä£ 4.2 Technical Approach ‚Ä£ 4 System Architecture and Technical Approach ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows our simple document ontology.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/1807.09842/assets/figures/latest_document_ontology_design_diagram.jpg" id="S4.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="399" height="180" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.3.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.4.2" class="ltx_text" style="font-size:90%;">The upper level of our document ontology, with rectangles representing classes and ovals properties. Additional classes are mentioned in Table <a href="#S4.T1" title="Table 1 ‚Ä£ 4.2 Technical Approach ‚Ä£ 4 System Architecture and Technical Approach ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</span></figcaption>
</figure>
<div id="S4.SS2.SSS3.p2" class="ltx_para">
<p id="S4.SS2.SSS3.p2.1" class="ltx_p">The document ontology includes classes that describe concepts induced from both <span id="S4.SS2.SSS3.p2.1.1" class="ltx_text ltx_font_italic">arXiv</span> academic articles and RFP documents. The top level ‚ÄúDocument‚Äù class has two subclasses: ‚ÄúAcademic Article‚Äù and ‚ÄúRFP‚Äù. The Document class has ‚ÄúCategory‚Äù that describes the type of document, such as Computer Science, Mathematics, Social Science, Networking, Biomedical and Software articles/RFPs. Both Academic articles and RFPs have contents, which are sections. These sections are the classes of different semantic concepts in a document. Both Academic articles and RFPs share some concepts, such as ‚ÄúIntroduction‚Äù, ‚ÄúConclusion‚Äù and ‚ÄúBackground‚Äù. They also have their own concepts. For example, ‚ÄúApproach‚Äù and ‚ÄúResults‚Äù are available in Academic Articles whereas RFP has ‚ÄúContractClauses‚Äù and ‚ÄúDeliverable‚Äù concepts/classes. Due to space constraint, the classes are shown in Table <a href="#S4.T1" title="Table 1 ‚Ä£ 4.2 Technical Approach ‚Ä£ 4 System Architecture and Technical Approach ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S4.SS2.SSS3.p3" class="ltx_para">
<p id="S4.SS2.SSS3.p3.1" class="ltx_p">Each of the classes/concepts has two properties ‚ÄúSemanticTerms‚Äù and ‚ÄúContent‚Äù which are represented by the relationships ‚ÄúhasSemanticTerms‚Äù and ‚ÄúhasContent‚Äù. The data types for these two properties are String. The ‚ÄúhasSemanticTerms‚Äù property captures semantic topics applying Latent Dirichlet Allocation (LDA) to each section. Some concepts may have part, which is represented by a relationship ‚ÄúhasPart‚Äù. For example, a concept ‚ÄúResults‚Äù has another subconcept ‚ÄúExperiments‚Äù. Some of the concepts may be similar to another concepts, which is shown by a relationship ‚ÄúisSimilarTo‚Äù. For example ‚ÄúApproach‚Äù and ‚ÄúMethodology‚Äù are two similar concepts.</p>
</div>
</section>
<section id="S4.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.4 </span>Semantic Concepts using LDA</h4>

<div id="S4.SS2.SSS4.p1" class="ltx_para">
<p id="S4.SS2.SSS4.p1.1" class="ltx_p">We used latent Dirichlet allocation (LDA) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> to find domain-specific semantic concepts from a section. LDA is a generative topic model that is used to understand the hidden structure of a collection of documents. In an LDA model, each document has a mixture of various topics with a probability distribution. Again, each topic is a distribution of words. Using Gensim <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, we trained an LDA topic model on a set of semantically divided sections. The model is used to predict the topics for any text section. A few terms that have the highest probability values of the predicted topics, are used as domain specific semantic concepts, or terms, for a given section. These semantic concepts are also used as property values in the document ontology.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments and Results</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this section, we discuss the experimental setup followed by the detailed procedures. We also describe the results and the findings of each experiment and illustrate the results using comparative analysis.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Dataset</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.2" class="ltx_p">Using the dataset released by Rahman and Finin <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, we retrieved section headers from table of contents of all <span id="S5.SS1.p1.2.1" class="ltx_text ltx_font_typewriter">arXiv</span> articles and applied some heuristics to remove unwanted text from the headers (e.g., numbers and dots) and downcased the text. The total number of unique section headers in our collection was <math id="S5.SS1.p1.1.m1.3" class="ltx_Math" alttext="3,364,668" display="inline"><semantics id="S5.SS1.p1.1.m1.3a"><mrow id="S5.SS1.p1.1.m1.3.4.2" xref="S5.SS1.p1.1.m1.3.4.1.cmml"><mn id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">3</mn><mo id="S5.SS1.p1.1.m1.3.4.2.1" xref="S5.SS1.p1.1.m1.3.4.1.cmml">,</mo><mn id="S5.SS1.p1.1.m1.2.2" xref="S5.SS1.p1.1.m1.2.2.cmml">364</mn><mo id="S5.SS1.p1.1.m1.3.4.2.2" xref="S5.SS1.p1.1.m1.3.4.1.cmml">,</mo><mn id="S5.SS1.p1.1.m1.3.3" xref="S5.SS1.p1.1.m1.3.3.cmml">668</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.3b"><list id="S5.SS1.p1.1.m1.3.4.1.cmml" xref="S5.SS1.p1.1.m1.3.4.2"><cn type="integer" id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">3</cn><cn type="integer" id="S5.SS1.p1.1.m1.2.2.cmml" xref="S5.SS1.p1.1.m1.2.2">364</cn><cn type="integer" id="S5.SS1.p1.1.m1.3.3.cmml" xref="S5.SS1.p1.1.m1.3.3">668</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.3c">3,364,668</annotation></semantics></math> for all categories of <span id="S5.SS1.p1.2.2" class="ltx_text ltx_font_italic">arXiv</span> articles. We used these section headers to get classes or concepts for ontology design as explained in section <a href="#S4" title="4 System Architecture and Technical Approach ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. We also retrieved section headers from only Computer Science articles. After applying a similar approach, we found <math id="S5.SS1.p1.2.m2.2" class="ltx_Math" alttext="666,877" display="inline"><semantics id="S5.SS1.p1.2.m2.2a"><mrow id="S5.SS1.p1.2.m2.2.3.2" xref="S5.SS1.p1.2.m2.2.3.1.cmml"><mn id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml">666</mn><mo id="S5.SS1.p1.2.m2.2.3.2.1" xref="S5.SS1.p1.2.m2.2.3.1.cmml">,</mo><mn id="S5.SS1.p1.2.m2.2.2" xref="S5.SS1.p1.2.m2.2.2.cmml">877</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.2b"><list id="S5.SS1.p1.2.m2.2.3.1.cmml" xref="S5.SS1.p1.2.m2.2.3.2"><cn type="integer" id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1">666</cn><cn type="integer" id="S5.SS1.p1.2.m2.2.2.cmml" xref="S5.SS1.p1.2.m2.2.2">877</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.2c">666,877</annotation></semantics></math> unique section headers from Computer Science articles. The experiments and results for all categories, as well as Computer Science, are described below.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Experiments on the arXiv Dataset</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.3" class="ltx_p">As described in section <a href="#S4" title="4 System Architecture and Technical Approach ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we trained a VAE model to learn the header embedding for ontology design. We clustered the header embedding matrix into semantically meaningful groups and identified different classes for ontology. The VAE was trained with different configurations and hyperparameters to achieve the best results. We experimented with different input lengths, such as <math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><mn id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><cn type="integer" id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">10</annotation></semantics></math>, <math id="S5.SS2.p1.2.m2.1" class="ltx_Math" alttext="15" display="inline"><semantics id="S5.SS2.p1.2.m2.1a"><mn id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><cn type="integer" id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">15</annotation></semantics></math> and <math id="S5.SS2.p1.3.m3.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S5.SS2.p1.3.m3.1a"><mn id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><cn type="integer" id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">20</annotation></semantics></math> word length section headers. All section headers were converted into a multi-level <span id="S5.SS2.p1.3.1" class="ltx_text ltx_font_italic">one-hot</span> vector.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.7" class="ltx_p">We used <math id="S5.SS2.p2.1.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S5.SS2.p2.1.m1.1a"><mn id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><cn type="integer" id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">100</annotation></semantics></math> embedding dimensions, <math id="S5.SS2.p2.2.m2.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S5.SS2.p2.2.m2.1a"><mn id="S5.SS2.p2.2.m2.1.1" xref="S5.SS2.p2.2.m2.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.2.m2.1b"><cn type="integer" id="S5.SS2.p2.2.m2.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m2.1c">100</annotation></semantics></math> hidden layers and <math id="S5.SS2.p2.3.m3.1" class="ltx_Math" alttext="1.0" display="inline"><semantics id="S5.SS2.p2.3.m3.1a"><mn id="S5.SS2.p2.3.m3.1.1" xref="S5.SS2.p2.3.m3.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.3.m3.1b"><cn type="float" id="S5.SS2.p2.3.m3.1.1.cmml" xref="S5.SS2.p2.3.m3.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.3.m3.1c">1.0</annotation></semantics></math> <math id="S5.SS2.p2.4.m4.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S5.SS2.p2.4.m4.1a"><mi id="S5.SS2.p2.4.m4.1.1" xref="S5.SS2.p2.4.m4.1.1.cmml">œµ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.4.m4.1b"><ci id="S5.SS2.p2.4.m4.1.1.cmml" xref="S5.SS2.p2.4.m4.1.1">italic-œµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.4.m4.1c">\epsilon</annotation></semantics></math> to learn latent variables. The <span id="S5.SS2.p2.7.1" class="ltx_text ltx_font_italic">one-hot</span> vector was the input to the network, which was followed by an embedding layer with <math id="S5.SS2.p2.5.m5.1" class="ltx_Math" alttext="ReLu" display="inline"><semantics id="S5.SS2.p2.5.m5.1a"><mrow id="S5.SS2.p2.5.m5.1.1" xref="S5.SS2.p2.5.m5.1.1.cmml"><mi id="S5.SS2.p2.5.m5.1.1.2" xref="S5.SS2.p2.5.m5.1.1.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.5.m5.1.1.1" xref="S5.SS2.p2.5.m5.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p2.5.m5.1.1.3" xref="S5.SS2.p2.5.m5.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.5.m5.1.1.1a" xref="S5.SS2.p2.5.m5.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p2.5.m5.1.1.4" xref="S5.SS2.p2.5.m5.1.1.4.cmml">L</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.5.m5.1.1.1b" xref="S5.SS2.p2.5.m5.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p2.5.m5.1.1.5" xref="S5.SS2.p2.5.m5.1.1.5.cmml">u</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.5.m5.1b"><apply id="S5.SS2.p2.5.m5.1.1.cmml" xref="S5.SS2.p2.5.m5.1.1"><times id="S5.SS2.p2.5.m5.1.1.1.cmml" xref="S5.SS2.p2.5.m5.1.1.1"></times><ci id="S5.SS2.p2.5.m5.1.1.2.cmml" xref="S5.SS2.p2.5.m5.1.1.2">ùëÖ</ci><ci id="S5.SS2.p2.5.m5.1.1.3.cmml" xref="S5.SS2.p2.5.m5.1.1.3">ùëí</ci><ci id="S5.SS2.p2.5.m5.1.1.4.cmml" xref="S5.SS2.p2.5.m5.1.1.4">ùêø</ci><ci id="S5.SS2.p2.5.m5.1.1.5.cmml" xref="S5.SS2.p2.5.m5.1.1.5">ùë¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.5.m5.1c">ReLu</annotation></semantics></math> activation function. Then we had a dense layer to capture input features in a latent space. The model parameters were trained using two loss functions, which were a reconstruction loss to force the decoded output to match with the initial inputs, and a KL divergence between the learned latent and prior distributions. The decoder was used with a <math id="S5.SS2.p2.6.m6.1" class="ltx_Math" alttext="sigmoid" display="inline"><semantics id="S5.SS2.p2.6.m6.1a"><mrow id="S5.SS2.p2.6.m6.1.1" xref="S5.SS2.p2.6.m6.1.1.cmml"><mi id="S5.SS2.p2.6.m6.1.1.2" xref="S5.SS2.p2.6.m6.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.6.m6.1.1.1" xref="S5.SS2.p2.6.m6.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p2.6.m6.1.1.3" xref="S5.SS2.p2.6.m6.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.6.m6.1.1.1a" xref="S5.SS2.p2.6.m6.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p2.6.m6.1.1.4" xref="S5.SS2.p2.6.m6.1.1.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.6.m6.1.1.1b" xref="S5.SS2.p2.6.m6.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p2.6.m6.1.1.5" xref="S5.SS2.p2.6.m6.1.1.5.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.6.m6.1.1.1c" xref="S5.SS2.p2.6.m6.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p2.6.m6.1.1.6" xref="S5.SS2.p2.6.m6.1.1.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.6.m6.1.1.1d" xref="S5.SS2.p2.6.m6.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p2.6.m6.1.1.7" xref="S5.SS2.p2.6.m6.1.1.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.6.m6.1.1.1e" xref="S5.SS2.p2.6.m6.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p2.6.m6.1.1.8" xref="S5.SS2.p2.6.m6.1.1.8.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.6.m6.1b"><apply id="S5.SS2.p2.6.m6.1.1.cmml" xref="S5.SS2.p2.6.m6.1.1"><times id="S5.SS2.p2.6.m6.1.1.1.cmml" xref="S5.SS2.p2.6.m6.1.1.1"></times><ci id="S5.SS2.p2.6.m6.1.1.2.cmml" xref="S5.SS2.p2.6.m6.1.1.2">ùë†</ci><ci id="S5.SS2.p2.6.m6.1.1.3.cmml" xref="S5.SS2.p2.6.m6.1.1.3">ùëñ</ci><ci id="S5.SS2.p2.6.m6.1.1.4.cmml" xref="S5.SS2.p2.6.m6.1.1.4">ùëî</ci><ci id="S5.SS2.p2.6.m6.1.1.5.cmml" xref="S5.SS2.p2.6.m6.1.1.5">ùëö</ci><ci id="S5.SS2.p2.6.m6.1.1.6.cmml" xref="S5.SS2.p2.6.m6.1.1.6">ùëú</ci><ci id="S5.SS2.p2.6.m6.1.1.7.cmml" xref="S5.SS2.p2.6.m6.1.1.7">ùëñ</ci><ci id="S5.SS2.p2.6.m6.1.1.8.cmml" xref="S5.SS2.p2.6.m6.1.1.8">ùëë</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.6.m6.1c">sigmoid</annotation></semantics></math> activation function and the model was compiled with an <math id="S5.SS2.p2.7.m7.1" class="ltx_Math" alttext="rmsprop" display="inline"><semantics id="S5.SS2.p2.7.m7.1a"><mrow id="S5.SS2.p2.7.m7.1.1" xref="S5.SS2.p2.7.m7.1.1.cmml"><mi id="S5.SS2.p2.7.m7.1.1.2" xref="S5.SS2.p2.7.m7.1.1.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.7.m7.1.1.1" xref="S5.SS2.p2.7.m7.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p2.7.m7.1.1.3" xref="S5.SS2.p2.7.m7.1.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.7.m7.1.1.1a" xref="S5.SS2.p2.7.m7.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p2.7.m7.1.1.4" xref="S5.SS2.p2.7.m7.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.7.m7.1.1.1b" xref="S5.SS2.p2.7.m7.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p2.7.m7.1.1.5" xref="S5.SS2.p2.7.m7.1.1.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.7.m7.1.1.1c" xref="S5.SS2.p2.7.m7.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p2.7.m7.1.1.6" xref="S5.SS2.p2.7.m7.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.7.m7.1.1.1d" xref="S5.SS2.p2.7.m7.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p2.7.m7.1.1.7" xref="S5.SS2.p2.7.m7.1.1.7.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.7.m7.1.1.1e" xref="S5.SS2.p2.7.m7.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p2.7.m7.1.1.8" xref="S5.SS2.p2.7.m7.1.1.8.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.7.m7.1b"><apply id="S5.SS2.p2.7.m7.1.1.cmml" xref="S5.SS2.p2.7.m7.1.1"><times id="S5.SS2.p2.7.m7.1.1.1.cmml" xref="S5.SS2.p2.7.m7.1.1.1"></times><ci id="S5.SS2.p2.7.m7.1.1.2.cmml" xref="S5.SS2.p2.7.m7.1.1.2">ùëü</ci><ci id="S5.SS2.p2.7.m7.1.1.3.cmml" xref="S5.SS2.p2.7.m7.1.1.3">ùëö</ci><ci id="S5.SS2.p2.7.m7.1.1.4.cmml" xref="S5.SS2.p2.7.m7.1.1.4">ùë†</ci><ci id="S5.SS2.p2.7.m7.1.1.5.cmml" xref="S5.SS2.p2.7.m7.1.1.5">ùëù</ci><ci id="S5.SS2.p2.7.m7.1.1.6.cmml" xref="S5.SS2.p2.7.m7.1.1.6">ùëü</ci><ci id="S5.SS2.p2.7.m7.1.1.7.cmml" xref="S5.SS2.p2.7.m7.1.1.7">ùëú</ci><ci id="S5.SS2.p2.7.m7.1.1.8.cmml" xref="S5.SS2.p2.7.m7.1.1.8">ùëù</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.7.m7.1c">rmsprop</annotation></semantics></math> optimizer and KL divergence loss function.</p>
</div>
<figure id="S5.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/1807.09842/assets/figures/ontology_encoder_vae_15_clusters_50_encoded_layer.png" id="S5.F5.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="240" height="130" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F5.sf1.3.2" class="ltx_text" style="font-size:90%;">VAE for arXiv: Input Length 15 </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/1807.09842/assets/figures/ontology_encoder_vae_20_clusters_50_encoded_layer.png" id="S5.F5.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="240" height="130" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F5.sf2.3.2" class="ltx_text" style="font-size:90%;">VAE for arXiv: Input Length 20 </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F5.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/1807.09842/assets/figures/conv_autoencoder_ontology_encoder_clusters_30_layer_layer.png" id="S5.F5.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="240" height="130" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S5.F5.sf3.3.2" class="ltx_text" style="font-size:90%;">CAE for arXiv: Input Length 15 </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F5.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/1807.09842/assets/figures/ontology_encoder_vae_15_clusters_20_encoded_layer_rfp_new.png" id="S5.F5.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="240" height="130" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S5.F5.sf4.3.2" class="ltx_text" style="font-size:90%;">VAE for RFP </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S5.F5.3.2" class="ltx_text" style="font-size:90%;">t-SNE Visualization of Embedding Matrix Clusters </span></figcaption>
</figure>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.3" class="ltx_p">We also trained a CAE model as described earlier and experimented with different hyperparameters. The model was trained with a <math id="S5.SS2.p3.1.m1.1" class="ltx_Math" alttext="sigmoid" display="inline"><semantics id="S5.SS2.p3.1.m1.1a"><mrow id="S5.SS2.p3.1.m1.1.1" xref="S5.SS2.p3.1.m1.1.1.cmml"><mi id="S5.SS2.p3.1.m1.1.1.2" xref="S5.SS2.p3.1.m1.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.1.m1.1.1.1" xref="S5.SS2.p3.1.m1.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.1.m1.1.1.3" xref="S5.SS2.p3.1.m1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.1.m1.1.1.1a" xref="S5.SS2.p3.1.m1.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.1.m1.1.1.4" xref="S5.SS2.p3.1.m1.1.1.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.1.m1.1.1.1b" xref="S5.SS2.p3.1.m1.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.1.m1.1.1.5" xref="S5.SS2.p3.1.m1.1.1.5.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.1.m1.1.1.1c" xref="S5.SS2.p3.1.m1.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.1.m1.1.1.6" xref="S5.SS2.p3.1.m1.1.1.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.1.m1.1.1.1d" xref="S5.SS2.p3.1.m1.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.1.m1.1.1.7" xref="S5.SS2.p3.1.m1.1.1.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.1.m1.1.1.1e" xref="S5.SS2.p3.1.m1.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.1.m1.1.1.8" xref="S5.SS2.p3.1.m1.1.1.8.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.1.m1.1b"><apply id="S5.SS2.p3.1.m1.1.1.cmml" xref="S5.SS2.p3.1.m1.1.1"><times id="S5.SS2.p3.1.m1.1.1.1.cmml" xref="S5.SS2.p3.1.m1.1.1.1"></times><ci id="S5.SS2.p3.1.m1.1.1.2.cmml" xref="S5.SS2.p3.1.m1.1.1.2">ùë†</ci><ci id="S5.SS2.p3.1.m1.1.1.3.cmml" xref="S5.SS2.p3.1.m1.1.1.3">ùëñ</ci><ci id="S5.SS2.p3.1.m1.1.1.4.cmml" xref="S5.SS2.p3.1.m1.1.1.4">ùëî</ci><ci id="S5.SS2.p3.1.m1.1.1.5.cmml" xref="S5.SS2.p3.1.m1.1.1.5">ùëö</ci><ci id="S5.SS2.p3.1.m1.1.1.6.cmml" xref="S5.SS2.p3.1.m1.1.1.6">ùëú</ci><ci id="S5.SS2.p3.1.m1.1.1.7.cmml" xref="S5.SS2.p3.1.m1.1.1.7">ùëñ</ci><ci id="S5.SS2.p3.1.m1.1.1.8.cmml" xref="S5.SS2.p3.1.m1.1.1.8">ùëë</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.1.m1.1c">sigmoid</annotation></semantics></math> activation function, <math id="S5.SS2.p3.2.m2.1" class="ltx_Math" alttext="binary\_crossentropy" display="inline"><semantics id="S5.SS2.p3.2.m2.1a"><mrow id="S5.SS2.p3.2.m2.1.1" xref="S5.SS2.p3.2.m2.1.1.cmml"><mi id="S5.SS2.p3.2.m2.1.1.2" xref="S5.SS2.p3.2.m2.1.1.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.2.m2.1.1.3" xref="S5.SS2.p3.2.m2.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1a" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.2.m2.1.1.4" xref="S5.SS2.p3.2.m2.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1b" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.2.m2.1.1.5" xref="S5.SS2.p3.2.m2.1.1.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1c" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.2.m2.1.1.6" xref="S5.SS2.p3.2.m2.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1d" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.2.m2.1.1.7" xref="S5.SS2.p3.2.m2.1.1.7.cmml">y</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1e" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi mathvariant="normal" id="S5.SS2.p3.2.m2.1.1.8" xref="S5.SS2.p3.2.m2.1.1.8.cmml">_</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1f" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.2.m2.1.1.9" xref="S5.SS2.p3.2.m2.1.1.9.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1g" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.2.m2.1.1.10" xref="S5.SS2.p3.2.m2.1.1.10.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1h" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.2.m2.1.1.11" xref="S5.SS2.p3.2.m2.1.1.11.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1i" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.2.m2.1.1.12" xref="S5.SS2.p3.2.m2.1.1.12.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1j" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.2.m2.1.1.13" xref="S5.SS2.p3.2.m2.1.1.13.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1k" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.2.m2.1.1.14" xref="S5.SS2.p3.2.m2.1.1.14.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1l" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.2.m2.1.1.15" xref="S5.SS2.p3.2.m2.1.1.15.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1m" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.2.m2.1.1.16" xref="S5.SS2.p3.2.m2.1.1.16.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1n" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.2.m2.1.1.17" xref="S5.SS2.p3.2.m2.1.1.17.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1o" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.2.m2.1.1.18" xref="S5.SS2.p3.2.m2.1.1.18.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1p" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.2.m2.1.1.19" xref="S5.SS2.p3.2.m2.1.1.19.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.2.m2.1.1.1q" xref="S5.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.2.m2.1.1.20" xref="S5.SS2.p3.2.m2.1.1.20.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.2.m2.1b"><apply id="S5.SS2.p3.2.m2.1.1.cmml" xref="S5.SS2.p3.2.m2.1.1"><times id="S5.SS2.p3.2.m2.1.1.1.cmml" xref="S5.SS2.p3.2.m2.1.1.1"></times><ci id="S5.SS2.p3.2.m2.1.1.2.cmml" xref="S5.SS2.p3.2.m2.1.1.2">ùëè</ci><ci id="S5.SS2.p3.2.m2.1.1.3.cmml" xref="S5.SS2.p3.2.m2.1.1.3">ùëñ</ci><ci id="S5.SS2.p3.2.m2.1.1.4.cmml" xref="S5.SS2.p3.2.m2.1.1.4">ùëõ</ci><ci id="S5.SS2.p3.2.m2.1.1.5.cmml" xref="S5.SS2.p3.2.m2.1.1.5">ùëé</ci><ci id="S5.SS2.p3.2.m2.1.1.6.cmml" xref="S5.SS2.p3.2.m2.1.1.6">ùëü</ci><ci id="S5.SS2.p3.2.m2.1.1.7.cmml" xref="S5.SS2.p3.2.m2.1.1.7">ùë¶</ci><ci id="S5.SS2.p3.2.m2.1.1.8.cmml" xref="S5.SS2.p3.2.m2.1.1.8">_</ci><ci id="S5.SS2.p3.2.m2.1.1.9.cmml" xref="S5.SS2.p3.2.m2.1.1.9">ùëê</ci><ci id="S5.SS2.p3.2.m2.1.1.10.cmml" xref="S5.SS2.p3.2.m2.1.1.10">ùëü</ci><ci id="S5.SS2.p3.2.m2.1.1.11.cmml" xref="S5.SS2.p3.2.m2.1.1.11">ùëú</ci><ci id="S5.SS2.p3.2.m2.1.1.12.cmml" xref="S5.SS2.p3.2.m2.1.1.12">ùë†</ci><ci id="S5.SS2.p3.2.m2.1.1.13.cmml" xref="S5.SS2.p3.2.m2.1.1.13">ùë†</ci><ci id="S5.SS2.p3.2.m2.1.1.14.cmml" xref="S5.SS2.p3.2.m2.1.1.14">ùëí</ci><ci id="S5.SS2.p3.2.m2.1.1.15.cmml" xref="S5.SS2.p3.2.m2.1.1.15">ùëõ</ci><ci id="S5.SS2.p3.2.m2.1.1.16.cmml" xref="S5.SS2.p3.2.m2.1.1.16">ùë°</ci><ci id="S5.SS2.p3.2.m2.1.1.17.cmml" xref="S5.SS2.p3.2.m2.1.1.17">ùëü</ci><ci id="S5.SS2.p3.2.m2.1.1.18.cmml" xref="S5.SS2.p3.2.m2.1.1.18">ùëú</ci><ci id="S5.SS2.p3.2.m2.1.1.19.cmml" xref="S5.SS2.p3.2.m2.1.1.19">ùëù</ci><ci id="S5.SS2.p3.2.m2.1.1.20.cmml" xref="S5.SS2.p3.2.m2.1.1.20">ùë¶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.2.m2.1c">binary\_crossentropy</annotation></semantics></math> loss function, and <math id="S5.SS2.p3.3.m3.1" class="ltx_Math" alttext="adam" display="inline"><semantics id="S5.SS2.p3.3.m3.1a"><mrow id="S5.SS2.p3.3.m3.1.1" xref="S5.SS2.p3.3.m3.1.1.cmml"><mi id="S5.SS2.p3.3.m3.1.1.2" xref="S5.SS2.p3.3.m3.1.1.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.3.m3.1.1.1" xref="S5.SS2.p3.3.m3.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.3.m3.1.1.3" xref="S5.SS2.p3.3.m3.1.1.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.3.m3.1.1.1a" xref="S5.SS2.p3.3.m3.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.3.m3.1.1.4" xref="S5.SS2.p3.3.m3.1.1.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p3.3.m3.1.1.1b" xref="S5.SS2.p3.3.m3.1.1.1.cmml">‚Äã</mo><mi id="S5.SS2.p3.3.m3.1.1.5" xref="S5.SS2.p3.3.m3.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.3.m3.1b"><apply id="S5.SS2.p3.3.m3.1.1.cmml" xref="S5.SS2.p3.3.m3.1.1"><times id="S5.SS2.p3.3.m3.1.1.1.cmml" xref="S5.SS2.p3.3.m3.1.1.1"></times><ci id="S5.SS2.p3.3.m3.1.1.2.cmml" xref="S5.SS2.p3.3.m3.1.1.2">ùëé</ci><ci id="S5.SS2.p3.3.m3.1.1.3.cmml" xref="S5.SS2.p3.3.m3.1.1.3">ùëë</ci><ci id="S5.SS2.p3.3.m3.1.1.4.cmml" xref="S5.SS2.p3.3.m3.1.1.4">ùëé</ci><ci id="S5.SS2.p3.3.m3.1.1.5.cmml" xref="S5.SS2.p3.3.m3.1.1.5">ùëö</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.3.m3.1c">adam</annotation></semantics></math> optimizer. We also dumped and clustered the embedding matrix to get semantically meaningful header groups.</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1 </span>Results and Evaluation</h4>

<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.3" class="ltx_p">Both the VAE and CAE models were trained in an unsupervised way to capture the semantic meaning of each section header. The outputs of the bottleneck layer were dumped and clustered after <span id="S5.SS2.SSS1.p1.3.1" class="ltx_text ltx_font_italic">t-SNE</span> dimensionality reduction. Figure <a href="#S5.F5.sf1" title="In Figure 5 ‚Ä£ 5.2 Experiments on the arXiv Dataset ‚Ä£ 5 Experiments and Results ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(a)</span></a> shows the visualization of <span id="S5.SS2.SSS1.p1.3.2" class="ltx_text ltx_font_italic">k-means</span> clustering with <math id="S5.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="k=50" display="inline"><semantics id="S5.SS2.SSS1.p1.1.m1.1a"><mrow id="S5.SS2.SSS1.p1.1.m1.1.1" xref="S5.SS2.SSS1.p1.1.m1.1.1.cmml"><mi id="S5.SS2.SSS1.p1.1.m1.1.1.2" xref="S5.SS2.SSS1.p1.1.m1.1.1.2.cmml">k</mi><mo id="S5.SS2.SSS1.p1.1.m1.1.1.1" xref="S5.SS2.SSS1.p1.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS2.SSS1.p1.1.m1.1.1.3" xref="S5.SS2.SSS1.p1.1.m1.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.1.m1.1b"><apply id="S5.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1"><eq id="S5.SS2.SSS1.p1.1.m1.1.1.1.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1.1"></eq><ci id="S5.SS2.SSS1.p1.1.m1.1.1.2.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1.2">ùëò</ci><cn type="integer" id="S5.SS2.SSS1.p1.1.m1.1.1.3.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.1.m1.1c">k=50</annotation></semantics></math> and <math id="S5.SS2.SSS1.p1.2.m2.1" class="ltx_Math" alttext="inputlength=15" display="inline"><semantics id="S5.SS2.SSS1.p1.2.m2.1a"><mrow id="S5.SS2.SSS1.p1.2.m2.1.1" xref="S5.SS2.SSS1.p1.2.m2.1.1.cmml"><mrow id="S5.SS2.SSS1.p1.2.m2.1.1.2" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.cmml"><mi id="S5.SS2.SSS1.p1.2.m2.1.1.2.2" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.2.m2.1.1.2.1" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.2.m2.1.1.2.3" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.2.m2.1.1.2.1a" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.2.m2.1.1.2.4" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.2.m2.1.1.2.1b" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.2.m2.1.1.2.5" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.2.m2.1.1.2.1c" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.2.m2.1.1.2.6" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.2.m2.1.1.2.1d" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.2.m2.1.1.2.7" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.7.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.2.m2.1.1.2.1e" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.2.m2.1.1.2.8" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.2.m2.1.1.2.1f" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.2.m2.1.1.2.9" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.9.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.2.m2.1.1.2.1g" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.2.m2.1.1.2.10" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.10.cmml">g</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.2.m2.1.1.2.1h" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.2.m2.1.1.2.11" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.11.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.2.m2.1.1.2.1i" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.2.m2.1.1.2.12" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.12.cmml">h</mi></mrow><mo id="S5.SS2.SSS1.p1.2.m2.1.1.1" xref="S5.SS2.SSS1.p1.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS2.SSS1.p1.2.m2.1.1.3" xref="S5.SS2.SSS1.p1.2.m2.1.1.3.cmml">15</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.2.m2.1b"><apply id="S5.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1"><eq id="S5.SS2.SSS1.p1.2.m2.1.1.1.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.1"></eq><apply id="S5.SS2.SSS1.p1.2.m2.1.1.2.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2"><times id="S5.SS2.SSS1.p1.2.m2.1.1.2.1.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.1"></times><ci id="S5.SS2.SSS1.p1.2.m2.1.1.2.2.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.2">ùëñ</ci><ci id="S5.SS2.SSS1.p1.2.m2.1.1.2.3.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.3">ùëõ</ci><ci id="S5.SS2.SSS1.p1.2.m2.1.1.2.4.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.4">ùëù</ci><ci id="S5.SS2.SSS1.p1.2.m2.1.1.2.5.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.5">ùë¢</ci><ci id="S5.SS2.SSS1.p1.2.m2.1.1.2.6.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.6">ùë°</ci><ci id="S5.SS2.SSS1.p1.2.m2.1.1.2.7.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.7">ùëô</ci><ci id="S5.SS2.SSS1.p1.2.m2.1.1.2.8.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.8">ùëí</ci><ci id="S5.SS2.SSS1.p1.2.m2.1.1.2.9.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.9">ùëõ</ci><ci id="S5.SS2.SSS1.p1.2.m2.1.1.2.10.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.10">ùëî</ci><ci id="S5.SS2.SSS1.p1.2.m2.1.1.2.11.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.11">ùë°</ci><ci id="S5.SS2.SSS1.p1.2.m2.1.1.2.12.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.12">‚Ñé</ci></apply><cn type="integer" id="S5.SS2.SSS1.p1.2.m2.1.1.3.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.3">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.2.m2.1c">inputlength=15</annotation></semantics></math> for VAE embedding after <span id="S5.SS2.SSS1.p1.3.3" class="ltx_text ltx_font_italic">t-SNE</span> dimensionality reduction. Similar visualization with <math id="S5.SS2.SSS1.p1.3.m3.1" class="ltx_Math" alttext="inputlength=20" display="inline"><semantics id="S5.SS2.SSS1.p1.3.m3.1a"><mrow id="S5.SS2.SSS1.p1.3.m3.1.1" xref="S5.SS2.SSS1.p1.3.m3.1.1.cmml"><mrow id="S5.SS2.SSS1.p1.3.m3.1.1.2" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.cmml"><mi id="S5.SS2.SSS1.p1.3.m3.1.1.2.2" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.3.m3.1.1.2.1" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.3.m3.1.1.2.3" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.3.m3.1.1.2.1a" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.3.m3.1.1.2.4" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.3.m3.1.1.2.1b" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.3.m3.1.1.2.5" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.3.m3.1.1.2.1c" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.3.m3.1.1.2.6" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.3.m3.1.1.2.1d" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.3.m3.1.1.2.7" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.7.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.3.m3.1.1.2.1e" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.3.m3.1.1.2.8" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.3.m3.1.1.2.1f" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.3.m3.1.1.2.9" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.9.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.3.m3.1.1.2.1g" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.3.m3.1.1.2.10" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.10.cmml">g</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.3.m3.1.1.2.1h" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.3.m3.1.1.2.11" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.11.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS1.p1.3.m3.1.1.2.1i" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS1.p1.3.m3.1.1.2.12" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.12.cmml">h</mi></mrow><mo id="S5.SS2.SSS1.p1.3.m3.1.1.1" xref="S5.SS2.SSS1.p1.3.m3.1.1.1.cmml">=</mo><mn id="S5.SS2.SSS1.p1.3.m3.1.1.3" xref="S5.SS2.SSS1.p1.3.m3.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.3.m3.1b"><apply id="S5.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1"><eq id="S5.SS2.SSS1.p1.3.m3.1.1.1.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.1"></eq><apply id="S5.SS2.SSS1.p1.3.m3.1.1.2.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.2"><times id="S5.SS2.SSS1.p1.3.m3.1.1.2.1.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.1"></times><ci id="S5.SS2.SSS1.p1.3.m3.1.1.2.2.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.2">ùëñ</ci><ci id="S5.SS2.SSS1.p1.3.m3.1.1.2.3.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.3">ùëõ</ci><ci id="S5.SS2.SSS1.p1.3.m3.1.1.2.4.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.4">ùëù</ci><ci id="S5.SS2.SSS1.p1.3.m3.1.1.2.5.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.5">ùë¢</ci><ci id="S5.SS2.SSS1.p1.3.m3.1.1.2.6.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.6">ùë°</ci><ci id="S5.SS2.SSS1.p1.3.m3.1.1.2.7.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.7">ùëô</ci><ci id="S5.SS2.SSS1.p1.3.m3.1.1.2.8.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.8">ùëí</ci><ci id="S5.SS2.SSS1.p1.3.m3.1.1.2.9.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.9">ùëõ</ci><ci id="S5.SS2.SSS1.p1.3.m3.1.1.2.10.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.10">ùëî</ci><ci id="S5.SS2.SSS1.p1.3.m3.1.1.2.11.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.11">ùë°</ci><ci id="S5.SS2.SSS1.p1.3.m3.1.1.2.12.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.12">‚Ñé</ci></apply><cn type="integer" id="S5.SS2.SSS1.p1.3.m3.1.1.3.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.3.m3.1c">inputlength=20</annotation></semantics></math> is shown in Figure <a href="#S5.F5.sf2" title="In Figure 5 ‚Ä£ 5.2 Experiments on the arXiv Dataset ‚Ä£ 5 Experiments and Results ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(b)</span></a>. After analyzing both the visualizations, we observed that VAE models learned very well and were able to capture similar section headers together. We noticed that semantically similar section headers were plotted nearby. We also realized that semantically similar section headers were constructed gradually from one concept to another. For example, we detected a pattern in the graph where a sequence of concepts from ‚Äúmethods‚Äù gradually moved to ‚Äúdata construction‚Äù, ‚Äúresults‚Äù, ‚Äúdiscussion‚Äù, ‚Äúremarks‚Äù and ‚Äúconclusion‚Äù. From this analysis, we could infer that VAE learned concepts over section headers in a semantic pattern. From the analysis and visualization of VAE, we found that the VAE models were capable of learning a manifold in the section header embeddings. This manifold can be used for computing semantically similar concepts in our ontology.</p>
</div>
<div id="S5.SS2.SSS1.p2" class="ltx_para">
<p id="S5.SS2.SSS1.p2.1" class="ltx_p">Figure <a href="#S5.F5.sf3" title="In Figure 5 ‚Ä£ 5.2 Experiments on the arXiv Dataset ‚Ä£ 5 Experiments and Results ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(c)</span></a> shows the clustering visualization of the embedding matrix generated by the CAE. After analyzing the cluster visualization, we observed that CAE models were not as good as VAE models. We also noticed that CAE models were not capable of learning a manifold in our dataset.</p>
</div>
<figure id="S5.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/1807.09842/assets/figures/vae_20_val_loss.png" id="S5.F6.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="250" height="100" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F6.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F6.sf1.3.2" class="ltx_text" style="font-size:90%;">For VAE </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/1807.09842/assets/figures/cae_val_loss.png" id="S5.F6.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="250" height="100" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F6.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F6.sf2.3.2" class="ltx_text" style="font-size:90%;">For CAE </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S5.F6.3.2" class="ltx_text" style="font-size:90%;">Validation loss </span></figcaption>
</figure>
<div id="S5.SS2.SSS1.p3" class="ltx_para">
<p id="S5.SS2.SSS1.p3.4" class="ltx_p">We achieved the best validation loss of <math id="S5.SS2.SSS1.p3.1.m1.1" class="ltx_Math" alttext="0.0947" display="inline"><semantics id="S5.SS2.SSS1.p3.1.m1.1a"><mn id="S5.SS2.SSS1.p3.1.m1.1.1" xref="S5.SS2.SSS1.p3.1.m1.1.1.cmml">0.0947</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p3.1.m1.1b"><cn type="float" id="S5.SS2.SSS1.p3.1.m1.1.1.cmml" xref="S5.SS2.SSS1.p3.1.m1.1.1">0.0947</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p3.1.m1.1c">0.0947</annotation></semantics></math> for the VAE model and <math id="S5.SS2.SSS1.p3.2.m2.1" class="ltx_Math" alttext="0.1574" display="inline"><semantics id="S5.SS2.SSS1.p3.2.m2.1a"><mn id="S5.SS2.SSS1.p3.2.m2.1.1" xref="S5.SS2.SSS1.p3.2.m2.1.1.cmml">0.1574</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p3.2.m2.1b"><cn type="float" id="S5.SS2.SSS1.p3.2.m2.1.1.cmml" xref="S5.SS2.SSS1.p3.2.m2.1.1">0.1574</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p3.2.m2.1c">0.1574</annotation></semantics></math> for the CAE model. Figures <a href="#S5.F6.sf1" title="In Figure 6 ‚Ä£ 5.2.1 Results and Evaluation ‚Ä£ 5.2 Experiments on the arXiv Dataset ‚Ä£ 5 Experiments and Results ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a> and <a href="#S5.F6.sf2" title="In Figure 6 ‚Ä£ 5.2.1 Results and Evaluation ‚Ä£ 5.2 Experiments on the arXiv Dataset ‚Ä£ 5 Experiments and Results ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a> show the validation losses over number of epochs for the VAE and CAE models, respectively. After analyzing these losses, we observed that VAE loss was steady after <math id="S5.SS2.SSS1.p3.3.m3.1" class="ltx_Math" alttext="600" display="inline"><semantics id="S5.SS2.SSS1.p3.3.m3.1a"><mn id="S5.SS2.SSS1.p3.3.m3.1.1" xref="S5.SS2.SSS1.p3.3.m3.1.1.cmml">600</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p3.3.m3.1b"><cn type="integer" id="S5.SS2.SSS1.p3.3.m3.1.1.cmml" xref="S5.SS2.SSS1.p3.3.m3.1.1">600</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p3.3.m3.1c">600</annotation></semantics></math> epochs but that the CAE loss was oscillating after <math id="S5.SS2.SSS1.p3.4.m4.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S5.SS2.SSS1.p3.4.m4.1a"><mn id="S5.SS2.SSS1.p3.4.m4.1.1" xref="S5.SS2.SSS1.p3.4.m4.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p3.4.m4.1b"><cn type="integer" id="S5.SS2.SSS1.p3.4.m4.1.1.cmml" xref="S5.SS2.SSS1.p3.4.m4.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p3.4.m4.1c">20</annotation></semantics></math> epochs. This suggests that the VAE model performs better than the CAE model for our dataset. Since we achieved a better performance for VAE architecture on our dataset, we also trained VAE models for section headers from Computer Science articles, achieving performance metrics similar to those for all <span id="S5.SS2.SSS1.p3.4.1" class="ltx_text ltx_font_italic">arXiv</span> articles.</p>
</div>
</section>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Experiment on RFP Dataset</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">We leveraged our existing collaboration with RedShred <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> to get a wide range of RFPs for our experiments. We trained VAE models for section headers from RFP documents. Due to a fewer number of section headers collected from RFP documents, we obtained different patterns, where most of the section headers were scattered all over the embedding space. Figure <a href="#S5.F5.sf4" title="In Figure 5 ‚Ä£ 5.2 Experiments on the arXiv Dataset ‚Ä£ 5 Experiments and Results ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(d)</span></a> shows the embedding visualization for RFP documents. It is interesting to notice that the VAE models for the RFP dataset are also capable of learning manifold, which can be used for calculating similar concepts.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T2.2.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S5.T2.3.2" class="ltx_text" style="font-size:90%;">Comparative analysis of LDA models for semantic concepts</span></figcaption>
<div id="S5.T2.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:218.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-95.8pt,48.3pt) scale(0.693605873482533,0.693605873482533) ;">
<table id="S5.T2.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.4.1.1.1" class="ltx_tr">
<th id="S5.T2.4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S5.T2.4.1.1.1.1.1" class="ltx_text ltx_font_bold">arXiv Category</span></th>
<th id="S5.T2.4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S5.T2.4.1.1.1.2.1" class="ltx_text ltx_font_bold">Word based LDA</span></th>
<th id="S5.T2.4.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S5.T2.4.1.1.1.3.1" class="ltx_text ltx_font_bold">Bigram based LDA</span></th>
<th id="S5.T2.4.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S5.T2.4.1.1.1.4.1" class="ltx_text ltx_font_bold">Phrase based LDA</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.4.1.2.1" class="ltx_tr">
<td id="S5.T2.4.1.2.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.2.1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.2.1.1.1.1" class="ltx_tr">
<td id="S5.T2.4.1.2.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S5.T2.4.1.2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Mathematics - Algebraic Topology,</span></td>
</tr>
<tr id="S5.T2.4.1.2.1.1.1.2" class="ltx_tr">
<td id="S5.T2.4.1.2.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S5.T2.4.1.2.1.1.1.2.1.1" class="ltx_text ltx_font_bold">Mathematics - Combinatorics</span></td>
</tr>
</table>
</td>
<td id="S5.T2.4.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.2.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.2.1.2.1.1" class="ltx_tr">
<td id="S5.T2.4.1.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">algebra, lie, maps,</td>
</tr>
<tr id="S5.T2.4.1.2.1.2.1.2" class="ltx_tr">
<td id="S5.T2.4.1.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">element and metric</td>
</tr>
</table>
</td>
<td id="S5.T2.4.1.2.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.2.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.2.1.3.1.1" class="ltx_tr">
<td id="S5.T2.4.1.2.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">half plane, complex plane,</td>
</tr>
<tr id="S5.T2.4.1.2.1.3.1.2" class="ltx_tr">
<td id="S5.T2.4.1.2.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">real axis, rational functions</td>
</tr>
<tr id="S5.T2.4.1.2.1.3.1.3" class="ltx_tr">
<td id="S5.T2.4.1.2.1.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">and unit disk</td>
</tr>
</table>
</td>
<td id="S5.T2.4.1.2.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.2.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.2.1.4.1.1" class="ltx_tr">
<td id="S5.T2.4.1.2.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">recent, paper is, theoretical,</td>
</tr>
<tr id="S5.T2.4.1.2.1.4.1.2" class="ltx_tr">
<td id="S5.T2.4.1.2.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">framework, and developed</td>
</tr>
</table>
</td>
</tr>
<tr id="S5.T2.4.1.3.2" class="ltx_tr">
<td id="S5.T2.4.1.3.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S5.T2.4.1.3.2.1.1" class="ltx_text ltx_font_bold">Nuclear Theory</span></td>
<td id="S5.T2.4.1.3.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.3.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.3.2.2.1.1" class="ltx_tr">
<td id="S5.T2.4.1.3.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">phase, spin, magnetic,</td>
</tr>
<tr id="S5.T2.4.1.3.2.2.1.2" class="ltx_tr">
<td id="S5.T2.4.1.3.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">particle and momentum</td>
</tr>
</table>
</td>
<td id="S5.T2.4.1.3.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.3.2.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.3.2.3.1.1" class="ltx_tr">
<td id="S5.T2.4.1.3.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">form factor, matrix elements,</td>
</tr>
<tr id="S5.T2.4.1.3.2.3.1.2" class="ltx_tr">
<td id="S5.T2.4.1.3.2.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">heavy ion, transverse</td>
</tr>
<tr id="S5.T2.4.1.3.2.3.1.3" class="ltx_tr">
<td id="S5.T2.4.1.3.2.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">momentum and u‚Äôenergy loss</td>
</tr>
</table>
</td>
<td id="S5.T2.4.1.3.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.3.2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.3.2.4.1.1" class="ltx_tr">
<td id="S5.T2.4.1.3.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">scattering, quark, momentum,</td>
</tr>
<tr id="S5.T2.4.1.3.2.4.1.2" class="ltx_tr">
<td id="S5.T2.4.1.3.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">neutron move and gcd</td>
</tr>
</table>
</td>
</tr>
<tr id="S5.T2.4.1.4.3" class="ltx_tr">
<td id="S5.T2.4.1.4.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.4.3.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.4.3.1.1.1" class="ltx_tr">
<td id="S5.T2.4.1.4.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S5.T2.4.1.4.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Computer Science - Computer Vision</span></td>
</tr>
<tr id="S5.T2.4.1.4.3.1.1.2" class="ltx_tr">
<td id="S5.T2.4.1.4.3.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S5.T2.4.1.4.3.1.1.2.1.1" class="ltx_text ltx_font_bold">and Pattern Recognition</span></td>
</tr>
</table>
</td>
<td id="S5.T2.4.1.4.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.4.3.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.4.3.2.1.1" class="ltx_tr">
<td id="S5.T2.4.1.4.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">network, performance,</td>
</tr>
<tr id="S5.T2.4.1.4.3.2.1.2" class="ltx_tr">
<td id="S5.T2.4.1.4.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">error, channel and average</td>
</tr>
</table>
</td>
<td id="S5.T2.4.1.4.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.4.3.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.4.3.3.1.1" class="ltx_tr">
<td id="S5.T2.4.1.4.3.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">neural networks, machine</td>
</tr>
<tr id="S5.T2.4.1.4.3.3.1.2" class="ltx_tr">
<td id="S5.T2.4.1.4.3.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">learning, loss function,</td>
</tr>
<tr id="S5.T2.4.1.4.3.3.1.3" class="ltx_tr">
<td id="S5.T2.4.1.4.3.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">training data and deep learning</td>
</tr>
</table>
</td>
<td id="S5.T2.4.1.4.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.4.3.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.4.3.4.1.1" class="ltx_tr">
<td id="S5.T2.4.1.4.3.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">learning, deep, layers, image</td>
</tr>
<tr id="S5.T2.4.1.4.3.4.1.2" class="ltx_tr">
<td id="S5.T2.4.1.4.3.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">and machine learning</td>
</tr>
</table>
</td>
</tr>
<tr id="S5.T2.4.1.5.4" class="ltx_tr">
<td id="S5.T2.4.1.5.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S5.T2.4.1.5.4.1.1" class="ltx_text ltx_font_bold">Mathematical Physics</span></td>
<td id="S5.T2.4.1.5.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.5.4.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.5.4.2.1.1" class="ltx_tr">
<td id="S5.T2.4.1.5.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">quantum, entropy,</td>
</tr>
<tr id="S5.T2.4.1.5.4.2.1.2" class="ltx_tr">
<td id="S5.T2.4.1.5.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">asymptotic, boundary and</td>
</tr>
<tr id="S5.T2.4.1.5.4.2.1.3" class="ltx_tr">
<td id="S5.T2.4.1.5.4.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">classical</td>
</tr>
</table>
</td>
<td id="S5.T2.4.1.5.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.5.4.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.5.4.3.1.1" class="ltx_tr">
<td id="S5.T2.4.1.5.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">dx dx, initial data, unique</td>
</tr>
<tr id="S5.T2.4.1.5.4.3.1.2" class="ltx_tr">
<td id="S5.T2.4.1.5.4.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">solution, positive constant</td>
</tr>
<tr id="S5.T2.4.1.5.4.3.1.3" class="ltx_tr">
<td id="S5.T2.4.1.5.4.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">and uniformly bounded</td>
</tr>
</table>
</td>
<td id="S5.T2.4.1.5.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.5.4.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.5.4.4.1.1" class="ltx_tr">
<td id="S5.T2.4.1.5.4.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">stochastic, the process of,</td>
</tr>
<tr id="S5.T2.4.1.5.4.4.1.2" class="ltx_tr">
<td id="S5.T2.4.1.5.4.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">convergence rate, diffusion</td>
</tr>
<tr id="S5.T2.4.1.5.4.4.1.3" class="ltx_tr">
<td id="S5.T2.4.1.5.4.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">rate and walk</td>
</tr>
</table>
</td>
</tr>
<tr id="S5.T2.4.1.6.5" class="ltx_tr">
<td id="S5.T2.4.1.6.5.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.6.5.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.6.5.1.1.1" class="ltx_tr">
<td id="S5.T2.4.1.6.5.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S5.T2.4.1.6.5.1.1.1.1.1" class="ltx_text ltx_font_bold">Astrophysics - Solar and</span></td>
</tr>
<tr id="S5.T2.4.1.6.5.1.1.2" class="ltx_tr">
<td id="S5.T2.4.1.6.5.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S5.T2.4.1.6.5.1.1.2.1.1" class="ltx_text ltx_font_bold">Stellar Astrophysics</span></td>
</tr>
</table>
</td>
<td id="S5.T2.4.1.6.5.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.6.5.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.6.5.2.1.1" class="ltx_tr">
<td id="S5.T2.4.1.6.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">stars, emission,</td>
</tr>
<tr id="S5.T2.4.1.6.5.2.1.2" class="ltx_tr">
<td id="S5.T2.4.1.6.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">gas, stellar and velocity</td>
</tr>
</table>
</td>
<td id="S5.T2.4.1.6.5.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.6.5.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.6.5.3.1.1" class="ltx_tr">
<td id="S5.T2.4.1.6.5.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">active region, flux rope,</td>
</tr>
<tr id="S5.T2.4.1.6.5.3.1.2" class="ltx_tr">
<td id="S5.T2.4.1.6.5.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">magnetic reconnection,</td>
</tr>
<tr id="S5.T2.4.1.6.5.3.1.3" class="ltx_tr">
<td id="S5.T2.4.1.6.5.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">model set and solar cycle</td>
</tr>
</table>
</td>
<td id="S5.T2.4.1.6.5.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.6.5.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.6.5.4.1.1" class="ltx_tr">
<td id="S5.T2.4.1.6.5.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">magnetic ray, the magnetic,</td>
</tr>
<tr id="S5.T2.4.1.6.5.4.1.2" class="ltx_tr">
<td id="S5.T2.4.1.6.5.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">plasma, shock and rays</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Domain Specific Semantic Concepts using LDA</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.5" class="ltx_p">As described in section <a href="#S4" title="4 System Architecture and Technical Approach ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we trained an LDA model using the divided sections generated from <span id="S6.p1.5.1" class="ltx_text ltx_font_italic">arXiv</span> articles by the system developed in our earlier work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. The total number of training and test sections for the LDA were <math id="S6.p1.1.m1.2" class="ltx_Math" alttext="128,505" display="inline"><semantics id="S6.p1.1.m1.2a"><mrow id="S6.p1.1.m1.2.3.2" xref="S6.p1.1.m1.2.3.1.cmml"><mn id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml">128</mn><mo id="S6.p1.1.m1.2.3.2.1" xref="S6.p1.1.m1.2.3.1.cmml">,</mo><mn id="S6.p1.1.m1.2.2" xref="S6.p1.1.m1.2.2.cmml">505</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.2b"><list id="S6.p1.1.m1.2.3.1.cmml" xref="S6.p1.1.m1.2.3.2"><cn type="integer" id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1">128</cn><cn type="integer" id="S6.p1.1.m1.2.2.cmml" xref="S6.p1.1.m1.2.2">505</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.2c">128,505</annotation></semantics></math> and <math id="S6.p1.2.m2.2" class="ltx_Math" alttext="11,633" display="inline"><semantics id="S6.p1.2.m2.2a"><mrow id="S6.p1.2.m2.2.3.2" xref="S6.p1.2.m2.2.3.1.cmml"><mn id="S6.p1.2.m2.1.1" xref="S6.p1.2.m2.1.1.cmml">11</mn><mo id="S6.p1.2.m2.2.3.2.1" xref="S6.p1.2.m2.2.3.1.cmml">,</mo><mn id="S6.p1.2.m2.2.2" xref="S6.p1.2.m2.2.2.cmml">633</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.p1.2.m2.2b"><list id="S6.p1.2.m2.2.3.1.cmml" xref="S6.p1.2.m2.2.3.2"><cn type="integer" id="S6.p1.2.m2.1.1.cmml" xref="S6.p1.2.m2.1.1">11</cn><cn type="integer" id="S6.p1.2.m2.2.2.cmml" xref="S6.p1.2.m2.2.2">633</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.2.m2.2c">11,633</annotation></semantics></math>, respectively. We applied different experimental approaches using word, phrase and bigram dictionaries. The word-based dictionary contains only unigram terms whereas the bigram dictionary has only bigram terms. The phrase-based dictionary contains combination of unigram, bigram and trigram terms. All three dictionaries were developed from the training dataset by ignoring terms that appeared in less than <math id="S6.p1.3.m3.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S6.p1.3.m3.1a"><mn id="S6.p1.3.m3.1.1" xref="S6.p1.3.m3.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S6.p1.3.m3.1b"><cn type="integer" id="S6.p1.3.m3.1.1.cmml" xref="S6.p1.3.m3.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.3.m3.1c">20</annotation></semantics></math> sections or in more than <math id="S6.p1.4.m4.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="S6.p1.4.m4.1a"><mrow id="S6.p1.4.m4.1.1" xref="S6.p1.4.m4.1.1.cmml"><mn id="S6.p1.4.m4.1.1.2" xref="S6.p1.4.m4.1.1.2.cmml">10</mn><mo id="S6.p1.4.m4.1.1.1" xref="S6.p1.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.p1.4.m4.1b"><apply id="S6.p1.4.m4.1.1.cmml" xref="S6.p1.4.m4.1.1"><csymbol cd="latexml" id="S6.p1.4.m4.1.1.1.cmml" xref="S6.p1.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S6.p1.4.m4.1.1.2.cmml" xref="S6.p1.4.m4.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.4.m4.1c">10\%</annotation></semantics></math> of the sections of the whole training dataset. The final dictionary size, after filtering, was <math id="S6.p1.5.m5.2" class="ltx_Math" alttext="100,000" display="inline"><semantics id="S6.p1.5.m5.2a"><mrow id="S6.p1.5.m5.2.3.2" xref="S6.p1.5.m5.2.3.1.cmml"><mn id="S6.p1.5.m5.1.1" xref="S6.p1.5.m5.1.1.cmml">100</mn><mo id="S6.p1.5.m5.2.3.2.1" xref="S6.p1.5.m5.2.3.1.cmml">,</mo><mn id="S6.p1.5.m5.2.2" xref="S6.p1.5.m5.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.p1.5.m5.2b"><list id="S6.p1.5.m5.2.3.1.cmml" xref="S6.p1.5.m5.2.3.2"><cn type="integer" id="S6.p1.5.m5.1.1.cmml" xref="S6.p1.5.m5.1.1">100</cn><cn type="integer" id="S6.p1.5.m5.2.2.cmml" xref="S6.p1.5.m5.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.5.m5.2c">100,000</annotation></semantics></math>. Different LDA models were trained based on various number of topics and passes. We ran the trained model to identify a topic for any section, which was used to retrieve top terms with the highest probability. The terms with the highest probability were used as a domain specific semantic concepts for a section.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">For the evaluation, we loaded the trained LDA models and generated domain specific semantic concepts from <math id="S6.p2.1.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S6.p2.1.m1.1a"><mn id="S6.p2.1.m1.1.1" xref="S6.p2.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S6.p2.1.m1.1b"><cn type="integer" id="S6.p2.1.m1.1.1.cmml" xref="S6.p2.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.1.m1.1c">100</annotation></semantics></math> <span id="S6.p2.1.1" class="ltx_text ltx_font_italic">arXiv</span> abstracts, where we knew the categories of the articles. We analyzed their categories and semantic terms. We noticed a very interesting correlation between the <span id="S6.p2.1.2" class="ltx_text ltx_font_italic">arXiv</span> category and the semantic terms from LDA topic models, finding that most of the top semantic terms were strongly co-related to their original <span id="S6.p2.1.3" class="ltx_text ltx_font_italic">arXiv</span> categories. A comparative analysis is shown in Table <a href="#S5.T2" title="Table 2 ‚Ä£ 5.3 Experiment on RFP Dataset ‚Ä£ 5 Experiments and Results ‚Ä£ Understanding and representing the semantics of large structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. After analysis of the results, we noticed that a bigram LDA model was more meaningful than either of the other two models.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">Semantic annotation can be described as a technique of enhancing a document with automatic annotations that provide a human-understandable way to represent a document‚Äôs meaning. It also describes the document in such a way that the document is understandable to a machine. Using our developed ontology, we built a system to annotate a PDF document with human understandable semantic concepts from the ontology. The system, along with the research components and ontology, will be available soon<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>These will be available in summer 2018.</span></span></span>. In this research, We have presented Variational and Convolutional Autoencoders which capture general purpose semantic structure and different LDA models for domain specific semantic concept extraction from low level representation of large documents. Our approaches are able to detect semantic concepts and properties from a large number of academic and business documents in an unsupervised way.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgment</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The work was partially supported by National Science Foundation grant 1549697 and a gifts from IBM and Northrop Grumman.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Sections of an rfp (2017),
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://www.wipp.org/resource/resmgr/gm5_podcasts_rev/RFP_Help.pdf</span>,
accessed 22-October-2017

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Redshred (2018), <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.redshred.com/</span>, accessed 26-January-2018

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Angelo Di¬†Iorio, Fabio¬†Vitali, S.P.: Document structural patterns ontology
(2017), <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://www.sparontologies.net/ontologies/pattern/source.html</span>,
accessed 09-October-2017

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Blei, D.M., Ng, A.Y., Jordan, M.I.: Latent dirichlet allocation. Journal of
machine Learning research <span id="bib.bib4.1.1" class="ltx_text ltx_font_bold">3</span>(Jan), 993‚Äì1022 (2003)

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Ciccarese, P., Groza, T.: Ontology of rhetorical blocks (orb). editor‚Äôs
draft, 5 june 2011. World Wide Web Consortium. http://www. w3.
org/2001/sw/hcls/notes/orb/(last visited March 12, 2012) (2011)

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Constantin, A., Peroni, S., Pettifer, S., Shotton, D., Vitali, F.: The document
components ontology (doco). Semantic Web <span id="bib.bib6.1.1" class="ltx_text ltx_font_bold">7</span>(2), 167‚Äì181 (2016)

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
David¬†Shotton, S.P.: Discourse elements ontology(deo) (2017),
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://www.sparontologies.net/ontologies/deo/source.html</span>, accessed
09-October-2017

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Dolin, R.H., Garber, L., Solutions, I.: Hl7 implementation guide for
cda¬Æ release 2: Consolidated cda templates for clinical notes
(us realm) draft standard for trial use release 2

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Eisenstein, J., O‚ÄôConnor, B., Smith, N.A., Xing, E.P.: A latent variable model
for geographic lexical variation. In: Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Processing. pp. 1277‚Äì1287. Association
for Computational Linguistics (2010)

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Ghosh, S., Vinyals, O., Strope, B., Roy, S., Dean, T., Heck, L.: Contextual
lstm (clstm) models for large scale nlp tasks. arXiv preprint
arXiv:1602.06291 (2016)

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Hartigan, J.A., Wong, M.A.: Algorithm as 136: A k-means clustering algorithm.
Journal of the Royal Statistical Society. Series C (Applied Statistics)
<span id="bib.bib11.1.1" class="ltx_text ltx_font_bold">28</span>(1), 100‚Äì108 (1979)

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural computation
<span id="bib.bib12.1.1" class="ltx_text ltx_font_bold">9</span>(8), 1735‚Äì1780 (1997)

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Holden, D., Saito, J., Komura, T., Joyce, T.: Learning motion manifolds with
convolutional autoencoders. In: SIGGRAPH Asia 2015 Technical Briefs. p.¬†18.
ACM (2015)

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Kingma, D.P., Welling, M.: Auto-encoding variational bayes. arXiv preprint
arXiv:1312.6114 (2013)

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Lopyrev, K.: Generating news headlines with recurrent neural networks. arXiv
preprint arXiv:1512.01712 (2015)

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Maaten, L.v.d., Hinton, G.: Visualizing data using t-sne. Journal of Machine
Learning Research <span id="bib.bib16.1.1" class="ltx_text ltx_font_bold">9</span>(Nov), 2579‚Äì2605 (2008)

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Monti, D., Morisio, M.: Semantic annotation of medical documents in cda
context. In: International Conference on Information Technology in Bio-and
Medical Informatics. pp. 163‚Äì172. Springer (2016)

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Peroni, S.: The semantic publishing and referencing ontologies. In: Semantic
Web Technologies and Legal Scholarly Publishing, pp. 121‚Äì193. Springer
(2014)

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Rahman, M.M., Finin, T.: Deep understanding of a document‚Äôs structure. In:
4th IEEE/ACM Int. Conf. on Big Data Computing, Applications and Technologies
(December 2017)

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Rahman, M.M., Finin, T.: Understanding the logical and semantic structure of
large documents. arXiv preprint arXiv:1709.00770 (2017)

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Rehurek, R., Sojka, P.: Software framework for topic modelling with large
corpora. In: Proceedings of the LREC 2010 Workshop on New Challenges for NLP
Frameworks. pp. 45‚Äì50. ELRA, Valletta, Malta (2010)

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Rehurek, R., Sojka, P.: Gensim‚Äìpython framework for vector space modelling.
NLP Centre, Faculty of Informatics, Masaryk University, Brno, Czech Republic
(2011)

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Shotton, D., Peroni, S.: Doco, the document components ontology (2011)

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Sollaci, L.B., Pereira, M.G.: The introduction, methods, results, and
discussion (imrad) structure: a fifty-year survey. Journal of the medical
library association <span id="bib.bib24.1.1" class="ltx_text ltx_font_bold">92</span>(3), ¬†364 (2004)

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Srivastava, N., Salakhutdinov, R.R., Hinton, G.E.: Modeling documents with deep
boltzmann machines. arXiv preprint arXiv:1309.6865 (2013)

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Tuarob, S., Mitra, P., Giles, C.L.: A hybrid approach to discover semantic
hierarchical sections in scholarly documents. In: Document Analysis and
Recognition (ICDAR), 2015 13th International Conference on. pp. 1081‚Äì1085.
IEEE (2015)

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Turchenko, V., Chalmers, E., Luczak, A.: A deep convolutional auto-encoder with
pooling-unpooling layers in caffe. arXiv preprint arXiv:1701.04949 (2017)

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Wikipedia: Apache pdfbox ‚Äî wikipedia, the free encyclopedia (2016),
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://en.wikipedia.org/w/index.php?title=Apache_PDFBox&amp;oldid=740366251</span>,
accessed 20-September-2016

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/1807.09841" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/1807.09842" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+1807.09842">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/1807.09842" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/1807.09843" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar 16 17:08:08 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
