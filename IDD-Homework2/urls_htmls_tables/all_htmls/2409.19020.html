<!DOCTYPE html>
<html lang="en" prefix="dcterms: http://purl.org/dc/terms/">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications</title>
<!--Generated on Tue Oct 15 12:55:03 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.19020v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S1" title="In DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S2" title="In DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S2.SS1" title="In 2 Related Work ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Personality in Synthetic Data Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S2.SS2" title="In 2 Related Work ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Prompting Task-Oriented Dialogue Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S2.SS3" title="In 2 Related Work ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Existing Task-Oriented Dialogue Datasets</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S3" title="In DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>DiaSynth</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S3.SS1" title="In 3 DiaSynth ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Subtopic Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S3.SS2" title="In 3 DiaSynth ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Persona Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S3.SS3" title="In 3 DiaSynth ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Dialogue Generation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S4" title="In DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experimental Setup</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S4.SS1" title="In 4 Experimental Setup ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Quality of the dialogues</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S4.SS2" title="In 4 Experimental Setup ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Downstream Task - Summarization</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S5" title="In DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S5.SS1" title="In 5 Results ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Quality of the Dialogues</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S5.SS1.SSS1" title="In 5.1 Quality of the Dialogues ‣ 5 Results ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.1 </span>Metric Scores</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S5.SS1.SSS2" title="In 5.1 Quality of the Dialogues ‣ 5 Results ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.2 </span>Strong performance of LLaMA-3</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S5.SS2" title="In 5 Results ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Fine-tuning and Performance Results</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S6" title="In DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S7" title="In DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A1" title="In DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Hallucination Study</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A1.SS1" title="In Appendix A Hallucination Study ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>SelfCheckGPT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A1.SS2" title="In Appendix A Hallucination Study ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>ChainPoll</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A1.SS3" title="In Appendix A Hallucination Study ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Implications for DiaSynth</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A2" title="In DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Scalability of DiaSynth</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A2.SS1" title="In Appendix B Scalability of DiaSynth ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Example 1</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A2.SS2" title="In Appendix B Scalability of DiaSynth ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Example 2</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A2.SS3" title="In Appendix B Scalability of DiaSynth ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3 </span>Example 3</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A2.SS4" title="In Appendix B Scalability of DiaSynth ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.4 </span>Scaling Observations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A3" title="In DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Characteristics for the conversation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A4" title="In DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Example CoT environments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A5" title="In DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Ablation study on the use of CoT</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Sathya Krishnan Suresh<sup class="ltx_sup" id="id7.2.id1"><span class="ltx_text ltx_font_italic" id="id7.2.id1.1">1</span></sup>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Wu Mengjun<sup class="ltx_sup" id="id8.2.id1"><span class="ltx_text ltx_font_italic" id="id8.2.id1.1">1</span></sup>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Tushar Pranav<sup class="ltx_sup" id="id9.2.id1"><span class="ltx_text ltx_font_italic" id="id9.2.id1.1">2</span></sup>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Eng Siong Chng<sup class="ltx_sup" id="id10.3.id1"><span class="ltx_text ltx_font_italic" id="id10.3.id1.1">1</span></sup>
<br class="ltx_break"/><sup class="ltx_sup" id="id11.4.id2">1</sup>Nanyang Technological University
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Singapore
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<sup class="ltx_sup" id="id12.2.id1">2</sup>Singapore Institute of Technology
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Singapore 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id13.1.id1">sathyakr001@e.ntu.edu.sg, mwu016@e.ntu.edu.sg, pranav.tushar@singaporetech.edu.sg, ASESChng@ntu.edu.sg</span>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id14.id1">The scarcity of domain-specific dialogue datasets limits the development of dialogue systems across applications. Existing research is constrained by general or niche datasets that lack sufficient scale for training dialogue systems. To address this gap, we introduce <span class="ltx_text ltx_font_bold" id="id14.id1.1">DiaSynth</span> - a synthetic dialogue generation framework capable of generating high-quality, contextually rich dialogues across a wide range of domains. Unlike existing frameworks, DiaSynth uses Large Language Models (LLMs) and Chain of Thought (CoT) reasoning to generate dynamic, domain-specific dialogues with simulated personas and diverse conversational features. We perform our experiments by generating synthetic data using different LLMs and few-shot examples from DialogSum and SAMSum. The pretrained language models fine-tuned on the synthetic data outperform the base models by <span class="ltx_text ltx_font_bold" id="id14.id1.2">16.47%</span> on dialogue summarization, while the comparison between models fine-tuned on in-domain data and synthetic data shows that the synthetic data is able to capture <span class="ltx_text ltx_font_bold" id="id14.id1.3">90.48%</span> of the performance distribution of the in-domain data on dialogue summarization. The quality of the data generated also increases as we increase the size of LLM from 3B to 8B. These results validate DiaSynth’s potential as a robust alternative to traditional data collection methods. We open source the code and data generated for future research.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="313" id="S1.F1.g1" src="extracted/5928586/diasynth.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of DiaSynth</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Dialogue systems are crucial in natural language processing due to applications like customer service chatbots and virtual assistants. Their effectiveness depends on large, high-quality, domain-specific datasets. The lack of large-scale, high-quality datasets across domains like academic discussions, healthcare, and everyday conversations poses a challenge. This scarcity limits the development of dialogue systems that generalize well across domains.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Prior work (<cite class="ltx_cite ltx_citemacro_citet">Feng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib1" title="">2020</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Zeng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib2" title="">2020</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Budzianowski et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib3" title="">2018</a>)</cite>) collects domain-specific dialogues but often lacks depth, scale, or domain diversity. On the one hand, the conversations in a domain specific dataset are superficial and do not go deep into the domain. On the other hand, niche domain dialogue datasets, while contextually rich, often suffer from limited scale. This imbalance hinders dialogue system development in underrepresented domains, where data collection is costly and complex.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To address these problems, we introduce <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">DiaSynth</span>, a synthetic dialogue generation framework that produces contextually rich and realistic dialogues tailored to specific domains. DiaSynth, using a Large Language Model (LLM), generates high-quality conversations by simulating personas and conversation characteristics like tone and formality. With LLMs and Chain of Thoughts (CoT) <cite class="ltx_cite ltx_citemacro_citet">Wei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib4" title="">2024</a>)</cite>, DiaSynth generates dialogues that mimic real-world conversations for a wide range of domains. CoT plays a crucial part by building different environments for different personas (refer to Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A4" title="Appendix D Example CoT environments ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">D</span></a> for examples) which influence varied conversations. This approach addresses data scarcity and offers a scalable, cost-effective alternative to traditional methods.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">To validate the effectiveness of DiaSynth, we evaluated the framework on two criteria: the quality of the generated data and the usability of this data for downstream tasks. The results for the quality criterion showed that the data quality improved with the scale of the model. For usability, we tested DiaSynth on dialogue summarization. Models fine-tuned on DiaSynth data outperformed base versions by <span class="ltx_text ltx_font_bold" id="S1.p4.1.1">16.47%</span> on average. Additionally, DiaSynth’s synthetic data captures <span class="ltx_text ltx_font_bold" id="S1.p4.1.2">90.48%</span> of in-domain performance, highlighting its potential as a strong alternative when domain-specific data is unavailable.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">The remainder of this paper is organized as follows: Section <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S2" title="2 Related Work ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">2</span></a> reviews related work on dialogue datasets and synthetic data. Section <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S3" title="3 DiaSynth ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">3</span></a> details the DiaSynth framework and methodology. Section <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S4" title="4 Experimental Setup ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">4</span></a> describes our experimental setup and evaluation. Section <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S5" title="5 Results ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">5</span></a> compares the performance of models fine-tuned on DiaSynth data to in-domain data. Section <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S6" title="6 Conclusion ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">6</span></a> concludes with a summary of our findings and Section <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S7" title="7 Limitations ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">7</span></a> discusses the limitations of DiaSynth and potential future directions for this research.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Personality in Synthetic Data Generation</h3>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">In recent years, there has been a significant increase in research focused on synthetic dialogue generation, largely driven by advancements in Large Language Models (LLMs). To generate <span class="ltx_text ltx_font_bold" id="S2.SS1.p1.1.1">realistic and diverse</span> synthetic data, researchers have incorporated personalities, profiles, and character information when prompting LLMs to generate dialogues <cite class="ltx_cite ltx_citemacro_citet">Han et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib5" title="">2024</a>)</cite>. By enhancing dialogue realism through the simulation of various personality profiles, utilizing the Big Five personality model, and employing structured prompts, this approach has improved task performance in models fine-tuned on these generated dialogues compared to those trained on general chit-chat datasets.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Moreover, integrating personas into synthetic data generation prompts <cite class="ltx_cite ltx_citemacro_citet">Chan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib6" title="">2024</a>)</cite> has demonstrated that models fine-tuned on personalized synthetic data outperform some LLMs of much larger scales. The inclusion of personas in prompts provides diversity in difficulty levels and ranges within the synthetic data, enabling the models to handle situations of varying complexity.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">Our approach involves persona extraction after generating subtopics related to the general topics. This enables the generated dialogues to be more in-depth and specific to those subtopics, enhancing both the scale and quality of domain-specific dialogue generation.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Prompting Task-Oriented Dialogue Generation</h3>
<figure class="ltx_table" id="S2.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S2.T1.1" style="width:433.6pt;height:111.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-97.7pt,25.2pt) scale(0.689363571766177,0.689363571766177) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T1.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S2.T1.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S2.T1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.1.1">LLM</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S2.T1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.2.1">Few-shot examples</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S2.T1.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.3.1">Number of Samples</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.4.1">Avg. number of turns</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.5.1">Avg. number of tokens per turn</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.6.1">Diversity (ROUGE-L)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T1.1.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S2.T1.1.1.2.1.1">Phi-3</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S2.T1.1.1.2.1.2">DialogSum</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S2.T1.1.1.2.1.3">1215</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.1.2.1.4">9.13</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.1.2.1.5">20.38</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.1.2.1.6">0.27</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.3.2.1">InternLM-2.5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.3.2.2">DialogSum</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.3.2.3">1035</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.3.2.4">9.23</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.3.2.5">27.98</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.3.2.6">0.30</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.4.3.1">LLaMA-3</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.4.3.2">DialogSum</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.4.3.3">1154</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.4.3.4">6.86</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.4.3.5">31.99</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.4.3.6">0.29</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.5.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.5.4.1">GPT-4o</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.5.4.2">DialogSum</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.5.4.3">1375</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.5.4.4">15.16</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.5.4.5">15.96</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.5.4.6">0.29</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.6.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.6.5.1">Phi-3</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.6.5.2">SAMSum</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.6.5.3">1410</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.6.5.4">13.98</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.6.5.5">13.94</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.6.5.6">0.27</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.7.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.7.6.1">InternLM-2.5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.7.6.2">SAMSum</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.7.6.3">1135</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.7.6.4">13.96</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.7.6.5">19.07</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.7.6.6">0.29</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.8.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.8.7.1">LLaMA-3</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.8.7.2">SAMSum</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.8.7.3">1195</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.8.7.4">10.54</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.8.7.5">20.41</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.8.7.6">0.29</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.9.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S2.T1.1.1.9.8.1">GPT-4o</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S2.T1.1.1.9.8.2">SAMSum</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S2.T1.1.1.9.8.3">1380</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.1.1.9.8.4">15.43</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.1.1.9.8.5">13.53</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.1.1.9.8.6">0.28</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Data Statistics</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Prompt-based techniques have also emerged as powerful methods for generating high-quality synthetic dialogues, particularly for task-oriented dialogue systems. <cite class="ltx_cite ltx_citemacro_citet">Steindl et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib7" title="">2023</a>)</cite> explore the generation of synthetic dialogues from structured prompts, focusing on enhancing task-oriented dialogue systems. Their work demonstrates that prompt engineering can produce dialogues that are contextually appropriate and improve system performance by aligning synthetic data more closely with real-world requirements.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">To achieve a <span class="ltx_text ltx_font_bold" id="S2.SS2.p2.1.1">higher quantity, diversity, and creativity</span> in human-written instruction data, <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib8" title="">2022</a>)</cite> propose inputting prompts to LLMs to generate instructions based on a small set of seed human-written instructions. This approach aligns the expanded training data more closely with desired task objectives and allows for iterative improvements, producing more nuanced and effective dialogues that meet specific task demands.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">Similarly, our study expands topics into subtopics, ensuring that the generated dialogues provide more in-depth and high-quality conversations. By doing so, we aim to produce synthetic data that not only covers a broader range of scenarios but also delves deeper into each topic, thereby enhancing the overall effectiveness of the dialogue systems trained on this data.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Existing Task-Oriented Dialogue Datasets</h3>
<div class="ltx_para ltx_noindent" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">In addition to prompt-based synthetic data generation, various large-scale dialogue datasets have been instrumental in advancing task-oriented dialogue systems. Among these, the MultiWOZ dataset <cite class="ltx_cite ltx_citemacro_citet">Budzianowski et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib3" title="">2018</a>)</cite> is a prominent resource, providing richly annotated dialogues across multiple domains. MultiWOZ has enabled researchers to train models capable of handling complex, multi-turn interactions across diverse tasks. The nature of MultiWOZ’s annotations has made it a benchmark for evaluating the performance of dialogue systems, though it is often complemented by synthetic data to introduce further diversity and variation in dialogue scenarios.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">Similarly, Doc2Dial <cite class="ltx_cite ltx_citemacro_citet">Feng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib1" title="">2020</a>)</cite> is another widely used dataset designed specifically for document-grounded dialogue systems. Doc2Dial includes conversations grounded in structured documents, focusing on providing users with accurate and relevant information based on their inquiries. This dataset has been instrumental in improving the ability of dialogue systems to retrieve and generate accurate responses when interacting with complex information sources. However, much like MultiWOZ, Doc2Dial’s scope is limited to the predefined topics and domains covered within the dataset, which can restrict model generalizability to new or unseen situations.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1">To overcome the domain-specific limitations of datasets, our study adopts a synthetic data generation approach that expands existing topics into subtopics, thus providing a broader and deeper pool of conversational data. By incorporating both task-oriented prompts and personas, our generated dialogues aim to complement these datasets by offering more personalized and contextually rich conversations, thereby enhancing the robustness and versatility of dialogue systems</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>DiaSynth</h2>
<figure class="ltx_table" id="S3.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T2.1" style="width:433.6pt;height:141.5pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-88.1pt,28.6pt) scale(0.711110412677819,0.711110412677819) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T2.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S3.T2.1.1.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.2.1">coherent</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.3.1">error recovery</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.4.1">consistent</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.5.1">diverse</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.6.1">depth</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.7.1">likeable</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.8.1">understand</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.1.9"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.9.1">flexible</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.1.10"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.10.1">informative</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.1.11"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.11.1">inquisitive</span></th>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" colspan="11" id="S3.T2.1.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.2.2.1.1">DIALOGUESUM</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T2.1.1.3.1.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.3.1.1.1">Phi-3</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.3.1.2">0.9536</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.3.1.3">0.9440</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.3.1.4">0.9540</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.3.1.5">0.9534</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.3.1.6">0.9521</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.3.1.7">-0.0005</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.3.1.8">0.9353</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.3.1.9"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.3.1.9.1">-3.96E-05</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.3.1.10">0.0009</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.3.1.11">-0.0033</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.1.1.4.2.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.4.2.1.1">InternLM-2.5</span></th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.2.2">0.8439</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.2.3">0.8313</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.2.4">0.8359</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.2.5">0.8353</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.2.6">0.8352</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.2.7">0.0048</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.2.8">0.8278</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.2.9">-0.0046</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.2.10">0.0042</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.2.11">0.0069</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.1.1.5.3.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.5.3.1.1">LLaMA-3</span></th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.5.3.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.5.3.2.1">0.9684</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.5.3.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.5.3.3.1">0.9522</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.5.3.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.5.3.4.1">0.9570</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.5.3.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.5.3.5.1">0.9596</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.5.3.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.5.3.6.1">0.9592</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.5.3.7">0.0032</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.5.3.8"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.5.3.8.1">0.9453</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.5.3.9">-0.0063</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.5.3.10">0.0063</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.5.3.11">0.0105</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.1.1.6.4.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.6.4.1.1">GPT-4o</span></th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.6.4.2">0.9525</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.6.4.3">0.9407</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.6.4.4">0.9417</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.6.4.5">0.9423</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.6.4.6">0.9425</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.6.4.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.6.4.7.1">0.0121</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.6.4.8">0.9368</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.6.4.9">-0.0027</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.6.4.10"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.6.4.10.1">0.0085</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.6.4.11"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.6.4.11.1">0.0144</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.7.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="11" id="S3.T2.1.1.7.5.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.7.5.1.1">SAMSUM</span></th>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T2.1.1.8.6.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.8.6.1.1">Phi-3</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.8.6.2">0.9161</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.8.6.3">0.9088</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.8.6.4">0.9199</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.8.6.5">0.9161</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.8.6.6">0.9130</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.8.6.7">-0.0004</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.8.6.8">0.9014</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.8.6.9">-0.0024</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.8.6.10">0.0034</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.8.6.11">-0.0040</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.9.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.1.1.9.7.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.9.7.1.1">InternLM-2.5</span></th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.9.7.2">0.8746</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.9.7.3">0.8647</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.9.7.4">0.8734</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.9.7.5">0.8655</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.9.7.6">0.8661</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.9.7.7">0.0033</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.9.7.8">0.8582</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.9.7.9">-0.0019</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.9.7.10">0.0106</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.9.7.11">0.0028</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.10.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.1.1.10.8.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.10.8.1.1">LLaMA-3</span></th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.10.8.2">0.9829</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.10.8.3">0.9677</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.10.8.4">0.9757</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.10.8.5">0.9712</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.10.8.6">0.9731</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.10.8.7">0.0003</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.10.8.8">0.9593</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.10.8.9">-0.0048</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.10.8.10">0.0100</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.10.8.11">0.0029</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.11.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T2.1.1.11.9.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.11.9.1.1">GPT-4o</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.11.9.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.11.9.2.1">0.9939</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.11.9.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.11.9.3.1">0.9876</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.11.9.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.11.9.4.1">0.9878</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.11.9.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.11.9.5.1">0.9836</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.11.9.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.11.9.6.1">0.9824</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.11.9.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.11.9.7.1">0.0083</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.11.9.8"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.11.9.8.1">0.9788</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.11.9.9"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.11.9.9.1">0.0004</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.11.9.10"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.11.9.10.1">0.0141</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.11.9.11"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.11.9.11.1">0.006</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>FED scores</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">DiaSynth is a synthetic dialogue generation framework designed to address the scarcity of high-quality, large-scale, domain-specific dialogue datasets. DiaSynth uses an LLM and CoT reasoning to simulate diverse, nuanced dialogues.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p2">
<p class="ltx_p" id="S3.p2.3">DiaSynth takes a list of user-provided topics to generate dialogues. The users can optionally provide few-shot examples of the format in which they want the dialogue to be generated. Directly generating dialogues from user topics would be too superficial due to their lack of specificity. To overcome this lack of specificity, we generate <math alttext="m" class="ltx_Math" display="inline" id="S3.p2.1.m1.1"><semantics id="S3.p2.1.m1.1a"><mi id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.p2.1.m1.1d">italic_m</annotation></semantics></math> sub topics for each of the <math alttext="n" class="ltx_Math" display="inline" id="S3.p2.2.m2.1"><semantics id="S3.p2.2.m2.1a"><mi id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><ci id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.p2.2.m2.1d">italic_n</annotation></semantics></math> topics given by the user. Generating dialogues from the subtopics will have specificity but the dialogues will lack variety. This is because every dialogue is influenced implicitly by the personas of the people involved in the dialogue and, other characteristics such as the location, emotion and more. To enhance variety and depth, we generate <math alttext="p" class="ltx_Math" display="inline" id="S3.p2.3.m3.1"><semantics id="S3.p2.3.m3.1a"><mi id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b"><ci id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">p</annotation><annotation encoding="application/x-llamapun" id="S3.p2.3.m3.1d">italic_p</annotation></semantics></math> personas per subtopic and create dialogues for all persona-subtopic combinations. To further ground the dialogues in various settings and characteristics, we employ CoT reasoning during the generation process. DiaSynth employs CoT to reason about the settings and characteristics of a dialogue, which are listed in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A3" title="Appendix C Characteristics for the conversation ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">C</span></a>, ensuring that the dialogues are contextually rich and realistic. This three-stage pipeline not only guarantees the quality of the generated dialogues but also allows for exponential scalability, as illustrated programmatically in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A2" title="Appendix B Scalability of DiaSynth ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Subtopic Generation</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Subtopic generation is a crucial step in DiaSynth’s pipeline, since it enhances the specificity and depth of the dialogues that will be generated later. For each primary topic given by the user, DiaSynth generates multiple subtopics, effectively narrowing the focus of the conversation. This breakdown is necessary because the primary topics are often too general to generate contextually rich dialogues on their own. For instance, a topic like “healthcare” can be expanded into subtopics such as “doctor-patient consultations,” “mental health discussions,” and “medical diagnostics,” each of which offers a more focused context for dialogue generation. To achieve this, DiaSynth prompts an LLM to generate the user specified number of subtopics for each primary topic. We also run a similarity check between each of the subtopics and remove subtopics that are too similar to other subtopics using a threshold.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Persona Generation</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Personas of the individuals involved in a conversation are primary influencers in determining how a conversation pans out. Using random personas from persona datasets and prompting the LLM to simulate a dialogue between them about a random topic often leads to superficial dialogues that lack depth and contextual richness. To address this issue, DiaSynth generates a user-specified number of personas for each subtopic, ensuring that the personas are conditioned on the subtopic context. This conditioning prompts the LLM to create personas that are most likely to engage in a meaningful dialogue about the subtopic, such as a medical professional and a patient discussing "medical diagnostics" or a researcher and a student talking about "academic publishing." We also run a similarity check for the personas too. The conditioned persona generation is crucial because it ensures that future dialogues will not only be contextually rich but also exhibit a high level of depth. Each dialogue will be between two personas who have relevant expertise or perspectives on the given subtopic, allowing the conversation to explore nuances that would otherwise be missed in a generic dialogue setting.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Dialogue Generation</h3>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">The final stage in DiaSynth’s pipeline is the generation of dialogues, where all the components—subtopics, personas, and characteristics—converge to create contextually rich and realistic conversations. This step uses an LLM as the backbone and CoT as the reasoning mechanism, allowing the model to simulate dialogues that incorporate various aspects of human interaction. DiaSynth generates dialogues by pairing all persona-subtopic combinations. The process also integrates predefined characteristics (Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A3.T11" title="Table 11 ‣ Appendix C Characteristics for the conversation ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">11</span></a>) like emotional state, formality, and familiarity to guide the flow and style. These characteristics are defined in the CoT prompt, guiding the LLM to generate realistic, contextually appropriate dialogues. The importance of CoT and the lack of it affects the quality of the dialogues, which is shown quantitatively in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A5" title="Appendix E Ablation study on the use of CoT ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">E</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Setup</h2>
<figure class="ltx_table" id="S4.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.1" style="width:433.6pt;height:122.9pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-134.1pt,37.8pt) scale(0.617862404613372,0.617862404613372) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S4.T3.1.1.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.2.1">coherence</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.3.1">diversity</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.4.1">flexibility</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.5.1">understandability</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.6.1">inquisitiveness</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.7.1">consistency</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.8.1">informativeness</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.9"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.9.1">likeability</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.10"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.10.1">depth</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.11"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.11.1">error recovery</span></th>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" colspan="11" id="S4.T3.1.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.2.2.1.1">DIALOGUESUM</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.1.1.3.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.1.1.1">Phi-3</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.1.2.1">0.0286</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.1.3">0.0310</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.1.4"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.1.4.1">0.0218</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.1.5">0.0193</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.1.6">0.0363</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.1.7"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.1.7.1">0.0369</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.1.8">0.0172</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.1.9"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.1.9.1">0.0213</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.1.10">0.0117</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.1.11">0.0342</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.1.1.4.2.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.2.1.1">InternLM-2.5</span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.2.2">0.0069</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.2.3">0.0196</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.2.4">0.0084</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.2.5">0.0061</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.2.6">0.0244</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.2.7">0.0137</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.2.8">0.0148</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.2.9">0.0050</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.2.10">0.0080</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.2.11">0.0197</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.1.1.5.3.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.5.3.1.1">LLaMA-3</span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.3.2">0.0189</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.3.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.5.3.3.1">0.0430</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.3.4">0.0186</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.3.5"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.5.3.5.1">0.0220</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.3.6"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.5.3.6.1">0.0415</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.3.7">0.0321</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.3.8"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.5.3.8.1">0.0318</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.3.9">0.0110</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.3.10"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.5.3.10.1">0.0201</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.3.11"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.5.3.11.1">0.0440</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.1.1.6.4.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.6.4.1.1">GPT-4o</span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.4.2">0.0039</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.4.3">0.0156</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.4.4">0.0059</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.4.5">0.0039</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.4.6">0.018</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.4.7">0.0080</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.4.8">0.0097</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.4.9">0.0026</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.4.10">0.0053</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.4.11">0.0135</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.7.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="11" id="S4.T3.1.1.7.5.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.5.1.1">SAMSUM</span></th>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.1.1.8.6.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.8.6.1.1">Phi-3</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.8.6.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.8.6.2.1">0.0325</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.8.6.3">0.0372</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.8.6.4">0.0260</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.8.6.5">0.0270</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.8.6.6">0.0395</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.8.6.7">0.0415</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.8.6.8">0.0201</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.8.6.9"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.8.6.9.1">0.0232</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.8.6.10">0.0126</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.8.6.11">0.0290</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.9.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.1.1.9.7.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.9.7.1.1">InternLM-2.5</span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.7.2">0.0128</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.7.3">0.0408</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.7.4">0.0194</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.7.5">0.0174</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.7.6">0.0504</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.7.7">0.0306</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.7.8">0.0328</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.7.9">0.0142</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.7.10">0.0177</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.7.11">0.0407</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.10.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.1.1.10.8.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.10.8.1.1">LLaMA-3</span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.8.2">0.0288</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.8.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.10.8.3.1">0.0655</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.8.4"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.10.8.4.1">0.0306</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.8.5"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.10.8.5.1">0.0365</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.8.6"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.10.8.6.1">0.0622</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.8.7"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.10.8.7.1">0.0612</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.8.8"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.10.8.8.1">0.0542</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.8.9">0.0168</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.8.10"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.10.8.10.1">0.0270</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.8.11"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.10.8.11.1">0.0558</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.11.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T3.1.1.11.9.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.11.9.1.1">GPT-4o</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.11.9.2">0.0055</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.11.9.3">0.0162</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.11.9.4">0.0094</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.11.9.5">0.0084</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.11.9.6">0.0186</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.11.9.7">0.0119</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.11.9.8">0.0129</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.11.9.9">0.0038</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.11.9.10">0.0079</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.11.9.11">0.0199</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>GPTScore</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we detail the experimental setup used to evaluate the effectiveness of DiaSynth. Our evaluation focuses on two criteria - quality of the dialogues generated and usability of the dialogues generated for a downstream task. Quality of the dialogues is evaluated using metrics such as FED, GPTScore, and G-Eval. We evaluate the usability of DiaSynth-generated dialogues by using summarization as the downstream task.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Quality of the dialogues</h3>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">To evaluate the quality of the dialogues, we employ the metrics that have been developed for evaluating the quality of text generated by LLMs. We use the following metrics:</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">FED</span> <cite class="ltx_cite ltx_citemacro_citet">Mehri and Eskenazi (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib9" title="">2020</a>)</cite> - FED evaluates dialogue quality by comparing the probabilities of appended positive and negative utterances.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">GPTScore</span> <cite class="ltx_cite ltx_citemacro_citet">Fu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib10" title="">2024</a>)</cite> - GPTScore assesses dialogue quality by asking an LLM to evaluate criteria like coherence and diversity, with scores based on the probability of affirmative responses.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.1.1">G-Eval</span> <cite class="ltx_cite ltx_citemacro_citet">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib11" title="">2023</a>)</cite> - G-Eval rates dialogue on a 1-3 scale across criteria, with final scores as a weighted average from the LLM’s probability distribution.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">To validate the framework across models and also domains, we generate data using three open source LLMs, one closed source LLM and also use few shot examples from two different dialogue datasets. The open sourced LLMs are - <span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">Phi-3</span> <cite class="ltx_cite ltx_citemacro_citet">Abdin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib12" title="">2024</a>)</cite>, <span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.2">InternLM-2.5</span> <cite class="ltx_cite ltx_citemacro_citet">Cai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib13" title="">2024</a>)</cite>, <span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.3">LLaMA-3</span> <cite class="ltx_cite ltx_citemacro_citet">Dubey et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib14" title="">2024</a>)</cite> and the closed source LLM used is <span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.4">GPT-4o</span>. The 8-bit quantized versions of the open source LLMs were used for faster experimentation and generation. The two different dialogue datasets that were used as few-shot examples are DialogSum <cite class="ltx_cite ltx_citemacro_citet">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib15" title="">2021</a>)</cite> and SAMSum <cite class="ltx_cite ltx_citemacro_citet">Gliwa et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib16" title="">2019</a>)</cite></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Downstream Task - Summarization</h3>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">To evaluate the usability of the dialogues generated by DiaSynth, we choose summarization as the downstream task. Summarization, a key application of dialogue systems, aims to generate concise, contextually relevant summaries. We use three established evaluation metrics—QAGS, BERTScore, and ROUGE-L—to assess the performance of summarization models fine-tuned on DiaSynth-generated data.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.1">QAGS</span> <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib17" title="">2020</a>)</cite> - QAGS evaluates factual consistency by generating questions from the summary and comparing answers to those from the source dialogue.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i2.p1.1.1">BERTScore</span> <cite class="ltx_cite ltx_citemacro_citet">Zhang* et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib18" title="">2020</a>)</cite> - BERTScore measures semantic similarity between generated and reference summaries using contextual embeddings.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I2.i3.p1">
<p class="ltx_p" id="S4.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i3.p1.1.1">ROUGE-L</span> <cite class="ltx_cite ltx_citemacro_citet">Lin (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib19" title="">2004</a>)</cite> - ROUGE-L measures longest common subsequence (LCS) overlap between generated and reference summaries.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">We fine-tune pretrained summarization models like DistilBART, BART <cite class="ltx_cite ltx_citemacro_citet">Lewis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib20" title="">2020</a>)</cite>, T5 <cite class="ltx_cite ltx_citemacro_citet">Raffel et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib21" title="">2020</a>)</cite> and LED <cite class="ltx_cite ltx_citemacro_citet">Beltagy et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib22" title="">2020</a>)</cite>, on DiaSynth-generated dialogues and evaluate their performance using the above metrics. We evaluate the usability of DiaSynth in two key aspects: first, by assessing the performance improvement of models fine-tuned on DiaSynth-generated data compared to the pretrained models; and second, by measuring the extent to which DiaSynth-generated data reflects real-world data distribution by comparing the performance of models fine-tuned on DiaSynth data versus those fine-tuned on in-domain data.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">This section discusses the results of the data generated using DiaSynth (quality of the data and usability in downstream tasks) with different LLMs and varying few-shot examples. Specifically, we utilized Phi-3, InternLM-2.5, LLaMA-3 and GPT-4o as the LLM backbones, and the few-shot examples were sourced from DialogueSum and SAMSum datasets. These combinations allow us to evaluate the robustness and adaptability of DiaSynth across different models and few shot examples. In total, eight distinct datasets were generated using DiaSynth by pairing each LLM with the two sets of few-shot examples, resulting in all possible combinations. For each combination, DiaSynth was provided with the same 16 broad topics and tasked with generating 6 subtopics for each topic, followed by creating 6 personas for each subtopic. The statistics of the datasets generated using DiaSynth, including the number of dialogues, average number of turns, and average number of tokens per turn, are summarized in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S2.T1" title="Table 1 ‣ 2.2 Prompting Task-Oriented Dialogue Generation ‣ 2 Related Work ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">1</span></a>. All the experiments were run on a single A100 GPU with the generation time ranging from 2 hours to 4 hours.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Quality of the Dialogues</h3>
<div class="ltx_para ltx_noindent" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">The quality of the synthetic datasets produced by DiaSynth was evaluated using FED, GPTScore, and G-Eval metrics, as detailed in Tables <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S3.T2" title="Table 2 ‣ 3 DiaSynth ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">2</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S4.T3" title="Table 3 ‣ 4 Experimental Setup ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">3</span></a>, and <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S5.T4" title="Table 4 ‣ 5.1.1 Metric Scores ‣ 5.1 Quality of the Dialogues ‣ 5 Results ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">4</span></a>. The results reveal distinct variations in performance across different model and dataset configurations, reflecting the unique characteristics of each.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1 </span>Metric Scores</h4>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS1.p1">
<p class="ltx_p" id="S5.SS1.SSS1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS1.p1.1.1">FED:</span> The FED scores in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S3.T2" title="Table 2 ‣ 3 DiaSynth ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">2</span></a> show that LLaMA-3 and GPT-4o achieve almost a perfect score (+1) in most of the criteria, while Phi-3 and InternLM-2.5 also have decent performances. GPT-4o has a clear advantage when it comes to generating likeable dialogues while there is not much separation on other criteria.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS1.p2">
<p class="ltx_p" id="S5.SS1.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS1.p2.1.1">GPTScore:</span> Results illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S4.T3" title="Table 3 ‣ 4 Experimental Setup ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">3</span></a> are surprising in that GPT-4o is the worst performing model on GPTScore, which might require further research while LLaMA-3 clearly dominates the other models.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS1.p3">
<p class="ltx_p" id="S5.SS1.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS1.p3.1.1">G-Eval:</span> Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S5.T4" title="Table 4 ‣ 5.1.1 Metric Scores ‣ 5.1 Quality of the Dialogues ‣ 5 Results ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">4</span></a> highlights GPT-4o’s dominance in engagingness and naturalness with perfect scores (3.0) for DialogSum, while InternLM-2.5 stands out in coherence (2.9990) and groundedness (2.9973) for DialogSum, and coherence (2.9983) and groundedness (2.9952) for SAMSum, suggesting it maintains high factual accuracy.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS1.p4">
<p class="ltx_p" id="S5.SS1.SSS1.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS1.p4.1.1">Dataset-Specific Performance. </span>The contrasting performance of GPT-4o on the DialogSum and SAMSum datasets in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S3.T2" title="Table 2 ‣ 3 DiaSynth ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">2</span></a> can be attributed to the differing structures of the dialogues in these datasets. DialogSum consists of more formal and structured dialogues, which aligns with the typical response style of GPT-4o, leading to its stronger performance. In contrast, SAMSum contains more casual, human-like conversations, which might explain GPT-4o’s relatively poorer performance, as it may not adapt as well to the informal, spontaneous nature of such dialogues. Overall, while GPT-4o excels in natural and engaging dialogue, LLaMA-3 offers the most versatility, and InternLM-2.5 provides a strong alternative with high coherence and groundedness.</p>
</div>
<figure class="ltx_table" id="S5.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T4.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S5.T4.1.1.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.1.2.1">engagingness</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.1.3.1">naturalness</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.1.4.1">coherence</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.1.5.1">groundedness</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="5" id="S5.T4.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.2.2.1.1">DIALOGUESUM</span></th>
</tr>
<tr class="ltx_tr" id="S5.T4.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T4.1.3.3.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.3.3.1.1">Phi-3</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.3.2">2.5236</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.3.3">2.7238</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.3.4">2.6308</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.3.5">2.5557</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.4.4.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.4.4.1.1">InternLM-2.5</span></th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.4.4.2">2.9995</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.4.4.3">2.9989</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.4.4.4">2.9990</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.4.4.5">2.9973</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.5.5.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.5.5.1.1">LLaMA-3</span></th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.5.5.2">2.9987</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.5.5.3">2.9988</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.5.5.4">2.9972</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.5.5.5">2.9935</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.6.6.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.6.6.1.1">GPT-4o</span></th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.6.6.2"><span class="ltx_text ltx_font_bold" id="S5.T4.1.6.6.2.1">3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.6.6.3"><span class="ltx_text ltx_font_bold" id="S5.T4.1.6.6.3.1">3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.6.6.4"><span class="ltx_text ltx_font_bold" id="S5.T4.1.6.6.4.1">3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.6.6.5"><span class="ltx_text ltx_font_bold" id="S5.T4.1.6.6.5.1">2.9975</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.7.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="5" id="S5.T4.1.7.7.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.7.7.1.1">SAMSUM</span></th>
</tr>
<tr class="ltx_tr" id="S5.T4.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T4.1.8.8.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.8.8.1.1">Phi-3</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.8.8.2">2.4623</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.8.8.3">2.6821</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.8.8.4">2.5848</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.8.8.5">2.5060</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.9.9.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.9.9.1.1">InternLM-2.5</span></th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.9.9.2">2.9992</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.9.9.3">2.9969</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.9.9.4"><span class="ltx_text ltx_font_bold" id="S5.T4.1.9.9.4.1">2.9983</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.9.9.5"><span class="ltx_text ltx_font_bold" id="S5.T4.1.9.9.5.1">2.9952</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.10.10.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.10.10.1.1">LLaMA-3</span></th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.10.10.2">2.9976</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.10.10.3">2.9971</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.10.10.4">2.9969</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.10.10.5">2.9916</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T4.1.11.11.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.11.11.1.1">GPT-4o</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.11.11.2"><span class="ltx_text ltx_font_bold" id="S5.T4.1.11.11.2.1">2.9994</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.11.11.3"><span class="ltx_text ltx_font_bold" id="S5.T4.1.11.11.3.1">2.9977</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.11.11.4">2.9982</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.11.11.5">2.9944</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>G-EVAL</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2 </span>Strong performance of LLaMA-3</h4>
<figure class="ltx_table" id="S5.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T5.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T5.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T5.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S5.T5.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T5.1.1.1.2.1">Before Finetuning</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S5.T5.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T5.1.1.1.3.1">Finetuning on In-Domain Data</span></th>
</tr>
<tr class="ltx_tr" id="S5.T5.1.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T5.1.2.2.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.1.2.2.2"><span class="ltx_text ltx_font_bold" id="S5.T5.1.2.2.2.1">QAGS</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.1.2.2.3"><span class="ltx_text ltx_font_bold" id="S5.T5.1.2.2.3.1">BERTScore</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.1.2.2.4"><span class="ltx_text ltx_font_bold" id="S5.T5.1.2.2.4.1">ROUGE-L</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.1.2.2.5"><span class="ltx_text ltx_font_bold" id="S5.T5.1.2.2.5.1">QAGS</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.1.2.2.6"><span class="ltx_text ltx_font_bold" id="S5.T5.1.2.2.6.1">BERTScore</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T5.1.2.2.7"><span class="ltx_text ltx_font_bold" id="S5.T5.1.2.2.7.1">ROUGE-L</span></th>
</tr>
<tr class="ltx_tr" id="S5.T5.1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" colspan="7" id="S5.T5.1.3.3.1"><span class="ltx_text ltx_font_bold" id="S5.T5.1.3.3.1.1">DIALOGSUM</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T5.1.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T5.1.4.1.1"><span class="ltx_text ltx_font_bold" id="S5.T5.1.4.1.1.1">distillbart-cnn</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.4.1.2">0.6134</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.4.1.3">0.5093</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.4.1.4">0.1950</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.4.1.5">0.5586</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.4.1.6">0.7005</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.4.1.7">0.3367</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.5.2.1"><span class="ltx_text ltx_font_bold" id="S5.T5.1.5.2.1.1">bart-base</span></th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.5.2.2">0.7007</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.5.2.3">0.5274</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.5.2.4">0.1375</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.5.2.5">0.4789</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.5.2.6">0.6868</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.5.2.7">0.2969</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.6.3.1"><span class="ltx_text ltx_font_bold" id="S5.T5.1.6.3.1.1">t5-base</span></th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.6.3.2">0.5901</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.6.3.3">0.5491</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.6.3.4">0.1812</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.6.3.5">0.4766</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.6.3.6">0.6953</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.6.3.7">0.2986</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.7.4.1"><span class="ltx_text ltx_font_bold" id="S5.T5.1.7.4.1.1">led-base-16384</span></th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.7.4.2">0.8261</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.7.4.3">0.5471</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.7.4.4">0.1634</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.7.4.5">0.4872</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.7.4.6">0.7084</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.7.4.7">0.3165</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.8.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="7" id="S5.T5.1.8.5.1"><span class="ltx_text ltx_font_bold" id="S5.T5.1.8.5.1.1">SAMSUM</span></th>
</tr>
<tr class="ltx_tr" id="S5.T5.1.9.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T5.1.9.6.1"><span class="ltx_text ltx_font_bold" id="S5.T5.1.9.6.1.1">distillbart-cnn</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.9.6.2">0.6627</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.9.6.3">0.5500</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.9.6.4">0.2394</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.9.6.5">0.6041</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.9.6.6">0.6849</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.9.6.7">0.3578</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.10.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.10.7.1"><span class="ltx_text ltx_font_bold" id="S5.T5.1.10.7.1.1">bart-base</span></th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.10.7.2">0.7563</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.10.7.3">0.4389</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.10.7.4">0.1765</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.10.7.5">0.5302</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.10.7.6">0.6520</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.10.7.7">0.3049</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.11.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.11.8.1"><span class="ltx_text ltx_font_bold" id="S5.T5.1.11.8.1.1">t5-base</span></th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.11.8.2">0.5574</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.11.8.3">0.4190</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.11.8.4">0.1237</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.11.8.5">0.5460</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.11.8.6">0.6448</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.11.8.7">0.3000</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.12.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T5.1.12.9.1"><span class="ltx_text ltx_font_bold" id="S5.T5.1.12.9.1.1">led-base-16384</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.12.9.2">0.7429</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.12.9.3">0.4310</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.12.9.4">0.1812</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.12.9.5">0.5440</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.12.9.6">0.6522</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.12.9.7">0.3175</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Performance of models before and after finetuning on in-domain data</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS2.p1">
<p class="ltx_p" id="S5.SS1.SSS2.p1.1">The observed superiority of LLaMA-3 over GPT-4o is surprising because an 8 billion 8-bit quantized model not only competes with but also performs better than GPT-4o in certain metrics. We hypothesize that this could be due to the way GPT-4o was trained, which might make it more constrained in its responses, whereas LLaMA-3, being an open-source model, operates with fewer restrictions. This allows LLaMA-3 to exhibit greater flexibility, diversity, and adaptability in generating dialogues, potentially explaining its better performance in certain metrics. These characteristics can be seen in criteria like ’inquisitiveness’ and ’likeability’ in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S4.T3" title="Table 3 ‣ 4 Experimental Setup ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">3</span></a> and, ’depth’ and ’diverse’ in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S3.T2" title="Table 2 ‣ 3 DiaSynth ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">2</span></a>. These results suggest that for building human-like data generation frameworks, open-source LLMs are a more suitable choice than closed-source LLMs. The minimal constraints on response formatting during the training of open-source models enable them to generate more diverse, flexible, and human-like dialogues, making them better suited for tasks requiring natural and conversational interactions.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Fine-tuning and Performance Results</h3>
<figure class="ltx_table" id="S5.T6">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T6.1" style="width:433.6pt;height:129.5pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-146.6pt,43.6pt) scale(0.596678401513509,0.596678401513509) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T6.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T6.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S5.T6.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S5.T6.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.1.2.1">Phi-3</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S5.T6.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.1.3.1">InternLM-2.5</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S5.T6.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.1.4.1">LLaMA-3</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S5.T6.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.1.5.1">GPT-4o</span></th>
</tr>
<tr class="ltx_tr" id="S5.T6.1.1.2.2">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S5.T6.1.1.2.2.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T6.1.1.2.2.2"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.2.2.2.1">QAGS</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T6.1.1.2.2.3"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.2.2.3.1">BERTScore</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T6.1.1.2.2.4"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.2.2.4.1">ROUGE-L</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T6.1.1.2.2.5"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.2.2.5.1">QAGS</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T6.1.1.2.2.6"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.2.2.6.1">BERTScore</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T6.1.1.2.2.7"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.2.2.7.1">ROUGE-L</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T6.1.1.2.2.8"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.2.2.8.1">QAGS</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T6.1.1.2.2.9"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.2.2.9.1">BERTScore</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T6.1.1.2.2.10"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.2.2.10.1">ROUGE-L</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T6.1.1.2.2.11"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.2.2.11.1">QAGS</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T6.1.1.2.2.12"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.2.2.12.1">BERTScore</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T6.1.1.2.2.13"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.2.2.13.1">ROUGE-L</span></th>
</tr>
<tr class="ltx_tr" id="S5.T6.1.1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" colspan="13" id="S5.T6.1.1.3.3.1"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.3.3.1.1">DIALOGUESUM</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T6.1.1.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T6.1.1.4.1.1"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.4.1.1.1">distillbart-cnn</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.4.1.2">0.6588</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.4.1.3">0.5778</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T6.1.1.4.1.4"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.4.1.4.1">0.2187</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.4.1.5">0.6420</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.4.1.6">0.6008</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T6.1.1.4.1.7">0.2167</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.4.1.8">0.6586</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.4.1.9">0.6161</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T6.1.1.4.1.10">0.2040</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.4.1.11"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.4.1.11.1">0.6713</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.4.1.12"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.4.1.12.1">0.6242</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.4.1.13">0.2014</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.1.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T6.1.1.5.2.1"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.5.2.1.1">bart-base</span></th>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.5.2.2">0.5355</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.5.2.3">0.5958</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.5.2.4"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.5.2.4.1">0.2029</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.5.2.5">0.5418</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.5.2.6"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.5.2.6.1">0.6212</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.5.2.7">0.1897</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.5.2.8"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.5.2.8.1">0.5825</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.5.2.9">0.6033</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.5.2.10">0.1789</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.5.2.11">0.5590</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.5.2.12">0.6039</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.5.2.13">0.1769</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.1.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T6.1.1.6.3.1"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.6.3.1.1">t5-base</span></th>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.6.3.2">0.5937</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.6.3.3">0.5949</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.6.3.4"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.6.3.4.1">0.2047</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.6.3.5">0.5825</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.6.3.6">0.5941</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.6.3.7">0.1878</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.6.3.8">0.6034</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.6.3.9">0.6172</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.6.3.10">0.1959</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.6.3.11"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.6.3.11.1">0.6305</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.6.3.12"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.6.3.12.1">0.6319</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.6.3.13">0.2044</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.1.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T6.1.1.7.4.1"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.7.4.1.1">led-base-16384</span></th>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.7.4.2">0.5358</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.7.4.3">0.6129</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.7.4.4"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.7.4.4.1">0.2109</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.7.4.5">0.5189</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.7.4.6">0.6027</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.7.4.7">0.1606</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.7.4.8">0.5697</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.7.4.9">0.6302</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.7.4.10">0.1999</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.7.4.11"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.7.4.11.1">0.5791</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.7.4.12"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.7.4.12.1">0.6308</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.7.4.13">0.1989</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.1.8.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="13" id="S5.T6.1.1.8.5.1"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.8.5.1.1">SAMSUM</span></th>
</tr>
<tr class="ltx_tr" id="S5.T6.1.1.9.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T6.1.1.9.6.1"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.9.6.1.1">distillbart-cnn</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.9.6.2">0.6585</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.9.6.3">0.5931</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T6.1.1.9.6.4">0.2262</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.9.6.5">0.6388</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.9.6.6">0.6066</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T6.1.1.9.6.7">0.2422</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.9.6.8"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.9.6.8.1">0.6849</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.9.6.9"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.9.6.9.1">0.6029</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T6.1.1.9.6.10"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.9.6.10.1">0.2374</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.9.6.11">0.6757</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.9.6.12">0.6029</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.9.6.13">0.2291</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.1.10.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T6.1.1.10.7.1"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.10.7.1.1">bart-base</span></th>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.10.7.2">0.5648</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.10.7.3">0.5665</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.10.7.4">0.2146</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.10.7.5">0.5435</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.10.7.6">0.5663</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.10.7.7">0.2021</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.10.7.8"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.10.7.8.1">0.6132</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.10.7.9"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.10.7.9.1">0.5899</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.10.7.10"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.10.7.10.1">0.2345</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.10.7.11">0.5707</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.10.7.12">0.5808</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.10.7.13">0.2154</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.1.11.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T6.1.1.11.8.1"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.11.8.1.1">t5-base</span></th>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.11.8.2">0.5905</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.11.8.3">0.5397</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.11.8.4"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.11.8.4.1">0.2085</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.11.8.5">0.5457</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.11.8.6">0.5193</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.11.8.7">0.1854</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.11.8.8"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.11.8.8.1">0.6412</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.11.8.9">0.5054</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.11.8.10">0.1976</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.11.8.11">0.6023</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.11.8.12"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.11.8.12.1">0.5419</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.11.8.13">0.1979</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.1.12.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S5.T6.1.1.12.9.1"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.12.9.1.1">led-base-16384</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.1.1.12.9.2">0.5883</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.1.1.12.9.3">0.5477</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T6.1.1.12.9.4">0.2289</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.1.1.12.9.5">0.5457</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.1.1.12.9.6">0.5615</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T6.1.1.12.9.7">0.2167</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.1.1.12.9.8"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.12.9.8.1">0.5917</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.1.1.12.9.9"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.12.9.9.1">0.5785</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T6.1.1.12.9.10"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.12.9.10.1">0.2390</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.1.1.12.9.11">0.5738</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.1.1.12.9.12">0.569</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.1.1.12.9.13">0.2298</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Performance after finetuning on synthetic data</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">To validate the usability of the synthetic data generated using DiaSynth, we fine-tuned and evaluated several pretrained language models on the task of dialogue summarization. The summaries for dialogues generated by different LLMs were created using the corresponding LLMs through prompting. The pretrained models used for evaluation include DistilBART, BART, T5, and LED.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">The experimental setup is designed as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p3">
<ul class="ltx_itemize" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1">Metrics are reported on the validation and test sets of DialogSum and SAMSum.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1">To evaluate DiaSynth-generated data, we compared models fine-tuned on DiaSynth data with their base versions (no fine-tuning).</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i3.p1">
<p class="ltx_p" id="S5.I1.i3.p1.1">In-domain training sets were randomly sampled to match the size of the DiaSynth-generated data, enabling fair comparison.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i4.p1">
<p class="ltx_p" id="S5.I1.i4.p1.1">The experiment aimed to quantify performance improvement of DiaSynth-fine-tuned models and assess alignment with in-domain data distributions.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S5.I1.i5.p1">
<p class="ltx_p" id="S5.I1.i5.p1.1">Models were fine-tuned for 2 epochs with a learning rate of <span class="ltx_text ltx_font_typewriter" id="S5.I1.i5.p1.1.1">5e-5</span> and a warmup of <span class="ltx_text ltx_font_typewriter" id="S5.I1.i5.p1.1.2">50</span> steps.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1">The results presented in Tables <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S5.T5" title="Table 5 ‣ 5.1.2 Strong performance of LLaMA-3 ‣ 5.1 Quality of the Dialogues ‣ 5 Results ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">5</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S5.T6" title="Table 6 ‣ 5.2 Fine-tuning and Performance Results ‣ 5 Results ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">6</span></a> present the performance of the base models, models finetuned on in-domain data and models finetuned on DiaSynth generated data. Models finetuned on DiaSynth data generally improves the performances from the BERTScore and ROUGE-L metrics. Surprisingly, for some models (LED and BART) the QAGS scores were higher than the models finetuned on DiaSynth. On further exploration, we found out that these models extracted multiple sentences from the given dialogue instead of generating a summary which led to high QAGS scores. Comparing models finetuned on in-domain data to those finetuned on DiaSynth data reveals that DiaSynth finetuning generally enhances factual accuracy, with BERTScore and ROUGE-L scores remaining comparable. The disparity in BERTScore and ROUGE-L results may be due to format variations. Models fine-tuned on in-domain data were evaluated on summaries that matched the training format closely, while DiaSynth-fine-tuned models were trained on LLM-generated summaries and evaluated on human-generated summaries, leading to minor format mismatches. Comparison between the different LLMs from Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S5.T6" title="Table 6 ‣ 5.2 Fine-tuning and Performance Results ‣ 5 Results ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">6</span></a>, shows that GPT-4o is better at generating dialogues and summaries that are formal in nature while LLaMA-3 and open source LLMs would be better for generating dialogues that are informal and casual in nature.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p5">
<table class="ltx_equationgroup ltx_eqn_table" id="S5.E1">
<tbody>
<tr class="ltx_eqn_row" id="A5.EGx1"><td class="ltx_eqn_cell" colspan="5"></td></tr>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S5.E1.1">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span class="ltx_text ltx_markedasmath" id="S5.E1.1.2.1.1.1">% Improvement</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\frac{\text{After - Before}}{\text{Before}}" class="ltx_Math" display="inline" id="S5.E1.1.m2.1"><semantics id="S5.E1.1.m2.1a"><mrow id="S5.E1.1.m2.1.1" xref="S5.E1.1.m2.1.1.cmml"><mi id="S5.E1.1.m2.1.1.2" xref="S5.E1.1.m2.1.1.2.cmml"></mi><mo id="S5.E1.1.m2.1.1.1" xref="S5.E1.1.m2.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S5.E1.1.m2.1.1.3" xref="S5.E1.1.m2.1.1.3.cmml"><mfrac id="S5.E1.1.m2.1.1.3a" xref="S5.E1.1.m2.1.1.3.cmml"><mtext id="S5.E1.1.m2.1.1.3.2" xref="S5.E1.1.m2.1.1.3.2a.cmml">After - Before</mtext><mtext id="S5.E1.1.m2.1.1.3.3" xref="S5.E1.1.m2.1.1.3.3a.cmml">Before</mtext></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S5.E1.1.m2.1b"><apply id="S5.E1.1.m2.1.1.cmml" xref="S5.E1.1.m2.1.1"><eq id="S5.E1.1.m2.1.1.1.cmml" xref="S5.E1.1.m2.1.1.1"></eq><csymbol cd="latexml" id="S5.E1.1.m2.1.1.2.cmml" xref="S5.E1.1.m2.1.1.2">absent</csymbol><apply id="S5.E1.1.m2.1.1.3.cmml" xref="S5.E1.1.m2.1.1.3"><divide id="S5.E1.1.m2.1.1.3.1.cmml" xref="S5.E1.1.m2.1.1.3"></divide><ci id="S5.E1.1.m2.1.1.3.2a.cmml" xref="S5.E1.1.m2.1.1.3.2"><mtext id="S5.E1.1.m2.1.1.3.2.cmml" xref="S5.E1.1.m2.1.1.3.2">After - Before</mtext></ci><ci id="S5.E1.1.m2.1.1.3.3a.cmml" xref="S5.E1.1.m2.1.1.3.3"><mtext id="S5.E1.1.m2.1.1.3.3.cmml" xref="S5.E1.1.m2.1.1.3.3">Before</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E1.1.m2.1c">\displaystyle=\frac{\text{After - Before}}{\text{Before}}</annotation><annotation encoding="application/x-llamapun" id="S5.E1.1.m2.1d">= divide start_ARG After - Before end_ARG start_ARG Before end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1a)</span></td>
</tr>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S5.E1.2">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span class="ltx_text ltx_markedasmath" id="S5.E1.2.2.1.1.1">% Coverage</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\frac{\text{Score DiaSynth}}{\text{Score In-domain}}" class="ltx_Math" display="inline" id="S5.E1.2.m2.1"><semantics id="S5.E1.2.m2.1a"><mrow id="S5.E1.2.m2.1.1" xref="S5.E1.2.m2.1.1.cmml"><mi id="S5.E1.2.m2.1.1.2" xref="S5.E1.2.m2.1.1.2.cmml"></mi><mo id="S5.E1.2.m2.1.1.1" xref="S5.E1.2.m2.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S5.E1.2.m2.1.1.3" xref="S5.E1.2.m2.1.1.3.cmml"><mfrac id="S5.E1.2.m2.1.1.3a" xref="S5.E1.2.m2.1.1.3.cmml"><mtext id="S5.E1.2.m2.1.1.3.2" xref="S5.E1.2.m2.1.1.3.2a.cmml">Score DiaSynth</mtext><mtext id="S5.E1.2.m2.1.1.3.3" xref="S5.E1.2.m2.1.1.3.3a.cmml">Score In-domain</mtext></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S5.E1.2.m2.1b"><apply id="S5.E1.2.m2.1.1.cmml" xref="S5.E1.2.m2.1.1"><eq id="S5.E1.2.m2.1.1.1.cmml" xref="S5.E1.2.m2.1.1.1"></eq><csymbol cd="latexml" id="S5.E1.2.m2.1.1.2.cmml" xref="S5.E1.2.m2.1.1.2">absent</csymbol><apply id="S5.E1.2.m2.1.1.3.cmml" xref="S5.E1.2.m2.1.1.3"><divide id="S5.E1.2.m2.1.1.3.1.cmml" xref="S5.E1.2.m2.1.1.3"></divide><ci id="S5.E1.2.m2.1.1.3.2a.cmml" xref="S5.E1.2.m2.1.1.3.2"><mtext id="S5.E1.2.m2.1.1.3.2.cmml" xref="S5.E1.2.m2.1.1.3.2">Score DiaSynth</mtext></ci><ci id="S5.E1.2.m2.1.1.3.3a.cmml" xref="S5.E1.2.m2.1.1.3.3"><mtext id="S5.E1.2.m2.1.1.3.3.cmml" xref="S5.E1.2.m2.1.1.3.3">Score In-domain</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E1.2.m2.1c">\displaystyle=\frac{\text{Score DiaSynth}}{\text{Score In-domain}}</annotation><annotation encoding="application/x-llamapun" id="S5.E1.2.m2.1d">= divide start_ARG Score DiaSynth end_ARG start_ARG Score In-domain end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1b)</span></td>
</tr>
</tbody>
</table>
</div>
<figure class="ltx_table" id="S5.T8">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.T8.fig1" style="width:195.1pt;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T8.fig1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T8.fig1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T8.fig1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T8.fig1.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T8.fig1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T8.fig1.1.1.1.2.1">% Improvement</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T8.fig1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T8.fig1.1.1.1.3.1">% Covered</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T8.fig1.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.fig1.1.2.1.1">distilbart-cnn</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.fig1.1.2.1.2">10.96</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.fig1.1.2.1.3">88.81</td>
</tr>
<tr class="ltx_tr" id="S5.T8.fig1.1.3.2">
<td class="ltx_td ltx_align_center" id="S5.T8.fig1.1.3.2.1">bart-base</td>
<td class="ltx_td ltx_align_center" id="S5.T8.fig1.1.3.2.2">9.21</td>
<td class="ltx_td ltx_align_center" id="S5.T8.fig1.1.3.2.3">90.6</td>
</tr>
<tr class="ltx_tr" id="S5.T8.fig1.1.4.3">
<td class="ltx_td ltx_align_center" id="S5.T8.fig1.1.4.3.1">t5-base</td>
<td class="ltx_td ltx_align_center" id="S5.T8.fig1.1.4.3.2">7.59</td>
<td class="ltx_td ltx_align_center" id="S5.T8.fig1.1.4.3.3">93.67</td>
</tr>
<tr class="ltx_tr" id="S5.T8.fig1.1.5.4">
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T8.fig1.1.5.4.1">led-base-16384</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T8.fig1.1.5.4.2">2.14</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T8.fig1.1.5.4.3">89.68</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Table 7: </span>Summarization results on DialogSum</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.T8.fig2" style="width:195.1pt;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T8.fig2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T8.fig2.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T8.fig2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T8.fig2.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T8.fig2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T8.fig2.1.1.1.2.1">% Improvement</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T8.fig2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T8.fig2.1.1.1.3.1">% Covered</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T8.fig2.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.fig2.1.2.1.1">distilbart-cnn</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.fig2.1.2.1.2">6.07</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.fig2.1.2.1.3">87.25</td>
</tr>
<tr class="ltx_tr" id="S5.T8.fig2.1.3.2">
<td class="ltx_td ltx_align_center" id="S5.T8.fig2.1.3.2.1">bart-base</td>
<td class="ltx_td ltx_align_center" id="S5.T8.fig2.1.3.2.2">16.12</td>
<td class="ltx_td ltx_align_center" id="S5.T8.fig2.1.3.2.3">94.35</td>
</tr>
<tr class="ltx_tr" id="S5.T8.fig2.1.4.3">
<td class="ltx_td ltx_align_center" id="S5.T8.fig2.1.4.3.1">t5-base</td>
<td class="ltx_td ltx_align_center" id="S5.T8.fig2.1.4.3.2">30.04</td>
<td class="ltx_td ltx_align_center" id="S5.T8.fig2.1.4.3.3">87.36</td>
</tr>
<tr class="ltx_tr" id="S5.T8.fig2.1.5.4">
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T8.fig2.1.5.4.1">led-base-16384</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T8.fig2.1.5.4.2">15.25</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T8.fig2.1.5.4.3">90.91</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Table 8: </span>Summarization results on SAMSum</figcaption>
</figure>
</div>
</div>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS2.p6">
<p class="ltx_p" id="S5.SS2.p6.1">To assess the percentage improvement and percentage coverage of the distributional characteristics of the in-domain data by the synthetically generated data, we use Equations <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S5.E1.1" title="In 1 ‣ 5.2 Fine-tuning and Performance Results ‣ 5 Results ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">1a</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S5.E1.2" title="In 1 ‣ 5.2 Fine-tuning and Performance Results ‣ 5 Results ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">1b</span></a> respectively. We use the scores of models finetuned on LLaMA-3 generated data because of its dominance in both quality and usability. Across the 24 reported results, the overall coverage percentage of the LLaMA-3 generated data is <span class="ltx_text ltx_font_bold" id="S5.SS2.p6.1.1">90.48%</span>. Notably, the QAGS scores of models fine-tuned on synthetic data surpass those of models trained on in-domain data, suggesting that synthetic data can match or even exceed in-domain data performance in some aspects. Excluding QAGS, the coverage percentage is calculated to be <span class="ltx_text ltx_font_bold" id="S5.SS2.p6.1.2">77.07%</span>. In addition to the average percentages, we also present the model wise percentage improvement and coverage in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S5.T8" title="Table 8 ‣ 5.2 Fine-tuning and Performance Results ‣ 5 Results ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">8</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#S5.T8" title="Table 8 ‣ 5.2 Fine-tuning and Performance Results ‣ 5 Results ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">8</span></a>. The results presented are with respect to the dialogues generated using LLaMA-3 and they illustrate clear improvements for every model, highlighting that even with moderate LLMs of small scale (3B - 8B), high-quality synthetic dialogue datasets can be effectively created across different domains and different dialogue formats.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this paper, we introduced DiaSynth, a synthetic dialogue generation framework capable of producing high-quality, contextually rich dialogues across a wide range of domains. Our experiments demonstrated that models fine-tuned on DiaSynth-generated data exhibit significant improvements in downstream tasks, as evidenced by substantial increases in BERTScore and ROUGE-L compared to their base models. These results highlight the potential of DiaSynth as an effective tool for generating dialogue data, particularly in domains where training data is scarce.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">Furthermore, our analysis showed that different LLMs excel in different dialogue structures, with LLaMA-3 performing better for informal dialogues and GPT-4o for more structured settings. This insight suggests that leveraging open-source LLMs may be more advantageous for generating human-like conversational data. Despite certain limitations, such as varying LLM performance across dialogue types and knowledge gaps in zero-shot generation, DiaSynth presents a promising approach to dialogue data generation and offers a valuable resource for future advancements in building more sophisticated and adaptable dialogue systems.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Limitations</h2>
<div class="ltx_para ltx_noindent" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">Despite the promising results, our approach has some limitations. Firstly, different LLMs exhibit varied performance based on the dialogue structure, with certain models like LLaMA-3 performing better for more informal dialogues (e.g., SAMSum) and others like GPT-4o excelling in structured, formal dialogues (e.g., DialogSum). This indicates that there is no single model that can universally handle all types of dialogue structures, but a single SOTA model can give stable and decent results like LLaMA-3.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">Secondly, the generation process may suffer from a lack of knowledge on certain topics, especially in cases where the LLMs were not sufficiently trained on those domains. Additionally, our framework relies on zero-shot generation for personas and sub-topics, which, while flexible, can sometimes result in less coherent or less accurate persona simulation, as it is not fine-tuned for specific contexts.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.p3">
<p class="ltx_p" id="S7.p3.1">Since LLMs power DiaSynth, hallucinations and compute-need are two inherent limitations. We present a detailed hallucination study in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A1" title="Appendix A Hallucination Study ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">A</span></a>, which indicates that though the hallucinations rates are acceptable, there is still scope for improvements. These limitations suggest directions for future work, such as combining LLMs to leverage their strengths or incorporating more topic-specific training to enhance knowledge coverage.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al. [2020]</span>
<span class="ltx_bibblock">
Song Feng, Hui Wan, Chulaka Gunasekara, Siva Patel, Sachindra Joshi, and Luis Lastras.

</span>
<span class="ltx_bibblock">doc2dial: A goal-oriented document-grounded dialogue dataset.

</span>
<span class="ltx_bibblock">In Bonnie Webber, Trevor Cohn, Yulan He, and Yang Liu, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 8118–8128, Online, November 2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.emnlp-main.652" title="">10.18653/v1/2020.emnlp-main.652</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.emnlp-main.652" title="">https://aclanthology.org/2020.emnlp-main.652</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et al. [2020]</span>
<span class="ltx_bibblock">
Guangtao Zeng, Wenmian Yang, Zeqian Ju, Yue Yang, Sicheng Wang, Ruisi Zhang, Meng Zhou, Jiaqi Zeng, Xiangyu Dong, Ruoyu Zhang, Hongchao Fang, Penghui Zhu, Shu Chen, and Pengtao Xie.

</span>
<span class="ltx_bibblock">MedDialog: Large-scale medical dialogue datasets.

</span>
<span class="ltx_bibblock">In Bonnie Webber, Trevor Cohn, Yulan He, and Yang Liu, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 9241–9250, Online, November 2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.emnlp-main.743" title="">10.18653/v1/2020.emnlp-main.743</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.emnlp-main.743" title="">https://aclanthology.org/2020.emnlp-main.743</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Budzianowski et al. [2018]</span>
<span class="ltx_bibblock">
Paweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang Tseng, Iñigo Casanueva, Stefan Ultes, Osman Ramadan, and Milica Gašić.

</span>
<span class="ltx_bibblock">MultiWOZ - a large-scale multi-domain Wizard-of-Oz dataset for task-oriented dialogue modelling.

</span>
<span class="ltx_bibblock">In Ellen Riloff, David Chiang, Julia Hockenmaier, and Jun’ichi Tsujii, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, pages 5016–5026, Brussels, Belgium, October-November 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D18-1547" title="">10.18653/v1/D18-1547</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/D18-1547" title="">https://aclanthology.org/D18-1547</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. [2024]</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the 36th International Conference on Neural Information Processing Systems</em>, NIPS ’22, Red Hook, NY, USA, 2024. Curran Associates Inc.

</span>
<span class="ltx_bibblock">ISBN 9781713871088.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al. [2024]</span>
<span class="ltx_bibblock">
Ji-Eun Han, Jun-Seok Koh, Hyeon-Tae Seo, Du-Seong Chang, and Kyung-Ah Sohn.

</span>
<span class="ltx_bibblock">PSYDIAL: Personality-based synthetic dialogue generation using large language models.

</span>
<span class="ltx_bibblock">In Nicoletta Calzolari, Min-Yen Kan, Veronique Hoste, Alessandro Lenci, Sakriani Sakti, and Nianwen Xue, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)</em>, pages 13321–13331, Torino, Italia, May 2024. ELRA and ICCL.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2024.lrec-main.1166" title="">https://aclanthology.org/2024.lrec-main.1166</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chan et al. [2024]</span>
<span class="ltx_bibblock">
Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi, and Dong Yu.

</span>
<span class="ltx_bibblock">Scaling synthetic data creation with 1,000,000,000 personas.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2406.20094</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Steindl et al. [2023]</span>
<span class="ltx_bibblock">
Sebastian Steindl, Ulrich Schäfer, and Bernd Ludwig.

</span>
<span class="ltx_bibblock">Generating synthetic dialogues from prompts to improve task-oriented dialogue systems.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">KI 2023: Advances in Artificial Intelligence: 46th German Conference on AI, Berlin, Germany, September 26–29, 2023, Proceedings</em>, page 207–214, Berlin, Heidelberg, 2023. Springer-Verlag.

</span>
<span class="ltx_bibblock">ISBN 978-3-031-42607-0.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1007/978-3-031-42608-7_17" title="">10.1007/978-3-031-42608-7_17</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-031-42608-7_17" title="">https://doi.org/10.1007/978-3-031-42608-7_17</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2022]</span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi.

</span>
<span class="ltx_bibblock">Self-instruct: Aligning language models with self-generated instructions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2212.10560</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mehri and Eskenazi [2020]</span>
<span class="ltx_bibblock">
Shikib Mehri and Maxine Eskenazi.

</span>
<span class="ltx_bibblock">Unsupervised evaluation of interactive dialog with DialoGPT.

</span>
<span class="ltx_bibblock">In Olivier Pietquin, Smaranda Muresan, Vivian Chen, Casey Kennington, David Vandyke, Nina Dethlefs, Koji Inoue, Erik Ekstedt, and Stefan Ultes, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</em>, pages 225–235, 1st virtual meeting, July 2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.sigdial-1.28" title="">10.18653/v1/2020.sigdial-1.28</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.sigdial-1.28" title="">https://aclanthology.org/2020.sigdial-1.28</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et al. [2024]</span>
<span class="ltx_bibblock">
Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu.

</span>
<span class="ltx_bibblock">GPTScore: Evaluate as you desire.

</span>
<span class="ltx_bibblock">In Kevin Duh, Helena Gomez, and Steven Bethard, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)</em>, pages 6556–6576, Mexico City, Mexico, June 2024. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2024.naacl-long.365" title="">10.18653/v1/2024.naacl-long.365</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2024.naacl-long.365" title="">https://aclanthology.org/2024.naacl-long.365</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2023]</span>
<span class="ltx_bibblock">
Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu.

</span>
<span class="ltx_bibblock">G-eval: NLG evaluation using gpt-4 with better human alignment.

</span>
<span class="ltx_bibblock">In Houda Bouamor, Juan Pino, and Kalika Bali, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 2511–2522, Singapore, December 2023. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.153" title="">10.18653/v1/2023.emnlp-main.153</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.emnlp-main.153" title="">https://aclanthology.org/2023.emnlp-main.153</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdin et al. [2024]</span>
<span class="ltx_bibblock">
Marah Abdin, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Harkirat Behl, et al.

</span>
<span class="ltx_bibblock">Phi-3 technical report: A highly capable language model locally on your phone.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2404.14219</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai et al. [2024]</span>
<span class="ltx_bibblock">
Zheng Cai, Maosong Cao, Haojiong Chen, Kai Chen, Keyu Chen, Xin Chen, Xun Chen, Zehui Chen, Zhi Chen, Pei Chu, Xiao wen Dong, Haodong Duan, Qi Fan, Zhaoye Fei, Yang Gao, Jiaye Ge, Chenya Gu, Yuzhe Gu, Tao Gui, Aijia Guo, Qipeng Guo, Conghui He, Yingfan Hu, Ting Huang, Tao Jiang, Penglong Jiao, Zhen Jin, Zhikai Lei, Jiaxing Li, Jingwen Li, Linyang Li, Shuaibin Li, Wei Li, Yining Li, Hongwei Liu, Jiangning Liu, Jiawei Hong, Kaiwen Liu, Kui-Jie Liu, Xiaoran Liu, Chen Lv, Haijun Lv, Kai Lv, Li Ma, Runyuan Ma, Zerun Ma, Wenchang Ning, Linke Ouyang, Jiantao Qiu, Yuan Qu, Fukai Shang, Yunfan Shao, Demin Song, Zifan Song, Zhihao Sui, Peng Sun, Yu Sun, Huanze Tang, Bin Wang, Guoteng Wang, Jiaqi Wang, Jiayu Wang, Rui Wang, Yudong Wang, Ziyi Wang, Xing Wei, Qizhen Weng, Fan Wu, Yingtong Xiong, Chao Xu, Rui Ze Xu, Hang Yan, Yirong Yan, Xiaogui Yang, Haochen Ye, Huaiyuan Ying, Jia Yu, Jing Yu, Yuhang Zang, Chuyu Zhang, Li Zhang, Pan Zhang, Peng Zhang, Ruijie Zhang, Shuo Zhang, Songyang Zhang, Wenjian Zhang, Wenwei Zhang,
Xingcheng Zhang, Xinyue Zhang, Hui Zhao, Qian Zhao, Xiaomeng Zhao, Fen-Fang Zhou, Zaida Zhou, Jingming Zhuo, Yi-Ling Zou, Xipeng Qiu, Yu Qiao, and Dahua Lin.

</span>
<span class="ltx_bibblock">Internlm2 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">ArXiv</em>, abs/2403.17297, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:268691939" title="">https://api.semanticscholar.org/CorpusID:268691939</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubey et al. [2024]</span>
<span class="ltx_bibblock">
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al.

</span>
<span class="ltx_bibblock">The llama 3 herd of models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2407.21783</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2021]</span>
<span class="ltx_bibblock">
Yulong Chen, Yang Liu, Liang Chen, and Yue Zhang.

</span>
<span class="ltx_bibblock">DialogSum: A real-life scenario dialogue summarization dataset.

</span>
<span class="ltx_bibblock">In Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</em>, pages 5062–5074, Online, August 2021. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.findings-acl.449" title="">10.18653/v1/2021.findings-acl.449</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2021.findings-acl.449" title="">https://aclanthology.org/2021.findings-acl.449</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gliwa et al. [2019]</span>
<span class="ltx_bibblock">
Bogdan Gliwa, Iwona Mochol, Maciej Biesek, and Aleksander Wawer.

</span>
<span class="ltx_bibblock">SAMSum corpus: A human-annotated dialogue dataset for abstractive summarization.

</span>
<span class="ltx_bibblock">In Lu Wang, Jackie Chi Kit Cheung, Giuseppe Carenini, and Fei Liu, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the 2nd Workshop on New Frontiers in Summarization</em>, pages 70–79, Hong Kong, China, November 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D19-5409" title="">10.18653/v1/D19-5409</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/D19-5409" title="">https://aclanthology.org/D19-5409</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2020]</span>
<span class="ltx_bibblock">
Alex Wang, Kyunghyun Cho, and Mike Lewis.

</span>
<span class="ltx_bibblock">Asking and answering questions to evaluate the factual consistency of summaries.

</span>
<span class="ltx_bibblock">In Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 5008–5020, Online, July 2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.450" title="">10.18653/v1/2020.acl-main.450</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.acl-main.450" title="">https://aclanthology.org/2020.acl-main.450</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang* et al. [2020]</span>
<span class="ltx_bibblock">
Tianyi Zhang*, Varsha Kishore*, Felix Wu*, Kilian Q. Weinberger, and Yoav Artzi.

</span>
<span class="ltx_bibblock">Bertscore: Evaluating text generation with bert.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">International Conference on Learning Representations</em>, 2020.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=SkeHuCVFDr" title="">https://openreview.net/forum?id=SkeHuCVFDr</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin [2004]</span>
<span class="ltx_bibblock">
Chin-Yew Lin.

</span>
<span class="ltx_bibblock">ROUGE: A package for automatic evaluation of summaries.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Text Summarization Branches Out</em>, pages 74–81, Barcelona, Spain, July 2004. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/W04-1013" title="">https://aclanthology.org/W04-1013</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. [2020]</span>
<span class="ltx_bibblock">
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension.

</span>
<span class="ltx_bibblock">In Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 7871–7880, Online, July 2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.703" title="">10.18653/v1/2020.acl-main.703</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.acl-main.703" title="">https://aclanthology.org/2020.acl-main.703</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al. [2020]</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Journal of machine learning research</em>, 21(140):1–67, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beltagy et al. [2020]</span>
<span class="ltx_bibblock">
Iz Beltagy, Matthew E Peters, and Arman Cohan.

</span>
<span class="ltx_bibblock">Longformer: The long-document transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2004.05150</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Manakul et al. [2023]</span>
<span class="ltx_bibblock">
Potsawee Manakul, Adian Liusie, and Mark Gales.

</span>
<span class="ltx_bibblock">SelfCheckGPT: Zero-resource black-box hallucination detection for generative large language models.

</span>
<span class="ltx_bibblock">In Houda Bouamor, Juan Pino, and Kalika Bali, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 9004–9017, Singapore, December 2023. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.557" title="">10.18653/v1/2023.emnlp-main.557</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.emnlp-main.557" title="">https://aclanthology.org/2023.emnlp-main.557</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Friel and Sanyal [2023]</span>
<span class="ltx_bibblock">
Robert Friel and Atindriyo Sanyal.

</span>
<span class="ltx_bibblock">Chainpoll: A high efficacy method for llm hallucination detection.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">ArXiv</em>, abs/2310.18344, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:264590664" title="">https://api.semanticscholar.org/CorpusID:264590664</a>.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Hallucination Study</h2>
<div class="ltx_para ltx_noindent" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">In addition to evaluating the quality and usability of dialogues produced by DiaSynth, we conducted a study on the phenomenon of hallucinations within the generated dialogues. Hallucinations in language models refer to instances where the output contains misleading or incorrect information or situations where the model repeats the same content. To evaluate the occurrence of hallucinations, we compared the generated dialogues with their respective summaries and assessed them using two well-known hallucination benchmarks: <span class="ltx_text ltx_font_bold" id="A1.p1.1.1">SelfCheckGPT</span> <cite class="ltx_cite ltx_citemacro_cite">Manakul et al. [<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib23" title="">2023</a>]</cite> and <span class="ltx_text ltx_font_bold" id="A1.p1.1.2">ChainPoll</span> <cite class="ltx_cite ltx_citemacro_cite">Friel and Sanyal [<a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#bib.bib24" title="">2023</a>]</cite>. This analysis provides insights into the prevalence of hallucinations and informs strategies for improving dialogue quality in future iterations of DiaSynth. The results are presented in Tables <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A1.T10" title="Table 10 ‣ A.3 Implications for DiaSynth ‣ Appendix A Hallucination Study ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">10</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A1.T10" title="Table 10 ‣ A.3 Implications for DiaSynth ‣ Appendix A Hallucination Study ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">10</span></a>.</p>
</div>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>SelfCheckGPT</h3>
<div class="ltx_para ltx_noindent" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">SelfCheckGPT quantifies the self-consistency of LLM outputs by examining agreement across multiple outputs from the same prompt. This assessment reveals potential inaccuracies through metrics like SelfCheck-BertScore.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS1.p2">
<p class="ltx_p" id="A1.SS1.p2.1">The SelfCheck-BERTScore results for various models show that hallucination levels are at worst around 25%, which is acceptable but still indicates areas for improvement. Across both datasets, <span class="ltx_text ltx_font_bold" id="A1.SS1.p2.1.1">Phi-3</span> demonstrates the most robustness, likely due to its pretraining on structured, textbook-like data, which may contribute to greater consistency and factual accuracy.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>ChainPoll</h3>
<div class="ltx_para ltx_noindent" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">ChainPoll utilizes a chain-of-thought prompting approach to identify hallucinations by iteratively polling the model with structured reasoning prompts. This method systematically detects both open-domain and closed-domain hallucinations, where lower scores indicate fewer hallucinations.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS2.p2">
<p class="ltx_p" id="A1.SS2.p2.1">The ChainPoll scores indicate that hallucination levels on these models are generally low, with the best performance seen by <span class="ltx_text ltx_font_bold" id="A1.SS2.p2.1.1">GPT-4o</span> on SAMSum, which achieves the lowest score of 0.120, suggesting minimal hallucinations. On the other hand, <span class="ltx_text ltx_font_bold" id="A1.SS2.p2.1.2">LLaMA-3</span> scores higher at 0.237 on SAMSum, indicating more frequent hallucinations. These findings highlight different models’ strengths in generating accurate and reliable dialogues.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Implications for DiaSynth</h3>
<div class="ltx_para ltx_noindent" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.1">The results from both SelfCheckGPT and ChainPoll evaluations suggest that DiaSynth, when leveraging models like Llama 3, is capable of generating dialogues with relatively low hallucination rates. However, specific models show variability in performance across datasets, indicating that further enhancements, such as fine-tuning or incorporating additional guardrails, could improve DiaSynth’s robustness in generating reliable dialogues across diverse domains.</p>
</div>
<figure class="ltx_table" id="A1.T10">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A1.T10.fig1" style="width:195.1pt;">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T10.fig1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T10.fig1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="A1.T10.fig1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.T10.fig1.1.1.1.1.1">LLM</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T10.fig1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T10.fig1.1.1.1.2.1">ChainPoll</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T10.fig1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A1.T10.fig1.1.1.1.3.1">SCGPT-BERTScore</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T10.fig1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A1.T10.fig1.1.2.1.1">Phi-3</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T10.fig1.1.2.1.2">0.198</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T10.fig1.1.2.1.3">0.791</td>
</tr>
<tr class="ltx_tr" id="A1.T10.fig1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T10.fig1.1.3.2.1">InternLM-2.5</th>
<td class="ltx_td ltx_align_center" id="A1.T10.fig1.1.3.2.2">0.199</td>
<td class="ltx_td ltx_align_center" id="A1.T10.fig1.1.3.2.3">0.726</td>
</tr>
<tr class="ltx_tr" id="A1.T10.fig1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T10.fig1.1.4.3.1">LLaMA-3</th>
<td class="ltx_td ltx_align_center" id="A1.T10.fig1.1.4.3.2">0.205</td>
<td class="ltx_td ltx_align_center" id="A1.T10.fig1.1.4.3.3">0.793</td>
</tr>
<tr class="ltx_tr" id="A1.T10.fig1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="A1.T10.fig1.1.5.4.1">GPT-4o</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="A1.T10.fig1.1.5.4.2">0.178</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A1.T10.fig1.1.5.4.3">0.765</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Table 9: </span>Hallucination calculation for DialogSum few-shot data</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A1.T10.fig2" style="width:195.1pt;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A1.T10.fig2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T10.fig2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="A1.T10.fig2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.T10.fig2.1.1.1.1.1">LLM</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T10.fig2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T10.fig2.1.1.1.2.1">ChainPoll</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T10.fig2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A1.T10.fig2.1.1.1.3.1">SCGPT-BERTScore</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T10.fig2.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A1.T10.fig2.1.2.1.1">Phi-3</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T10.fig2.1.2.1.2">0.154</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T10.fig2.1.2.1.3">0.785</td>
</tr>
<tr class="ltx_tr" id="A1.T10.fig2.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T10.fig2.1.3.2.1">InternLM-2.5</th>
<td class="ltx_td ltx_align_center" id="A1.T10.fig2.1.3.2.2">0.159</td>
<td class="ltx_td ltx_align_center" id="A1.T10.fig2.1.3.2.3">0.716</td>
</tr>
<tr class="ltx_tr" id="A1.T10.fig2.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T10.fig2.1.4.3.1">LLaMA-3</th>
<td class="ltx_td ltx_align_center" id="A1.T10.fig2.1.4.3.2">0.237</td>
<td class="ltx_td ltx_align_center" id="A1.T10.fig2.1.4.3.3">0.733</td>
</tr>
<tr class="ltx_tr" id="A1.T10.fig2.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="A1.T10.fig2.1.5.4.1">GPT-4o</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="A1.T10.fig2.1.5.4.2">0.120</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A1.T10.fig2.1.5.4.3">0.742</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Table 10: </span>Hallucination calculation for SAMSum few-shot data</figcaption>
</figure>
</div>
</div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Scalability of DiaSynth</h2>
<div class="ltx_para ltx_noindent" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">This section illustrates the scalability of DiaSynth with a python program and examples.</p>
</div>
<figure class="ltx_float ltx_lstlisting" id="LST1">
<div class="ltx_listing ltx_lst_language_Python ltx_lst_numbers_left ltx_lstlisting ltx_framed ltx_framed_rectangle ltx_listing" id="LST1.1" style="background-color:#F2F2F2;">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,ZGVmIGNhbGN1bGF0ZV90b3RhbF9kaWFsb2dzKG4sIG0sIHApOgogICAgIiIiCiAgICBDYWxjdWxhdGUgdGhlIHRvdGFsIG51bWJlciBvZiBkaWFsb2dzIGdlbmVyYXRlZC4KCiAgICBQYXJhbWV0ZXJzOgogICAgbiAoaW50KTogTnVtYmVyIG9mIHRvcGljcwogICAgbSAoaW50KTogTnVtYmVyIG9mIHN1YnRvcGljcyBwZXIgdG9waWMKICAgIHAgKGludCk6IE51bWJlciBvZiBwZXJzb25hcyBwZXIgc3VidG9waWMKCiAgICBSZXR1cm5zOgogICAgaW50OiBUb3RhbCBudW1iZXIgb2YgZGlhbG9ncyBnZW5lcmF0ZWQKICAgICIiIgogICAgIyBDYWxjdWxhdGUgdGhlIHRvdGFsIG51bWJlciBvZiBzdWJ0b3BpY3MKICAgIHRvdGFsX3N1YnRvcGljcyA9IG4gKiBtCgogICAgIyBDYWxjdWxhdGUgdGhlIG51bWJlciBvZiBkaWFsb2dzIGZvciBlYWNoIHN1YnRvcGljIHVzaW5nIGNvbWJpbmF0aW9ucyBvZiBwZXJzb25hcwogICAgZGlhbG9nc19wZXJfc3VidG9waWMgPSAocCAqIChwIC0gMSkpIC8vIDIKCiAgICAjIFRvdGFsIGRpYWxvZ3MgZ2VuZXJhdGVkIGFjcm9zcyBhbGwgc3VidG9waWNzCiAgICB0b3RhbF9kaWFsb2dzID0gdG90YWxfc3VidG9waWNzICogZGlhbG9nc19wZXJfc3VidG9waWMKCiAgICByZXR1cm4gdG90YWxfZGlhbG9ncw==">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx1">
<span class="ltx_tag ltx_tag_listingline">1</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx1.1" style="color:#0000FF;">def</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx1.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx1.3">calculate_total_dialogs</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.4">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx1.5">n</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.6">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx1.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx1.8">m</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.9">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx1.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx1.11">p</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.12">):</span>
</div>
<div class="ltx_listingline" id="lstnumberx2">
<span class="ltx_tag ltx_tag_listingline">2</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx2.1"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx2.2" style="color:#B30000;">""</span><span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx2.3" style="color:#B30000;">"</span>
</div>
<div class="ltx_listingline" id="lstnumberx3">
<span class="ltx_tag ltx_tag_listingline">3</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.1" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.2" style="color:#B30000;">Calculate</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.3" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.4" style="color:#B30000;">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.5" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.6" style="color:#B30000;">total</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.7" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.8" style="color:#B30000;">number</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.9" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.10" style="color:#B30000;">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.11" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.12" style="color:#B30000;">dialogs</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.13" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.14" style="color:#B30000;">generated.</span>
</div>
<div class="ltx_listingline" id="lstnumberx4">
<span class="ltx_tag ltx_tag_listingline">4</span>
</div>
<div class="ltx_listingline" id="lstnumberx5">
<span class="ltx_tag ltx_tag_listingline">5</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.1" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.2" style="color:#B30000;">Parameters:</span>
</div>
<div class="ltx_listingline" id="lstnumberx6">
<span class="ltx_tag ltx_tag_listingline">6</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.1" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.2" style="color:#B30000;">n</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.3" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.4" style="color:#B30000;">(int):</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.5" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.6" style="color:#B30000;">Number</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.7" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.8" style="color:#B30000;">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.9" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.10" style="color:#B30000;">topics</span>
</div>
<div class="ltx_listingline" id="lstnumberx7">
<span class="ltx_tag ltx_tag_listingline">7</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.1" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.2" style="color:#B30000;">m</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.3" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.4" style="color:#B30000;">(int):</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.5" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.6" style="color:#B30000;">Number</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.7" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.8" style="color:#B30000;">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.9" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.10" style="color:#B30000;">subtopics</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.11" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.12" style="color:#B30000;">per</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.13" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.14" style="color:#B30000;">topic</span>
</div>
<div class="ltx_listingline" id="lstnumberx8">
<span class="ltx_tag ltx_tag_listingline">8</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.1" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.2" style="color:#B30000;">p</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.3" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.4" style="color:#B30000;">(int):</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.5" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.6" style="color:#B30000;">Number</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.7" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.8" style="color:#B30000;">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.9" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.10" style="color:#B30000;">personas</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.11" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.12" style="color:#B30000;">per</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.13" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.14" style="color:#B30000;">subtopic</span>
</div>
<div class="ltx_listingline" id="lstnumberx9">
<span class="ltx_tag ltx_tag_listingline">9</span>
</div>
<div class="ltx_listingline" id="lstnumberx10">
<span class="ltx_tag ltx_tag_listingline">10</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.1" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.2" style="color:#B30000;">Returns:</span>
</div>
<div class="ltx_listingline" id="lstnumberx11">
<span class="ltx_tag ltx_tag_listingline">11</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.1" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.2" style="color:#B30000;">int:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.3" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.4" style="color:#B30000;">Total</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.5" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.6" style="color:#B30000;">number</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.7" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.8" style="color:#B30000;">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.9" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.10" style="color:#B30000;">dialogs</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.11" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.12" style="color:#B30000;">generated</span>
</div>
<div class="ltx_listingline" id="lstnumberx12">
<span class="ltx_tag ltx_tag_listingline">12</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx12.1" style="color:#B30000;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx12.2" style="color:#B30000;">"</span><span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx12.3" style="color:#B30000;">""</span>
</div>
<div class="ltx_listingline" id="lstnumberx13">
<span class="ltx_tag ltx_tag_listingline">13</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.1"> </span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx13.2" style="color:#008000;">#<span class="ltx_text ltx_lst_space" id="lstnumberx13.2.1"> </span>Calculate<span class="ltx_text ltx_lst_space" id="lstnumberx13.2.2"> </span>the<span class="ltx_text ltx_lst_space" id="lstnumberx13.2.3"> </span>total<span class="ltx_text ltx_lst_space" id="lstnumberx13.2.4"> </span>number<span class="ltx_text ltx_lst_space" id="lstnumberx13.2.5"> </span>of<span class="ltx_text ltx_lst_space" id="lstnumberx13.2.6"> </span>subtopics</span>
</div>
<div class="ltx_listingline" id="lstnumberx14">
<span class="ltx_tag ltx_tag_listingline">14</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.2">total_subtopics</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx14.4">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.6">n</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.7"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx14.8">*</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.10">m</span>
</div>
<div class="ltx_listingline" id="lstnumberx15">
<span class="ltx_tag ltx_tag_listingline">15</span>
</div>
<div class="ltx_listingline" id="lstnumberx16">
<span class="ltx_tag ltx_tag_listingline">16</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.1"> </span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx16.2" style="color:#008000;">#<span class="ltx_text ltx_lst_space" id="lstnumberx16.2.1"> </span>Calculate<span class="ltx_text ltx_lst_space" id="lstnumberx16.2.2"> </span>the<span class="ltx_text ltx_lst_space" id="lstnumberx16.2.3"> </span>number<span class="ltx_text ltx_lst_space" id="lstnumberx16.2.4"> </span>of<span class="ltx_text ltx_lst_space" id="lstnumberx16.2.5"> </span>dialogs<span class="ltx_text ltx_lst_space" id="lstnumberx16.2.6"> </span>for<span class="ltx_text ltx_lst_space" id="lstnumberx16.2.7"> </span>each<span class="ltx_text ltx_lst_space" id="lstnumberx16.2.8"> </span>subtopic<span class="ltx_text ltx_lst_space" id="lstnumberx16.2.9"> </span>using<span class="ltx_text ltx_lst_space" id="lstnumberx16.2.10"> </span>combinations<span class="ltx_text ltx_lst_space" id="lstnumberx16.2.11"> </span>of<span class="ltx_text ltx_lst_space" id="lstnumberx16.2.12"> </span>personas</span>
</div>
<div class="ltx_listingline" id="lstnumberx17">
<span class="ltx_tag ltx_tag_listingline">17</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.2">dialogs_per_subtopic</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.4">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.5"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.6">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.7">p</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.8"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.9">*</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.10"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.11">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.12">p</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.13"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.14">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.15"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.16">1))</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.17"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.18">//</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.19"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.20">2</span>
</div>
<div class="ltx_listingline" id="lstnumberx18">
<span class="ltx_tag ltx_tag_listingline">18</span>
</div>
<div class="ltx_listingline" id="lstnumberx19">
<span class="ltx_tag ltx_tag_listingline">19</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.1"> </span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx19.2" style="color:#008000;">#<span class="ltx_text ltx_lst_space" id="lstnumberx19.2.1"> </span>Total<span class="ltx_text ltx_lst_space" id="lstnumberx19.2.2"> </span>dialogs<span class="ltx_text ltx_lst_space" id="lstnumberx19.2.3"> </span>generated<span class="ltx_text ltx_lst_space" id="lstnumberx19.2.4"> </span>across<span class="ltx_text ltx_lst_space" id="lstnumberx19.2.5"> </span>all<span class="ltx_text ltx_lst_space" id="lstnumberx19.2.6"> </span>subtopics</span>
</div>
<div class="ltx_listingline" id="lstnumberx20">
<span class="ltx_tag ltx_tag_listingline">20</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.2">total_dialogs</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.4">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.6">total_subtopics</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.7"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.8">*</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.10">dialogs_per_subtopic</span>
</div>
<div class="ltx_listingline" id="lstnumberx21">
<span class="ltx_tag ltx_tag_listingline">21</span>
</div>
<div class="ltx_listingline" id="lstnumberx22">
<span class="ltx_tag ltx_tag_listingline">22</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.1"> </span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx22.2" style="color:#0000FF;">return</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.4">total_dialogs</span>
</div>
</div>
<figcaption class="ltx_caption" style="background-color:#F2F2F2;"><span class="ltx_tag ltx_tag_float">Listing 1: </span>Calculation of Total Dialogs Generated</figcaption>
</figure>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Example 1</h3>
<div class="ltx_para ltx_noindent" id="A2.SS1.p1">
<ul class="ltx_itemize" id="A2.I1">
<li class="ltx_item" id="A2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i1.p1">
<p class="ltx_p" id="A2.I1.i1.p1.1">Number of topics (<math alttext="n" class="ltx_Math" display="inline" id="A2.I1.i1.p1.1.m1.1"><semantics id="A2.I1.i1.p1.1.m1.1a"><mi id="A2.I1.i1.p1.1.m1.1.1" xref="A2.I1.i1.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="A2.I1.i1.p1.1.m1.1b"><ci id="A2.I1.i1.p1.1.m1.1.1.cmml" xref="A2.I1.i1.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i1.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="A2.I1.i1.p1.1.m1.1d">italic_n</annotation></semantics></math>): 10</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i2.p1">
<p class="ltx_p" id="A2.I1.i2.p1.1">Number of subtopics per topic (<math alttext="m" class="ltx_Math" display="inline" id="A2.I1.i2.p1.1.m1.1"><semantics id="A2.I1.i2.p1.1.m1.1a"><mi id="A2.I1.i2.p1.1.m1.1.1" xref="A2.I1.i2.p1.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="A2.I1.i2.p1.1.m1.1b"><ci id="A2.I1.i2.p1.1.m1.1.1.cmml" xref="A2.I1.i2.p1.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i2.p1.1.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="A2.I1.i2.p1.1.m1.1d">italic_m</annotation></semantics></math>): 5</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="A2.I1.i3.p1">
<p class="ltx_p" id="A2.I1.i3.p1.1">Number of personas per subtopic (<math alttext="p" class="ltx_Math" display="inline" id="A2.I1.i3.p1.1.m1.1"><semantics id="A2.I1.i3.p1.1.m1.1a"><mi id="A2.I1.i3.p1.1.m1.1.1" xref="A2.I1.i3.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.1.m1.1b"><ci id="A2.I1.i3.p1.1.m1.1.1.cmml" xref="A2.I1.i3.p1.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="A2.I1.i3.p1.1.m1.1d">italic_p</annotation></semantics></math>): 3</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS1.p2">
<p class="ltx_p" id="A2.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.1">Calculation:</span></p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A5.EGx2">
<tbody id="A2.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span class="ltx_text ltx_markedasmath" id="A2.Ex1.2.1.1.1">Total subtopics</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=n\times m=10\times 5=50" class="ltx_Math" display="inline" id="A2.Ex1.m2.1"><semantics id="A2.Ex1.m2.1a"><mrow id="A2.Ex1.m2.1.1" xref="A2.Ex1.m2.1.1.cmml"><mi id="A2.Ex1.m2.1.1.2" xref="A2.Ex1.m2.1.1.2.cmml"></mi><mo id="A2.Ex1.m2.1.1.3" xref="A2.Ex1.m2.1.1.3.cmml">=</mo><mrow id="A2.Ex1.m2.1.1.4" xref="A2.Ex1.m2.1.1.4.cmml"><mi id="A2.Ex1.m2.1.1.4.2" xref="A2.Ex1.m2.1.1.4.2.cmml">n</mi><mo id="A2.Ex1.m2.1.1.4.1" lspace="0.222em" rspace="0.222em" xref="A2.Ex1.m2.1.1.4.1.cmml">×</mo><mi id="A2.Ex1.m2.1.1.4.3" xref="A2.Ex1.m2.1.1.4.3.cmml">m</mi></mrow><mo id="A2.Ex1.m2.1.1.5" xref="A2.Ex1.m2.1.1.5.cmml">=</mo><mrow id="A2.Ex1.m2.1.1.6" xref="A2.Ex1.m2.1.1.6.cmml"><mn id="A2.Ex1.m2.1.1.6.2" xref="A2.Ex1.m2.1.1.6.2.cmml">10</mn><mo id="A2.Ex1.m2.1.1.6.1" lspace="0.222em" rspace="0.222em" xref="A2.Ex1.m2.1.1.6.1.cmml">×</mo><mn id="A2.Ex1.m2.1.1.6.3" xref="A2.Ex1.m2.1.1.6.3.cmml">5</mn></mrow><mo id="A2.Ex1.m2.1.1.7" xref="A2.Ex1.m2.1.1.7.cmml">=</mo><mn id="A2.Ex1.m2.1.1.8" xref="A2.Ex1.m2.1.1.8.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.Ex1.m2.1b"><apply id="A2.Ex1.m2.1.1.cmml" xref="A2.Ex1.m2.1.1"><and id="A2.Ex1.m2.1.1a.cmml" xref="A2.Ex1.m2.1.1"></and><apply id="A2.Ex1.m2.1.1b.cmml" xref="A2.Ex1.m2.1.1"><eq id="A2.Ex1.m2.1.1.3.cmml" xref="A2.Ex1.m2.1.1.3"></eq><csymbol cd="latexml" id="A2.Ex1.m2.1.1.2.cmml" xref="A2.Ex1.m2.1.1.2">absent</csymbol><apply id="A2.Ex1.m2.1.1.4.cmml" xref="A2.Ex1.m2.1.1.4"><times id="A2.Ex1.m2.1.1.4.1.cmml" xref="A2.Ex1.m2.1.1.4.1"></times><ci id="A2.Ex1.m2.1.1.4.2.cmml" xref="A2.Ex1.m2.1.1.4.2">𝑛</ci><ci id="A2.Ex1.m2.1.1.4.3.cmml" xref="A2.Ex1.m2.1.1.4.3">𝑚</ci></apply></apply><apply id="A2.Ex1.m2.1.1c.cmml" xref="A2.Ex1.m2.1.1"><eq id="A2.Ex1.m2.1.1.5.cmml" xref="A2.Ex1.m2.1.1.5"></eq><share href="https://arxiv.org/html/2409.19020v2#A2.Ex1.m2.1.1.4.cmml" id="A2.Ex1.m2.1.1d.cmml" xref="A2.Ex1.m2.1.1"></share><apply id="A2.Ex1.m2.1.1.6.cmml" xref="A2.Ex1.m2.1.1.6"><times id="A2.Ex1.m2.1.1.6.1.cmml" xref="A2.Ex1.m2.1.1.6.1"></times><cn id="A2.Ex1.m2.1.1.6.2.cmml" type="integer" xref="A2.Ex1.m2.1.1.6.2">10</cn><cn id="A2.Ex1.m2.1.1.6.3.cmml" type="integer" xref="A2.Ex1.m2.1.1.6.3">5</cn></apply></apply><apply id="A2.Ex1.m2.1.1e.cmml" xref="A2.Ex1.m2.1.1"><eq id="A2.Ex1.m2.1.1.7.cmml" xref="A2.Ex1.m2.1.1.7"></eq><share href="https://arxiv.org/html/2409.19020v2#A2.Ex1.m2.1.1.6.cmml" id="A2.Ex1.m2.1.1f.cmml" xref="A2.Ex1.m2.1.1"></share><cn id="A2.Ex1.m2.1.1.8.cmml" type="integer" xref="A2.Ex1.m2.1.1.8">50</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.Ex1.m2.1c">\displaystyle=n\times m=10\times 5=50</annotation><annotation encoding="application/x-llamapun" id="A2.Ex1.m2.1d">= italic_n × italic_m = 10 × 5 = 50</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="A2.Ex2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span class="ltx_text ltx_markedasmath" id="A2.Ex2.2.1.1.1">Dialogues per subtopic</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\frac{p\times(p-1)}{2}=\frac{3\times 2}{2}=3" class="ltx_Math" display="inline" id="A2.Ex2.m2.1"><semantics id="A2.Ex2.m2.1a"><mrow id="A2.Ex2.m2.1.2" xref="A2.Ex2.m2.1.2.cmml"><mi id="A2.Ex2.m2.1.2.2" xref="A2.Ex2.m2.1.2.2.cmml"></mi><mo id="A2.Ex2.m2.1.2.3" xref="A2.Ex2.m2.1.2.3.cmml">=</mo><mstyle displaystyle="true" id="A2.Ex2.m2.1.1" xref="A2.Ex2.m2.1.1.cmml"><mfrac id="A2.Ex2.m2.1.1a" xref="A2.Ex2.m2.1.1.cmml"><mrow id="A2.Ex2.m2.1.1.1" xref="A2.Ex2.m2.1.1.1.cmml"><mi id="A2.Ex2.m2.1.1.1.3" xref="A2.Ex2.m2.1.1.1.3.cmml">p</mi><mo id="A2.Ex2.m2.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="A2.Ex2.m2.1.1.1.2.cmml">×</mo><mrow id="A2.Ex2.m2.1.1.1.1.1" xref="A2.Ex2.m2.1.1.1.1.1.1.cmml"><mo id="A2.Ex2.m2.1.1.1.1.1.2" stretchy="false" xref="A2.Ex2.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="A2.Ex2.m2.1.1.1.1.1.1" xref="A2.Ex2.m2.1.1.1.1.1.1.cmml"><mi id="A2.Ex2.m2.1.1.1.1.1.1.2" xref="A2.Ex2.m2.1.1.1.1.1.1.2.cmml">p</mi><mo id="A2.Ex2.m2.1.1.1.1.1.1.1" xref="A2.Ex2.m2.1.1.1.1.1.1.1.cmml">−</mo><mn id="A2.Ex2.m2.1.1.1.1.1.1.3" xref="A2.Ex2.m2.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="A2.Ex2.m2.1.1.1.1.1.3" stretchy="false" xref="A2.Ex2.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mn id="A2.Ex2.m2.1.1.3" xref="A2.Ex2.m2.1.1.3.cmml">2</mn></mfrac></mstyle><mo id="A2.Ex2.m2.1.2.4" xref="A2.Ex2.m2.1.2.4.cmml">=</mo><mstyle displaystyle="true" id="A2.Ex2.m2.1.2.5" xref="A2.Ex2.m2.1.2.5.cmml"><mfrac id="A2.Ex2.m2.1.2.5a" xref="A2.Ex2.m2.1.2.5.cmml"><mrow id="A2.Ex2.m2.1.2.5.2" xref="A2.Ex2.m2.1.2.5.2.cmml"><mn id="A2.Ex2.m2.1.2.5.2.2" xref="A2.Ex2.m2.1.2.5.2.2.cmml">3</mn><mo id="A2.Ex2.m2.1.2.5.2.1" lspace="0.222em" rspace="0.222em" xref="A2.Ex2.m2.1.2.5.2.1.cmml">×</mo><mn id="A2.Ex2.m2.1.2.5.2.3" xref="A2.Ex2.m2.1.2.5.2.3.cmml">2</mn></mrow><mn id="A2.Ex2.m2.1.2.5.3" xref="A2.Ex2.m2.1.2.5.3.cmml">2</mn></mfrac></mstyle><mo id="A2.Ex2.m2.1.2.6" xref="A2.Ex2.m2.1.2.6.cmml">=</mo><mn id="A2.Ex2.m2.1.2.7" xref="A2.Ex2.m2.1.2.7.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.Ex2.m2.1b"><apply id="A2.Ex2.m2.1.2.cmml" xref="A2.Ex2.m2.1.2"><and id="A2.Ex2.m2.1.2a.cmml" xref="A2.Ex2.m2.1.2"></and><apply id="A2.Ex2.m2.1.2b.cmml" xref="A2.Ex2.m2.1.2"><eq id="A2.Ex2.m2.1.2.3.cmml" xref="A2.Ex2.m2.1.2.3"></eq><csymbol cd="latexml" id="A2.Ex2.m2.1.2.2.cmml" xref="A2.Ex2.m2.1.2.2">absent</csymbol><apply id="A2.Ex2.m2.1.1.cmml" xref="A2.Ex2.m2.1.1"><divide id="A2.Ex2.m2.1.1.2.cmml" xref="A2.Ex2.m2.1.1"></divide><apply id="A2.Ex2.m2.1.1.1.cmml" xref="A2.Ex2.m2.1.1.1"><times id="A2.Ex2.m2.1.1.1.2.cmml" xref="A2.Ex2.m2.1.1.1.2"></times><ci id="A2.Ex2.m2.1.1.1.3.cmml" xref="A2.Ex2.m2.1.1.1.3">𝑝</ci><apply id="A2.Ex2.m2.1.1.1.1.1.1.cmml" xref="A2.Ex2.m2.1.1.1.1.1"><minus id="A2.Ex2.m2.1.1.1.1.1.1.1.cmml" xref="A2.Ex2.m2.1.1.1.1.1.1.1"></minus><ci id="A2.Ex2.m2.1.1.1.1.1.1.2.cmml" xref="A2.Ex2.m2.1.1.1.1.1.1.2">𝑝</ci><cn id="A2.Ex2.m2.1.1.1.1.1.1.3.cmml" type="integer" xref="A2.Ex2.m2.1.1.1.1.1.1.3">1</cn></apply></apply><cn id="A2.Ex2.m2.1.1.3.cmml" type="integer" xref="A2.Ex2.m2.1.1.3">2</cn></apply></apply><apply id="A2.Ex2.m2.1.2c.cmml" xref="A2.Ex2.m2.1.2"><eq id="A2.Ex2.m2.1.2.4.cmml" xref="A2.Ex2.m2.1.2.4"></eq><share href="https://arxiv.org/html/2409.19020v2#A2.Ex2.m2.1.1.cmml" id="A2.Ex2.m2.1.2d.cmml" xref="A2.Ex2.m2.1.2"></share><apply id="A2.Ex2.m2.1.2.5.cmml" xref="A2.Ex2.m2.1.2.5"><divide id="A2.Ex2.m2.1.2.5.1.cmml" xref="A2.Ex2.m2.1.2.5"></divide><apply id="A2.Ex2.m2.1.2.5.2.cmml" xref="A2.Ex2.m2.1.2.5.2"><times id="A2.Ex2.m2.1.2.5.2.1.cmml" xref="A2.Ex2.m2.1.2.5.2.1"></times><cn id="A2.Ex2.m2.1.2.5.2.2.cmml" type="integer" xref="A2.Ex2.m2.1.2.5.2.2">3</cn><cn id="A2.Ex2.m2.1.2.5.2.3.cmml" type="integer" xref="A2.Ex2.m2.1.2.5.2.3">2</cn></apply><cn id="A2.Ex2.m2.1.2.5.3.cmml" type="integer" xref="A2.Ex2.m2.1.2.5.3">2</cn></apply></apply><apply id="A2.Ex2.m2.1.2e.cmml" xref="A2.Ex2.m2.1.2"><eq id="A2.Ex2.m2.1.2.6.cmml" xref="A2.Ex2.m2.1.2.6"></eq><share href="https://arxiv.org/html/2409.19020v2#A2.Ex2.m2.1.2.5.cmml" id="A2.Ex2.m2.1.2f.cmml" xref="A2.Ex2.m2.1.2"></share><cn id="A2.Ex2.m2.1.2.7.cmml" type="integer" xref="A2.Ex2.m2.1.2.7">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.Ex2.m2.1c">\displaystyle=\frac{p\times(p-1)}{2}=\frac{3\times 2}{2}=3</annotation><annotation encoding="application/x-llamapun" id="A2.Ex2.m2.1d">= divide start_ARG italic_p × ( italic_p - 1 ) end_ARG start_ARG 2 end_ARG = divide start_ARG 3 × 2 end_ARG start_ARG 2 end_ARG = 3</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="A2.Ex3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span class="ltx_text ltx_markedasmath" id="A2.Ex3.2.1.1.1">Total dialogues</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=50\times 3=150" class="ltx_Math" display="inline" id="A2.Ex3.m2.1"><semantics id="A2.Ex3.m2.1a"><mrow id="A2.Ex3.m2.1.1" xref="A2.Ex3.m2.1.1.cmml"><mi id="A2.Ex3.m2.1.1.2" xref="A2.Ex3.m2.1.1.2.cmml"></mi><mo id="A2.Ex3.m2.1.1.3" xref="A2.Ex3.m2.1.1.3.cmml">=</mo><mrow id="A2.Ex3.m2.1.1.4" xref="A2.Ex3.m2.1.1.4.cmml"><mn id="A2.Ex3.m2.1.1.4.2" xref="A2.Ex3.m2.1.1.4.2.cmml">50</mn><mo id="A2.Ex3.m2.1.1.4.1" lspace="0.222em" rspace="0.222em" xref="A2.Ex3.m2.1.1.4.1.cmml">×</mo><mn id="A2.Ex3.m2.1.1.4.3" xref="A2.Ex3.m2.1.1.4.3.cmml">3</mn></mrow><mo id="A2.Ex3.m2.1.1.5" xref="A2.Ex3.m2.1.1.5.cmml">=</mo><mn id="A2.Ex3.m2.1.1.6" xref="A2.Ex3.m2.1.1.6.cmml">150</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.Ex3.m2.1b"><apply id="A2.Ex3.m2.1.1.cmml" xref="A2.Ex3.m2.1.1"><and id="A2.Ex3.m2.1.1a.cmml" xref="A2.Ex3.m2.1.1"></and><apply id="A2.Ex3.m2.1.1b.cmml" xref="A2.Ex3.m2.1.1"><eq id="A2.Ex3.m2.1.1.3.cmml" xref="A2.Ex3.m2.1.1.3"></eq><csymbol cd="latexml" id="A2.Ex3.m2.1.1.2.cmml" xref="A2.Ex3.m2.1.1.2">absent</csymbol><apply id="A2.Ex3.m2.1.1.4.cmml" xref="A2.Ex3.m2.1.1.4"><times id="A2.Ex3.m2.1.1.4.1.cmml" xref="A2.Ex3.m2.1.1.4.1"></times><cn id="A2.Ex3.m2.1.1.4.2.cmml" type="integer" xref="A2.Ex3.m2.1.1.4.2">50</cn><cn id="A2.Ex3.m2.1.1.4.3.cmml" type="integer" xref="A2.Ex3.m2.1.1.4.3">3</cn></apply></apply><apply id="A2.Ex3.m2.1.1c.cmml" xref="A2.Ex3.m2.1.1"><eq id="A2.Ex3.m2.1.1.5.cmml" xref="A2.Ex3.m2.1.1.5"></eq><share href="https://arxiv.org/html/2409.19020v2#A2.Ex3.m2.1.1.4.cmml" id="A2.Ex3.m2.1.1d.cmml" xref="A2.Ex3.m2.1.1"></share><cn id="A2.Ex3.m2.1.1.6.cmml" type="integer" xref="A2.Ex3.m2.1.1.6">150</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.Ex3.m2.1c">\displaystyle=50\times 3=150</annotation><annotation encoding="application/x-llamapun" id="A2.Ex3.m2.1d">= 50 × 3 = 150</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS1.p3">
<p class="ltx_p" id="A2.SS1.p3.1">This setup generates <span class="ltx_text ltx_font_bold" id="A2.SS1.p3.1.1">150 dialogues</span>.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Example 2</h3>
<div class="ltx_para ltx_noindent" id="A2.SS2.p1">
<ul class="ltx_itemize" id="A2.I2">
<li class="ltx_item" id="A2.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I2.i1.p1">
<p class="ltx_p" id="A2.I2.i1.p1.1">Number of topics (<math alttext="n" class="ltx_Math" display="inline" id="A2.I2.i1.p1.1.m1.1"><semantics id="A2.I2.i1.p1.1.m1.1a"><mi id="A2.I2.i1.p1.1.m1.1.1" xref="A2.I2.i1.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="A2.I2.i1.p1.1.m1.1b"><ci id="A2.I2.i1.p1.1.m1.1.1.cmml" xref="A2.I2.i1.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I2.i1.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="A2.I2.i1.p1.1.m1.1d">italic_n</annotation></semantics></math>): 20</p>
</div>
</li>
<li class="ltx_item" id="A2.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I2.i2.p1">
<p class="ltx_p" id="A2.I2.i2.p1.1">Number of subtopics per topic (<math alttext="m" class="ltx_Math" display="inline" id="A2.I2.i2.p1.1.m1.1"><semantics id="A2.I2.i2.p1.1.m1.1a"><mi id="A2.I2.i2.p1.1.m1.1.1" xref="A2.I2.i2.p1.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="A2.I2.i2.p1.1.m1.1b"><ci id="A2.I2.i2.p1.1.m1.1.1.cmml" xref="A2.I2.i2.p1.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I2.i2.p1.1.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="A2.I2.i2.p1.1.m1.1d">italic_m</annotation></semantics></math>): 4</p>
</div>
</li>
<li class="ltx_item" id="A2.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="A2.I2.i3.p1">
<p class="ltx_p" id="A2.I2.i3.p1.1">Number of personas per subtopic (<math alttext="p" class="ltx_Math" display="inline" id="A2.I2.i3.p1.1.m1.1"><semantics id="A2.I2.i3.p1.1.m1.1a"><mi id="A2.I2.i3.p1.1.m1.1.1" xref="A2.I2.i3.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="A2.I2.i3.p1.1.m1.1b"><ci id="A2.I2.i3.p1.1.m1.1.1.cmml" xref="A2.I2.i3.p1.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I2.i3.p1.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="A2.I2.i3.p1.1.m1.1d">italic_p</annotation></semantics></math>): 5</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS2.p2">
<p class="ltx_p" id="A2.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="A2.SS2.p2.1.1">Calculation:</span></p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A5.EGx3">
<tbody id="A2.Ex4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span class="ltx_text ltx_markedasmath" id="A2.Ex4.2.1.1.1">Total subtopics</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=20\times 4=80" class="ltx_Math" display="inline" id="A2.Ex4.m2.1"><semantics id="A2.Ex4.m2.1a"><mrow id="A2.Ex4.m2.1.1" xref="A2.Ex4.m2.1.1.cmml"><mi id="A2.Ex4.m2.1.1.2" xref="A2.Ex4.m2.1.1.2.cmml"></mi><mo id="A2.Ex4.m2.1.1.3" xref="A2.Ex4.m2.1.1.3.cmml">=</mo><mrow id="A2.Ex4.m2.1.1.4" xref="A2.Ex4.m2.1.1.4.cmml"><mn id="A2.Ex4.m2.1.1.4.2" xref="A2.Ex4.m2.1.1.4.2.cmml">20</mn><mo id="A2.Ex4.m2.1.1.4.1" lspace="0.222em" rspace="0.222em" xref="A2.Ex4.m2.1.1.4.1.cmml">×</mo><mn id="A2.Ex4.m2.1.1.4.3" xref="A2.Ex4.m2.1.1.4.3.cmml">4</mn></mrow><mo id="A2.Ex4.m2.1.1.5" xref="A2.Ex4.m2.1.1.5.cmml">=</mo><mn id="A2.Ex4.m2.1.1.6" xref="A2.Ex4.m2.1.1.6.cmml">80</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.Ex4.m2.1b"><apply id="A2.Ex4.m2.1.1.cmml" xref="A2.Ex4.m2.1.1"><and id="A2.Ex4.m2.1.1a.cmml" xref="A2.Ex4.m2.1.1"></and><apply id="A2.Ex4.m2.1.1b.cmml" xref="A2.Ex4.m2.1.1"><eq id="A2.Ex4.m2.1.1.3.cmml" xref="A2.Ex4.m2.1.1.3"></eq><csymbol cd="latexml" id="A2.Ex4.m2.1.1.2.cmml" xref="A2.Ex4.m2.1.1.2">absent</csymbol><apply id="A2.Ex4.m2.1.1.4.cmml" xref="A2.Ex4.m2.1.1.4"><times id="A2.Ex4.m2.1.1.4.1.cmml" xref="A2.Ex4.m2.1.1.4.1"></times><cn id="A2.Ex4.m2.1.1.4.2.cmml" type="integer" xref="A2.Ex4.m2.1.1.4.2">20</cn><cn id="A2.Ex4.m2.1.1.4.3.cmml" type="integer" xref="A2.Ex4.m2.1.1.4.3">4</cn></apply></apply><apply id="A2.Ex4.m2.1.1c.cmml" xref="A2.Ex4.m2.1.1"><eq id="A2.Ex4.m2.1.1.5.cmml" xref="A2.Ex4.m2.1.1.5"></eq><share href="https://arxiv.org/html/2409.19020v2#A2.Ex4.m2.1.1.4.cmml" id="A2.Ex4.m2.1.1d.cmml" xref="A2.Ex4.m2.1.1"></share><cn id="A2.Ex4.m2.1.1.6.cmml" type="integer" xref="A2.Ex4.m2.1.1.6">80</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.Ex4.m2.1c">\displaystyle=20\times 4=80</annotation><annotation encoding="application/x-llamapun" id="A2.Ex4.m2.1d">= 20 × 4 = 80</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="A2.Ex5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span class="ltx_text ltx_markedasmath" id="A2.Ex5.2.1.1.1">Dialogues per subtopic</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\frac{5\times 4}{2}=10" class="ltx_Math" display="inline" id="A2.Ex5.m2.1"><semantics id="A2.Ex5.m2.1a"><mrow id="A2.Ex5.m2.1.1" xref="A2.Ex5.m2.1.1.cmml"><mi id="A2.Ex5.m2.1.1.2" xref="A2.Ex5.m2.1.1.2.cmml"></mi><mo id="A2.Ex5.m2.1.1.3" xref="A2.Ex5.m2.1.1.3.cmml">=</mo><mstyle displaystyle="true" id="A2.Ex5.m2.1.1.4" xref="A2.Ex5.m2.1.1.4.cmml"><mfrac id="A2.Ex5.m2.1.1.4a" xref="A2.Ex5.m2.1.1.4.cmml"><mrow id="A2.Ex5.m2.1.1.4.2" xref="A2.Ex5.m2.1.1.4.2.cmml"><mn id="A2.Ex5.m2.1.1.4.2.2" xref="A2.Ex5.m2.1.1.4.2.2.cmml">5</mn><mo id="A2.Ex5.m2.1.1.4.2.1" lspace="0.222em" rspace="0.222em" xref="A2.Ex5.m2.1.1.4.2.1.cmml">×</mo><mn id="A2.Ex5.m2.1.1.4.2.3" xref="A2.Ex5.m2.1.1.4.2.3.cmml">4</mn></mrow><mn id="A2.Ex5.m2.1.1.4.3" xref="A2.Ex5.m2.1.1.4.3.cmml">2</mn></mfrac></mstyle><mo id="A2.Ex5.m2.1.1.5" xref="A2.Ex5.m2.1.1.5.cmml">=</mo><mn id="A2.Ex5.m2.1.1.6" xref="A2.Ex5.m2.1.1.6.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.Ex5.m2.1b"><apply id="A2.Ex5.m2.1.1.cmml" xref="A2.Ex5.m2.1.1"><and id="A2.Ex5.m2.1.1a.cmml" xref="A2.Ex5.m2.1.1"></and><apply id="A2.Ex5.m2.1.1b.cmml" xref="A2.Ex5.m2.1.1"><eq id="A2.Ex5.m2.1.1.3.cmml" xref="A2.Ex5.m2.1.1.3"></eq><csymbol cd="latexml" id="A2.Ex5.m2.1.1.2.cmml" xref="A2.Ex5.m2.1.1.2">absent</csymbol><apply id="A2.Ex5.m2.1.1.4.cmml" xref="A2.Ex5.m2.1.1.4"><divide id="A2.Ex5.m2.1.1.4.1.cmml" xref="A2.Ex5.m2.1.1.4"></divide><apply id="A2.Ex5.m2.1.1.4.2.cmml" xref="A2.Ex5.m2.1.1.4.2"><times id="A2.Ex5.m2.1.1.4.2.1.cmml" xref="A2.Ex5.m2.1.1.4.2.1"></times><cn id="A2.Ex5.m2.1.1.4.2.2.cmml" type="integer" xref="A2.Ex5.m2.1.1.4.2.2">5</cn><cn id="A2.Ex5.m2.1.1.4.2.3.cmml" type="integer" xref="A2.Ex5.m2.1.1.4.2.3">4</cn></apply><cn id="A2.Ex5.m2.1.1.4.3.cmml" type="integer" xref="A2.Ex5.m2.1.1.4.3">2</cn></apply></apply><apply id="A2.Ex5.m2.1.1c.cmml" xref="A2.Ex5.m2.1.1"><eq id="A2.Ex5.m2.1.1.5.cmml" xref="A2.Ex5.m2.1.1.5"></eq><share href="https://arxiv.org/html/2409.19020v2#A2.Ex5.m2.1.1.4.cmml" id="A2.Ex5.m2.1.1d.cmml" xref="A2.Ex5.m2.1.1"></share><cn id="A2.Ex5.m2.1.1.6.cmml" type="integer" xref="A2.Ex5.m2.1.1.6">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.Ex5.m2.1c">\displaystyle=\frac{5\times 4}{2}=10</annotation><annotation encoding="application/x-llamapun" id="A2.Ex5.m2.1d">= divide start_ARG 5 × 4 end_ARG start_ARG 2 end_ARG = 10</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="A2.Ex6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span class="ltx_text ltx_markedasmath" id="A2.Ex6.2.1.1.1">Total dialogues</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=80\times 10=800" class="ltx_Math" display="inline" id="A2.Ex6.m2.1"><semantics id="A2.Ex6.m2.1a"><mrow id="A2.Ex6.m2.1.1" xref="A2.Ex6.m2.1.1.cmml"><mi id="A2.Ex6.m2.1.1.2" xref="A2.Ex6.m2.1.1.2.cmml"></mi><mo id="A2.Ex6.m2.1.1.3" xref="A2.Ex6.m2.1.1.3.cmml">=</mo><mrow id="A2.Ex6.m2.1.1.4" xref="A2.Ex6.m2.1.1.4.cmml"><mn id="A2.Ex6.m2.1.1.4.2" xref="A2.Ex6.m2.1.1.4.2.cmml">80</mn><mo id="A2.Ex6.m2.1.1.4.1" lspace="0.222em" rspace="0.222em" xref="A2.Ex6.m2.1.1.4.1.cmml">×</mo><mn id="A2.Ex6.m2.1.1.4.3" xref="A2.Ex6.m2.1.1.4.3.cmml">10</mn></mrow><mo id="A2.Ex6.m2.1.1.5" xref="A2.Ex6.m2.1.1.5.cmml">=</mo><mn id="A2.Ex6.m2.1.1.6" xref="A2.Ex6.m2.1.1.6.cmml">800</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.Ex6.m2.1b"><apply id="A2.Ex6.m2.1.1.cmml" xref="A2.Ex6.m2.1.1"><and id="A2.Ex6.m2.1.1a.cmml" xref="A2.Ex6.m2.1.1"></and><apply id="A2.Ex6.m2.1.1b.cmml" xref="A2.Ex6.m2.1.1"><eq id="A2.Ex6.m2.1.1.3.cmml" xref="A2.Ex6.m2.1.1.3"></eq><csymbol cd="latexml" id="A2.Ex6.m2.1.1.2.cmml" xref="A2.Ex6.m2.1.1.2">absent</csymbol><apply id="A2.Ex6.m2.1.1.4.cmml" xref="A2.Ex6.m2.1.1.4"><times id="A2.Ex6.m2.1.1.4.1.cmml" xref="A2.Ex6.m2.1.1.4.1"></times><cn id="A2.Ex6.m2.1.1.4.2.cmml" type="integer" xref="A2.Ex6.m2.1.1.4.2">80</cn><cn id="A2.Ex6.m2.1.1.4.3.cmml" type="integer" xref="A2.Ex6.m2.1.1.4.3">10</cn></apply></apply><apply id="A2.Ex6.m2.1.1c.cmml" xref="A2.Ex6.m2.1.1"><eq id="A2.Ex6.m2.1.1.5.cmml" xref="A2.Ex6.m2.1.1.5"></eq><share href="https://arxiv.org/html/2409.19020v2#A2.Ex6.m2.1.1.4.cmml" id="A2.Ex6.m2.1.1d.cmml" xref="A2.Ex6.m2.1.1"></share><cn id="A2.Ex6.m2.1.1.6.cmml" type="integer" xref="A2.Ex6.m2.1.1.6">800</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.Ex6.m2.1c">\displaystyle=80\times 10=800</annotation><annotation encoding="application/x-llamapun" id="A2.Ex6.m2.1d">= 80 × 10 = 800</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS2.p3">
<p class="ltx_p" id="A2.SS2.p3.1">This setup generates <span class="ltx_text ltx_font_bold" id="A2.SS2.p3.1.1">800 dialogues</span>.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Example 3</h3>
<div class="ltx_para ltx_noindent" id="A2.SS3.p1">
<ul class="ltx_itemize" id="A2.I3">
<li class="ltx_item" id="A2.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I3.i1.p1">
<p class="ltx_p" id="A2.I3.i1.p1.1">Number of topics (<math alttext="n" class="ltx_Math" display="inline" id="A2.I3.i1.p1.1.m1.1"><semantics id="A2.I3.i1.p1.1.m1.1a"><mi id="A2.I3.i1.p1.1.m1.1.1" xref="A2.I3.i1.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="A2.I3.i1.p1.1.m1.1b"><ci id="A2.I3.i1.p1.1.m1.1.1.cmml" xref="A2.I3.i1.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I3.i1.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="A2.I3.i1.p1.1.m1.1d">italic_n</annotation></semantics></math>): 15</p>
</div>
</li>
<li class="ltx_item" id="A2.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I3.i2.p1">
<p class="ltx_p" id="A2.I3.i2.p1.1">Number of subtopics per topic (<math alttext="m" class="ltx_Math" display="inline" id="A2.I3.i2.p1.1.m1.1"><semantics id="A2.I3.i2.p1.1.m1.1a"><mi id="A2.I3.i2.p1.1.m1.1.1" xref="A2.I3.i2.p1.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="A2.I3.i2.p1.1.m1.1b"><ci id="A2.I3.i2.p1.1.m1.1.1.cmml" xref="A2.I3.i2.p1.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I3.i2.p1.1.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="A2.I3.i2.p1.1.m1.1d">italic_m</annotation></semantics></math>): 6</p>
</div>
</li>
<li class="ltx_item" id="A2.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="A2.I3.i3.p1">
<p class="ltx_p" id="A2.I3.i3.p1.1">Number of personas per subtopic (<math alttext="p" class="ltx_Math" display="inline" id="A2.I3.i3.p1.1.m1.1"><semantics id="A2.I3.i3.p1.1.m1.1a"><mi id="A2.I3.i3.p1.1.m1.1.1" xref="A2.I3.i3.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="A2.I3.i3.p1.1.m1.1b"><ci id="A2.I3.i3.p1.1.m1.1.1.cmml" xref="A2.I3.i3.p1.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I3.i3.p1.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="A2.I3.i3.p1.1.m1.1d">italic_p</annotation></semantics></math>): 10</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS3.p2">
<p class="ltx_p" id="A2.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="A2.SS3.p2.1.1">Calculation:</span></p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A5.EGx4">
<tbody id="A2.Ex7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span class="ltx_text ltx_markedasmath" id="A2.Ex7.2.1.1.1">Total subtopics</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=15\times 6=90" class="ltx_Math" display="inline" id="A2.Ex7.m2.1"><semantics id="A2.Ex7.m2.1a"><mrow id="A2.Ex7.m2.1.1" xref="A2.Ex7.m2.1.1.cmml"><mi id="A2.Ex7.m2.1.1.2" xref="A2.Ex7.m2.1.1.2.cmml"></mi><mo id="A2.Ex7.m2.1.1.3" xref="A2.Ex7.m2.1.1.3.cmml">=</mo><mrow id="A2.Ex7.m2.1.1.4" xref="A2.Ex7.m2.1.1.4.cmml"><mn id="A2.Ex7.m2.1.1.4.2" xref="A2.Ex7.m2.1.1.4.2.cmml">15</mn><mo id="A2.Ex7.m2.1.1.4.1" lspace="0.222em" rspace="0.222em" xref="A2.Ex7.m2.1.1.4.1.cmml">×</mo><mn id="A2.Ex7.m2.1.1.4.3" xref="A2.Ex7.m2.1.1.4.3.cmml">6</mn></mrow><mo id="A2.Ex7.m2.1.1.5" xref="A2.Ex7.m2.1.1.5.cmml">=</mo><mn id="A2.Ex7.m2.1.1.6" xref="A2.Ex7.m2.1.1.6.cmml">90</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.Ex7.m2.1b"><apply id="A2.Ex7.m2.1.1.cmml" xref="A2.Ex7.m2.1.1"><and id="A2.Ex7.m2.1.1a.cmml" xref="A2.Ex7.m2.1.1"></and><apply id="A2.Ex7.m2.1.1b.cmml" xref="A2.Ex7.m2.1.1"><eq id="A2.Ex7.m2.1.1.3.cmml" xref="A2.Ex7.m2.1.1.3"></eq><csymbol cd="latexml" id="A2.Ex7.m2.1.1.2.cmml" xref="A2.Ex7.m2.1.1.2">absent</csymbol><apply id="A2.Ex7.m2.1.1.4.cmml" xref="A2.Ex7.m2.1.1.4"><times id="A2.Ex7.m2.1.1.4.1.cmml" xref="A2.Ex7.m2.1.1.4.1"></times><cn id="A2.Ex7.m2.1.1.4.2.cmml" type="integer" xref="A2.Ex7.m2.1.1.4.2">15</cn><cn id="A2.Ex7.m2.1.1.4.3.cmml" type="integer" xref="A2.Ex7.m2.1.1.4.3">6</cn></apply></apply><apply id="A2.Ex7.m2.1.1c.cmml" xref="A2.Ex7.m2.1.1"><eq id="A2.Ex7.m2.1.1.5.cmml" xref="A2.Ex7.m2.1.1.5"></eq><share href="https://arxiv.org/html/2409.19020v2#A2.Ex7.m2.1.1.4.cmml" id="A2.Ex7.m2.1.1d.cmml" xref="A2.Ex7.m2.1.1"></share><cn id="A2.Ex7.m2.1.1.6.cmml" type="integer" xref="A2.Ex7.m2.1.1.6">90</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.Ex7.m2.1c">\displaystyle=15\times 6=90</annotation><annotation encoding="application/x-llamapun" id="A2.Ex7.m2.1d">= 15 × 6 = 90</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="A2.Ex8"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span class="ltx_text ltx_markedasmath" id="A2.Ex8.2.1.1.1">Dialogues per subtopic</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\frac{10\times 9}{2}=45" class="ltx_Math" display="inline" id="A2.Ex8.m2.1"><semantics id="A2.Ex8.m2.1a"><mrow id="A2.Ex8.m2.1.1" xref="A2.Ex8.m2.1.1.cmml"><mi id="A2.Ex8.m2.1.1.2" xref="A2.Ex8.m2.1.1.2.cmml"></mi><mo id="A2.Ex8.m2.1.1.3" xref="A2.Ex8.m2.1.1.3.cmml">=</mo><mstyle displaystyle="true" id="A2.Ex8.m2.1.1.4" xref="A2.Ex8.m2.1.1.4.cmml"><mfrac id="A2.Ex8.m2.1.1.4a" xref="A2.Ex8.m2.1.1.4.cmml"><mrow id="A2.Ex8.m2.1.1.4.2" xref="A2.Ex8.m2.1.1.4.2.cmml"><mn id="A2.Ex8.m2.1.1.4.2.2" xref="A2.Ex8.m2.1.1.4.2.2.cmml">10</mn><mo id="A2.Ex8.m2.1.1.4.2.1" lspace="0.222em" rspace="0.222em" xref="A2.Ex8.m2.1.1.4.2.1.cmml">×</mo><mn id="A2.Ex8.m2.1.1.4.2.3" xref="A2.Ex8.m2.1.1.4.2.3.cmml">9</mn></mrow><mn id="A2.Ex8.m2.1.1.4.3" xref="A2.Ex8.m2.1.1.4.3.cmml">2</mn></mfrac></mstyle><mo id="A2.Ex8.m2.1.1.5" xref="A2.Ex8.m2.1.1.5.cmml">=</mo><mn id="A2.Ex8.m2.1.1.6" xref="A2.Ex8.m2.1.1.6.cmml">45</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.Ex8.m2.1b"><apply id="A2.Ex8.m2.1.1.cmml" xref="A2.Ex8.m2.1.1"><and id="A2.Ex8.m2.1.1a.cmml" xref="A2.Ex8.m2.1.1"></and><apply id="A2.Ex8.m2.1.1b.cmml" xref="A2.Ex8.m2.1.1"><eq id="A2.Ex8.m2.1.1.3.cmml" xref="A2.Ex8.m2.1.1.3"></eq><csymbol cd="latexml" id="A2.Ex8.m2.1.1.2.cmml" xref="A2.Ex8.m2.1.1.2">absent</csymbol><apply id="A2.Ex8.m2.1.1.4.cmml" xref="A2.Ex8.m2.1.1.4"><divide id="A2.Ex8.m2.1.1.4.1.cmml" xref="A2.Ex8.m2.1.1.4"></divide><apply id="A2.Ex8.m2.1.1.4.2.cmml" xref="A2.Ex8.m2.1.1.4.2"><times id="A2.Ex8.m2.1.1.4.2.1.cmml" xref="A2.Ex8.m2.1.1.4.2.1"></times><cn id="A2.Ex8.m2.1.1.4.2.2.cmml" type="integer" xref="A2.Ex8.m2.1.1.4.2.2">10</cn><cn id="A2.Ex8.m2.1.1.4.2.3.cmml" type="integer" xref="A2.Ex8.m2.1.1.4.2.3">9</cn></apply><cn id="A2.Ex8.m2.1.1.4.3.cmml" type="integer" xref="A2.Ex8.m2.1.1.4.3">2</cn></apply></apply><apply id="A2.Ex8.m2.1.1c.cmml" xref="A2.Ex8.m2.1.1"><eq id="A2.Ex8.m2.1.1.5.cmml" xref="A2.Ex8.m2.1.1.5"></eq><share href="https://arxiv.org/html/2409.19020v2#A2.Ex8.m2.1.1.4.cmml" id="A2.Ex8.m2.1.1d.cmml" xref="A2.Ex8.m2.1.1"></share><cn id="A2.Ex8.m2.1.1.6.cmml" type="integer" xref="A2.Ex8.m2.1.1.6">45</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.Ex8.m2.1c">\displaystyle=\frac{10\times 9}{2}=45</annotation><annotation encoding="application/x-llamapun" id="A2.Ex8.m2.1d">= divide start_ARG 10 × 9 end_ARG start_ARG 2 end_ARG = 45</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="A2.Ex9"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span class="ltx_text ltx_markedasmath" id="A2.Ex9.2.1.1.1">Total dialogues</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=90\times 45=4050" class="ltx_Math" display="inline" id="A2.Ex9.m2.1"><semantics id="A2.Ex9.m2.1a"><mrow id="A2.Ex9.m2.1.1" xref="A2.Ex9.m2.1.1.cmml"><mi id="A2.Ex9.m2.1.1.2" xref="A2.Ex9.m2.1.1.2.cmml"></mi><mo id="A2.Ex9.m2.1.1.3" xref="A2.Ex9.m2.1.1.3.cmml">=</mo><mrow id="A2.Ex9.m2.1.1.4" xref="A2.Ex9.m2.1.1.4.cmml"><mn id="A2.Ex9.m2.1.1.4.2" xref="A2.Ex9.m2.1.1.4.2.cmml">90</mn><mo id="A2.Ex9.m2.1.1.4.1" lspace="0.222em" rspace="0.222em" xref="A2.Ex9.m2.1.1.4.1.cmml">×</mo><mn id="A2.Ex9.m2.1.1.4.3" xref="A2.Ex9.m2.1.1.4.3.cmml">45</mn></mrow><mo id="A2.Ex9.m2.1.1.5" xref="A2.Ex9.m2.1.1.5.cmml">=</mo><mn id="A2.Ex9.m2.1.1.6" xref="A2.Ex9.m2.1.1.6.cmml">4050</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.Ex9.m2.1b"><apply id="A2.Ex9.m2.1.1.cmml" xref="A2.Ex9.m2.1.1"><and id="A2.Ex9.m2.1.1a.cmml" xref="A2.Ex9.m2.1.1"></and><apply id="A2.Ex9.m2.1.1b.cmml" xref="A2.Ex9.m2.1.1"><eq id="A2.Ex9.m2.1.1.3.cmml" xref="A2.Ex9.m2.1.1.3"></eq><csymbol cd="latexml" id="A2.Ex9.m2.1.1.2.cmml" xref="A2.Ex9.m2.1.1.2">absent</csymbol><apply id="A2.Ex9.m2.1.1.4.cmml" xref="A2.Ex9.m2.1.1.4"><times id="A2.Ex9.m2.1.1.4.1.cmml" xref="A2.Ex9.m2.1.1.4.1"></times><cn id="A2.Ex9.m2.1.1.4.2.cmml" type="integer" xref="A2.Ex9.m2.1.1.4.2">90</cn><cn id="A2.Ex9.m2.1.1.4.3.cmml" type="integer" xref="A2.Ex9.m2.1.1.4.3">45</cn></apply></apply><apply id="A2.Ex9.m2.1.1c.cmml" xref="A2.Ex9.m2.1.1"><eq id="A2.Ex9.m2.1.1.5.cmml" xref="A2.Ex9.m2.1.1.5"></eq><share href="https://arxiv.org/html/2409.19020v2#A2.Ex9.m2.1.1.4.cmml" id="A2.Ex9.m2.1.1d.cmml" xref="A2.Ex9.m2.1.1"></share><cn id="A2.Ex9.m2.1.1.6.cmml" type="integer" xref="A2.Ex9.m2.1.1.6">4050</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.Ex9.m2.1c">\displaystyle=90\times 45=4050</annotation><annotation encoding="application/x-llamapun" id="A2.Ex9.m2.1d">= 90 × 45 = 4050</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS3.p3">
<p class="ltx_p" id="A2.SS3.p3.1">This setup generates <span class="ltx_text ltx_font_bold" id="A2.SS3.p3.1.1">4050 dialogues</span>.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.4 </span>Scaling Observations</h3>
<div class="ltx_para ltx_noindent" id="A2.SS4.p1">
<ul class="ltx_itemize" id="A2.I4">
<li class="ltx_item" id="A2.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I4.i1.p1">
<p class="ltx_p" id="A2.I4.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I4.i1.p1.1.1">Linear Scaling with Topics and Subtopics</span>: Increasing the number of topics or subtopics results in a linear increase in the total number of dialogues, making it straightforward to expand the scope of dialogue generation.</p>
</div>
</li>
<li class="ltx_item" id="A2.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I4.i2.p1">
<p class="ltx_p" id="A2.I4.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I4.i2.p1.1.1">Exponential Scaling with Personas</span>: The number of dialogues scales exponentially as the number of personas increases because each additional persona allows for more combinations, making the framework highly scalable for complex scenarios.</p>
</div>
</li>
<li class="ltx_item" id="A2.I4.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="A2.I4.i3.p1">
<p class="ltx_p" id="A2.I4.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I4.i3.p1.1.1">Practical Use Case</span>: For specific domains like academic, healthcare, or business, these parameters can be adjusted to generate thousands of dialogues to fit the needs of various applications such as training chatbots, virtual assistants, or dialogue-based assessments.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS4.p2">
<p class="ltx_p" id="A2.SS4.p2.1">These examples illustrate DiaSynth’s potential for rapid and scalable generation of dialogues, which can be tailored to different domains by simply adjusting the input parameters.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Characteristics for the conversation</h2>
<div class="ltx_para ltx_noindent" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A3.T11" title="Table 11 ‣ Appendix C Characteristics for the conversation ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">11</span></a> shows different characteristics that we let the LLMs reason and decide using CoT. Before generating the dialogues, the LLMs are prompted to first reason about the various characteristics list for the dialogue given the topic and the personas and how the LLMs reason are illustrated in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A4" title="Appendix D Example CoT environments ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
<figure class="ltx_table" id="A3.T11">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A3.T11.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A3.T11.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="A3.T11.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.1.1.1.1">
<span class="ltx_p" id="A3.T11.1.1.1.1.1.1" style="width:151.8pt;"><span class="ltx_text ltx_font_bold" id="A3.T11.1.1.1.1.1.1.1">Characteristic</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A3.T11.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.1.1.2.1">
<span class="ltx_p" id="A3.T11.1.1.1.2.1.1" style="width:238.5pt;"><span class="ltx_text ltx_font_bold" id="A3.T11.1.1.1.2.1.1.1">Description</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T11.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A3.T11.1.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.2.1.1.1">
<span class="ltx_p" id="A3.T11.1.2.1.1.1.1" style="width:151.8pt;">Age and Gender</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T11.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.2.1.2.1">
<span class="ltx_p" id="A3.T11.1.2.1.2.1.1" style="width:238.5pt;">Defines demographic details, influencing style and tone.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T11.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A3.T11.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.3.2.1.1">
<span class="ltx_p" id="A3.T11.1.3.2.1.1.1" style="width:151.8pt;">Familiarity Level</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T11.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.3.2.2.1">
<span class="ltx_p" id="A3.T11.1.3.2.2.1.1" style="width:238.5pt;">Affects formality and depth based on relationship between speakers.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T11.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A3.T11.1.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.4.3.1.1">
<span class="ltx_p" id="A3.T11.1.4.3.1.1.1" style="width:151.8pt;">Emotional States</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T11.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.4.3.2.1">
<span class="ltx_p" id="A3.T11.1.4.3.2.1.1" style="width:238.5pt;">Impacts tone and flow based on emotions (e.g., happy, sad).</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T11.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A3.T11.1.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.5.4.1.1">
<span class="ltx_p" id="A3.T11.1.5.4.1.1.1" style="width:151.8pt;">Formality Level</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T11.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.5.4.2.1">
<span class="ltx_p" id="A3.T11.1.5.4.2.1.1" style="width:238.5pt;">Determines level of politeness or casualness.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T11.1.6.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A3.T11.1.6.5.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.6.5.1.1">
<span class="ltx_p" id="A3.T11.1.6.5.1.1.1" style="width:151.8pt;">Duration of the Conversation</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T11.1.6.5.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.6.5.2.1">
<span class="ltx_p" id="A3.T11.1.6.5.2.1.1" style="width:238.5pt;">Suggests the intended length and complexity of dialogue.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T11.1.7.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A3.T11.1.7.6.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.7.6.1.1">
<span class="ltx_p" id="A3.T11.1.7.6.1.1.1" style="width:151.8pt;">Communication Medium</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T11.1.7.6.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.7.6.2.1">
<span class="ltx_p" id="A3.T11.1.7.6.2.1.1" style="width:238.5pt;">Defines the medium (e.g., face-to-face, phone), influencing style.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T11.1.8.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A3.T11.1.8.7.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.8.7.1.1">
<span class="ltx_p" id="A3.T11.1.8.7.1.1.1" style="width:151.8pt;">Topic of the Conversation</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T11.1.8.7.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.8.7.2.1">
<span class="ltx_p" id="A3.T11.1.8.7.2.1.1" style="width:238.5pt;">Guides the content and direction of the dialogue.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T11.1.9.8">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A3.T11.1.9.8.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.9.8.1.1">
<span class="ltx_p" id="A3.T11.1.9.8.1.1.1" style="width:151.8pt;">Location of the Conversation</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T11.1.9.8.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.9.8.2.1">
<span class="ltx_p" id="A3.T11.1.9.8.2.1.1" style="width:238.5pt;">Adds context influencing formality and content.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T11.1.10.9">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A3.T11.1.10.9.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.10.9.1.1">
<span class="ltx_p" id="A3.T11.1.10.9.1.1.1" style="width:151.8pt;">Agreement or Disagreement</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T11.1.10.9.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.10.9.2.1">
<span class="ltx_p" id="A3.T11.1.10.9.2.1.1" style="width:238.5pt;">Drives dialogue dynamics based on agreement level.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T11.1.11.10">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="A3.T11.1.11.10.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.11.10.1.1">
<span class="ltx_p" id="A3.T11.1.11.10.1.1.1" style="width:151.8pt;">Natural Dialogue Features</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="A3.T11.1.11.10.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T11.1.11.10.2.1">
<span class="ltx_p" id="A3.T11.1.11.10.2.1.1" style="width:238.5pt;">Adds authenticity with fillers, pauses, and slang.</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>Characteristics of the Dialogue for CoT Prompt</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Example CoT environments</h2>
<div class="ltx_para ltx_noindent" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">These examples illustrate how CoT sets the various dialogue characteristics defined in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A3" title="Appendix C Characteristics for the conversation ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">C</span></a>. As can be seen in the examples, the characteristics for the conversation are completely changed based on the personas and the topics, resulting in more grounded conversation generation. Future works can further explore how CoT can be used to further break down to generate even more realistic dialogues.</p>
</div>
<figure class="ltx_figure" id="A4.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A4.F2.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="818" id="A4.F2.sf1.g1" src="extracted/5928586/cot_example_1.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>CoT Example 1</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A4.F2.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="818" id="A4.F2.sf2.g1" src="extracted/5928586/cot_example_2.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>CoT Example 2</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Illustration of Example CoT environments</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Ablation study on the use of CoT</h2>
<div class="ltx_para ltx_noindent" id="A5.p1">
<p class="ltx_p" id="A5.p1.1">In this section of the appendix, we present the impact of CoT in the dialogues generated by DiaSynth. We generate two datasets without CoT, using Phi-3 using DialogSum and SAMSum as few-shot examples with 8 topics. Tables <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A5.T13" title="Table 13 ‣ Appendix E Ablation study on the use of CoT ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">13</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A5.T13" title="Table 13 ‣ Appendix E Ablation study on the use of CoT ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">13</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A5.T15" title="Table 15 ‣ Appendix E Ablation study on the use of CoT ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">15</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A5.T15" title="Table 15 ‣ Appendix E Ablation study on the use of CoT ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">15</span></a> compare the scores of dialogues generated with and without CoT for the FED score and GPTScore and it can be clearly that CoT tends to increase the quality of the dialogues generated by DiaSynth.</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.p2">
<p class="ltx_p" id="A5.p2.1">We hypothesize that this improvement in quality is due to allowing the LLM to set diverse characteristics for the dialogue before generating the dialogue. This illustrates that either manually setting the relevant context or letting the LLM on its own to set the relevant context, we get better outputs, as adding relevant context lowers the probabilities of sequences that are not useful. The lower FED scores of CoT generated dialogues in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19020v2#A5.T15" title="Table 15 ‣ Appendix E Ablation study on the use of CoT ‣ DiaSynth: Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications"><span class="ltx_text ltx_ref_tag">15</span></a>, might be because of the CoT generated dialogues being longer in length but it needs further research.</p>
</div>
<figure class="ltx_table" id="A5.T13">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A5.T13.fig1" style="width:195.1pt;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A5.T13.fig1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A5.T13.fig1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A5.T13.fig1.1.1.1.1.1">Criteria</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T13.fig1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A5.T13.fig1.1.1.1.2.1">Without CoT</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T13.fig1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig1.1.1.1.3.1">With CoT</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T13.fig1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig1.1.2.1.1">Coherent</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.2.1.2">0.9507</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.2.1.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig1.1.2.1.3.1">0.9521</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig1.1.3.2.1">Error Recovery</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.3.2.2">0.938</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.3.2.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig1.1.3.2.3.1">0.9424</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig1.1.4.3.1">Consistent</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.4.3.2">0.9424</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.4.3.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig1.1.4.3.3.1">0.9523</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig1.1.5.4.1">Diverse</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.5.4.2">0.9431</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.5.4.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig1.1.5.4.3.1">0.952</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig1.1.6.5.1">Depth</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.6.5.2">0.9451</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.6.5.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig1.1.6.5.3.1">0.9506</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig1.1.7.6.1">Likeable</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.7.6.2"><span class="ltx_text ltx_font_bold" id="A5.T13.fig1.1.7.6.2.1">0.0088</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.7.6.3">-0.0003</td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig1.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig1.1.8.7.1">Understand</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.8.7.2">0.9317</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.8.7.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig1.1.8.7.3.1">0.9338</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig1.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig1.1.9.8.1">Flexible</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.9.8.2">-0.0013</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.9.8.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig1.1.9.8.3.1">0.0001</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig1.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig1.1.10.9.1">Informative</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.10.9.2"><span class="ltx_text ltx_font_bold" id="A5.T13.fig1.1.10.9.2.1">0.0032</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig1.1.10.9.3">0.0009</td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig1.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig1.1.11.10.1">Inquisitive</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A5.T13.fig1.1.11.10.2"><span class="ltx_text ltx_font_bold" id="A5.T13.fig1.1.11.10.2.1">0.0095</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A5.T13.fig1.1.11.10.3">-0.003</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Table 12: </span>FED scores of dialogues generated with and without CoT for DialogSum few-shot</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A5.T13.fig2" style="width:195.1pt;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A5.T13.fig2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A5.T13.fig2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A5.T13.fig2.1.1.1.1.1">Criteria</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T13.fig2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A5.T13.fig2.1.1.1.2.1">Without CoT</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T13.fig2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig2.1.1.1.3.1">With CoT</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T13.fig2.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig2.1.2.1.1">Coherence</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.2.1.2">0.0052</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.2.1.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig2.1.2.1.3.1">0.0284</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig2.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig2.1.3.2.1">Diversity</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.3.2.2">0.0120</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.3.2.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig2.1.3.2.3.1">0.0303</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig2.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig2.1.4.3.1">Flexibility</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.4.3.2">0.0074</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.4.3.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig2.1.4.3.3.1">0.0215</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig2.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig2.1.5.4.1">Understandability</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.5.4.2">0.0056</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.5.4.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig2.1.5.4.3.1">0.019</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig2.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig2.1.6.5.1">Inquistiveness</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.6.5.2">0.0162</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.6.5.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig2.1.6.5.3.1">0.0362</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig2.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig2.1.7.6.1">Consistency</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.7.6.2">0.0091</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.7.6.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig2.1.7.6.3.1">0.0366</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig2.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig2.1.8.7.1">Informativeness</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.8.7.2">0.0099</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.8.7.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig2.1.8.7.3.1">0.0168</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig2.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig2.1.9.8.1">Likeability</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.9.8.2">0.0029</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.9.8.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig2.1.9.8.3.1">0.0209</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig2.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig2.1.10.9.1">Depth</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.10.9.2">0.0062</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T13.fig2.1.10.9.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig2.1.10.9.3.1">0.0115</span></td>
</tr>
<tr class="ltx_tr" id="A5.T13.fig2.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="A5.T13.fig2.1.11.10.1">Error Recovery</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A5.T13.fig2.1.11.10.2">0.0142</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A5.T13.fig2.1.11.10.3"><span class="ltx_text ltx_font_bold" id="A5.T13.fig2.1.11.10.3.1">0.0242</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Table 13: </span>GPTScore of dialogues generated with and without CoT for DialogSum few-shot</figcaption>
</figure>
</div>
</div>
</figure>
<figure class="ltx_table" id="A5.T15">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A5.T15.fig1" style="width:195.1pt;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A5.T15.fig1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A5.T15.fig1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A5.T15.fig1.1.1.1.1.1">Criteria</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T15.fig1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A5.T15.fig1.1.1.1.2.1">Without CoT</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T15.fig1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A5.T15.fig1.1.1.1.3.1">With CoT</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T15.fig1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig1.1.2.1.1">Coherent</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.2.1.2"><span class="ltx_text ltx_font_bold" id="A5.T15.fig1.1.2.1.2.1">0.9667</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.2.1.3">0.9125</td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig1.1.3.2.1">Error Recovery</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.3.2.2"><span class="ltx_text ltx_font_bold" id="A5.T15.fig1.1.3.2.2.1">0.9577</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.3.2.3">0.9051</td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig1.1.4.3.1">Consistent</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.4.3.2"><span class="ltx_text ltx_font_bold" id="A5.T15.fig1.1.4.3.2.1">0.9621</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.4.3.3">0.9163</td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig1.1.5.4.1">Diverse</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.5.4.2"><span class="ltx_text ltx_font_bold" id="A5.T15.fig1.1.5.4.2.1">0.9586</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.5.4.3">0.9124</td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig1.1.6.5.1">Depth</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.6.5.2"><span class="ltx_text ltx_font_bold" id="A5.T15.fig1.1.6.5.2.1">0.9589</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.6.5.3">0.9094</td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig1.1.7.6.1">Likeable</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.7.6.2"><span class="ltx_text ltx_font_bold" id="A5.T15.fig1.1.7.6.2.1">0.0059</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.7.6.3">-0.0003</td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig1.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig1.1.8.7.1">Understand</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.8.7.2"><span class="ltx_text ltx_font_bold" id="A5.T15.fig1.1.8.7.2.1">0.9503</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.8.7.3">0.8978</td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig1.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig1.1.9.8.1">Flexible</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.9.8.2"><span class="ltx_text ltx_font_bold" id="A5.T15.fig1.1.9.8.2.1">-0.0022</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.9.8.3">-0.0023</td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig1.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig1.1.10.9.1">Informative</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.10.9.2"><span class="ltx_text ltx_font_bold" id="A5.T15.fig1.1.10.9.2.1">0.0110</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig1.1.10.9.3">0.0035</td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig1.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig1.1.11.10.1">Inquisitive</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A5.T15.fig1.1.11.10.2"><span class="ltx_text ltx_font_bold" id="A5.T15.fig1.1.11.10.2.1">0.0030</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A5.T15.fig1.1.11.10.3">-0.0037</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Table 14: </span>FED scores of dialogues generated with and without CoT for SAMSum few-shot</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A5.T15.fig2" style="width:195.1pt;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A5.T15.fig2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A5.T15.fig2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A5.T15.fig2.1.1.1.1.1">Criteria</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T15.fig2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A5.T15.fig2.1.1.1.2.1">Without CoT</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T15.fig2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A5.T15.fig2.1.1.1.3.1">With CoT</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T15.fig2.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig2.1.2.1.1">Coherence</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.2.1.2">0.0076</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.2.1.3"><span class="ltx_text ltx_font_bold" id="A5.T15.fig2.1.2.1.3.1">0.0324</span></td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig2.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig2.1.3.2.1">Diversity</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.3.2.2">0.0172</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.3.2.3"><span class="ltx_text ltx_font_bold" id="A5.T15.fig2.1.3.2.3.1">0.0372</span></td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig2.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig2.1.4.3.1">Flexibility</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.4.3.2">0.0116</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.4.3.3"><span class="ltx_text ltx_font_bold" id="A5.T15.fig2.1.4.3.3.1">0.0259</span></td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig2.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig2.1.5.4.1">Understandability</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.5.4.2">0.0104</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.5.4.3"><span class="ltx_text ltx_font_bold" id="A5.T15.fig2.1.5.4.3.1">0.0272</span></td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig2.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig2.1.6.5.1">Inquistiveness</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.6.5.2">0.0201</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.6.5.3"><span class="ltx_text ltx_font_bold" id="A5.T15.fig2.1.6.5.3.1">0.0389</span></td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig2.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig2.1.7.6.1">Consistency</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.7.6.2">0.0149</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.7.6.3"><span class="ltx_text ltx_font_bold" id="A5.T15.fig2.1.7.6.3.1">0.0415</span></td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig2.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig2.1.8.7.1">Informativeness</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.8.7.2">0.0148</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.8.7.3"><span class="ltx_text ltx_font_bold" id="A5.T15.fig2.1.8.7.3.1">0.0200</span></td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig2.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig2.1.9.8.1">Likeability</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.9.8.2">0.0041</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.9.8.3"><span class="ltx_text ltx_font_bold" id="A5.T15.fig2.1.9.8.3.1">0.023</span></td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig2.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig2.1.10.9.1">Depth</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.10.9.2">0.0078</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T15.fig2.1.10.9.3"><span class="ltx_text ltx_font_bold" id="A5.T15.fig2.1.10.9.3.1">0.0124</span></td>
</tr>
<tr class="ltx_tr" id="A5.T15.fig2.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="A5.T15.fig2.1.11.10.1">Error Recovery</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A5.T15.fig2.1.11.10.2">0.0163</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A5.T15.fig2.1.11.10.3"><span class="ltx_text ltx_font_bold" id="A5.T15.fig2.1.11.10.3.1">0.0289</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Table 15: </span>GPTScore of dialogues generated with and without CoT for SAMSum few-shot</figcaption>
</figure>
</div>
</div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section><div about="" class="ltx_rdf" content="Sathya Krishnan Suresh" property="dcterms:creator"></div>
<div about="" class="ltx_rdf" content="DiaSynth" property="dcterms:title"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Oct 15 12:55:03 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
