<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods</title>
<!--Generated on Thu Sep 26 15:05:57 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.17939v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S1" title="In Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S2" title="In Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S3" title="In Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S3.SS1" title="In 3 Methodology ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Machine Translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S3.SS2" title="In 3 Methodology ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Word2Vec</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S3.SS3" title="In 3 Methodology ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>BERT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S3.SS4" title="In 3 Methodology ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>GPT-4</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S4" title="In Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experimental Settings</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S4.SS1" title="In 4 Experimental Settings ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Corpus</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S4.SS2" title="In 4 Experimental Settings ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Machine Translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S4.SS3" title="In 4 Experimental Settings ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Word2Vec</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S4.SS4" title="In 4 Experimental Settings ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>BERT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S4.SS5" title="In 4 Experimental Settings ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>GPT-4</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S5" title="In Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S6" title="In Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<span class="ltx_ERROR undefined" id="id7.1.id1">\name</span><span class="ltx_text ltx_font_bold" id="id8.2.id2">Richard Yue</span> <span class="ltx_ERROR undefined" id="id9.3.id3">\addr</span>yue.r@northeastern.edu
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id10.4.id4">\addr</span>Northeastern University, San Jose, CA
<span class="ltx_ERROR undefined" id="id11.5.id5">\AND</span><span class="ltx_ERROR undefined" id="id12.6.id6">\name</span><span class="ltx_text ltx_font_bold" id="id13.7.id7">John E. Ortega</span> <span class="ltx_ERROR undefined" id="id14.8.id8">\addr</span>j.ortega@northeastern.edu
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id15.9.id9">\addr</span>Institute for Experiential AI, Northeastern University, Boston, MA
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id6.6">Translation memories (TMs) are the backbone for professional translation tools called computer-aided translation (CAT) tools. In order to perform a translation using a CAT tool, a translator uses the TM to gather translations similar to the desired segment to translate (<math alttext="s^{\prime}" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><msup id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mi id="id1.1.m1.1.1.2" xref="id1.1.m1.1.1.2.cmml">s</mi><mo id="id1.1.m1.1.1.3" xref="id1.1.m1.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><csymbol cd="ambiguous" id="id1.1.m1.1.1.1.cmml" xref="id1.1.m1.1.1">superscript</csymbol><ci id="id1.1.m1.1.1.2.cmml" xref="id1.1.m1.1.1.2">ùë†</ci><ci id="id1.1.m1.1.1.3.cmml" xref="id1.1.m1.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">s^{\prime}</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">italic_s start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math>). Many CAT tools offer a fuzzy-match algorithm to locate segments (<math alttext="s" class="ltx_Math" display="inline" id="id2.2.m2.1"><semantics id="id2.2.m2.1a"><mi id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><ci id="id2.2.m2.1.1.cmml" xref="id2.2.m2.1.1">ùë†</ci></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">s</annotation><annotation encoding="application/x-llamapun" id="id2.2.m2.1d">italic_s</annotation></semantics></math>) in the TM that are close in distance to <math alttext="s^{\prime}" class="ltx_Math" display="inline" id="id3.3.m3.1"><semantics id="id3.3.m3.1a"><msup id="id3.3.m3.1.1" xref="id3.3.m3.1.1.cmml"><mi id="id3.3.m3.1.1.2" xref="id3.3.m3.1.1.2.cmml">s</mi><mo id="id3.3.m3.1.1.3" xref="id3.3.m3.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="id3.3.m3.1b"><apply id="id3.3.m3.1.1.cmml" xref="id3.3.m3.1.1"><csymbol cd="ambiguous" id="id3.3.m3.1.1.1.cmml" xref="id3.3.m3.1.1">superscript</csymbol><ci id="id3.3.m3.1.1.2.cmml" xref="id3.3.m3.1.1.2">ùë†</ci><ci id="id3.3.m3.1.1.3.cmml" xref="id3.3.m3.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id3.3.m3.1c">s^{\prime}</annotation><annotation encoding="application/x-llamapun" id="id3.3.m3.1d">italic_s start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math>. After locating two similar segments, the CAT tool will present parallel segments (<math alttext="s" class="ltx_Math" display="inline" id="id4.4.m4.1"><semantics id="id4.4.m4.1a"><mi id="id4.4.m4.1.1" xref="id4.4.m4.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="id4.4.m4.1b"><ci id="id4.4.m4.1.1.cmml" xref="id4.4.m4.1.1">ùë†</ci></annotation-xml><annotation encoding="application/x-tex" id="id4.4.m4.1c">s</annotation><annotation encoding="application/x-llamapun" id="id4.4.m4.1d">italic_s</annotation></semantics></math>, <math alttext="t" class="ltx_Math" display="inline" id="id5.5.m5.1"><semantics id="id5.5.m5.1a"><mi id="id5.5.m5.1.1" xref="id5.5.m5.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="id5.5.m5.1b"><ci id="id5.5.m5.1.1.cmml" xref="id5.5.m5.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="id5.5.m5.1c">t</annotation><annotation encoding="application/x-llamapun" id="id5.5.m5.1d">italic_t</annotation></semantics></math>) that contain one segment in the source language along with its translation in the target language. Additionally, CAT tools contain fuzzy-match repair (FMR) techniques that will automatically use the parallel segments from the TM to create new TM entries containing a modified version of the original with the idea in mind that it will be the translation of <math alttext="s^{\prime}" class="ltx_Math" display="inline" id="id6.6.m6.1"><semantics id="id6.6.m6.1a"><msup id="id6.6.m6.1.1" xref="id6.6.m6.1.1.cmml"><mi id="id6.6.m6.1.1.2" xref="id6.6.m6.1.1.2.cmml">s</mi><mo id="id6.6.m6.1.1.3" xref="id6.6.m6.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="id6.6.m6.1b"><apply id="id6.6.m6.1.1.cmml" xref="id6.6.m6.1.1"><csymbol cd="ambiguous" id="id6.6.m6.1.1.1.cmml" xref="id6.6.m6.1.1">superscript</csymbol><ci id="id6.6.m6.1.1.2.cmml" xref="id6.6.m6.1.1.2">ùë†</ci><ci id="id6.6.m6.1.1.3.cmml" xref="id6.6.m6.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id6.6.m6.1c">s^{\prime}</annotation><annotation encoding="application/x-llamapun" id="id6.6.m6.1d">italic_s start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math>. Most FMR techniques use machine translation as a way of ‚Äúrepairing‚Äù those words that have to be modified. In this article, we show that for a large part of those words which are <span class="ltx_text ltx_font_italic" id="id6.6.1">anchored</span>, we can use other techniques that are based on machine learning approaches such as Word2Vec. BERT, and even ChatGPT. Specifically, we show that for anchored words that follow the continuous bag-of-words (CBOW) paradigm, Word2Vec, BERT, and GPT-4 can be used to achieve similar and, for some cases, better results than neural machine translation for translating anchored words from French to English.</p>
</div>
<div class="ltx_pagination ltx_role_start_2_columns"></div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.7">Professional translators use computer-aided translation (CAT) tools <cite class="ltx_cite ltx_citemacro_citep">(Bowker,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib3" title="">2002</a>)</cite> to translate text from one language called the source language (SL) to a target language (TL). Most CAT tools have an option known as <span class="ltx_text ltx_font_italic" id="S1.p1.7.1">fuzzy-match repair</span> (FMR) <cite class="ltx_cite ltx_citemacro_citep">(Kranias and Samiotou,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib15" title="">2004</a>; Hewavitharana et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib10" title="">2005</a>; Dandapat et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib7" title="">2011</a>; Ortega et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib21" title="">2016</a>; Bulte et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib6" title="">2018</a>; Tezcan et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib26" title="">2021</a>)</cite>, which is backed by a parallel translation memory (TM) that contains sentences (called segments) in the SL and TL. Each pair, or unit, of parallel segments in the TM is known as a <span class="ltx_text ltx_font_italic" id="S1.p1.7.2">translation unit</span> (TU). A TU contains a source segment (<math alttext="s" class="ltx_Math" display="inline" id="S1.p1.1.m1.1"><semantics id="S1.p1.1.m1.1a"><mi id="S1.p1.1.m1.1.1" xref="S1.p1.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S1.p1.1.m1.1b"><ci id="S1.p1.1.m1.1.1.cmml" xref="S1.p1.1.m1.1.1">ùë†</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.1.m1.1c">s</annotation><annotation encoding="application/x-llamapun" id="S1.p1.1.m1.1d">italic_s</annotation></semantics></math>) along with a target segment (<math alttext="t" class="ltx_Math" display="inline" id="S1.p1.2.m2.1"><semantics id="S1.p1.2.m2.1a"><mi id="S1.p1.2.m2.1.1" xref="S1.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S1.p1.2.m2.1b"><ci id="S1.p1.2.m2.1.1.cmml" xref="S1.p1.2.m2.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.2.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="S1.p1.2.m2.1d">italic_t</annotation></semantics></math>). When a professional translator attempts to translate a segment in the SL (denoted as <math alttext="s^{\prime}" class="ltx_Math" display="inline" id="S1.p1.3.m3.1"><semantics id="S1.p1.3.m3.1a"><msup id="S1.p1.3.m3.1.1" xref="S1.p1.3.m3.1.1.cmml"><mi id="S1.p1.3.m3.1.1.2" xref="S1.p1.3.m3.1.1.2.cmml">s</mi><mo id="S1.p1.3.m3.1.1.3" xref="S1.p1.3.m3.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S1.p1.3.m3.1b"><apply id="S1.p1.3.m3.1.1.cmml" xref="S1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S1.p1.3.m3.1.1.1.cmml" xref="S1.p1.3.m3.1.1">superscript</csymbol><ci id="S1.p1.3.m3.1.1.2.cmml" xref="S1.p1.3.m3.1.1.2">ùë†</ci><ci id="S1.p1.3.m3.1.1.3.cmml" xref="S1.p1.3.m3.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.3.m3.1c">s^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S1.p1.3.m3.1d">italic_s start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math>) a fuzzy-match lookup is performed using a word-based Levenshtein distance <cite class="ltx_cite ltx_citemacro_citep">(Levenshtein,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib16" title="">1966</a>)</cite> between <math alttext="s^{\prime}" class="ltx_Math" display="inline" id="S1.p1.4.m4.1"><semantics id="S1.p1.4.m4.1a"><msup id="S1.p1.4.m4.1.1" xref="S1.p1.4.m4.1.1.cmml"><mi id="S1.p1.4.m4.1.1.2" xref="S1.p1.4.m4.1.1.2.cmml">s</mi><mo id="S1.p1.4.m4.1.1.3" xref="S1.p1.4.m4.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S1.p1.4.m4.1b"><apply id="S1.p1.4.m4.1.1.cmml" xref="S1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S1.p1.4.m4.1.1.1.cmml" xref="S1.p1.4.m4.1.1">superscript</csymbol><ci id="S1.p1.4.m4.1.1.2.cmml" xref="S1.p1.4.m4.1.1.2">ùë†</ci><ci id="S1.p1.4.m4.1.1.3.cmml" xref="S1.p1.4.m4.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.4.m4.1c">s^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S1.p1.4.m4.1d">italic_s start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="s" class="ltx_Math" display="inline" id="S1.p1.5.m5.1"><semantics id="S1.p1.5.m5.1a"><mi id="S1.p1.5.m5.1.1" xref="S1.p1.5.m5.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S1.p1.5.m5.1b"><ci id="S1.p1.5.m5.1.1.cmml" xref="S1.p1.5.m5.1.1">ùë†</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.5.m5.1c">s</annotation><annotation encoding="application/x-llamapun" id="S1.p1.5.m5.1d">italic_s</annotation></semantics></math> where a 100% match means that the words from <math alttext="s^{\prime}" class="ltx_Math" display="inline" id="S1.p1.6.m6.1"><semantics id="S1.p1.6.m6.1a"><msup id="S1.p1.6.m6.1.1" xref="S1.p1.6.m6.1.1.cmml"><mi id="S1.p1.6.m6.1.1.2" xref="S1.p1.6.m6.1.1.2.cmml">s</mi><mo id="S1.p1.6.m6.1.1.3" xref="S1.p1.6.m6.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S1.p1.6.m6.1b"><apply id="S1.p1.6.m6.1.1.cmml" xref="S1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S1.p1.6.m6.1.1.1.cmml" xref="S1.p1.6.m6.1.1">superscript</csymbol><ci id="S1.p1.6.m6.1.1.2.cmml" xref="S1.p1.6.m6.1.1.2">ùë†</ci><ci id="S1.p1.6.m6.1.1.3.cmml" xref="S1.p1.6.m6.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.6.m6.1c">s^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S1.p1.6.m6.1d">italic_s start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> are identical to the words in <math alttext="s" class="ltx_Math" display="inline" id="S1.p1.7.m7.1"><semantics id="S1.p1.7.m7.1a"><mi id="S1.p1.7.m7.1.1" xref="S1.p1.7.m7.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S1.p1.7.m7.1b"><ci id="S1.p1.7.m7.1.1.cmml" xref="S1.p1.7.m7.1.1">ùë†</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.7.m7.1c">s</annotation><annotation encoding="application/x-llamapun" id="S1.p1.7.m7.1d">italic_s</annotation></semantics></math>. It is often the case that a professional translator uses matches from FMR to only translate a few words (called sub-segments) from the entire segment. In this article, we focus on improving those cases where there exists only one word to translate, known as an <span class="ltx_text ltx_font_italic" id="S1.p1.7.3">anchored</span> word, whose position is in between two words that are already captured. In our studies, the anchored word is a common case that professional translators often use. We experiment with four techniques to translate the anchored word: (1) Neural Machine Translation, (2) a BERT-based <cite class="ltx_cite ltx_citemacro_citep">(Sanh et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib22" title="">2019</a>)</cite> implementation, (3) Word2Vec <cite class="ltx_cite ltx_citemacro_citep">(Mikolov et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib19" title="">2013</a>)</cite> and (4) OpenAI GPT-4 prompting <cite class="ltx_cite ltx_citemacro_citep">(Achiam et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib1" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">The prediction of an anchored word has been presented in many contexts and can be considered the main objective of a language model. Several models based on attention allow a weight to be assigned to certain words within a context window so that surrounding words that strongly influence the overall context can have a greater impact on the prediction made. This could potentially be used in order to improve predictions made for anchored text by taking longer contexts into account than the surrounding words. We discuss this approach in the context of generative models, where such systems could be harnessed to generate highly accurate predictions.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The rest of this article is structured as follows. The next section discusses related work by accentuating the differences between FMR based on MT and anchored-word prediction. Section <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S3" title="3 Methodology ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_tag">3</span></a> then presents the BERT, Word2Vec, and GPT-4 approaches used for translating anchored words. In Section <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S4" title="4 Experimental Settings ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_tag">4</span></a>, we describe the corpus and configurations used for our experiments whose results are reflected in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S5" title="5 Results ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_tag">5</span></a>, followed by concluding remarks in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S6" title="6 Conclusion ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.6">For the majority of FMR approaches, MT is used to translate mismatches, regardless if they are anchored words or not. Generally, MT techniques for FMR are focused on the decoding process where statistical-based systems <cite class="ltx_cite ltx_citemacro_citep">(Biccici and Dymetman,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib2" title="">2008</a>; Simard and Isabelle,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib23" title="">2009</a>; Zhechev and Genabith,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib31" title="">2010</a>; Koehn and Senellart,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib14" title="">2010</a>; Li et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib17" title="">2016</a>; Liu et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib18" title="">2019</a>)</cite> or neural-based systems <cite class="ltx_cite ltx_citemacro_citep">(Ortega et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib20" title="">2014</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib21" title="">2016</a>; Gu et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib9" title="">2018</a>; Bulte et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib6" title="">2018</a>; Bulte and Tezcan,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib5" title="">2019</a>)</cite> are used in such a manner to ‚Äúrepair‚Äù either the MT system or the mismatched sub-segments between <math alttext="s^{\prime}" class="ltx_Math" display="inline" id="S2.p1.1.m1.1"><semantics id="S2.p1.1.m1.1a"><msup id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml"><mi id="S2.p1.1.m1.1.1.2" xref="S2.p1.1.m1.1.1.2.cmml">s</mi><mo id="S2.p1.1.m1.1.1.3" xref="S2.p1.1.m1.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><apply id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.p1.1.m1.1.1.1.cmml" xref="S2.p1.1.m1.1.1">superscript</csymbol><ci id="S2.p1.1.m1.1.1.2.cmml" xref="S2.p1.1.m1.1.1.2">ùë†</ci><ci id="S2.p1.1.m1.1.1.3.cmml" xref="S2.p1.1.m1.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">s^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.1.m1.1d">italic_s start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="s" class="ltx_Math" display="inline" id="S2.p1.2.m2.1"><semantics id="S2.p1.2.m2.1a"><mi id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><ci id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1">ùë†</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">s</annotation><annotation encoding="application/x-llamapun" id="S2.p1.2.m2.1d">italic_s</annotation></semantics></math>. This article is focused on repairing the mismatched sub-segments in specific situations where sub-segments of <math alttext="s" class="ltx_Math" display="inline" id="S2.p1.3.m3.1"><semantics id="S2.p1.3.m3.1a"><mi id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><ci id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1">ùë†</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">s</annotation><annotation encoding="application/x-llamapun" id="S2.p1.3.m3.1d">italic_s</annotation></semantics></math> are common in <math alttext="s^{\prime}" class="ltx_Math" display="inline" id="S2.p1.4.m4.1"><semantics id="S2.p1.4.m4.1a"><msup id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml"><mi id="S2.p1.4.m4.1.1.2" xref="S2.p1.4.m4.1.1.2.cmml">s</mi><mo id="S2.p1.4.m4.1.1.3" xref="S2.p1.4.m4.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><apply id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.p1.4.m4.1.1.1.cmml" xref="S2.p1.4.m4.1.1">superscript</csymbol><ci id="S2.p1.4.m4.1.1.2.cmml" xref="S2.p1.4.m4.1.1.2">ùë†</ci><ci id="S2.p1.4.m4.1.1.3.cmml" xref="S2.p1.4.m4.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">s^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.4.m4.1d">italic_s start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> with the exception of one word (e.g. <math alttext="s" class="ltx_Math" display="inline" id="S2.p1.5.m5.1"><semantics id="S2.p1.5.m5.1a"><mi id="S2.p1.5.m5.1.1" xref="S2.p1.5.m5.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S2.p1.5.m5.1b"><ci id="S2.p1.5.m5.1.1.cmml" xref="S2.p1.5.m5.1.1">ùë†</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.5.m5.1c">s</annotation><annotation encoding="application/x-llamapun" id="S2.p1.5.m5.1d">italic_s</annotation></semantics></math>=‚Äòthe <span class="ltx_text ltx_font_bold" id="S2.p1.6.1">brown</span> dog‚Äô and <math alttext="s^{\prime}" class="ltx_Math" display="inline" id="S2.p1.6.m6.1"><semantics id="S2.p1.6.m6.1a"><msup id="S2.p1.6.m6.1.1" xref="S2.p1.6.m6.1.1.cmml"><mi id="S2.p1.6.m6.1.1.2" xref="S2.p1.6.m6.1.1.2.cmml">s</mi><mo id="S2.p1.6.m6.1.1.3" xref="S2.p1.6.m6.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S2.p1.6.m6.1b"><apply id="S2.p1.6.m6.1.1.cmml" xref="S2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.p1.6.m6.1.1.1.cmml" xref="S2.p1.6.m6.1.1">superscript</csymbol><ci id="S2.p1.6.m6.1.1.2.cmml" xref="S2.p1.6.m6.1.1.2">ùë†</ci><ci id="S2.p1.6.m6.1.1.3.cmml" xref="S2.p1.6.m6.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.6.m6.1c">s^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.6.m6.1d">italic_s start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math>=‚Äòthe <span class="ltx_text ltx_font_bold" id="S2.p1.6.2">red</span> dog‚Äô).</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.4">Previous work <cite class="ltx_cite ltx_citemacro_citep">(Ortega et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib21" title="">2016</a>; Bulte et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib6" title="">2018</a>)</cite> can be considered identical to this article as it uses FMR to first find mismatches between <math alttext="s^{\prime}" class="ltx_Math" display="inline" id="S2.p2.1.m1.1"><semantics id="S2.p2.1.m1.1a"><msup id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml"><mi id="S2.p2.1.m1.1.1.2" xref="S2.p2.1.m1.1.1.2.cmml">s</mi><mo id="S2.p2.1.m1.1.1.3" xref="S2.p2.1.m1.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><apply id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.p2.1.m1.1.1.1.cmml" xref="S2.p2.1.m1.1.1">superscript</csymbol><ci id="S2.p2.1.m1.1.1.2.cmml" xref="S2.p2.1.m1.1.1.2">ùë†</ci><ci id="S2.p2.1.m1.1.1.3.cmml" xref="S2.p2.1.m1.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">s^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.p2.1.m1.1d">italic_s start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="s" class="ltx_Math" display="inline" id="S2.p2.2.m2.1"><semantics id="S2.p2.2.m2.1a"><mi id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><ci id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1">ùë†</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">s</annotation><annotation encoding="application/x-llamapun" id="S2.p2.2.m2.1d">italic_s</annotation></semantics></math> and then translates the missing words with different MT systems. However, their system uses context around <span class="ltx_text ltx_font_italic" id="S2.p2.4.1">all</span> mismatches where we only consider mismatches with anchored words, similar to <cite class="ltx_cite ltx_citemacro_cite">Kranias and Samiotou, (<a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib15" title="">2004</a>)</cite>. While other techniques <cite class="ltx_cite ltx_citemacro_citep">(Hewavitharana et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib10" title="">2005</a>; Dandapat et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib7" title="">2011</a>)</cite> are based on probabilistic MT models or employ different algorithms for aligning <math alttext="s^{\prime}" class="ltx_Math" display="inline" id="S2.p2.3.m3.1"><semantics id="S2.p2.3.m3.1a"><msup id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml"><mi id="S2.p2.3.m3.1.1.2" xref="S2.p2.3.m3.1.1.2.cmml">s</mi><mo id="S2.p2.3.m3.1.1.3" xref="S2.p2.3.m3.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.1b"><apply id="S2.p2.3.m3.1.1.cmml" xref="S2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.p2.3.m3.1.1.1.cmml" xref="S2.p2.3.m3.1.1">superscript</csymbol><ci id="S2.p2.3.m3.1.1.2.cmml" xref="S2.p2.3.m3.1.1.2">ùë†</ci><ci id="S2.p2.3.m3.1.1.3.cmml" xref="S2.p2.3.m3.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.1c">s^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.p2.3.m3.1d">italic_s start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="s" class="ltx_Math" display="inline" id="S2.p2.4.m4.1"><semantics id="S2.p2.4.m4.1a"><mi id="S2.p2.4.m4.1.1" xref="S2.p2.4.m4.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S2.p2.4.m4.1b"><ci id="S2.p2.4.m4.1.1.cmml" xref="S2.p2.4.m4.1.1">ùë†</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.4.m4.1c">s</annotation><annotation encoding="application/x-llamapun" id="S2.p2.4.m4.1d">italic_s</annotation></semantics></math>, we use a word-based edit distance <cite class="ltx_cite ltx_citemacro_citep">(Levenshtein,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib16" title="">1966</a>; Wagner and Fischer,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib30" title="">1974</a>)</cite> that marks the mismatched sub-segments and discards non-anchored words.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1"><cite class="ltx_cite ltx_citemacro_cite">Tezcan and Bulte, (<a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib25" title="">2022</a>)</cite> investigate a wide range of automatic quality estimation (QE) metrics in order to assess what effect integrating fuzzy matches can have on a number of aspects of translation quality, in addition to performing manual MT error analysis. They further evaluate what influence fuzzy matches have on a translation and how further quality improvements can be made by quantitative analyses that focus on the specific characteristics of a retrieved fuzzy match. Neural Fuzzy Repair (NFR) outperforms baselines in all automated evaluation metrics. There was not a discernable difference between NFR and Neural Machine Translation (NMT) error in manual evaluation, but different error profiles emerged in this study, highlighting some of the strengths and weaknesses of each method. Namely, NFR produced more errors in the category of ‚Äúsemantically unrelated‚Äù, whereas the baseline NMT system produced more errors in the categories of ‚Äúword sense‚Äù and ‚Äúmulti-word expression‚Äù. The NFR system made more accuracy errors, but producing fluent output was its strong suit. Meanwhile, in terms of lexical choices, NMT produced more ‚Äúnon-existing/foreign‚Äù errors, which was not an issue for NFR. The baseline system performed better on grammar and syntax. Our study differs in that it focuses specifically on anchored text and on leveraging the strengths of language models in next word prediction in order to fill in single-word gaps.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.2"><cite class="ltx_cite ltx_citemacro_cite">Espla-Gomis et¬†al., (<a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib8" title="">2011</a>)</cite> attempt to improve CAT via the TM using pre-computed word alignments between source and target TUs in the TM. When a user is translating <math alttext="s^{\prime}" class="ltx_Math" display="inline" id="S2.p4.1.m1.1"><semantics id="S2.p4.1.m1.1a"><msup id="S2.p4.1.m1.1.1" xref="S2.p4.1.m1.1.1.cmml"><mi id="S2.p4.1.m1.1.1.2" xref="S2.p4.1.m1.1.1.2.cmml">s</mi><mo id="S2.p4.1.m1.1.1.3" xref="S2.p4.1.m1.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S2.p4.1.m1.1b"><apply id="S2.p4.1.m1.1.1.cmml" xref="S2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S2.p4.1.m1.1.1.1.cmml" xref="S2.p4.1.m1.1.1">superscript</csymbol><ci id="S2.p4.1.m1.1.1.2.cmml" xref="S2.p4.1.m1.1.1.2">ùë†</ci><ci id="S2.p4.1.m1.1.1.3.cmml" xref="S2.p4.1.m1.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.1.m1.1c">s^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.p4.1.m1.1d">italic_s start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> with a fuzzy match score greater than or equal to 60%, the proposed system marks the words that need to change as well as those that must remain the same in order to obtain <math alttext="t^{\prime}" class="ltx_Math" display="inline" id="S2.p4.2.m2.1"><semantics id="S2.p4.2.m2.1a"><msup id="S2.p4.2.m2.1.1" xref="S2.p4.2.m2.1.1.cmml"><mi id="S2.p4.2.m2.1.1.2" xref="S2.p4.2.m2.1.1.2.cmml">t</mi><mo id="S2.p4.2.m2.1.1.3" xref="S2.p4.2.m2.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S2.p4.2.m2.1b"><apply id="S2.p4.2.m2.1.1.cmml" xref="S2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p4.2.m2.1.1.1.cmml" xref="S2.p4.2.m2.1.1">superscript</csymbol><ci id="S2.p4.2.m2.1.1.2.cmml" xref="S2.p4.2.m2.1.1.2">ùë°</ci><ci id="S2.p4.2.m2.1.1.3.cmml" xref="S2.p4.2.m2.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.2.m2.1c">t^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.p4.2.m2.1d">italic_t start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math>. Alignments are obtained from GIZA++ <cite class="ltx_cite ltx_citemacro_citep">(Brown et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib4" title="">1993</a>; Vogel et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib28" title="">1996</a>)</cite> and take both a statistical and syntactic approach to detecting where changes need to occur. The experiments offer insight into how human decisions to keep/change text during translation can be integrated into FMR. Our approach differs in that we specifically locate anchored text and, following that, continue on to a prediction step, providing the content needed to perform fuzzy match repair in the translation step.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1"><cite class="ltx_cite ltx_citemacro_cite">Irsoy et¬†al., (<a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib11" title="">2020</a>)</cite> compare performance of pre-trained word embeddings in use in language models such as BERT with continuous bag of words (CBOW) embeddings trained with Word2Vec. The authors claim that, while BERT embeddings are useful and effective, they often offer only marginal gains as compared to Word2Vec embeddings trained using Gensim <cite class="ltx_cite ltx_citemacro_citep">(VRehuuVrek et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib29" title="">2011</a>)</cite>. The latter are much less computationally expensive to obtain; 768-dimensional vectors were trained in one epoch in 1.61 days on a 16-CPU machine. CBOW embeddings are trained by using surrounding context to predict a center word. While training via CBOW has often shown inferior performance to training via skipgram (SG), this paper shows that with a proper implementation, performance of CBOW embeddings can be on par with SG. Our work puts the CBOW prediction objective to good use, harnessing it to predict anchored text in source language segments.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Neural MT systems have been shown by previous work <cite class="ltx_cite ltx_citemacro_citep">(Bulte and Tezcan,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib5" title="">2019</a>)</cite> to be the state-of-the-art for FMR. In this article, we experiment on the one hand with word-based language models that are trained using context around a word, like those that use the continuous bag of words (CBOW) model <cite class="ltx_cite ltx_citemacro_citep">(Mikolov et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib19" title="">2013</a>)</cite> (Word2Vec) or masked language modeling <cite class="ltx_cite ltx_citemacro_citep">(Sanh et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib22" title="">2019</a>)</cite> (BERT). On the other hand, it is our belief also that generative language modeling techniques may be a good candidate for accomplishing this task. To explore this avenue, we also compare output from these models with predictions obtained from prompting GPT-4 and find it to be competitive with the other methods. An example of a source sentence and the output from each method is provided in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S3.T1" title="Table 1 ‚Ä£ 3 Methodology ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_tag">1</span></a> with predicted (or reference) word in bold. In our experiment, the two language modeling techniques as well as the generative approach are compared against machine translation and measured using character rate and accuracy against sets of anchored words from the test set. A prediction or translation was deemed correct when the center word from a tri-gram of anchored words was correctly found. In the following sub-sections, we discuss each approach. In Section <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S4" title="4 Experimental Settings ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_tag">4</span></a> we provide further details about the corpora and configuration.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.2.1">Output</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.2.1.1">Original French</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.2.1.2">‚ÄúAfin d‚Äô<span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.2.1.2.1">√©valuer si</span> l‚Äô√©tablissement identifie toutes</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.3.2">
<th class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T1.1.3.2.1"></th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.3.2.2">les situations qui doivent √™tre consid√©r√©es comme</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4.3">
<th class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T1.1.4.3.1"></th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.4.3.2">des d√©fauts, conform√©ment √† l‚Äôarticle 178,</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.5.4">
<th class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T1.1.5.4.1"></th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.5.4.2">paragraphes 1 √† 5, du r√®glement (UE) no 575/2013‚Ä¶‚Äù</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.6.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.6.5.1">Reference Translation</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.6.5.2">‚ÄúIn order to <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.6.5.2.1">assess whether the</span> institution</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.7.6">
<th class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T1.1.7.6.1"></th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.7.6.2">identifies all situations which are to be considered</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.8.7">
<th class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T1.1.8.7.1"></th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.8.7.2">defaults in accordance with Article 178 (1)</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.9.8">
<th class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T1.1.9.8.1"></th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.9.8.2">to (5) of Regulation (EU) No 575/2013‚Ä¶‚Äù</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.10.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.10.9.1">Reference tri-gram</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.10.9.2">assess <span class="ltx_text ltx_font_bold" id="S3.T1.1.10.9.2.1">whether</span> the</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.11.10">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.11.10.1">BERT</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.11.10.2">assess <span class="ltx_text ltx_font_bold" id="S3.T1.1.11.10.2.1">whether</span> the</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.12.11">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.12.11.1">Word2Vec</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.12.11.2">assess <span class="ltx_text ltx_font_bold" id="S3.T1.1.12.11.2.1">commission</span> the</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.13.12">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.13.12.1">MT</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.13.12.2">assess <span class="ltx_text ltx_font_bold" id="S3.T1.1.13.12.2.1">obligatory</span> the</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.14.13">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.14.13.1">GPT-4</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.1.14.13.2">assess <span class="ltx_text ltx_font_bold" id="S3.T1.1.14.13.2.1">and</span> the</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Anchored tri-gram reference and predictions (predicted word in bold)</figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Machine Translation</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.8">We train the neural MT system with Open-NMT <cite class="ltx_cite ltx_citemacro_citep">(Klein et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib13" title="">2020</a>)</cite> using the default transformer configuration. In order to get a wider range of difference with the MT system, we translate using two methods: (1) the translation of the <math alttext="s^{\prime}_{en}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><msubsup id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2.2" xref="S3.SS1.p1.1.m1.1.1.2.2.cmml">s</mi><mrow id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS1.p1.1.m1.1.1.3.2" xref="S3.SS1.p1.1.m1.1.1.3.2.cmml">e</mi><mo id="S3.SS1.p1.1.m1.1.1.3.1" xref="S3.SS1.p1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.1.m1.1.1.3.3" xref="S3.SS1.p1.1.m1.1.1.3.3.cmml">n</mi></mrow><mo id="S3.SS1.p1.1.m1.1.1.2.3" xref="S3.SS1.p1.1.m1.1.1.2.3.cmml">‚Ä≤</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">subscript</csymbol><apply id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.2.1.cmml" xref="S3.SS1.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2.2">ùë†</ci><ci id="S3.SS1.p1.1.m1.1.1.2.3.cmml" xref="S3.SS1.p1.1.m1.1.1.2.3">‚Ä≤</ci></apply><apply id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3"><times id="S3.SS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.3.1"></times><ci id="S3.SS1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.3.2">ùëí</ci><ci id="S3.SS1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3">ùëõ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">s^{\prime}_{en}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_s start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_e italic_n end_POSTSUBSCRIPT</annotation></semantics></math> segment to <math alttext="t^{*}_{fr}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><msubsup id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2.2" xref="S3.SS1.p1.2.m2.1.1.2.2.cmml">t</mi><mrow id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.2" xref="S3.SS1.p1.2.m2.1.1.3.2.cmml">f</mi><mo id="S3.SS1.p1.2.m2.1.1.3.1" xref="S3.SS1.p1.2.m2.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.2.m2.1.1.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.cmml">r</mi></mrow><mo id="S3.SS1.p1.2.m2.1.1.2.3" xref="S3.SS1.p1.2.m2.1.1.2.3.cmml">‚àó</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><apply id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.2.1.cmml" xref="S3.SS1.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2.2">ùë°</ci><times id="S3.SS1.p1.2.m2.1.1.2.3.cmml" xref="S3.SS1.p1.2.m2.1.1.2.3"></times></apply><apply id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3"><times id="S3.SS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3.1"></times><ci id="S3.SS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.2">ùëì</ci><ci id="S3.SS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3">ùëü</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">t^{*}_{fr}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_t start_POSTSUPERSCRIPT ‚àó end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_f italic_r end_POSTSUBSCRIPT</annotation></semantics></math> then translation from <math alttext="t^{*}_{fr}" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><msubsup id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2.2" xref="S3.SS1.p1.3.m3.1.1.2.2.cmml">t</mi><mrow id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml"><mi id="S3.SS1.p1.3.m3.1.1.3.2" xref="S3.SS1.p1.3.m3.1.1.3.2.cmml">f</mi><mo id="S3.SS1.p1.3.m3.1.1.3.1" xref="S3.SS1.p1.3.m3.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.3.m3.1.1.3.3" xref="S3.SS1.p1.3.m3.1.1.3.3.cmml">r</mi></mrow><mo id="S3.SS1.p1.3.m3.1.1.2.3" xref="S3.SS1.p1.3.m3.1.1.2.3.cmml">‚àó</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">subscript</csymbol><apply id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.2.1.cmml" xref="S3.SS1.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2.2">ùë°</ci><times id="S3.SS1.p1.3.m3.1.1.2.3.cmml" xref="S3.SS1.p1.3.m3.1.1.2.3"></times></apply><apply id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3"><times id="S3.SS1.p1.3.m3.1.1.3.1.cmml" xref="S3.SS1.p1.3.m3.1.1.3.1"></times><ci id="S3.SS1.p1.3.m3.1.1.3.2.cmml" xref="S3.SS1.p1.3.m3.1.1.3.2">ùëì</ci><ci id="S3.SS1.p1.3.m3.1.1.3.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3">ùëü</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">t^{*}_{fr}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_t start_POSTSUPERSCRIPT ‚àó end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_f italic_r end_POSTSUBSCRIPT</annotation></semantics></math> to <math alttext="s^{*}_{en}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><msubsup id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2.2" xref="S3.SS1.p1.4.m4.1.1.2.2.cmml">s</mi><mrow id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml"><mi id="S3.SS1.p1.4.m4.1.1.3.2" xref="S3.SS1.p1.4.m4.1.1.3.2.cmml">e</mi><mo id="S3.SS1.p1.4.m4.1.1.3.1" xref="S3.SS1.p1.4.m4.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.4.m4.1.1.3.3" xref="S3.SS1.p1.4.m4.1.1.3.3.cmml">n</mi></mrow><mo id="S3.SS1.p1.4.m4.1.1.2.3" xref="S3.SS1.p1.4.m4.1.1.2.3.cmml">‚àó</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">subscript</csymbol><apply id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.2.1.cmml" xref="S3.SS1.p1.4.m4.1.1">superscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2.2">ùë†</ci><times id="S3.SS1.p1.4.m4.1.1.2.3.cmml" xref="S3.SS1.p1.4.m4.1.1.2.3"></times></apply><apply id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3"><times id="S3.SS1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3.1"></times><ci id="S3.SS1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.2">ùëí</ci><ci id="S3.SS1.p1.4.m4.1.1.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3">ùëõ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">s^{*}_{en}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">italic_s start_POSTSUPERSCRIPT ‚àó end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_e italic_n end_POSTSUBSCRIPT</annotation></semantics></math>; and, (2) the translation of the three-word sub-segment only (i.e. the anchored tri-gram with the center word to be translated) from <math alttext="s_{trigram\textrm{-}en}^{\prime}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1"><semantics id="S3.SS1.p1.5.m5.1a"><msubsup id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2.2" xref="S3.SS1.p1.5.m5.1.1.2.2.cmml">s</mi><mrow id="S3.SS1.p1.5.m5.1.1.2.3" xref="S3.SS1.p1.5.m5.1.1.2.3.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2.3.2" xref="S3.SS1.p1.5.m5.1.1.2.3.2.cmml">t</mi><mo id="S3.SS1.p1.5.m5.1.1.2.3.1" xref="S3.SS1.p1.5.m5.1.1.2.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.5.m5.1.1.2.3.3" xref="S3.SS1.p1.5.m5.1.1.2.3.3.cmml">r</mi><mo id="S3.SS1.p1.5.m5.1.1.2.3.1a" xref="S3.SS1.p1.5.m5.1.1.2.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.5.m5.1.1.2.3.4" xref="S3.SS1.p1.5.m5.1.1.2.3.4.cmml">i</mi><mo id="S3.SS1.p1.5.m5.1.1.2.3.1b" xref="S3.SS1.p1.5.m5.1.1.2.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.5.m5.1.1.2.3.5" xref="S3.SS1.p1.5.m5.1.1.2.3.5.cmml">g</mi><mo id="S3.SS1.p1.5.m5.1.1.2.3.1c" xref="S3.SS1.p1.5.m5.1.1.2.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.5.m5.1.1.2.3.6" xref="S3.SS1.p1.5.m5.1.1.2.3.6.cmml">r</mi><mo id="S3.SS1.p1.5.m5.1.1.2.3.1d" xref="S3.SS1.p1.5.m5.1.1.2.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.5.m5.1.1.2.3.7" xref="S3.SS1.p1.5.m5.1.1.2.3.7.cmml">a</mi><mo id="S3.SS1.p1.5.m5.1.1.2.3.1e" xref="S3.SS1.p1.5.m5.1.1.2.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.5.m5.1.1.2.3.8" xref="S3.SS1.p1.5.m5.1.1.2.3.8.cmml">m</mi><mo id="S3.SS1.p1.5.m5.1.1.2.3.1f" xref="S3.SS1.p1.5.m5.1.1.2.3.1.cmml">‚Å¢</mo><mtext id="S3.SS1.p1.5.m5.1.1.2.3.9" xref="S3.SS1.p1.5.m5.1.1.2.3.9a.cmml">-</mtext><mo id="S3.SS1.p1.5.m5.1.1.2.3.1g" xref="S3.SS1.p1.5.m5.1.1.2.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.5.m5.1.1.2.3.10" xref="S3.SS1.p1.5.m5.1.1.2.3.10.cmml">e</mi><mo id="S3.SS1.p1.5.m5.1.1.2.3.1h" xref="S3.SS1.p1.5.m5.1.1.2.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.5.m5.1.1.2.3.11" xref="S3.SS1.p1.5.m5.1.1.2.3.11.cmml">n</mi></mrow><mo id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">‚Ä≤</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">superscript</csymbol><apply id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.2.1.cmml" xref="S3.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.2.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2.2">ùë†</ci><apply id="S3.SS1.p1.5.m5.1.1.2.3.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3"><times id="S3.SS1.p1.5.m5.1.1.2.3.1.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3.1"></times><ci id="S3.SS1.p1.5.m5.1.1.2.3.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3.2">ùë°</ci><ci id="S3.SS1.p1.5.m5.1.1.2.3.3.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3.3">ùëü</ci><ci id="S3.SS1.p1.5.m5.1.1.2.3.4.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3.4">ùëñ</ci><ci id="S3.SS1.p1.5.m5.1.1.2.3.5.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3.5">ùëî</ci><ci id="S3.SS1.p1.5.m5.1.1.2.3.6.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3.6">ùëü</ci><ci id="S3.SS1.p1.5.m5.1.1.2.3.7.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3.7">ùëé</ci><ci id="S3.SS1.p1.5.m5.1.1.2.3.8.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3.8">ùëö</ci><ci id="S3.SS1.p1.5.m5.1.1.2.3.9a.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3.9"><mtext id="S3.SS1.p1.5.m5.1.1.2.3.9.cmml" mathsize="70%" xref="S3.SS1.p1.5.m5.1.1.2.3.9">-</mtext></ci><ci id="S3.SS1.p1.5.m5.1.1.2.3.10.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3.10">ùëí</ci><ci id="S3.SS1.p1.5.m5.1.1.2.3.11.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3.11">ùëõ</ci></apply></apply><ci id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">s_{trigram\textrm{-}en}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m5.1d">italic_s start_POSTSUBSCRIPT italic_t italic_r italic_i italic_g italic_r italic_a italic_m - italic_e italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> to <math alttext="t^{*}_{trigram\textrm{-}fr}" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1"><semantics id="S3.SS1.p1.6.m6.1a"><msubsup id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2.2" xref="S3.SS1.p1.6.m6.1.1.2.2.cmml">t</mi><mrow id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml"><mi id="S3.SS1.p1.6.m6.1.1.3.2" xref="S3.SS1.p1.6.m6.1.1.3.2.cmml">t</mi><mo id="S3.SS1.p1.6.m6.1.1.3.1" xref="S3.SS1.p1.6.m6.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.6.m6.1.1.3.3" xref="S3.SS1.p1.6.m6.1.1.3.3.cmml">r</mi><mo id="S3.SS1.p1.6.m6.1.1.3.1a" xref="S3.SS1.p1.6.m6.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.6.m6.1.1.3.4" xref="S3.SS1.p1.6.m6.1.1.3.4.cmml">i</mi><mo id="S3.SS1.p1.6.m6.1.1.3.1b" xref="S3.SS1.p1.6.m6.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.6.m6.1.1.3.5" xref="S3.SS1.p1.6.m6.1.1.3.5.cmml">g</mi><mo id="S3.SS1.p1.6.m6.1.1.3.1c" xref="S3.SS1.p1.6.m6.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.6.m6.1.1.3.6" xref="S3.SS1.p1.6.m6.1.1.3.6.cmml">r</mi><mo id="S3.SS1.p1.6.m6.1.1.3.1d" xref="S3.SS1.p1.6.m6.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.6.m6.1.1.3.7" xref="S3.SS1.p1.6.m6.1.1.3.7.cmml">a</mi><mo id="S3.SS1.p1.6.m6.1.1.3.1e" xref="S3.SS1.p1.6.m6.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.6.m6.1.1.3.8" xref="S3.SS1.p1.6.m6.1.1.3.8.cmml">m</mi><mo id="S3.SS1.p1.6.m6.1.1.3.1f" xref="S3.SS1.p1.6.m6.1.1.3.1.cmml">‚Å¢</mo><mtext id="S3.SS1.p1.6.m6.1.1.3.9" xref="S3.SS1.p1.6.m6.1.1.3.9a.cmml">-</mtext><mo id="S3.SS1.p1.6.m6.1.1.3.1g" xref="S3.SS1.p1.6.m6.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.6.m6.1.1.3.10" xref="S3.SS1.p1.6.m6.1.1.3.10.cmml">f</mi><mo id="S3.SS1.p1.6.m6.1.1.3.1h" xref="S3.SS1.p1.6.m6.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.6.m6.1.1.3.11" xref="S3.SS1.p1.6.m6.1.1.3.11.cmml">r</mi></mrow><mo id="S3.SS1.p1.6.m6.1.1.2.3" xref="S3.SS1.p1.6.m6.1.1.2.3.cmml">‚àó</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">subscript</csymbol><apply id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.2.1.cmml" xref="S3.SS1.p1.6.m6.1.1">superscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.2.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2.2">ùë°</ci><times id="S3.SS1.p1.6.m6.1.1.2.3.cmml" xref="S3.SS1.p1.6.m6.1.1.2.3"></times></apply><apply id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3"><times id="S3.SS1.p1.6.m6.1.1.3.1.cmml" xref="S3.SS1.p1.6.m6.1.1.3.1"></times><ci id="S3.SS1.p1.6.m6.1.1.3.2.cmml" xref="S3.SS1.p1.6.m6.1.1.3.2">ùë°</ci><ci id="S3.SS1.p1.6.m6.1.1.3.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3.3">ùëü</ci><ci id="S3.SS1.p1.6.m6.1.1.3.4.cmml" xref="S3.SS1.p1.6.m6.1.1.3.4">ùëñ</ci><ci id="S3.SS1.p1.6.m6.1.1.3.5.cmml" xref="S3.SS1.p1.6.m6.1.1.3.5">ùëî</ci><ci id="S3.SS1.p1.6.m6.1.1.3.6.cmml" xref="S3.SS1.p1.6.m6.1.1.3.6">ùëü</ci><ci id="S3.SS1.p1.6.m6.1.1.3.7.cmml" xref="S3.SS1.p1.6.m6.1.1.3.7">ùëé</ci><ci id="S3.SS1.p1.6.m6.1.1.3.8.cmml" xref="S3.SS1.p1.6.m6.1.1.3.8">ùëö</ci><ci id="S3.SS1.p1.6.m6.1.1.3.9a.cmml" xref="S3.SS1.p1.6.m6.1.1.3.9"><mtext id="S3.SS1.p1.6.m6.1.1.3.9.cmml" mathsize="70%" xref="S3.SS1.p1.6.m6.1.1.3.9">-</mtext></ci><ci id="S3.SS1.p1.6.m6.1.1.3.10.cmml" xref="S3.SS1.p1.6.m6.1.1.3.10">ùëì</ci><ci id="S3.SS1.p1.6.m6.1.1.3.11.cmml" xref="S3.SS1.p1.6.m6.1.1.3.11">ùëü</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">t^{*}_{trigram\textrm{-}fr}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m6.1d">italic_t start_POSTSUPERSCRIPT ‚àó end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t italic_r italic_i italic_g italic_r italic_a italic_m - italic_f italic_r end_POSTSUBSCRIPT</annotation></semantics></math> then translation from <math alttext="t^{*}_{trigram\textrm{-}fr}" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m7.1"><semantics id="S3.SS1.p1.7.m7.1a"><msubsup id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml"><mi id="S3.SS1.p1.7.m7.1.1.2.2" xref="S3.SS1.p1.7.m7.1.1.2.2.cmml">t</mi><mrow id="S3.SS1.p1.7.m7.1.1.3" xref="S3.SS1.p1.7.m7.1.1.3.cmml"><mi id="S3.SS1.p1.7.m7.1.1.3.2" xref="S3.SS1.p1.7.m7.1.1.3.2.cmml">t</mi><mo id="S3.SS1.p1.7.m7.1.1.3.1" xref="S3.SS1.p1.7.m7.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.7.m7.1.1.3.3" xref="S3.SS1.p1.7.m7.1.1.3.3.cmml">r</mi><mo id="S3.SS1.p1.7.m7.1.1.3.1a" xref="S3.SS1.p1.7.m7.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.7.m7.1.1.3.4" xref="S3.SS1.p1.7.m7.1.1.3.4.cmml">i</mi><mo id="S3.SS1.p1.7.m7.1.1.3.1b" xref="S3.SS1.p1.7.m7.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.7.m7.1.1.3.5" xref="S3.SS1.p1.7.m7.1.1.3.5.cmml">g</mi><mo id="S3.SS1.p1.7.m7.1.1.3.1c" xref="S3.SS1.p1.7.m7.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.7.m7.1.1.3.6" xref="S3.SS1.p1.7.m7.1.1.3.6.cmml">r</mi><mo id="S3.SS1.p1.7.m7.1.1.3.1d" xref="S3.SS1.p1.7.m7.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.7.m7.1.1.3.7" xref="S3.SS1.p1.7.m7.1.1.3.7.cmml">a</mi><mo id="S3.SS1.p1.7.m7.1.1.3.1e" xref="S3.SS1.p1.7.m7.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.7.m7.1.1.3.8" xref="S3.SS1.p1.7.m7.1.1.3.8.cmml">m</mi><mo id="S3.SS1.p1.7.m7.1.1.3.1f" xref="S3.SS1.p1.7.m7.1.1.3.1.cmml">‚Å¢</mo><mtext id="S3.SS1.p1.7.m7.1.1.3.9" xref="S3.SS1.p1.7.m7.1.1.3.9a.cmml">-</mtext><mo id="S3.SS1.p1.7.m7.1.1.3.1g" xref="S3.SS1.p1.7.m7.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.7.m7.1.1.3.10" xref="S3.SS1.p1.7.m7.1.1.3.10.cmml">f</mi><mo id="S3.SS1.p1.7.m7.1.1.3.1h" xref="S3.SS1.p1.7.m7.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.7.m7.1.1.3.11" xref="S3.SS1.p1.7.m7.1.1.3.11.cmml">r</mi></mrow><mo id="S3.SS1.p1.7.m7.1.1.2.3" xref="S3.SS1.p1.7.m7.1.1.2.3.cmml">‚àó</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">subscript</csymbol><apply id="S3.SS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.2.1.cmml" xref="S3.SS1.p1.7.m7.1.1">superscript</csymbol><ci id="S3.SS1.p1.7.m7.1.1.2.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2.2">ùë°</ci><times id="S3.SS1.p1.7.m7.1.1.2.3.cmml" xref="S3.SS1.p1.7.m7.1.1.2.3"></times></apply><apply id="S3.SS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3"><times id="S3.SS1.p1.7.m7.1.1.3.1.cmml" xref="S3.SS1.p1.7.m7.1.1.3.1"></times><ci id="S3.SS1.p1.7.m7.1.1.3.2.cmml" xref="S3.SS1.p1.7.m7.1.1.3.2">ùë°</ci><ci id="S3.SS1.p1.7.m7.1.1.3.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3">ùëü</ci><ci id="S3.SS1.p1.7.m7.1.1.3.4.cmml" xref="S3.SS1.p1.7.m7.1.1.3.4">ùëñ</ci><ci id="S3.SS1.p1.7.m7.1.1.3.5.cmml" xref="S3.SS1.p1.7.m7.1.1.3.5">ùëî</ci><ci id="S3.SS1.p1.7.m7.1.1.3.6.cmml" xref="S3.SS1.p1.7.m7.1.1.3.6">ùëü</ci><ci id="S3.SS1.p1.7.m7.1.1.3.7.cmml" xref="S3.SS1.p1.7.m7.1.1.3.7">ùëé</ci><ci id="S3.SS1.p1.7.m7.1.1.3.8.cmml" xref="S3.SS1.p1.7.m7.1.1.3.8">ùëö</ci><ci id="S3.SS1.p1.7.m7.1.1.3.9a.cmml" xref="S3.SS1.p1.7.m7.1.1.3.9"><mtext id="S3.SS1.p1.7.m7.1.1.3.9.cmml" mathsize="70%" xref="S3.SS1.p1.7.m7.1.1.3.9">-</mtext></ci><ci id="S3.SS1.p1.7.m7.1.1.3.10.cmml" xref="S3.SS1.p1.7.m7.1.1.3.10">ùëì</ci><ci id="S3.SS1.p1.7.m7.1.1.3.11.cmml" xref="S3.SS1.p1.7.m7.1.1.3.11">ùëü</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">t^{*}_{trigram\textrm{-}fr}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.7.m7.1d">italic_t start_POSTSUPERSCRIPT ‚àó end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t italic_r italic_i italic_g italic_r italic_a italic_m - italic_f italic_r end_POSTSUBSCRIPT</annotation></semantics></math> to <math alttext="s^{*}_{trigram\textrm{-}en}" class="ltx_Math" display="inline" id="S3.SS1.p1.8.m8.1"><semantics id="S3.SS1.p1.8.m8.1a"><msubsup id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml"><mi id="S3.SS1.p1.8.m8.1.1.2.2" xref="S3.SS1.p1.8.m8.1.1.2.2.cmml">s</mi><mrow id="S3.SS1.p1.8.m8.1.1.3" xref="S3.SS1.p1.8.m8.1.1.3.cmml"><mi id="S3.SS1.p1.8.m8.1.1.3.2" xref="S3.SS1.p1.8.m8.1.1.3.2.cmml">t</mi><mo id="S3.SS1.p1.8.m8.1.1.3.1" xref="S3.SS1.p1.8.m8.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.8.m8.1.1.3.3" xref="S3.SS1.p1.8.m8.1.1.3.3.cmml">r</mi><mo id="S3.SS1.p1.8.m8.1.1.3.1a" xref="S3.SS1.p1.8.m8.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.8.m8.1.1.3.4" xref="S3.SS1.p1.8.m8.1.1.3.4.cmml">i</mi><mo id="S3.SS1.p1.8.m8.1.1.3.1b" xref="S3.SS1.p1.8.m8.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.8.m8.1.1.3.5" xref="S3.SS1.p1.8.m8.1.1.3.5.cmml">g</mi><mo id="S3.SS1.p1.8.m8.1.1.3.1c" xref="S3.SS1.p1.8.m8.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.8.m8.1.1.3.6" xref="S3.SS1.p1.8.m8.1.1.3.6.cmml">r</mi><mo id="S3.SS1.p1.8.m8.1.1.3.1d" xref="S3.SS1.p1.8.m8.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.8.m8.1.1.3.7" xref="S3.SS1.p1.8.m8.1.1.3.7.cmml">a</mi><mo id="S3.SS1.p1.8.m8.1.1.3.1e" xref="S3.SS1.p1.8.m8.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.8.m8.1.1.3.8" xref="S3.SS1.p1.8.m8.1.1.3.8.cmml">m</mi><mo id="S3.SS1.p1.8.m8.1.1.3.1f" xref="S3.SS1.p1.8.m8.1.1.3.1.cmml">‚Å¢</mo><mtext id="S3.SS1.p1.8.m8.1.1.3.9" xref="S3.SS1.p1.8.m8.1.1.3.9a.cmml">-</mtext><mo id="S3.SS1.p1.8.m8.1.1.3.1g" xref="S3.SS1.p1.8.m8.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.8.m8.1.1.3.10" xref="S3.SS1.p1.8.m8.1.1.3.10.cmml">e</mi><mo id="S3.SS1.p1.8.m8.1.1.3.1h" xref="S3.SS1.p1.8.m8.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p1.8.m8.1.1.3.11" xref="S3.SS1.p1.8.m8.1.1.3.11.cmml">n</mi></mrow><mo id="S3.SS1.p1.8.m8.1.1.2.3" xref="S3.SS1.p1.8.m8.1.1.2.3.cmml">‚àó</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><apply id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">subscript</csymbol><apply id="S3.SS1.p1.8.m8.1.1.2.cmml" xref="S3.SS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.1.2.1.cmml" xref="S3.SS1.p1.8.m8.1.1">superscript</csymbol><ci id="S3.SS1.p1.8.m8.1.1.2.2.cmml" xref="S3.SS1.p1.8.m8.1.1.2.2">ùë†</ci><times id="S3.SS1.p1.8.m8.1.1.2.3.cmml" xref="S3.SS1.p1.8.m8.1.1.2.3"></times></apply><apply id="S3.SS1.p1.8.m8.1.1.3.cmml" xref="S3.SS1.p1.8.m8.1.1.3"><times id="S3.SS1.p1.8.m8.1.1.3.1.cmml" xref="S3.SS1.p1.8.m8.1.1.3.1"></times><ci id="S3.SS1.p1.8.m8.1.1.3.2.cmml" xref="S3.SS1.p1.8.m8.1.1.3.2">ùë°</ci><ci id="S3.SS1.p1.8.m8.1.1.3.3.cmml" xref="S3.SS1.p1.8.m8.1.1.3.3">ùëü</ci><ci id="S3.SS1.p1.8.m8.1.1.3.4.cmml" xref="S3.SS1.p1.8.m8.1.1.3.4">ùëñ</ci><ci id="S3.SS1.p1.8.m8.1.1.3.5.cmml" xref="S3.SS1.p1.8.m8.1.1.3.5">ùëî</ci><ci id="S3.SS1.p1.8.m8.1.1.3.6.cmml" xref="S3.SS1.p1.8.m8.1.1.3.6">ùëü</ci><ci id="S3.SS1.p1.8.m8.1.1.3.7.cmml" xref="S3.SS1.p1.8.m8.1.1.3.7">ùëé</ci><ci id="S3.SS1.p1.8.m8.1.1.3.8.cmml" xref="S3.SS1.p1.8.m8.1.1.3.8">ùëö</ci><ci id="S3.SS1.p1.8.m8.1.1.3.9a.cmml" xref="S3.SS1.p1.8.m8.1.1.3.9"><mtext id="S3.SS1.p1.8.m8.1.1.3.9.cmml" mathsize="70%" xref="S3.SS1.p1.8.m8.1.1.3.9">-</mtext></ci><ci id="S3.SS1.p1.8.m8.1.1.3.10.cmml" xref="S3.SS1.p1.8.m8.1.1.3.10">ùëí</ci><ci id="S3.SS1.p1.8.m8.1.1.3.11.cmml" xref="S3.SS1.p1.8.m8.1.1.3.11">ùëõ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">s^{*}_{trigram\textrm{-}en}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.8.m8.1d">italic_s start_POSTSUPERSCRIPT ‚àó end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t italic_r italic_i italic_g italic_r italic_a italic_m - italic_e italic_n end_POSTSUBSCRIPT</annotation></semantics></math>. For both methods, correctly translated center words from tri-grams were counted in the overall evaluation. Predictions by the other two methods were scored similarly. Further details on parameters and configuration are found in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S4.SS2" title="4.2 Machine Translation ‚Ä£ 4 Experimental Settings ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_tag">4.2</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Word2Vec</h3>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="258" id="S3.F1.g1" src="extracted/5880809/cbow.jpg" width="228"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An illustration of predicting a word given the context around it (denoted as <span class="ltx_text ltx_font_italic" id="S3.F1.2.1">anchored words in this article)</span>, called Continuos Bag of Words (CBOW) by <cite class="ltx_cite ltx_citemacro_cite">Mikolov et¬†al., (<a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib19" title="">2013</a>)</cite>.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We used a pre-trained language model (PLM) for experimentation with Word2Vec <cite class="ltx_cite ltx_citemacro_citep">(Mikolov et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib19" title="">2013</a>)</cite>.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We use the pre-trained word news vectors from Google found here:<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/mmihaltz/word2vec-GoogleNews-vectors?tab=readme-ov-file." title="">https://github.com/mmihaltz/word2vec-GoogleNews-vectors?tab=readme-ov-file.</a></span></span></span> The hope is that through the use of a PLM we can capture context in several different domains, specifically the corpus that we use which is parliamentary in nature.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">The PLM weights from Word2Vec were used as a manner to predict anchored words due to the fact that the training method for them is based on a CBOW model. CBOW was selected because, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S3.F1" title="Figure 1 ‚Ä£ 3.2 Word2Vec ‚Ä£ 3 Methodology ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_tag">1</span></a>, its training objective most closely resembles the task we are trying to accomplish‚Äîthe prediction of a word surrounded by anchored text (one word on the left and one word on the right).</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">As a first step, the PLM was downloaded and experimented as-is in its out-of-the-box state which consists of 300 dimensions and a default vocabulary. Then, in order to fine-tune the model, we adapted it to our parliamentary corpus. After the fine-tuning of the model, anchored tri-grams were extracted from <math alttext="s^{\prime}" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><msup id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">s</mi><mo id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">ùë†</ci><ci id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">s^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_s start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> and used as input to the PLM where the center word is used for prediction and the left and right ‚Äúanchors‚Äù are used as input one-hot encoded embeddings, similar to the training exercise from <cite class="ltx_cite ltx_citemacro_cite">Mikolov et¬†al., (<a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib19" title="">2013</a>)</cite>. Further details on parameters and configuration are found in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S4.SS3" title="4.3 Word2Vec ‚Ä£ 4 Experimental Settings ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_tag">4.3</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>BERT</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Models based on the BERT <cite class="ltx_cite ltx_citemacro_citep">(Kenton and Toutanova,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib12" title="">2019</a>)</cite> algorithm are used frequently in modern times. They use an attention mechanism <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib27" title="">2017</a>)</cite> and are known to be capable of capturing information better than previous implementations such as Word2vec. Therefore, in order to compare both algorithms to MT for predicting anchored words, we experiment with DistilBERT <cite class="ltx_cite ltx_citemacro_citep">(Sanh et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib22" title="">2019</a>)</cite>, a BERT-based model that uses masked language modeling that in theory captures more parameters than the Word2Vec CBOW model.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">Similar to the Word2Vec method, we fine-tune our DistilBERT model on the parliamentary corpus with a masked language modeling objective. We chose the masked language modeling objective as it is the most similar objective to CBOW. Further details on parameters and configuration are found in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S4.SS4" title="4.4 BERT ‚Ä£ 4 Experimental Settings ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_tag">4.4</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>GPT-4</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">We experiment with prompting GPT-4 to predict anchored text using a temperature of 0 and the following prompt: <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.1">‚ÄúYou are an expert lexicographer and natural language processing assistant. Additionally, you are highly specialized in parliamentary proceedings. Given a trigram I provide with a ‚Äô?‚Äô character in the center word, I need you to predict the ‚Äô?‚Äô character with the most likely single-word token. Please return one predicted token without any text except the predicted token in your response. Do not provide the surrounding text or any additional information. Do not include the text ‚Äôpredicting‚Äô, ‚Äôpredict‚Äô, ‚Äôprediction‚Äô, ‚Äôpredicted‚Äô ‚Äôthe predicted token is‚Äô or ‚ÄôThe predicted token is‚Äô in your response. Do not include any extra characters such as apostrophes, commas, colons, or semicolons in your response. Do not include any newline characters in your response.‚Äù</span>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Settings</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Corpus</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">The corpus consists of 393,371 SL-TL pairs of European parliamentary proceedings, a freely available translation memory <cite class="ltx_cite ltx_citemacro_citep">(Steinberger et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib24" title="">2012</a>)</cite> obtained from the European Commission DGT-Translation Memory repository.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://joint-research-centre.ec.europa.eu/language-technology-resources/dgt-translation-memory_en" title="">https://joint-research-centre.ec.europa.eu/language-technology-resources/dgt-translation-memory_en</a></span></span></span> The corpus is divided randomly with a random state of <math alttext="42" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mn id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">42</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><cn id="S4.SS1.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS1.p1.1.m1.1.1">42</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">42</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">42</annotation></semantics></math>. We divide the corpus up into 70% train, 20% dev, and 10% test sets as shown in in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S4.T2" title="Table 2 ‚Ä£ 4.1 Corpus ‚Ä£ 4 Experimental Settings ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_t" id="S4.T2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.1">Data set</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.2.1">Segment Size</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t" id="S4.T2.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.2.1.1.1">Train</span></th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.1.2.1.2">275,317</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l" id="S4.T2.1.3.2.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.3.2.1.1">Development</span></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T2.1.3.2.2">77,877</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l" id="S4.T2.1.4.3.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.4.3.1.1">Test</span></th>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T2.1.4.3.2">40,117</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_t" id="S4.T2.1.5.4.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.5.4.1.1">Total</span></th>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.1.5.4.2">393,371</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Experimental sets from the European Commission DGT Translation memory used for creating and evaluating the three approaches.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Machine Translation</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">As mentioned previously, we use the Open-NMT <cite class="ltx_cite ltx_citemacro_citep">(Klein et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib13" title="">2020</a>)</cite> framework to build our French to English (FR‚ÄìEN) and English to French (EN‚ÄìFR) MT system. The system is based on a transformer architecture model with the following hyper-parameters: A maximum sequence length of 500, an early stopping parameter of 4, 7,800 train steps, 1,000 validation steps, a bucket size of 262,144, a batch size of 4,096, and a validation batch size of 2,048. The optimizer is an Adam (beta2 of 0.998) optimizer with with fp16 activated, a learning rate of 2, noam decay, label smoothing of 0.1, a hidden size of 512, word vector size of 512, 8 attention heads, a dropout of 0.1, and an attention dropout of 0.1. The choice of parameter selection is inspired by previous work from Yasmin Moslem.<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ymoslem/OpenNMT-Tutorial" title="">https://github.com/ymoslem/OpenNMT-Tutorial</a></span></span></span></p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">In order to verify that the NMT system is on-par with the latest MT systems for FR‚ÄìEN and EN‚ÄìFR, we first test the system in both directions on the test set. During test, we achieved a BLEU score of 55.84 for FR‚ÄìEN and 62.60 for EN-FR. Nonetheless, as we show in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S5" title="5 Results ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_tag">5</span></a>, the translation of anchored words as measured by character rate and accuracy was not remarkable.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Word2Vec</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">The CBOW algorithm for Word2vec is a well-known algorithm performed as a way of capturing semantics via a language model <cite class="ltx_cite ltx_citemacro_citep">(Mikolov et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib19" title="">2013</a>)</cite>. We describe our Word2Vec CBOW implemenation. Before fine-tuning, the Word2Vec model has 300 dimensions with a window size of 2 and a minimum word count of 1. Additionally, pre-defined vocabulary is used in the Google News Vectors that contains billions of words. The model is fine-tuned with our training set which is tokenized using the NLTK RegexpTokenizer<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.nltk.org/_modules/nltk/tokenize/regexp.html" title="">https://www.nltk.org/_modules/nltk/tokenize/regexp.html</a></span></span></span>. The embeddings created from the training set use lockf at 1.0 and a window size of 3, similar to Zarrar Shehzad.<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://czarrar.github.io/Gensim-Word2Vec/" title="">https://czarrar.github.io/Gensim-Word2Vec/</a></span></span></span></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>BERT</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">Our BERT model is based on a PLM called DistilBERT<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation" title="">https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation</a></span></span></span>. <cite class="ltx_cite ltx_citemacro_citep">(Sanh et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib22" title="">2019</a>)</cite> We train DistilBERT using the HuggingFace PyTorch Trainer with 10 training epochs, a learning rate of 2e-5, weight decay of 0.01, and FP16 mixed precision set to true. Hyperparameters are inspired by HuggingFace.<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/learn/nlp-course/en/chapter7/3" title="">https://huggingface.co/learn/nlp-course/en/chapter7/3</a></span></span></span></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>GPT-4</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">GPT-4 was prompted using the gpt-4-turbo variant and queried repetitively through the OpenAI API. Due to newline mismatches that occurred during batch processing, we opted to run an API call for every line in the dataset.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>
<figure class="ltx_table" id="S5.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T3.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S5.T3.1.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.2.1">60‚Äì69%</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.3.1">70‚Äì79%</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.4.1">80‚Äì89%</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.5.1">90‚Äì100%</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.1.2.1.1">BERT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.2.1.2.1">8.97</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.1.3"><span class="ltx_text ltx_font_bold" id="S5.T3.1.2.1.3.1">9.61</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.1.4"><span class="ltx_text ltx_font_bold" id="S5.T3.1.2.1.4.1">7.98</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.1.5"><span class="ltx_text ltx_font_bold" id="S5.T3.1.2.1.5.1">7.87</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.3.2.1">GPT</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.2.2">4.82</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.2.3">5.58</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.2.4">3.85</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.2.5">2.74</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.4.3.1">W2V</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.3.2">3.39</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.3.3">3.46</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.3.4">2.89</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.3.5">3.02</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.5.4.1">NMT-1</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.5.4.2">0.15</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.5.4.3">0.14</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.5.4.4">0.28</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.5.4.5">0.19</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S5.T3.1.6.5.1">NMT-2</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.1.6.5.2">3.75</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.1.6.5.3">4.36</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.1.6.5.4">4.16</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.1.6.5.5">6.35</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Accuracy scores for various fuzzy-match threshold on five deep-learning approaches.</figcaption>
</figure>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this section, we compare the results obtained from running four approaches for predicting the anchored word: (1) Neural Machine Translation (NMT) (2) Word2Vec (3) BERT and (4) GPT-4. NMT is divided into the two approaches mentioned in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S3.SS1" title="3.1 Machine Translation ‚Ä£ 3 Methodology ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_tag">3.1</span></a> (sentence-level and tri-grams). Accuracy measurements are performed and reported for all holes<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>A hole is a span of a tri-gram where the center word is predicted.</span></span></span>. Additionally, we report on character matches for each approach after dividing the segments into fuzzy-match thresholds, common practice for FMR work (see <cite class="ltx_cite ltx_citemacro_citep">(Ortega et¬†al.,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib21" title="">2016</a>; Bulte and Tezcan,, <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#bib.bib5" title="">2019</a>)</cite>).</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">First, we report on character match rates for the three approaches. Character match is defined as the number of characters in the output token that correspond to characters in the desired string. In Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S5.F2" title="Figure 2 ‚Ä£ 5 Results ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_tag">2</span></a>, we report the average character match for GPT-4, BERT, Word2Vec, NMT-1 (segment-level MT) and NMT-2 (tri-gram MT). We observe a marked improvement in average character match with language modeling approaches (BERT and Word2Vec) and GPT-4 performs competitively in most cases. BERT outperforms all approaches across all fuzzy-match thresholds. From an MT standpoint, the secondary approach (called NMT-2 in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S5.F2" title="Figure 2 ‚Ä£ 5 Results ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_tag">2</span></a>) outperforms the primary approach; it appears that in our experiments the translation of anchored tri-grams is better than translating the entire segment.</p>
</div>
<figure class="ltx_figure" id="S5.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="360" id="S5.F2.g1" src="extracted/5880809/character.jpg" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Average character match (y-axis) by fuzzy-match rate percentage (x-axis) by segment of the four experimental approaches: BERT, GPT, Word2Vec, Neural Machine Translation 1 and Neural Machine Translation 2 systems for different segment-level fuzzy-match thresholds.</figcaption>
</figure>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">Additionally, we measured the accuracy for the three approaches in order to better understand the hole span coverage. For accuracy, we measure only if prediction was correct or not; we do not take into account other predictions like blank, extra words, or others. To this end, we present accuracy scores in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.17939v1#S5.T3" title="Table 3 ‚Ä£ 5 Results ‚Ä£ Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.1">In our experiments, we notice that the NMT systems perform better on stop words and digits such as the phrase: ‚Äúbeyond <span class="ltx_text ltx_font_bold" id="S5.p4.1.1">90</span> ghz‚Äù. Both the BERT and NMT systems were found to perform well in those situations. However, the MT system oftentimes did not replace one word only‚Äîin several cases it aggregated several words more. BERT performed well on average when compared with the other approaches. GPT remains competitive on all fuzzy match ranges except 90‚Äì100.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this article, we have illustrated that via the use of a language model, predicting anchored words performed better in our experiments. The BERT model outperforms other approaches including neural machine translation (with two approaches) when measured via character match and tri-gram anchored word coverage.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">We also demonstrate how generative models might be prompted to aid in predicting anchored text. It is our belief that this work could assist CAT tools backed by TMs and MT systems.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et¬†al.,  (2023)</span>
<span class="ltx_bibblock">
Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F.¬†L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., et¬†al. (2023).

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2303.08774</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biccici and Dymetman,  (2008)</span>
<span class="ltx_bibblock">
Biccici, E. and Dymetman, M. (2008).

</span>
<span class="ltx_bibblock">Dynamic translation memory: Using statistical machine translation to improve translation memory fuzzy matches.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">Computational Linguistics and Intelligent Text Processing</span>, pages 454‚Äì465.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bowker,  (2002)</span>
<span class="ltx_bibblock">
Bowker, L. (2002).

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">Computer-aided translation technology: a practical introduction</span>.

</span>
<span class="ltx_bibblock">University of Ottawa Press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et¬†al.,  (1993)</span>
<span class="ltx_bibblock">
Brown, P.¬†F., Della¬†Pietra, S.¬†A., Della¬†Pietra, V.¬†J., and Mercer, R.¬†L. (1993).

</span>
<span class="ltx_bibblock">The mathematics of statistical machine translation: Parameter estimation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">Computational Linguistics</span>, 19(2):263‚Äì311.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bulte and Tezcan,  (2019)</span>
<span class="ltx_bibblock">
Bulte, B. and Tezcan, A. (2019).

</span>
<span class="ltx_bibblock">Neural fuzzy repair: Integrating fuzzy matches into neural machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</span>, pages 1800‚Äì1809, Florence, Italy.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bulte et¬†al.,  (2018)</span>
<span class="ltx_bibblock">
Bulte, B., Vanallemeersch, T., and Vandeghinste, V. (2018).

</span>
<span class="ltx_bibblock">M3TRA: integrating TM and MT for professional translators.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">Proceedings of the 21st Annual Conference of the European Association for Machine Translation</span>, pages 69‚Äì78, Alacant, Spain.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dandapat et¬†al.,  (2011)</span>
<span class="ltx_bibblock">
Dandapat, S., Morrissey, S., Way, A., and Forcada, M.¬†L. (2011).

</span>
<span class="ltx_bibblock">Using example-based MT to support statistical MT when translating homogeneous data in a resource-poor setting.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 15th Annual Conference of the European Association for Machine Translation</span>, pages 201‚Äì208, Leuven, Belgium.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Espla-Gomis et¬†al.,  (2011)</span>
<span class="ltx_bibblock">
Espla-Gomis, M., Sanchez-Martinez, F., and Forcada, M.¬†L. (2011).

</span>
<span class="ltx_bibblock">Using word alignments to assist computer-aided translation users by marking which target-side words to change or keep unedited.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">European Association for Machine Translation Conferences/Workshops</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et¬†al.,  (2018)</span>
<span class="ltx_bibblock">
Gu, J., Wang, Y., Cho, K., and Li, V.¬†O. (2018).

</span>
<span class="ltx_bibblock">Search engine guided neural machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 32 AAAI Conference on Artificial Intelligence</span>, pages 5133‚Äì5140, New Orleans, USA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hewavitharana et¬†al.,  (2005)</span>
<span class="ltx_bibblock">
Hewavitharana, S., Vogel, S., and Waibel, A. (2005).

</span>
<span class="ltx_bibblock">Augmenting a statistical translation system with a translation memory.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">Proceedings of the 10th Annual Conference of the European Association for Machine Translation</span>, pages 126‚Äì132, Budapest, Hungary.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Irsoy et¬†al.,  (2020)</span>
<span class="ltx_bibblock">
Irsoy, O., Benton, A., and Stratos, K. (2020).

</span>
<span class="ltx_bibblock">Corrected cbow performs as well as skip-gram.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2012.15332</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kenton and Toutanova,  (2019)</span>
<span class="ltx_bibblock">
Kenton, J. D. M.-W.¬†C. and Toutanova, L.¬†K. (2019).

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">Proceedings of NAACL-HLT</span>, pages 4171‚Äì4186.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Klein et¬†al.,  (2020)</span>
<span class="ltx_bibblock">
Klein, G., Hernandez, F., Nguyen, V., and Senellart, J. (2020).

</span>
<span class="ltx_bibblock">The opennmt neural machine translation toolkit: 2020 edition.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 14th Conference of the Association for Machine Translation in the Americas (Volume 1: Research Track)</span>, pages 102‚Äì109.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koehn and Senellart,  (2010)</span>
<span class="ltx_bibblock">
Koehn, P. and Senellart, J. (2010).

</span>
<span class="ltx_bibblock">Convergence of translation memory and statistical machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">Proceedings of AMTA Workshop on MT Research and the Translation Industry</span>, pages 21‚Äì31, Denver, USA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kranias and Samiotou,  (2004)</span>
<span class="ltx_bibblock">
Kranias, L. and Samiotou, A. (2004).

</span>
<span class="ltx_bibblock">Automatic translation memory fuzzy match post-editing: a step beyond traditional TM/MT integration.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">Proceedings of the Fourth International Conference on Language Resources and Evaluation</span>, pages 331‚Äì334, Lisbon, Portugal.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Levenshtein,  (1966)</span>
<span class="ltx_bibblock">
Levenshtein, V. (1966).

</span>
<span class="ltx_bibblock">Binary codes capable of correcting deletions, insertions and reversals.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">Soviet Physics Doklady.</span>, 10(8):707‚Äì710.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et¬†al.,  (2016)</span>
<span class="ltx_bibblock">
Li, L., Parra¬†Escartin, C., and Liu, Q. (2016).

</span>
<span class="ltx_bibblock">Combining translation memories and syntax-based SMT.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">Baltic Journal of Modern Computing</span>, 4:165‚Äì177.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et¬†al.,  (2019)</span>
<span class="ltx_bibblock">
Liu, Y., Wang, K., Zong, C., and Su, K.-Y. (2019).

</span>
<span class="ltx_bibblock">A unified framework and models for integrating translation memory into phrase-based statistical machine translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">Computer Speech and Language</span>, 54:176‚Äì206.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mikolov et¬†al.,  (2013)</span>
<span class="ltx_bibblock">
Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013).

</span>
<span class="ltx_bibblock">Efficient estimation of word representations in vector space.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:1301.3781</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ortega et¬†al.,  (2014)</span>
<span class="ltx_bibblock">
Ortega, J.¬†E., Sanchez-Martinez, F., and Forcada, M.¬†L. (2014).

</span>
<span class="ltx_bibblock">Using any machine translation source for fuzzy-match repair in a computer-aided translation setting.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">Proceedings of the 11th Biennial Conference of the Association for Machine Translation in the Americas (AMTA 2014, vol. 1: MT Rsearchers)</span>, pages 42‚Äì53, Vancouver, BC, Canada.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ortega et¬†al.,  (2016)</span>
<span class="ltx_bibblock">
Ortega, J.¬†E., Sanchez-Martinez, F., and Forcada, M.¬†L. (2016).

</span>
<span class="ltx_bibblock">Fuzzy-match repair using black-box machine translation systems: what can be expected?

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">Proceedings of the 12th Biennial Conference of the Association for Machine Translation in the Americas (AMTA 2016, vol. 1: MT Researchers‚Äô Track)</span>, pages 27‚Äì39, Austin, USA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanh et¬†al.,  (2019)</span>
<span class="ltx_bibblock">
Sanh, V., Debut, L., Chaumond, J., and Wolf, T. (2019).

</span>
<span class="ltx_bibblock">Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:1910.01108</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Simard and Isabelle,  (2009)</span>
<span class="ltx_bibblock">
Simard, M. and Isabelle, P. (2009).

</span>
<span class="ltx_bibblock">Phrase-based machine translation in a computer-assisted translation environment.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">Proceeding of the 12th Machine Translation Summit (MT Summit XII)</span>, pages 120‚Äì127, Quebec, Canada.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Steinberger et¬†al.,  (2012)</span>
<span class="ltx_bibblock">
Steinberger, R., Eisele, A., Klocek, S., Pilos, S., and Schluter, P. (2012).

</span>
<span class="ltx_bibblock">DGT-TM: A freely available translation memory in 22 languages.

</span>
<span class="ltx_bibblock">In Calzolari, N., Choukri, K., Declerck, T., Dougan, M.¬†U., Maegaard, B., Mariani, J., Moreno, A., Odijk, J., and Piperidis, S., editors, <span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC‚Äô12)</span>, pages 454‚Äì459, Istanbul, Turkey. European Language Resources Association (ELRA).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tezcan and Bulte,  (2022)</span>
<span class="ltx_bibblock">
Tezcan, A. and Bulte, B. (2022).

</span>
<span class="ltx_bibblock">Evaluating the impact of integrating similar translations into neural machine translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">Inf.</span>, 13:19.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tezcan et¬†al.,  (2021)</span>
<span class="ltx_bibblock">
Tezcan, A., Bulte, B., and Vanroy, B. (2021).

</span>
<span class="ltx_bibblock">Towards a better integration of fuzzy matches in neural machine translation through data augmentation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib26.1.1">Informatics</span>, volume¬†8, page¬†7. MDPI.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et¬†al.,  (2017)</span>
<span class="ltx_bibblock">
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.¬†N., Kaiser, L., and Polosukhin, I. (2017).

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib27.1.1">Advances in neural information processing systems</span>, 30.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vogel et¬†al.,  (1996)</span>
<span class="ltx_bibblock">
Vogel, S., Ney, H., and Tillmann, C. (1996).

</span>
<span class="ltx_bibblock">HMM-based word alignment in statistical translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib28.1.1">COLING96</span>, pages 836‚Äì841, Copenhagen.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">VRehuuVrek et¬†al.,  (2011)</span>
<span class="ltx_bibblock">
VRehuuVrek, R., Sojka, P., et¬†al. (2011).

</span>
<span class="ltx_bibblock">Gensim‚Äîstatistical semantics in python.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib29.1.1">Retrieved from genism. org</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wagner and Fischer,  (1974)</span>
<span class="ltx_bibblock">
Wagner, R.¬†A. and Fischer, M.¬†J. (1974).

</span>
<span class="ltx_bibblock">The string-to-string correction problem.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib30.1.1">Journal of the Association for Computing Machinery</span>, 21(1):168‚Äì173.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhechev and Genabith,  (2010)</span>
<span class="ltx_bibblock">
Zhechev, V. and Genabith, J.¬†V. (2010).

</span>
<span class="ltx_bibblock">Seeding statistical machine translation with translation memory output through tree-based structural alignment.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib31.1.1">Proceedings of SSST-4 - 4th Workshop on Syntax and Structure in Statistical Translation</span>, pages 43‚Äì49, Dublin, Ireland.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_end_2_columns"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Sep 26 15:05:57 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
