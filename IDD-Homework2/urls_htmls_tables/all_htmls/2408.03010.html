<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs</title>
<!--Generated on Tue Aug  6 07:40:27 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2408.03010v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S1" title="In Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S2" title="In Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S3" title="In Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>System Description</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S3.SS1" title="In 3 System Description ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Cypher Query Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S3.SS2" title="In 3 System Description ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Query Pre-Processors</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S3.SS3" title="In 3 System Description ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Graph Question Answering and Verbalization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S3.SS4" title="In 3 System Description ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Explainability through Evidence</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S3.SS5" title="In 3 System Description ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>User Interface and Example of Usage</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S4" title="In Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S4.SS1" title="In 4 Evaluation ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Graph Retrieval Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S4.SS2" title="In 4 Evaluation ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Evaluating Correctness and Completeness</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S4.SS3" title="In 4 Evaluation ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Handling Incorrect Graph Responses</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S5" title="In Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#A1" title="In Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Daniel Steinigen<sup class="ltx_sup" id="id1.1.id1">1</sup>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id2.2.id2">Roman Teucher<sup class="ltx_sup" id="id2.2.id2.1">1</sup></span>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id3.3.id3">Timm Heine Ruland<sup class="ltx_sup" id="id3.3.id3.1">1</sup></span>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id4.4.id4">Max Rudat<sup class="ltx_sup" id="id4.4.id4.1">1</sup></span>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id5.5.id5">Nicolas Flores-Herr</span>
<br class="ltx_break"/>Fraunhofer IAIS 
<br class="ltx_break"/>Sankt Augustin, Germany 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id6.6.id6">&lt;first-name&gt;.&lt;last-name&gt;@iais.fraunhofer.de</span>
<br class="ltx_break"/><sup class="ltx_sup" id="id7.7.id7">1</sup>All authors contributed equally to this work 
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id8.8.id8">\And</span>Peter Fischer<sup class="ltx_sup" id="id9.9.id9">2</sup>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id10.10.id10">Nikola Milosevic<sup class="ltx_sup" id="id10.10.id10.1">2</sup></span>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id11.11.id11">Christopher Schymura<sup class="ltx_sup" id="id11.11.id11.1">2</sup></span>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id12.12.id12">Angelo Ziletti<sup class="ltx_sup" id="id12.12.id12.1">2</sup></span>
<br class="ltx_break"/>Bayer AG 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id13.13.id13">&lt;first-name&gt;.&lt;last-name&gt;@bayer.com</span>
<br class="ltx_break"/><sup class="ltx_sup" id="id14.14.id14">2</sup>Shared senior authorship 
<br class="ltx_break"/>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id15.id1">Recent advancements in Large Language Models (LLMs) have showcased their proficiency in answering natural language queries. However, their effectiveness is hindered by limited domain-specific knowledge, raising concerns about the reliability of their responses. We introduce a hybrid system that augments LLMs with domain-specific knowledge graphs (KGs), thereby aiming to enhance factual correctness using a KG-based retrieval approach. We focus on a medical KG to demonstrate our methodology, which includes (1) pre-processing, (2) Cypher query generation, (3) Cypher query processing, (4) KG retrieval, and (5) LLM-enhanced response generation. We evaluate our system on a curated dataset of 69 samples, achieving a precision of 78% in retrieving correct KG nodes. Our findings indicate that the hybrid system surpasses a standalone LLM in accuracy and completeness, as verified by an LLM-as-a-Judge evaluation method. This positions the system as a promising tool for applications that demand factual correctness and completeness, such as target identification — a critical process in pinpointing biological entities for disease treatment or crop enhancement. Moreover, its intuitive search interface and ability to provide accurate responses within seconds make it well-suited for time-sensitive, precision-focused research contexts. We publish the source code together with the dataset and the prompt templates used<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/chrschy/fact-finder" title="">https://github.com/chrschy/fact-finder</a></span></span></span>.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.1.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.1">
Daniel Steinigen<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.1">1</sup></span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.2.2.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.2.2.1.1">Roman Teucher<sup class="ltx_sup" id="p1.1.2.1.1.2.2.1.1.1">1</sup></span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.3.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.3.3.1.1">Timm Heine Ruland<sup class="ltx_sup" id="p1.1.2.1.1.3.3.1.1.1">1</sup></span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.4.4">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.4.4.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.4.4.1.1">Max Rudat<sup class="ltx_sup" id="p1.1.2.1.1.4.4.1.1.1">1</sup></span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.5.5">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.5.5.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.5.5.1.1">Nicolas Flores-Herr</span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.6.6">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.6.6.1">Fraunhofer IAIS</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.7.7">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.7.7.1">Sankt Augustin, Germany</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.8.8">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.8.8.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.8.8.1.1">&lt;first-name&gt;.&lt;last-name&gt;@iais.fraunhofer.de</span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.9.9">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.9.9.1"><sup class="ltx_sup" id="p1.1.2.1.1.9.9.1.1">1</sup>All authors contributed equally to this work</span></span>
</span>
</span></span>                      <span class="ltx_text ltx_inline-block" id="p1.1.2.2" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.2.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.2.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.2.1.1.1.1.1">Peter Fischer<sup class="ltx_sup" id="p1.1.2.2.1.1.1.1.1.1">2</sup></span></span></span>
<span class="ltx_tr" id="p1.1.2.2.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.2.1.2.2.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.2.1.2.2.1.1">Nikola Milosevic<sup class="ltx_sup" id="p1.1.2.2.1.2.2.1.1.1">2</sup></span></span></span>
<span class="ltx_tr" id="p1.1.2.2.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.2.1.3.3.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.2.1.3.3.1.1">Christopher Schymura<sup class="ltx_sup" id="p1.1.2.2.1.3.3.1.1.1">2</sup></span></span></span>
<span class="ltx_tr" id="p1.1.2.2.1.4.4">
<span class="ltx_td ltx_align_center" id="p1.1.2.2.1.4.4.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.2.1.4.4.1.1">Angelo Ziletti<sup class="ltx_sup" id="p1.1.2.2.1.4.4.1.1.1">2</sup></span></span></span>
<span class="ltx_tr" id="p1.1.2.2.1.5.5">
<span class="ltx_td ltx_align_center" id="p1.1.2.2.1.5.5.1">Bayer AG</span></span>
<span class="ltx_tr" id="p1.1.2.2.1.6.6">
<span class="ltx_td ltx_align_center" id="p1.1.2.2.1.6.6.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.2.2.1.6.6.1.1">&lt;first-name&gt;.&lt;last-name&gt;@bayer.com</span></span></span>
<span class="ltx_tr" id="p1.1.2.2.1.7.7">
<span class="ltx_td ltx_align_center" id="p1.1.2.2.1.7.7.1"><sup class="ltx_sup" id="p1.1.2.2.1.7.7.1.1">2</sup>Shared senior authorship</span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<figure class="ltx_figure" id="S0.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="402" id="S0.F1.1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of the FactFinder pipeline using large language models and knowledge graphs to answer scientific questions.</figcaption>
</figure>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recently, Large Language Models (LLMs) have enabled sophisticated question-answering systems, revolutionizing the landscape of natural language processing <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib22" title="">2023</a>); Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib15" title="">2023a</a>); Bubeck et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib4" title="">2023</a>); Park et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib24" title="">2023</a>); Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib28" title="">2023</a>); Katz et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib17" title="">2023</a>)</cite>. These advanced models, with their ability to understand and generate human-like text, have shown great potential in various domains, including life sciences <cite class="ltx_cite ltx_citemacro_cite">Nori et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib21" title="">2023</a>); Waisberg et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib29" title="">2023</a>); Bašaragin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib3" title="">2024</a>)</cite>.
However, LLMs are limited by the timeframe of their training data and can produce incorrect statements, known as hallucinations <cite class="ltx_cite ltx_citemacro_cite">Ji et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib14" title="">2023</a>)</cite>, or incomplete answers by providing only a few relevant entities while missing others not included in their internal knowledge.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">In domains such as life sciences, obtaining answers with current and factual information is paramount for many use cases <cite class="ltx_cite ltx_citemacro_cite">Malaviya et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib19" title="">2023</a>); Ljajić et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib18" title="">2024</a>)</cite>. Factually correct AI-generated reviews can aid researchers in information retrieval and hypothesis building.
For example, target identification requires up-to-date knowledge of the latest literature. Target identification involves pinpointing a biological entity, such as a gene or protein, that can be manipulated to achieve a desired effect, like treating a disease in humans (pharmaceuticals) or improving crop resilience in plants (crop sciences).
Similarly, designing effective field or clinical trials requires considering up-to-date information. For field trials in crop sciences, this may include environmental and climatic conditions, market developments, and regulatory requirements. For clinical trials and medical writing, relevant information includes details about the drug under development, market conditions, planned sites, and regulatory requirements.
Current and timely information is crucial for competitive intelligence, including insights on competitor products, disease epidemiology, and market size. AI-based solutions can assist in identifying concurrent disease occurrences and help researchers develop hypotheses using real-world data.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Knowledge Graphs (KGs) represent a promising strategy for improving factual correctness in LLMs <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib16" title="">2023b</a>); Baek et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib2" title="">2023</a>); Sen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib26" title="">2023</a>)</cite>, including the life science domain <cite class="ltx_cite ltx_citemacro_cite">Feng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib10" title="">2024</a>)</cite>. By organizing entities such as drugs, diseases, and genes, along with their relationships, into a structured network, KGs provide useful additional context for LLMs for precise and relevant information retrieval <cite class="ltx_cite ltx_citemacro_cite">Chandak et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib6" title="">2023</a>); Milošević and Thielemann (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib20" title="">2023</a>); Badenes-Olmedo and Corcho (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib1" title="">2023</a>)</cite>. This organized data framework allows LLMs to produce more factually accurate and comprehensive responses <cite class="ltx_cite ltx_citemacro_cite">Pan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib23" title="">2024</a>)</cite>.
In addition, KGs enable systems to leverage current and comprehensive information, including recent data not available during the LLMs’ training phase. From an organizational standpoint, integrating KGs enhances top-tier LLMs with proprietary or specialized knowledge. This integration facilitates the inclusion of unique organizational data sources, such as historical and ongoing lab experiments or licensed datasets.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this paper, we present FactFinder - a hybrid question answering (QA) system - which leverages both KG and LLM to provide answers to scientific questions. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S0.F1" title="Figure 1 ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_tag">1</span></a> depicts the system’s architecture, which is structured as a pipeline with several subcomponents.
Our main contributions are:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We provide an easy-to-use system that answers scientific questions combining LLMs and KGs.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We release a dataset of manually annotated text-to-Cypher query pairs, which could serve as benchmark for validating text-to-Cypher conversion system.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We present a methodology showing that current state-of-the-art LLMs are able to generate satisfactory Cypher queries for the life science domain.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">We share our dataset, source code, and prompt templates<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/chrschy/fact-finder" title="">https://github.com/chrschy/fact-finder</a></span></span></span>.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Data</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Knowledge graph.</span>
We use PrimeKG <cite class="ltx_cite ltx_citemacro_cite">Chandak et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib6" title="">2023</a>)</cite> as our source of fact-based background knowledge. PrimeKG integrates 20 high-quality resources to describe 17,080 diseases with 4,050,249 relationships, including over 100,000 nodes and 29 types of edges that densely connect disease nodes with drugs, genes, exposures, and phenotypes.
We preprocess the graph data by mapping names to their preferred terms, as described in <a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S3.SS1" title="3.1 Cypher Query Generation ‣ 3 System Description ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3.1</span></a>, and converting all entries to lowercase.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.p2.1.1">Text-to-Cypher dataset.</span>

We manually generated a ground-truth dataset containing 69 text-to-Cypher query pairs specifically designed for medical questions. These queries are complex, often involving multiple hops in the graph, aggregation, and boolean question structures. They require deep knowledge of Cypher and the KG. Each entry includes a natural language question, the corresponding Cypher query, the expected answer, and relevant nodes and relationships.
This dataset provides a benchmark to evaluate the ability of text-to-Cypher systems to interpret and execute complex queries. While specialized to the PrimeKG graph, the dataset leverages PrimeKG’s extensive applicability, making it a valuable resource for various medical information retrieval tasks.
Examples from the dataset include simpler questions like <span class="ltx_text ltx_font_italic" id="S2.p2.1.2">Which drugs have pterygium as a side effect?</span> and more complex ones such as <span class="ltx_text ltx_font_italic" id="S2.p2.1.3">Which medications have more off-label uses than approved indications?</span> and <span class="ltx_text ltx_font_italic" id="S2.p2.1.4">Which diseases have only treatments that have no side effects at all?</span></p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>System Description</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Cypher Query Generation</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Generating code to query structured databases from natural language inquiries used to be a complex process, involving steps such as entity and relation extraction, entity and relation linking, query type classification, template-based or compositional query generation <cite class="ltx_cite ltx_citemacro_cite">Srivastava et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib27" title="">2021</a>); Chakraborty et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib5" title="">2021</a>)</cite>.
Retrieval-based approaches like Graph-RAG aim to simplify this by partitioning the graph into communities of nodes and edges, which are then retrieved and summarized using a LLM to generate an answer <cite class="ltx_cite ltx_citemacro_cite">Edge et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib8" title="">2024</a>)</cite>. However, Graph-RAG struggles with complex queries that span multiple graph communities</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">With the advent of LLMs, however, QA systems can now understand domain-specific questions and generate valid queries directly, allowing for more flexible approaches.
Much of the research has been centered on text-to-SQL generation, where LLMs have demonstrated considerable effectiveness <cite class="ltx_cite ltx_citemacro_cite">Gao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib11" title="">2023</a>); Chang and Fosler-Lussier (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib7" title="">2023</a>)</cite>, including in the medical domain <cite class="ltx_cite ltx_citemacro_cite">Ziletti and D’Ambrosi (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib32" title="">2024</a>)</cite>, and have often performed better than specialized models <cite class="ltx_cite ltx_citemacro_cite">Pourreza and Rafiei (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib25" title="">2023</a>)</cite>.
Conversely, the area of text-to-Cypher query generation remains relatively under-explored, with prior research primarily focused on sequence-to-sequence models <cite class="ltx_cite ltx_citemacro_cite">Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib30" title="">2024</a>); Guo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib13" title="">2022</a>)</cite>. Only recently has the application of LLMs to this task begun to emerge <cite class="ltx_cite ltx_citemacro_cite">Feng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib9" title="">2023</a>)</cite>.
To bridge this gap, our work evaluates the capabilities of LLMs to produce Cypher queries for scientific QA in the medical domain (see Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S4.SS1" title="4.1 Graph Retrieval Evaluation ‣ 4 Evaluation ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_tag">4.1</span></a>).</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">We prompt LLMs with questions and graph schemas, including node and relationship types and their properties, to generate Cypher queries.
When a graph relation is not self-explanatory, we add its natural language description to the prompt. For instance, for the relation <span class="ltx_text ltx_font_italic" id="S3.SS1.p3.1.1">ppi</span>, we add <span class="ltx_text ltx_font_italic" id="S3.SS1.p3.1.2">"Temporary, non-covalent binding between protein molecules. Protein-protein interactions occur…"</span>.
During instruction prompting, we also identify questions that cannot be answered by the given graph schema. In such cases, the LLM returns the string SCHEMA_ERROR along with a brief explanation of why it could not generate an answer. FactFinder detects this marker using a regex and returns the explanation to the user.</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">We include an entity extraction model to align entity names in questions with those in the KG, based on Linnaeus <cite class="ltx_cite ltx_citemacro_cite">Gerner et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib12" title="">2010</a>)</cite> and developed set of vocabularies for entity types. This step ensures consistency by replacing detected entities with their preferred KG terms (e.g., <span class="ltx_text ltx_font_italic" id="S3.SS1.p4.1.1">alcohol</span> to <span class="ltx_text ltx_font_italic" id="S3.SS1.p4.1.2">ethanol</span>) and generating sentences linking each entity to its category (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S0.F1" title="Figure 1 ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_tag">1</span></a> left), reducing the LLM’s reliance on domain-specific knowledge.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Query Pre-Processors</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Before querying the graph with the generated Cypher query, we preprocess it to increase the system’s robustness. This leverages the structured natural language understanding provided by the translation of questions to Cypher queries. Various regular expression-based methods target specific query elements.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">Formatting.</span> First, we format the query to improve readability and consistency. This includes adding indentation, line breaks, and ensuring consistent naming conventions, which simplifies the application of regular expressions in subsequent steps.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1">Lowercasing Property Values.</span> We convert property values in the Cypher query to lowercase, matching the pre-lowered graph properties.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">Synonym Selection.</span> We map entities in the Cypher query to preferred terms used in the graph. If no mapping is available, we use external tools (e.g., <span class="ltx_text ltx_font_italic" id="S3.SS2.p4.1.2">skos:altLabel</span> queries against Wikidata) to find synonyms and match them to graph terms.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p5.1.1">Deprecated Code Handling.</span> We correct deprecated code generated by the LLM, such as replacing the obsolete SIZE() keyword with the current COUNT() keyword.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p6.1.1">Child to Parent Node Mapping.</span> In PrimeKG <cite class="ltx_cite ltx_citemacro_cite">Chandak et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib6" title="">2023</a>)</cite>, some node types are connected by parent-child relationships. We replace child nodes with their parent nodes in the Cypher query to ensure completeness.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Graph Question Answering and Verbalization</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">The pre-processed Cypher query is executed on the graph, returning a unique set of nodes that may include names, properties, IDs, and other elements.
Next, the question and graph results are incorporated into a prompt template and sent to an LLM. The prompt instructs the LLM to rely solely on the graph information to formulate an answer, which is then provided as the final natural language output.
We use the Neo4j graph database<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://neo4j.com/" title="">https://neo4j.com/</a></span></span></span> to provide the KG and build our pipeline borrowing components from Langchain<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.langchain.com/" title="">https://www.langchain.com/</a></span></span></span>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Explainability through Evidence</h3>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="249" id="S3.F2.g1" src="extracted/5776544/screenshot_graph.png" width="269"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Example of the evidence subgraph for <span class="ltx_text ltx_font_italic" id="S3.F2.2.1">Which drugs against epilepsy should not be used by patients with hypertension?</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">To ensure transparency and explainability, the system provides various forms of evidence alongside the natural language answer. These include intermediate results, such as Cypher generation prompts and graph results, as well as explicitly created information like the underlying subgraph for a query. These evidences are displayed in the frontend to track the system’s behavior.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS4.p2.1.1">Cypher Query Evidence.</span> The primary evidence is the Cypher query generated by the model, demonstrating how the given question maps to the graph structure. This enables expert users to evaluate the model’s understanding of the question and the quality of the generated query.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS4.p3.1.1">Graph Response.</span> The system also provides the actual response from the graph, consisting of the nodes and relationships returned by the executed query.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p4">
<p class="ltx_p" id="S3.SS4.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS4.p4.1.1">Subgraph Visualization.</span> To enhance interpretability, we provide a subgraph as part of the evidence. This subgraph visually displays (via Pyvis<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://pyvis.readthedocs.io/" title="">https://pyvis.readthedocs.io/</a></span></span></span>) the relevant nodes and edges, illustrating the subset of the main graph that contributed to the specific answer, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S3.F2" title="Figure 2 ‣ 3.4 Explainability through Evidence ‣ 3 System Description ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p5">
<p class="ltx_p" id="S3.SS4.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS4.p5.1.1">Sub-Graph Generator.</span> A notable challenge is that the original Cypher query usually returns only the nodes required to answer the question, omitting the edges that connect the question’s entity to the answer nodes. To address this, we generate a new Cypher query that fetches both the answer nodes and the connecting edges. This is achieved by submitting the original Cypher query to a LLM and instructing it to return all nodes and edges present in the query.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p6">
<p class="ltx_p" id="S3.SS4.p6.1">For example, if our original Cypher query is:</p>
</div>
<div class="ltx_para" id="S3.SS4.p7">
<p class="ltx_p" id="S3.SS4.p7.1"><span class="ltx_text ltx_font_typewriter" id="S3.SS4.p7.1.1"><span class="ltx_text ltx_inline-block" id="S3.SS4.p7.1.1.1" style="width:0.0pt;"></span><span class="ltx_text ltx_inline-block" id="S3.SS4.p7.1.1.2" style="width:469.8pt;"> <span class="ltx_text" id="S3.SS4.p7.1.1.2.1" style="color:#00FFFF;">MATCH</span> (g:gene_or_protein <span class="ltx_text" id="S3.SS4.p7.1.1.2.2" style="color:#00FFFF;">name</span>:<span class="ltx_text" id="S3.SS4.p7.1.1.2.3" style="color:#FF00FF;">"pink1"</span>)-</span></span><span class="ltx_text ltx_font_typewriter ltx_inline-block" id="S3.SS4.p7.1.2" style="width:469.8pt;"> [:associated_with]-&gt;(d:disease)</span><span class="ltx_text ltx_font_typewriter ltx_inline-block" id="S3.SS4.p7.1.3" style="width:469.8pt;"> <span class="ltx_text" id="S3.SS4.p7.1.3.1" style="color:#00FFFF;">RETURN</span> d.id <span class="ltx_text" id="S3.SS4.p7.1.3.2" style="color:#00FFFF;">AS</span> ID, d.<span class="ltx_text" id="S3.SS4.p7.1.3.3" style="color:#00FFFF;">name</span> <span class="ltx_text" id="S3.SS4.p7.1.3.4" style="color:#00FFFF;">AS</span> Name</span>our subgraph Cypher query is:</p>
</div>
<div class="ltx_para" id="S3.SS4.p8">
<p class="ltx_p" id="S3.SS4.p8.1"><span class="ltx_text ltx_font_typewriter" id="S3.SS4.p8.1.1"><span class="ltx_text ltx_inline-block" id="S3.SS4.p8.1.1.1" style="width:0.0pt;"></span><span class="ltx_text ltx_inline-block" id="S3.SS4.p8.1.1.2" style="width:469.8pt;"> <span class="ltx_text" id="S3.SS4.p8.1.1.2.1" style="color:#00FFFF;">MATCH</span> (g:gene_or_protein <span class="ltx_text" id="S3.SS4.p8.1.1.2.2" style="color:#00FFFF;">name</span>:<span class="ltx_text" id="S3.SS4.p8.1.1.2.3" style="color:#FF00FF;">"pink1"</span>)-</span></span><span class="ltx_text ltx_font_typewriter ltx_inline-block" id="S3.SS4.p8.1.2" style="width:469.8pt;"> [a:associated_with]-&gt;(d:disease)</span><span class="ltx_text ltx_font_typewriter ltx_inline-block" id="S3.SS4.p8.1.3" style="width:469.8pt;"> <span class="ltx_text" id="S3.SS4.p8.1.3.1" style="color:#00FFFF;">RETURN</span> g, d, a</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p9">
<p class="ltx_p" id="S3.SS4.p9.1">Note that this last subgraph Cypher query returns all relevant nodes and edges.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>User Interface and Example of Usage</h3>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="359" id="S3.F3.g1" src="extracted/5776544/screenshot_answers.png" width="269"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>User Interface with question and answers of the standalone LLM and our graph-based hybrid system.</figcaption>
</figure>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="221" id="S3.F4.g1" src="extracted/5776544/screenshot_drugs.png" width="269"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Answer for exploring drugs used to treat epilepsy.</figcaption>
</figure>
<figure class="ltx_figure" id="S3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="154" id="S3.F5.g1" src="extracted/5776544/screenshot_genes.png" width="269"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Answer for exploring genes targeted by amobarbital but not lamotrigine.</figcaption>
</figure>
<figure class="ltx_figure" id="S3.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="142" id="S3.F6.1.g1" src="extracted/5776544/screenshot_evidence.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>User Interface with the generated Cypher query and the graph response as evidence.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1">Our target audience includes researchers in the life sciences, such as those working in medical research and crop science, who are interested in exploring connections between drugs, genes, proteins, and other biological entities to discover new research directions.
To make our pipelines accessible, we developed a graphical user interface using Streamlit<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://streamlit.io/" title="">https://streamlit.io/</a></span></span></span>. This interface allows users to input questions and view generated answers. Users can select different pipelines, such as LLM-only or those incorporating KGs or documents.
For instance, a medical researcher might ask, <span class="ltx_text ltx_font_italic" id="S3.SS5.p1.1.1">Which drugs against epilepsy should not be used by patients with hypertension?</span> (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S3.F3" title="Figure 3 ‣ 3.5 User Interface and Example of Usage ‣ 3 System Description ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_tag">3</span></a>). To delve deeper, they could follow up with <span class="ltx_text ltx_font_italic" id="S3.SS5.p1.1.2">Which drugs are used to treat epilepsy?</span> (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S3.F4" title="Figure 4 ‣ 3.5 User Interface and Example of Usage ‣ 3 System Description ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_tag">4</span></a>).
Going further, with the question <span class="ltx_text ltx_font_italic" id="S3.SS5.p1.1.3">Which genes are targeted by amobarbital but not lamotrigine?</span>, they could take a first step towards understanding the genetic interactions that differentiate drug effects, resulting in the identification of four genes exclusively targeted by amobarbital (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S3.F5" title="Figure 5 ‣ 3.5 User Interface and Example of Usage ‣ 3 System Description ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_tag">5</span></a>).
Additionally, users can interactively visualize the relevant subgraph, generated Cypher query, and graph response, enabling them to verify response accuracy and understand the underlying data (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S3.F6" title="Figure 6 ‣ 3.5 User Interface and Example of Usage ‣ 3 System Description ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_tag">6</span></a>). These features (see <a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S3.SS4" title="3.4 Explainability through Evidence ‣ 3 System Description ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3.4</span></a>) enhance transparency and foster trust in the system.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluation</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Graph Retrieval Evaluation</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">To quantify the graph retrieval step, we assess the returned nodes from graph queries by comparing result nodes from executing the ground truth queries with those from the generated queries. This enables a quantitative evaluation of the text-to-Cypher step. We use the ground truth text-to-Cypher dataset described in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S2" title="2 Data ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_tag">2</span></a> for this evaluation. We compute intersection over union (IoU), precision, and recall for the expected and generated graph result sets, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S4.T1" title="Table 1 ‣ 4.1 Graph Retrieval Evaluation ‣ 4 Evaluation ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">The results indicate strong performance, with the best model exceeding 75%. GPT-4o outperforms GPT-4-Turbo overall. Entity Enhancement (EE, Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S0.F1" title="Figure 1 ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_tag">1</span></a> left and Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S3.SS1" title="3.1 Cypher Query Generation ‣ 3 System Description ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_tag">3.1</span></a>) improves GPT-4-Turbo’s performance but slightly decreases GPT-4o’s effectiveness. Manual analysis revealed that PrimeKG’s merging of genes and proteins into a single node can mislead GPT-4o when EE is applied, directing it towards incorrect relations. GPT-4o’s internal knowledge allows it to infer relationships more accurately without EE, while GPT-4-Turbo benefits from the additional clarity provided by EE.
This suggests that LLM’s internal knowledge can be beneficial for Cypher query generation.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.2.1">EE</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.3.1">IoU</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.4.1">Precision</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.5.1">Recall</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.1.2.1.1">gpt-4-turbo</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T1.1.2.1.2">True</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.1.2.1.3">71.3</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.1.2.1.4">73.6</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T1.1.2.1.5">71.6</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.3.2.1">gpt-4-turbo</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T1.1.3.2.2">False</th>
<td class="ltx_td ltx_align_right" id="S4.T1.1.3.2.3">62.7</td>
<td class="ltx_td ltx_align_right" id="S4.T1.1.3.2.4">65.3</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T1.1.3.2.5">64.9</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.4.3.1">gpt-4o</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T1.1.4.3.2">True</th>
<td class="ltx_td ltx_align_right" id="S4.T1.1.4.3.3">74.9</td>
<td class="ltx_td ltx_align_right" id="S4.T1.1.4.3.4">77.0</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T1.1.4.3.5">77.6</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T1.1.5.4.1">gpt-4o</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S4.T1.1.5.4.2">False</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.1.5.4.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.5.4.3.1">75.2</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.1.5.4.4"><span class="ltx_text ltx_font_bold" id="S4.T1.1.5.4.4.1">77.5</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb" id="S4.T1.1.5.4.5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.5.4.5.1">77.8</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Results for the graph retrieval evaluation (metrics in %). IoU stands for intersection over union and EE for Entity Enhancement, see <a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S4.SS1" title="4.1 Graph Retrieval Evaluation ‣ 4 Evaluation ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.1</span></a>.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Evaluating Correctness and Completeness</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">To assess the quality of LLM-generated answers, we conduct two evaluations using the LLM-as-a-Judge approach <cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#bib.bib31" title="">2024</a>)</cite>: (1) comparing the answers from our KG-LLM-based system to those from an LLM-only system, and (2) evaluating the reliability of LLM verbalization of information provided by the KG. In both cases, correctness is defined as the inclusion of only facts from the graph nodes, and completeness as the inclusion of all such facts.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">Hybrid system vs. LLM-only.</span>
We compare the hybrid KG-based system against a standalone LLM. The hybrid system (GPT-4o without entity enhancement, Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S4.SS1" title="4.1 Graph Retrieval Evaluation ‣ 4 Evaluation ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_tag">4.1</span></a>) is evaluated to produce more correct (complete) answers in 94.12% (96.08%) of cases, demonstrating its superior performance in providing accurate and complete responses.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.1">LLM verbalization.</span>
We evaluate the verbalization of natural language answers from graph results. In this evaluation, 89.13% of answers are deemed correct, and 80.43% complete, indicating high accuracy in verbalization.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Handling Incorrect Graph Responses</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Finally, we evaluate FactFinder’s ability to handle incorrect or incomplete information in graph responses. The system should be able to refuse to answer if the Cypher query generation step produces a wrong query, thus retrieving the correct data from the KG. We test this by disabling Cypher query generation and supplying incorrect Cypher queries for each question, resulting in incorrect graph results.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.1">(in %)</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.2.1">gpt-4o</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.3.1">gpt-4-turbo</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.2.1.1">Answer Denied</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.1.2.1.2">65/69 (94.2)</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T2.1.2.1.3">63/69 (91.3)</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.3.2.1">Uncertain Answer</th>
<td class="ltx_td ltx_align_right" id="S4.T2.1.3.2.2">1/69 (1.5)</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T2.1.3.2.3">1/69 (1.5)</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T2.1.4.3.1">Full Answer</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.1.4.3.2">3/69 (4.3)</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb" id="S4.T2.1.4.3.3">5/69 (7.3)</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Handling irrelevant information in graph responses.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">The results in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.03010v1#S4.T2" title="Table 2 ‣ 4.3 Handling Incorrect Graph Responses ‣ 4 Evaluation ‣ Fact Finder - Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs"><span class="ltx_text ltx_ref_tag">2</span></a> show that both GPT-4-turbo and GPT-4-o can detect irrelevant information and correctly respond with "I don’t know" in over 90% of cases, demonstrating that the LLMs can reason and understand when the knowledge passed to them is not relevant. This highlights FactFinder’s ability to enhance reliability by leveraging both structured and world knowledge.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">Manual analysis revealed that in one case, the LLM expressed uncertainty with the phrase "The provided information does not mention …" indicating potential inaccuracies. In a few cases, the models provided full answers despite unrelated KG results, especially for count, boolean, and lengthy responses, highlighting detection challenges in these scenarios.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">This work demonstrates the value of integrating structured, factual knowledge into a user-friendly chat system, providing researchers with a reliable tool for answering scientific questions while minimizing hallucinations. We show that LLMs can generate valid Cypher queries to retrieve relevant data from a KG, informing accurate answers. The creation of such a robust system is crucial for enhancing research capabilities. Future work will focus on expanding the evaluation dataset, quantifying system uncertainty, and enabling access to multiple KGs, possibly through agent-based retrieval.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Badenes-Olmedo and Corcho (2023)</span>
<span class="ltx_bibblock">
Carlos Badenes-Olmedo and Oscar Corcho. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1016/j.jbi.2023.104382" title="">Lessons learned to enable question answering on knowledge graphs extracted from scientific publications: A case study on the coronavirus literature</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Journal of Biomedical Informatics</em>, 142:104382.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baek et al. (2023)</span>
<span class="ltx_bibblock">
Jinheon Baek, Alham Fikri Aji, and Amir Saffari. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.nlrse-1.7" title="">Knowledge-augmented language model prompting for zero-shot knowledge graph question answering</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 1st Workshop on Natural Language Reasoning and Structured Explanations (NLRSE)</em>, pages 78–106, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bašaragin et al. (2024)</span>
<span class="ltx_bibblock">
Bojana Bašaragin, Adela Ljajić, Darija Medvecki, Lorenzo Cassano, Miloš Košprdić, and Nikola Milošević. 2024.

</span>
<span class="ltx_bibblock">How do you know that? teaching generative language models to reference answers to biomedical questions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">BioNLP Workshop 2024</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bubeck et al. (2023)</span>
<span class="ltx_bibblock">
Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. 2023.

</span>
<span class="ltx_bibblock">Sparks of artificial general intelligence: Early experiments with gpt-4.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2303.12712</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chakraborty et al. (2021)</span>
<span class="ltx_bibblock">
Nilesh Chakraborty, Denis Lukovnikov, Gaurav Maheshwari, Priyansh Trivedi, Jens Lehmann, and Asja Fischer. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1002/widm.1389" title="">Introduction to neural network-based question answering over knowledge graphs</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">WIREs Data Mining and Knowledge Discovery</em>, 11(3):e1389.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chandak et al. (2023)</span>
<span class="ltx_bibblock">
Payal Chandak, Kexin Huang, and Marinka Zitnik. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1038/s41597-023-01960-3" title="">Building a knowledge graph to enable precision medicine</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Scientific Data</em>, 10(1):67.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang and Fosler-Lussier (2023)</span>
<span class="ltx_bibblock">
Shuaichen Chang and Eric Fosler-Lussier. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2305.11853" title="">How to prompt llms for text-to-sql: A study in zero-shot, single-domain, and cross-domain settings</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Preprint</em>, arXiv:2305.11853.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Edge et al. (2024)</span>
<span class="ltx_bibblock">
Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, and Jonathan Larson. 2024.

</span>
<span class="ltx_bibblock">From local to global: A graph rag approach to query-focused summarization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2404.16130</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al. (2023)</span>
<span class="ltx_bibblock">
Guandong Feng, Guoliang Zhu, Shengze Shi, Yue Sun, Zhongyi Fan, Sulin Gao, and Jun Hu. 2023.

</span>
<span class="ltx_bibblock">Robust nl-to-cypher translation for kbqa: Harnessing large language model with chain of prompts.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence</em>, pages 317–326, Singapore. Springer Nature Singapore.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al. (2024)</span>
<span class="ltx_bibblock">
Yichun Feng, Lu Zhou, Yikai Zheng, Ruikun He, Chao Ma, and Yixue Li. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1101/2024.04.17.589873" title="">Knowledge graph-based thought: a knowledge graph enhanced llms framework for pan-cancer question answering</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">bioRxiv</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2023)</span>
<span class="ltx_bibblock">
Dawei Gao, Haibin Wang, Yaliang Li, Xiuyu Sun, Yichen Qian, Bolin Ding, and Jingren Zhou. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2308.15363" title="">Text-to-sql empowered by large language models: A benchmark evaluation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Preprint</em>, arXiv:2308.15363.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gerner et al. (2010)</span>
<span class="ltx_bibblock">
Martin Gerner, G. Nenadic, and Casey M. Bergman. 2010.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:10197117" title="">Linnaeus: A species name identification system for biomedical literature</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">BMC Bioinformatics</em>, 11:85 – 85.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. (2022)</span>
<span class="ltx_bibblock">
Aibo Guo, Xinyi Li, Guanchen Xiao, Zhen Tan, and Xiang Zhao. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3511808.3557703" title="">Spcql: A semantic parsing dataset for converting natural language into cypher</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management</em>, CIKM ’22, page 3973–3977, New York, NY, USA. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et al. (2023)</span>
<span class="ltx_bibblock">
Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3571730" title="">Survey of hallucination in natural language generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">ACM Comput. Surv.</em>, 55(12).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023a)</span>
<span class="ltx_bibblock">
Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. 2023a.

</span>
<span class="ltx_bibblock">Mistral 7b.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2310.06825</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023b)</span>
<span class="ltx_bibblock">
Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Xin Zhao, and Ji-Rong Wen. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.574" title="">StructGPT: A general framework for large language model to reason over structured data</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 9237–9251, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Katz et al. (2023)</span>
<span class="ltx_bibblock">
Daniel Martin Katz, Michael James Bommarito, Shang Gao, and Pablo Arredondo. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 passes the bar exam.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Available at SSRN 4389233</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ljajić et al. (2024)</span>
<span class="ltx_bibblock">
Adela Ljajić, Miloš Košprdić, Bojana Bašaragin, Darija Medvecki, Lorenzo Cassano, and Nikola Milošević. 2024.

</span>
<span class="ltx_bibblock">Scientific qa system with verifiable answers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">The 6th International Open Search Symposium</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Malaviya et al. (2023)</span>
<span class="ltx_bibblock">
Chaitanya Malaviya, Subin Lee, Sihao Chen, Elizabeth Sieber, Mark Yatskar, and Dan Roth. 2023.

</span>
<span class="ltx_bibblock">Expertqa: Expert-curated questions and attributed answers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2309.07852</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Milošević and Thielemann (2023)</span>
<span class="ltx_bibblock">
Nikola Milošević and Wolfgang Thielemann. 2023.

</span>
<span class="ltx_bibblock">Comparison of biomedical relationship extraction methods and models for knowledge graph creation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Journal of Web Semantics</em>, 75:100756.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nori et al. (2023)</span>
<span class="ltx_bibblock">
Harsha Nori, Nicholas King, Scott Mayer McKinney, Dean Carignan, and Eric Horvitz. 2023.

</span>
<span class="ltx_bibblock">Capabilities of gpt-4 on medical challenge problems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2303.13375</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2303.08774" title="">Gpt-4 technical report</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Preprint</em>, arXiv:2303.08774.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan et al. (2024)</span>
<span class="ltx_bibblock">
Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. 2024.

</span>
<span class="ltx_bibblock">Unifying large language models and knowledge graphs: A roadmap.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">IEEE Transactions on Knowledge and Data Engineering</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et al. (2023)</span>
<span class="ltx_bibblock">
Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein. 2023.

</span>
<span class="ltx_bibblock">Generative agents: Interactive simulacra of human behavior.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology</em>, pages 1–22.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pourreza and Rafiei (2023)</span>
<span class="ltx_bibblock">
Mohammadreza Pourreza and Davood Rafiei. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=p53QDxSIc5" title="">DIN-SQL: Decomposed in-context learning of text-to-SQL with self-correction</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Thirty-seventh Conference on Neural Information Processing Systems</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sen et al. (2023)</span>
<span class="ltx_bibblock">
Priyanka Sen, Sandeep Mavadia, and Amir Saffari. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.nlrse-1.1" title="">Knowledge graph-augmented language models for complex question answering</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of the 1st Workshop on Natural Language Reasoning and Structured Explanations (NLRSE)</em>, pages 1–8, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Srivastava et al. (2021)</span>
<span class="ltx_bibblock">
Saurabh Srivastava, Mayur Patidar, Sudip Chowdhury, Puneet Agarwal, Indrajit Bhattacharya, and Gautam Shroff. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.eacl-main.300" title="">Complex question answering on knowledge graphs using machine translation and multi-task learning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</em>, pages 3428–3439, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2307.09288</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Waisberg et al. (2023)</span>
<span class="ltx_bibblock">
Ethan Waisberg, Joshua Ong, Mouayad Masalkhi, Sharif Amit Kamran, Nasif Zaman, Prithul Sarker, Andrew G Lee, and Alireza Tavakkoli. 2023.

</span>
<span class="ltx_bibblock">Gpt-4: a new era of artificial intelligence in medicine.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Irish Journal of Medical Science (1971-)</em>, 192(6):3197–3200.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2024)</span>
<span class="ltx_bibblock">
Ziyu Zhao, Wei Liu, Tim French, and Michael Stewart. 2024.

</span>
<span class="ltx_bibblock">Cyspider: A neural semantic parsing corpus with baseline models for property graphs.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">AI 2023: Advances in Artificial Intelligence</em>, pages 120–132, Singapore. Springer Nature Singapore.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. (2024)</span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2024.

</span>
<span class="ltx_bibblock">Judging llm-as-a-judge with mt-bench and chatbot arena.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ziletti and D’Ambrosi (2024)</span>
<span class="ltx_bibblock">
Angelo Ziletti and Leonardo D’Ambrosi. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2403.09226" title="">Retrieval augmented text-to-sql generation for epidemiological question answering using electronic health records</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Preprint</em>, arXiv:2403.09226.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>
<figure class="ltx_figure" id="A1.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="851" id="A1.F7.1.g1" src="extracted/5776544/screenshot_demo.png" width="550"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>User interface of Fact Finder for the question <span class="ltx_text ltx_font_italic" id="A1.F7.3.1">Which drugs are used to treat ocular hypertension?</span>. The answers of the standalone LLM and our graph-based hybrid system are compared as output. In addition, the relevant subgraph is displayed as evidence together with the generated Cypher query and the answer from the graph.</figcaption>
</figure>
<figure class="ltx_figure" id="A1.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="808" id="A1.F8.1.g1" src="extracted/5776544/screenshot_demo_2.png" width="586"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>User interface of Fact Finder for the question <span class="ltx_text ltx_font_italic" id="A1.F8.3.1">Which drugs against epilepsy should not be used by patients with hypertension?</span>.</figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Aug  6 07:40:27 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
