<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Negative Feedback for Music Personalization</title>
<!--Generated on Thu Jun  6 20:16:42 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="music recommendation,  negative feedback,  recommender systems,  transformers" lang="en" name="keywords"/>
<base href="/html/2406.04488v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S1" title="In Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S2" title="In Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S3" title="In Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Model Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S4" title="In Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5" title="In Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results and Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.SS1" title="In 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Ablation study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.SS2" title="In 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Hard negative samples</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.SS2.SSS1" title="In 5.2. Hard negative samples â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.1 </span>Test accuracy</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.SS2.SSS2" title="In 5.2. Hard negative samples â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.2 </span>Training time</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.SS2.SSS3" title="In 5.2. Hard negative samples â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.3 </span>Relation to other metrics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.SS3" title="In 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Feedback types</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S6" title="In Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Negative Feedback for Music Personalization</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">M. Jeffrey Mei
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:jeffrey.mei@siriusxm.com">jeffrey.mei@siriusxm.com</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-1083-598X" title="ORCID identifier">0000-0002-1083-598X</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id3.1.id1">SiriusXM Radio Inc.</span><span class="ltx_text ltx_affiliation_streetaddress" id="id4.2.id2">1221 Avenue of the Americas</span><span class="ltx_text ltx_affiliation_city" id="id5.3.id3">New York</span><span class="ltx_text ltx_affiliation_state" id="id6.4.id4">New York</span><span class="ltx_text ltx_affiliation_country" id="id7.5.id5">USA</span><span class="ltx_text ltx_affiliation_postcode" id="id8.6.id6">10020</span>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Oliver Bembom
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:oliver.bembom@siriusxm.com">oliver.bembom@siriusxm.com</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0002-2617-5776" title="ORCID identifier">0009-0002-2617-5776</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id9.1.id1">SiriusXM Radio Inc.</span><span class="ltx_text ltx_affiliation_streetaddress" id="id10.2.id2">1221 Avenue of the Americas</span><span class="ltx_text ltx_affiliation_city" id="id11.3.id3">New York</span><span class="ltx_text ltx_affiliation_state" id="id12.4.id4">New York</span><span class="ltx_text ltx_affiliation_country" id="id13.5.id5">USA</span><span class="ltx_text ltx_affiliation_postcode" id="id14.6.id6">10020</span>
</span></span></span>
<span class="ltx_author_before">Â andÂ </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Andreas F. Ehmann
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:andreas.ehmann@siriusxm.com">andreas.ehmann@siriusxm.com</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0003-9589-0666" title="ORCID identifier">0009-0003-9589-0666</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id15.1.id1">SiriusXM Radio Inc.</span><span class="ltx_text ltx_affiliation_streetaddress" id="id16.2.id2">1221 Avenue of the Americas</span><span class="ltx_text ltx_affiliation_city" id="id17.3.id3">New York</span><span class="ltx_text ltx_affiliation_state" id="id18.4.id4">New York</span><span class="ltx_text ltx_affiliation_country" id="id19.5.id5">USA</span><span class="ltx_text ltx_affiliation_postcode" id="id20.6.id6">10020</span>
</span></span></span>
</div>
<div class="ltx_dates">(2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id2.2">Next-item recommender systems are often trained using only positive feedback with randomly-sampled negative feedback.
We show the benefits of using real negative feedback both as inputs into the user sequence and also as negative targets for training a next-song recommender system for internet radio.
In particular, using explicit negative samples during training helps reduce training time by <math alttext="\sim" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mo id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><csymbol cd="latexml" id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">âˆ¼</annotation></semantics></math>60% while also improving test accuracy by <math alttext="6\%" class="ltx_Math" display="inline" id="id2.2.m2.1"><semantics id="id2.2.m2.1a"><mrow id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml"><mn id="id2.2.m2.1.1.2" xref="id2.2.m2.1.1.2.cmml">6</mn><mo id="id2.2.m2.1.1.1" xref="id2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><apply id="id2.2.m2.1.1.cmml" xref="id2.2.m2.1.1"><csymbol cd="latexml" id="id2.2.m2.1.1.1.cmml" xref="id2.2.m2.1.1.1">percent</csymbol><cn id="id2.2.m2.1.1.2.cmml" type="integer" xref="id2.2.m2.1.1.2">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">6\%</annotation><annotation encoding="application/x-llamapun" id="id2.2.m2.1d">6 %</annotation></semantics></math>; adding user skips as additional inputs also can considerably increase user coverage alongside improving accuracy.
We test the impact of using a large number of random negative samples to capture a â€˜harderâ€™ one and find that the test accuracy increases with more randomly-sampled negatives, but only to a point. Too many random negatives leads to false negatives that limits the lift, which is still lower than if using true negative feedback.
We also find that the test accuracy is fairly robust with respect to the proportion of different feedback types, and compare the learned embeddings for different feedback types.</p>
</div>
<div class="ltx_keywords">music recommendation, negative feedback, recommender systems, transformers
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id1"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id2"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id3"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">conference: </span>Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization; July 1â€“4, 2024; Cagliari, Italy</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_booktitle" id="id4"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">booktitle: </span>Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization (UMAP â€™24), July 1â€“4, 2024, Cagliari, Italy</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id5"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">doi: </span>10.1145/3627043.3659553</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id6"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">isbn: </span>979-8-4007-0433-8/24/07</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id7"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Computing methodologiesÂ Learning from implicit feedback</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id8"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Information systemsÂ Personalization</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id9"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Information systemsÂ Recommender systems</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id10"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Computing methodologiesÂ Learning latent representations</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The rise of online streaming for music has led to millions, if not tens of millions, of distinct tracks being immediately accessible to users.
However, users may only want to hear a small fraction of these tracks, so online music streaming services may rely on recommender systems to filter their catalogs for songs that are relevant to the user.
Using each userâ€™s feedback to further personalize their song recommendations is crucial to increasing their engagement.
</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">This song recommendation can take the form of generating a static playlist, or a dynamic online radio station. In both cases, these song recommendations are provided in some sequence, but there are some salient differences between these sequences and other domains (e.g. e-commerce or natural language processing).
Firstly, the sequential structure is much fuzzier - songs can be randomly swapped between positions to some extent (sometimes formalized in the user interface as â€˜shuffle modeâ€™), which weakens the positional effects.
Secondly, certain feedback types are generally not repeatable, as a song that is explicitly liked (e.g. a â€˜thumb-upâ€™) cannot be re-liked without first being un-liked, and a song that is explicitly disliked (e.g. a â€˜thumb-downâ€™) is generally not played again and cannot receive further feedback.
This is not the case with all feedback types (e.g. songs can be skipped repeatedly, independently of prior feedback).</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.7">For sequential modeling, most current research has coalesced around SASRec <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib6" title="">2018</a>)</cite> or BERT4Rec <cite class="ltx_cite ltx_citemacro_citep">(Sun etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib15" title="">2019</a>)</cite>. Both methods use the Transformer architecture <cite class="ltx_cite ltx_citemacro_citep">(Vaswani etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib16" title="">2017</a>)</cite>.
SASRec trains using a causal filter where each <math alttext="i" class="ltx_Math" display="inline" id="S1.p3.1.m1.1"><semantics id="S1.p3.1.m1.1a"><mi id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><ci id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="S1.p3.1.m1.1d">italic_i</annotation></semantics></math>-th item in a sequence of <math alttext="N" class="ltx_Math" display="inline" id="S1.p3.2.m2.1"><semantics id="S1.p3.2.m2.1a"><mi id="S1.p3.2.m2.1.1" xref="S1.p3.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S1.p3.2.m2.1b"><ci id="S1.p3.2.m2.1.1.cmml" xref="S1.p3.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S1.p3.2.m2.1d">italic_N</annotation></semantics></math> total items is predicted using the preceding <math alttext="i-1" class="ltx_Math" display="inline" id="S1.p3.3.m3.1"><semantics id="S1.p3.3.m3.1a"><mrow id="S1.p3.3.m3.1.1" xref="S1.p3.3.m3.1.1.cmml"><mi id="S1.p3.3.m3.1.1.2" xref="S1.p3.3.m3.1.1.2.cmml">i</mi><mo id="S1.p3.3.m3.1.1.1" xref="S1.p3.3.m3.1.1.1.cmml">âˆ’</mo><mn id="S1.p3.3.m3.1.1.3" xref="S1.p3.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.p3.3.m3.1b"><apply id="S1.p3.3.m3.1.1.cmml" xref="S1.p3.3.m3.1.1"><minus id="S1.p3.3.m3.1.1.1.cmml" xref="S1.p3.3.m3.1.1.1"></minus><ci id="S1.p3.3.m3.1.1.2.cmml" xref="S1.p3.3.m3.1.1.2">ğ‘–</ci><cn id="S1.p3.3.m3.1.1.3.cmml" type="integer" xref="S1.p3.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.3.m3.1c">i-1</annotation><annotation encoding="application/x-llamapun" id="S1.p3.3.m3.1d">italic_i - 1</annotation></semantics></math> items, whereas BERT4Rec treats each training row as a cloze completion task for some <math alttext="k" class="ltx_Math" display="inline" id="S1.p3.4.m4.1"><semantics id="S1.p3.4.m4.1a"><mi id="S1.p3.4.m4.1.1" xref="S1.p3.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.p3.4.m4.1b"><ci id="S1.p3.4.m4.1.1.cmml" xref="S1.p3.4.m4.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S1.p3.4.m4.1d">italic_k</annotation></semantics></math> positions, using the other <math alttext="N-k" class="ltx_Math" display="inline" id="S1.p3.5.m5.1"><semantics id="S1.p3.5.m5.1a"><mrow id="S1.p3.5.m5.1.1" xref="S1.p3.5.m5.1.1.cmml"><mi id="S1.p3.5.m5.1.1.2" xref="S1.p3.5.m5.1.1.2.cmml">N</mi><mo id="S1.p3.5.m5.1.1.1" xref="S1.p3.5.m5.1.1.1.cmml">âˆ’</mo><mi id="S1.p3.5.m5.1.1.3" xref="S1.p3.5.m5.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S1.p3.5.m5.1b"><apply id="S1.p3.5.m5.1.1.cmml" xref="S1.p3.5.m5.1.1"><minus id="S1.p3.5.m5.1.1.1.cmml" xref="S1.p3.5.m5.1.1.1"></minus><ci id="S1.p3.5.m5.1.1.2.cmml" xref="S1.p3.5.m5.1.1.2">ğ‘</ci><ci id="S1.p3.5.m5.1.1.3.cmml" xref="S1.p3.5.m5.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.5.m5.1c">N-k</annotation><annotation encoding="application/x-llamapun" id="S1.p3.5.m5.1d">italic_N - italic_k</annotation></semantics></math> items as inputs.
SASRec uses a binary cross-entropy loss with a random item as the negative sample, which may lead to overconfidence in the output scores as a random negative is generally very easy to distinguish from the target item <cite class="ltx_cite ltx_citemacro_citep">(Petrov and Macdonald, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib11" title="">2023</a>)</cite>.
BERT4Rec avoids this issue by calculating the softmax with the entire population as negatives, which comes at the cost of increased training complexity that may not be viable for industrial datasets that have millions of items in their catalog.
There are ways around this, such as using sampled softmax as an estimate of the total loss <cite class="ltx_cite ltx_citemacro_citep">(Bengio and Senecal, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib2" title="">2008</a>; Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib23" title="">2023</a>)</cite>; custom loss functions that weight the random negatives differently <cite class="ltx_cite ltx_citemacro_citep">(Petrov and Macdonald, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib11" title="">2023</a>)</cite>; or trying to generate pseudo-negative samples, for example by choosing the top-<math alttext="k" class="ltx_Math" display="inline" id="S1.p3.6.m6.1"><semantics id="S1.p3.6.m6.1a"><mi id="S1.p3.6.m6.1.1" xref="S1.p3.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.p3.6.m6.1b"><ci id="S1.p3.6.m6.1.1.cmml" xref="S1.p3.6.m6.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.6.m6.1c">k</annotation><annotation encoding="application/x-llamapun" id="S1.p3.6.m6.1d">italic_k</annotation></semantics></math> negative samples as the hardest <math alttext="k" class="ltx_Math" display="inline" id="S1.p3.7.m7.1"><semantics id="S1.p3.7.m7.1a"><mi id="S1.p3.7.m7.1.1" xref="S1.p3.7.m7.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.p3.7.m7.1b"><ci id="S1.p3.7.m7.1.1.cmml" xref="S1.p3.7.m7.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.7.m7.1c">k</annotation><annotation encoding="application/x-llamapun" id="S1.p3.7.m7.1d">italic_k</annotation></semantics></math> negatives for weight updates <cite class="ltx_cite ltx_citemacro_citep">(Wilm etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib22" title="">2023</a>)</cite> or more complex scoring methods to identify these harder negatives (e.g.<cite class="ltx_cite ltx_citemacro_citep">(Weston etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib21" title="">2011</a>; Zhao etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib24" title="">2023</a>)</cite>).</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Choosing a representative negative sample is thus a critical component of improving the training process for collaborative recommender systems.
Often negative feedback is simply not collected; for example, in e-commerce it is easy to see what a user has clicked on and ordered, but it is not known if other items shown to the user were not clicked on because the user did not like them.
However, if explicit negative feedback is collected, this data source can be a valuable source of negative sampling for training. For music recommendations, this negative feedback may be collected <span class="ltx_text ltx_font_bold" id="S1.p4.1.1">explicitly</span> via a thumb-down button, or more <span class="ltx_text ltx_font_bold" id="S1.p4.1.2">implicitly</span> like a skipped song, though skips may not always be a negative signal <cite class="ltx_cite ltx_citemacro_citep">(Meggetto etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib8" title="">2023</a>)</cite>.
Songs may receive both positive and negative feedback, such as if a userâ€™s taste changes or if a liked song is overplayed; hence, it is also important to treat the inputs as a sequence, with the caveat of certain feedback types being less sequential.
These negative samples can be directly used in the training loss <cite class="ltx_cite ltx_citemacro_citep">(Stoikov and Wen, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib14" title="">2021</a>; Wen etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib20" title="">2019</a>)</cite>, or possibly as a complementary training task, whereby a model tries to minimize negative feedback instead of (or in addition to) maximizing positive feedback <cite class="ltx_cite ltx_citemacro_citep">(Seshadri and Knees, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib13" title="">2023</a>; Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib19" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">An issue with collaborative methods is the cold-start problem, both from an item perspective and a user perspective. Some items which are either new or unpopular do not have enough feedback to have a well-converged embedding; similarly, new or low-activity users do not have enough (or any) feedback to receive good recommendations via collaborative models.
The former can be mitigated with additional data, such as partially sharing embeddings with similar items (e.g. songs by the same artist or items in the same e-commerce category) <cite class="ltx_cite ltx_citemacro_citep">(Mei etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib9" title="">2023</a>; Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib17" title="">2018</a>)</cite> or by using content-based embeddings <cite class="ltx_cite ltx_citemacro_citep">(Wang and Wang, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib18" title="">2014</a>)</cite>.
The latter is harder to overcome, but may be partially sidestepped by considering other data sources that may be more numerous, such as song skips or other contextual features like time/location <cite class="ltx_cite ltx_citemacro_citep">(Dias and Fonseca, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib4" title="">2013</a>; Schedl and Schnitzer, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib12" title="">2014</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">Internet radio stations have some salient differences to other domains for next-item recommendation.
Usersâ€™ song preferences are highly contextual on the station: a user may like both jazz and rock songs, but not in the same session.
Stations may therefore have some filtered set of eligible songs, which can be further ranked to personalize the station for the user.
This also extends to user feedback: users may thumb up a song on one station and thumb down the same song on a different station.
Because of this filtering, this means that songs on the same station are generally stylistically similar, and so it is harder to predict which songs from a given station a user may not like, as compared to other random songs that may be an entirely different genre or style.
The balance between maximizing songs that a user may like (true positives) versus minimizing songs that a user may dislike (false positives) is not well understood, and may be differ by user, or even differ for the same user in different contexts. These objectives may disagree with each other, such as in deciding whether to suggest more popular songs <cite class="ltx_cite ltx_citemacro_citep">(Mena-Maldonado etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib10" title="">2020</a>)</cite>.
Nevertheless, the cost of bad recommendations may degrade the user experience (e.g. causing them to switch to a different provider).</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.3">In this paper, we explore the benefits of incorporating additional feedback to a baseline transformer-based recommender system, both as inputs and as a source of negative samples. For brevity, we may refer to positive feedback (whether explicit or implicit) as â€˜upâ€™ (â€˜<math alttext="+" class="ltx_Math" display="inline" id="S1.p7.1.m1.1"><semantics id="S1.p7.1.m1.1a"><mo id="S1.p7.1.m1.1.1" xref="S1.p7.1.m1.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="S1.p7.1.m1.1b"><plus id="S1.p7.1.m1.1.1.cmml" xref="S1.p7.1.m1.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="S1.p7.1.m1.1c">+</annotation><annotation encoding="application/x-llamapun" id="S1.p7.1.m1.1d">+</annotation></semantics></math>â€™) signals and explicit negative feedback as â€˜downâ€™ (â€˜<math alttext="-" class="ltx_Math" display="inline" id="S1.p7.2.m2.1"><semantics id="S1.p7.2.m2.1a"><mo id="S1.p7.2.m2.1.1" xref="S1.p7.2.m2.1.1.cmml">âˆ’</mo><annotation-xml encoding="MathML-Content" id="S1.p7.2.m2.1b"><minus id="S1.p7.2.m2.1.1.cmml" xref="S1.p7.2.m2.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S1.p7.2.m2.1c">-</annotation><annotation encoding="application/x-llamapun" id="S1.p7.2.m2.1d">-</annotation></semantics></math>â€™) signals, in addition to implicit â€˜skipâ€™ (â€˜<math alttext="/" class="ltx_Math" display="inline" id="S1.p7.3.m3.1"><semantics id="S1.p7.3.m3.1a"><mo id="S1.p7.3.m3.1.1" xref="S1.p7.3.m3.1.1.cmml">/</mo><annotation-xml encoding="MathML-Content" id="S1.p7.3.m3.1b"><divide id="S1.p7.3.m3.1.1.cmml" xref="S1.p7.3.m3.1.1"></divide></annotation-xml><annotation encoding="application/x-tex" id="S1.p7.3.m3.1c">/</annotation><annotation encoding="application/x-llamapun" id="S1.p7.3.m3.1d">/</annotation></semantics></math>â€™) signals.
The contributions of this paper are as follows:
</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We use explicit user-given hard negatives as negative samples to improve the test accuracy, and show that a hard negative can only be partially approximated by using the hardest negative from <math alttext="k" class="ltx_Math" display="inline" id="S1.I1.i1.p1.1.m1.1"><semantics id="S1.I1.i1.p1.1.m1.1a"><mi id="S1.I1.i1.p1.1.m1.1.1" xref="S1.I1.i1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.I1.i1.p1.1.m1.1b"><ci id="S1.I1.i1.p1.1.m1.1.1.cmml" xref="S1.I1.i1.p1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S1.I1.i1.p1.1.m1.1d">italic_k</annotation></semantics></math> randomly-sampled negatives</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We show that using additional inputs (e.g. skips) improves personalization coverage while also improving accuracy, and explore the dependency of the prediction accuracy on the proportion of skips in a userâ€™s feedback</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We show the relationship between our test accuracy metric and metrics using true and false positives, and how these depend on the proportion of hard negatives used in training
</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Data</h2>
<figure class="ltx_table ltx_align_floatright" id="S2.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Summary statistics for the processed training sets. â€˜<math alttext="+" class="ltx_Math" display="inline" id="S2.T1.4.m1.1"><semantics id="S2.T1.4.m1.1b"><mo id="S2.T1.4.m1.1.1" xref="S2.T1.4.m1.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="S2.T1.4.m1.1c"><plus id="S2.T1.4.m1.1.1.cmml" xref="S2.T1.4.m1.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.m1.1d">+</annotation><annotation encoding="application/x-llamapun" id="S2.T1.4.m1.1e">+</annotation></semantics></math>â€™ denotes explicit positive feedback, â€˜<math alttext="-" class="ltx_Math" display="inline" id="S2.T1.5.m2.1"><semantics id="S2.T1.5.m2.1b"><mo id="S2.T1.5.m2.1.1" xref="S2.T1.5.m2.1.1.cmml">âˆ’</mo><annotation-xml encoding="MathML-Content" id="S2.T1.5.m2.1c"><minus id="S2.T1.5.m2.1.1.cmml" xref="S2.T1.5.m2.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.5.m2.1d">-</annotation><annotation encoding="application/x-llamapun" id="S2.T1.5.m2.1e">-</annotation></semantics></math>â€™ denotes explicit negative feedback and â€˜<math alttext="/" class="ltx_Math" display="inline" id="S2.T1.6.m3.1"><semantics id="S2.T1.6.m3.1b"><mo id="S2.T1.6.m3.1.1" xref="S2.T1.6.m3.1.1.cmml">/</mo><annotation-xml encoding="MathML-Content" id="S2.T1.6.m3.1c"><divide id="S2.T1.6.m3.1.1.cmml" xref="S2.T1.6.m3.1.1"></divide></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.6.m3.1d">/</annotation><annotation encoding="application/x-llamapun" id="S2.T1.6.m3.1e">/</annotation></semantics></math>â€™ denotes song skips. Statistics here are not necessarily representative of their user bases.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S2.T1.25">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T1.25.20.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S2.T1.25.20.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.25.20.1.2">Piki</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.25.20.1.3">Spotify</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.25.20.1.4">Pandora</td>
</tr>
<tr class="ltx_tr" id="S2.T1.25.21.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S2.T1.25.21.2.1">Granularity</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.25.21.2.2">User</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.25.21.2.3">Session</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.25.21.2.4">User</td>
</tr>
<tr class="ltx_tr" id="S2.T1.13.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S2.T1.13.7.8">Feedback types</th>
<td class="ltx_td ltx_align_center" id="S2.T1.8.2.2">
<math alttext="+" class="ltx_Math" display="inline" id="S2.T1.7.1.1.m1.1"><semantics id="S2.T1.7.1.1.m1.1a"><mo id="S2.T1.7.1.1.m1.1.1" xref="S2.T1.7.1.1.m1.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="S2.T1.7.1.1.m1.1b"><plus id="S2.T1.7.1.1.m1.1.1.cmml" xref="S2.T1.7.1.1.m1.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.7.1.1.m1.1c">+</annotation><annotation encoding="application/x-llamapun" id="S2.T1.7.1.1.m1.1d">+</annotation></semantics></math>, <math alttext="-" class="ltx_Math" display="inline" id="S2.T1.8.2.2.m2.1"><semantics id="S2.T1.8.2.2.m2.1a"><mo id="S2.T1.8.2.2.m2.1.1" xref="S2.T1.8.2.2.m2.1.1.cmml">âˆ’</mo><annotation-xml encoding="MathML-Content" id="S2.T1.8.2.2.m2.1b"><minus id="S2.T1.8.2.2.m2.1.1.cmml" xref="S2.T1.8.2.2.m2.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.8.2.2.m2.1c">-</annotation><annotation encoding="application/x-llamapun" id="S2.T1.8.2.2.m2.1d">-</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S2.T1.10.4.4">
<math alttext="+" class="ltx_Math" display="inline" id="S2.T1.9.3.3.m1.1"><semantics id="S2.T1.9.3.3.m1.1a"><mo id="S2.T1.9.3.3.m1.1.1" xref="S2.T1.9.3.3.m1.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="S2.T1.9.3.3.m1.1b"><plus id="S2.T1.9.3.3.m1.1.1.cmml" xref="S2.T1.9.3.3.m1.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.9.3.3.m1.1c">+</annotation><annotation encoding="application/x-llamapun" id="S2.T1.9.3.3.m1.1d">+</annotation></semantics></math>, <math alttext="/" class="ltx_Math" display="inline" id="S2.T1.10.4.4.m2.1"><semantics id="S2.T1.10.4.4.m2.1a"><mo id="S2.T1.10.4.4.m2.1.1" xref="S2.T1.10.4.4.m2.1.1.cmml">/</mo><annotation-xml encoding="MathML-Content" id="S2.T1.10.4.4.m2.1b"><divide id="S2.T1.10.4.4.m2.1.1.cmml" xref="S2.T1.10.4.4.m2.1.1"></divide></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.10.4.4.m2.1c">/</annotation><annotation encoding="application/x-llamapun" id="S2.T1.10.4.4.m2.1d">/</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S2.T1.13.7.7">
<math alttext="+" class="ltx_Math" display="inline" id="S2.T1.11.5.5.m1.1"><semantics id="S2.T1.11.5.5.m1.1a"><mo id="S2.T1.11.5.5.m1.1.1" xref="S2.T1.11.5.5.m1.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="S2.T1.11.5.5.m1.1b"><plus id="S2.T1.11.5.5.m1.1.1.cmml" xref="S2.T1.11.5.5.m1.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.11.5.5.m1.1c">+</annotation><annotation encoding="application/x-llamapun" id="S2.T1.11.5.5.m1.1d">+</annotation></semantics></math>, <math alttext="/" class="ltx_Math" display="inline" id="S2.T1.12.6.6.m2.1"><semantics id="S2.T1.12.6.6.m2.1a"><mo id="S2.T1.12.6.6.m2.1.1" xref="S2.T1.12.6.6.m2.1.1.cmml">/</mo><annotation-xml encoding="MathML-Content" id="S2.T1.12.6.6.m2.1b"><divide id="S2.T1.12.6.6.m2.1.1.cmml" xref="S2.T1.12.6.6.m2.1.1"></divide></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.12.6.6.m2.1c">/</annotation><annotation encoding="application/x-llamapun" id="S2.T1.12.6.6.m2.1d">/</annotation></semantics></math>, <math alttext="-" class="ltx_Math" display="inline" id="S2.T1.13.7.7.m3.1"><semantics id="S2.T1.13.7.7.m3.1a"><mo id="S2.T1.13.7.7.m3.1.1" xref="S2.T1.13.7.7.m3.1.1.cmml">âˆ’</mo><annotation-xml encoding="MathML-Content" id="S2.T1.13.7.7.m3.1b"><minus id="S2.T1.13.7.7.m3.1.1.cmml" xref="S2.T1.13.7.7.m3.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.13.7.7.m3.1c">-</annotation><annotation encoding="application/x-llamapun" id="S2.T1.13.7.7.m3.1d">-</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.19.13">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S2.T1.16.10.3">Ratio of <math alttext="+" class="ltx_Math" display="inline" id="S2.T1.14.8.1.m1.1"><semantics id="S2.T1.14.8.1.m1.1a"><mo id="S2.T1.14.8.1.m1.1.1" xref="S2.T1.14.8.1.m1.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="S2.T1.14.8.1.m1.1b"><plus id="S2.T1.14.8.1.m1.1.1.cmml" xref="S2.T1.14.8.1.m1.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.14.8.1.m1.1c">+</annotation><annotation encoding="application/x-llamapun" id="S2.T1.14.8.1.m1.1d">+</annotation></semantics></math>:<math alttext="/" class="ltx_Math" display="inline" id="S2.T1.15.9.2.m2.1"><semantics id="S2.T1.15.9.2.m2.1a"><mo id="S2.T1.15.9.2.m2.1.1" xref="S2.T1.15.9.2.m2.1.1.cmml">/</mo><annotation-xml encoding="MathML-Content" id="S2.T1.15.9.2.m2.1b"><divide id="S2.T1.15.9.2.m2.1.1.cmml" xref="S2.T1.15.9.2.m2.1.1"></divide></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.15.9.2.m2.1c">/</annotation><annotation encoding="application/x-llamapun" id="S2.T1.15.9.2.m2.1d">/</annotation></semantics></math>:<math alttext="-" class="ltx_Math" display="inline" id="S2.T1.16.10.3.m3.1"><semantics id="S2.T1.16.10.3.m3.1a"><mo id="S2.T1.16.10.3.m3.1.1" xref="S2.T1.16.10.3.m3.1.1.cmml">âˆ’</mo><annotation-xml encoding="MathML-Content" id="S2.T1.16.10.3.m3.1b"><minus id="S2.T1.16.10.3.m3.1.1.cmml" xref="S2.T1.16.10.3.m3.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.16.10.3.m3.1c">-</annotation><annotation encoding="application/x-llamapun" id="S2.T1.16.10.3.m3.1d">-</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S2.T1.17.11.4"><math alttext="1.1:0:1" class="ltx_Math" display="inline" id="S2.T1.17.11.4.m1.1"><semantics id="S2.T1.17.11.4.m1.1a"><mrow id="S2.T1.17.11.4.m1.1.1" xref="S2.T1.17.11.4.m1.1.1.cmml"><mn id="S2.T1.17.11.4.m1.1.1.2" xref="S2.T1.17.11.4.m1.1.1.2.cmml">1.1</mn><mo id="S2.T1.17.11.4.m1.1.1.3" lspace="0.278em" rspace="0.278em" xref="S2.T1.17.11.4.m1.1.1.3.cmml">:</mo><mn id="S2.T1.17.11.4.m1.1.1.4" xref="S2.T1.17.11.4.m1.1.1.4.cmml">0</mn><mo id="S2.T1.17.11.4.m1.1.1.5" lspace="0.278em" rspace="0.278em" xref="S2.T1.17.11.4.m1.1.1.5.cmml">:</mo><mn id="S2.T1.17.11.4.m1.1.1.6" xref="S2.T1.17.11.4.m1.1.1.6.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.17.11.4.m1.1b"><apply id="S2.T1.17.11.4.m1.1.1.cmml" xref="S2.T1.17.11.4.m1.1.1"><and id="S2.T1.17.11.4.m1.1.1a.cmml" xref="S2.T1.17.11.4.m1.1.1"></and><apply id="S2.T1.17.11.4.m1.1.1b.cmml" xref="S2.T1.17.11.4.m1.1.1"><ci id="S2.T1.17.11.4.m1.1.1.3.cmml" xref="S2.T1.17.11.4.m1.1.1.3">:</ci><cn id="S2.T1.17.11.4.m1.1.1.2.cmml" type="float" xref="S2.T1.17.11.4.m1.1.1.2">1.1</cn><cn id="S2.T1.17.11.4.m1.1.1.4.cmml" type="integer" xref="S2.T1.17.11.4.m1.1.1.4">0</cn></apply><apply id="S2.T1.17.11.4.m1.1.1c.cmml" xref="S2.T1.17.11.4.m1.1.1"><ci id="S2.T1.17.11.4.m1.1.1.5.cmml" xref="S2.T1.17.11.4.m1.1.1.5">:</ci><share href="https://arxiv.org/html/2406.04488v1#S2.T1.17.11.4.m1.1.1.4.cmml" id="S2.T1.17.11.4.m1.1.1d.cmml" xref="S2.T1.17.11.4.m1.1.1"></share><cn id="S2.T1.17.11.4.m1.1.1.6.cmml" type="integer" xref="S2.T1.17.11.4.m1.1.1.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.17.11.4.m1.1c">1.1:0:1</annotation><annotation encoding="application/x-llamapun" id="S2.T1.17.11.4.m1.1d">1.1 : 0 : 1</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S2.T1.18.12.5"><math alttext="1:0.9:0" class="ltx_Math" display="inline" id="S2.T1.18.12.5.m1.1"><semantics id="S2.T1.18.12.5.m1.1a"><mrow id="S2.T1.18.12.5.m1.1.1" xref="S2.T1.18.12.5.m1.1.1.cmml"><mn id="S2.T1.18.12.5.m1.1.1.2" xref="S2.T1.18.12.5.m1.1.1.2.cmml">1</mn><mo id="S2.T1.18.12.5.m1.1.1.3" lspace="0.278em" rspace="0.278em" xref="S2.T1.18.12.5.m1.1.1.3.cmml">:</mo><mn id="S2.T1.18.12.5.m1.1.1.4" xref="S2.T1.18.12.5.m1.1.1.4.cmml">0.9</mn><mo id="S2.T1.18.12.5.m1.1.1.5" lspace="0.278em" rspace="0.278em" xref="S2.T1.18.12.5.m1.1.1.5.cmml">:</mo><mn id="S2.T1.18.12.5.m1.1.1.6" xref="S2.T1.18.12.5.m1.1.1.6.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.18.12.5.m1.1b"><apply id="S2.T1.18.12.5.m1.1.1.cmml" xref="S2.T1.18.12.5.m1.1.1"><and id="S2.T1.18.12.5.m1.1.1a.cmml" xref="S2.T1.18.12.5.m1.1.1"></and><apply id="S2.T1.18.12.5.m1.1.1b.cmml" xref="S2.T1.18.12.5.m1.1.1"><ci id="S2.T1.18.12.5.m1.1.1.3.cmml" xref="S2.T1.18.12.5.m1.1.1.3">:</ci><cn id="S2.T1.18.12.5.m1.1.1.2.cmml" type="integer" xref="S2.T1.18.12.5.m1.1.1.2">1</cn><cn id="S2.T1.18.12.5.m1.1.1.4.cmml" type="float" xref="S2.T1.18.12.5.m1.1.1.4">0.9</cn></apply><apply id="S2.T1.18.12.5.m1.1.1c.cmml" xref="S2.T1.18.12.5.m1.1.1"><ci id="S2.T1.18.12.5.m1.1.1.5.cmml" xref="S2.T1.18.12.5.m1.1.1.5">:</ci><share href="https://arxiv.org/html/2406.04488v1#S2.T1.18.12.5.m1.1.1.4.cmml" id="S2.T1.18.12.5.m1.1.1d.cmml" xref="S2.T1.18.12.5.m1.1.1"></share><cn id="S2.T1.18.12.5.m1.1.1.6.cmml" type="integer" xref="S2.T1.18.12.5.m1.1.1.6">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.18.12.5.m1.1c">1:0.9:0</annotation><annotation encoding="application/x-llamapun" id="S2.T1.18.12.5.m1.1d">1 : 0.9 : 0</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S2.T1.19.13.6"><math alttext="4:13:1" class="ltx_Math" display="inline" id="S2.T1.19.13.6.m1.1"><semantics id="S2.T1.19.13.6.m1.1a"><mrow id="S2.T1.19.13.6.m1.1.1" xref="S2.T1.19.13.6.m1.1.1.cmml"><mn id="S2.T1.19.13.6.m1.1.1.2" xref="S2.T1.19.13.6.m1.1.1.2.cmml">4</mn><mo id="S2.T1.19.13.6.m1.1.1.3" lspace="0.278em" rspace="0.278em" xref="S2.T1.19.13.6.m1.1.1.3.cmml">:</mo><mn id="S2.T1.19.13.6.m1.1.1.4" xref="S2.T1.19.13.6.m1.1.1.4.cmml">13</mn><mo id="S2.T1.19.13.6.m1.1.1.5" lspace="0.278em" rspace="0.278em" xref="S2.T1.19.13.6.m1.1.1.5.cmml">:</mo><mn id="S2.T1.19.13.6.m1.1.1.6" xref="S2.T1.19.13.6.m1.1.1.6.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.19.13.6.m1.1b"><apply id="S2.T1.19.13.6.m1.1.1.cmml" xref="S2.T1.19.13.6.m1.1.1"><and id="S2.T1.19.13.6.m1.1.1a.cmml" xref="S2.T1.19.13.6.m1.1.1"></and><apply id="S2.T1.19.13.6.m1.1.1b.cmml" xref="S2.T1.19.13.6.m1.1.1"><ci id="S2.T1.19.13.6.m1.1.1.3.cmml" xref="S2.T1.19.13.6.m1.1.1.3">:</ci><cn id="S2.T1.19.13.6.m1.1.1.2.cmml" type="integer" xref="S2.T1.19.13.6.m1.1.1.2">4</cn><cn id="S2.T1.19.13.6.m1.1.1.4.cmml" type="integer" xref="S2.T1.19.13.6.m1.1.1.4">13</cn></apply><apply id="S2.T1.19.13.6.m1.1.1c.cmml" xref="S2.T1.19.13.6.m1.1.1"><ci id="S2.T1.19.13.6.m1.1.1.5.cmml" xref="S2.T1.19.13.6.m1.1.1.5">:</ci><share href="https://arxiv.org/html/2406.04488v1#S2.T1.19.13.6.m1.1.1.4.cmml" id="S2.T1.19.13.6.m1.1.1d.cmml" xref="S2.T1.19.13.6.m1.1.1"></share><cn id="S2.T1.19.13.6.m1.1.1.6.cmml" type="integer" xref="S2.T1.19.13.6.m1.1.1.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.19.13.6.m1.1c">4:13:1</annotation><annotation encoding="application/x-llamapun" id="S2.T1.19.13.6.m1.1d">4 : 13 : 1</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S2.T1.25.22.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S2.T1.25.22.3.1">Max. seq. length</th>
<td class="ltx_td ltx_align_center" id="S2.T1.25.22.3.2">400</td>
<td class="ltx_td ltx_align_center" id="S2.T1.25.22.3.3">20</td>
<td class="ltx_td ltx_align_center" id="S2.T1.25.22.3.4">400</td>
</tr>
<tr class="ltx_tr" id="S2.T1.25.23.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S2.T1.25.23.4.1">Median seq. length</th>
<td class="ltx_td ltx_align_center" id="S2.T1.25.23.4.2">24</td>
<td class="ltx_td ltx_align_center" id="S2.T1.25.23.4.3">9</td>
<td class="ltx_td ltx_align_center" id="S2.T1.25.23.4.4">289</td>
</tr>
<tr class="ltx_tr" id="S2.T1.25.24.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S2.T1.25.24.5.1">Max. lookback</th>
<td class="ltx_td ltx_align_center" id="S2.T1.25.24.5.2">3.7 years</td>
<td class="ltx_td ltx_align_center" id="S2.T1.25.24.5.3">Same day</td>
<td class="ltx_td ltx_align_center" id="S2.T1.25.24.5.4">1 year</td>
</tr>
<tr class="ltx_tr" id="S2.T1.25.25.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S2.T1.25.25.6.1">Median lookback</th>
<td class="ltx_td ltx_align_center" id="S2.T1.25.25.6.2">2 days</td>
<td class="ltx_td ltx_align_center" id="S2.T1.25.25.6.3">Same day</td>
<td class="ltx_td ltx_align_center" id="S2.T1.25.25.6.4">9 months</td>
</tr>
<tr class="ltx_tr" id="S2.T1.22.16">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S2.T1.22.16.4">No. of sequences</th>
<td class="ltx_td ltx_align_center" id="S2.T1.20.14.1"><math alttext="8\times 10^{3}" class="ltx_Math" display="inline" id="S2.T1.20.14.1.m1.1"><semantics id="S2.T1.20.14.1.m1.1a"><mrow id="S2.T1.20.14.1.m1.1.1" xref="S2.T1.20.14.1.m1.1.1.cmml"><mn id="S2.T1.20.14.1.m1.1.1.2" xref="S2.T1.20.14.1.m1.1.1.2.cmml">8</mn><mo id="S2.T1.20.14.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.T1.20.14.1.m1.1.1.1.cmml">Ã—</mo><msup id="S2.T1.20.14.1.m1.1.1.3" xref="S2.T1.20.14.1.m1.1.1.3.cmml"><mn id="S2.T1.20.14.1.m1.1.1.3.2" xref="S2.T1.20.14.1.m1.1.1.3.2.cmml">10</mn><mn id="S2.T1.20.14.1.m1.1.1.3.3" xref="S2.T1.20.14.1.m1.1.1.3.3.cmml">3</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.20.14.1.m1.1b"><apply id="S2.T1.20.14.1.m1.1.1.cmml" xref="S2.T1.20.14.1.m1.1.1"><times id="S2.T1.20.14.1.m1.1.1.1.cmml" xref="S2.T1.20.14.1.m1.1.1.1"></times><cn id="S2.T1.20.14.1.m1.1.1.2.cmml" type="integer" xref="S2.T1.20.14.1.m1.1.1.2">8</cn><apply id="S2.T1.20.14.1.m1.1.1.3.cmml" xref="S2.T1.20.14.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.T1.20.14.1.m1.1.1.3.1.cmml" xref="S2.T1.20.14.1.m1.1.1.3">superscript</csymbol><cn id="S2.T1.20.14.1.m1.1.1.3.2.cmml" type="integer" xref="S2.T1.20.14.1.m1.1.1.3.2">10</cn><cn id="S2.T1.20.14.1.m1.1.1.3.3.cmml" type="integer" xref="S2.T1.20.14.1.m1.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.20.14.1.m1.1c">8\times 10^{3}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.20.14.1.m1.1d">8 Ã— 10 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S2.T1.21.15.2"><math alttext="8\times 10^{6}" class="ltx_Math" display="inline" id="S2.T1.21.15.2.m1.1"><semantics id="S2.T1.21.15.2.m1.1a"><mrow id="S2.T1.21.15.2.m1.1.1" xref="S2.T1.21.15.2.m1.1.1.cmml"><mn id="S2.T1.21.15.2.m1.1.1.2" xref="S2.T1.21.15.2.m1.1.1.2.cmml">8</mn><mo id="S2.T1.21.15.2.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.T1.21.15.2.m1.1.1.1.cmml">Ã—</mo><msup id="S2.T1.21.15.2.m1.1.1.3" xref="S2.T1.21.15.2.m1.1.1.3.cmml"><mn id="S2.T1.21.15.2.m1.1.1.3.2" xref="S2.T1.21.15.2.m1.1.1.3.2.cmml">10</mn><mn id="S2.T1.21.15.2.m1.1.1.3.3" xref="S2.T1.21.15.2.m1.1.1.3.3.cmml">6</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.21.15.2.m1.1b"><apply id="S2.T1.21.15.2.m1.1.1.cmml" xref="S2.T1.21.15.2.m1.1.1"><times id="S2.T1.21.15.2.m1.1.1.1.cmml" xref="S2.T1.21.15.2.m1.1.1.1"></times><cn id="S2.T1.21.15.2.m1.1.1.2.cmml" type="integer" xref="S2.T1.21.15.2.m1.1.1.2">8</cn><apply id="S2.T1.21.15.2.m1.1.1.3.cmml" xref="S2.T1.21.15.2.m1.1.1.3"><csymbol cd="ambiguous" id="S2.T1.21.15.2.m1.1.1.3.1.cmml" xref="S2.T1.21.15.2.m1.1.1.3">superscript</csymbol><cn id="S2.T1.21.15.2.m1.1.1.3.2.cmml" type="integer" xref="S2.T1.21.15.2.m1.1.1.3.2">10</cn><cn id="S2.T1.21.15.2.m1.1.1.3.3.cmml" type="integer" xref="S2.T1.21.15.2.m1.1.1.3.3">6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.21.15.2.m1.1c">8\times 10^{6}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.21.15.2.m1.1d">8 Ã— 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S2.T1.22.16.3"><math alttext="10^{7}" class="ltx_Math" display="inline" id="S2.T1.22.16.3.m1.1"><semantics id="S2.T1.22.16.3.m1.1a"><msup id="S2.T1.22.16.3.m1.1.1" xref="S2.T1.22.16.3.m1.1.1.cmml"><mn id="S2.T1.22.16.3.m1.1.1.2" xref="S2.T1.22.16.3.m1.1.1.2.cmml">10</mn><mn id="S2.T1.22.16.3.m1.1.1.3" xref="S2.T1.22.16.3.m1.1.1.3.cmml">7</mn></msup><annotation-xml encoding="MathML-Content" id="S2.T1.22.16.3.m1.1b"><apply id="S2.T1.22.16.3.m1.1.1.cmml" xref="S2.T1.22.16.3.m1.1.1"><csymbol cd="ambiguous" id="S2.T1.22.16.3.m1.1.1.1.cmml" xref="S2.T1.22.16.3.m1.1.1">superscript</csymbol><cn id="S2.T1.22.16.3.m1.1.1.2.cmml" type="integer" xref="S2.T1.22.16.3.m1.1.1.2">10</cn><cn id="S2.T1.22.16.3.m1.1.1.3.cmml" type="integer" xref="S2.T1.22.16.3.m1.1.1.3">7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.22.16.3.m1.1c">10^{7}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.22.16.3.m1.1d">10 start_POSTSUPERSCRIPT 7 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S2.T1.25.19">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S2.T1.25.19.4">No. of tracks</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.23.17.1">2.5 <math alttext="\times 10^{5}" class="ltx_Math" display="inline" id="S2.T1.23.17.1.m1.1"><semantics id="S2.T1.23.17.1.m1.1a"><mrow id="S2.T1.23.17.1.m1.1.1" xref="S2.T1.23.17.1.m1.1.1.cmml"><mi id="S2.T1.23.17.1.m1.1.1.2" xref="S2.T1.23.17.1.m1.1.1.2.cmml"></mi><mo id="S2.T1.23.17.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.T1.23.17.1.m1.1.1.1.cmml">Ã—</mo><msup id="S2.T1.23.17.1.m1.1.1.3" xref="S2.T1.23.17.1.m1.1.1.3.cmml"><mn id="S2.T1.23.17.1.m1.1.1.3.2" xref="S2.T1.23.17.1.m1.1.1.3.2.cmml">10</mn><mn id="S2.T1.23.17.1.m1.1.1.3.3" xref="S2.T1.23.17.1.m1.1.1.3.3.cmml">5</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.23.17.1.m1.1b"><apply id="S2.T1.23.17.1.m1.1.1.cmml" xref="S2.T1.23.17.1.m1.1.1"><times id="S2.T1.23.17.1.m1.1.1.1.cmml" xref="S2.T1.23.17.1.m1.1.1.1"></times><csymbol cd="latexml" id="S2.T1.23.17.1.m1.1.1.2.cmml" xref="S2.T1.23.17.1.m1.1.1.2">absent</csymbol><apply id="S2.T1.23.17.1.m1.1.1.3.cmml" xref="S2.T1.23.17.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.T1.23.17.1.m1.1.1.3.1.cmml" xref="S2.T1.23.17.1.m1.1.1.3">superscript</csymbol><cn id="S2.T1.23.17.1.m1.1.1.3.2.cmml" type="integer" xref="S2.T1.23.17.1.m1.1.1.3.2">10</cn><cn id="S2.T1.23.17.1.m1.1.1.3.3.cmml" type="integer" xref="S2.T1.23.17.1.m1.1.1.3.3">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.23.17.1.m1.1c">\times 10^{5}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.23.17.1.m1.1d">Ã— 10 start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.24.18.2">3 <math alttext="\times 10^{6}" class="ltx_Math" display="inline" id="S2.T1.24.18.2.m1.1"><semantics id="S2.T1.24.18.2.m1.1a"><mrow id="S2.T1.24.18.2.m1.1.1" xref="S2.T1.24.18.2.m1.1.1.cmml"><mi id="S2.T1.24.18.2.m1.1.1.2" xref="S2.T1.24.18.2.m1.1.1.2.cmml"></mi><mo id="S2.T1.24.18.2.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.T1.24.18.2.m1.1.1.1.cmml">Ã—</mo><msup id="S2.T1.24.18.2.m1.1.1.3" xref="S2.T1.24.18.2.m1.1.1.3.cmml"><mn id="S2.T1.24.18.2.m1.1.1.3.2" xref="S2.T1.24.18.2.m1.1.1.3.2.cmml">10</mn><mn id="S2.T1.24.18.2.m1.1.1.3.3" xref="S2.T1.24.18.2.m1.1.1.3.3.cmml">6</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.24.18.2.m1.1b"><apply id="S2.T1.24.18.2.m1.1.1.cmml" xref="S2.T1.24.18.2.m1.1.1"><times id="S2.T1.24.18.2.m1.1.1.1.cmml" xref="S2.T1.24.18.2.m1.1.1.1"></times><csymbol cd="latexml" id="S2.T1.24.18.2.m1.1.1.2.cmml" xref="S2.T1.24.18.2.m1.1.1.2">absent</csymbol><apply id="S2.T1.24.18.2.m1.1.1.3.cmml" xref="S2.T1.24.18.2.m1.1.1.3"><csymbol cd="ambiguous" id="S2.T1.24.18.2.m1.1.1.3.1.cmml" xref="S2.T1.24.18.2.m1.1.1.3">superscript</csymbol><cn id="S2.T1.24.18.2.m1.1.1.3.2.cmml" type="integer" xref="S2.T1.24.18.2.m1.1.1.3.2">10</cn><cn id="S2.T1.24.18.2.m1.1.1.3.3.cmml" type="integer" xref="S2.T1.24.18.2.m1.1.1.3.3">6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.24.18.2.m1.1c">\times 10^{6}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.24.18.2.m1.1d">Ã— 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.25.19.3"><math alttext="10^{6}" class="ltx_Math" display="inline" id="S2.T1.25.19.3.m1.1"><semantics id="S2.T1.25.19.3.m1.1a"><msup id="S2.T1.25.19.3.m1.1.1" xref="S2.T1.25.19.3.m1.1.1.cmml"><mn id="S2.T1.25.19.3.m1.1.1.2" xref="S2.T1.25.19.3.m1.1.1.2.cmml">10</mn><mn id="S2.T1.25.19.3.m1.1.1.3" xref="S2.T1.25.19.3.m1.1.1.3.cmml">6</mn></msup><annotation-xml encoding="MathML-Content" id="S2.T1.25.19.3.m1.1b"><apply id="S2.T1.25.19.3.m1.1.1.cmml" xref="S2.T1.25.19.3.m1.1.1"><csymbol cd="ambiguous" id="S2.T1.25.19.3.m1.1.1.1.cmml" xref="S2.T1.25.19.3.m1.1.1">superscript</csymbol><cn id="S2.T1.25.19.3.m1.1.1.2.cmml" type="integer" xref="S2.T1.25.19.3.m1.1.1.2">10</cn><cn id="S2.T1.25.19.3.m1.1.1.3.cmml" type="integer" xref="S2.T1.25.19.3.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.25.19.3.m1.1c">10^{6}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.25.19.3.m1.1d">10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">We evaluate our model on three datasets. Two of them (Piki <cite class="ltx_cite ltx_citemacro_citep">(Stoikov and Wen, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib14" title="">2021</a>)</cite> and Spotifyâ€™s Sequential Skip Prediction <cite class="ltx_cite ltx_citemacro_citep">(Brost etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib3" title="">2019</a>)</cite> datasets) are open-source and the third is a proprietary dataset from Pandora.
Dataset statistics are summarized in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S2.T1" title="Table 1 â€£ 2. Data â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">1</span></a>.
The Spotify dataset consists of plays and skips, which are not quite <span class="ltx_text ltx_font_italic" id="S2.p1.1.1">explicit</span> feedback, but can be mapped to positive and negative feedback respectively. It is a much larger dataset than the Piki one and is therefore included for comparison.
The Piki dataset is filtered for only feedback coming from â€˜personalizedâ€˜ recommendations. We assume that Piki playlists are comprised of similar songs (like a radio station); similarly, we filter the Spotify data to â€˜radioâ€™-type data only.
This is necessary for our accuracy metric (Section <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S4" title="4. Evaluation â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">4</span></a>), which is based off distinguishing which songs from a stylistically-consistent set of songs on some station may be liked by a user.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">The Pandora dataset additionally has station information logged to provide context for each feedback, which is treated as another additive embedding <cite class="ltx_cite ltx_citemacro_citep">(Mei etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib9" title="">2023</a>)</cite>. The Piki and Spotify datasets, which do not have station information, are effectively trained with a null station embedding.
In all cases, the data is randomly split at the user level, with the final month of data time-separated for the test set, and 90% of the remainder used for training and 10% used for validation.
The test sets consist of paired user feedback, consisting of one positive and one negative feedback (using explicit feedback where available, as for the Piki and Pandora datasets, and plays/skips in the Spotify dataset).
For the Pandora dataset, the positive and negative test samples are further required to come from the same station.
We assume this condition is also satisfied by the Spotify dataset, which it is filtered for same-session â€˜radioâ€™ tracks only.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">The Piki and Pandora datasets use explicit positive and negative feedback, with the Pandora dataset also having implicit negative feedback (skips). The Spotify dataset uses track plays and skips, which are more implicit, but can be thought of as positive and negative feedback.
The Piki and Spotify datasets have a fairly even proportion of positive and negative feedback, whereas the Pandora feedback is dominated by skips.
This is significant as although model <span class="ltx_text ltx_font_italic" id="S2.p3.1.1">training</span> requires users to have positive feedback (to use as training targets), there is no such requirement at <span class="ltx_text ltx_font_italic" id="S2.p3.1.2">inference</span>.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">For all datasets, though less prominent in the Spotify dataset due to its smaller maximum input length, the distribution of user input sizes skews towards shorter sequences.
This skew is stronger for the Piki dataset than the Pandora dataset and is reflected in the median sequence lengths in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S2.T1" title="Table 1 â€£ 2. Data â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">1</span></a>.
To better align the training and test tasks, we enforce a condition that the final position will always be a prediction task (i.e. with no future feedback for inference).
This means that training, validation and test sequences always end with an â€˜upâ€™, to be used as a target for prediction.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">Around one-third (32%) of users in the Pandora dataset do not give any up thumbs at all, but do give some skips: these users are not included in the training set as they do not have positive examples for prediction, but can nevertheless be covered by a personalization model that accepts skips as inputs. A similar proportion (37%) of users in the Spotify dataset also only give skips and are excluded from training.
This means that a model that accepts skips as inputs can increase the personalization rate, though the test accuracy for such skip-only users should be separately checked as they do not occur in the training set (Section <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.SS3" title="5.3. Feedback types â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">5.3</span></a>).
These high-skip users still contribute listener-hours and it is important to personalize their songs too.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Model Details</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">The training architecture is a hybrid of SASRec and BERT4Rec: essentially, we combine the binary cross-entropy and general Transformer architecture of SASRec with the cloze task completion method of BERT4Rec.
For some proportion <math alttext="p_{task}=0.15" class="ltx_Math" display="inline" id="S3.p1.1.m1.1"><semantics id="S3.p1.1.m1.1a"><mrow id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><msub id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml"><mi id="S3.p1.1.m1.1.1.2.2" xref="S3.p1.1.m1.1.1.2.2.cmml">p</mi><mrow id="S3.p1.1.m1.1.1.2.3" xref="S3.p1.1.m1.1.1.2.3.cmml"><mi id="S3.p1.1.m1.1.1.2.3.2" xref="S3.p1.1.m1.1.1.2.3.2.cmml">t</mi><mo id="S3.p1.1.m1.1.1.2.3.1" xref="S3.p1.1.m1.1.1.2.3.1.cmml">â¢</mo><mi id="S3.p1.1.m1.1.1.2.3.3" xref="S3.p1.1.m1.1.1.2.3.3.cmml">a</mi><mo id="S3.p1.1.m1.1.1.2.3.1a" xref="S3.p1.1.m1.1.1.2.3.1.cmml">â¢</mo><mi id="S3.p1.1.m1.1.1.2.3.4" xref="S3.p1.1.m1.1.1.2.3.4.cmml">s</mi><mo id="S3.p1.1.m1.1.1.2.3.1b" xref="S3.p1.1.m1.1.1.2.3.1.cmml">â¢</mo><mi id="S3.p1.1.m1.1.1.2.3.5" xref="S3.p1.1.m1.1.1.2.3.5.cmml">k</mi></mrow></msub><mo id="S3.p1.1.m1.1.1.1" xref="S3.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3.cmml">0.15</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><eq id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.1"></eq><apply id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.2.1.cmml" xref="S3.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.p1.1.m1.1.1.2.2.cmml" xref="S3.p1.1.m1.1.1.2.2">ğ‘</ci><apply id="S3.p1.1.m1.1.1.2.3.cmml" xref="S3.p1.1.m1.1.1.2.3"><times id="S3.p1.1.m1.1.1.2.3.1.cmml" xref="S3.p1.1.m1.1.1.2.3.1"></times><ci id="S3.p1.1.m1.1.1.2.3.2.cmml" xref="S3.p1.1.m1.1.1.2.3.2">ğ‘¡</ci><ci id="S3.p1.1.m1.1.1.2.3.3.cmml" xref="S3.p1.1.m1.1.1.2.3.3">ğ‘</ci><ci id="S3.p1.1.m1.1.1.2.3.4.cmml" xref="S3.p1.1.m1.1.1.2.3.4">ğ‘ </ci><ci id="S3.p1.1.m1.1.1.2.3.5.cmml" xref="S3.p1.1.m1.1.1.2.3.5">ğ‘˜</ci></apply></apply><cn id="S3.p1.1.m1.1.1.3.cmml" type="float" xref="S3.p1.1.m1.1.1.3">0.15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">p_{task}=0.15</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.1d">italic_p start_POSTSUBSCRIPT italic_t italic_a italic_s italic_k end_POSTSUBSCRIPT = 0.15</annotation></semantics></math> of â€˜upâ€™ positions, we replace the â€˜upâ€™ song with a mask token.
Only the song attributes are masked; the target station at the prediction position is kept (null for Piki/Spotify) and the target feedback type is an â€˜upâ€™.
This reflects the real-life situation where we may seek to provide song recommendations for a user-selected station.
The standard SASRec architecture cannot simulate this as it lacks mask tokens and the causal filter does not allow for any information at the prediction position to be used in training.</p>
</div>
<figure class="ltx_figure" id="S3.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="100" id="S3.F1.g1" src="extracted/5649672/figs/all_negs_h.png" width="538"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Proportion of sources for hard negative samples used at each position. More recent positions (higher <math alttext="x" class="ltx_Math" display="inline" id="S3.F1.2.m1.1"><semantics id="S3.F1.2.m1.1b"><mi id="S3.F1.2.m1.1.1" xref="S3.F1.2.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.F1.2.m1.1c"><ci id="S3.F1.2.m1.1.1.cmml" xref="S3.F1.2.m1.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.2.m1.1d">x</annotation><annotation encoding="application/x-llamapun" id="S3.F1.2.m1.1e">italic_x</annotation></semantics></math>) are more likely to use randomly-selected negatives as there is less future feedback by definition.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S3.F1.3">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S3.F1.4">A chart showing the distribution of sources for hard negative samples by position. Generally more skips are used than down thumbs, and more recent positions are more likely to lack future feedback and therefore use a random negative sample.</p>
</div>
</div>
</figure>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.2">For the hard negative sample at each masked position, we use a <span class="ltx_text ltx_font_bold" id="S3.p2.2.1">same-day down thumb</span> from the same station (if one exists), otherwise a<span class="ltx_text ltx_font_bold" id="S3.p2.2.2"> same-day skip</span> from the same station (if it exists), otherwise any <span class="ltx_text ltx_font_bold" id="S3.p2.2.3">future</span> <span class="ltx_text ltx_font_bold" id="S3.p2.2.4">down</span> thumb (if it exists), otherwise any <span class="ltx_text ltx_font_bold" id="S3.p2.2.5">future</span> <span class="ltx_text ltx_font_bold" id="S3.p2.2.6">skip</span> (if it exists), otherwise a <span class="ltx_text ltx_font_bold" id="S3.p2.2.7">random</span> song (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S3.F1" title="Figure 1 â€£ 3. Model Details â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">1</span></a>).
For the Spotify dataset, this simplifies greatly as there are no down thumbs and only same-day feedback (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S3.F1" title="Figure 1 â€£ 3. Model Details â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">1</span></a>).
Similarly, the Piki dataset has no skips and has a median sequence length of 2 days (Table <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S2.T1" title="Table 1 â€£ 2. Data â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">1</span></a>) so rarely has future feedback to use.
For all datasets, future feedback is less frequent for more recent positions, which are therefore more likely to use random negative samples (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S3.F1" title="Figure 1 â€£ 3. Model Details â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">1</span></a>).
The proportion of hard negatives used during training can be further controlled with a parameter <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S3.p2.1.m1.1"><semantics id="S3.p2.1.m1.1a"><msub id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml"><mi id="S3.p2.1.m1.1.1.2" xref="S3.p2.1.m1.1.1.2.cmml">p</mi><mrow id="S3.p2.1.m1.1.1.3" xref="S3.p2.1.m1.1.1.3.cmml"><mi id="S3.p2.1.m1.1.1.3.2" xref="S3.p2.1.m1.1.1.3.2.cmml">h</mi><mo id="S3.p2.1.m1.1.1.3.1" xref="S3.p2.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S3.p2.1.m1.1.1.3.3" xref="S3.p2.1.m1.1.1.3.3.cmml">a</mi><mo id="S3.p2.1.m1.1.1.3.1a" xref="S3.p2.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S3.p2.1.m1.1.1.3.4" xref="S3.p2.1.m1.1.1.3.4.cmml">r</mi><mo id="S3.p2.1.m1.1.1.3.1b" xref="S3.p2.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S3.p2.1.m1.1.1.3.5" xref="S3.p2.1.m1.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><apply id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.cmml" xref="S3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.p2.1.m1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.2">ğ‘</ci><apply id="S3.p2.1.m1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.3"><times id="S3.p2.1.m1.1.1.3.1.cmml" xref="S3.p2.1.m1.1.1.3.1"></times><ci id="S3.p2.1.m1.1.1.3.2.cmml" xref="S3.p2.1.m1.1.1.3.2">â„</ci><ci id="S3.p2.1.m1.1.1.3.3.cmml" xref="S3.p2.1.m1.1.1.3.3">ğ‘</ci><ci id="S3.p2.1.m1.1.1.3.4.cmml" xref="S3.p2.1.m1.1.1.3.4">ğ‘Ÿ</ci><ci id="S3.p2.1.m1.1.1.3.5.cmml" xref="S3.p2.1.m1.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.1.m1.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, which is the proportion of training positions that use a hard negative.
We discuss the impact of changing <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S3.p2.2.m2.1"><semantics id="S3.p2.2.m2.1a"><msub id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml"><mi id="S3.p2.2.m2.1.1.2" xref="S3.p2.2.m2.1.1.2.cmml">p</mi><mrow id="S3.p2.2.m2.1.1.3" xref="S3.p2.2.m2.1.1.3.cmml"><mi id="S3.p2.2.m2.1.1.3.2" xref="S3.p2.2.m2.1.1.3.2.cmml">h</mi><mo id="S3.p2.2.m2.1.1.3.1" xref="S3.p2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S3.p2.2.m2.1.1.3.3" xref="S3.p2.2.m2.1.1.3.3.cmml">a</mi><mo id="S3.p2.2.m2.1.1.3.1a" xref="S3.p2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S3.p2.2.m2.1.1.3.4" xref="S3.p2.2.m2.1.1.3.4.cmml">r</mi><mo id="S3.p2.2.m2.1.1.3.1b" xref="S3.p2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S3.p2.2.m2.1.1.3.5" xref="S3.p2.2.m2.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><apply id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m2.1.1.1.cmml" xref="S3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.p2.2.m2.1.1.2.cmml" xref="S3.p2.2.m2.1.1.2">ğ‘</ci><apply id="S3.p2.2.m2.1.1.3.cmml" xref="S3.p2.2.m2.1.1.3"><times id="S3.p2.2.m2.1.1.3.1.cmml" xref="S3.p2.2.m2.1.1.3.1"></times><ci id="S3.p2.2.m2.1.1.3.2.cmml" xref="S3.p2.2.m2.1.1.3.2">â„</ci><ci id="S3.p2.2.m2.1.1.3.3.cmml" xref="S3.p2.2.m2.1.1.3.3">ğ‘</ci><ci id="S3.p2.2.m2.1.1.3.4.cmml" xref="S3.p2.2.m2.1.1.3.4">ğ‘Ÿ</ci><ci id="S3.p2.2.m2.1.1.3.5.cmml" xref="S3.p2.2.m2.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.2.m2.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math> in Section <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.SS2" title="5.2. Hard negative samples â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">5.2</span></a>.
â€˜Skipsâ€™ and â€˜downsâ€™ that are used as negative samples are removed from the userâ€™s input sequence.
To distinguish feedback types in the input, we use a learned additive embedding mapped to the different feedback types (discussed further in Section <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.SS3" title="5.3. Feedback types â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">5.3</span></a>). The total embedding at each position is therefore the sum of the song, station (null for Piki and Spotify datasets), feedback and positional embeddings.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.2">The <span class="ltx_text ltx_font_bold" id="S3.p3.2.1">baseline</span> model uses only positive feedback as inputs (i.e. no feedback embedding) and uses <math alttext="p_{hard}=0" class="ltx_Math" display="inline" id="S3.p3.1.m1.1"><semantics id="S3.p3.1.m1.1a"><mrow id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml"><msub id="S3.p3.1.m1.1.1.2" xref="S3.p3.1.m1.1.1.2.cmml"><mi id="S3.p3.1.m1.1.1.2.2" xref="S3.p3.1.m1.1.1.2.2.cmml">p</mi><mrow id="S3.p3.1.m1.1.1.2.3" xref="S3.p3.1.m1.1.1.2.3.cmml"><mi id="S3.p3.1.m1.1.1.2.3.2" xref="S3.p3.1.m1.1.1.2.3.2.cmml">h</mi><mo id="S3.p3.1.m1.1.1.2.3.1" xref="S3.p3.1.m1.1.1.2.3.1.cmml">â¢</mo><mi id="S3.p3.1.m1.1.1.2.3.3" xref="S3.p3.1.m1.1.1.2.3.3.cmml">a</mi><mo id="S3.p3.1.m1.1.1.2.3.1a" xref="S3.p3.1.m1.1.1.2.3.1.cmml">â¢</mo><mi id="S3.p3.1.m1.1.1.2.3.4" xref="S3.p3.1.m1.1.1.2.3.4.cmml">r</mi><mo id="S3.p3.1.m1.1.1.2.3.1b" xref="S3.p3.1.m1.1.1.2.3.1.cmml">â¢</mo><mi id="S3.p3.1.m1.1.1.2.3.5" xref="S3.p3.1.m1.1.1.2.3.5.cmml">d</mi></mrow></msub><mo id="S3.p3.1.m1.1.1.1" xref="S3.p3.1.m1.1.1.1.cmml">=</mo><mn id="S3.p3.1.m1.1.1.3" xref="S3.p3.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><apply id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1"><eq id="S3.p3.1.m1.1.1.1.cmml" xref="S3.p3.1.m1.1.1.1"></eq><apply id="S3.p3.1.m1.1.1.2.cmml" xref="S3.p3.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.p3.1.m1.1.1.2.1.cmml" xref="S3.p3.1.m1.1.1.2">subscript</csymbol><ci id="S3.p3.1.m1.1.1.2.2.cmml" xref="S3.p3.1.m1.1.1.2.2">ğ‘</ci><apply id="S3.p3.1.m1.1.1.2.3.cmml" xref="S3.p3.1.m1.1.1.2.3"><times id="S3.p3.1.m1.1.1.2.3.1.cmml" xref="S3.p3.1.m1.1.1.2.3.1"></times><ci id="S3.p3.1.m1.1.1.2.3.2.cmml" xref="S3.p3.1.m1.1.1.2.3.2">â„</ci><ci id="S3.p3.1.m1.1.1.2.3.3.cmml" xref="S3.p3.1.m1.1.1.2.3.3">ğ‘</ci><ci id="S3.p3.1.m1.1.1.2.3.4.cmml" xref="S3.p3.1.m1.1.1.2.3.4">ğ‘Ÿ</ci><ci id="S3.p3.1.m1.1.1.2.3.5.cmml" xref="S3.p3.1.m1.1.1.2.3.5">ğ‘‘</ci></apply></apply><cn id="S3.p3.1.m1.1.1.3.cmml" type="integer" xref="S3.p3.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">p_{hard}=0</annotation><annotation encoding="application/x-llamapun" id="S3.p3.1.m1.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT = 0</annotation></semantics></math> (randomly-sampled instead of user-provided hard negatives during training).
Generally, these random samples are likely to be from an unrelated genre and thus are too easy for the model to rank (leading to the overconfidence issue identified by Petrov &amp; Macdonald (2023) <cite class="ltx_cite ltx_citemacro_citep">(Petrov and Macdonald, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib11" title="">2023</a>)</cite>).
In the absence of real negative user feedback, one can attempt to sample more negatives (up to the entire set of <math alttext="N" class="ltx_Math" display="inline" id="S3.p3.2.m2.1"><semantics id="S3.p3.2.m2.1a"><mi id="S3.p3.2.m2.1.1" xref="S3.p3.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.p3.2.m2.1b"><ci id="S3.p3.2.m2.1.1.cmml" xref="S3.p3.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.p3.2.m2.1d">italic_N</annotation></semantics></math> items, like BERT4Rec) to try and capture some hard(er) negative(s); this is explored in Section <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.SS2" title="5.2. Hard negative samples â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">5.2</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Evaluation</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">The model is evaluated against real user data from the subsequent month after the training period, using users who have given both positive and negative feedback (on the same station for Pandora).
Because songs (whether thumbed up or down) that are played on the same station are fairly similar in musical style, this is a much harder problem than simply comparing an â€˜upâ€™ song against a random negative sample.
Generally, even â€˜downâ€™ songs by some user are thumbed up by many other users, making them harder to distinguish than a random negative sample.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.2">An accurate prediction is when the â€˜upâ€™ song is scored higher than the â€˜downâ€™ song; a model that randomly guesses would therefore have an accuracy of <math alttext="0.5" class="ltx_Math" display="inline" id="S4.p2.1.m1.1"><semantics id="S4.p2.1.m1.1a"><mn id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><cn id="S4.p2.1.m1.1.1.cmml" type="float" xref="S4.p2.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">0.5</annotation><annotation encoding="application/x-llamapun" id="S4.p2.1.m1.1d">0.5</annotation></semantics></math>.
Our â€˜test accuracyâ€™ is therefore equivalent to the probability that a random pair of positive/negative feedback is correctly ranked, which is equivalent to the average area, of all users, under the receiver operating characteristic curve (<span class="ltx_text ltx_font_bold" id="S4.p2.2.1">AUC</span>) <cite class="ltx_cite ltx_citemacro_citep">(Hanley and McNeil, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib5" title="">1982</a>)</cite>.
If testing against random negatives, both our model and the baseline have an accuracy <math alttext="\gg 0.99" class="ltx_Math" display="inline" id="S4.p2.2.m2.1"><semantics id="S4.p2.2.m2.1a"><mrow id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml"><mi id="S4.p2.2.m2.1.1.2" xref="S4.p2.2.m2.1.1.2.cmml"></mi><mo id="S4.p2.2.m2.1.1.1" xref="S4.p2.2.m2.1.1.1.cmml">â‰«</mo><mn id="S4.p2.2.m2.1.1.3" xref="S4.p2.2.m2.1.1.3.cmml">0.99</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><apply id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.p2.2.m2.1.1.1.cmml" xref="S4.p2.2.m2.1.1.1">much-greater-than</csymbol><csymbol cd="latexml" id="S4.p2.2.m2.1.1.2.cmml" xref="S4.p2.2.m2.1.1.2">absent</csymbol><cn id="S4.p2.2.m2.1.1.3.cmml" type="float" xref="S4.p2.2.m2.1.1.3">0.99</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">\gg 0.99</annotation><annotation encoding="application/x-llamapun" id="S4.p2.2.m2.1d">â‰« 0.99</annotation></semantics></math>.
This is not very useful, and also not very relevant to the actual usage of these models, which is to distinguish and rank songs that are on a given station (i.e. songs that are generally similar) for each user.
The link between test accuracy and other metrics that focus on true positives (e.g. recall) is explored further in Section <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.SS2.SSS3" title="5.2.3. Relation to other metrics â€£ 5.2. Hard negative samples â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">5.2.3</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Results and Discussion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">For the Spotify and Pandora datasets, we find that incorporating additional feedback (both as inputs and as hard negative samples during training) improves the test set accuracy by <math alttext="6\%" class="ltx_Math" display="inline" id="S5.p1.1.m1.1"><semantics id="S5.p1.1.m1.1a"><mrow id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml"><mn id="S5.p1.1.m1.1.1.2" xref="S5.p1.1.m1.1.1.2.cmml">6</mn><mo id="S5.p1.1.m1.1.1.1" xref="S5.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><apply id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.p1.1.m1.1.1.1.cmml" xref="S5.p1.1.m1.1.1.1">percent</csymbol><cn id="S5.p1.1.m1.1.1.2.cmml" type="integer" xref="S5.p1.1.m1.1.1.2">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">6\%</annotation><annotation encoding="application/x-llamapun" id="S5.p1.1.m1.1d">6 %</annotation></semantics></math> as compared to a model that is only trained on positive feedback and random negatives.
The Piki dataset has a similar lift but due to its smaller size, the lift is not statistically significant.
By far, the biggest contribution to the lift comes from incorporating hard negatives into the loss function.
We explore the impact of hard negatives further in Section <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.SS2" title="5.2. Hard negative samples â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">5.2</span></a>, and the impact of additional feedback types in <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.SS3" title="5.3. Feedback types â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">5.3</span></a>.</p>
</div>
<figure class="ltx_table ltx_align_floatright" id="S5.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2. </span>Ablation study with percentage point changes in accuracy.
The Piki data is too small for any significant results and is omitted.
</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T2.9">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T2.1.1.2" rowspan="2"><span class="ltx_text" id="S5.T2.1.1.2.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S5.T2.1.1.1">
<math alttext="\Delta" class="ltx_Math" display="inline" id="S5.T2.1.1.1.m1.1"><semantics id="S5.T2.1.1.1.m1.1a"><mi id="S5.T2.1.1.1.m1.1.1" mathvariant="normal" xref="S5.T2.1.1.1.m1.1.1.cmml">Î”</mi><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.m1.1b"><ci id="S5.T2.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1">Î”</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S5.T2.1.1.1.m1.1d">roman_Î”</annotation></semantics></math> Accuracy</th>
</tr>
<tr class="ltx_tr" id="S5.T2.9.10.1">
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S5.T2.9.10.1.1">Spotify</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column" id="S5.T2.9.10.1.2">Â Â Pandora</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S5.T2.3.3.3">No positional emb.</th>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T2.2.2.1"><math alttext="-0.6\%" class="ltx_Math" display="inline" id="S5.T2.2.2.1.m1.1"><semantics id="S5.T2.2.2.1.m1.1a"><mrow id="S5.T2.2.2.1.m1.1.1" xref="S5.T2.2.2.1.m1.1.1.cmml"><mo id="S5.T2.2.2.1.m1.1.1a" xref="S5.T2.2.2.1.m1.1.1.cmml">âˆ’</mo><mrow id="S5.T2.2.2.1.m1.1.1.2" xref="S5.T2.2.2.1.m1.1.1.2.cmml"><mn id="S5.T2.2.2.1.m1.1.1.2.2" xref="S5.T2.2.2.1.m1.1.1.2.2.cmml">0.6</mn><mo id="S5.T2.2.2.1.m1.1.1.2.1" xref="S5.T2.2.2.1.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.1.m1.1b"><apply id="S5.T2.2.2.1.m1.1.1.cmml" xref="S5.T2.2.2.1.m1.1.1"><minus id="S5.T2.2.2.1.m1.1.1.1.cmml" xref="S5.T2.2.2.1.m1.1.1"></minus><apply id="S5.T2.2.2.1.m1.1.1.2.cmml" xref="S5.T2.2.2.1.m1.1.1.2"><csymbol cd="latexml" id="S5.T2.2.2.1.m1.1.1.2.1.cmml" xref="S5.T2.2.2.1.m1.1.1.2.1">percent</csymbol><cn id="S5.T2.2.2.1.m1.1.1.2.2.cmml" type="float" xref="S5.T2.2.2.1.m1.1.1.2.2">0.6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.1.m1.1c">-0.6\%</annotation><annotation encoding="application/x-llamapun" id="S5.T2.2.2.1.m1.1d">- 0.6 %</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S5.T2.3.3.2"><math alttext="-0.7\%" class="ltx_Math" display="inline" id="S5.T2.3.3.2.m1.1"><semantics id="S5.T2.3.3.2.m1.1a"><mrow id="S5.T2.3.3.2.m1.1.1" xref="S5.T2.3.3.2.m1.1.1.cmml"><mo id="S5.T2.3.3.2.m1.1.1a" xref="S5.T2.3.3.2.m1.1.1.cmml">âˆ’</mo><mrow id="S5.T2.3.3.2.m1.1.1.2" xref="S5.T2.3.3.2.m1.1.1.2.cmml"><mn id="S5.T2.3.3.2.m1.1.1.2.2" xref="S5.T2.3.3.2.m1.1.1.2.2.cmml">0.7</mn><mo id="S5.T2.3.3.2.m1.1.1.2.1" xref="S5.T2.3.3.2.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.2.m1.1b"><apply id="S5.T2.3.3.2.m1.1.1.cmml" xref="S5.T2.3.3.2.m1.1.1"><minus id="S5.T2.3.3.2.m1.1.1.1.cmml" xref="S5.T2.3.3.2.m1.1.1"></minus><apply id="S5.T2.3.3.2.m1.1.1.2.cmml" xref="S5.T2.3.3.2.m1.1.1.2"><csymbol cd="latexml" id="S5.T2.3.3.2.m1.1.1.2.1.cmml" xref="S5.T2.3.3.2.m1.1.1.2.1">percent</csymbol><cn id="S5.T2.3.3.2.m1.1.1.2.2.cmml" type="float" xref="S5.T2.3.3.2.m1.1.1.2.2">0.7</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.2.m1.1c">-0.7\%</annotation><annotation encoding="application/x-llamapun" id="S5.T2.3.3.2.m1.1d">- 0.7 %</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T2.5.5.3">No hard negatives</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T2.4.4.1"><math alttext="-5.4\%" class="ltx_Math" display="inline" id="S5.T2.4.4.1.m1.1"><semantics id="S5.T2.4.4.1.m1.1a"><mrow id="S5.T2.4.4.1.m1.1.1" xref="S5.T2.4.4.1.m1.1.1.cmml"><mo id="S5.T2.4.4.1.m1.1.1a" xref="S5.T2.4.4.1.m1.1.1.cmml">âˆ’</mo><mrow id="S5.T2.4.4.1.m1.1.1.2" xref="S5.T2.4.4.1.m1.1.1.2.cmml"><mn id="S5.T2.4.4.1.m1.1.1.2.2" xref="S5.T2.4.4.1.m1.1.1.2.2.cmml">5.4</mn><mo id="S5.T2.4.4.1.m1.1.1.2.1" xref="S5.T2.4.4.1.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.1.m1.1b"><apply id="S5.T2.4.4.1.m1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1"><minus id="S5.T2.4.4.1.m1.1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1"></minus><apply id="S5.T2.4.4.1.m1.1.1.2.cmml" xref="S5.T2.4.4.1.m1.1.1.2"><csymbol cd="latexml" id="S5.T2.4.4.1.m1.1.1.2.1.cmml" xref="S5.T2.4.4.1.m1.1.1.2.1">percent</csymbol><cn id="S5.T2.4.4.1.m1.1.1.2.2.cmml" type="float" xref="S5.T2.4.4.1.m1.1.1.2.2">5.4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.1.m1.1c">-5.4\%</annotation><annotation encoding="application/x-llamapun" id="S5.T2.4.4.1.m1.1d">- 5.4 %</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T2.5.5.2"><math alttext="-6.3\%" class="ltx_Math" display="inline" id="S5.T2.5.5.2.m1.1"><semantics id="S5.T2.5.5.2.m1.1a"><mrow id="S5.T2.5.5.2.m1.1.1" xref="S5.T2.5.5.2.m1.1.1.cmml"><mo id="S5.T2.5.5.2.m1.1.1a" xref="S5.T2.5.5.2.m1.1.1.cmml">âˆ’</mo><mrow id="S5.T2.5.5.2.m1.1.1.2" xref="S5.T2.5.5.2.m1.1.1.2.cmml"><mn id="S5.T2.5.5.2.m1.1.1.2.2" xref="S5.T2.5.5.2.m1.1.1.2.2.cmml">6.3</mn><mo id="S5.T2.5.5.2.m1.1.1.2.1" xref="S5.T2.5.5.2.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.2.m1.1b"><apply id="S5.T2.5.5.2.m1.1.1.cmml" xref="S5.T2.5.5.2.m1.1.1"><minus id="S5.T2.5.5.2.m1.1.1.1.cmml" xref="S5.T2.5.5.2.m1.1.1"></minus><apply id="S5.T2.5.5.2.m1.1.1.2.cmml" xref="S5.T2.5.5.2.m1.1.1.2"><csymbol cd="latexml" id="S5.T2.5.5.2.m1.1.1.2.1.cmml" xref="S5.T2.5.5.2.m1.1.1.2.1">percent</csymbol><cn id="S5.T2.5.5.2.m1.1.1.2.2.cmml" type="float" xref="S5.T2.5.5.2.m1.1.1.2.2">6.3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.2.m1.1c">-6.3\%</annotation><annotation encoding="application/x-llamapun" id="S5.T2.5.5.2.m1.1d">- 6.3 %</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S5.T2.7.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T2.7.7.3">Only positive inputs</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T2.6.6.1"><math alttext="-0.6\%" class="ltx_Math" display="inline" id="S5.T2.6.6.1.m1.1"><semantics id="S5.T2.6.6.1.m1.1a"><mrow id="S5.T2.6.6.1.m1.1.1" xref="S5.T2.6.6.1.m1.1.1.cmml"><mo id="S5.T2.6.6.1.m1.1.1a" xref="S5.T2.6.6.1.m1.1.1.cmml">âˆ’</mo><mrow id="S5.T2.6.6.1.m1.1.1.2" xref="S5.T2.6.6.1.m1.1.1.2.cmml"><mn id="S5.T2.6.6.1.m1.1.1.2.2" xref="S5.T2.6.6.1.m1.1.1.2.2.cmml">0.6</mn><mo id="S5.T2.6.6.1.m1.1.1.2.1" xref="S5.T2.6.6.1.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.6.6.1.m1.1b"><apply id="S5.T2.6.6.1.m1.1.1.cmml" xref="S5.T2.6.6.1.m1.1.1"><minus id="S5.T2.6.6.1.m1.1.1.1.cmml" xref="S5.T2.6.6.1.m1.1.1"></minus><apply id="S5.T2.6.6.1.m1.1.1.2.cmml" xref="S5.T2.6.6.1.m1.1.1.2"><csymbol cd="latexml" id="S5.T2.6.6.1.m1.1.1.2.1.cmml" xref="S5.T2.6.6.1.m1.1.1.2.1">percent</csymbol><cn id="S5.T2.6.6.1.m1.1.1.2.2.cmml" type="float" xref="S5.T2.6.6.1.m1.1.1.2.2">0.6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.6.1.m1.1c">-0.6\%</annotation><annotation encoding="application/x-llamapun" id="S5.T2.6.6.1.m1.1d">- 0.6 %</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T2.7.7.2"><math alttext="-0.5\%" class="ltx_Math" display="inline" id="S5.T2.7.7.2.m1.1"><semantics id="S5.T2.7.7.2.m1.1a"><mrow id="S5.T2.7.7.2.m1.1.1" xref="S5.T2.7.7.2.m1.1.1.cmml"><mo id="S5.T2.7.7.2.m1.1.1a" xref="S5.T2.7.7.2.m1.1.1.cmml">âˆ’</mo><mrow id="S5.T2.7.7.2.m1.1.1.2" xref="S5.T2.7.7.2.m1.1.1.2.cmml"><mn id="S5.T2.7.7.2.m1.1.1.2.2" xref="S5.T2.7.7.2.m1.1.1.2.2.cmml">0.5</mn><mo id="S5.T2.7.7.2.m1.1.1.2.1" xref="S5.T2.7.7.2.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.7.7.2.m1.1b"><apply id="S5.T2.7.7.2.m1.1.1.cmml" xref="S5.T2.7.7.2.m1.1.1"><minus id="S5.T2.7.7.2.m1.1.1.1.cmml" xref="S5.T2.7.7.2.m1.1.1"></minus><apply id="S5.T2.7.7.2.m1.1.1.2.cmml" xref="S5.T2.7.7.2.m1.1.1.2"><csymbol cd="latexml" id="S5.T2.7.7.2.m1.1.1.2.1.cmml" xref="S5.T2.7.7.2.m1.1.1.2.1">percent</csymbol><cn id="S5.T2.7.7.2.m1.1.1.2.2.cmml" type="float" xref="S5.T2.7.7.2.m1.1.1.2.2">0.5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.7.7.2.m1.1c">-0.5\%</annotation><annotation encoding="application/x-llamapun" id="S5.T2.7.7.2.m1.1d">- 0.5 %</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S5.T2.9.9.3">Half max. seq. length</th>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T2.8.8.1"><math alttext="+0.1\%" class="ltx_Math" display="inline" id="S5.T2.8.8.1.m1.1"><semantics id="S5.T2.8.8.1.m1.1a"><mrow id="S5.T2.8.8.1.m1.1.1" xref="S5.T2.8.8.1.m1.1.1.cmml"><mo id="S5.T2.8.8.1.m1.1.1a" xref="S5.T2.8.8.1.m1.1.1.cmml">+</mo><mrow id="S5.T2.8.8.1.m1.1.1.2" xref="S5.T2.8.8.1.m1.1.1.2.cmml"><mn id="S5.T2.8.8.1.m1.1.1.2.2" xref="S5.T2.8.8.1.m1.1.1.2.2.cmml">0.1</mn><mo id="S5.T2.8.8.1.m1.1.1.2.1" xref="S5.T2.8.8.1.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.8.8.1.m1.1b"><apply id="S5.T2.8.8.1.m1.1.1.cmml" xref="S5.T2.8.8.1.m1.1.1"><plus id="S5.T2.8.8.1.m1.1.1.1.cmml" xref="S5.T2.8.8.1.m1.1.1"></plus><apply id="S5.T2.8.8.1.m1.1.1.2.cmml" xref="S5.T2.8.8.1.m1.1.1.2"><csymbol cd="latexml" id="S5.T2.8.8.1.m1.1.1.2.1.cmml" xref="S5.T2.8.8.1.m1.1.1.2.1">percent</csymbol><cn id="S5.T2.8.8.1.m1.1.1.2.2.cmml" type="float" xref="S5.T2.8.8.1.m1.1.1.2.2">0.1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.8.8.1.m1.1c">+0.1\%</annotation><annotation encoding="application/x-llamapun" id="S5.T2.8.8.1.m1.1d">+ 0.1 %</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="S5.T2.9.9.2"><math alttext="-0.2\%" class="ltx_Math" display="inline" id="S5.T2.9.9.2.m1.1"><semantics id="S5.T2.9.9.2.m1.1a"><mrow id="S5.T2.9.9.2.m1.1.1" xref="S5.T2.9.9.2.m1.1.1.cmml"><mo id="S5.T2.9.9.2.m1.1.1a" xref="S5.T2.9.9.2.m1.1.1.cmml">âˆ’</mo><mrow id="S5.T2.9.9.2.m1.1.1.2" xref="S5.T2.9.9.2.m1.1.1.2.cmml"><mn id="S5.T2.9.9.2.m1.1.1.2.2" xref="S5.T2.9.9.2.m1.1.1.2.2.cmml">0.2</mn><mo id="S5.T2.9.9.2.m1.1.1.2.1" xref="S5.T2.9.9.2.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.9.9.2.m1.1b"><apply id="S5.T2.9.9.2.m1.1.1.cmml" xref="S5.T2.9.9.2.m1.1.1"><minus id="S5.T2.9.9.2.m1.1.1.1.cmml" xref="S5.T2.9.9.2.m1.1.1"></minus><apply id="S5.T2.9.9.2.m1.1.1.2.cmml" xref="S5.T2.9.9.2.m1.1.1.2"><csymbol cd="latexml" id="S5.T2.9.9.2.m1.1.1.2.1.cmml" xref="S5.T2.9.9.2.m1.1.1.2.1">percent</csymbol><cn id="S5.T2.9.9.2.m1.1.1.2.2.cmml" type="float" xref="S5.T2.9.9.2.m1.1.1.2.2">0.2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.9.9.2.m1.1c">-0.2\%</annotation><annotation encoding="application/x-llamapun" id="S5.T2.9.9.2.m1.1d">- 0.2 %</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Ablation study</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.3">The overall lift in accuracy after incorporating negative feedback (<math alttext="6\%" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1"><semantics id="S5.SS1.p1.1.m1.1a"><mrow id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml"><mn id="S5.SS1.p1.1.m1.1.1.2" xref="S5.SS1.p1.1.m1.1.1.2.cmml">6</mn><mo id="S5.SS1.p1.1.m1.1.1.1" xref="S5.SS1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><apply id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.SS1.p1.1.m1.1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1.1">percent</csymbol><cn id="S5.SS1.p1.1.m1.1.1.2.cmml" type="integer" xref="S5.SS1.p1.1.m1.1.1.2">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">6\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.1d">6 %</annotation></semantics></math>) predominantly comes from the use of hard negatives in training (Table <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.T2" title="Table 2 â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">2</span></a>).
The lift from adding additional feedback types into the user inputs, although positive, is an order of magnitude smaller.
An additional benefit of including skips as inputs is in increasing the coverage, by <math alttext="50\%" class="ltx_Math" display="inline" id="S5.SS1.p1.2.m2.1"><semantics id="S5.SS1.p1.2.m2.1a"><mrow id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml"><mn id="S5.SS1.p1.2.m2.1.1.2" xref="S5.SS1.p1.2.m2.1.1.2.cmml">50</mn><mo id="S5.SS1.p1.2.m2.1.1.1" xref="S5.SS1.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><apply id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1"><csymbol cd="latexml" id="S5.SS1.p1.2.m2.1.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1.1">percent</csymbol><cn id="S5.SS1.p1.2.m2.1.1.2.cmml" type="integer" xref="S5.SS1.p1.2.m2.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">50\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.2.m2.1d">50 %</annotation></semantics></math> for Pandora and <math alttext="37\%" class="ltx_Math" display="inline" id="S5.SS1.p1.3.m3.1"><semantics id="S5.SS1.p1.3.m3.1a"><mrow id="S5.SS1.p1.3.m3.1.1" xref="S5.SS1.p1.3.m3.1.1.cmml"><mn id="S5.SS1.p1.3.m3.1.1.2" xref="S5.SS1.p1.3.m3.1.1.2.cmml">37</mn><mo id="S5.SS1.p1.3.m3.1.1.1" xref="S5.SS1.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.3.m3.1b"><apply id="S5.SS1.p1.3.m3.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1"><csymbol cd="latexml" id="S5.SS1.p1.3.m3.1.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1.1">percent</csymbol><cn id="S5.SS1.p1.3.m3.1.1.2.cmml" type="integer" xref="S5.SS1.p1.3.m3.1.1.2">37</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.3.m3.1c">37\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.3.m3.1d">37 %</annotation></semantics></math> for Spotify, of the model to skip-only users.
The benefit of positional embeddings is similar in magnitude for both datasets.
Halving the maximum sequence length slightly improves the Spotify accuracy while slightly reducing the Pandora accuracy; this may arise from differences between noisier implicit (â€˜playâ€™) and explicit (â€˜upâ€™) positive feedback.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Hard negative samples</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.4">Generally, a hard negative will have a higher score (and thus be harder to distinguish from the actual positive sample) than an unrelated random negative sample.
It is not necessarily the highest-scoring negative sample possible, as other songs (e.g. by the same artist as the positive sample that are not yet known to the user) may have higher scores, although we do not necessarily know if the user would like or dislike those songs.
This means that generally, for <math alttext="k\ll N" class="ltx_Math" display="inline" id="S5.SS2.p1.1.m1.1"><semantics id="S5.SS2.p1.1.m1.1a"><mrow id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mi id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml">k</mi><mo id="S5.SS2.p1.1.m1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.cmml">â‰ª</mo><mi id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1">much-less-than</csymbol><ci id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">ğ‘˜</ci><ci id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">k\ll N</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.1.m1.1d">italic_k â‰ª italic_N</annotation></semantics></math>, <math alttext="k" class="ltx_Math" display="inline" id="S5.SS2.p1.2.m2.1"><semantics id="S5.SS2.p1.2.m2.1a"><mi id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><ci id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.2.m2.1d">italic_k</annotation></semantics></math> random-chosen negatives are likely to all have lower scores than a hard negative.
Conversely, this means that we may estimate the value of a hard negative by comparing the performance of a model trained with <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.4.1">one</span> hard negative per positive sample to one that is trained with <math alttext="k" class="ltx_Math" display="inline" id="S5.SS2.p1.3.m3.1"><semantics id="S5.SS2.p1.3.m3.1a"><mi id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><ci id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.3.m3.1d">italic_k</annotation></semantics></math> randomly-selected negatives and using the top-scoring (i.e. hardest) one for computing the loss and comparing the test accuracy for different <math alttext="k" class="ltx_Math" display="inline" id="S5.SS2.p1.4.m4.1"><semantics id="S5.SS2.p1.4.m4.1a"><mi id="S5.SS2.p1.4.m4.1.1" xref="S5.SS2.p1.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.4.m4.1b"><ci id="S5.SS2.p1.4.m4.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.4.m4.1d">italic_k</annotation></semantics></math>.</p>
</div>
<figure class="ltx_figure" id="S5.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel" id="S5.F2.5">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="109" id="S5.F2.g1" src="extracted/5649672/figs/test_results_h.png" width="287"/><span class="ltx_ERROR undefined" id="S5.F2.5.1">\Description</span>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="S5.F2.2">Left: a chart showing the general increase in test accuracy as the proportion of hard negatives increases.
Right: a chart showing the increase with accuracy as more random negative samples are used up to 10<sup class="ltx_sup" id="S5.F2.2.1">3</sup> (10<sup class="ltx_sup" id="S5.F2.2.2">2</sup> for Piki), and then a decline for higher values.</p>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Left: The test accuracy generally increases with higher <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S5.F2.4.m1.1"><semantics id="S5.F2.4.m1.1b"><msub id="S5.F2.4.m1.1.1" xref="S5.F2.4.m1.1.1.cmml"><mi id="S5.F2.4.m1.1.1.2" xref="S5.F2.4.m1.1.1.2.cmml">p</mi><mrow id="S5.F2.4.m1.1.1.3" xref="S5.F2.4.m1.1.1.3.cmml"><mi id="S5.F2.4.m1.1.1.3.2" xref="S5.F2.4.m1.1.1.3.2.cmml">h</mi><mo id="S5.F2.4.m1.1.1.3.1" xref="S5.F2.4.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.F2.4.m1.1.1.3.3" xref="S5.F2.4.m1.1.1.3.3.cmml">a</mi><mo id="S5.F2.4.m1.1.1.3.1b" xref="S5.F2.4.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.F2.4.m1.1.1.3.4" xref="S5.F2.4.m1.1.1.3.4.cmml">r</mi><mo id="S5.F2.4.m1.1.1.3.1c" xref="S5.F2.4.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.F2.4.m1.1.1.3.5" xref="S5.F2.4.m1.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.F2.4.m1.1c"><apply id="S5.F2.4.m1.1.1.cmml" xref="S5.F2.4.m1.1.1"><csymbol cd="ambiguous" id="S5.F2.4.m1.1.1.1.cmml" xref="S5.F2.4.m1.1.1">subscript</csymbol><ci id="S5.F2.4.m1.1.1.2.cmml" xref="S5.F2.4.m1.1.1.2">ğ‘</ci><apply id="S5.F2.4.m1.1.1.3.cmml" xref="S5.F2.4.m1.1.1.3"><times id="S5.F2.4.m1.1.1.3.1.cmml" xref="S5.F2.4.m1.1.1.3.1"></times><ci id="S5.F2.4.m1.1.1.3.2.cmml" xref="S5.F2.4.m1.1.1.3.2">â„</ci><ci id="S5.F2.4.m1.1.1.3.3.cmml" xref="S5.F2.4.m1.1.1.3.3">ğ‘</ci><ci id="S5.F2.4.m1.1.1.3.4.cmml" xref="S5.F2.4.m1.1.1.3.4">ğ‘Ÿ</ci><ci id="S5.F2.4.m1.1.1.3.5.cmml" xref="S5.F2.4.m1.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F2.4.m1.1d">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S5.F2.4.m1.1e">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math>.
Right: Test accuracy increases with more batched random negatives, but using too many hurts performance. The maximum lift is also smaller than using a true hard negative sample.</figcaption>
</figure>
<section class="ltx_subsubsection" id="S5.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1. </span>Test accuracy</h4>
<div class="ltx_para" id="S5.SS2.SSS1.p1">
<p class="ltx_p" id="S5.SS2.SSS1.p1.4">We find that the test accuracy increases with higher <math alttext="k" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p1.1.m1.1"><semantics id="S5.SS2.SSS1.p1.1.m1.1a"><mi id="S5.SS2.SSS1.p1.1.m1.1.1" xref="S5.SS2.SSS1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.1.m1.1b"><ci id="S5.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS1.p1.1.m1.1d">italic_k</annotation></semantics></math>, but peaks around <math alttext="k=10^{3}" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p1.2.m2.1"><semantics id="S5.SS2.SSS1.p1.2.m2.1a"><mrow id="S5.SS2.SSS1.p1.2.m2.1.1" xref="S5.SS2.SSS1.p1.2.m2.1.1.cmml"><mi id="S5.SS2.SSS1.p1.2.m2.1.1.2" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.cmml">k</mi><mo id="S5.SS2.SSS1.p1.2.m2.1.1.1" xref="S5.SS2.SSS1.p1.2.m2.1.1.1.cmml">=</mo><msup id="S5.SS2.SSS1.p1.2.m2.1.1.3" xref="S5.SS2.SSS1.p1.2.m2.1.1.3.cmml"><mn id="S5.SS2.SSS1.p1.2.m2.1.1.3.2" xref="S5.SS2.SSS1.p1.2.m2.1.1.3.2.cmml">10</mn><mn id="S5.SS2.SSS1.p1.2.m2.1.1.3.3" xref="S5.SS2.SSS1.p1.2.m2.1.1.3.3.cmml">3</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.2.m2.1b"><apply id="S5.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1"><eq id="S5.SS2.SSS1.p1.2.m2.1.1.1.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.1"></eq><ci id="S5.SS2.SSS1.p1.2.m2.1.1.2.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2">ğ‘˜</ci><apply id="S5.SS2.SSS1.p1.2.m2.1.1.3.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S5.SS2.SSS1.p1.2.m2.1.1.3.1.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.3">superscript</csymbol><cn id="S5.SS2.SSS1.p1.2.m2.1.1.3.2.cmml" type="integer" xref="S5.SS2.SSS1.p1.2.m2.1.1.3.2">10</cn><cn id="S5.SS2.SSS1.p1.2.m2.1.1.3.3.cmml" type="integer" xref="S5.SS2.SSS1.p1.2.m2.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.2.m2.1c">k=10^{3}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS1.p1.2.m2.1d">italic_k = 10 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT</annotation></semantics></math> for the Pandora and Spotify datasets and <math alttext="k=10^{2}" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p1.3.m3.1"><semantics id="S5.SS2.SSS1.p1.3.m3.1a"><mrow id="S5.SS2.SSS1.p1.3.m3.1.1" xref="S5.SS2.SSS1.p1.3.m3.1.1.cmml"><mi id="S5.SS2.SSS1.p1.3.m3.1.1.2" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.cmml">k</mi><mo id="S5.SS2.SSS1.p1.3.m3.1.1.1" xref="S5.SS2.SSS1.p1.3.m3.1.1.1.cmml">=</mo><msup id="S5.SS2.SSS1.p1.3.m3.1.1.3" xref="S5.SS2.SSS1.p1.3.m3.1.1.3.cmml"><mn id="S5.SS2.SSS1.p1.3.m3.1.1.3.2" xref="S5.SS2.SSS1.p1.3.m3.1.1.3.2.cmml">10</mn><mn id="S5.SS2.SSS1.p1.3.m3.1.1.3.3" xref="S5.SS2.SSS1.p1.3.m3.1.1.3.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.3.m3.1b"><apply id="S5.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1"><eq id="S5.SS2.SSS1.p1.3.m3.1.1.1.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.1"></eq><ci id="S5.SS2.SSS1.p1.3.m3.1.1.2.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.2">ğ‘˜</ci><apply id="S5.SS2.SSS1.p1.3.m3.1.1.3.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S5.SS2.SSS1.p1.3.m3.1.1.3.1.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.3">superscript</csymbol><cn id="S5.SS2.SSS1.p1.3.m3.1.1.3.2.cmml" type="integer" xref="S5.SS2.SSS1.p1.3.m3.1.1.3.2">10</cn><cn id="S5.SS2.SSS1.p1.3.m3.1.1.3.3.cmml" type="integer" xref="S5.SS2.SSS1.p1.3.m3.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.3.m3.1c">k=10^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS1.p1.3.m3.1d">italic_k = 10 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> for the Piki dataset, and then drops beyond that (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.F2" title="Figure 2 â€£ 5.2. Hard negative samples â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">2</span></a>).
This suggests that with too many random negatives, the highest-scoring negative is potentially a false negative, which worsens model performance.
The Piki dataset has fewer songs by an order of magnitude, which may be why the <math alttext="k" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p1.4.m4.1"><semantics id="S5.SS2.SSS1.p1.4.m4.1a"><mi id="S5.SS2.SSS1.p1.4.m4.1.1" xref="S5.SS2.SSS1.p1.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.4.m4.1b"><ci id="S5.SS2.SSS1.p1.4.m4.1.1.cmml" xref="S5.SS2.SSS1.p1.4.m4.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS1.p1.4.m4.1d">italic_k</annotation></semantics></math> turning point is also an order of magnitude lower than the Spotify/Pandora datasets.
Important to note is that the best test accuracy using batched random negatives is still lower than the best test accuracy using explicit hard negative samples.
Further work can be done to implement other ways of distinguishing true and false negatives <cite class="ltx_cite ltx_citemacro_citep">(e.g. Weston etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib21" title="">2011</a>; Zhao etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib24" title="">2023</a>)</cite>.
For datasets that lack explicit negatives, more research should be done on how to determine if/how sampling too many negatives can hurt performance.
</p>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S5.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="214" id="S5.F3.g1" src="extracted/5649672/figs/mrr_epochs.png" width="180"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>For higher <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S5.F3.4.m1.1"><semantics id="S5.F3.4.m1.1b"><msub id="S5.F3.4.m1.1.1" xref="S5.F3.4.m1.1.1.cmml"><mi id="S5.F3.4.m1.1.1.2" xref="S5.F3.4.m1.1.1.2.cmml">p</mi><mrow id="S5.F3.4.m1.1.1.3" xref="S5.F3.4.m1.1.1.3.cmml"><mi id="S5.F3.4.m1.1.1.3.2" xref="S5.F3.4.m1.1.1.3.2.cmml">h</mi><mo id="S5.F3.4.m1.1.1.3.1" xref="S5.F3.4.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.F3.4.m1.1.1.3.3" xref="S5.F3.4.m1.1.1.3.3.cmml">a</mi><mo id="S5.F3.4.m1.1.1.3.1b" xref="S5.F3.4.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.F3.4.m1.1.1.3.4" xref="S5.F3.4.m1.1.1.3.4.cmml">r</mi><mo id="S5.F3.4.m1.1.1.3.1c" xref="S5.F3.4.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.F3.4.m1.1.1.3.5" xref="S5.F3.4.m1.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.F3.4.m1.1c"><apply id="S5.F3.4.m1.1.1.cmml" xref="S5.F3.4.m1.1.1"><csymbol cd="ambiguous" id="S5.F3.4.m1.1.1.1.cmml" xref="S5.F3.4.m1.1.1">subscript</csymbol><ci id="S5.F3.4.m1.1.1.2.cmml" xref="S5.F3.4.m1.1.1.2">ğ‘</ci><apply id="S5.F3.4.m1.1.1.3.cmml" xref="S5.F3.4.m1.1.1.3"><times id="S5.F3.4.m1.1.1.3.1.cmml" xref="S5.F3.4.m1.1.1.3.1"></times><ci id="S5.F3.4.m1.1.1.3.2.cmml" xref="S5.F3.4.m1.1.1.3.2">â„</ci><ci id="S5.F3.4.m1.1.1.3.3.cmml" xref="S5.F3.4.m1.1.1.3.3">ğ‘</ci><ci id="S5.F3.4.m1.1.1.3.4.cmml" xref="S5.F3.4.m1.1.1.3.4">ğ‘Ÿ</ci><ci id="S5.F3.4.m1.1.1.3.5.cmml" xref="S5.F3.4.m1.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F3.4.m1.1d">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S5.F3.4.m1.1e">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, training time tends to decrease (top), while the mean reciprocal ranks of both the positive (<math alttext="+" class="ltx_Math" display="inline" id="S5.F3.5.m2.1"><semantics id="S5.F3.5.m2.1b"><mo id="S5.F3.5.m2.1.1" xref="S5.F3.5.m2.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="S5.F3.5.m2.1c"><plus id="S5.F3.5.m2.1.1.cmml" xref="S5.F3.5.m2.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="S5.F3.5.m2.1d">+</annotation><annotation encoding="application/x-llamapun" id="S5.F3.5.m2.1e">+</annotation></semantics></math>) and negative (<math alttext="-" class="ltx_Math" display="inline" id="S5.F3.6.m3.1"><semantics id="S5.F3.6.m3.1b"><mo id="S5.F3.6.m3.1.1" xref="S5.F3.6.m3.1.1.cmml">âˆ’</mo><annotation-xml encoding="MathML-Content" id="S5.F3.6.m3.1c"><minus id="S5.F3.6.m3.1.1.cmml" xref="S5.F3.6.m3.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S5.F3.6.m3.1d">-</annotation><annotation encoding="application/x-llamapun" id="S5.F3.6.m3.1e">-</annotation></semantics></math>) samples generally decrease (bottom), even as the test accuracy increases (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.F2" title="Figure 2 â€£ 5.2. Hard negative samples â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">2</span></a>).
The Piki dataset is omitted as it is too small/noisy.
</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S5.F3.9">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S5.F3.8">Top: A chart showing how training time decreases when using higher <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S5.F3.7.m1.1"><semantics id="S5.F3.7.m1.1a"><msub id="S5.F3.7.m1.1.1" xref="S5.F3.7.m1.1.1.cmml"><mi id="S5.F3.7.m1.1.1.2" xref="S5.F3.7.m1.1.1.2.cmml">p</mi><mrow id="S5.F3.7.m1.1.1.3" xref="S5.F3.7.m1.1.1.3.cmml"><mi id="S5.F3.7.m1.1.1.3.2" xref="S5.F3.7.m1.1.1.3.2.cmml">h</mi><mo id="S5.F3.7.m1.1.1.3.1" xref="S5.F3.7.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.F3.7.m1.1.1.3.3" xref="S5.F3.7.m1.1.1.3.3.cmml">a</mi><mo id="S5.F3.7.m1.1.1.3.1a" xref="S5.F3.7.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.F3.7.m1.1.1.3.4" xref="S5.F3.7.m1.1.1.3.4.cmml">r</mi><mo id="S5.F3.7.m1.1.1.3.1b" xref="S5.F3.7.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.F3.7.m1.1.1.3.5" xref="S5.F3.7.m1.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.F3.7.m1.1b"><apply id="S5.F3.7.m1.1.1.cmml" xref="S5.F3.7.m1.1.1"><csymbol cd="ambiguous" id="S5.F3.7.m1.1.1.1.cmml" xref="S5.F3.7.m1.1.1">subscript</csymbol><ci id="S5.F3.7.m1.1.1.2.cmml" xref="S5.F3.7.m1.1.1.2">ğ‘</ci><apply id="S5.F3.7.m1.1.1.3.cmml" xref="S5.F3.7.m1.1.1.3"><times id="S5.F3.7.m1.1.1.3.1.cmml" xref="S5.F3.7.m1.1.1.3.1"></times><ci id="S5.F3.7.m1.1.1.3.2.cmml" xref="S5.F3.7.m1.1.1.3.2">â„</ci><ci id="S5.F3.7.m1.1.1.3.3.cmml" xref="S5.F3.7.m1.1.1.3.3">ğ‘</ci><ci id="S5.F3.7.m1.1.1.3.4.cmml" xref="S5.F3.7.m1.1.1.3.4">ğ‘Ÿ</ci><ci id="S5.F3.7.m1.1.1.3.5.cmml" xref="S5.F3.7.m1.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F3.7.m1.1c">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S5.F3.7.m1.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math>. Bottom: A chart showing how the ranks of both the positive and negative songs decline as <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S5.F3.8.m2.1"><semantics id="S5.F3.8.m2.1a"><msub id="S5.F3.8.m2.1.1" xref="S5.F3.8.m2.1.1.cmml"><mi id="S5.F3.8.m2.1.1.2" xref="S5.F3.8.m2.1.1.2.cmml">p</mi><mrow id="S5.F3.8.m2.1.1.3" xref="S5.F3.8.m2.1.1.3.cmml"><mi id="S5.F3.8.m2.1.1.3.2" xref="S5.F3.8.m2.1.1.3.2.cmml">h</mi><mo id="S5.F3.8.m2.1.1.3.1" xref="S5.F3.8.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.F3.8.m2.1.1.3.3" xref="S5.F3.8.m2.1.1.3.3.cmml">a</mi><mo id="S5.F3.8.m2.1.1.3.1a" xref="S5.F3.8.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.F3.8.m2.1.1.3.4" xref="S5.F3.8.m2.1.1.3.4.cmml">r</mi><mo id="S5.F3.8.m2.1.1.3.1b" xref="S5.F3.8.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.F3.8.m2.1.1.3.5" xref="S5.F3.8.m2.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.F3.8.m2.1b"><apply id="S5.F3.8.m2.1.1.cmml" xref="S5.F3.8.m2.1.1"><csymbol cd="ambiguous" id="S5.F3.8.m2.1.1.1.cmml" xref="S5.F3.8.m2.1.1">subscript</csymbol><ci id="S5.F3.8.m2.1.1.2.cmml" xref="S5.F3.8.m2.1.1.2">ğ‘</ci><apply id="S5.F3.8.m2.1.1.3.cmml" xref="S5.F3.8.m2.1.1.3"><times id="S5.F3.8.m2.1.1.3.1.cmml" xref="S5.F3.8.m2.1.1.3.1"></times><ci id="S5.F3.8.m2.1.1.3.2.cmml" xref="S5.F3.8.m2.1.1.3.2">â„</ci><ci id="S5.F3.8.m2.1.1.3.3.cmml" xref="S5.F3.8.m2.1.1.3.3">ğ‘</ci><ci id="S5.F3.8.m2.1.1.3.4.cmml" xref="S5.F3.8.m2.1.1.3.4">ğ‘Ÿ</ci><ci id="S5.F3.8.m2.1.1.3.5.cmml" xref="S5.F3.8.m2.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F3.8.m2.1c">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S5.F3.8.m2.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math> increases.</p>
</div>
</div>
</figure>
<div class="ltx_para" id="S5.SS2.SSS1.p2">
<p class="ltx_p" id="S5.SS2.SSS1.p2.5">The test accuracy is considerably higher, though quickly plateaus, for any <math alttext="p_{hard}\neq 0" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p2.1.m1.1"><semantics id="S5.SS2.SSS1.p2.1.m1.1a"><mrow id="S5.SS2.SSS1.p2.1.m1.1.1" xref="S5.SS2.SSS1.p2.1.m1.1.1.cmml"><msub id="S5.SS2.SSS1.p2.1.m1.1.1.2" xref="S5.SS2.SSS1.p2.1.m1.1.1.2.cmml"><mi id="S5.SS2.SSS1.p2.1.m1.1.1.2.2" xref="S5.SS2.SSS1.p2.1.m1.1.1.2.2.cmml">p</mi><mrow id="S5.SS2.SSS1.p2.1.m1.1.1.2.3" xref="S5.SS2.SSS1.p2.1.m1.1.1.2.3.cmml"><mi id="S5.SS2.SSS1.p2.1.m1.1.1.2.3.2" xref="S5.SS2.SSS1.p2.1.m1.1.1.2.3.2.cmml">h</mi><mo id="S5.SS2.SSS1.p2.1.m1.1.1.2.3.1" xref="S5.SS2.SSS1.p2.1.m1.1.1.2.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS1.p2.1.m1.1.1.2.3.3" xref="S5.SS2.SSS1.p2.1.m1.1.1.2.3.3.cmml">a</mi><mo id="S5.SS2.SSS1.p2.1.m1.1.1.2.3.1a" xref="S5.SS2.SSS1.p2.1.m1.1.1.2.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS1.p2.1.m1.1.1.2.3.4" xref="S5.SS2.SSS1.p2.1.m1.1.1.2.3.4.cmml">r</mi><mo id="S5.SS2.SSS1.p2.1.m1.1.1.2.3.1b" xref="S5.SS2.SSS1.p2.1.m1.1.1.2.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS1.p2.1.m1.1.1.2.3.5" xref="S5.SS2.SSS1.p2.1.m1.1.1.2.3.5.cmml">d</mi></mrow></msub><mo id="S5.SS2.SSS1.p2.1.m1.1.1.1" xref="S5.SS2.SSS1.p2.1.m1.1.1.1.cmml">â‰ </mo><mn id="S5.SS2.SSS1.p2.1.m1.1.1.3" xref="S5.SS2.SSS1.p2.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p2.1.m1.1b"><apply id="S5.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S5.SS2.SSS1.p2.1.m1.1.1"><neq id="S5.SS2.SSS1.p2.1.m1.1.1.1.cmml" xref="S5.SS2.SSS1.p2.1.m1.1.1.1"></neq><apply id="S5.SS2.SSS1.p2.1.m1.1.1.2.cmml" xref="S5.SS2.SSS1.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.SS2.SSS1.p2.1.m1.1.1.2.1.cmml" xref="S5.SS2.SSS1.p2.1.m1.1.1.2">subscript</csymbol><ci id="S5.SS2.SSS1.p2.1.m1.1.1.2.2.cmml" xref="S5.SS2.SSS1.p2.1.m1.1.1.2.2">ğ‘</ci><apply id="S5.SS2.SSS1.p2.1.m1.1.1.2.3.cmml" xref="S5.SS2.SSS1.p2.1.m1.1.1.2.3"><times id="S5.SS2.SSS1.p2.1.m1.1.1.2.3.1.cmml" xref="S5.SS2.SSS1.p2.1.m1.1.1.2.3.1"></times><ci id="S5.SS2.SSS1.p2.1.m1.1.1.2.3.2.cmml" xref="S5.SS2.SSS1.p2.1.m1.1.1.2.3.2">â„</ci><ci id="S5.SS2.SSS1.p2.1.m1.1.1.2.3.3.cmml" xref="S5.SS2.SSS1.p2.1.m1.1.1.2.3.3">ğ‘</ci><ci id="S5.SS2.SSS1.p2.1.m1.1.1.2.3.4.cmml" xref="S5.SS2.SSS1.p2.1.m1.1.1.2.3.4">ğ‘Ÿ</ci><ci id="S5.SS2.SSS1.p2.1.m1.1.1.2.3.5.cmml" xref="S5.SS2.SSS1.p2.1.m1.1.1.2.3.5">ğ‘‘</ci></apply></apply><cn id="S5.SS2.SSS1.p2.1.m1.1.1.3.cmml" type="integer" xref="S5.SS2.SSS1.p2.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p2.1.m1.1c">p_{hard}\neq 0</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS1.p2.1.m1.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT â‰  0</annotation></semantics></math> (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.F2" title="Figure 2 â€£ 5.2. Hard negative samples â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">2</span></a>).
This is likely because at each epoch, the specific <math alttext="p_{task}" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p2.2.m2.1"><semantics id="S5.SS2.SSS1.p2.2.m2.1a"><msub id="S5.SS2.SSS1.p2.2.m2.1.1" xref="S5.SS2.SSS1.p2.2.m2.1.1.cmml"><mi id="S5.SS2.SSS1.p2.2.m2.1.1.2" xref="S5.SS2.SSS1.p2.2.m2.1.1.2.cmml">p</mi><mrow id="S5.SS2.SSS1.p2.2.m2.1.1.3" xref="S5.SS2.SSS1.p2.2.m2.1.1.3.cmml"><mi id="S5.SS2.SSS1.p2.2.m2.1.1.3.2" xref="S5.SS2.SSS1.p2.2.m2.1.1.3.2.cmml">t</mi><mo id="S5.SS2.SSS1.p2.2.m2.1.1.3.1" xref="S5.SS2.SSS1.p2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS1.p2.2.m2.1.1.3.3" xref="S5.SS2.SSS1.p2.2.m2.1.1.3.3.cmml">a</mi><mo id="S5.SS2.SSS1.p2.2.m2.1.1.3.1a" xref="S5.SS2.SSS1.p2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS1.p2.2.m2.1.1.3.4" xref="S5.SS2.SSS1.p2.2.m2.1.1.3.4.cmml">s</mi><mo id="S5.SS2.SSS1.p2.2.m2.1.1.3.1b" xref="S5.SS2.SSS1.p2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS1.p2.2.m2.1.1.3.5" xref="S5.SS2.SSS1.p2.2.m2.1.1.3.5.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p2.2.m2.1b"><apply id="S5.SS2.SSS1.p2.2.m2.1.1.cmml" xref="S5.SS2.SSS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS1.p2.2.m2.1.1.1.cmml" xref="S5.SS2.SSS1.p2.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.SSS1.p2.2.m2.1.1.2.cmml" xref="S5.SS2.SSS1.p2.2.m2.1.1.2">ğ‘</ci><apply id="S5.SS2.SSS1.p2.2.m2.1.1.3.cmml" xref="S5.SS2.SSS1.p2.2.m2.1.1.3"><times id="S5.SS2.SSS1.p2.2.m2.1.1.3.1.cmml" xref="S5.SS2.SSS1.p2.2.m2.1.1.3.1"></times><ci id="S5.SS2.SSS1.p2.2.m2.1.1.3.2.cmml" xref="S5.SS2.SSS1.p2.2.m2.1.1.3.2">ğ‘¡</ci><ci id="S5.SS2.SSS1.p2.2.m2.1.1.3.3.cmml" xref="S5.SS2.SSS1.p2.2.m2.1.1.3.3">ğ‘</ci><ci id="S5.SS2.SSS1.p2.2.m2.1.1.3.4.cmml" xref="S5.SS2.SSS1.p2.2.m2.1.1.3.4">ğ‘ </ci><ci id="S5.SS2.SSS1.p2.2.m2.1.1.3.5.cmml" xref="S5.SS2.SSS1.p2.2.m2.1.1.3.5">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p2.2.m2.1c">p_{task}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS1.p2.2.m2.1d">italic_p start_POSTSUBSCRIPT italic_t italic_a italic_s italic_k end_POSTSUBSCRIPT</annotation></semantics></math> positions that see hard negatives are re-sampled with probability <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p2.3.m3.1"><semantics id="S5.SS2.SSS1.p2.3.m3.1a"><msub id="S5.SS2.SSS1.p2.3.m3.1.1" xref="S5.SS2.SSS1.p2.3.m3.1.1.cmml"><mi id="S5.SS2.SSS1.p2.3.m3.1.1.2" xref="S5.SS2.SSS1.p2.3.m3.1.1.2.cmml">p</mi><mrow id="S5.SS2.SSS1.p2.3.m3.1.1.3" xref="S5.SS2.SSS1.p2.3.m3.1.1.3.cmml"><mi id="S5.SS2.SSS1.p2.3.m3.1.1.3.2" xref="S5.SS2.SSS1.p2.3.m3.1.1.3.2.cmml">h</mi><mo id="S5.SS2.SSS1.p2.3.m3.1.1.3.1" xref="S5.SS2.SSS1.p2.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS1.p2.3.m3.1.1.3.3" xref="S5.SS2.SSS1.p2.3.m3.1.1.3.3.cmml">a</mi><mo id="S5.SS2.SSS1.p2.3.m3.1.1.3.1a" xref="S5.SS2.SSS1.p2.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS1.p2.3.m3.1.1.3.4" xref="S5.SS2.SSS1.p2.3.m3.1.1.3.4.cmml">r</mi><mo id="S5.SS2.SSS1.p2.3.m3.1.1.3.1b" xref="S5.SS2.SSS1.p2.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS1.p2.3.m3.1.1.3.5" xref="S5.SS2.SSS1.p2.3.m3.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p2.3.m3.1b"><apply id="S5.SS2.SSS1.p2.3.m3.1.1.cmml" xref="S5.SS2.SSS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS1.p2.3.m3.1.1.1.cmml" xref="S5.SS2.SSS1.p2.3.m3.1.1">subscript</csymbol><ci id="S5.SS2.SSS1.p2.3.m3.1.1.2.cmml" xref="S5.SS2.SSS1.p2.3.m3.1.1.2">ğ‘</ci><apply id="S5.SS2.SSS1.p2.3.m3.1.1.3.cmml" xref="S5.SS2.SSS1.p2.3.m3.1.1.3"><times id="S5.SS2.SSS1.p2.3.m3.1.1.3.1.cmml" xref="S5.SS2.SSS1.p2.3.m3.1.1.3.1"></times><ci id="S5.SS2.SSS1.p2.3.m3.1.1.3.2.cmml" xref="S5.SS2.SSS1.p2.3.m3.1.1.3.2">â„</ci><ci id="S5.SS2.SSS1.p2.3.m3.1.1.3.3.cmml" xref="S5.SS2.SSS1.p2.3.m3.1.1.3.3">ğ‘</ci><ci id="S5.SS2.SSS1.p2.3.m3.1.1.3.4.cmml" xref="S5.SS2.SSS1.p2.3.m3.1.1.3.4">ğ‘Ÿ</ci><ci id="S5.SS2.SSS1.p2.3.m3.1.1.3.5.cmml" xref="S5.SS2.SSS1.p2.3.m3.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p2.3.m3.1c">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS1.p2.3.m3.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math> and so even with lower <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p2.4.m4.1"><semantics id="S5.SS2.SSS1.p2.4.m4.1a"><msub id="S5.SS2.SSS1.p2.4.m4.1.1" xref="S5.SS2.SSS1.p2.4.m4.1.1.cmml"><mi id="S5.SS2.SSS1.p2.4.m4.1.1.2" xref="S5.SS2.SSS1.p2.4.m4.1.1.2.cmml">p</mi><mrow id="S5.SS2.SSS1.p2.4.m4.1.1.3" xref="S5.SS2.SSS1.p2.4.m4.1.1.3.cmml"><mi id="S5.SS2.SSS1.p2.4.m4.1.1.3.2" xref="S5.SS2.SSS1.p2.4.m4.1.1.3.2.cmml">h</mi><mo id="S5.SS2.SSS1.p2.4.m4.1.1.3.1" xref="S5.SS2.SSS1.p2.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS1.p2.4.m4.1.1.3.3" xref="S5.SS2.SSS1.p2.4.m4.1.1.3.3.cmml">a</mi><mo id="S5.SS2.SSS1.p2.4.m4.1.1.3.1a" xref="S5.SS2.SSS1.p2.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS1.p2.4.m4.1.1.3.4" xref="S5.SS2.SSS1.p2.4.m4.1.1.3.4.cmml">r</mi><mo id="S5.SS2.SSS1.p2.4.m4.1.1.3.1b" xref="S5.SS2.SSS1.p2.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS1.p2.4.m4.1.1.3.5" xref="S5.SS2.SSS1.p2.4.m4.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p2.4.m4.1b"><apply id="S5.SS2.SSS1.p2.4.m4.1.1.cmml" xref="S5.SS2.SSS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS1.p2.4.m4.1.1.1.cmml" xref="S5.SS2.SSS1.p2.4.m4.1.1">subscript</csymbol><ci id="S5.SS2.SSS1.p2.4.m4.1.1.2.cmml" xref="S5.SS2.SSS1.p2.4.m4.1.1.2">ğ‘</ci><apply id="S5.SS2.SSS1.p2.4.m4.1.1.3.cmml" xref="S5.SS2.SSS1.p2.4.m4.1.1.3"><times id="S5.SS2.SSS1.p2.4.m4.1.1.3.1.cmml" xref="S5.SS2.SSS1.p2.4.m4.1.1.3.1"></times><ci id="S5.SS2.SSS1.p2.4.m4.1.1.3.2.cmml" xref="S5.SS2.SSS1.p2.4.m4.1.1.3.2">â„</ci><ci id="S5.SS2.SSS1.p2.4.m4.1.1.3.3.cmml" xref="S5.SS2.SSS1.p2.4.m4.1.1.3.3">ğ‘</ci><ci id="S5.SS2.SSS1.p2.4.m4.1.1.3.4.cmml" xref="S5.SS2.SSS1.p2.4.m4.1.1.3.4">ğ‘Ÿ</ci><ci id="S5.SS2.SSS1.p2.4.m4.1.1.3.5.cmml" xref="S5.SS2.SSS1.p2.4.m4.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p2.4.m4.1c">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS1.p2.4.m4.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math> values, eventually all positions that have hard negatives will use them for some part of the training time.
However, higher <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p2.5.m5.1"><semantics id="S5.SS2.SSS1.p2.5.m5.1a"><msub id="S5.SS2.SSS1.p2.5.m5.1.1" xref="S5.SS2.SSS1.p2.5.m5.1.1.cmml"><mi id="S5.SS2.SSS1.p2.5.m5.1.1.2" xref="S5.SS2.SSS1.p2.5.m5.1.1.2.cmml">p</mi><mrow id="S5.SS2.SSS1.p2.5.m5.1.1.3" xref="S5.SS2.SSS1.p2.5.m5.1.1.3.cmml"><mi id="S5.SS2.SSS1.p2.5.m5.1.1.3.2" xref="S5.SS2.SSS1.p2.5.m5.1.1.3.2.cmml">h</mi><mo id="S5.SS2.SSS1.p2.5.m5.1.1.3.1" xref="S5.SS2.SSS1.p2.5.m5.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS1.p2.5.m5.1.1.3.3" xref="S5.SS2.SSS1.p2.5.m5.1.1.3.3.cmml">a</mi><mo id="S5.SS2.SSS1.p2.5.m5.1.1.3.1a" xref="S5.SS2.SSS1.p2.5.m5.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS1.p2.5.m5.1.1.3.4" xref="S5.SS2.SSS1.p2.5.m5.1.1.3.4.cmml">r</mi><mo id="S5.SS2.SSS1.p2.5.m5.1.1.3.1b" xref="S5.SS2.SSS1.p2.5.m5.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS1.p2.5.m5.1.1.3.5" xref="S5.SS2.SSS1.p2.5.m5.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p2.5.m5.1b"><apply id="S5.SS2.SSS1.p2.5.m5.1.1.cmml" xref="S5.SS2.SSS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS1.p2.5.m5.1.1.1.cmml" xref="S5.SS2.SSS1.p2.5.m5.1.1">subscript</csymbol><ci id="S5.SS2.SSS1.p2.5.m5.1.1.2.cmml" xref="S5.SS2.SSS1.p2.5.m5.1.1.2">ğ‘</ci><apply id="S5.SS2.SSS1.p2.5.m5.1.1.3.cmml" xref="S5.SS2.SSS1.p2.5.m5.1.1.3"><times id="S5.SS2.SSS1.p2.5.m5.1.1.3.1.cmml" xref="S5.SS2.SSS1.p2.5.m5.1.1.3.1"></times><ci id="S5.SS2.SSS1.p2.5.m5.1.1.3.2.cmml" xref="S5.SS2.SSS1.p2.5.m5.1.1.3.2">â„</ci><ci id="S5.SS2.SSS1.p2.5.m5.1.1.3.3.cmml" xref="S5.SS2.SSS1.p2.5.m5.1.1.3.3">ğ‘</ci><ci id="S5.SS2.SSS1.p2.5.m5.1.1.3.4.cmml" xref="S5.SS2.SSS1.p2.5.m5.1.1.3.4">ğ‘Ÿ</ci><ci id="S5.SS2.SSS1.p2.5.m5.1.1.3.5.cmml" xref="S5.SS2.SSS1.p2.5.m5.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p2.5.m5.1c">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS1.p2.5.m5.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math> values allow the model to use more of these per epoch, and hence the model can converge faster.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2. </span>Training time</h4>
<div class="ltx_para" id="S5.SS2.SSS2.p1">
<p class="ltx_p" id="S5.SS2.SSS2.p1.3">We find that the number of epochs necessary for convergence reduces considerably for higher values of <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S5.SS2.SSS2.p1.1.m1.1"><semantics id="S5.SS2.SSS2.p1.1.m1.1a"><msub id="S5.SS2.SSS2.p1.1.m1.1.1" xref="S5.SS2.SSS2.p1.1.m1.1.1.cmml"><mi id="S5.SS2.SSS2.p1.1.m1.1.1.2" xref="S5.SS2.SSS2.p1.1.m1.1.1.2.cmml">p</mi><mrow id="S5.SS2.SSS2.p1.1.m1.1.1.3" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.cmml"><mi id="S5.SS2.SSS2.p1.1.m1.1.1.3.2" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.2.cmml">h</mi><mo id="S5.SS2.SSS2.p1.1.m1.1.1.3.1" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS2.p1.1.m1.1.1.3.3" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.3.cmml">a</mi><mo id="S5.SS2.SSS2.p1.1.m1.1.1.3.1a" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS2.p1.1.m1.1.1.3.4" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.4.cmml">r</mi><mo id="S5.SS2.SSS2.p1.1.m1.1.1.3.1b" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS2.p1.1.m1.1.1.3.5" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p1.1.m1.1b"><apply id="S5.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.SSS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1.2">ğ‘</ci><apply id="S5.SS2.SSS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1.3"><times id="S5.SS2.SSS2.p1.1.m1.1.1.3.1.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.1"></times><ci id="S5.SS2.SSS2.p1.1.m1.1.1.3.2.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.2">â„</ci><ci id="S5.SS2.SSS2.p1.1.m1.1.1.3.3.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.3">ğ‘</ci><ci id="S5.SS2.SSS2.p1.1.m1.1.1.3.4.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.4">ğ‘Ÿ</ci><ci id="S5.SS2.SSS2.p1.1.m1.1.1.3.5.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p1.1.m1.1c">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS2.p1.1.m1.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math> (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.F3" title="Figure 3 â€£ 5.2.1. Test accuracy â€£ 5.2. Hard negative samples â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">3</span></a>). This is less noticeable/relevant for the Piki dataset because it is so small.
Weighing this against the plateau in accuracy for higher <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S5.SS2.SSS2.p1.2.m2.1"><semantics id="S5.SS2.SSS2.p1.2.m2.1a"><msub id="S5.SS2.SSS2.p1.2.m2.1.1" xref="S5.SS2.SSS2.p1.2.m2.1.1.cmml"><mi id="S5.SS2.SSS2.p1.2.m2.1.1.2" xref="S5.SS2.SSS2.p1.2.m2.1.1.2.cmml">p</mi><mrow id="S5.SS2.SSS2.p1.2.m2.1.1.3" xref="S5.SS2.SSS2.p1.2.m2.1.1.3.cmml"><mi id="S5.SS2.SSS2.p1.2.m2.1.1.3.2" xref="S5.SS2.SSS2.p1.2.m2.1.1.3.2.cmml">h</mi><mo id="S5.SS2.SSS2.p1.2.m2.1.1.3.1" xref="S5.SS2.SSS2.p1.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS2.p1.2.m2.1.1.3.3" xref="S5.SS2.SSS2.p1.2.m2.1.1.3.3.cmml">a</mi><mo id="S5.SS2.SSS2.p1.2.m2.1.1.3.1a" xref="S5.SS2.SSS2.p1.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS2.p1.2.m2.1.1.3.4" xref="S5.SS2.SSS2.p1.2.m2.1.1.3.4.cmml">r</mi><mo id="S5.SS2.SSS2.p1.2.m2.1.1.3.1b" xref="S5.SS2.SSS2.p1.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS2.p1.2.m2.1.1.3.5" xref="S5.SS2.SSS2.p1.2.m2.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p1.2.m2.1b"><apply id="S5.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS2.p1.2.m2.1.1.1.cmml" xref="S5.SS2.SSS2.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.SSS2.p1.2.m2.1.1.2.cmml" xref="S5.SS2.SSS2.p1.2.m2.1.1.2">ğ‘</ci><apply id="S5.SS2.SSS2.p1.2.m2.1.1.3.cmml" xref="S5.SS2.SSS2.p1.2.m2.1.1.3"><times id="S5.SS2.SSS2.p1.2.m2.1.1.3.1.cmml" xref="S5.SS2.SSS2.p1.2.m2.1.1.3.1"></times><ci id="S5.SS2.SSS2.p1.2.m2.1.1.3.2.cmml" xref="S5.SS2.SSS2.p1.2.m2.1.1.3.2">â„</ci><ci id="S5.SS2.SSS2.p1.2.m2.1.1.3.3.cmml" xref="S5.SS2.SSS2.p1.2.m2.1.1.3.3">ğ‘</ci><ci id="S5.SS2.SSS2.p1.2.m2.1.1.3.4.cmml" xref="S5.SS2.SSS2.p1.2.m2.1.1.3.4">ğ‘Ÿ</ci><ci id="S5.SS2.SSS2.p1.2.m2.1.1.3.5.cmml" xref="S5.SS2.SSS2.p1.2.m2.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p1.2.m2.1c">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS2.p1.2.m2.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, this suggests that higher values of <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S5.SS2.SSS2.p1.3.m3.1"><semantics id="S5.SS2.SSS2.p1.3.m3.1a"><msub id="S5.SS2.SSS2.p1.3.m3.1.1" xref="S5.SS2.SSS2.p1.3.m3.1.1.cmml"><mi id="S5.SS2.SSS2.p1.3.m3.1.1.2" xref="S5.SS2.SSS2.p1.3.m3.1.1.2.cmml">p</mi><mrow id="S5.SS2.SSS2.p1.3.m3.1.1.3" xref="S5.SS2.SSS2.p1.3.m3.1.1.3.cmml"><mi id="S5.SS2.SSS2.p1.3.m3.1.1.3.2" xref="S5.SS2.SSS2.p1.3.m3.1.1.3.2.cmml">h</mi><mo id="S5.SS2.SSS2.p1.3.m3.1.1.3.1" xref="S5.SS2.SSS2.p1.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS2.p1.3.m3.1.1.3.3" xref="S5.SS2.SSS2.p1.3.m3.1.1.3.3.cmml">a</mi><mo id="S5.SS2.SSS2.p1.3.m3.1.1.3.1a" xref="S5.SS2.SSS2.p1.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS2.p1.3.m3.1.1.3.4" xref="S5.SS2.SSS2.p1.3.m3.1.1.3.4.cmml">r</mi><mo id="S5.SS2.SSS2.p1.3.m3.1.1.3.1b" xref="S5.SS2.SSS2.p1.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS2.p1.3.m3.1.1.3.5" xref="S5.SS2.SSS2.p1.3.m3.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p1.3.m3.1b"><apply id="S5.SS2.SSS2.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS2.p1.3.m3.1.1.1.cmml" xref="S5.SS2.SSS2.p1.3.m3.1.1">subscript</csymbol><ci id="S5.SS2.SSS2.p1.3.m3.1.1.2.cmml" xref="S5.SS2.SSS2.p1.3.m3.1.1.2">ğ‘</ci><apply id="S5.SS2.SSS2.p1.3.m3.1.1.3.cmml" xref="S5.SS2.SSS2.p1.3.m3.1.1.3"><times id="S5.SS2.SSS2.p1.3.m3.1.1.3.1.cmml" xref="S5.SS2.SSS2.p1.3.m3.1.1.3.1"></times><ci id="S5.SS2.SSS2.p1.3.m3.1.1.3.2.cmml" xref="S5.SS2.SSS2.p1.3.m3.1.1.3.2">â„</ci><ci id="S5.SS2.SSS2.p1.3.m3.1.1.3.3.cmml" xref="S5.SS2.SSS2.p1.3.m3.1.1.3.3">ğ‘</ci><ci id="S5.SS2.SSS2.p1.3.m3.1.1.3.4.cmml" xref="S5.SS2.SSS2.p1.3.m3.1.1.3.4">ğ‘Ÿ</ci><ci id="S5.SS2.SSS2.p1.3.m3.1.1.3.5.cmml" xref="S5.SS2.SSS2.p1.3.m3.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p1.3.m3.1c">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS2.p1.3.m3.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math> are better.
However, this may lead to poorer embeddings and hence poorer recommendation quality for more tail-end songs, which are more rarely encountered (as random negative samples) in the training set.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.3. </span>Relation to other metrics</h4>
<div class="ltx_para" id="S5.SS2.SSS3.p1">
<p class="ltx_p" id="S5.SS2.SSS3.p1.1">The prediction task of comparing a userâ€™s positive and negative feedback is generally much harder than comparing a userâ€™s positive feedback to a random negative sample.
The latter is somewhat connected to true positive metrics such as recall or the mean reciprocal rank (MRR).
However, in our use case, the songs eligible to be ranked on a given station are generally similarly-popular songs, whether positive or negative.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS3.p2">
<p class="ltx_p" id="S5.SS2.SSS3.p2.4">The MRR (and the recall) of both the â€˜upâ€™ and â€˜downâ€™ samples decrease with higher <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S5.SS2.SSS3.p2.1.m1.1"><semantics id="S5.SS2.SSS3.p2.1.m1.1a"><msub id="S5.SS2.SSS3.p2.1.m1.1.1" xref="S5.SS2.SSS3.p2.1.m1.1.1.cmml"><mi id="S5.SS2.SSS3.p2.1.m1.1.1.2" xref="S5.SS2.SSS3.p2.1.m1.1.1.2.cmml">p</mi><mrow id="S5.SS2.SSS3.p2.1.m1.1.1.3" xref="S5.SS2.SSS3.p2.1.m1.1.1.3.cmml"><mi id="S5.SS2.SSS3.p2.1.m1.1.1.3.2" xref="S5.SS2.SSS3.p2.1.m1.1.1.3.2.cmml">h</mi><mo id="S5.SS2.SSS3.p2.1.m1.1.1.3.1" xref="S5.SS2.SSS3.p2.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p2.1.m1.1.1.3.3" xref="S5.SS2.SSS3.p2.1.m1.1.1.3.3.cmml">a</mi><mo id="S5.SS2.SSS3.p2.1.m1.1.1.3.1a" xref="S5.SS2.SSS3.p2.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p2.1.m1.1.1.3.4" xref="S5.SS2.SSS3.p2.1.m1.1.1.3.4.cmml">r</mi><mo id="S5.SS2.SSS3.p2.1.m1.1.1.3.1b" xref="S5.SS2.SSS3.p2.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p2.1.m1.1.1.3.5" xref="S5.SS2.SSS3.p2.1.m1.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p2.1.m1.1b"><apply id="S5.SS2.SSS3.p2.1.m1.1.1.cmml" xref="S5.SS2.SSS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS3.p2.1.m1.1.1.1.cmml" xref="S5.SS2.SSS3.p2.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.SSS3.p2.1.m1.1.1.2.cmml" xref="S5.SS2.SSS3.p2.1.m1.1.1.2">ğ‘</ci><apply id="S5.SS2.SSS3.p2.1.m1.1.1.3.cmml" xref="S5.SS2.SSS3.p2.1.m1.1.1.3"><times id="S5.SS2.SSS3.p2.1.m1.1.1.3.1.cmml" xref="S5.SS2.SSS3.p2.1.m1.1.1.3.1"></times><ci id="S5.SS2.SSS3.p2.1.m1.1.1.3.2.cmml" xref="S5.SS2.SSS3.p2.1.m1.1.1.3.2">â„</ci><ci id="S5.SS2.SSS3.p2.1.m1.1.1.3.3.cmml" xref="S5.SS2.SSS3.p2.1.m1.1.1.3.3">ğ‘</ci><ci id="S5.SS2.SSS3.p2.1.m1.1.1.3.4.cmml" xref="S5.SS2.SSS3.p2.1.m1.1.1.3.4">ğ‘Ÿ</ci><ci id="S5.SS2.SSS3.p2.1.m1.1.1.3.5.cmml" xref="S5.SS2.SSS3.p2.1.m1.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p2.1.m1.1c">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS3.p2.1.m1.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, though the â€˜downâ€™ samples decrease faster than the â€˜upâ€™ samples (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.F3" title="Figure 3 â€£ 5.2.1. Test accuracy â€£ 5.2. Hard negative samples â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">3</span></a>), such that the overall test accuracy increases (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.F2" title="Figure 2 â€£ 5.2. Hard negative samples â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">2</span></a>).
The prediction accuracy is somewhat connected to the distance between the positive and negative ranks.
This can be interpreted as higher <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S5.SS2.SSS3.p2.2.m2.1"><semantics id="S5.SS2.SSS3.p2.2.m2.1a"><msub id="S5.SS2.SSS3.p2.2.m2.1.1" xref="S5.SS2.SSS3.p2.2.m2.1.1.cmml"><mi id="S5.SS2.SSS3.p2.2.m2.1.1.2" xref="S5.SS2.SSS3.p2.2.m2.1.1.2.cmml">p</mi><mrow id="S5.SS2.SSS3.p2.2.m2.1.1.3" xref="S5.SS2.SSS3.p2.2.m2.1.1.3.cmml"><mi id="S5.SS2.SSS3.p2.2.m2.1.1.3.2" xref="S5.SS2.SSS3.p2.2.m2.1.1.3.2.cmml">h</mi><mo id="S5.SS2.SSS3.p2.2.m2.1.1.3.1" xref="S5.SS2.SSS3.p2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p2.2.m2.1.1.3.3" xref="S5.SS2.SSS3.p2.2.m2.1.1.3.3.cmml">a</mi><mo id="S5.SS2.SSS3.p2.2.m2.1.1.3.1a" xref="S5.SS2.SSS3.p2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p2.2.m2.1.1.3.4" xref="S5.SS2.SSS3.p2.2.m2.1.1.3.4.cmml">r</mi><mo id="S5.SS2.SSS3.p2.2.m2.1.1.3.1b" xref="S5.SS2.SSS3.p2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p2.2.m2.1.1.3.5" xref="S5.SS2.SSS3.p2.2.m2.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p2.2.m2.1b"><apply id="S5.SS2.SSS3.p2.2.m2.1.1.cmml" xref="S5.SS2.SSS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS3.p2.2.m2.1.1.1.cmml" xref="S5.SS2.SSS3.p2.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.SSS3.p2.2.m2.1.1.2.cmml" xref="S5.SS2.SSS3.p2.2.m2.1.1.2">ğ‘</ci><apply id="S5.SS2.SSS3.p2.2.m2.1.1.3.cmml" xref="S5.SS2.SSS3.p2.2.m2.1.1.3"><times id="S5.SS2.SSS3.p2.2.m2.1.1.3.1.cmml" xref="S5.SS2.SSS3.p2.2.m2.1.1.3.1"></times><ci id="S5.SS2.SSS3.p2.2.m2.1.1.3.2.cmml" xref="S5.SS2.SSS3.p2.2.m2.1.1.3.2">â„</ci><ci id="S5.SS2.SSS3.p2.2.m2.1.1.3.3.cmml" xref="S5.SS2.SSS3.p2.2.m2.1.1.3.3">ğ‘</ci><ci id="S5.SS2.SSS3.p2.2.m2.1.1.3.4.cmml" xref="S5.SS2.SSS3.p2.2.m2.1.1.3.4">ğ‘Ÿ</ci><ci id="S5.SS2.SSS3.p2.2.m2.1.1.3.5.cmml" xref="S5.SS2.SSS3.p2.2.m2.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p2.2.m2.1c">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS3.p2.2.m2.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math> attempting to minimize false positives (at the cost of fewer true positives), or inversely, that lower <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S5.SS2.SSS3.p2.3.m3.1"><semantics id="S5.SS2.SSS3.p2.3.m3.1a"><msub id="S5.SS2.SSS3.p2.3.m3.1.1" xref="S5.SS2.SSS3.p2.3.m3.1.1.cmml"><mi id="S5.SS2.SSS3.p2.3.m3.1.1.2" xref="S5.SS2.SSS3.p2.3.m3.1.1.2.cmml">p</mi><mrow id="S5.SS2.SSS3.p2.3.m3.1.1.3" xref="S5.SS2.SSS3.p2.3.m3.1.1.3.cmml"><mi id="S5.SS2.SSS3.p2.3.m3.1.1.3.2" xref="S5.SS2.SSS3.p2.3.m3.1.1.3.2.cmml">h</mi><mo id="S5.SS2.SSS3.p2.3.m3.1.1.3.1" xref="S5.SS2.SSS3.p2.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p2.3.m3.1.1.3.3" xref="S5.SS2.SSS3.p2.3.m3.1.1.3.3.cmml">a</mi><mo id="S5.SS2.SSS3.p2.3.m3.1.1.3.1a" xref="S5.SS2.SSS3.p2.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p2.3.m3.1.1.3.4" xref="S5.SS2.SSS3.p2.3.m3.1.1.3.4.cmml">r</mi><mo id="S5.SS2.SSS3.p2.3.m3.1.1.3.1b" xref="S5.SS2.SSS3.p2.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p2.3.m3.1.1.3.5" xref="S5.SS2.SSS3.p2.3.m3.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p2.3.m3.1b"><apply id="S5.SS2.SSS3.p2.3.m3.1.1.cmml" xref="S5.SS2.SSS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS3.p2.3.m3.1.1.1.cmml" xref="S5.SS2.SSS3.p2.3.m3.1.1">subscript</csymbol><ci id="S5.SS2.SSS3.p2.3.m3.1.1.2.cmml" xref="S5.SS2.SSS3.p2.3.m3.1.1.2">ğ‘</ci><apply id="S5.SS2.SSS3.p2.3.m3.1.1.3.cmml" xref="S5.SS2.SSS3.p2.3.m3.1.1.3"><times id="S5.SS2.SSS3.p2.3.m3.1.1.3.1.cmml" xref="S5.SS2.SSS3.p2.3.m3.1.1.3.1"></times><ci id="S5.SS2.SSS3.p2.3.m3.1.1.3.2.cmml" xref="S5.SS2.SSS3.p2.3.m3.1.1.3.2">â„</ci><ci id="S5.SS2.SSS3.p2.3.m3.1.1.3.3.cmml" xref="S5.SS2.SSS3.p2.3.m3.1.1.3.3">ğ‘</ci><ci id="S5.SS2.SSS3.p2.3.m3.1.1.3.4.cmml" xref="S5.SS2.SSS3.p2.3.m3.1.1.3.4">ğ‘Ÿ</ci><ci id="S5.SS2.SSS3.p2.3.m3.1.1.3.5.cmml" xref="S5.SS2.SSS3.p2.3.m3.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p2.3.m3.1c">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS3.p2.3.m3.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math> maximizes true positives but also increases false positives.
Similar to Mena-Maldonado et al. (2020), we find that reducing false positives with a higher <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S5.SS2.SSS3.p2.4.m4.1"><semantics id="S5.SS2.SSS3.p2.4.m4.1a"><msub id="S5.SS2.SSS3.p2.4.m4.1.1" xref="S5.SS2.SSS3.p2.4.m4.1.1.cmml"><mi id="S5.SS2.SSS3.p2.4.m4.1.1.2" xref="S5.SS2.SSS3.p2.4.m4.1.1.2.cmml">p</mi><mrow id="S5.SS2.SSS3.p2.4.m4.1.1.3" xref="S5.SS2.SSS3.p2.4.m4.1.1.3.cmml"><mi id="S5.SS2.SSS3.p2.4.m4.1.1.3.2" xref="S5.SS2.SSS3.p2.4.m4.1.1.3.2.cmml">h</mi><mo id="S5.SS2.SSS3.p2.4.m4.1.1.3.1" xref="S5.SS2.SSS3.p2.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p2.4.m4.1.1.3.3" xref="S5.SS2.SSS3.p2.4.m4.1.1.3.3.cmml">a</mi><mo id="S5.SS2.SSS3.p2.4.m4.1.1.3.1a" xref="S5.SS2.SSS3.p2.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p2.4.m4.1.1.3.4" xref="S5.SS2.SSS3.p2.4.m4.1.1.3.4.cmml">r</mi><mo id="S5.SS2.SSS3.p2.4.m4.1.1.3.1b" xref="S5.SS2.SSS3.p2.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p2.4.m4.1.1.3.5" xref="S5.SS2.SSS3.p2.4.m4.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p2.4.m4.1b"><apply id="S5.SS2.SSS3.p2.4.m4.1.1.cmml" xref="S5.SS2.SSS3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS3.p2.4.m4.1.1.1.cmml" xref="S5.SS2.SSS3.p2.4.m4.1.1">subscript</csymbol><ci id="S5.SS2.SSS3.p2.4.m4.1.1.2.cmml" xref="S5.SS2.SSS3.p2.4.m4.1.1.2">ğ‘</ci><apply id="S5.SS2.SSS3.p2.4.m4.1.1.3.cmml" xref="S5.SS2.SSS3.p2.4.m4.1.1.3"><times id="S5.SS2.SSS3.p2.4.m4.1.1.3.1.cmml" xref="S5.SS2.SSS3.p2.4.m4.1.1.3.1"></times><ci id="S5.SS2.SSS3.p2.4.m4.1.1.3.2.cmml" xref="S5.SS2.SSS3.p2.4.m4.1.1.3.2">â„</ci><ci id="S5.SS2.SSS3.p2.4.m4.1.1.3.3.cmml" xref="S5.SS2.SSS3.p2.4.m4.1.1.3.3">ğ‘</ci><ci id="S5.SS2.SSS3.p2.4.m4.1.1.3.4.cmml" xref="S5.SS2.SSS3.p2.4.m4.1.1.3.4">ğ‘Ÿ</ci><ci id="S5.SS2.SSS3.p2.4.m4.1.1.3.5.cmml" xref="S5.SS2.SSS3.p2.4.m4.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p2.4.m4.1c">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS3.p2.4.m4.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math> also leads to generally less-popular songs being recommended <cite class="ltx_cite ltx_citemacro_citep">(Mena-Maldonado etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib10" title="">2020</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS3.p3">
<p class="ltx_p" id="S5.SS2.SSS3.p3.3">For candidate generation, it may be better to use a low <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S5.SS2.SSS3.p3.1.m1.1"><semantics id="S5.SS2.SSS3.p3.1.m1.1a"><msub id="S5.SS2.SSS3.p3.1.m1.1.1" xref="S5.SS2.SSS3.p3.1.m1.1.1.cmml"><mi id="S5.SS2.SSS3.p3.1.m1.1.1.2" xref="S5.SS2.SSS3.p3.1.m1.1.1.2.cmml">p</mi><mrow id="S5.SS2.SSS3.p3.1.m1.1.1.3" xref="S5.SS2.SSS3.p3.1.m1.1.1.3.cmml"><mi id="S5.SS2.SSS3.p3.1.m1.1.1.3.2" xref="S5.SS2.SSS3.p3.1.m1.1.1.3.2.cmml">h</mi><mo id="S5.SS2.SSS3.p3.1.m1.1.1.3.1" xref="S5.SS2.SSS3.p3.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p3.1.m1.1.1.3.3" xref="S5.SS2.SSS3.p3.1.m1.1.1.3.3.cmml">a</mi><mo id="S5.SS2.SSS3.p3.1.m1.1.1.3.1a" xref="S5.SS2.SSS3.p3.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p3.1.m1.1.1.3.4" xref="S5.SS2.SSS3.p3.1.m1.1.1.3.4.cmml">r</mi><mo id="S5.SS2.SSS3.p3.1.m1.1.1.3.1b" xref="S5.SS2.SSS3.p3.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p3.1.m1.1.1.3.5" xref="S5.SS2.SSS3.p3.1.m1.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p3.1.m1.1b"><apply id="S5.SS2.SSS3.p3.1.m1.1.1.cmml" xref="S5.SS2.SSS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS3.p3.1.m1.1.1.1.cmml" xref="S5.SS2.SSS3.p3.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.SSS3.p3.1.m1.1.1.2.cmml" xref="S5.SS2.SSS3.p3.1.m1.1.1.2">ğ‘</ci><apply id="S5.SS2.SSS3.p3.1.m1.1.1.3.cmml" xref="S5.SS2.SSS3.p3.1.m1.1.1.3"><times id="S5.SS2.SSS3.p3.1.m1.1.1.3.1.cmml" xref="S5.SS2.SSS3.p3.1.m1.1.1.3.1"></times><ci id="S5.SS2.SSS3.p3.1.m1.1.1.3.2.cmml" xref="S5.SS2.SSS3.p3.1.m1.1.1.3.2">â„</ci><ci id="S5.SS2.SSS3.p3.1.m1.1.1.3.3.cmml" xref="S5.SS2.SSS3.p3.1.m1.1.1.3.3">ğ‘</ci><ci id="S5.SS2.SSS3.p3.1.m1.1.1.3.4.cmml" xref="S5.SS2.SSS3.p3.1.m1.1.1.3.4">ğ‘Ÿ</ci><ci id="S5.SS2.SSS3.p3.1.m1.1.1.3.5.cmml" xref="S5.SS2.SSS3.p3.1.m1.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p3.1.m1.1c">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS3.p3.1.m1.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math> model which pushes all potentially likeable songs to the top of the rankings (even if some are false positives).
For ranking some pre-existing song candidates (which could be generated by a low <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S5.SS2.SSS3.p3.2.m2.1"><semantics id="S5.SS2.SSS3.p3.2.m2.1a"><msub id="S5.SS2.SSS3.p3.2.m2.1.1" xref="S5.SS2.SSS3.p3.2.m2.1.1.cmml"><mi id="S5.SS2.SSS3.p3.2.m2.1.1.2" xref="S5.SS2.SSS3.p3.2.m2.1.1.2.cmml">p</mi><mrow id="S5.SS2.SSS3.p3.2.m2.1.1.3" xref="S5.SS2.SSS3.p3.2.m2.1.1.3.cmml"><mi id="S5.SS2.SSS3.p3.2.m2.1.1.3.2" xref="S5.SS2.SSS3.p3.2.m2.1.1.3.2.cmml">h</mi><mo id="S5.SS2.SSS3.p3.2.m2.1.1.3.1" xref="S5.SS2.SSS3.p3.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p3.2.m2.1.1.3.3" xref="S5.SS2.SSS3.p3.2.m2.1.1.3.3.cmml">a</mi><mo id="S5.SS2.SSS3.p3.2.m2.1.1.3.1a" xref="S5.SS2.SSS3.p3.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p3.2.m2.1.1.3.4" xref="S5.SS2.SSS3.p3.2.m2.1.1.3.4.cmml">r</mi><mo id="S5.SS2.SSS3.p3.2.m2.1.1.3.1b" xref="S5.SS2.SSS3.p3.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p3.2.m2.1.1.3.5" xref="S5.SS2.SSS3.p3.2.m2.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p3.2.m2.1b"><apply id="S5.SS2.SSS3.p3.2.m2.1.1.cmml" xref="S5.SS2.SSS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS3.p3.2.m2.1.1.1.cmml" xref="S5.SS2.SSS3.p3.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.SSS3.p3.2.m2.1.1.2.cmml" xref="S5.SS2.SSS3.p3.2.m2.1.1.2">ğ‘</ci><apply id="S5.SS2.SSS3.p3.2.m2.1.1.3.cmml" xref="S5.SS2.SSS3.p3.2.m2.1.1.3"><times id="S5.SS2.SSS3.p3.2.m2.1.1.3.1.cmml" xref="S5.SS2.SSS3.p3.2.m2.1.1.3.1"></times><ci id="S5.SS2.SSS3.p3.2.m2.1.1.3.2.cmml" xref="S5.SS2.SSS3.p3.2.m2.1.1.3.2">â„</ci><ci id="S5.SS2.SSS3.p3.2.m2.1.1.3.3.cmml" xref="S5.SS2.SSS3.p3.2.m2.1.1.3.3">ğ‘</ci><ci id="S5.SS2.SSS3.p3.2.m2.1.1.3.4.cmml" xref="S5.SS2.SSS3.p3.2.m2.1.1.3.4">ğ‘Ÿ</ci><ci id="S5.SS2.SSS3.p3.2.m2.1.1.3.5.cmml" xref="S5.SS2.SSS3.p3.2.m2.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p3.2.m2.1c">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS3.p3.2.m2.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math> model), it may be better to use a higher <math alttext="p_{hard}" class="ltx_Math" display="inline" id="S5.SS2.SSS3.p3.3.m3.1"><semantics id="S5.SS2.SSS3.p3.3.m3.1a"><msub id="S5.SS2.SSS3.p3.3.m3.1.1" xref="S5.SS2.SSS3.p3.3.m3.1.1.cmml"><mi id="S5.SS2.SSS3.p3.3.m3.1.1.2" xref="S5.SS2.SSS3.p3.3.m3.1.1.2.cmml">p</mi><mrow id="S5.SS2.SSS3.p3.3.m3.1.1.3" xref="S5.SS2.SSS3.p3.3.m3.1.1.3.cmml"><mi id="S5.SS2.SSS3.p3.3.m3.1.1.3.2" xref="S5.SS2.SSS3.p3.3.m3.1.1.3.2.cmml">h</mi><mo id="S5.SS2.SSS3.p3.3.m3.1.1.3.1" xref="S5.SS2.SSS3.p3.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p3.3.m3.1.1.3.3" xref="S5.SS2.SSS3.p3.3.m3.1.1.3.3.cmml">a</mi><mo id="S5.SS2.SSS3.p3.3.m3.1.1.3.1a" xref="S5.SS2.SSS3.p3.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p3.3.m3.1.1.3.4" xref="S5.SS2.SSS3.p3.3.m3.1.1.3.4.cmml">r</mi><mo id="S5.SS2.SSS3.p3.3.m3.1.1.3.1b" xref="S5.SS2.SSS3.p3.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.SSS3.p3.3.m3.1.1.3.5" xref="S5.SS2.SSS3.p3.3.m3.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p3.3.m3.1b"><apply id="S5.SS2.SSS3.p3.3.m3.1.1.cmml" xref="S5.SS2.SSS3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS3.p3.3.m3.1.1.1.cmml" xref="S5.SS2.SSS3.p3.3.m3.1.1">subscript</csymbol><ci id="S5.SS2.SSS3.p3.3.m3.1.1.2.cmml" xref="S5.SS2.SSS3.p3.3.m3.1.1.2">ğ‘</ci><apply id="S5.SS2.SSS3.p3.3.m3.1.1.3.cmml" xref="S5.SS2.SSS3.p3.3.m3.1.1.3"><times id="S5.SS2.SSS3.p3.3.m3.1.1.3.1.cmml" xref="S5.SS2.SSS3.p3.3.m3.1.1.3.1"></times><ci id="S5.SS2.SSS3.p3.3.m3.1.1.3.2.cmml" xref="S5.SS2.SSS3.p3.3.m3.1.1.3.2">â„</ci><ci id="S5.SS2.SSS3.p3.3.m3.1.1.3.3.cmml" xref="S5.SS2.SSS3.p3.3.m3.1.1.3.3">ğ‘</ci><ci id="S5.SS2.SSS3.p3.3.m3.1.1.3.4.cmml" xref="S5.SS2.SSS3.p3.3.m3.1.1.3.4">ğ‘Ÿ</ci><ci id="S5.SS2.SSS3.p3.3.m3.1.1.3.5.cmml" xref="S5.SS2.SSS3.p3.3.m3.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p3.3.m3.1c">p_{hard}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS3.p3.3.m3.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT</annotation></semantics></math> model that pushes down bad songs for the user.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>Feedback types</h3>
<figure class="ltx_figure ltx_align_floatright" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="186" id="S5.F4.g1" src="extracted/5649672/figs/all_skip_small.png" width="192"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>Test accuracy is fairly consistent across users with different proportion of feedback types (top). The distribution of feedback proportions differs by dataset (bottom).</figcaption>
</figure>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.6">The Pandora dataset includes three different types of feedback and so can be used to identify some qualitative aspects of â€˜skipâ€™ feedback.
We have generally asserted that skips are implicit negative feedback, but it is also possible that they share some aspects of positive feedback, as users may thumb up a song, then skip it if it is replayed too much.
The raw embeddings for â€˜skipâ€™ feedback are more similar to â€˜downâ€™ feedback (cosine similarity: <math alttext="0.82\pm 0.01" class="ltx_Math" display="inline" id="S5.SS3.p1.1.m1.1"><semantics id="S5.SS3.p1.1.m1.1a"><mrow id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml"><mn id="S5.SS3.p1.1.m1.1.1.2" xref="S5.SS3.p1.1.m1.1.1.2.cmml">0.82</mn><mo id="S5.SS3.p1.1.m1.1.1.1" xref="S5.SS3.p1.1.m1.1.1.1.cmml">Â±</mo><mn id="S5.SS3.p1.1.m1.1.1.3" xref="S5.SS3.p1.1.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><apply id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.SS3.p1.1.m1.1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S5.SS3.p1.1.m1.1.1.2.cmml" type="float" xref="S5.SS3.p1.1.m1.1.1.2">0.82</cn><cn id="S5.SS3.p1.1.m1.1.1.3.cmml" type="float" xref="S5.SS3.p1.1.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">0.82\pm 0.01</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.1.m1.1d">0.82 Â± 0.01</annotation></semantics></math> when averaged over all <math alttext="p_{hard}&gt;0" class="ltx_Math" display="inline" id="S5.SS3.p1.2.m2.1"><semantics id="S5.SS3.p1.2.m2.1a"><mrow id="S5.SS3.p1.2.m2.1.1" xref="S5.SS3.p1.2.m2.1.1.cmml"><msub id="S5.SS3.p1.2.m2.1.1.2" xref="S5.SS3.p1.2.m2.1.1.2.cmml"><mi id="S5.SS3.p1.2.m2.1.1.2.2" xref="S5.SS3.p1.2.m2.1.1.2.2.cmml">p</mi><mrow id="S5.SS3.p1.2.m2.1.1.2.3" xref="S5.SS3.p1.2.m2.1.1.2.3.cmml"><mi id="S5.SS3.p1.2.m2.1.1.2.3.2" xref="S5.SS3.p1.2.m2.1.1.2.3.2.cmml">h</mi><mo id="S5.SS3.p1.2.m2.1.1.2.3.1" xref="S5.SS3.p1.2.m2.1.1.2.3.1.cmml">â¢</mo><mi id="S5.SS3.p1.2.m2.1.1.2.3.3" xref="S5.SS3.p1.2.m2.1.1.2.3.3.cmml">a</mi><mo id="S5.SS3.p1.2.m2.1.1.2.3.1a" xref="S5.SS3.p1.2.m2.1.1.2.3.1.cmml">â¢</mo><mi id="S5.SS3.p1.2.m2.1.1.2.3.4" xref="S5.SS3.p1.2.m2.1.1.2.3.4.cmml">r</mi><mo id="S5.SS3.p1.2.m2.1.1.2.3.1b" xref="S5.SS3.p1.2.m2.1.1.2.3.1.cmml">â¢</mo><mi id="S5.SS3.p1.2.m2.1.1.2.3.5" xref="S5.SS3.p1.2.m2.1.1.2.3.5.cmml">d</mi></mrow></msub><mo id="S5.SS3.p1.2.m2.1.1.1" xref="S5.SS3.p1.2.m2.1.1.1.cmml">&gt;</mo><mn id="S5.SS3.p1.2.m2.1.1.3" xref="S5.SS3.p1.2.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.2.m2.1b"><apply id="S5.SS3.p1.2.m2.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1"><gt id="S5.SS3.p1.2.m2.1.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1.1"></gt><apply id="S5.SS3.p1.2.m2.1.1.2.cmml" xref="S5.SS3.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S5.SS3.p1.2.m2.1.1.2.1.cmml" xref="S5.SS3.p1.2.m2.1.1.2">subscript</csymbol><ci id="S5.SS3.p1.2.m2.1.1.2.2.cmml" xref="S5.SS3.p1.2.m2.1.1.2.2">ğ‘</ci><apply id="S5.SS3.p1.2.m2.1.1.2.3.cmml" xref="S5.SS3.p1.2.m2.1.1.2.3"><times id="S5.SS3.p1.2.m2.1.1.2.3.1.cmml" xref="S5.SS3.p1.2.m2.1.1.2.3.1"></times><ci id="S5.SS3.p1.2.m2.1.1.2.3.2.cmml" xref="S5.SS3.p1.2.m2.1.1.2.3.2">â„</ci><ci id="S5.SS3.p1.2.m2.1.1.2.3.3.cmml" xref="S5.SS3.p1.2.m2.1.1.2.3.3">ğ‘</ci><ci id="S5.SS3.p1.2.m2.1.1.2.3.4.cmml" xref="S5.SS3.p1.2.m2.1.1.2.3.4">ğ‘Ÿ</ci><ci id="S5.SS3.p1.2.m2.1.1.2.3.5.cmml" xref="S5.SS3.p1.2.m2.1.1.2.3.5">ğ‘‘</ci></apply></apply><cn id="S5.SS3.p1.2.m2.1.1.3.cmml" type="integer" xref="S5.SS3.p1.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.2.m2.1c">p_{hard}&gt;0</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.2.m2.1d">italic_p start_POSTSUBSCRIPT italic_h italic_a italic_r italic_d end_POSTSUBSCRIPT &gt; 0</annotation></semantics></math> models)
than to â€˜upâ€™ feedback (similarity <math alttext="0.16\pm 0.01" class="ltx_Math" display="inline" id="S5.SS3.p1.3.m3.1"><semantics id="S5.SS3.p1.3.m3.1a"><mrow id="S5.SS3.p1.3.m3.1.1" xref="S5.SS3.p1.3.m3.1.1.cmml"><mn id="S5.SS3.p1.3.m3.1.1.2" xref="S5.SS3.p1.3.m3.1.1.2.cmml">0.16</mn><mo id="S5.SS3.p1.3.m3.1.1.1" xref="S5.SS3.p1.3.m3.1.1.1.cmml">Â±</mo><mn id="S5.SS3.p1.3.m3.1.1.3" xref="S5.SS3.p1.3.m3.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.3.m3.1b"><apply id="S5.SS3.p1.3.m3.1.1.cmml" xref="S5.SS3.p1.3.m3.1.1"><csymbol cd="latexml" id="S5.SS3.p1.3.m3.1.1.1.cmml" xref="S5.SS3.p1.3.m3.1.1.1">plus-or-minus</csymbol><cn id="S5.SS3.p1.3.m3.1.1.2.cmml" type="float" xref="S5.SS3.p1.3.m3.1.1.2">0.16</cn><cn id="S5.SS3.p1.3.m3.1.1.3.cmml" type="float" xref="S5.SS3.p1.3.m3.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.3.m3.1c">0.16\pm 0.01</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.3.m3.1d">0.16 Â± 0.01</annotation></semantics></math>), although the fact that the model does not learn identical embeddings for â€˜skipsâ€™ and â€˜downsâ€™ suggests that they are still distinct in some way.
The similarity for the â€˜upâ€™ and â€˜downâ€™ embeddings is <math alttext="0.00\pm 0.02" class="ltx_Math" display="inline" id="S5.SS3.p1.4.m4.1"><semantics id="S5.SS3.p1.4.m4.1a"><mrow id="S5.SS3.p1.4.m4.1.1" xref="S5.SS3.p1.4.m4.1.1.cmml"><mn id="S5.SS3.p1.4.m4.1.1.2" xref="S5.SS3.p1.4.m4.1.1.2.cmml">0.00</mn><mo id="S5.SS3.p1.4.m4.1.1.1" xref="S5.SS3.p1.4.m4.1.1.1.cmml">Â±</mo><mn id="S5.SS3.p1.4.m4.1.1.3" xref="S5.SS3.p1.4.m4.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.4.m4.1b"><apply id="S5.SS3.p1.4.m4.1.1.cmml" xref="S5.SS3.p1.4.m4.1.1"><csymbol cd="latexml" id="S5.SS3.p1.4.m4.1.1.1.cmml" xref="S5.SS3.p1.4.m4.1.1.1">plus-or-minus</csymbol><cn id="S5.SS3.p1.4.m4.1.1.2.cmml" type="float" xref="S5.SS3.p1.4.m4.1.1.2">0.00</cn><cn id="S5.SS3.p1.4.m4.1.1.3.cmml" type="float" xref="S5.SS3.p1.4.m4.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.4.m4.1c">0.00\pm 0.02</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.4.m4.1d">0.00 Â± 0.02</annotation></semantics></math>. The Spotify â€˜upâ€™ (i.e. â€˜playâ€™) and â€˜skipâ€™ embeddings have an average similarity of <math alttext="-0.53\pm 0.08" class="ltx_Math" display="inline" id="S5.SS3.p1.5.m5.1"><semantics id="S5.SS3.p1.5.m5.1a"><mrow id="S5.SS3.p1.5.m5.1.1" xref="S5.SS3.p1.5.m5.1.1.cmml"><mrow id="S5.SS3.p1.5.m5.1.1.2" xref="S5.SS3.p1.5.m5.1.1.2.cmml"><mo id="S5.SS3.p1.5.m5.1.1.2a" xref="S5.SS3.p1.5.m5.1.1.2.cmml">âˆ’</mo><mn id="S5.SS3.p1.5.m5.1.1.2.2" xref="S5.SS3.p1.5.m5.1.1.2.2.cmml">0.53</mn></mrow><mo id="S5.SS3.p1.5.m5.1.1.1" xref="S5.SS3.p1.5.m5.1.1.1.cmml">Â±</mo><mn id="S5.SS3.p1.5.m5.1.1.3" xref="S5.SS3.p1.5.m5.1.1.3.cmml">0.08</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.5.m5.1b"><apply id="S5.SS3.p1.5.m5.1.1.cmml" xref="S5.SS3.p1.5.m5.1.1"><csymbol cd="latexml" id="S5.SS3.p1.5.m5.1.1.1.cmml" xref="S5.SS3.p1.5.m5.1.1.1">plus-or-minus</csymbol><apply id="S5.SS3.p1.5.m5.1.1.2.cmml" xref="S5.SS3.p1.5.m5.1.1.2"><minus id="S5.SS3.p1.5.m5.1.1.2.1.cmml" xref="S5.SS3.p1.5.m5.1.1.2"></minus><cn id="S5.SS3.p1.5.m5.1.1.2.2.cmml" type="float" xref="S5.SS3.p1.5.m5.1.1.2.2">0.53</cn></apply><cn id="S5.SS3.p1.5.m5.1.1.3.cmml" type="float" xref="S5.SS3.p1.5.m5.1.1.3">0.08</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.5.m5.1c">-0.53\pm 0.08</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.5.m5.1d">- 0.53 Â± 0.08</annotation></semantics></math>; the Piki â€˜upâ€™ and â€˜downâ€™ embeddings have an average similarity of <math alttext="0.39\pm 0.03" class="ltx_Math" display="inline" id="S5.SS3.p1.6.m6.1"><semantics id="S5.SS3.p1.6.m6.1a"><mrow id="S5.SS3.p1.6.m6.1.1" xref="S5.SS3.p1.6.m6.1.1.cmml"><mn id="S5.SS3.p1.6.m6.1.1.2" xref="S5.SS3.p1.6.m6.1.1.2.cmml">0.39</mn><mo id="S5.SS3.p1.6.m6.1.1.1" xref="S5.SS3.p1.6.m6.1.1.1.cmml">Â±</mo><mn id="S5.SS3.p1.6.m6.1.1.3" xref="S5.SS3.p1.6.m6.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.6.m6.1b"><apply id="S5.SS3.p1.6.m6.1.1.cmml" xref="S5.SS3.p1.6.m6.1.1"><csymbol cd="latexml" id="S5.SS3.p1.6.m6.1.1.1.cmml" xref="S5.SS3.p1.6.m6.1.1.1">plus-or-minus</csymbol><cn id="S5.SS3.p1.6.m6.1.1.2.cmml" type="float" xref="S5.SS3.p1.6.m6.1.1.2">0.39</cn><cn id="S5.SS3.p1.6.m6.1.1.3.cmml" type="float" xref="S5.SS3.p1.6.m6.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.6.m6.1c">0.39\pm 0.03</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.6.m6.1d">0.39 Â± 0.03</annotation></semantics></math>.
This may suggest that users may use feedback features differently between these datasets.</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.2">The test accuracy is generally consistent across users with different proportions of positive feedback (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.F4" title="Figure 4 â€£ 5.3. Feedback types â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">4</span></a>). Pandora users with almost no positive feedback (i.e. â€˜mostly-skipâ€™ users) have a slightly lower test accuracy by <math alttext="\sim 2\%" class="ltx_Math" display="inline" id="S5.SS3.p2.1.m1.1"><semantics id="S5.SS3.p2.1.m1.1a"><mrow id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml"><mi id="S5.SS3.p2.1.m1.1.1.2" xref="S5.SS3.p2.1.m1.1.1.2.cmml"></mi><mo id="S5.SS3.p2.1.m1.1.1.1" xref="S5.SS3.p2.1.m1.1.1.1.cmml">âˆ¼</mo><mrow id="S5.SS3.p2.1.m1.1.1.3" xref="S5.SS3.p2.1.m1.1.1.3.cmml"><mn id="S5.SS3.p2.1.m1.1.1.3.2" xref="S5.SS3.p2.1.m1.1.1.3.2.cmml">2</mn><mo id="S5.SS3.p2.1.m1.1.1.3.1" xref="S5.SS3.p2.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><apply id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"><csymbol cd="latexml" id="S5.SS3.p2.1.m1.1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS3.p2.1.m1.1.1.2.cmml" xref="S5.SS3.p2.1.m1.1.1.2">absent</csymbol><apply id="S5.SS3.p2.1.m1.1.1.3.cmml" xref="S5.SS3.p2.1.m1.1.1.3"><csymbol cd="latexml" id="S5.SS3.p2.1.m1.1.1.3.1.cmml" xref="S5.SS3.p2.1.m1.1.1.3.1">percent</csymbol><cn id="S5.SS3.p2.1.m1.1.1.3.2.cmml" type="integer" xref="S5.SS3.p2.1.m1.1.1.3.2">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">\sim 2\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.1.m1.1d">âˆ¼ 2 %</annotation></semantics></math>; inversely, Spotify users with almost no skips (i.e. â€˜mostly-playâ€™ users) have a higher test accuracy by <math alttext="\sim 6\%" class="ltx_Math" display="inline" id="S5.SS3.p2.2.m2.1"><semantics id="S5.SS3.p2.2.m2.1a"><mrow id="S5.SS3.p2.2.m2.1.1" xref="S5.SS3.p2.2.m2.1.1.cmml"><mi id="S5.SS3.p2.2.m2.1.1.2" xref="S5.SS3.p2.2.m2.1.1.2.cmml"></mi><mo id="S5.SS3.p2.2.m2.1.1.1" xref="S5.SS3.p2.2.m2.1.1.1.cmml">âˆ¼</mo><mrow id="S5.SS3.p2.2.m2.1.1.3" xref="S5.SS3.p2.2.m2.1.1.3.cmml"><mn id="S5.SS3.p2.2.m2.1.1.3.2" xref="S5.SS3.p2.2.m2.1.1.3.2.cmml">6</mn><mo id="S5.SS3.p2.2.m2.1.1.3.1" xref="S5.SS3.p2.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.2.m2.1b"><apply id="S5.SS3.p2.2.m2.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1"><csymbol cd="latexml" id="S5.SS3.p2.2.m2.1.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS3.p2.2.m2.1.1.2.cmml" xref="S5.SS3.p2.2.m2.1.1.2">absent</csymbol><apply id="S5.SS3.p2.2.m2.1.1.3.cmml" xref="S5.SS3.p2.2.m2.1.1.3"><csymbol cd="latexml" id="S5.SS3.p2.2.m2.1.1.3.1.cmml" xref="S5.SS3.p2.2.m2.1.1.3.1">percent</csymbol><cn id="S5.SS3.p2.2.m2.1.1.3.2.cmml" type="integer" xref="S5.SS3.p2.2.m2.1.1.3.2">6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.2.m2.1c">\sim 6\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.2.m2.1d">âˆ¼ 6 %</annotation></semantics></math>.
Further work should be done to better understand these user segments; we note that the bimodal distribution of positive feedback proportions in the Spotify dataset (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#S5.F4" title="Figure 4 â€£ 5.3. Feedback types â€£ 5. Results and Discussion â€£ Negative Feedback for Music Personalization"><span class="ltx_text ltx_ref_tag">4</span></a>) aligns with prior research clustering user types into â€˜mostly-playâ€™ and â€˜mostly-skipâ€™ <cite class="ltx_cite ltx_citemacro_citep">(Meggetto etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.04488v1#bib.bib7" title="">2021</a>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">We find that incorporating user-given hard negatives in training considerably improves the test accuracy of user-liked songs as compared to using random negative samples.
An approximation to a hard negative can be found by sampling multiple negatives and choosing the hardest one: we find that this can help test accuracy up to a point, but too many random negatives are likely to include some false negatives which reduces the test accuracy.
As many users give â€˜skipâ€™ feedback, this can be used directly in the input to help define a userâ€™s context vector, which slightly improves the overall accuracy of the model and also considerably improves the user coverage compared to only using positive feedback.
We also find that the test accuracy is robust with respect to differing proportions of feedback types, and that â€˜skipâ€™ feedback is more similar to negative feedback than positive feedback.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bengio and Senecal (2008)</span>
<span class="ltx_bibblock">
Yoshua Bengio and Jean-SÃ‰bastien Senecal. 2008.

</span>
<span class="ltx_bibblock">Adaptive Importance Sampling to Accelerate Training of a Neural Probabilistic Language Model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">IEEE Transactions on Neural Networks</em> 19, 4 (2008), 713â€“722.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/TNN.2007.912312" title="">https://doi.org/10.1109/TNN.2007.912312</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brost etÂ al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Brian Brost, Rishabh Mehrotra, and Tristan Jehan. 2019.

</span>
<span class="ltx_bibblock">The Music Streaming Sessions Dataset. In <em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">Proceedings of the 2019 Web Conference</em>. ACM.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dias and Fonseca (2013)</span>
<span class="ltx_bibblock">
Ricardo Dias and ManuelÂ J Fonseca. 2013.

</span>
<span class="ltx_bibblock">Improving music recommendation in session-based collaborative filtering by using temporal context. In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">2013 IEEE 25th international conference on tools with artificial intelligence</em>. IEEE, 783â€“788.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ICTAI.2013.120" title="">https://doi.org/10.1109/ICTAI.2013.120</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hanley and McNeil (1982)</span>
<span class="ltx_bibblock">
JamesÂ A Hanley and BarbaraÂ J McNeil. 1982.

</span>
<span class="ltx_bibblock">The meaning and use of the area under a receiver operating characteristic (ROC) curve.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Radiology</em> 143, 1 (1982), 29â€“36.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang and McAuley (2018)</span>
<span class="ltx_bibblock">
Wang-Cheng Kang and Julian McAuley. 2018.

</span>
<span class="ltx_bibblock">Self-attentive sequential recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">2018 IEEE International Conference on Data Mining (ICDM)</em>. IEEE, 197â€“206.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ICDM.2018.00035" title="">https://doi.org/10.1109/ICDM.2018.00035</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meggetto etÂ al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Francesco Meggetto, Crawford Revie, John Levine, and Yashar Moshfeghi. 2021.

</span>
<span class="ltx_bibblock">On Skipping Behaviour Types in Music Streaming Sessions. In <em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</em> (Virtual Event, Queensland, Australia) <em class="ltx_emph ltx_font_italic" id="bib.bib7.4.2">(CIKM â€™21)</em>. Association for Computing Machinery, New York, NY, USA, 3333â€“3337.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3459637.3482123" title="">https://doi.org/10.1145/3459637.3482123</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meggetto etÂ al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Francesco Meggetto, Crawford Revie, John Levine, and Yashar Moshfeghi. 2023.

</span>
<span class="ltx_bibblock">Why People Skip Music? On Predicting Music Skips using Deep Reinforcement Learning. In <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">Proceedings of the 2023 Conference on Human Information Interaction and Retrieval</em> (Â¡conf-locÂ¿, Â¡cityÂ¿AustinÂ¡/cityÂ¿, Â¡stateÂ¿TXÂ¡/stateÂ¿, Â¡countryÂ¿USAÂ¡/countryÂ¿, Â¡/conf-locÂ¿) <em class="ltx_emph ltx_font_italic" id="bib.bib8.4.2">(CHIIR â€™23)</em>. Association for Computing Machinery, New York, NY, USA, 95â€“106.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3576840.3578312" title="">https://doi.org/10.1145/3576840.3578312</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mei etÂ al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
M.Â Jeffrey Mei, Oliver Bembom, and Andreas Ehmann. 2023.

</span>
<span class="ltx_bibblock">Station and Track Attribute-Aware Music Personalization. In <em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib9.4.2">(RecSys â€™23)</em>. Association for Computing Machinery, New York, NY, USA, 1031â€“1035.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3610239" title="">https://doi.org/10.1145/3604915.3610239</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mena-Maldonado etÂ al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Elisa Mena-Maldonado, RocÃ­o CaÃ±amares, Pablo Castells, Yongli Ren, and Mark Sanderson. 2020.

</span>
<span class="ltx_bibblock">Agreement and Disagreement between True and False-Positive Metrics in Recommender Systems Evaluation. In <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Virtual Event, China) <em class="ltx_emph ltx_font_italic" id="bib.bib10.4.2">(SIGIR â€™20)</em>. Association for Computing Machinery, New York, NY, USA, 841â€“850.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3397271.3401096" title="">https://doi.org/10.1145/3397271.3401096</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petrov and Macdonald (2023)</span>
<span class="ltx_bibblock">
AleksandrÂ Vladimirovich Petrov and Craig Macdonald. 2023.

</span>
<span class="ltx_bibblock">GSASRec: Reducing Overconfidence in Sequential Recommendation Trained with Negative Sampling. In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib11.2.2">(RecSys â€™23)</em>. Association for Computing Machinery, New York, NY, USA, 116â€“128.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3608783" title="">https://doi.org/10.1145/3604915.3608783</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schedl and Schnitzer (2014)</span>
<span class="ltx_bibblock">
Markus Schedl and Dominik Schnitzer. 2014.

</span>
<span class="ltx_bibblock">Location-aware music artist recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">MultiMedia Modeling: 20th Anniversary International Conference, MMM 2014, Dublin, Ireland, January 6-10, 2014, Proceedings, Part II 20</em>. Springer, 205â€“213.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Seshadri and Knees (2023)</span>
<span class="ltx_bibblock">
Pavan Seshadri and Peter Knees. 2023.

</span>
<span class="ltx_bibblock">Leveraging Negative Signals with Self-Attention for Sequential Music Recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2309.11623</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stoikov and Wen (2021)</span>
<span class="ltx_bibblock">
Sasha Stoikov and Hongyi Wen. 2021.

</span>
<span class="ltx_bibblock">Evaluating Music Recommendations with Binary Feedback for Multiple Stakeholders. In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 1st Workshop on Multi-Objective Recommender Systems (MORS 2021) co-located with 15th ACM Conference on Recommender Systems (RecSys 2021)</em> <em class="ltx_emph ltx_font_italic" id="bib.bib14.2.2">(CEUR Workshop Proceedings, Vol.Â 2959)</em>. CEUR-WS.org.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ceur-ws.org/Vol-2959/paper9.pdf" title="">https://ceur-ws.org/Vol-2959/paper9.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun etÂ al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019.

</span>
<span class="ltx_bibblock">BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer. In <em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</em> (Beijing, China) <em class="ltx_emph ltx_font_italic" id="bib.bib15.4.2">(CIKM â€™19)</em>. Association for Computing Machinery, New York, NY, USA, 1441â€“1450.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3357384.3357895" title="">https://doi.org/10.1145/3357384.3357895</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani etÂ al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, AidanÂ N Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">Advances in Neural Information Processing Systems</em> 30 (2017).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.1706.03762" title="">https://doi.org/10.48550/arXiv.1706.03762</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Jizhe Wang, Pipei Huang, Huan Zhao, Zhibo Zhang, Binqiang Zhao, and DikÂ Lun Lee. 2018.

</span>
<span class="ltx_bibblock">Billion-Scale Commodity Embedding for E-Commerce Recommendation in Alibaba. In <em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em> (London, United Kingdom) <em class="ltx_emph ltx_font_italic" id="bib.bib17.4.2">(KDD â€™18)</em>. Association for Computing Machinery, New York, NY, USA, 839â€“848.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3219819.3219869" title="">https://doi.org/10.1145/3219819.3219869</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and Wang (2014)</span>
<span class="ltx_bibblock">
Xinxi Wang and Ye Wang. 2014.

</span>
<span class="ltx_bibblock">Improving content-based and hybrid music recommendation using deep learning. In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the 22nd ACM international conference on Multimedia</em>. 627â€“636.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2647868.2654940" title="">https://doi.org/10.1145/2647868.2654940</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yueqi Wang, Yoni Halpern, Shuo Chang, Jingchen Feng, ElaineÂ Ya Le, Longfei Li, Xujian Liang, Min-Cheng Huang, Shane Li, Alex Beutel, Yaping Zhang, and Shuchao Bi. 2023.

</span>
<span class="ltx_bibblock">Learning from Negative User Feedback and Measuring Responsiveness for Sequential Recommenders. In <em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib19.4.2">(RecSys â€™23)</em>. Association for Computing Machinery, New York, NY, USA, 1049â€“1053.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3610244" title="">https://doi.org/10.1145/3604915.3610244</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen etÂ al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Hongyi Wen, Longqi Yang, and Deborah Estrin. 2019.

</span>
<span class="ltx_bibblock">Leveraging post-click feedback for content recommendations. In <em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">Proceedings of the 13th ACM Conference on Recommender Systems</em> (Copenhagen, Denmark) <em class="ltx_emph ltx_font_italic" id="bib.bib20.4.2">(RecSys â€™19)</em>. Association for Computing Machinery, New York, NY, USA, 278â€“286.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3298689.3347037" title="">https://doi.org/10.1145/3298689.3347037</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weston etÂ al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2011)</span>
<span class="ltx_bibblock">
Jason Weston, Samy Bengio, and Nicolas Usunier. 2011.

</span>
<span class="ltx_bibblock">Wsabie: Scaling Up To Large Vocabulary Image Annotation. In <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">Proceedings of the International Joint Conference on Artificial Intelligence, IJCAI</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wilm etÂ al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Timo Wilm, Philipp Normann, Sophie Baumeister, and Paul-Vincent Kobow. 2023.

</span>
<span class="ltx_bibblock">Scaling Session-Based Transformer Recommendations Using Optimized Negative Sampling and Loss Functions <em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">(RecSys â€™23)</em>. Association for Computing Machinery, New York, NY, USA, 1023â€“1026.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3610236" title="">https://doi.org/10.1145/3604915.3610236</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jiancan Wu, Xiang Wang, Xingyu Gao, Jiawei Chen, Hongcheng Fu, Tianyu Qiu, and Xiangnan He. 2023.

</span>
<span class="ltx_bibblock">On the Effectiveness of Sampled Softmax Loss for Item Recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">ACM Trans. Inf. Syst.</em> (dec 2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3637061" title="">https://doi.org/10.1145/3637061</a>
</span>
<span class="ltx_bibblock">Just Accepted.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao etÂ al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yuhan Zhao, Rui Chen, Riwei Lai, Qilong Han, Hongtao Song, and Li Chen. 2023.

</span>
<span class="ltx_bibblock">Augmented Negative Sampling for Collaborative Filtering. In <em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib24.4.2">(RecSys â€™23)</em>. Association for Computing Machinery, New York, NY, USA, 256â€“266.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3604915.3608811" title="">https://doi.org/10.1145/3604915.3608811</a>
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Jun  6 20:16:42 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
