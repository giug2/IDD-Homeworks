<!DOCTYPE html>

<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning</title>
<!--Generated on Wed Feb 21 12:08:56 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2312.07250v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S1" title="1 Introduction ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S2" title="2 Related Work ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S3" title="3 Experimental Designs ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experimental Designs</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S3.SS1" title="3.1 Multilingual Marian NMT ‣ 3 Experimental Designs ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Multilingual Marian NMT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S3.SS2" title="3.2 Extra-Large Multilingual WMT21fb and NLLB ‣ 3 Experimental Designs ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Extra-Large Multilingual WMT21fb and NLLB</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S4" title="4 Experimental Settings and Evaluations ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experimental Settings and Evaluations</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S4.SS1" title="4.1 Domain Fine-tuning Corpus ‣ 4 Experimental Settings and Evaluations ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Domain Fine-tuning Corpus</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S4.SS2" title="4.2 Model Parameter Settings ‣ 4 Experimental Settings and Evaluations ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Model Parameter Settings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S4.SS3" title="4.3 Test Sets and Automatic Evaluations ‣ 4 Experimental Settings and Evaluations ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Test Sets and Automatic Evaluations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S4.SS4" title="4.4 Comparisons ‣ 4 Experimental Settings and Evaluations ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Comparisons</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5" title="5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Human Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.SS1" title="5.1 Human Evaluation Setup ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Human Evaluation Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.SS2" title="5.2 Human Evaluation Output ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Human Evaluation Output</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.SS3" title="5.3 Inter-Rater-Reliability ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Inter-Rater-Reliability</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.SS4" title="5.4 Error Analysis ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Error Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S6" title="6 Discussions and Conclusions ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussions and Conclusions</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content"><div class="section" id="target-section"><div id="license-tr">License: CC BY-NC-SA 4.0</div><div id="watermark-tr">arXiv:2312.07250v2 [cs.CL] 21 Feb 2024</div></div>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Lifeng Han<math alttext="{}^{1}" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><msup id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mi id="id1.1.m1.1.1a" xref="id1.1.m1.1.1.cmml"></mi><mn id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><cn id="id1.1.m1.1.1.1.cmml" type="integer" xref="id1.1.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math>, Serge Gladkoff<math alttext="{}^{2}" class="ltx_Math" display="inline" id="id2.2.m2.1"><semantics id="id2.2.m2.1a"><msup id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml"><mi id="id2.2.m2.1.1a" xref="id2.2.m2.1.1.cmml"></mi><mn id="id2.2.m2.1.1.1" xref="id2.2.m2.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><apply id="id2.2.m2.1.1.cmml" xref="id2.2.m2.1.1"><cn id="id2.2.m2.1.1.1.cmml" type="integer" xref="id2.2.m2.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="id2.2.m2.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>, Gleb Erofeev<math alttext="{}^{2}" class="ltx_Math" display="inline" id="id3.3.m3.1"><semantics id="id3.3.m3.1a"><msup id="id3.3.m3.1.1" xref="id3.3.m3.1.1.cmml"><mi id="id3.3.m3.1.1a" xref="id3.3.m3.1.1.cmml"></mi><mn id="id3.3.m3.1.1.1" xref="id3.3.m3.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id3.3.m3.1b"><apply id="id3.3.m3.1.1.cmml" xref="id3.3.m3.1.1"><cn id="id3.3.m3.1.1.1.cmml" type="integer" xref="id3.3.m3.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id3.3.m3.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="id3.3.m3.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id4.4.1">Irina Sorokina<math alttext="{}^{2}" class="ltx_Math" display="inline" id="id4.4.1.m1.1"><semantics id="id4.4.1.m1.1a"><msup id="id4.4.1.m1.1.1" xref="id4.4.1.m1.1.1.cmml"><mi id="id4.4.1.m1.1.1a" xref="id4.4.1.m1.1.1.cmml"></mi><mn id="id4.4.1.m1.1.1.1" mathvariant="normal" xref="id4.4.1.m1.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id4.4.1.m1.1b"><apply id="id4.4.1.m1.1.1.cmml" xref="id4.4.1.m1.1.1"><cn id="id4.4.1.m1.1.1.1.cmml" type="integer" xref="id4.4.1.m1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id4.4.1.m1.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="id4.4.1.m1.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>,
<span class="ltx_text ltx_font_bold" id="id5.5.2">Betty Galiano<math alttext="{}^{3}" class="ltx_Math" display="inline" id="id5.5.2.m1.1"><semantics id="id5.5.2.m1.1a"><msup id="id5.5.2.m1.1.1" xref="id5.5.2.m1.1.1.cmml"><mi id="id5.5.2.m1.1.1a" xref="id5.5.2.m1.1.1.cmml"></mi><mn id="id5.5.2.m1.1.1.1" mathvariant="normal" xref="id5.5.2.m1.1.1.1.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="id5.5.2.m1.1b"><apply id="id5.5.2.m1.1.1.cmml" xref="id5.5.2.m1.1.1"><cn id="id5.5.2.m1.1.1.1.cmml" type="integer" xref="id5.5.2.m1.1.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id5.5.2.m1.1c">{}^{3}</annotation><annotation encoding="application/x-llamapun" id="id5.5.2.m1.1d">start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_text ltx_font_bold" id="id6.1.1">Goran Nenadic<math alttext="{}^{1}" class="ltx_Math" display="inline" id="id6.1.1.m1.1"><semantics id="id6.1.1.m1.1a"><msup id="id6.1.1.m1.1.1" xref="id6.1.1.m1.1.1.cmml"><mi id="id6.1.1.m1.1.1a" xref="id6.1.1.m1.1.1.cmml"></mi><mn id="id6.1.1.m1.1.1.1" mathvariant="normal" xref="id6.1.1.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id6.1.1.m1.1b"><apply id="id6.1.1.m1.1.1.cmml" xref="id6.1.1.m1.1.1"><cn id="id6.1.1.m1.1.1.1.cmml" type="integer" xref="id6.1.1.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id6.1.1.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id6.1.1.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>
<br class="ltx_break"/><math alttext="{}^{1}" class="ltx_Math" display="inline" id="id7.2.m1.1"><semantics id="id7.2.m1.1a"><msup id="id7.2.m1.1.1" xref="id7.2.m1.1.1.cmml"><mi id="id7.2.m1.1.1a" xref="id7.2.m1.1.1.cmml"></mi><mn id="id7.2.m1.1.1.1" xref="id7.2.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id7.2.m1.1b"><apply id="id7.2.m1.1.1.cmml" xref="id7.2.m1.1.1"><cn id="id7.2.m1.1.1.1.cmml" type="integer" xref="id7.2.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id7.2.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id7.2.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math> The University of Manchester, UK 
<br class="ltx_break"/><math alttext="{}^{2}" class="ltx_Math" display="inline" id="id8.3.m2.1"><semantics id="id8.3.m2.1a"><msup id="id8.3.m2.1.1" xref="id8.3.m2.1.1.cmml"><mi id="id8.3.m2.1.1a" xref="id8.3.m2.1.1.cmml"></mi><mn id="id8.3.m2.1.1.1" xref="id8.3.m2.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id8.3.m2.1b"><apply id="id8.3.m2.1.1.cmml" xref="id8.3.m2.1.1"><cn id="id8.3.m2.1.1.1.cmml" type="integer" xref="id8.3.m2.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id8.3.m2.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="id8.3.m2.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math> Logrus Global, Translation &amp; Localization &amp;
<math alttext="{}^{3}" class="ltx_Math" display="inline" id="id9.4.m3.1"><semantics id="id9.4.m3.1a"><msup id="id9.4.m3.1.1" xref="id9.4.m3.1.1.cmml"><mi id="id9.4.m3.1.1a" xref="id9.4.m3.1.1.cmml"></mi><mn id="id9.4.m3.1.1.1" xref="id9.4.m3.1.1.1.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="id9.4.m3.1b"><apply id="id9.4.m3.1.1.cmml" xref="id9.4.m3.1.1"><cn id="id9.4.m3.1.1.1.cmml" type="integer" xref="id9.4.m3.1.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id9.4.m3.1c">{}^{3}</annotation><annotation encoding="application/x-llamapun" id="id9.4.m3.1d">start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT</annotation></semantics></math> Ocean Translations

<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id10.5.id1">lifeng.han, g.nenadic@manchester.ac.uk</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id11.6.id2">serge.gladkoff, gleb.erofeev, irina.sorokina@logrusglobal.com
</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id12.7.id3">betty.galiano@oceantranslations.com</span>
<br class="ltx_break"/>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id13.id1">Clinical texts and documents contain a wealth of information and knowledge in the field of healthcare, and their processing, using state-of-the-art language technology, has become very important for building intelligent systems capable of supporting healthcare and providing greater social good. This processing includes creating language understanding models and translating resources into other natural languages to share domain-specific cross-lingual knowledge. In this work, we conduct investigations on clinical text machine translation by examining multilingual neural network models using deep learning methods such as Transformer-based structures. Furthermore, to address the issue of language resource imbalance, we also carry out experiments using a transfer learning methodology based on massive multilingual pre-trained language models (MMPLMs). The experimental results on three sub-tasks including 1) clinical case (CC), 2) clinical terminology (CT), and 3) ontological concept (OC) show that our models achieved top-level performances in the ClinSpEn-2022 shared task on English-Spanish clinical domain data. Furthermore, our expert-based human evaluations demonstrate that the small-sized pre-trained language model (PLM) wins in the clinical domain fine-tuning over the other two extra-large language models by a large margin. This finding has never been previously reported in the field. Finally, the transfer learning method works well in our experimental setting using the WMT21fb model to accommodate a new Spanish language space that was not seen at the pretraining stage within WMT21fb itself – and this deserves further exploration for clinical knowledge transformation, e.g. investigation into more languages. These research findings can shed some light on domain-specific machine translation development, especially in clinical and healthcare fields. Further research projects can be carried out based on our work to improve healthcare text analytics and knowledge transformations. Our data will be openly available for research purposes at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/HECTA-UoM/ClinicalNMT" title="">https://github.com/HECTA-UoM/ClinicalNMT</a> </p>
<p class="ltx_p" id="id14.id2"><span class="ltx_text ltx_font_bold" id="id14.id2.1">Keywords:</span> Neural Machine Translation; Clinical Text Translation; Multilingual Pre-trained Language Model; Large Language Model; Transfer Learning; Clinical Knowledge Transformation; Spanish-English Translation</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">In recent years, Healthcare Text Analytics (HECTA) have gained more attention from researchers across different disciplines, due to their impact on clinical treatment, decision-making, hospital operation, and their recently empowered capabilities. These developments have much to do with the latest development of powerful language models (LMs), advanced machine-learning (ML) technologies, and increasingly available digital healthcare data from the social media <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx17" title="">Griciūtė et al., 2023</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx42" title="">Oyebode et al., 2021</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx36" title="">Luo et al., 2022</a>]</cite> and discharged outpatient letters from hospital settings <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx25" title="">Henry et al., 2020</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx53" title="">Spasic and Nenadic, 2020</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx45" title="">Percha, 2021</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Intelligent healthcare systems have been deployed in some hospitals to support the clinicians’ diagnostics and decision-making regarding patients and their health problems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx41" title="">Noor et al., 2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx48" title="">Qian et al., 2021</a>]</cite>. Such usages include key information extraction (IE) from electronic health records (EHRs),
normalisation to medical terminologies,
knowledge graph (KG) construction, and relation extraction (RE) between symptoms (problems), diagnoses, treatments, and adverse drug events <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx63" title="">Wu et al., 2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx40" title="">Nguyen et al., 2023</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx4" title="">Belkadi et al., 2023</a>]</cite>.
Some of these digital healthcare systems can also help patients self-diagnose in situations where no General Practitioners (GPs) and professional doctors are available <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx62" title="">Wroge et al., 2018</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx67" title="">Zhu et al., 2021</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">However, due to the language barriers and inequal accessibility of digital resources across languages, there is an urgent need for knowledge transfer, such as from one human language to another <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx7" title="">Costa-jussà et al., 2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx31" title="">Khoong and Rodriguez, 2022</a>]</cite>.
Thus, to help address digital health disparity, machine translation (MT) technologies can be of good use.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">MT is one of the earliest artificial intelligence (AI) branches dating back to the 1950s, and it has boomed in recent years along with other natural language processing (NLP) tasks due to the newly designed powerful Transformers learning model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx61" title="">Weaver, 1955</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx58" title="">Vaswani et al., 2017</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx10" title="">Devlin et al., 2018</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx19" title="">Han et al., 2021a</a>]</cite>.
Several attention mechanisms designed in Transformer deep neural models have proven themselves capable of better learning from a large amount of available digital data compared to traditional statistical and neural network-based models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx24" title="">Han, 2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx33" title="">Kuang et al., 2018</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx18" title="">Han and Kuang, 2018</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In this work, we investigate the state-of-the-art Transformer-based Neural MT (NMT) models in connection with clinical domain text translation, to facilitate digital healthcare and knowledge transfer with the workflow drawn in Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">1</span></a>.
Being aware of some current development in the competition of language model sizes in the NLP field, we set up the following base models for comparison study: 1) a small-sized multilingual pre-trained Marian language model (s-MPLM), which was developed by researchers
at the Adam Mickiewicz
University in Poznan and by the NLP group at the University of Edinburgh
<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx29" title="">Junczys-Dowmunt et al., 2018a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx30" title="">Junczys-Dowmunt et al., 2018b</a>]</cite>; and 2) a massive-sized multilingual pre-trained NLLB LM (MMPLM/xL-MPLM), developed by Meta-AI covering more than 200 languages <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx7" title="">Costa-jussà et al., 2022</a>]</cite>.
In addition to this, we set up a third model to investigate the possibility of transfer learning in the clinical domain MT: 3) the WMT21fb model which is another MMPLM from Meta-AI but with a limited amount of pre-trained language pairs including from English to Czech, German, Hausa, Icelandic, Japanese, Russian, and Chinese, and the opposite <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx56" title="">Tran et al., 2021</a>]</cite>.
</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">The testing language pairs of these translation models in our work are English <math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S1.p6.1.m1.1"><semantics id="S1.p6.1.m1.1a"><mo id="S1.p6.1.m1.1.1" stretchy="false" xref="S1.p6.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S1.p6.1.m1.1b"><ci id="S1.p6.1.m1.1.1.cmml" xref="S1.p6.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S1.p6.1.m1.1d">↔</annotation></semantics></math> Spanish.
As far as we know, there are no other language pairs of openly available resources in the clinical domain MT.
We use the international shared task challenge data from ClinSpEn2022 “clinical domain Spanish-English MT 2022” for this purpose <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://codalab.lisn.upsaclay.fr/competitions/6696" title="">https://codalab.lisn.upsaclay.fr/competitions/6696</a></span></span></span>. ClinSpEn2022 was a sub-task of the BioMedical MT track at WMT2022 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx39" title="">Neves et al., 2022</a>]</cite>.
There are three translation tasks inside ClinSpEn2022 including i) clinical cases report; ii) clinical terms, and iii) ontological concepts from the biomedical domain.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">Regarding the evaluation of these LMs, we used the evaluation platform offered by the ClinSpEn2022 shared task including several automatic metrics such as BLEU, METEOR, ROUGE, COMET. However, the automatic evaluation results did not give any apparent differentiation between the models on some of the tasks. Furthermore, there are issues like inconsistency regarding model ranking across automatic metrics.
To address these issues and give a high-quality evaluation, we performed an expert-based human evaluation on the three models using outputs of Task one “clinical case report”.</p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">Our experimental investigation shows that 1) the extra-large MMPLM does not necessarily win over the small-sized MPLM on clinical domain MT via fine-tuning; 2) our transfer-learning model works successfully for clinical domain MT task on language pairs that were not pre-trained for, but added with fine-tuning.
The first finding can shed some light on the idea that in clinical domain-specific MT, it is better to do more data cleaning and fine-tuning rather than build extra large LMs.
Our second finding tells us the capability of MMPLMs in generating a new language pair knowledge space for translating clinical domain text even though this language pair was unseen in the pre-training stage with our experimental settings. This can be useful to low-resource NLP, such as the work by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx1" title="">Almansor and Al-Ani, 2018</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx26" title="">Islam et al., 2021</a>]</cite>. <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>This paper reports systematic investigation findings based upon the preliminary work from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx21" title="">Han et al., 2022a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx22" title="">Han et al., 2022b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx23" title="">Han et al., 2023</a>]</cite>.</span></span></span></p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="187" id="S1.F1.g1" src="x1.png" width="784"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Illustration of the Investigation Workflow</figcaption>
</figure>
<div class="ltx_para" id="S1.p9">
<p class="ltx_p" id="S1.p9.1">The rest of this article is organised as below: Section <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S2" title="2 Related Work ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">2</span></a> surveys other works related to ours, including clinical domain MT and NLP, large LMs, and transfer learning. Section <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S3" title="3 Experimental Designs ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">3</span></a> details the three LMs we deployed for comparison study. Section <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S4" title="4 Experimental Settings and Evaluations ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">4</span></a> introduces the experimental work we carried out and automatic evaluation outcomes. Section <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5" title="5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">5</span></a> follows up with expert-based human evaluation and the results. Finally, Section <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S6" title="6 Discussions and Conclusions ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">6</span></a> concludes our work with discussion.
</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Applying NLP models to clinical healthcare has attracted much attention of researchers, such as the work on disease status prediction using discharge summaries by <span class="ltx_text ltx_font_bold" id="S2.p1.1.1">?</span>),
temporal expressions and events extraction from clinical narratives using combined methods of rules and machine learning by <span class="ltx_text ltx_font_bold" id="S2.p1.1.2">?</span>) and recent deep-learning models by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx57" title="">Tu et al., 2023</a>]</cite>, Temporal Relation modelling on treatments using prompt engineering on GPT models by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx8" title="">Cui et al., 2023</a>]</cite>,
using knowledge-based and data-driven methods for de-identification task in clinical narratives by <span class="ltx_text ltx_font_bold" id="S2.p1.1.3">?</span>), systematic reviews on clinical text mining and healthcare by <span class="ltx_text ltx_font_bold" id="S2.p1.1.4">?</span>) and <span class="ltx_text ltx_font_bold" id="S2.p1.1.5">?</span>), etc.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">However, using MT to help translate clinical text for knowledge transfer and improved clinical decision-making is still a relative novelty <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx31" title="">Khoong and Rodriguez, 2022</a>]</cite>, even though it has proven its usefulness for assisting <span class="ltx_text ltx_font_italic" id="S2.p2.1.1">health communication</span> especially with post-editing strategies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx11" title="">Dew et al., 2018</a>]</cite>. This is partially the result of the sensitive nature of domain and high risk in clinical settings <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx49" title="">Randhawa et al., 2013</a>]</cite>.
Some of the recent progress on using MT for clinical texts includes the work by <span class="ltx_text ltx_font_bold" id="S2.p2.1.2">?</span>) which leverages SNOMED-CT terms <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx12" title="">Donnelly, 2006</a>]</cite> and relations for MT between Basque and Spanish languages; <span class="ltx_text ltx_font_bold" id="S2.p2.1.3">?</span>) which applies NMT model to identify semantic concepts in
“abundant interchangeable words” in clinical domain and their experimental result shows that NMT model can greatly improve the efficiency on extracting
UMLS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx5" title="">Bodenreider, 2004</a>]</cite> concepts from a single document by using 30 milliseconds in comparison to traditional regular expression-based methods which take 3 seconds; and <span class="ltx_text ltx_font_bold" id="S2.p2.1.4">?</span>) which uses NMT to
simplify the typical multi-stage workflow on clinical report dictation and even correct the errors from speech recognition.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">With the prevalence of multilingual PLMs (MPLMs) developed from NLP fields, it becomes necessary to test their performances in the clinical domain of NMT.
MPLMs have been adopted for many NLP tasks since the first emergence of the Transformer-based learning structure <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx58" title="">Vaswani et al., 2017</a>]</cite>.
Among these, Marian is a small-sized MPLM led by Microsoft Translator based upon Nenatus NMT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx51" title="">Sennrich et al., 2017</a>]</cite> with around 7.6 million parameters <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx29" title="">Junczys-Dowmunt et al., 2018a</a>]</cite>. At the same time, different research and development teams have been competing in recent years in terms of the size of their LMs such as the massive MPLMs (MMPLMs) WMT21fb and NLLB by Meta-AI that have the number of parameters set at 4.7 billion and 54 billion respectively <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx56" title="">Tran et al., 2021</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx7" title="">Costa-jussà et al., 2022</a>]</cite>.
To investigate the performances of these different models with varied model sizes towards clinical domain NMT with fine-tuning, we set up all three of these as our base models.
To the best of our knowledge, our work is the first to compare small-size and extra-large MPLMs in the clinical domain of NMT.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Close to the clinical domain, there is a biomedical domain MT challengethat has been organised along with the Annual Conference of MT (WMT) since 2016 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx6" title="">Bojar et al., 2016</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx65" title="">Yeganova et al., 2021</a>]</cite>. The historical biomedical MT tasks have covered corpus of biomedical terminologies, scientific abstracts from Medline, summaries of proposals for animal experiments, etc. In 2022, it was the first time that this Biomedical-MT shared task introduced clinical domain data for Spanish-English language pairs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx39" title="">Neves et al., 2022</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">As the WMT21fb model does not include Spanish in its pre-training, we also examined the transfer learning technology into the clinical domain NMT towards Spanish-English using the WMT21fb model.
Transfer-learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx2" title="">Alyafeai et al., 2020</a>]</cite> has proved useful for text classification and relation extraction <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx46" title="">Pomares-Quimbaya et al., 2021</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx44" title="">Peng et al., 2019</a>]</cite>, and low-resource MT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx27" title="">Jiang et al., 2022</a>]</cite> fields.
However, to the best of our knowledge, we are the first to test clinical domain NMT via transfer learning using MMPLMs.
</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Designs</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we introduce more information about the three MPLMs that we investigate in this work, i.e., Marian <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx29" title="">Junczys-Dowmunt et al., 2018a</a>]</cite>, WMT21fb <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx56" title="">Tran et al., 2021</a>]</cite>, and NLLB <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx7" title="">Costa-jussà et al., 2022</a>]</cite>.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="185" id="S3.F2.g1" src="x2.png" width="697"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Marian Pre-Trained NMT - Training Pipeline. </figcaption>
</figure>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="770" id="S3.F3.g1" src="x3.png" width="523"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Several Attention-based Transformer NMT structure <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx58" title="">Vaswani et al., 2017</a>]</cite>. </figcaption>
</figure>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="559" id="S3.F4.g1" src="extracted/5422690/figs/dense_vs_MoE_Transformer.png" width="503"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Original Dense Transformer vs MoE Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx7" title="">Costa-jussà et al., 2022</a>]</cite></figcaption>
</figure>
<figure class="ltx_figure" id="S3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="233" id="S3.F5.g1" src="extracted/5422690/figs/MoE_vs_ConditionalMoE.png" width="503"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>MoE vs Conditional MoE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx7" title="">Costa-jussà et al., 2022</a>]</cite></figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Multilingual Marian NMT</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">First, we draw a training diagram of the original Marian model on its pre-training steps in Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S3.F2" title="Figure 2 ‣ 3 Experimental Designs ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">2</span></a> according to <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx29" title="">Junczys-Dowmunt et al., 2018a</a>]</cite>. The pre-processing step includes tokenisation, true-casing, and Byte-Pair Encoding (BPE) for sub-words. The shallow training is to teach a mid-phase translation model to produce temporary target outputs for back-translation. Then, the back-translation step produces the same amount of input source sentences to enlarge the corpus.
The deep-training step first uses four left-to-right models which can be RNN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx51" title="">Sennrich et al., 2017</a>]</cite> or Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx58" title="">Vaswani et al., 2017</a>]</cite> structures, which is followed by four right-to-left models in the opposite direction.
The ensemble-decoding step will generate the n-best hypothesis translations for each source input segment, which will be re-ranked using a re-scoring mechanism.
Finally, in Marian NMT, there is an automatic post-editing step taken before the final output is produced. This step is also based on an end-to-end neural structure by modelling the <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">set</span>(MT-output, source sentence)<math alttext="\rightarrow" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mo id="S3.SS1.p1.1.m1.1.1" stretchy="false" xref="S3.SS1.p1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">→</annotation></semantics></math>“post-edited output” as introduced by <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.2">?</span>).</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.2">The Marian NMT model we deployed is from the Language Technology Research Group at the University of Helsinki led by <span class="ltx_text ltx_font_bold" id="S3.SS1.p2.2.1">?</span>). It is based on the original Marian model but continuously trained on the multilingual OPUS corpus <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx55" title="">Tiedemann, 2012</a>]</cite> to make the model available to more languages. It includes Spanish<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mo id="S3.SS1.p2.1.m1.1.1" stretchy="false" xref="S3.SS1.p2.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">↔</annotation></semantics></math>English (es<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mo id="S3.SS1.p2.2.m2.1.1" stretchy="false" xref="S3.SS1.p2.2.m2.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">↔</annotation></semantics></math>en) pre-trained models and has
7.6 million parameters for fine-tuning. <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/Helsinki-NLP" title="">https://huggingface.co/Helsinki-NLP</a></span></span></span></p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Extra-Large Multilingual WMT21fb and NLLB</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Instead of the optional RNN structure used in the Marian model, both WMT21fb and NLLB massive-sized multilingual PLMs (MMPLMs) adopted Transformer as the main methodology. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S3.F3" title="Figure 3 ‣ 3 Experimental Designs ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">3</span></a>, Transformer’s main components for encoder include position encoding, Multi-Head Attention, and Feed-Forward Network with layer normalisation at both two steps. The decoder uses Masked Multi-Head Attention to constrain the generation model only taking into account the already generated text.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">To increase the model capacity without making the extra-large model too slow for training, the WMT21fb model included “Sparsely Gated Mixture-of- Expert (MoE)” models,
inspired by the work from <span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">?</span>), into the FFN layer of the Transformer, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S3.F4" title="Figure 4 ‣ 3 Experimental Designs ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">4</span></a>. The MoE model will only pass a sub-set of model parameters into the next level, thus decreasing the computational cost. However, this dropout is done in a random manner.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">Furthermore, this structure design still needs language-specific training, such as English-to-other and other-to-English used by WMT21fb.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1">To further improve on this, the NLLB model designed a Conditional MoE Routing layer inspired by <span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">?</span>) to ask the MoE model to decide which tokens to dropout based on how computationally intensive/resource-heavy they are to process or based on their routing efficiency.
This is achieved by a binary gate, which assigns weights to dense FNN <math alttext="FFN_{shared}" class="ltx_Math" display="inline" id="S3.SS2.p4.1.m1.1"><semantics id="S3.SS2.p4.1.m1.1a"><mrow id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml"><mi id="S3.SS2.p4.1.m1.1.1.2" xref="S3.SS2.p4.1.m1.1.1.2.cmml">F</mi><mo id="S3.SS2.p4.1.m1.1.1.1" xref="S3.SS2.p4.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p4.1.m1.1.1.3" xref="S3.SS2.p4.1.m1.1.1.3.cmml">F</mi><mo id="S3.SS2.p4.1.m1.1.1.1a" xref="S3.SS2.p4.1.m1.1.1.1.cmml">⁢</mo><msub id="S3.SS2.p4.1.m1.1.1.4" xref="S3.SS2.p4.1.m1.1.1.4.cmml"><mi id="S3.SS2.p4.1.m1.1.1.4.2" xref="S3.SS2.p4.1.m1.1.1.4.2.cmml">N</mi><mrow id="S3.SS2.p4.1.m1.1.1.4.3" xref="S3.SS2.p4.1.m1.1.1.4.3.cmml"><mi id="S3.SS2.p4.1.m1.1.1.4.3.2" xref="S3.SS2.p4.1.m1.1.1.4.3.2.cmml">s</mi><mo id="S3.SS2.p4.1.m1.1.1.4.3.1" xref="S3.SS2.p4.1.m1.1.1.4.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.1.m1.1.1.4.3.3" xref="S3.SS2.p4.1.m1.1.1.4.3.3.cmml">h</mi><mo id="S3.SS2.p4.1.m1.1.1.4.3.1a" xref="S3.SS2.p4.1.m1.1.1.4.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.1.m1.1.1.4.3.4" xref="S3.SS2.p4.1.m1.1.1.4.3.4.cmml">a</mi><mo id="S3.SS2.p4.1.m1.1.1.4.3.1b" xref="S3.SS2.p4.1.m1.1.1.4.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.1.m1.1.1.4.3.5" xref="S3.SS2.p4.1.m1.1.1.4.3.5.cmml">r</mi><mo id="S3.SS2.p4.1.m1.1.1.4.3.1c" xref="S3.SS2.p4.1.m1.1.1.4.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.1.m1.1.1.4.3.6" xref="S3.SS2.p4.1.m1.1.1.4.3.6.cmml">e</mi><mo id="S3.SS2.p4.1.m1.1.1.4.3.1d" xref="S3.SS2.p4.1.m1.1.1.4.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.1.m1.1.1.4.3.7" xref="S3.SS2.p4.1.m1.1.1.4.3.7.cmml">d</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><apply id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1"><times id="S3.SS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1.1"></times><ci id="S3.SS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.1.1.2">𝐹</ci><ci id="S3.SS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3">𝐹</ci><apply id="S3.SS2.p4.1.m1.1.1.4.cmml" xref="S3.SS2.p4.1.m1.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.1.1.4.1.cmml" xref="S3.SS2.p4.1.m1.1.1.4">subscript</csymbol><ci id="S3.SS2.p4.1.m1.1.1.4.2.cmml" xref="S3.SS2.p4.1.m1.1.1.4.2">𝑁</ci><apply id="S3.SS2.p4.1.m1.1.1.4.3.cmml" xref="S3.SS2.p4.1.m1.1.1.4.3"><times id="S3.SS2.p4.1.m1.1.1.4.3.1.cmml" xref="S3.SS2.p4.1.m1.1.1.4.3.1"></times><ci id="S3.SS2.p4.1.m1.1.1.4.3.2.cmml" xref="S3.SS2.p4.1.m1.1.1.4.3.2">𝑠</ci><ci id="S3.SS2.p4.1.m1.1.1.4.3.3.cmml" xref="S3.SS2.p4.1.m1.1.1.4.3.3">ℎ</ci><ci id="S3.SS2.p4.1.m1.1.1.4.3.4.cmml" xref="S3.SS2.p4.1.m1.1.1.4.3.4">𝑎</ci><ci id="S3.SS2.p4.1.m1.1.1.4.3.5.cmml" xref="S3.SS2.p4.1.m1.1.1.4.3.5">𝑟</ci><ci id="S3.SS2.p4.1.m1.1.1.4.3.6.cmml" xref="S3.SS2.p4.1.m1.1.1.4.3.6">𝑒</ci><ci id="S3.SS2.p4.1.m1.1.1.4.3.7.cmml" xref="S3.SS2.p4.1.m1.1.1.4.3.7">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">FFN_{shared}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.m1.1d">italic_F italic_F italic_N start_POSTSUBSCRIPT italic_s italic_h italic_a italic_r italic_e italic_d end_POSTSUBSCRIPT</annotation></semantics></math> or MoE Gating, as in Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S3.F5" title="Figure 5 ‣ 3 Experimental Designs ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">5</span></a>.
The Conditional MoE also
removes language-specific parameters for learning.</p>
</div>
<div class="ltx_para" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1">In summary, the WMT21fb and NLLB models share very similar learning structures, the biggest difference being that WMT21fb used language-specific constrained learning.
The WMT21fb model we applied is ‘wmt21-dense-24-wide.En-X’ (and X-En direction) which has 4.7 billion parameters <span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/facebookresearch/fairseq/tree/main/examples/wmt21" title="">https://github.com/facebookresearch/fairseq/tree/main/examples/wmt21</a></span></span></span> and contains the language pairs English <math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S3.SS2.p5.1.m1.1"><semantics id="S3.SS2.p5.1.m1.1a"><mo id="S3.SS2.p5.1.m1.1.1" stretchy="false" xref="S3.SS2.p5.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><ci id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.1.m1.1d">↔</annotation></semantics></math> Chinese, Czech, German, Hausa, Icelandic, Japanese, and Russian.
The full NLLB model includes 200+ languages and has 54.5 billion parameters.
Due to the computational restriction, we applied the distilled model of NLLB, i.e. NLLB-distilled, which has 1.3 billion parameters.</p>
</div>
<div class="ltx_para" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.1">The WMT21fb model does not have Spanish among its trained language pairs, while NLLB includes Spanish as a high-resource language. This is a perfect setting for us to examine the transfer-learning technology on the clinical domain NMT by fine-tuning a translation model for the Spanish language on the WMT21fb model and comparing the output with the NLLB model (Spanish version).</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Settings and Evaluations</h2>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.1">
<td class="ltx_td ltx_border_tt" id="S4.T1.1.1.2"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S4.T1.1.1.1">Task-I: Clinical Cases (CC) EN<math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.T1.1.1.1.m1.1"><semantics id="S4.T1.1.1.1.m1.1a"><mo id="S4.T1.1.1.1.m1.1.1" stretchy="false" xref="S4.T1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.m1.1d">→</annotation></semantics></math>ES</td>
<td class="ltx_td ltx_border_tt" id="S4.T1.1.1.3"></td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.4.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.1.1">MT fine-tuning</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.1.2">plm.es</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.1.3">S<span class="ltx_text ltx_font_smallcaps" id="S4.T1.3.4.1.3.1">acre</span>BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.1.4">METEOR</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.1.5">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.1.6">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.1.7">ROUGE-L-F1</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.5.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.5.2.1">Clinical-Marian</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.5.2.2">Yes</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.5.2.3"><span class="ltx_text ltx_font_italic" id="S4.T1.3.5.2.3.1">38.18</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.5.2.4"><span class="ltx_text ltx_font_italic" id="S4.T1.3.5.2.4.1">0.6338</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.5.2.5"><span class="ltx_text ltx_font_italic" id="S4.T1.3.5.2.5.1">0.4237</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.5.2.6"><span class="ltx_text ltx_font_italic" id="S4.T1.3.5.2.6.1">0.3650</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.5.2.7"><span class="ltx_text ltx_font_italic" id="S4.T1.3.5.2.7.1">0.6271</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.6.3">
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.3.1">Clnical-NLLB</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.3.2">Yes</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.3.3">37.74</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.3.4">0.6273</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.3.5">0.4081</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.3.6">0.3601</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.3.7">0.6193</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.7.4">
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.4.1">Clinical-WMT21fb</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.4.2"><span class="ltx_text ltx_font_bold" id="S4.T1.3.7.4.2.1">No</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.4.3">34.30</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.4.4">0.5868</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.4.5">0.3448</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.4.6">0.3266</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.4.7">0.5927</td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.2">
<td class="ltx_td ltx_border_tt" id="S4.T1.2.2.2"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S4.T1.2.2.1">Task-II: Clinical Terms (CT) EN<math alttext="\leftarrow" class="ltx_Math" display="inline" id="S4.T1.2.2.1.m1.1"><semantics id="S4.T1.2.2.1.m1.1a"><mo id="S4.T1.2.2.1.m1.1.1" stretchy="false" xref="S4.T1.2.2.1.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.1.m1.1b"><ci id="S4.T1.2.2.1.m1.1.1.cmml" xref="S4.T1.2.2.1.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.1.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.2.1.m1.1d">←</annotation></semantics></math>ES</td>
<td class="ltx_td ltx_border_tt" id="S4.T1.2.2.3"></td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.8.5">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.8.5.1">MT fine-tuning</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.8.5.2">plm.es</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.8.5.3">S<span class="ltx_text ltx_font_smallcaps" id="S4.T1.3.8.5.3.1">acre</span>BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.8.5.4">METEOR</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.8.5.5">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.8.5.6">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.8.5.7">ROUGE-L-F1</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.9.6">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.9.6.1">Clinical-Marian</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.9.6.2">Yes</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.9.6.3">26.87</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.9.6.4"><span class="ltx_text ltx_font_italic" id="S4.T1.3.9.6.4.1">0.5885</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.9.6.5">0.9791</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.9.6.6">0.2667</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.9.6.7"><span class="ltx_text ltx_font_italic" id="S4.T1.3.9.6.7.1">0.6720</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.10.7">
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.7.1">Clinical-NLLB</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.7.2">Yes</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.7.3"><span class="ltx_text ltx_font_italic" id="S4.T1.3.10.7.3.1">28.57</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.7.4">0.5873</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.7.5"><span class="ltx_text ltx_font_italic" id="S4.T1.3.10.7.5.1">1.0290</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.7.6"><span class="ltx_text ltx_font_italic" id="S4.T1.3.10.7.6.1">0.2844</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.7.7">0.6710</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.11.8">
<td class="ltx_td ltx_align_center" id="S4.T1.3.11.8.1">Clinical-WMT21fb</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.11.8.2"><span class="ltx_text ltx_font_bold" id="S4.T1.3.11.8.2.1">No</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.11.8.3">24.39</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.11.8.4">0.5840</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.11.8.5">0.8584</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.11.8.6">0.2431</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.11.8.7">0.6699</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.3">
<td class="ltx_td ltx_border_tt" id="S4.T1.3.3.2"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S4.T1.3.3.1">Task-III: Ontology Concept (OC) EN<math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.T1.3.3.1.m1.1"><semantics id="S4.T1.3.3.1.m1.1a"><mo id="S4.T1.3.3.1.m1.1.1" stretchy="false" xref="S4.T1.3.3.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.1.m1.1b"><ci id="S4.T1.3.3.1.m1.1.1.cmml" xref="S4.T1.3.3.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.3.3.1.m1.1d">→</annotation></semantics></math>ES</td>
<td class="ltx_td ltx_border_tt" id="S4.T1.3.3.3"></td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.12.9">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.12.9.1">MT fine-tuning</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.12.9.2">plm.es</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.12.9.3">S<span class="ltx_text ltx_font_smallcaps" id="S4.T1.3.12.9.3.1">acre</span>BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.12.9.4">METEOR</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.12.9.5">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.12.9.6">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.12.9.7">ROUGE-L-F1</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.13.10">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.13.10.1">Clinical-Marian</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.13.10.2">Yes</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.13.10.3">39.10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.13.10.4"><span class="ltx_text ltx_font_italic" id="S4.T1.3.13.10.4.1">0.6262</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.13.10.5">0.9495</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.13.10.6">0.3675</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.13.10.7"><span class="ltx_text ltx_font_italic" id="S4.T1.3.13.10.7.1">0.7688</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.14.11">
<td class="ltx_td ltx_align_center" id="S4.T1.3.14.11.1">Clinical-NLLB</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.14.11.2">Yes</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.14.11.3"><span class="ltx_text ltx_font_italic" id="S4.T1.3.14.11.3.1">41.63</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.14.11.4">0.6072</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.14.11.5">0.9180</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.14.11.6"><span class="ltx_text ltx_font_italic" id="S4.T1.3.14.11.6.1">0.3932</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.14.11.7">0.7477</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.15.12">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.15.12.1">Clinical-WMT21fb</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.15.12.2"><span class="ltx_text ltx_font_bold" id="S4.T1.3.15.12.2.1">No</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.15.12.3">40.71</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.15.12.4">0.5686</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.15.12.5"><span class="ltx_text ltx_font_italic" id="S4.T1.3.15.12.5.1">0.9908</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.15.12.6">0.3859</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.15.12.7">0.7199</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Automatic Evaluation of Three MPLMs using ClinSpEn-2022 Platform. ‘plm.es’ means if the Spanish language is included in PLMs.</figcaption>
</figure>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Domain Fine-tuning Corpus</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.3">To fine-tune the three MPLMs for English <math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mo id="S4.SS1.p1.1.m1.1.1" stretchy="false" xref="S4.SS1.p1.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">↔</annotation></semantics></math> Spanish language pair towards the clinical domain, we used the medical bilingual corpus MeSpEn from <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.3.1">?</span>), which contains sentences, glossaries, and terminologies.
We performed data cleaning and extracted around 250K pairs of segments in this language pair for domain fine-tuning of the three models. These extracted 250K pairs of segments are randomly chosen from the original MeSpEn corpus and we divided them into 9:1 ratio for training and development purposes.
Because the WMT21fb pre-trained model did not include Spanish as one of the pre-trained language models, we could not use <math alttext="&lt;2es&gt;" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1"><semantics id="S4.SS1.p1.2.m2.1a"><mrow id="S4.SS1.p1.2.m2.1.1.1" xref="S4.SS1.p1.2.m2.1.1.2.cmml"><mo fence="true" id="S4.SS1.p1.2.m2.1.1.1.2" rspace="0em" xref="S4.SS1.p1.2.m2.1.1.2.1.cmml">&lt;</mo><mrow id="S4.SS1.p1.2.m2.1.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.1.cmml"><mn id="S4.SS1.p1.2.m2.1.1.1.1.2" xref="S4.SS1.p1.2.m2.1.1.1.1.2.cmml">2</mn><mo id="S4.SS1.p1.2.m2.1.1.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.2.m2.1.1.1.1.3" xref="S4.SS1.p1.2.m2.1.1.1.1.3.cmml">e</mi><mo id="S4.SS1.p1.2.m2.1.1.1.1.1a" xref="S4.SS1.p1.2.m2.1.1.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.2.m2.1.1.1.1.4" xref="S4.SS1.p1.2.m2.1.1.1.1.4.cmml">s</mi></mrow><mo fence="true" id="S4.SS1.p1.2.m2.1.1.1.3" lspace="0em" xref="S4.SS1.p1.2.m2.1.1.2.1.cmml">&gt;</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.1"><csymbol cd="latexml" id="S4.SS1.p1.2.m2.1.1.2.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1.2">expectation</csymbol><apply id="S4.SS1.p1.2.m2.1.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1.1"><times id="S4.SS1.p1.2.m2.1.1.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1.1.1"></times><cn id="S4.SS1.p1.2.m2.1.1.1.1.2.cmml" type="integer" xref="S4.SS1.p1.2.m2.1.1.1.1.2">2</cn><ci id="S4.SS1.p1.2.m2.1.1.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.1.1.3">𝑒</ci><ci id="S4.SS1.p1.2.m2.1.1.1.1.4.cmml" xref="S4.SS1.p1.2.m2.1.1.1.1.4">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">&lt;2es&gt;</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">&lt; 2 italic_e italic_s &gt;</annotation></semantics></math> (to-Spanish) indicator for fine-tuning. As a solution, we used <math alttext="&lt;2ru&gt;" class="ltx_Math" display="inline" id="S4.SS1.p1.3.m3.1"><semantics id="S4.SS1.p1.3.m3.1a"><mrow id="S4.SS1.p1.3.m3.1.1.1" xref="S4.SS1.p1.3.m3.1.1.2.cmml"><mo fence="true" id="S4.SS1.p1.3.m3.1.1.1.2" rspace="0em" xref="S4.SS1.p1.3.m3.1.1.2.1.cmml">&lt;</mo><mrow id="S4.SS1.p1.3.m3.1.1.1.1" xref="S4.SS1.p1.3.m3.1.1.1.1.cmml"><mn id="S4.SS1.p1.3.m3.1.1.1.1.2" xref="S4.SS1.p1.3.m3.1.1.1.1.2.cmml">2</mn><mo id="S4.SS1.p1.3.m3.1.1.1.1.1" xref="S4.SS1.p1.3.m3.1.1.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.3.m3.1.1.1.1.3" xref="S4.SS1.p1.3.m3.1.1.1.1.3.cmml">r</mi><mo id="S4.SS1.p1.3.m3.1.1.1.1.1a" xref="S4.SS1.p1.3.m3.1.1.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.3.m3.1.1.1.1.4" xref="S4.SS1.p1.3.m3.1.1.1.1.4.cmml">u</mi></mrow><mo fence="true" id="S4.SS1.p1.3.m3.1.1.1.3" lspace="0em" xref="S4.SS1.p1.3.m3.1.1.2.1.cmml">&gt;</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.1"><csymbol cd="latexml" id="S4.SS1.p1.3.m3.1.1.2.1.cmml" xref="S4.SS1.p1.3.m3.1.1.1.2">expectation</csymbol><apply id="S4.SS1.p1.3.m3.1.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1.1.1"><times id="S4.SS1.p1.3.m3.1.1.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1.1.1.1"></times><cn id="S4.SS1.p1.3.m3.1.1.1.1.2.cmml" type="integer" xref="S4.SS1.p1.3.m3.1.1.1.1.2">2</cn><ci id="S4.SS1.p1.3.m3.1.1.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.1.1.3">𝑟</ci><ci id="S4.SS1.p1.3.m3.1.1.1.1.4.cmml" xref="S4.SS1.p1.3.m3.1.1.1.1.4">𝑢</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">&lt;2ru&gt;</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.3.m3.1d">&lt; 2 italic_r italic_u &gt;</annotation></semantics></math> as the indicator for this purpose (to-Spanish).
This means a transfer learning challenge to investigate if the extra-large multilingual PLM (xL-PLM) WMT21fb has created a semantic space to accommodate a new language pair for translation modelling using the 250K size of corpus we extracted.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Model Parameter Settings</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Some parameter settings for s-MPLM Marian model fine-tuning are listed below. The last activation function for generative model is a linear layer. Within the decoder and encoder, we used the Sigmoid Linear Units (SiLU) activation function. More detailed parameter and layer settings are displayed in Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#Sx2.F12" title="Figure 12 ‣ Appendix ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">12</span></a> (Appendix).
</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">learning rate = 2e-5</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">batch size = 128</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">weight decay - 0.01</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1">training epochs = 1</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i5.p1">
<p class="ltx_p" id="S4.I1.i5.p1.1">encoder-decoder layers = 6+6</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">Some fine-tuning parameters for NLLB-200-distilled <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx7" title="">Costa-jussà et al., 2022</a>]</cite> are listed below:</p>
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1">batch size = 24</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1">gradient accumulation steps = 8</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i3.p1">
<p class="ltx_p" id="S4.I2.i3.p1.1">weight decay = 0.01
</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i4.p1">
<p class="ltx_p" id="S4.I2.i4.p1.1">learning rate = 2e-5</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i5.p1">
<p class="ltx_p" id="S4.I2.i5.p1.1">Activation function (encoder/decoder) = ReLU</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i6.p1">
<p class="ltx_p" id="S4.I2.i6.p1.1">number of training epochs = 1</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i7.p1">
<p class="ltx_p" id="S4.I2.i7.p1.1">encoder-decoder layers = 24+24</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1">The fine-tuning parameters for WMT21fb model are the same as the NLLB-200-distilled, except for the batch size value which is set as 2. This is because the model is too large and we would get out-of-memory (OOM) errors if we increase the batch size to anything larger than 2.
More details on M2M-100 parameters and layer settings for Conditional Generation Structure <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx14" title="">Fan et al., 2021</a>]</cite> we used for xL-MPLM WMT21fb and NLLB-200
can be found in Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#Sx2.F13" title="Figure 13 ‣ Appendix ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">13</span></a> (Appendix).</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Test Sets and Automatic Evaluations</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.3">The evaluation corpus we used is from the ClinSpEn-2022 shared task challenge data organised as part of the Biomedical MT track in WMT2022 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx39" title="">Neves et al., 2022</a>]</cite>.
It has three sub-tasks: 1) EN<math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS3.p1.1.m1.1"><semantics id="S4.SS3.p1.1.m1.1a"><mo id="S4.SS3.p1.1.m1.1.1" stretchy="false" xref="S4.SS3.p1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.1.m1.1d">→</annotation></semantics></math>ES translation of 202 COVID19 clinical case reports;
2) ES<math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS3.p1.2.m2.1"><semantics id="S4.SS3.p1.2.m2.1a"><mo id="S4.SS3.p1.2.m2.1.1" stretchy="false" xref="S4.SS3.p1.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><ci id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.2.m2.1d">→</annotation></semantics></math>EN translation of 19K clinical terms from biomedical literature and EHRs; and 3) EN<math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS3.p1.3.m3.1"><semantics id="S4.SS3.p1.3.m3.1a"><mo id="S4.SS3.p1.3.m3.1.1" stretchy="false" xref="S4.SS3.p1.3.m3.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><ci id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.3.m3.1d">→</annotation></semantics></math>ES 2K ontological concept from biomedical ontology.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">The automatic evaluation metrics used for testing include
BLEU (HuggingFace) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx43" title="">Papineni et al., 2002</a>]</cite>, ROUGE-L-F1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx35" title="">Lin, 2004</a>]</cite>,
METEOR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx3" title="">Banerjee and Lavie, 2005</a>]</cite>, S<span class="ltx_text ltx_font_smallcaps" id="S4.SS3.p2.1.1">acre</span>BLEU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx47" title="">Post, 2018</a>]</cite>, and COMET <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx50" title="">Rei et al., 2020</a>]</cite>, hosted by the ClinSpEn-2022 platform <span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://temu.bsc.es/clinspen/" title="">https://temu.bsc.es/clinspen/</a></span></span></span>.
The metric scores are reported in Table <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S4.T1" title="Table 1 ‣ 4 Experimental Settings and Evaluations ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">1</span></a> for three translation tasks. In the table, the parameter ‘plm.es’ is a question mark asking if the Spanish language was already included in the original off-the-shelf PLMs. For this question, both Marian and NLLB have Spanish in their PLMs, while WMT21fb does not, which indicates that Clinical-WMT21fb is a transfer learning model for EN<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S4.SS3.p2.1.m1.1"><semantics id="S4.SS3.p2.1.m1.1a"><mo id="S4.SS3.p2.1.m1.1.1" stretchy="false" xref="S4.SS3.p2.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><ci id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.1.m1.1d">↔</annotation></semantics></math>ES language pair.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">From this automatic evaluation result, the first surprising finding is that the much smaller Clinical-Marian model had most of the highest scores across the three tasks, as indicated by <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.1">italics</span>.
The second finding concerns the two xL-MPLMs: even though the transfer-learning model Clinical-WMT21fb has a certain score gap to Clinical-NLLB on Task 1, it almost catches up with Clinical-NLLB for Task 2 and 3 even winning one of the scores, the COMET for Task 3 (0.9908 vs 0.9180).
This means that the xL-MPLM has the capacity to create a multilingual semantic space and the capability to generate a new language model as long as there is a sufficeint amount of fine-tuning corpus for this new language.
Third, there are issues with automatic metrics. This includes the confidence level on score difference (significance test), such as the very closely related scores for Task 1 on the first two winner models. In addition, the winner models change across Task 2 and 3 via different metrics.</p>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1">We also observed that there are 4 percent of Russian tokens in the EN <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS3.p4.1.m1.1"><semantics id="S4.SS3.p4.1.m1.1a"><mo id="S4.SS3.p4.1.m1.1.1" stretchy="false" xref="S4.SS3.p4.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.m1.1b"><ci id="S4.SS3.p4.1.m1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p4.1.m1.1d">→</annotation></semantics></math> ES output from the Clinical WMT21fb model. This indicates that the model keeps Russian tokens when it does not know how to translate the English token into Spanish. This is very interesting since the Russian tokens reserved in the text are not a nonsense - instead, they are tokens with correct meaning, only in a different language.
This might be the reason why COMET generated higher score for Clinical-WMT21fb model than Clinical-NLLB on Task-3 ‘ontological concept’ since COMET is a neural metric that calculates the semantic similarity on an embedding space, ignoring the word surface form.</p>
</div>
<div class="ltx_para" id="S4.SS3.p5">
<p class="ltx_p" id="S4.SS3.p5.1">To improve the trustworthiness of our empirical investigation and generate a clearer evaluation output across the three models, we perform human expert-based evaluations in the next section.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Comparisons</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">To compare our much smaller Clinical-Marian model with other existing work on this shared task data, such as Optum <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx37" title="">Manchanda and Bhagwat, 2022</a>]</cite> and Huawei <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx60" title="">Wang et al., 2022</a>]</cite>, we list the automatic evaluation scores in Table <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S4.T2" title="Table 2 ‣ 4.4 Comparisons ‣ 4 Experimental Settings and Evaluations ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">2</span></a> where Optum attended all three sub-tasks, while Huawei only attended Task 2: Clinical Terminology (CT).
From the comparison scores using automatic metrics, we can see that the much smaller Clinical-Marian wins some metrics in each of the tasks. In addition, Optum used their in-house clinical data as extra training resources in addition to WMT-offered training set, while the 250K training set we used for Clinical-Marian is extracted only using WMT data.
Huawei’s model only wins one metric (COMET) out of five metrics on Task 2 (CT), however, both Clinical-Marian and Optum win two metrics out of five.
This means that Huawei’s performance on this task is not much better even though they have much greater online resources and computational support.
</p>
</div>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S4.T2.1.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" colspan="5" id="S4.T2.1.1.1.2">Task-1: Translating Clinical Cases</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.2.1.1">Models</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.2.1.2">S<span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.2.1.2.1">acre</span>BLEU</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.1.3">METEOR</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.1.4">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.1.5">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.1.6">ROUGE</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.3.2.1">Clinical-Marian</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.3.2.2"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.3.2.2.1">38.17</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.2.3">0.6337</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.2.4">0.4237</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.2.5"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.3.2.5.1">0.3650</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.2.6">0.6270</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.1.4.3.1">Optum</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="S4.T2.1.4.3.2">38.12</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.3.3"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.4.3.3.1">0.6447</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.3.4"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.4.3.4.1">0.4425</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.3.5">0.3642</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.3.6"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.4.3.6.1">0.6285</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.5.4">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.5.4.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="5" id="S4.T2.1.5.4.2">Task-2: Clinical Terminologies</th>
</tr>
<tr class="ltx_tr" id="S4.T2.1.6.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.6.5.1">Models</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.6.5.2">S<span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.6.5.2.1">acre</span>BLEU</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.6.5.3">METEOR</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.6.5.4">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.6.5.5">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.6.5.6">ROUGE</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.7.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.7.6.1">Optum</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.7.6.2"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.7.6.2.1">44.97</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.7.6.3">0.5880</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.7.6.4">1.1197</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.7.6.5"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.7.6.5.1">0.4396</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.7.6.6">0.7479</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.8.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.1.8.7.1">Huawei</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="S4.T2.1.8.7.2">41.57</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.8.7.3">0.624</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.8.7.4"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.8.7.4.1">1.190</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.8.7.5">0.4132</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.8.7.6">0.721</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.9.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.1.9.8.1">Clinical-Marian</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="S4.T2.1.9.8.2">39.10</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.9.8.3"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.9.8.3.1">0.6261</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.9.8.4">0.9494</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.9.8.5">0.3674</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.9.8.6"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.9.8.6.1">0.7688</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.10.9">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.10.9.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="5" id="S4.T2.1.10.9.2">Task-3: Translating Ontology Concepts</th>
</tr>
<tr class="ltx_tr" id="S4.T2.1.11.10">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.11.10.1">Models</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.11.10.2">S<span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.11.10.2.1">acre</span>BLEU</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.11.10.3">METEOR</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.11.10.4">COMET</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.11.10.5">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.11.10.6">ROUGE</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.12.11">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.12.11.1">Optum</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.12.11.2"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.12.11.2.1">44.97</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.12.11.3">0.5880</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.12.11.4"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.12.11.4.1">1.1197</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.12.11.5"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.12.11.5.1">0.4396</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.12.11.6">0.7479</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.13.12">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_b" id="S4.T2.1.13.12.1">Clinical-Marian</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_b" id="S4.T2.1.13.12.2">39.10</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T2.1.13.12.3"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.13.12.3.1">0.6261</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T2.1.13.12.4">0.9494</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T2.1.13.12.5">0.3674</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T2.1.13.12.6"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.13.12.6.1">0.7688</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Model Comparisons on 3 Tasks between Clinical-Marian and Others.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Human Evaluation</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">As observed in the last section, we had two reasons to set up the expert-based human evaluation: 1) it is really surprising that the much smaller MPLM (s-MPLM) Clinical-Marian performs better than the xL-MPLMs Clinical-NLLB and Clinical-WMT21fb; 2) to verify the automatic evaluation hypothesis that Clinical-Marian really does have the best performance.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Human Evaluation Setup</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">To achieve both the qualitative and quantitative human evaluation, we deployed a human-centric expert-based post-editing quality evaluation metric called HOPE by <span class="ltx_text ltx_font_bold" id="S5.SS1.p1.1.1">?</span>) (it is also called LOGIPEM and invented by Logrus Global LLC, a language service provider).
The HOPE evaluation metric has 8 predefined error types and each error type has corresponding different levels of penalty points according to the severity level. The sentence level and system level HOPE score is a comprehensive score reflecting the overall quality of outputs.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">First, we recruited five human evaluators who have the backgrounds in professional translation, linguistics, and biomedical research.
For the evaluation data set, we took all the test set output from Task 1 ‘clinical case’ reports since this is the only task with full sentences.
For the other two tasks on term and ontology level translation, MT engines can produce relatively good outcomes even without an effective encoder-decoder neural model, e.g. via a well-prepared bilingual dictionary.
We prepared 100 strings for each set and delivered all the sets to five professional evaluators <span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>The 100 examples for evaluators were randomly selected from the test dataset and we we will make the data available.</span></span></span>.
The tasks consisted of strings of medical cases going in order one by one, so the context of each case is clear to the evaluator.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">Each one of them was given three files for evaluation from different engines, and instructions were given on both the online Perfectionist tool that was used for evaluation and the HOPE metrics.
Then, to ensure the human evaluation quality, we have also asked the strictest reviewer/evaluator to validate the work of other evaluators.
The strictest reviewer is one of our experts from the language service provider industry and has our trust according to their long-term experiences in post-editing MT outputs and selecting MT engines in real world projects.
The strictest reviewer made better distinctions between all three evaluated models, while the less-strict reviewers sometimes gave similar scores to these models without picking their errors rigorously.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Human Evaluation Output</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">The results of the evaluation can be seen in the online Perfectionist tool that was used for this purpose, as downloaded from the tool in the form of familiar Excel scorecards. They are tallied in Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.F6" title="Figure 6 ‣ 5.2 Human Evaluation Output ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">6</span></a> and Table <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.T3" title="Table 3 ‣ 5.2 Human Evaluation Output ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">3</span></a>.
The human evaluation clearly shows which model is the best demonstrating a large score gap in-between: the Clinical-Marian has a score of 0.801625, followed by Clinical-NLLB and Clinical-WMT21fb with scores of 0.768125 and 0.692429 respectively.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">To compare the human evaluation outputs with the automatic metric scores, we also added two metrics, METEOR and ROUGE, and their average score into the figure.
The reason we chose these two particular metrics is that they have a relatively positive correlation to human judgements.
For the other three metrics, there are several issues that prevented their use. First, BLEU shows NLLB as being better for terms and concepts, which does not correspond to the human judgement.
Moreover, BLEU shows WMT21fb concepts to be better than those of the Marian Helsinki model, which is completely incorrect.
Second, COMET score for the NLLB model is higher than 1, which is clearly caused by the fact that this implementation of COMET was not normalised by the Sigmoid function. Also, this COMET score for NLLB is higher than the one for Marian Helsinki. Another error is that the COMET score for clinical cases is much better than for both Marian and NLLB, which is completely impossible due to the presence of foreign language tokens in WMT21fb output.
Finally, when we see COMET scores like 0.99 and 0.949 for Concepts, the score 0.42, 0.40 and 0.34 for Cases look clearly out of line.
The BLEU-HF scores for all content types are ridiculously low on the scale of [0, 1] for both Cases and especially for Terms.</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">Below is the list of findings made from the comparisons.</p>
</div>
<div class="ltx_para" id="S5.SS2.p4">
<ul class="ltx_itemize" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1">Most importantly, all human evaluators consistently showed positive correlation with preliminary human judgement of the MT output quality. Some of them gave more rigorous evaluations than the others, but all of them rated the worst model as the worst and the best model as the best with only one exception. Results of human evaluation fully confirm initial hypothesis about the quality of outputs of different engines, which is based on initial holistic spot-check human evaluation.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1">The LOGIPEM/HOPE metric shows a much greater difference in output quality than any of the automated metrics. Where the automatic score shows a 6 percent difference, human evaluation gives 14 percent. In other words, the human linguists clearly see a significant difference between output quality of different engines. Even the less-trained evaluators show a positive correlation with the hypothesis.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i3.p1">
<p class="ltx_p" id="S5.I1.i3.p1.1">Even for those automatic metrics that correlate with human judgement, the score values do not seem to be representations of the uniform interval of [0, 1]. The LOGIPEM/HOPE score will be exactly 1 if the segments, in the reviewer’s opinion, do not have to be edited, and LOGIPEM/HOPE score of 0.8 means only about 20% by total wordcount of work left to be done on the text with that score, since the LOGIPEM/HOPE scoring model is designed with productivity assumptions in mind for various degrees of quality. The COMET or ROUGE score of 0.6 means that MT has generated words that are different from those in the reference, and this in turn means that even a perfect translation which is different from the reference would be rated much lower than 1. This is a huge distortion of linearity, which is metric-specific because all scores for different metrics live in their own ranges. Automatic scores appear to live on some sort of non-uniform scale of their own, which is yet another reason why they are not comparable to each other. The scale is compressed, and the difference between samples becomes statistically insignificant.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i4.p1">
<p class="ltx_p" id="S5.I1.i4.p1.1">The margin of error for all three engines is about 6%, which is about the same as the difference between the mean of the measurements for different engines. This means that the difference between measurement is statistically significant, but a lot depends on the subjectivity of the reviewer, and the difference between reviewers’ positions may negate the difference in scores. However, even despite the reviewers’ subjectivity, the groups of measurements for different engines appear to provide a statistically and visually significant difference.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i5.p1">
<p class="ltx_p" id="S5.I1.i5.p1.1">In general, human evaluators have to be trained / highly experienced, and need to maintain a certain level of rigour. The desired target quality should be stipulated quite clearly by customer specifications, as defined in ISO 11669 and ASTM F2575. To avoid incorrect (inflated) scores and decrease Inter-Rater Reliability (IRR), the linguists must be either tested prior to doing evaluations or cross-validated afterwards.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i6.p1">
<p class="ltx_p" id="S5.I1.i6.p1.1">One evaluation task only takes 1 hour. There were 24 evaluation tasks in total, each task with 100 segments. It does not require setting up any data processing, software development, reference “golden standard” data or model-trained evaluation metric. It is clearly faster, more cost-effective and reliable than the research on whether an automatic metric can even pass the positive correlation test with human judgement (3 out of 5 did not in our case). While individual human measurements have variance, they are all valid and all correlate with human judgement if done with minimal training and rigour.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i7.p1">
<p class="ltx_p" id="S5.I1.i7.p1.1">Automatic metrics are not comparable across different engines, different data sets, different languages and different domains. On the contrary, human measurement is the golden universal standard that provides the least common denominator between these scenarios. In other words, if Rouge is 0.67 for En-Fr for medical text, and Rouge is 0.82 for En-De for automotive text, we can’t compare these numbers. In contrast, LOGIPEM/HOPE score would mean one and the same thing across the board.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S5.SS2.p5">
<p class="ltx_p" id="S5.SS2.p5.1">All of the above confirms the validity and interoperability of our human evaluation using LOGIPEM/HOPE metrics <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx16" title="">Gladkoff and Han, 2022</a>]</cite>, which can be used as a single quick and easy validator of automatic metrics, and the ultimate fast and easy way to carry out analytic quality measurement to compare the engines and evaluate the quality of translation and post-editing.</p>
</div>
<figure class="ltx_figure" id="S5.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="217" id="S5.F6.g1" src="extracted/5422690/figs/compare_auto_vs_human_eval.png" width="565"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Comparison of Automatic Evaluations against Human Evaluation (HOPE)</figcaption>
</figure>
<figure class="ltx_table" id="S5.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T3.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.1.1.1.1">MPLMs</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S5.T3.1.1.1.2">Auto. Metrics</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S5.T3.1.1.1.3">Average</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S5.T3.1.1.1.4">Diff. in Scores</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.1.2.1">
<td class="ltx_td ltx_border_t" id="S5.T3.1.2.1.1"></td>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.2.1.2">METEOR</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.2.1.3">ROUGE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.2.1.4">Averge(M,R)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.2.1.5">HOPE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.2.1.6">Auto.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.2.1.7">HOPE</th>
</tr>
<tr class="ltx_tr" id="S5.T3.1.3.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.3.2.1">Clinical-Marian</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.3.2.2">0.6338</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.3.2.3">0.6271</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.3.2.4">0.6304</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.3.2.5">0.8016</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.3.2.6">6.45%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.3.2.7">13.62%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.4.3">
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.3.1">Clnical-NLLB</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.3.2">0.6273</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.3.3">0.6193</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.3.4">0.6233</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.3.5">0.7681</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.3.6">1.13%</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.3.7">4.18%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.5.4">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T3.1.5.4.1">Clinical-WMT21fb</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T3.1.5.4.2">0.5868</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T3.1.5.4.3">0.5927</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T3.1.5.4.4">0.5898</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T3.1.5.4.5">0.6924</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T3.1.5.4.6">5.38%</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T3.1.5.4.7">9.85%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Automatic Evaluations vs Human Evaluations (HOPE) on Three MPLMs</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Inter-Rater-Reliability</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">To measure the inter-rater-reliability (IRR) of the human evaluation we carried out, we summarise the evaluation output from five human evaluators on three models in Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.F7" title="Figure 7 ‣ 5.3 Inter-Rater-Reliability ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">7</span></a>. The summaries include the average scores for each model, the score difference between these three models, and the average scores from the three models, from each person.</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">In this case we have continuous ratings (ranging from 0 to 1) rather than categorical ratings. Therefore, Cohen’s Kappa or Fleiss’ Kappa are not the most appropriate measures for this work.
The Intraclass Correlation Coefficient (ICC) which measures reliability of ratings by comparing variability of different ratings of the same subject to the total variation across all ratings and all subjects would also not be appropriate here because there is a greater variation within the ratings of the same MT engine than between different MT engines.</p>
</div>
<div class="ltx_para" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1">However, we can compute standard deviations of the evaluations by different reviewers for each engine as follows:</p>
<ul class="ltx_itemize" id="S5.I2">
<li class="ltx_item" id="S5.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i1.p1">
<p class="ltx_p" id="S5.I2.i1.p1.1">Marian: approximately 0.101</p>
</div>
</li>
<li class="ltx_item" id="S5.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i2.p1">
<p class="ltx_p" id="S5.I2.i2.p1.1">NLLB: approximately 0.100</p>
</div>
</li>
<li class="ltx_item" id="S5.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i3.p1">
<p class="ltx_p" id="S5.I2.i3.p1.1">WMT21: approximately 0.125</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S5.SS3.p4">
<p class="ltx_p" id="S5.SS3.p4.1">These values represent the amount of variability in the ratings given by different reviewers for each engine. The confidence intervals for these measurements for confidence level of 80% are:</p>
<ul class="ltx_itemize" id="S5.I3">
<li class="ltx_item" id="S5.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I3.i1.p1">
<p class="ltx_p" id="S5.I3.i1.p1.1">Marian: approximately (0.759, 0.875)
</p>
</div>
</li>
<li class="ltx_item" id="S5.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I3.i2.p1">
<p class="ltx_p" id="S5.I3.i2.p1.1">NLLB: approximately (0.729, 0.844)</p>
</div>
</li>
<li class="ltx_item" id="S5.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I3.i3.p1">
<p class="ltx_p" id="S5.I3.i3.p1.1">WMT21: approximately (0.658, 0.802)</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S5.SS3.p5">
<p class="ltx_p" id="S5.SS3.p5.1">In other words, with 80% confidence:</p>
<ul class="ltx_itemize" id="S5.I4">
<li class="ltx_item" id="S5.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I4.i1.p1">
<p class="ltx_p" id="S5.I4.i1.p1.1">Marian: 0.817 ± 0.058</p>
</div>
</li>
<li class="ltx_item" id="S5.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I4.i2.p1">
<p class="ltx_p" id="S5.I4.i2.p1.1">NLLB: 0.7865 ± 0.0575</p>
</div>
</li>
<li class="ltx_item" id="S5.I4.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I4.i3.p1">
<p class="ltx_p" id="S5.I4.i3.p1.1">WMT21: 0.73 ± 0.072</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_figure" id="S5.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="265" id="S5.F7.g1" src="x4.png" width="784"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Summary of Human Expert-Based Evaluations</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="367" id="S5.F8.g1" src="extracted/5422690/figs/CI_each_model.png" width="565"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Confidence Intervals of Three Models (M, N, W): Clinical-Marian, Clinical-NLLB, and Clinical-WMT21fb </figcaption>
</figure>
<div class="ltx_para" id="S5.SS3.p6">
<p class="ltx_p" id="S5.SS3.p6.1">This can be visualised in Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.F8" title="Figure 8 ‣ 5.3 Inter-Rater-Reliability ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">8</span></a>. These intervals indeed overlap; however, Marian is reliably better than NLLB, and it is of course extremely surprising that WMT21fb rating is that high, considering that this result has been achieved with transfer learning by fine-tuning the engine without English-Spanish in the original PLM training dataset! As we can see, for some reviewers who are quite tolerant to errors (e.g. Evaluator-1) the quality of all the engines is almost the same.
The more proficient and knowledgeable the reviewer is, the higher is the difference in their ratings.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Error Analysis</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">We list sampled error analyses on the outputs from the fine-tuned WMT21fb and NLLB models in Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.F9" title="Figure 9 ‣ 5.4 Error Analysis ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">9</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.F10" title="Figure 10 ‣ 5.4 Error Analysis ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">10</span></a>, and <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.F11" title="Figure 11 ‣ 5.4 Error Analysis ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">11</span></a> for the three tasks on translations of sentences, terms, and concepts. The preferred translations are highlighted in green colour and “both sounds ok” is marked in orange.</p>
</div>
<div class="ltx_para" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1">From the comparisons of sampled output sentences, we discovered that the most frequent errors in a fine-grained analysis include <span class="ltx_text ltx_font_italic" id="S5.SS4.p2.1.1">literal</span> translations, <span class="ltx_text ltx_font_italic" id="S5.SS4.p2.1.2">oral vs written</span> languages, translation <span class="ltx_text ltx_font_italic" id="S5.SS4.p2.1.3">inconsistency</span>, <span class="ltx_text ltx_font_italic" id="S5.SS4.p2.1.4">inaccuracy</span> of terms, <span class="ltx_text ltx_font_italic" id="S5.SS4.p2.1.5">hallucination/made-up</span> words, and <span class="ltx_text ltx_font_italic" id="S5.SS4.p2.1.6">gender</span>-related errors such as feminine vs masculine, in addition to the standard fluency and adequacy that have been commonly used by traditional MT researchers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx20" title="">Han et al., 2021b</a>]</cite>.
For instance, in Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.F9" title="Figure 9 ‣ 5.4 Error Analysis ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">9</span></a>, the first two sentences (line 0 and 1) from clinical-WMT21fb model are more written Spanish than the clinical-NLLB model whose outputs are more oral Spanish.
However, line 6 from clinical-WMT21fb model includes the words “fuertes” which means “strong” that is not as accurate as “severas/severe” from the other model. In addition, “de manana” in the same line is less natural than “matinal” from clinical-NLLB.
Regarding gender-related issues, we can see the examples also in line 6, where clinical-WMT21fb produced “el paciente” in masculine while clinical-NLLB produced “la paciente” in feminine. However, the source did not say what gender is “the patient”.
Regarding literal translation examples, we can see in Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.F11" title="Figure 11 ‣ 5.4 Error Analysis ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">11</span></a>, line ont-19 shows that clinical-WMT21fb gives more literal translation “Mal función vesical” than the preferred one “Función vesical deficiente” by clinical-NLLB when translating “Poor bladder function”.
The neural model output hallucinations can also be found in Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.F11" title="Figure 11 ‣ 5.4 Error Analysis ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">11</span></a>, e.g. “Vejícula” does not exist and is likely a mix of “vejiga” and “vesicula” in Line ont-27; similarly, in Line ont-2, “multicística” is a mix of Spanish and English, because the correct Spanish shall be “multiquística”.</p>
</div>
<div class="ltx_para" id="S5.SS4.p3">
<p class="ltx_p" id="S5.SS4.p3.1">As we mentioned in Section <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S4" title="4 Experimental Settings and Evaluations ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">4</span></a>, there are 4% Russian tokens in the English-to-Spanish translation outputs from the Clinical-WMT21fb model which can be observed in Figures <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.F9" title="Figure 9 ‣ 5.4 Error Analysis ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">9</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.F11" title="Figure 11 ‣ 5.4 Error Analysis ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">11</span></a>. However, they are meaningful tokens, not some nonsense, e.g. the Russian tokens in Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.F9" title="Figure 9 ‣ 5.4 Error Analysis ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">9</span></a> from line n-4 means “soon” and in Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#S5.F11" title="Figure 11 ‣ 5.4 Error Analysis ‣ 5 Human Evaluation ‣ Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning"><span class="ltx_text ltx_ref_tag">11</span></a> means “type of” from ont-11.</p>
</div>
<figure class="ltx_figure" id="S5.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="270" id="S5.F9.g1" src="extracted/5422690/figs/cases_src_clinicWMT21_clinicNLLB-v3.png" width="622"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span> Task-1 Cases/Sentences EN-ES Translation Examples: clinic-WMT21fb <span class="ltx_text ltx_font_italic" id="S5.F9.2.1">vs</span> clinic-NLLB</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="468" id="S5.F10.g1" src="extracted/5422690/figs/term_src_clinicWMT21_clinicNLLB-v4.png" width="622"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span> Task-2 Clinical Term ES-EN Translation Examples: clinic-WMT21fb <span class="ltx_text ltx_font_italic" id="S5.F10.2.1">vs</span> clinic-NLLB</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="451" id="S5.F11.g1" src="extracted/5422690/figs/concept_src_clinicWMT21_clinicNLLB-v4.png" width="622"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span> Task-3 Concept EN-ES Translation Examples: clinic-WMT21fb <span class="ltx_text ltx_font_italic" id="S5.F11.2.1">vs</span> clinic-NLLB</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussions and Conclusions</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">To boost the knowledge transfer for digital healthcare and get the most knowledge out of available clinical resources, we explored the state-of-the-art neural language models regarding their performances in clinical machine translation.
We investigated a smaller multilingual pre-trained language model (s-MPLM) Marian from the Helsinki NLP group, in comparison to two extra-large MPLM (xL-MPLM) NLLB and WMT21fb from Meta-AI.
We also investigated the transfer-learning possibility in clinical domain translation using xL-MPLM WMT21fb.
We carried out data cleaning and fine-tuning in the clinical domain. We evaluated our work using both automatic evaluation metrics and human expert-based evaluation using the HOPE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.07250v2#bib.bibx16" title="">Gladkoff and Han, 2022</a>]</cite> framework.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">The experiment has led to some far-reaching conclusions about MT models and their design, test, and applications, in particular:</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">1) <span class="ltx_text ltx_font_bold" id="S6.p3.1.1">The bigger size of the model does not mean that the quality is better</span>. This premise proved to be false, evidently because researchers need vast amounts of data to train very large models and very often such data is not clear enough.
On the contrary, when we clean the data very well for fine-tuning, we can bring the model quality to much higher levels in specific domains, e.g. clinical text.
We reached the point where <span class="ltx_text ltx_font_italic" id="S6.p3.1.2">the data quality was more important than the model’s size</span>.
One key takeaway for researchers and practitioners from this is that if they can get 250,000 clean segments in a new low-resource language, they can fine-tune large language models (LLMs) and get a good enough engine in this language. Then, the next step is to continue to get clean data by post-editing translation output from that engine. This is a very important implication for “low resource languages.”</p>
</div>
<div class="ltx_para" id="S6.p4">
<p class="ltx_p" id="S6.p4.1">2) <span class="ltx_text ltx_font_bold" id="S6.p4.1.1">The automated metrics deliver an illusion of measurement</span> – they are a good tool for iterative stochastic gradient descent during training, but <span class="ltx_text ltx_font_italic" id="S6.p4.1.2">they do not measure quality</span> (only some sort of similarity), are not compatible when any of the underlying factors change, provide results on a non-uniform scale even on their interval of validity, and in general are not sufficiently reliable, and may be misleading. <span class="ltx_text ltx_font_italic" id="S6.p4.1.3">We cannot rely on automatic metrics alone</span>. Instead, human translation quality validation is a must and such validation can deny and reverse the results of automatic measurement.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">The human evaluation of this work was carried out by Betty Galiano, Marta Martínez Albaladejo, Valeria López Expósito, Carlos Mateos, and
Alfredo Madrid. We thank our human evaluators for their volunteering and hard work.
We also thank Cristina Sánchez for assisting with double checking the sampled human evaluations.
LH and GN are grateful for the support from the grant “Assembling the Data Jigsaw: Powering Robust Research on the
Causes, Determinants and Outcomes of MSK Disease.” The project has been funded by the Nuffield
Foundation, but the views expressed are those of the authors and not necessarily of the Foundation.
Visit www.nuffieldfoundation.org.
LH and GN are also supported by the grant “Integrating hospital outpatient letters into the healthcare data space” (EP/V047949/1; funder: UKRI/EPSRC).</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bibx1">
<span class="ltx_tag ltx_tag_bibitem">[Almansor and Al-Ani, 2018] </span>
<span class="ltx_bibblock">
Ebtesam H. Almansor and Ahmed Al-Ani.

</span>
<span class="ltx_bibblock">2018.

</span>
<span class="ltx_bibblock">A hybrid neural machine translation technique for translating low resource languages.

</span>
<span class="ltx_bibblock">In Petra Perner, editor, <span class="ltx_text ltx_font_italic" id="bib.bibx1.1.1">Machine Learning and Data Mining in Pattern Recognition</span>, pages 347–356, Cham. Springer International Publishing.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx2">
<span class="ltx_tag ltx_tag_bibitem">[Alyafeai et al., 2020] </span>
<span class="ltx_bibblock">
Zaid Alyafeai, Maged Saeed AlShaibani, and Irfan Ahmad.

</span>
<span class="ltx_bibblock">2020.

</span>
<span class="ltx_bibblock">A survey on transfer learning in natural language processing.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx2.1.1">arXiv preprint arXiv:2007.04239</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx3">
<span class="ltx_tag ltx_tag_bibitem">[Banerjee and Lavie, 2005] </span>
<span class="ltx_bibblock">
Satanjeev Banerjee and Alon Lavie.

</span>
<span class="ltx_bibblock">2005.

</span>
<span class="ltx_bibblock">Meteor: An automatic metric for mt evaluation with improved correlation with human judgments.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx3.1.1">Proceedings of the ACL</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx4">
<span class="ltx_tag ltx_tag_bibitem">[Belkadi et al., 2023] </span>
<span class="ltx_bibblock">
Samuel Belkadi, Nicolo Micheletti, Lifeng Han, Warren Del-Pinto, and Goran Nenadic.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Generating medical instructions with conditional transformer.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx4.1.1">NeurIPS 2023 Workshop on Synthetic Data Generation with Generative AI</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx5">
<span class="ltx_tag ltx_tag_bibitem">[Bodenreider, 2004] </span>
<span class="ltx_bibblock">
Olivier Bodenreider.

</span>
<span class="ltx_bibblock">2004.

</span>
<span class="ltx_bibblock">The unified medical language system (umls): integrating biomedical terminology.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx5.1.1">Nucleic acids research</span>, 32(suppl_1):D267–D270.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx6">
<span class="ltx_tag ltx_tag_bibitem">[Bojar et al., 2016] </span>
<span class="ltx_bibblock">
Ondřej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, Antonio Jimeno Yepes, Philipp Koehn, Varvara Logacheva, Christof Monz, Matteo Negri, Aurélie Névéol, Mariana Neves, Martin Popel, Matt Post, Raphael Rubino, Carolina Scarton, Lucia Specia, Marco Turchi, Karin Verspoor, and Marcos Zampieri.

</span>
<span class="ltx_bibblock">2016.

</span>
<span class="ltx_bibblock">Findings of the 2016 conference on machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx6.1.1">Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers</span>, pages 131–198, Berlin, Germany, August. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx7">
<span class="ltx_tag ltx_tag_bibitem">[Costa-jussà et al., 2022] </span>
<span class="ltx_bibblock">
Marta R Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, et al.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">No language left behind: Scaling human-centered machine translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx7.1.1">arXiv preprint arXiv:2207.04672</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx8">
<span class="ltx_tag ltx_tag_bibitem">[Cui et al., 2023] </span>
<span class="ltx_bibblock">
Yang Cui, Lifeng Han, and Goran Nenadic.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">MedTem2.0: Prompt-based temporal classification of treatment events from discharge summaries.

</span>
<span class="ltx_bibblock">In Vishakh Padmakumar, Gisela Vallejo, and Yao Fu, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx8.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)</span>, pages 160–183, Toronto, Canada, July. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx9">
<span class="ltx_tag ltx_tag_bibitem">[Dehghan et al., 2015] </span>
<span class="ltx_bibblock">
Azad Dehghan, Aleksandar Kovacevic, George Karystianis, John A Keane, and Goran Nenadic.

</span>
<span class="ltx_bibblock">2015.

</span>
<span class="ltx_bibblock">Combining knowledge-and data-driven methods for de-identification of clinical narratives.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx9.1.1">Journal of biomedical informatics</span>, 58(Suppl):S53.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx10">
<span class="ltx_tag ltx_tag_bibitem">[Devlin et al., 2018] </span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">2018.

</span>
<span class="ltx_bibblock">BERT: pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx10.1.1">CoRR</span>, abs/1810.04805.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx11">
<span class="ltx_tag ltx_tag_bibitem">[Dew et al., 2018] </span>
<span class="ltx_bibblock">
Kristin N Dew, Anne M Turner, Yong K Choi, Alyssa Bosold, and Katrin Kirchhoff.

</span>
<span class="ltx_bibblock">2018.

</span>
<span class="ltx_bibblock">Development of machine translation technology for assisting health communication: A systematic review.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx11.1.1">Journal of biomedical informatics</span>, 85:56–67.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx12">
<span class="ltx_tag ltx_tag_bibitem">[Donnelly, 2006] </span>
<span class="ltx_bibblock">
Kevin Donnelly.

</span>
<span class="ltx_bibblock">2006.

</span>
<span class="ltx_bibblock">Snomed-ct: The advanced terminology and coding system for ehealth.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx12.1.1">Studies in health technology and informatics</span>, 121:279.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx13">
<span class="ltx_tag ltx_tag_bibitem">[Elbattah et al., 2021] </span>
<span class="ltx_bibblock">
Mahmoud Elbattah, Émilien Arnaud, Maxime Gignon, and Gilles Dequen.

</span>
<span class="ltx_bibblock">2021.

</span>
<span class="ltx_bibblock">The role of text analytics in healthcare: A review of recent developments and applications.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx13.1.1">Healthinf</span>, 5:825–832.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx14">
<span class="ltx_tag ltx_tag_bibitem">[Fan et al., 2021] </span>
<span class="ltx_bibblock">
Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, and Armand Joulin.

</span>
<span class="ltx_bibblock">2021.

</span>
<span class="ltx_bibblock">Beyond english-centric multilingual machine translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx14.1.1">J. Mach. Learn. Res.</span>, 22(1):1–48, jan.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx15">
<span class="ltx_tag ltx_tag_bibitem">[Finley et al., 2018] </span>
<span class="ltx_bibblock">
Gregory Finley, Wael Salloum, Najmeh Sadoughi, Erik Edwards, Amanda Robinson, Nico Axtmann, Michael Brenndoerfer, Mark Miller, and David Suendermann-Oeft.

</span>
<span class="ltx_bibblock">2018.

</span>
<span class="ltx_bibblock">From dictations to clinical reports using machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx15.1.1">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)</span>, pages 121–128, New Orleans - Louisiana, June. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx16">
<span class="ltx_tag ltx_tag_bibitem">[Gladkoff and Han, 2022] </span>
<span class="ltx_bibblock">
Serge Gladkoff and Lifeng Han.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">HOPE: A task-oriented and human-centric evaluation framework using professional post-editing towards more effective MT evaluation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx16.1.1">Proceedings of the Thirteenth Language Resources and Evaluation Conference</span>, pages 13–21, Marseille, France, June. European Language Resources Association.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx17">
<span class="ltx_tag ltx_tag_bibitem">[Griciūtė et al., 2023] </span>
<span class="ltx_bibblock">
Bernadeta Griciūtė, Lifeng Han, and Goran Nenadic.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Topic modelling of swedish newspaper articles about coronavirus: a case study using latent dirichlet allocation method.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx17.1.1">2023 IEEE 11th International Conference on Healthcare Informatics (ICHI)</span>, pages 627–636.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx18">
<span class="ltx_tag ltx_tag_bibitem">[Han and Kuang, 2018] </span>
<span class="ltx_bibblock">
Lifeng Han and Shaohui Kuang.

</span>
<span class="ltx_bibblock">2018.

</span>
<span class="ltx_bibblock">Incorporating chinese radicals into neural machine translation: Deeper than character level.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx18.1.1">Proceedings of ESSLLI-2018</span>, pages 54–65. Association for Logic, Language and Information (FoLLI), August.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx19">
<span class="ltx_tag ltx_tag_bibitem">[Han et al., 2021a] </span>
<span class="ltx_bibblock">
Lifeng Han, Gareth Jones, Alan Smeaton, and Paolo Bolzoni.

</span>
<span class="ltx_bibblock">2021a.

</span>
<span class="ltx_bibblock">Chinese character decomposition for neural MT with multi-word expressions.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx19.1.1">Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa)</span>, pages 336–344, Reykjavik, Iceland (Online), May 31–2 June. Linköping University Electronic Press, Sweden.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx20">
<span class="ltx_tag ltx_tag_bibitem">[Han et al., 2021b] </span>
<span class="ltx_bibblock">
Lifeng Han, Alan Smeaton, and Gareth Jones.

</span>
<span class="ltx_bibblock">2021b.

</span>
<span class="ltx_bibblock">Translation quality assessment: A brief survey on manual and automatic methods.

</span>
<span class="ltx_bibblock">In Yuri Bizzoni, Elke Teich, Cristina España-Bonet, and Josef van Genabith, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx20.1.1">Proceedings for the First Workshop on Modelling Translation: Translatology in the Digital Age</span>, pages 15–33, online, May. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx21">
<span class="ltx_tag ltx_tag_bibitem">[Han et al., 2022a] </span>
<span class="ltx_bibblock">
Lifeng Han, Gleb Erofeev, Irina Sorokina, Serge Gladkoff, and Goran Nenadic.

</span>
<span class="ltx_bibblock">2022a.

</span>
<span class="ltx_bibblock">Examining large pre-trained language models for machine translation: What you don’t know about it.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx21.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</span>, pages 908–919, Abu Dhabi, United Arab Emirates (Hybrid), December. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx22">
<span class="ltx_tag ltx_tag_bibitem">[Han et al., 2022b] </span>
<span class="ltx_bibblock">
Lifeng Han, Gleb Erofeev, Irina Sorokina, Serge Gladkoff, and Goran Nenadic.

</span>
<span class="ltx_bibblock">2022b.

</span>
<span class="ltx_bibblock">Using massive multilingual pre-trained language models towards real zero-shot neural machine translation in clinical domain.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx22.1.1">CoRR</span>, abs/2210.06068.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx23">
<span class="ltx_tag ltx_tag_bibitem">[Han et al., 2023] </span>
<span class="ltx_bibblock">
Lifeng Han, Gleb Erofeev, Irina Sorokina, Serge Gladkoff, and Goran Nenadic.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Investigating massive multilingual pre-trained machine translation models for clinical domain via transfer learning.

</span>
<span class="ltx_bibblock">In Tristan Naumann, Asma Ben Abacha, Steven Bethard, Kirk Roberts, and Anna Rumshisky, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx23.1.1">Proceedings of the 5th Clinical Natural Language Processing Workshop</span>, pages 31–40, Toronto, Canada, July. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx24">
<span class="ltx_tag ltx_tag_bibitem">[Han, 2022] </span>
<span class="ltx_bibblock">
Lifeng Han.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx24.1.1">An investigation into multi-word expressions in machine translation</span>.

</span>
<span class="ltx_bibblock">Ph.D. thesis, Dublin City University.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx25">
<span class="ltx_tag ltx_tag_bibitem">[Henry et al., 2020] </span>
<span class="ltx_bibblock">
Sam Henry, Kevin Buchan, Michele Filannino, Amber Stubbs, and Ozlem Uzuner.

</span>
<span class="ltx_bibblock">2020.

</span>
<span class="ltx_bibblock">2018 n2c2 shared task on adverse drug events and medication extraction in electronic health records.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx25.1.1">Journal of the American Medical Informatics Association</span>, 27(1):3–12.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx26">
<span class="ltx_tag ltx_tag_bibitem">[Islam et al., 2021] </span>
<span class="ltx_bibblock">
Md Adnanul Islam, Md Saidul Hoque Anik, and ABM Alim Al Islam.

</span>
<span class="ltx_bibblock">2021.

</span>
<span class="ltx_bibblock">Towards achieving a delicate blending between rule-based translator and neural machine translator.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx26.1.1">Neural Computing and Applications</span>, 33:12141–12167.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx27">
<span class="ltx_tag ltx_tag_bibitem">[Jiang et al., 2022] </span>
<span class="ltx_bibblock">
Hao Jiang, Chao Zhang, Zhihui Xin, Xiaoqiao Huang, Chengli Li, and Yonghang Tai.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">Transfer learning based on lexical constraint mechanism in low-resource machine translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx27.1.1">Computers and Electrical Engineering</span>, 100:107856.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx28">
<span class="ltx_tag ltx_tag_bibitem">[Junczys-Dowmunt and Grundkiewicz, 2017] </span>
<span class="ltx_bibblock">
Marcin Junczys-Dowmunt and Roman Grundkiewicz.

</span>
<span class="ltx_bibblock">2017.

</span>
<span class="ltx_bibblock">An exploration of neural sequence-to-sequence architectures for automatic post-editing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx28.1.1">Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</span>, pages 120–129, Taipei, Taiwan, November. Asian Federation of Natural Language Processing.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx29">
<span class="ltx_tag ltx_tag_bibitem">[Junczys-Dowmunt et al., 2018a] </span>
<span class="ltx_bibblock">
Marcin Junczys-Dowmunt, Roman Grundkiewicz, Tomasz Dwojak, Hieu Hoang, Kenneth Heafield, Tom Neckermann, Frank Seide, Ulrich Germann, Alham Fikri Aji, Nikolay Bogoychev, André F. T. Martins, and Alexandra Birch.

</span>
<span class="ltx_bibblock">2018a.

</span>
<span class="ltx_bibblock">Marian: Fast neural machine translation in C++.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx29.1.1">Proceedings of ACL 2018, System Demonstrations</span>, pages 116–121, Melbourne, Australia, July. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx30">
<span class="ltx_tag ltx_tag_bibitem">[Junczys-Dowmunt et al., 2018b] </span>
<span class="ltx_bibblock">
Marcin Junczys-Dowmunt, Kenneth Heafield, Hieu Hoang, Roman Grundkiewicz, and Anthony Aue.

</span>
<span class="ltx_bibblock">2018b.

</span>
<span class="ltx_bibblock">Marian: Cost-effective high-quality neural machine translation in C++.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx30.1.1">Proceedings of the 2nd Workshop on Neural Machine Translation and Generation</span>, pages 129–135, Melbourne, Australia, July. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx31">
<span class="ltx_tag ltx_tag_bibitem">[Khoong and Rodriguez, 2022] </span>
<span class="ltx_bibblock">
Elaine C Khoong and Jorge A Rodriguez.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">A research agenda for using machine translation in clinical medicine.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx31.1.1">Journal of General Internal Medicine</span>, 37(5):1275–1277.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx32">
<span class="ltx_tag ltx_tag_bibitem">[Kovačević et al., 2013] </span>
<span class="ltx_bibblock">
Aleksandar Kovačević, Azad Dehghan, Michele Filannino, John A Keane, and Goran Nenadic.

</span>
<span class="ltx_bibblock">2013.

</span>
<span class="ltx_bibblock">Combining rules and machine learning for extraction of temporal expressions and events from clinical narratives.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx32.1.1">Journal of the American Medical Informatics Association: JAMIA</span>, 20(5):859.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx33">
<span class="ltx_tag ltx_tag_bibitem">[Kuang et al., 2018] </span>
<span class="ltx_bibblock">
Shaohui Kuang, Junhui Li, António Branco, Weihua Luo, and Deyi Xiong.

</span>
<span class="ltx_bibblock">2018.

</span>
<span class="ltx_bibblock">Attention focusing for neural machine translation by bridging source and target embeddings.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx33.1.1">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</span>, pages 1767–1776, Melbourne, Australia, July. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx34">
<span class="ltx_tag ltx_tag_bibitem">[Lepikhin et al., 2020] </span>
<span class="ltx_bibblock">
Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen.

</span>
<span class="ltx_bibblock">2020.

</span>
<span class="ltx_bibblock">Gshard: Scaling giant models with conditional computation and automatic sharding.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx34.1.1">International Conference on Learning Representations</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx35">
<span class="ltx_tag ltx_tag_bibitem">[Lin, 2004] </span>
<span class="ltx_bibblock">
Chin-Yew Lin.

</span>
<span class="ltx_bibblock">2004.

</span>
<span class="ltx_bibblock">ROUGE: A package for automatic evaluation of summaries.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx35.1.1">Text Summarization Branches Out</span>, pages 74–81, Barcelona, Spain, July. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx36">
<span class="ltx_tag ltx_tag_bibitem">[Luo et al., 2022] </span>
<span class="ltx_bibblock">
Xiao Luo, Priyanka Gandhi, Susan Storey, and Kun Huang.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">A deep language model for symptom extraction from clinical text and its application to extract covid-19 symptoms from social media.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx36.1.1">IEEE Journal of Biomedical and Health Informatics</span>, 26(4):1737–1748.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx37">
<span class="ltx_tag ltx_tag_bibitem">[Manchanda and Bhagwat, 2022] </span>
<span class="ltx_bibblock">
Sahil Manchanda and Saurabh Bhagwat.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">Optum’s submission to WMT22 biomedical translation tasks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx37.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</span>, pages 925–929, Abu Dhabi, United Arab Emirates (Hybrid), December. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx38">
<span class="ltx_tag ltx_tag_bibitem">[Mujjiga et al., 2019] </span>
<span class="ltx_bibblock">
Srikanth Mujjiga, Vamsi Krishna, Kalyan Chakravarthi, and J Vijayananda.

</span>
<span class="ltx_bibblock">2019.

</span>
<span class="ltx_bibblock">Identifying semantics in clinical reports using neural machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx38.1.1">Proceedings of the AAAI conference on artificial intelligence</span>, volume 33, pages 9552–9557.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx39">
<span class="ltx_tag ltx_tag_bibitem">[Neves et al., 2022] </span>
<span class="ltx_bibblock">
Mariana Neves, Antonio Jimeno Yepes, Amy Siu, Roland Roller, Philippe Thomas, Maika Vicente Navarro, Lana Yeganova, Dina Wiemann, Giorgio Maria Di Nunzio, Federica Vezzani, Christel Gerardin, Rachel Bawden, Darryl Johan Estrada, Salvador Lima-lopez, Eulalia Farre-maduel, Martin Krallinger, Cristian Grozea, and Aurelie Neveol.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">Findings of the WMT 2022 biomedical translation shared task: Monolingual clinical case reports.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx39.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</span>, pages 694–723, Abu Dhabi, United Arab Emirates (Hybrid), December. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx40">
<span class="ltx_tag ltx_tag_bibitem">[Nguyen et al., 2023] </span>
<span class="ltx_bibblock">
Nhung T. H. Nguyen, Makoto Miwa, and Sophia Ananiadou.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Span-based named entity recognition by generating and compressing information.

</span>
<span class="ltx_bibblock">In Andreas Vlachos and Isabelle Augenstein, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx40.1.1">Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics</span>, pages 1984–1996, Dubrovnik, Croatia, May. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx41">
<span class="ltx_tag ltx_tag_bibitem">[Noor et al., 2022] </span>
<span class="ltx_bibblock">
Kawsar Noor, Lukasz Roguski, Xi Bai, Alex Handy, Roman Klapaukh, Amos Folarin, Luis Romao, Joshua Matteson, Nathan Lea, Leilei Zhu, et al.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">Deployment of a free-text analytics platform at a uk national health service research hospital: Cogstack at university college london hospitals.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx41.1.1">JMIR Medical Informatics</span>, 10(8):e38122.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx42">
<span class="ltx_tag ltx_tag_bibitem">[Oyebode et al., 2021] </span>
<span class="ltx_bibblock">
Oladapo Oyebode, Chinenye Ndulue, Ashfaq Adib, Dinesh Mulchandani, Banuchitra Suruliraj, Fidelia Anulika Orji, Christine T Chambers, Sandra Meier, Rita Orji, et al.

</span>
<span class="ltx_bibblock">2021.

</span>
<span class="ltx_bibblock">Health, psychosocial, and social issues emanating from the covid-19 pandemic based on social media comments: text mining and thematic analysis approach.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx42.1.1">JMIR medical informatics</span>, 9(4):e22734.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx43">
<span class="ltx_tag ltx_tag_bibitem">[Papineni et al., 2002] </span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.

</span>
<span class="ltx_bibblock">2002.

</span>
<span class="ltx_bibblock">Bleu: a method for automatic evaluation of machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx43.1.1">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</span>, pages 311–318, Philadelphia, Pennsylvania, USA, July. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx44">
<span class="ltx_tag ltx_tag_bibitem">[Peng et al., 2019] </span>
<span class="ltx_bibblock">
Yifan Peng, Shankai Yan, and Zhiyong Lu.

</span>
<span class="ltx_bibblock">2019.

</span>
<span class="ltx_bibblock">Transfer learning in biomedical natural language processing: An evaluation of BERT and ELMo on ten benchmarking datasets.

</span>
<span class="ltx_bibblock">In Dina Demner-Fushman, Kevin Bretonnel Cohen, Sophia Ananiadou, and Junichi Tsujii, editors, <span class="ltx_text ltx_font_italic" id="bib.bibx44.1.1">Proceedings of the 18th BioNLP Workshop and Shared Task</span>, pages 58–65, Florence, Italy, August. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx45">
<span class="ltx_tag ltx_tag_bibitem">[Percha, 2021] </span>
<span class="ltx_bibblock">
Bethany Percha.

</span>
<span class="ltx_bibblock">2021.

</span>
<span class="ltx_bibblock">Modern clinical text mining: a guide and review.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx45.1.1">Annual review of biomedical data science</span>, 4:165–187.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx46">
<span class="ltx_tag ltx_tag_bibitem">[Pomares-Quimbaya et al., 2021] </span>
<span class="ltx_bibblock">
Alexandra Pomares-Quimbaya, Pilar López-Úbeda, and Stefan Schulz.

</span>
<span class="ltx_bibblock">2021.

</span>
<span class="ltx_bibblock">Transfer learning for classifying spanish and english text by clinical specialties.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx46.1.1">Public Health and Informatics</span>, pages 377–381. IOS Press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx47">
<span class="ltx_tag ltx_tag_bibitem">[Post, 2018] </span>
<span class="ltx_bibblock">
Matt Post.

</span>
<span class="ltx_bibblock">2018.

</span>
<span class="ltx_bibblock">A call for clarity in reporting BLEU scores.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx47.1.1">Proceedings of the Third Conference on Machine Translation: Research Papers</span>, pages 186–191, Belgium, Brussels, October. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx48">
<span class="ltx_tag ltx_tag_bibitem">[Qian et al., 2021] </span>
<span class="ltx_bibblock">
Zhaozhi Qian, Ahmed M Alaa, and Mihaela van der Schaar.

</span>
<span class="ltx_bibblock">2021.

</span>
<span class="ltx_bibblock">Cpas: the uk’s national machine learning-based hospital capacity planning system for covid-19.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx48.1.1">Machine Learning</span>, 110:15–35.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx49">
<span class="ltx_tag ltx_tag_bibitem">[Randhawa et al., 2013] </span>
<span class="ltx_bibblock">
Gurdeeshpal Randhawa, Mariella Ferreyra, Rukhsana Ahmed, Omar Ezzat, and Kevin Pottie.

</span>
<span class="ltx_bibblock">2013.

</span>
<span class="ltx_bibblock">Using machine translation in clinical practice.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx49.1.1">Canadian Family Physician</span>, 59(4):382–383.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx50">
<span class="ltx_tag ltx_tag_bibitem">[Rei et al., 2020] </span>
<span class="ltx_bibblock">
Ricardo Rei, Craig Stewart, Ana C Farinha, and Alon Lavie.

</span>
<span class="ltx_bibblock">2020.

</span>
<span class="ltx_bibblock">COMET: A neural framework for MT evaluation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx50.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</span>, pages 2685–2702, Online, November. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx51">
<span class="ltx_tag ltx_tag_bibitem">[Sennrich et al., 2017] </span>
<span class="ltx_bibblock">
Rico Sennrich, Orhan Firat, Kyunghyun Cho, Alexandra Birch, Barry Haddow, Julian Hitschler, Marcin Junczys-Dowmunt, Samuel Läubli, Antonio Valerio Miceli Barone, Jozef Mokry, and Maria Nadejde.

</span>
<span class="ltx_bibblock">2017.

</span>
<span class="ltx_bibblock">Nematus: a toolkit for neural machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx51.1.1">Proceedings of the Demonstrations at the 15th Conference of the European Chapter of the Association for Computational Linguistics</span>, Valencia, Spain.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx52">
<span class="ltx_tag ltx_tag_bibitem">[Soto et al., 2019] </span>
<span class="ltx_bibblock">
Xabier Soto, Olatz Perez-De-Vinaspre, Maite Oronoz, and Gorka Labaka.

</span>
<span class="ltx_bibblock">2019.

</span>
<span class="ltx_bibblock">Leveraging snomed ct terms and relations for machine translation of clinical texts from basque to spanish.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx52.1.1">Proceedings of the Second Workshop on Multilingualism at the Intersection of Knowledge Bases and Machine Translation</span>, pages 8–18.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx53">
<span class="ltx_tag ltx_tag_bibitem">[Spasic and Nenadic, 2020] </span>
<span class="ltx_bibblock">
Irena Spasic and Goran Nenadic.

</span>
<span class="ltx_bibblock">2020.

</span>
<span class="ltx_bibblock">Clinical text data in machine learning: Systematic review.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx53.1.1">JMIR Medical Informatics</span>, 8(3):e17984.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx54">
<span class="ltx_tag ltx_tag_bibitem">[Tiedemann and Thottingal, 2020] </span>
<span class="ltx_bibblock">
Jörg Tiedemann and Santhosh Thottingal.

</span>
<span class="ltx_bibblock">2020.

</span>
<span class="ltx_bibblock">OPUS-MT — Building open translation services for the World.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx54.1.1">Proceedings of the 22nd Annual Conferenec of the European Association for Machine Translation (EAMT)</span>, Lisbon, Portugal.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx55">
<span class="ltx_tag ltx_tag_bibitem">[Tiedemann, 2012] </span>
<span class="ltx_bibblock">
Jörg Tiedemann.

</span>
<span class="ltx_bibblock">2012.

</span>
<span class="ltx_bibblock">Parallel data, tools and interfaces in opus.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx55.1.1">Lrec</span>, volume 2012, pages 2214–2218. Citeseer.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx56">
<span class="ltx_tag ltx_tag_bibitem">[Tran et al., 2021] </span>
<span class="ltx_bibblock">
Chau Tran, Shruti Bhosale, James Cross, Philipp Koehn, Sergey Edunov, and Angela Fan.

</span>
<span class="ltx_bibblock">2021.

</span>
<span class="ltx_bibblock">Facebook ai’s wmt21 news translation task submission.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx56.1.1">Proc. of WMT</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx57">
<span class="ltx_tag ltx_tag_bibitem">[Tu et al., 2023] </span>
<span class="ltx_bibblock">
Hangyu Tu, Lifeng Han, and Goran Nenadic.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">Extraction of medication and temporal relation from clinical text using neural language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx57.1.1">2023 IEEE International Conference on Big Data (BigData)</span>, pages 2735–2744. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx58">
<span class="ltx_tag ltx_tag_bibitem">[Vaswani et al., 2017] </span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">2017.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx58.1.1">Proceedings of the 31st Conference on Neural Information Processing System</span>, pages 6000–6010, Long Beach, CA, USA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx59">
<span class="ltx_tag ltx_tag_bibitem">[Villegas et al., 2018] </span>
<span class="ltx_bibblock">
Marta Villegas, Ander Intxaurrondo, Aitor Gonzalez-Agirre, Montserrat Marimon, and Martin Krallinger.

</span>
<span class="ltx_bibblock">2018.

</span>
<span class="ltx_bibblock">The mespen resource for english-spanish medical machine translation and terminologies: census of parallel corpora, glossaries and term translations.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx59.1.1">LREC MultilingualBIO: multilingual biomedical text processing</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx60">
<span class="ltx_tag ltx_tag_bibitem">[Wang et al., 2022] </span>
<span class="ltx_bibblock">
Weixuan Wang, Xupeng Meng, Suqing Yan, Ye Tian, and Wei Peng.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">Huawei BabelTar NMT at WMT22 biomedical translation task: How we further improve domain-specific NMT.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx60.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</span>, pages 930–935, Abu Dhabi, United Arab Emirates (Hybrid), December. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx61">
<span class="ltx_tag ltx_tag_bibitem">[Weaver, 1955] </span>
<span class="ltx_bibblock">
Warren Weaver.

</span>
<span class="ltx_bibblock">1955.

</span>
<span class="ltx_bibblock">Translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx61.1.1">Machine Translation of Languages: Fourteen Essays</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx62">
<span class="ltx_tag ltx_tag_bibitem">[Wroge et al., 2018] </span>
<span class="ltx_bibblock">
Timothy J Wroge, Yasin Özkanca, Cenk Demiroglu, Dong Si, David C Atkins, and Reza Hosseini Ghomi.

</span>
<span class="ltx_bibblock">2018.

</span>
<span class="ltx_bibblock">Parkinson’s disease diagnosis using machine learning and voice.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx62.1.1">2018 IEEE signal processing in medicine and biology symposium (SPMB)</span>, pages 1–7. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx63">
<span class="ltx_tag ltx_tag_bibitem">[Wu et al., 2022] </span>
<span class="ltx_bibblock">
Yuping Wu, Lifeng Han, Valerio Antonini, and Goran Nenadic.

</span>
<span class="ltx_bibblock">2022.

</span>
<span class="ltx_bibblock">On cross-domain pre-trained language models for clinical text mining: How do they perform on data-constrained fine-tuning?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx63.1.1">arXiv preprint arXiv:2210.12770</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx64">
<span class="ltx_tag ltx_tag_bibitem">[Yang et al., 2009] </span>
<span class="ltx_bibblock">
Hui Yang, Irena Spasic, John A Keane, and Goran Nenadic.

</span>
<span class="ltx_bibblock">2009.

</span>
<span class="ltx_bibblock">A text mining approach to the prediction of disease status from clinical discharge summaries.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx64.1.1">Journal of the American Medical Informatics Association: JAMIA</span>, 16(4):596.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx65">
<span class="ltx_tag ltx_tag_bibitem">[Yeganova et al., 2021] </span>
<span class="ltx_bibblock">
Lana Yeganova, Dina Wiemann, Mariana Neves, Federica Vezzani, Amy Siu, Inigo Jauregi Unanue, Maite Oronoz, Nancy Mah, Aurélie Névéol, David Martinez, Rachel Bawden, Giorgio Maria Di Nunzio, Roland Roller, Philippe Thomas, Cristian Grozea, Olatz Perez-de Viñaspre, Maika Vicente Navarro, and Antonio Jimeno Yepes.

</span>
<span class="ltx_bibblock">2021.

</span>
<span class="ltx_bibblock">Findings of the WMT 2021 biomedical translation shared task: Summaries of animal experiments as new test set.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx65.1.1">Proceedings of the Sixth Conference on Machine Translation</span>, pages 664–683, Online, November. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx66">
<span class="ltx_tag ltx_tag_bibitem">[Zhang et al., 2021] </span>
<span class="ltx_bibblock">
Biao Zhang, Ankur Bapna, Rico Sennrich, and Orhan Firat.

</span>
<span class="ltx_bibblock">2021.

</span>
<span class="ltx_bibblock">Share or not? learning to schedule language-specific capacity for multilingual translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bibx66.1.1">Ninth International Conference on Learning Representations 2021</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx67">
<span class="ltx_tag ltx_tag_bibitem">[Zhu et al., 2021] </span>
<span class="ltx_bibblock">
Ziwei Zhu, Zhang Xingming, Guihua Tao, Tingting Dan, Jiao Li, Xijie Chen, Yang Li, Zhichao Zhou, Xiang Zhang, Jinzhao Zhou, et al.

</span>
<span class="ltx_bibblock">2021.

</span>
<span class="ltx_bibblock">Classification of covid-19 by compressed chest ct image through deep learning on a large patients cohort.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bibx67.1.1">Interdisciplinary Sciences: Computational Life Sciences</span>, 13:73–82.

</span>
</li>
</ul>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Appendix</h2>
<figure class="ltx_figure" id="Sx2.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="941" id="Sx2.F12.g1" src="x5.png" width="697"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>MarianNMT Fine-Tuning Parameters: Encoder and Decoder with 6+6 Layers</figcaption>
</figure>
<figure class="ltx_figure" id="Sx2.F13"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1072" id="Sx2.F13.g1" src="x6.png" width="741"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>M2M-100 Model Structure For Conditional Generation: Encoder and Decoder Parameters with 24+24 Layers</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Feb 21 12:08:56 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span style="font-size:70%;position:relative; bottom:2.2pt;">A</span>T<span style="position:relative; bottom:-0.4ex;">E</span></span><span class="ltx_font_smallcaps">xml</span><img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
