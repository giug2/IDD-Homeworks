<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2311.05790] The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning</title><meta property="og:description" content="In a data-centric era, concerns regarding privacy and ethical data handling grow as machine learning relies more on personal information. This empirical study investigates the privacy, generalization, and stability of …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2311.05790">

<!--Generated on Tue Feb 27 19:18:50 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_fleqn">
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p">[1]<span id="p1.1.1" class="ltx_ERROR undefined">\fnm</span>Elaheh <span id="p1.1.2" class="ltx_ERROR undefined">\sur</span>Jafarigol</p>
</div>
<div id="p2" class="ltx_para">
<p id="p2.1" class="ltx_p">[1]<span id="p2.1.1" class="ltx_ERROR undefined">\orgdiv</span>Data Science and Analytics Institute, <span id="p2.1.2" class="ltx_ERROR undefined">\orgname</span>University of Oklahoma, <span id="p2.1.3" class="ltx_ERROR undefined">\orgaddress</span><span id="p2.1.4" class="ltx_ERROR undefined">\street</span>202 W. Boyd St., Room 409, <span id="p2.1.5" class="ltx_ERROR undefined">\city</span>Norman, <span id="p2.1.6" class="ltx_ERROR undefined">\postcode</span>73019, <span id="p2.1.7" class="ltx_ERROR undefined">\state</span>Ok, <span id="p2.1.8" class="ltx_ERROR undefined">\country</span>USA
2]<span id="p2.1.9" class="ltx_ERROR undefined">\orgdiv</span>Industrial and Systems Engineering, <span id="p2.1.10" class="ltx_ERROR undefined">\orgname</span>University of Oklahoma, <span id="p2.1.11" class="ltx_ERROR undefined">\orgaddress</span><span id="p2.1.12" class="ltx_ERROR undefined">\street</span>202 W. Boyd St., Room 104, <span id="p2.1.13" class="ltx_ERROR undefined">\city</span>Norman, <span id="p2.1.14" class="ltx_ERROR undefined">\postcode</span>73019, <span id="p2.1.15" class="ltx_ERROR undefined">\state</span>OK, <span id="p2.1.16" class="ltx_ERROR undefined">\country</span>USA</p>
</div>
<h1 class="ltx_title ltx_title_document">The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:elaheh.jafarigol@ou.edu">elaheh.jafarigol@ou.edu</a>
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id1.1.id1" class="ltx_ERROR undefined">\fnm</span>Theodore B. <span id="id2.2.id2" class="ltx_ERROR undefined">\sur</span>Trafalis
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">*
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id3.id1" class="ltx_p">In a data-centric era, concerns regarding privacy and ethical data handling grow as machine learning relies more on personal information. This empirical study investigates the privacy, generalization, and stability of deep learning models in the presence of additive noise in federated learning frameworks. Our main objective is to provide strategies to measure the generalization, stability, and privacy-preserving capabilities of these models and further improve them.
To this end, five noise infusion mechanisms at varying noise levels within centralized and federated learning settings are explored. As model complexity is a key component of the generalization and stability of deep learning models during training and evaluation, a comparative analysis of three Convolutional Neural Network (CNN) architectures is provided.
The paper introduces Signal-to-Noise Ratio (SNR) as a quantitative measure of the trade-off between privacy and training accuracy of noise-infused models, aiming to find the noise level that yields optimal privacy and accuracy. Moreover, the Price of Stability and Price of Anarchy are defined in the context of privacy-preserving deep learning, contributing to the systematic investigation of the noise infusion strategies to enhance privacy without compromising performance. Our research sheds light on the delicate balance between these critical factors, fostering a deeper understanding of the implications of noise-based regularization in machine learning.
By leveraging noise as a tool for regularization and privacy enhancement, we aim to contribute to the development of robust, privacy-aware algorithms, ensuring that AI-driven solutions prioritize both utility and privacy.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>Federated Learning, Differential Privacy, Noise, Stability, Generalization
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In a world dominated by data-driven decision-making, artificial intelligence has offered remarkable capabilities in a wide range of applications, from healthcare to finance, smart cities, and beyond. Machine learning models, particularly deep neural networks, are built on abundant personal data, such as health records, financial data, browsing history, etc., collected by governmental organizations and the private sector. Despite the growing popularity of deep learning across domains, there are still concerns related to the algorithms’ ability to generalize, maintain stability, and ensure privacy protection against adversaries. As the new applications of artificial intelligence enter different aspects of our lives, the recognition of privacy as a fundamental human right has increased. This calls for the development of ethical and responsible learning frameworks. Without proper mechanisms, individuals are exposed to potential misuse of personal data and harm. Adhering to privacy protection policies, machine learning practitioners strive to develop tools that enable the use of sensitive data while maintaining privacy. If privacy concerns are addressed, organizations and practitioners can leverage sensitive data responsibly to harness the power of machine learning without exposing individuals to risks. Differential privacy is designed to provide strong privacy guarantees for data analysis. By adding noise to the data, the differential privacy guarantee ensures that an attacker cannot infer sensitive information from the released data.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Despite its promising implications for ensuring data privacy, adding noise to the data can result in a loss of accuracy. Therefore, more complex models are utilized to address the decline in performance since they are better at distinguishing helpful information from the noise in the data. Increasing the number of layers and hidden units in the network results in more complex models and improved generalization. However, overly complex models run the risk of overfitting and performing poorly on unseen data. Moreover, such models are more sensitive to variations in the data and model, resulting in significant fluctuations in the output.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">While excessive noise can be disruptive, introducing controlled perturbations during training can contribute to improved privacy protection through techniques like differential privacy, generalization, and stability.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The objective of this study is to evaluate this claim and develop a systematic method of fine-tuning the noise parameters to achieve the desired privacy protection guarantees without sacrificing the accuracy of the results. We focus on Convolutional Neural Networks (CNN) for image classification and delve into the challenges and strategies of noise infusion mechanisms in centralized and federated settings. The scope of this research study is outlined. The two research questions with their corresponding tasks have been proposed as follows:

<br class="ltx_break"><span id="S1.p4.1.1" class="ltx_text ltx_font_bold">Research Question 1:</span> How does the incorporation of noise in different locations within the model structure or the data affect training outcomes?

<br class="ltx_break">Task 1: Comparison of three CNN architectures to assess the impact of model capacity on generalization and stability during training and evaluation in noisy conditions.

<br class="ltx_break">Task 2: Comparison of training models with Gaussian noise hidden layers against other noise infusion mechanisms.

<br class="ltx_break">Task 3: Comparative analysis of training CNN models with Gaussian noise hidden layers under various noise levels in centralized and federated learning.

<br class="ltx_break">
<br class="ltx_break"><span id="S1.p4.1.2" class="ltx_text ltx_font_bold">Research Question 2:</span> How can we estimate the level of additive noise prior to detecting a significant model performance decrease?

<br class="ltx_break">Task 1: Introducing the Signal-to-Noise ratio to quantify the trade-off between increasing the noise level and training accuracy and to find the optimal balance between privacy and accuracy.

<br class="ltx_break">Task 2: Introducing the Price of Stability and Price of Anarchy to gain a measurable perspective on the trade-offs between model performance and privacy due to increasing noise levels.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Motivated by the potential benefits of noise, we explore the implications and limitations of training with noise to gain a deeper insight into the impact of noise on generalization, stability, privacy, and overall model performance. We combine structural stabilization and noise infusion mechanisms to improve the generalization and stability in deep neural networks while maintaining privacy. Proper architecture and regularization scheme balances the generalization power of the training model with its capacity to memorize the intricate patterns within the data without oversimplifying the model and possibly losing information. Enhanced by differential privacy, federated learning plays a pivotal role in the future of machine learning. As a collaborative framework, federated learning enables data processing without requiring the data to be centralized. Given the decentralized nature of data in federated learning, we can not utilize the sample size as we possibly could with aggregated data. Therefore, achieving stable models with great generalization is especially beneficial when working on unseen data distributed over multiple devices. Our findings shed light on the benefits of using noise to improve generalization, stability, and privacy. As federated learning provides a unique approach, the capacity of deep learning models to generalize beyond the training data while maintaining privacy and stability in the face of perturbations becomes more critical in real-world applications. By doing so, we hope to contribute to developing stable and differentially private algorithms, allowing them to generalize effectively and support federated learning.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">The paper is organized as follows. Section <a href="#S2" title="2 Preliminaries ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> discusses some background material related to generalization, stability, privacy, differential privacy, and federated learning. Section <a href="#S3" title="3 Training with Noise in Deep Neural Networks ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> explores the potential of training with noise in deep neural network architectures. We also delve into the description of the Signal-to-Noise ratio, Price of Stability, and Price of Anarchy and their applications. In section <a href="#S4" title="4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, the outcome of the numerical experimentation with a discussion of the results is provided. The numerical analysis consists of four experiments in centralized and federated settings and multiple noise infusion mechanisms. Finally, section <a href="#S5" title="5 Conclusion ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> concludes the paper.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Preliminaries</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Generalization</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Generalization is the model’s ability to make accurate predictions about unseen data drawn from the same distribution as the training data. Generalization is measured by generalization error which is the difference between the training error and the test error. The generalization capability of the algorithms can be improved in three ways:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">Structural stabilization: This approach is based on adjusting the number of free parameters to control bias in the network. In deep learning tasks, structural stabilization is done by changing the number of hidden units or pruning the weights in the architecture.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">Regularization: Controls the variance by applying modifications to the cost function and adding a penalty term.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p">Random noise injection: Empirical studies have shown that additive noise improves generalization in deep neural networks. Adding random noise behaves as a form of regularization, which prevents the model from getting too complex and memorizing the input data. Section <a href="#S3" title="3 Training with Noise in Deep Neural Networks ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> provides more details on this topic.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">In deep neural networks, generalization is impacted by the complexity and capacity of the model.</p>
</div>
<section id="S2.SS1.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Rademacher Complexity</h4>

<div id="S2.SS1.SSSx1.p1" class="ltx_para">
<p id="S2.SS1.SSSx1.p1.1" class="ltx_p">Rademacher complexity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> is a great tool for measuring the complexity of a learning algorithm.
Rademacher complexity is a quantitative way of measuring the complexity of a hypothesis class based on its ability to learn the random noise within the data and minimize the gap between the empirical risk and the true risk <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="Thmdefinition1" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="Thmdefinition1.1.1.1" class="ltx_text ltx_font_bold">Definition 1</span></span></h6>
<div id="Thmdefinition1.p1" class="ltx_para">
<p id="Thmdefinition1.p1.10" class="ltx_p"><span id="Thmdefinition1.p1.10.10" class="ltx_text ltx_font_italic">Assuming that <math id="Thmdefinition1.p1.1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="Thmdefinition1.p1.1.1.m1.1a"><mi id="Thmdefinition1.p1.1.1.m1.1.1" xref="Thmdefinition1.p1.1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.1.1.m1.1b"><ci id="Thmdefinition1.p1.1.1.m1.1.1.cmml" xref="Thmdefinition1.p1.1.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.1.1.m1.1c">S</annotation></semantics></math> is a set of data sampled from distribution <math id="Thmdefinition1.p1.2.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="Thmdefinition1.p1.2.2.m2.1a"><mi id="Thmdefinition1.p1.2.2.m2.1.1" xref="Thmdefinition1.p1.2.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.2.2.m2.1b"><ci id="Thmdefinition1.p1.2.2.m2.1.1.cmml" xref="Thmdefinition1.p1.2.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.2.2.m2.1c">D</annotation></semantics></math>, with input <math id="Thmdefinition1.p1.3.3.m3.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="Thmdefinition1.p1.3.3.m3.1a"><msub id="Thmdefinition1.p1.3.3.m3.1.1" xref="Thmdefinition1.p1.3.3.m3.1.1.cmml"><mi id="Thmdefinition1.p1.3.3.m3.1.1.2" xref="Thmdefinition1.p1.3.3.m3.1.1.2.cmml">x</mi><mi id="Thmdefinition1.p1.3.3.m3.1.1.3" xref="Thmdefinition1.p1.3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.3.3.m3.1b"><apply id="Thmdefinition1.p1.3.3.m3.1.1.cmml" xref="Thmdefinition1.p1.3.3.m3.1.1"><csymbol cd="ambiguous" id="Thmdefinition1.p1.3.3.m3.1.1.1.cmml" xref="Thmdefinition1.p1.3.3.m3.1.1">subscript</csymbol><ci id="Thmdefinition1.p1.3.3.m3.1.1.2.cmml" xref="Thmdefinition1.p1.3.3.m3.1.1.2">𝑥</ci><ci id="Thmdefinition1.p1.3.3.m3.1.1.3.cmml" xref="Thmdefinition1.p1.3.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.3.3.m3.1c">x_{i}</annotation></semantics></math> and label <math id="Thmdefinition1.p1.4.4.m4.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="Thmdefinition1.p1.4.4.m4.1a"><msub id="Thmdefinition1.p1.4.4.m4.1.1" xref="Thmdefinition1.p1.4.4.m4.1.1.cmml"><mi id="Thmdefinition1.p1.4.4.m4.1.1.2" xref="Thmdefinition1.p1.4.4.m4.1.1.2.cmml">y</mi><mi id="Thmdefinition1.p1.4.4.m4.1.1.3" xref="Thmdefinition1.p1.4.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.4.4.m4.1b"><apply id="Thmdefinition1.p1.4.4.m4.1.1.cmml" xref="Thmdefinition1.p1.4.4.m4.1.1"><csymbol cd="ambiguous" id="Thmdefinition1.p1.4.4.m4.1.1.1.cmml" xref="Thmdefinition1.p1.4.4.m4.1.1">subscript</csymbol><ci id="Thmdefinition1.p1.4.4.m4.1.1.2.cmml" xref="Thmdefinition1.p1.4.4.m4.1.1.2">𝑦</ci><ci id="Thmdefinition1.p1.4.4.m4.1.1.3.cmml" xref="Thmdefinition1.p1.4.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.4.4.m4.1c">y_{i}</annotation></semantics></math>, <math id="Thmdefinition1.p1.5.5.m5.2" class="ltx_Math" alttext="S=((x_{1},y_{1}),...(x_{m},y_{m}))\sim D" display="inline"><semantics id="Thmdefinition1.p1.5.5.m5.2a"><mrow id="Thmdefinition1.p1.5.5.m5.2.2" xref="Thmdefinition1.p1.5.5.m5.2.2.cmml"><mi id="Thmdefinition1.p1.5.5.m5.2.2.4" xref="Thmdefinition1.p1.5.5.m5.2.2.4.cmml">S</mi><mo id="Thmdefinition1.p1.5.5.m5.2.2.5" xref="Thmdefinition1.p1.5.5.m5.2.2.5.cmml">=</mo><mrow id="Thmdefinition1.p1.5.5.m5.2.2.2.2" xref="Thmdefinition1.p1.5.5.m5.2.2.2.3.cmml"><mo stretchy="false" id="Thmdefinition1.p1.5.5.m5.2.2.2.2.3" xref="Thmdefinition1.p1.5.5.m5.2.2.2.3.cmml">(</mo><mrow id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.3.cmml"><mo stretchy="false" id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2.3" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.3.cmml">(</mo><msub id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.1.1" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.1.1.cmml"><mi id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.1.1.2" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.1.1.2.cmml">x</mi><mn id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.1.1.3" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2.4" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.3.cmml">,</mo><msub id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2.2" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2.2.cmml"><mi id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2.2.2" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2.2.2.cmml">y</mi><mn id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2.2.3" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2.2.3.cmml">1</mn></msub><mo stretchy="false" id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2.5" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.3.cmml">)</mo></mrow><mo id="Thmdefinition1.p1.5.5.m5.2.2.2.2.4" xref="Thmdefinition1.p1.5.5.m5.2.2.2.3.cmml">,</mo><mrow id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.cmml"><mi mathvariant="normal" id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.4" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.4.cmml">…</mi><mo lspace="0em" rspace="0em" id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.3" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.3.cmml">​</mo><mrow id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.3.cmml"><mo stretchy="false" id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2.3" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.3.cmml">(</mo><msub id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.1.1.1" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.1.1.1.cmml"><mi id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.1.1.1.2" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.1.1.1.2.cmml">x</mi><mi id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.1.1.1.3" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.1.1.1.3.cmml">m</mi></msub><mo id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2.4" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.3.cmml">,</mo><msub id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2.2" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2.2.cmml"><mi id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2.2.2" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2.2.2.cmml">y</mi><mi id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2.2.3" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2.2.3.cmml">m</mi></msub><mo stretchy="false" id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2.5" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="Thmdefinition1.p1.5.5.m5.2.2.2.2.5" xref="Thmdefinition1.p1.5.5.m5.2.2.2.3.cmml">)</mo></mrow><mo id="Thmdefinition1.p1.5.5.m5.2.2.6" xref="Thmdefinition1.p1.5.5.m5.2.2.6.cmml">∼</mo><mi id="Thmdefinition1.p1.5.5.m5.2.2.7" xref="Thmdefinition1.p1.5.5.m5.2.2.7.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.5.5.m5.2b"><apply id="Thmdefinition1.p1.5.5.m5.2.2.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2"><and id="Thmdefinition1.p1.5.5.m5.2.2a.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2"></and><apply id="Thmdefinition1.p1.5.5.m5.2.2b.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2"><eq id="Thmdefinition1.p1.5.5.m5.2.2.5.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.5"></eq><ci id="Thmdefinition1.p1.5.5.m5.2.2.4.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.4">𝑆</ci><interval closure="open" id="Thmdefinition1.p1.5.5.m5.2.2.2.3.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2"><interval closure="open" id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.3.cmml" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2"><apply id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.1.1.cmml" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.1.1.1.cmml" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.1.1">subscript</csymbol><ci id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.1.1.2.cmml" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.1.1.2">𝑥</ci><cn type="integer" id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.1.1.3.cmml" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.1.1.3">1</cn></apply><apply id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2.2.cmml" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2.2.1.cmml" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2.2">subscript</csymbol><ci id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2.2.2.cmml" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2.2.2">𝑦</ci><cn type="integer" id="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2.2.3.cmml" xref="Thmdefinition1.p1.5.5.m5.1.1.1.1.1.2.2.3">1</cn></apply></interval><apply id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2"><times id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.3.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.3"></times><ci id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.4.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.4">…</ci><interval closure="open" id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.3.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2"><apply id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.1.1.1.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.1.1.1.1.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.1.1.1">subscript</csymbol><ci id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.1.1.1.2.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.1.1.1.2">𝑥</ci><ci id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.1.1.1.3.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.1.1.1.3">𝑚</ci></apply><apply id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2.2.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2.2.1.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2.2">subscript</csymbol><ci id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2.2.2.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2.2.2">𝑦</ci><ci id="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2.2.3.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.2.2.2.2.2.2.3">𝑚</ci></apply></interval></apply></interval></apply><apply id="Thmdefinition1.p1.5.5.m5.2.2c.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2"><csymbol cd="latexml" id="Thmdefinition1.p1.5.5.m5.2.2.6.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.6">similar-to</csymbol><share href="#Thmdefinition1.p1.5.5.m5.2.2.2.cmml" id="Thmdefinition1.p1.5.5.m5.2.2d.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2"></share><ci id="Thmdefinition1.p1.5.5.m5.2.2.7.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.7">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.5.5.m5.2c">S=((x_{1},y_{1}),...(x_{m},y_{m}))\sim D</annotation></semantics></math>, then the hypothesis class <math id="Thmdefinition1.p1.6.6.m6.1" class="ltx_Math" alttext="H" display="inline"><semantics id="Thmdefinition1.p1.6.6.m6.1a"><mi id="Thmdefinition1.p1.6.6.m6.1.1" xref="Thmdefinition1.p1.6.6.m6.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.6.6.m6.1b"><ci id="Thmdefinition1.p1.6.6.m6.1.1.cmml" xref="Thmdefinition1.p1.6.6.m6.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.6.6.m6.1c">H</annotation></semantics></math> is the set of functions that maps input <math id="Thmdefinition1.p1.7.7.m7.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="Thmdefinition1.p1.7.7.m7.1a"><msub id="Thmdefinition1.p1.7.7.m7.1.1" xref="Thmdefinition1.p1.7.7.m7.1.1.cmml"><mi id="Thmdefinition1.p1.7.7.m7.1.1.2" xref="Thmdefinition1.p1.7.7.m7.1.1.2.cmml">x</mi><mi id="Thmdefinition1.p1.7.7.m7.1.1.3" xref="Thmdefinition1.p1.7.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.7.7.m7.1b"><apply id="Thmdefinition1.p1.7.7.m7.1.1.cmml" xref="Thmdefinition1.p1.7.7.m7.1.1"><csymbol cd="ambiguous" id="Thmdefinition1.p1.7.7.m7.1.1.1.cmml" xref="Thmdefinition1.p1.7.7.m7.1.1">subscript</csymbol><ci id="Thmdefinition1.p1.7.7.m7.1.1.2.cmml" xref="Thmdefinition1.p1.7.7.m7.1.1.2">𝑥</ci><ci id="Thmdefinition1.p1.7.7.m7.1.1.3.cmml" xref="Thmdefinition1.p1.7.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.7.7.m7.1c">x_{i}</annotation></semantics></math> to <math id="Thmdefinition1.p1.8.8.m8.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="Thmdefinition1.p1.8.8.m8.1a"><msub id="Thmdefinition1.p1.8.8.m8.1.1" xref="Thmdefinition1.p1.8.8.m8.1.1.cmml"><mi id="Thmdefinition1.p1.8.8.m8.1.1.2" xref="Thmdefinition1.p1.8.8.m8.1.1.2.cmml">y</mi><mi id="Thmdefinition1.p1.8.8.m8.1.1.3" xref="Thmdefinition1.p1.8.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.8.8.m8.1b"><apply id="Thmdefinition1.p1.8.8.m8.1.1.cmml" xref="Thmdefinition1.p1.8.8.m8.1.1"><csymbol cd="ambiguous" id="Thmdefinition1.p1.8.8.m8.1.1.1.cmml" xref="Thmdefinition1.p1.8.8.m8.1.1">subscript</csymbol><ci id="Thmdefinition1.p1.8.8.m8.1.1.2.cmml" xref="Thmdefinition1.p1.8.8.m8.1.1.2">𝑦</ci><ci id="Thmdefinition1.p1.8.8.m8.1.1.3.cmml" xref="Thmdefinition1.p1.8.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.8.8.m8.1c">y_{i}</annotation></semantics></math>.
The empirical Rademacher complexity of <math id="Thmdefinition1.p1.9.9.m9.1" class="ltx_Math" alttext="H" display="inline"><semantics id="Thmdefinition1.p1.9.9.m9.1a"><mi id="Thmdefinition1.p1.9.9.m9.1.1" xref="Thmdefinition1.p1.9.9.m9.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.9.9.m9.1b"><ci id="Thmdefinition1.p1.9.9.m9.1.1.cmml" xref="Thmdefinition1.p1.9.9.m9.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.9.9.m9.1c">H</annotation></semantics></math> over <math id="Thmdefinition1.p1.10.10.m10.1" class="ltx_Math" alttext="S" display="inline"><semantics id="Thmdefinition1.p1.10.10.m10.1a"><mi id="Thmdefinition1.p1.10.10.m10.1.1" xref="Thmdefinition1.p1.10.10.m10.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.10.10.m10.1b"><ci id="Thmdefinition1.p1.10.10.m10.1.1.cmml" xref="Thmdefinition1.p1.10.10.m10.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.10.10.m10.1c">S</annotation></semantics></math> is defined as:</span></p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S2.E1.m1.2" class="ltx_Math" alttext="\mathscr{R}_{S}(H)=E_{\sigma}\left[max_{h\in H}\frac{1}{N}\sum_{i=1}^{N}\sigma_{i}h(x_{i})\right]" display="block"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml"><mrow id="S2.E1.m1.2.2.3" xref="S2.E1.m1.2.2.3.cmml"><msub id="S2.E1.m1.2.2.3.2" xref="S2.E1.m1.2.2.3.2.cmml"><mi class="ltx_font_mathscript" id="S2.E1.m1.2.2.3.2.2" xref="S2.E1.m1.2.2.3.2.2.cmml">ℛ</mi><mi id="S2.E1.m1.2.2.3.2.3" xref="S2.E1.m1.2.2.3.2.3.cmml">S</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.3.1" xref="S2.E1.m1.2.2.3.1.cmml">​</mo><mrow id="S2.E1.m1.2.2.3.3.2" xref="S2.E1.m1.2.2.3.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.3.3.2.1" xref="S2.E1.m1.2.2.3.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">H</mi><mo stretchy="false" id="S2.E1.m1.2.2.3.3.2.2" xref="S2.E1.m1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.2.2.2" xref="S2.E1.m1.2.2.2.cmml">=</mo><mrow id="S2.E1.m1.2.2.1" xref="S2.E1.m1.2.2.1.cmml"><msub id="S2.E1.m1.2.2.1.3" xref="S2.E1.m1.2.2.1.3.cmml"><mi id="S2.E1.m1.2.2.1.3.2" xref="S2.E1.m1.2.2.1.3.2.cmml">E</mi><mi id="S2.E1.m1.2.2.1.3.3" xref="S2.E1.m1.2.2.1.3.3.cmml">σ</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.2" xref="S2.E1.m1.2.2.1.2.cmml">​</mo><mrow id="S2.E1.m1.2.2.1.1.1" xref="S2.E1.m1.2.2.1.1.2.cmml"><mo id="S2.E1.m1.2.2.1.1.1.2" xref="S2.E1.m1.2.2.1.1.2.1.cmml">[</mo><mrow id="S2.E1.m1.2.2.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.2.cmml">​</mo><mi id="S2.E1.m1.2.2.1.1.1.1.4" xref="S2.E1.m1.2.2.1.1.1.1.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.1.1.2a" xref="S2.E1.m1.2.2.1.1.1.1.2.cmml">​</mo><msub id="S2.E1.m1.2.2.1.1.1.1.5" xref="S2.E1.m1.2.2.1.1.1.1.5.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.5.2" xref="S2.E1.m1.2.2.1.1.1.1.5.2.cmml">x</mi><mrow id="S2.E1.m1.2.2.1.1.1.1.5.3" xref="S2.E1.m1.2.2.1.1.1.1.5.3.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.5.3.2" xref="S2.E1.m1.2.2.1.1.1.1.5.3.2.cmml">h</mi><mo id="S2.E1.m1.2.2.1.1.1.1.5.3.1" xref="S2.E1.m1.2.2.1.1.1.1.5.3.1.cmml">∈</mo><mi id="S2.E1.m1.2.2.1.1.1.1.5.3.3" xref="S2.E1.m1.2.2.1.1.1.1.5.3.3.cmml">H</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.1.1.2b" xref="S2.E1.m1.2.2.1.1.1.1.2.cmml">​</mo><mfrac id="S2.E1.m1.2.2.1.1.1.1.6" xref="S2.E1.m1.2.2.1.1.1.1.6.cmml"><mn id="S2.E1.m1.2.2.1.1.1.1.6.2" xref="S2.E1.m1.2.2.1.1.1.1.6.2.cmml">1</mn><mi id="S2.E1.m1.2.2.1.1.1.1.6.3" xref="S2.E1.m1.2.2.1.1.1.1.6.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.1.1.2c" xref="S2.E1.m1.2.2.1.1.1.1.2.cmml">​</mo><mrow id="S2.E1.m1.2.2.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.cmml"><munderover id="S2.E1.m1.2.2.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.2.cmml"><mo movablelimits="false" id="S2.E1.m1.2.2.1.1.1.1.1.2.2.2" xref="S2.E1.m1.2.2.1.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S2.E1.m1.2.2.1.1.1.1.1.2.2.3" xref="S2.E1.m1.2.2.1.1.1.1.1.2.2.3.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.1.2.2.3.2" xref="S2.E1.m1.2.2.1.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S2.E1.m1.2.2.1.1.1.1.1.2.2.3.1" xref="S2.E1.m1.2.2.1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S2.E1.m1.2.2.1.1.1.1.1.2.2.3.3" xref="S2.E1.m1.2.2.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S2.E1.m1.2.2.1.1.1.1.1.2.3" xref="S2.E1.m1.2.2.1.1.1.1.1.2.3.cmml">N</mi></munderover><mrow id="S2.E1.m1.2.2.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.cmml"><msub id="S2.E1.m1.2.2.1.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.1.1.3.2" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3.2.cmml">σ</mi><mi id="S2.E1.m1.2.2.1.1.1.1.1.1.3.3" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.1.2.cmml">​</mo><mi id="S2.E1.m1.2.2.1.1.1.1.1.1.4" xref="S2.E1.m1.2.2.1.1.1.1.1.1.4.cmml">h</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.1.1.1.1.2a" xref="S2.E1.m1.2.2.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S2.E1.m1.2.2.1.1.1.3" xref="S2.E1.m1.2.2.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2"><eq id="S2.E1.m1.2.2.2.cmml" xref="S2.E1.m1.2.2.2"></eq><apply id="S2.E1.m1.2.2.3.cmml" xref="S2.E1.m1.2.2.3"><times id="S2.E1.m1.2.2.3.1.cmml" xref="S2.E1.m1.2.2.3.1"></times><apply id="S2.E1.m1.2.2.3.2.cmml" xref="S2.E1.m1.2.2.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.3.2.1.cmml" xref="S2.E1.m1.2.2.3.2">subscript</csymbol><ci id="S2.E1.m1.2.2.3.2.2.cmml" xref="S2.E1.m1.2.2.3.2.2">ℛ</ci><ci id="S2.E1.m1.2.2.3.2.3.cmml" xref="S2.E1.m1.2.2.3.2.3">𝑆</ci></apply><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">𝐻</ci></apply><apply id="S2.E1.m1.2.2.1.cmml" xref="S2.E1.m1.2.2.1"><times id="S2.E1.m1.2.2.1.2.cmml" xref="S2.E1.m1.2.2.1.2"></times><apply id="S2.E1.m1.2.2.1.3.cmml" xref="S2.E1.m1.2.2.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.3.1.cmml" xref="S2.E1.m1.2.2.1.3">subscript</csymbol><ci id="S2.E1.m1.2.2.1.3.2.cmml" xref="S2.E1.m1.2.2.1.3.2">𝐸</ci><ci id="S2.E1.m1.2.2.1.3.3.cmml" xref="S2.E1.m1.2.2.1.3.3">𝜎</ci></apply><apply id="S2.E1.m1.2.2.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.2.2.1.1.2.1.cmml" xref="S2.E1.m1.2.2.1.1.1.2">delimited-[]</csymbol><apply id="S2.E1.m1.2.2.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1"><times id="S2.E1.m1.2.2.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.2"></times><ci id="S2.E1.m1.2.2.1.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.3">𝑚</ci><ci id="S2.E1.m1.2.2.1.1.1.1.4.cmml" xref="S2.E1.m1.2.2.1.1.1.1.4">𝑎</ci><apply id="S2.E1.m1.2.2.1.1.1.1.5.cmml" xref="S2.E1.m1.2.2.1.1.1.1.5"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.1.5.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.5">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.1.1.5.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.5.2">𝑥</ci><apply id="S2.E1.m1.2.2.1.1.1.1.5.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.5.3"><in id="S2.E1.m1.2.2.1.1.1.1.5.3.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.5.3.1"></in><ci id="S2.E1.m1.2.2.1.1.1.1.5.3.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.5.3.2">ℎ</ci><ci id="S2.E1.m1.2.2.1.1.1.1.5.3.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.5.3.3">𝐻</ci></apply></apply><apply id="S2.E1.m1.2.2.1.1.1.1.6.cmml" xref="S2.E1.m1.2.2.1.1.1.1.6"><divide id="S2.E1.m1.2.2.1.1.1.1.6.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.6"></divide><cn type="integer" id="S2.E1.m1.2.2.1.1.1.1.6.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.6.2">1</cn><ci id="S2.E1.m1.2.2.1.1.1.1.6.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.6.3">𝑁</ci></apply><apply id="S2.E1.m1.2.2.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1"><apply id="S2.E1.m1.2.2.1.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.2">superscript</csymbol><apply id="S2.E1.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.1.1.2.2.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.2">subscript</csymbol><sum id="S2.E1.m1.2.2.1.1.1.1.1.2.2.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.2.2.2"></sum><apply id="S2.E1.m1.2.2.1.1.1.1.1.2.2.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.2.2.3"><eq id="S2.E1.m1.2.2.1.1.1.1.1.2.2.3.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.2.2.3.1"></eq><ci id="S2.E1.m1.2.2.1.1.1.1.1.2.2.3.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.2.2.3.2">𝑖</ci><cn type="integer" id="S2.E1.m1.2.2.1.1.1.1.1.2.2.3.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.2.2.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.2.3">𝑁</ci></apply><apply id="S2.E1.m1.2.2.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1"><times id="S2.E1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.2"></times><apply id="S2.E1.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3.2">𝜎</ci><ci id="S2.E1.m1.2.2.1.1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3.3">𝑖</ci></apply><ci id="S2.E1.m1.2.2.1.1.1.1.1.1.4.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.4">ℎ</ci><apply id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">\mathscr{R}_{S}(H)=E_{\sigma}\left[max_{h\in H}\frac{1}{N}\sum_{i=1}^{N}\sigma_{i}h(x_{i})\right]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="Thmdefinition1.p1.13" class="ltx_p"><span id="Thmdefinition1.p1.13.1" class="ltx_text ltx_font_italic">where,</span></p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S2.E2.m1.4" class="ltx_Math" alttext="\sigma_{i}=\begin{cases}1&amp;\text{With probability 0.5}\\
-1&amp;\text{With probability 0.5}\\
\end{cases}" display="block"><semantics id="S2.E2.m1.4a"><mrow id="S2.E2.m1.4.5" xref="S2.E2.m1.4.5.cmml"><msub id="S2.E2.m1.4.5.2" xref="S2.E2.m1.4.5.2.cmml"><mi id="S2.E2.m1.4.5.2.2" xref="S2.E2.m1.4.5.2.2.cmml">σ</mi><mi id="S2.E2.m1.4.5.2.3" xref="S2.E2.m1.4.5.2.3.cmml">i</mi></msub><mo id="S2.E2.m1.4.5.1" xref="S2.E2.m1.4.5.1.cmml">=</mo><mrow id="S2.E2.m1.4.4" xref="S2.E2.m1.4.5.3.1.cmml"><mo id="S2.E2.m1.4.4.5" xref="S2.E2.m1.4.5.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S2.E2.m1.4.4.4" xref="S2.E2.m1.4.5.3.1.cmml"><mtr id="S2.E2.m1.4.4.4a" xref="S2.E2.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.E2.m1.4.4.4b" xref="S2.E2.m1.4.5.3.1.cmml"><mn id="S2.E2.m1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.cmml">1</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.E2.m1.4.4.4c" xref="S2.E2.m1.4.5.3.1.cmml"><mtext class="ltx_mathvariant_italic" id="S2.E2.m1.2.2.2.2.2.1" xref="S2.E2.m1.2.2.2.2.2.1a.cmml">With probability 0.5</mtext></mtd></mtr><mtr id="S2.E2.m1.4.4.4d" xref="S2.E2.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.E2.m1.4.4.4e" xref="S2.E2.m1.4.5.3.1.cmml"><mrow id="S2.E2.m1.3.3.3.3.1.1" xref="S2.E2.m1.3.3.3.3.1.1.cmml"><mo id="S2.E2.m1.3.3.3.3.1.1a" xref="S2.E2.m1.3.3.3.3.1.1.cmml">−</mo><mn id="S2.E2.m1.3.3.3.3.1.1.2" xref="S2.E2.m1.3.3.3.3.1.1.2.cmml">1</mn></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.E2.m1.4.4.4f" xref="S2.E2.m1.4.5.3.1.cmml"><mtext class="ltx_mathvariant_italic" id="S2.E2.m1.4.4.4.4.2.1" xref="S2.E2.m1.4.4.4.4.2.1a.cmml">With probability 0.5</mtext></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.4b"><apply id="S2.E2.m1.4.5.cmml" xref="S2.E2.m1.4.5"><eq id="S2.E2.m1.4.5.1.cmml" xref="S2.E2.m1.4.5.1"></eq><apply id="S2.E2.m1.4.5.2.cmml" xref="S2.E2.m1.4.5.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.5.2.1.cmml" xref="S2.E2.m1.4.5.2">subscript</csymbol><ci id="S2.E2.m1.4.5.2.2.cmml" xref="S2.E2.m1.4.5.2.2">𝜎</ci><ci id="S2.E2.m1.4.5.2.3.cmml" xref="S2.E2.m1.4.5.2.3">𝑖</ci></apply><apply id="S2.E2.m1.4.5.3.1.cmml" xref="S2.E2.m1.4.4"><csymbol cd="latexml" id="S2.E2.m1.4.5.3.1.1.cmml" xref="S2.E2.m1.4.4.5">cases</csymbol><cn type="integer" id="S2.E2.m1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1">1</cn><ci id="S2.E2.m1.2.2.2.2.2.1a.cmml" xref="S2.E2.m1.2.2.2.2.2.1"><mtext class="ltx_mathvariant_italic" id="S2.E2.m1.2.2.2.2.2.1.cmml" xref="S2.E2.m1.2.2.2.2.2.1">With probability 0.5</mtext></ci><apply id="S2.E2.m1.3.3.3.3.1.1.cmml" xref="S2.E2.m1.3.3.3.3.1.1"><minus id="S2.E2.m1.3.3.3.3.1.1.1.cmml" xref="S2.E2.m1.3.3.3.3.1.1"></minus><cn type="integer" id="S2.E2.m1.3.3.3.3.1.1.2.cmml" xref="S2.E2.m1.3.3.3.3.1.1.2">1</cn></apply><ci id="S2.E2.m1.4.4.4.4.2.1a.cmml" xref="S2.E2.m1.4.4.4.4.2.1"><mtext class="ltx_mathvariant_italic" id="S2.E2.m1.4.4.4.4.2.1.cmml" xref="S2.E2.m1.4.4.4.4.2.1">With probability 0.5</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.4c">\sigma_{i}=\begin{cases}1&amp;\text{With probability 0.5}\\
-1&amp;\text{With probability 0.5}\\
\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="Thmdefinition1.p1.12" class="ltx_p"><span id="Thmdefinition1.p1.12.2" class="ltx_text ltx_font_italic">In this equation, <math id="Thmdefinition1.p1.11.1.m1.1" class="ltx_Math" alttext="E_{\sigma}" display="inline"><semantics id="Thmdefinition1.p1.11.1.m1.1a"><msub id="Thmdefinition1.p1.11.1.m1.1.1" xref="Thmdefinition1.p1.11.1.m1.1.1.cmml"><mi id="Thmdefinition1.p1.11.1.m1.1.1.2" xref="Thmdefinition1.p1.11.1.m1.1.1.2.cmml">E</mi><mi id="Thmdefinition1.p1.11.1.m1.1.1.3" xref="Thmdefinition1.p1.11.1.m1.1.1.3.cmml">σ</mi></msub><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.11.1.m1.1b"><apply id="Thmdefinition1.p1.11.1.m1.1.1.cmml" xref="Thmdefinition1.p1.11.1.m1.1.1"><csymbol cd="ambiguous" id="Thmdefinition1.p1.11.1.m1.1.1.1.cmml" xref="Thmdefinition1.p1.11.1.m1.1.1">subscript</csymbol><ci id="Thmdefinition1.p1.11.1.m1.1.1.2.cmml" xref="Thmdefinition1.p1.11.1.m1.1.1.2">𝐸</ci><ci id="Thmdefinition1.p1.11.1.m1.1.1.3.cmml" xref="Thmdefinition1.p1.11.1.m1.1.1.3">𝜎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.11.1.m1.1c">E_{\sigma}</annotation></semantics></math> is the expectation over the Rademacher random variable <math id="Thmdefinition1.p1.12.2.m2.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="Thmdefinition1.p1.12.2.m2.1a"><mi id="Thmdefinition1.p1.12.2.m2.1.1" xref="Thmdefinition1.p1.12.2.m2.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.12.2.m2.1b"><ci id="Thmdefinition1.p1.12.2.m2.1.1.cmml" xref="Thmdefinition1.p1.12.2.m2.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.12.2.m2.1c">\sigma</annotation></semantics></math>.</span></p>
</div>
</div>
<div id="S2.SS1.SSSx1.p2" class="ltx_para">
<p id="S2.SS1.SSSx1.p2.3" class="ltx_p">Rademacher random variable behaves similarly to a coin flip. Assuming that <math id="S2.SS1.SSSx1.p2.1.m1.1" class="ltx_math_unparsed" alttext="S\prime\sim D" display="inline"><semantics id="S2.SS1.SSSx1.p2.1.m1.1a"><mrow id="S2.SS1.SSSx1.p2.1.m1.1b"><mi id="S2.SS1.SSSx1.p2.1.m1.1.1">S</mi><mo lspace="0em" rspace="0.1389em" id="S2.SS1.SSSx1.p2.1.m1.1.2">′</mo><mo lspace="0.1389em" id="S2.SS1.SSSx1.p2.1.m1.1.3">∼</mo><mi id="S2.SS1.SSSx1.p2.1.m1.1.4">D</mi></mrow><annotation encoding="application/x-tex" id="S2.SS1.SSSx1.p2.1.m1.1c">S\prime\sim D</annotation></semantics></math> is a ghost sample, the labels are flipped using the Rademacher random variable, which acts as introducing random noise into the data. The goal is to find a function that minimizes the gap between the true and empirical risks while classifying the new sample <math id="S2.SS1.SSSx1.p2.2.m2.1" class="ltx_math_unparsed" alttext="S\prime" display="inline"><semantics id="S2.SS1.SSSx1.p2.2.m2.1a"><mrow id="S2.SS1.SSSx1.p2.2.m2.1b"><mi id="S2.SS1.SSSx1.p2.2.m2.1.1">S</mi><mo lspace="0em" id="S2.SS1.SSSx1.p2.2.m2.1.2">′</mo></mrow><annotation encoding="application/x-tex" id="S2.SS1.SSSx1.p2.2.m2.1c">S\prime</annotation></semantics></math>. Rademacher complexity evaluates the classifier’s success in minimizing the gap between the empirical and true risks, denoted as <math id="S2.SS1.SSSx1.p2.3.m3.2" class="ltx_Math" alttext="R(H)-\hat{R}(H)" display="inline"><semantics id="S2.SS1.SSSx1.p2.3.m3.2a"><mrow id="S2.SS1.SSSx1.p2.3.m3.2.3" xref="S2.SS1.SSSx1.p2.3.m3.2.3.cmml"><mrow id="S2.SS1.SSSx1.p2.3.m3.2.3.2" xref="S2.SS1.SSSx1.p2.3.m3.2.3.2.cmml"><mi id="S2.SS1.SSSx1.p2.3.m3.2.3.2.2" xref="S2.SS1.SSSx1.p2.3.m3.2.3.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSSx1.p2.3.m3.2.3.2.1" xref="S2.SS1.SSSx1.p2.3.m3.2.3.2.1.cmml">​</mo><mrow id="S2.SS1.SSSx1.p2.3.m3.2.3.2.3.2" xref="S2.SS1.SSSx1.p2.3.m3.2.3.2.cmml"><mo stretchy="false" id="S2.SS1.SSSx1.p2.3.m3.2.3.2.3.2.1" xref="S2.SS1.SSSx1.p2.3.m3.2.3.2.cmml">(</mo><mi id="S2.SS1.SSSx1.p2.3.m3.1.1" xref="S2.SS1.SSSx1.p2.3.m3.1.1.cmml">H</mi><mo stretchy="false" id="S2.SS1.SSSx1.p2.3.m3.2.3.2.3.2.2" xref="S2.SS1.SSSx1.p2.3.m3.2.3.2.cmml">)</mo></mrow></mrow><mo id="S2.SS1.SSSx1.p2.3.m3.2.3.1" xref="S2.SS1.SSSx1.p2.3.m3.2.3.1.cmml">−</mo><mrow id="S2.SS1.SSSx1.p2.3.m3.2.3.3" xref="S2.SS1.SSSx1.p2.3.m3.2.3.3.cmml"><mover accent="true" id="S2.SS1.SSSx1.p2.3.m3.2.3.3.2" xref="S2.SS1.SSSx1.p2.3.m3.2.3.3.2.cmml"><mi id="S2.SS1.SSSx1.p2.3.m3.2.3.3.2.2" xref="S2.SS1.SSSx1.p2.3.m3.2.3.3.2.2.cmml">R</mi><mo id="S2.SS1.SSSx1.p2.3.m3.2.3.3.2.1" xref="S2.SS1.SSSx1.p2.3.m3.2.3.3.2.1.cmml">^</mo></mover><mo lspace="0em" rspace="0em" id="S2.SS1.SSSx1.p2.3.m3.2.3.3.1" xref="S2.SS1.SSSx1.p2.3.m3.2.3.3.1.cmml">​</mo><mrow id="S2.SS1.SSSx1.p2.3.m3.2.3.3.3.2" xref="S2.SS1.SSSx1.p2.3.m3.2.3.3.cmml"><mo stretchy="false" id="S2.SS1.SSSx1.p2.3.m3.2.3.3.3.2.1" xref="S2.SS1.SSSx1.p2.3.m3.2.3.3.cmml">(</mo><mi id="S2.SS1.SSSx1.p2.3.m3.2.2" xref="S2.SS1.SSSx1.p2.3.m3.2.2.cmml">H</mi><mo stretchy="false" id="S2.SS1.SSSx1.p2.3.m3.2.3.3.3.2.2" xref="S2.SS1.SSSx1.p2.3.m3.2.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSSx1.p2.3.m3.2b"><apply id="S2.SS1.SSSx1.p2.3.m3.2.3.cmml" xref="S2.SS1.SSSx1.p2.3.m3.2.3"><minus id="S2.SS1.SSSx1.p2.3.m3.2.3.1.cmml" xref="S2.SS1.SSSx1.p2.3.m3.2.3.1"></minus><apply id="S2.SS1.SSSx1.p2.3.m3.2.3.2.cmml" xref="S2.SS1.SSSx1.p2.3.m3.2.3.2"><times id="S2.SS1.SSSx1.p2.3.m3.2.3.2.1.cmml" xref="S2.SS1.SSSx1.p2.3.m3.2.3.2.1"></times><ci id="S2.SS1.SSSx1.p2.3.m3.2.3.2.2.cmml" xref="S2.SS1.SSSx1.p2.3.m3.2.3.2.2">𝑅</ci><ci id="S2.SS1.SSSx1.p2.3.m3.1.1.cmml" xref="S2.SS1.SSSx1.p2.3.m3.1.1">𝐻</ci></apply><apply id="S2.SS1.SSSx1.p2.3.m3.2.3.3.cmml" xref="S2.SS1.SSSx1.p2.3.m3.2.3.3"><times id="S2.SS1.SSSx1.p2.3.m3.2.3.3.1.cmml" xref="S2.SS1.SSSx1.p2.3.m3.2.3.3.1"></times><apply id="S2.SS1.SSSx1.p2.3.m3.2.3.3.2.cmml" xref="S2.SS1.SSSx1.p2.3.m3.2.3.3.2"><ci id="S2.SS1.SSSx1.p2.3.m3.2.3.3.2.1.cmml" xref="S2.SS1.SSSx1.p2.3.m3.2.3.3.2.1">^</ci><ci id="S2.SS1.SSSx1.p2.3.m3.2.3.3.2.2.cmml" xref="S2.SS1.SSSx1.p2.3.m3.2.3.3.2.2">𝑅</ci></apply><ci id="S2.SS1.SSSx1.p2.3.m3.2.2.cmml" xref="S2.SS1.SSSx1.p2.3.m3.2.2">𝐻</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSSx1.p2.3.m3.2c">R(H)-\hat{R}(H)</annotation></semantics></math>. The idea behind Rademacher complexity is that maximizing the correlations between the output of the hypothesis and labels is equivalent to minimizing the training error in the presence of the Rademacher random variable. Empirical studies show that the correlation is more significant when the hypothesis space is more complex.</p>
</div>
<div id="S2.SS1.SSSx1.p3" class="ltx_para">
<p id="S2.SS1.SSSx1.p3.1" class="ltx_p">Rademacher complexity measures the trade-off between the model’s capacity to learn noise and generalizing to unseen data. Higher Rademacher complexity indicates that the classifier is better at memorizing the noise and more prone to overfitting. We can decrease model complexity by controlling the capacity to avoid this issue.</p>
</div>
</section>
<section id="S2.SS1.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Vapnik-Chervonenkis (VC) Dimension</h4>

<div id="S2.SS1.SSSx2.p1" class="ltx_para">
<p id="S2.SS1.SSSx2.p1.1" class="ltx_p">Model capacity, quantified by the VC dimension (Vapnik-Chervonenkis dimension) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, is the network’s ability to capture the underlying patterns and learn the intricate relationships within the data.</p>
</div>
<div id="Thmdefinition2" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="Thmdefinition2.1.1.1" class="ltx_text ltx_font_bold">Definition 2</span></span></h6>
<div id="Thmdefinition2.p1" class="ltx_para">
<p id="Thmdefinition2.p1.1" class="ltx_p"><span id="Thmdefinition2.p1.1.1" class="ltx_text ltx_font_italic">VC dimension of a set of functions is the largest set of finite data points that can be classified perfectly by the classifier. Hence, the training error of the model is zero. In other words, it is the maximum number of data points the classifier shatters in all possible ways.</span></p>
</div>
</div>
<div id="S2.SS1.SSSx2.p2" class="ltx_para">
<p id="S2.SS1.SSSx2.p2.1" class="ltx_p">Classifiers with higher VC dimensions have higher capacity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.</p>
</div>
<div id="S2.SS1.SSSx2.p3" class="ltx_para">
<p id="S2.SS1.SSSx2.p3.1" class="ltx_p">Focusing on neural networks as learning algorithms, the model’s capacity is correlated with the number and depth of fully connected layers and the interplay between the architecture and the non-linear activation functions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. Deep neural networks with multiple layers and millions of parameters have high capacity and VC dimension <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.</p>
</div>
<div id="S2.SS1.SSSx2.p4" class="ltx_para">
<p id="S2.SS1.SSSx2.p4.1" class="ltx_p">High model capacity indicates that the model is capable of memorizing details from the training data and possibly overfitting when facing unseen data. Conversely, low model capacity results in an oversimplified model failing to fit the data properly. So, selecting the right architecture with sufficient model capacity is critical in deep learning. Figure <a href="#S2.F1" title="Figure 1 ‣ Vapnik-Chervonenkis (VC) Dimension ‣ 2.1 Generalization ‣ 2 Preliminaries ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> summarizes the interconnections between these concepts and how they influence each other in the context of deep learning and training with noise.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2311.05790/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The relationships between the VC dimension and Rademacher complexity allow for a more unified understanding of algorithm behaviors in nondeterministic circumstances in the presence of noise and the conditions leading to improved generalization.</figcaption>
</figure>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Stability</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Stability is an essential property for learning algorithms. An algorithm is stable if the output of the algorithm doesn’t change much when the training set is altered by one point, regardless of the sample size <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite></p>
</div>
<div id="Thmdefinition3" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="Thmdefinition3.1.1.1" class="ltx_text ltx_font_bold">Definition 3</span></span></h6>
<div id="Thmdefinition3.p1" class="ltx_para">
<p id="Thmdefinition3.p1.7" class="ltx_p"><span id="Thmdefinition3.p1.7.7" class="ltx_text ltx_font_italic">Lets assume <math id="Thmdefinition3.p1.1.1.m1.4" class="ltx_Math" alttext="S=(z_{1},z_{2},...,z_{i})" display="inline"><semantics id="Thmdefinition3.p1.1.1.m1.4a"><mrow id="Thmdefinition3.p1.1.1.m1.4.4" xref="Thmdefinition3.p1.1.1.m1.4.4.cmml"><mi id="Thmdefinition3.p1.1.1.m1.4.4.5" xref="Thmdefinition3.p1.1.1.m1.4.4.5.cmml">S</mi><mo id="Thmdefinition3.p1.1.1.m1.4.4.4" xref="Thmdefinition3.p1.1.1.m1.4.4.4.cmml">=</mo><mrow id="Thmdefinition3.p1.1.1.m1.4.4.3.3" xref="Thmdefinition3.p1.1.1.m1.4.4.3.4.cmml"><mo stretchy="false" id="Thmdefinition3.p1.1.1.m1.4.4.3.3.4" xref="Thmdefinition3.p1.1.1.m1.4.4.3.4.cmml">(</mo><msub id="Thmdefinition3.p1.1.1.m1.2.2.1.1.1" xref="Thmdefinition3.p1.1.1.m1.2.2.1.1.1.cmml"><mi id="Thmdefinition3.p1.1.1.m1.2.2.1.1.1.2" xref="Thmdefinition3.p1.1.1.m1.2.2.1.1.1.2.cmml">z</mi><mn id="Thmdefinition3.p1.1.1.m1.2.2.1.1.1.3" xref="Thmdefinition3.p1.1.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="Thmdefinition3.p1.1.1.m1.4.4.3.3.5" xref="Thmdefinition3.p1.1.1.m1.4.4.3.4.cmml">,</mo><msub id="Thmdefinition3.p1.1.1.m1.3.3.2.2.2" xref="Thmdefinition3.p1.1.1.m1.3.3.2.2.2.cmml"><mi id="Thmdefinition3.p1.1.1.m1.3.3.2.2.2.2" xref="Thmdefinition3.p1.1.1.m1.3.3.2.2.2.2.cmml">z</mi><mn id="Thmdefinition3.p1.1.1.m1.3.3.2.2.2.3" xref="Thmdefinition3.p1.1.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo id="Thmdefinition3.p1.1.1.m1.4.4.3.3.6" xref="Thmdefinition3.p1.1.1.m1.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="Thmdefinition3.p1.1.1.m1.1.1" xref="Thmdefinition3.p1.1.1.m1.1.1.cmml">…</mi><mo id="Thmdefinition3.p1.1.1.m1.4.4.3.3.7" xref="Thmdefinition3.p1.1.1.m1.4.4.3.4.cmml">,</mo><msub id="Thmdefinition3.p1.1.1.m1.4.4.3.3.3" xref="Thmdefinition3.p1.1.1.m1.4.4.3.3.3.cmml"><mi id="Thmdefinition3.p1.1.1.m1.4.4.3.3.3.2" xref="Thmdefinition3.p1.1.1.m1.4.4.3.3.3.2.cmml">z</mi><mi id="Thmdefinition3.p1.1.1.m1.4.4.3.3.3.3" xref="Thmdefinition3.p1.1.1.m1.4.4.3.3.3.3.cmml">i</mi></msub><mo stretchy="false" id="Thmdefinition3.p1.1.1.m1.4.4.3.3.8" xref="Thmdefinition3.p1.1.1.m1.4.4.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition3.p1.1.1.m1.4b"><apply id="Thmdefinition3.p1.1.1.m1.4.4.cmml" xref="Thmdefinition3.p1.1.1.m1.4.4"><eq id="Thmdefinition3.p1.1.1.m1.4.4.4.cmml" xref="Thmdefinition3.p1.1.1.m1.4.4.4"></eq><ci id="Thmdefinition3.p1.1.1.m1.4.4.5.cmml" xref="Thmdefinition3.p1.1.1.m1.4.4.5">𝑆</ci><vector id="Thmdefinition3.p1.1.1.m1.4.4.3.4.cmml" xref="Thmdefinition3.p1.1.1.m1.4.4.3.3"><apply id="Thmdefinition3.p1.1.1.m1.2.2.1.1.1.cmml" xref="Thmdefinition3.p1.1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="Thmdefinition3.p1.1.1.m1.2.2.1.1.1.1.cmml" xref="Thmdefinition3.p1.1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="Thmdefinition3.p1.1.1.m1.2.2.1.1.1.2.cmml" xref="Thmdefinition3.p1.1.1.m1.2.2.1.1.1.2">𝑧</ci><cn type="integer" id="Thmdefinition3.p1.1.1.m1.2.2.1.1.1.3.cmml" xref="Thmdefinition3.p1.1.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="Thmdefinition3.p1.1.1.m1.3.3.2.2.2.cmml" xref="Thmdefinition3.p1.1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="Thmdefinition3.p1.1.1.m1.3.3.2.2.2.1.cmml" xref="Thmdefinition3.p1.1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="Thmdefinition3.p1.1.1.m1.3.3.2.2.2.2.cmml" xref="Thmdefinition3.p1.1.1.m1.3.3.2.2.2.2">𝑧</ci><cn type="integer" id="Thmdefinition3.p1.1.1.m1.3.3.2.2.2.3.cmml" xref="Thmdefinition3.p1.1.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="Thmdefinition3.p1.1.1.m1.1.1.cmml" xref="Thmdefinition3.p1.1.1.m1.1.1">…</ci><apply id="Thmdefinition3.p1.1.1.m1.4.4.3.3.3.cmml" xref="Thmdefinition3.p1.1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="Thmdefinition3.p1.1.1.m1.4.4.3.3.3.1.cmml" xref="Thmdefinition3.p1.1.1.m1.4.4.3.3.3">subscript</csymbol><ci id="Thmdefinition3.p1.1.1.m1.4.4.3.3.3.2.cmml" xref="Thmdefinition3.p1.1.1.m1.4.4.3.3.3.2">𝑧</ci><ci id="Thmdefinition3.p1.1.1.m1.4.4.3.3.3.3.cmml" xref="Thmdefinition3.p1.1.1.m1.4.4.3.3.3.3">𝑖</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition3.p1.1.1.m1.4c">S=(z_{1},z_{2},...,z_{i})</annotation></semantics></math> and <math id="Thmdefinition3.p1.2.2.m2.1" class="ltx_math_unparsed" alttext="S^{\prime}=(z_{1},z_{2},...,z_{i},z^{\prime}" display="inline"><semantics id="Thmdefinition3.p1.2.2.m2.1a"><mrow id="Thmdefinition3.p1.2.2.m2.1b"><msup id="Thmdefinition3.p1.2.2.m2.1.2"><mi id="Thmdefinition3.p1.2.2.m2.1.2.2">S</mi><mo id="Thmdefinition3.p1.2.2.m2.1.2.3">′</mo></msup><mo id="Thmdefinition3.p1.2.2.m2.1.3">=</mo><mrow id="Thmdefinition3.p1.2.2.m2.1.4"><mo stretchy="false" id="Thmdefinition3.p1.2.2.m2.1.4.1">(</mo><msub id="Thmdefinition3.p1.2.2.m2.1.4.2"><mi id="Thmdefinition3.p1.2.2.m2.1.4.2.2">z</mi><mn id="Thmdefinition3.p1.2.2.m2.1.4.2.3">1</mn></msub><mo id="Thmdefinition3.p1.2.2.m2.1.4.3">,</mo><msub id="Thmdefinition3.p1.2.2.m2.1.4.4"><mi id="Thmdefinition3.p1.2.2.m2.1.4.4.2">z</mi><mn id="Thmdefinition3.p1.2.2.m2.1.4.4.3">2</mn></msub><mo id="Thmdefinition3.p1.2.2.m2.1.4.5">,</mo><mi mathvariant="normal" id="Thmdefinition3.p1.2.2.m2.1.1">…</mi><mo id="Thmdefinition3.p1.2.2.m2.1.4.6">,</mo><msub id="Thmdefinition3.p1.2.2.m2.1.4.7"><mi id="Thmdefinition3.p1.2.2.m2.1.4.7.2">z</mi><mi id="Thmdefinition3.p1.2.2.m2.1.4.7.3">i</mi></msub><mo id="Thmdefinition3.p1.2.2.m2.1.4.8">,</mo><msup id="Thmdefinition3.p1.2.2.m2.1.4.9"><mi id="Thmdefinition3.p1.2.2.m2.1.4.9.2">z</mi><mo id="Thmdefinition3.p1.2.2.m2.1.4.9.3">′</mo></msup></mrow></mrow><annotation encoding="application/x-tex" id="Thmdefinition3.p1.2.2.m2.1c">S^{\prime}=(z_{1},z_{2},...,z_{i},z^{\prime}</annotation></semantics></math>) are two neighboring datasets that differ in one point <math id="Thmdefinition3.p1.3.3.m3.1" class="ltx_Math" alttext="z^{\prime}" display="inline"><semantics id="Thmdefinition3.p1.3.3.m3.1a"><msup id="Thmdefinition3.p1.3.3.m3.1.1" xref="Thmdefinition3.p1.3.3.m3.1.1.cmml"><mi id="Thmdefinition3.p1.3.3.m3.1.1.2" xref="Thmdefinition3.p1.3.3.m3.1.1.2.cmml">z</mi><mo id="Thmdefinition3.p1.3.3.m3.1.1.3" xref="Thmdefinition3.p1.3.3.m3.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="Thmdefinition3.p1.3.3.m3.1b"><apply id="Thmdefinition3.p1.3.3.m3.1.1.cmml" xref="Thmdefinition3.p1.3.3.m3.1.1"><csymbol cd="ambiguous" id="Thmdefinition3.p1.3.3.m3.1.1.1.cmml" xref="Thmdefinition3.p1.3.3.m3.1.1">superscript</csymbol><ci id="Thmdefinition3.p1.3.3.m3.1.1.2.cmml" xref="Thmdefinition3.p1.3.3.m3.1.1.2">𝑧</ci><ci id="Thmdefinition3.p1.3.3.m3.1.1.3.cmml" xref="Thmdefinition3.p1.3.3.m3.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition3.p1.3.3.m3.1c">z^{\prime}</annotation></semantics></math>. For learning algorithm <math id="Thmdefinition3.p1.4.4.m4.1" class="ltx_Math" alttext="h" display="inline"><semantics id="Thmdefinition3.p1.4.4.m4.1a"><mi id="Thmdefinition3.p1.4.4.m4.1.1" xref="Thmdefinition3.p1.4.4.m4.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition3.p1.4.4.m4.1b"><ci id="Thmdefinition3.p1.4.4.m4.1.1.cmml" xref="Thmdefinition3.p1.4.4.m4.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition3.p1.4.4.m4.1c">h</annotation></semantics></math>, the loss function at point <math id="Thmdefinition3.p1.5.5.m5.1" class="ltx_Math" alttext="z" display="inline"><semantics id="Thmdefinition3.p1.5.5.m5.1a"><mi id="Thmdefinition3.p1.5.5.m5.1.1" xref="Thmdefinition3.p1.5.5.m5.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition3.p1.5.5.m5.1b"><ci id="Thmdefinition3.p1.5.5.m5.1.1.cmml" xref="Thmdefinition3.p1.5.5.m5.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition3.p1.5.5.m5.1c">z</annotation></semantics></math> is denoted as <math id="Thmdefinition3.p1.6.6.m6.1" class="ltx_Math" alttext="L_{z}(h)" display="inline"><semantics id="Thmdefinition3.p1.6.6.m6.1a"><mrow id="Thmdefinition3.p1.6.6.m6.1.2" xref="Thmdefinition3.p1.6.6.m6.1.2.cmml"><msub id="Thmdefinition3.p1.6.6.m6.1.2.2" xref="Thmdefinition3.p1.6.6.m6.1.2.2.cmml"><mi id="Thmdefinition3.p1.6.6.m6.1.2.2.2" xref="Thmdefinition3.p1.6.6.m6.1.2.2.2.cmml">L</mi><mi id="Thmdefinition3.p1.6.6.m6.1.2.2.3" xref="Thmdefinition3.p1.6.6.m6.1.2.2.3.cmml">z</mi></msub><mo lspace="0em" rspace="0em" id="Thmdefinition3.p1.6.6.m6.1.2.1" xref="Thmdefinition3.p1.6.6.m6.1.2.1.cmml">​</mo><mrow id="Thmdefinition3.p1.6.6.m6.1.2.3.2" xref="Thmdefinition3.p1.6.6.m6.1.2.cmml"><mo stretchy="false" id="Thmdefinition3.p1.6.6.m6.1.2.3.2.1" xref="Thmdefinition3.p1.6.6.m6.1.2.cmml">(</mo><mi id="Thmdefinition3.p1.6.6.m6.1.1" xref="Thmdefinition3.p1.6.6.m6.1.1.cmml">h</mi><mo stretchy="false" id="Thmdefinition3.p1.6.6.m6.1.2.3.2.2" xref="Thmdefinition3.p1.6.6.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition3.p1.6.6.m6.1b"><apply id="Thmdefinition3.p1.6.6.m6.1.2.cmml" xref="Thmdefinition3.p1.6.6.m6.1.2"><times id="Thmdefinition3.p1.6.6.m6.1.2.1.cmml" xref="Thmdefinition3.p1.6.6.m6.1.2.1"></times><apply id="Thmdefinition3.p1.6.6.m6.1.2.2.cmml" xref="Thmdefinition3.p1.6.6.m6.1.2.2"><csymbol cd="ambiguous" id="Thmdefinition3.p1.6.6.m6.1.2.2.1.cmml" xref="Thmdefinition3.p1.6.6.m6.1.2.2">subscript</csymbol><ci id="Thmdefinition3.p1.6.6.m6.1.2.2.2.cmml" xref="Thmdefinition3.p1.6.6.m6.1.2.2.2">𝐿</ci><ci id="Thmdefinition3.p1.6.6.m6.1.2.2.3.cmml" xref="Thmdefinition3.p1.6.6.m6.1.2.2.3">𝑧</ci></apply><ci id="Thmdefinition3.p1.6.6.m6.1.1.cmml" xref="Thmdefinition3.p1.6.6.m6.1.1">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition3.p1.6.6.m6.1c">L_{z}(h)</annotation></semantics></math>. A learning algorithm is uniformly stable if equation <a href="#S2.E3" title="In Definition 3 ‣ 2.2 Stability ‣ 2 Preliminaries ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> holds for all <math id="Thmdefinition3.p1.7.7.m7.1" class="ltx_Math" alttext="z" display="inline"><semantics id="Thmdefinition3.p1.7.7.m7.1a"><mi id="Thmdefinition3.p1.7.7.m7.1.1" xref="Thmdefinition3.p1.7.7.m7.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition3.p1.7.7.m7.1b"><ci id="Thmdefinition3.p1.7.7.m7.1.1.cmml" xref="Thmdefinition3.p1.7.7.m7.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition3.p1.7.7.m7.1c">z</annotation></semantics></math>.</span></p>
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S2.E3.m1.2" class="ltx_Math" alttext="\forall z\in z,|L_{z}(h_{s})-L_{Z}(H_{S^{\prime}})|\leq\beta" display="block"><semantics id="S2.E3.m1.2a"><mrow id="S2.E3.m1.2.2.2" xref="S2.E3.m1.2.2.3.cmml"><mrow id="S2.E3.m1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml"><mrow id="S2.E3.m1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.2.cmml"><mo rspace="0.167em" id="S2.E3.m1.1.1.1.1.2.1" xref="S2.E3.m1.1.1.1.1.2.1.cmml">∀</mo><mi id="S2.E3.m1.1.1.1.1.2.2" xref="S2.E3.m1.1.1.1.1.2.2.cmml">z</mi></mrow><mo id="S2.E3.m1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.cmml">∈</mo><mi id="S2.E3.m1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.3.cmml">z</mi></mrow><mo id="S2.E3.m1.2.2.2.3" xref="S2.E3.m1.2.2.3a.cmml">,</mo><mrow id="S2.E3.m1.2.2.2.2" xref="S2.E3.m1.2.2.2.2.cmml"><mrow id="S2.E3.m1.2.2.2.2.1.1" xref="S2.E3.m1.2.2.2.2.1.2.cmml"><mo stretchy="false" id="S2.E3.m1.2.2.2.2.1.1.2" xref="S2.E3.m1.2.2.2.2.1.2.1.cmml">|</mo><mrow id="S2.E3.m1.2.2.2.2.1.1.1" xref="S2.E3.m1.2.2.2.2.1.1.1.cmml"><mrow id="S2.E3.m1.2.2.2.2.1.1.1.1" xref="S2.E3.m1.2.2.2.2.1.1.1.1.cmml"><msub id="S2.E3.m1.2.2.2.2.1.1.1.1.3" xref="S2.E3.m1.2.2.2.2.1.1.1.1.3.cmml"><mi id="S2.E3.m1.2.2.2.2.1.1.1.1.3.2" xref="S2.E3.m1.2.2.2.2.1.1.1.1.3.2.cmml">L</mi><mi id="S2.E3.m1.2.2.2.2.1.1.1.1.3.3" xref="S2.E3.m1.2.2.2.2.1.1.1.1.3.3.cmml">z</mi></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.2.2.1.1.1.1.2" xref="S2.E3.m1.2.2.2.2.1.1.1.1.2.cmml">​</mo><mrow id="S2.E3.m1.2.2.2.2.1.1.1.1.1.1" xref="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.2" xref="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.1" xref="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.1.2" xref="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.1.2.cmml">h</mi><mi id="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.1.3" xref="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.1.3.cmml">s</mi></msub><mo stretchy="false" id="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.3" xref="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.2.2.2.2.1.1.1.3" xref="S2.E3.m1.2.2.2.2.1.1.1.3.cmml">−</mo><mrow id="S2.E3.m1.2.2.2.2.1.1.1.2" xref="S2.E3.m1.2.2.2.2.1.1.1.2.cmml"><msub id="S2.E3.m1.2.2.2.2.1.1.1.2.3" xref="S2.E3.m1.2.2.2.2.1.1.1.2.3.cmml"><mi id="S2.E3.m1.2.2.2.2.1.1.1.2.3.2" xref="S2.E3.m1.2.2.2.2.1.1.1.2.3.2.cmml">L</mi><mi id="S2.E3.m1.2.2.2.2.1.1.1.2.3.3" xref="S2.E3.m1.2.2.2.2.1.1.1.2.3.3.cmml">Z</mi></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.2.2.1.1.1.2.2" xref="S2.E3.m1.2.2.2.2.1.1.1.2.2.cmml">​</mo><mrow id="S2.E3.m1.2.2.2.2.1.1.1.2.1.1" xref="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.2" xref="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.cmml">(</mo><msub id="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1" xref="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.cmml"><mi id="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.2" xref="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.2.cmml">H</mi><msup id="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.3" xref="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.3.cmml"><mi id="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.3.2" xref="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.3.2.cmml">S</mi><mo id="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.3.3" xref="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.3.3.cmml">′</mo></msup></msub><mo stretchy="false" id="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.3" xref="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S2.E3.m1.2.2.2.2.1.1.3" xref="S2.E3.m1.2.2.2.2.1.2.1.cmml">|</mo></mrow><mo id="S2.E3.m1.2.2.2.2.2" xref="S2.E3.m1.2.2.2.2.2.cmml">≤</mo><mi id="S2.E3.m1.2.2.2.2.3" xref="S2.E3.m1.2.2.2.2.3.cmml">β</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.2b"><apply id="S2.E3.m1.2.2.3.cmml" xref="S2.E3.m1.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.3a.cmml" xref="S2.E3.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S2.E3.m1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1"><in id="S2.E3.m1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1"></in><apply id="S2.E3.m1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.2"><csymbol cd="latexml" id="S2.E3.m1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.1.1.1.1.2.1">for-all</csymbol><ci id="S2.E3.m1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.1.1.1.1.2.2">𝑧</ci></apply><ci id="S2.E3.m1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.3">𝑧</ci></apply><apply id="S2.E3.m1.2.2.2.2.cmml" xref="S2.E3.m1.2.2.2.2"><leq id="S2.E3.m1.2.2.2.2.2.cmml" xref="S2.E3.m1.2.2.2.2.2"></leq><apply id="S2.E3.m1.2.2.2.2.1.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1"><abs id="S2.E3.m1.2.2.2.2.1.2.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2"></abs><apply id="S2.E3.m1.2.2.2.2.1.1.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1"><minus id="S2.E3.m1.2.2.2.2.1.1.1.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.3"></minus><apply id="S2.E3.m1.2.2.2.2.1.1.1.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.1"><times id="S2.E3.m1.2.2.2.2.1.1.1.1.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.1.2"></times><apply id="S2.E3.m1.2.2.2.2.1.1.1.1.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.2.1.1.1.1.3.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.1.3">subscript</csymbol><ci id="S2.E3.m1.2.2.2.2.1.1.1.1.3.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.1.3.2">𝐿</ci><ci id="S2.E3.m1.2.2.2.2.1.1.1.1.3.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.1.3.3">𝑧</ci></apply><apply id="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.1.2">ℎ</ci><ci id="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.1.3">𝑠</ci></apply></apply><apply id="S2.E3.m1.2.2.2.2.1.1.1.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.2"><times id="S2.E3.m1.2.2.2.2.1.1.1.2.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.2.2"></times><apply id="S2.E3.m1.2.2.2.2.1.1.1.2.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.2.1.1.1.2.3.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.2.3">subscript</csymbol><ci id="S2.E3.m1.2.2.2.2.1.1.1.2.3.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.2.3.2">𝐿</ci><ci id="S2.E3.m1.2.2.2.2.1.1.1.2.3.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.2.3.3">𝑍</ci></apply><apply id="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.2.1.1">subscript</csymbol><ci id="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.2">𝐻</ci><apply id="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.3.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.3">superscript</csymbol><ci id="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.3.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.3.2">𝑆</ci><ci id="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.3.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.2.1.1.1.3.3">′</ci></apply></apply></apply></apply></apply><ci id="S2.E3.m1.2.2.2.2.3.cmml" xref="S2.E3.m1.2.2.2.2.3">𝛽</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.2c">\forall z\in z,|L_{z}(h_{s})-L_{Z}(H_{S^{\prime}})|\leq\beta</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="Thmdefinition3.p1.11" class="ltx_p"><math id="Thmdefinition3.p1.8.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="Thmdefinition3.p1.8.m1.1a"><mi id="Thmdefinition3.p1.8.m1.1.1" xref="Thmdefinition3.p1.8.m1.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition3.p1.8.m1.1b"><ci id="Thmdefinition3.p1.8.m1.1.1.cmml" xref="Thmdefinition3.p1.8.m1.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition3.p1.8.m1.1c">\beta</annotation></semantics></math><span id="Thmdefinition3.p1.11.3" class="ltx_text ltx_font_italic"> is the stability coefficient in this equation and is the smallest value that measures the difference between the loss of the algorithm on <math id="Thmdefinition3.p1.9.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="Thmdefinition3.p1.9.1.m1.1a"><mi id="Thmdefinition3.p1.9.1.m1.1.1" xref="Thmdefinition3.p1.9.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition3.p1.9.1.m1.1b"><ci id="Thmdefinition3.p1.9.1.m1.1.1.cmml" xref="Thmdefinition3.p1.9.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition3.p1.9.1.m1.1c">S</annotation></semantics></math> and <math id="Thmdefinition3.p1.10.2.m2.1" class="ltx_Math" alttext="S^{\prime}" display="inline"><semantics id="Thmdefinition3.p1.10.2.m2.1a"><msup id="Thmdefinition3.p1.10.2.m2.1.1" xref="Thmdefinition3.p1.10.2.m2.1.1.cmml"><mi id="Thmdefinition3.p1.10.2.m2.1.1.2" xref="Thmdefinition3.p1.10.2.m2.1.1.2.cmml">S</mi><mo id="Thmdefinition3.p1.10.2.m2.1.1.3" xref="Thmdefinition3.p1.10.2.m2.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="Thmdefinition3.p1.10.2.m2.1b"><apply id="Thmdefinition3.p1.10.2.m2.1.1.cmml" xref="Thmdefinition3.p1.10.2.m2.1.1"><csymbol cd="ambiguous" id="Thmdefinition3.p1.10.2.m2.1.1.1.cmml" xref="Thmdefinition3.p1.10.2.m2.1.1">superscript</csymbol><ci id="Thmdefinition3.p1.10.2.m2.1.1.2.cmml" xref="Thmdefinition3.p1.10.2.m2.1.1.2">𝑆</ci><ci id="Thmdefinition3.p1.10.2.m2.1.1.3.cmml" xref="Thmdefinition3.p1.10.2.m2.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition3.p1.10.2.m2.1c">S^{\prime}</annotation></semantics></math>. Smaller <math id="Thmdefinition3.p1.11.3.m3.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="Thmdefinition3.p1.11.3.m3.1a"><mi id="Thmdefinition3.p1.11.3.m3.1.1" xref="Thmdefinition3.p1.11.3.m3.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition3.p1.11.3.m3.1b"><ci id="Thmdefinition3.p1.11.3.m3.1.1.cmml" xref="Thmdefinition3.p1.11.3.m3.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition3.p1.11.3.m3.1c">\beta</annotation></semantics></math> corresponds to more stable algorithms.</span></p>
</div>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Stability is closely related to the model’s generalization ability on unseen data. Bousquet and Elisseeff <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> define the notion of stability for learning algorithms and demonstrate that stability is an algorithmic way of measuring generalization. Stable models are less prone to overfitting and have better generalization.
Stability is critical in designing practical learning algorithms, and a sensitivity analysis is the means to measure stability. This method, also known as perturbation analysis, is conducted by measuring the changes in the algorithm output in the presence of noise. Perturbation analysis allows us to utilize noise to design models capable of learning the underlying systems that produce data rather than the data itself <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Sensitivity analysis is an essential component in defining generalization, stability, and differential privacy.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Privacy</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">In the modern world, where governments and private companies frequently use data for strategic planning, decision-making, policies, and even services, privacy is a serious concern. Privacy is the individual’s autonomy in collecting, storing, sharing, and analysis of personal data. Privacy violations can have serious personal and social implications for vulnerable populations, causing discrimination, surveillance, and other potential harms. Emerging technologies in data generation, storage, and analysis raise new concerns about individuals’ right to privacy in the machine learning domain. Motivated by the Fundamental Law on Information Reconstruction, the researchers in Microsoft Research Lab focused on designing a holistic approach to preserving privacy in the statistical learning of individuals’ data. However, without a structured definition of privacy, evaluating the privacy-preserving methods was subject to failure. An intuitive definition of privacy is the one by Gavison<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</p>
</div>
<div id="Thmdefinition4" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="Thmdefinition4.1.1.1" class="ltx_text ltx_font_bold">Definition 4</span></span></h6>
<div id="Thmdefinition4.p1" class="ltx_para">
<p id="Thmdefinition4.p1.1" class="ltx_p"><span id="Thmdefinition4.p1.1.1" class="ltx_text ltx_font_italic">Privacy is the protection from being brought to the attention of others.</span></p>
</div>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">As governments and organizations strive to harness the potential knowledge and value in the data, reliable and trustworthy algorithms become crucial. Researchers encourage policymakers to incorporate privacy as a human right in the processes and establish privacy protection mechanisms that ensure individuals’ safety in the age of artificial intelligence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Differential Privacy</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">One of the most stringent measures of privacy is differential privacy, which ensures that adding or removing any individual’s data does not change the probability of an outcome by ”too much”.</p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<p id="S2.SS4.p2.1" class="ltx_p">The definition of differential privacy relies on the concept of a randomized algorithm, which has been employed in various applications, including cryptography and accelerating solutions of algebraic equations. Randomized algorithms are computational procedures that incorporate random choices or probabilistic decisions to solve problems. Rather than following a deterministic path, these algorithms leverage randomness, either to simplify the process or to achieve a solution with high probability. For example, a randomized algorithm can use a random event, such as flipping a coin as part of its description, and make decisions based on the outcome of the coin flips. Therefore a randomized algorithm maps inputs to probabilities of different outputs rather than deterministically mapping inputs to specific outputs.</p>
</div>
<div id="S2.SS4.p3" class="ltx_para">
<p id="S2.SS4.p3.1" class="ltx_p">A key benefit of differential privacy is providing mathematically rigorous privacy guarantees. Therefore, any particular algorithm’s privacy protection level is clearly understood. The mathematical definition of privacy provides a measurable term for evaluating and maintaining privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>.</p>
</div>
<div id="Thmdefinition5" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="Thmdefinition5.1.1.1" class="ltx_text ltx_font_bold">Definition 5</span></span></h6>
<div id="Thmdefinition5.p1" class="ltx_para">
<p id="Thmdefinition5.p1.4" class="ltx_p"><span id="Thmdefinition5.p1.4.4" class="ltx_text ltx_font_italic">Let’s assume <math id="Thmdefinition5.p1.1.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="Thmdefinition5.p1.1.1.m1.1a"><mi id="Thmdefinition5.p1.1.1.m1.1.1" xref="Thmdefinition5.p1.1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.1.1.m1.1b"><ci id="Thmdefinition5.p1.1.1.m1.1.1.cmml" xref="Thmdefinition5.p1.1.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.1.1.m1.1c">x</annotation></semantics></math> and <math id="Thmdefinition5.p1.2.2.m2.1" class="ltx_Math" alttext="y" display="inline"><semantics id="Thmdefinition5.p1.2.2.m2.1a"><mi id="Thmdefinition5.p1.2.2.m2.1.1" xref="Thmdefinition5.p1.2.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.2.2.m2.1b"><ci id="Thmdefinition5.p1.2.2.m2.1.1.cmml" xref="Thmdefinition5.p1.2.2.m2.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.2.2.m2.1c">y</annotation></semantics></math> are two datasets; the <math id="Thmdefinition5.p1.3.3.m3.1" class="ltx_Math" alttext="l_{1}" display="inline"><semantics id="Thmdefinition5.p1.3.3.m3.1a"><msub id="Thmdefinition5.p1.3.3.m3.1.1" xref="Thmdefinition5.p1.3.3.m3.1.1.cmml"><mi id="Thmdefinition5.p1.3.3.m3.1.1.2" xref="Thmdefinition5.p1.3.3.m3.1.1.2.cmml">l</mi><mn id="Thmdefinition5.p1.3.3.m3.1.1.3" xref="Thmdefinition5.p1.3.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.3.3.m3.1b"><apply id="Thmdefinition5.p1.3.3.m3.1.1.cmml" xref="Thmdefinition5.p1.3.3.m3.1.1"><csymbol cd="ambiguous" id="Thmdefinition5.p1.3.3.m3.1.1.1.cmml" xref="Thmdefinition5.p1.3.3.m3.1.1">subscript</csymbol><ci id="Thmdefinition5.p1.3.3.m3.1.1.2.cmml" xref="Thmdefinition5.p1.3.3.m3.1.1.2">𝑙</ci><cn type="integer" id="Thmdefinition5.p1.3.3.m3.1.1.3.cmml" xref="Thmdefinition5.p1.3.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.3.3.m3.1c">l_{1}</annotation></semantics></math> norm of dataset x, denoted as <math id="Thmdefinition5.p1.4.4.m4.1" class="ltx_Math" alttext="||x||_{1}" display="inline"><semantics id="Thmdefinition5.p1.4.4.m4.1a"><msub id="Thmdefinition5.p1.4.4.m4.1.2" xref="Thmdefinition5.p1.4.4.m4.1.2.cmml"><mrow id="Thmdefinition5.p1.4.4.m4.1.2.2.2" xref="Thmdefinition5.p1.4.4.m4.1.2.2.1.cmml"><mo stretchy="false" id="Thmdefinition5.p1.4.4.m4.1.2.2.2.1" xref="Thmdefinition5.p1.4.4.m4.1.2.2.1.1.cmml">‖</mo><mi id="Thmdefinition5.p1.4.4.m4.1.1" xref="Thmdefinition5.p1.4.4.m4.1.1.cmml">x</mi><mo stretchy="false" id="Thmdefinition5.p1.4.4.m4.1.2.2.2.2" xref="Thmdefinition5.p1.4.4.m4.1.2.2.1.1.cmml">‖</mo></mrow><mn id="Thmdefinition5.p1.4.4.m4.1.2.3" xref="Thmdefinition5.p1.4.4.m4.1.2.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.4.4.m4.1b"><apply id="Thmdefinition5.p1.4.4.m4.1.2.cmml" xref="Thmdefinition5.p1.4.4.m4.1.2"><csymbol cd="ambiguous" id="Thmdefinition5.p1.4.4.m4.1.2.1.cmml" xref="Thmdefinition5.p1.4.4.m4.1.2">subscript</csymbol><apply id="Thmdefinition5.p1.4.4.m4.1.2.2.1.cmml" xref="Thmdefinition5.p1.4.4.m4.1.2.2.2"><csymbol cd="latexml" id="Thmdefinition5.p1.4.4.m4.1.2.2.1.1.cmml" xref="Thmdefinition5.p1.4.4.m4.1.2.2.2.1">norm</csymbol><ci id="Thmdefinition5.p1.4.4.m4.1.1.cmml" xref="Thmdefinition5.p1.4.4.m4.1.1">𝑥</ci></apply><cn type="integer" id="Thmdefinition5.p1.4.4.m4.1.2.3.cmml" xref="Thmdefinition5.p1.4.4.m4.1.2.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.4.4.m4.1c">||x||_{1}</annotation></semantics></math>, is a measure of the size of the dataset, and it is defined to be:</span></p>
<table id="S2.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S2.E4.m1.4" class="ltx_Math" alttext="||x||_{1}=\sum_{i=1}^{|x|}|x|_{i}," display="block"><semantics id="S2.E4.m1.4a"><mrow id="S2.E4.m1.4.4.1" xref="S2.E4.m1.4.4.1.1.cmml"><mrow id="S2.E4.m1.4.4.1.1" xref="S2.E4.m1.4.4.1.1.cmml"><msub id="S2.E4.m1.4.4.1.1.2" xref="S2.E4.m1.4.4.1.1.2.cmml"><mrow id="S2.E4.m1.4.4.1.1.2.2.2" xref="S2.E4.m1.4.4.1.1.2.2.1.cmml"><mo stretchy="false" id="S2.E4.m1.4.4.1.1.2.2.2.1" xref="S2.E4.m1.4.4.1.1.2.2.1.1.cmml">‖</mo><mi id="S2.E4.m1.2.2" xref="S2.E4.m1.2.2.cmml">x</mi><mo stretchy="false" id="S2.E4.m1.4.4.1.1.2.2.2.2" xref="S2.E4.m1.4.4.1.1.2.2.1.1.cmml">‖</mo></mrow><mn id="S2.E4.m1.4.4.1.1.2.3" xref="S2.E4.m1.4.4.1.1.2.3.cmml">1</mn></msub><mo rspace="0.111em" id="S2.E4.m1.4.4.1.1.1" xref="S2.E4.m1.4.4.1.1.1.cmml">=</mo><mrow id="S2.E4.m1.4.4.1.1.3" xref="S2.E4.m1.4.4.1.1.3.cmml"><munderover id="S2.E4.m1.4.4.1.1.3.1" xref="S2.E4.m1.4.4.1.1.3.1.cmml"><mo movablelimits="false" rspace="0em" id="S2.E4.m1.4.4.1.1.3.1.2.2" xref="S2.E4.m1.4.4.1.1.3.1.2.2.cmml">∑</mo><mrow id="S2.E4.m1.4.4.1.1.3.1.2.3" xref="S2.E4.m1.4.4.1.1.3.1.2.3.cmml"><mi id="S2.E4.m1.4.4.1.1.3.1.2.3.2" xref="S2.E4.m1.4.4.1.1.3.1.2.3.2.cmml">i</mi><mo id="S2.E4.m1.4.4.1.1.3.1.2.3.1" xref="S2.E4.m1.4.4.1.1.3.1.2.3.1.cmml">=</mo><mn id="S2.E4.m1.4.4.1.1.3.1.2.3.3" xref="S2.E4.m1.4.4.1.1.3.1.2.3.3.cmml">1</mn></mrow><mrow id="S2.E4.m1.1.1.1.3" xref="S2.E4.m1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E4.m1.1.1.1.3.1" xref="S2.E4.m1.1.1.1.2.1.cmml">|</mo><mi id="S2.E4.m1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.cmml">x</mi><mo stretchy="false" id="S2.E4.m1.1.1.1.3.2" xref="S2.E4.m1.1.1.1.2.1.cmml">|</mo></mrow></munderover><msub id="S2.E4.m1.4.4.1.1.3.2" xref="S2.E4.m1.4.4.1.1.3.2.cmml"><mrow id="S2.E4.m1.4.4.1.1.3.2.2.2" xref="S2.E4.m1.4.4.1.1.3.2.2.1.cmml"><mo stretchy="false" id="S2.E4.m1.4.4.1.1.3.2.2.2.1" xref="S2.E4.m1.4.4.1.1.3.2.2.1.1.cmml">|</mo><mi id="S2.E4.m1.3.3" xref="S2.E4.m1.3.3.cmml">x</mi><mo stretchy="false" id="S2.E4.m1.4.4.1.1.3.2.2.2.2" xref="S2.E4.m1.4.4.1.1.3.2.2.1.1.cmml">|</mo></mrow><mi id="S2.E4.m1.4.4.1.1.3.2.3" xref="S2.E4.m1.4.4.1.1.3.2.3.cmml">i</mi></msub></mrow></mrow><mo id="S2.E4.m1.4.4.1.2" xref="S2.E4.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.4b"><apply id="S2.E4.m1.4.4.1.1.cmml" xref="S2.E4.m1.4.4.1"><eq id="S2.E4.m1.4.4.1.1.1.cmml" xref="S2.E4.m1.4.4.1.1.1"></eq><apply id="S2.E4.m1.4.4.1.1.2.cmml" xref="S2.E4.m1.4.4.1.1.2"><csymbol cd="ambiguous" id="S2.E4.m1.4.4.1.1.2.1.cmml" xref="S2.E4.m1.4.4.1.1.2">subscript</csymbol><apply id="S2.E4.m1.4.4.1.1.2.2.1.cmml" xref="S2.E4.m1.4.4.1.1.2.2.2"><csymbol cd="latexml" id="S2.E4.m1.4.4.1.1.2.2.1.1.cmml" xref="S2.E4.m1.4.4.1.1.2.2.2.1">norm</csymbol><ci id="S2.E4.m1.2.2.cmml" xref="S2.E4.m1.2.2">𝑥</ci></apply><cn type="integer" id="S2.E4.m1.4.4.1.1.2.3.cmml" xref="S2.E4.m1.4.4.1.1.2.3">1</cn></apply><apply id="S2.E4.m1.4.4.1.1.3.cmml" xref="S2.E4.m1.4.4.1.1.3"><apply id="S2.E4.m1.4.4.1.1.3.1.cmml" xref="S2.E4.m1.4.4.1.1.3.1"><csymbol cd="ambiguous" id="S2.E4.m1.4.4.1.1.3.1.1.cmml" xref="S2.E4.m1.4.4.1.1.3.1">superscript</csymbol><apply id="S2.E4.m1.4.4.1.1.3.1.2.cmml" xref="S2.E4.m1.4.4.1.1.3.1"><csymbol cd="ambiguous" id="S2.E4.m1.4.4.1.1.3.1.2.1.cmml" xref="S2.E4.m1.4.4.1.1.3.1">subscript</csymbol><sum id="S2.E4.m1.4.4.1.1.3.1.2.2.cmml" xref="S2.E4.m1.4.4.1.1.3.1.2.2"></sum><apply id="S2.E4.m1.4.4.1.1.3.1.2.3.cmml" xref="S2.E4.m1.4.4.1.1.3.1.2.3"><eq id="S2.E4.m1.4.4.1.1.3.1.2.3.1.cmml" xref="S2.E4.m1.4.4.1.1.3.1.2.3.1"></eq><ci id="S2.E4.m1.4.4.1.1.3.1.2.3.2.cmml" xref="S2.E4.m1.4.4.1.1.3.1.2.3.2">𝑖</ci><cn type="integer" id="S2.E4.m1.4.4.1.1.3.1.2.3.3.cmml" xref="S2.E4.m1.4.4.1.1.3.1.2.3.3">1</cn></apply></apply><apply id="S2.E4.m1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.3"><abs id="S2.E4.m1.1.1.1.2.1.cmml" xref="S2.E4.m1.1.1.1.3.1"></abs><ci id="S2.E4.m1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1">𝑥</ci></apply></apply><apply id="S2.E4.m1.4.4.1.1.3.2.cmml" xref="S2.E4.m1.4.4.1.1.3.2"><csymbol cd="ambiguous" id="S2.E4.m1.4.4.1.1.3.2.1.cmml" xref="S2.E4.m1.4.4.1.1.3.2">subscript</csymbol><apply id="S2.E4.m1.4.4.1.1.3.2.2.1.cmml" xref="S2.E4.m1.4.4.1.1.3.2.2.2"><abs id="S2.E4.m1.4.4.1.1.3.2.2.1.1.cmml" xref="S2.E4.m1.4.4.1.1.3.2.2.2.1"></abs><ci id="S2.E4.m1.3.3.cmml" xref="S2.E4.m1.3.3">𝑥</ci></apply><ci id="S2.E4.m1.4.4.1.1.3.2.3.cmml" xref="S2.E4.m1.4.4.1.1.3.2.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.4c">||x||_{1}=\sum_{i=1}^{|x|}|x|_{i},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="Thmdefinition5.p1.26" class="ltx_p"><span id="Thmdefinition5.p1.26.22" class="ltx_text ltx_font_italic">The <math id="Thmdefinition5.p1.5.1.m1.1" class="ltx_Math" alttext="l_{1}" display="inline"><semantics id="Thmdefinition5.p1.5.1.m1.1a"><msub id="Thmdefinition5.p1.5.1.m1.1.1" xref="Thmdefinition5.p1.5.1.m1.1.1.cmml"><mi id="Thmdefinition5.p1.5.1.m1.1.1.2" xref="Thmdefinition5.p1.5.1.m1.1.1.2.cmml">l</mi><mn id="Thmdefinition5.p1.5.1.m1.1.1.3" xref="Thmdefinition5.p1.5.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.5.1.m1.1b"><apply id="Thmdefinition5.p1.5.1.m1.1.1.cmml" xref="Thmdefinition5.p1.5.1.m1.1.1"><csymbol cd="ambiguous" id="Thmdefinition5.p1.5.1.m1.1.1.1.cmml" xref="Thmdefinition5.p1.5.1.m1.1.1">subscript</csymbol><ci id="Thmdefinition5.p1.5.1.m1.1.1.2.cmml" xref="Thmdefinition5.p1.5.1.m1.1.1.2">𝑙</ci><cn type="integer" id="Thmdefinition5.p1.5.1.m1.1.1.3.cmml" xref="Thmdefinition5.p1.5.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.5.1.m1.1c">l_{1}</annotation></semantics></math> distance between <math id="Thmdefinition5.p1.6.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="Thmdefinition5.p1.6.2.m2.1a"><mi id="Thmdefinition5.p1.6.2.m2.1.1" xref="Thmdefinition5.p1.6.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.6.2.m2.1b"><ci id="Thmdefinition5.p1.6.2.m2.1.1.cmml" xref="Thmdefinition5.p1.6.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.6.2.m2.1c">x</annotation></semantics></math> and <math id="Thmdefinition5.p1.7.3.m3.1" class="ltx_Math" alttext="y" display="inline"><semantics id="Thmdefinition5.p1.7.3.m3.1a"><mi id="Thmdefinition5.p1.7.3.m3.1.1" xref="Thmdefinition5.p1.7.3.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.7.3.m3.1b"><ci id="Thmdefinition5.p1.7.3.m3.1.1.cmml" xref="Thmdefinition5.p1.7.3.m3.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.7.3.m3.1c">y</annotation></semantics></math> is <math id="Thmdefinition5.p1.8.4.m4.1" class="ltx_Math" alttext="||x-y||_{1}" display="inline"><semantics id="Thmdefinition5.p1.8.4.m4.1a"><msub id="Thmdefinition5.p1.8.4.m4.1.1" xref="Thmdefinition5.p1.8.4.m4.1.1.cmml"><mrow id="Thmdefinition5.p1.8.4.m4.1.1.1.1" xref="Thmdefinition5.p1.8.4.m4.1.1.1.2.cmml"><mo stretchy="false" id="Thmdefinition5.p1.8.4.m4.1.1.1.1.2" xref="Thmdefinition5.p1.8.4.m4.1.1.1.2.1.cmml">‖</mo><mrow id="Thmdefinition5.p1.8.4.m4.1.1.1.1.1" xref="Thmdefinition5.p1.8.4.m4.1.1.1.1.1.cmml"><mi id="Thmdefinition5.p1.8.4.m4.1.1.1.1.1.2" xref="Thmdefinition5.p1.8.4.m4.1.1.1.1.1.2.cmml">x</mi><mo id="Thmdefinition5.p1.8.4.m4.1.1.1.1.1.1" xref="Thmdefinition5.p1.8.4.m4.1.1.1.1.1.1.cmml">−</mo><mi id="Thmdefinition5.p1.8.4.m4.1.1.1.1.1.3" xref="Thmdefinition5.p1.8.4.m4.1.1.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="Thmdefinition5.p1.8.4.m4.1.1.1.1.3" xref="Thmdefinition5.p1.8.4.m4.1.1.1.2.1.cmml">‖</mo></mrow><mn id="Thmdefinition5.p1.8.4.m4.1.1.3" xref="Thmdefinition5.p1.8.4.m4.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.8.4.m4.1b"><apply id="Thmdefinition5.p1.8.4.m4.1.1.cmml" xref="Thmdefinition5.p1.8.4.m4.1.1"><csymbol cd="ambiguous" id="Thmdefinition5.p1.8.4.m4.1.1.2.cmml" xref="Thmdefinition5.p1.8.4.m4.1.1">subscript</csymbol><apply id="Thmdefinition5.p1.8.4.m4.1.1.1.2.cmml" xref="Thmdefinition5.p1.8.4.m4.1.1.1.1"><csymbol cd="latexml" id="Thmdefinition5.p1.8.4.m4.1.1.1.2.1.cmml" xref="Thmdefinition5.p1.8.4.m4.1.1.1.1.2">norm</csymbol><apply id="Thmdefinition5.p1.8.4.m4.1.1.1.1.1.cmml" xref="Thmdefinition5.p1.8.4.m4.1.1.1.1.1"><minus id="Thmdefinition5.p1.8.4.m4.1.1.1.1.1.1.cmml" xref="Thmdefinition5.p1.8.4.m4.1.1.1.1.1.1"></minus><ci id="Thmdefinition5.p1.8.4.m4.1.1.1.1.1.2.cmml" xref="Thmdefinition5.p1.8.4.m4.1.1.1.1.1.2">𝑥</ci><ci id="Thmdefinition5.p1.8.4.m4.1.1.1.1.1.3.cmml" xref="Thmdefinition5.p1.8.4.m4.1.1.1.1.1.3">𝑦</ci></apply></apply><cn type="integer" id="Thmdefinition5.p1.8.4.m4.1.1.3.cmml" xref="Thmdefinition5.p1.8.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.8.4.m4.1c">||x-y||_{1}</annotation></semantics></math>, which measures the difference between the number of records in <math id="Thmdefinition5.p1.9.5.m5.1" class="ltx_Math" alttext="x" display="inline"><semantics id="Thmdefinition5.p1.9.5.m5.1a"><mi id="Thmdefinition5.p1.9.5.m5.1.1" xref="Thmdefinition5.p1.9.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.9.5.m5.1b"><ci id="Thmdefinition5.p1.9.5.m5.1.1.cmml" xref="Thmdefinition5.p1.9.5.m5.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.9.5.m5.1c">x</annotation></semantics></math> and <math id="Thmdefinition5.p1.10.6.m6.1" class="ltx_Math" alttext="y" display="inline"><semantics id="Thmdefinition5.p1.10.6.m6.1a"><mi id="Thmdefinition5.p1.10.6.m6.1.1" xref="Thmdefinition5.p1.10.6.m6.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.10.6.m6.1b"><ci id="Thmdefinition5.p1.10.6.m6.1.1.cmml" xref="Thmdefinition5.p1.10.6.m6.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.10.6.m6.1c">y</annotation></semantics></math>. Datasets are also perceived as a multiset of rows, so the distance between the datasets can be measured by the Hamming distance; that is, the difference in the number of rows between <math id="Thmdefinition5.p1.11.7.m7.1" class="ltx_Math" alttext="x" display="inline"><semantics id="Thmdefinition5.p1.11.7.m7.1a"><mi id="Thmdefinition5.p1.11.7.m7.1.1" xref="Thmdefinition5.p1.11.7.m7.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.11.7.m7.1b"><ci id="Thmdefinition5.p1.11.7.m7.1.1.cmml" xref="Thmdefinition5.p1.11.7.m7.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.11.7.m7.1c">x</annotation></semantics></math> and <math id="Thmdefinition5.p1.12.8.m8.1" class="ltx_Math" alttext="y" display="inline"><semantics id="Thmdefinition5.p1.12.8.m8.1a"><mi id="Thmdefinition5.p1.12.8.m8.1.1" xref="Thmdefinition5.p1.12.8.m8.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.12.8.m8.1b"><ci id="Thmdefinition5.p1.12.8.m8.1.1.cmml" xref="Thmdefinition5.p1.12.8.m8.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.12.8.m8.1c">y</annotation></semantics></math>. 
<br class="ltx_break"><math id="Thmdefinition5.p1.13.9.m9.1" class="ltx_Math" alttext="M" display="inline"><semantics id="Thmdefinition5.p1.13.9.m9.1a"><mi id="Thmdefinition5.p1.13.9.m9.1.1" xref="Thmdefinition5.p1.13.9.m9.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.13.9.m9.1b"><ci id="Thmdefinition5.p1.13.9.m9.1.1.cmml" xref="Thmdefinition5.p1.13.9.m9.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.13.9.m9.1c">M</annotation></semantics></math> is a randomized mechanism with domain <math id="Thmdefinition5.p1.14.10.m10.1" class="ltx_Math" alttext="{\mathbb{N}}^{|x|}" display="inline"><semantics id="Thmdefinition5.p1.14.10.m10.1a"><msup id="Thmdefinition5.p1.14.10.m10.1.2" xref="Thmdefinition5.p1.14.10.m10.1.2.cmml"><mi id="Thmdefinition5.p1.14.10.m10.1.2.2" xref="Thmdefinition5.p1.14.10.m10.1.2.2.cmml">ℕ</mi><mrow id="Thmdefinition5.p1.14.10.m10.1.1.1.3" xref="Thmdefinition5.p1.14.10.m10.1.1.1.2.cmml"><mo stretchy="false" id="Thmdefinition5.p1.14.10.m10.1.1.1.3.1" xref="Thmdefinition5.p1.14.10.m10.1.1.1.2.1.cmml">|</mo><mi id="Thmdefinition5.p1.14.10.m10.1.1.1.1" xref="Thmdefinition5.p1.14.10.m10.1.1.1.1.cmml">x</mi><mo stretchy="false" id="Thmdefinition5.p1.14.10.m10.1.1.1.3.2" xref="Thmdefinition5.p1.14.10.m10.1.1.1.2.1.cmml">|</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.14.10.m10.1b"><apply id="Thmdefinition5.p1.14.10.m10.1.2.cmml" xref="Thmdefinition5.p1.14.10.m10.1.2"><csymbol cd="ambiguous" id="Thmdefinition5.p1.14.10.m10.1.2.1.cmml" xref="Thmdefinition5.p1.14.10.m10.1.2">superscript</csymbol><ci id="Thmdefinition5.p1.14.10.m10.1.2.2.cmml" xref="Thmdefinition5.p1.14.10.m10.1.2.2">ℕ</ci><apply id="Thmdefinition5.p1.14.10.m10.1.1.1.2.cmml" xref="Thmdefinition5.p1.14.10.m10.1.1.1.3"><abs id="Thmdefinition5.p1.14.10.m10.1.1.1.2.1.cmml" xref="Thmdefinition5.p1.14.10.m10.1.1.1.3.1"></abs><ci id="Thmdefinition5.p1.14.10.m10.1.1.1.1.cmml" xref="Thmdefinition5.p1.14.10.m10.1.1.1.1">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.14.10.m10.1c">{\mathbb{N}}^{|x|}</annotation></semantics></math>. 
<br class="ltx_break"><math id="Thmdefinition5.p1.15.11.m11.1" class="ltx_Math" alttext="S" display="inline"><semantics id="Thmdefinition5.p1.15.11.m11.1a"><mi id="Thmdefinition5.p1.15.11.m11.1.1" xref="Thmdefinition5.p1.15.11.m11.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.15.11.m11.1b"><ci id="Thmdefinition5.p1.15.11.m11.1.1.cmml" xref="Thmdefinition5.p1.15.11.m11.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.15.11.m11.1c">S</annotation></semantics></math> is the set of outcomes of <math id="Thmdefinition5.p1.16.12.m12.1" class="ltx_Math" alttext="M" display="inline"><semantics id="Thmdefinition5.p1.16.12.m12.1a"><mi id="Thmdefinition5.p1.16.12.m12.1.1" xref="Thmdefinition5.p1.16.12.m12.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.16.12.m12.1b"><ci id="Thmdefinition5.p1.16.12.m12.1.1.cmml" xref="Thmdefinition5.p1.16.12.m12.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.16.12.m12.1c">M</annotation></semantics></math>; therefore, <math id="Thmdefinition5.p1.17.13.m13.1" class="ltx_Math" alttext="S\in Range(M)" display="inline"><semantics id="Thmdefinition5.p1.17.13.m13.1a"><mrow id="Thmdefinition5.p1.17.13.m13.1.2" xref="Thmdefinition5.p1.17.13.m13.1.2.cmml"><mi id="Thmdefinition5.p1.17.13.m13.1.2.2" xref="Thmdefinition5.p1.17.13.m13.1.2.2.cmml">S</mi><mo id="Thmdefinition5.p1.17.13.m13.1.2.1" xref="Thmdefinition5.p1.17.13.m13.1.2.1.cmml">∈</mo><mrow id="Thmdefinition5.p1.17.13.m13.1.2.3" xref="Thmdefinition5.p1.17.13.m13.1.2.3.cmml"><mi id="Thmdefinition5.p1.17.13.m13.1.2.3.2" xref="Thmdefinition5.p1.17.13.m13.1.2.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="Thmdefinition5.p1.17.13.m13.1.2.3.1" xref="Thmdefinition5.p1.17.13.m13.1.2.3.1.cmml">​</mo><mi id="Thmdefinition5.p1.17.13.m13.1.2.3.3" xref="Thmdefinition5.p1.17.13.m13.1.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="Thmdefinition5.p1.17.13.m13.1.2.3.1a" xref="Thmdefinition5.p1.17.13.m13.1.2.3.1.cmml">​</mo><mi id="Thmdefinition5.p1.17.13.m13.1.2.3.4" xref="Thmdefinition5.p1.17.13.m13.1.2.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="Thmdefinition5.p1.17.13.m13.1.2.3.1b" xref="Thmdefinition5.p1.17.13.m13.1.2.3.1.cmml">​</mo><mi id="Thmdefinition5.p1.17.13.m13.1.2.3.5" xref="Thmdefinition5.p1.17.13.m13.1.2.3.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="Thmdefinition5.p1.17.13.m13.1.2.3.1c" xref="Thmdefinition5.p1.17.13.m13.1.2.3.1.cmml">​</mo><mi id="Thmdefinition5.p1.17.13.m13.1.2.3.6" xref="Thmdefinition5.p1.17.13.m13.1.2.3.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="Thmdefinition5.p1.17.13.m13.1.2.3.1d" xref="Thmdefinition5.p1.17.13.m13.1.2.3.1.cmml">​</mo><mrow id="Thmdefinition5.p1.17.13.m13.1.2.3.7.2" xref="Thmdefinition5.p1.17.13.m13.1.2.3.cmml"><mo stretchy="false" id="Thmdefinition5.p1.17.13.m13.1.2.3.7.2.1" xref="Thmdefinition5.p1.17.13.m13.1.2.3.cmml">(</mo><mi id="Thmdefinition5.p1.17.13.m13.1.1" xref="Thmdefinition5.p1.17.13.m13.1.1.cmml">M</mi><mo stretchy="false" id="Thmdefinition5.p1.17.13.m13.1.2.3.7.2.2" xref="Thmdefinition5.p1.17.13.m13.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.17.13.m13.1b"><apply id="Thmdefinition5.p1.17.13.m13.1.2.cmml" xref="Thmdefinition5.p1.17.13.m13.1.2"><in id="Thmdefinition5.p1.17.13.m13.1.2.1.cmml" xref="Thmdefinition5.p1.17.13.m13.1.2.1"></in><ci id="Thmdefinition5.p1.17.13.m13.1.2.2.cmml" xref="Thmdefinition5.p1.17.13.m13.1.2.2">𝑆</ci><apply id="Thmdefinition5.p1.17.13.m13.1.2.3.cmml" xref="Thmdefinition5.p1.17.13.m13.1.2.3"><times id="Thmdefinition5.p1.17.13.m13.1.2.3.1.cmml" xref="Thmdefinition5.p1.17.13.m13.1.2.3.1"></times><ci id="Thmdefinition5.p1.17.13.m13.1.2.3.2.cmml" xref="Thmdefinition5.p1.17.13.m13.1.2.3.2">𝑅</ci><ci id="Thmdefinition5.p1.17.13.m13.1.2.3.3.cmml" xref="Thmdefinition5.p1.17.13.m13.1.2.3.3">𝑎</ci><ci id="Thmdefinition5.p1.17.13.m13.1.2.3.4.cmml" xref="Thmdefinition5.p1.17.13.m13.1.2.3.4">𝑛</ci><ci id="Thmdefinition5.p1.17.13.m13.1.2.3.5.cmml" xref="Thmdefinition5.p1.17.13.m13.1.2.3.5">𝑔</ci><ci id="Thmdefinition5.p1.17.13.m13.1.2.3.6.cmml" xref="Thmdefinition5.p1.17.13.m13.1.2.3.6">𝑒</ci><ci id="Thmdefinition5.p1.17.13.m13.1.1.cmml" xref="Thmdefinition5.p1.17.13.m13.1.1">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.17.13.m13.1c">S\in Range(M)</annotation></semantics></math>. 
<br class="ltx_break">Differential privacy is defined on two neighboring datasets. <math id="Thmdefinition5.p1.18.14.m14.1" class="ltx_Math" alttext="x" display="inline"><semantics id="Thmdefinition5.p1.18.14.m14.1a"><mi id="Thmdefinition5.p1.18.14.m14.1.1" xref="Thmdefinition5.p1.18.14.m14.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.18.14.m14.1b"><ci id="Thmdefinition5.p1.18.14.m14.1.1.cmml" xref="Thmdefinition5.p1.18.14.m14.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.18.14.m14.1c">x</annotation></semantics></math> and <math id="Thmdefinition5.p1.19.15.m15.1" class="ltx_Math" alttext="y" display="inline"><semantics id="Thmdefinition5.p1.19.15.m15.1a"><mi id="Thmdefinition5.p1.19.15.m15.1.1" xref="Thmdefinition5.p1.19.15.m15.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.19.15.m15.1b"><ci id="Thmdefinition5.p1.19.15.m15.1.1.cmml" xref="Thmdefinition5.p1.19.15.m15.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.19.15.m15.1c">y</annotation></semantics></math> are two neighboring datasets if the two datasets differ by only one sample (row). Hence, for all <math id="Thmdefinition5.p1.20.16.m16.1" class="ltx_Math" alttext="x" display="inline"><semantics id="Thmdefinition5.p1.20.16.m16.1a"><mi id="Thmdefinition5.p1.20.16.m16.1.1" xref="Thmdefinition5.p1.20.16.m16.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.20.16.m16.1b"><ci id="Thmdefinition5.p1.20.16.m16.1.1.cmml" xref="Thmdefinition5.p1.20.16.m16.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.20.16.m16.1c">x</annotation></semantics></math> and <math id="Thmdefinition5.p1.21.17.m17.1" class="ltx_Math" alttext="y" display="inline"><semantics id="Thmdefinition5.p1.21.17.m17.1a"><mi id="Thmdefinition5.p1.21.17.m17.1.1" xref="Thmdefinition5.p1.21.17.m17.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.21.17.m17.1b"><ci id="Thmdefinition5.p1.21.17.m17.1.1.cmml" xref="Thmdefinition5.p1.21.17.m17.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.21.17.m17.1c">y</annotation></semantics></math>, the <math id="Thmdefinition5.p1.22.18.m18.1" class="ltx_Math" alttext="l_{1}" display="inline"><semantics id="Thmdefinition5.p1.22.18.m18.1a"><msub id="Thmdefinition5.p1.22.18.m18.1.1" xref="Thmdefinition5.p1.22.18.m18.1.1.cmml"><mi id="Thmdefinition5.p1.22.18.m18.1.1.2" xref="Thmdefinition5.p1.22.18.m18.1.1.2.cmml">l</mi><mn id="Thmdefinition5.p1.22.18.m18.1.1.3" xref="Thmdefinition5.p1.22.18.m18.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.22.18.m18.1b"><apply id="Thmdefinition5.p1.22.18.m18.1.1.cmml" xref="Thmdefinition5.p1.22.18.m18.1.1"><csymbol cd="ambiguous" id="Thmdefinition5.p1.22.18.m18.1.1.1.cmml" xref="Thmdefinition5.p1.22.18.m18.1.1">subscript</csymbol><ci id="Thmdefinition5.p1.22.18.m18.1.1.2.cmml" xref="Thmdefinition5.p1.22.18.m18.1.1.2">𝑙</ci><cn type="integer" id="Thmdefinition5.p1.22.18.m18.1.1.3.cmml" xref="Thmdefinition5.p1.22.18.m18.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.22.18.m18.1c">l_{1}</annotation></semantics></math> distance is <math id="Thmdefinition5.p1.23.19.m19.1" class="ltx_Math" alttext="||x-y||_{1}\leq 1" display="inline"><semantics id="Thmdefinition5.p1.23.19.m19.1a"><mrow id="Thmdefinition5.p1.23.19.m19.1.1" xref="Thmdefinition5.p1.23.19.m19.1.1.cmml"><msub id="Thmdefinition5.p1.23.19.m19.1.1.1" xref="Thmdefinition5.p1.23.19.m19.1.1.1.cmml"><mrow id="Thmdefinition5.p1.23.19.m19.1.1.1.1.1" xref="Thmdefinition5.p1.23.19.m19.1.1.1.1.2.cmml"><mo stretchy="false" id="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.2" xref="Thmdefinition5.p1.23.19.m19.1.1.1.1.2.1.cmml">‖</mo><mrow id="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.1" xref="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.1.cmml"><mi id="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.1.2" xref="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.1.2.cmml">x</mi><mo id="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.1.1" xref="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.1.1.cmml">−</mo><mi id="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.1.3" xref="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.3" xref="Thmdefinition5.p1.23.19.m19.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="Thmdefinition5.p1.23.19.m19.1.1.1.3" xref="Thmdefinition5.p1.23.19.m19.1.1.1.3.cmml">1</mn></msub><mo id="Thmdefinition5.p1.23.19.m19.1.1.2" xref="Thmdefinition5.p1.23.19.m19.1.1.2.cmml">≤</mo><mn id="Thmdefinition5.p1.23.19.m19.1.1.3" xref="Thmdefinition5.p1.23.19.m19.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.23.19.m19.1b"><apply id="Thmdefinition5.p1.23.19.m19.1.1.cmml" xref="Thmdefinition5.p1.23.19.m19.1.1"><leq id="Thmdefinition5.p1.23.19.m19.1.1.2.cmml" xref="Thmdefinition5.p1.23.19.m19.1.1.2"></leq><apply id="Thmdefinition5.p1.23.19.m19.1.1.1.cmml" xref="Thmdefinition5.p1.23.19.m19.1.1.1"><csymbol cd="ambiguous" id="Thmdefinition5.p1.23.19.m19.1.1.1.2.cmml" xref="Thmdefinition5.p1.23.19.m19.1.1.1">subscript</csymbol><apply id="Thmdefinition5.p1.23.19.m19.1.1.1.1.2.cmml" xref="Thmdefinition5.p1.23.19.m19.1.1.1.1.1"><csymbol cd="latexml" id="Thmdefinition5.p1.23.19.m19.1.1.1.1.2.1.cmml" xref="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.2">norm</csymbol><apply id="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.1.cmml" xref="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.1"><minus id="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.1.1.cmml" xref="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.1.1"></minus><ci id="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.1.2.cmml" xref="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.1.2">𝑥</ci><ci id="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.1.3.cmml" xref="Thmdefinition5.p1.23.19.m19.1.1.1.1.1.1.3">𝑦</ci></apply></apply><cn type="integer" id="Thmdefinition5.p1.23.19.m19.1.1.1.3.cmml" xref="Thmdefinition5.p1.23.19.m19.1.1.1.3">1</cn></apply><cn type="integer" id="Thmdefinition5.p1.23.19.m19.1.1.3.cmml" xref="Thmdefinition5.p1.23.19.m19.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.23.19.m19.1c">||x-y||_{1}\leq 1</annotation></semantics></math>. <math id="Thmdefinition5.p1.24.20.m20.1" class="ltx_Math" alttext="M" display="inline"><semantics id="Thmdefinition5.p1.24.20.m20.1a"><mi id="Thmdefinition5.p1.24.20.m20.1.1" xref="Thmdefinition5.p1.24.20.m20.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.24.20.m20.1b"><ci id="Thmdefinition5.p1.24.20.m20.1.1.cmml" xref="Thmdefinition5.p1.24.20.m20.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.24.20.m20.1c">M</annotation></semantics></math> is <math id="Thmdefinition5.p1.25.21.m21.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="Thmdefinition5.p1.25.21.m21.1a"><mi id="Thmdefinition5.p1.25.21.m21.1.1" xref="Thmdefinition5.p1.25.21.m21.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.25.21.m21.1b"><ci id="Thmdefinition5.p1.25.21.m21.1.1.cmml" xref="Thmdefinition5.p1.25.21.m21.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.25.21.m21.1c">\epsilon</annotation></semantics></math>-Differentially Private (<math id="Thmdefinition5.p1.26.22.m22.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="Thmdefinition5.p1.26.22.m22.1a"><mi id="Thmdefinition5.p1.26.22.m22.1.1" xref="Thmdefinition5.p1.26.22.m22.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition5.p1.26.22.m22.1b"><ci id="Thmdefinition5.p1.26.22.m22.1.1.cmml" xref="Thmdefinition5.p1.26.22.m22.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition5.p1.26.22.m22.1c">\epsilon</annotation></semantics></math>-DP) if equation <a href="#Thmdefinition5" title="Definition 5 ‣ 2.4 Differential Privacy ‣ 2 Preliminaries ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> holds for any two neighboring datasets derived from the dataset:</span></p>
<table id="S2.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S2.E5.m1.5" class="ltx_Math" alttext="P[M(x)\in S]\leq exp(\epsilon)P[M(y)\in S]" display="block"><semantics id="S2.E5.m1.5a"><mrow id="S2.E5.m1.5.5" xref="S2.E5.m1.5.5.cmml"><mrow id="S2.E5.m1.4.4.1" xref="S2.E5.m1.4.4.1.cmml"><mi id="S2.E5.m1.4.4.1.3" xref="S2.E5.m1.4.4.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.E5.m1.4.4.1.2" xref="S2.E5.m1.4.4.1.2.cmml">​</mo><mrow id="S2.E5.m1.4.4.1.1.1" xref="S2.E5.m1.4.4.1.1.2.cmml"><mo stretchy="false" id="S2.E5.m1.4.4.1.1.1.2" xref="S2.E5.m1.4.4.1.1.2.1.cmml">[</mo><mrow id="S2.E5.m1.4.4.1.1.1.1" xref="S2.E5.m1.4.4.1.1.1.1.cmml"><mrow id="S2.E5.m1.4.4.1.1.1.1.2" xref="S2.E5.m1.4.4.1.1.1.1.2.cmml"><mi id="S2.E5.m1.4.4.1.1.1.1.2.2" xref="S2.E5.m1.4.4.1.1.1.1.2.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.E5.m1.4.4.1.1.1.1.2.1" xref="S2.E5.m1.4.4.1.1.1.1.2.1.cmml">​</mo><mrow id="S2.E5.m1.4.4.1.1.1.1.2.3.2" xref="S2.E5.m1.4.4.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E5.m1.4.4.1.1.1.1.2.3.2.1" xref="S2.E5.m1.4.4.1.1.1.1.2.cmml">(</mo><mi id="S2.E5.m1.1.1" xref="S2.E5.m1.1.1.cmml">x</mi><mo stretchy="false" id="S2.E5.m1.4.4.1.1.1.1.2.3.2.2" xref="S2.E5.m1.4.4.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E5.m1.4.4.1.1.1.1.1" xref="S2.E5.m1.4.4.1.1.1.1.1.cmml">∈</mo><mi id="S2.E5.m1.4.4.1.1.1.1.3" xref="S2.E5.m1.4.4.1.1.1.1.3.cmml">S</mi></mrow><mo stretchy="false" id="S2.E5.m1.4.4.1.1.1.3" xref="S2.E5.m1.4.4.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.E5.m1.5.5.3" xref="S2.E5.m1.5.5.3.cmml">≤</mo><mrow id="S2.E5.m1.5.5.2" xref="S2.E5.m1.5.5.2.cmml"><mi id="S2.E5.m1.5.5.2.3" xref="S2.E5.m1.5.5.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E5.m1.5.5.2.2" xref="S2.E5.m1.5.5.2.2.cmml">​</mo><mi id="S2.E5.m1.5.5.2.4" xref="S2.E5.m1.5.5.2.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="S2.E5.m1.5.5.2.2a" xref="S2.E5.m1.5.5.2.2.cmml">​</mo><mi id="S2.E5.m1.5.5.2.5" xref="S2.E5.m1.5.5.2.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E5.m1.5.5.2.2b" xref="S2.E5.m1.5.5.2.2.cmml">​</mo><mrow id="S2.E5.m1.5.5.2.6.2" xref="S2.E5.m1.5.5.2.cmml"><mo stretchy="false" id="S2.E5.m1.5.5.2.6.2.1" xref="S2.E5.m1.5.5.2.cmml">(</mo><mi id="S2.E5.m1.2.2" xref="S2.E5.m1.2.2.cmml">ϵ</mi><mo stretchy="false" id="S2.E5.m1.5.5.2.6.2.2" xref="S2.E5.m1.5.5.2.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E5.m1.5.5.2.2c" xref="S2.E5.m1.5.5.2.2.cmml">​</mo><mi id="S2.E5.m1.5.5.2.7" xref="S2.E5.m1.5.5.2.7.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.E5.m1.5.5.2.2d" xref="S2.E5.m1.5.5.2.2.cmml">​</mo><mrow id="S2.E5.m1.5.5.2.1.1" xref="S2.E5.m1.5.5.2.1.2.cmml"><mo stretchy="false" id="S2.E5.m1.5.5.2.1.1.2" xref="S2.E5.m1.5.5.2.1.2.1.cmml">[</mo><mrow id="S2.E5.m1.5.5.2.1.1.1" xref="S2.E5.m1.5.5.2.1.1.1.cmml"><mrow id="S2.E5.m1.5.5.2.1.1.1.2" xref="S2.E5.m1.5.5.2.1.1.1.2.cmml"><mi id="S2.E5.m1.5.5.2.1.1.1.2.2" xref="S2.E5.m1.5.5.2.1.1.1.2.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.E5.m1.5.5.2.1.1.1.2.1" xref="S2.E5.m1.5.5.2.1.1.1.2.1.cmml">​</mo><mrow id="S2.E5.m1.5.5.2.1.1.1.2.3.2" xref="S2.E5.m1.5.5.2.1.1.1.2.cmml"><mo stretchy="false" id="S2.E5.m1.5.5.2.1.1.1.2.3.2.1" xref="S2.E5.m1.5.5.2.1.1.1.2.cmml">(</mo><mi id="S2.E5.m1.3.3" xref="S2.E5.m1.3.3.cmml">y</mi><mo stretchy="false" id="S2.E5.m1.5.5.2.1.1.1.2.3.2.2" xref="S2.E5.m1.5.5.2.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E5.m1.5.5.2.1.1.1.1" xref="S2.E5.m1.5.5.2.1.1.1.1.cmml">∈</mo><mi id="S2.E5.m1.5.5.2.1.1.1.3" xref="S2.E5.m1.5.5.2.1.1.1.3.cmml">S</mi></mrow><mo stretchy="false" id="S2.E5.m1.5.5.2.1.1.3" xref="S2.E5.m1.5.5.2.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E5.m1.5b"><apply id="S2.E5.m1.5.5.cmml" xref="S2.E5.m1.5.5"><leq id="S2.E5.m1.5.5.3.cmml" xref="S2.E5.m1.5.5.3"></leq><apply id="S2.E5.m1.4.4.1.cmml" xref="S2.E5.m1.4.4.1"><times id="S2.E5.m1.4.4.1.2.cmml" xref="S2.E5.m1.4.4.1.2"></times><ci id="S2.E5.m1.4.4.1.3.cmml" xref="S2.E5.m1.4.4.1.3">𝑃</ci><apply id="S2.E5.m1.4.4.1.1.2.cmml" xref="S2.E5.m1.4.4.1.1.1"><csymbol cd="latexml" id="S2.E5.m1.4.4.1.1.2.1.cmml" xref="S2.E5.m1.4.4.1.1.1.2">delimited-[]</csymbol><apply id="S2.E5.m1.4.4.1.1.1.1.cmml" xref="S2.E5.m1.4.4.1.1.1.1"><in id="S2.E5.m1.4.4.1.1.1.1.1.cmml" xref="S2.E5.m1.4.4.1.1.1.1.1"></in><apply id="S2.E5.m1.4.4.1.1.1.1.2.cmml" xref="S2.E5.m1.4.4.1.1.1.1.2"><times id="S2.E5.m1.4.4.1.1.1.1.2.1.cmml" xref="S2.E5.m1.4.4.1.1.1.1.2.1"></times><ci id="S2.E5.m1.4.4.1.1.1.1.2.2.cmml" xref="S2.E5.m1.4.4.1.1.1.1.2.2">𝑀</ci><ci id="S2.E5.m1.1.1.cmml" xref="S2.E5.m1.1.1">𝑥</ci></apply><ci id="S2.E5.m1.4.4.1.1.1.1.3.cmml" xref="S2.E5.m1.4.4.1.1.1.1.3">𝑆</ci></apply></apply></apply><apply id="S2.E5.m1.5.5.2.cmml" xref="S2.E5.m1.5.5.2"><times id="S2.E5.m1.5.5.2.2.cmml" xref="S2.E5.m1.5.5.2.2"></times><ci id="S2.E5.m1.5.5.2.3.cmml" xref="S2.E5.m1.5.5.2.3">𝑒</ci><ci id="S2.E5.m1.5.5.2.4.cmml" xref="S2.E5.m1.5.5.2.4">𝑥</ci><ci id="S2.E5.m1.5.5.2.5.cmml" xref="S2.E5.m1.5.5.2.5">𝑝</ci><ci id="S2.E5.m1.2.2.cmml" xref="S2.E5.m1.2.2">italic-ϵ</ci><ci id="S2.E5.m1.5.5.2.7.cmml" xref="S2.E5.m1.5.5.2.7">𝑃</ci><apply id="S2.E5.m1.5.5.2.1.2.cmml" xref="S2.E5.m1.5.5.2.1.1"><csymbol cd="latexml" id="S2.E5.m1.5.5.2.1.2.1.cmml" xref="S2.E5.m1.5.5.2.1.1.2">delimited-[]</csymbol><apply id="S2.E5.m1.5.5.2.1.1.1.cmml" xref="S2.E5.m1.5.5.2.1.1.1"><in id="S2.E5.m1.5.5.2.1.1.1.1.cmml" xref="S2.E5.m1.5.5.2.1.1.1.1"></in><apply id="S2.E5.m1.5.5.2.1.1.1.2.cmml" xref="S2.E5.m1.5.5.2.1.1.1.2"><times id="S2.E5.m1.5.5.2.1.1.1.2.1.cmml" xref="S2.E5.m1.5.5.2.1.1.1.2.1"></times><ci id="S2.E5.m1.5.5.2.1.1.1.2.2.cmml" xref="S2.E5.m1.5.5.2.1.1.1.2.2">𝑀</ci><ci id="S2.E5.m1.3.3.cmml" xref="S2.E5.m1.3.3">𝑦</ci></apply><ci id="S2.E5.m1.5.5.2.1.1.1.3.cmml" xref="S2.E5.m1.5.5.2.1.1.1.3">𝑆</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E5.m1.5c">P[M(x)\in S]\leq exp(\epsilon)P[M(y)\in S]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
</div>
<div id="S2.SS4.p4" class="ltx_para">
<p id="S2.SS4.p4.4" class="ltx_p">This definition is the strict definition of <math id="S2.SS4.p4.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S2.SS4.p4.1.m1.1a"><mi id="S2.SS4.p4.1.m1.1.1" xref="S2.SS4.p4.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.1.m1.1b"><ci id="S2.SS4.p4.1.m1.1.1.cmml" xref="S2.SS4.p4.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.1.m1.1c">\epsilon</annotation></semantics></math>-DP, and it has been studied explicitly in the book published on differential privacy by Dwork and Roth <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. Differential privacy can be adjusted using a parameter that measures the desired privacy levels. In this definition, <math id="S2.SS4.p4.2.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S2.SS4.p4.2.m2.1a"><mi id="S2.SS4.p4.2.m2.1.1" xref="S2.SS4.p4.2.m2.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.2.m2.1b"><ci id="S2.SS4.p4.2.m2.1.1.cmml" xref="S2.SS4.p4.2.m2.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.2.m2.1c">\epsilon</annotation></semantics></math> is a very small value known as privacy loss or leakage. <math id="S2.SS4.p4.3.m3.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S2.SS4.p4.3.m3.1a"><mi id="S2.SS4.p4.3.m3.1.1" xref="S2.SS4.p4.3.m3.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.3.m3.1b"><ci id="S2.SS4.p4.3.m3.1.1.cmml" xref="S2.SS4.p4.3.m3.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.3.m3.1c">\epsilon</annotation></semantics></math> determines the acceptable change in the output of the mechanism due to the inclusion or removal of any individual, so information learned about the individual as a result of participating in the dataset is limited. A relaxed version of this definition, currently used in most applications of differential privacy, is <math id="S2.SS4.p4.4.m4.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S2.SS4.p4.4.m4.2a"><mrow id="S2.SS4.p4.4.m4.2.3.2" xref="S2.SS4.p4.4.m4.2.3.1.cmml"><mo stretchy="false" id="S2.SS4.p4.4.m4.2.3.2.1" xref="S2.SS4.p4.4.m4.2.3.1.cmml">(</mo><mi id="S2.SS4.p4.4.m4.1.1" xref="S2.SS4.p4.4.m4.1.1.cmml">ϵ</mi><mo id="S2.SS4.p4.4.m4.2.3.2.2" xref="S2.SS4.p4.4.m4.2.3.1.cmml">,</mo><mi id="S2.SS4.p4.4.m4.2.2" xref="S2.SS4.p4.4.m4.2.2.cmml">δ</mi><mo stretchy="false" id="S2.SS4.p4.4.m4.2.3.2.3" xref="S2.SS4.p4.4.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.4.m4.2b"><interval closure="open" id="S2.SS4.p4.4.m4.2.3.1.cmml" xref="S2.SS4.p4.4.m4.2.3.2"><ci id="S2.SS4.p4.4.m4.1.1.cmml" xref="S2.SS4.p4.4.m4.1.1">italic-ϵ</ci><ci id="S2.SS4.p4.4.m4.2.2.cmml" xref="S2.SS4.p4.4.m4.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.4.m4.2c">(\epsilon,\delta)</annotation></semantics></math>-DP provided in Equation <a href="#S2.E6" title="In 2.4 Differential Privacy ‣ 2 Preliminaries ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
<table id="S2.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S2.E6.m1.5" class="ltx_Math" alttext="P[M(x)\in S]\leq exp(\epsilon)P[M(y)\in S]+\delta" display="block"><semantics id="S2.E6.m1.5a"><mrow id="S2.E6.m1.5.5" xref="S2.E6.m1.5.5.cmml"><mrow id="S2.E6.m1.4.4.1" xref="S2.E6.m1.4.4.1.cmml"><mi id="S2.E6.m1.4.4.1.3" xref="S2.E6.m1.4.4.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.E6.m1.4.4.1.2" xref="S2.E6.m1.4.4.1.2.cmml">​</mo><mrow id="S2.E6.m1.4.4.1.1.1" xref="S2.E6.m1.4.4.1.1.2.cmml"><mo stretchy="false" id="S2.E6.m1.4.4.1.1.1.2" xref="S2.E6.m1.4.4.1.1.2.1.cmml">[</mo><mrow id="S2.E6.m1.4.4.1.1.1.1" xref="S2.E6.m1.4.4.1.1.1.1.cmml"><mrow id="S2.E6.m1.4.4.1.1.1.1.2" xref="S2.E6.m1.4.4.1.1.1.1.2.cmml"><mi id="S2.E6.m1.4.4.1.1.1.1.2.2" xref="S2.E6.m1.4.4.1.1.1.1.2.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.E6.m1.4.4.1.1.1.1.2.1" xref="S2.E6.m1.4.4.1.1.1.1.2.1.cmml">​</mo><mrow id="S2.E6.m1.4.4.1.1.1.1.2.3.2" xref="S2.E6.m1.4.4.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E6.m1.4.4.1.1.1.1.2.3.2.1" xref="S2.E6.m1.4.4.1.1.1.1.2.cmml">(</mo><mi id="S2.E6.m1.1.1" xref="S2.E6.m1.1.1.cmml">x</mi><mo stretchy="false" id="S2.E6.m1.4.4.1.1.1.1.2.3.2.2" xref="S2.E6.m1.4.4.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E6.m1.4.4.1.1.1.1.1" xref="S2.E6.m1.4.4.1.1.1.1.1.cmml">∈</mo><mi id="S2.E6.m1.4.4.1.1.1.1.3" xref="S2.E6.m1.4.4.1.1.1.1.3.cmml">S</mi></mrow><mo stretchy="false" id="S2.E6.m1.4.4.1.1.1.3" xref="S2.E6.m1.4.4.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.E6.m1.5.5.3" xref="S2.E6.m1.5.5.3.cmml">≤</mo><mrow id="S2.E6.m1.5.5.2" xref="S2.E6.m1.5.5.2.cmml"><mrow id="S2.E6.m1.5.5.2.1" xref="S2.E6.m1.5.5.2.1.cmml"><mi id="S2.E6.m1.5.5.2.1.3" xref="S2.E6.m1.5.5.2.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E6.m1.5.5.2.1.2" xref="S2.E6.m1.5.5.2.1.2.cmml">​</mo><mi id="S2.E6.m1.5.5.2.1.4" xref="S2.E6.m1.5.5.2.1.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="S2.E6.m1.5.5.2.1.2a" xref="S2.E6.m1.5.5.2.1.2.cmml">​</mo><mi id="S2.E6.m1.5.5.2.1.5" xref="S2.E6.m1.5.5.2.1.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E6.m1.5.5.2.1.2b" xref="S2.E6.m1.5.5.2.1.2.cmml">​</mo><mrow id="S2.E6.m1.5.5.2.1.6.2" xref="S2.E6.m1.5.5.2.1.cmml"><mo stretchy="false" id="S2.E6.m1.5.5.2.1.6.2.1" xref="S2.E6.m1.5.5.2.1.cmml">(</mo><mi id="S2.E6.m1.2.2" xref="S2.E6.m1.2.2.cmml">ϵ</mi><mo stretchy="false" id="S2.E6.m1.5.5.2.1.6.2.2" xref="S2.E6.m1.5.5.2.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E6.m1.5.5.2.1.2c" xref="S2.E6.m1.5.5.2.1.2.cmml">​</mo><mi id="S2.E6.m1.5.5.2.1.7" xref="S2.E6.m1.5.5.2.1.7.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.E6.m1.5.5.2.1.2d" xref="S2.E6.m1.5.5.2.1.2.cmml">​</mo><mrow id="S2.E6.m1.5.5.2.1.1.1" xref="S2.E6.m1.5.5.2.1.1.2.cmml"><mo stretchy="false" id="S2.E6.m1.5.5.2.1.1.1.2" xref="S2.E6.m1.5.5.2.1.1.2.1.cmml">[</mo><mrow id="S2.E6.m1.5.5.2.1.1.1.1" xref="S2.E6.m1.5.5.2.1.1.1.1.cmml"><mrow id="S2.E6.m1.5.5.2.1.1.1.1.2" xref="S2.E6.m1.5.5.2.1.1.1.1.2.cmml"><mi id="S2.E6.m1.5.5.2.1.1.1.1.2.2" xref="S2.E6.m1.5.5.2.1.1.1.1.2.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.E6.m1.5.5.2.1.1.1.1.2.1" xref="S2.E6.m1.5.5.2.1.1.1.1.2.1.cmml">​</mo><mrow id="S2.E6.m1.5.5.2.1.1.1.1.2.3.2" xref="S2.E6.m1.5.5.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E6.m1.5.5.2.1.1.1.1.2.3.2.1" xref="S2.E6.m1.5.5.2.1.1.1.1.2.cmml">(</mo><mi id="S2.E6.m1.3.3" xref="S2.E6.m1.3.3.cmml">y</mi><mo stretchy="false" id="S2.E6.m1.5.5.2.1.1.1.1.2.3.2.2" xref="S2.E6.m1.5.5.2.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E6.m1.5.5.2.1.1.1.1.1" xref="S2.E6.m1.5.5.2.1.1.1.1.1.cmml">∈</mo><mi id="S2.E6.m1.5.5.2.1.1.1.1.3" xref="S2.E6.m1.5.5.2.1.1.1.1.3.cmml">S</mi></mrow><mo stretchy="false" id="S2.E6.m1.5.5.2.1.1.1.3" xref="S2.E6.m1.5.5.2.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.E6.m1.5.5.2.2" xref="S2.E6.m1.5.5.2.2.cmml">+</mo><mi id="S2.E6.m1.5.5.2.3" xref="S2.E6.m1.5.5.2.3.cmml">δ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E6.m1.5b"><apply id="S2.E6.m1.5.5.cmml" xref="S2.E6.m1.5.5"><leq id="S2.E6.m1.5.5.3.cmml" xref="S2.E6.m1.5.5.3"></leq><apply id="S2.E6.m1.4.4.1.cmml" xref="S2.E6.m1.4.4.1"><times id="S2.E6.m1.4.4.1.2.cmml" xref="S2.E6.m1.4.4.1.2"></times><ci id="S2.E6.m1.4.4.1.3.cmml" xref="S2.E6.m1.4.4.1.3">𝑃</ci><apply id="S2.E6.m1.4.4.1.1.2.cmml" xref="S2.E6.m1.4.4.1.1.1"><csymbol cd="latexml" id="S2.E6.m1.4.4.1.1.2.1.cmml" xref="S2.E6.m1.4.4.1.1.1.2">delimited-[]</csymbol><apply id="S2.E6.m1.4.4.1.1.1.1.cmml" xref="S2.E6.m1.4.4.1.1.1.1"><in id="S2.E6.m1.4.4.1.1.1.1.1.cmml" xref="S2.E6.m1.4.4.1.1.1.1.1"></in><apply id="S2.E6.m1.4.4.1.1.1.1.2.cmml" xref="S2.E6.m1.4.4.1.1.1.1.2"><times id="S2.E6.m1.4.4.1.1.1.1.2.1.cmml" xref="S2.E6.m1.4.4.1.1.1.1.2.1"></times><ci id="S2.E6.m1.4.4.1.1.1.1.2.2.cmml" xref="S2.E6.m1.4.4.1.1.1.1.2.2">𝑀</ci><ci id="S2.E6.m1.1.1.cmml" xref="S2.E6.m1.1.1">𝑥</ci></apply><ci id="S2.E6.m1.4.4.1.1.1.1.3.cmml" xref="S2.E6.m1.4.4.1.1.1.1.3">𝑆</ci></apply></apply></apply><apply id="S2.E6.m1.5.5.2.cmml" xref="S2.E6.m1.5.5.2"><plus id="S2.E6.m1.5.5.2.2.cmml" xref="S2.E6.m1.5.5.2.2"></plus><apply id="S2.E6.m1.5.5.2.1.cmml" xref="S2.E6.m1.5.5.2.1"><times id="S2.E6.m1.5.5.2.1.2.cmml" xref="S2.E6.m1.5.5.2.1.2"></times><ci id="S2.E6.m1.5.5.2.1.3.cmml" xref="S2.E6.m1.5.5.2.1.3">𝑒</ci><ci id="S2.E6.m1.5.5.2.1.4.cmml" xref="S2.E6.m1.5.5.2.1.4">𝑥</ci><ci id="S2.E6.m1.5.5.2.1.5.cmml" xref="S2.E6.m1.5.5.2.1.5">𝑝</ci><ci id="S2.E6.m1.2.2.cmml" xref="S2.E6.m1.2.2">italic-ϵ</ci><ci id="S2.E6.m1.5.5.2.1.7.cmml" xref="S2.E6.m1.5.5.2.1.7">𝑃</ci><apply id="S2.E6.m1.5.5.2.1.1.2.cmml" xref="S2.E6.m1.5.5.2.1.1.1"><csymbol cd="latexml" id="S2.E6.m1.5.5.2.1.1.2.1.cmml" xref="S2.E6.m1.5.5.2.1.1.1.2">delimited-[]</csymbol><apply id="S2.E6.m1.5.5.2.1.1.1.1.cmml" xref="S2.E6.m1.5.5.2.1.1.1.1"><in id="S2.E6.m1.5.5.2.1.1.1.1.1.cmml" xref="S2.E6.m1.5.5.2.1.1.1.1.1"></in><apply id="S2.E6.m1.5.5.2.1.1.1.1.2.cmml" xref="S2.E6.m1.5.5.2.1.1.1.1.2"><times id="S2.E6.m1.5.5.2.1.1.1.1.2.1.cmml" xref="S2.E6.m1.5.5.2.1.1.1.1.2.1"></times><ci id="S2.E6.m1.5.5.2.1.1.1.1.2.2.cmml" xref="S2.E6.m1.5.5.2.1.1.1.1.2.2">𝑀</ci><ci id="S2.E6.m1.3.3.cmml" xref="S2.E6.m1.3.3">𝑦</ci></apply><ci id="S2.E6.m1.5.5.2.1.1.1.1.3.cmml" xref="S2.E6.m1.5.5.2.1.1.1.1.3">𝑆</ci></apply></apply></apply><ci id="S2.E6.m1.5.5.2.3.cmml" xref="S2.E6.m1.5.5.2.3">𝛿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E6.m1.5c">P[M(x)\in S]\leq exp(\epsilon)P[M(y)\in S]+\delta</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S2.SS4.p4.14" class="ltx_p">In this definition, <math id="S2.SS4.p4.5.m1.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S2.SS4.p4.5.m1.1a"><mi id="S2.SS4.p4.5.m1.1.1" xref="S2.SS4.p4.5.m1.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.5.m1.1b"><ci id="S2.SS4.p4.5.m1.1.1.cmml" xref="S2.SS4.p4.5.m1.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.5.m1.1c">\delta</annotation></semantics></math> is the probability of leaking more information than what <math id="S2.SS4.p4.6.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S2.SS4.p4.6.m2.1a"><mi id="S2.SS4.p4.6.m2.1.1" xref="S2.SS4.p4.6.m2.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.6.m2.1b"><ci id="S2.SS4.p4.6.m2.1.1.cmml" xref="S2.SS4.p4.6.m2.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.6.m2.1c">\epsilon</annotation></semantics></math> claims. <math id="S2.SS4.p4.7.m3.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S2.SS4.p4.7.m3.1a"><mi id="S2.SS4.p4.7.m3.1.1" xref="S2.SS4.p4.7.m3.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.7.m3.1b"><ci id="S2.SS4.p4.7.m3.1.1.cmml" xref="S2.SS4.p4.7.m3.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.7.m3.1c">\delta</annotation></semantics></math> is preferably zero or a very small value, typically the inverse polynomial of the sample size denoted as <math id="S2.SS4.p4.8.m4.1" class="ltx_Math" alttext="\delta=1/n^{k}" display="inline"><semantics id="S2.SS4.p4.8.m4.1a"><mrow id="S2.SS4.p4.8.m4.1.1" xref="S2.SS4.p4.8.m4.1.1.cmml"><mi id="S2.SS4.p4.8.m4.1.1.2" xref="S2.SS4.p4.8.m4.1.1.2.cmml">δ</mi><mo id="S2.SS4.p4.8.m4.1.1.1" xref="S2.SS4.p4.8.m4.1.1.1.cmml">=</mo><mrow id="S2.SS4.p4.8.m4.1.1.3" xref="S2.SS4.p4.8.m4.1.1.3.cmml"><mn id="S2.SS4.p4.8.m4.1.1.3.2" xref="S2.SS4.p4.8.m4.1.1.3.2.cmml">1</mn><mo id="S2.SS4.p4.8.m4.1.1.3.1" xref="S2.SS4.p4.8.m4.1.1.3.1.cmml">/</mo><msup id="S2.SS4.p4.8.m4.1.1.3.3" xref="S2.SS4.p4.8.m4.1.1.3.3.cmml"><mi id="S2.SS4.p4.8.m4.1.1.3.3.2" xref="S2.SS4.p4.8.m4.1.1.3.3.2.cmml">n</mi><mi id="S2.SS4.p4.8.m4.1.1.3.3.3" xref="S2.SS4.p4.8.m4.1.1.3.3.3.cmml">k</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.8.m4.1b"><apply id="S2.SS4.p4.8.m4.1.1.cmml" xref="S2.SS4.p4.8.m4.1.1"><eq id="S2.SS4.p4.8.m4.1.1.1.cmml" xref="S2.SS4.p4.8.m4.1.1.1"></eq><ci id="S2.SS4.p4.8.m4.1.1.2.cmml" xref="S2.SS4.p4.8.m4.1.1.2">𝛿</ci><apply id="S2.SS4.p4.8.m4.1.1.3.cmml" xref="S2.SS4.p4.8.m4.1.1.3"><divide id="S2.SS4.p4.8.m4.1.1.3.1.cmml" xref="S2.SS4.p4.8.m4.1.1.3.1"></divide><cn type="integer" id="S2.SS4.p4.8.m4.1.1.3.2.cmml" xref="S2.SS4.p4.8.m4.1.1.3.2">1</cn><apply id="S2.SS4.p4.8.m4.1.1.3.3.cmml" xref="S2.SS4.p4.8.m4.1.1.3.3"><csymbol cd="ambiguous" id="S2.SS4.p4.8.m4.1.1.3.3.1.cmml" xref="S2.SS4.p4.8.m4.1.1.3.3">superscript</csymbol><ci id="S2.SS4.p4.8.m4.1.1.3.3.2.cmml" xref="S2.SS4.p4.8.m4.1.1.3.3.2">𝑛</ci><ci id="S2.SS4.p4.8.m4.1.1.3.3.3.cmml" xref="S2.SS4.p4.8.m4.1.1.3.3.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.8.m4.1c">\delta=1/n^{k}</annotation></semantics></math> where <math id="S2.SS4.p4.9.m5.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.SS4.p4.9.m5.1a"><mi id="S2.SS4.p4.9.m5.1.1" xref="S2.SS4.p4.9.m5.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.9.m5.1b"><ci id="S2.SS4.p4.9.m5.1.1.cmml" xref="S2.SS4.p4.9.m5.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.9.m5.1c">n</annotation></semantics></math> is the sample size, and <math id="S2.SS4.p4.10.m6.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS4.p4.10.m6.1a"><mi id="S2.SS4.p4.10.m6.1.1" xref="S2.SS4.p4.10.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.10.m6.1b"><ci id="S2.SS4.p4.10.m6.1.1.cmml" xref="S2.SS4.p4.10.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.10.m6.1c">k</annotation></semantics></math> is a positive integer. This implies that a larger sample size reduces the risk of unintentional disclosure of private information resulting from a query. To achieve (<math id="S2.SS4.p4.11.m7.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S2.SS4.p4.11.m7.1a"><mi id="S2.SS4.p4.11.m7.1.1" xref="S2.SS4.p4.11.m7.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.11.m7.1b"><ci id="S2.SS4.p4.11.m7.1.1.cmml" xref="S2.SS4.p4.11.m7.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.11.m7.1c">\epsilon</annotation></semantics></math>, <math id="S2.SS4.p4.12.m8.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S2.SS4.p4.12.m8.1a"><mi id="S2.SS4.p4.12.m8.1.1" xref="S2.SS4.p4.12.m8.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.12.m8.1b"><ci id="S2.SS4.p4.12.m8.1.1.cmml" xref="S2.SS4.p4.12.m8.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.12.m8.1c">\delta</annotation></semantics></math>)-DP, additive noise is conditioned on the type of noise we are adding, the desired <math id="S2.SS4.p4.13.m9.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S2.SS4.p4.13.m9.1a"><mi id="S2.SS4.p4.13.m9.1.1" xref="S2.SS4.p4.13.m9.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.13.m9.1b"><ci id="S2.SS4.p4.13.m9.1.1.cmml" xref="S2.SS4.p4.13.m9.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.13.m9.1c">\epsilon</annotation></semantics></math> and <math id="S2.SS4.p4.14.m10.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S2.SS4.p4.14.m10.1a"><mi id="S2.SS4.p4.14.m10.1.1" xref="S2.SS4.p4.14.m10.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.14.m10.1b"><ci id="S2.SS4.p4.14.m10.1.1.cmml" xref="S2.SS4.p4.14.m10.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.14.m10.1c">\delta</annotation></semantics></math>, the sample size, the number of queries performed on the database, and the desired accuracy. In differential privacy, computations involving noise safeguard personal data and prevent it from being reverse-engineered from the results <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. However, leaking private information due to statistical queries and machine learning models compromises privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. Sensitivity is used to monitor this leakage of information.</p>
</div>
<div id="Thmdefinition6" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="Thmdefinition6.1.1.1" class="ltx_text ltx_font_bold">Definition 6</span></span></h6>
<div id="Thmdefinition6.p1" class="ltx_para">
<p id="Thmdefinition6.p1.1" class="ltx_p"><span id="Thmdefinition6.p1.1.1" class="ltx_text ltx_font_italic">Sensitivity is the maximum change in the output of a query as a result of removing an individual from the database.</span></p>
</div>
</div>
<div id="S2.SS4.p5" class="ltx_para">
<p id="S2.SS4.p5.5" class="ltx_p">Sensitivity is measured based on the distance (<math id="S2.SS4.p5.1.m1.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S2.SS4.p5.1.m1.1a"><mi id="S2.SS4.p5.1.m1.1.1" xref="S2.SS4.p5.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p5.1.m1.1b"><ci id="S2.SS4.p5.1.m1.1.1.cmml" xref="S2.SS4.p5.1.m1.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p5.1.m1.1c">d</annotation></semantics></math>) between the output of mechanism <math id="S2.SS4.p5.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.SS4.p5.2.m2.1a"><mi id="S2.SS4.p5.2.m2.1.1" xref="S2.SS4.p5.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p5.2.m2.1b"><ci id="S2.SS4.p5.2.m2.1.1.cmml" xref="S2.SS4.p5.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p5.2.m2.1c">M</annotation></semantics></math> on the neighboring datasets <math id="S2.SS4.p5.3.m3.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.SS4.p5.3.m3.1a"><mi id="S2.SS4.p5.3.m3.1.1" xref="S2.SS4.p5.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p5.3.m3.1b"><ci id="S2.SS4.p5.3.m3.1.1.cmml" xref="S2.SS4.p5.3.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p5.3.m3.1c">x</annotation></semantics></math> and <math id="S2.SS4.p5.4.m4.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S2.SS4.p5.4.m4.1a"><mi id="S2.SS4.p5.4.m4.1.1" xref="S2.SS4.p5.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p5.4.m4.1b"><ci id="S2.SS4.p5.4.m4.1.1.cmml" xref="S2.SS4.p5.4.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p5.4.m4.1c">y</annotation></semantics></math>, where <math id="S2.SS4.p5.5.m5.2" class="ltx_Math" alttext="d(x,y)\leq 1" display="inline"><semantics id="S2.SS4.p5.5.m5.2a"><mrow id="S2.SS4.p5.5.m5.2.3" xref="S2.SS4.p5.5.m5.2.3.cmml"><mrow id="S2.SS4.p5.5.m5.2.3.2" xref="S2.SS4.p5.5.m5.2.3.2.cmml"><mi id="S2.SS4.p5.5.m5.2.3.2.2" xref="S2.SS4.p5.5.m5.2.3.2.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.SS4.p5.5.m5.2.3.2.1" xref="S2.SS4.p5.5.m5.2.3.2.1.cmml">​</mo><mrow id="S2.SS4.p5.5.m5.2.3.2.3.2" xref="S2.SS4.p5.5.m5.2.3.2.3.1.cmml"><mo stretchy="false" id="S2.SS4.p5.5.m5.2.3.2.3.2.1" xref="S2.SS4.p5.5.m5.2.3.2.3.1.cmml">(</mo><mi id="S2.SS4.p5.5.m5.1.1" xref="S2.SS4.p5.5.m5.1.1.cmml">x</mi><mo id="S2.SS4.p5.5.m5.2.3.2.3.2.2" xref="S2.SS4.p5.5.m5.2.3.2.3.1.cmml">,</mo><mi id="S2.SS4.p5.5.m5.2.2" xref="S2.SS4.p5.5.m5.2.2.cmml">y</mi><mo stretchy="false" id="S2.SS4.p5.5.m5.2.3.2.3.2.3" xref="S2.SS4.p5.5.m5.2.3.2.3.1.cmml">)</mo></mrow></mrow><mo id="S2.SS4.p5.5.m5.2.3.1" xref="S2.SS4.p5.5.m5.2.3.1.cmml">≤</mo><mn id="S2.SS4.p5.5.m5.2.3.3" xref="S2.SS4.p5.5.m5.2.3.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p5.5.m5.2b"><apply id="S2.SS4.p5.5.m5.2.3.cmml" xref="S2.SS4.p5.5.m5.2.3"><leq id="S2.SS4.p5.5.m5.2.3.1.cmml" xref="S2.SS4.p5.5.m5.2.3.1"></leq><apply id="S2.SS4.p5.5.m5.2.3.2.cmml" xref="S2.SS4.p5.5.m5.2.3.2"><times id="S2.SS4.p5.5.m5.2.3.2.1.cmml" xref="S2.SS4.p5.5.m5.2.3.2.1"></times><ci id="S2.SS4.p5.5.m5.2.3.2.2.cmml" xref="S2.SS4.p5.5.m5.2.3.2.2">𝑑</ci><interval closure="open" id="S2.SS4.p5.5.m5.2.3.2.3.1.cmml" xref="S2.SS4.p5.5.m5.2.3.2.3.2"><ci id="S2.SS4.p5.5.m5.1.1.cmml" xref="S2.SS4.p5.5.m5.1.1">𝑥</ci><ci id="S2.SS4.p5.5.m5.2.2.cmml" xref="S2.SS4.p5.5.m5.2.2">𝑦</ci></interval></apply><cn type="integer" id="S2.SS4.p5.5.m5.2.3.3.cmml" xref="S2.SS4.p5.5.m5.2.3.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p5.5.m5.2c">d(x,y)\leq 1</annotation></semantics></math>. Sensitivity is defined as:</p>
<table id="S2.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S2.E7.m1.31" class="ltx_Math" alttext="\begin{split}&amp;Sensitivity=max||M(x)-M(y)||_{1}\end{split}" display="block"><semantics id="S2.E7.m1.31a"><mtable columnspacing="0pt" displaystyle="true" id="S2.E7.m1.31.31.2" xref="S2.E7.m1.30.30.1.cmml"><mtr id="S2.E7.m1.31.31.2a" xref="S2.E7.m1.30.30.1.cmml"><mtd id="S2.E7.m1.31.31.2b" xref="S2.E7.m1.30.30.1.cmml"></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.E7.m1.31.31.2c" xref="S2.E7.m1.30.30.1.cmml"><mrow id="S2.E7.m1.31.31.2.30.30.30" xref="S2.E7.m1.30.30.1.cmml"><mrow id="S2.E7.m1.31.31.2.30.30.30.31" xref="S2.E7.m1.30.30.1.cmml"><mi id="S2.E7.m1.1.1.1.1.1.1" xref="S2.E7.m1.1.1.1.1.1.1.cmml">S</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.31.31.2.30.30.30.31.1" xref="S2.E7.m1.30.30.1.cmml">​</mo><mi id="S2.E7.m1.2.2.2.2.2.2" xref="S2.E7.m1.2.2.2.2.2.2.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.31.31.2.30.30.30.31.1a" xref="S2.E7.m1.30.30.1.cmml">​</mo><mi id="S2.E7.m1.3.3.3.3.3.3" xref="S2.E7.m1.3.3.3.3.3.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.31.31.2.30.30.30.31.1b" xref="S2.E7.m1.30.30.1.cmml">​</mo><mi id="S2.E7.m1.4.4.4.4.4.4" xref="S2.E7.m1.4.4.4.4.4.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.31.31.2.30.30.30.31.1c" xref="S2.E7.m1.30.30.1.cmml">​</mo><mi id="S2.E7.m1.5.5.5.5.5.5" xref="S2.E7.m1.5.5.5.5.5.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.31.31.2.30.30.30.31.1d" xref="S2.E7.m1.30.30.1.cmml">​</mo><mi id="S2.E7.m1.6.6.6.6.6.6" xref="S2.E7.m1.6.6.6.6.6.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.31.31.2.30.30.30.31.1e" xref="S2.E7.m1.30.30.1.cmml">​</mo><mi id="S2.E7.m1.7.7.7.7.7.7" xref="S2.E7.m1.7.7.7.7.7.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.31.31.2.30.30.30.31.1f" xref="S2.E7.m1.30.30.1.cmml">​</mo><mi id="S2.E7.m1.8.8.8.8.8.8" xref="S2.E7.m1.8.8.8.8.8.8.cmml">v</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.31.31.2.30.30.30.31.1g" xref="S2.E7.m1.30.30.1.cmml">​</mo><mi id="S2.E7.m1.9.9.9.9.9.9" xref="S2.E7.m1.9.9.9.9.9.9.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.31.31.2.30.30.30.31.1h" xref="S2.E7.m1.30.30.1.cmml">​</mo><mi id="S2.E7.m1.10.10.10.10.10.10" xref="S2.E7.m1.10.10.10.10.10.10.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.31.31.2.30.30.30.31.1i" xref="S2.E7.m1.30.30.1.cmml">​</mo><mi id="S2.E7.m1.11.11.11.11.11.11" xref="S2.E7.m1.11.11.11.11.11.11.cmml">y</mi></mrow><mo id="S2.E7.m1.12.12.12.12.12.12" xref="S2.E7.m1.12.12.12.12.12.12.cmml">=</mo><mrow id="S2.E7.m1.31.31.2.30.30.30.30" xref="S2.E7.m1.30.30.1.cmml"><mi id="S2.E7.m1.13.13.13.13.13.13" xref="S2.E7.m1.13.13.13.13.13.13.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.31.31.2.30.30.30.30.2" xref="S2.E7.m1.30.30.1.cmml">​</mo><mi id="S2.E7.m1.14.14.14.14.14.14" xref="S2.E7.m1.14.14.14.14.14.14.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.31.31.2.30.30.30.30.2a" xref="S2.E7.m1.30.30.1.cmml">​</mo><mi id="S2.E7.m1.15.15.15.15.15.15" xref="S2.E7.m1.15.15.15.15.15.15.cmml">x</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.31.31.2.30.30.30.30.2b" xref="S2.E7.m1.30.30.1.cmml">​</mo><msub id="S2.E7.m1.31.31.2.30.30.30.30.1" xref="S2.E7.m1.30.30.1.cmml"><mrow id="S2.E7.m1.31.31.2.30.30.30.30.1.1.1" xref="S2.E7.m1.30.30.1.cmml"><mo stretchy="false" id="S2.E7.m1.16.16.16.16.16.16b" xref="S2.E7.m1.30.30.1.cmml">‖</mo><mrow id="S2.E7.m1.31.31.2.30.30.30.30.1.1.1.1" xref="S2.E7.m1.30.30.1.cmml"><mrow id="S2.E7.m1.31.31.2.30.30.30.30.1.1.1.1.1" xref="S2.E7.m1.30.30.1.cmml"><mi id="S2.E7.m1.18.18.18.18.18.18" xref="S2.E7.m1.18.18.18.18.18.18.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.31.31.2.30.30.30.30.1.1.1.1.1.1" xref="S2.E7.m1.30.30.1.cmml">​</mo><mrow id="S2.E7.m1.31.31.2.30.30.30.30.1.1.1.1.1.2" xref="S2.E7.m1.30.30.1.cmml"><mo stretchy="false" id="S2.E7.m1.19.19.19.19.19.19" xref="S2.E7.m1.30.30.1.cmml">(</mo><mi id="S2.E7.m1.20.20.20.20.20.20" xref="S2.E7.m1.20.20.20.20.20.20.cmml">x</mi><mo stretchy="false" id="S2.E7.m1.21.21.21.21.21.21" xref="S2.E7.m1.30.30.1.cmml">)</mo></mrow></mrow><mo id="S2.E7.m1.22.22.22.22.22.22" xref="S2.E7.m1.22.22.22.22.22.22.cmml">−</mo><mrow id="S2.E7.m1.31.31.2.30.30.30.30.1.1.1.1.2" xref="S2.E7.m1.30.30.1.cmml"><mi id="S2.E7.m1.23.23.23.23.23.23" xref="S2.E7.m1.23.23.23.23.23.23.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.31.31.2.30.30.30.30.1.1.1.1.2.1" xref="S2.E7.m1.30.30.1.cmml">​</mo><mrow id="S2.E7.m1.31.31.2.30.30.30.30.1.1.1.1.2.2" xref="S2.E7.m1.30.30.1.cmml"><mo stretchy="false" id="S2.E7.m1.24.24.24.24.24.24" xref="S2.E7.m1.30.30.1.cmml">(</mo><mi id="S2.E7.m1.25.25.25.25.25.25" xref="S2.E7.m1.25.25.25.25.25.25.cmml">y</mi><mo stretchy="false" id="S2.E7.m1.26.26.26.26.26.26" xref="S2.E7.m1.30.30.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S2.E7.m1.27.27.27.27.27.27b" xref="S2.E7.m1.30.30.1.cmml">‖</mo></mrow><mn id="S2.E7.m1.29.29.29.29.29.29.1" xref="S2.E7.m1.29.29.29.29.29.29.1.cmml">1</mn></msub></mrow></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S2.E7.m1.31b"><apply id="S2.E7.m1.30.30.1.cmml" xref="S2.E7.m1.31.31.2"><eq id="S2.E7.m1.12.12.12.12.12.12.cmml" xref="S2.E7.m1.12.12.12.12.12.12"></eq><apply id="S2.E7.m1.30.30.1.3.cmml" xref="S2.E7.m1.31.31.2"><times id="S2.E7.m1.30.30.1.3.1.cmml" xref="S2.E7.m1.31.31.2"></times><ci id="S2.E7.m1.1.1.1.1.1.1.cmml" xref="S2.E7.m1.1.1.1.1.1.1">𝑆</ci><ci id="S2.E7.m1.2.2.2.2.2.2.cmml" xref="S2.E7.m1.2.2.2.2.2.2">𝑒</ci><ci id="S2.E7.m1.3.3.3.3.3.3.cmml" xref="S2.E7.m1.3.3.3.3.3.3">𝑛</ci><ci id="S2.E7.m1.4.4.4.4.4.4.cmml" xref="S2.E7.m1.4.4.4.4.4.4">𝑠</ci><ci id="S2.E7.m1.5.5.5.5.5.5.cmml" xref="S2.E7.m1.5.5.5.5.5.5">𝑖</ci><ci id="S2.E7.m1.6.6.6.6.6.6.cmml" xref="S2.E7.m1.6.6.6.6.6.6">𝑡</ci><ci id="S2.E7.m1.7.7.7.7.7.7.cmml" xref="S2.E7.m1.7.7.7.7.7.7">𝑖</ci><ci id="S2.E7.m1.8.8.8.8.8.8.cmml" xref="S2.E7.m1.8.8.8.8.8.8">𝑣</ci><ci id="S2.E7.m1.9.9.9.9.9.9.cmml" xref="S2.E7.m1.9.9.9.9.9.9">𝑖</ci><ci id="S2.E7.m1.10.10.10.10.10.10.cmml" xref="S2.E7.m1.10.10.10.10.10.10">𝑡</ci><ci id="S2.E7.m1.11.11.11.11.11.11.cmml" xref="S2.E7.m1.11.11.11.11.11.11">𝑦</ci></apply><apply id="S2.E7.m1.30.30.1.1.cmml" xref="S2.E7.m1.31.31.2"><times id="S2.E7.m1.30.30.1.1.2.cmml" xref="S2.E7.m1.31.31.2"></times><ci id="S2.E7.m1.13.13.13.13.13.13.cmml" xref="S2.E7.m1.13.13.13.13.13.13">𝑚</ci><ci id="S2.E7.m1.14.14.14.14.14.14.cmml" xref="S2.E7.m1.14.14.14.14.14.14">𝑎</ci><ci id="S2.E7.m1.15.15.15.15.15.15.cmml" xref="S2.E7.m1.15.15.15.15.15.15">𝑥</ci><apply id="S2.E7.m1.30.30.1.1.1.cmml" xref="S2.E7.m1.31.31.2"><csymbol cd="ambiguous" id="S2.E7.m1.30.30.1.1.1.2.cmml" xref="S2.E7.m1.31.31.2">subscript</csymbol><apply id="S2.E7.m1.30.30.1.1.1.1.2.cmml" xref="S2.E7.m1.31.31.2"><csymbol cd="latexml" id="S2.E7.m1.30.30.1.1.1.1.2.1.cmml" xref="S2.E7.m1.31.31.2">norm</csymbol><apply id="S2.E7.m1.30.30.1.1.1.1.1.1.cmml" xref="S2.E7.m1.31.31.2"><minus id="S2.E7.m1.22.22.22.22.22.22.cmml" xref="S2.E7.m1.22.22.22.22.22.22"></minus><apply id="S2.E7.m1.30.30.1.1.1.1.1.1.2.cmml" xref="S2.E7.m1.31.31.2"><times id="S2.E7.m1.30.30.1.1.1.1.1.1.2.1.cmml" xref="S2.E7.m1.31.31.2"></times><ci id="S2.E7.m1.18.18.18.18.18.18.cmml" xref="S2.E7.m1.18.18.18.18.18.18">𝑀</ci><ci id="S2.E7.m1.20.20.20.20.20.20.cmml" xref="S2.E7.m1.20.20.20.20.20.20">𝑥</ci></apply><apply id="S2.E7.m1.30.30.1.1.1.1.1.1.3.cmml" xref="S2.E7.m1.31.31.2"><times id="S2.E7.m1.30.30.1.1.1.1.1.1.3.1.cmml" xref="S2.E7.m1.31.31.2"></times><ci id="S2.E7.m1.23.23.23.23.23.23.cmml" xref="S2.E7.m1.23.23.23.23.23.23">𝑀</ci><ci id="S2.E7.m1.25.25.25.25.25.25.cmml" xref="S2.E7.m1.25.25.25.25.25.25">𝑦</ci></apply></apply></apply><cn type="integer" id="S2.E7.m1.29.29.29.29.29.29.1.cmml" xref="S2.E7.m1.29.29.29.29.29.29.1">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E7.m1.31c">\begin{split}&amp;Sensitivity=max||M(x)-M(y)||_{1}\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS4.p6" class="ltx_para">
<p id="S2.SS4.p6.1" class="ltx_p">Sensitivity helps characterize the impact of individual data on the output, while <math id="S2.SS4.p6.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S2.SS4.p6.1.m1.1a"><mi id="S2.SS4.p6.1.m1.1.1" xref="S2.SS4.p6.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p6.1.m1.1b"><ci id="S2.SS4.p6.1.m1.1.1.cmml" xref="S2.SS4.p6.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p6.1.m1.1c">\epsilon</annotation></semantics></math> quantifies the upper bound on the level of privacy protection that the algorithm can guarantee.</p>
</div>
<div id="S2.SS4.p7" class="ltx_para">
<p id="S2.SS4.p7.2" class="ltx_p">In practice, differentially private algorithms are required to randomize the query or training model output by adding noise before publicly communicating it with other users. Under differential privacy, we must carefully choose where to add noise and select the appropriate type and amount. A common approach is adding noise sampled from a Gaussian distribution with a mean of <math id="S2.SS4.p7.1.m1.1" class="ltx_Math" alttext="\mu=0" display="inline"><semantics id="S2.SS4.p7.1.m1.1a"><mrow id="S2.SS4.p7.1.m1.1.1" xref="S2.SS4.p7.1.m1.1.1.cmml"><mi id="S2.SS4.p7.1.m1.1.1.2" xref="S2.SS4.p7.1.m1.1.1.2.cmml">μ</mi><mo id="S2.SS4.p7.1.m1.1.1.1" xref="S2.SS4.p7.1.m1.1.1.1.cmml">=</mo><mn id="S2.SS4.p7.1.m1.1.1.3" xref="S2.SS4.p7.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p7.1.m1.1b"><apply id="S2.SS4.p7.1.m1.1.1.cmml" xref="S2.SS4.p7.1.m1.1.1"><eq id="S2.SS4.p7.1.m1.1.1.1.cmml" xref="S2.SS4.p7.1.m1.1.1.1"></eq><ci id="S2.SS4.p7.1.m1.1.1.2.cmml" xref="S2.SS4.p7.1.m1.1.1.2">𝜇</ci><cn type="integer" id="S2.SS4.p7.1.m1.1.1.3.cmml" xref="S2.SS4.p7.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p7.1.m1.1c">\mu=0</annotation></semantics></math> and a standard deviation of <math id="S2.SS4.p7.2.m2.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S2.SS4.p7.2.m2.1a"><mi id="S2.SS4.p7.2.m2.1.1" xref="S2.SS4.p7.2.m2.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p7.2.m2.1b"><ci id="S2.SS4.p7.2.m2.1.1.cmml" xref="S2.SS4.p7.2.m2.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p7.2.m2.1c">\sigma</annotation></semantics></math>. A higher noise level provides stronger privacy guarantees. We can design private models that abide by the definition of differential privacy and are restricted under the desired privacy guarantees. In recent years, differential privacy has been widely used in the federated learning framework.</p>
</div>
</section>
<section id="S2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Federated Learning</h3>

<div id="S2.SS5.p1" class="ltx_para">
<p id="S2.SS5.p1.1" class="ltx_p">Federated learning is a promising paradigm for collaborative model training across multiple devices without data sharing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. Keeping the data decentralized reduces the risk of leakage and data breach <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. This ensures that the benefits of machine learning can be utilized without compromising the privacy of individuals or organizations. The training process starts by sending the global base model to a subset of data centers. The model is trained locally, and the parameters are securely transmitted to the global server. The parameters received from the data centers at each round of training are aggregated in the global server. The model is updated and sent to the data centers for training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>.</p>
</div>
<div id="S2.SS5.p2" class="ltx_para">
<p id="S2.SS5.p2.1" class="ltx_p">Apart from keeping data decentralized, differential privacy is used to provide privacy by adding noise during training and sending perturbed parameters to the global server. Federated learning has a wide range of applications in healthcare, protection of genomics data, social sciences, finance, information collected on personal devices such as location, browsing history, user activities on the web, and many more.</p>
</div>
</section>
<section id="S2.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.6 </span>Highlights</h3>

<div id="S2.SS6.p1" class="ltx_para">
<p id="S2.SS6.p1.1" class="ltx_p">Understanding the intricacies of machine learning models’ ability to generalize is rooted in several key concepts. The main takeaways of this section for deep learning and privacy are provided.

<br class="ltx_break">1. Interplay of VC dimension, Rademacher complexity, stability, and generalization: The notions of VC dimension, Rademacher complexity, and stability are closely intertwined and essential to the model’s generalization ability.</p>
<ul id="S2.I2" class="ltx_itemize">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p">Rademacher complexity and stability encapsulate the algorithm’s behavior towards noise in the data. While stability measures the changes in the model output in the presence of noise, Rademacher complexity quantifies the model’s ability to learn the random noise in the data, and it is upper bounded by the VC dimension.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p">Research by Ron and Kearns <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> on the connection between VC dimension and stability indicates that for algorithms with finite VC dimensions, stability is bounded by the VC dimensions.</p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.1" class="ltx_p">Studies on the relationship between VC dimension and Rademacher complexity in deep neural network models by Neyshabour et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> and Karpinski and Macintyre <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> suggest that VC dimension, Rademacher complexity, and the number of parameters are equivalent. Hence, the number of model parameters determines the model capacity.</p>
</div>
</li>
<li id="S2.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i4.p1" class="ltx_para">
<p id="S2.I2.i4.p1.1" class="ltx_p">Deep learning models are said to be over-parameterized if the number of parameters is significantly larger than the number of available data points in the training set.</p>
</div>
</li>
<li id="S2.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i5.p1" class="ltx_para">
<p id="S2.I2.i5.p1.1" class="ltx_p">Over-parameterized models are more prone to overfitting due to increased model capacity.</p>
</div>
</li>
<li id="S2.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i6.p1" class="ltx_para">
<p id="S2.I2.i6.p1.1" class="ltx_p">Large, diverse data can mitigate the risk of overfitting caused by over-parameterization. The abundance of data allows the model to learn the underlying patterns beyond the noise and perform well on unseen data. In situations with limited data, regularization techniques can be employed to prevent overfitting and enhance the generalization capability of a model. Regularization techniques control the variance by modifying the cost function and applying a penalty term.</p>
</div>
</li>
<li id="S2.I2.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i7.p1" class="ltx_para">
<p id="S2.I2.i7.p1.1" class="ltx_p">Bishop <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> demonstrated that the regularization term is written as a Tikhonov regularizer in a simple neural network architecture with one input and one output. Tikhonov regularization is often referred to as ridge regression or <math id="S2.I2.i7.p1.1.m1.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="S2.I2.i7.p1.1.m1.1a"><msub id="S2.I2.i7.p1.1.m1.1.1" xref="S2.I2.i7.p1.1.m1.1.1.cmml"><mi id="S2.I2.i7.p1.1.m1.1.1.2" xref="S2.I2.i7.p1.1.m1.1.1.2.cmml">L</mi><mn id="S2.I2.i7.p1.1.m1.1.1.3" xref="S2.I2.i7.p1.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S2.I2.i7.p1.1.m1.1b"><apply id="S2.I2.i7.p1.1.m1.1.1.cmml" xref="S2.I2.i7.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I2.i7.p1.1.m1.1.1.1.cmml" xref="S2.I2.i7.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I2.i7.p1.1.m1.1.1.2.cmml" xref="S2.I2.i7.p1.1.m1.1.1.2">𝐿</ci><cn type="integer" id="S2.I2.i7.p1.1.m1.1.1.3.cmml" xref="S2.I2.i7.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i7.p1.1.m1.1c">L_{2}</annotation></semantics></math> regularization in machine learning. Bishop <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> also</p>
</div>
</li>
<li id="S2.I2.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i8.p1" class="ltx_para">
<p id="S2.I2.i8.p1.1" class="ltx_p">Bishop <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> also highlights that training with noise is a form of regularization in neural network models. His findings and the research by others, such as Shalev-Shwartz and Ben-David <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, suggest that regularization results in stable algorithms.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS6.p2" class="ltx_para">
<p id="S2.SS6.p2.1" class="ltx_p">Careful regularization and architectural choices are essential to finding the balance between model complexity, stability, and generalization. Research Question 1 aims to explore this intricate balance further and provide insights on how to improve it.

<br class="ltx_break">2. Stability and Differential Privacy:</p>
<ul id="S2.I3" class="ltx_itemize">
<li id="S2.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i1.p1" class="ltx_para">
<p id="S2.I3.i1.p1.1" class="ltx_p">Stability is a desirable property in machine learning models, as it ensures that minor changes in the input do not result in drastic changes in the output predictions.</p>
</div>
</li>
<li id="S2.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i2.p1" class="ltx_para">
<p id="S2.I3.i2.p1.1" class="ltx_p">The definition of differential privacy inherently aligns with stability. Maximizing stability in algorithms offers stronger privacy protection guarantees under differential privacy.</p>
</div>
</li>
<li id="S2.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i3.p1" class="ltx_para">
<p id="S2.I3.i3.p1.1" class="ltx_p">A potential drawback of differential privacy is its negative impact on accuracy due to introducing noise during training. Excessive noise during training can disrupt the data and cause loss of information, leading to reduced model performance.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS6.p3" class="ltx_para">
<p id="S2.SS6.p3.1" class="ltx_p">Careful tuning of the noise parameters is a critical step in training with noise. The optimal amount of noise can vary depending on factors such as the problem, the data, and the desired properties of the training model. Research Question 2 aims to provide solutions that can help improve the tuning process and enable the selection of an optimal amount of noise for a given problem and dataset.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Training with Noise in Deep Neural Networks</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Noise infusion has been studied in various domains. This phenomenon, known as <span id="S3.p1.1.1" class="ltx_text ltx_font_italic">stochastic resonance</span>, employs Gaussian noise to enhance the system’s signal detection capabilities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. The idea of stochastic resonance dates back to the early 1980s when Benzi et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>
introduced the phenomena and investigated its effect on complex systems. Figure <a href="#S3.F2" title="Figure 2 ‣ 3 Training with Noise in Deep Neural Networks ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> demonstrates the impact of Gaussian noise on amplifying the weak signals.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2311.05790/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The weak signal becomes more distinguishable after stochastic resonance. </figcaption>
</figure>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">When the noise magnitude is small, additive noise enhances weak signals and improves the system’s ability to identify useful data without negatively impacting the input. It also helps biological systems to adapt and learn from noisy environments <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. Stochastic resonance has a wide range of applications in science and engineering, from neuroscience to biological processes, signal processing, and information transmission. Numerous studies focus on the benefits of additive noise in pattern recognition in the nervous system and how it applies to computational neural network settings<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">Adding noise to a dataset alters the output of the queries. Figure <a href="#S3.F3" title="Figure 3 ‣ 3 Training with Noise in Deep Neural Networks ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> demonstrates the impact of input noise on two images taken from the CIFAR-10 dataset. The input noise is implemented by adding a random value sampled from the Gaussian distribution with a standard deviation of <math id="S3.p3.1.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S3.p3.1.m1.1a"><mi id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><ci id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">\sigma</annotation></semantics></math> during training. It can be observed that the images can absorb different noise magnitudes before they are completely corrupted. The problem specifications, data, and training models contribute to determining the appropriate noise level for training.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2311.05790/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Perturbed images with Gaussian noise.</figcaption>
</figure>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">Deep neural networks can learn the complex relationships in the data, making them well-suited for tasks such as image and speech recognition, natural language processing, and many other applications in artificial intelligence and machine learning.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p">Despite their popularity, they are not a silver bullet that can solve all problems in artificial intelligence. Deep learning models are notoriously data-hungry and require a large amount of data to train on. Therefore, their performance relies on the intricacy of the problem and the data, model architecture, and optimization techniques. Their sensitivity to changes in the data distribution and complexity of the model architecture affects their ability to identify critical information rather than memorize the data. Failure in learning leads to overfitting the data. The benefits of adding noise during training are but are not limited to the following:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">Handling inherently noisy data as a result of measurement errors or corrupted data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite></p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">Handling inadequate training data for training: Noise infusion is an effective data augmentation method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. Noise infusion schemes help diversify the data collected on edge devices to improve the distributed learning results <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">Reducing overfitting and improving generalization: Empirical studies demonstrate that additive noise improves generalization in deep neural networks by preventing the model from getting too complex and memorizing the input data. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p">Improving the robustness of the neural network model against adversarial noise <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.1" class="ltx_p">In deep learning, we can introduce noise into the algorithm by perturbing input, labels, gradients, weights, or the network’s architecture. Table <a href="#S3.T1" title="Table 1 ‣ 3 Training with Noise in Deep Neural Networks ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> presents some of the studies on noise infusion mechanisms in deep learning. The choice of the amount of noise and noise infusion mechanism is critical in designing an efficient model with the desired stability and generalization ability.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Noise infusion mechanisms in deep learning literature</figcaption>
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Noise Infusion Mechanisms</th>
<th id="S3.T1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">References</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.1.2.1" class="ltx_tr">
<th id="S3.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Input</th>
<td id="S3.T1.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>, <a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite></td>
</tr>
<tr id="S3.T1.1.3.2" class="ltx_tr">
<th id="S3.T1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Hidden Layers</th>
<td id="S3.T1.1.3.2.2" class="ltx_td ltx_align_left ltx_border_r"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite></td>
</tr>
<tr id="S3.T1.1.4.3" class="ltx_tr">
<th id="S3.T1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Model Weights</th>
<td id="S3.T1.1.4.3.2" class="ltx_td ltx_align_left ltx_border_r"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>, <a href="#bib.bib67" title="" class="ltx_ref">67</a>, <a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite></td>
</tr>
<tr id="S3.T1.1.5.4" class="ltx_tr">
<th id="S3.T1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Gradients</th>
<td id="S3.T1.1.5.4.2" class="ltx_td ltx_align_left ltx_border_r"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>, <a href="#bib.bib72" title="" class="ltx_ref">72</a>, <a href="#bib.bib73" title="" class="ltx_ref">73</a>, <a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite></td>
</tr>
<tr id="S3.T1.1.6.5" class="ltx_tr">
<th id="S3.T1.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">Labels</th>
<td id="S3.T1.1.6.5.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>, <a href="#bib.bib76" title="" class="ltx_ref">76</a>, <a href="#bib.bib77" title="" class="ltx_ref">77</a>, <a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite></td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.p7" class="ltx_para">
<p id="S3.p7.1" class="ltx_p">In this paper, we explore various noise infusion mechanisms for image classification using CNN. CNNs are a class of deep learning models designed primarily for processing and analyzing visual data, such as images and videos. They have revolutionized computer vision and have found widespread applications in various fields. CNN uses convolutional layers to automatically learn hierarchical features from input data, making them well-suited for tasks like image classification, object detection, and facial recognition. CNNs continue to evolve, pushing the boundaries of what is possible in machine perception and understanding.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Signal-to-Noise Ratio</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Signal-to-Noise Ratio (SNR) quantifies the clarity of the desired signal in the presence of noise in the signal processing domain. The idea of SNR is closely related to stochastic resonance, in which additive noise enhances weak signals<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>, <a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>. SNR is defined as:</p>
<table id="S3.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S3.E8.m1.1" class="ltx_Math" alttext="SNR=10\times\log_{10}\frac{Signal\;power}{Noise\;power}" display="block"><semantics id="S3.E8.m1.1a"><mrow id="S3.E8.m1.1.1" xref="S3.E8.m1.1.1.cmml"><mrow id="S3.E8.m1.1.1.2" xref="S3.E8.m1.1.1.2.cmml"><mi id="S3.E8.m1.1.1.2.2" xref="S3.E8.m1.1.1.2.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.2.1" xref="S3.E8.m1.1.1.2.1.cmml">​</mo><mi id="S3.E8.m1.1.1.2.3" xref="S3.E8.m1.1.1.2.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.2.1a" xref="S3.E8.m1.1.1.2.1.cmml">​</mo><mi id="S3.E8.m1.1.1.2.4" xref="S3.E8.m1.1.1.2.4.cmml">R</mi></mrow><mo id="S3.E8.m1.1.1.1" xref="S3.E8.m1.1.1.1.cmml">=</mo><mrow id="S3.E8.m1.1.1.3" xref="S3.E8.m1.1.1.3.cmml"><mn id="S3.E8.m1.1.1.3.2" xref="S3.E8.m1.1.1.3.2.cmml">10</mn><mo lspace="0.222em" rspace="0.222em" id="S3.E8.m1.1.1.3.1" xref="S3.E8.m1.1.1.3.1.cmml">×</mo><mrow id="S3.E8.m1.1.1.3.3" xref="S3.E8.m1.1.1.3.3.cmml"><msub id="S3.E8.m1.1.1.3.3.1" xref="S3.E8.m1.1.1.3.3.1.cmml"><mi id="S3.E8.m1.1.1.3.3.1.2" xref="S3.E8.m1.1.1.3.3.1.2.cmml">log</mi><mn id="S3.E8.m1.1.1.3.3.1.3" xref="S3.E8.m1.1.1.3.3.1.3.cmml">10</mn></msub><mo lspace="0.167em" id="S3.E8.m1.1.1.3.3a" xref="S3.E8.m1.1.1.3.3.cmml">⁡</mo><mfrac id="S3.E8.m1.1.1.3.3.2" xref="S3.E8.m1.1.1.3.3.2.cmml"><mrow id="S3.E8.m1.1.1.3.3.2.2" xref="S3.E8.m1.1.1.3.3.2.2.cmml"><mi id="S3.E8.m1.1.1.3.3.2.2.2" xref="S3.E8.m1.1.1.3.3.2.2.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.2.1" xref="S3.E8.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.2.3" xref="S3.E8.m1.1.1.3.3.2.2.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.2.1a" xref="S3.E8.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.2.4" xref="S3.E8.m1.1.1.3.3.2.2.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.2.1b" xref="S3.E8.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.2.5" xref="S3.E8.m1.1.1.3.3.2.2.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.2.1c" xref="S3.E8.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.2.6" xref="S3.E8.m1.1.1.3.3.2.2.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.2.1d" xref="S3.E8.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.2.7" xref="S3.E8.m1.1.1.3.3.2.2.7.cmml">l</mi><mo lspace="0.280em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.2.1e" xref="S3.E8.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.2.8" xref="S3.E8.m1.1.1.3.3.2.2.8.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.2.1f" xref="S3.E8.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.2.9" xref="S3.E8.m1.1.1.3.3.2.2.9.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.2.1g" xref="S3.E8.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.2.10" xref="S3.E8.m1.1.1.3.3.2.2.10.cmml">w</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.2.1h" xref="S3.E8.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.2.11" xref="S3.E8.m1.1.1.3.3.2.2.11.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.2.1i" xref="S3.E8.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.2.12" xref="S3.E8.m1.1.1.3.3.2.2.12.cmml">r</mi></mrow><mrow id="S3.E8.m1.1.1.3.3.2.3" xref="S3.E8.m1.1.1.3.3.2.3.cmml"><mi id="S3.E8.m1.1.1.3.3.2.3.2" xref="S3.E8.m1.1.1.3.3.2.3.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.3.1" xref="S3.E8.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.3.3" xref="S3.E8.m1.1.1.3.3.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.3.1a" xref="S3.E8.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.3.4" xref="S3.E8.m1.1.1.3.3.2.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.3.1b" xref="S3.E8.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.3.5" xref="S3.E8.m1.1.1.3.3.2.3.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.3.1c" xref="S3.E8.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.3.6" xref="S3.E8.m1.1.1.3.3.2.3.6.cmml">e</mi><mo lspace="0.280em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.3.1d" xref="S3.E8.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.3.7" xref="S3.E8.m1.1.1.3.3.2.3.7.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.3.1e" xref="S3.E8.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.3.8" xref="S3.E8.m1.1.1.3.3.2.3.8.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.3.1f" xref="S3.E8.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.3.9" xref="S3.E8.m1.1.1.3.3.2.3.9.cmml">w</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.3.1g" xref="S3.E8.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.3.10" xref="S3.E8.m1.1.1.3.3.2.3.10.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.3.2.3.1h" xref="S3.E8.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E8.m1.1.1.3.3.2.3.11" xref="S3.E8.m1.1.1.3.3.2.3.11.cmml">r</mi></mrow></mfrac></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.1b"><apply id="S3.E8.m1.1.1.cmml" xref="S3.E8.m1.1.1"><eq id="S3.E8.m1.1.1.1.cmml" xref="S3.E8.m1.1.1.1"></eq><apply id="S3.E8.m1.1.1.2.cmml" xref="S3.E8.m1.1.1.2"><times id="S3.E8.m1.1.1.2.1.cmml" xref="S3.E8.m1.1.1.2.1"></times><ci id="S3.E8.m1.1.1.2.2.cmml" xref="S3.E8.m1.1.1.2.2">𝑆</ci><ci id="S3.E8.m1.1.1.2.3.cmml" xref="S3.E8.m1.1.1.2.3">𝑁</ci><ci id="S3.E8.m1.1.1.2.4.cmml" xref="S3.E8.m1.1.1.2.4">𝑅</ci></apply><apply id="S3.E8.m1.1.1.3.cmml" xref="S3.E8.m1.1.1.3"><times id="S3.E8.m1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.3.1"></times><cn type="integer" id="S3.E8.m1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.3.2">10</cn><apply id="S3.E8.m1.1.1.3.3.cmml" xref="S3.E8.m1.1.1.3.3"><apply id="S3.E8.m1.1.1.3.3.1.cmml" xref="S3.E8.m1.1.1.3.3.1"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.3.3.1.1.cmml" xref="S3.E8.m1.1.1.3.3.1">subscript</csymbol><log id="S3.E8.m1.1.1.3.3.1.2.cmml" xref="S3.E8.m1.1.1.3.3.1.2"></log><cn type="integer" id="S3.E8.m1.1.1.3.3.1.3.cmml" xref="S3.E8.m1.1.1.3.3.1.3">10</cn></apply><apply id="S3.E8.m1.1.1.3.3.2.cmml" xref="S3.E8.m1.1.1.3.3.2"><divide id="S3.E8.m1.1.1.3.3.2.1.cmml" xref="S3.E8.m1.1.1.3.3.2"></divide><apply id="S3.E8.m1.1.1.3.3.2.2.cmml" xref="S3.E8.m1.1.1.3.3.2.2"><times id="S3.E8.m1.1.1.3.3.2.2.1.cmml" xref="S3.E8.m1.1.1.3.3.2.2.1"></times><ci id="S3.E8.m1.1.1.3.3.2.2.2.cmml" xref="S3.E8.m1.1.1.3.3.2.2.2">𝑆</ci><ci id="S3.E8.m1.1.1.3.3.2.2.3.cmml" xref="S3.E8.m1.1.1.3.3.2.2.3">𝑖</ci><ci id="S3.E8.m1.1.1.3.3.2.2.4.cmml" xref="S3.E8.m1.1.1.3.3.2.2.4">𝑔</ci><ci id="S3.E8.m1.1.1.3.3.2.2.5.cmml" xref="S3.E8.m1.1.1.3.3.2.2.5">𝑛</ci><ci id="S3.E8.m1.1.1.3.3.2.2.6.cmml" xref="S3.E8.m1.1.1.3.3.2.2.6">𝑎</ci><ci id="S3.E8.m1.1.1.3.3.2.2.7.cmml" xref="S3.E8.m1.1.1.3.3.2.2.7">𝑙</ci><ci id="S3.E8.m1.1.1.3.3.2.2.8.cmml" xref="S3.E8.m1.1.1.3.3.2.2.8">𝑝</ci><ci id="S3.E8.m1.1.1.3.3.2.2.9.cmml" xref="S3.E8.m1.1.1.3.3.2.2.9">𝑜</ci><ci id="S3.E8.m1.1.1.3.3.2.2.10.cmml" xref="S3.E8.m1.1.1.3.3.2.2.10">𝑤</ci><ci id="S3.E8.m1.1.1.3.3.2.2.11.cmml" xref="S3.E8.m1.1.1.3.3.2.2.11">𝑒</ci><ci id="S3.E8.m1.1.1.3.3.2.2.12.cmml" xref="S3.E8.m1.1.1.3.3.2.2.12">𝑟</ci></apply><apply id="S3.E8.m1.1.1.3.3.2.3.cmml" xref="S3.E8.m1.1.1.3.3.2.3"><times id="S3.E8.m1.1.1.3.3.2.3.1.cmml" xref="S3.E8.m1.1.1.3.3.2.3.1"></times><ci id="S3.E8.m1.1.1.3.3.2.3.2.cmml" xref="S3.E8.m1.1.1.3.3.2.3.2">𝑁</ci><ci id="S3.E8.m1.1.1.3.3.2.3.3.cmml" xref="S3.E8.m1.1.1.3.3.2.3.3">𝑜</ci><ci id="S3.E8.m1.1.1.3.3.2.3.4.cmml" xref="S3.E8.m1.1.1.3.3.2.3.4">𝑖</ci><ci id="S3.E8.m1.1.1.3.3.2.3.5.cmml" xref="S3.E8.m1.1.1.3.3.2.3.5">𝑠</ci><ci id="S3.E8.m1.1.1.3.3.2.3.6.cmml" xref="S3.E8.m1.1.1.3.3.2.3.6">𝑒</ci><ci id="S3.E8.m1.1.1.3.3.2.3.7.cmml" xref="S3.E8.m1.1.1.3.3.2.3.7">𝑝</ci><ci id="S3.E8.m1.1.1.3.3.2.3.8.cmml" xref="S3.E8.m1.1.1.3.3.2.3.8">𝑜</ci><ci id="S3.E8.m1.1.1.3.3.2.3.9.cmml" xref="S3.E8.m1.1.1.3.3.2.3.9">𝑤</ci><ci id="S3.E8.m1.1.1.3.3.2.3.10.cmml" xref="S3.E8.m1.1.1.3.3.2.3.10">𝑒</ci><ci id="S3.E8.m1.1.1.3.3.2.3.11.cmml" xref="S3.E8.m1.1.1.3.3.2.3.11">𝑟</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.1c">SNR=10\times\log_{10}\frac{Signal\;power}{Noise\;power}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">The definitions of signal power and noise power are as follows:</p>
</div>
<div id="Thmdefinition7" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="Thmdefinition7.1.1.1" class="ltx_text ltx_font_bold">Definition 7</span></span></h6>
<div id="Thmdefinition7.p1" class="ltx_para">
<p id="Thmdefinition7.p1.3" class="ltx_p"><span id="Thmdefinition7.p1.3.3" class="ltx_text ltx_font_italic">Signal power refers to the power of the desired signal, which is the information or data being transmitted or received. Mathematically, it is calculated as the average or mean squared value of the signal. 
<br class="ltx_break">In the case of a discrete signal (<math id="Thmdefinition7.p1.1.1.m1.1" class="ltx_Math" alttext="s[n]" display="inline"><semantics id="Thmdefinition7.p1.1.1.m1.1a"><mrow id="Thmdefinition7.p1.1.1.m1.1.2" xref="Thmdefinition7.p1.1.1.m1.1.2.cmml"><mi id="Thmdefinition7.p1.1.1.m1.1.2.2" xref="Thmdefinition7.p1.1.1.m1.1.2.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="Thmdefinition7.p1.1.1.m1.1.2.1" xref="Thmdefinition7.p1.1.1.m1.1.2.1.cmml">​</mo><mrow id="Thmdefinition7.p1.1.1.m1.1.2.3.2" xref="Thmdefinition7.p1.1.1.m1.1.2.3.1.cmml"><mo stretchy="false" id="Thmdefinition7.p1.1.1.m1.1.2.3.2.1" xref="Thmdefinition7.p1.1.1.m1.1.2.3.1.1.cmml">[</mo><mi id="Thmdefinition7.p1.1.1.m1.1.1" xref="Thmdefinition7.p1.1.1.m1.1.1.cmml">n</mi><mo stretchy="false" id="Thmdefinition7.p1.1.1.m1.1.2.3.2.2" xref="Thmdefinition7.p1.1.1.m1.1.2.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition7.p1.1.1.m1.1b"><apply id="Thmdefinition7.p1.1.1.m1.1.2.cmml" xref="Thmdefinition7.p1.1.1.m1.1.2"><times id="Thmdefinition7.p1.1.1.m1.1.2.1.cmml" xref="Thmdefinition7.p1.1.1.m1.1.2.1"></times><ci id="Thmdefinition7.p1.1.1.m1.1.2.2.cmml" xref="Thmdefinition7.p1.1.1.m1.1.2.2">𝑠</ci><apply id="Thmdefinition7.p1.1.1.m1.1.2.3.1.cmml" xref="Thmdefinition7.p1.1.1.m1.1.2.3.2"><csymbol cd="latexml" id="Thmdefinition7.p1.1.1.m1.1.2.3.1.1.cmml" xref="Thmdefinition7.p1.1.1.m1.1.2.3.2.1">delimited-[]</csymbol><ci id="Thmdefinition7.p1.1.1.m1.1.1.cmml" xref="Thmdefinition7.p1.1.1.m1.1.1">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition7.p1.1.1.m1.1c">s[n]</annotation></semantics></math>), which has values for only discrete points in time, the signal power <math id="Thmdefinition7.p1.2.2.m2.1" class="ltx_Math" alttext="P_{s}" display="inline"><semantics id="Thmdefinition7.p1.2.2.m2.1a"><msub id="Thmdefinition7.p1.2.2.m2.1.1" xref="Thmdefinition7.p1.2.2.m2.1.1.cmml"><mi id="Thmdefinition7.p1.2.2.m2.1.1.2" xref="Thmdefinition7.p1.2.2.m2.1.1.2.cmml">P</mi><mi id="Thmdefinition7.p1.2.2.m2.1.1.3" xref="Thmdefinition7.p1.2.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="Thmdefinition7.p1.2.2.m2.1b"><apply id="Thmdefinition7.p1.2.2.m2.1.1.cmml" xref="Thmdefinition7.p1.2.2.m2.1.1"><csymbol cd="ambiguous" id="Thmdefinition7.p1.2.2.m2.1.1.1.cmml" xref="Thmdefinition7.p1.2.2.m2.1.1">subscript</csymbol><ci id="Thmdefinition7.p1.2.2.m2.1.1.2.cmml" xref="Thmdefinition7.p1.2.2.m2.1.1.2">𝑃</ci><ci id="Thmdefinition7.p1.2.2.m2.1.1.3.cmml" xref="Thmdefinition7.p1.2.2.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition7.p1.2.2.m2.1c">P_{s}</annotation></semantics></math> is represented as follows:
<math id="Thmdefinition7.p1.3.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="Thmdefinition7.p1.3.3.m3.1a"><mi id="Thmdefinition7.p1.3.3.m3.1.1" xref="Thmdefinition7.p1.3.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition7.p1.3.3.m3.1b"><ci id="Thmdefinition7.p1.3.3.m3.1.1.cmml" xref="Thmdefinition7.p1.3.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition7.p1.3.3.m3.1c">N</annotation></semantics></math>: The number of samples taken for computation from a snapshot of the signal over an arbitrary time duration,</span></p>
<table id="S3.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S3.E9.m1.2" class="ltx_Math" alttext="P_{s}=lim_{N\to\infty}\frac{1}{2N+1}\sum_{n=-N}^{N}|s[n]|^{2}" display="block"><semantics id="S3.E9.m1.2a"><mrow id="S3.E9.m1.2.2" xref="S3.E9.m1.2.2.cmml"><msub id="S3.E9.m1.2.2.3" xref="S3.E9.m1.2.2.3.cmml"><mi id="S3.E9.m1.2.2.3.2" xref="S3.E9.m1.2.2.3.2.cmml">P</mi><mi id="S3.E9.m1.2.2.3.3" xref="S3.E9.m1.2.2.3.3.cmml">s</mi></msub><mo id="S3.E9.m1.2.2.2" xref="S3.E9.m1.2.2.2.cmml">=</mo><mrow id="S3.E9.m1.2.2.1" xref="S3.E9.m1.2.2.1.cmml"><mi id="S3.E9.m1.2.2.1.3" xref="S3.E9.m1.2.2.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.2.2.1.2" xref="S3.E9.m1.2.2.1.2.cmml">​</mo><mi id="S3.E9.m1.2.2.1.4" xref="S3.E9.m1.2.2.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.2.2.1.2a" xref="S3.E9.m1.2.2.1.2.cmml">​</mo><msub id="S3.E9.m1.2.2.1.5" xref="S3.E9.m1.2.2.1.5.cmml"><mi id="S3.E9.m1.2.2.1.5.2" xref="S3.E9.m1.2.2.1.5.2.cmml">m</mi><mrow id="S3.E9.m1.2.2.1.5.3" xref="S3.E9.m1.2.2.1.5.3.cmml"><mi id="S3.E9.m1.2.2.1.5.3.2" xref="S3.E9.m1.2.2.1.5.3.2.cmml">N</mi><mo stretchy="false" id="S3.E9.m1.2.2.1.5.3.1" xref="S3.E9.m1.2.2.1.5.3.1.cmml">→</mo><mi mathvariant="normal" id="S3.E9.m1.2.2.1.5.3.3" xref="S3.E9.m1.2.2.1.5.3.3.cmml">∞</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E9.m1.2.2.1.2b" xref="S3.E9.m1.2.2.1.2.cmml">​</mo><mfrac id="S3.E9.m1.2.2.1.6" xref="S3.E9.m1.2.2.1.6.cmml"><mn id="S3.E9.m1.2.2.1.6.2" xref="S3.E9.m1.2.2.1.6.2.cmml">1</mn><mrow id="S3.E9.m1.2.2.1.6.3" xref="S3.E9.m1.2.2.1.6.3.cmml"><mrow id="S3.E9.m1.2.2.1.6.3.2" xref="S3.E9.m1.2.2.1.6.3.2.cmml"><mn id="S3.E9.m1.2.2.1.6.3.2.2" xref="S3.E9.m1.2.2.1.6.3.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E9.m1.2.2.1.6.3.2.1" xref="S3.E9.m1.2.2.1.6.3.2.1.cmml">​</mo><mi id="S3.E9.m1.2.2.1.6.3.2.3" xref="S3.E9.m1.2.2.1.6.3.2.3.cmml">N</mi></mrow><mo id="S3.E9.m1.2.2.1.6.3.1" xref="S3.E9.m1.2.2.1.6.3.1.cmml">+</mo><mn id="S3.E9.m1.2.2.1.6.3.3" xref="S3.E9.m1.2.2.1.6.3.3.cmml">1</mn></mrow></mfrac><mo lspace="0em" rspace="0em" id="S3.E9.m1.2.2.1.2c" xref="S3.E9.m1.2.2.1.2.cmml">​</mo><mrow id="S3.E9.m1.2.2.1.1" xref="S3.E9.m1.2.2.1.1.cmml"><munderover id="S3.E9.m1.2.2.1.1.2" xref="S3.E9.m1.2.2.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.E9.m1.2.2.1.1.2.2.2" xref="S3.E9.m1.2.2.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E9.m1.2.2.1.1.2.2.3" xref="S3.E9.m1.2.2.1.1.2.2.3.cmml"><mi id="S3.E9.m1.2.2.1.1.2.2.3.2" xref="S3.E9.m1.2.2.1.1.2.2.3.2.cmml">n</mi><mo id="S3.E9.m1.2.2.1.1.2.2.3.1" xref="S3.E9.m1.2.2.1.1.2.2.3.1.cmml">=</mo><mrow id="S3.E9.m1.2.2.1.1.2.2.3.3" xref="S3.E9.m1.2.2.1.1.2.2.3.3.cmml"><mo id="S3.E9.m1.2.2.1.1.2.2.3.3a" xref="S3.E9.m1.2.2.1.1.2.2.3.3.cmml">−</mo><mi id="S3.E9.m1.2.2.1.1.2.2.3.3.2" xref="S3.E9.m1.2.2.1.1.2.2.3.3.2.cmml">N</mi></mrow></mrow><mi id="S3.E9.m1.2.2.1.1.2.3" xref="S3.E9.m1.2.2.1.1.2.3.cmml">N</mi></munderover><msup id="S3.E9.m1.2.2.1.1.1" xref="S3.E9.m1.2.2.1.1.1.cmml"><mrow id="S3.E9.m1.2.2.1.1.1.1.1" xref="S3.E9.m1.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E9.m1.2.2.1.1.1.1.1.2" xref="S3.E9.m1.2.2.1.1.1.1.2.1.cmml">|</mo><mrow id="S3.E9.m1.2.2.1.1.1.1.1.1" xref="S3.E9.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S3.E9.m1.2.2.1.1.1.1.1.1.2" xref="S3.E9.m1.2.2.1.1.1.1.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.2.2.1.1.1.1.1.1.1" xref="S3.E9.m1.2.2.1.1.1.1.1.1.1.cmml">​</mo><mrow id="S3.E9.m1.2.2.1.1.1.1.1.1.3.2" xref="S3.E9.m1.2.2.1.1.1.1.1.1.3.1.cmml"><mo stretchy="false" id="S3.E9.m1.2.2.1.1.1.1.1.1.3.2.1" xref="S3.E9.m1.2.2.1.1.1.1.1.1.3.1.1.cmml">[</mo><mi id="S3.E9.m1.1.1" xref="S3.E9.m1.1.1.cmml">n</mi><mo stretchy="false" id="S3.E9.m1.2.2.1.1.1.1.1.1.3.2.2" xref="S3.E9.m1.2.2.1.1.1.1.1.1.3.1.1.cmml">]</mo></mrow></mrow><mo stretchy="false" id="S3.E9.m1.2.2.1.1.1.1.1.3" xref="S3.E9.m1.2.2.1.1.1.1.2.1.cmml">|</mo></mrow><mn id="S3.E9.m1.2.2.1.1.1.3" xref="S3.E9.m1.2.2.1.1.1.3.cmml">2</mn></msup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E9.m1.2b"><apply id="S3.E9.m1.2.2.cmml" xref="S3.E9.m1.2.2"><eq id="S3.E9.m1.2.2.2.cmml" xref="S3.E9.m1.2.2.2"></eq><apply id="S3.E9.m1.2.2.3.cmml" xref="S3.E9.m1.2.2.3"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.3.1.cmml" xref="S3.E9.m1.2.2.3">subscript</csymbol><ci id="S3.E9.m1.2.2.3.2.cmml" xref="S3.E9.m1.2.2.3.2">𝑃</ci><ci id="S3.E9.m1.2.2.3.3.cmml" xref="S3.E9.m1.2.2.3.3">𝑠</ci></apply><apply id="S3.E9.m1.2.2.1.cmml" xref="S3.E9.m1.2.2.1"><times id="S3.E9.m1.2.2.1.2.cmml" xref="S3.E9.m1.2.2.1.2"></times><ci id="S3.E9.m1.2.2.1.3.cmml" xref="S3.E9.m1.2.2.1.3">𝑙</ci><ci id="S3.E9.m1.2.2.1.4.cmml" xref="S3.E9.m1.2.2.1.4">𝑖</ci><apply id="S3.E9.m1.2.2.1.5.cmml" xref="S3.E9.m1.2.2.1.5"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.1.5.1.cmml" xref="S3.E9.m1.2.2.1.5">subscript</csymbol><ci id="S3.E9.m1.2.2.1.5.2.cmml" xref="S3.E9.m1.2.2.1.5.2">𝑚</ci><apply id="S3.E9.m1.2.2.1.5.3.cmml" xref="S3.E9.m1.2.2.1.5.3"><ci id="S3.E9.m1.2.2.1.5.3.1.cmml" xref="S3.E9.m1.2.2.1.5.3.1">→</ci><ci id="S3.E9.m1.2.2.1.5.3.2.cmml" xref="S3.E9.m1.2.2.1.5.3.2">𝑁</ci><infinity id="S3.E9.m1.2.2.1.5.3.3.cmml" xref="S3.E9.m1.2.2.1.5.3.3"></infinity></apply></apply><apply id="S3.E9.m1.2.2.1.6.cmml" xref="S3.E9.m1.2.2.1.6"><divide id="S3.E9.m1.2.2.1.6.1.cmml" xref="S3.E9.m1.2.2.1.6"></divide><cn type="integer" id="S3.E9.m1.2.2.1.6.2.cmml" xref="S3.E9.m1.2.2.1.6.2">1</cn><apply id="S3.E9.m1.2.2.1.6.3.cmml" xref="S3.E9.m1.2.2.1.6.3"><plus id="S3.E9.m1.2.2.1.6.3.1.cmml" xref="S3.E9.m1.2.2.1.6.3.1"></plus><apply id="S3.E9.m1.2.2.1.6.3.2.cmml" xref="S3.E9.m1.2.2.1.6.3.2"><times id="S3.E9.m1.2.2.1.6.3.2.1.cmml" xref="S3.E9.m1.2.2.1.6.3.2.1"></times><cn type="integer" id="S3.E9.m1.2.2.1.6.3.2.2.cmml" xref="S3.E9.m1.2.2.1.6.3.2.2">2</cn><ci id="S3.E9.m1.2.2.1.6.3.2.3.cmml" xref="S3.E9.m1.2.2.1.6.3.2.3">𝑁</ci></apply><cn type="integer" id="S3.E9.m1.2.2.1.6.3.3.cmml" xref="S3.E9.m1.2.2.1.6.3.3">1</cn></apply></apply><apply id="S3.E9.m1.2.2.1.1.cmml" xref="S3.E9.m1.2.2.1.1"><apply id="S3.E9.m1.2.2.1.1.2.cmml" xref="S3.E9.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.1.1.2.1.cmml" xref="S3.E9.m1.2.2.1.1.2">superscript</csymbol><apply id="S3.E9.m1.2.2.1.1.2.2.cmml" xref="S3.E9.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.1.1.2.2.1.cmml" xref="S3.E9.m1.2.2.1.1.2">subscript</csymbol><sum id="S3.E9.m1.2.2.1.1.2.2.2.cmml" xref="S3.E9.m1.2.2.1.1.2.2.2"></sum><apply id="S3.E9.m1.2.2.1.1.2.2.3.cmml" xref="S3.E9.m1.2.2.1.1.2.2.3"><eq id="S3.E9.m1.2.2.1.1.2.2.3.1.cmml" xref="S3.E9.m1.2.2.1.1.2.2.3.1"></eq><ci id="S3.E9.m1.2.2.1.1.2.2.3.2.cmml" xref="S3.E9.m1.2.2.1.1.2.2.3.2">𝑛</ci><apply id="S3.E9.m1.2.2.1.1.2.2.3.3.cmml" xref="S3.E9.m1.2.2.1.1.2.2.3.3"><minus id="S3.E9.m1.2.2.1.1.2.2.3.3.1.cmml" xref="S3.E9.m1.2.2.1.1.2.2.3.3"></minus><ci id="S3.E9.m1.2.2.1.1.2.2.3.3.2.cmml" xref="S3.E9.m1.2.2.1.1.2.2.3.3.2">𝑁</ci></apply></apply></apply><ci id="S3.E9.m1.2.2.1.1.2.3.cmml" xref="S3.E9.m1.2.2.1.1.2.3">𝑁</ci></apply><apply id="S3.E9.m1.2.2.1.1.1.cmml" xref="S3.E9.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.1.1.1.2.cmml" xref="S3.E9.m1.2.2.1.1.1">superscript</csymbol><apply id="S3.E9.m1.2.2.1.1.1.1.2.cmml" xref="S3.E9.m1.2.2.1.1.1.1.1"><abs id="S3.E9.m1.2.2.1.1.1.1.2.1.cmml" xref="S3.E9.m1.2.2.1.1.1.1.1.2"></abs><apply id="S3.E9.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E9.m1.2.2.1.1.1.1.1.1"><times id="S3.E9.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.2.2.1.1.1.1.1.1.1"></times><ci id="S3.E9.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E9.m1.2.2.1.1.1.1.1.1.2">𝑠</ci><apply id="S3.E9.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="S3.E9.m1.2.2.1.1.1.1.1.1.3.2"><csymbol cd="latexml" id="S3.E9.m1.2.2.1.1.1.1.1.1.3.1.1.cmml" xref="S3.E9.m1.2.2.1.1.1.1.1.1.3.2.1">delimited-[]</csymbol><ci id="S3.E9.m1.1.1.cmml" xref="S3.E9.m1.1.1">𝑛</ci></apply></apply></apply><cn type="integer" id="S3.E9.m1.2.2.1.1.1.3.cmml" xref="S3.E9.m1.2.2.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E9.m1.2c">P_{s}=lim_{N\to\infty}\frac{1}{2N+1}\sum_{n=-N}^{N}|s[n]|^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
</div>
</div>
<div id="Thmdefinition8" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="Thmdefinition8.1.1.1" class="ltx_text ltx_font_bold">Definition 8</span></span></h6>
<div id="Thmdefinition8.p1" class="ltx_para">
<p id="Thmdefinition8.p1.1" class="ltx_p"><span id="Thmdefinition8.p1.1.1" class="ltx_text ltx_font_italic">Noise power represents the power of the unwanted signal or interference, which corrupts the desired signal. Similar to signal power, noise power is often calculated as the average or mean squared value of the noise. 
<br class="ltx_break">Similar to the signal power, for a discrete noise <math id="Thmdefinition8.p1.1.1.m1.1" class="ltx_Math" alttext="n[n]" display="inline"><semantics id="Thmdefinition8.p1.1.1.m1.1a"><mrow id="Thmdefinition8.p1.1.1.m1.1.2" xref="Thmdefinition8.p1.1.1.m1.1.2.cmml"><mi id="Thmdefinition8.p1.1.1.m1.1.2.2" xref="Thmdefinition8.p1.1.1.m1.1.2.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="Thmdefinition8.p1.1.1.m1.1.2.1" xref="Thmdefinition8.p1.1.1.m1.1.2.1.cmml">​</mo><mrow id="Thmdefinition8.p1.1.1.m1.1.2.3.2" xref="Thmdefinition8.p1.1.1.m1.1.2.3.1.cmml"><mo stretchy="false" id="Thmdefinition8.p1.1.1.m1.1.2.3.2.1" xref="Thmdefinition8.p1.1.1.m1.1.2.3.1.1.cmml">[</mo><mi id="Thmdefinition8.p1.1.1.m1.1.1" xref="Thmdefinition8.p1.1.1.m1.1.1.cmml">n</mi><mo stretchy="false" id="Thmdefinition8.p1.1.1.m1.1.2.3.2.2" xref="Thmdefinition8.p1.1.1.m1.1.2.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition8.p1.1.1.m1.1b"><apply id="Thmdefinition8.p1.1.1.m1.1.2.cmml" xref="Thmdefinition8.p1.1.1.m1.1.2"><times id="Thmdefinition8.p1.1.1.m1.1.2.1.cmml" xref="Thmdefinition8.p1.1.1.m1.1.2.1"></times><ci id="Thmdefinition8.p1.1.1.m1.1.2.2.cmml" xref="Thmdefinition8.p1.1.1.m1.1.2.2">𝑛</ci><apply id="Thmdefinition8.p1.1.1.m1.1.2.3.1.cmml" xref="Thmdefinition8.p1.1.1.m1.1.2.3.2"><csymbol cd="latexml" id="Thmdefinition8.p1.1.1.m1.1.2.3.1.1.cmml" xref="Thmdefinition8.p1.1.1.m1.1.2.3.2.1">delimited-[]</csymbol><ci id="Thmdefinition8.p1.1.1.m1.1.1.cmml" xref="Thmdefinition8.p1.1.1.m1.1.1">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition8.p1.1.1.m1.1c">n[n]</annotation></semantics></math>, the noise power is represented as:</span></p>
<table id="S3.E10" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S3.E10.m1.2" class="ltx_Math" alttext="P_{n}=lim_{N\to\infty}\frac{1}{2N+1}\sum_{n=-N}^{N}|n[n]|^{2}" display="block"><semantics id="S3.E10.m1.2a"><mrow id="S3.E10.m1.2.2" xref="S3.E10.m1.2.2.cmml"><msub id="S3.E10.m1.2.2.3" xref="S3.E10.m1.2.2.3.cmml"><mi id="S3.E10.m1.2.2.3.2" xref="S3.E10.m1.2.2.3.2.cmml">P</mi><mi id="S3.E10.m1.2.2.3.3" xref="S3.E10.m1.2.2.3.3.cmml">n</mi></msub><mo id="S3.E10.m1.2.2.2" xref="S3.E10.m1.2.2.2.cmml">=</mo><mrow id="S3.E10.m1.2.2.1" xref="S3.E10.m1.2.2.1.cmml"><mi id="S3.E10.m1.2.2.1.3" xref="S3.E10.m1.2.2.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E10.m1.2.2.1.2" xref="S3.E10.m1.2.2.1.2.cmml">​</mo><mi id="S3.E10.m1.2.2.1.4" xref="S3.E10.m1.2.2.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E10.m1.2.2.1.2a" xref="S3.E10.m1.2.2.1.2.cmml">​</mo><msub id="S3.E10.m1.2.2.1.5" xref="S3.E10.m1.2.2.1.5.cmml"><mi id="S3.E10.m1.2.2.1.5.2" xref="S3.E10.m1.2.2.1.5.2.cmml">m</mi><mrow id="S3.E10.m1.2.2.1.5.3" xref="S3.E10.m1.2.2.1.5.3.cmml"><mi id="S3.E10.m1.2.2.1.5.3.2" xref="S3.E10.m1.2.2.1.5.3.2.cmml">N</mi><mo stretchy="false" id="S3.E10.m1.2.2.1.5.3.1" xref="S3.E10.m1.2.2.1.5.3.1.cmml">→</mo><mi mathvariant="normal" id="S3.E10.m1.2.2.1.5.3.3" xref="S3.E10.m1.2.2.1.5.3.3.cmml">∞</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E10.m1.2.2.1.2b" xref="S3.E10.m1.2.2.1.2.cmml">​</mo><mfrac id="S3.E10.m1.2.2.1.6" xref="S3.E10.m1.2.2.1.6.cmml"><mn id="S3.E10.m1.2.2.1.6.2" xref="S3.E10.m1.2.2.1.6.2.cmml">1</mn><mrow id="S3.E10.m1.2.2.1.6.3" xref="S3.E10.m1.2.2.1.6.3.cmml"><mrow id="S3.E10.m1.2.2.1.6.3.2" xref="S3.E10.m1.2.2.1.6.3.2.cmml"><mn id="S3.E10.m1.2.2.1.6.3.2.2" xref="S3.E10.m1.2.2.1.6.3.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E10.m1.2.2.1.6.3.2.1" xref="S3.E10.m1.2.2.1.6.3.2.1.cmml">​</mo><mi id="S3.E10.m1.2.2.1.6.3.2.3" xref="S3.E10.m1.2.2.1.6.3.2.3.cmml">N</mi></mrow><mo id="S3.E10.m1.2.2.1.6.3.1" xref="S3.E10.m1.2.2.1.6.3.1.cmml">+</mo><mn id="S3.E10.m1.2.2.1.6.3.3" xref="S3.E10.m1.2.2.1.6.3.3.cmml">1</mn></mrow></mfrac><mo lspace="0em" rspace="0em" id="S3.E10.m1.2.2.1.2c" xref="S3.E10.m1.2.2.1.2.cmml">​</mo><mrow id="S3.E10.m1.2.2.1.1" xref="S3.E10.m1.2.2.1.1.cmml"><munderover id="S3.E10.m1.2.2.1.1.2" xref="S3.E10.m1.2.2.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.E10.m1.2.2.1.1.2.2.2" xref="S3.E10.m1.2.2.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E10.m1.2.2.1.1.2.2.3" xref="S3.E10.m1.2.2.1.1.2.2.3.cmml"><mi id="S3.E10.m1.2.2.1.1.2.2.3.2" xref="S3.E10.m1.2.2.1.1.2.2.3.2.cmml">n</mi><mo id="S3.E10.m1.2.2.1.1.2.2.3.1" xref="S3.E10.m1.2.2.1.1.2.2.3.1.cmml">=</mo><mrow id="S3.E10.m1.2.2.1.1.2.2.3.3" xref="S3.E10.m1.2.2.1.1.2.2.3.3.cmml"><mo id="S3.E10.m1.2.2.1.1.2.2.3.3a" xref="S3.E10.m1.2.2.1.1.2.2.3.3.cmml">−</mo><mi id="S3.E10.m1.2.2.1.1.2.2.3.3.2" xref="S3.E10.m1.2.2.1.1.2.2.3.3.2.cmml">N</mi></mrow></mrow><mi id="S3.E10.m1.2.2.1.1.2.3" xref="S3.E10.m1.2.2.1.1.2.3.cmml">N</mi></munderover><msup id="S3.E10.m1.2.2.1.1.1" xref="S3.E10.m1.2.2.1.1.1.cmml"><mrow id="S3.E10.m1.2.2.1.1.1.1.1" xref="S3.E10.m1.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E10.m1.2.2.1.1.1.1.1.2" xref="S3.E10.m1.2.2.1.1.1.1.2.1.cmml">|</mo><mrow id="S3.E10.m1.2.2.1.1.1.1.1.1" xref="S3.E10.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S3.E10.m1.2.2.1.1.1.1.1.1.2" xref="S3.E10.m1.2.2.1.1.1.1.1.1.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E10.m1.2.2.1.1.1.1.1.1.1" xref="S3.E10.m1.2.2.1.1.1.1.1.1.1.cmml">​</mo><mrow id="S3.E10.m1.2.2.1.1.1.1.1.1.3.2" xref="S3.E10.m1.2.2.1.1.1.1.1.1.3.1.cmml"><mo stretchy="false" id="S3.E10.m1.2.2.1.1.1.1.1.1.3.2.1" xref="S3.E10.m1.2.2.1.1.1.1.1.1.3.1.1.cmml">[</mo><mi id="S3.E10.m1.1.1" xref="S3.E10.m1.1.1.cmml">n</mi><mo stretchy="false" id="S3.E10.m1.2.2.1.1.1.1.1.1.3.2.2" xref="S3.E10.m1.2.2.1.1.1.1.1.1.3.1.1.cmml">]</mo></mrow></mrow><mo stretchy="false" id="S3.E10.m1.2.2.1.1.1.1.1.3" xref="S3.E10.m1.2.2.1.1.1.1.2.1.cmml">|</mo></mrow><mn id="S3.E10.m1.2.2.1.1.1.3" xref="S3.E10.m1.2.2.1.1.1.3.cmml">2</mn></msup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E10.m1.2b"><apply id="S3.E10.m1.2.2.cmml" xref="S3.E10.m1.2.2"><eq id="S3.E10.m1.2.2.2.cmml" xref="S3.E10.m1.2.2.2"></eq><apply id="S3.E10.m1.2.2.3.cmml" xref="S3.E10.m1.2.2.3"><csymbol cd="ambiguous" id="S3.E10.m1.2.2.3.1.cmml" xref="S3.E10.m1.2.2.3">subscript</csymbol><ci id="S3.E10.m1.2.2.3.2.cmml" xref="S3.E10.m1.2.2.3.2">𝑃</ci><ci id="S3.E10.m1.2.2.3.3.cmml" xref="S3.E10.m1.2.2.3.3">𝑛</ci></apply><apply id="S3.E10.m1.2.2.1.cmml" xref="S3.E10.m1.2.2.1"><times id="S3.E10.m1.2.2.1.2.cmml" xref="S3.E10.m1.2.2.1.2"></times><ci id="S3.E10.m1.2.2.1.3.cmml" xref="S3.E10.m1.2.2.1.3">𝑙</ci><ci id="S3.E10.m1.2.2.1.4.cmml" xref="S3.E10.m1.2.2.1.4">𝑖</ci><apply id="S3.E10.m1.2.2.1.5.cmml" xref="S3.E10.m1.2.2.1.5"><csymbol cd="ambiguous" id="S3.E10.m1.2.2.1.5.1.cmml" xref="S3.E10.m1.2.2.1.5">subscript</csymbol><ci id="S3.E10.m1.2.2.1.5.2.cmml" xref="S3.E10.m1.2.2.1.5.2">𝑚</ci><apply id="S3.E10.m1.2.2.1.5.3.cmml" xref="S3.E10.m1.2.2.1.5.3"><ci id="S3.E10.m1.2.2.1.5.3.1.cmml" xref="S3.E10.m1.2.2.1.5.3.1">→</ci><ci id="S3.E10.m1.2.2.1.5.3.2.cmml" xref="S3.E10.m1.2.2.1.5.3.2">𝑁</ci><infinity id="S3.E10.m1.2.2.1.5.3.3.cmml" xref="S3.E10.m1.2.2.1.5.3.3"></infinity></apply></apply><apply id="S3.E10.m1.2.2.1.6.cmml" xref="S3.E10.m1.2.2.1.6"><divide id="S3.E10.m1.2.2.1.6.1.cmml" xref="S3.E10.m1.2.2.1.6"></divide><cn type="integer" id="S3.E10.m1.2.2.1.6.2.cmml" xref="S3.E10.m1.2.2.1.6.2">1</cn><apply id="S3.E10.m1.2.2.1.6.3.cmml" xref="S3.E10.m1.2.2.1.6.3"><plus id="S3.E10.m1.2.2.1.6.3.1.cmml" xref="S3.E10.m1.2.2.1.6.3.1"></plus><apply id="S3.E10.m1.2.2.1.6.3.2.cmml" xref="S3.E10.m1.2.2.1.6.3.2"><times id="S3.E10.m1.2.2.1.6.3.2.1.cmml" xref="S3.E10.m1.2.2.1.6.3.2.1"></times><cn type="integer" id="S3.E10.m1.2.2.1.6.3.2.2.cmml" xref="S3.E10.m1.2.2.1.6.3.2.2">2</cn><ci id="S3.E10.m1.2.2.1.6.3.2.3.cmml" xref="S3.E10.m1.2.2.1.6.3.2.3">𝑁</ci></apply><cn type="integer" id="S3.E10.m1.2.2.1.6.3.3.cmml" xref="S3.E10.m1.2.2.1.6.3.3">1</cn></apply></apply><apply id="S3.E10.m1.2.2.1.1.cmml" xref="S3.E10.m1.2.2.1.1"><apply id="S3.E10.m1.2.2.1.1.2.cmml" xref="S3.E10.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E10.m1.2.2.1.1.2.1.cmml" xref="S3.E10.m1.2.2.1.1.2">superscript</csymbol><apply id="S3.E10.m1.2.2.1.1.2.2.cmml" xref="S3.E10.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E10.m1.2.2.1.1.2.2.1.cmml" xref="S3.E10.m1.2.2.1.1.2">subscript</csymbol><sum id="S3.E10.m1.2.2.1.1.2.2.2.cmml" xref="S3.E10.m1.2.2.1.1.2.2.2"></sum><apply id="S3.E10.m1.2.2.1.1.2.2.3.cmml" xref="S3.E10.m1.2.2.1.1.2.2.3"><eq id="S3.E10.m1.2.2.1.1.2.2.3.1.cmml" xref="S3.E10.m1.2.2.1.1.2.2.3.1"></eq><ci id="S3.E10.m1.2.2.1.1.2.2.3.2.cmml" xref="S3.E10.m1.2.2.1.1.2.2.3.2">𝑛</ci><apply id="S3.E10.m1.2.2.1.1.2.2.3.3.cmml" xref="S3.E10.m1.2.2.1.1.2.2.3.3"><minus id="S3.E10.m1.2.2.1.1.2.2.3.3.1.cmml" xref="S3.E10.m1.2.2.1.1.2.2.3.3"></minus><ci id="S3.E10.m1.2.2.1.1.2.2.3.3.2.cmml" xref="S3.E10.m1.2.2.1.1.2.2.3.3.2">𝑁</ci></apply></apply></apply><ci id="S3.E10.m1.2.2.1.1.2.3.cmml" xref="S3.E10.m1.2.2.1.1.2.3">𝑁</ci></apply><apply id="S3.E10.m1.2.2.1.1.1.cmml" xref="S3.E10.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E10.m1.2.2.1.1.1.2.cmml" xref="S3.E10.m1.2.2.1.1.1">superscript</csymbol><apply id="S3.E10.m1.2.2.1.1.1.1.2.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1"><abs id="S3.E10.m1.2.2.1.1.1.1.2.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2"></abs><apply id="S3.E10.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.1"><times id="S3.E10.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.1.1"></times><ci id="S3.E10.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.1.2">𝑛</ci><apply id="S3.E10.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.1.3.2"><csymbol cd="latexml" id="S3.E10.m1.2.2.1.1.1.1.1.1.3.1.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.1.3.2.1">delimited-[]</csymbol><ci id="S3.E10.m1.1.1.cmml" xref="S3.E10.m1.1.1">𝑛</ci></apply></apply></apply><cn type="integer" id="S3.E10.m1.2.2.1.1.1.3.cmml" xref="S3.E10.m1.2.2.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E10.m1.2c">P_{n}=lim_{N\to\infty}\frac{1}{2N+1}\sum_{n=-N}^{N}|n[n]|^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
</div>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.2" class="ltx_p">While signal power measures the ”strength” or ”magnitude” of the signal. Signal variance (denoted as <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="\sigma^{2}_{s}" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><msubsup id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2.2" xref="S3.SS1.p3.1.m1.1.1.2.2.cmml">σ</mi><mi id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">s</mi><mn id="S3.SS1.p3.1.m1.1.1.2.3" xref="S3.SS1.p3.1.m1.1.1.2.3.cmml">2</mn></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><apply id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.2.1.cmml" xref="S3.SS1.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2.2">𝜎</ci><cn type="integer" id="S3.SS1.p3.1.m1.1.1.2.3.cmml" xref="S3.SS1.p3.1.m1.1.1.2.3">2</cn></apply><ci id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\sigma^{2}_{s}</annotation></semantics></math>) measures how much the signal values deviate from the mean (<math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="\mu_{s}" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><msub id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2" xref="S3.SS1.p3.2.m2.1.1.2.cmml">μ</mi><mi id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2">𝜇</ci><ci id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">\mu_{s}</annotation></semantics></math>). It provides an indication of the ”spread” or ”dispersion” of the signal values around their average.
In the general case, the relationship between the variance and power for a signal with a non-zero mean is:</p>
<table id="S3.E11" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S3.E11.m1.1" class="ltx_Math" alttext="\sigma^{2}_{s}=P_{s}-\mu_{s}^{2}" display="block"><semantics id="S3.E11.m1.1a"><mrow id="S3.E11.m1.1.1" xref="S3.E11.m1.1.1.cmml"><msubsup id="S3.E11.m1.1.1.2" xref="S3.E11.m1.1.1.2.cmml"><mi id="S3.E11.m1.1.1.2.2.2" xref="S3.E11.m1.1.1.2.2.2.cmml">σ</mi><mi id="S3.E11.m1.1.1.2.3" xref="S3.E11.m1.1.1.2.3.cmml">s</mi><mn id="S3.E11.m1.1.1.2.2.3" xref="S3.E11.m1.1.1.2.2.3.cmml">2</mn></msubsup><mo id="S3.E11.m1.1.1.1" xref="S3.E11.m1.1.1.1.cmml">=</mo><mrow id="S3.E11.m1.1.1.3" xref="S3.E11.m1.1.1.3.cmml"><msub id="S3.E11.m1.1.1.3.2" xref="S3.E11.m1.1.1.3.2.cmml"><mi id="S3.E11.m1.1.1.3.2.2" xref="S3.E11.m1.1.1.3.2.2.cmml">P</mi><mi id="S3.E11.m1.1.1.3.2.3" xref="S3.E11.m1.1.1.3.2.3.cmml">s</mi></msub><mo id="S3.E11.m1.1.1.3.1" xref="S3.E11.m1.1.1.3.1.cmml">−</mo><msubsup id="S3.E11.m1.1.1.3.3" xref="S3.E11.m1.1.1.3.3.cmml"><mi id="S3.E11.m1.1.1.3.3.2.2" xref="S3.E11.m1.1.1.3.3.2.2.cmml">μ</mi><mi id="S3.E11.m1.1.1.3.3.2.3" xref="S3.E11.m1.1.1.3.3.2.3.cmml">s</mi><mn id="S3.E11.m1.1.1.3.3.3" xref="S3.E11.m1.1.1.3.3.3.cmml">2</mn></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E11.m1.1b"><apply id="S3.E11.m1.1.1.cmml" xref="S3.E11.m1.1.1"><eq id="S3.E11.m1.1.1.1.cmml" xref="S3.E11.m1.1.1.1"></eq><apply id="S3.E11.m1.1.1.2.cmml" xref="S3.E11.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E11.m1.1.1.2.1.cmml" xref="S3.E11.m1.1.1.2">subscript</csymbol><apply id="S3.E11.m1.1.1.2.2.cmml" xref="S3.E11.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E11.m1.1.1.2.2.1.cmml" xref="S3.E11.m1.1.1.2">superscript</csymbol><ci id="S3.E11.m1.1.1.2.2.2.cmml" xref="S3.E11.m1.1.1.2.2.2">𝜎</ci><cn type="integer" id="S3.E11.m1.1.1.2.2.3.cmml" xref="S3.E11.m1.1.1.2.2.3">2</cn></apply><ci id="S3.E11.m1.1.1.2.3.cmml" xref="S3.E11.m1.1.1.2.3">𝑠</ci></apply><apply id="S3.E11.m1.1.1.3.cmml" xref="S3.E11.m1.1.1.3"><minus id="S3.E11.m1.1.1.3.1.cmml" xref="S3.E11.m1.1.1.3.1"></minus><apply id="S3.E11.m1.1.1.3.2.cmml" xref="S3.E11.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E11.m1.1.1.3.2.1.cmml" xref="S3.E11.m1.1.1.3.2">subscript</csymbol><ci id="S3.E11.m1.1.1.3.2.2.cmml" xref="S3.E11.m1.1.1.3.2.2">𝑃</ci><ci id="S3.E11.m1.1.1.3.2.3.cmml" xref="S3.E11.m1.1.1.3.2.3">𝑠</ci></apply><apply id="S3.E11.m1.1.1.3.3.cmml" xref="S3.E11.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E11.m1.1.1.3.3.1.cmml" xref="S3.E11.m1.1.1.3.3">superscript</csymbol><apply id="S3.E11.m1.1.1.3.3.2.cmml" xref="S3.E11.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E11.m1.1.1.3.3.2.1.cmml" xref="S3.E11.m1.1.1.3.3">subscript</csymbol><ci id="S3.E11.m1.1.1.3.3.2.2.cmml" xref="S3.E11.m1.1.1.3.3.2.2">𝜇</ci><ci id="S3.E11.m1.1.1.3.3.2.3.cmml" xref="S3.E11.m1.1.1.3.3.2.3">𝑠</ci></apply><cn type="integer" id="S3.E11.m1.1.1.3.3.3.cmml" xref="S3.E11.m1.1.1.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E11.m1.1c">\sigma^{2}_{s}=P_{s}-\mu_{s}^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(11)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p3.3" class="ltx_p">The signal variance for discrete Signals:</p>
<table id="S3.E12" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S3.E12.m1.2" class="ltx_Math" alttext="\sigma^{2}_{s}=\frac{1}{N}\sum_{n=1}^{N}(s[n]-\mu_{s})^{2}" display="block"><semantics id="S3.E12.m1.2a"><mrow id="S3.E12.m1.2.2" xref="S3.E12.m1.2.2.cmml"><msubsup id="S3.E12.m1.2.2.3" xref="S3.E12.m1.2.2.3.cmml"><mi id="S3.E12.m1.2.2.3.2.2" xref="S3.E12.m1.2.2.3.2.2.cmml">σ</mi><mi id="S3.E12.m1.2.2.3.3" xref="S3.E12.m1.2.2.3.3.cmml">s</mi><mn id="S3.E12.m1.2.2.3.2.3" xref="S3.E12.m1.2.2.3.2.3.cmml">2</mn></msubsup><mo id="S3.E12.m1.2.2.2" xref="S3.E12.m1.2.2.2.cmml">=</mo><mrow id="S3.E12.m1.2.2.1" xref="S3.E12.m1.2.2.1.cmml"><mfrac id="S3.E12.m1.2.2.1.3" xref="S3.E12.m1.2.2.1.3.cmml"><mn id="S3.E12.m1.2.2.1.3.2" xref="S3.E12.m1.2.2.1.3.2.cmml">1</mn><mi id="S3.E12.m1.2.2.1.3.3" xref="S3.E12.m1.2.2.1.3.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E12.m1.2.2.1.2" xref="S3.E12.m1.2.2.1.2.cmml">​</mo><mrow id="S3.E12.m1.2.2.1.1" xref="S3.E12.m1.2.2.1.1.cmml"><munderover id="S3.E12.m1.2.2.1.1.2" xref="S3.E12.m1.2.2.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.E12.m1.2.2.1.1.2.2.2" xref="S3.E12.m1.2.2.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E12.m1.2.2.1.1.2.2.3" xref="S3.E12.m1.2.2.1.1.2.2.3.cmml"><mi id="S3.E12.m1.2.2.1.1.2.2.3.2" xref="S3.E12.m1.2.2.1.1.2.2.3.2.cmml">n</mi><mo id="S3.E12.m1.2.2.1.1.2.2.3.1" xref="S3.E12.m1.2.2.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E12.m1.2.2.1.1.2.2.3.3" xref="S3.E12.m1.2.2.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E12.m1.2.2.1.1.2.3" xref="S3.E12.m1.2.2.1.1.2.3.cmml">N</mi></munderover><msup id="S3.E12.m1.2.2.1.1.1" xref="S3.E12.m1.2.2.1.1.1.cmml"><mrow id="S3.E12.m1.2.2.1.1.1.1.1" xref="S3.E12.m1.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E12.m1.2.2.1.1.1.1.1.2" xref="S3.E12.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E12.m1.2.2.1.1.1.1.1.1" xref="S3.E12.m1.2.2.1.1.1.1.1.1.cmml"><mrow id="S3.E12.m1.2.2.1.1.1.1.1.1.2" xref="S3.E12.m1.2.2.1.1.1.1.1.1.2.cmml"><mi id="S3.E12.m1.2.2.1.1.1.1.1.1.2.2" xref="S3.E12.m1.2.2.1.1.1.1.1.1.2.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.2.2.1.1.1.1.1.1.2.1" xref="S3.E12.m1.2.2.1.1.1.1.1.1.2.1.cmml">​</mo><mrow id="S3.E12.m1.2.2.1.1.1.1.1.1.2.3.2" xref="S3.E12.m1.2.2.1.1.1.1.1.1.2.3.1.cmml"><mo stretchy="false" id="S3.E12.m1.2.2.1.1.1.1.1.1.2.3.2.1" xref="S3.E12.m1.2.2.1.1.1.1.1.1.2.3.1.1.cmml">[</mo><mi id="S3.E12.m1.1.1" xref="S3.E12.m1.1.1.cmml">n</mi><mo stretchy="false" id="S3.E12.m1.2.2.1.1.1.1.1.1.2.3.2.2" xref="S3.E12.m1.2.2.1.1.1.1.1.1.2.3.1.1.cmml">]</mo></mrow></mrow><mo id="S3.E12.m1.2.2.1.1.1.1.1.1.1" xref="S3.E12.m1.2.2.1.1.1.1.1.1.1.cmml">−</mo><msub id="S3.E12.m1.2.2.1.1.1.1.1.1.3" xref="S3.E12.m1.2.2.1.1.1.1.1.1.3.cmml"><mi id="S3.E12.m1.2.2.1.1.1.1.1.1.3.2" xref="S3.E12.m1.2.2.1.1.1.1.1.1.3.2.cmml">μ</mi><mi id="S3.E12.m1.2.2.1.1.1.1.1.1.3.3" xref="S3.E12.m1.2.2.1.1.1.1.1.1.3.3.cmml">s</mi></msub></mrow><mo stretchy="false" id="S3.E12.m1.2.2.1.1.1.1.1.3" xref="S3.E12.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow><mn id="S3.E12.m1.2.2.1.1.1.3" xref="S3.E12.m1.2.2.1.1.1.3.cmml">2</mn></msup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E12.m1.2b"><apply id="S3.E12.m1.2.2.cmml" xref="S3.E12.m1.2.2"><eq id="S3.E12.m1.2.2.2.cmml" xref="S3.E12.m1.2.2.2"></eq><apply id="S3.E12.m1.2.2.3.cmml" xref="S3.E12.m1.2.2.3"><csymbol cd="ambiguous" id="S3.E12.m1.2.2.3.1.cmml" xref="S3.E12.m1.2.2.3">subscript</csymbol><apply id="S3.E12.m1.2.2.3.2.cmml" xref="S3.E12.m1.2.2.3"><csymbol cd="ambiguous" id="S3.E12.m1.2.2.3.2.1.cmml" xref="S3.E12.m1.2.2.3">superscript</csymbol><ci id="S3.E12.m1.2.2.3.2.2.cmml" xref="S3.E12.m1.2.2.3.2.2">𝜎</ci><cn type="integer" id="S3.E12.m1.2.2.3.2.3.cmml" xref="S3.E12.m1.2.2.3.2.3">2</cn></apply><ci id="S3.E12.m1.2.2.3.3.cmml" xref="S3.E12.m1.2.2.3.3">𝑠</ci></apply><apply id="S3.E12.m1.2.2.1.cmml" xref="S3.E12.m1.2.2.1"><times id="S3.E12.m1.2.2.1.2.cmml" xref="S3.E12.m1.2.2.1.2"></times><apply id="S3.E12.m1.2.2.1.3.cmml" xref="S3.E12.m1.2.2.1.3"><divide id="S3.E12.m1.2.2.1.3.1.cmml" xref="S3.E12.m1.2.2.1.3"></divide><cn type="integer" id="S3.E12.m1.2.2.1.3.2.cmml" xref="S3.E12.m1.2.2.1.3.2">1</cn><ci id="S3.E12.m1.2.2.1.3.3.cmml" xref="S3.E12.m1.2.2.1.3.3">𝑁</ci></apply><apply id="S3.E12.m1.2.2.1.1.cmml" xref="S3.E12.m1.2.2.1.1"><apply id="S3.E12.m1.2.2.1.1.2.cmml" xref="S3.E12.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E12.m1.2.2.1.1.2.1.cmml" xref="S3.E12.m1.2.2.1.1.2">superscript</csymbol><apply id="S3.E12.m1.2.2.1.1.2.2.cmml" xref="S3.E12.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E12.m1.2.2.1.1.2.2.1.cmml" xref="S3.E12.m1.2.2.1.1.2">subscript</csymbol><sum id="S3.E12.m1.2.2.1.1.2.2.2.cmml" xref="S3.E12.m1.2.2.1.1.2.2.2"></sum><apply id="S3.E12.m1.2.2.1.1.2.2.3.cmml" xref="S3.E12.m1.2.2.1.1.2.2.3"><eq id="S3.E12.m1.2.2.1.1.2.2.3.1.cmml" xref="S3.E12.m1.2.2.1.1.2.2.3.1"></eq><ci id="S3.E12.m1.2.2.1.1.2.2.3.2.cmml" xref="S3.E12.m1.2.2.1.1.2.2.3.2">𝑛</ci><cn type="integer" id="S3.E12.m1.2.2.1.1.2.2.3.3.cmml" xref="S3.E12.m1.2.2.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E12.m1.2.2.1.1.2.3.cmml" xref="S3.E12.m1.2.2.1.1.2.3">𝑁</ci></apply><apply id="S3.E12.m1.2.2.1.1.1.cmml" xref="S3.E12.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E12.m1.2.2.1.1.1.2.cmml" xref="S3.E12.m1.2.2.1.1.1">superscript</csymbol><apply id="S3.E12.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E12.m1.2.2.1.1.1.1.1"><minus id="S3.E12.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E12.m1.2.2.1.1.1.1.1.1.1"></minus><apply id="S3.E12.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E12.m1.2.2.1.1.1.1.1.1.2"><times id="S3.E12.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E12.m1.2.2.1.1.1.1.1.1.2.1"></times><ci id="S3.E12.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="S3.E12.m1.2.2.1.1.1.1.1.1.2.2">𝑠</ci><apply id="S3.E12.m1.2.2.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E12.m1.2.2.1.1.1.1.1.1.2.3.2"><csymbol cd="latexml" id="S3.E12.m1.2.2.1.1.1.1.1.1.2.3.1.1.cmml" xref="S3.E12.m1.2.2.1.1.1.1.1.1.2.3.2.1">delimited-[]</csymbol><ci id="S3.E12.m1.1.1.cmml" xref="S3.E12.m1.1.1">𝑛</ci></apply></apply><apply id="S3.E12.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E12.m1.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E12.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="S3.E12.m1.2.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E12.m1.2.2.1.1.1.1.1.1.3.2.cmml" xref="S3.E12.m1.2.2.1.1.1.1.1.1.3.2">𝜇</ci><ci id="S3.E12.m1.2.2.1.1.1.1.1.1.3.3.cmml" xref="S3.E12.m1.2.2.1.1.1.1.1.1.3.3">𝑠</ci></apply></apply><cn type="integer" id="S3.E12.m1.2.2.1.1.1.3.cmml" xref="S3.E12.m1.2.2.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E12.m1.2c">\sigma^{2}_{s}=\frac{1}{N}\sum_{n=1}^{N}(s[n]-\mu_{s})^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(12)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p3.4" class="ltx_p">In the case in which the mean of the signal is zero, the power is equivalent to the signal variance. The same computations can be applied to the noisy signal.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">SNR, often expressed in decibels, is sensitive to the scale of the noise and signal in the system. Higher SNR indicates the signal is of high quality and is easier to identify from noise. Conversely, when SNR is low, the signal is weak, or the system is too noisy, and distinguishing the true signal from noise is more challenging. We redefine SNR using the signal variance and noise variance as:</p>
<table id="S3.E13" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S3.E13.m1.1" class="ltx_Math" alttext="SNR=10\times\log_{10}\frac{Signal\;variance}{Noise\;variance}" display="block"><semantics id="S3.E13.m1.1a"><mrow id="S3.E13.m1.1.1" xref="S3.E13.m1.1.1.cmml"><mrow id="S3.E13.m1.1.1.2" xref="S3.E13.m1.1.1.2.cmml"><mi id="S3.E13.m1.1.1.2.2" xref="S3.E13.m1.1.1.2.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.2.1" xref="S3.E13.m1.1.1.2.1.cmml">​</mo><mi id="S3.E13.m1.1.1.2.3" xref="S3.E13.m1.1.1.2.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.2.1a" xref="S3.E13.m1.1.1.2.1.cmml">​</mo><mi id="S3.E13.m1.1.1.2.4" xref="S3.E13.m1.1.1.2.4.cmml">R</mi></mrow><mo id="S3.E13.m1.1.1.1" xref="S3.E13.m1.1.1.1.cmml">=</mo><mrow id="S3.E13.m1.1.1.3" xref="S3.E13.m1.1.1.3.cmml"><mn id="S3.E13.m1.1.1.3.2" xref="S3.E13.m1.1.1.3.2.cmml">10</mn><mo lspace="0.222em" rspace="0.222em" id="S3.E13.m1.1.1.3.1" xref="S3.E13.m1.1.1.3.1.cmml">×</mo><mrow id="S3.E13.m1.1.1.3.3" xref="S3.E13.m1.1.1.3.3.cmml"><msub id="S3.E13.m1.1.1.3.3.1" xref="S3.E13.m1.1.1.3.3.1.cmml"><mi id="S3.E13.m1.1.1.3.3.1.2" xref="S3.E13.m1.1.1.3.3.1.2.cmml">log</mi><mn id="S3.E13.m1.1.1.3.3.1.3" xref="S3.E13.m1.1.1.3.3.1.3.cmml">10</mn></msub><mo lspace="0.167em" id="S3.E13.m1.1.1.3.3a" xref="S3.E13.m1.1.1.3.3.cmml">⁡</mo><mfrac id="S3.E13.m1.1.1.3.3.2" xref="S3.E13.m1.1.1.3.3.2.cmml"><mrow id="S3.E13.m1.1.1.3.3.2.2" xref="S3.E13.m1.1.1.3.3.2.2.cmml"><mi id="S3.E13.m1.1.1.3.3.2.2.2" xref="S3.E13.m1.1.1.3.3.2.2.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.2.1" xref="S3.E13.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.2.3" xref="S3.E13.m1.1.1.3.3.2.2.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.2.1a" xref="S3.E13.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.2.4" xref="S3.E13.m1.1.1.3.3.2.2.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.2.1b" xref="S3.E13.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.2.5" xref="S3.E13.m1.1.1.3.3.2.2.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.2.1c" xref="S3.E13.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.2.6" xref="S3.E13.m1.1.1.3.3.2.2.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.2.1d" xref="S3.E13.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.2.7" xref="S3.E13.m1.1.1.3.3.2.2.7.cmml">l</mi><mo lspace="0.280em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.2.1e" xref="S3.E13.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.2.8" xref="S3.E13.m1.1.1.3.3.2.2.8.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.2.1f" xref="S3.E13.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.2.9" xref="S3.E13.m1.1.1.3.3.2.2.9.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.2.1g" xref="S3.E13.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.2.10" xref="S3.E13.m1.1.1.3.3.2.2.10.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.2.1h" xref="S3.E13.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.2.11" xref="S3.E13.m1.1.1.3.3.2.2.11.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.2.1i" xref="S3.E13.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.2.12" xref="S3.E13.m1.1.1.3.3.2.2.12.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.2.1j" xref="S3.E13.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.2.13" xref="S3.E13.m1.1.1.3.3.2.2.13.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.2.1k" xref="S3.E13.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.2.14" xref="S3.E13.m1.1.1.3.3.2.2.14.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.2.1l" xref="S3.E13.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.2.15" xref="S3.E13.m1.1.1.3.3.2.2.15.cmml">e</mi></mrow><mrow id="S3.E13.m1.1.1.3.3.2.3" xref="S3.E13.m1.1.1.3.3.2.3.cmml"><mi id="S3.E13.m1.1.1.3.3.2.3.2" xref="S3.E13.m1.1.1.3.3.2.3.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.3.1" xref="S3.E13.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.3.3" xref="S3.E13.m1.1.1.3.3.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.3.1a" xref="S3.E13.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.3.4" xref="S3.E13.m1.1.1.3.3.2.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.3.1b" xref="S3.E13.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.3.5" xref="S3.E13.m1.1.1.3.3.2.3.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.3.1c" xref="S3.E13.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.3.6" xref="S3.E13.m1.1.1.3.3.2.3.6.cmml">e</mi><mo lspace="0.280em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.3.1d" xref="S3.E13.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.3.7" xref="S3.E13.m1.1.1.3.3.2.3.7.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.3.1e" xref="S3.E13.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.3.8" xref="S3.E13.m1.1.1.3.3.2.3.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.3.1f" xref="S3.E13.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.3.9" xref="S3.E13.m1.1.1.3.3.2.3.9.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.3.1g" xref="S3.E13.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.3.10" xref="S3.E13.m1.1.1.3.3.2.3.10.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.3.1h" xref="S3.E13.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.3.11" xref="S3.E13.m1.1.1.3.3.2.3.11.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.3.1i" xref="S3.E13.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.3.12" xref="S3.E13.m1.1.1.3.3.2.3.12.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.3.1j" xref="S3.E13.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.3.13" xref="S3.E13.m1.1.1.3.3.2.3.13.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.2.3.1k" xref="S3.E13.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.2.3.14" xref="S3.E13.m1.1.1.3.3.2.3.14.cmml">e</mi></mrow></mfrac></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E13.m1.1b"><apply id="S3.E13.m1.1.1.cmml" xref="S3.E13.m1.1.1"><eq id="S3.E13.m1.1.1.1.cmml" xref="S3.E13.m1.1.1.1"></eq><apply id="S3.E13.m1.1.1.2.cmml" xref="S3.E13.m1.1.1.2"><times id="S3.E13.m1.1.1.2.1.cmml" xref="S3.E13.m1.1.1.2.1"></times><ci id="S3.E13.m1.1.1.2.2.cmml" xref="S3.E13.m1.1.1.2.2">𝑆</ci><ci id="S3.E13.m1.1.1.2.3.cmml" xref="S3.E13.m1.1.1.2.3">𝑁</ci><ci id="S3.E13.m1.1.1.2.4.cmml" xref="S3.E13.m1.1.1.2.4">𝑅</ci></apply><apply id="S3.E13.m1.1.1.3.cmml" xref="S3.E13.m1.1.1.3"><times id="S3.E13.m1.1.1.3.1.cmml" xref="S3.E13.m1.1.1.3.1"></times><cn type="integer" id="S3.E13.m1.1.1.3.2.cmml" xref="S3.E13.m1.1.1.3.2">10</cn><apply id="S3.E13.m1.1.1.3.3.cmml" xref="S3.E13.m1.1.1.3.3"><apply id="S3.E13.m1.1.1.3.3.1.cmml" xref="S3.E13.m1.1.1.3.3.1"><csymbol cd="ambiguous" id="S3.E13.m1.1.1.3.3.1.1.cmml" xref="S3.E13.m1.1.1.3.3.1">subscript</csymbol><log id="S3.E13.m1.1.1.3.3.1.2.cmml" xref="S3.E13.m1.1.1.3.3.1.2"></log><cn type="integer" id="S3.E13.m1.1.1.3.3.1.3.cmml" xref="S3.E13.m1.1.1.3.3.1.3">10</cn></apply><apply id="S3.E13.m1.1.1.3.3.2.cmml" xref="S3.E13.m1.1.1.3.3.2"><divide id="S3.E13.m1.1.1.3.3.2.1.cmml" xref="S3.E13.m1.1.1.3.3.2"></divide><apply id="S3.E13.m1.1.1.3.3.2.2.cmml" xref="S3.E13.m1.1.1.3.3.2.2"><times id="S3.E13.m1.1.1.3.3.2.2.1.cmml" xref="S3.E13.m1.1.1.3.3.2.2.1"></times><ci id="S3.E13.m1.1.1.3.3.2.2.2.cmml" xref="S3.E13.m1.1.1.3.3.2.2.2">𝑆</ci><ci id="S3.E13.m1.1.1.3.3.2.2.3.cmml" xref="S3.E13.m1.1.1.3.3.2.2.3">𝑖</ci><ci id="S3.E13.m1.1.1.3.3.2.2.4.cmml" xref="S3.E13.m1.1.1.3.3.2.2.4">𝑔</ci><ci id="S3.E13.m1.1.1.3.3.2.2.5.cmml" xref="S3.E13.m1.1.1.3.3.2.2.5">𝑛</ci><ci id="S3.E13.m1.1.1.3.3.2.2.6.cmml" xref="S3.E13.m1.1.1.3.3.2.2.6">𝑎</ci><ci id="S3.E13.m1.1.1.3.3.2.2.7.cmml" xref="S3.E13.m1.1.1.3.3.2.2.7">𝑙</ci><ci id="S3.E13.m1.1.1.3.3.2.2.8.cmml" xref="S3.E13.m1.1.1.3.3.2.2.8">𝑣</ci><ci id="S3.E13.m1.1.1.3.3.2.2.9.cmml" xref="S3.E13.m1.1.1.3.3.2.2.9">𝑎</ci><ci id="S3.E13.m1.1.1.3.3.2.2.10.cmml" xref="S3.E13.m1.1.1.3.3.2.2.10">𝑟</ci><ci id="S3.E13.m1.1.1.3.3.2.2.11.cmml" xref="S3.E13.m1.1.1.3.3.2.2.11">𝑖</ci><ci id="S3.E13.m1.1.1.3.3.2.2.12.cmml" xref="S3.E13.m1.1.1.3.3.2.2.12">𝑎</ci><ci id="S3.E13.m1.1.1.3.3.2.2.13.cmml" xref="S3.E13.m1.1.1.3.3.2.2.13">𝑛</ci><ci id="S3.E13.m1.1.1.3.3.2.2.14.cmml" xref="S3.E13.m1.1.1.3.3.2.2.14">𝑐</ci><ci id="S3.E13.m1.1.1.3.3.2.2.15.cmml" xref="S3.E13.m1.1.1.3.3.2.2.15">𝑒</ci></apply><apply id="S3.E13.m1.1.1.3.3.2.3.cmml" xref="S3.E13.m1.1.1.3.3.2.3"><times id="S3.E13.m1.1.1.3.3.2.3.1.cmml" xref="S3.E13.m1.1.1.3.3.2.3.1"></times><ci id="S3.E13.m1.1.1.3.3.2.3.2.cmml" xref="S3.E13.m1.1.1.3.3.2.3.2">𝑁</ci><ci id="S3.E13.m1.1.1.3.3.2.3.3.cmml" xref="S3.E13.m1.1.1.3.3.2.3.3">𝑜</ci><ci id="S3.E13.m1.1.1.3.3.2.3.4.cmml" xref="S3.E13.m1.1.1.3.3.2.3.4">𝑖</ci><ci id="S3.E13.m1.1.1.3.3.2.3.5.cmml" xref="S3.E13.m1.1.1.3.3.2.3.5">𝑠</ci><ci id="S3.E13.m1.1.1.3.3.2.3.6.cmml" xref="S3.E13.m1.1.1.3.3.2.3.6">𝑒</ci><ci id="S3.E13.m1.1.1.3.3.2.3.7.cmml" xref="S3.E13.m1.1.1.3.3.2.3.7">𝑣</ci><ci id="S3.E13.m1.1.1.3.3.2.3.8.cmml" xref="S3.E13.m1.1.1.3.3.2.3.8">𝑎</ci><ci id="S3.E13.m1.1.1.3.3.2.3.9.cmml" xref="S3.E13.m1.1.1.3.3.2.3.9">𝑟</ci><ci id="S3.E13.m1.1.1.3.3.2.3.10.cmml" xref="S3.E13.m1.1.1.3.3.2.3.10">𝑖</ci><ci id="S3.E13.m1.1.1.3.3.2.3.11.cmml" xref="S3.E13.m1.1.1.3.3.2.3.11">𝑎</ci><ci id="S3.E13.m1.1.1.3.3.2.3.12.cmml" xref="S3.E13.m1.1.1.3.3.2.3.12">𝑛</ci><ci id="S3.E13.m1.1.1.3.3.2.3.13.cmml" xref="S3.E13.m1.1.1.3.3.2.3.13">𝑐</ci><ci id="S3.E13.m1.1.1.3.3.2.3.14.cmml" xref="S3.E13.m1.1.1.3.3.2.3.14">𝑒</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E13.m1.1c">SNR=10\times\log_{10}\frac{Signal\;variance}{Noise\;variance}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(13)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p">SNR is used as a metric to evaluate the strength of the signal in the presence of noise and achieve optimal performance. In this context, using signal variance over signal power offers certain advantages:</p>
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p">Variance captures the fluctuations of the signal around its mean. In the case of CNN models, the variance provides an understanding of the model’s confidence or consistency in its responses. By focusing on variance, the model’s behavior is tied directly to the properties of noise. A higher noise variance indicates that the model is more uncertain and less stable in the presence of noise.</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p">Variance is a normalized measure, making it a relative metric. This can be advantageous when comparing the performance of different models or the same model under varying noise conditions, as it ensures that the measure is scaled and comparable.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.1" class="ltx_p">Computing SNR based on the model output is a quantitative tool for evaluating the model’s performance in detecting useful information (signal) from unwanted variations (noise) in the data. SNR allows us to observe the changes in the output and find the noise level that meets the desired trade-off between accuracy, stability, and generalization. Understanding the impact of noise during training provides a guideline for determining the privacy budget without concerns about the quality of results. Leveraging noise to improve stability and generalization without sacrificing performance leads to stronger privacy protection strategies against adversaries.</p>
</div>
<div id="S3.SS1.p7" class="ltx_para">
<p id="S3.SS1.p7.1" class="ltx_p">In the context of CNN, the signal represents the true underlying patterns that the model is trying to capture, and noise is any internal or external variation, perturbation, or distortion in the data that affects the model’s ability to detect the signal. The formal definition of signal and noise is provided:</p>
</div>
<div id="Thmdefinition9" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="Thmdefinition9.1.1.1" class="ltx_text ltx_font_bold">Definition 9</span></span></h6>
<div id="Thmdefinition9.p1" class="ltx_para">
<p id="Thmdefinition9.p1.1" class="ltx_p"><span id="Thmdefinition9.p1.1.1" class="ltx_text ltx_font_italic">A signal is the validation accuracy of the base model (model without noise).</span></p>
</div>
</div>
<div id="Thmdefinition10" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="Thmdefinition10.1.1.1" class="ltx_text ltx_font_bold">Definition 10</span></span></h6>
<div id="Thmdefinition10.p1" class="ltx_para">
<p id="Thmdefinition10.p1.1" class="ltx_p"><span id="Thmdefinition10.p1.1.1" class="ltx_text ltx_font_italic">Noise is defined as the difference between the base model’s validation accuracy and the perturbed model’s validation accuracy. A model is perturbed by introducing a randomly generated value from the Gaussian distribution with a standard deviation of <math id="Thmdefinition10.p1.1.1.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="Thmdefinition10.p1.1.1.m1.1a"><mi id="Thmdefinition10.p1.1.1.m1.1.1" xref="Thmdefinition10.p1.1.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition10.p1.1.1.m1.1b"><ci id="Thmdefinition10.p1.1.1.m1.1.1.cmml" xref="Thmdefinition10.p1.1.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition10.p1.1.1.m1.1c">\sigma</annotation></semantics></math>.</span></p>
</div>
</div>
<div id="S3.SS1.p8" class="ltx_para">
<p id="S3.SS1.p8.1" class="ltx_p">Using validation accuracy obtained from the noisy and clean data provides a more reliable assessment of how well a model handles noise and generalizes to new, challenging conditions. Training accuracy tends to overstate performance, while test accuracy is reserved for final evaluation and should not be influenced by noise during model development.</p>
</div>
<div id="S3.SS1.p9" class="ltx_para">
<p id="S3.SS1.p9.1" class="ltx_p">The choice of the noise infusion scenario relies on the problem’s complexity and dataset. In classification, higher SNR values indicate that the model is capable of predicting values that are closer to the true signal and have less noise interference. The lower SNR values suggest that the noise is more dominant, resulting in less accurate predictions by the model. The noise level that yields the maximum SNR is preferable because it identifies the noise level where the model can most extract useful information from noise, leading to better generalization of unseen data.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Price of Stability &amp; Price of Anarchy</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.6" class="ltx_p">Originally used for the analysis of network and routing games, the Price of Stability (PoS) and Price of Anarchy (PoA) measure the efficiency of outcomes in decentralized systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>, <a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>. PoS compares the outcome achieved by self-interested agents to the socially optimal solution. PoA compares the worst-case outcome achieved by self-interested agents to the socially optimal solution. We propose to define the image classification process as a game where the players are Gaussian noise-infused CNNs under various noise levels. For <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">N</annotation></semantics></math> players, and <math id="S3.SS2.p1.2.m2.3" class="ltx_Math" alttext="i=1,...,n" display="inline"><semantics id="S3.SS2.p1.2.m2.3a"><mrow id="S3.SS2.p1.2.m2.3.4" xref="S3.SS2.p1.2.m2.3.4.cmml"><mi id="S3.SS2.p1.2.m2.3.4.2" xref="S3.SS2.p1.2.m2.3.4.2.cmml">i</mi><mo id="S3.SS2.p1.2.m2.3.4.1" xref="S3.SS2.p1.2.m2.3.4.1.cmml">=</mo><mrow id="S3.SS2.p1.2.m2.3.4.3.2" xref="S3.SS2.p1.2.m2.3.4.3.1.cmml"><mn id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">1</mn><mo id="S3.SS2.p1.2.m2.3.4.3.2.1" xref="S3.SS2.p1.2.m2.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.p1.2.m2.2.2" xref="S3.SS2.p1.2.m2.2.2.cmml">…</mi><mo id="S3.SS2.p1.2.m2.3.4.3.2.2" xref="S3.SS2.p1.2.m2.3.4.3.1.cmml">,</mo><mi id="S3.SS2.p1.2.m2.3.3" xref="S3.SS2.p1.2.m2.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.3b"><apply id="S3.SS2.p1.2.m2.3.4.cmml" xref="S3.SS2.p1.2.m2.3.4"><eq id="S3.SS2.p1.2.m2.3.4.1.cmml" xref="S3.SS2.p1.2.m2.3.4.1"></eq><ci id="S3.SS2.p1.2.m2.3.4.2.cmml" xref="S3.SS2.p1.2.m2.3.4.2">𝑖</ci><list id="S3.SS2.p1.2.m2.3.4.3.1.cmml" xref="S3.SS2.p1.2.m2.3.4.3.2"><cn type="integer" id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">1</cn><ci id="S3.SS2.p1.2.m2.2.2.cmml" xref="S3.SS2.p1.2.m2.2.2">…</ci><ci id="S3.SS2.p1.2.m2.3.3.cmml" xref="S3.SS2.p1.2.m2.3.3">𝑛</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.3c">i=1,...,n</annotation></semantics></math>, the standard deviation of the Gaussian noise of the <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="i^{th}" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><msup id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml">i</mi><mrow id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml"><mi id="S3.SS2.p1.3.m3.1.1.3.2" xref="S3.SS2.p1.3.m3.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.3.m3.1.1.3.1" xref="S3.SS2.p1.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p1.3.m3.1.1.3.3" xref="S3.SS2.p1.3.m3.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2">𝑖</ci><apply id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3"><times id="S3.SS2.p1.3.m3.1.1.3.1.cmml" xref="S3.SS2.p1.3.m3.1.1.3.1"></times><ci id="S3.SS2.p1.3.m3.1.1.3.2.cmml" xref="S3.SS2.p1.3.m3.1.1.3.2">𝑡</ci><ci id="S3.SS2.p1.3.m3.1.1.3.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">i^{th}</annotation></semantics></math> player is <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="\sigma_{i}" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><msub id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml"><mi id="S3.SS2.p1.4.m4.1.1.2" xref="S3.SS2.p1.4.m4.1.1.2.cmml">σ</mi><mi id="S3.SS2.p1.4.m4.1.1.3" xref="S3.SS2.p1.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><apply id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1.2">𝜎</ci><ci id="S3.SS2.p1.4.m4.1.1.3.cmml" xref="S3.SS2.p1.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">\sigma_{i}</annotation></semantics></math>, where <math id="S3.SS2.p1.5.m5.2" class="ltx_Math" alttext="\sigma_{i}\in[0,1]" display="inline"><semantics id="S3.SS2.p1.5.m5.2a"><mrow id="S3.SS2.p1.5.m5.2.3" xref="S3.SS2.p1.5.m5.2.3.cmml"><msub id="S3.SS2.p1.5.m5.2.3.2" xref="S3.SS2.p1.5.m5.2.3.2.cmml"><mi id="S3.SS2.p1.5.m5.2.3.2.2" xref="S3.SS2.p1.5.m5.2.3.2.2.cmml">σ</mi><mi id="S3.SS2.p1.5.m5.2.3.2.3" xref="S3.SS2.p1.5.m5.2.3.2.3.cmml">i</mi></msub><mo id="S3.SS2.p1.5.m5.2.3.1" xref="S3.SS2.p1.5.m5.2.3.1.cmml">∈</mo><mrow id="S3.SS2.p1.5.m5.2.3.3.2" xref="S3.SS2.p1.5.m5.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.p1.5.m5.2.3.3.2.1" xref="S3.SS2.p1.5.m5.2.3.3.1.cmml">[</mo><mn id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml">0</mn><mo id="S3.SS2.p1.5.m5.2.3.3.2.2" xref="S3.SS2.p1.5.m5.2.3.3.1.cmml">,</mo><mn id="S3.SS2.p1.5.m5.2.2" xref="S3.SS2.p1.5.m5.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS2.p1.5.m5.2.3.3.2.3" xref="S3.SS2.p1.5.m5.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.2b"><apply id="S3.SS2.p1.5.m5.2.3.cmml" xref="S3.SS2.p1.5.m5.2.3"><in id="S3.SS2.p1.5.m5.2.3.1.cmml" xref="S3.SS2.p1.5.m5.2.3.1"></in><apply id="S3.SS2.p1.5.m5.2.3.2.cmml" xref="S3.SS2.p1.5.m5.2.3.2"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.2.3.2.1.cmml" xref="S3.SS2.p1.5.m5.2.3.2">subscript</csymbol><ci id="S3.SS2.p1.5.m5.2.3.2.2.cmml" xref="S3.SS2.p1.5.m5.2.3.2.2">𝜎</ci><ci id="S3.SS2.p1.5.m5.2.3.2.3.cmml" xref="S3.SS2.p1.5.m5.2.3.2.3">𝑖</ci></apply><interval closure="closed" id="S3.SS2.p1.5.m5.2.3.3.1.cmml" xref="S3.SS2.p1.5.m5.2.3.3.2"><cn type="integer" id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">0</cn><cn type="integer" id="S3.SS2.p1.5.m5.2.2.cmml" xref="S3.SS2.p1.5.m5.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.2c">\sigma_{i}\in[0,1]</annotation></semantics></math>. Suppose the ideal scenario is training the model without noise (base model denoted as <math id="S3.SS2.p1.6.m6.1" class="ltx_Math" alttext="CNN_{\sigma_{0}}" display="inline"><semantics id="S3.SS2.p1.6.m6.1a"><mrow id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml"><mi id="S3.SS2.p1.6.m6.1.1.2" xref="S3.SS2.p1.6.m6.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.6.m6.1.1.1" xref="S3.SS2.p1.6.m6.1.1.1.cmml">​</mo><mi id="S3.SS2.p1.6.m6.1.1.3" xref="S3.SS2.p1.6.m6.1.1.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.6.m6.1.1.1a" xref="S3.SS2.p1.6.m6.1.1.1.cmml">​</mo><msub id="S3.SS2.p1.6.m6.1.1.4" xref="S3.SS2.p1.6.m6.1.1.4.cmml"><mi id="S3.SS2.p1.6.m6.1.1.4.2" xref="S3.SS2.p1.6.m6.1.1.4.2.cmml">N</mi><msub id="S3.SS2.p1.6.m6.1.1.4.3" xref="S3.SS2.p1.6.m6.1.1.4.3.cmml"><mi id="S3.SS2.p1.6.m6.1.1.4.3.2" xref="S3.SS2.p1.6.m6.1.1.4.3.2.cmml">σ</mi><mn id="S3.SS2.p1.6.m6.1.1.4.3.3" xref="S3.SS2.p1.6.m6.1.1.4.3.3.cmml">0</mn></msub></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><apply id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1"><times id="S3.SS2.p1.6.m6.1.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1.1"></times><ci id="S3.SS2.p1.6.m6.1.1.2.cmml" xref="S3.SS2.p1.6.m6.1.1.2">𝐶</ci><ci id="S3.SS2.p1.6.m6.1.1.3.cmml" xref="S3.SS2.p1.6.m6.1.1.3">𝑁</ci><apply id="S3.SS2.p1.6.m6.1.1.4.cmml" xref="S3.SS2.p1.6.m6.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.1.1.4.1.cmml" xref="S3.SS2.p1.6.m6.1.1.4">subscript</csymbol><ci id="S3.SS2.p1.6.m6.1.1.4.2.cmml" xref="S3.SS2.p1.6.m6.1.1.4.2">𝑁</ci><apply id="S3.SS2.p1.6.m6.1.1.4.3.cmml" xref="S3.SS2.p1.6.m6.1.1.4.3"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.1.1.4.3.1.cmml" xref="S3.SS2.p1.6.m6.1.1.4.3">subscript</csymbol><ci id="S3.SS2.p1.6.m6.1.1.4.3.2.cmml" xref="S3.SS2.p1.6.m6.1.1.4.3.2">𝜎</ci><cn type="integer" id="S3.SS2.p1.6.m6.1.1.4.3.3.cmml" xref="S3.SS2.p1.6.m6.1.1.4.3.3">0</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">CNN_{\sigma_{0}}</annotation></semantics></math>). PoS is defined as the ratio of the model with noise and the base model:</p>
<table id="S3.E14" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S3.E14.m1.26" class="ltx_Math" alttext="\begin{split}Price\;of\;Stability\;(PoS_{i})=\frac{Test\;accuracy\;of\;CNN_{\sigma_{i}}}{Test\;accuracy\;of\;CNN_{\sigma_{0}}}\end{split}" display="block"><semantics id="S3.E14.m1.26a"><mtable displaystyle="true" id="S3.E14.m1.26.26.2" xref="S3.E14.m1.25.25.1.cmml"><mtr id="S3.E14.m1.26.26.2a" xref="S3.E14.m1.25.25.1.cmml"><mtd class="ltx_align_right" columnalign="right" id="S3.E14.m1.26.26.2b" xref="S3.E14.m1.25.25.1.cmml"><mrow id="S3.E14.m1.26.26.2.25.25.25" xref="S3.E14.m1.25.25.1.cmml"><mrow id="S3.E14.m1.26.26.2.25.25.25.25" xref="S3.E14.m1.25.25.1.cmml"><mi id="S3.E14.m1.1.1.1.1.1.1" xref="S3.E14.m1.1.1.1.1.1.1.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.2" xref="S3.E14.m1.25.25.1.cmml">​</mo><mi id="S3.E14.m1.2.2.2.2.2.2" xref="S3.E14.m1.2.2.2.2.2.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.2a" xref="S3.E14.m1.25.25.1.cmml">​</mo><mi id="S3.E14.m1.3.3.3.3.3.3" xref="S3.E14.m1.3.3.3.3.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.2b" xref="S3.E14.m1.25.25.1.cmml">​</mo><mi id="S3.E14.m1.4.4.4.4.4.4" xref="S3.E14.m1.4.4.4.4.4.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.2c" xref="S3.E14.m1.25.25.1.cmml">​</mo><mi id="S3.E14.m1.5.5.5.5.5.5" xref="S3.E14.m1.5.5.5.5.5.5.cmml">e</mi><mo lspace="0.280em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.2d" xref="S3.E14.m1.25.25.1.cmml">​</mo><mi id="S3.E14.m1.6.6.6.6.6.6" xref="S3.E14.m1.6.6.6.6.6.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.2e" xref="S3.E14.m1.25.25.1.cmml">​</mo><mi id="S3.E14.m1.7.7.7.7.7.7" xref="S3.E14.m1.7.7.7.7.7.7.cmml">f</mi><mo lspace="0.280em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.2f" xref="S3.E14.m1.25.25.1.cmml">​</mo><mi id="S3.E14.m1.8.8.8.8.8.8" xref="S3.E14.m1.8.8.8.8.8.8.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.2g" xref="S3.E14.m1.25.25.1.cmml">​</mo><mi id="S3.E14.m1.9.9.9.9.9.9" xref="S3.E14.m1.9.9.9.9.9.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.2h" xref="S3.E14.m1.25.25.1.cmml">​</mo><mi id="S3.E14.m1.10.10.10.10.10.10" xref="S3.E14.m1.10.10.10.10.10.10.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.2i" xref="S3.E14.m1.25.25.1.cmml">​</mo><mi id="S3.E14.m1.11.11.11.11.11.11" xref="S3.E14.m1.11.11.11.11.11.11.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.2j" xref="S3.E14.m1.25.25.1.cmml">​</mo><mi id="S3.E14.m1.12.12.12.12.12.12" xref="S3.E14.m1.12.12.12.12.12.12.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.2k" xref="S3.E14.m1.25.25.1.cmml">​</mo><mi id="S3.E14.m1.13.13.13.13.13.13" xref="S3.E14.m1.13.13.13.13.13.13.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.2l" xref="S3.E14.m1.25.25.1.cmml">​</mo><mi id="S3.E14.m1.14.14.14.14.14.14" xref="S3.E14.m1.14.14.14.14.14.14.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.2m" xref="S3.E14.m1.25.25.1.cmml">​</mo><mi id="S3.E14.m1.15.15.15.15.15.15" xref="S3.E14.m1.15.15.15.15.15.15.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.2n" xref="S3.E14.m1.25.25.1.cmml">​</mo><mi id="S3.E14.m1.16.16.16.16.16.16" xref="S3.E14.m1.16.16.16.16.16.16.cmml">y</mi><mo lspace="0.280em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.2o" xref="S3.E14.m1.25.25.1.cmml">​</mo><mrow id="S3.E14.m1.26.26.2.25.25.25.25.1.1" xref="S3.E14.m1.25.25.1.cmml"><mo stretchy="false" id="S3.E14.m1.17.17.17.17.17.17" xref="S3.E14.m1.25.25.1.cmml">(</mo><mrow id="S3.E14.m1.26.26.2.25.25.25.25.1.1.1" xref="S3.E14.m1.25.25.1.cmml"><mi id="S3.E14.m1.18.18.18.18.18.18" xref="S3.E14.m1.18.18.18.18.18.18.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.1.1.1.1" xref="S3.E14.m1.25.25.1.cmml">​</mo><mi id="S3.E14.m1.19.19.19.19.19.19" xref="S3.E14.m1.19.19.19.19.19.19.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.26.26.2.25.25.25.25.1.1.1.1a" xref="S3.E14.m1.25.25.1.cmml">​</mo><msub id="S3.E14.m1.26.26.2.25.25.25.25.1.1.1.2" xref="S3.E14.m1.25.25.1.cmml"><mi id="S3.E14.m1.20.20.20.20.20.20" xref="S3.E14.m1.20.20.20.20.20.20.cmml">S</mi><mi id="S3.E14.m1.21.21.21.21.21.21.1" xref="S3.E14.m1.21.21.21.21.21.21.1.cmml">i</mi></msub></mrow><mo stretchy="false" id="S3.E14.m1.22.22.22.22.22.22" xref="S3.E14.m1.25.25.1.cmml">)</mo></mrow></mrow><mo id="S3.E14.m1.23.23.23.23.23.23" xref="S3.E14.m1.23.23.23.23.23.23.cmml">=</mo><mfrac id="S3.E14.m1.24.24.24.24.24.24" xref="S3.E14.m1.24.24.24.24.24.24.cmml"><mrow id="S3.E14.m1.24.24.24.24.24.24.2" xref="S3.E14.m1.24.24.24.24.24.24.2.cmml"><mi id="S3.E14.m1.24.24.24.24.24.24.2.2" xref="S3.E14.m1.24.24.24.24.24.24.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.2.1" xref="S3.E14.m1.24.24.24.24.24.24.2.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.2.3" xref="S3.E14.m1.24.24.24.24.24.24.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.2.1a" xref="S3.E14.m1.24.24.24.24.24.24.2.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.2.4" xref="S3.E14.m1.24.24.24.24.24.24.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.2.1b" xref="S3.E14.m1.24.24.24.24.24.24.2.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.2.5" xref="S3.E14.m1.24.24.24.24.24.24.2.5.cmml">t</mi><mo lspace="0.280em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.2.1c" xref="S3.E14.m1.24.24.24.24.24.24.2.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.2.6" xref="S3.E14.m1.24.24.24.24.24.24.2.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.2.1d" xref="S3.E14.m1.24.24.24.24.24.24.2.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.2.7" xref="S3.E14.m1.24.24.24.24.24.24.2.7.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.2.1e" xref="S3.E14.m1.24.24.24.24.24.24.2.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.2.8" xref="S3.E14.m1.24.24.24.24.24.24.2.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.2.1f" xref="S3.E14.m1.24.24.24.24.24.24.2.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.2.9" xref="S3.E14.m1.24.24.24.24.24.24.2.9.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.2.1g" xref="S3.E14.m1.24.24.24.24.24.24.2.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.2.10" xref="S3.E14.m1.24.24.24.24.24.24.2.10.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.2.1h" xref="S3.E14.m1.24.24.24.24.24.24.2.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.2.11" xref="S3.E14.m1.24.24.24.24.24.24.2.11.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.2.1i" xref="S3.E14.m1.24.24.24.24.24.24.2.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.2.12" xref="S3.E14.m1.24.24.24.24.24.24.2.12.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.2.1j" xref="S3.E14.m1.24.24.24.24.24.24.2.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.2.13" xref="S3.E14.m1.24.24.24.24.24.24.2.13.cmml">y</mi><mo lspace="0.280em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.2.1k" xref="S3.E14.m1.24.24.24.24.24.24.2.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.2.14" xref="S3.E14.m1.24.24.24.24.24.24.2.14.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.2.1l" xref="S3.E14.m1.24.24.24.24.24.24.2.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.2.15" xref="S3.E14.m1.24.24.24.24.24.24.2.15.cmml">f</mi><mo lspace="0.280em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.2.1m" xref="S3.E14.m1.24.24.24.24.24.24.2.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.2.16" xref="S3.E14.m1.24.24.24.24.24.24.2.16.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.2.1n" xref="S3.E14.m1.24.24.24.24.24.24.2.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.2.17" xref="S3.E14.m1.24.24.24.24.24.24.2.17.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.2.1o" xref="S3.E14.m1.24.24.24.24.24.24.2.1.cmml">​</mo><msub id="S3.E14.m1.24.24.24.24.24.24.2.18" xref="S3.E14.m1.24.24.24.24.24.24.2.18.cmml"><mi id="S3.E14.m1.24.24.24.24.24.24.2.18.2" xref="S3.E14.m1.24.24.24.24.24.24.2.18.2.cmml">N</mi><msub id="S3.E14.m1.24.24.24.24.24.24.2.18.3" xref="S3.E14.m1.24.24.24.24.24.24.2.18.3.cmml"><mi id="S3.E14.m1.24.24.24.24.24.24.2.18.3.2" xref="S3.E14.m1.24.24.24.24.24.24.2.18.3.2.cmml">σ</mi><mi id="S3.E14.m1.24.24.24.24.24.24.2.18.3.3" xref="S3.E14.m1.24.24.24.24.24.24.2.18.3.3.cmml">i</mi></msub></msub></mrow><mrow id="S3.E14.m1.24.24.24.24.24.24.3" xref="S3.E14.m1.24.24.24.24.24.24.3.cmml"><mi id="S3.E14.m1.24.24.24.24.24.24.3.2" xref="S3.E14.m1.24.24.24.24.24.24.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.3.1" xref="S3.E14.m1.24.24.24.24.24.24.3.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.3.3" xref="S3.E14.m1.24.24.24.24.24.24.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.3.1a" xref="S3.E14.m1.24.24.24.24.24.24.3.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.3.4" xref="S3.E14.m1.24.24.24.24.24.24.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.3.1b" xref="S3.E14.m1.24.24.24.24.24.24.3.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.3.5" xref="S3.E14.m1.24.24.24.24.24.24.3.5.cmml">t</mi><mo lspace="0.280em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.3.1c" xref="S3.E14.m1.24.24.24.24.24.24.3.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.3.6" xref="S3.E14.m1.24.24.24.24.24.24.3.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.3.1d" xref="S3.E14.m1.24.24.24.24.24.24.3.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.3.7" xref="S3.E14.m1.24.24.24.24.24.24.3.7.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.3.1e" xref="S3.E14.m1.24.24.24.24.24.24.3.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.3.8" xref="S3.E14.m1.24.24.24.24.24.24.3.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.3.1f" xref="S3.E14.m1.24.24.24.24.24.24.3.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.3.9" xref="S3.E14.m1.24.24.24.24.24.24.3.9.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.3.1g" xref="S3.E14.m1.24.24.24.24.24.24.3.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.3.10" xref="S3.E14.m1.24.24.24.24.24.24.3.10.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.3.1h" xref="S3.E14.m1.24.24.24.24.24.24.3.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.3.11" xref="S3.E14.m1.24.24.24.24.24.24.3.11.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.3.1i" xref="S3.E14.m1.24.24.24.24.24.24.3.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.3.12" xref="S3.E14.m1.24.24.24.24.24.24.3.12.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.3.1j" xref="S3.E14.m1.24.24.24.24.24.24.3.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.3.13" xref="S3.E14.m1.24.24.24.24.24.24.3.13.cmml">y</mi><mo lspace="0.280em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.3.1k" xref="S3.E14.m1.24.24.24.24.24.24.3.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.3.14" xref="S3.E14.m1.24.24.24.24.24.24.3.14.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.3.1l" xref="S3.E14.m1.24.24.24.24.24.24.3.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.3.15" xref="S3.E14.m1.24.24.24.24.24.24.3.15.cmml">f</mi><mo lspace="0.280em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.3.1m" xref="S3.E14.m1.24.24.24.24.24.24.3.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.3.16" xref="S3.E14.m1.24.24.24.24.24.24.3.16.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.3.1n" xref="S3.E14.m1.24.24.24.24.24.24.3.1.cmml">​</mo><mi id="S3.E14.m1.24.24.24.24.24.24.3.17" xref="S3.E14.m1.24.24.24.24.24.24.3.17.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.E14.m1.24.24.24.24.24.24.3.1o" xref="S3.E14.m1.24.24.24.24.24.24.3.1.cmml">​</mo><msub id="S3.E14.m1.24.24.24.24.24.24.3.18" xref="S3.E14.m1.24.24.24.24.24.24.3.18.cmml"><mi id="S3.E14.m1.24.24.24.24.24.24.3.18.2" xref="S3.E14.m1.24.24.24.24.24.24.3.18.2.cmml">N</mi><msub id="S3.E14.m1.24.24.24.24.24.24.3.18.3" xref="S3.E14.m1.24.24.24.24.24.24.3.18.3.cmml"><mi id="S3.E14.m1.24.24.24.24.24.24.3.18.3.2" xref="S3.E14.m1.24.24.24.24.24.24.3.18.3.2.cmml">σ</mi><mn id="S3.E14.m1.24.24.24.24.24.24.3.18.3.3" xref="S3.E14.m1.24.24.24.24.24.24.3.18.3.3.cmml">0</mn></msub></msub></mrow></mfrac></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E14.m1.26b"><apply id="S3.E14.m1.25.25.1.cmml" xref="S3.E14.m1.26.26.2"><eq id="S3.E14.m1.23.23.23.23.23.23.cmml" xref="S3.E14.m1.23.23.23.23.23.23"></eq><apply id="S3.E14.m1.25.25.1.1.cmml" xref="S3.E14.m1.26.26.2"><times id="S3.E14.m1.25.25.1.1.2.cmml" xref="S3.E14.m1.26.26.2"></times><ci id="S3.E14.m1.1.1.1.1.1.1.cmml" xref="S3.E14.m1.1.1.1.1.1.1">𝑃</ci><ci id="S3.E14.m1.2.2.2.2.2.2.cmml" xref="S3.E14.m1.2.2.2.2.2.2">𝑟</ci><ci id="S3.E14.m1.3.3.3.3.3.3.cmml" xref="S3.E14.m1.3.3.3.3.3.3">𝑖</ci><ci id="S3.E14.m1.4.4.4.4.4.4.cmml" xref="S3.E14.m1.4.4.4.4.4.4">𝑐</ci><ci id="S3.E14.m1.5.5.5.5.5.5.cmml" xref="S3.E14.m1.5.5.5.5.5.5">𝑒</ci><ci id="S3.E14.m1.6.6.6.6.6.6.cmml" xref="S3.E14.m1.6.6.6.6.6.6">𝑜</ci><ci id="S3.E14.m1.7.7.7.7.7.7.cmml" xref="S3.E14.m1.7.7.7.7.7.7">𝑓</ci><ci id="S3.E14.m1.8.8.8.8.8.8.cmml" xref="S3.E14.m1.8.8.8.8.8.8">𝑆</ci><ci id="S3.E14.m1.9.9.9.9.9.9.cmml" xref="S3.E14.m1.9.9.9.9.9.9">𝑡</ci><ci id="S3.E14.m1.10.10.10.10.10.10.cmml" xref="S3.E14.m1.10.10.10.10.10.10">𝑎</ci><ci id="S3.E14.m1.11.11.11.11.11.11.cmml" xref="S3.E14.m1.11.11.11.11.11.11">𝑏</ci><ci id="S3.E14.m1.12.12.12.12.12.12.cmml" xref="S3.E14.m1.12.12.12.12.12.12">𝑖</ci><ci id="S3.E14.m1.13.13.13.13.13.13.cmml" xref="S3.E14.m1.13.13.13.13.13.13">𝑙</ci><ci id="S3.E14.m1.14.14.14.14.14.14.cmml" xref="S3.E14.m1.14.14.14.14.14.14">𝑖</ci><ci id="S3.E14.m1.15.15.15.15.15.15.cmml" xref="S3.E14.m1.15.15.15.15.15.15">𝑡</ci><ci id="S3.E14.m1.16.16.16.16.16.16.cmml" xref="S3.E14.m1.16.16.16.16.16.16">𝑦</ci><apply id="S3.E14.m1.25.25.1.1.1.1.1.cmml" xref="S3.E14.m1.26.26.2"><times id="S3.E14.m1.25.25.1.1.1.1.1.1.cmml" xref="S3.E14.m1.26.26.2"></times><ci id="S3.E14.m1.18.18.18.18.18.18.cmml" xref="S3.E14.m1.18.18.18.18.18.18">𝑃</ci><ci id="S3.E14.m1.19.19.19.19.19.19.cmml" xref="S3.E14.m1.19.19.19.19.19.19">𝑜</ci><apply id="S3.E14.m1.25.25.1.1.1.1.1.4.cmml" xref="S3.E14.m1.26.26.2"><csymbol cd="ambiguous" id="S3.E14.m1.25.25.1.1.1.1.1.4.1.cmml" xref="S3.E14.m1.26.26.2">subscript</csymbol><ci id="S3.E14.m1.20.20.20.20.20.20.cmml" xref="S3.E14.m1.20.20.20.20.20.20">𝑆</ci><ci id="S3.E14.m1.21.21.21.21.21.21.1.cmml" xref="S3.E14.m1.21.21.21.21.21.21.1">𝑖</ci></apply></apply></apply><apply id="S3.E14.m1.24.24.24.24.24.24.cmml" xref="S3.E14.m1.24.24.24.24.24.24"><divide id="S3.E14.m1.24.24.24.24.24.24.1.cmml" xref="S3.E14.m1.24.24.24.24.24.24"></divide><apply id="S3.E14.m1.24.24.24.24.24.24.2.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2"><times id="S3.E14.m1.24.24.24.24.24.24.2.1.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.1"></times><ci id="S3.E14.m1.24.24.24.24.24.24.2.2.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.2">𝑇</ci><ci id="S3.E14.m1.24.24.24.24.24.24.2.3.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.3">𝑒</ci><ci id="S3.E14.m1.24.24.24.24.24.24.2.4.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.4">𝑠</ci><ci id="S3.E14.m1.24.24.24.24.24.24.2.5.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.5">𝑡</ci><ci id="S3.E14.m1.24.24.24.24.24.24.2.6.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.6">𝑎</ci><ci id="S3.E14.m1.24.24.24.24.24.24.2.7.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.7">𝑐</ci><ci id="S3.E14.m1.24.24.24.24.24.24.2.8.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.8">𝑐</ci><ci id="S3.E14.m1.24.24.24.24.24.24.2.9.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.9">𝑢</ci><ci id="S3.E14.m1.24.24.24.24.24.24.2.10.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.10">𝑟</ci><ci id="S3.E14.m1.24.24.24.24.24.24.2.11.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.11">𝑎</ci><ci id="S3.E14.m1.24.24.24.24.24.24.2.12.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.12">𝑐</ci><ci id="S3.E14.m1.24.24.24.24.24.24.2.13.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.13">𝑦</ci><ci id="S3.E14.m1.24.24.24.24.24.24.2.14.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.14">𝑜</ci><ci id="S3.E14.m1.24.24.24.24.24.24.2.15.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.15">𝑓</ci><ci id="S3.E14.m1.24.24.24.24.24.24.2.16.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.16">𝐶</ci><ci id="S3.E14.m1.24.24.24.24.24.24.2.17.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.17">𝑁</ci><apply id="S3.E14.m1.24.24.24.24.24.24.2.18.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.18"><csymbol cd="ambiguous" id="S3.E14.m1.24.24.24.24.24.24.2.18.1.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.18">subscript</csymbol><ci id="S3.E14.m1.24.24.24.24.24.24.2.18.2.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.18.2">𝑁</ci><apply id="S3.E14.m1.24.24.24.24.24.24.2.18.3.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.18.3"><csymbol cd="ambiguous" id="S3.E14.m1.24.24.24.24.24.24.2.18.3.1.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.18.3">subscript</csymbol><ci id="S3.E14.m1.24.24.24.24.24.24.2.18.3.2.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.18.3.2">𝜎</ci><ci id="S3.E14.m1.24.24.24.24.24.24.2.18.3.3.cmml" xref="S3.E14.m1.24.24.24.24.24.24.2.18.3.3">𝑖</ci></apply></apply></apply><apply id="S3.E14.m1.24.24.24.24.24.24.3.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3"><times id="S3.E14.m1.24.24.24.24.24.24.3.1.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.1"></times><ci id="S3.E14.m1.24.24.24.24.24.24.3.2.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.2">𝑇</ci><ci id="S3.E14.m1.24.24.24.24.24.24.3.3.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.3">𝑒</ci><ci id="S3.E14.m1.24.24.24.24.24.24.3.4.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.4">𝑠</ci><ci id="S3.E14.m1.24.24.24.24.24.24.3.5.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.5">𝑡</ci><ci id="S3.E14.m1.24.24.24.24.24.24.3.6.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.6">𝑎</ci><ci id="S3.E14.m1.24.24.24.24.24.24.3.7.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.7">𝑐</ci><ci id="S3.E14.m1.24.24.24.24.24.24.3.8.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.8">𝑐</ci><ci id="S3.E14.m1.24.24.24.24.24.24.3.9.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.9">𝑢</ci><ci id="S3.E14.m1.24.24.24.24.24.24.3.10.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.10">𝑟</ci><ci id="S3.E14.m1.24.24.24.24.24.24.3.11.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.11">𝑎</ci><ci id="S3.E14.m1.24.24.24.24.24.24.3.12.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.12">𝑐</ci><ci id="S3.E14.m1.24.24.24.24.24.24.3.13.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.13">𝑦</ci><ci id="S3.E14.m1.24.24.24.24.24.24.3.14.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.14">𝑜</ci><ci id="S3.E14.m1.24.24.24.24.24.24.3.15.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.15">𝑓</ci><ci id="S3.E14.m1.24.24.24.24.24.24.3.16.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.16">𝐶</ci><ci id="S3.E14.m1.24.24.24.24.24.24.3.17.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.17">𝑁</ci><apply id="S3.E14.m1.24.24.24.24.24.24.3.18.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.18"><csymbol cd="ambiguous" id="S3.E14.m1.24.24.24.24.24.24.3.18.1.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.18">subscript</csymbol><ci id="S3.E14.m1.24.24.24.24.24.24.3.18.2.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.18.2">𝑁</ci><apply id="S3.E14.m1.24.24.24.24.24.24.3.18.3.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.18.3"><csymbol cd="ambiguous" id="S3.E14.m1.24.24.24.24.24.24.3.18.3.1.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.18.3">subscript</csymbol><ci id="S3.E14.m1.24.24.24.24.24.24.3.18.3.2.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.18.3.2">𝜎</ci><cn type="integer" id="S3.E14.m1.24.24.24.24.24.24.3.18.3.3.cmml" xref="S3.E14.m1.24.24.24.24.24.24.3.18.3.3">0</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E14.m1.26c">\begin{split}Price\;of\;Stability\;(PoS_{i})=\frac{Test\;accuracy\;of\;CNN_{\sigma_{i}}}{Test\;accuracy\;of\;CNN_{\sigma_{0}}}\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(14)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">By comparing against the base model, we can assess how training with noise impacts the prediction results of the test data.</p>
<ul id="S3.I3" class="ltx_itemize">
<li id="S3.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i1.p1" class="ltx_para">
<p id="S3.I3.i1.p1.1" class="ltx_p">The PoS of the base model is always 1.</p>
</div>
</li>
<li id="S3.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i2.p1" class="ltx_para">
<p id="S3.I3.i2.p1.1" class="ltx_p">If PoS <math id="S3.I3.i2.p1.1.m1.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S3.I3.i2.p1.1.m1.1a"><mo id="S3.I3.i2.p1.1.m1.1.1" xref="S3.I3.i2.p1.1.m1.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S3.I3.i2.p1.1.m1.1b"><eq id="S3.I3.i2.p1.1.m1.1.1.cmml" xref="S3.I3.i2.p1.1.m1.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S3.I3.i2.p1.1.m1.1c">=</annotation></semantics></math> 1, the model’s sensitivity to noise is minimal. The noisy model is performing similarly to the base model. It also suggests that the model is relatively stable across different noise levels.</p>
</div>
</li>
<li id="S3.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i3.p1" class="ltx_para">
<p id="S3.I3.i3.p1.1" class="ltx_p">If PoS <math id="S3.I3.i3.p1.1.m1.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="S3.I3.i3.p1.1.m1.1a"><mo id="S3.I3.i3.p1.1.m1.1.1" xref="S3.I3.i3.p1.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S3.I3.i3.p1.1.m1.1b"><gt id="S3.I3.i3.p1.1.m1.1.1.cmml" xref="S3.I3.i3.p1.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S3.I3.i3.p1.1.m1.1c">&gt;</annotation></semantics></math> 1, the noisy model performs better than the base model. It suggests that additive noise improves the model’s generalization on unseen data. Therefore, test accuracy has improved in the presence of noise.</p>
</div>
</li>
<li id="S3.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i4.p1" class="ltx_para">
<p id="S3.I3.i4.p1.1" class="ltx_p">If PoS <math id="S3.I3.i4.p1.1.m1.1" class="ltx_Math" alttext="&lt;" display="inline"><semantics id="S3.I3.i4.p1.1.m1.1a"><mo id="S3.I3.i4.p1.1.m1.1.1" xref="S3.I3.i4.p1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S3.I3.i4.p1.1.m1.1b"><lt id="S3.I3.i4.p1.1.m1.1.1.cmml" xref="S3.I3.i4.p1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S3.I3.i4.p1.1.m1.1c">&lt;</annotation></semantics></math> 1, the noisy model performs worse than the base model. Smaller PoS suggests a lack of stability in the presence of noise. The model has less potential for privacy-preserving applications.</p>
</div>
</li>
</ul>
<p id="S3.SS2.p2.2" class="ltx_p">The PoA is defined as:</p>
<table id="S3.E15" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S3.E15.m1.24" class="ltx_Math" alttext="\begin{split}Price\;of\;Anarchy\;(PoA_{i})=\frac{Test\;loss\;of\;CNN_{\sigma_{i}}}{Test\;loss\;of\;CNN_{\sigma_{0}}}\end{split}" display="block"><semantics id="S3.E15.m1.24a"><mtable displaystyle="true" id="S3.E15.m1.24.24.2" xref="S3.E15.m1.23.23.1.cmml"><mtr id="S3.E15.m1.24.24.2a" xref="S3.E15.m1.23.23.1.cmml"><mtd class="ltx_align_right" columnalign="right" id="S3.E15.m1.24.24.2b" xref="S3.E15.m1.23.23.1.cmml"><mrow id="S3.E15.m1.24.24.2.23.23.23" xref="S3.E15.m1.23.23.1.cmml"><mrow id="S3.E15.m1.24.24.2.23.23.23.23" xref="S3.E15.m1.23.23.1.cmml"><mi id="S3.E15.m1.1.1.1.1.1.1" xref="S3.E15.m1.1.1.1.1.1.1.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.24.24.2.23.23.23.23.2" xref="S3.E15.m1.23.23.1.cmml">​</mo><mi id="S3.E15.m1.2.2.2.2.2.2" xref="S3.E15.m1.2.2.2.2.2.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.24.24.2.23.23.23.23.2a" xref="S3.E15.m1.23.23.1.cmml">​</mo><mi id="S3.E15.m1.3.3.3.3.3.3" xref="S3.E15.m1.3.3.3.3.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.24.24.2.23.23.23.23.2b" xref="S3.E15.m1.23.23.1.cmml">​</mo><mi id="S3.E15.m1.4.4.4.4.4.4" xref="S3.E15.m1.4.4.4.4.4.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.24.24.2.23.23.23.23.2c" xref="S3.E15.m1.23.23.1.cmml">​</mo><mi id="S3.E15.m1.5.5.5.5.5.5" xref="S3.E15.m1.5.5.5.5.5.5.cmml">e</mi><mo lspace="0.280em" rspace="0em" id="S3.E15.m1.24.24.2.23.23.23.23.2d" xref="S3.E15.m1.23.23.1.cmml">​</mo><mi id="S3.E15.m1.6.6.6.6.6.6" xref="S3.E15.m1.6.6.6.6.6.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.24.24.2.23.23.23.23.2e" xref="S3.E15.m1.23.23.1.cmml">​</mo><mi id="S3.E15.m1.7.7.7.7.7.7" xref="S3.E15.m1.7.7.7.7.7.7.cmml">f</mi><mo lspace="0.280em" rspace="0em" id="S3.E15.m1.24.24.2.23.23.23.23.2f" xref="S3.E15.m1.23.23.1.cmml">​</mo><mi id="S3.E15.m1.8.8.8.8.8.8" xref="S3.E15.m1.8.8.8.8.8.8.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.24.24.2.23.23.23.23.2g" xref="S3.E15.m1.23.23.1.cmml">​</mo><mi id="S3.E15.m1.9.9.9.9.9.9" xref="S3.E15.m1.9.9.9.9.9.9.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.24.24.2.23.23.23.23.2h" xref="S3.E15.m1.23.23.1.cmml">​</mo><mi id="S3.E15.m1.10.10.10.10.10.10" xref="S3.E15.m1.10.10.10.10.10.10.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.24.24.2.23.23.23.23.2i" xref="S3.E15.m1.23.23.1.cmml">​</mo><mi id="S3.E15.m1.11.11.11.11.11.11" xref="S3.E15.m1.11.11.11.11.11.11.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.24.24.2.23.23.23.23.2j" xref="S3.E15.m1.23.23.1.cmml">​</mo><mi id="S3.E15.m1.12.12.12.12.12.12" xref="S3.E15.m1.12.12.12.12.12.12.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.24.24.2.23.23.23.23.2k" xref="S3.E15.m1.23.23.1.cmml">​</mo><mi id="S3.E15.m1.13.13.13.13.13.13" xref="S3.E15.m1.13.13.13.13.13.13.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.24.24.2.23.23.23.23.2l" xref="S3.E15.m1.23.23.1.cmml">​</mo><mi id="S3.E15.m1.14.14.14.14.14.14" xref="S3.E15.m1.14.14.14.14.14.14.cmml">y</mi><mo lspace="0.280em" rspace="0em" id="S3.E15.m1.24.24.2.23.23.23.23.2m" xref="S3.E15.m1.23.23.1.cmml">​</mo><mrow id="S3.E15.m1.24.24.2.23.23.23.23.1.1" xref="S3.E15.m1.23.23.1.cmml"><mo stretchy="false" id="S3.E15.m1.15.15.15.15.15.15" xref="S3.E15.m1.23.23.1.cmml">(</mo><mrow id="S3.E15.m1.24.24.2.23.23.23.23.1.1.1" xref="S3.E15.m1.23.23.1.cmml"><mi id="S3.E15.m1.16.16.16.16.16.16" xref="S3.E15.m1.16.16.16.16.16.16.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.24.24.2.23.23.23.23.1.1.1.1" xref="S3.E15.m1.23.23.1.cmml">​</mo><mi id="S3.E15.m1.17.17.17.17.17.17" xref="S3.E15.m1.17.17.17.17.17.17.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.24.24.2.23.23.23.23.1.1.1.1a" xref="S3.E15.m1.23.23.1.cmml">​</mo><msub id="S3.E15.m1.24.24.2.23.23.23.23.1.1.1.2" xref="S3.E15.m1.23.23.1.cmml"><mi id="S3.E15.m1.18.18.18.18.18.18" xref="S3.E15.m1.18.18.18.18.18.18.cmml">A</mi><mi id="S3.E15.m1.19.19.19.19.19.19.1" xref="S3.E15.m1.19.19.19.19.19.19.1.cmml">i</mi></msub></mrow><mo stretchy="false" id="S3.E15.m1.20.20.20.20.20.20" xref="S3.E15.m1.23.23.1.cmml">)</mo></mrow></mrow><mo id="S3.E15.m1.21.21.21.21.21.21" xref="S3.E15.m1.21.21.21.21.21.21.cmml">=</mo><mfrac id="S3.E15.m1.22.22.22.22.22.22" xref="S3.E15.m1.22.22.22.22.22.22.cmml"><mrow id="S3.E15.m1.22.22.22.22.22.22.2" xref="S3.E15.m1.22.22.22.22.22.22.2.cmml"><mi id="S3.E15.m1.22.22.22.22.22.22.2.2" xref="S3.E15.m1.22.22.22.22.22.22.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.2.1" xref="S3.E15.m1.22.22.22.22.22.22.2.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.2.3" xref="S3.E15.m1.22.22.22.22.22.22.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.2.1a" xref="S3.E15.m1.22.22.22.22.22.22.2.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.2.4" xref="S3.E15.m1.22.22.22.22.22.22.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.2.1b" xref="S3.E15.m1.22.22.22.22.22.22.2.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.2.5" xref="S3.E15.m1.22.22.22.22.22.22.2.5.cmml">t</mi><mo lspace="0.280em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.2.1c" xref="S3.E15.m1.22.22.22.22.22.22.2.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.2.6" xref="S3.E15.m1.22.22.22.22.22.22.2.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.2.1d" xref="S3.E15.m1.22.22.22.22.22.22.2.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.2.7" xref="S3.E15.m1.22.22.22.22.22.22.2.7.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.2.1e" xref="S3.E15.m1.22.22.22.22.22.22.2.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.2.8" xref="S3.E15.m1.22.22.22.22.22.22.2.8.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.2.1f" xref="S3.E15.m1.22.22.22.22.22.22.2.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.2.9" xref="S3.E15.m1.22.22.22.22.22.22.2.9.cmml">s</mi><mo lspace="0.280em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.2.1g" xref="S3.E15.m1.22.22.22.22.22.22.2.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.2.10" xref="S3.E15.m1.22.22.22.22.22.22.2.10.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.2.1h" xref="S3.E15.m1.22.22.22.22.22.22.2.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.2.11" xref="S3.E15.m1.22.22.22.22.22.22.2.11.cmml">f</mi><mo lspace="0.280em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.2.1i" xref="S3.E15.m1.22.22.22.22.22.22.2.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.2.12" xref="S3.E15.m1.22.22.22.22.22.22.2.12.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.2.1j" xref="S3.E15.m1.22.22.22.22.22.22.2.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.2.13" xref="S3.E15.m1.22.22.22.22.22.22.2.13.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.2.1k" xref="S3.E15.m1.22.22.22.22.22.22.2.1.cmml">​</mo><msub id="S3.E15.m1.22.22.22.22.22.22.2.14" xref="S3.E15.m1.22.22.22.22.22.22.2.14.cmml"><mi id="S3.E15.m1.22.22.22.22.22.22.2.14.2" xref="S3.E15.m1.22.22.22.22.22.22.2.14.2.cmml">N</mi><msub id="S3.E15.m1.22.22.22.22.22.22.2.14.3" xref="S3.E15.m1.22.22.22.22.22.22.2.14.3.cmml"><mi id="S3.E15.m1.22.22.22.22.22.22.2.14.3.2" xref="S3.E15.m1.22.22.22.22.22.22.2.14.3.2.cmml">σ</mi><mi id="S3.E15.m1.22.22.22.22.22.22.2.14.3.3" xref="S3.E15.m1.22.22.22.22.22.22.2.14.3.3.cmml">i</mi></msub></msub></mrow><mrow id="S3.E15.m1.22.22.22.22.22.22.3" xref="S3.E15.m1.22.22.22.22.22.22.3.cmml"><mi id="S3.E15.m1.22.22.22.22.22.22.3.2" xref="S3.E15.m1.22.22.22.22.22.22.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.3.1" xref="S3.E15.m1.22.22.22.22.22.22.3.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.3.3" xref="S3.E15.m1.22.22.22.22.22.22.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.3.1a" xref="S3.E15.m1.22.22.22.22.22.22.3.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.3.4" xref="S3.E15.m1.22.22.22.22.22.22.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.3.1b" xref="S3.E15.m1.22.22.22.22.22.22.3.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.3.5" xref="S3.E15.m1.22.22.22.22.22.22.3.5.cmml">t</mi><mo lspace="0.280em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.3.1c" xref="S3.E15.m1.22.22.22.22.22.22.3.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.3.6" xref="S3.E15.m1.22.22.22.22.22.22.3.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.3.1d" xref="S3.E15.m1.22.22.22.22.22.22.3.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.3.7" xref="S3.E15.m1.22.22.22.22.22.22.3.7.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.3.1e" xref="S3.E15.m1.22.22.22.22.22.22.3.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.3.8" xref="S3.E15.m1.22.22.22.22.22.22.3.8.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.3.1f" xref="S3.E15.m1.22.22.22.22.22.22.3.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.3.9" xref="S3.E15.m1.22.22.22.22.22.22.3.9.cmml">s</mi><mo lspace="0.280em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.3.1g" xref="S3.E15.m1.22.22.22.22.22.22.3.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.3.10" xref="S3.E15.m1.22.22.22.22.22.22.3.10.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.3.1h" xref="S3.E15.m1.22.22.22.22.22.22.3.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.3.11" xref="S3.E15.m1.22.22.22.22.22.22.3.11.cmml">f</mi><mo lspace="0.280em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.3.1i" xref="S3.E15.m1.22.22.22.22.22.22.3.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.3.12" xref="S3.E15.m1.22.22.22.22.22.22.3.12.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.3.1j" xref="S3.E15.m1.22.22.22.22.22.22.3.1.cmml">​</mo><mi id="S3.E15.m1.22.22.22.22.22.22.3.13" xref="S3.E15.m1.22.22.22.22.22.22.3.13.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.E15.m1.22.22.22.22.22.22.3.1k" xref="S3.E15.m1.22.22.22.22.22.22.3.1.cmml">​</mo><msub id="S3.E15.m1.22.22.22.22.22.22.3.14" xref="S3.E15.m1.22.22.22.22.22.22.3.14.cmml"><mi id="S3.E15.m1.22.22.22.22.22.22.3.14.2" xref="S3.E15.m1.22.22.22.22.22.22.3.14.2.cmml">N</mi><msub id="S3.E15.m1.22.22.22.22.22.22.3.14.3" xref="S3.E15.m1.22.22.22.22.22.22.3.14.3.cmml"><mi id="S3.E15.m1.22.22.22.22.22.22.3.14.3.2" xref="S3.E15.m1.22.22.22.22.22.22.3.14.3.2.cmml">σ</mi><mn id="S3.E15.m1.22.22.22.22.22.22.3.14.3.3" xref="S3.E15.m1.22.22.22.22.22.22.3.14.3.3.cmml">0</mn></msub></msub></mrow></mfrac></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E15.m1.24b"><apply id="S3.E15.m1.23.23.1.cmml" xref="S3.E15.m1.24.24.2"><eq id="S3.E15.m1.21.21.21.21.21.21.cmml" xref="S3.E15.m1.21.21.21.21.21.21"></eq><apply id="S3.E15.m1.23.23.1.1.cmml" xref="S3.E15.m1.24.24.2"><times id="S3.E15.m1.23.23.1.1.2.cmml" xref="S3.E15.m1.24.24.2"></times><ci id="S3.E15.m1.1.1.1.1.1.1.cmml" xref="S3.E15.m1.1.1.1.1.1.1">𝑃</ci><ci id="S3.E15.m1.2.2.2.2.2.2.cmml" xref="S3.E15.m1.2.2.2.2.2.2">𝑟</ci><ci id="S3.E15.m1.3.3.3.3.3.3.cmml" xref="S3.E15.m1.3.3.3.3.3.3">𝑖</ci><ci id="S3.E15.m1.4.4.4.4.4.4.cmml" xref="S3.E15.m1.4.4.4.4.4.4">𝑐</ci><ci id="S3.E15.m1.5.5.5.5.5.5.cmml" xref="S3.E15.m1.5.5.5.5.5.5">𝑒</ci><ci id="S3.E15.m1.6.6.6.6.6.6.cmml" xref="S3.E15.m1.6.6.6.6.6.6">𝑜</ci><ci id="S3.E15.m1.7.7.7.7.7.7.cmml" xref="S3.E15.m1.7.7.7.7.7.7">𝑓</ci><ci id="S3.E15.m1.8.8.8.8.8.8.cmml" xref="S3.E15.m1.8.8.8.8.8.8">𝐴</ci><ci id="S3.E15.m1.9.9.9.9.9.9.cmml" xref="S3.E15.m1.9.9.9.9.9.9">𝑛</ci><ci id="S3.E15.m1.10.10.10.10.10.10.cmml" xref="S3.E15.m1.10.10.10.10.10.10">𝑎</ci><ci id="S3.E15.m1.11.11.11.11.11.11.cmml" xref="S3.E15.m1.11.11.11.11.11.11">𝑟</ci><ci id="S3.E15.m1.12.12.12.12.12.12.cmml" xref="S3.E15.m1.12.12.12.12.12.12">𝑐</ci><ci id="S3.E15.m1.13.13.13.13.13.13.cmml" xref="S3.E15.m1.13.13.13.13.13.13">ℎ</ci><ci id="S3.E15.m1.14.14.14.14.14.14.cmml" xref="S3.E15.m1.14.14.14.14.14.14">𝑦</ci><apply id="S3.E15.m1.23.23.1.1.1.1.1.cmml" xref="S3.E15.m1.24.24.2"><times id="S3.E15.m1.23.23.1.1.1.1.1.1.cmml" xref="S3.E15.m1.24.24.2"></times><ci id="S3.E15.m1.16.16.16.16.16.16.cmml" xref="S3.E15.m1.16.16.16.16.16.16">𝑃</ci><ci id="S3.E15.m1.17.17.17.17.17.17.cmml" xref="S3.E15.m1.17.17.17.17.17.17">𝑜</ci><apply id="S3.E15.m1.23.23.1.1.1.1.1.4.cmml" xref="S3.E15.m1.24.24.2"><csymbol cd="ambiguous" id="S3.E15.m1.23.23.1.1.1.1.1.4.1.cmml" xref="S3.E15.m1.24.24.2">subscript</csymbol><ci id="S3.E15.m1.18.18.18.18.18.18.cmml" xref="S3.E15.m1.18.18.18.18.18.18">𝐴</ci><ci id="S3.E15.m1.19.19.19.19.19.19.1.cmml" xref="S3.E15.m1.19.19.19.19.19.19.1">𝑖</ci></apply></apply></apply><apply id="S3.E15.m1.22.22.22.22.22.22.cmml" xref="S3.E15.m1.22.22.22.22.22.22"><divide id="S3.E15.m1.22.22.22.22.22.22.1.cmml" xref="S3.E15.m1.22.22.22.22.22.22"></divide><apply id="S3.E15.m1.22.22.22.22.22.22.2.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2"><times id="S3.E15.m1.22.22.22.22.22.22.2.1.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.1"></times><ci id="S3.E15.m1.22.22.22.22.22.22.2.2.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.2">𝑇</ci><ci id="S3.E15.m1.22.22.22.22.22.22.2.3.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.3">𝑒</ci><ci id="S3.E15.m1.22.22.22.22.22.22.2.4.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.4">𝑠</ci><ci id="S3.E15.m1.22.22.22.22.22.22.2.5.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.5">𝑡</ci><ci id="S3.E15.m1.22.22.22.22.22.22.2.6.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.6">𝑙</ci><ci id="S3.E15.m1.22.22.22.22.22.22.2.7.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.7">𝑜</ci><ci id="S3.E15.m1.22.22.22.22.22.22.2.8.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.8">𝑠</ci><ci id="S3.E15.m1.22.22.22.22.22.22.2.9.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.9">𝑠</ci><ci id="S3.E15.m1.22.22.22.22.22.22.2.10.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.10">𝑜</ci><ci id="S3.E15.m1.22.22.22.22.22.22.2.11.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.11">𝑓</ci><ci id="S3.E15.m1.22.22.22.22.22.22.2.12.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.12">𝐶</ci><ci id="S3.E15.m1.22.22.22.22.22.22.2.13.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.13">𝑁</ci><apply id="S3.E15.m1.22.22.22.22.22.22.2.14.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.14"><csymbol cd="ambiguous" id="S3.E15.m1.22.22.22.22.22.22.2.14.1.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.14">subscript</csymbol><ci id="S3.E15.m1.22.22.22.22.22.22.2.14.2.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.14.2">𝑁</ci><apply id="S3.E15.m1.22.22.22.22.22.22.2.14.3.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.14.3"><csymbol cd="ambiguous" id="S3.E15.m1.22.22.22.22.22.22.2.14.3.1.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.14.3">subscript</csymbol><ci id="S3.E15.m1.22.22.22.22.22.22.2.14.3.2.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.14.3.2">𝜎</ci><ci id="S3.E15.m1.22.22.22.22.22.22.2.14.3.3.cmml" xref="S3.E15.m1.22.22.22.22.22.22.2.14.3.3">𝑖</ci></apply></apply></apply><apply id="S3.E15.m1.22.22.22.22.22.22.3.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3"><times id="S3.E15.m1.22.22.22.22.22.22.3.1.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.1"></times><ci id="S3.E15.m1.22.22.22.22.22.22.3.2.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.2">𝑇</ci><ci id="S3.E15.m1.22.22.22.22.22.22.3.3.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.3">𝑒</ci><ci id="S3.E15.m1.22.22.22.22.22.22.3.4.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.4">𝑠</ci><ci id="S3.E15.m1.22.22.22.22.22.22.3.5.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.5">𝑡</ci><ci id="S3.E15.m1.22.22.22.22.22.22.3.6.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.6">𝑙</ci><ci id="S3.E15.m1.22.22.22.22.22.22.3.7.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.7">𝑜</ci><ci id="S3.E15.m1.22.22.22.22.22.22.3.8.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.8">𝑠</ci><ci id="S3.E15.m1.22.22.22.22.22.22.3.9.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.9">𝑠</ci><ci id="S3.E15.m1.22.22.22.22.22.22.3.10.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.10">𝑜</ci><ci id="S3.E15.m1.22.22.22.22.22.22.3.11.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.11">𝑓</ci><ci id="S3.E15.m1.22.22.22.22.22.22.3.12.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.12">𝐶</ci><ci id="S3.E15.m1.22.22.22.22.22.22.3.13.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.13">𝑁</ci><apply id="S3.E15.m1.22.22.22.22.22.22.3.14.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.14"><csymbol cd="ambiguous" id="S3.E15.m1.22.22.22.22.22.22.3.14.1.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.14">subscript</csymbol><ci id="S3.E15.m1.22.22.22.22.22.22.3.14.2.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.14.2">𝑁</ci><apply id="S3.E15.m1.22.22.22.22.22.22.3.14.3.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.14.3"><csymbol cd="ambiguous" id="S3.E15.m1.22.22.22.22.22.22.3.14.3.1.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.14.3">subscript</csymbol><ci id="S3.E15.m1.22.22.22.22.22.22.3.14.3.2.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.14.3.2">𝜎</ci><cn type="integer" id="S3.E15.m1.22.22.22.22.22.22.3.14.3.3.cmml" xref="S3.E15.m1.22.22.22.22.22.22.3.14.3.3">0</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E15.m1.24c">\begin{split}Price\;of\;Anarchy\;(PoA_{i})=\frac{Test\;loss\;of\;CNN_{\sigma_{i}}}{Test\;loss\;of\;CNN_{\sigma_{0}}}\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(15)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<ul id="S3.I4" class="ltx_itemize">
<li id="S3.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i1.p1" class="ltx_para">
<p id="S3.I4.i1.p1.1" class="ltx_p">The PoA of the base model is always 1.</p>
</div>
</li>
<li id="S3.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i2.p1" class="ltx_para">
<p id="S3.I4.i2.p1.1" class="ltx_p">If PoA <math id="S3.I4.i2.p1.1.m1.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S3.I4.i2.p1.1.m1.1a"><mo id="S3.I4.i2.p1.1.m1.1.1" xref="S3.I4.i2.p1.1.m1.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S3.I4.i2.p1.1.m1.1b"><eq id="S3.I4.i2.p1.1.m1.1.1.cmml" xref="S3.I4.i2.p1.1.m1.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S3.I4.i2.p1.1.m1.1c">=</annotation></semantics></math> 1, the model is able to identify the patterns in the data, even in noisy conditions.</p>
</div>
</li>
<li id="S3.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i3.p1" class="ltx_para">
<p id="S3.I4.i3.p1.1" class="ltx_p">If PoA <math id="S3.I4.i3.p1.1.m1.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="S3.I4.i3.p1.1.m1.1a"><mo id="S3.I4.i3.p1.1.m1.1.1" xref="S3.I4.i3.p1.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S3.I4.i3.p1.1.m1.1b"><gt id="S3.I4.i3.p1.1.m1.1.1.cmml" xref="S3.I4.i3.p1.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S3.I4.i3.p1.1.m1.1c">&gt;</annotation></semantics></math> 1, the model is negatively impacted by the noise, and it loses useful information, so the noisy model performs worse than the base model.</p>
</div>
</li>
<li id="S3.I4.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i4.p1" class="ltx_para">
<p id="S3.I4.i4.p1.1" class="ltx_p">If PoA <math id="S3.I4.i4.p1.1.m1.1" class="ltx_Math" alttext="&lt;" display="inline"><semantics id="S3.I4.i4.p1.1.m1.1a"><mo id="S3.I4.i4.p1.1.m1.1.1" xref="S3.I4.i4.p1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S3.I4.i4.p1.1.m1.1b"><lt id="S3.I4.i4.p1.1.m1.1.1.cmml" xref="S3.I4.i4.p1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S3.I4.i4.p1.1.m1.1c">&lt;</annotation></semantics></math> 1, the model performs better than the base model, and the additive noise has improved the model’s generalization on unseen data.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">The proposed metrics provide insights into the effect of noise on the models’ accuracy, loss, and overall stability. The metrics also offer a clear reference point to monitor the changes in the models’ generalization and efficiency of predictions on test data.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Computational Results and Analysis</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we explore the use of noise as a means of improving generalization, stability, and privacy in deep neural networks. This is particularly important when data is distributed across multiple devices and access to sufficient data for training is limited. We aim to design stable and differentially private deep learning models that can generalize well in centralized and federated learning settings while preserving privacy. To achieve this goal, we will compare various methods of designing algorithms that can perform well in the presence of noise and evaluate their effectiveness for image classification. We will build upon the foundational work of Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite> and expand their findings through our experimentation.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">We start the experiments by selecting the appropriate CNN architecture. As mentioned earlier, the VC dimension is the measure of the model’s expressive power and is often used to analyze the model’s capacity to fit data. Training large CNN models with millions of trainable parameters requires significant computation resources and careful fine-tuning of the hyperparameters. We use CIFAR-10, a well-known benchmark dataset for image classification, where 40,000 images are used for training, 10,000 images for validation, and 10,000 for testing. Our experiments are designed around three network architectures with different model capacities determined by the number of parameters in the neural network architecture provided in Table <a href="#S4.T2" title="Table 2 ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>The models vary in the number of trainable parameters, a factor of model capacity that impacts the model’s ability to generalize on unseen data. Model 3 is over-parameterized</figcaption>
<table id="S4.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Architecture</th>
<th id="S4.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Trainable Param</th>
<th id="S4.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Non-trainable Param</th>
<th id="S4.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Total</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.2.1" class="ltx_tr">
<th id="S4.T2.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Model 1</th>
<td id="S4.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">22,784,938</td>
<td id="S4.T2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1,920</td>
<td id="S4.T2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">22,786,858</td>
</tr>
<tr id="S4.T2.1.3.2" class="ltx_tr">
<th id="S4.T2.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Model 2</th>
<td id="S4.T2.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r">2,396,330</td>
<td id="S4.T2.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r">1,896</td>
<td id="S4.T2.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r">2,397,226</td>
</tr>
<tr id="S4.T2.1.4.3" class="ltx_tr">
<th id="S4.T2.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">Model 3</th>
<td id="S4.T2.1.4.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">43,415,850</td>
<td id="S4.T2.1.4.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">3,968</td>
<td id="S4.T2.1.4.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">43,411,882</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">The CNN models are modifications of VGG-19 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>, and the key layers are the 2D convolutional, batch normalization, 2D max pooling, dropout, and dense layers. The architecture details for models 1, 2, and 3 are available in Tables <a href="#S4.T3" title="Table 3 ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, <a href="#S4.T4" title="Table 4 ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, and <a href="#S4.T5" title="Table 5 ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, respectively. The parameters of the CNN are configured as a batch size of 64, a learning rate of 0.001, and a momentum of 0.9. The local models are trained for 80 epochs. The three models with different numbers of parameters are compared in their efficiency of prediction, generalization, and stability under different noise levels and noise infusion mechanisms.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Architecture for Model 1</figcaption>
<table id="S4.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Layer Type</th>
<th id="S4.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Output Shape</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.2.1" class="ltx_tr">
<th id="S4.T3.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Conv2D</th>
<td id="S4.T3.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">(32, 32, 32)</td>
</tr>
<tr id="S4.T3.1.3.2" class="ltx_tr">
<th id="S4.T3.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T3.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r">(32, 32, 32)</td>
</tr>
<tr id="S4.T3.1.4.3" class="ltx_tr">
<th id="S4.T3.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T3.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r">(32, 32, 32)</td>
</tr>
<tr id="S4.T3.1.5.4" class="ltx_tr">
<th id="S4.T3.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T3.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r">(32, 32, 32)</td>
</tr>
<tr id="S4.T3.1.6.5" class="ltx_tr">
<th id="S4.T3.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">MaxPooling2D</th>
<td id="S4.T3.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r">(16, 16, 32)</td>
</tr>
<tr id="S4.T3.1.7.6" class="ltx_tr">
<th id="S4.T3.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Dropout</th>
<td id="S4.T3.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r">(16, 16, 32)</td>
</tr>
<tr id="S4.T3.1.8.7" class="ltx_tr">
<th id="S4.T3.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T3.1.8.7.2" class="ltx_td ltx_align_center ltx_border_r">(16, 16, 64)</td>
</tr>
<tr id="S4.T3.1.9.8" class="ltx_tr">
<th id="S4.T3.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T3.1.9.8.2" class="ltx_td ltx_align_center ltx_border_r">(16, 16, 64)</td>
</tr>
<tr id="S4.T3.1.10.9" class="ltx_tr">
<th id="S4.T3.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T3.1.10.9.2" class="ltx_td ltx_align_center ltx_border_r">(16, 16, 64)</td>
</tr>
<tr id="S4.T3.1.11.10" class="ltx_tr">
<th id="S4.T3.1.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T3.1.11.10.2" class="ltx_td ltx_align_center ltx_border_r">(16, 16, 64)</td>
</tr>
<tr id="S4.T3.1.12.11" class="ltx_tr">
<th id="S4.T3.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">MaxPooling2D</th>
<td id="S4.T3.1.12.11.2" class="ltx_td ltx_align_center ltx_border_r">(8, 8, 64)</td>
</tr>
<tr id="S4.T3.1.13.12" class="ltx_tr">
<th id="S4.T3.1.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Dropout</th>
<td id="S4.T3.1.13.12.2" class="ltx_td ltx_align_center ltx_border_r">(8, 8, 64)</td>
</tr>
<tr id="S4.T3.1.14.13" class="ltx_tr">
<th id="S4.T3.1.14.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T3.1.14.13.2" class="ltx_td ltx_align_center ltx_border_r">(8, 8, 128)</td>
</tr>
<tr id="S4.T3.1.15.14" class="ltx_tr">
<th id="S4.T3.1.15.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T3.1.15.14.2" class="ltx_td ltx_align_center ltx_border_r">(8, 8, 128)</td>
</tr>
<tr id="S4.T3.1.16.15" class="ltx_tr">
<th id="S4.T3.1.16.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T3.1.16.15.2" class="ltx_td ltx_align_center ltx_border_r">(8, 8, 128)</td>
</tr>
<tr id="S4.T3.1.17.16" class="ltx_tr">
<th id="S4.T3.1.17.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T3.1.17.16.2" class="ltx_td ltx_align_center ltx_border_r">(8, 8, 128)</td>
</tr>
<tr id="S4.T3.1.18.17" class="ltx_tr">
<th id="S4.T3.1.18.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">MaxPooling2D</th>
<td id="S4.T3.1.18.17.2" class="ltx_td ltx_align_center ltx_border_r">(4, 4, 128)</td>
</tr>
<tr id="S4.T3.1.19.18" class="ltx_tr">
<th id="S4.T3.1.19.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Dropout</th>
<td id="S4.T3.1.19.18.2" class="ltx_td ltx_align_center ltx_border_r">(4, 4, 128)</td>
</tr>
<tr id="S4.T3.1.20.19" class="ltx_tr">
<th id="S4.T3.1.20.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T3.1.20.19.2" class="ltx_td ltx_align_center ltx_border_r">(4, 4, 256)</td>
</tr>
<tr id="S4.T3.1.21.20" class="ltx_tr">
<th id="S4.T3.1.21.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T3.1.21.20.2" class="ltx_td ltx_align_center ltx_border_r">(4, 4, 256)</td>
</tr>
<tr id="S4.T3.1.22.21" class="ltx_tr">
<th id="S4.T3.1.22.21.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T3.1.22.21.2" class="ltx_td ltx_align_center ltx_border_r">(4, 4, 256)</td>
</tr>
<tr id="S4.T3.1.23.22" class="ltx_tr">
<th id="S4.T3.1.23.22.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T3.1.23.22.2" class="ltx_td ltx_align_center ltx_border_r">(4, 4, 256)</td>
</tr>
<tr id="S4.T3.1.24.23" class="ltx_tr">
<th id="S4.T3.1.24.23.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T3.1.24.23.2" class="ltx_td ltx_align_center ltx_border_r">(4, 4, 256)</td>
</tr>
<tr id="S4.T3.1.25.24" class="ltx_tr">
<th id="S4.T3.1.25.24.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">MaxPooling2D</th>
<td id="S4.T3.1.25.24.2" class="ltx_td ltx_align_center ltx_border_r">(2, 2, 256)</td>
</tr>
<tr id="S4.T3.1.26.25" class="ltx_tr">
<th id="S4.T3.1.26.25.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Dropout</th>
<td id="S4.T3.1.26.25.2" class="ltx_td ltx_align_center ltx_border_r">(2, 2, 256)</td>
</tr>
<tr id="S4.T3.1.27.26" class="ltx_tr">
<th id="S4.T3.1.27.26.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Flatten</th>
<td id="S4.T3.1.27.26.2" class="ltx_td ltx_align_center ltx_border_r">(1024,)</td>
</tr>
<tr id="S4.T3.1.28.27" class="ltx_tr">
<th id="S4.T3.1.28.27.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Dense</th>
<td id="S4.T3.1.28.27.2" class="ltx_td ltx_align_center ltx_border_r">(4096,)</td>
</tr>
<tr id="S4.T3.1.29.28" class="ltx_tr">
<th id="S4.T3.1.29.28.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Dropout</th>
<td id="S4.T3.1.29.28.2" class="ltx_td ltx_align_center ltx_border_r">(4096,)</td>
</tr>
<tr id="S4.T3.1.30.29" class="ltx_tr">
<th id="S4.T3.1.30.29.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Dense</th>
<td id="S4.T3.1.30.29.2" class="ltx_td ltx_align_center ltx_border_r">(4096,)</td>
</tr>
<tr id="S4.T3.1.31.30" class="ltx_tr">
<th id="S4.T3.1.31.30.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">Dense</th>
<td id="S4.T3.1.31.30.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">(10,)</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Architecture for Model 2</figcaption>
<table id="S4.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.1.1.1" class="ltx_tr">
<th id="S4.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Layer Type</th>
<th id="S4.T4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Output Shape</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.1.2.1" class="ltx_tr">
<th id="S4.T4.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Conv2D</th>
<td id="S4.T4.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">(32, 32, 32)</td>
</tr>
<tr id="S4.T4.1.3.2" class="ltx_tr">
<th id="S4.T4.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T4.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r">(32, 32, 32)</td>
</tr>
<tr id="S4.T4.1.4.3" class="ltx_tr">
<th id="S4.T4.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T4.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r">(32, 32, 32)</td>
</tr>
<tr id="S4.T4.1.5.4" class="ltx_tr">
<th id="S4.T4.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T4.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r">(32, 32, 32)</td>
</tr>
<tr id="S4.T4.1.6.5" class="ltx_tr">
<th id="S4.T4.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">MaxPooling2D</th>
<td id="S4.T4.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r">(16, 16, 32)</td>
</tr>
<tr id="S4.T4.1.7.6" class="ltx_tr">
<th id="S4.T4.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T4.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r">(16, 16, 64)</td>
</tr>
<tr id="S4.T4.1.8.7" class="ltx_tr">
<th id="S4.T4.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T4.1.8.7.2" class="ltx_td ltx_align_center ltx_border_r">(16, 16, 64)</td>
</tr>
<tr id="S4.T4.1.9.8" class="ltx_tr">
<th id="S4.T4.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T4.1.9.8.2" class="ltx_td ltx_align_center ltx_border_r">(16, 16, 64)</td>
</tr>
<tr id="S4.T4.1.10.9" class="ltx_tr">
<th id="S4.T4.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T4.1.10.9.2" class="ltx_td ltx_align_center ltx_border_r">(16, 16, 64)</td>
</tr>
<tr id="S4.T4.1.11.10" class="ltx_tr">
<th id="S4.T4.1.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">MaxPooling2D</th>
<td id="S4.T4.1.11.10.2" class="ltx_td ltx_align_center ltx_border_r">(8, 8, 64)</td>
</tr>
<tr id="S4.T4.1.12.11" class="ltx_tr">
<th id="S4.T4.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T4.1.12.11.2" class="ltx_td ltx_align_center ltx_border_r">(8, 8, 128)</td>
</tr>
<tr id="S4.T4.1.13.12" class="ltx_tr">
<th id="S4.T4.1.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T4.1.13.12.2" class="ltx_td ltx_align_center ltx_border_r">(8, 8, 128)</td>
</tr>
<tr id="S4.T4.1.14.13" class="ltx_tr">
<th id="S4.T4.1.14.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T4.1.14.13.2" class="ltx_td ltx_align_center ltx_border_r">(8, 8, 128)</td>
</tr>
<tr id="S4.T4.1.15.14" class="ltx_tr">
<th id="S4.T4.1.15.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T4.1.15.14.2" class="ltx_td ltx_align_center ltx_border_r">(8, 8, 128)</td>
</tr>
<tr id="S4.T4.1.16.15" class="ltx_tr">
<th id="S4.T4.1.16.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">MaxPooling2D</th>
<td id="S4.T4.1.16.15.2" class="ltx_td ltx_align_center ltx_border_r">(4, 4, 128)</td>
</tr>
<tr id="S4.T4.1.17.16" class="ltx_tr">
<th id="S4.T4.1.17.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Flatten</th>
<td id="S4.T4.1.17.16.2" class="ltx_td ltx_align_center ltx_border_r">(2048,)</td>
</tr>
<tr id="S4.T4.1.18.17" class="ltx_tr">
<th id="S4.T4.1.18.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Dropout</th>
<td id="S4.T4.1.18.17.2" class="ltx_td ltx_align_center ltx_border_r">(2048,)</td>
</tr>
<tr id="S4.T4.1.19.18" class="ltx_tr">
<th id="S4.T4.1.19.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Dense</th>
<td id="S4.T4.1.19.18.2" class="ltx_td ltx_align_center ltx_border_r">(1024,)</td>
</tr>
<tr id="S4.T4.1.20.19" class="ltx_tr">
<th id="S4.T4.1.20.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Dropout</th>
<td id="S4.T4.1.20.19.2" class="ltx_td ltx_align_center ltx_border_r">(1024,)</td>
</tr>
<tr id="S4.T4.1.21.20" class="ltx_tr">
<th id="S4.T4.1.21.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">Dense</th>
<td id="S4.T4.1.21.20.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">(10,)</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Architecture for Model 3</figcaption>
<table id="S4.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.1.1.1" class="ltx_tr">
<th id="S4.T5.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Layer Type</th>
<th id="S4.T5.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Output shape</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.1.2.1" class="ltx_tr">
<th id="S4.T5.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Conv2D</th>
<td id="S4.T5.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">(32, 32, 32)</td>
</tr>
<tr id="S4.T5.1.3.2" class="ltx_tr">
<th id="S4.T5.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T5.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r">(32, 32, 32)</td>
</tr>
<tr id="S4.T5.1.4.3" class="ltx_tr">
<th id="S4.T5.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T5.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r">(32, 32, 32)</td>
</tr>
<tr id="S4.T5.1.5.4" class="ltx_tr">
<th id="S4.T5.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T5.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r">(32, 32, 32)</td>
</tr>
<tr id="S4.T5.1.6.5" class="ltx_tr">
<th id="S4.T5.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">MaxPooling2D</th>
<td id="S4.T5.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r">(16, 16, 32)</td>
</tr>
<tr id="S4.T5.1.7.6" class="ltx_tr">
<th id="S4.T5.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T5.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r">(16, 16, 64)</td>
</tr>
<tr id="S4.T5.1.8.7" class="ltx_tr">
<th id="S4.T5.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T5.1.8.7.2" class="ltx_td ltx_align_center ltx_border_r">(16, 16, 64)</td>
</tr>
<tr id="S4.T5.1.9.8" class="ltx_tr">
<th id="S4.T5.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T5.1.9.8.2" class="ltx_td ltx_align_center ltx_border_r">(16, 16, 64)</td>
</tr>
<tr id="S4.T5.1.10.9" class="ltx_tr">
<th id="S4.T5.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T5.1.10.9.2" class="ltx_td ltx_align_center ltx_border_r">(16, 16, 64)</td>
</tr>
<tr id="S4.T5.1.11.10" class="ltx_tr">
<th id="S4.T5.1.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">MaxPooling2D</th>
<td id="S4.T5.1.11.10.2" class="ltx_td ltx_align_center ltx_border_r">(8, 8, 64)</td>
</tr>
<tr id="S4.T5.1.12.11" class="ltx_tr">
<th id="S4.T5.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T5.1.12.11.2" class="ltx_td ltx_align_center ltx_border_r">(8, 8, 128)</td>
</tr>
<tr id="S4.T5.1.13.12" class="ltx_tr">
<th id="S4.T5.1.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T5.1.13.12.2" class="ltx_td ltx_align_center ltx_border_r">(8, 8, 128)</td>
</tr>
<tr id="S4.T5.1.14.13" class="ltx_tr">
<th id="S4.T5.1.14.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T5.1.14.13.2" class="ltx_td ltx_align_center ltx_border_r">(8, 8, 128)</td>
</tr>
<tr id="S4.T5.1.15.14" class="ltx_tr">
<th id="S4.T5.1.15.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T5.1.15.14.2" class="ltx_td ltx_align_center ltx_border_r">(8, 8, 128)</td>
</tr>
<tr id="S4.T5.1.16.15" class="ltx_tr">
<th id="S4.T5.1.16.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">MaxPooling2D</th>
<td id="S4.T5.1.16.15.2" class="ltx_td ltx_align_center ltx_border_r">(4, 4, 128)</td>
</tr>
<tr id="S4.T5.1.17.16" class="ltx_tr">
<th id="S4.T5.1.17.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T5.1.17.16.2" class="ltx_td ltx_align_center ltx_border_r">(4, 4, 256)</td>
</tr>
<tr id="S4.T5.1.18.17" class="ltx_tr">
<th id="S4.T5.1.18.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T5.1.18.17.2" class="ltx_td ltx_align_center ltx_border_r">(4, 4, 256)</td>
</tr>
<tr id="S4.T5.1.19.18" class="ltx_tr">
<th id="S4.T5.1.19.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T5.1.19.18.2" class="ltx_td ltx_align_center ltx_border_r">(4, 4, 256)</td>
</tr>
<tr id="S4.T5.1.20.19" class="ltx_tr">
<th id="S4.T5.1.20.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T5.1.20.19.2" class="ltx_td ltx_align_center ltx_border_r">(4, 4, 256)</td>
</tr>
<tr id="S4.T5.1.21.20" class="ltx_tr">
<th id="S4.T5.1.21.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T5.1.21.20.2" class="ltx_td ltx_align_center ltx_border_r">(4, 4, 256)</td>
</tr>
<tr id="S4.T5.1.22.21" class="ltx_tr">
<th id="S4.T5.1.22.21.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">MaxPooling2D</th>
<td id="S4.T5.1.22.21.2" class="ltx_td ltx_align_center ltx_border_r">(2, 2, 256)</td>
</tr>
<tr id="S4.T5.1.23.22" class="ltx_tr">
<th id="S4.T5.1.23.22.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Dropout</th>
<td id="S4.T5.1.23.22.2" class="ltx_td ltx_align_center ltx_border_r">(2, 2, 256)</td>
</tr>
<tr id="S4.T5.1.24.23" class="ltx_tr">
<th id="S4.T5.1.24.23.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T5.1.24.23.2" class="ltx_td ltx_align_center ltx_border_r">(2, 2, 512)</td>
</tr>
<tr id="S4.T5.1.25.24" class="ltx_tr">
<th id="S4.T5.1.25.24.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T5.1.25.24.2" class="ltx_td ltx_align_center ltx_border_r">(2, 2, 512)</td>
</tr>
<tr id="S4.T5.1.26.25" class="ltx_tr">
<th id="S4.T5.1.26.25.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T5.1.26.25.2" class="ltx_td ltx_align_center ltx_border_r">(2, 2, 512)</td>
</tr>
<tr id="S4.T5.1.27.26" class="ltx_tr">
<th id="S4.T5.1.27.26.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">BatchNormalization</th>
<td id="S4.T5.1.27.26.2" class="ltx_td ltx_align_center ltx_border_r">(2, 2, 512)</td>
</tr>
<tr id="S4.T5.1.28.27" class="ltx_tr">
<th id="S4.T5.1.28.27.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Conv2D</th>
<td id="S4.T5.1.28.27.2" class="ltx_td ltx_align_center ltx_border_r">(2, 2, 512)</td>
</tr>
<tr id="S4.T5.1.29.28" class="ltx_tr">
<th id="S4.T5.1.29.28.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">MaxPooling2D</th>
<td id="S4.T5.1.29.28.2" class="ltx_td ltx_align_center ltx_border_r">(1, 1, 512)</td>
</tr>
<tr id="S4.T5.1.30.29" class="ltx_tr">
<th id="S4.T5.1.30.29.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Dropout</th>
<td id="S4.T5.1.30.29.2" class="ltx_td ltx_align_center ltx_border_r">(1, 1, 512)</td>
</tr>
<tr id="S4.T5.1.31.30" class="ltx_tr">
<th id="S4.T5.1.31.30.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Flatten</th>
<td id="S4.T5.1.31.30.2" class="ltx_td ltx_align_center ltx_border_r">(512,)</td>
</tr>
<tr id="S4.T5.1.32.31" class="ltx_tr">
<th id="S4.T5.1.32.31.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Dense</th>
<td id="S4.T5.1.32.31.2" class="ltx_td ltx_align_center ltx_border_r">(4096,)</td>
</tr>
<tr id="S4.T5.1.33.32" class="ltx_tr">
<th id="S4.T5.1.33.32.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Dropout</th>
<td id="S4.T5.1.33.32.2" class="ltx_td ltx_align_center ltx_border_r">(4096,)</td>
</tr>
<tr id="S4.T5.1.34.33" class="ltx_tr">
<th id="S4.T5.1.34.33.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Dense</th>
<td id="S4.T5.1.34.33.2" class="ltx_td ltx_align_center ltx_border_r">(8192,)</td>
</tr>
<tr id="S4.T5.1.35.34" class="ltx_tr">
<th id="S4.T5.1.35.34.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">Dense</th>
<td id="S4.T5.1.35.34.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">(10,)</td>
</tr>
</tbody>
</table>
</figure>
<section id="S4.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Experiment 1: CNN with Gaussian noise hidden layers in Centralized Setting</h3>

<div id="S4.SSx1.p1" class="ltx_para">
<p id="S4.SSx1.p1.1" class="ltx_p">Leveraging the properties of training with noise, we design a CNN with Gaussian noise hidden layers, an innovative approach to enhance the robustness and generalization capabilities of deep learning models. In this design illustrated in Figure<a href="#S4.F4" title="Figure 4 ‣ Experiment 1: CNN with Gaussian noise hidden layers in Centralized Setting ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, Gaussian noise is intentionally added as a form of regularization to hidden layers within the CNN architecture.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2311.05790/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>A simplified illustration of the CNN architecture with Gaussian noise layer.</figcaption>
</figure>
<div id="S4.SSx1.p2" class="ltx_para">
<p id="S4.SSx1.p2.1" class="ltx_p">Training with Gaussian noise hidden layers involves inserting uncorrelated layers of Gaussian noise that will add a randomly generated value within the range of the specified standard deviation to the activation of the previous layer during training. Uncorrelated noise sources are statistically independent.</p>
</div>
<div id="S4.SSx1.p3" class="ltx_para">
<p id="S4.SSx1.p3.1" class="ltx_p">In the first set of experiments, we evaluate the performance of three CNN models with Gaussian noise hidden layers presented in Figure <a href="#S4.F5" title="Figure 5 ‣ Experiment 1: CNN with Gaussian noise hidden layers in Centralized Setting ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2311.05790/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Visual representation of the CNN models with Gaussian noise layers.</figcaption>
</figure>
<div id="S4.SSx1.p4" class="ltx_para">
<p id="S4.SSx1.p4.7" class="ltx_p">For the implementation of the models in this study, we insert the noise layers before the convolutional layers, followed by a batch normalization layer.
Let us assume: 
<br class="ltx_break"><math id="S4.SSx1.p4.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S4.SSx1.p4.1.m1.1a"><mi id="S4.SSx1.p4.1.m1.1.1" xref="S4.SSx1.p4.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.SSx1.p4.1.m1.1b"><ci id="S4.SSx1.p4.1.m1.1.1.cmml" xref="S4.SSx1.p4.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx1.p4.1.m1.1c">x</annotation></semantics></math>: The output of the layer before the convolutional layer 
<br class="ltx_break"><math id="S4.SSx1.p4.2.m2.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S4.SSx1.p4.2.m2.1a"><mi id="S4.SSx1.p4.2.m2.1.1" xref="S4.SSx1.p4.2.m2.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S4.SSx1.p4.2.m2.1b"><ci id="S4.SSx1.p4.2.m2.1.1.cmml" xref="S4.SSx1.p4.2.m2.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx1.p4.2.m2.1c">z</annotation></semantics></math>: A randomly generated number from Gaussian distribution with mean, <math id="S4.SSx1.p4.3.m3.1" class="ltx_Math" alttext="\mu=0" display="inline"><semantics id="S4.SSx1.p4.3.m3.1a"><mrow id="S4.SSx1.p4.3.m3.1.1" xref="S4.SSx1.p4.3.m3.1.1.cmml"><mi id="S4.SSx1.p4.3.m3.1.1.2" xref="S4.SSx1.p4.3.m3.1.1.2.cmml">μ</mi><mo id="S4.SSx1.p4.3.m3.1.1.1" xref="S4.SSx1.p4.3.m3.1.1.1.cmml">=</mo><mn id="S4.SSx1.p4.3.m3.1.1.3" xref="S4.SSx1.p4.3.m3.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SSx1.p4.3.m3.1b"><apply id="S4.SSx1.p4.3.m3.1.1.cmml" xref="S4.SSx1.p4.3.m3.1.1"><eq id="S4.SSx1.p4.3.m3.1.1.1.cmml" xref="S4.SSx1.p4.3.m3.1.1.1"></eq><ci id="S4.SSx1.p4.3.m3.1.1.2.cmml" xref="S4.SSx1.p4.3.m3.1.1.2">𝜇</ci><cn type="integer" id="S4.SSx1.p4.3.m3.1.1.3.cmml" xref="S4.SSx1.p4.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx1.p4.3.m3.1c">\mu=0</annotation></semantics></math> and standard deviation of <math id="S4.SSx1.p4.4.m4.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SSx1.p4.4.m4.1a"><mi id="S4.SSx1.p4.4.m4.1.1" xref="S4.SSx1.p4.4.m4.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S4.SSx1.p4.4.m4.1b"><ci id="S4.SSx1.p4.4.m4.1.1.cmml" xref="S4.SSx1.p4.4.m4.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx1.p4.4.m4.1c">\sigma</annotation></semantics></math> 
<br class="ltx_break"><math id="S4.SSx1.p4.5.m5.1" class="ltx_math_unparsed" alttext="x\prime" display="inline"><semantics id="S4.SSx1.p4.5.m5.1a"><mrow id="S4.SSx1.p4.5.m5.1b"><mi id="S4.SSx1.p4.5.m5.1.1">x</mi><mo lspace="0em" id="S4.SSx1.p4.5.m5.1.2">′</mo></mrow><annotation encoding="application/x-tex" id="S4.SSx1.p4.5.m5.1c">x\prime</annotation></semantics></math>: The output of the Gaussian noise layer, <math id="S4.SSx1.p4.6.m6.1" class="ltx_math_unparsed" alttext="x\prime=x+z" display="inline"><semantics id="S4.SSx1.p4.6.m6.1a"><mrow id="S4.SSx1.p4.6.m6.1b"><mi id="S4.SSx1.p4.6.m6.1.1">x</mi><mo lspace="0em" rspace="0.1389em" id="S4.SSx1.p4.6.m6.1.2">′</mo><mo lspace="0.1389em" id="S4.SSx1.p4.6.m6.1.3">=</mo><mi id="S4.SSx1.p4.6.m6.1.4">x</mi><mo id="S4.SSx1.p4.6.m6.1.5">+</mo><mi id="S4.SSx1.p4.6.m6.1.6">z</mi></mrow><annotation encoding="application/x-tex" id="S4.SSx1.p4.6.m6.1c">x\prime=x+z</annotation></semantics></math>. 
<br class="ltx_break"><math id="S4.SSx1.p4.7.m7.1" class="ltx_math_unparsed" alttext="x\prime\prime" display="inline"><semantics id="S4.SSx1.p4.7.m7.1a"><mrow id="S4.SSx1.p4.7.m7.1b"><mi id="S4.SSx1.p4.7.m7.1.1">x</mi><mo lspace="0em" rspace="0em" id="S4.SSx1.p4.7.m7.1.2">′</mo><mo lspace="0em" id="S4.SSx1.p4.7.m7.1.3">′</mo></mrow><annotation encoding="application/x-tex" id="S4.SSx1.p4.7.m7.1c">x\prime\prime</annotation></semantics></math>: The output of the batch normalization layer obtained after passing the output of the convolutional layer through a batch normalization layer:</p>
<table id="S4.E16" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S4.E16.m1.1" class="ltx_math_unparsed" alttext="x\prime\prime=(\frac{x\prime-\mu\prime}{\sigma\prime})*\alpha+\beta" display="block"><semantics id="S4.E16.m1.1a"><mrow id="S4.E16.m1.1b"><mi id="S4.E16.m1.1.1">x</mi><mo lspace="0em" rspace="0em" id="S4.E16.m1.1.2">′</mo><mo lspace="0em" rspace="0.1389em" id="S4.E16.m1.1.3">′</mo><mo lspace="0.1389em" id="S4.E16.m1.1.4">=</mo><mrow id="S4.E16.m1.1.5"><mo stretchy="false" id="S4.E16.m1.1.5.1">(</mo><mfrac id="S4.E16.m1.1.5.2"><mrow id="S4.E16.m1.1.5.2.2"><mi id="S4.E16.m1.1.5.2.2.1">x</mi><mo lspace="0em" rspace="0em" id="S4.E16.m1.1.5.2.2.2">′</mo><mo id="S4.E16.m1.1.5.2.2.3">−</mo><mi id="S4.E16.m1.1.5.2.2.4">μ</mi><mo lspace="0em" id="S4.E16.m1.1.5.2.2.5">′</mo></mrow><mrow id="S4.E16.m1.1.5.2.3"><mi id="S4.E16.m1.1.5.2.3.1">σ</mi><mo lspace="0em" id="S4.E16.m1.1.5.2.3.2">′</mo></mrow></mfrac><mo rspace="0.055em" stretchy="false" id="S4.E16.m1.1.5.3">)</mo></mrow><mo rspace="0.222em" id="S4.E16.m1.1.6">∗</mo><mi id="S4.E16.m1.1.7">α</mi><mo id="S4.E16.m1.1.8">+</mo><mi id="S4.E16.m1.1.9">β</mi></mrow><annotation encoding="application/x-tex" id="S4.E16.m1.1c">x\prime\prime=(\frac{x\prime-\mu\prime}{\sigma\prime})*\alpha+\beta</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(16)</span></td>
</tr></tbody>
</table>
<p id="S4.SSx1.p4.11" class="ltx_p">Where <math id="S4.SSx1.p4.8.m1.1" class="ltx_math_unparsed" alttext="\mu\prime" display="inline"><semantics id="S4.SSx1.p4.8.m1.1a"><mrow id="S4.SSx1.p4.8.m1.1b"><mi id="S4.SSx1.p4.8.m1.1.1">μ</mi><mo lspace="0em" id="S4.SSx1.p4.8.m1.1.2">′</mo></mrow><annotation encoding="application/x-tex" id="S4.SSx1.p4.8.m1.1c">\mu\prime</annotation></semantics></math> and <math id="S4.SSx1.p4.9.m2.1" class="ltx_math_unparsed" alttext="\sigma\prime" display="inline"><semantics id="S4.SSx1.p4.9.m2.1a"><mrow id="S4.SSx1.p4.9.m2.1b"><mi id="S4.SSx1.p4.9.m2.1.1">σ</mi><mo lspace="0em" id="S4.SSx1.p4.9.m2.1.2">′</mo></mrow><annotation encoding="application/x-tex" id="S4.SSx1.p4.9.m2.1c">\sigma\prime</annotation></semantics></math> are the mean and standard deviation of the neuron’s output of the activation function in the convolutional layer, and <math id="S4.SSx1.p4.10.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SSx1.p4.10.m3.1a"><mi id="S4.SSx1.p4.10.m3.1.1" xref="S4.SSx1.p4.10.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SSx1.p4.10.m3.1b"><ci id="S4.SSx1.p4.10.m3.1.1.cmml" xref="S4.SSx1.p4.10.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx1.p4.10.m3.1c">\alpha</annotation></semantics></math> and <math id="S4.SSx1.p4.11.m4.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S4.SSx1.p4.11.m4.1a"><mi id="S4.SSx1.p4.11.m4.1.1" xref="S4.SSx1.p4.11.m4.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S4.SSx1.p4.11.m4.1b"><ci id="S4.SSx1.p4.11.m4.1.1.cmml" xref="S4.SSx1.p4.11.m4.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx1.p4.11.m4.1c">\beta</annotation></semantics></math> are trainable parameters used for rescaling and shifting the values from the previous operations. As the training continues, the data goes through multiple blocks of Gaussian noise, convolutional, and batch normalization layers. Batch normalization prevents the accumulation of noise throughout the network.</p>
</div>
<div id="S4.SSx1.p5" class="ltx_para">
<p id="S4.SSx1.p5.1" class="ltx_p">Figure <a href="#S4.F6" title="Figure 6 ‣ Experiment 1: CNN with Gaussian noise hidden layers in Centralized Setting ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> compares accuracy and loss obtained from training the models under different noise levels in a centralized framework. The standard deviation is selected from Gaussian distribution with 20 levels between <math id="S4.SSx1.p5.1.m1.2" class="ltx_Math" alttext="\{0,1\}" display="inline"><semantics id="S4.SSx1.p5.1.m1.2a"><mrow id="S4.SSx1.p5.1.m1.2.3.2" xref="S4.SSx1.p5.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.SSx1.p5.1.m1.2.3.2.1" xref="S4.SSx1.p5.1.m1.2.3.1.cmml">{</mo><mn id="S4.SSx1.p5.1.m1.1.1" xref="S4.SSx1.p5.1.m1.1.1.cmml">0</mn><mo id="S4.SSx1.p5.1.m1.2.3.2.2" xref="S4.SSx1.p5.1.m1.2.3.1.cmml">,</mo><mn id="S4.SSx1.p5.1.m1.2.2" xref="S4.SSx1.p5.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S4.SSx1.p5.1.m1.2.3.2.3" xref="S4.SSx1.p5.1.m1.2.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SSx1.p5.1.m1.2b"><set id="S4.SSx1.p5.1.m1.2.3.1.cmml" xref="S4.SSx1.p5.1.m1.2.3.2"><cn type="integer" id="S4.SSx1.p5.1.m1.1.1.cmml" xref="S4.SSx1.p5.1.m1.1.1">0</cn><cn type="integer" id="S4.SSx1.p5.1.m1.2.2.cmml" xref="S4.SSx1.p5.1.m1.2.2">1</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx1.p5.1.m1.2c">\{0,1\}</annotation></semantics></math>. Setting the standard deviation to zero refers to the base model.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2311.05790/assets/x6.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>The optimal test accuracy and loss value are marked with the associated training accuracy and loss. Stable models that perform well at higher noise levels are better candidates for federated learning. </figcaption>
</figure>
<div id="S4.SSx1.p6" class="ltx_para">
<p id="S4.SSx1.p6.2" class="ltx_p">Models 1 and 3 offer similar trends; as noise increases, the accuracy drops, and loss increases further from the base model. In models 1 and 3, the optimal test accuracy and loss are achieved when <math id="S4.SSx1.p6.1.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SSx1.p6.1.m1.1a"><mi id="S4.SSx1.p6.1.m1.1.1" xref="S4.SSx1.p6.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S4.SSx1.p6.1.m1.1b"><ci id="S4.SSx1.p6.1.m1.1.1.cmml" xref="S4.SSx1.p6.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx1.p6.1.m1.1c">\sigma</annotation></semantics></math> are 0.32 and 0.21, respectively. The drop in performance as a result of increasing the noise suggests that the models have difficulty fitting the noisy data when <math id="S4.SSx1.p6.2.m2.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SSx1.p6.2.m2.1a"><mi id="S4.SSx1.p6.2.m2.1.1" xref="S4.SSx1.p6.2.m2.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S4.SSx1.p6.2.m2.1b"><ci id="S4.SSx1.p6.2.m2.1.1.cmml" xref="S4.SSx1.p6.2.m2.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx1.p6.2.m2.1c">\sigma</annotation></semantics></math> is high.</p>
</div>
<div id="S4.SSx1.p7" class="ltx_para">
<p id="S4.SSx1.p7.1" class="ltx_p">Unlike models 1 and 3, model 2 can maintain consistent performance with noisy data, suggesting that the model is the most stable among the three. In model 2, the optimal test accuracy and loss are achieved when <math id="S4.SSx1.p7.1.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SSx1.p7.1.m1.1a"><mi id="S4.SSx1.p7.1.m1.1.1" xref="S4.SSx1.p7.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S4.SSx1.p7.1.m1.1b"><ci id="S4.SSx1.p7.1.m1.1.1.cmml" xref="S4.SSx1.p7.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx1.p7.1.m1.1c">\sigma</annotation></semantics></math> is 0.58, which is significantly higher than in models 1 and 3. While all three models yield the optimal accuracy of approximately 0.82, maintaining a high accuracy and loss in the presence of higher noise levels demonstrates that model 2 is better at generalizing to unseen data. Compared to models 1 and 3, model 2 experiences a less rapid performance degradation at higher noise levels.</p>
</div>
<div id="S4.SSx1.p8" class="ltx_para">
<p id="S4.SSx1.p8.1" class="ltx_p">Often, better privacy guarantees are achieved at the expense of worse accuracy and loss, so we strive to find a systematic way to reach a balance between accuracy and privacy. However, the balance is not possible without fine-tuning the noise level during training while monitoring its impact on test data. To this end, we explore SNR, PoS, and PoA to measure the trade-off between performance efficiency and privacy under noise.
Figure <a href="#S4.F7" title="Figure 7 ‣ Experiment 1: CNN with Gaussian noise hidden layers in Centralized Setting ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> demonstrates the SNR, PoS, and PoA values for the three models with Gaussian noise hidden layers (<math id="S4.SSx1.p8.1.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SSx1.p8.1.m1.1a"><mi id="S4.SSx1.p8.1.m1.1.1" xref="S4.SSx1.p8.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S4.SSx1.p8.1.m1.1b"><ci id="S4.SSx1.p8.1.m1.1.1.cmml" xref="S4.SSx1.p8.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx1.p8.1.m1.1c">\sigma</annotation></semantics></math> between 0 and 1).</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2311.05790/assets/x7.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Increasing the noise levels decreases model utility. However, stable models suffer less as the noise levels are heightened, offering consistent performance under higher noise levels.</figcaption>
</figure>
<div id="S4.SSx1.p9" class="ltx_para">
<p id="S4.SSx1.p9.1" class="ltx_p">Since the range of SNR is problem-dependent, we focus on the fluctuations of SNR at different noise levels to compare the models.</p>
</div>
<div id="S4.SSx1.p10" class="ltx_para">
<p id="S4.SSx1.p10.1" class="ltx_p">In models 1 and 3, the value of SNR is initially higher but drops significantly as we increase the noise. This means at lower noise levels, the model is effective in distinguishing the signal, but as noise increases, the model becomes overwhelmed and can not handle noise effectively. However, model 2 stands out as having relatively consistent SNR values at higher noise levels. This implies the model’s ability to remain relatively stable, even in the presence of higher noise levels.</p>
</div>
<div id="S4.SSx1.p11" class="ltx_para">
<p id="S4.SSx1.p11.1" class="ltx_p">Training the models at the noise level that maximizes SNR provides the highest test accuracy and sets the balance between stability and accuracy in the presence of noise. Under differential privacy, the maximum SNR guarantees privacy without loss of accuracy. While finding the balance is ideal, in federated learning, privacy is prioritized over accuracy when dealing with sensitive data. PoS and PoA measure the impact of noise on test accuracy and loss compared to the base model. In Model 2, the PoS and PoA remain consistent despite the increase in the noise level. Model 2 offers a trade-off between performance and privacy, where accuracy and loss are stable under higher noise levels. In model 2, while the optimal SNR identifies the noise level for the perfect balance between accuracy and privacy at 0.58, we can further increase the noise, and the accuracy degrades by less than 4<math id="S4.SSx1.p11.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SSx1.p11.1.m1.1a"><mo id="S4.SSx1.p11.1.m1.1.1" xref="S4.SSx1.p11.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SSx1.p11.1.m1.1b"><csymbol cd="latexml" id="S4.SSx1.p11.1.m1.1.1.cmml" xref="S4.SSx1.p11.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx1.p11.1.m1.1c">\%</annotation></semantics></math>. Model 2 is a potential candidate for cases where privacy and stability take precedence over achieving the highest accuracy, such as federated learning applications.</p>
</div>
<div id="S4.SSx1.p12" class="ltx_para">
<p id="S4.SSx1.p12.1" class="ltx_p">Ultimately, selecting the appropriate model depends on the specifics and requirements of the problem, whether it prioritizes accuracy, privacy, or stability. These analyses provide insights into the trade-offs and strengths of each model under different noise levels.</p>
</div>
<div id="S4.SSx1.p13" class="ltx_para">
<p id="S4.SSx1.p13.1" class="ltx_p">Overall, a comparison of the performance of the three models under various noise conditions measured by SNR, PoS, and PoA suggests that in models with higher stability, PoS and PoA remain relatively consistent. Given the overlap between the definitions of stability and privacy, we can conclude that models with relatively consistent PoS and PoA can provide better privacy protection guarantees without drastic degradation of accuracy.</p>
</div>
</section>
<section id="S4.SSx2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Experiment 2: CNN with Multiple Gaussian Noise Layers vs. a Single Layer</h3>

<div id="S4.SSx2.p1" class="ltx_para">
<p id="S4.SSx2.p1.1" class="ltx_p">When an image is passed through the convolutional layers, the network learns different complex features of the image, such as the edges and the texture. The network learns patterns and objects from the later convolutional layers as training continues. We use feature visualization to gain insight into the learning procedure of a CNN with Gaussian noise hidden layers inserted before the convolutional layer, focusing on the first layers of model 1. Figure <a href="#S4.F8" title="Figure 8 ‣ Experiment 2: CNN with Multiple Gaussian Noise Layers vs. a Single Layer ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> is a visual representation of the output of the first two convolutional layers of model 1, where a single image is fed into the network.</p>
</div>
<figure id="S4.F8" class="ltx_figure"><img src="/html/2311.05790/assets/x8.png" id="S4.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>CNN feature maps</figcaption>
</figure>
<div id="S4.SSx2.p2" class="ltx_para">
<p id="S4.SSx2.p2.1" class="ltx_p">The first two convolutional layers have 32 filters. The figure includes three sets of feature maps from the initial training steps extracted from the model without noise and the noisy model, where a noise layer is inserted before the second convolutional layer. The first column represents the feature maps from the input layer of CNN models. The slight variations in the maps are due to the inherent variations in training a neural network model. The lower layers of the CNN are responsible for learning the edges and textures in the image. The bright spots on the feature map indicate that the region was most activated in its corresponding map in the prior layer.</p>
</div>
<div id="S4.SSx2.p3" class="ltx_para">
<p id="S4.SSx2.p3.1" class="ltx_p">In training with noise, we utilize the idea of stochastic resonance and use noise to enhance weak signals. Figure <a href="#S4.F9" title="Figure 9 ‣ Experiment 2: CNN with Multiple Gaussian Noise Layers vs. a Single Layer ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> is a closer look at the feature map. For a relatively similar map in layer 1, the noise-infused maps in the second and third rows have led to better identification of edges, and more key regions are activated.</p>
</div>
<figure id="S4.F9" class="ltx_figure"><img src="/html/2311.05790/assets/x9.png" id="S4.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>The optimal noise level improves generalization by helping the deep learning model better distinguish the objects during training.</figcaption>
</figure>
<div id="S4.SSx2.p4" class="ltx_para">
<p id="S4.SSx2.p4.1" class="ltx_p">We emphasize that uncorrelated noise sources are critical when designing CNN models with Gaussian noise hidden layers. If noise layers are correlated, we must consider different magnitudes and phase variations when combining the additive noise. We can ensure that the noise layers are uncorrelated by assigning a unique random seed at each layer. Derived from the signal processing conventions, we can compute the total additive noise in the system for multiple statistically independent noise sources.</p>
</div>
<div id="S4.SSx2.p5" class="ltx_para">
<p id="S4.SSx2.p5.4" class="ltx_p">Let us assume that <math id="S4.SSx2.p5.1.m1.1" class="ltx_Math" alttext="G_{1}" display="inline"><semantics id="S4.SSx2.p5.1.m1.1a"><msub id="S4.SSx2.p5.1.m1.1.1" xref="S4.SSx2.p5.1.m1.1.1.cmml"><mi id="S4.SSx2.p5.1.m1.1.1.2" xref="S4.SSx2.p5.1.m1.1.1.2.cmml">G</mi><mn id="S4.SSx2.p5.1.m1.1.1.3" xref="S4.SSx2.p5.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SSx2.p5.1.m1.1b"><apply id="S4.SSx2.p5.1.m1.1.1.cmml" xref="S4.SSx2.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SSx2.p5.1.m1.1.1.1.cmml" xref="S4.SSx2.p5.1.m1.1.1">subscript</csymbol><ci id="S4.SSx2.p5.1.m1.1.1.2.cmml" xref="S4.SSx2.p5.1.m1.1.1.2">𝐺</ci><cn type="integer" id="S4.SSx2.p5.1.m1.1.1.3.cmml" xref="S4.SSx2.p5.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx2.p5.1.m1.1c">G_{1}</annotation></semantics></math> and <math id="S4.SSx2.p5.2.m2.1" class="ltx_Math" alttext="G_{2}" display="inline"><semantics id="S4.SSx2.p5.2.m2.1a"><msub id="S4.SSx2.p5.2.m2.1.1" xref="S4.SSx2.p5.2.m2.1.1.cmml"><mi id="S4.SSx2.p5.2.m2.1.1.2" xref="S4.SSx2.p5.2.m2.1.1.2.cmml">G</mi><mn id="S4.SSx2.p5.2.m2.1.1.3" xref="S4.SSx2.p5.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SSx2.p5.2.m2.1b"><apply id="S4.SSx2.p5.2.m2.1.1.cmml" xref="S4.SSx2.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SSx2.p5.2.m2.1.1.1.cmml" xref="S4.SSx2.p5.2.m2.1.1">subscript</csymbol><ci id="S4.SSx2.p5.2.m2.1.1.2.cmml" xref="S4.SSx2.p5.2.m2.1.1.2">𝐺</ci><cn type="integer" id="S4.SSx2.p5.2.m2.1.1.3.cmml" xref="S4.SSx2.p5.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx2.p5.2.m2.1c">G_{2}</annotation></semantics></math> are two uncorrelated noise layers, with standard deviations <math id="S4.SSx2.p5.3.m3.1" class="ltx_Math" alttext="\sigma_{1}" display="inline"><semantics id="S4.SSx2.p5.3.m3.1a"><msub id="S4.SSx2.p5.3.m3.1.1" xref="S4.SSx2.p5.3.m3.1.1.cmml"><mi id="S4.SSx2.p5.3.m3.1.1.2" xref="S4.SSx2.p5.3.m3.1.1.2.cmml">σ</mi><mn id="S4.SSx2.p5.3.m3.1.1.3" xref="S4.SSx2.p5.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SSx2.p5.3.m3.1b"><apply id="S4.SSx2.p5.3.m3.1.1.cmml" xref="S4.SSx2.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SSx2.p5.3.m3.1.1.1.cmml" xref="S4.SSx2.p5.3.m3.1.1">subscript</csymbol><ci id="S4.SSx2.p5.3.m3.1.1.2.cmml" xref="S4.SSx2.p5.3.m3.1.1.2">𝜎</ci><cn type="integer" id="S4.SSx2.p5.3.m3.1.1.3.cmml" xref="S4.SSx2.p5.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx2.p5.3.m3.1c">\sigma_{1}</annotation></semantics></math> and <math id="S4.SSx2.p5.4.m4.1" class="ltx_Math" alttext="\sigma_{2}" display="inline"><semantics id="S4.SSx2.p5.4.m4.1a"><msub id="S4.SSx2.p5.4.m4.1.1" xref="S4.SSx2.p5.4.m4.1.1.cmml"><mi id="S4.SSx2.p5.4.m4.1.1.2" xref="S4.SSx2.p5.4.m4.1.1.2.cmml">σ</mi><mn id="S4.SSx2.p5.4.m4.1.1.3" xref="S4.SSx2.p5.4.m4.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SSx2.p5.4.m4.1b"><apply id="S4.SSx2.p5.4.m4.1.1.cmml" xref="S4.SSx2.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SSx2.p5.4.m4.1.1.1.cmml" xref="S4.SSx2.p5.4.m4.1.1">subscript</csymbol><ci id="S4.SSx2.p5.4.m4.1.1.2.cmml" xref="S4.SSx2.p5.4.m4.1.1.2">𝜎</ci><cn type="integer" id="S4.SSx2.p5.4.m4.1.1.3.cmml" xref="S4.SSx2.p5.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx2.p5.4.m4.1c">\sigma_{2}</annotation></semantics></math>, respectively.</p>
<table id="S4.E17" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S4.E17.m1.74" class="ltx_Math" alttext="\begin{split}Variance(G_{1},G_{2})=Variance(G_{1})+Variance(G_{2})+2\rho*CoVariance(G_{1},G_{2})\end{split}" display="block"><semantics id="S4.E17.m1.74a"><mtable displaystyle="true" id="S4.E17.m1.74.74.12" xref="S4.E17.m1.68.68.6.cmml"><mtr id="S4.E17.m1.74.74.12a" xref="S4.E17.m1.68.68.6.cmml"><mtd class="ltx_align_right" columnalign="right" id="S4.E17.m1.74.74.12b" xref="S4.E17.m1.68.68.6.cmml"><mrow id="S4.E17.m1.74.74.12.68.68.68" xref="S4.E17.m1.68.68.6.cmml"><mrow id="S4.E17.m1.70.70.8.64.64.64.64" xref="S4.E17.m1.68.68.6.cmml"><mi id="S4.E17.m1.1.1.1.1.1.1" xref="S4.E17.m1.1.1.1.1.1.1.cmml">V</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.70.70.8.64.64.64.64.3" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.2.2.2.2.2.2" xref="S4.E17.m1.2.2.2.2.2.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.70.70.8.64.64.64.64.3a" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.3.3.3.3.3.3" xref="S4.E17.m1.3.3.3.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.70.70.8.64.64.64.64.3b" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.4.4.4.4.4.4" xref="S4.E17.m1.4.4.4.4.4.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.70.70.8.64.64.64.64.3c" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.5.5.5.5.5.5" xref="S4.E17.m1.5.5.5.5.5.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.70.70.8.64.64.64.64.3d" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.6.6.6.6.6.6" xref="S4.E17.m1.6.6.6.6.6.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.70.70.8.64.64.64.64.3e" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.7.7.7.7.7.7" xref="S4.E17.m1.7.7.7.7.7.7.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.70.70.8.64.64.64.64.3f" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.8.8.8.8.8.8" xref="S4.E17.m1.8.8.8.8.8.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.70.70.8.64.64.64.64.3g" xref="S4.E17.m1.68.68.6.cmml">​</mo><mrow id="S4.E17.m1.70.70.8.64.64.64.64.2.2" xref="S4.E17.m1.68.68.6.cmml"><mo stretchy="false" id="S4.E17.m1.9.9.9.9.9.9" xref="S4.E17.m1.68.68.6.cmml">(</mo><msub id="S4.E17.m1.69.69.7.63.63.63.63.1.1.1" xref="S4.E17.m1.68.68.6.cmml"><mi id="S4.E17.m1.10.10.10.10.10.10" xref="S4.E17.m1.10.10.10.10.10.10.cmml">G</mi><mn id="S4.E17.m1.11.11.11.11.11.11.1" xref="S4.E17.m1.11.11.11.11.11.11.1.cmml">1</mn></msub><mo id="S4.E17.m1.12.12.12.12.12.12" xref="S4.E17.m1.68.68.6.cmml">,</mo><msub id="S4.E17.m1.70.70.8.64.64.64.64.2.2.2" xref="S4.E17.m1.68.68.6.cmml"><mi id="S4.E17.m1.13.13.13.13.13.13" xref="S4.E17.m1.13.13.13.13.13.13.cmml">G</mi><mn id="S4.E17.m1.14.14.14.14.14.14.1" xref="S4.E17.m1.14.14.14.14.14.14.1.cmml">2</mn></msub><mo stretchy="false" id="S4.E17.m1.15.15.15.15.15.15" xref="S4.E17.m1.68.68.6.cmml">)</mo></mrow></mrow><mo id="S4.E17.m1.16.16.16.16.16.16" xref="S4.E17.m1.16.16.16.16.16.16.cmml">=</mo><mrow id="S4.E17.m1.74.74.12.68.68.68.68" xref="S4.E17.m1.68.68.6.cmml"><mrow id="S4.E17.m1.71.71.9.65.65.65.65.1" xref="S4.E17.m1.68.68.6.cmml"><mi id="S4.E17.m1.17.17.17.17.17.17" xref="S4.E17.m1.17.17.17.17.17.17.cmml">V</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.71.71.9.65.65.65.65.1.2" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.18.18.18.18.18.18" xref="S4.E17.m1.18.18.18.18.18.18.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.71.71.9.65.65.65.65.1.2a" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.19.19.19.19.19.19" xref="S4.E17.m1.19.19.19.19.19.19.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.71.71.9.65.65.65.65.1.2b" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.20.20.20.20.20.20" xref="S4.E17.m1.20.20.20.20.20.20.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.71.71.9.65.65.65.65.1.2c" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.21.21.21.21.21.21" xref="S4.E17.m1.21.21.21.21.21.21.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.71.71.9.65.65.65.65.1.2d" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.22.22.22.22.22.22" xref="S4.E17.m1.22.22.22.22.22.22.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.71.71.9.65.65.65.65.1.2e" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.23.23.23.23.23.23" xref="S4.E17.m1.23.23.23.23.23.23.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.71.71.9.65.65.65.65.1.2f" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.24.24.24.24.24.24" xref="S4.E17.m1.24.24.24.24.24.24.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.71.71.9.65.65.65.65.1.2g" xref="S4.E17.m1.68.68.6.cmml">​</mo><mrow id="S4.E17.m1.71.71.9.65.65.65.65.1.1.1" xref="S4.E17.m1.68.68.6.cmml"><mo stretchy="false" id="S4.E17.m1.25.25.25.25.25.25" xref="S4.E17.m1.68.68.6.cmml">(</mo><msub id="S4.E17.m1.71.71.9.65.65.65.65.1.1.1.1" xref="S4.E17.m1.68.68.6.cmml"><mi id="S4.E17.m1.26.26.26.26.26.26" xref="S4.E17.m1.26.26.26.26.26.26.cmml">G</mi><mn id="S4.E17.m1.27.27.27.27.27.27.1" xref="S4.E17.m1.27.27.27.27.27.27.1.cmml">1</mn></msub><mo stretchy="false" id="S4.E17.m1.28.28.28.28.28.28" xref="S4.E17.m1.68.68.6.cmml">)</mo></mrow></mrow><mo id="S4.E17.m1.29.29.29.29.29.29" xref="S4.E17.m1.29.29.29.29.29.29.cmml">+</mo><mrow id="S4.E17.m1.72.72.10.66.66.66.66.2" xref="S4.E17.m1.68.68.6.cmml"><mi id="S4.E17.m1.30.30.30.30.30.30" xref="S4.E17.m1.30.30.30.30.30.30.cmml">V</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.72.72.10.66.66.66.66.2.2" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.31.31.31.31.31.31" xref="S4.E17.m1.31.31.31.31.31.31.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.72.72.10.66.66.66.66.2.2a" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.32.32.32.32.32.32" xref="S4.E17.m1.32.32.32.32.32.32.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.72.72.10.66.66.66.66.2.2b" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.33.33.33.33.33.33" xref="S4.E17.m1.33.33.33.33.33.33.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.72.72.10.66.66.66.66.2.2c" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.34.34.34.34.34.34" xref="S4.E17.m1.34.34.34.34.34.34.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.72.72.10.66.66.66.66.2.2d" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.35.35.35.35.35.35" xref="S4.E17.m1.35.35.35.35.35.35.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.72.72.10.66.66.66.66.2.2e" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.36.36.36.36.36.36" xref="S4.E17.m1.36.36.36.36.36.36.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.72.72.10.66.66.66.66.2.2f" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.37.37.37.37.37.37" xref="S4.E17.m1.37.37.37.37.37.37.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.72.72.10.66.66.66.66.2.2g" xref="S4.E17.m1.68.68.6.cmml">​</mo><mrow id="S4.E17.m1.72.72.10.66.66.66.66.2.1.1" xref="S4.E17.m1.68.68.6.cmml"><mo stretchy="false" id="S4.E17.m1.38.38.38.38.38.38" xref="S4.E17.m1.68.68.6.cmml">(</mo><msub id="S4.E17.m1.72.72.10.66.66.66.66.2.1.1.1" xref="S4.E17.m1.68.68.6.cmml"><mi id="S4.E17.m1.39.39.39.39.39.39" xref="S4.E17.m1.39.39.39.39.39.39.cmml">G</mi><mn id="S4.E17.m1.40.40.40.40.40.40.1" xref="S4.E17.m1.40.40.40.40.40.40.1.cmml">2</mn></msub><mo stretchy="false" id="S4.E17.m1.41.41.41.41.41.41" xref="S4.E17.m1.68.68.6.cmml">)</mo></mrow></mrow><mo id="S4.E17.m1.29.29.29.29.29.29a" xref="S4.E17.m1.29.29.29.29.29.29.cmml">+</mo><mrow id="S4.E17.m1.74.74.12.68.68.68.68.4" xref="S4.E17.m1.68.68.6.cmml"><mrow id="S4.E17.m1.74.74.12.68.68.68.68.4.4" xref="S4.E17.m1.68.68.6.cmml"><mrow id="S4.E17.m1.74.74.12.68.68.68.68.4.4.1" xref="S4.E17.m1.68.68.6.cmml"><mn id="S4.E17.m1.43.43.43.43.43.43" xref="S4.E17.m1.43.43.43.43.43.43.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.E17.m1.74.74.12.68.68.68.68.4.4.1.1" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.44.44.44.44.44.44" xref="S4.E17.m1.44.44.44.44.44.44.cmml">ρ</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S4.E17.m1.45.45.45.45.45.45" xref="S4.E17.m1.45.45.45.45.45.45.cmml">∗</mo><mi id="S4.E17.m1.46.46.46.46.46.46" xref="S4.E17.m1.46.46.46.46.46.46.cmml">C</mi></mrow><mo lspace="0em" rspace="0em" id="S4.E17.m1.74.74.12.68.68.68.68.4.3" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.47.47.47.47.47.47" xref="S4.E17.m1.47.47.47.47.47.47.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.74.74.12.68.68.68.68.4.3a" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.48.48.48.48.48.48" xref="S4.E17.m1.48.48.48.48.48.48.cmml">V</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.74.74.12.68.68.68.68.4.3b" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.49.49.49.49.49.49" xref="S4.E17.m1.49.49.49.49.49.49.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.74.74.12.68.68.68.68.4.3c" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.50.50.50.50.50.50" xref="S4.E17.m1.50.50.50.50.50.50.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.74.74.12.68.68.68.68.4.3d" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.51.51.51.51.51.51" xref="S4.E17.m1.51.51.51.51.51.51.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.74.74.12.68.68.68.68.4.3e" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.52.52.52.52.52.52" xref="S4.E17.m1.52.52.52.52.52.52.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.74.74.12.68.68.68.68.4.3f" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.53.53.53.53.53.53" xref="S4.E17.m1.53.53.53.53.53.53.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.74.74.12.68.68.68.68.4.3g" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.54.54.54.54.54.54" xref="S4.E17.m1.54.54.54.54.54.54.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.74.74.12.68.68.68.68.4.3h" xref="S4.E17.m1.68.68.6.cmml">​</mo><mi id="S4.E17.m1.55.55.55.55.55.55" xref="S4.E17.m1.55.55.55.55.55.55.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E17.m1.74.74.12.68.68.68.68.4.3i" xref="S4.E17.m1.68.68.6.cmml">​</mo><mrow id="S4.E17.m1.74.74.12.68.68.68.68.4.2.2" xref="S4.E17.m1.68.68.6.cmml"><mo stretchy="false" id="S4.E17.m1.56.56.56.56.56.56" xref="S4.E17.m1.68.68.6.cmml">(</mo><msub id="S4.E17.m1.73.73.11.67.67.67.67.3.1.1.1" xref="S4.E17.m1.68.68.6.cmml"><mi id="S4.E17.m1.57.57.57.57.57.57" xref="S4.E17.m1.57.57.57.57.57.57.cmml">G</mi><mn id="S4.E17.m1.58.58.58.58.58.58.1" xref="S4.E17.m1.58.58.58.58.58.58.1.cmml">1</mn></msub><mo id="S4.E17.m1.59.59.59.59.59.59" xref="S4.E17.m1.68.68.6.cmml">,</mo><msub id="S4.E17.m1.74.74.12.68.68.68.68.4.2.2.2" xref="S4.E17.m1.68.68.6.cmml"><mi id="S4.E17.m1.60.60.60.60.60.60" xref="S4.E17.m1.60.60.60.60.60.60.cmml">G</mi><mn id="S4.E17.m1.61.61.61.61.61.61.1" xref="S4.E17.m1.61.61.61.61.61.61.1.cmml">2</mn></msub><mo stretchy="false" id="S4.E17.m1.62.62.62.62.62.62" xref="S4.E17.m1.68.68.6.cmml">)</mo></mrow></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S4.E17.m1.74b"><apply id="S4.E17.m1.68.68.6.cmml" xref="S4.E17.m1.74.74.12"><eq id="S4.E17.m1.16.16.16.16.16.16.cmml" xref="S4.E17.m1.16.16.16.16.16.16"></eq><apply id="S4.E17.m1.64.64.2.2.cmml" xref="S4.E17.m1.74.74.12"><times id="S4.E17.m1.64.64.2.2.3.cmml" xref="S4.E17.m1.74.74.12"></times><ci id="S4.E17.m1.1.1.1.1.1.1.cmml" xref="S4.E17.m1.1.1.1.1.1.1">𝑉</ci><ci id="S4.E17.m1.2.2.2.2.2.2.cmml" xref="S4.E17.m1.2.2.2.2.2.2">𝑎</ci><ci id="S4.E17.m1.3.3.3.3.3.3.cmml" xref="S4.E17.m1.3.3.3.3.3.3">𝑟</ci><ci id="S4.E17.m1.4.4.4.4.4.4.cmml" xref="S4.E17.m1.4.4.4.4.4.4">𝑖</ci><ci id="S4.E17.m1.5.5.5.5.5.5.cmml" xref="S4.E17.m1.5.5.5.5.5.5">𝑎</ci><ci id="S4.E17.m1.6.6.6.6.6.6.cmml" xref="S4.E17.m1.6.6.6.6.6.6">𝑛</ci><ci id="S4.E17.m1.7.7.7.7.7.7.cmml" xref="S4.E17.m1.7.7.7.7.7.7">𝑐</ci><ci id="S4.E17.m1.8.8.8.8.8.8.cmml" xref="S4.E17.m1.8.8.8.8.8.8">𝑒</ci><interval closure="open" id="S4.E17.m1.64.64.2.2.2.3.cmml" xref="S4.E17.m1.74.74.12"><apply id="S4.E17.m1.63.63.1.1.1.1.1.cmml" xref="S4.E17.m1.74.74.12"><csymbol cd="ambiguous" id="S4.E17.m1.63.63.1.1.1.1.1.1.cmml" xref="S4.E17.m1.74.74.12">subscript</csymbol><ci id="S4.E17.m1.10.10.10.10.10.10.cmml" xref="S4.E17.m1.10.10.10.10.10.10">𝐺</ci><cn type="integer" id="S4.E17.m1.11.11.11.11.11.11.1.cmml" xref="S4.E17.m1.11.11.11.11.11.11.1">1</cn></apply><apply id="S4.E17.m1.64.64.2.2.2.2.2.cmml" xref="S4.E17.m1.74.74.12"><csymbol cd="ambiguous" id="S4.E17.m1.64.64.2.2.2.2.2.1.cmml" xref="S4.E17.m1.74.74.12">subscript</csymbol><ci id="S4.E17.m1.13.13.13.13.13.13.cmml" xref="S4.E17.m1.13.13.13.13.13.13">𝐺</ci><cn type="integer" id="S4.E17.m1.14.14.14.14.14.14.1.cmml" xref="S4.E17.m1.14.14.14.14.14.14.1">2</cn></apply></interval></apply><apply id="S4.E17.m1.68.68.6.6.cmml" xref="S4.E17.m1.74.74.12"><plus id="S4.E17.m1.29.29.29.29.29.29.cmml" xref="S4.E17.m1.29.29.29.29.29.29"></plus><apply id="S4.E17.m1.65.65.3.3.1.cmml" xref="S4.E17.m1.74.74.12"><times id="S4.E17.m1.65.65.3.3.1.2.cmml" xref="S4.E17.m1.74.74.12"></times><ci id="S4.E17.m1.17.17.17.17.17.17.cmml" xref="S4.E17.m1.17.17.17.17.17.17">𝑉</ci><ci id="S4.E17.m1.18.18.18.18.18.18.cmml" xref="S4.E17.m1.18.18.18.18.18.18">𝑎</ci><ci id="S4.E17.m1.19.19.19.19.19.19.cmml" xref="S4.E17.m1.19.19.19.19.19.19">𝑟</ci><ci id="S4.E17.m1.20.20.20.20.20.20.cmml" xref="S4.E17.m1.20.20.20.20.20.20">𝑖</ci><ci id="S4.E17.m1.21.21.21.21.21.21.cmml" xref="S4.E17.m1.21.21.21.21.21.21">𝑎</ci><ci id="S4.E17.m1.22.22.22.22.22.22.cmml" xref="S4.E17.m1.22.22.22.22.22.22">𝑛</ci><ci id="S4.E17.m1.23.23.23.23.23.23.cmml" xref="S4.E17.m1.23.23.23.23.23.23">𝑐</ci><ci id="S4.E17.m1.24.24.24.24.24.24.cmml" xref="S4.E17.m1.24.24.24.24.24.24">𝑒</ci><apply id="S4.E17.m1.65.65.3.3.1.1.1.1.cmml" xref="S4.E17.m1.74.74.12"><csymbol cd="ambiguous" id="S4.E17.m1.65.65.3.3.1.1.1.1.1.cmml" xref="S4.E17.m1.74.74.12">subscript</csymbol><ci id="S4.E17.m1.26.26.26.26.26.26.cmml" xref="S4.E17.m1.26.26.26.26.26.26">𝐺</ci><cn type="integer" id="S4.E17.m1.27.27.27.27.27.27.1.cmml" xref="S4.E17.m1.27.27.27.27.27.27.1">1</cn></apply></apply><apply id="S4.E17.m1.66.66.4.4.2.cmml" xref="S4.E17.m1.74.74.12"><times id="S4.E17.m1.66.66.4.4.2.2.cmml" xref="S4.E17.m1.74.74.12"></times><ci id="S4.E17.m1.30.30.30.30.30.30.cmml" xref="S4.E17.m1.30.30.30.30.30.30">𝑉</ci><ci id="S4.E17.m1.31.31.31.31.31.31.cmml" xref="S4.E17.m1.31.31.31.31.31.31">𝑎</ci><ci id="S4.E17.m1.32.32.32.32.32.32.cmml" xref="S4.E17.m1.32.32.32.32.32.32">𝑟</ci><ci id="S4.E17.m1.33.33.33.33.33.33.cmml" xref="S4.E17.m1.33.33.33.33.33.33">𝑖</ci><ci id="S4.E17.m1.34.34.34.34.34.34.cmml" xref="S4.E17.m1.34.34.34.34.34.34">𝑎</ci><ci id="S4.E17.m1.35.35.35.35.35.35.cmml" xref="S4.E17.m1.35.35.35.35.35.35">𝑛</ci><ci id="S4.E17.m1.36.36.36.36.36.36.cmml" xref="S4.E17.m1.36.36.36.36.36.36">𝑐</ci><ci id="S4.E17.m1.37.37.37.37.37.37.cmml" xref="S4.E17.m1.37.37.37.37.37.37">𝑒</ci><apply id="S4.E17.m1.66.66.4.4.2.1.1.1.cmml" xref="S4.E17.m1.74.74.12"><csymbol cd="ambiguous" id="S4.E17.m1.66.66.4.4.2.1.1.1.1.cmml" xref="S4.E17.m1.74.74.12">subscript</csymbol><ci id="S4.E17.m1.39.39.39.39.39.39.cmml" xref="S4.E17.m1.39.39.39.39.39.39">𝐺</ci><cn type="integer" id="S4.E17.m1.40.40.40.40.40.40.1.cmml" xref="S4.E17.m1.40.40.40.40.40.40.1">2</cn></apply></apply><apply id="S4.E17.m1.68.68.6.6.4.cmml" xref="S4.E17.m1.74.74.12"><times id="S4.E17.m1.68.68.6.6.4.3.cmml" xref="S4.E17.m1.74.74.12"></times><apply id="S4.E17.m1.68.68.6.6.4.4.cmml" xref="S4.E17.m1.74.74.12"><times id="S4.E17.m1.45.45.45.45.45.45.cmml" xref="S4.E17.m1.45.45.45.45.45.45"></times><apply id="S4.E17.m1.68.68.6.6.4.4.2.cmml" xref="S4.E17.m1.74.74.12"><times id="S4.E17.m1.68.68.6.6.4.4.2.1.cmml" xref="S4.E17.m1.74.74.12"></times><cn type="integer" id="S4.E17.m1.43.43.43.43.43.43.cmml" xref="S4.E17.m1.43.43.43.43.43.43">2</cn><ci id="S4.E17.m1.44.44.44.44.44.44.cmml" xref="S4.E17.m1.44.44.44.44.44.44">𝜌</ci></apply><ci id="S4.E17.m1.46.46.46.46.46.46.cmml" xref="S4.E17.m1.46.46.46.46.46.46">𝐶</ci></apply><ci id="S4.E17.m1.47.47.47.47.47.47.cmml" xref="S4.E17.m1.47.47.47.47.47.47">𝑜</ci><ci id="S4.E17.m1.48.48.48.48.48.48.cmml" xref="S4.E17.m1.48.48.48.48.48.48">𝑉</ci><ci id="S4.E17.m1.49.49.49.49.49.49.cmml" xref="S4.E17.m1.49.49.49.49.49.49">𝑎</ci><ci id="S4.E17.m1.50.50.50.50.50.50.cmml" xref="S4.E17.m1.50.50.50.50.50.50">𝑟</ci><ci id="S4.E17.m1.51.51.51.51.51.51.cmml" xref="S4.E17.m1.51.51.51.51.51.51">𝑖</ci><ci id="S4.E17.m1.52.52.52.52.52.52.cmml" xref="S4.E17.m1.52.52.52.52.52.52">𝑎</ci><ci id="S4.E17.m1.53.53.53.53.53.53.cmml" xref="S4.E17.m1.53.53.53.53.53.53">𝑛</ci><ci id="S4.E17.m1.54.54.54.54.54.54.cmml" xref="S4.E17.m1.54.54.54.54.54.54">𝑐</ci><ci id="S4.E17.m1.55.55.55.55.55.55.cmml" xref="S4.E17.m1.55.55.55.55.55.55">𝑒</ci><interval closure="open" id="S4.E17.m1.68.68.6.6.4.2.3.cmml" xref="S4.E17.m1.74.74.12"><apply id="S4.E17.m1.67.67.5.5.3.1.1.1.cmml" xref="S4.E17.m1.74.74.12"><csymbol cd="ambiguous" id="S4.E17.m1.67.67.5.5.3.1.1.1.1.cmml" xref="S4.E17.m1.74.74.12">subscript</csymbol><ci id="S4.E17.m1.57.57.57.57.57.57.cmml" xref="S4.E17.m1.57.57.57.57.57.57">𝐺</ci><cn type="integer" id="S4.E17.m1.58.58.58.58.58.58.1.cmml" xref="S4.E17.m1.58.58.58.58.58.58.1">1</cn></apply><apply id="S4.E17.m1.68.68.6.6.4.2.2.2.cmml" xref="S4.E17.m1.74.74.12"><csymbol cd="ambiguous" id="S4.E17.m1.68.68.6.6.4.2.2.2.1.cmml" xref="S4.E17.m1.74.74.12">subscript</csymbol><ci id="S4.E17.m1.60.60.60.60.60.60.cmml" xref="S4.E17.m1.60.60.60.60.60.60">𝐺</ci><cn type="integer" id="S4.E17.m1.61.61.61.61.61.61.1.cmml" xref="S4.E17.m1.61.61.61.61.61.61.1">2</cn></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E17.m1.74c">\begin{split}Variance(G_{1},G_{2})=Variance(G_{1})+Variance(G_{2})+2\rho*CoVariance(G_{1},G_{2})\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(17)</span></td>
</tr></tbody>
</table>
<p id="S4.SSx2.p5.5" class="ltx_p">Since the noise layers are uncorrelated, <math id="S4.SSx2.p5.5.m1.1" class="ltx_Math" alttext="\rho=0" display="inline"><semantics id="S4.SSx2.p5.5.m1.1a"><mrow id="S4.SSx2.p5.5.m1.1.1" xref="S4.SSx2.p5.5.m1.1.1.cmml"><mi id="S4.SSx2.p5.5.m1.1.1.2" xref="S4.SSx2.p5.5.m1.1.1.2.cmml">ρ</mi><mo id="S4.SSx2.p5.5.m1.1.1.1" xref="S4.SSx2.p5.5.m1.1.1.1.cmml">=</mo><mn id="S4.SSx2.p5.5.m1.1.1.3" xref="S4.SSx2.p5.5.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SSx2.p5.5.m1.1b"><apply id="S4.SSx2.p5.5.m1.1.1.cmml" xref="S4.SSx2.p5.5.m1.1.1"><eq id="S4.SSx2.p5.5.m1.1.1.1.cmml" xref="S4.SSx2.p5.5.m1.1.1.1"></eq><ci id="S4.SSx2.p5.5.m1.1.1.2.cmml" xref="S4.SSx2.p5.5.m1.1.1.2">𝜌</ci><cn type="integer" id="S4.SSx2.p5.5.m1.1.1.3.cmml" xref="S4.SSx2.p5.5.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx2.p5.5.m1.1c">\rho=0</annotation></semantics></math>, and,</p>
<table id="S4.E18" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S4.E18.m1.1" class="ltx_Math" alttext="Variance(G_{1}+G_{2})=\sigma_{1}^{2}+\sigma_{2}^{2}." display="block"><semantics id="S4.E18.m1.1a"><mrow id="S4.E18.m1.1.1.1" xref="S4.E18.m1.1.1.1.1.cmml"><mrow id="S4.E18.m1.1.1.1.1" xref="S4.E18.m1.1.1.1.1.cmml"><mrow id="S4.E18.m1.1.1.1.1.1" xref="S4.E18.m1.1.1.1.1.1.cmml"><mi id="S4.E18.m1.1.1.1.1.1.3" xref="S4.E18.m1.1.1.1.1.1.3.cmml">V</mi><mo lspace="0em" rspace="0em" id="S4.E18.m1.1.1.1.1.1.2" xref="S4.E18.m1.1.1.1.1.1.2.cmml">​</mo><mi id="S4.E18.m1.1.1.1.1.1.4" xref="S4.E18.m1.1.1.1.1.1.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E18.m1.1.1.1.1.1.2a" xref="S4.E18.m1.1.1.1.1.1.2.cmml">​</mo><mi id="S4.E18.m1.1.1.1.1.1.5" xref="S4.E18.m1.1.1.1.1.1.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E18.m1.1.1.1.1.1.2b" xref="S4.E18.m1.1.1.1.1.1.2.cmml">​</mo><mi id="S4.E18.m1.1.1.1.1.1.6" xref="S4.E18.m1.1.1.1.1.1.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E18.m1.1.1.1.1.1.2c" xref="S4.E18.m1.1.1.1.1.1.2.cmml">​</mo><mi id="S4.E18.m1.1.1.1.1.1.7" xref="S4.E18.m1.1.1.1.1.1.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E18.m1.1.1.1.1.1.2d" xref="S4.E18.m1.1.1.1.1.1.2.cmml">​</mo><mi id="S4.E18.m1.1.1.1.1.1.8" xref="S4.E18.m1.1.1.1.1.1.8.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E18.m1.1.1.1.1.1.2e" xref="S4.E18.m1.1.1.1.1.1.2.cmml">​</mo><mi id="S4.E18.m1.1.1.1.1.1.9" xref="S4.E18.m1.1.1.1.1.1.9.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E18.m1.1.1.1.1.1.2f" xref="S4.E18.m1.1.1.1.1.1.2.cmml">​</mo><mi id="S4.E18.m1.1.1.1.1.1.10" xref="S4.E18.m1.1.1.1.1.1.10.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E18.m1.1.1.1.1.1.2g" xref="S4.E18.m1.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.E18.m1.1.1.1.1.1.1.1" xref="S4.E18.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E18.m1.1.1.1.1.1.1.1.2" xref="S4.E18.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E18.m1.1.1.1.1.1.1.1.1" xref="S4.E18.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S4.E18.m1.1.1.1.1.1.1.1.1.2" xref="S4.E18.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E18.m1.1.1.1.1.1.1.1.1.2.2" xref="S4.E18.m1.1.1.1.1.1.1.1.1.2.2.cmml">G</mi><mn id="S4.E18.m1.1.1.1.1.1.1.1.1.2.3" xref="S4.E18.m1.1.1.1.1.1.1.1.1.2.3.cmml">1</mn></msub><mo id="S4.E18.m1.1.1.1.1.1.1.1.1.1" xref="S4.E18.m1.1.1.1.1.1.1.1.1.1.cmml">+</mo><msub id="S4.E18.m1.1.1.1.1.1.1.1.1.3" xref="S4.E18.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E18.m1.1.1.1.1.1.1.1.1.3.2" xref="S4.E18.m1.1.1.1.1.1.1.1.1.3.2.cmml">G</mi><mn id="S4.E18.m1.1.1.1.1.1.1.1.1.3.3" xref="S4.E18.m1.1.1.1.1.1.1.1.1.3.3.cmml">2</mn></msub></mrow><mo stretchy="false" id="S4.E18.m1.1.1.1.1.1.1.1.3" xref="S4.E18.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E18.m1.1.1.1.1.2" xref="S4.E18.m1.1.1.1.1.2.cmml">=</mo><mrow id="S4.E18.m1.1.1.1.1.3" xref="S4.E18.m1.1.1.1.1.3.cmml"><msubsup id="S4.E18.m1.1.1.1.1.3.2" xref="S4.E18.m1.1.1.1.1.3.2.cmml"><mi id="S4.E18.m1.1.1.1.1.3.2.2.2" xref="S4.E18.m1.1.1.1.1.3.2.2.2.cmml">σ</mi><mn id="S4.E18.m1.1.1.1.1.3.2.2.3" xref="S4.E18.m1.1.1.1.1.3.2.2.3.cmml">1</mn><mn id="S4.E18.m1.1.1.1.1.3.2.3" xref="S4.E18.m1.1.1.1.1.3.2.3.cmml">2</mn></msubsup><mo id="S4.E18.m1.1.1.1.1.3.1" xref="S4.E18.m1.1.1.1.1.3.1.cmml">+</mo><msubsup id="S4.E18.m1.1.1.1.1.3.3" xref="S4.E18.m1.1.1.1.1.3.3.cmml"><mi id="S4.E18.m1.1.1.1.1.3.3.2.2" xref="S4.E18.m1.1.1.1.1.3.3.2.2.cmml">σ</mi><mn id="S4.E18.m1.1.1.1.1.3.3.2.3" xref="S4.E18.m1.1.1.1.1.3.3.2.3.cmml">2</mn><mn id="S4.E18.m1.1.1.1.1.3.3.3" xref="S4.E18.m1.1.1.1.1.3.3.3.cmml">2</mn></msubsup></mrow></mrow><mo lspace="0em" id="S4.E18.m1.1.1.1.2" xref="S4.E18.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E18.m1.1b"><apply id="S4.E18.m1.1.1.1.1.cmml" xref="S4.E18.m1.1.1.1"><eq id="S4.E18.m1.1.1.1.1.2.cmml" xref="S4.E18.m1.1.1.1.1.2"></eq><apply id="S4.E18.m1.1.1.1.1.1.cmml" xref="S4.E18.m1.1.1.1.1.1"><times id="S4.E18.m1.1.1.1.1.1.2.cmml" xref="S4.E18.m1.1.1.1.1.1.2"></times><ci id="S4.E18.m1.1.1.1.1.1.3.cmml" xref="S4.E18.m1.1.1.1.1.1.3">𝑉</ci><ci id="S4.E18.m1.1.1.1.1.1.4.cmml" xref="S4.E18.m1.1.1.1.1.1.4">𝑎</ci><ci id="S4.E18.m1.1.1.1.1.1.5.cmml" xref="S4.E18.m1.1.1.1.1.1.5">𝑟</ci><ci id="S4.E18.m1.1.1.1.1.1.6.cmml" xref="S4.E18.m1.1.1.1.1.1.6">𝑖</ci><ci id="S4.E18.m1.1.1.1.1.1.7.cmml" xref="S4.E18.m1.1.1.1.1.1.7">𝑎</ci><ci id="S4.E18.m1.1.1.1.1.1.8.cmml" xref="S4.E18.m1.1.1.1.1.1.8">𝑛</ci><ci id="S4.E18.m1.1.1.1.1.1.9.cmml" xref="S4.E18.m1.1.1.1.1.1.9">𝑐</ci><ci id="S4.E18.m1.1.1.1.1.1.10.cmml" xref="S4.E18.m1.1.1.1.1.1.10">𝑒</ci><apply id="S4.E18.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E18.m1.1.1.1.1.1.1.1"><plus id="S4.E18.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E18.m1.1.1.1.1.1.1.1.1.1"></plus><apply id="S4.E18.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E18.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E18.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E18.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E18.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E18.m1.1.1.1.1.1.1.1.1.2.2">𝐺</ci><cn type="integer" id="S4.E18.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E18.m1.1.1.1.1.1.1.1.1.2.3">1</cn></apply><apply id="S4.E18.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E18.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E18.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E18.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E18.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E18.m1.1.1.1.1.1.1.1.1.3.2">𝐺</ci><cn type="integer" id="S4.E18.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E18.m1.1.1.1.1.1.1.1.1.3.3">2</cn></apply></apply></apply><apply id="S4.E18.m1.1.1.1.1.3.cmml" xref="S4.E18.m1.1.1.1.1.3"><plus id="S4.E18.m1.1.1.1.1.3.1.cmml" xref="S4.E18.m1.1.1.1.1.3.1"></plus><apply id="S4.E18.m1.1.1.1.1.3.2.cmml" xref="S4.E18.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E18.m1.1.1.1.1.3.2.1.cmml" xref="S4.E18.m1.1.1.1.1.3.2">superscript</csymbol><apply id="S4.E18.m1.1.1.1.1.3.2.2.cmml" xref="S4.E18.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E18.m1.1.1.1.1.3.2.2.1.cmml" xref="S4.E18.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S4.E18.m1.1.1.1.1.3.2.2.2.cmml" xref="S4.E18.m1.1.1.1.1.3.2.2.2">𝜎</ci><cn type="integer" id="S4.E18.m1.1.1.1.1.3.2.2.3.cmml" xref="S4.E18.m1.1.1.1.1.3.2.2.3">1</cn></apply><cn type="integer" id="S4.E18.m1.1.1.1.1.3.2.3.cmml" xref="S4.E18.m1.1.1.1.1.3.2.3">2</cn></apply><apply id="S4.E18.m1.1.1.1.1.3.3.cmml" xref="S4.E18.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.E18.m1.1.1.1.1.3.3.1.cmml" xref="S4.E18.m1.1.1.1.1.3.3">superscript</csymbol><apply id="S4.E18.m1.1.1.1.1.3.3.2.cmml" xref="S4.E18.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.E18.m1.1.1.1.1.3.3.2.1.cmml" xref="S4.E18.m1.1.1.1.1.3.3">subscript</csymbol><ci id="S4.E18.m1.1.1.1.1.3.3.2.2.cmml" xref="S4.E18.m1.1.1.1.1.3.3.2.2">𝜎</ci><cn type="integer" id="S4.E18.m1.1.1.1.1.3.3.2.3.cmml" xref="S4.E18.m1.1.1.1.1.3.3.2.3">2</cn></apply><cn type="integer" id="S4.E18.m1.1.1.1.1.3.3.3.cmml" xref="S4.E18.m1.1.1.1.1.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E18.m1.1c">Variance(G_{1}+G_{2})=\sigma_{1}^{2}+\sigma_{2}^{2}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(18)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SSx2.p6" class="ltx_para">
<p id="S4.SSx2.p6.1" class="ltx_p">In a CNN model with N uncorrelated Gaussian noise hidden layers, the total noise introduced by multiple noise layers with standard deviation <math id="S4.SSx2.p6.1.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SSx2.p6.1.m1.1a"><mi id="S4.SSx2.p6.1.m1.1.1" xref="S4.SSx2.p6.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S4.SSx2.p6.1.m1.1b"><ci id="S4.SSx2.p6.1.m1.1.1.cmml" xref="S4.SSx2.p6.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx2.p6.1.m1.1c">\sigma</annotation></semantics></math> is equivalent to a single noise layer with a standard deviation of:</p>
<table id="S4.E19" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S4.E19.m1.1" class="ltx_Math" alttext="\sigma_{Total}=\sqrt{N}\sigma" display="block"><semantics id="S4.E19.m1.1a"><mrow id="S4.E19.m1.1.1" xref="S4.E19.m1.1.1.cmml"><msub id="S4.E19.m1.1.1.2" xref="S4.E19.m1.1.1.2.cmml"><mi id="S4.E19.m1.1.1.2.2" xref="S4.E19.m1.1.1.2.2.cmml">σ</mi><mrow id="S4.E19.m1.1.1.2.3" xref="S4.E19.m1.1.1.2.3.cmml"><mi id="S4.E19.m1.1.1.2.3.2" xref="S4.E19.m1.1.1.2.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S4.E19.m1.1.1.2.3.1" xref="S4.E19.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.E19.m1.1.1.2.3.3" xref="S4.E19.m1.1.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E19.m1.1.1.2.3.1a" xref="S4.E19.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.E19.m1.1.1.2.3.4" xref="S4.E19.m1.1.1.2.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.E19.m1.1.1.2.3.1b" xref="S4.E19.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.E19.m1.1.1.2.3.5" xref="S4.E19.m1.1.1.2.3.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E19.m1.1.1.2.3.1c" xref="S4.E19.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.E19.m1.1.1.2.3.6" xref="S4.E19.m1.1.1.2.3.6.cmml">l</mi></mrow></msub><mo id="S4.E19.m1.1.1.1" xref="S4.E19.m1.1.1.1.cmml">=</mo><mrow id="S4.E19.m1.1.1.3" xref="S4.E19.m1.1.1.3.cmml"><msqrt id="S4.E19.m1.1.1.3.2" xref="S4.E19.m1.1.1.3.2.cmml"><mi id="S4.E19.m1.1.1.3.2.2" xref="S4.E19.m1.1.1.3.2.2.cmml">N</mi></msqrt><mo lspace="0em" rspace="0em" id="S4.E19.m1.1.1.3.1" xref="S4.E19.m1.1.1.3.1.cmml">​</mo><mi id="S4.E19.m1.1.1.3.3" xref="S4.E19.m1.1.1.3.3.cmml">σ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E19.m1.1b"><apply id="S4.E19.m1.1.1.cmml" xref="S4.E19.m1.1.1"><eq id="S4.E19.m1.1.1.1.cmml" xref="S4.E19.m1.1.1.1"></eq><apply id="S4.E19.m1.1.1.2.cmml" xref="S4.E19.m1.1.1.2"><csymbol cd="ambiguous" id="S4.E19.m1.1.1.2.1.cmml" xref="S4.E19.m1.1.1.2">subscript</csymbol><ci id="S4.E19.m1.1.1.2.2.cmml" xref="S4.E19.m1.1.1.2.2">𝜎</ci><apply id="S4.E19.m1.1.1.2.3.cmml" xref="S4.E19.m1.1.1.2.3"><times id="S4.E19.m1.1.1.2.3.1.cmml" xref="S4.E19.m1.1.1.2.3.1"></times><ci id="S4.E19.m1.1.1.2.3.2.cmml" xref="S4.E19.m1.1.1.2.3.2">𝑇</ci><ci id="S4.E19.m1.1.1.2.3.3.cmml" xref="S4.E19.m1.1.1.2.3.3">𝑜</ci><ci id="S4.E19.m1.1.1.2.3.4.cmml" xref="S4.E19.m1.1.1.2.3.4">𝑡</ci><ci id="S4.E19.m1.1.1.2.3.5.cmml" xref="S4.E19.m1.1.1.2.3.5">𝑎</ci><ci id="S4.E19.m1.1.1.2.3.6.cmml" xref="S4.E19.m1.1.1.2.3.6">𝑙</ci></apply></apply><apply id="S4.E19.m1.1.1.3.cmml" xref="S4.E19.m1.1.1.3"><times id="S4.E19.m1.1.1.3.1.cmml" xref="S4.E19.m1.1.1.3.1"></times><apply id="S4.E19.m1.1.1.3.2.cmml" xref="S4.E19.m1.1.1.3.2"><root id="S4.E19.m1.1.1.3.2a.cmml" xref="S4.E19.m1.1.1.3.2"></root><ci id="S4.E19.m1.1.1.3.2.2.cmml" xref="S4.E19.m1.1.1.3.2.2">𝑁</ci></apply><ci id="S4.E19.m1.1.1.3.3.cmml" xref="S4.E19.m1.1.1.3.3">𝜎</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E19.m1.1c">\sigma_{Total}=\sqrt{N}\sigma</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(19)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SSx2.p7" class="ltx_para">
<p id="S4.SSx2.p7.1" class="ltx_p">Table <a href="#S4.T6" title="Table 6 ‣ Experiment 2: CNN with Multiple Gaussian Noise Layers vs. a Single Layer ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> presents the results from training models with multiple noisy layers vs. a single noise layer. For comparison, we set <math id="S4.SSx2.p7.1.m1.1" class="ltx_Math" alttext="\sigma=0.1" display="inline"><semantics id="S4.SSx2.p7.1.m1.1a"><mrow id="S4.SSx2.p7.1.m1.1.1" xref="S4.SSx2.p7.1.m1.1.1.cmml"><mi id="S4.SSx2.p7.1.m1.1.1.2" xref="S4.SSx2.p7.1.m1.1.1.2.cmml">σ</mi><mo id="S4.SSx2.p7.1.m1.1.1.1" xref="S4.SSx2.p7.1.m1.1.1.1.cmml">=</mo><mn id="S4.SSx2.p7.1.m1.1.1.3" xref="S4.SSx2.p7.1.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SSx2.p7.1.m1.1b"><apply id="S4.SSx2.p7.1.m1.1.1.cmml" xref="S4.SSx2.p7.1.m1.1.1"><eq id="S4.SSx2.p7.1.m1.1.1.1.cmml" xref="S4.SSx2.p7.1.m1.1.1.1"></eq><ci id="S4.SSx2.p7.1.m1.1.1.2.cmml" xref="S4.SSx2.p7.1.m1.1.1.2">𝜎</ci><cn type="float" id="S4.SSx2.p7.1.m1.1.1.3.cmml" xref="S4.SSx2.p7.1.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx2.p7.1.m1.1c">\sigma=0.1</annotation></semantics></math> when training all three models with multiple noise layers shown in Figure <a href="#S4.F5" title="Figure 5 ‣ Experiment 1: CNN with Gaussian noise hidden layers in Centralized Setting ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
The standard deviation of the model with a single noise layer is computed based on Equation <a href="#S4.E18" title="In Experiment 2: CNN with Multiple Gaussian Noise Layers vs. a Single Layer ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">18</span></a>.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Training deep learning models with a single Gaussian noise hidden layer versus multiple layers.</figcaption>
<table id="S4.T6.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.1.1.1" class="ltx_tr">
<th id="S4.T6.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" colspan="4">Model 1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.1.2.1" class="ltx_tr">
<td id="S4.T6.1.2.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Model Type</td>
<td id="S4.T6.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Standard Deviation</td>
<td id="S4.T6.1.2.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Train Accuracy</td>
<td id="S4.T6.1.2.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Test Accuracy</td>
</tr>
<tr id="S4.T6.1.3.2" class="ltx_tr">
<td id="S4.T6.1.3.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Base model</td>
<td id="S4.T6.1.3.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.0</td>
<td id="S4.T6.1.3.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.93</td>
<td id="S4.T6.1.3.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.82</td>
</tr>
<tr id="S4.T6.1.4.3" class="ltx_tr">
<td id="S4.T6.1.4.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">Multiple noise layers</td>
<td id="S4.T6.1.4.3.2" class="ltx_td ltx_align_left ltx_border_r">0.1</td>
<td id="S4.T6.1.4.3.3" class="ltx_td ltx_align_left ltx_border_r">0.92</td>
<td id="S4.T6.1.4.3.4" class="ltx_td ltx_align_left ltx_border_r">0.83</td>
</tr>
<tr id="S4.T6.1.5.4" class="ltx_tr">
<td id="S4.T6.1.5.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">Single layer substitute</td>
<td id="S4.T6.1.5.4.2" class="ltx_td ltx_align_left ltx_border_r">0.28</td>
<td id="S4.T6.1.5.4.3" class="ltx_td ltx_align_left ltx_border_r">0.92</td>
<td id="S4.T6.1.5.4.4" class="ltx_td ltx_align_left ltx_border_r">0.83</td>
</tr>
<tr id="S4.T6.1.6.5" class="ltx_tr">
<th id="S4.T6.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_tt" colspan="4">Model 2</th>
</tr>
<tr id="S4.T6.1.7.6" class="ltx_tr">
<td id="S4.T6.1.7.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Model Type</td>
<td id="S4.T6.1.7.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Standard Deviation</td>
<td id="S4.T6.1.7.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Train Accuracy</td>
<td id="S4.T6.1.7.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Test Accuracy</td>
</tr>
<tr id="S4.T6.1.8.7" class="ltx_tr">
<td id="S4.T6.1.8.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Base model</td>
<td id="S4.T6.1.8.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.0</td>
<td id="S4.T6.1.8.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.99</td>
<td id="S4.T6.1.8.7.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.79</td>
</tr>
<tr id="S4.T6.1.9.8" class="ltx_tr">
<td id="S4.T6.1.9.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">Multiple noise layers</td>
<td id="S4.T6.1.9.8.2" class="ltx_td ltx_align_left ltx_border_r">0.1</td>
<td id="S4.T6.1.9.8.3" class="ltx_td ltx_align_left ltx_border_r">0.99</td>
<td id="S4.T6.1.9.8.4" class="ltx_td ltx_align_left ltx_border_r">0.80</td>
</tr>
<tr id="S4.T6.1.10.9" class="ltx_tr">
<td id="S4.T6.1.10.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">Single layer substitute</td>
<td id="S4.T6.1.10.9.2" class="ltx_td ltx_align_left ltx_border_r">0.22</td>
<td id="S4.T6.1.10.9.3" class="ltx_td ltx_align_left ltx_border_r">0.99</td>
<td id="S4.T6.1.10.9.4" class="ltx_td ltx_align_left ltx_border_r">0.80</td>
</tr>
<tr id="S4.T6.1.11.10" class="ltx_tr">
<th id="S4.T6.1.11.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_tt" colspan="4">Model 3</th>
</tr>
<tr id="S4.T6.1.12.11" class="ltx_tr">
<td id="S4.T6.1.12.11.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Model Type</td>
<td id="S4.T6.1.12.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Standard Deviation</td>
<td id="S4.T6.1.12.11.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Train Accuracy</td>
<td id="S4.T6.1.12.11.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Test Accuracy</td>
</tr>
<tr id="S4.T6.1.13.12" class="ltx_tr">
<td id="S4.T6.1.13.12.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Base model</td>
<td id="S4.T6.1.13.12.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.0</td>
<td id="S4.T6.1.13.12.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.92</td>
<td id="S4.T6.1.13.12.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.82</td>
</tr>
<tr id="S4.T6.1.14.13" class="ltx_tr">
<td id="S4.T6.1.14.13.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">Multiple noise layers</td>
<td id="S4.T6.1.14.13.2" class="ltx_td ltx_align_left ltx_border_r">0.1</td>
<td id="S4.T6.1.14.13.3" class="ltx_td ltx_align_left ltx_border_r">0.91</td>
<td id="S4.T6.1.14.13.4" class="ltx_td ltx_align_left ltx_border_r">0.83</td>
</tr>
<tr id="S4.T6.1.15.14" class="ltx_tr">
<td id="S4.T6.1.15.14.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">Single layer substitute</td>
<td id="S4.T6.1.15.14.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">0.33</td>
<td id="S4.T6.1.15.14.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">0.92</td>
<td id="S4.T6.1.15.14.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">0.83</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SSx2.p8" class="ltx_para">
<p id="S4.SSx2.p8.1" class="ltx_p">The obtained results suggest that the number of layers does not affect the model performance. In this framework, the controlling parameter is the standard deviation of the added noise. Training the models with multiple noise layers allows us to fine-tune the standard deviation of the noise generated at the layers and adjust the model according to the problem specifications and data at hand to achieve optimal performance.</p>
</div>
</section>
<section id="S4.SSx3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Experiment 3: Gaussian noise hidden layers in Federated Setting </h3>

<div id="S4.SSx3.p1" class="ltx_para">
<p id="S4.SSx3.p1.1" class="ltx_p">Extending the experiments to federated learning, we explore the effect of different noise levels and compare the results with the centralized models. Choosing the Gaussian noise magnitude is critical because it determines the level of privacy. A lower noise level will result in a more accurate CNN model but will also provide weaker privacy guarantees.
It is important to note that, in practice, it is possible for an attacker to learn sensitive information about the training data by exploiting vulnerabilities in the model or the training process. Therefore, it is important to take additional steps to protect the privacy of the training data, such as using secure training environments and encryption. Using horizontal partitioning, the data is randomly and equally split between 3 arbitrary clients.</p>
</div>
<div id="S4.SSx3.p2" class="ltx_para">
<p id="S4.SSx3.p2.1" class="ltx_p">First, the models were trained locally with 20 noise levels between <math id="S4.SSx3.p2.1.m1.2" class="ltx_Math" alttext="\{0,1\}" display="inline"><semantics id="S4.SSx3.p2.1.m1.2a"><mrow id="S4.SSx3.p2.1.m1.2.3.2" xref="S4.SSx3.p2.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.SSx3.p2.1.m1.2.3.2.1" xref="S4.SSx3.p2.1.m1.2.3.1.cmml">{</mo><mn id="S4.SSx3.p2.1.m1.1.1" xref="S4.SSx3.p2.1.m1.1.1.cmml">0</mn><mo id="S4.SSx3.p2.1.m1.2.3.2.2" xref="S4.SSx3.p2.1.m1.2.3.1.cmml">,</mo><mn id="S4.SSx3.p2.1.m1.2.2" xref="S4.SSx3.p2.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S4.SSx3.p2.1.m1.2.3.2.3" xref="S4.SSx3.p2.1.m1.2.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SSx3.p2.1.m1.2b"><set id="S4.SSx3.p2.1.m1.2.3.1.cmml" xref="S4.SSx3.p2.1.m1.2.3.2"><cn type="integer" id="S4.SSx3.p2.1.m1.1.1.cmml" xref="S4.SSx3.p2.1.m1.1.1">0</cn><cn type="integer" id="S4.SSx3.p2.1.m1.2.2.cmml" xref="S4.SSx3.p2.1.m1.2.2">1</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx3.p2.1.m1.2c">\{0,1\}</annotation></semantics></math>, and SNR was computed. The noise level that yields the optimal SNR for the clients and the results from training the federated learning model with optimized noise obtained from maximizing SNR are presented in Table <a href="#S4.T7" title="Table 7 ‣ Experiment 3: Gaussian noise hidden layers in Federated Setting ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. The federated learning models are trained for 20 communication rounds at different noise levels. Global accuracy and global loss are measured for evaluation. It can be observed that despite significant differences in size, the models vary by a maximum of 3% in global accuracy, while global loss remains relatively consistent.</p>
</div>
<figure id="S4.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span>The standard deviation of the additive noise is set based on the optimal SNR.</figcaption>
<table id="S4.T7.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T7.1.1.1" class="ltx_tr">
<th id="S4.T7.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Architecture</th>
<th id="S4.T7.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Client 1</th>
<th id="S4.T7.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Client 2</th>
<th id="S4.T7.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Client 3</th>
<th id="S4.T7.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Global Loss</th>
<th id="S4.T7.1.1.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Global Accuracy</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T7.1.2.1" class="ltx_tr">
<td id="S4.T7.1.2.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Model 1</td>
<td id="S4.T7.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.21</td>
<td id="S4.T7.1.2.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.26</td>
<td id="S4.T7.1.2.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.16</td>
<td id="S4.T7.1.2.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.60</td>
<td id="S4.T7.1.2.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.87</td>
</tr>
<tr id="S4.T7.1.3.2" class="ltx_tr">
<td id="S4.T7.1.3.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">Model 2</td>
<td id="S4.T7.1.3.2.2" class="ltx_td ltx_align_left ltx_border_r">0.53</td>
<td id="S4.T7.1.3.2.3" class="ltx_td ltx_align_left ltx_border_r">0.37</td>
<td id="S4.T7.1.3.2.4" class="ltx_td ltx_align_left ltx_border_r">0.16</td>
<td id="S4.T7.1.3.2.5" class="ltx_td ltx_align_left ltx_border_r">1.63</td>
<td id="S4.T7.1.3.2.6" class="ltx_td ltx_align_left ltx_border_r">0.84</td>
</tr>
<tr id="S4.T7.1.4.3" class="ltx_tr">
<td id="S4.T7.1.4.3.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">Model 3</td>
<td id="S4.T7.1.4.3.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">0.11</td>
<td id="S4.T7.1.4.3.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">0.16</td>
<td id="S4.T7.1.4.3.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">0.16</td>
<td id="S4.T7.1.4.3.5" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">1.60</td>
<td id="S4.T7.1.4.3.6" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">0.86</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SSx3.p3" class="ltx_para">
<p id="S4.SSx3.p3.1" class="ltx_p">In the next step, we trained the model at five noise levels, the results of which are shown in <a href="#S4.T8" title="Table 8 ‣ Experiment 3: Gaussian noise hidden layers in Federated Setting ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. Training the models with Gaussian noise hidden layers significantly improves the model stability.</p>
</div>
<div id="S4.SSx3.p4" class="ltx_para">
<p id="S4.SSx3.p4.1" class="ltx_p">As seen in Figure <a href="#S4.F7" title="Figure 7 ‣ Experiment 1: CNN with Gaussian noise hidden layers in Centralized Setting ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, it is possible to add higher noise levels to improve privacy guarantees, and the global accuracy and loss remain relatively constant with varying noise levels.</p>
</div>
<figure id="S4.T8" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8: </span>The standard deviation of the additive noise is fixed across all clients.</figcaption>
<table id="S4.T8.10" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T8.10.11.1" class="ltx_tr">
<th id="S4.T8.10.11.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" colspan="6">Global Accuracy</th>
</tr>
<tr id="S4.T8.5.5" class="ltx_tr">
<th id="S4.T8.5.5.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Architecture</th>
<th id="S4.T8.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">
<math id="S4.T8.1.1.1.m1.1" class="ltx_Math" alttext="\sigma=" display="inline"><semantics id="S4.T8.1.1.1.m1.1a"><mrow id="S4.T8.1.1.1.m1.1.1" xref="S4.T8.1.1.1.m1.1.1.cmml"><mi id="S4.T8.1.1.1.m1.1.1.2" xref="S4.T8.1.1.1.m1.1.1.2.cmml">σ</mi><mo id="S4.T8.1.1.1.m1.1.1.1" xref="S4.T8.1.1.1.m1.1.1.1.cmml">=</mo><mi id="S4.T8.1.1.1.m1.1.1.3" xref="S4.T8.1.1.1.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.1.1.1.m1.1b"><apply id="S4.T8.1.1.1.m1.1.1.cmml" xref="S4.T8.1.1.1.m1.1.1"><eq id="S4.T8.1.1.1.m1.1.1.1.cmml" xref="S4.T8.1.1.1.m1.1.1.1"></eq><ci id="S4.T8.1.1.1.m1.1.1.2.cmml" xref="S4.T8.1.1.1.m1.1.1.2">𝜎</ci><csymbol cd="latexml" id="S4.T8.1.1.1.m1.1.1.3.cmml" xref="S4.T8.1.1.1.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.1.1.1.m1.1c">\sigma=</annotation></semantics></math>0.1</th>
<th id="S4.T8.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">
<math id="S4.T8.2.2.2.m1.1" class="ltx_Math" alttext="\sigma=" display="inline"><semantics id="S4.T8.2.2.2.m1.1a"><mrow id="S4.T8.2.2.2.m1.1.1" xref="S4.T8.2.2.2.m1.1.1.cmml"><mi id="S4.T8.2.2.2.m1.1.1.2" xref="S4.T8.2.2.2.m1.1.1.2.cmml">σ</mi><mo id="S4.T8.2.2.2.m1.1.1.1" xref="S4.T8.2.2.2.m1.1.1.1.cmml">=</mo><mi id="S4.T8.2.2.2.m1.1.1.3" xref="S4.T8.2.2.2.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.2.2.2.m1.1b"><apply id="S4.T8.2.2.2.m1.1.1.cmml" xref="S4.T8.2.2.2.m1.1.1"><eq id="S4.T8.2.2.2.m1.1.1.1.cmml" xref="S4.T8.2.2.2.m1.1.1.1"></eq><ci id="S4.T8.2.2.2.m1.1.1.2.cmml" xref="S4.T8.2.2.2.m1.1.1.2">𝜎</ci><csymbol cd="latexml" id="S4.T8.2.2.2.m1.1.1.3.cmml" xref="S4.T8.2.2.2.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.2.2.2.m1.1c">\sigma=</annotation></semantics></math>0.3</th>
<th id="S4.T8.3.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">
<math id="S4.T8.3.3.3.m1.1" class="ltx_Math" alttext="\sigma=" display="inline"><semantics id="S4.T8.3.3.3.m1.1a"><mrow id="S4.T8.3.3.3.m1.1.1" xref="S4.T8.3.3.3.m1.1.1.cmml"><mi id="S4.T8.3.3.3.m1.1.1.2" xref="S4.T8.3.3.3.m1.1.1.2.cmml">σ</mi><mo id="S4.T8.3.3.3.m1.1.1.1" xref="S4.T8.3.3.3.m1.1.1.1.cmml">=</mo><mi id="S4.T8.3.3.3.m1.1.1.3" xref="S4.T8.3.3.3.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.3.3.3.m1.1b"><apply id="S4.T8.3.3.3.m1.1.1.cmml" xref="S4.T8.3.3.3.m1.1.1"><eq id="S4.T8.3.3.3.m1.1.1.1.cmml" xref="S4.T8.3.3.3.m1.1.1.1"></eq><ci id="S4.T8.3.3.3.m1.1.1.2.cmml" xref="S4.T8.3.3.3.m1.1.1.2">𝜎</ci><csymbol cd="latexml" id="S4.T8.3.3.3.m1.1.1.3.cmml" xref="S4.T8.3.3.3.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.3.3.3.m1.1c">\sigma=</annotation></semantics></math>0.5</th>
<th id="S4.T8.4.4.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">
<math id="S4.T8.4.4.4.m1.1" class="ltx_Math" alttext="\sigma=" display="inline"><semantics id="S4.T8.4.4.4.m1.1a"><mrow id="S4.T8.4.4.4.m1.1.1" xref="S4.T8.4.4.4.m1.1.1.cmml"><mi id="S4.T8.4.4.4.m1.1.1.2" xref="S4.T8.4.4.4.m1.1.1.2.cmml">σ</mi><mo id="S4.T8.4.4.4.m1.1.1.1" xref="S4.T8.4.4.4.m1.1.1.1.cmml">=</mo><mi id="S4.T8.4.4.4.m1.1.1.3" xref="S4.T8.4.4.4.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.4.4.4.m1.1b"><apply id="S4.T8.4.4.4.m1.1.1.cmml" xref="S4.T8.4.4.4.m1.1.1"><eq id="S4.T8.4.4.4.m1.1.1.1.cmml" xref="S4.T8.4.4.4.m1.1.1.1"></eq><ci id="S4.T8.4.4.4.m1.1.1.2.cmml" xref="S4.T8.4.4.4.m1.1.1.2">𝜎</ci><csymbol cd="latexml" id="S4.T8.4.4.4.m1.1.1.3.cmml" xref="S4.T8.4.4.4.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.4.4.4.m1.1c">\sigma=</annotation></semantics></math>0.7</th>
<th id="S4.T8.5.5.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">
<math id="S4.T8.5.5.5.m1.1" class="ltx_Math" alttext="\sigma=" display="inline"><semantics id="S4.T8.5.5.5.m1.1a"><mrow id="S4.T8.5.5.5.m1.1.1" xref="S4.T8.5.5.5.m1.1.1.cmml"><mi id="S4.T8.5.5.5.m1.1.1.2" xref="S4.T8.5.5.5.m1.1.1.2.cmml">σ</mi><mo id="S4.T8.5.5.5.m1.1.1.1" xref="S4.T8.5.5.5.m1.1.1.1.cmml">=</mo><mi id="S4.T8.5.5.5.m1.1.1.3" xref="S4.T8.5.5.5.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.5.5.5.m1.1b"><apply id="S4.T8.5.5.5.m1.1.1.cmml" xref="S4.T8.5.5.5.m1.1.1"><eq id="S4.T8.5.5.5.m1.1.1.1.cmml" xref="S4.T8.5.5.5.m1.1.1.1"></eq><ci id="S4.T8.5.5.5.m1.1.1.2.cmml" xref="S4.T8.5.5.5.m1.1.1.2">𝜎</ci><csymbol cd="latexml" id="S4.T8.5.5.5.m1.1.1.3.cmml" xref="S4.T8.5.5.5.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.5.5.5.m1.1c">\sigma=</annotation></semantics></math>0.9</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T8.10.12.1" class="ltx_tr">
<td id="S4.T8.10.12.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Model 1</td>
<td id="S4.T8.10.12.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.86</td>
<td id="S4.T8.10.12.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.86</td>
<td id="S4.T8.10.12.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.87</td>
<td id="S4.T8.10.12.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.86</td>
<td id="S4.T8.10.12.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.86</td>
</tr>
<tr id="S4.T8.10.13.2" class="ltx_tr">
<td id="S4.T8.10.13.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">Model 2</td>
<td id="S4.T8.10.13.2.2" class="ltx_td ltx_align_left ltx_border_r">0.78</td>
<td id="S4.T8.10.13.2.3" class="ltx_td ltx_align_left ltx_border_r">0.83</td>
<td id="S4.T8.10.13.2.4" class="ltx_td ltx_align_left ltx_border_r">0.84</td>
<td id="S4.T8.10.13.2.5" class="ltx_td ltx_align_left ltx_border_r">0.84</td>
<td id="S4.T8.10.13.2.6" class="ltx_td ltx_align_left ltx_border_r">0.86</td>
</tr>
<tr id="S4.T8.10.14.3" class="ltx_tr">
<td id="S4.T8.10.14.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">Model 3</td>
<td id="S4.T8.10.14.3.2" class="ltx_td ltx_align_left ltx_border_r">0.85</td>
<td id="S4.T8.10.14.3.3" class="ltx_td ltx_align_left ltx_border_r">0.86</td>
<td id="S4.T8.10.14.3.4" class="ltx_td ltx_align_left ltx_border_r">0.87</td>
<td id="S4.T8.10.14.3.5" class="ltx_td ltx_align_left ltx_border_r">0.87</td>
<td id="S4.T8.10.14.3.6" class="ltx_td ltx_align_left ltx_border_r">0.85</td>
</tr>
<tr id="S4.T8.10.15.4" class="ltx_tr">
<th id="S4.T8.10.15.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_tt" colspan="6">Global Loss</th>
</tr>
<tr id="S4.T8.10.10" class="ltx_tr">
<th id="S4.T8.10.10.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Architecture</th>
<th id="S4.T8.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">
<math id="S4.T8.6.6.1.m1.1" class="ltx_Math" alttext="\sigma=" display="inline"><semantics id="S4.T8.6.6.1.m1.1a"><mrow id="S4.T8.6.6.1.m1.1.1" xref="S4.T8.6.6.1.m1.1.1.cmml"><mi id="S4.T8.6.6.1.m1.1.1.2" xref="S4.T8.6.6.1.m1.1.1.2.cmml">σ</mi><mo id="S4.T8.6.6.1.m1.1.1.1" xref="S4.T8.6.6.1.m1.1.1.1.cmml">=</mo><mi id="S4.T8.6.6.1.m1.1.1.3" xref="S4.T8.6.6.1.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.6.6.1.m1.1b"><apply id="S4.T8.6.6.1.m1.1.1.cmml" xref="S4.T8.6.6.1.m1.1.1"><eq id="S4.T8.6.6.1.m1.1.1.1.cmml" xref="S4.T8.6.6.1.m1.1.1.1"></eq><ci id="S4.T8.6.6.1.m1.1.1.2.cmml" xref="S4.T8.6.6.1.m1.1.1.2">𝜎</ci><csymbol cd="latexml" id="S4.T8.6.6.1.m1.1.1.3.cmml" xref="S4.T8.6.6.1.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.6.6.1.m1.1c">\sigma=</annotation></semantics></math>0.1</th>
<th id="S4.T8.7.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">
<math id="S4.T8.7.7.2.m1.1" class="ltx_Math" alttext="\sigma=" display="inline"><semantics id="S4.T8.7.7.2.m1.1a"><mrow id="S4.T8.7.7.2.m1.1.1" xref="S4.T8.7.7.2.m1.1.1.cmml"><mi id="S4.T8.7.7.2.m1.1.1.2" xref="S4.T8.7.7.2.m1.1.1.2.cmml">σ</mi><mo id="S4.T8.7.7.2.m1.1.1.1" xref="S4.T8.7.7.2.m1.1.1.1.cmml">=</mo><mi id="S4.T8.7.7.2.m1.1.1.3" xref="S4.T8.7.7.2.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.7.7.2.m1.1b"><apply id="S4.T8.7.7.2.m1.1.1.cmml" xref="S4.T8.7.7.2.m1.1.1"><eq id="S4.T8.7.7.2.m1.1.1.1.cmml" xref="S4.T8.7.7.2.m1.1.1.1"></eq><ci id="S4.T8.7.7.2.m1.1.1.2.cmml" xref="S4.T8.7.7.2.m1.1.1.2">𝜎</ci><csymbol cd="latexml" id="S4.T8.7.7.2.m1.1.1.3.cmml" xref="S4.T8.7.7.2.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.7.7.2.m1.1c">\sigma=</annotation></semantics></math>0.3</th>
<th id="S4.T8.8.8.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">
<math id="S4.T8.8.8.3.m1.1" class="ltx_Math" alttext="\sigma=" display="inline"><semantics id="S4.T8.8.8.3.m1.1a"><mrow id="S4.T8.8.8.3.m1.1.1" xref="S4.T8.8.8.3.m1.1.1.cmml"><mi id="S4.T8.8.8.3.m1.1.1.2" xref="S4.T8.8.8.3.m1.1.1.2.cmml">σ</mi><mo id="S4.T8.8.8.3.m1.1.1.1" xref="S4.T8.8.8.3.m1.1.1.1.cmml">=</mo><mi id="S4.T8.8.8.3.m1.1.1.3" xref="S4.T8.8.8.3.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.8.8.3.m1.1b"><apply id="S4.T8.8.8.3.m1.1.1.cmml" xref="S4.T8.8.8.3.m1.1.1"><eq id="S4.T8.8.8.3.m1.1.1.1.cmml" xref="S4.T8.8.8.3.m1.1.1.1"></eq><ci id="S4.T8.8.8.3.m1.1.1.2.cmml" xref="S4.T8.8.8.3.m1.1.1.2">𝜎</ci><csymbol cd="latexml" id="S4.T8.8.8.3.m1.1.1.3.cmml" xref="S4.T8.8.8.3.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.8.8.3.m1.1c">\sigma=</annotation></semantics></math>0.5</th>
<th id="S4.T8.9.9.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">
<math id="S4.T8.9.9.4.m1.1" class="ltx_Math" alttext="\sigma=" display="inline"><semantics id="S4.T8.9.9.4.m1.1a"><mrow id="S4.T8.9.9.4.m1.1.1" xref="S4.T8.9.9.4.m1.1.1.cmml"><mi id="S4.T8.9.9.4.m1.1.1.2" xref="S4.T8.9.9.4.m1.1.1.2.cmml">σ</mi><mo id="S4.T8.9.9.4.m1.1.1.1" xref="S4.T8.9.9.4.m1.1.1.1.cmml">=</mo><mi id="S4.T8.9.9.4.m1.1.1.3" xref="S4.T8.9.9.4.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.9.9.4.m1.1b"><apply id="S4.T8.9.9.4.m1.1.1.cmml" xref="S4.T8.9.9.4.m1.1.1"><eq id="S4.T8.9.9.4.m1.1.1.1.cmml" xref="S4.T8.9.9.4.m1.1.1.1"></eq><ci id="S4.T8.9.9.4.m1.1.1.2.cmml" xref="S4.T8.9.9.4.m1.1.1.2">𝜎</ci><csymbol cd="latexml" id="S4.T8.9.9.4.m1.1.1.3.cmml" xref="S4.T8.9.9.4.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.9.9.4.m1.1c">\sigma=</annotation></semantics></math>0.7</th>
<th id="S4.T8.10.10.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">
<math id="S4.T8.10.10.5.m1.1" class="ltx_Math" alttext="\sigma=" display="inline"><semantics id="S4.T8.10.10.5.m1.1a"><mrow id="S4.T8.10.10.5.m1.1.1" xref="S4.T8.10.10.5.m1.1.1.cmml"><mi id="S4.T8.10.10.5.m1.1.1.2" xref="S4.T8.10.10.5.m1.1.1.2.cmml">σ</mi><mo id="S4.T8.10.10.5.m1.1.1.1" xref="S4.T8.10.10.5.m1.1.1.1.cmml">=</mo><mi id="S4.T8.10.10.5.m1.1.1.3" xref="S4.T8.10.10.5.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.10.10.5.m1.1b"><apply id="S4.T8.10.10.5.m1.1.1.cmml" xref="S4.T8.10.10.5.m1.1.1"><eq id="S4.T8.10.10.5.m1.1.1.1.cmml" xref="S4.T8.10.10.5.m1.1.1.1"></eq><ci id="S4.T8.10.10.5.m1.1.1.2.cmml" xref="S4.T8.10.10.5.m1.1.1.2">𝜎</ci><csymbol cd="latexml" id="S4.T8.10.10.5.m1.1.1.3.cmml" xref="S4.T8.10.10.5.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.10.10.5.m1.1c">\sigma=</annotation></semantics></math>0.9</th>
</tr>
<tr id="S4.T8.10.16.5" class="ltx_tr">
<td id="S4.T8.10.16.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Model 1</td>
<td id="S4.T8.10.16.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.60</td>
<td id="S4.T8.10.16.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.61</td>
<td id="S4.T8.10.16.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.60</td>
<td id="S4.T8.10.16.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.61</td>
<td id="S4.T8.10.16.5.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.62</td>
</tr>
<tr id="S4.T8.10.17.6" class="ltx_tr">
<td id="S4.T8.10.17.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">Model 2</td>
<td id="S4.T8.10.17.6.2" class="ltx_td ltx_align_left ltx_border_r">1.68</td>
<td id="S4.T8.10.17.6.3" class="ltx_td ltx_align_left ltx_border_r">1.64</td>
<td id="S4.T8.10.17.6.4" class="ltx_td ltx_align_left ltx_border_r">1.63</td>
<td id="S4.T8.10.17.6.5" class="ltx_td ltx_align_left ltx_border_r">1.63</td>
<td id="S4.T8.10.17.6.6" class="ltx_td ltx_align_left ltx_border_r">1.62</td>
</tr>
<tr id="S4.T8.10.18.7" class="ltx_tr">
<td id="S4.T8.10.18.7.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">Model 3</td>
<td id="S4.T8.10.18.7.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">1.61</td>
<td id="S4.T8.10.18.7.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">1.61</td>
<td id="S4.T8.10.18.7.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">1.61</td>
<td id="S4.T8.10.18.7.5" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">1.63</td>
<td id="S4.T8.10.18.7.6" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">1.72</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SSx3.p5" class="ltx_para">
<p id="S4.SSx3.p5.1" class="ltx_p">The analysis suggests that deep learning models are relatively noise-stable in federated settings. The models can learn the patterns of the data and the added noise while preserving privacy. The stability of the models in federated learning is beneficial as it increases the model’s threshold for added noise, ensuring that privacy is maintained. Increasing the standard deviation of Gaussian noise, which acts as a regularization method, also improves the overall accuracy of test data.</p>
</div>
</section>
<section id="S4.SSx4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Experiment 4: Comparison of Noise Infusion Mechanisms</h3>

<div id="S4.SSx4.p1" class="ltx_para">
<p id="S4.SSx4.p1.1" class="ltx_p">The choice of noise infusion mechanism plays a crucial role in enhancing deep learning models’ generalization, stability, and privacy. This section compares the impact of noise infusion schemes mentioned in Table <a href="#S3.T1" title="Table 1 ‣ 3 Training with Noise in Deep Neural Networks ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">Noisy input: The input noise is implemented by adding a random value sampled from the Gaussian distribution in the predefined standard deviation range to the input data during training. Input noise behaves as a data augmentation method, often used to expand the input sample or introduce randomness in the data to reduce overfitting. However, if the noise level is too high, it can distort the data and lead to the model learning incorrect patterns.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">Noisy network weights: To introduce noise to model weights, the noise is directly added to the weights retrieved from the model.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p">Noisy gradients: Noise is added to the original gradients. The modified gradients are then used to update the model weights during training.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p">Noisy labels: For noisy labels, the random value is added to the labels before training. We also included noise clipping to ensure the labels were within the correct range to avoid extreme changes and too much distortion in the labels.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SSx4.p2" class="ltx_para">
<p id="S4.SSx4.p2.1" class="ltx_p">In this section, We explore the effectiveness of different mechanisms and compare their results with those of Gaussian noise hidden layers. We train the centralized CNN models using five noise infusion mechanisms where the standard deviation of the additive noise is consistently set at <math id="S4.SSx4.p2.1.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S4.SSx4.p2.1.m1.1a"><mn id="S4.SSx4.p2.1.m1.1.1" xref="S4.SSx4.p2.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S4.SSx4.p2.1.m1.1b"><cn type="float" id="S4.SSx4.p2.1.m1.1.1.cmml" xref="S4.SSx4.p2.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx4.p2.1.m1.1c">0.1</annotation></semantics></math>. The results are presented in Figure <a href="#S4.F10" title="Figure 10 ‣ Experiment 4: Comparison of Noise Infusion Mechanisms ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>.</p>
</div>
<figure id="S4.F10" class="ltx_figure"><img src="/html/2311.05790/assets/x10.png" id="S4.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>This figure presents a comparison of the training and test accuracy of three models across six mechanisms. The first set of columns for each figure represents the base model trained without noise.</figcaption>
</figure>
<div id="S4.SSx4.p3" class="ltx_para">
<p id="S4.SSx4.p3.1" class="ltx_p">The base model serves as a control group without additive noise. Models 1 and 3 are most sensitive to injecting noise into input and weights, significantly dropping training and test accuracy. The models with noisy weights also fail to learn effectively and generalize, which indicates the detrimental impact of noisy weights on training. While there is a slight decrease in training and test accuracy, models trained with Gaussian noise hidden layers, labels, and gradients are less sensitive to noise. Model 2 is the most stable among the three, and the decrease in the accuracy is less significant. When the added noise’s standard deviation is <math id="S4.SSx4.p3.1.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S4.SSx4.p3.1.m1.1a"><mn id="S4.SSx4.p3.1.m1.1.1" xref="S4.SSx4.p3.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S4.SSx4.p3.1.m1.1b"><cn type="float" id="S4.SSx4.p3.1.m1.1.1.cmml" xref="S4.SSx4.p3.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx4.p3.1.m1.1c">0.1</annotation></semantics></math>, Gaussian noise hidden layers, noisy gradients, and noisy labels are the most resilient. Hence, we continue studying these models under varying noise levels.</p>
</div>
<div id="S4.SSx4.p4" class="ltx_para">
<p id="S4.SSx4.p4.2" class="ltx_p">The results from training the centralized data with Gaussian noise hidden layers, noisy gradients, and noisy labels using the three models are presented in Figure <a href="#S4.F11" title="Figure 11 ‣ Experiment 4: Comparison of Noise Infusion Mechanisms ‣ 4 Computational Results and Analysis ‣ The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to Improve Generalization, Stability, and Privacy in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>. The noise levels are <math id="S4.SSx4.p4.1.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SSx4.p4.1.m1.1a"><mi id="S4.SSx4.p4.1.m1.1.1" xref="S4.SSx4.p4.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S4.SSx4.p4.1.m1.1b"><ci id="S4.SSx4.p4.1.m1.1.1.cmml" xref="S4.SSx4.p4.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx4.p4.1.m1.1c">\sigma</annotation></semantics></math> = <math id="S4.SSx4.p4.2.m2.5" class="ltx_Math" alttext="\{0.1,0.3,0.5,0.7,0.9\}" display="inline"><semantics id="S4.SSx4.p4.2.m2.5a"><mrow id="S4.SSx4.p4.2.m2.5.6.2" xref="S4.SSx4.p4.2.m2.5.6.1.cmml"><mo stretchy="false" id="S4.SSx4.p4.2.m2.5.6.2.1" xref="S4.SSx4.p4.2.m2.5.6.1.cmml">{</mo><mn id="S4.SSx4.p4.2.m2.1.1" xref="S4.SSx4.p4.2.m2.1.1.cmml">0.1</mn><mo id="S4.SSx4.p4.2.m2.5.6.2.2" xref="S4.SSx4.p4.2.m2.5.6.1.cmml">,</mo><mn id="S4.SSx4.p4.2.m2.2.2" xref="S4.SSx4.p4.2.m2.2.2.cmml">0.3</mn><mo id="S4.SSx4.p4.2.m2.5.6.2.3" xref="S4.SSx4.p4.2.m2.5.6.1.cmml">,</mo><mn id="S4.SSx4.p4.2.m2.3.3" xref="S4.SSx4.p4.2.m2.3.3.cmml">0.5</mn><mo id="S4.SSx4.p4.2.m2.5.6.2.4" xref="S4.SSx4.p4.2.m2.5.6.1.cmml">,</mo><mn id="S4.SSx4.p4.2.m2.4.4" xref="S4.SSx4.p4.2.m2.4.4.cmml">0.7</mn><mo id="S4.SSx4.p4.2.m2.5.6.2.5" xref="S4.SSx4.p4.2.m2.5.6.1.cmml">,</mo><mn id="S4.SSx4.p4.2.m2.5.5" xref="S4.SSx4.p4.2.m2.5.5.cmml">0.9</mn><mo stretchy="false" id="S4.SSx4.p4.2.m2.5.6.2.6" xref="S4.SSx4.p4.2.m2.5.6.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SSx4.p4.2.m2.5b"><set id="S4.SSx4.p4.2.m2.5.6.1.cmml" xref="S4.SSx4.p4.2.m2.5.6.2"><cn type="float" id="S4.SSx4.p4.2.m2.1.1.cmml" xref="S4.SSx4.p4.2.m2.1.1">0.1</cn><cn type="float" id="S4.SSx4.p4.2.m2.2.2.cmml" xref="S4.SSx4.p4.2.m2.2.2">0.3</cn><cn type="float" id="S4.SSx4.p4.2.m2.3.3.cmml" xref="S4.SSx4.p4.2.m2.3.3">0.5</cn><cn type="float" id="S4.SSx4.p4.2.m2.4.4.cmml" xref="S4.SSx4.p4.2.m2.4.4">0.7</cn><cn type="float" id="S4.SSx4.p4.2.m2.5.5.cmml" xref="S4.SSx4.p4.2.m2.5.5">0.9</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SSx4.p4.2.m2.5c">\{0.1,0.3,0.5,0.7,0.9\}</annotation></semantics></math>.</p>
</div>
<figure id="S4.F11" class="ltx_figure"><img src="/html/2311.05790/assets/x11.png" id="S4.F11.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Results of training and evaluating models with top 3 noise infusion methods and varying noise levels.</figcaption>
</figure>
<div id="S4.SSx4.p5" class="ltx_para">
<p id="S4.SSx4.p5.1" class="ltx_p">While all models are somewhat sensitive to additive noise, they exhibit different performance variations under the noise infusion mechanisms. We can increase the noise in the models with Gaussian noise hidden layers while preserving test accuracy, especially in model 2, where the accuracy remains relatively constant compared to the base model. It is also interesting to see that increasing noise improves test accuracy, indicating the regularization effect of noise. In models 1 and 3, we can increase the noise levels to 0.1, and the test accuracy is 0.83 and 0.82, respectively.</p>
</div>
<div id="S4.SSx4.p6" class="ltx_para">
<p id="S4.SSx4.p6.1" class="ltx_p">The models exhibit similar performance with noisy gradients. With models 1 and 3, the test accuracy gradually decreases as we increase the noise. However, even with a high standard deviation, model 2 remains stable against additive noise.
Models 1 and 3, trained on data with noisy labels, have better stability, and we can increase the standard deviation to 0.5 and 0.3, respectively. Model 2 performs equally well when trained with noisy labels compared to the base model, demonstrating resilience to label noise.</p>
</div>
<div id="S4.SSx4.p7" class="ltx_para">
<p id="S4.SSx4.p7.1" class="ltx_p">Noise can negatively impact both training and test accuracy. However, the impact of noise on model performance varies depending on the noise infusion mechanism and the standard deviation of the additive noise. While the model’s performance gradually degrades, noise can be used as a regularization technique. The results indicate that models with Gaussian noise hidden layers are effective in remaining stable even when the standard deviation of the noise is high.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">The present work is an empirical study on the role of noise in enhancing generalization, stability, and privacy within CNN for image classification. Through a series of carefully designed experiments, we observed that the introduction of noise during training helps prevent overfitting by making the model less reliant on precise features and patterns in the training data. By encouraging the network to learn more robust representations of data, CNNs with Gaussian noise hidden layers tend to perform better on unseen or noisy data, making them particularly useful for tasks where the input data may contain variations or uncertainties. This technique can improve CNN’s ability to handle real-world scenarios and noisy environments, making it a valuable tool in applications such as image recognition, denoising, and signal processing. Our experimental results demonstrate that when the model is not over-parameterized, perturbing the parameters associated with the deep learning model by adding Gaussian noise behaves as an implicit regularization technique. Models trained with noise generalize better, achieve higher accuracy, and are more stable in centralized and federated settings.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Introducing SNR as a measure of the signal quality (the base model performance) relative to the noise (noisy model performance) serves as a powerful tool for balancing accuracy and privacy in privacy-preserving settings. Additionally, PoS and PoA provide an in-depth understanding of the interplay of utility, stability, and privacy under different conditions. PoS and PoA can be used as tangible metrics for assessing the trade-off between privacy and accuracy in privacy-aware machine learning.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">Furthermore, we conducted a comparative analysis over CNN-based image classification noise infusion scenarios to determine the most effective methods of enhancing generalization, stability, and privacy. This investigation particularly benefits federated learning, where higher noise levels offer stronger privacy guarantees.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">This study has significant implications for practical machine learning applications that require reliable performance under varying conditions. Noise-infused models can help achieve models capable of handling diverse and noisy datasets.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p">In the context of federated learning, understanding the impact of noise leads to designing computationally efficient private models. The findings of this study demonstrate the potential of noise as a privacy-enhancing mechanism that can empower individuals and organizations to make informed decisions regarding data sharing and model deployment. By incorporating privacy-preserving techniques and acknowledging privacy as a fundamental human right, this research contributes to the responsible and ethical use of data and machine learning technologies.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Declarations</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p"><span id="Sx1.p1.1.1" class="ltx_text ltx_font_bold">Conflict of interest</span> The authors declare no competing interests. 
<br class="ltx_break"><span id="Sx1.p1.1.2" class="ltx_text ltx_font_bold">Consent to participate </span> Not applicable 
<br class="ltx_break"><span id="Sx1.p1.1.3" class="ltx_text ltx_font_bold">Consent for publication</span> Not applicable
<br class="ltx_break"><span id="Sx1.p1.1.4" class="ltx_text ltx_font_bold">Ethics Approval</span> Not applicable
<br class="ltx_break"><span id="Sx1.p1.1.5" class="ltx_text ltx_font_bold">Funding</span> Not applicable 
<br class="ltx_break"><span id="Sx1.p1.1.6" class="ltx_text ltx_font_bold">Data availability</span> The dataset analyzed during the current study is publicly available in the repository created by Alex Krizhevsky. 
<br class="ltx_break"><a target="_blank" href="https://www.cs.toronto.edu/~kriz/cifar.html" title="" class="ltx_ref ltx_href">https://www.cs.toronto.edu/ kriz/cifar.html</a>
<br class="ltx_break"><span id="Sx1.p1.1.7" class="ltx_text ltx_font_bold">Code availability</span> The code is available in the author’s GitHub repository.
<br class="ltx_break"></p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Peter L Bartlett and Shahar Mendelson.

</span>
<span class="ltx_bibblock">Rademacher and gaussian complexities: Risk bounds and structural results.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Journal of Machine Learning Research</span>, 3(Nov):463–482, 2002.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Giorgio Gnecco, Marcello Sanguineti, et al.

</span>
<span class="ltx_bibblock">Approximation error bounds via rademacher complexity.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Applied Mathematical Sciences</span>, 2:153–176, 2008.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Michel Ledoux and Michel Talagrand.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Probability in Banach Spaces: isoperimetry and processes</span>, volume 23.

</span>
<span class="ltx_bibblock">Springer Science &amp; Business Media, 1991.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Mehryar Mohri and Afshin Rostamizadeh.

</span>
<span class="ltx_bibblock">Rademacher complexity bounds for non-iid processes.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 21, 2008.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Foundations of machine learning</span>.

</span>
<span class="ltx_bibblock">MIT press, 2018.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Vladimir N Vapnik and Alexey Ya Chervonenkis.

</span>
<span class="ltx_bibblock">On the uniform convergence of the frequencies of occurrence of events to their probabilities.

</span>
<span class="ltx_bibblock">In <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Empirical Inference</span>, pages 7–12. Springer, 2013.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
George Cybenko.

</span>
<span class="ltx_bibblock">Just-in-time learning and estimation.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Nato ASI Series F Computer and Systems Sciences</span>, 153:423–434, 1996.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Marek Karpinski and Angus Macintyre.

</span>
<span class="ltx_bibblock">Bounding vc-dimension for neural networks: progress and prospects.

</span>
<span class="ltx_bibblock">In <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">European Conference on Computational Learning Theory</span>, pages 337–341. Springer, 1995.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Eduardo D Sontag et al.

</span>
<span class="ltx_bibblock">Vc dimension of neural networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">NATO ASI Series F Computer and Systems Sciences</span>, 168:69–96, 1998.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Ian Goodfellow, Yoshua Bengio, and Aaron Courville.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Deep learning</span>.

</span>
<span class="ltx_bibblock">MIT press, 2016.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Alexander Rakhlin, Sayan Mukherjee, and Tomaso Poggio.

</span>
<span class="ltx_bibblock">Stability results in learning theory.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Analysis and Applications</span>, 3(04):397–417, 2005.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Olivier Bousquet and André Elisseeff.

</span>
<span class="ltx_bibblock">Stability and generalization.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">The Journal of Machine Learning Research</span>, 2:499–526, 2002.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J Frédéric Bonnans and Alexander Shapiro.

</span>
<span class="ltx_bibblock">Optimization problems with perturbations: A guided tour.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">SIAM review</span>, 40(2):228–264, 1998.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Ruth Gavison.

</span>
<span class="ltx_bibblock">Privacy and the limits of law.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">The Yale law journal</span>, 89(3):421–471, 1980.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Omer Tene and Jules Polonetsky.

</span>
<span class="ltx_bibblock">Privacy in the age of big data: a time for big decisions.

</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Stan. L. Rev. Online</span>, 64:63, 2011.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Louis Brandeis and Samuel Warren.

</span>
<span class="ltx_bibblock">The right to privacy.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Harvard law review</span>, 4(5):193–220, 1890.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Irit Dinur and Kobbi Nissim.

</span>
<span class="ltx_bibblock">Revealing information while preserving privacy.

</span>
<span class="ltx_bibblock">In <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Proceedings of the twenty-second ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems</span>, pages 202–210, 2003.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Avrim Blum, Cynthia Dwork, Frank McSherry, and Kobbi Nissim.

</span>
<span class="ltx_bibblock">Practical privacy: the sulq framework.

</span>
<span class="ltx_bibblock">In <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Proceedings of the twenty-fourth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems</span>, pages 128–138, 2005.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith.

</span>
<span class="ltx_bibblock">Calibrating noise to sensitivity in private data analysis.

</span>
<span class="ltx_bibblock">In <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Theory of cryptography conference</span>, pages 265–284. Springer, 2006.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith.

</span>
<span class="ltx_bibblock">Differential privacy—a primer for the perplexed,”.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Joint UNECE/Eurostat work session on statistical data confidentiality</span>, 11, 2011.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Cynthia Dwork, Aaron Roth, et al.

</span>
<span class="ltx_bibblock">The algorithmic foundations of differential privacy.

</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Foundations and Trends® in Theoretical Computer Science</span>, 9(3–4):211–407, 2014.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Kang Wei, Jun Li, Ming Ding, Chuan Ma, Howard H Yang, Farhad Farokhi, Shi Jin, Tony QS Quek, and H Vincent Poor.

</span>
<span class="ltx_bibblock">Federated learning with differential privacy: Algorithms and performance analysis.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Information Forensics and Security</span>, 15:3454–3469, 2020.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor.

</span>
<span class="ltx_bibblock">Our data, ourselves: Privacy via distributed noise generation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Annual international conference on the theory and applications of cryptographic techniques</span>, pages 486–503. Springer, 2006.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">Artificial intelligence and statistics</span>, pages 1273–1282. PMLR, 2017.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Konečnỳ, Stefano Mazzocchi, Brendan McMahan, et al.

</span>
<span class="ltx_bibblock">Towards federated learning at scale: System design.

</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">Proceedings of machine learning and systems</span>, 1:374–388, 2019.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">Foundations and Trends® in Machine Learning</span>, 14(1–2):1–210, 2021.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Dana Ron and M Kearns.

</span>
<span class="ltx_bibblock">Algorithmic stability and sanity-check bounds for leave-one-out crossvaildation.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">Neural Computation</span>, 11(6):1427–1453, 1999.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nati Srebro.

</span>
<span class="ltx_bibblock">Exploring generalization in deep learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 30, 2017.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Chris M Bishop.

</span>
<span class="ltx_bibblock">Training with noise is equivalent to tikhonov regularization.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">Neural computation</span>, 7(1):108–116, 1995.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Christopher M Bishop et al.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">Neural networks for pattern recognition</span>.

</span>
<span class="ltx_bibblock">Oxford University Press, 1995.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Shai Shalev-Shwartz and Shai Ben-David.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">Understanding machine learning: From theory to algorithms</span>.

</span>
<span class="ltx_bibblock">Cambridge University Press, 2014.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Mark D McDonnell and Lawrence M Ward.

</span>
<span class="ltx_bibblock">The benefits of noise in neural systems: bridging theory and experiment.

</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">Nature Reviews Neuroscience</span>, 12(7):415–425, 2011.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
J Andrew Doyle and Alan C Evans.

</span>
<span class="ltx_bibblock">What colour is neural noise?

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1806.03704</span>, 2018.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Sumit Kumar, Ayush Kumar, and Rajib Kumar Jha.

</span>
<span class="ltx_bibblock">A novel noise-enhanced back-propagation technique for weak signal detection in neyman–pearson framework.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">Neural Processing Letters</span>, 50(3):2389–2406, 2019.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Roberto Benzi, Alfonso Sutera, and Angelo Vulpiani.

</span>
<span class="ltx_bibblock">The mechanism of stochastic resonance.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Journal of Physics A: mathematical and general</span>, 14(11):L453, 1981.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Roberto Benzi, Giorgio Parisi, Alfonso Sutera, and Angelo Vulpiani.

</span>
<span class="ltx_bibblock">A theory of stochastic resonance in climatic change.

</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">SIAM Journal on applied mathematics</span>, 43(3):565–578, 1983.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Shuhei Ikemoto, Fabio DallaLibera, and Koh Hosoda.

</span>
<span class="ltx_bibblock">Noise-modulated neural networks as an application of stochastic resonance.

</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">Neurocomputing</span>, 277:29–37, 2018.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
A Aldo Faisal, Luc PJ Selen, and Daniel M Wolpert.

</span>
<span class="ltx_bibblock">Noise in the nervous system.

</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">Nature reviews neuroscience</span>, 9(4):292–303, 2008.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Wolfgang Maass.

</span>
<span class="ltx_bibblock">Noise as a resource for computation and learning in networks of spiking neurons.

</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE</span>, 102(5):860–880, 2014.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Lasse Holmstrom and Petri Koistinen.

</span>
<span class="ltx_bibblock">Using additive noise in back-propagation training.

</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Neural Networks</span>, 3(1):24–38, 1992.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Vladimir Karpukhin, Omer Levy, Jacob Eisenstein, and Marjan Ghazvininejad.

</span>
<span class="ltx_bibblock">Training on synthetic noise improves robustness to natural noise in machine translation.

</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1902.01509</span>, 2019.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Jocelyn Sietsma and Robert JF Dow.

</span>
<span class="ltx_bibblock">Creating artificial neural networks that generalize.

</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">Neural networks</span>, 4(1):67–79, 1991.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Zhi Zeng, Yuan Liu, Weijun Tang, and Fangjiong Chen.

</span>
<span class="ltx_bibblock">Noise is useful: Exploiting data diversity for edge intelligence.

</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">IEEE Wireless Communications Letters</span>, 10(5):957–961, 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Russell Reed and Robert J MarksII.

</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">Neural smithing: supervised learning in feedforward artificial neural networks</span>.

</span>
<span class="ltx_bibblock">Mit Press, 1999.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Richard M Zur, Yulei Jiang, Lorenzo L Pesce, and Karen Drukker.

</span>
<span class="ltx_bibblock">Noise injection for training artificial neural networks: A comparison with weight decay and early stopping.

</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">Medical physics</span>, 36(10):4810–4818, 2009.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Naresh Nagabushan, Nishank Satish, and S Raghuram.

</span>
<span class="ltx_bibblock">Effect of injected noise in deep neural networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">2016 IEEE International Conference on Computational Intelligence and Computing Research (ICCIC)</span>, pages 1–5. IEEE, 2016.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Oussama Dhifallah and Yue Lu.

</span>
<span class="ltx_bibblock">On the inherent regularization effects of noise injection during training.

</span>
<span class="ltx_bibblock">In <span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 2665–2675. PMLR, 2021.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Zhezhi He, Adnan Siraj Rakin, and Deliang Fan.

</span>
<span class="ltx_bibblock">Parametric noise injection: Trainable randomness to improve deep neural network robustness against adversarial attack.

</span>
<span class="ltx_bibblock">In <span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span>, pages 588–597, 2019.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Li Xiao, Zeliang Zhang, and Yijie Peng.

</span>
<span class="ltx_bibblock">Noise optimization for artificial neural networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2102.04450</span>, 2021.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Aishan Liu, Xianglong Liu, Hang Yu, Chongzhi Zhang, Qiang Liu, and Dacheng Tao.

</span>
<span class="ltx_bibblock">Training robust deep neural networks via adversarial noise propagation.

</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Image Processing</span>, 30:5769–5781, 2021.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
P. Koistinen and L. Holmstrom.

</span>
<span class="ltx_bibblock">Kernel regression and backpropagation training with noise.

</span>
<span class="ltx_bibblock">In <span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">[Proceedings] 1991 IEEE International Joint Conference on Neural Networks</span>, pages 367–372 vol.1, 1991.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Kiyotoshi Matsuoka.

</span>
<span class="ltx_bibblock">Noise injection into inputs in back-propagation learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Systems, Man, and Cybernetics</span>, 22(3):436–440, 1992.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang.

</span>
<span class="ltx_bibblock">Deep learning with differential privacy.

</span>
<span class="ltx_bibblock">In <span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2016 ACM SIGSAC conference on computer and communications security</span>, pages 308–318, 2016.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Guozhong An.

</span>
<span class="ltx_bibblock">The effects of adding noise during backpropagation training on a generalization performance.

</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">Neural computation</span>, 8(3):643–674, 1996.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Chuan Wang and Jose C Principe.

</span>
<span class="ltx_bibblock">Training neural networks with additive noise in the desired signal.

</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Neural Networks</span>, 10(6):1511–1517, 1999.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Azian Azamimi, Yoko Uwate, and Yoshifumi Nishio.

</span>
<span class="ltx_bibblock">Effect of chaos noise on the learning ability of back propagation algorithm in feed forward neural network.

</span>
<span class="ltx_bibblock">In <span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">2010 6th International Colloquium on Signal Processing &amp; its Applications</span>, pages 1–4. IEEE, 2010.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Juan Manuel Alonso-Weber, MP Sesmero, and Araceli Sanchis.

</span>
<span class="ltx_bibblock">Combining additive input noise annealing and pattern transformations for improved handwritten character recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">Expert systems with applications</span>, 41(18):8180–8188, 2014.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
IV Isaev and SA Dolenko.

</span>
<span class="ltx_bibblock">Training with noise as a method to increase noise resilience of neural network solution of inverse problems.

</span>
<span class="ltx_bibblock"><span id="bib.bib58.1.1" class="ltx_text ltx_font_italic">Optical Memory and Neural Networks</span>, 25(3):142–148, 2016.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Bart Kosko, Kartik Audhkhasi, and Osonde Osoba.

</span>
<span class="ltx_bibblock">Noise can speed backpropagation learning and deep bidirectional pretraining.

</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">Neural Networks</span>, 129:359–384, 2020.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Warick M Brown, Tamás D Gedeon, and David I Groves.

</span>
<span class="ltx_bibblock">Use of noise to augment training data: a neural network method of mineral–potential mapping in regions of limited known deposit examples.

</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">Natural Resources Research</span>, 12(2):141–152, 2003.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Jianping Hua, James Lowey, Zixiang Xiong, and Edward R Dougherty.

</span>
<span class="ltx_bibblock">Noise-injected neural networks show promise for use on small-sample expression data.

</span>
<span class="ltx_bibblock"><span id="bib.bib61.1.1" class="ltx_text ltx_font_italic">BMC bioinformatics</span>, 7(1):1–14, 2006.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Yinan Li and Fang Liu.

</span>
<span class="ltx_bibblock">Whiteout: Gaussian adaptive noise regularization in deep neural networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1612.01490</span>, 2016.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Soon Hoe Lim, N Benjamin Erichson, Francisco Utrera, Winnie Xu, and Michael W Mahoney.

</span>
<span class="ltx_bibblock">Noisy feature mixup.

</span>
<span class="ltx_bibblock"><span id="bib.bib63.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2110.02180</span>, 2021.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Elahe Arani, Fahad Sarfraz, and Bahram Zonooz.

</span>
<span class="ltx_bibblock">Noise as a resource for learning in knowledge distillation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib64.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</span>, pages 3129–3138, 2021.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Zhonghui You, Jinmian Ye, Kunming Li, Zenglin Xu, and Ping Wang.

</span>
<span class="ltx_bibblock">Adversarial noise layer: Regularize neural network by adding noise.

</span>
<span class="ltx_bibblock">In <span id="bib.bib65.1.1" class="ltx_text ltx_font_italic">2019 IEEE International Conference on Image Processing (ICIP)</span>, pages 909–913. IEEE, 2019.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Linara Adilova, Nathalie Paul, and Peter Schlicht.

</span>
<span class="ltx_bibblock">Introducing noise in decentralized training of neural networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib66.1.1" class="ltx_text ltx_font_italic">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</span>, pages 37–48. Springer, 2018.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Ashwini Sapkal and UV Kulkarni.

</span>
<span class="ltx_bibblock">Modified backpropagation with added white gaussian noise in weighted sum for convergence improvement.

</span>
<span class="ltx_bibblock"><span id="bib.bib67.1.1" class="ltx_text ltx_font_italic">Procedia computer science</span>, 143:309–316, 2018.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Jiashuo Shi, Mingce Chen, Dong Wei, Chai Hu, Jun Luo, Haiwei Wang, Xinyu Zhang, and Changsheng Xie.

</span>
<span class="ltx_bibblock">Anti-noise diffractive neural network for constructing an intelligent imaging detector array.

</span>
<span class="ltx_bibblock"><span id="bib.bib68.1.1" class="ltx_text ltx_font_italic">Optics Express</span>, 28(25):37686–37699, 2020.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Kirill Bykov, Anna Hedström, Shinichi Nakajima, and Marina M-C Höhne.

</span>
<span class="ltx_bibblock">Noisegrad: enhancing explanations by introducing stochasticity to model weights.

</span>
<span class="ltx_bibblock"><span id="bib.bib69.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2106.10185</span>, 2021.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Peter J Edwards and Alan F Murray.

</span>
<span class="ltx_bibblock">Fault tolerance via weight noise in analog vlsi implementations of mlps-a case study with epsilon.

</span>
<span class="ltx_bibblock"><span id="bib.bib70.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Circuits and Systems II: Analog and Digital Signal Processing</span>, 45(9):1255–1262, 1998.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Mo Zhou, Tianyi Liu, Yan Li, Dachao Lin, Enlu Zhou, and Tuo Zhao.

</span>
<span class="ltx_bibblock">Toward understanding the importance of noise in training neural networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib71.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 7594–7602. PMLR, 2019.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Lingling Duan, Fabing Duan, François Chapeau-Blondeau, and Derek Abbott.

</span>
<span class="ltx_bibblock">Noise-boosted backpropagation learning of feedforward threshold neural networks for function approximation.

</span>
<span class="ltx_bibblock"><span id="bib.bib72.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Instrumentation and Measurement</span>, 70:1–12, 2021.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
PRATIK Chaudhari and STEFANO Soatto.

</span>
<span class="ltx_bibblock">The effect of gradient noise on the energy landscape of deep networks.

</span>
<span class="ltx_bibblock">Technical report, Technical Report Preprint, 2015.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Arvind Neelakantan, Luke Vilnis, Quoc V Le, Ilya Sutskever, Lukasz Kaiser, Karol Kurach, and James Martens.

</span>
<span class="ltx_bibblock">Adding gradient noise improves learning for very deep networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib74.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1511.06807</span>, 2015.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
Baharan Mirzasoleiman, Kaidi Cao, and Jure Leskovec.

</span>
<span class="ltx_bibblock">Coresets for robust training of deep neural networks against noisy labels.

</span>
<span class="ltx_bibblock"><span id="bib.bib75.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 33:11465–11477, 2020.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Xuefeng Jiang, Sheng Sun, Yuwei Wang, and Min Liu.

</span>
<span class="ltx_bibblock">Towards federated learning against noisy labels via local self-regularization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib76.1.1" class="ltx_text ltx_font_italic">Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management</span>, pages 862–873, 2022.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
Tingting Wu, Xiao Ding, Minji Tang, Hao Zhang, Bing Qin, and Ting Liu.

</span>
<span class="ltx_bibblock">Stgn: an implicit regularization method for learning with noisy labels in natural language processing.

</span>
<span class="ltx_bibblock">In <span id="bib.bib77.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</span>, pages 7587–7598, 2022.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Hwanjun Song, Minseok Kim, Dongmin Park, Yooju Shin, and Jae-Gil Lee.

</span>
<span class="ltx_bibblock">Learning from noisy labels with deep neural networks: A survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib78.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</span>, 2022.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Steven W Smith et al.

</span>
<span class="ltx_bibblock">The scientist and engineer’s guide to digital signal processing, 1997.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
Fraidoon Mazda.

</span>
<span class="ltx_bibblock"><span id="bib.bib80.1.1" class="ltx_text ltx_font_italic">Telecommunications engineer’s reference book</span>.

</span>
<span class="ltx_bibblock">Butterworth-Heinemann, 2014.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
Elliot Anshelevich, Anirban Dasgupta, Jon Kleinberg, Éva Tardos, Tom Wexler, and Tim Roughgarden.

</span>
<span class="ltx_bibblock">The price of stability for network design with fair cost allocation.

</span>
<span class="ltx_bibblock"><span id="bib.bib81.1.1" class="ltx_text ltx_font_italic">SIAM Journal on Computing</span>, 38(4):1602–1623, 2008.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
Elias Koutsoupias and Christos Papadimitriou.

</span>
<span class="ltx_bibblock">Worst-case equilibria.

</span>
<span class="ltx_bibblock"><span id="bib.bib82.1.1" class="ltx_text ltx_font_italic">Computer science review</span>, 3(2):65–69, 2009.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals.

</span>
<span class="ltx_bibblock">Understanding deep learning (still) requires rethinking generalization.

</span>
<span class="ltx_bibblock"><span id="bib.bib83.1.1" class="ltx_text ltx_font_italic">Communications of the ACM</span>, 64(3):107–115, 2021.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
Karen Simonyan and Andrew Zisserman.

</span>
<span class="ltx_bibblock">Very deep convolutional networks for large-scale image recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib84.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1409.1556</span>, 2014.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2311.05789" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2311.05790" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2311.05790">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2311.05790" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2311.05792" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 19:18:50 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
