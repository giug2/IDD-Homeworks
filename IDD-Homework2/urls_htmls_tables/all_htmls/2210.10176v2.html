<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2210.10176] Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering</title><meta property="og:description" content="Most Outside-Knowledge Visual Question Answering (OK-VQA) systems employ a two-stage framework that first retrieves external knowledge given the visual question and then predicts the answer based on the retrieved conteâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2210.10176">

<!--Generated on Thu Mar 14 02:44:41 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Entity-Focused Dense Passage Retrieval for 
<br class="ltx_break">Outside-Knowledge Visual Question Answering</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jialin Wu
<br class="ltx_break">Department of Computer Science 
<br class="ltx_break">The University of Texas at Austin 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">jialinwu@utexas.edu</span> 
<br class="ltx_break">&amp;Raymond J. Mooney 
<br class="ltx_break">Department of Computer Science 
<br class="ltx_break">The University of Texas at Austin 
<br class="ltx_break"><span id="id2.2.id2" class="ltx_text ltx_font_typewriter">mooney@cs.utexas.edu</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id3.id1" class="ltx_p">Most Outside-Knowledge Visual Question Answering (OK-VQA) systems employ a two-stage framework that first retrieves external knowledge given the visual question and then predicts the answer based on the retrieved content. However, the retrieved knowledge is often inadequate. Retrievals are frequently too general and fail to cover specific knowledge needed to answer the question. Also, the naturally available supervision (whether the passage contains the correct answer) is weak and does not guarantee question relevancy. To address these issues, we propose an <span id="id3.id1.1" class="ltx_text ltx_font_bold">En</span>tity-<span id="id3.id1.2" class="ltx_text ltx_font_bold">Fo</span>cused <span id="id3.id1.3" class="ltx_text ltx_font_bold">Re</span>trieval (EnFoRe) model that provides stronger supervision during training and recognizes question-relevant entities to help retrieve more specific knowledge. Experiments show that our EnFoRe model achieves superior retrieval performance on OK-VQA, the currently largest outside-knowledge VQA dataset. We also combine the retrieved knowledge with state-of-the-art VQA models, and achieve a new state-of-the-art performance on OK-VQA.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Passage retrieval under a multi-modal setting is a critical prerequisite for applications such as outside-knowledge visual question answering (OK-VQA) <cite class="ltx_cite ltx_citemacro_cite">Marino etÂ al. (<a href="#bib.bib27" title="" class="ltx_ref">2019</a>)</cite>, which requires effectively utilizing knowledge external to the image. Recently, dense passage retrievers with deep semantic representations powered by large transformer models have shown superior performance to traditional sparse retrievers such as BM25 <cite class="ltx_cite ltx_citemacro_cite">Robertson and Zaragoza (<a href="#bib.bib33" title="" class="ltx_ref">2009</a>)</cite> and TF-IDF under both textual <cite class="ltx_cite ltx_citemacro_cite">Karpukhin etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>); Chen etÂ al. (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>); Lewis etÂ al. (<a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite> and multi-modal settings <cite class="ltx_cite ltx_citemacro_cite">Luo etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2021</a>); Qu etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>); Gui etÂ al. (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In this work, we investigate two main drawbacks of recent dense retrievers <cite class="ltx_cite ltx_citemacro_cite">Karpukhin etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>); Chen etÂ al. (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>); Lewis etÂ al. (<a href="#bib.bib19" title="" class="ltx_ref">2022</a>); Luo etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2021</a>); Qu etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>); Gui etÂ al. (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite>, which are typically trained to produce similar representations for input queries and passages containing ground-truth answers.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2210.10176/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="298" height="271" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Top: Examples of critical entities upon which retrieval models should focus; Bottom: Example of improved passage retrieval using critical entities. </figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">First, as most retrieval models encode the query and passages as a whole, they fail to explicitly discover entities critical to answering the question <cite class="ltx_cite ltx_citemacro_cite">Chen etÂ al. (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite>. This frequently leads to retrieving overly-general knowledge lacking a specific focus. Ideally, a retrieval model should identify the critical entities for the query and then retrieve question-relevant knowledge specifically about them. For example, as shown in the top half of Figure <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, retrieval models should realize that the entities â€œturkeyâ€ and â€œteddy bearâ€ are critical.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Second, on the supervision side, the positive signals are often passages containing the right answers with top sparse-retrieval scores such as BM 25 <cite class="ltx_cite ltx_citemacro_cite">Robertson and Zaragoza (<a href="#bib.bib33" title="" class="ltx_ref">2009</a>)</cite> and TF-IDF. However, this criterion is inadequate to guarantee question relevancy, since good positive passages should reveal facts that actually support the correct answer using the critical entities depicted in the image. For example, as shown in the bottom of Figure <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, both passages mention the correct answer â€œvegetableâ€ but only the second one which focuses on the critical entity â€œbell pepperâ€ is question-relevant.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In order to address these shortcomings, we propose an <span id="S1.p5.1.1" class="ltx_text ltx_font_bold">En</span>tity-<span id="S1.p5.1.2" class="ltx_text ltx_font_bold">Fo</span>cused <span id="S1.p5.1.3" class="ltx_text ltx_font_bold">Re</span>trieval (EnFoRe) model that improves the quality of the positive passages for stronger supervision. EnFoRe automatically identifies critical entities for the question and then retrieves knowledge focused on them. We focus on entities that improve a sparse retrieverâ€™s performance if emphasized during retrieval as critical entities. We use the top passages containing <span id="S1.p5.1.4" class="ltx_text ltx_font_italic">both</span> critical entities and the correct answer as positive supervision. Then, our EnFoRe model learns two scores to indicate (1) the importance of each entity given the question and the image and (2) a score that measured how well each entity fits the context of each candidate passage.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">We evaluate EnFoRe on OK-VQA <cite class="ltx_cite ltx_citemacro_cite">Marino etÂ al. (<a href="#bib.bib27" title="" class="ltx_ref">2019</a>)</cite>, currently the largest knowledge-based VQA dataset. Our approach achieves state-of-the-art (SOTA) knowledge retrieval results, indicating the effectiveness of explicitly recognizing key entities during retrieval. We also combine this retreived knowledge with SOTA OK-VQA models and achieve a new SOTA OK-VQA performance. Our code is available at <a target="_blank" href="https://github.com/jialinwu17/EnFoRe.git" title="" class="ltx_ref ltx_url">https://github.com/jialinwu17/EnFoRe.git</a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background and Related Work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>OK-VQA</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Visual Question Answering (VQA) has witnessed remarkable progress over the past few years, in terms of both the scope of the questions <cite class="ltx_cite ltx_citemacro_cite">Antol etÂ al. (<a href="#bib.bib2" title="" class="ltx_ref">2015</a>); Hudson and Manning (<a href="#bib.bib12" title="" class="ltx_ref">2019</a>); Wang etÂ al. (<a href="#bib.bib38" title="" class="ltx_ref">2018</a>); Gurari etÂ al. (<a href="#bib.bib10" title="" class="ltx_ref">2018</a>); Singh etÂ al. (<a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite>, and the sophistication of the model design <cite class="ltx_cite ltx_citemacro_cite">Antol etÂ al. (<a href="#bib.bib2" title="" class="ltx_ref">2015</a>); Lu etÂ al. (<a href="#bib.bib24" title="" class="ltx_ref">2016</a>); Anderson etÂ al. (<a href="#bib.bib1" title="" class="ltx_ref">2018</a>); Kim etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2018</a>, <a href="#bib.bib17" title="" class="ltx_ref">2020</a>); Wu etÂ al. (<a href="#bib.bib42" title="" class="ltx_ref">2019</a>); Wu and Mooney (<a href="#bib.bib44" title="" class="ltx_ref">2019</a>); Jiang etÂ al. (<a href="#bib.bib14" title="" class="ltx_ref">2018</a>); Lu etÂ al. (<a href="#bib.bib22" title="" class="ltx_ref">2019</a>); Nguyen etÂ al. (<a href="#bib.bib29" title="" class="ltx_ref">2021</a>)</cite>. There is a recent trend towards outside knowledge visual question answering (OK-VQA) <cite class="ltx_cite ltx_citemacro_cite">Marino etÂ al. (<a href="#bib.bib27" title="" class="ltx_ref">2019</a>)</cite>, where open domain external knowledge outside the image is necessary. Most OK-VQA models <cite class="ltx_cite ltx_citemacro_cite">Marino etÂ al. (<a href="#bib.bib27" title="" class="ltx_ref">2019</a>); GardÃ¨res etÂ al. (<a href="#bib.bib7" title="" class="ltx_ref">2020</a>); Zhu etÂ al. (<a href="#bib.bib47" title="" class="ltx_ref">2020</a>); Li etÂ al. (<a href="#bib.bib20" title="" class="ltx_ref">2020</a>); Narasimhan etÂ al. (<a href="#bib.bib28" title="" class="ltx_ref">2018</a>); Marino etÂ al. (<a href="#bib.bib26" title="" class="ltx_ref">2021</a>); Wu etÂ al. (<a href="#bib.bib43" title="" class="ltx_ref">2022</a>); Gui etÂ al. (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite> incorporate a retriever-reader framework that first retrieves textual knowledge relevant to the question and image and then â€œreadsâ€ this text to predicts the answer. As an online free encyclopedia, Wikipedia is often used as the knowledge source for OK-VQA. While most previous works focused more on the answer prediction stage, the performance is still lacking because of the imperfect quality of the retrieved knowledge. This work focuses on knowledge retrieval and aims at retrieving question-relevant knowledge that focuses explicitly on the critical entities for the visual question.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Passage Retrieval</h3>

<div id="S2.SS2.p1" class="ltx_para ltx_noindent">
<p id="S2.SS2.p1.1" class="ltx_p"><span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_bold">Sparse Retrieval:</span>
Before the recent proliferation of transformer-based dense passage retrieval models <cite class="ltx_cite ltx_citemacro_cite">Karpukhin etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>)</cite>, previous work mainly explored sparse retrievers, such as TF-IDF and BM25 <cite class="ltx_cite ltx_citemacro_cite">Robertson and Zaragoza (<a href="#bib.bib33" title="" class="ltx_ref">2009</a>)</cite>, that measure the similarity between the search query and candidate passage using weighted term matching.
These sparse retrievers require no training signals on the relevancy of the passage and show solid baseline performances. However, exact term matching prevents them from capturing synonyms and paraphrases and understanding the semantic meanings of the query and the passages.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold">Dense Retrieval:</span>
To better represent semantics, dense retrievers <cite class="ltx_cite ltx_citemacro_cite">Karpukhin etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>); Chen etÂ al. (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>); Lewis etÂ al. (<a href="#bib.bib19" title="" class="ltx_ref">2022</a>); Lee etÂ al. (<a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite> extract deep representations for the query and the candidate passages using large pretrained transformer models. Most dense retrievers are trained using a contrastive objective that encourages the representation of the query to be more similar to the relevant passages than other irrelevant passages. During training, the passage with a high sparse retrieval score containing the answer is often regarded as a positive sample for the question-answering task. However, these positive passages may not fit the questionâ€™s context and only serve as very weak supervision.
Moreover, the query and passages are often encoded as single vectors. Therefore most dense retrievers fail to explicitly discover and utilize critical entities for the question <cite class="ltx_cite ltx_citemacro_cite">Chen etÂ al. (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite>. This often leads to overly general knowledge without a specific focus.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Dense Passage Retrieval for VQA</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Motivated by the trend toward dense retrievers, previous work has also applied them to OK-VQA. <cite class="ltx_cite ltx_citemacro_citet">Qu etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite> utilize Wikipedia as a knowledge source. <cite class="ltx_cite ltx_citemacro_citet">Luo etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite> crawl Google search results on the training set as a knowledge source. However, the weak training signals for passage retrieval become more problematic for VQA as the visual context of the question makes it more complex. Therefore, a â€œpositive passageâ€ becomes less likely to fit the visual context and actually provide suitable supervision. In order to better incorporate visual content, <cite class="ltx_cite ltx_citemacro_citet">Gui etÂ al. (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite> adopt an image-based knowledge retriever that employs the CLIP model <cite class="ltx_cite ltx_citemacro_cite">Radford etÂ al. (<a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite> pretrained on large-scale multi-modal pairs as the backbone. However, question relevancy is not considered, so the retriever has to retrieve knowledge on every aspect of the image for different possible questions.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">This work proposes an <span id="S2.SS3.p2.1.1" class="ltx_text ltx_font_bold">En</span>tity-<span id="S2.SS3.p2.1.2" class="ltx_text ltx_font_bold">Fo</span>cused <span id="S2.SS3.p2.1.3" class="ltx_text ltx_font_bold">Re</span>trieval (EnFoRe) model that recognizes key entities for the visual question and retrieves question-relevant knowledge specifically focused on them. Our approach also benefits from stronger passage-retrieval supervision with the help of those key entities.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Phrase-Based Dense Passage Retrieval</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">The most relevant work to ours is phrase-based dense passage retrieval. <cite class="ltx_cite ltx_citemacro_citet">Chen etÂ al. (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite> employ a separate lexical model that is trained to mimic the performance of a sparse retriever that is better at matching phrases. <cite class="ltx_cite ltx_citemacro_citet">Lee etÂ al. (<a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite> propose DensePhrase model that extracts each possible phrase feature in the passage and only uses the most relevant phrase to measure the similarity between the query and passage. However, the training signals still come from exactly matching ground truth answers, and the phrases are parsed from the candidate passage, limiting the scope of the search.
In contrast, our approach collects entities from many aspects of the question and image, including object recognition, attribute detection, OCR, brands, captioning, etc., building a rich unified intermediate representation.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Entity Set Construction</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Our EnFoRe model is empowered by a comprehensive set of extracted entities. Â Entities are not limited to phrases from the question and passages as in <cite class="ltx_cite ltx_citemacro_cite">Lee etÂ al. (<a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite>. We collect entities from the sources below. Most entity extraction steps are independent and can execute in parallel, except for answering sub-questions, which first requires parsing the questions. Parallelizing these steps can significantly reduce run time.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Question-Based Entities</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p"><span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_bold">Entities from Questions:</span> First, the noun phrases in questions usually reveal critical entities. Following <cite class="ltx_cite ltx_citemacro_citet">Wu etÂ al. (<a href="#bib.bib43" title="" class="ltx_ref">2022</a>)</cite>, we parse the question using a constituency parser <cite class="ltx_cite ltx_citemacro_cite">Gardner etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2018</a>)</cite> and extract noun phrases at the leaves of the parse tree. Then, we link each phrase to the image and extract the referred object with its attributes. We use a pretrained ViLBERT model <cite class="ltx_cite ltx_citemacro_cite">Lu etÂ al. (<a href="#bib.bib23" title="" class="ltx_ref">2020</a>)</cite> as the object linker.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">Entities from Sub-Questions:</span> OK-VQA often requires systems to solve visual reference problems as well as comprehend relevant outside knowledge. Therefore, we employ a general VQA model to find answers to the visual aspects of the question. In particular, we collect a set of sub-questions by appending each noun phrase in the parse tree to the common question phrases â€œWhat isâ€¦â€ and â€œHow isâ€¦â€ When the confidence for an answer from a pretrained VilBERT model <cite class="ltx_cite ltx_citemacro_cite">Lu etÂ al. (<a href="#bib.bib23" title="" class="ltx_ref">2020</a>)</cite> exceeds 0.5, it is added to the entity set.
For the example in Fig.Â <a href="#S3.F2" title="Figure 2 â€£ 3.3 Oracle Critical Entity Detection â€£ 3 Entity Set Construction â€£ Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the noun phrases â€œplush toyâ€ and â€œpresidentâ€ generate the sub-questions: â€œWhat is plush toy?â€, â€œHow is plush toy?â€, â€œWhat is president?â€, â€œHow is president?â€. The answer confidence for â€œteddy bearâ€ exceeds 0.5 for the first question, so we include it in the entity set.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.1" class="ltx_p"><span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_bold">Entities from Answer Candidates:</span> Standard state-of-the-art VQA models are surprisingly effective at generating a small set of promising answer candidates for OK-VQA <cite class="ltx_cite ltx_citemacro_cite">Wu etÂ al. (<a href="#bib.bib43" title="" class="ltx_ref">2022</a>, <a href="#bib.bib40" title="" class="ltx_ref">2020</a>)</cite>. Therefore, we finetune a ViLBERT model <cite class="ltx_cite ltx_citemacro_cite">Lu etÂ al. (<a href="#bib.bib22" title="" class="ltx_ref">2019</a>)</cite> on the OK-VQA data set and extract the top <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mn id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><cn type="integer" id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">5</annotation></semantics></math> answer candidates and add them to entity set.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Image-Based Entities</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Question-based entities are high precision and narrow down the search space for knowledge retrievers. To complement this, we also collect image-based entities to help achieve higher recall.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Entities from Azure tagging:</span> Following <cite class="ltx_cite ltx_citemacro_citet">Yang etÂ al. (<a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite>, we use Azure OCR and brand tagging to annotate the detected objects in the images using a Mask R-CNN detector <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. (<a href="#bib.bib11" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.1" class="ltx_p"><span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">Entities from Wikidata:</span> As suggested by <cite class="ltx_cite ltx_citemacro_citet">Gui etÂ al. (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite>, common image and object tags can be generic with a limited vocabulary, leading to noise or irrelevant knowledge. Therefore, we also leverage recent advanced visual-semantic matching approaches, i.e. CLIP <cite class="ltx_cite ltx_citemacro_cite">Radford etÂ al. (<a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite>, to extract image-relevant entities from Wikidata. In particular, the entities with their descriptions in Wikidata and sliding windows of the images are used as inputs. Then, at most <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="18" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mn id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">18</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><cn type="integer" id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">18</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">18</annotation></semantics></math> entities with top maximum CLIP scores over these sliding windows are preserved. We follow the released code for KAT <cite class="ltx_cite ltx_citemacro_cite">Gui etÂ al. (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite> and resize the image such that the size of the shorter edge is 384. The sliding window size is set to 256 with a stride of 128.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.p4.1" class="ltx_p"><span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold">Entities from Captions:</span> Captions provide a natural source of salient objects in the image, and do not suffer from the limited vocabulary of object detectors <cite class="ltx_cite ltx_citemacro_cite">Wu etÂ al. (<a href="#bib.bib41" title="" class="ltx_ref">2018</a>)</cite>. Similar to extracting entities from the question, we parse captions and extract noun phrases from the parse tree. During training, we use the human captions provided by the COCO dataset to provide richer entities, and during testing, we use generated captions from the OFA captioning model <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib39" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Oracle Critical Entity Detection</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Given the comprehensive set of entities <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{E}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\mathcal{E}</annotation></semantics></math> covering different aspects of the question and image, we introduce an approach to automatically find critical entities and passages containing them. Then, those entities and passages are used during training to provide more substantial supervision. The intuition is that a good passage that fits the visual questionâ€™s context should mention <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_italic">both</span> the key entities and the correct answer. Also, emphasizing critical entities should improve retrieval performance.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.4" class="ltx_p">Given a question <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mi id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><ci id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">q</annotation></semantics></math>, we use BM25<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span> https://github.com/castorini/pyserini.git</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Robertson and Zaragoza (<a href="#bib.bib33" title="" class="ltx_ref">2009</a>)</cite> as the sparse retriever to retrieve an initial set of passages <math id="S3.SS3.p2.2.m2.3" class="ltx_Math" alttext="\mathcal{P}_{init}=\{p_{1},...,p_{K}\}" display="inline"><semantics id="S3.SS3.p2.2.m2.3a"><mrow id="S3.SS3.p2.2.m2.3.3" xref="S3.SS3.p2.2.m2.3.3.cmml"><msub id="S3.SS3.p2.2.m2.3.3.4" xref="S3.SS3.p2.2.m2.3.3.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p2.2.m2.3.3.4.2" xref="S3.SS3.p2.2.m2.3.3.4.2.cmml">ğ’«</mi><mrow id="S3.SS3.p2.2.m2.3.3.4.3" xref="S3.SS3.p2.2.m2.3.3.4.3.cmml"><mi id="S3.SS3.p2.2.m2.3.3.4.3.2" xref="S3.SS3.p2.2.m2.3.3.4.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.2.m2.3.3.4.3.1" xref="S3.SS3.p2.2.m2.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.2.m2.3.3.4.3.3" xref="S3.SS3.p2.2.m2.3.3.4.3.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.2.m2.3.3.4.3.1a" xref="S3.SS3.p2.2.m2.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.2.m2.3.3.4.3.4" xref="S3.SS3.p2.2.m2.3.3.4.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.2.m2.3.3.4.3.1b" xref="S3.SS3.p2.2.m2.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.2.m2.3.3.4.3.5" xref="S3.SS3.p2.2.m2.3.3.4.3.5.cmml">t</mi></mrow></msub><mo id="S3.SS3.p2.2.m2.3.3.3" xref="S3.SS3.p2.2.m2.3.3.3.cmml">=</mo><mrow id="S3.SS3.p2.2.m2.3.3.2.2" xref="S3.SS3.p2.2.m2.3.3.2.3.cmml"><mo stretchy="false" id="S3.SS3.p2.2.m2.3.3.2.2.3" xref="S3.SS3.p2.2.m2.3.3.2.3.cmml">{</mo><msub id="S3.SS3.p2.2.m2.2.2.1.1.1" xref="S3.SS3.p2.2.m2.2.2.1.1.1.cmml"><mi id="S3.SS3.p2.2.m2.2.2.1.1.1.2" xref="S3.SS3.p2.2.m2.2.2.1.1.1.2.cmml">p</mi><mn id="S3.SS3.p2.2.m2.2.2.1.1.1.3" xref="S3.SS3.p2.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.p2.2.m2.3.3.2.2.4" xref="S3.SS3.p2.2.m2.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml">â€¦</mi><mo id="S3.SS3.p2.2.m2.3.3.2.2.5" xref="S3.SS3.p2.2.m2.3.3.2.3.cmml">,</mo><msub id="S3.SS3.p2.2.m2.3.3.2.2.2" xref="S3.SS3.p2.2.m2.3.3.2.2.2.cmml"><mi id="S3.SS3.p2.2.m2.3.3.2.2.2.2" xref="S3.SS3.p2.2.m2.3.3.2.2.2.2.cmml">p</mi><mi id="S3.SS3.p2.2.m2.3.3.2.2.2.3" xref="S3.SS3.p2.2.m2.3.3.2.2.2.3.cmml">K</mi></msub><mo stretchy="false" id="S3.SS3.p2.2.m2.3.3.2.2.6" xref="S3.SS3.p2.2.m2.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.3b"><apply id="S3.SS3.p2.2.m2.3.3.cmml" xref="S3.SS3.p2.2.m2.3.3"><eq id="S3.SS3.p2.2.m2.3.3.3.cmml" xref="S3.SS3.p2.2.m2.3.3.3"></eq><apply id="S3.SS3.p2.2.m2.3.3.4.cmml" xref="S3.SS3.p2.2.m2.3.3.4"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.3.3.4.1.cmml" xref="S3.SS3.p2.2.m2.3.3.4">subscript</csymbol><ci id="S3.SS3.p2.2.m2.3.3.4.2.cmml" xref="S3.SS3.p2.2.m2.3.3.4.2">ğ’«</ci><apply id="S3.SS3.p2.2.m2.3.3.4.3.cmml" xref="S3.SS3.p2.2.m2.3.3.4.3"><times id="S3.SS3.p2.2.m2.3.3.4.3.1.cmml" xref="S3.SS3.p2.2.m2.3.3.4.3.1"></times><ci id="S3.SS3.p2.2.m2.3.3.4.3.2.cmml" xref="S3.SS3.p2.2.m2.3.3.4.3.2">ğ‘–</ci><ci id="S3.SS3.p2.2.m2.3.3.4.3.3.cmml" xref="S3.SS3.p2.2.m2.3.3.4.3.3">ğ‘›</ci><ci id="S3.SS3.p2.2.m2.3.3.4.3.4.cmml" xref="S3.SS3.p2.2.m2.3.3.4.3.4">ğ‘–</ci><ci id="S3.SS3.p2.2.m2.3.3.4.3.5.cmml" xref="S3.SS3.p2.2.m2.3.3.4.3.5">ğ‘¡</ci></apply></apply><set id="S3.SS3.p2.2.m2.3.3.2.3.cmml" xref="S3.SS3.p2.2.m2.3.3.2.2"><apply id="S3.SS3.p2.2.m2.2.2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS3.p2.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S3.SS3.p2.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS3.p2.2.m2.2.2.1.1.1.2">ğ‘</ci><cn type="integer" id="S3.SS3.p2.2.m2.2.2.1.1.1.3.cmml" xref="S3.SS3.p2.2.m2.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">â€¦</ci><apply id="S3.SS3.p2.2.m2.3.3.2.2.2.cmml" xref="S3.SS3.p2.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS3.p2.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S3.SS3.p2.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS3.p2.2.m2.3.3.2.2.2.2">ğ‘</ci><ci id="S3.SS3.p2.2.m2.3.3.2.2.2.3.cmml" xref="S3.SS3.p2.2.m2.3.3.2.2.2.3">ğ¾</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.3c">\mathcal{P}_{init}=\{p_{1},...,p_{K}\}</annotation></semantics></math>. We calculate a baseline score <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="\texttt{SRR}_{init}" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><msub id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.SS3.p2.3.m3.1.1.2" xref="S3.SS3.p2.3.m3.1.1.2a.cmml">SRR</mtext><mrow id="S3.SS3.p2.3.m3.1.1.3" xref="S3.SS3.p2.3.m3.1.1.3.cmml"><mi id="S3.SS3.p2.3.m3.1.1.3.2" xref="S3.SS3.p2.3.m3.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.3.m3.1.1.3.1" xref="S3.SS3.p2.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.3.m3.1.1.3.3" xref="S3.SS3.p2.3.m3.1.1.3.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.3.m3.1.1.3.1a" xref="S3.SS3.p2.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.3.m3.1.1.3.4" xref="S3.SS3.p2.3.m3.1.1.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.3.m3.1.1.3.1b" xref="S3.SS3.p2.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.3.m3.1.1.3.5" xref="S3.SS3.p2.3.m3.1.1.3.5.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><apply id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p2.3.m3.1.1.2a.cmml" xref="S3.SS3.p2.3.m3.1.1.2"><mtext class="ltx_mathvariant_monospace" id="S3.SS3.p2.3.m3.1.1.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2">SRR</mtext></ci><apply id="S3.SS3.p2.3.m3.1.1.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3"><times id="S3.SS3.p2.3.m3.1.1.3.1.cmml" xref="S3.SS3.p2.3.m3.1.1.3.1"></times><ci id="S3.SS3.p2.3.m3.1.1.3.2.cmml" xref="S3.SS3.p2.3.m3.1.1.3.2">ğ‘–</ci><ci id="S3.SS3.p2.3.m3.1.1.3.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3.3">ğ‘›</ci><ci id="S3.SS3.p2.3.m3.1.1.3.4.cmml" xref="S3.SS3.p2.3.m3.1.1.3.4">ğ‘–</ci><ci id="S3.SS3.p2.3.m3.1.1.3.5.cmml" xref="S3.SS3.p2.3.m3.1.1.3.5">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">\texttt{SRR}_{init}</annotation></semantics></math> for these <math id="S3.SS3.p2.4.m4.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS3.p2.4.m4.1a"><mi id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><ci id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">K</annotation></semantics></math> passages using summed reciprocal ranking (<span id="S3.SS3.p2.4.1" class="ltx_text ltx_font_typewriter">SRR</span>) as shown in Eq. <a href="#S3.E1" title="In 3.3 Oracle Critical Entity Detection â€£ 3 Entity Set Construction â€£ Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.2" class="ltx_Math" alttext="\texttt{SRR}(\mathcal{P})=\sum_{i=1}^{K}\frac{\text{1}[\texttt{ans}\in p_{i}]}{i}" display="block"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.3" xref="S3.E1.m1.2.3.cmml"><mrow id="S3.E1.m1.2.3.2" xref="S3.E1.m1.2.3.2.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.2.3.2.2" xref="S3.E1.m1.2.3.2.2a.cmml">SRR</mtext><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.3.2.1" xref="S3.E1.m1.2.3.2.1.cmml">â€‹</mo><mrow id="S3.E1.m1.2.3.2.3.2" xref="S3.E1.m1.2.3.2.cmml"><mo stretchy="false" id="S3.E1.m1.2.3.2.3.2.1" xref="S3.E1.m1.2.3.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">ğ’«</mi><mo stretchy="false" id="S3.E1.m1.2.3.2.3.2.2" xref="S3.E1.m1.2.3.2.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S3.E1.m1.2.3.1" xref="S3.E1.m1.2.3.1.cmml">=</mo><mrow id="S3.E1.m1.2.3.3" xref="S3.E1.m1.2.3.3.cmml"><munderover id="S3.E1.m1.2.3.3.1" xref="S3.E1.m1.2.3.3.1.cmml"><mo movablelimits="false" id="S3.E1.m1.2.3.3.1.2.2" xref="S3.E1.m1.2.3.3.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E1.m1.2.3.3.1.2.3" xref="S3.E1.m1.2.3.3.1.2.3.cmml"><mi id="S3.E1.m1.2.3.3.1.2.3.2" xref="S3.E1.m1.2.3.3.1.2.3.2.cmml">i</mi><mo id="S3.E1.m1.2.3.3.1.2.3.1" xref="S3.E1.m1.2.3.3.1.2.3.1.cmml">=</mo><mn id="S3.E1.m1.2.3.3.1.2.3.3" xref="S3.E1.m1.2.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.2.3.3.1.3" xref="S3.E1.m1.2.3.3.1.3.cmml">K</mi></munderover><mfrac id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><mtext class="ltx_mathvariant_double-struck" id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.3a.cmml">1</mtext><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.1.cmml">[</mo><mrow id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.2a.cmml">ans</mtext><mo id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">âˆˆ</mo><msub id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.2.cmml">p</mi><mi id="S3.E1.m1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.2.1.cmml">]</mo></mrow></mrow><mi id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml">i</mi></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.3.cmml" xref="S3.E1.m1.2.3"><eq id="S3.E1.m1.2.3.1.cmml" xref="S3.E1.m1.2.3.1"></eq><apply id="S3.E1.m1.2.3.2.cmml" xref="S3.E1.m1.2.3.2"><times id="S3.E1.m1.2.3.2.1.cmml" xref="S3.E1.m1.2.3.2.1"></times><ci id="S3.E1.m1.2.3.2.2a.cmml" xref="S3.E1.m1.2.3.2.2"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.2.3.2.2.cmml" xref="S3.E1.m1.2.3.2.2">SRR</mtext></ci><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">ğ’«</ci></apply><apply id="S3.E1.m1.2.3.3.cmml" xref="S3.E1.m1.2.3.3"><apply id="S3.E1.m1.2.3.3.1.cmml" xref="S3.E1.m1.2.3.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.3.3.1.1.cmml" xref="S3.E1.m1.2.3.3.1">superscript</csymbol><apply id="S3.E1.m1.2.3.3.1.2.cmml" xref="S3.E1.m1.2.3.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.3.3.1.2.1.cmml" xref="S3.E1.m1.2.3.3.1">subscript</csymbol><sum id="S3.E1.m1.2.3.3.1.2.2.cmml" xref="S3.E1.m1.2.3.3.1.2.2"></sum><apply id="S3.E1.m1.2.3.3.1.2.3.cmml" xref="S3.E1.m1.2.3.3.1.2.3"><eq id="S3.E1.m1.2.3.3.1.2.3.1.cmml" xref="S3.E1.m1.2.3.3.1.2.3.1"></eq><ci id="S3.E1.m1.2.3.3.1.2.3.2.cmml" xref="S3.E1.m1.2.3.3.1.2.3.2">ğ‘–</ci><cn type="integer" id="S3.E1.m1.2.3.3.1.2.3.3.cmml" xref="S3.E1.m1.2.3.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.2.3.3.1.3.cmml" xref="S3.E1.m1.2.3.3.1.3">ğ¾</ci></apply><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><divide id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1"></divide><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><times id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.2"></times><ci id="S3.E1.m1.1.1.1.3a.cmml" xref="S3.E1.m1.1.1.1.3"><mtext class="ltx_mathvariant_double-struck" id="S3.E1.m1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.3">1</mtext></ci><apply id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1"><in id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"></in><ci id="S3.E1.m1.1.1.1.1.1.1.2a.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2">ans</mtext></ci><apply id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2">ğ‘</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply></apply><ci id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">\texttt{SRR}(\mathcal{P})=\sum_{i=1}^{K}\frac{\text{1}[\texttt{ans}\in p_{i}]}{i}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.5" class="ltx_p">We use summed reciprocal ranking instead of reciprocal ranking since it provides more stable scores for evaluating the set of retrieved passages and does not overweight the highest ranked document.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.2" class="ltx_p">Then, for each entity <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="e\in\mathcal{E}" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><mrow id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">e</mi><mo id="S3.SS3.p3.1.m1.1.1.1" xref="S3.SS3.p3.1.m1.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">â„°</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><in id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1"></in><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">ğ‘’</ci><ci id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">â„°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">e\in\mathcal{E}</annotation></semantics></math>, we retrieve another set of passages <math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="\mathcal{P}_{e}" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><msub id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.2.m2.1.1.2" xref="S3.SS3.p3.2.m2.1.1.2.cmml">ğ’«</mi><mi id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p3.2.m2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2">ğ’«</ci><ci id="S3.SS3.p3.2.m2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">\mathcal{P}_{e}</annotation></semantics></math> using an entity-emphasizing query where the entity is appended to the end of the question. Note that the BM25 retriever does not take word order into account, so simply appending entities will not lead to undesired results due to the linguistic disfluency of the query.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.6" class="ltx_p">The final score for an entity <math id="S3.SS3.p4.1.m1.1" class="ltx_Math" alttext="S(e)" display="inline"><semantics id="S3.SS3.p4.1.m1.1a"><mrow id="S3.SS3.p4.1.m1.1.2" xref="S3.SS3.p4.1.m1.1.2.cmml"><mi id="S3.SS3.p4.1.m1.1.2.2" xref="S3.SS3.p4.1.m1.1.2.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.1.m1.1.2.1" xref="S3.SS3.p4.1.m1.1.2.1.cmml">â€‹</mo><mrow id="S3.SS3.p4.1.m1.1.2.3.2" xref="S3.SS3.p4.1.m1.1.2.cmml"><mo stretchy="false" id="S3.SS3.p4.1.m1.1.2.3.2.1" xref="S3.SS3.p4.1.m1.1.2.cmml">(</mo><mi id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml">e</mi><mo stretchy="false" id="S3.SS3.p4.1.m1.1.2.3.2.2" xref="S3.SS3.p4.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><apply id="S3.SS3.p4.1.m1.1.2.cmml" xref="S3.SS3.p4.1.m1.1.2"><times id="S3.SS3.p4.1.m1.1.2.1.cmml" xref="S3.SS3.p4.1.m1.1.2.1"></times><ci id="S3.SS3.p4.1.m1.1.2.2.cmml" xref="S3.SS3.p4.1.m1.1.2.2">ğ‘†</ci><ci id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">S(e)</annotation></semantics></math> is computed as the difference between the <span id="S3.SS3.p4.6.1" class="ltx_text ltx_markedasmath ltx_font_typewriter">SRR</span> of these two sets of retrieved passages, i.e. <math id="S3.SS3.p4.3.m3.3" class="ltx_Math" alttext="S(e)=\texttt{SRR}(\mathcal{P}_{e})-\texttt{SRR}(\mathcal{P}_{init})" display="inline"><semantics id="S3.SS3.p4.3.m3.3a"><mrow id="S3.SS3.p4.3.m3.3.3" xref="S3.SS3.p4.3.m3.3.3.cmml"><mrow id="S3.SS3.p4.3.m3.3.3.4" xref="S3.SS3.p4.3.m3.3.3.4.cmml"><mi id="S3.SS3.p4.3.m3.3.3.4.2" xref="S3.SS3.p4.3.m3.3.3.4.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.3.m3.3.3.4.1" xref="S3.SS3.p4.3.m3.3.3.4.1.cmml">â€‹</mo><mrow id="S3.SS3.p4.3.m3.3.3.4.3.2" xref="S3.SS3.p4.3.m3.3.3.4.cmml"><mo stretchy="false" id="S3.SS3.p4.3.m3.3.3.4.3.2.1" xref="S3.SS3.p4.3.m3.3.3.4.cmml">(</mo><mi id="S3.SS3.p4.3.m3.1.1" xref="S3.SS3.p4.3.m3.1.1.cmml">e</mi><mo stretchy="false" id="S3.SS3.p4.3.m3.3.3.4.3.2.2" xref="S3.SS3.p4.3.m3.3.3.4.cmml">)</mo></mrow></mrow><mo id="S3.SS3.p4.3.m3.3.3.3" xref="S3.SS3.p4.3.m3.3.3.3.cmml">=</mo><mrow id="S3.SS3.p4.3.m3.3.3.2" xref="S3.SS3.p4.3.m3.3.3.2.cmml"><mrow id="S3.SS3.p4.3.m3.2.2.1.1" xref="S3.SS3.p4.3.m3.2.2.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.SS3.p4.3.m3.2.2.1.1.3" xref="S3.SS3.p4.3.m3.2.2.1.1.3a.cmml">SRR</mtext><mo lspace="0em" rspace="0em" id="S3.SS3.p4.3.m3.2.2.1.1.2" xref="S3.SS3.p4.3.m3.2.2.1.1.2.cmml">â€‹</mo><mrow id="S3.SS3.p4.3.m3.2.2.1.1.1.1" xref="S3.SS3.p4.3.m3.2.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p4.3.m3.2.2.1.1.1.1.2" xref="S3.SS3.p4.3.m3.2.2.1.1.1.1.1.cmml">(</mo><msub id="S3.SS3.p4.3.m3.2.2.1.1.1.1.1" xref="S3.SS3.p4.3.m3.2.2.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p4.3.m3.2.2.1.1.1.1.1.2" xref="S3.SS3.p4.3.m3.2.2.1.1.1.1.1.2.cmml">ğ’«</mi><mi id="S3.SS3.p4.3.m3.2.2.1.1.1.1.1.3" xref="S3.SS3.p4.3.m3.2.2.1.1.1.1.1.3.cmml">e</mi></msub><mo stretchy="false" id="S3.SS3.p4.3.m3.2.2.1.1.1.1.3" xref="S3.SS3.p4.3.m3.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS3.p4.3.m3.3.3.2.3" xref="S3.SS3.p4.3.m3.3.3.2.3.cmml">âˆ’</mo><mrow id="S3.SS3.p4.3.m3.3.3.2.2" xref="S3.SS3.p4.3.m3.3.3.2.2.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.SS3.p4.3.m3.3.3.2.2.3" xref="S3.SS3.p4.3.m3.3.3.2.2.3a.cmml">SRR</mtext><mo lspace="0em" rspace="0em" id="S3.SS3.p4.3.m3.3.3.2.2.2" xref="S3.SS3.p4.3.m3.3.3.2.2.2.cmml">â€‹</mo><mrow id="S3.SS3.p4.3.m3.3.3.2.2.1.1" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p4.3.m3.3.3.2.2.1.1.2" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.cmml">(</mo><msub id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.2" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.2.cmml">ğ’«</mi><mrow id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.cmml"><mi id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.2" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.1" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.3" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.1a" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.4" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.1b" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.5" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.5.cmml">t</mi></mrow></msub><mo stretchy="false" id="S3.SS3.p4.3.m3.3.3.2.2.1.1.3" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m3.3b"><apply id="S3.SS3.p4.3.m3.3.3.cmml" xref="S3.SS3.p4.3.m3.3.3"><eq id="S3.SS3.p4.3.m3.3.3.3.cmml" xref="S3.SS3.p4.3.m3.3.3.3"></eq><apply id="S3.SS3.p4.3.m3.3.3.4.cmml" xref="S3.SS3.p4.3.m3.3.3.4"><times id="S3.SS3.p4.3.m3.3.3.4.1.cmml" xref="S3.SS3.p4.3.m3.3.3.4.1"></times><ci id="S3.SS3.p4.3.m3.3.3.4.2.cmml" xref="S3.SS3.p4.3.m3.3.3.4.2">ğ‘†</ci><ci id="S3.SS3.p4.3.m3.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1">ğ‘’</ci></apply><apply id="S3.SS3.p4.3.m3.3.3.2.cmml" xref="S3.SS3.p4.3.m3.3.3.2"><minus id="S3.SS3.p4.3.m3.3.3.2.3.cmml" xref="S3.SS3.p4.3.m3.3.3.2.3"></minus><apply id="S3.SS3.p4.3.m3.2.2.1.1.cmml" xref="S3.SS3.p4.3.m3.2.2.1.1"><times id="S3.SS3.p4.3.m3.2.2.1.1.2.cmml" xref="S3.SS3.p4.3.m3.2.2.1.1.2"></times><ci id="S3.SS3.p4.3.m3.2.2.1.1.3a.cmml" xref="S3.SS3.p4.3.m3.2.2.1.1.3"><mtext class="ltx_mathvariant_monospace" id="S3.SS3.p4.3.m3.2.2.1.1.3.cmml" xref="S3.SS3.p4.3.m3.2.2.1.1.3">SRR</mtext></ci><apply id="S3.SS3.p4.3.m3.2.2.1.1.1.1.1.cmml" xref="S3.SS3.p4.3.m3.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.3.m3.2.2.1.1.1.1.1.1.cmml" xref="S3.SS3.p4.3.m3.2.2.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p4.3.m3.2.2.1.1.1.1.1.2.cmml" xref="S3.SS3.p4.3.m3.2.2.1.1.1.1.1.2">ğ’«</ci><ci id="S3.SS3.p4.3.m3.2.2.1.1.1.1.1.3.cmml" xref="S3.SS3.p4.3.m3.2.2.1.1.1.1.1.3">ğ‘’</ci></apply></apply><apply id="S3.SS3.p4.3.m3.3.3.2.2.cmml" xref="S3.SS3.p4.3.m3.3.3.2.2"><times id="S3.SS3.p4.3.m3.3.3.2.2.2.cmml" xref="S3.SS3.p4.3.m3.3.3.2.2.2"></times><ci id="S3.SS3.p4.3.m3.3.3.2.2.3a.cmml" xref="S3.SS3.p4.3.m3.3.3.2.2.3"><mtext class="ltx_mathvariant_monospace" id="S3.SS3.p4.3.m3.3.3.2.2.3.cmml" xref="S3.SS3.p4.3.m3.3.3.2.2.3">SRR</mtext></ci><apply id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.cmml" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.1.cmml" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1">subscript</csymbol><ci id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.2.cmml" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.2">ğ’«</ci><apply id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.cmml" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3"><times id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.1.cmml" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.1"></times><ci id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.2.cmml" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.2">ğ‘–</ci><ci id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.3.cmml" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.3">ğ‘›</ci><ci id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.4.cmml" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.4">ğ‘–</ci><ci id="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.5.cmml" xref="S3.SS3.p4.3.m3.3.3.2.2.1.1.1.3.5">ğ‘¡</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.3.m3.3c">S(e)=\texttt{SRR}(\mathcal{P}_{e})-\texttt{SRR}(\mathcal{P}_{init})</annotation></semantics></math>. We regard entities with <math id="S3.SS3.p4.4.m4.1" class="ltx_Math" alttext="S(e)" display="inline"><semantics id="S3.SS3.p4.4.m4.1a"><mrow id="S3.SS3.p4.4.m4.1.2" xref="S3.SS3.p4.4.m4.1.2.cmml"><mi id="S3.SS3.p4.4.m4.1.2.2" xref="S3.SS3.p4.4.m4.1.2.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.4.m4.1.2.1" xref="S3.SS3.p4.4.m4.1.2.1.cmml">â€‹</mo><mrow id="S3.SS3.p4.4.m4.1.2.3.2" xref="S3.SS3.p4.4.m4.1.2.cmml"><mo stretchy="false" id="S3.SS3.p4.4.m4.1.2.3.2.1" xref="S3.SS3.p4.4.m4.1.2.cmml">(</mo><mi id="S3.SS3.p4.4.m4.1.1" xref="S3.SS3.p4.4.m4.1.1.cmml">e</mi><mo stretchy="false" id="S3.SS3.p4.4.m4.1.2.3.2.2" xref="S3.SS3.p4.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.4.m4.1b"><apply id="S3.SS3.p4.4.m4.1.2.cmml" xref="S3.SS3.p4.4.m4.1.2"><times id="S3.SS3.p4.4.m4.1.2.1.cmml" xref="S3.SS3.p4.4.m4.1.2.1"></times><ci id="S3.SS3.p4.4.m4.1.2.2.cmml" xref="S3.SS3.p4.4.m4.1.2.2">ğ‘†</ci><ci id="S3.SS3.p4.4.m4.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.4.m4.1c">S(e)</annotation></semantics></math> over a threshold <math id="S3.SS3.p4.5.m5.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS3.p4.5.m5.1a"><mi id="S3.SS3.p4.5.m5.1.1" xref="S3.SS3.p4.5.m5.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.5.m5.1b"><ci id="S3.SS3.p4.5.m5.1.1.cmml" xref="S3.SS3.p4.5.m5.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.5.m5.1c">\theta</annotation></semantics></math> as critical entities, i.e. <math id="S3.SS3.p4.6.m6.3" class="ltx_Math" alttext="\mathcal{E}_{oracle}=\{e\in\mathcal{E}|S(e)&gt;\theta\}" display="inline"><semantics id="S3.SS3.p4.6.m6.3a"><mrow id="S3.SS3.p4.6.m6.3.3" xref="S3.SS3.p4.6.m6.3.3.cmml"><msub id="S3.SS3.p4.6.m6.3.3.4" xref="S3.SS3.p4.6.m6.3.3.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p4.6.m6.3.3.4.2" xref="S3.SS3.p4.6.m6.3.3.4.2.cmml">â„°</mi><mrow id="S3.SS3.p4.6.m6.3.3.4.3" xref="S3.SS3.p4.6.m6.3.3.4.3.cmml"><mi id="S3.SS3.p4.6.m6.3.3.4.3.2" xref="S3.SS3.p4.6.m6.3.3.4.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.6.m6.3.3.4.3.1" xref="S3.SS3.p4.6.m6.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS3.p4.6.m6.3.3.4.3.3" xref="S3.SS3.p4.6.m6.3.3.4.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.6.m6.3.3.4.3.1a" xref="S3.SS3.p4.6.m6.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS3.p4.6.m6.3.3.4.3.4" xref="S3.SS3.p4.6.m6.3.3.4.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.6.m6.3.3.4.3.1b" xref="S3.SS3.p4.6.m6.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS3.p4.6.m6.3.3.4.3.5" xref="S3.SS3.p4.6.m6.3.3.4.3.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.6.m6.3.3.4.3.1c" xref="S3.SS3.p4.6.m6.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS3.p4.6.m6.3.3.4.3.6" xref="S3.SS3.p4.6.m6.3.3.4.3.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.6.m6.3.3.4.3.1d" xref="S3.SS3.p4.6.m6.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS3.p4.6.m6.3.3.4.3.7" xref="S3.SS3.p4.6.m6.3.3.4.3.7.cmml">e</mi></mrow></msub><mo id="S3.SS3.p4.6.m6.3.3.3" xref="S3.SS3.p4.6.m6.3.3.3.cmml">=</mo><mrow id="S3.SS3.p4.6.m6.3.3.2.2" xref="S3.SS3.p4.6.m6.3.3.2.3.cmml"><mo stretchy="false" id="S3.SS3.p4.6.m6.3.3.2.2.3" xref="S3.SS3.p4.6.m6.3.3.2.3.1.cmml">{</mo><mrow id="S3.SS3.p4.6.m6.2.2.1.1.1" xref="S3.SS3.p4.6.m6.2.2.1.1.1.cmml"><mi id="S3.SS3.p4.6.m6.2.2.1.1.1.2" xref="S3.SS3.p4.6.m6.2.2.1.1.1.2.cmml">e</mi><mo id="S3.SS3.p4.6.m6.2.2.1.1.1.1" xref="S3.SS3.p4.6.m6.2.2.1.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p4.6.m6.2.2.1.1.1.3" xref="S3.SS3.p4.6.m6.2.2.1.1.1.3.cmml">â„°</mi></mrow><mo lspace="0em" rspace="0em" id="S3.SS3.p4.6.m6.3.3.2.2.4" xref="S3.SS3.p4.6.m6.3.3.2.3.1.cmml">|</mo><mrow id="S3.SS3.p4.6.m6.3.3.2.2.2" xref="S3.SS3.p4.6.m6.3.3.2.2.2.cmml"><mrow id="S3.SS3.p4.6.m6.3.3.2.2.2.2" xref="S3.SS3.p4.6.m6.3.3.2.2.2.2.cmml"><mi id="S3.SS3.p4.6.m6.3.3.2.2.2.2.2" xref="S3.SS3.p4.6.m6.3.3.2.2.2.2.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.6.m6.3.3.2.2.2.2.1" xref="S3.SS3.p4.6.m6.3.3.2.2.2.2.1.cmml">â€‹</mo><mrow id="S3.SS3.p4.6.m6.3.3.2.2.2.2.3.2" xref="S3.SS3.p4.6.m6.3.3.2.2.2.2.cmml"><mo stretchy="false" id="S3.SS3.p4.6.m6.3.3.2.2.2.2.3.2.1" xref="S3.SS3.p4.6.m6.3.3.2.2.2.2.cmml">(</mo><mi id="S3.SS3.p4.6.m6.1.1" xref="S3.SS3.p4.6.m6.1.1.cmml">e</mi><mo stretchy="false" id="S3.SS3.p4.6.m6.3.3.2.2.2.2.3.2.2" xref="S3.SS3.p4.6.m6.3.3.2.2.2.2.cmml">)</mo></mrow></mrow><mo id="S3.SS3.p4.6.m6.3.3.2.2.2.1" xref="S3.SS3.p4.6.m6.3.3.2.2.2.1.cmml">&gt;</mo><mi id="S3.SS3.p4.6.m6.3.3.2.2.2.3" xref="S3.SS3.p4.6.m6.3.3.2.2.2.3.cmml">Î¸</mi></mrow><mo stretchy="false" id="S3.SS3.p4.6.m6.3.3.2.2.5" xref="S3.SS3.p4.6.m6.3.3.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.6.m6.3b"><apply id="S3.SS3.p4.6.m6.3.3.cmml" xref="S3.SS3.p4.6.m6.3.3"><eq id="S3.SS3.p4.6.m6.3.3.3.cmml" xref="S3.SS3.p4.6.m6.3.3.3"></eq><apply id="S3.SS3.p4.6.m6.3.3.4.cmml" xref="S3.SS3.p4.6.m6.3.3.4"><csymbol cd="ambiguous" id="S3.SS3.p4.6.m6.3.3.4.1.cmml" xref="S3.SS3.p4.6.m6.3.3.4">subscript</csymbol><ci id="S3.SS3.p4.6.m6.3.3.4.2.cmml" xref="S3.SS3.p4.6.m6.3.3.4.2">â„°</ci><apply id="S3.SS3.p4.6.m6.3.3.4.3.cmml" xref="S3.SS3.p4.6.m6.3.3.4.3"><times id="S3.SS3.p4.6.m6.3.3.4.3.1.cmml" xref="S3.SS3.p4.6.m6.3.3.4.3.1"></times><ci id="S3.SS3.p4.6.m6.3.3.4.3.2.cmml" xref="S3.SS3.p4.6.m6.3.3.4.3.2">ğ‘œ</ci><ci id="S3.SS3.p4.6.m6.3.3.4.3.3.cmml" xref="S3.SS3.p4.6.m6.3.3.4.3.3">ğ‘Ÿ</ci><ci id="S3.SS3.p4.6.m6.3.3.4.3.4.cmml" xref="S3.SS3.p4.6.m6.3.3.4.3.4">ğ‘</ci><ci id="S3.SS3.p4.6.m6.3.3.4.3.5.cmml" xref="S3.SS3.p4.6.m6.3.3.4.3.5">ğ‘</ci><ci id="S3.SS3.p4.6.m6.3.3.4.3.6.cmml" xref="S3.SS3.p4.6.m6.3.3.4.3.6">ğ‘™</ci><ci id="S3.SS3.p4.6.m6.3.3.4.3.7.cmml" xref="S3.SS3.p4.6.m6.3.3.4.3.7">ğ‘’</ci></apply></apply><apply id="S3.SS3.p4.6.m6.3.3.2.3.cmml" xref="S3.SS3.p4.6.m6.3.3.2.2"><csymbol cd="latexml" id="S3.SS3.p4.6.m6.3.3.2.3.1.cmml" xref="S3.SS3.p4.6.m6.3.3.2.2.3">conditional-set</csymbol><apply id="S3.SS3.p4.6.m6.2.2.1.1.1.cmml" xref="S3.SS3.p4.6.m6.2.2.1.1.1"><in id="S3.SS3.p4.6.m6.2.2.1.1.1.1.cmml" xref="S3.SS3.p4.6.m6.2.2.1.1.1.1"></in><ci id="S3.SS3.p4.6.m6.2.2.1.1.1.2.cmml" xref="S3.SS3.p4.6.m6.2.2.1.1.1.2">ğ‘’</ci><ci id="S3.SS3.p4.6.m6.2.2.1.1.1.3.cmml" xref="S3.SS3.p4.6.m6.2.2.1.1.1.3">â„°</ci></apply><apply id="S3.SS3.p4.6.m6.3.3.2.2.2.cmml" xref="S3.SS3.p4.6.m6.3.3.2.2.2"><gt id="S3.SS3.p4.6.m6.3.3.2.2.2.1.cmml" xref="S3.SS3.p4.6.m6.3.3.2.2.2.1"></gt><apply id="S3.SS3.p4.6.m6.3.3.2.2.2.2.cmml" xref="S3.SS3.p4.6.m6.3.3.2.2.2.2"><times id="S3.SS3.p4.6.m6.3.3.2.2.2.2.1.cmml" xref="S3.SS3.p4.6.m6.3.3.2.2.2.2.1"></times><ci id="S3.SS3.p4.6.m6.3.3.2.2.2.2.2.cmml" xref="S3.SS3.p4.6.m6.3.3.2.2.2.2.2">ğ‘†</ci><ci id="S3.SS3.p4.6.m6.1.1.cmml" xref="S3.SS3.p4.6.m6.1.1">ğ‘’</ci></apply><ci id="S3.SS3.p4.6.m6.3.3.2.2.2.3.cmml" xref="S3.SS3.p4.6.m6.3.3.2.2.2.3">ğœƒ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.6.m6.3c">\mathcal{E}_{oracle}=\{e\in\mathcal{E}|S(e)&gt;\theta\}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<p id="S3.SS3.p5.6" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Qu etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite> extract the top-<math id="S3.SS3.p5.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.p5.1.m1.1a"><mi id="S3.SS3.p5.1.m1.1.1" xref="S3.SS3.p5.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.m1.1b"><ci id="S3.SS3.p5.1.m1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.1.m1.1c">k</annotation></semantics></math> passages containing the correct answer from <math id="S3.SS3.p5.2.m2.1" class="ltx_Math" alttext="\mathcal{P}_{init}" display="inline"><semantics id="S3.SS3.p5.2.m2.1a"><msub id="S3.SS3.p5.2.m2.1.1" xref="S3.SS3.p5.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p5.2.m2.1.1.2" xref="S3.SS3.p5.2.m2.1.1.2.cmml">ğ’«</mi><mrow id="S3.SS3.p5.2.m2.1.1.3" xref="S3.SS3.p5.2.m2.1.1.3.cmml"><mi id="S3.SS3.p5.2.m2.1.1.3.2" xref="S3.SS3.p5.2.m2.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.2.m2.1.1.3.1" xref="S3.SS3.p5.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p5.2.m2.1.1.3.3" xref="S3.SS3.p5.2.m2.1.1.3.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.2.m2.1.1.3.1a" xref="S3.SS3.p5.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p5.2.m2.1.1.3.4" xref="S3.SS3.p5.2.m2.1.1.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.2.m2.1.1.3.1b" xref="S3.SS3.p5.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p5.2.m2.1.1.3.5" xref="S3.SS3.p5.2.m2.1.1.3.5.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.2.m2.1b"><apply id="S3.SS3.p5.2.m2.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.2.m2.1.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p5.2.m2.1.1.2.cmml" xref="S3.SS3.p5.2.m2.1.1.2">ğ’«</ci><apply id="S3.SS3.p5.2.m2.1.1.3.cmml" xref="S3.SS3.p5.2.m2.1.1.3"><times id="S3.SS3.p5.2.m2.1.1.3.1.cmml" xref="S3.SS3.p5.2.m2.1.1.3.1"></times><ci id="S3.SS3.p5.2.m2.1.1.3.2.cmml" xref="S3.SS3.p5.2.m2.1.1.3.2">ğ‘–</ci><ci id="S3.SS3.p5.2.m2.1.1.3.3.cmml" xref="S3.SS3.p5.2.m2.1.1.3.3">ğ‘›</ci><ci id="S3.SS3.p5.2.m2.1.1.3.4.cmml" xref="S3.SS3.p5.2.m2.1.1.3.4">ğ‘–</ci><ci id="S3.SS3.p5.2.m2.1.1.3.5.cmml" xref="S3.SS3.p5.2.m2.1.1.3.5">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.2.m2.1c">\mathcal{P}_{init}</annotation></semantics></math> to construct the positive passage set <math id="S3.SS3.p5.3.m3.1" class="ltx_Math" alttext="\mathcal{P}^{+}_{init}" display="inline"><semantics id="S3.SS3.p5.3.m3.1a"><msubsup id="S3.SS3.p5.3.m3.1.1" xref="S3.SS3.p5.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p5.3.m3.1.1.2.2" xref="S3.SS3.p5.3.m3.1.1.2.2.cmml">ğ’«</mi><mrow id="S3.SS3.p5.3.m3.1.1.3" xref="S3.SS3.p5.3.m3.1.1.3.cmml"><mi id="S3.SS3.p5.3.m3.1.1.3.2" xref="S3.SS3.p5.3.m3.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.3.m3.1.1.3.1" xref="S3.SS3.p5.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p5.3.m3.1.1.3.3" xref="S3.SS3.p5.3.m3.1.1.3.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.3.m3.1.1.3.1a" xref="S3.SS3.p5.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p5.3.m3.1.1.3.4" xref="S3.SS3.p5.3.m3.1.1.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.3.m3.1.1.3.1b" xref="S3.SS3.p5.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p5.3.m3.1.1.3.5" xref="S3.SS3.p5.3.m3.1.1.3.5.cmml">t</mi></mrow><mo id="S3.SS3.p5.3.m3.1.1.2.3" xref="S3.SS3.p5.3.m3.1.1.2.3.cmml">+</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.3.m3.1b"><apply id="S3.SS3.p5.3.m3.1.1.cmml" xref="S3.SS3.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.3.m3.1.1.1.cmml" xref="S3.SS3.p5.3.m3.1.1">subscript</csymbol><apply id="S3.SS3.p5.3.m3.1.1.2.cmml" xref="S3.SS3.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.3.m3.1.1.2.1.cmml" xref="S3.SS3.p5.3.m3.1.1">superscript</csymbol><ci id="S3.SS3.p5.3.m3.1.1.2.2.cmml" xref="S3.SS3.p5.3.m3.1.1.2.2">ğ’«</ci><plus id="S3.SS3.p5.3.m3.1.1.2.3.cmml" xref="S3.SS3.p5.3.m3.1.1.2.3"></plus></apply><apply id="S3.SS3.p5.3.m3.1.1.3.cmml" xref="S3.SS3.p5.3.m3.1.1.3"><times id="S3.SS3.p5.3.m3.1.1.3.1.cmml" xref="S3.SS3.p5.3.m3.1.1.3.1"></times><ci id="S3.SS3.p5.3.m3.1.1.3.2.cmml" xref="S3.SS3.p5.3.m3.1.1.3.2">ğ‘–</ci><ci id="S3.SS3.p5.3.m3.1.1.3.3.cmml" xref="S3.SS3.p5.3.m3.1.1.3.3">ğ‘›</ci><ci id="S3.SS3.p5.3.m3.1.1.3.4.cmml" xref="S3.SS3.p5.3.m3.1.1.3.4">ğ‘–</ci><ci id="S3.SS3.p5.3.m3.1.1.3.5.cmml" xref="S3.SS3.p5.3.m3.1.1.3.5">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.3.m3.1c">\mathcal{P}^{+}_{init}</annotation></semantics></math>. As we have identified oracle entities, the passage that contains both the right answer and the oracle entity is more likely to fit in the context of the question.
Therefore, we augmented the positive passage set to include those passages for each oracle entity, <math id="S3.SS3.p5.4.m4.3" class="ltx_Math" alttext="i.e." display="inline"><semantics id="S3.SS3.p5.4.m4.3a"><mrow id="S3.SS3.p5.4.m4.3.3.1"><mrow id="S3.SS3.p5.4.m4.3.3.1.1.2" xref="S3.SS3.p5.4.m4.3.3.1.1.1.cmml"><mi id="S3.SS3.p5.4.m4.1.1" xref="S3.SS3.p5.4.m4.1.1.cmml">i</mi><mo lspace="0em" rspace="0.167em" id="S3.SS3.p5.4.m4.3.3.1.1.2.1" xref="S3.SS3.p5.4.m4.3.3.1.1.1a.cmml">.</mo><mi id="S3.SS3.p5.4.m4.2.2" xref="S3.SS3.p5.4.m4.2.2.cmml">e</mi></mrow><mo lspace="0em" id="S3.SS3.p5.4.m4.3.3.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.4.m4.3b"><apply id="S3.SS3.p5.4.m4.3.3.1.1.1.cmml" xref="S3.SS3.p5.4.m4.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p5.4.m4.3.3.1.1.1a.cmml" xref="S3.SS3.p5.4.m4.3.3.1.1.2.1">formulae-sequence</csymbol><ci id="S3.SS3.p5.4.m4.1.1.cmml" xref="S3.SS3.p5.4.m4.1.1">ğ‘–</ci><ci id="S3.SS3.p5.4.m4.2.2.cmml" xref="S3.SS3.p5.4.m4.2.2">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.4.m4.3c">i.e.</annotation></semantics></math> <math id="S3.SS3.p5.5.m5.1" class="ltx_Math" alttext="\mathcal{P}^{+}_{\mathcal{E}}=\bigcup_{e\in\mathcal{E}_{oracle}}(\{p^{+}_{e}\})" display="inline"><semantics id="S3.SS3.p5.5.m5.1a"><mrow id="S3.SS3.p5.5.m5.1.1" xref="S3.SS3.p5.5.m5.1.1.cmml"><msubsup id="S3.SS3.p5.5.m5.1.1.3" xref="S3.SS3.p5.5.m5.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p5.5.m5.1.1.3.2.2" xref="S3.SS3.p5.5.m5.1.1.3.2.2.cmml">ğ’«</mi><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p5.5.m5.1.1.3.3" xref="S3.SS3.p5.5.m5.1.1.3.3.cmml">â„°</mi><mo id="S3.SS3.p5.5.m5.1.1.3.2.3" xref="S3.SS3.p5.5.m5.1.1.3.2.3.cmml">+</mo></msubsup><mo rspace="0.111em" id="S3.SS3.p5.5.m5.1.1.2" xref="S3.SS3.p5.5.m5.1.1.2.cmml">=</mo><mrow id="S3.SS3.p5.5.m5.1.1.1" xref="S3.SS3.p5.5.m5.1.1.1.cmml"><msub id="S3.SS3.p5.5.m5.1.1.1.2" xref="S3.SS3.p5.5.m5.1.1.1.2.cmml"><mo rspace="0em" id="S3.SS3.p5.5.m5.1.1.1.2.2" xref="S3.SS3.p5.5.m5.1.1.1.2.2.cmml">â‹ƒ</mo><mrow id="S3.SS3.p5.5.m5.1.1.1.2.3" xref="S3.SS3.p5.5.m5.1.1.1.2.3.cmml"><mi id="S3.SS3.p5.5.m5.1.1.1.2.3.2" xref="S3.SS3.p5.5.m5.1.1.1.2.3.2.cmml">e</mi><mo id="S3.SS3.p5.5.m5.1.1.1.2.3.1" xref="S3.SS3.p5.5.m5.1.1.1.2.3.1.cmml">âˆˆ</mo><msub id="S3.SS3.p5.5.m5.1.1.1.2.3.3" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p5.5.m5.1.1.1.2.3.3.2" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.2.cmml">â„°</mi><mrow id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.cmml"><mi id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.2" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.1" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.3" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.1a" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.4" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.1b" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.5" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.1c" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.6" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.1d" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.7" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.7.cmml">e</mi></mrow></msub></mrow></msub><mrow id="S3.SS3.p5.5.m5.1.1.1.1.1" xref="S3.SS3.p5.5.m5.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p5.5.m5.1.1.1.1.1.2" xref="S3.SS3.p5.5.m5.1.1.1.cmml">(</mo><mrow id="S3.SS3.p5.5.m5.1.1.1.1.1.1.1" xref="S3.SS3.p5.5.m5.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.2" xref="S3.SS3.p5.5.m5.1.1.1.1.1.1.2.cmml">{</mo><msubsup id="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1" xref="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1.2.2" xref="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1.2.2.cmml">p</mi><mi id="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1.3" xref="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1.3.cmml">e</mi><mo id="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1.2.3" xref="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1.2.3.cmml">+</mo></msubsup><mo stretchy="false" id="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.3" xref="S3.SS3.p5.5.m5.1.1.1.1.1.1.2.cmml">}</mo></mrow><mo stretchy="false" id="S3.SS3.p5.5.m5.1.1.1.1.1.3" xref="S3.SS3.p5.5.m5.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.5.m5.1b"><apply id="S3.SS3.p5.5.m5.1.1.cmml" xref="S3.SS3.p5.5.m5.1.1"><eq id="S3.SS3.p5.5.m5.1.1.2.cmml" xref="S3.SS3.p5.5.m5.1.1.2"></eq><apply id="S3.SS3.p5.5.m5.1.1.3.cmml" xref="S3.SS3.p5.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p5.5.m5.1.1.3.1.cmml" xref="S3.SS3.p5.5.m5.1.1.3">subscript</csymbol><apply id="S3.SS3.p5.5.m5.1.1.3.2.cmml" xref="S3.SS3.p5.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p5.5.m5.1.1.3.2.1.cmml" xref="S3.SS3.p5.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS3.p5.5.m5.1.1.3.2.2.cmml" xref="S3.SS3.p5.5.m5.1.1.3.2.2">ğ’«</ci><plus id="S3.SS3.p5.5.m5.1.1.3.2.3.cmml" xref="S3.SS3.p5.5.m5.1.1.3.2.3"></plus></apply><ci id="S3.SS3.p5.5.m5.1.1.3.3.cmml" xref="S3.SS3.p5.5.m5.1.1.3.3">â„°</ci></apply><apply id="S3.SS3.p5.5.m5.1.1.1.cmml" xref="S3.SS3.p5.5.m5.1.1.1"><apply id="S3.SS3.p5.5.m5.1.1.1.2.cmml" xref="S3.SS3.p5.5.m5.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p5.5.m5.1.1.1.2.1.cmml" xref="S3.SS3.p5.5.m5.1.1.1.2">subscript</csymbol><union id="S3.SS3.p5.5.m5.1.1.1.2.2.cmml" xref="S3.SS3.p5.5.m5.1.1.1.2.2"></union><apply id="S3.SS3.p5.5.m5.1.1.1.2.3.cmml" xref="S3.SS3.p5.5.m5.1.1.1.2.3"><in id="S3.SS3.p5.5.m5.1.1.1.2.3.1.cmml" xref="S3.SS3.p5.5.m5.1.1.1.2.3.1"></in><ci id="S3.SS3.p5.5.m5.1.1.1.2.3.2.cmml" xref="S3.SS3.p5.5.m5.1.1.1.2.3.2">ğ‘’</ci><apply id="S3.SS3.p5.5.m5.1.1.1.2.3.3.cmml" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3"><csymbol cd="ambiguous" id="S3.SS3.p5.5.m5.1.1.1.2.3.3.1.cmml" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3">subscript</csymbol><ci id="S3.SS3.p5.5.m5.1.1.1.2.3.3.2.cmml" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.2">â„°</ci><apply id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.cmml" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3"><times id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.1.cmml" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.1"></times><ci id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.2.cmml" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.2">ğ‘œ</ci><ci id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.3.cmml" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.3">ğ‘Ÿ</ci><ci id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.4.cmml" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.4">ğ‘</ci><ci id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.5.cmml" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.5">ğ‘</ci><ci id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.6.cmml" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.6">ğ‘™</ci><ci id="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.7.cmml" xref="S3.SS3.p5.5.m5.1.1.1.2.3.3.3.7">ğ‘’</ci></apply></apply></apply></apply><set id="S3.SS3.p5.5.m5.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p5.5.m5.1.1.1.1.1.1.1"><apply id="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1.2.2">ğ‘</ci><plus id="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1.2.3"></plus></apply><ci id="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p5.5.m5.1.1.1.1.1.1.1.1.3">ğ‘’</ci></apply></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.5.m5.1c">\mathcal{P}^{+}_{\mathcal{E}}=\bigcup_{e\in\mathcal{E}_{oracle}}(\{p^{+}_{e}\})</annotation></semantics></math>, where <math id="S3.SS3.p5.6.m6.1" class="ltx_Math" alttext="p^{+}_{e}" display="inline"><semantics id="S3.SS3.p5.6.m6.1a"><msubsup id="S3.SS3.p5.6.m6.1.1" xref="S3.SS3.p5.6.m6.1.1.cmml"><mi id="S3.SS3.p5.6.m6.1.1.2.2" xref="S3.SS3.p5.6.m6.1.1.2.2.cmml">p</mi><mi id="S3.SS3.p5.6.m6.1.1.3" xref="S3.SS3.p5.6.m6.1.1.3.cmml">e</mi><mo id="S3.SS3.p5.6.m6.1.1.2.3" xref="S3.SS3.p5.6.m6.1.1.2.3.cmml">+</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.6.m6.1b"><apply id="S3.SS3.p5.6.m6.1.1.cmml" xref="S3.SS3.p5.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.6.m6.1.1.1.cmml" xref="S3.SS3.p5.6.m6.1.1">subscript</csymbol><apply id="S3.SS3.p5.6.m6.1.1.2.cmml" xref="S3.SS3.p5.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.6.m6.1.1.2.1.cmml" xref="S3.SS3.p5.6.m6.1.1">superscript</csymbol><ci id="S3.SS3.p5.6.m6.1.1.2.2.cmml" xref="S3.SS3.p5.6.m6.1.1.2.2">ğ‘</ci><plus id="S3.SS3.p5.6.m6.1.1.2.3.cmml" xref="S3.SS3.p5.6.m6.1.1.2.3"></plus></apply><ci id="S3.SS3.p5.6.m6.1.1.3.cmml" xref="S3.SS3.p5.6.m6.1.1.3">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.6.m6.1c">p^{+}_{e}</annotation></semantics></math> denotes the first passage that contains both the right answer and the oracle entity. On average, there are 3.4 new positive passages per question. The negative passages are the same as those in <cite class="ltx_cite ltx_citemacro_cite">Qu etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite>, and the number of training instances (positive-negative pairs) is not changed.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2210.10176/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="531" height="318" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>EnFoRe model overview. We first extract a set of entities from the query consisting of a question and an image (Sec. 3). Then, the EnFoRe model computes the features for the query, the entities, and the passages (Sec. 4.1). Query features and passage features, together with entity features, are used to compute a query-entity score and a passage-entity score to indicate the importance of the entities given the query and the passages, respectively (Sec. 4.2). These two importance scores are combined to produce an entity-matching score, and the features of the query and the passages are used to predict a query-passage matching score. </figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Entity-Focused Retrieval</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p"><span id="S4.p1.1.1" class="ltx_text ltx_font_bold">En</span>tity-<span id="S4.p1.1.2" class="ltx_text ltx_font_bold">Fo</span>cused <span id="S4.p1.1.3" class="ltx_text ltx_font_bold">Re</span>trieval (EnFoRe) automatically recognizes critical entities and retrieves question-relevant knowledge specifically focused on them. â€œ<span id="S4.p1.1.4" class="ltx_text ltx_font_typewriter">proj</span>â€ denotes a projection function that consists of an MLP layer with layer-norm as normalization.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Encoders</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.4" class="ltx_p"><span id="S4.SS1.p1.4.1" class="ltx_text ltx_font_bold">Query encoder:</span> As observed by <cite class="ltx_cite ltx_citemacro_citet">Qu etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Luo etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite>, multi-modal transformers encode questions and visual content better than uni-modal transformers, so we adopt LXMERT <cite class="ltx_cite ltx_citemacro_cite">Tan and Bansal (<a href="#bib.bib37" title="" class="ltx_ref">2019</a>)</cite> for query encoding. In particular, we project the â€œ<span id="S4.SS1.p1.4.2" class="ltx_text ltx_font_typewriter">pooled_output</span>â€ at the last layer from LXMERT as the feature vector <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="f_{q}\in R^{d}" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><msub id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2.2" xref="S4.SS1.p1.1.m1.1.1.2.2.cmml">f</mi><mi id="S4.SS1.p1.1.m1.1.1.2.3" xref="S4.SS1.p1.1.m1.1.1.2.3.cmml">q</mi></msub><mo id="S4.SS1.p1.1.m1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml"><mi id="S4.SS1.p1.1.m1.1.1.3.2" xref="S4.SS1.p1.1.m1.1.1.3.2.cmml">R</mi><mi id="S4.SS1.p1.1.m1.1.1.3.3" xref="S4.SS1.p1.1.m1.1.1.3.3.cmml">d</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><in id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1"></in><apply id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.2.1.cmml" xref="S4.SS1.p1.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.2.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2.2">ğ‘“</ci><ci id="S4.SS1.p1.1.m1.1.1.2.3.cmml" xref="S4.SS1.p1.1.m1.1.1.2.3">ğ‘</ci></apply><apply id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.3.1.cmml" xref="S4.SS1.p1.1.m1.1.1.3">superscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.3.2.cmml" xref="S4.SS1.p1.1.m1.1.1.3.2">ğ‘…</ci><ci id="S4.SS1.p1.1.m1.1.1.3.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">f_{q}\in R^{d}</annotation></semantics></math> given the query <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mi id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><ci id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">q</annotation></semantics></math> that contains a visual question <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mi id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><ci id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">Q</annotation></semantics></math> and the set of detected objects <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{V}" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml">ğ’±</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><ci id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">ğ’±</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">\mathcal{V}</annotation></semantics></math> in the image as shown in Eq. <a href="#S4.E2" title="In 4.1 Encoders â€£ 4 Entity-Focused Retrieval â€£ Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. See the LXMERT paper for further details.</p>
<table id="S4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E2.m1.3" class="ltx_Math" alttext="f_{q}=\texttt{proj}(\texttt{LXMERT}(Q,\mathcal{V}))" display="block"><semantics id="S4.E2.m1.3a"><mrow id="S4.E2.m1.3.3" xref="S4.E2.m1.3.3.cmml"><msub id="S4.E2.m1.3.3.3" xref="S4.E2.m1.3.3.3.cmml"><mi id="S4.E2.m1.3.3.3.2" xref="S4.E2.m1.3.3.3.2.cmml">f</mi><mi id="S4.E2.m1.3.3.3.3" xref="S4.E2.m1.3.3.3.3.cmml">q</mi></msub><mo id="S4.E2.m1.3.3.2" xref="S4.E2.m1.3.3.2.cmml">=</mo><mrow id="S4.E2.m1.3.3.1" xref="S4.E2.m1.3.3.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S4.E2.m1.3.3.1.3" xref="S4.E2.m1.3.3.1.3a.cmml">proj</mtext><mo lspace="0em" rspace="0em" id="S4.E2.m1.3.3.1.2" xref="S4.E2.m1.3.3.1.2.cmml">â€‹</mo><mrow id="S4.E2.m1.3.3.1.1.1" xref="S4.E2.m1.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S4.E2.m1.3.3.1.1.1.2" xref="S4.E2.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="S4.E2.m1.3.3.1.1.1.1" xref="S4.E2.m1.3.3.1.1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S4.E2.m1.3.3.1.1.1.1.2" xref="S4.E2.m1.3.3.1.1.1.1.2a.cmml">LXMERT</mtext><mo lspace="0em" rspace="0em" id="S4.E2.m1.3.3.1.1.1.1.1" xref="S4.E2.m1.3.3.1.1.1.1.1.cmml">â€‹</mo><mrow id="S4.E2.m1.3.3.1.1.1.1.3.2" xref="S4.E2.m1.3.3.1.1.1.1.3.1.cmml"><mo stretchy="false" id="S4.E2.m1.3.3.1.1.1.1.3.2.1" xref="S4.E2.m1.3.3.1.1.1.1.3.1.cmml">(</mo><mi id="S4.E2.m1.1.1" xref="S4.E2.m1.1.1.cmml">Q</mi><mo id="S4.E2.m1.3.3.1.1.1.1.3.2.2" xref="S4.E2.m1.3.3.1.1.1.1.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.2.2" xref="S4.E2.m1.2.2.cmml">ğ’±</mi><mo stretchy="false" id="S4.E2.m1.3.3.1.1.1.1.3.2.3" xref="S4.E2.m1.3.3.1.1.1.1.3.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.E2.m1.3.3.1.1.1.3" xref="S4.E2.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.3b"><apply id="S4.E2.m1.3.3.cmml" xref="S4.E2.m1.3.3"><eq id="S4.E2.m1.3.3.2.cmml" xref="S4.E2.m1.3.3.2"></eq><apply id="S4.E2.m1.3.3.3.cmml" xref="S4.E2.m1.3.3.3"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.3.1.cmml" xref="S4.E2.m1.3.3.3">subscript</csymbol><ci id="S4.E2.m1.3.3.3.2.cmml" xref="S4.E2.m1.3.3.3.2">ğ‘“</ci><ci id="S4.E2.m1.3.3.3.3.cmml" xref="S4.E2.m1.3.3.3.3">ğ‘</ci></apply><apply id="S4.E2.m1.3.3.1.cmml" xref="S4.E2.m1.3.3.1"><times id="S4.E2.m1.3.3.1.2.cmml" xref="S4.E2.m1.3.3.1.2"></times><ci id="S4.E2.m1.3.3.1.3a.cmml" xref="S4.E2.m1.3.3.1.3"><mtext class="ltx_mathvariant_monospace" id="S4.E2.m1.3.3.1.3.cmml" xref="S4.E2.m1.3.3.1.3">proj</mtext></ci><apply id="S4.E2.m1.3.3.1.1.1.1.cmml" xref="S4.E2.m1.3.3.1.1.1"><times id="S4.E2.m1.3.3.1.1.1.1.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1"></times><ci id="S4.E2.m1.3.3.1.1.1.1.2a.cmml" xref="S4.E2.m1.3.3.1.1.1.1.2"><mtext class="ltx_mathvariant_monospace" id="S4.E2.m1.3.3.1.1.1.1.2.cmml" xref="S4.E2.m1.3.3.1.1.1.1.2">LXMERT</mtext></ci><interval closure="open" id="S4.E2.m1.3.3.1.1.1.1.3.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.3.2"><ci id="S4.E2.m1.1.1.cmml" xref="S4.E2.m1.1.1">ğ‘„</ci><ci id="S4.E2.m1.2.2.cmml" xref="S4.E2.m1.2.2">ğ’±</ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.3c">f_{q}=\texttt{proj}(\texttt{LXMERT}(Q,\mathcal{V}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<br class="ltx_break">
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Passage encoder:</span> Following <cite class="ltx_cite ltx_citemacro_citet">Qu etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite>, we use BERT <cite class="ltx_cite ltx_citemacro_cite">Devlin etÂ al. (<a href="#bib.bib6" title="" class="ltx_ref">2019</a>)</cite> as the passage encoder and project the â€œ<span id="S4.SS1.p2.1.2" class="ltx_text ltx_font_typewriter">[CLS]</span>â€ representation to compute the vector features for each passage <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">p</annotation></semantics></math>.</p>
<table id="S4.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E3.m1.2" class="ltx_Math" alttext="f_{p}=\texttt{proj}(\texttt{BERT}(p))" display="block"><semantics id="S4.E3.m1.2a"><mrow id="S4.E3.m1.2.2" xref="S4.E3.m1.2.2.cmml"><msub id="S4.E3.m1.2.2.3" xref="S4.E3.m1.2.2.3.cmml"><mi id="S4.E3.m1.2.2.3.2" xref="S4.E3.m1.2.2.3.2.cmml">f</mi><mi id="S4.E3.m1.2.2.3.3" xref="S4.E3.m1.2.2.3.3.cmml">p</mi></msub><mo id="S4.E3.m1.2.2.2" xref="S4.E3.m1.2.2.2.cmml">=</mo><mrow id="S4.E3.m1.2.2.1" xref="S4.E3.m1.2.2.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S4.E3.m1.2.2.1.3" xref="S4.E3.m1.2.2.1.3a.cmml">proj</mtext><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.2.1.2" xref="S4.E3.m1.2.2.1.2.cmml">â€‹</mo><mrow id="S4.E3.m1.2.2.1.1.1" xref="S4.E3.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S4.E3.m1.2.2.1.1.1.2" xref="S4.E3.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S4.E3.m1.2.2.1.1.1.1" xref="S4.E3.m1.2.2.1.1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S4.E3.m1.2.2.1.1.1.1.2" xref="S4.E3.m1.2.2.1.1.1.1.2a.cmml">BERT</mtext><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.2.1.1.1.1.1" xref="S4.E3.m1.2.2.1.1.1.1.1.cmml">â€‹</mo><mrow id="S4.E3.m1.2.2.1.1.1.1.3.2" xref="S4.E3.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S4.E3.m1.2.2.1.1.1.1.3.2.1" xref="S4.E3.m1.2.2.1.1.1.1.cmml">(</mo><mi id="S4.E3.m1.1.1" xref="S4.E3.m1.1.1.cmml">p</mi><mo stretchy="false" id="S4.E3.m1.2.2.1.1.1.1.3.2.2" xref="S4.E3.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.E3.m1.2.2.1.1.1.3" xref="S4.E3.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.2b"><apply id="S4.E3.m1.2.2.cmml" xref="S4.E3.m1.2.2"><eq id="S4.E3.m1.2.2.2.cmml" xref="S4.E3.m1.2.2.2"></eq><apply id="S4.E3.m1.2.2.3.cmml" xref="S4.E3.m1.2.2.3"><csymbol cd="ambiguous" id="S4.E3.m1.2.2.3.1.cmml" xref="S4.E3.m1.2.2.3">subscript</csymbol><ci id="S4.E3.m1.2.2.3.2.cmml" xref="S4.E3.m1.2.2.3.2">ğ‘“</ci><ci id="S4.E3.m1.2.2.3.3.cmml" xref="S4.E3.m1.2.2.3.3">ğ‘</ci></apply><apply id="S4.E3.m1.2.2.1.cmml" xref="S4.E3.m1.2.2.1"><times id="S4.E3.m1.2.2.1.2.cmml" xref="S4.E3.m1.2.2.1.2"></times><ci id="S4.E3.m1.2.2.1.3a.cmml" xref="S4.E3.m1.2.2.1.3"><mtext class="ltx_mathvariant_monospace" id="S4.E3.m1.2.2.1.3.cmml" xref="S4.E3.m1.2.2.1.3">proj</mtext></ci><apply id="S4.E3.m1.2.2.1.1.1.1.cmml" xref="S4.E3.m1.2.2.1.1.1"><times id="S4.E3.m1.2.2.1.1.1.1.1.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1"></times><ci id="S4.E3.m1.2.2.1.1.1.1.2a.cmml" xref="S4.E3.m1.2.2.1.1.1.1.2"><mtext class="ltx_mathvariant_monospace" id="S4.E3.m1.2.2.1.1.1.1.2.cmml" xref="S4.E3.m1.2.2.1.1.1.1.2">BERT</mtext></ci><ci id="S4.E3.m1.1.1.cmml" xref="S4.E3.m1.1.1">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.2c">f_{p}=\texttt{proj}(\texttt{BERT}(p))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Entity encoder:</span> In order to provide query context for each entity, we append the question and a generated image caption <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib39" title="" class="ltx_ref">2022</a>)</cite> after each entity. The input to the Entity encoder is â€œ<span id="S4.SS1.p3.1.2" class="ltx_text ltx_font_typewriter">[CLS] entity [SEP] question [SEP] caption</span>â€. Similar to the passage encoder, we use BERT <cite class="ltx_cite ltx_citemacro_cite">Devlin etÂ al. (<a href="#bib.bib6" title="" class="ltx_ref">2019</a>)</cite> as the entity encoder and project the â€œ<span id="S4.SS1.p3.1.3" class="ltx_text ltx_font_typewriter">[CLS]</span>â€ representation to compute the features for each entity.</p>
<table id="S4.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E4.m1.2" class="ltx_Math" alttext="f_{e}=\texttt{proj}(\texttt{BERT}(e))" display="block"><semantics id="S4.E4.m1.2a"><mrow id="S4.E4.m1.2.2" xref="S4.E4.m1.2.2.cmml"><msub id="S4.E4.m1.2.2.3" xref="S4.E4.m1.2.2.3.cmml"><mi id="S4.E4.m1.2.2.3.2" xref="S4.E4.m1.2.2.3.2.cmml">f</mi><mi id="S4.E4.m1.2.2.3.3" xref="S4.E4.m1.2.2.3.3.cmml">e</mi></msub><mo id="S4.E4.m1.2.2.2" xref="S4.E4.m1.2.2.2.cmml">=</mo><mrow id="S4.E4.m1.2.2.1" xref="S4.E4.m1.2.2.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S4.E4.m1.2.2.1.3" xref="S4.E4.m1.2.2.1.3a.cmml">proj</mtext><mo lspace="0em" rspace="0em" id="S4.E4.m1.2.2.1.2" xref="S4.E4.m1.2.2.1.2.cmml">â€‹</mo><mrow id="S4.E4.m1.2.2.1.1.1" xref="S4.E4.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S4.E4.m1.2.2.1.1.1.2" xref="S4.E4.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S4.E4.m1.2.2.1.1.1.1" xref="S4.E4.m1.2.2.1.1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S4.E4.m1.2.2.1.1.1.1.2" xref="S4.E4.m1.2.2.1.1.1.1.2a.cmml">BERT</mtext><mo lspace="0em" rspace="0em" id="S4.E4.m1.2.2.1.1.1.1.1" xref="S4.E4.m1.2.2.1.1.1.1.1.cmml">â€‹</mo><mrow id="S4.E4.m1.2.2.1.1.1.1.3.2" xref="S4.E4.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S4.E4.m1.2.2.1.1.1.1.3.2.1" xref="S4.E4.m1.2.2.1.1.1.1.cmml">(</mo><mi id="S4.E4.m1.1.1" xref="S4.E4.m1.1.1.cmml">e</mi><mo stretchy="false" id="S4.E4.m1.2.2.1.1.1.1.3.2.2" xref="S4.E4.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.E4.m1.2.2.1.1.1.3" xref="S4.E4.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.2b"><apply id="S4.E4.m1.2.2.cmml" xref="S4.E4.m1.2.2"><eq id="S4.E4.m1.2.2.2.cmml" xref="S4.E4.m1.2.2.2"></eq><apply id="S4.E4.m1.2.2.3.cmml" xref="S4.E4.m1.2.2.3"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.3.1.cmml" xref="S4.E4.m1.2.2.3">subscript</csymbol><ci id="S4.E4.m1.2.2.3.2.cmml" xref="S4.E4.m1.2.2.3.2">ğ‘“</ci><ci id="S4.E4.m1.2.2.3.3.cmml" xref="S4.E4.m1.2.2.3.3">ğ‘’</ci></apply><apply id="S4.E4.m1.2.2.1.cmml" xref="S4.E4.m1.2.2.1"><times id="S4.E4.m1.2.2.1.2.cmml" xref="S4.E4.m1.2.2.1.2"></times><ci id="S4.E4.m1.2.2.1.3a.cmml" xref="S4.E4.m1.2.2.1.3"><mtext class="ltx_mathvariant_monospace" id="S4.E4.m1.2.2.1.3.cmml" xref="S4.E4.m1.2.2.1.3">proj</mtext></ci><apply id="S4.E4.m1.2.2.1.1.1.1.cmml" xref="S4.E4.m1.2.2.1.1.1"><times id="S4.E4.m1.2.2.1.1.1.1.1.cmml" xref="S4.E4.m1.2.2.1.1.1.1.1"></times><ci id="S4.E4.m1.2.2.1.1.1.1.2a.cmml" xref="S4.E4.m1.2.2.1.1.1.1.2"><mtext class="ltx_mathvariant_monospace" id="S4.E4.m1.2.2.1.1.1.1.2.cmml" xref="S4.E4.m1.2.2.1.1.1.1.2">BERT</mtext></ci><ci id="S4.E4.m1.1.1.cmml" xref="S4.E4.m1.1.1">ğ‘’</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.2c">f_{e}=\texttt{proj}(\texttt{BERT}(e))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Retrieval Scores </h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">EnFoRe aims to retrieve question-relevant knowledge that focuses on critical entities. Therefore, the similarity metric consists of two parts: a question relevancy term and an entity focus term.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.2" class="ltx_p"><span id="S4.SS2.p2.2.1" class="ltx_text ltx_font_bold">Modeling question relevancy:</span> We model the question relevancy term <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="S_{qp}" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><msub id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml">S</mi><mrow id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3.cmml"><mi id="S4.SS2.p2.1.m1.1.1.3.2" xref="S4.SS2.p2.1.m1.1.1.3.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p2.1.m1.1.1.3.1" xref="S4.SS2.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.p2.1.m1.1.1.3.3" xref="S4.SS2.p2.1.m1.1.1.3.3.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2">ğ‘†</ci><apply id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3"><times id="S4.SS2.p2.1.m1.1.1.3.1.cmml" xref="S4.SS2.p2.1.m1.1.1.3.1"></times><ci id="S4.SS2.p2.1.m1.1.1.3.2.cmml" xref="S4.SS2.p2.1.m1.1.1.3.2">ğ‘</ci><ci id="S4.SS2.p2.1.m1.1.1.3.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">S_{qp}</annotation></semantics></math> as the inner-product of the query and passage features, i.e. <math id="S4.SS2.p2.2.m2.2" class="ltx_Math" alttext="S_{qp}(q,p)=f_{q}^{T}f_{p}" display="inline"><semantics id="S4.SS2.p2.2.m2.2a"><mrow id="S4.SS2.p2.2.m2.2.3" xref="S4.SS2.p2.2.m2.2.3.cmml"><mrow id="S4.SS2.p2.2.m2.2.3.2" xref="S4.SS2.p2.2.m2.2.3.2.cmml"><msub id="S4.SS2.p2.2.m2.2.3.2.2" xref="S4.SS2.p2.2.m2.2.3.2.2.cmml"><mi id="S4.SS2.p2.2.m2.2.3.2.2.2" xref="S4.SS2.p2.2.m2.2.3.2.2.2.cmml">S</mi><mrow id="S4.SS2.p2.2.m2.2.3.2.2.3" xref="S4.SS2.p2.2.m2.2.3.2.2.3.cmml"><mi id="S4.SS2.p2.2.m2.2.3.2.2.3.2" xref="S4.SS2.p2.2.m2.2.3.2.2.3.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p2.2.m2.2.3.2.2.3.1" xref="S4.SS2.p2.2.m2.2.3.2.2.3.1.cmml">â€‹</mo><mi id="S4.SS2.p2.2.m2.2.3.2.2.3.3" xref="S4.SS2.p2.2.m2.2.3.2.2.3.3.cmml">p</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.SS2.p2.2.m2.2.3.2.1" xref="S4.SS2.p2.2.m2.2.3.2.1.cmml">â€‹</mo><mrow id="S4.SS2.p2.2.m2.2.3.2.3.2" xref="S4.SS2.p2.2.m2.2.3.2.3.1.cmml"><mo stretchy="false" id="S4.SS2.p2.2.m2.2.3.2.3.2.1" xref="S4.SS2.p2.2.m2.2.3.2.3.1.cmml">(</mo><mi id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml">q</mi><mo id="S4.SS2.p2.2.m2.2.3.2.3.2.2" xref="S4.SS2.p2.2.m2.2.3.2.3.1.cmml">,</mo><mi id="S4.SS2.p2.2.m2.2.2" xref="S4.SS2.p2.2.m2.2.2.cmml">p</mi><mo stretchy="false" id="S4.SS2.p2.2.m2.2.3.2.3.2.3" xref="S4.SS2.p2.2.m2.2.3.2.3.1.cmml">)</mo></mrow></mrow><mo id="S4.SS2.p2.2.m2.2.3.1" xref="S4.SS2.p2.2.m2.2.3.1.cmml">=</mo><mrow id="S4.SS2.p2.2.m2.2.3.3" xref="S4.SS2.p2.2.m2.2.3.3.cmml"><msubsup id="S4.SS2.p2.2.m2.2.3.3.2" xref="S4.SS2.p2.2.m2.2.3.3.2.cmml"><mi id="S4.SS2.p2.2.m2.2.3.3.2.2.2" xref="S4.SS2.p2.2.m2.2.3.3.2.2.2.cmml">f</mi><mi id="S4.SS2.p2.2.m2.2.3.3.2.2.3" xref="S4.SS2.p2.2.m2.2.3.3.2.2.3.cmml">q</mi><mi id="S4.SS2.p2.2.m2.2.3.3.2.3" xref="S4.SS2.p2.2.m2.2.3.3.2.3.cmml">T</mi></msubsup><mo lspace="0em" rspace="0em" id="S4.SS2.p2.2.m2.2.3.3.1" xref="S4.SS2.p2.2.m2.2.3.3.1.cmml">â€‹</mo><msub id="S4.SS2.p2.2.m2.2.3.3.3" xref="S4.SS2.p2.2.m2.2.3.3.3.cmml"><mi id="S4.SS2.p2.2.m2.2.3.3.3.2" xref="S4.SS2.p2.2.m2.2.3.3.3.2.cmml">f</mi><mi id="S4.SS2.p2.2.m2.2.3.3.3.3" xref="S4.SS2.p2.2.m2.2.3.3.3.3.cmml">p</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.2b"><apply id="S4.SS2.p2.2.m2.2.3.cmml" xref="S4.SS2.p2.2.m2.2.3"><eq id="S4.SS2.p2.2.m2.2.3.1.cmml" xref="S4.SS2.p2.2.m2.2.3.1"></eq><apply id="S4.SS2.p2.2.m2.2.3.2.cmml" xref="S4.SS2.p2.2.m2.2.3.2"><times id="S4.SS2.p2.2.m2.2.3.2.1.cmml" xref="S4.SS2.p2.2.m2.2.3.2.1"></times><apply id="S4.SS2.p2.2.m2.2.3.2.2.cmml" xref="S4.SS2.p2.2.m2.2.3.2.2"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.2.3.2.2.1.cmml" xref="S4.SS2.p2.2.m2.2.3.2.2">subscript</csymbol><ci id="S4.SS2.p2.2.m2.2.3.2.2.2.cmml" xref="S4.SS2.p2.2.m2.2.3.2.2.2">ğ‘†</ci><apply id="S4.SS2.p2.2.m2.2.3.2.2.3.cmml" xref="S4.SS2.p2.2.m2.2.3.2.2.3"><times id="S4.SS2.p2.2.m2.2.3.2.2.3.1.cmml" xref="S4.SS2.p2.2.m2.2.3.2.2.3.1"></times><ci id="S4.SS2.p2.2.m2.2.3.2.2.3.2.cmml" xref="S4.SS2.p2.2.m2.2.3.2.2.3.2">ğ‘</ci><ci id="S4.SS2.p2.2.m2.2.3.2.2.3.3.cmml" xref="S4.SS2.p2.2.m2.2.3.2.2.3.3">ğ‘</ci></apply></apply><interval closure="open" id="S4.SS2.p2.2.m2.2.3.2.3.1.cmml" xref="S4.SS2.p2.2.m2.2.3.2.3.2"><ci id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">ğ‘</ci><ci id="S4.SS2.p2.2.m2.2.2.cmml" xref="S4.SS2.p2.2.m2.2.2">ğ‘</ci></interval></apply><apply id="S4.SS2.p2.2.m2.2.3.3.cmml" xref="S4.SS2.p2.2.m2.2.3.3"><times id="S4.SS2.p2.2.m2.2.3.3.1.cmml" xref="S4.SS2.p2.2.m2.2.3.3.1"></times><apply id="S4.SS2.p2.2.m2.2.3.3.2.cmml" xref="S4.SS2.p2.2.m2.2.3.3.2"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.2.3.3.2.1.cmml" xref="S4.SS2.p2.2.m2.2.3.3.2">superscript</csymbol><apply id="S4.SS2.p2.2.m2.2.3.3.2.2.cmml" xref="S4.SS2.p2.2.m2.2.3.3.2"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.2.3.3.2.2.1.cmml" xref="S4.SS2.p2.2.m2.2.3.3.2">subscript</csymbol><ci id="S4.SS2.p2.2.m2.2.3.3.2.2.2.cmml" xref="S4.SS2.p2.2.m2.2.3.3.2.2.2">ğ‘“</ci><ci id="S4.SS2.p2.2.m2.2.3.3.2.2.3.cmml" xref="S4.SS2.p2.2.m2.2.3.3.2.2.3">ğ‘</ci></apply><ci id="S4.SS2.p2.2.m2.2.3.3.2.3.cmml" xref="S4.SS2.p2.2.m2.2.3.3.2.3">ğ‘‡</ci></apply><apply id="S4.SS2.p2.2.m2.2.3.3.3.cmml" xref="S4.SS2.p2.2.m2.2.3.3.3"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.2.3.3.3.1.cmml" xref="S4.SS2.p2.2.m2.2.3.3.3">subscript</csymbol><ci id="S4.SS2.p2.2.m2.2.3.3.3.2.cmml" xref="S4.SS2.p2.2.m2.2.3.3.3.2">ğ‘“</ci><ci id="S4.SS2.p2.2.m2.2.3.3.3.3.cmml" xref="S4.SS2.p2.2.m2.2.3.3.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.2c">S_{qp}(q,p)=f_{q}^{T}f_{p}</annotation></semantics></math>. During inference, as the query and passage features are decomposable, maximum inner product search (MIPS) can be applied to efficiently retrieve top passages for the query.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.4" class="ltx_p"><span id="S4.SS2.p3.4.1" class="ltx_text ltx_font_bold">Modeling entity focus:</span> The entity focus term consists of two parts, where query features are used to identify critical entities from the set of entities in Sec. 3, and passage features are used to determine whether it contains these key entities. For each entity, we compute the query-entity score <math id="S4.SS2.p3.1.m1.2" class="ltx_Math" alttext="S_{qe}(q,e)" display="inline"><semantics id="S4.SS2.p3.1.m1.2a"><mrow id="S4.SS2.p3.1.m1.2.3" xref="S4.SS2.p3.1.m1.2.3.cmml"><msub id="S4.SS2.p3.1.m1.2.3.2" xref="S4.SS2.p3.1.m1.2.3.2.cmml"><mi id="S4.SS2.p3.1.m1.2.3.2.2" xref="S4.SS2.p3.1.m1.2.3.2.2.cmml">S</mi><mrow id="S4.SS2.p3.1.m1.2.3.2.3" xref="S4.SS2.p3.1.m1.2.3.2.3.cmml"><mi id="S4.SS2.p3.1.m1.2.3.2.3.2" xref="S4.SS2.p3.1.m1.2.3.2.3.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.1.m1.2.3.2.3.1" xref="S4.SS2.p3.1.m1.2.3.2.3.1.cmml">â€‹</mo><mi id="S4.SS2.p3.1.m1.2.3.2.3.3" xref="S4.SS2.p3.1.m1.2.3.2.3.3.cmml">e</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.SS2.p3.1.m1.2.3.1" xref="S4.SS2.p3.1.m1.2.3.1.cmml">â€‹</mo><mrow id="S4.SS2.p3.1.m1.2.3.3.2" xref="S4.SS2.p3.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S4.SS2.p3.1.m1.2.3.3.2.1" xref="S4.SS2.p3.1.m1.2.3.3.1.cmml">(</mo><mi id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">q</mi><mo id="S4.SS2.p3.1.m1.2.3.3.2.2" xref="S4.SS2.p3.1.m1.2.3.3.1.cmml">,</mo><mi id="S4.SS2.p3.1.m1.2.2" xref="S4.SS2.p3.1.m1.2.2.cmml">e</mi><mo stretchy="false" id="S4.SS2.p3.1.m1.2.3.3.2.3" xref="S4.SS2.p3.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.2b"><apply id="S4.SS2.p3.1.m1.2.3.cmml" xref="S4.SS2.p3.1.m1.2.3"><times id="S4.SS2.p3.1.m1.2.3.1.cmml" xref="S4.SS2.p3.1.m1.2.3.1"></times><apply id="S4.SS2.p3.1.m1.2.3.2.cmml" xref="S4.SS2.p3.1.m1.2.3.2"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.2.3.2.1.cmml" xref="S4.SS2.p3.1.m1.2.3.2">subscript</csymbol><ci id="S4.SS2.p3.1.m1.2.3.2.2.cmml" xref="S4.SS2.p3.1.m1.2.3.2.2">ğ‘†</ci><apply id="S4.SS2.p3.1.m1.2.3.2.3.cmml" xref="S4.SS2.p3.1.m1.2.3.2.3"><times id="S4.SS2.p3.1.m1.2.3.2.3.1.cmml" xref="S4.SS2.p3.1.m1.2.3.2.3.1"></times><ci id="S4.SS2.p3.1.m1.2.3.2.3.2.cmml" xref="S4.SS2.p3.1.m1.2.3.2.3.2">ğ‘</ci><ci id="S4.SS2.p3.1.m1.2.3.2.3.3.cmml" xref="S4.SS2.p3.1.m1.2.3.2.3.3">ğ‘’</ci></apply></apply><interval closure="open" id="S4.SS2.p3.1.m1.2.3.3.1.cmml" xref="S4.SS2.p3.1.m1.2.3.3.2"><ci id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">ğ‘</ci><ci id="S4.SS2.p3.1.m1.2.2.cmml" xref="S4.SS2.p3.1.m1.2.2">ğ‘’</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.2c">S_{qe}(q,e)</annotation></semantics></math> as the inner-product of the projected query and entity feature, i.e. <math id="S4.SS2.p3.2.m2.4" class="ltx_Math" alttext="S_{qe}(q,e)=\texttt{proj}(f_{q})^{T}\texttt{proj}(f_{e})" display="inline"><semantics id="S4.SS2.p3.2.m2.4a"><mrow id="S4.SS2.p3.2.m2.4.4" xref="S4.SS2.p3.2.m2.4.4.cmml"><mrow id="S4.SS2.p3.2.m2.4.4.4" xref="S4.SS2.p3.2.m2.4.4.4.cmml"><msub id="S4.SS2.p3.2.m2.4.4.4.2" xref="S4.SS2.p3.2.m2.4.4.4.2.cmml"><mi id="S4.SS2.p3.2.m2.4.4.4.2.2" xref="S4.SS2.p3.2.m2.4.4.4.2.2.cmml">S</mi><mrow id="S4.SS2.p3.2.m2.4.4.4.2.3" xref="S4.SS2.p3.2.m2.4.4.4.2.3.cmml"><mi id="S4.SS2.p3.2.m2.4.4.4.2.3.2" xref="S4.SS2.p3.2.m2.4.4.4.2.3.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.2.m2.4.4.4.2.3.1" xref="S4.SS2.p3.2.m2.4.4.4.2.3.1.cmml">â€‹</mo><mi id="S4.SS2.p3.2.m2.4.4.4.2.3.3" xref="S4.SS2.p3.2.m2.4.4.4.2.3.3.cmml">e</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.SS2.p3.2.m2.4.4.4.1" xref="S4.SS2.p3.2.m2.4.4.4.1.cmml">â€‹</mo><mrow id="S4.SS2.p3.2.m2.4.4.4.3.2" xref="S4.SS2.p3.2.m2.4.4.4.3.1.cmml"><mo stretchy="false" id="S4.SS2.p3.2.m2.4.4.4.3.2.1" xref="S4.SS2.p3.2.m2.4.4.4.3.1.cmml">(</mo><mi id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml">q</mi><mo id="S4.SS2.p3.2.m2.4.4.4.3.2.2" xref="S4.SS2.p3.2.m2.4.4.4.3.1.cmml">,</mo><mi id="S4.SS2.p3.2.m2.2.2" xref="S4.SS2.p3.2.m2.2.2.cmml">e</mi><mo stretchy="false" id="S4.SS2.p3.2.m2.4.4.4.3.2.3" xref="S4.SS2.p3.2.m2.4.4.4.3.1.cmml">)</mo></mrow></mrow><mo id="S4.SS2.p3.2.m2.4.4.3" xref="S4.SS2.p3.2.m2.4.4.3.cmml">=</mo><mrow id="S4.SS2.p3.2.m2.4.4.2" xref="S4.SS2.p3.2.m2.4.4.2.cmml"><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p3.2.m2.4.4.2.4" xref="S4.SS2.p3.2.m2.4.4.2.4a.cmml">proj</mtext><mo lspace="0em" rspace="0em" id="S4.SS2.p3.2.m2.4.4.2.3" xref="S4.SS2.p3.2.m2.4.4.2.3.cmml">â€‹</mo><msup id="S4.SS2.p3.2.m2.3.3.1.1" xref="S4.SS2.p3.2.m2.3.3.1.1.cmml"><mrow id="S4.SS2.p3.2.m2.3.3.1.1.1.1" xref="S4.SS2.p3.2.m2.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.p3.2.m2.3.3.1.1.1.1.2" xref="S4.SS2.p3.2.m2.3.3.1.1.1.1.1.cmml">(</mo><msub id="S4.SS2.p3.2.m2.3.3.1.1.1.1.1" xref="S4.SS2.p3.2.m2.3.3.1.1.1.1.1.cmml"><mi id="S4.SS2.p3.2.m2.3.3.1.1.1.1.1.2" xref="S4.SS2.p3.2.m2.3.3.1.1.1.1.1.2.cmml">f</mi><mi id="S4.SS2.p3.2.m2.3.3.1.1.1.1.1.3" xref="S4.SS2.p3.2.m2.3.3.1.1.1.1.1.3.cmml">q</mi></msub><mo stretchy="false" id="S4.SS2.p3.2.m2.3.3.1.1.1.1.3" xref="S4.SS2.p3.2.m2.3.3.1.1.1.1.1.cmml">)</mo></mrow><mi id="S4.SS2.p3.2.m2.3.3.1.1.3" xref="S4.SS2.p3.2.m2.3.3.1.1.3.cmml">T</mi></msup><mo lspace="0em" rspace="0em" id="S4.SS2.p3.2.m2.4.4.2.3a" xref="S4.SS2.p3.2.m2.4.4.2.3.cmml">â€‹</mo><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p3.2.m2.4.4.2.5" xref="S4.SS2.p3.2.m2.4.4.2.5a.cmml">proj</mtext><mo lspace="0em" rspace="0em" id="S4.SS2.p3.2.m2.4.4.2.3b" xref="S4.SS2.p3.2.m2.4.4.2.3.cmml">â€‹</mo><mrow id="S4.SS2.p3.2.m2.4.4.2.2.1" xref="S4.SS2.p3.2.m2.4.4.2.2.1.1.cmml"><mo stretchy="false" id="S4.SS2.p3.2.m2.4.4.2.2.1.2" xref="S4.SS2.p3.2.m2.4.4.2.2.1.1.cmml">(</mo><msub id="S4.SS2.p3.2.m2.4.4.2.2.1.1" xref="S4.SS2.p3.2.m2.4.4.2.2.1.1.cmml"><mi id="S4.SS2.p3.2.m2.4.4.2.2.1.1.2" xref="S4.SS2.p3.2.m2.4.4.2.2.1.1.2.cmml">f</mi><mi id="S4.SS2.p3.2.m2.4.4.2.2.1.1.3" xref="S4.SS2.p3.2.m2.4.4.2.2.1.1.3.cmml">e</mi></msub><mo stretchy="false" id="S4.SS2.p3.2.m2.4.4.2.2.1.3" xref="S4.SS2.p3.2.m2.4.4.2.2.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.4b"><apply id="S4.SS2.p3.2.m2.4.4.cmml" xref="S4.SS2.p3.2.m2.4.4"><eq id="S4.SS2.p3.2.m2.4.4.3.cmml" xref="S4.SS2.p3.2.m2.4.4.3"></eq><apply id="S4.SS2.p3.2.m2.4.4.4.cmml" xref="S4.SS2.p3.2.m2.4.4.4"><times id="S4.SS2.p3.2.m2.4.4.4.1.cmml" xref="S4.SS2.p3.2.m2.4.4.4.1"></times><apply id="S4.SS2.p3.2.m2.4.4.4.2.cmml" xref="S4.SS2.p3.2.m2.4.4.4.2"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.4.4.4.2.1.cmml" xref="S4.SS2.p3.2.m2.4.4.4.2">subscript</csymbol><ci id="S4.SS2.p3.2.m2.4.4.4.2.2.cmml" xref="S4.SS2.p3.2.m2.4.4.4.2.2">ğ‘†</ci><apply id="S4.SS2.p3.2.m2.4.4.4.2.3.cmml" xref="S4.SS2.p3.2.m2.4.4.4.2.3"><times id="S4.SS2.p3.2.m2.4.4.4.2.3.1.cmml" xref="S4.SS2.p3.2.m2.4.4.4.2.3.1"></times><ci id="S4.SS2.p3.2.m2.4.4.4.2.3.2.cmml" xref="S4.SS2.p3.2.m2.4.4.4.2.3.2">ğ‘</ci><ci id="S4.SS2.p3.2.m2.4.4.4.2.3.3.cmml" xref="S4.SS2.p3.2.m2.4.4.4.2.3.3">ğ‘’</ci></apply></apply><interval closure="open" id="S4.SS2.p3.2.m2.4.4.4.3.1.cmml" xref="S4.SS2.p3.2.m2.4.4.4.3.2"><ci id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1">ğ‘</ci><ci id="S4.SS2.p3.2.m2.2.2.cmml" xref="S4.SS2.p3.2.m2.2.2">ğ‘’</ci></interval></apply><apply id="S4.SS2.p3.2.m2.4.4.2.cmml" xref="S4.SS2.p3.2.m2.4.4.2"><times id="S4.SS2.p3.2.m2.4.4.2.3.cmml" xref="S4.SS2.p3.2.m2.4.4.2.3"></times><ci id="S4.SS2.p3.2.m2.4.4.2.4a.cmml" xref="S4.SS2.p3.2.m2.4.4.2.4"><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p3.2.m2.4.4.2.4.cmml" xref="S4.SS2.p3.2.m2.4.4.2.4">proj</mtext></ci><apply id="S4.SS2.p3.2.m2.3.3.1.1.cmml" xref="S4.SS2.p3.2.m2.3.3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.3.3.1.1.2.cmml" xref="S4.SS2.p3.2.m2.3.3.1.1">superscript</csymbol><apply id="S4.SS2.p3.2.m2.3.3.1.1.1.1.1.cmml" xref="S4.SS2.p3.2.m2.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.3.3.1.1.1.1.1.1.cmml" xref="S4.SS2.p3.2.m2.3.3.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p3.2.m2.3.3.1.1.1.1.1.2.cmml" xref="S4.SS2.p3.2.m2.3.3.1.1.1.1.1.2">ğ‘“</ci><ci id="S4.SS2.p3.2.m2.3.3.1.1.1.1.1.3.cmml" xref="S4.SS2.p3.2.m2.3.3.1.1.1.1.1.3">ğ‘</ci></apply><ci id="S4.SS2.p3.2.m2.3.3.1.1.3.cmml" xref="S4.SS2.p3.2.m2.3.3.1.1.3">ğ‘‡</ci></apply><ci id="S4.SS2.p3.2.m2.4.4.2.5a.cmml" xref="S4.SS2.p3.2.m2.4.4.2.5"><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p3.2.m2.4.4.2.5.cmml" xref="S4.SS2.p3.2.m2.4.4.2.5">proj</mtext></ci><apply id="S4.SS2.p3.2.m2.4.4.2.2.1.1.cmml" xref="S4.SS2.p3.2.m2.4.4.2.2.1"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.4.4.2.2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.4.4.2.2.1">subscript</csymbol><ci id="S4.SS2.p3.2.m2.4.4.2.2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.4.4.2.2.1.1.2">ğ‘“</ci><ci id="S4.SS2.p3.2.m2.4.4.2.2.1.1.3.cmml" xref="S4.SS2.p3.2.m2.4.4.2.2.1.1.3">ğ‘’</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.4c">S_{qe}(q,e)=\texttt{proj}(f_{q})^{T}\texttt{proj}(f_{e})</annotation></semantics></math>, and we compute the passage-entity score as <math id="S4.SS2.p3.3.m3.4" class="ltx_Math" alttext="S_{pe}(p,e)=\texttt{proj}(f_{p})^{T}\texttt{proj}(f_{e})" display="inline"><semantics id="S4.SS2.p3.3.m3.4a"><mrow id="S4.SS2.p3.3.m3.4.4" xref="S4.SS2.p3.3.m3.4.4.cmml"><mrow id="S4.SS2.p3.3.m3.4.4.4" xref="S4.SS2.p3.3.m3.4.4.4.cmml"><msub id="S4.SS2.p3.3.m3.4.4.4.2" xref="S4.SS2.p3.3.m3.4.4.4.2.cmml"><mi id="S4.SS2.p3.3.m3.4.4.4.2.2" xref="S4.SS2.p3.3.m3.4.4.4.2.2.cmml">S</mi><mrow id="S4.SS2.p3.3.m3.4.4.4.2.3" xref="S4.SS2.p3.3.m3.4.4.4.2.3.cmml"><mi id="S4.SS2.p3.3.m3.4.4.4.2.3.2" xref="S4.SS2.p3.3.m3.4.4.4.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.3.m3.4.4.4.2.3.1" xref="S4.SS2.p3.3.m3.4.4.4.2.3.1.cmml">â€‹</mo><mi id="S4.SS2.p3.3.m3.4.4.4.2.3.3" xref="S4.SS2.p3.3.m3.4.4.4.2.3.3.cmml">e</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.SS2.p3.3.m3.4.4.4.1" xref="S4.SS2.p3.3.m3.4.4.4.1.cmml">â€‹</mo><mrow id="S4.SS2.p3.3.m3.4.4.4.3.2" xref="S4.SS2.p3.3.m3.4.4.4.3.1.cmml"><mo stretchy="false" id="S4.SS2.p3.3.m3.4.4.4.3.2.1" xref="S4.SS2.p3.3.m3.4.4.4.3.1.cmml">(</mo><mi id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml">p</mi><mo id="S4.SS2.p3.3.m3.4.4.4.3.2.2" xref="S4.SS2.p3.3.m3.4.4.4.3.1.cmml">,</mo><mi id="S4.SS2.p3.3.m3.2.2" xref="S4.SS2.p3.3.m3.2.2.cmml">e</mi><mo stretchy="false" id="S4.SS2.p3.3.m3.4.4.4.3.2.3" xref="S4.SS2.p3.3.m3.4.4.4.3.1.cmml">)</mo></mrow></mrow><mo id="S4.SS2.p3.3.m3.4.4.3" xref="S4.SS2.p3.3.m3.4.4.3.cmml">=</mo><mrow id="S4.SS2.p3.3.m3.4.4.2" xref="S4.SS2.p3.3.m3.4.4.2.cmml"><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p3.3.m3.4.4.2.4" xref="S4.SS2.p3.3.m3.4.4.2.4a.cmml">proj</mtext><mo lspace="0em" rspace="0em" id="S4.SS2.p3.3.m3.4.4.2.3" xref="S4.SS2.p3.3.m3.4.4.2.3.cmml">â€‹</mo><msup id="S4.SS2.p3.3.m3.3.3.1.1" xref="S4.SS2.p3.3.m3.3.3.1.1.cmml"><mrow id="S4.SS2.p3.3.m3.3.3.1.1.1.1" xref="S4.SS2.p3.3.m3.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.p3.3.m3.3.3.1.1.1.1.2" xref="S4.SS2.p3.3.m3.3.3.1.1.1.1.1.cmml">(</mo><msub id="S4.SS2.p3.3.m3.3.3.1.1.1.1.1" xref="S4.SS2.p3.3.m3.3.3.1.1.1.1.1.cmml"><mi id="S4.SS2.p3.3.m3.3.3.1.1.1.1.1.2" xref="S4.SS2.p3.3.m3.3.3.1.1.1.1.1.2.cmml">f</mi><mi id="S4.SS2.p3.3.m3.3.3.1.1.1.1.1.3" xref="S4.SS2.p3.3.m3.3.3.1.1.1.1.1.3.cmml">p</mi></msub><mo stretchy="false" id="S4.SS2.p3.3.m3.3.3.1.1.1.1.3" xref="S4.SS2.p3.3.m3.3.3.1.1.1.1.1.cmml">)</mo></mrow><mi id="S4.SS2.p3.3.m3.3.3.1.1.3" xref="S4.SS2.p3.3.m3.3.3.1.1.3.cmml">T</mi></msup><mo lspace="0em" rspace="0em" id="S4.SS2.p3.3.m3.4.4.2.3a" xref="S4.SS2.p3.3.m3.4.4.2.3.cmml">â€‹</mo><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p3.3.m3.4.4.2.5" xref="S4.SS2.p3.3.m3.4.4.2.5a.cmml">proj</mtext><mo lspace="0em" rspace="0em" id="S4.SS2.p3.3.m3.4.4.2.3b" xref="S4.SS2.p3.3.m3.4.4.2.3.cmml">â€‹</mo><mrow id="S4.SS2.p3.3.m3.4.4.2.2.1" xref="S4.SS2.p3.3.m3.4.4.2.2.1.1.cmml"><mo stretchy="false" id="S4.SS2.p3.3.m3.4.4.2.2.1.2" xref="S4.SS2.p3.3.m3.4.4.2.2.1.1.cmml">(</mo><msub id="S4.SS2.p3.3.m3.4.4.2.2.1.1" xref="S4.SS2.p3.3.m3.4.4.2.2.1.1.cmml"><mi id="S4.SS2.p3.3.m3.4.4.2.2.1.1.2" xref="S4.SS2.p3.3.m3.4.4.2.2.1.1.2.cmml">f</mi><mi id="S4.SS2.p3.3.m3.4.4.2.2.1.1.3" xref="S4.SS2.p3.3.m3.4.4.2.2.1.1.3.cmml">e</mi></msub><mo stretchy="false" id="S4.SS2.p3.3.m3.4.4.2.2.1.3" xref="S4.SS2.p3.3.m3.4.4.2.2.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.4b"><apply id="S4.SS2.p3.3.m3.4.4.cmml" xref="S4.SS2.p3.3.m3.4.4"><eq id="S4.SS2.p3.3.m3.4.4.3.cmml" xref="S4.SS2.p3.3.m3.4.4.3"></eq><apply id="S4.SS2.p3.3.m3.4.4.4.cmml" xref="S4.SS2.p3.3.m3.4.4.4"><times id="S4.SS2.p3.3.m3.4.4.4.1.cmml" xref="S4.SS2.p3.3.m3.4.4.4.1"></times><apply id="S4.SS2.p3.3.m3.4.4.4.2.cmml" xref="S4.SS2.p3.3.m3.4.4.4.2"><csymbol cd="ambiguous" id="S4.SS2.p3.3.m3.4.4.4.2.1.cmml" xref="S4.SS2.p3.3.m3.4.4.4.2">subscript</csymbol><ci id="S4.SS2.p3.3.m3.4.4.4.2.2.cmml" xref="S4.SS2.p3.3.m3.4.4.4.2.2">ğ‘†</ci><apply id="S4.SS2.p3.3.m3.4.4.4.2.3.cmml" xref="S4.SS2.p3.3.m3.4.4.4.2.3"><times id="S4.SS2.p3.3.m3.4.4.4.2.3.1.cmml" xref="S4.SS2.p3.3.m3.4.4.4.2.3.1"></times><ci id="S4.SS2.p3.3.m3.4.4.4.2.3.2.cmml" xref="S4.SS2.p3.3.m3.4.4.4.2.3.2">ğ‘</ci><ci id="S4.SS2.p3.3.m3.4.4.4.2.3.3.cmml" xref="S4.SS2.p3.3.m3.4.4.4.2.3.3">ğ‘’</ci></apply></apply><interval closure="open" id="S4.SS2.p3.3.m3.4.4.4.3.1.cmml" xref="S4.SS2.p3.3.m3.4.4.4.3.2"><ci id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">ğ‘</ci><ci id="S4.SS2.p3.3.m3.2.2.cmml" xref="S4.SS2.p3.3.m3.2.2">ğ‘’</ci></interval></apply><apply id="S4.SS2.p3.3.m3.4.4.2.cmml" xref="S4.SS2.p3.3.m3.4.4.2"><times id="S4.SS2.p3.3.m3.4.4.2.3.cmml" xref="S4.SS2.p3.3.m3.4.4.2.3"></times><ci id="S4.SS2.p3.3.m3.4.4.2.4a.cmml" xref="S4.SS2.p3.3.m3.4.4.2.4"><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p3.3.m3.4.4.2.4.cmml" xref="S4.SS2.p3.3.m3.4.4.2.4">proj</mtext></ci><apply id="S4.SS2.p3.3.m3.3.3.1.1.cmml" xref="S4.SS2.p3.3.m3.3.3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.3.m3.3.3.1.1.2.cmml" xref="S4.SS2.p3.3.m3.3.3.1.1">superscript</csymbol><apply id="S4.SS2.p3.3.m3.3.3.1.1.1.1.1.cmml" xref="S4.SS2.p3.3.m3.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.3.m3.3.3.1.1.1.1.1.1.cmml" xref="S4.SS2.p3.3.m3.3.3.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p3.3.m3.3.3.1.1.1.1.1.2.cmml" xref="S4.SS2.p3.3.m3.3.3.1.1.1.1.1.2">ğ‘“</ci><ci id="S4.SS2.p3.3.m3.3.3.1.1.1.1.1.3.cmml" xref="S4.SS2.p3.3.m3.3.3.1.1.1.1.1.3">ğ‘</ci></apply><ci id="S4.SS2.p3.3.m3.3.3.1.1.3.cmml" xref="S4.SS2.p3.3.m3.3.3.1.1.3">ğ‘‡</ci></apply><ci id="S4.SS2.p3.3.m3.4.4.2.5a.cmml" xref="S4.SS2.p3.3.m3.4.4.2.5"><mtext class="ltx_mathvariant_monospace" id="S4.SS2.p3.3.m3.4.4.2.5.cmml" xref="S4.SS2.p3.3.m3.4.4.2.5">proj</mtext></ci><apply id="S4.SS2.p3.3.m3.4.4.2.2.1.1.cmml" xref="S4.SS2.p3.3.m3.4.4.2.2.1"><csymbol cd="ambiguous" id="S4.SS2.p3.3.m3.4.4.2.2.1.1.1.cmml" xref="S4.SS2.p3.3.m3.4.4.2.2.1">subscript</csymbol><ci id="S4.SS2.p3.3.m3.4.4.2.2.1.1.2.cmml" xref="S4.SS2.p3.3.m3.4.4.2.2.1.1.2">ğ‘“</ci><ci id="S4.SS2.p3.3.m3.4.4.2.2.1.1.3.cmml" xref="S4.SS2.p3.3.m3.4.4.2.2.1.1.3">ğ‘’</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.4c">S_{pe}(p,e)=\texttt{proj}(f_{p})^{T}\texttt{proj}(f_{e})</annotation></semantics></math>. Then, we combine all of the entities and compute the entity-focused score <math id="S4.SS2.p3.4.m4.1" class="ltx_Math" alttext="S_{qpe}" display="inline"><semantics id="S4.SS2.p3.4.m4.1a"><msub id="S4.SS2.p3.4.m4.1.1" xref="S4.SS2.p3.4.m4.1.1.cmml"><mi id="S4.SS2.p3.4.m4.1.1.2" xref="S4.SS2.p3.4.m4.1.1.2.cmml">S</mi><mrow id="S4.SS2.p3.4.m4.1.1.3" xref="S4.SS2.p3.4.m4.1.1.3.cmml"><mi id="S4.SS2.p3.4.m4.1.1.3.2" xref="S4.SS2.p3.4.m4.1.1.3.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.4.m4.1.1.3.1" xref="S4.SS2.p3.4.m4.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.p3.4.m4.1.1.3.3" xref="S4.SS2.p3.4.m4.1.1.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.4.m4.1.1.3.1a" xref="S4.SS2.p3.4.m4.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.p3.4.m4.1.1.3.4" xref="S4.SS2.p3.4.m4.1.1.3.4.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.4.m4.1b"><apply id="S4.SS2.p3.4.m4.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.4.m4.1.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1">subscript</csymbol><ci id="S4.SS2.p3.4.m4.1.1.2.cmml" xref="S4.SS2.p3.4.m4.1.1.2">ğ‘†</ci><apply id="S4.SS2.p3.4.m4.1.1.3.cmml" xref="S4.SS2.p3.4.m4.1.1.3"><times id="S4.SS2.p3.4.m4.1.1.3.1.cmml" xref="S4.SS2.p3.4.m4.1.1.3.1"></times><ci id="S4.SS2.p3.4.m4.1.1.3.2.cmml" xref="S4.SS2.p3.4.m4.1.1.3.2">ğ‘</ci><ci id="S4.SS2.p3.4.m4.1.1.3.3.cmml" xref="S4.SS2.p3.4.m4.1.1.3.3">ğ‘</ci><ci id="S4.SS2.p3.4.m4.1.1.3.4.cmml" xref="S4.SS2.p3.4.m4.1.1.3.4">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.4.m4.1c">S_{qpe}</annotation></semantics></math> per Eq. <a href="#S4.E5" title="In 4.2 Retrieval Scores â€£ 4 Entity-Focused Retrieval â€£ Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>:</p>
<table id="S4.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E5.m1.11" class="ltx_Math" alttext="S_{qpe}(q,p,\mathcal{E})=\frac{\sum_{e\in\mathcal{E}}\sigma(S_{qe}(q,e))\times S_{pe}(p,e)}{\sum_{e\in\mathcal{E}}\sigma(S_{qe}(q,e))}" display="block"><semantics id="S4.E5.m1.11a"><mrow id="S4.E5.m1.11.12" xref="S4.E5.m1.11.12.cmml"><mrow id="S4.E5.m1.11.12.2" xref="S4.E5.m1.11.12.2.cmml"><msub id="S4.E5.m1.11.12.2.2" xref="S4.E5.m1.11.12.2.2.cmml"><mi id="S4.E5.m1.11.12.2.2.2" xref="S4.E5.m1.11.12.2.2.2.cmml">S</mi><mrow id="S4.E5.m1.11.12.2.2.3" xref="S4.E5.m1.11.12.2.2.3.cmml"><mi id="S4.E5.m1.11.12.2.2.3.2" xref="S4.E5.m1.11.12.2.2.3.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.11.12.2.2.3.1" xref="S4.E5.m1.11.12.2.2.3.1.cmml">â€‹</mo><mi id="S4.E5.m1.11.12.2.2.3.3" xref="S4.E5.m1.11.12.2.2.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.11.12.2.2.3.1a" xref="S4.E5.m1.11.12.2.2.3.1.cmml">â€‹</mo><mi id="S4.E5.m1.11.12.2.2.3.4" xref="S4.E5.m1.11.12.2.2.3.4.cmml">e</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.E5.m1.11.12.2.1" xref="S4.E5.m1.11.12.2.1.cmml">â€‹</mo><mrow id="S4.E5.m1.11.12.2.3.2" xref="S4.E5.m1.11.12.2.3.1.cmml"><mo stretchy="false" id="S4.E5.m1.11.12.2.3.2.1" xref="S4.E5.m1.11.12.2.3.1.cmml">(</mo><mi id="S4.E5.m1.9.9" xref="S4.E5.m1.9.9.cmml">q</mi><mo id="S4.E5.m1.11.12.2.3.2.2" xref="S4.E5.m1.11.12.2.3.1.cmml">,</mo><mi id="S4.E5.m1.10.10" xref="S4.E5.m1.10.10.cmml">p</mi><mo id="S4.E5.m1.11.12.2.3.2.3" xref="S4.E5.m1.11.12.2.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.E5.m1.11.11" xref="S4.E5.m1.11.11.cmml">â„°</mi><mo stretchy="false" id="S4.E5.m1.11.12.2.3.2.4" xref="S4.E5.m1.11.12.2.3.1.cmml">)</mo></mrow></mrow><mo id="S4.E5.m1.11.12.1" xref="S4.E5.m1.11.12.1.cmml">=</mo><mfrac id="S4.E5.m1.8.8" xref="S4.E5.m1.8.8.cmml"><mrow id="S4.E5.m1.5.5.5" xref="S4.E5.m1.5.5.5.cmml"><msub id="S4.E5.m1.5.5.5.6" xref="S4.E5.m1.5.5.5.6.cmml"><mo id="S4.E5.m1.5.5.5.6.2" xref="S4.E5.m1.5.5.5.6.2.cmml">âˆ‘</mo><mrow id="S4.E5.m1.5.5.5.6.3" xref="S4.E5.m1.5.5.5.6.3.cmml"><mi id="S4.E5.m1.5.5.5.6.3.2" xref="S4.E5.m1.5.5.5.6.3.2.cmml">e</mi><mo id="S4.E5.m1.5.5.5.6.3.1" xref="S4.E5.m1.5.5.5.6.3.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S4.E5.m1.5.5.5.6.3.3" xref="S4.E5.m1.5.5.5.6.3.3.cmml">â„°</mi></mrow></msub><mrow id="S4.E5.m1.5.5.5.5" xref="S4.E5.m1.5.5.5.5.cmml"><mrow id="S4.E5.m1.5.5.5.5.1" xref="S4.E5.m1.5.5.5.5.1.cmml"><mrow id="S4.E5.m1.5.5.5.5.1.1" xref="S4.E5.m1.5.5.5.5.1.1.cmml"><mi id="S4.E5.m1.5.5.5.5.1.1.3" xref="S4.E5.m1.5.5.5.5.1.1.3.cmml">Ïƒ</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.5.5.5.5.1.1.2" xref="S4.E5.m1.5.5.5.5.1.1.2.cmml">â€‹</mo><mrow id="S4.E5.m1.5.5.5.5.1.1.1.1" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E5.m1.5.5.5.5.1.1.1.1.2" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.cmml">(</mo><mrow id="S4.E5.m1.5.5.5.5.1.1.1.1.1" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.cmml"><msub id="S4.E5.m1.5.5.5.5.1.1.1.1.1.2" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.cmml"><mi id="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.2" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.2.cmml">S</mi><mrow id="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.3" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.3.cmml"><mi id="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.3.2" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.3.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.3.1" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.3.3" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.3.3.cmml">e</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.E5.m1.5.5.5.5.1.1.1.1.1.1" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.1.cmml">â€‹</mo><mrow id="S4.E5.m1.5.5.5.5.1.1.1.1.1.3.2" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.3.1.cmml"><mo stretchy="false" id="S4.E5.m1.5.5.5.5.1.1.1.1.1.3.2.1" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.3.1.cmml">(</mo><mi id="S4.E5.m1.1.1.1.1" xref="S4.E5.m1.1.1.1.1.cmml">q</mi><mo id="S4.E5.m1.5.5.5.5.1.1.1.1.1.3.2.2" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.3.1.cmml">,</mo><mi id="S4.E5.m1.2.2.2.2" xref="S4.E5.m1.2.2.2.2.cmml">e</mi><mo stretchy="false" id="S4.E5.m1.5.5.5.5.1.1.1.1.1.3.2.3" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.3.1.cmml">)</mo></mrow></mrow><mo rspace="0.055em" stretchy="false" id="S4.E5.m1.5.5.5.5.1.1.1.1.3" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S4.E5.m1.5.5.5.5.1.2" xref="S4.E5.m1.5.5.5.5.1.2.cmml">Ã—</mo><msub id="S4.E5.m1.5.5.5.5.1.3" xref="S4.E5.m1.5.5.5.5.1.3.cmml"><mi id="S4.E5.m1.5.5.5.5.1.3.2" xref="S4.E5.m1.5.5.5.5.1.3.2.cmml">S</mi><mrow id="S4.E5.m1.5.5.5.5.1.3.3" xref="S4.E5.m1.5.5.5.5.1.3.3.cmml"><mi id="S4.E5.m1.5.5.5.5.1.3.3.2" xref="S4.E5.m1.5.5.5.5.1.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.5.5.5.5.1.3.3.1" xref="S4.E5.m1.5.5.5.5.1.3.3.1.cmml">â€‹</mo><mi id="S4.E5.m1.5.5.5.5.1.3.3.3" xref="S4.E5.m1.5.5.5.5.1.3.3.3.cmml">e</mi></mrow></msub></mrow><mo lspace="0em" rspace="0em" id="S4.E5.m1.5.5.5.5.2" xref="S4.E5.m1.5.5.5.5.2.cmml">â€‹</mo><mrow id="S4.E5.m1.5.5.5.5.3.2" xref="S4.E5.m1.5.5.5.5.3.1.cmml"><mo stretchy="false" id="S4.E5.m1.5.5.5.5.3.2.1" xref="S4.E5.m1.5.5.5.5.3.1.cmml">(</mo><mi id="S4.E5.m1.3.3.3.3" xref="S4.E5.m1.3.3.3.3.cmml">p</mi><mo id="S4.E5.m1.5.5.5.5.3.2.2" xref="S4.E5.m1.5.5.5.5.3.1.cmml">,</mo><mi id="S4.E5.m1.4.4.4.4" xref="S4.E5.m1.4.4.4.4.cmml">e</mi><mo stretchy="false" id="S4.E5.m1.5.5.5.5.3.2.3" xref="S4.E5.m1.5.5.5.5.3.1.cmml">)</mo></mrow></mrow></mrow><mrow id="S4.E5.m1.8.8.8" xref="S4.E5.m1.8.8.8.cmml"><msub id="S4.E5.m1.8.8.8.4" xref="S4.E5.m1.8.8.8.4.cmml"><mo id="S4.E5.m1.8.8.8.4.2" xref="S4.E5.m1.8.8.8.4.2.cmml">âˆ‘</mo><mrow id="S4.E5.m1.8.8.8.4.3" xref="S4.E5.m1.8.8.8.4.3.cmml"><mi id="S4.E5.m1.8.8.8.4.3.2" xref="S4.E5.m1.8.8.8.4.3.2.cmml">e</mi><mo id="S4.E5.m1.8.8.8.4.3.1" xref="S4.E5.m1.8.8.8.4.3.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S4.E5.m1.8.8.8.4.3.3" xref="S4.E5.m1.8.8.8.4.3.3.cmml">â„°</mi></mrow></msub><mrow id="S4.E5.m1.8.8.8.3" xref="S4.E5.m1.8.8.8.3.cmml"><mi id="S4.E5.m1.8.8.8.3.3" xref="S4.E5.m1.8.8.8.3.3.cmml">Ïƒ</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.8.8.8.3.2" xref="S4.E5.m1.8.8.8.3.2.cmml">â€‹</mo><mrow id="S4.E5.m1.8.8.8.3.1.1" xref="S4.E5.m1.8.8.8.3.1.1.1.cmml"><mo stretchy="false" id="S4.E5.m1.8.8.8.3.1.1.2" xref="S4.E5.m1.8.8.8.3.1.1.1.cmml">(</mo><mrow id="S4.E5.m1.8.8.8.3.1.1.1" xref="S4.E5.m1.8.8.8.3.1.1.1.cmml"><msub id="S4.E5.m1.8.8.8.3.1.1.1.2" xref="S4.E5.m1.8.8.8.3.1.1.1.2.cmml"><mi id="S4.E5.m1.8.8.8.3.1.1.1.2.2" xref="S4.E5.m1.8.8.8.3.1.1.1.2.2.cmml">S</mi><mrow id="S4.E5.m1.8.8.8.3.1.1.1.2.3" xref="S4.E5.m1.8.8.8.3.1.1.1.2.3.cmml"><mi id="S4.E5.m1.8.8.8.3.1.1.1.2.3.2" xref="S4.E5.m1.8.8.8.3.1.1.1.2.3.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.8.8.8.3.1.1.1.2.3.1" xref="S4.E5.m1.8.8.8.3.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.E5.m1.8.8.8.3.1.1.1.2.3.3" xref="S4.E5.m1.8.8.8.3.1.1.1.2.3.3.cmml">e</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.E5.m1.8.8.8.3.1.1.1.1" xref="S4.E5.m1.8.8.8.3.1.1.1.1.cmml">â€‹</mo><mrow id="S4.E5.m1.8.8.8.3.1.1.1.3.2" xref="S4.E5.m1.8.8.8.3.1.1.1.3.1.cmml"><mo stretchy="false" id="S4.E5.m1.8.8.8.3.1.1.1.3.2.1" xref="S4.E5.m1.8.8.8.3.1.1.1.3.1.cmml">(</mo><mi id="S4.E5.m1.6.6.6.1" xref="S4.E5.m1.6.6.6.1.cmml">q</mi><mo id="S4.E5.m1.8.8.8.3.1.1.1.3.2.2" xref="S4.E5.m1.8.8.8.3.1.1.1.3.1.cmml">,</mo><mi id="S4.E5.m1.7.7.7.2" xref="S4.E5.m1.7.7.7.2.cmml">e</mi><mo stretchy="false" id="S4.E5.m1.8.8.8.3.1.1.1.3.2.3" xref="S4.E5.m1.8.8.8.3.1.1.1.3.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.E5.m1.8.8.8.3.1.1.3" xref="S4.E5.m1.8.8.8.3.1.1.1.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.E5.m1.11b"><apply id="S4.E5.m1.11.12.cmml" xref="S4.E5.m1.11.12"><eq id="S4.E5.m1.11.12.1.cmml" xref="S4.E5.m1.11.12.1"></eq><apply id="S4.E5.m1.11.12.2.cmml" xref="S4.E5.m1.11.12.2"><times id="S4.E5.m1.11.12.2.1.cmml" xref="S4.E5.m1.11.12.2.1"></times><apply id="S4.E5.m1.11.12.2.2.cmml" xref="S4.E5.m1.11.12.2.2"><csymbol cd="ambiguous" id="S4.E5.m1.11.12.2.2.1.cmml" xref="S4.E5.m1.11.12.2.2">subscript</csymbol><ci id="S4.E5.m1.11.12.2.2.2.cmml" xref="S4.E5.m1.11.12.2.2.2">ğ‘†</ci><apply id="S4.E5.m1.11.12.2.2.3.cmml" xref="S4.E5.m1.11.12.2.2.3"><times id="S4.E5.m1.11.12.2.2.3.1.cmml" xref="S4.E5.m1.11.12.2.2.3.1"></times><ci id="S4.E5.m1.11.12.2.2.3.2.cmml" xref="S4.E5.m1.11.12.2.2.3.2">ğ‘</ci><ci id="S4.E5.m1.11.12.2.2.3.3.cmml" xref="S4.E5.m1.11.12.2.2.3.3">ğ‘</ci><ci id="S4.E5.m1.11.12.2.2.3.4.cmml" xref="S4.E5.m1.11.12.2.2.3.4">ğ‘’</ci></apply></apply><vector id="S4.E5.m1.11.12.2.3.1.cmml" xref="S4.E5.m1.11.12.2.3.2"><ci id="S4.E5.m1.9.9.cmml" xref="S4.E5.m1.9.9">ğ‘</ci><ci id="S4.E5.m1.10.10.cmml" xref="S4.E5.m1.10.10">ğ‘</ci><ci id="S4.E5.m1.11.11.cmml" xref="S4.E5.m1.11.11">â„°</ci></vector></apply><apply id="S4.E5.m1.8.8.cmml" xref="S4.E5.m1.8.8"><divide id="S4.E5.m1.8.8.9.cmml" xref="S4.E5.m1.8.8"></divide><apply id="S4.E5.m1.5.5.5.cmml" xref="S4.E5.m1.5.5.5"><apply id="S4.E5.m1.5.5.5.6.cmml" xref="S4.E5.m1.5.5.5.6"><csymbol cd="ambiguous" id="S4.E5.m1.5.5.5.6.1.cmml" xref="S4.E5.m1.5.5.5.6">subscript</csymbol><sum id="S4.E5.m1.5.5.5.6.2.cmml" xref="S4.E5.m1.5.5.5.6.2"></sum><apply id="S4.E5.m1.5.5.5.6.3.cmml" xref="S4.E5.m1.5.5.5.6.3"><in id="S4.E5.m1.5.5.5.6.3.1.cmml" xref="S4.E5.m1.5.5.5.6.3.1"></in><ci id="S4.E5.m1.5.5.5.6.3.2.cmml" xref="S4.E5.m1.5.5.5.6.3.2">ğ‘’</ci><ci id="S4.E5.m1.5.5.5.6.3.3.cmml" xref="S4.E5.m1.5.5.5.6.3.3">â„°</ci></apply></apply><apply id="S4.E5.m1.5.5.5.5.cmml" xref="S4.E5.m1.5.5.5.5"><times id="S4.E5.m1.5.5.5.5.2.cmml" xref="S4.E5.m1.5.5.5.5.2"></times><apply id="S4.E5.m1.5.5.5.5.1.cmml" xref="S4.E5.m1.5.5.5.5.1"><times id="S4.E5.m1.5.5.5.5.1.2.cmml" xref="S4.E5.m1.5.5.5.5.1.2"></times><apply id="S4.E5.m1.5.5.5.5.1.1.cmml" xref="S4.E5.m1.5.5.5.5.1.1"><times id="S4.E5.m1.5.5.5.5.1.1.2.cmml" xref="S4.E5.m1.5.5.5.5.1.1.2"></times><ci id="S4.E5.m1.5.5.5.5.1.1.3.cmml" xref="S4.E5.m1.5.5.5.5.1.1.3">ğœ</ci><apply id="S4.E5.m1.5.5.5.5.1.1.1.1.1.cmml" xref="S4.E5.m1.5.5.5.5.1.1.1.1"><times id="S4.E5.m1.5.5.5.5.1.1.1.1.1.1.cmml" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.1"></times><apply id="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.cmml" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.1.cmml" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.2.cmml" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.2">ğ‘†</ci><apply id="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.3.cmml" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.3"><times id="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.3.1.cmml" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.3.1"></times><ci id="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.3.2.cmml" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.3.2">ğ‘</ci><ci id="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.3.3.cmml" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.2.3.3">ğ‘’</ci></apply></apply><interval closure="open" id="S4.E5.m1.5.5.5.5.1.1.1.1.1.3.1.cmml" xref="S4.E5.m1.5.5.5.5.1.1.1.1.1.3.2"><ci id="S4.E5.m1.1.1.1.1.cmml" xref="S4.E5.m1.1.1.1.1">ğ‘</ci><ci id="S4.E5.m1.2.2.2.2.cmml" xref="S4.E5.m1.2.2.2.2">ğ‘’</ci></interval></apply></apply><apply id="S4.E5.m1.5.5.5.5.1.3.cmml" xref="S4.E5.m1.5.5.5.5.1.3"><csymbol cd="ambiguous" id="S4.E5.m1.5.5.5.5.1.3.1.cmml" xref="S4.E5.m1.5.5.5.5.1.3">subscript</csymbol><ci id="S4.E5.m1.5.5.5.5.1.3.2.cmml" xref="S4.E5.m1.5.5.5.5.1.3.2">ğ‘†</ci><apply id="S4.E5.m1.5.5.5.5.1.3.3.cmml" xref="S4.E5.m1.5.5.5.5.1.3.3"><times id="S4.E5.m1.5.5.5.5.1.3.3.1.cmml" xref="S4.E5.m1.5.5.5.5.1.3.3.1"></times><ci id="S4.E5.m1.5.5.5.5.1.3.3.2.cmml" xref="S4.E5.m1.5.5.5.5.1.3.3.2">ğ‘</ci><ci id="S4.E5.m1.5.5.5.5.1.3.3.3.cmml" xref="S4.E5.m1.5.5.5.5.1.3.3.3">ğ‘’</ci></apply></apply></apply><interval closure="open" id="S4.E5.m1.5.5.5.5.3.1.cmml" xref="S4.E5.m1.5.5.5.5.3.2"><ci id="S4.E5.m1.3.3.3.3.cmml" xref="S4.E5.m1.3.3.3.3">ğ‘</ci><ci id="S4.E5.m1.4.4.4.4.cmml" xref="S4.E5.m1.4.4.4.4">ğ‘’</ci></interval></apply></apply><apply id="S4.E5.m1.8.8.8.cmml" xref="S4.E5.m1.8.8.8"><apply id="S4.E5.m1.8.8.8.4.cmml" xref="S4.E5.m1.8.8.8.4"><csymbol cd="ambiguous" id="S4.E5.m1.8.8.8.4.1.cmml" xref="S4.E5.m1.8.8.8.4">subscript</csymbol><sum id="S4.E5.m1.8.8.8.4.2.cmml" xref="S4.E5.m1.8.8.8.4.2"></sum><apply id="S4.E5.m1.8.8.8.4.3.cmml" xref="S4.E5.m1.8.8.8.4.3"><in id="S4.E5.m1.8.8.8.4.3.1.cmml" xref="S4.E5.m1.8.8.8.4.3.1"></in><ci id="S4.E5.m1.8.8.8.4.3.2.cmml" xref="S4.E5.m1.8.8.8.4.3.2">ğ‘’</ci><ci id="S4.E5.m1.8.8.8.4.3.3.cmml" xref="S4.E5.m1.8.8.8.4.3.3">â„°</ci></apply></apply><apply id="S4.E5.m1.8.8.8.3.cmml" xref="S4.E5.m1.8.8.8.3"><times id="S4.E5.m1.8.8.8.3.2.cmml" xref="S4.E5.m1.8.8.8.3.2"></times><ci id="S4.E5.m1.8.8.8.3.3.cmml" xref="S4.E5.m1.8.8.8.3.3">ğœ</ci><apply id="S4.E5.m1.8.8.8.3.1.1.1.cmml" xref="S4.E5.m1.8.8.8.3.1.1"><times id="S4.E5.m1.8.8.8.3.1.1.1.1.cmml" xref="S4.E5.m1.8.8.8.3.1.1.1.1"></times><apply id="S4.E5.m1.8.8.8.3.1.1.1.2.cmml" xref="S4.E5.m1.8.8.8.3.1.1.1.2"><csymbol cd="ambiguous" id="S4.E5.m1.8.8.8.3.1.1.1.2.1.cmml" xref="S4.E5.m1.8.8.8.3.1.1.1.2">subscript</csymbol><ci id="S4.E5.m1.8.8.8.3.1.1.1.2.2.cmml" xref="S4.E5.m1.8.8.8.3.1.1.1.2.2">ğ‘†</ci><apply id="S4.E5.m1.8.8.8.3.1.1.1.2.3.cmml" xref="S4.E5.m1.8.8.8.3.1.1.1.2.3"><times id="S4.E5.m1.8.8.8.3.1.1.1.2.3.1.cmml" xref="S4.E5.m1.8.8.8.3.1.1.1.2.3.1"></times><ci id="S4.E5.m1.8.8.8.3.1.1.1.2.3.2.cmml" xref="S4.E5.m1.8.8.8.3.1.1.1.2.3.2">ğ‘</ci><ci id="S4.E5.m1.8.8.8.3.1.1.1.2.3.3.cmml" xref="S4.E5.m1.8.8.8.3.1.1.1.2.3.3">ğ‘’</ci></apply></apply><interval closure="open" id="S4.E5.m1.8.8.8.3.1.1.1.3.1.cmml" xref="S4.E5.m1.8.8.8.3.1.1.1.3.2"><ci id="S4.E5.m1.6.6.6.1.cmml" xref="S4.E5.m1.6.6.6.1">ğ‘</ci><ci id="S4.E5.m1.7.7.7.2.cmml" xref="S4.E5.m1.7.7.7.2">ğ‘’</ci></interval></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m1.11c">S_{qpe}(q,p,\mathcal{E})=\frac{\sum_{e\in\mathcal{E}}\sigma(S_{qe}(q,e))\times S_{pe}(p,e)}{\sum_{e\in\mathcal{E}}\sigma(S_{qe}(q,e))}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.p3.6" class="ltx_p">where <math id="S4.SS2.p3.5.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SS2.p3.5.m1.1a"><mi id="S4.SS2.p3.5.m1.1.1" xref="S4.SS2.p3.5.m1.1.1.cmml">Ïƒ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.5.m1.1b"><ci id="S4.SS2.p3.5.m1.1.1.cmml" xref="S4.SS2.p3.5.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.5.m1.1c">\sigma</annotation></semantics></math> denotes the sigmoid function.
Another way to interpret Eq. <a href="#S4.E5" title="In 4.2 Retrieval Scores â€£ 4 Entity-Focused Retrieval â€£ Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> is to treat it as modeling the conditional distribution <math id="S4.SS2.p3.6.m2.2" class="ltx_Math" alttext="\Pr(p\mid q)" display="inline"><semantics id="S4.SS2.p3.6.m2.2a"><mrow id="S4.SS2.p3.6.m2.2.2.1" xref="S4.SS2.p3.6.m2.2.2.2.cmml"><mi id="S4.SS2.p3.6.m2.1.1" xref="S4.SS2.p3.6.m2.1.1.cmml">Pr</mi><mo id="S4.SS2.p3.6.m2.2.2.1a" xref="S4.SS2.p3.6.m2.2.2.2.cmml">â¡</mo><mrow id="S4.SS2.p3.6.m2.2.2.1.1" xref="S4.SS2.p3.6.m2.2.2.2.cmml"><mo stretchy="false" id="S4.SS2.p3.6.m2.2.2.1.1.2" xref="S4.SS2.p3.6.m2.2.2.2.cmml">(</mo><mrow id="S4.SS2.p3.6.m2.2.2.1.1.1" xref="S4.SS2.p3.6.m2.2.2.1.1.1.cmml"><mi id="S4.SS2.p3.6.m2.2.2.1.1.1.2" xref="S4.SS2.p3.6.m2.2.2.1.1.1.2.cmml">p</mi><mo id="S4.SS2.p3.6.m2.2.2.1.1.1.1" xref="S4.SS2.p3.6.m2.2.2.1.1.1.1.cmml">âˆ£</mo><mi id="S4.SS2.p3.6.m2.2.2.1.1.1.3" xref="S4.SS2.p3.6.m2.2.2.1.1.1.3.cmml">q</mi></mrow><mo stretchy="false" id="S4.SS2.p3.6.m2.2.2.1.1.3" xref="S4.SS2.p3.6.m2.2.2.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.6.m2.2b"><apply id="S4.SS2.p3.6.m2.2.2.2.cmml" xref="S4.SS2.p3.6.m2.2.2.1"><ci id="S4.SS2.p3.6.m2.1.1.cmml" xref="S4.SS2.p3.6.m2.1.1">Pr</ci><apply id="S4.SS2.p3.6.m2.2.2.1.1.1.cmml" xref="S4.SS2.p3.6.m2.2.2.1.1.1"><csymbol cd="latexml" id="S4.SS2.p3.6.m2.2.2.1.1.1.1.cmml" xref="S4.SS2.p3.6.m2.2.2.1.1.1.1">conditional</csymbol><ci id="S4.SS2.p3.6.m2.2.2.1.1.1.2.cmml" xref="S4.SS2.p3.6.m2.2.2.1.1.1.2">ğ‘</ci><ci id="S4.SS2.p3.6.m2.2.2.1.1.1.3.cmml" xref="S4.SS2.p3.6.m2.2.2.1.1.1.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.6.m2.2c">\Pr(p\mid q)</annotation></semantics></math> and consider the entities as hidden variables.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.5" class="ltx_p">The final score <math id="S4.SS2.p4.1.m1.2" class="ltx_Math" alttext="S(q,p)" display="inline"><semantics id="S4.SS2.p4.1.m1.2a"><mrow id="S4.SS2.p4.1.m1.2.3" xref="S4.SS2.p4.1.m1.2.3.cmml"><mi id="S4.SS2.p4.1.m1.2.3.2" xref="S4.SS2.p4.1.m1.2.3.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.1.m1.2.3.1" xref="S4.SS2.p4.1.m1.2.3.1.cmml">â€‹</mo><mrow id="S4.SS2.p4.1.m1.2.3.3.2" xref="S4.SS2.p4.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S4.SS2.p4.1.m1.2.3.3.2.1" xref="S4.SS2.p4.1.m1.2.3.3.1.cmml">(</mo><mi id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml">q</mi><mo id="S4.SS2.p4.1.m1.2.3.3.2.2" xref="S4.SS2.p4.1.m1.2.3.3.1.cmml">,</mo><mi id="S4.SS2.p4.1.m1.2.2" xref="S4.SS2.p4.1.m1.2.2.cmml">p</mi><mo stretchy="false" id="S4.SS2.p4.1.m1.2.3.3.2.3" xref="S4.SS2.p4.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.2b"><apply id="S4.SS2.p4.1.m1.2.3.cmml" xref="S4.SS2.p4.1.m1.2.3"><times id="S4.SS2.p4.1.m1.2.3.1.cmml" xref="S4.SS2.p4.1.m1.2.3.1"></times><ci id="S4.SS2.p4.1.m1.2.3.2.cmml" xref="S4.SS2.p4.1.m1.2.3.2">ğ‘†</ci><interval closure="open" id="S4.SS2.p4.1.m1.2.3.3.1.cmml" xref="S4.SS2.p4.1.m1.2.3.3.2"><ci id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1">ğ‘</ci><ci id="S4.SS2.p4.1.m1.2.2.cmml" xref="S4.SS2.p4.1.m1.2.2">ğ‘</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.2c">S(q,p)</annotation></semantics></math> for the query <math id="S4.SS2.p4.2.m2.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S4.SS2.p4.2.m2.1a"><mi id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.1b"><ci id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.1c">q</annotation></semantics></math> and passage <math id="S4.SS2.p4.3.m3.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.SS2.p4.3.m3.1a"><mi id="S4.SS2.p4.3.m3.1.1" xref="S4.SS2.p4.3.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.3.m3.1b"><ci id="S4.SS2.p4.3.m3.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.3.m3.1c">p</annotation></semantics></math> linearly combines both terms, i.e. <math id="S4.SS2.p4.4.m4.7" class="ltx_Math" alttext="S(q,p)=S_{qp}(q,p)+\lambda S_{qpe}(q,p,\mathcal{E})" display="inline"><semantics id="S4.SS2.p4.4.m4.7a"><mrow id="S4.SS2.p4.4.m4.7.8" xref="S4.SS2.p4.4.m4.7.8.cmml"><mrow id="S4.SS2.p4.4.m4.7.8.2" xref="S4.SS2.p4.4.m4.7.8.2.cmml"><mi id="S4.SS2.p4.4.m4.7.8.2.2" xref="S4.SS2.p4.4.m4.7.8.2.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.4.m4.7.8.2.1" xref="S4.SS2.p4.4.m4.7.8.2.1.cmml">â€‹</mo><mrow id="S4.SS2.p4.4.m4.7.8.2.3.2" xref="S4.SS2.p4.4.m4.7.8.2.3.1.cmml"><mo stretchy="false" id="S4.SS2.p4.4.m4.7.8.2.3.2.1" xref="S4.SS2.p4.4.m4.7.8.2.3.1.cmml">(</mo><mi id="S4.SS2.p4.4.m4.1.1" xref="S4.SS2.p4.4.m4.1.1.cmml">q</mi><mo id="S4.SS2.p4.4.m4.7.8.2.3.2.2" xref="S4.SS2.p4.4.m4.7.8.2.3.1.cmml">,</mo><mi id="S4.SS2.p4.4.m4.2.2" xref="S4.SS2.p4.4.m4.2.2.cmml">p</mi><mo stretchy="false" id="S4.SS2.p4.4.m4.7.8.2.3.2.3" xref="S4.SS2.p4.4.m4.7.8.2.3.1.cmml">)</mo></mrow></mrow><mo id="S4.SS2.p4.4.m4.7.8.1" xref="S4.SS2.p4.4.m4.7.8.1.cmml">=</mo><mrow id="S4.SS2.p4.4.m4.7.8.3" xref="S4.SS2.p4.4.m4.7.8.3.cmml"><mrow id="S4.SS2.p4.4.m4.7.8.3.2" xref="S4.SS2.p4.4.m4.7.8.3.2.cmml"><msub id="S4.SS2.p4.4.m4.7.8.3.2.2" xref="S4.SS2.p4.4.m4.7.8.3.2.2.cmml"><mi id="S4.SS2.p4.4.m4.7.8.3.2.2.2" xref="S4.SS2.p4.4.m4.7.8.3.2.2.2.cmml">S</mi><mrow id="S4.SS2.p4.4.m4.7.8.3.2.2.3" xref="S4.SS2.p4.4.m4.7.8.3.2.2.3.cmml"><mi id="S4.SS2.p4.4.m4.7.8.3.2.2.3.2" xref="S4.SS2.p4.4.m4.7.8.3.2.2.3.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.4.m4.7.8.3.2.2.3.1" xref="S4.SS2.p4.4.m4.7.8.3.2.2.3.1.cmml">â€‹</mo><mi id="S4.SS2.p4.4.m4.7.8.3.2.2.3.3" xref="S4.SS2.p4.4.m4.7.8.3.2.2.3.3.cmml">p</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.SS2.p4.4.m4.7.8.3.2.1" xref="S4.SS2.p4.4.m4.7.8.3.2.1.cmml">â€‹</mo><mrow id="S4.SS2.p4.4.m4.7.8.3.2.3.2" xref="S4.SS2.p4.4.m4.7.8.3.2.3.1.cmml"><mo stretchy="false" id="S4.SS2.p4.4.m4.7.8.3.2.3.2.1" xref="S4.SS2.p4.4.m4.7.8.3.2.3.1.cmml">(</mo><mi id="S4.SS2.p4.4.m4.3.3" xref="S4.SS2.p4.4.m4.3.3.cmml">q</mi><mo id="S4.SS2.p4.4.m4.7.8.3.2.3.2.2" xref="S4.SS2.p4.4.m4.7.8.3.2.3.1.cmml">,</mo><mi id="S4.SS2.p4.4.m4.4.4" xref="S4.SS2.p4.4.m4.4.4.cmml">p</mi><mo stretchy="false" id="S4.SS2.p4.4.m4.7.8.3.2.3.2.3" xref="S4.SS2.p4.4.m4.7.8.3.2.3.1.cmml">)</mo></mrow></mrow><mo id="S4.SS2.p4.4.m4.7.8.3.1" xref="S4.SS2.p4.4.m4.7.8.3.1.cmml">+</mo><mrow id="S4.SS2.p4.4.m4.7.8.3.3" xref="S4.SS2.p4.4.m4.7.8.3.3.cmml"><mi id="S4.SS2.p4.4.m4.7.8.3.3.2" xref="S4.SS2.p4.4.m4.7.8.3.3.2.cmml">Î»</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.4.m4.7.8.3.3.1" xref="S4.SS2.p4.4.m4.7.8.3.3.1.cmml">â€‹</mo><msub id="S4.SS2.p4.4.m4.7.8.3.3.3" xref="S4.SS2.p4.4.m4.7.8.3.3.3.cmml"><mi id="S4.SS2.p4.4.m4.7.8.3.3.3.2" xref="S4.SS2.p4.4.m4.7.8.3.3.3.2.cmml">S</mi><mrow id="S4.SS2.p4.4.m4.7.8.3.3.3.3" xref="S4.SS2.p4.4.m4.7.8.3.3.3.3.cmml"><mi id="S4.SS2.p4.4.m4.7.8.3.3.3.3.2" xref="S4.SS2.p4.4.m4.7.8.3.3.3.3.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.4.m4.7.8.3.3.3.3.1" xref="S4.SS2.p4.4.m4.7.8.3.3.3.3.1.cmml">â€‹</mo><mi id="S4.SS2.p4.4.m4.7.8.3.3.3.3.3" xref="S4.SS2.p4.4.m4.7.8.3.3.3.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.4.m4.7.8.3.3.3.3.1a" xref="S4.SS2.p4.4.m4.7.8.3.3.3.3.1.cmml">â€‹</mo><mi id="S4.SS2.p4.4.m4.7.8.3.3.3.3.4" xref="S4.SS2.p4.4.m4.7.8.3.3.3.3.4.cmml">e</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.SS2.p4.4.m4.7.8.3.3.1a" xref="S4.SS2.p4.4.m4.7.8.3.3.1.cmml">â€‹</mo><mrow id="S4.SS2.p4.4.m4.7.8.3.3.4.2" xref="S4.SS2.p4.4.m4.7.8.3.3.4.1.cmml"><mo stretchy="false" id="S4.SS2.p4.4.m4.7.8.3.3.4.2.1" xref="S4.SS2.p4.4.m4.7.8.3.3.4.1.cmml">(</mo><mi id="S4.SS2.p4.4.m4.5.5" xref="S4.SS2.p4.4.m4.5.5.cmml">q</mi><mo id="S4.SS2.p4.4.m4.7.8.3.3.4.2.2" xref="S4.SS2.p4.4.m4.7.8.3.3.4.1.cmml">,</mo><mi id="S4.SS2.p4.4.m4.6.6" xref="S4.SS2.p4.4.m4.6.6.cmml">p</mi><mo id="S4.SS2.p4.4.m4.7.8.3.3.4.2.3" xref="S4.SS2.p4.4.m4.7.8.3.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p4.4.m4.7.7" xref="S4.SS2.p4.4.m4.7.7.cmml">â„°</mi><mo stretchy="false" id="S4.SS2.p4.4.m4.7.8.3.3.4.2.4" xref="S4.SS2.p4.4.m4.7.8.3.3.4.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.4.m4.7b"><apply id="S4.SS2.p4.4.m4.7.8.cmml" xref="S4.SS2.p4.4.m4.7.8"><eq id="S4.SS2.p4.4.m4.7.8.1.cmml" xref="S4.SS2.p4.4.m4.7.8.1"></eq><apply id="S4.SS2.p4.4.m4.7.8.2.cmml" xref="S4.SS2.p4.4.m4.7.8.2"><times id="S4.SS2.p4.4.m4.7.8.2.1.cmml" xref="S4.SS2.p4.4.m4.7.8.2.1"></times><ci id="S4.SS2.p4.4.m4.7.8.2.2.cmml" xref="S4.SS2.p4.4.m4.7.8.2.2">ğ‘†</ci><interval closure="open" id="S4.SS2.p4.4.m4.7.8.2.3.1.cmml" xref="S4.SS2.p4.4.m4.7.8.2.3.2"><ci id="S4.SS2.p4.4.m4.1.1.cmml" xref="S4.SS2.p4.4.m4.1.1">ğ‘</ci><ci id="S4.SS2.p4.4.m4.2.2.cmml" xref="S4.SS2.p4.4.m4.2.2">ğ‘</ci></interval></apply><apply id="S4.SS2.p4.4.m4.7.8.3.cmml" xref="S4.SS2.p4.4.m4.7.8.3"><plus id="S4.SS2.p4.4.m4.7.8.3.1.cmml" xref="S4.SS2.p4.4.m4.7.8.3.1"></plus><apply id="S4.SS2.p4.4.m4.7.8.3.2.cmml" xref="S4.SS2.p4.4.m4.7.8.3.2"><times id="S4.SS2.p4.4.m4.7.8.3.2.1.cmml" xref="S4.SS2.p4.4.m4.7.8.3.2.1"></times><apply id="S4.SS2.p4.4.m4.7.8.3.2.2.cmml" xref="S4.SS2.p4.4.m4.7.8.3.2.2"><csymbol cd="ambiguous" id="S4.SS2.p4.4.m4.7.8.3.2.2.1.cmml" xref="S4.SS2.p4.4.m4.7.8.3.2.2">subscript</csymbol><ci id="S4.SS2.p4.4.m4.7.8.3.2.2.2.cmml" xref="S4.SS2.p4.4.m4.7.8.3.2.2.2">ğ‘†</ci><apply id="S4.SS2.p4.4.m4.7.8.3.2.2.3.cmml" xref="S4.SS2.p4.4.m4.7.8.3.2.2.3"><times id="S4.SS2.p4.4.m4.7.8.3.2.2.3.1.cmml" xref="S4.SS2.p4.4.m4.7.8.3.2.2.3.1"></times><ci id="S4.SS2.p4.4.m4.7.8.3.2.2.3.2.cmml" xref="S4.SS2.p4.4.m4.7.8.3.2.2.3.2">ğ‘</ci><ci id="S4.SS2.p4.4.m4.7.8.3.2.2.3.3.cmml" xref="S4.SS2.p4.4.m4.7.8.3.2.2.3.3">ğ‘</ci></apply></apply><interval closure="open" id="S4.SS2.p4.4.m4.7.8.3.2.3.1.cmml" xref="S4.SS2.p4.4.m4.7.8.3.2.3.2"><ci id="S4.SS2.p4.4.m4.3.3.cmml" xref="S4.SS2.p4.4.m4.3.3">ğ‘</ci><ci id="S4.SS2.p4.4.m4.4.4.cmml" xref="S4.SS2.p4.4.m4.4.4">ğ‘</ci></interval></apply><apply id="S4.SS2.p4.4.m4.7.8.3.3.cmml" xref="S4.SS2.p4.4.m4.7.8.3.3"><times id="S4.SS2.p4.4.m4.7.8.3.3.1.cmml" xref="S4.SS2.p4.4.m4.7.8.3.3.1"></times><ci id="S4.SS2.p4.4.m4.7.8.3.3.2.cmml" xref="S4.SS2.p4.4.m4.7.8.3.3.2">ğœ†</ci><apply id="S4.SS2.p4.4.m4.7.8.3.3.3.cmml" xref="S4.SS2.p4.4.m4.7.8.3.3.3"><csymbol cd="ambiguous" id="S4.SS2.p4.4.m4.7.8.3.3.3.1.cmml" xref="S4.SS2.p4.4.m4.7.8.3.3.3">subscript</csymbol><ci id="S4.SS2.p4.4.m4.7.8.3.3.3.2.cmml" xref="S4.SS2.p4.4.m4.7.8.3.3.3.2">ğ‘†</ci><apply id="S4.SS2.p4.4.m4.7.8.3.3.3.3.cmml" xref="S4.SS2.p4.4.m4.7.8.3.3.3.3"><times id="S4.SS2.p4.4.m4.7.8.3.3.3.3.1.cmml" xref="S4.SS2.p4.4.m4.7.8.3.3.3.3.1"></times><ci id="S4.SS2.p4.4.m4.7.8.3.3.3.3.2.cmml" xref="S4.SS2.p4.4.m4.7.8.3.3.3.3.2">ğ‘</ci><ci id="S4.SS2.p4.4.m4.7.8.3.3.3.3.3.cmml" xref="S4.SS2.p4.4.m4.7.8.3.3.3.3.3">ğ‘</ci><ci id="S4.SS2.p4.4.m4.7.8.3.3.3.3.4.cmml" xref="S4.SS2.p4.4.m4.7.8.3.3.3.3.4">ğ‘’</ci></apply></apply><vector id="S4.SS2.p4.4.m4.7.8.3.3.4.1.cmml" xref="S4.SS2.p4.4.m4.7.8.3.3.4.2"><ci id="S4.SS2.p4.4.m4.5.5.cmml" xref="S4.SS2.p4.4.m4.5.5">ğ‘</ci><ci id="S4.SS2.p4.4.m4.6.6.cmml" xref="S4.SS2.p4.4.m4.6.6">ğ‘</ci><ci id="S4.SS2.p4.4.m4.7.7.cmml" xref="S4.SS2.p4.4.m4.7.7">â„°</ci></vector></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.4.m4.7c">S(q,p)=S_{qp}(q,p)+\lambda S_{qpe}(q,p,\mathcal{E})</annotation></semantics></math>, where the weight <math id="S4.SS2.p4.5.m5.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.SS2.p4.5.m5.1a"><mi id="S4.SS2.p4.5.m5.1.1" xref="S4.SS2.p4.5.m5.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.5.m5.1b"><ci id="S4.SS2.p4.5.m5.1.1.cmml" xref="S4.SS2.p4.5.m5.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.5.m5.1c">\lambda</annotation></semantics></math> controls the balance between the these two terms.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<table id="S4.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.1.1.1" class="ltx_tr">
<td id="S4.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">Methods</td>
<td id="S4.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" colspan="2">Val</td>
<td id="S4.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Test</td>
</tr>
<tr id="S4.T1.1.2.2" class="ltx_tr">
<td id="S4.T1.1.2.2.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MRR@5</td>
<td id="S4.T1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">P@5</td>
<td id="S4.T1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MRR@5</td>
<td id="S4.T1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t">P@5</td>
</tr>
<tr id="S4.T1.1.3.3" class="ltx_tr">
<td id="S4.T1.1.3.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">BM25-Obj</td>
<td id="S4.T1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.3772</td>
<td id="S4.T1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.2667</td>
<td id="S4.T1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.3686</td>
<td id="S4.T1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t">0.2541</td>
</tr>
<tr id="S4.T1.1.4.4" class="ltx_tr">
<td id="S4.T1.1.4.4.1" class="ltx_td ltx_align_left ltx_border_r">BM25-Cap</td>
<td id="S4.T1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r">0.4727</td>
<td id="S4.T1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_rr">0.3483</td>
<td id="S4.T1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r">0.4622</td>
<td id="S4.T1.1.4.4.5" class="ltx_td ltx_align_center">0.3367</td>
</tr>
<tr id="S4.T1.1.5.5" class="ltx_tr">
<td id="S4.T1.1.5.5.1" class="ltx_td ltx_align_left ltx_border_r">BM25 w. entities</td>
<td id="S4.T1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r">0.3620</td>
<td id="S4.T1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_rr">0.2558</td>
<td id="S4.T1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">0.3732</td>
<td id="S4.T1.1.5.5.5" class="ltx_td ltx_align_center">0.2620</td>
</tr>
<tr id="S4.T1.1.6.6" class="ltx_tr">
<td id="S4.T1.1.6.6.1" class="ltx_td ltx_align_left ltx_border_r">BM25 w. oracle entities</td>
<td id="S4.T1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r">0.6591</td>
<td id="S4.T1.1.6.6.3" class="ltx_td ltx_align_center ltx_border_rr">0.4548</td>
<td id="S4.T1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r">0.6401</td>
<td id="S4.T1.1.6.6.5" class="ltx_td ltx_align_center">0.4345</td>
</tr>
<tr id="S4.T1.1.7.7" class="ltx_tr">
<td id="S4.T1.1.7.7.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">DPR-LXMERT <cite class="ltx_cite ltx_citemacro_cite">Qu etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S4.T1.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.4704</td>
<td id="S4.T1.1.7.7.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.3364</td>
<td id="S4.T1.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.4526</td>
<td id="S4.T1.1.7.7.5" class="ltx_td ltx_align_center ltx_border_t">0.3329</td>
</tr>
<tr id="S4.T1.1.8.8" class="ltx_tr">
<td id="S4.T1.1.8.8.1" class="ltx_td ltx_align_left ltx_border_r">EnFoRe-LXMERT</td>
<td id="S4.T1.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.8.8.2.1" class="ltx_text ltx_font_bold">0.4881</span></td>
<td id="S4.T1.1.8.8.3" class="ltx_td ltx_align_center ltx_border_rr"><span id="S4.T1.1.8.8.3.1" class="ltx_text ltx_font_bold">0.3488</span></td>
<td id="S4.T1.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.8.8.4.1" class="ltx_text ltx_font_bold">0.4800</span></td>
<td id="S4.T1.1.8.8.5" class="ltx_td ltx_align_center"><span id="S4.T1.1.8.8.5.1" class="ltx_text ltx_font_bold">0.3444</span></td>
</tr>
<tr id="S4.T1.1.9.9" class="ltx_tr">
<td id="S4.T1.1.9.9.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t">EnFoRe-LXMERT w. oracle entities</td>
<td id="S4.T1.1.9.9.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">0.4898</td>
<td id="S4.T1.1.9.9.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr ltx_border_t">0.3533</td>
<td id="S4.T1.1.9.9.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">0.4853</td>
<td id="S4.T1.1.9.9.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.3451</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>MRR and precision retreival results on OK-VQA. The first four rows present sparse retrieval results and the others are dense retrieval results. </figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Training</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.4" class="ltx_p">We train our EnFoRe model with a set of training instances consisting of a query containing the visual question with an image, a positive passage, a retrieved negative passage, and the set of entities. We present more details on constructing the training data in Sec. <a href="#S6.SS1" title="6.1 Dataset â€£ 6 Experimental Results â€£ Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a>. We adopt the â€œR-Neg+IB-Allâ€ setting introduced by <cite class="ltx_cite ltx_citemacro_citet">Qu etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite> that regards the retrieved negatives, along with all other in-batch passages, as negative samplings. Following previous work <cite class="ltx_cite ltx_citemacro_cite">Karpukhin etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>)</cite>, we use cross-entropy loss to maximize the relevancy score <math id="S4.SS3.p1.1.m1.2" class="ltx_Math" alttext="S_{qp}(q,p)" display="inline"><semantics id="S4.SS3.p1.1.m1.2a"><mrow id="S4.SS3.p1.1.m1.2.3" xref="S4.SS3.p1.1.m1.2.3.cmml"><msub id="S4.SS3.p1.1.m1.2.3.2" xref="S4.SS3.p1.1.m1.2.3.2.cmml"><mi id="S4.SS3.p1.1.m1.2.3.2.2" xref="S4.SS3.p1.1.m1.2.3.2.2.cmml">S</mi><mrow id="S4.SS3.p1.1.m1.2.3.2.3" xref="S4.SS3.p1.1.m1.2.3.2.3.cmml"><mi id="S4.SS3.p1.1.m1.2.3.2.3.2" xref="S4.SS3.p1.1.m1.2.3.2.3.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.1.m1.2.3.2.3.1" xref="S4.SS3.p1.1.m1.2.3.2.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.1.m1.2.3.2.3.3" xref="S4.SS3.p1.1.m1.2.3.2.3.3.cmml">p</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p1.1.m1.2.3.1" xref="S4.SS3.p1.1.m1.2.3.1.cmml">â€‹</mo><mrow id="S4.SS3.p1.1.m1.2.3.3.2" xref="S4.SS3.p1.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S4.SS3.p1.1.m1.2.3.3.2.1" xref="S4.SS3.p1.1.m1.2.3.3.1.cmml">(</mo><mi id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">q</mi><mo id="S4.SS3.p1.1.m1.2.3.3.2.2" xref="S4.SS3.p1.1.m1.2.3.3.1.cmml">,</mo><mi id="S4.SS3.p1.1.m1.2.2" xref="S4.SS3.p1.1.m1.2.2.cmml">p</mi><mo stretchy="false" id="S4.SS3.p1.1.m1.2.3.3.2.3" xref="S4.SS3.p1.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.2b"><apply id="S4.SS3.p1.1.m1.2.3.cmml" xref="S4.SS3.p1.1.m1.2.3"><times id="S4.SS3.p1.1.m1.2.3.1.cmml" xref="S4.SS3.p1.1.m1.2.3.1"></times><apply id="S4.SS3.p1.1.m1.2.3.2.cmml" xref="S4.SS3.p1.1.m1.2.3.2"><csymbol cd="ambiguous" id="S4.SS3.p1.1.m1.2.3.2.1.cmml" xref="S4.SS3.p1.1.m1.2.3.2">subscript</csymbol><ci id="S4.SS3.p1.1.m1.2.3.2.2.cmml" xref="S4.SS3.p1.1.m1.2.3.2.2">ğ‘†</ci><apply id="S4.SS3.p1.1.m1.2.3.2.3.cmml" xref="S4.SS3.p1.1.m1.2.3.2.3"><times id="S4.SS3.p1.1.m1.2.3.2.3.1.cmml" xref="S4.SS3.p1.1.m1.2.3.2.3.1"></times><ci id="S4.SS3.p1.1.m1.2.3.2.3.2.cmml" xref="S4.SS3.p1.1.m1.2.3.2.3.2">ğ‘</ci><ci id="S4.SS3.p1.1.m1.2.3.2.3.3.cmml" xref="S4.SS3.p1.1.m1.2.3.2.3.3">ğ‘</ci></apply></apply><interval closure="open" id="S4.SS3.p1.1.m1.2.3.3.1.cmml" xref="S4.SS3.p1.1.m1.2.3.3.2"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">ğ‘</ci><ci id="S4.SS3.p1.1.m1.2.2.cmml" xref="S4.SS3.p1.1.m1.2.2">ğ‘</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.2c">S_{qp}(q,p)</annotation></semantics></math> and the entity focusing score <math id="S4.SS3.p1.2.m2.3" class="ltx_Math" alttext="S_{qpe}(q,p,\mathcal{E})" display="inline"><semantics id="S4.SS3.p1.2.m2.3a"><mrow id="S4.SS3.p1.2.m2.3.4" xref="S4.SS3.p1.2.m2.3.4.cmml"><msub id="S4.SS3.p1.2.m2.3.4.2" xref="S4.SS3.p1.2.m2.3.4.2.cmml"><mi id="S4.SS3.p1.2.m2.3.4.2.2" xref="S4.SS3.p1.2.m2.3.4.2.2.cmml">S</mi><mrow id="S4.SS3.p1.2.m2.3.4.2.3" xref="S4.SS3.p1.2.m2.3.4.2.3.cmml"><mi id="S4.SS3.p1.2.m2.3.4.2.3.2" xref="S4.SS3.p1.2.m2.3.4.2.3.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.3.4.2.3.1" xref="S4.SS3.p1.2.m2.3.4.2.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.3.4.2.3.3" xref="S4.SS3.p1.2.m2.3.4.2.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.3.4.2.3.1a" xref="S4.SS3.p1.2.m2.3.4.2.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.3.4.2.3.4" xref="S4.SS3.p1.2.m2.3.4.2.3.4.cmml">e</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.3.4.1" xref="S4.SS3.p1.2.m2.3.4.1.cmml">â€‹</mo><mrow id="S4.SS3.p1.2.m2.3.4.3.2" xref="S4.SS3.p1.2.m2.3.4.3.1.cmml"><mo stretchy="false" id="S4.SS3.p1.2.m2.3.4.3.2.1" xref="S4.SS3.p1.2.m2.3.4.3.1.cmml">(</mo><mi id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">q</mi><mo id="S4.SS3.p1.2.m2.3.4.3.2.2" xref="S4.SS3.p1.2.m2.3.4.3.1.cmml">,</mo><mi id="S4.SS3.p1.2.m2.2.2" xref="S4.SS3.p1.2.m2.2.2.cmml">p</mi><mo id="S4.SS3.p1.2.m2.3.4.3.2.3" xref="S4.SS3.p1.2.m2.3.4.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p1.2.m2.3.3" xref="S4.SS3.p1.2.m2.3.3.cmml">â„°</mi><mo stretchy="false" id="S4.SS3.p1.2.m2.3.4.3.2.4" xref="S4.SS3.p1.2.m2.3.4.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.3b"><apply id="S4.SS3.p1.2.m2.3.4.cmml" xref="S4.SS3.p1.2.m2.3.4"><times id="S4.SS3.p1.2.m2.3.4.1.cmml" xref="S4.SS3.p1.2.m2.3.4.1"></times><apply id="S4.SS3.p1.2.m2.3.4.2.cmml" xref="S4.SS3.p1.2.m2.3.4.2"><csymbol cd="ambiguous" id="S4.SS3.p1.2.m2.3.4.2.1.cmml" xref="S4.SS3.p1.2.m2.3.4.2">subscript</csymbol><ci id="S4.SS3.p1.2.m2.3.4.2.2.cmml" xref="S4.SS3.p1.2.m2.3.4.2.2">ğ‘†</ci><apply id="S4.SS3.p1.2.m2.3.4.2.3.cmml" xref="S4.SS3.p1.2.m2.3.4.2.3"><times id="S4.SS3.p1.2.m2.3.4.2.3.1.cmml" xref="S4.SS3.p1.2.m2.3.4.2.3.1"></times><ci id="S4.SS3.p1.2.m2.3.4.2.3.2.cmml" xref="S4.SS3.p1.2.m2.3.4.2.3.2">ğ‘</ci><ci id="S4.SS3.p1.2.m2.3.4.2.3.3.cmml" xref="S4.SS3.p1.2.m2.3.4.2.3.3">ğ‘</ci><ci id="S4.SS3.p1.2.m2.3.4.2.3.4.cmml" xref="S4.SS3.p1.2.m2.3.4.2.3.4">ğ‘’</ci></apply></apply><vector id="S4.SS3.p1.2.m2.3.4.3.1.cmml" xref="S4.SS3.p1.2.m2.3.4.3.2"><ci id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">ğ‘</ci><ci id="S4.SS3.p1.2.m2.2.2.cmml" xref="S4.SS3.p1.2.m2.2.2">ğ‘</ci><ci id="S4.SS3.p1.2.m2.3.3.cmml" xref="S4.SS3.p1.2.m2.3.3">â„°</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.3c">S_{qpe}(q,p,\mathcal{E})</annotation></semantics></math> of the positive passage given the negatives identified above. In addition, we regard the oracle entities, defined in Sec.Â <a href="#S3.SS3" title="3.3 Oracle Critical Entity Detection â€£ 3 Entity Set Construction â€£ Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>, as positive entities and others as negative entities. We use binary cross-entropy loss to supervise the importance score <math id="S4.SS3.p1.3.m3.2" class="ltx_Math" alttext="S_{qe}(q,e)" display="inline"><semantics id="S4.SS3.p1.3.m3.2a"><mrow id="S4.SS3.p1.3.m3.2.3" xref="S4.SS3.p1.3.m3.2.3.cmml"><msub id="S4.SS3.p1.3.m3.2.3.2" xref="S4.SS3.p1.3.m3.2.3.2.cmml"><mi id="S4.SS3.p1.3.m3.2.3.2.2" xref="S4.SS3.p1.3.m3.2.3.2.2.cmml">S</mi><mrow id="S4.SS3.p1.3.m3.2.3.2.3" xref="S4.SS3.p1.3.m3.2.3.2.3.cmml"><mi id="S4.SS3.p1.3.m3.2.3.2.3.2" xref="S4.SS3.p1.3.m3.2.3.2.3.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m3.2.3.2.3.1" xref="S4.SS3.p1.3.m3.2.3.2.3.1.cmml">â€‹</mo><mi id="S4.SS3.p1.3.m3.2.3.2.3.3" xref="S4.SS3.p1.3.m3.2.3.2.3.3.cmml">e</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m3.2.3.1" xref="S4.SS3.p1.3.m3.2.3.1.cmml">â€‹</mo><mrow id="S4.SS3.p1.3.m3.2.3.3.2" xref="S4.SS3.p1.3.m3.2.3.3.1.cmml"><mo stretchy="false" id="S4.SS3.p1.3.m3.2.3.3.2.1" xref="S4.SS3.p1.3.m3.2.3.3.1.cmml">(</mo><mi id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml">q</mi><mo id="S4.SS3.p1.3.m3.2.3.3.2.2" xref="S4.SS3.p1.3.m3.2.3.3.1.cmml">,</mo><mi id="S4.SS3.p1.3.m3.2.2" xref="S4.SS3.p1.3.m3.2.2.cmml">e</mi><mo stretchy="false" id="S4.SS3.p1.3.m3.2.3.3.2.3" xref="S4.SS3.p1.3.m3.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.2b"><apply id="S4.SS3.p1.3.m3.2.3.cmml" xref="S4.SS3.p1.3.m3.2.3"><times id="S4.SS3.p1.3.m3.2.3.1.cmml" xref="S4.SS3.p1.3.m3.2.3.1"></times><apply id="S4.SS3.p1.3.m3.2.3.2.cmml" xref="S4.SS3.p1.3.m3.2.3.2"><csymbol cd="ambiguous" id="S4.SS3.p1.3.m3.2.3.2.1.cmml" xref="S4.SS3.p1.3.m3.2.3.2">subscript</csymbol><ci id="S4.SS3.p1.3.m3.2.3.2.2.cmml" xref="S4.SS3.p1.3.m3.2.3.2.2">ğ‘†</ci><apply id="S4.SS3.p1.3.m3.2.3.2.3.cmml" xref="S4.SS3.p1.3.m3.2.3.2.3"><times id="S4.SS3.p1.3.m3.2.3.2.3.1.cmml" xref="S4.SS3.p1.3.m3.2.3.2.3.1"></times><ci id="S4.SS3.p1.3.m3.2.3.2.3.2.cmml" xref="S4.SS3.p1.3.m3.2.3.2.3.2">ğ‘</ci><ci id="S4.SS3.p1.3.m3.2.3.2.3.3.cmml" xref="S4.SS3.p1.3.m3.2.3.2.3.3">ğ‘’</ci></apply></apply><interval closure="open" id="S4.SS3.p1.3.m3.2.3.3.1.cmml" xref="S4.SS3.p1.3.m3.2.3.3.2"><ci id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">ğ‘</ci><ci id="S4.SS3.p1.3.m3.2.2.cmml" xref="S4.SS3.p1.3.m3.2.2">ğ‘’</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.2c">S_{qe}(q,e)</annotation></semantics></math>.
We use AdamW <cite class="ltx_cite ltx_citemacro_cite">Loshchilov and Hutter (<a href="#bib.bib21" title="" class="ltx_ref">2018</a>)</cite> with a learning rate of 1e-5 to train the EnFoRe model for 8 epochs where 10% of the iterations are used to warm up the model linearly. The batch size is set to 6 per GPU, and we use 4 GPUs (Tesla V100) for each experiment. The training process takes about 45 hours for each model. We save the parameters every 5000 steps and present the best results (MRR@5) on the validation set. The hidden states size is set to 768 following <cite class="ltx_cite ltx_citemacro_citet">Qu etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite> for fair comparison. The threshold <math id="S4.SS3.p1.4.m4.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S4.SS3.p1.4.m4.1a"><mi id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><ci id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">\theta</annotation></semantics></math> for recognizing critical entities is set to 0.8. As our model consists of a BERT encoder and a LXMERT encoder, resulting in 430M parameters in total.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para ltx_noindent">
<p id="S4.SS3.p2.1" class="ltx_p"><span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_bold">Inference:</span> As the question relevancy term is decomposable, we again adopt MIPS to retrieve the top-80 passages. Then, we evaluate the entity focus term for each passage and use the combined score <math id="S4.SS3.p2.1.m1.2" class="ltx_Math" alttext="S(q,p)" display="inline"><semantics id="S4.SS3.p2.1.m1.2a"><mrow id="S4.SS3.p2.1.m1.2.3" xref="S4.SS3.p2.1.m1.2.3.cmml"><mi id="S4.SS3.p2.1.m1.2.3.2" xref="S4.SS3.p2.1.m1.2.3.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.1.m1.2.3.1" xref="S4.SS3.p2.1.m1.2.3.1.cmml">â€‹</mo><mrow id="S4.SS3.p2.1.m1.2.3.3.2" xref="S4.SS3.p2.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S4.SS3.p2.1.m1.2.3.3.2.1" xref="S4.SS3.p2.1.m1.2.3.3.1.cmml">(</mo><mi id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">q</mi><mo id="S4.SS3.p2.1.m1.2.3.3.2.2" xref="S4.SS3.p2.1.m1.2.3.3.1.cmml">,</mo><mi id="S4.SS3.p2.1.m1.2.2" xref="S4.SS3.p2.1.m1.2.2.cmml">p</mi><mo stretchy="false" id="S4.SS3.p2.1.m1.2.3.3.2.3" xref="S4.SS3.p2.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.2b"><apply id="S4.SS3.p2.1.m1.2.3.cmml" xref="S4.SS3.p2.1.m1.2.3"><times id="S4.SS3.p2.1.m1.2.3.1.cmml" xref="S4.SS3.p2.1.m1.2.3.1"></times><ci id="S4.SS3.p2.1.m1.2.3.2.cmml" xref="S4.SS3.p2.1.m1.2.3.2">ğ‘†</ci><interval closure="open" id="S4.SS3.p2.1.m1.2.3.3.1.cmml" xref="S4.SS3.p2.1.m1.2.3.3.2"><ci id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">ğ‘</ci><ci id="S4.SS3.p2.1.m1.2.2.cmml" xref="S4.SS3.p2.1.m1.2.2">ğ‘</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.2c">S(q,p)</annotation></semantics></math> to rerank the retrieved passages.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Reader</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We employ the current state-of-the-art KAT model <cite class="ltx_cite ltx_citemacro_cite">Gui etÂ al. (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite> as our VQA reader. KAT is a generation-based reader that learns to generate the answer given the retrieved knowledge. It adopts an FiD <cite class="ltx_cite ltx_citemacro_cite">Izacard and Grave (<a href="#bib.bib13" title="" class="ltx_ref">2021</a>)</cite> architecture to incorporate both implicit knowledge, generated by a frozen GPT-3 model, and explicit knowledge. For implicit GPT-3 knowledge, the input format is â€œ<span id="S5.p1.1.1" class="ltx_text ltx_font_typewriter">question:ques?candidate:cand.</span> <span id="S5.p1.1.2" class="ltx_text ltx_font_typewriter">evidence:expl.</span>â€, where the <span id="S5.p1.1.3" class="ltx_text ltx_font_typewriter">ques</span>, <span id="S5.p1.1.4" class="ltx_text ltx_font_typewriter">cand</span> and <span id="S5.p1.1.5" class="ltx_text ltx_font_typewriter">expl.</span> denotes the question, answer and its explanation generated by the GPT-3 model <cite class="ltx_cite ltx_citemacro_cite">Brown etÂ al. (<a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite>. For the explicit knowledge, the input format is â€œ<span id="S5.p1.1.6" class="ltx_text ltx_font_typewriter">question:ques?</span> <span id="S5.p1.1.7" class="ltx_text ltx_font_typewriter">entity:ent.</span> <span id="S5.p1.1.8" class="ltx_text ltx_font_typewriter">description:desc.</span>â€, where <span id="S5.p1.1.9" class="ltx_text ltx_font_typewriter">ent</span>, <span id="S5.p1.1.10" class="ltx_text ltx_font_typewriter">desc</span> denote the retrieved entity and its description. See <cite class="ltx_cite ltx_citemacro_cite">Gui etÂ al. (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite> for further details.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<table id="S5.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T2.1.1.1" class="ltx_tr">
<td id="S5.T2.1.1.1.1" class="ltx_td ltx_border_r ltx_border_tt"></td>
<td id="S5.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3">Image-based entities</td>
<td id="S5.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3">Question-Image-based entities</td>
<td id="S5.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MRR@5</td>
<td id="S5.T2.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">P@5</td>
</tr>
<tr id="S5.T2.1.2.2" class="ltx_tr">
<td id="S5.T2.1.2.2.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T2.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">Tags</td>
<td id="S5.T2.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">Wikidata</td>
<td id="S5.T2.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Cap.</td>
<td id="S5.T2.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t">Ques.</td>
<td id="S5.T2.1.2.2.6" class="ltx_td ltx_align_center ltx_border_t">Sub-Ques.</td>
<td id="S5.T2.1.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Cand.</td>
<td id="S5.T2.1.2.2.8" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T2.1.2.2.9" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S5.T2.1.3.3" class="ltx_tr">
<td id="S5.T2.1.3.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">DPR-LXMERT</td>
<td id="S5.T2.1.3.3.2" class="ltx_td ltx_border_t"></td>
<td id="S5.T2.1.3.3.3" class="ltx_td ltx_border_t"></td>
<td id="S5.T2.1.3.3.4" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T2.1.3.3.5" class="ltx_td ltx_border_t"></td>
<td id="S5.T2.1.3.3.6" class="ltx_td ltx_border_t"></td>
<td id="S5.T2.1.3.3.7" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T2.1.3.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.4526</td>
<td id="S5.T2.1.3.3.9" class="ltx_td ltx_align_center ltx_border_t">0.3329</td>
</tr>
<tr id="S5.T2.1.4.4" class="ltx_tr">
<td id="S5.T2.1.4.4.1" class="ltx_td ltx_align_left ltx_border_r">EnFoRe (Backbone)</td>
<td id="S5.T2.1.4.4.2" class="ltx_td"></td>
<td id="S5.T2.1.4.4.3" class="ltx_td"></td>
<td id="S5.T2.1.4.4.4" class="ltx_td ltx_border_r"></td>
<td id="S5.T2.1.4.4.5" class="ltx_td"></td>
<td id="S5.T2.1.4.4.6" class="ltx_td"></td>
<td id="S5.T2.1.4.4.7" class="ltx_td ltx_border_r"></td>
<td id="S5.T2.1.4.4.8" class="ltx_td ltx_align_center ltx_border_r">0.4632</td>
<td id="S5.T2.1.4.4.9" class="ltx_td ltx_align_center">0.3317</td>
</tr>
<tr id="S5.T2.1.5.5" class="ltx_tr">
<td id="S5.T2.1.5.5.1" class="ltx_td ltx_align_left ltx_border_r">EnFoRe (Image)</td>
<td id="S5.T2.1.5.5.2" class="ltx_td ltx_align_center">âœ“</td>
<td id="S5.T2.1.5.5.3" class="ltx_td ltx_align_center">âœ“</td>
<td id="S5.T2.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">âœ“</td>
<td id="S5.T2.1.5.5.5" class="ltx_td"></td>
<td id="S5.T2.1.5.5.6" class="ltx_td"></td>
<td id="S5.T2.1.5.5.7" class="ltx_td ltx_border_r"></td>
<td id="S5.T2.1.5.5.8" class="ltx_td ltx_align_center ltx_border_r">0.4688</td>
<td id="S5.T2.1.5.5.9" class="ltx_td ltx_align_center">0.3351</td>
</tr>
<tr id="S5.T2.1.6.6" class="ltx_tr">
<td id="S5.T2.1.6.6.1" class="ltx_td ltx_align_left ltx_border_r">EnFoRe (Question)</td>
<td id="S5.T2.1.6.6.2" class="ltx_td"></td>
<td id="S5.T2.1.6.6.3" class="ltx_td"></td>
<td id="S5.T2.1.6.6.4" class="ltx_td ltx_border_r"></td>
<td id="S5.T2.1.6.6.5" class="ltx_td ltx_align_center">âœ“</td>
<td id="S5.T2.1.6.6.6" class="ltx_td ltx_align_center">âœ“</td>
<td id="S5.T2.1.6.6.7" class="ltx_td ltx_align_center ltx_border_r">âœ“</td>
<td id="S5.T2.1.6.6.8" class="ltx_td ltx_align_center ltx_border_r">0.4750</td>
<td id="S5.T2.1.6.6.9" class="ltx_td ltx_align_center">0.3409</td>
</tr>
<tr id="S5.T2.1.7.7" class="ltx_tr">
<td id="S5.T2.1.7.7.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">EnFoRe (Full)</td>
<td id="S5.T2.1.7.7.2" class="ltx_td ltx_align_center ltx_border_bb">âœ“</td>
<td id="S5.T2.1.7.7.3" class="ltx_td ltx_align_center ltx_border_bb">âœ“</td>
<td id="S5.T2.1.7.7.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">âœ“</td>
<td id="S5.T2.1.7.7.5" class="ltx_td ltx_align_center ltx_border_bb">âœ“</td>
<td id="S5.T2.1.7.7.6" class="ltx_td ltx_align_center ltx_border_bb">âœ“</td>
<td id="S5.T2.1.7.7.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">âœ“</td>
<td id="S5.T2.1.7.7.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">0.4800</td>
<td id="S5.T2.1.7.7.9" class="ltx_td ltx_align_center ltx_border_bb">0.3444</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Ablation study on the entity sources used during re-ranking.</figcaption>
</figure>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">We change the original explicit knowledge to the knowledge retrieved by our EnFoRe model. As the retrieved passage contains multiple sentences, and usually not all are relevant, we select the most relevant sentence for each passage. Specifically, following <cite class="ltx_cite ltx_citemacro_citet">Wu etÂ al. (<a href="#bib.bib43" title="" class="ltx_ref">2022</a>)</cite>, we convert the question and the candidate answers to a set of statements. Then, we decontextualize each sentence for each passage and compute the BertScore <cite class="ltx_cite ltx_citemacro_cite">Zhang* etÂ al. (<a href="#bib.bib46" title="" class="ltx_ref">2020</a>)</cite> between the decontextualized sentences and each statement. The sentence with the highest BertScore across these statements is extracted for each passage. The input format is â€œ<span id="S5.p2.1.1" class="ltx_text ltx_font_typewriter">question:ques?entity:ents.</span> <span id="S5.p2.1.2" class="ltx_text ltx_font_typewriter">description:desc.</span>â€, where the <span id="S5.p2.1.3" class="ltx_text ltx_font_typewriter">ents</span>, <span id="S5.p2.1.4" class="ltx_text ltx_font_typewriter">desc</span> denote the top-10 entities judged by the query-entity importance score <math id="S5.p2.1.m1.2" class="ltx_Math" alttext="S_{qe}(q,e)" display="inline"><semantics id="S5.p2.1.m1.2a"><mrow id="S5.p2.1.m1.2.3" xref="S5.p2.1.m1.2.3.cmml"><msub id="S5.p2.1.m1.2.3.2" xref="S5.p2.1.m1.2.3.2.cmml"><mi id="S5.p2.1.m1.2.3.2.2" xref="S5.p2.1.m1.2.3.2.2.cmml">S</mi><mrow id="S5.p2.1.m1.2.3.2.3" xref="S5.p2.1.m1.2.3.2.3.cmml"><mi id="S5.p2.1.m1.2.3.2.3.2" xref="S5.p2.1.m1.2.3.2.3.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S5.p2.1.m1.2.3.2.3.1" xref="S5.p2.1.m1.2.3.2.3.1.cmml">â€‹</mo><mi id="S5.p2.1.m1.2.3.2.3.3" xref="S5.p2.1.m1.2.3.2.3.3.cmml">e</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S5.p2.1.m1.2.3.1" xref="S5.p2.1.m1.2.3.1.cmml">â€‹</mo><mrow id="S5.p2.1.m1.2.3.3.2" xref="S5.p2.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S5.p2.1.m1.2.3.3.2.1" xref="S5.p2.1.m1.2.3.3.1.cmml">(</mo><mi id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml">q</mi><mo id="S5.p2.1.m1.2.3.3.2.2" xref="S5.p2.1.m1.2.3.3.1.cmml">,</mo><mi id="S5.p2.1.m1.2.2" xref="S5.p2.1.m1.2.2.cmml">e</mi><mo stretchy="false" id="S5.p2.1.m1.2.3.3.2.3" xref="S5.p2.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.2b"><apply id="S5.p2.1.m1.2.3.cmml" xref="S5.p2.1.m1.2.3"><times id="S5.p2.1.m1.2.3.1.cmml" xref="S5.p2.1.m1.2.3.1"></times><apply id="S5.p2.1.m1.2.3.2.cmml" xref="S5.p2.1.m1.2.3.2"><csymbol cd="ambiguous" id="S5.p2.1.m1.2.3.2.1.cmml" xref="S5.p2.1.m1.2.3.2">subscript</csymbol><ci id="S5.p2.1.m1.2.3.2.2.cmml" xref="S5.p2.1.m1.2.3.2.2">ğ‘†</ci><apply id="S5.p2.1.m1.2.3.2.3.cmml" xref="S5.p2.1.m1.2.3.2.3"><times id="S5.p2.1.m1.2.3.2.3.1.cmml" xref="S5.p2.1.m1.2.3.2.3.1"></times><ci id="S5.p2.1.m1.2.3.2.3.2.cmml" xref="S5.p2.1.m1.2.3.2.3.2">ğ‘</ci><ci id="S5.p2.1.m1.2.3.2.3.3.cmml" xref="S5.p2.1.m1.2.3.2.3.3">ğ‘’</ci></apply></apply><interval closure="open" id="S5.p2.1.m1.2.3.3.1.cmml" xref="S5.p2.1.m1.2.3.3.2"><ci id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1">ğ‘</ci><ci id="S5.p2.1.m1.2.2.cmml" xref="S5.p2.1.m1.2.2">ğ‘’</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.2c">S_{qe}(q,e)</annotation></semantics></math> and the extracted sentence.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">Following <cite class="ltx_cite ltx_citemacro_citet">Gui etÂ al. (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite>, we perform experiments for two KAT settings: (1) â€œKAT-base + EnFoReâ€ setting is a single model that employs T5-base <cite class="ltx_cite ltx_citemacro_cite">Raffel etÂ al. (<a href="#bib.bib32" title="" class="ltx_ref">2020</a>)</cite> as the backbone encoder and decoder. (2) â€œKAT-full + EnFoReâ€ is an ensemble model, where each model employs T5-large as the backbone encoder and decoder. As our knowledge is question-aware, we only encode the top 10 retrieved sentences in contrast to the 40 sentences in the original KAT. We adopt the same training scheme as KAT.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Experimental Results</h2>

<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Dataset</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">We use the OK-VQA dataset<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://okvqa.allenai.org/</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Marino etÂ al. (<a href="#bib.bib27" title="" class="ltx_ref">2019</a>)</cite> (version 1.1), the largest open-domain English knowledge-based VQA dataset at present, to evaluate the EnFoRe model. The questions were crowd-sourced on Amazon Mechanical Turk (AMT) and are guaranteed to require external knowledge beyond the images. The dataset contains 14,031 images and 14,055 questions covering a variety of knowledge categories (i.e. 9,009 for training and 5046 for test). For knowledge retrieval, we adopt the same data configuration as <cite class="ltx_cite ltx_citemacro_citet">Qu etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite> that evenly splits the test set of the OK-VQA dataset into a validation set and a test set, and we refer to these as RetVal and RetTest, respectively.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">Following <cite class="ltx_cite ltx_citemacro_citet">Qu etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite>, we take the Wikipedia passage collection with 11 million passages created by previous work as our knowledge source, where each passage contains at most 384 â€œword piecesâ€ with intact sentence boundaries. We extract 25 passages with the highest BM 25 scores (CombSum setting in <cite class="ltx_cite ltx_citemacro_cite">Qu etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite>) that do not contain the correct answers
as our retrieved negative samples, and the top 5 passages that contain the correct answer as retrieved positive samples for training. In addition, we also consider the most relevant passage that contains each of the oracle entities and the correct answer as positive passages. The positive and negative passages are randomly paired up to form the training instances. During evaluation, any passages containing at least one of the correct answers are considered as gold passages.
For VQA models, we adopt the same model architecture and training scheme and only switch the external knowledge for the KAT models. Due to limits on computational resources, we adopt 10 retrieved sentences for the KAT model. The models are evaluated every 500 steps. We normalize the predictions by lowercasing, lemmatizing, and removing articles, punctuation and duplicated whitespace. We follow the standard evaluation metric recommended by the VQA challenge.<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://github.com/GT-Vision-Lab/VQA</span></span></span> The results for â€œKAT-base + EnFoReâ€ are obtained by averaging three runs with different random seeds.</p>
</div>
<figure id="S6.T3" class="ltx_table">
<table id="S6.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T3.1.1.1" class="ltx_tr">
<th id="S6.T3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt"><span id="S6.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<td id="S6.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S6.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">Knowledge Resources</span></td>
<td id="S6.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S6.T3.1.1.1.3.1" class="ltx_text ltx_font_bold">VQA Scores</span></td>
</tr>
<tr id="S6.T3.1.2.2" class="ltx_tr">
<th id="S6.T3.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Q-only <cite class="ltx_cite ltx_citemacro_cite">Marino etÂ al. (<a href="#bib.bib27" title="" class="ltx_ref">2019</a>)</cite>
</th>
<td id="S6.T3.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">â€”</td>
<td id="S6.T3.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">14.9</td>
</tr>
<tr id="S6.T3.1.3.3" class="ltx_tr">
<th id="S6.T3.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">BAN <cite class="ltx_cite ltx_citemacro_cite">Kim etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2018</a>)</cite>
</th>
<td id="S6.T3.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r">â€”</td>
<td id="S6.T3.1.3.3.3" class="ltx_td ltx_align_center">25.2</td>
</tr>
<tr id="S6.T3.1.4.4" class="ltx_tr">
<th id="S6.T3.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">MUTAN <cite class="ltx_cite ltx_citemacro_cite">Ben-Younes etÂ al. (<a href="#bib.bib3" title="" class="ltx_ref">2017</a>)</cite>
</th>
<td id="S6.T3.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r">â€”</td>
<td id="S6.T3.1.4.4.3" class="ltx_td ltx_align_center">26.4</td>
</tr>
<tr id="S6.T3.1.5.5" class="ltx_tr">
<th id="S6.T3.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Mucko <cite class="ltx_cite ltx_citemacro_cite">Zhu etÂ al. (<a href="#bib.bib47" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S6.T3.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r">Dense Caption</td>
<td id="S6.T3.1.5.5.3" class="ltx_td ltx_align_center">29.2</td>
</tr>
<tr id="S6.T3.1.6.6" class="ltx_tr">
<th id="S6.T3.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ConceptBert <cite class="ltx_cite ltx_citemacro_cite">GardÃ¨res etÂ al. (<a href="#bib.bib7" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S6.T3.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r">ConceptNet</td>
<td id="S6.T3.1.6.6.3" class="ltx_td ltx_align_center">33.7</td>
</tr>
<tr id="S6.T3.1.7.7" class="ltx_tr">
<th id="S6.T3.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">KRISP <cite class="ltx_cite ltx_citemacro_cite">Marino etÂ al. (<a href="#bib.bib26" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S6.T3.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r">Wikipedia + ConceptNet</td>
<td id="S6.T3.1.7.7.3" class="ltx_td ltx_align_center">38.9</td>
</tr>
<tr id="S6.T3.1.8.8" class="ltx_tr">
<th id="S6.T3.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">MAVEx <cite class="ltx_cite ltx_citemacro_cite">Wu etÂ al. (<a href="#bib.bib43" title="" class="ltx_ref">2022</a>)</cite>
</th>
<td id="S6.T3.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r">Wikipedia +ConceptNet + Google Image</td>
<td id="S6.T3.1.8.8.3" class="ltx_td ltx_align_center">39.4</td>
</tr>
<tr id="S6.T3.1.9.9" class="ltx_tr">
<th id="S6.T3.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">RVL <cite class="ltx_cite ltx_citemacro_cite">Shevchenko etÂ al. (<a href="#bib.bib34" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S6.T3.1.9.9.2" class="ltx_td ltx_align_center ltx_border_r">Wikipedia + ConceptNet</td>
<td id="S6.T3.1.9.9.3" class="ltx_td ltx_align_center">39.0</td>
</tr>
<tr id="S6.T3.1.10.10" class="ltx_tr">
<th id="S6.T3.1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">VRR <cite class="ltx_cite ltx_citemacro_cite">Luo etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S6.T3.1.10.10.2" class="ltx_td ltx_align_center ltx_border_r">Google Search</td>
<td id="S6.T3.1.10.10.3" class="ltx_td ltx_align_center">39.2</td>
</tr>
<tr id="S6.T3.1.11.11" class="ltx_tr">
<th id="S6.T3.1.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">PICa <cite class="ltx_cite ltx_citemacro_cite">Yang etÂ al. (<a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite>
</th>
<td id="S6.T3.1.11.11.2" class="ltx_td ltx_align_center ltx_border_r">Frozen GPT-3</td>
<td id="S6.T3.1.11.11.3" class="ltx_td ltx_align_center">48.0</td>
</tr>
<tr id="S6.T3.1.12.12" class="ltx_tr">
<th id="S6.T3.1.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">KAT-base</th>
<td id="S6.T3.1.12.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Frozen GPT3 + Wikidata</td>
<td id="S6.T3.1.12.12.3" class="ltx_td ltx_align_center ltx_border_t">(50.58)</td>
</tr>
<tr id="S6.T3.1.13.13" class="ltx_tr">
<th id="S6.T3.1.13.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">KAT-base + EnFoRe</th>
<td id="S6.T3.1.13.13.2" class="ltx_td ltx_align_center ltx_border_r">Frozen GPT3 + Wikipedia</td>
<td id="S6.T3.1.13.13.3" class="ltx_td ltx_align_center">51.34 (52.24)</td>
</tr>
<tr id="S6.T3.1.14.14" class="ltx_tr">
<th id="S6.T3.1.14.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">KAT-full</th>
<td id="S6.T3.1.14.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Frozen GPT3 + Wikidata</td>
<td id="S6.T3.1.14.14.3" class="ltx_td ltx_align_center ltx_border_t">(54.41)</td>
</tr>
<tr id="S6.T3.1.15.15" class="ltx_tr">
<th id="S6.T3.1.15.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">KAT-full + EnFoRe</th>
<td id="S6.T3.1.15.15.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">Frozen GPT3 + Wikipedia</td>
<td id="S6.T3.1.15.15.3" class="ltx_td ltx_align_center ltx_border_bb">54.35 (55.23)</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>EnFoRe knowledge boosts the current state-of-the-art approaches on OK-VQA. The middle column lists the external knowledge sources if any, used in each system. The additional result shown in parentheses is computed by an unofficial evaluation metric
that takes the max over 1.0 and number of annotators agreements divided by 3.</figcaption>
</figure>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Passage Retrieval Results</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">We present our passage retriever results in Table <a href="#S4.T1" title="Table 1 â€£ 4.2 Retrieval Scores â€£ 4 Entity-Focused Retrieval â€£ Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, comparing them with the current state-of-the-art systems. We adopt MRR and Precision at a cut-off of 5 as our automatic evaluation metric. The first four rows present sparse retrieval results. The BM25 approach using our oracle entities achieves an MRR@5 of 0.6401, and a precision@5 of 0.4345 on the OK-VQA RetTest set, indicating the comprehensiveness and the potential helpfulness of the extracted entities. With the help of these entities, EnFoRe-LXMERT outperforms the previous SOTA DPR-LXMERT (with the same architecture for visual and textual embedding) by 2.74% MRR@5 and 1.15% precision@5.
We perform a studentâ€™s paired t-tests with a p-value of 5% to test the significance of our results. In particular, we found that the MRR and the precision gap between our EnFoRe (Full) model and (1) the DPR-LXMERT and (2) the EnFoRe (Backbone) are statistically significant.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para ltx_noindent">
<p id="S6.SS2.p2.1" class="ltx_p"><span id="S6.SS2.p2.1.1" class="ltx_text ltx_font_bold">Ablation study on entity sources:</span>
We also performed an ablation study on entity-based re-ranking shown in Table <a href="#S5.T2" title="Table 2 â€£ 5 Reader â€£ Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The EnFoRe backbone without re-ranking achieves an MRR of 0.4632, outperforming DPR <cite class="ltx_cite ltx_citemacro_cite">Qu etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite> by 1.06%. This indicates that using our entities during training helps the retriever build better representations. It is because (1) we add additional supervision that tells the retriever which entities are more likely to lead to the correct answers, and (2) we add additional training passages that contain both the oracle entities and the right answers. Image-based and Question-based entities help our EnFoRe model achieve MRR of 0.4688 and 0.4750, respectively. Our full model, taking advantage of both image- and question-based entities, achieves an MRR of 0.4800, showing that these two types of entities are complementary.</p>
</div>
<figure id="S6.F3" class="ltx_figure"><img src="/html/2210.10176/assets/x3.png" id="S6.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="332" height="85" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Qualitative results on EnFoRe; (a)-(d) present cases where EnFoRe correctly identifies the critical entities and retrieved question-relevant knowledge properly focuses on them; (e) and (f) present two failure cases.</figcaption>
</figure>
<figure id="S6.T4" class="ltx_table">
<table id="S6.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T4.1.1.1" class="ltx_tr">
<th id="S6.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span id="S6.T4.1.1.1.1.1" class="ltx_text">Sources</span></th>
<td id="S6.T4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">RetTest</td>
<td id="S6.T4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">RetTest Hard</td>
</tr>
<tr id="S6.T4.1.2.2" class="ltx_tr">
<td id="S6.T4.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MRR@5</td>
<td id="S6.T4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">P@5</td>
<td id="S6.T4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MRR@5</td>
<td id="S6.T4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">P@5</td>
</tr>
<tr id="S6.T4.1.3.3" class="ltx_tr">
<th id="S6.T4.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">None</th>
<td id="S6.T4.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.4632</td>
<td id="S6.T4.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.3329</td>
<td id="S6.T4.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.2525</td>
<td id="S6.T4.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t">0.1553</td>
</tr>
<tr id="S6.T4.1.4.4" class="ltx_tr">
<th id="S6.T4.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Image-based entities</th>
<td id="S6.T4.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r">0.4688</td>
<td id="S6.T4.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r">0.3351</td>
<td id="S6.T4.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T4.1.4.4.4.1" class="ltx_text ltx_font_bold">0.2709</span></td>
<td id="S6.T4.1.4.4.5" class="ltx_td ltx_align_center"><span id="S6.T4.1.4.4.5.1" class="ltx_text ltx_font_bold">0.1637</span></td>
</tr>
<tr id="S6.T4.1.5.5" class="ltx_tr">
<th id="S6.T4.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Question-based entities</th>
<td id="S6.T4.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r">0.4750</td>
<td id="S6.T4.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r">0.3409</td>
<td id="S6.T4.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">0.2594</td>
<td id="S6.T4.1.5.5.5" class="ltx_td ltx_align_center">0.1612</td>
</tr>
<tr id="S6.T4.1.6.6" class="ltx_tr">
<th id="S6.T4.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Full</th>
<td id="S6.T4.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T4.1.6.6.2.1" class="ltx_text ltx_font_bold">0.4800</span></td>
<td id="S6.T4.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r">0.3444</td>
<td id="S6.T4.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r">0.2643</td>
<td id="S6.T4.1.6.6.5" class="ltx_td ltx_align_center">0.1632</td>
</tr>
<tr id="S6.T4.1.7.7" class="ltx_tr">
<th id="S6.T4.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt">w/o. Tags</th>
<td id="S6.T4.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.4788</td>
<td id="S6.T4.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.3410</td>
<td id="S6.T4.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.2624</td>
<td id="S6.T4.1.7.7.5" class="ltx_td ltx_align_center ltx_border_tt">0.1606</td>
</tr>
<tr id="S6.T4.1.8.8" class="ltx_tr">
<th id="S6.T4.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">w/o. Wikidata</th>
<td id="S6.T4.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r">0.4775</td>
<td id="S6.T4.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r">0.3429</td>
<td id="S6.T4.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r">0.2617</td>
<td id="S6.T4.1.8.8.5" class="ltx_td ltx_align_center">0.1574</td>
</tr>
<tr id="S6.T4.1.9.9" class="ltx_tr">
<th id="S6.T4.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">w/o. Caption</th>
<td id="S6.T4.1.9.9.2" class="ltx_td ltx_align_center ltx_border_r">0.4794</td>
<td id="S6.T4.1.9.9.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T4.1.9.9.3.1" class="ltx_text ltx_font_bold">0.3449</span></td>
<td id="S6.T4.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r">0.2626</td>
<td id="S6.T4.1.9.9.5" class="ltx_td ltx_align_center">0.1611</td>
</tr>
<tr id="S6.T4.1.10.10" class="ltx_tr">
<th id="S6.T4.1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">w/o. Question</th>
<td id="S6.T4.1.10.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.4786</td>
<td id="S6.T4.1.10.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.3442</td>
<td id="S6.T4.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.2647</td>
<td id="S6.T4.1.10.10.5" class="ltx_td ltx_align_center ltx_border_t">0.1627</td>
</tr>
<tr id="S6.T4.1.11.11" class="ltx_tr">
<th id="S6.T4.1.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">w/o. Sub-Question</th>
<td id="S6.T4.1.11.11.2" class="ltx_td ltx_align_center ltx_border_r">0.4784</td>
<td id="S6.T4.1.11.11.3" class="ltx_td ltx_align_center ltx_border_r">0.3411</td>
<td id="S6.T4.1.11.11.4" class="ltx_td ltx_align_center ltx_border_r">0.2625</td>
<td id="S6.T4.1.11.11.5" class="ltx_td ltx_align_center">0.1605</td>
</tr>
<tr id="S6.T4.1.12.12" class="ltx_tr">
<th id="S6.T4.1.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">w/o. Candidate</th>
<td id="S6.T4.1.12.12.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">0.4693</td>
<td id="S6.T4.1.12.12.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">0.3332</td>
<td id="S6.T4.1.12.12.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">0.2664</td>
<td id="S6.T4.1.12.12.5" class="ltx_td ltx_align_center ltx_border_bb">0.1622</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Ablation study on entity sources.</figcaption>
</figure>
<div id="S6.SS2.p3" class="ltx_para">
<p id="S6.SS2.p3.1" class="ltx_p">We also present an ablation study on individual entity sources in Table <a href="#S6.T4" title="Table 4 â€£ 6.2 Passage Retrieval Results â€£ 6 Experimental Results â€£ Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. We introduce a particularly challenging â€œRetTest Hardâ€ split that collects all of the examples in â€œRetTestâ€ where none of the correct answers is in the entity set. Our EnFoRe model consistently achieves better retrieval performance (i.e. MRR@5 and P@5) by incorporating entities extracted from each source. On the normal RetTest set, removing entities from candidate answers yields the largest decrease in MRR@5. This is due to the fact that the candidate answers cover plenty of correct answers in the OK-VQA test split and therefore provide direct hints to the desired content. On the RetTest Hard set, image-based entities generally help improve the retrieval performance more, indicating the need for explicitly discovering critical visual clues.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Visual Question Answering Results</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">We present the VQA performance of incorporating our EnFoRe knowledge in the state-of-the-art KAT model in Table <a href="#S6.T3" title="Table 3 â€£ 6.1 Dataset â€£ 6 Experimental Results â€£ Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. While a plain KAT-base model, which uses GPT-3 and CLIP <cite class="ltx_cite ltx_citemacro_cite">Radford etÂ al. (<a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite> to retrieve image-based knowledge, achieves a score of (50.58)<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>The additional result shown in parentheses is computed by an unofficial evaluation metric
that takes the max over 1.0 and number of annotators agreements divided by 3.
</span></span></span>, switching to our EnFoRe knowledge brings a 1.7 point improvements, achieving a score of 51.34 (52.24). Our ensemble model
(KAT-full + EnFoRe) achieves a new SOTA score of 54.35 (55.23).</p>
</div>
<div id="S6.SS3.p2" class="ltx_para ltx_noindent">
<p id="S6.SS3.p2.1" class="ltx_p"><span id="S6.SS3.p2.1.1" class="ltx_text ltx_font_bold">Qualitative results:</span> We present sample results in Figure <a href="#S6.F3" title="Figure 3 â€£ 6.2 Passage Retrieval Results â€£ 6 Experimental Results â€£ Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> where (a)â€“(d) show cases where our EnFoRe model correctly identifies the critical entities (<math id="S6.SS3.p2.1.m1.3" class="ltx_Math" alttext="i.e." display="inline"><semantics id="S6.SS3.p2.1.m1.3a"><mrow id="S6.SS3.p2.1.m1.3.3.1"><mrow id="S6.SS3.p2.1.m1.3.3.1.1.2" xref="S6.SS3.p2.1.m1.3.3.1.1.1.cmml"><mi id="S6.SS3.p2.1.m1.1.1" xref="S6.SS3.p2.1.m1.1.1.cmml">i</mi><mo lspace="0em" rspace="0.167em" id="S6.SS3.p2.1.m1.3.3.1.1.2.1" xref="S6.SS3.p2.1.m1.3.3.1.1.1a.cmml">.</mo><mi id="S6.SS3.p2.1.m1.2.2" xref="S6.SS3.p2.1.m1.2.2.cmml">e</mi></mrow><mo lspace="0em" id="S6.SS3.p2.1.m1.3.3.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p2.1.m1.3b"><apply id="S6.SS3.p2.1.m1.3.3.1.1.1.cmml" xref="S6.SS3.p2.1.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S6.SS3.p2.1.m1.3.3.1.1.1a.cmml" xref="S6.SS3.p2.1.m1.3.3.1.1.2.1">formulae-sequence</csymbol><ci id="S6.SS3.p2.1.m1.1.1.cmml" xref="S6.SS3.p2.1.m1.1.1">ğ‘–</ci><ci id="S6.SS3.p2.1.m1.2.2.cmml" xref="S6.SS3.p2.1.m1.2.2">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p2.1.m1.3c">i.e.</annotation></semantics></math> the orange, the kite, the calico cat, and the teddy bear) and retrieved question-relevant knowledge focused on them.
Case (e) shows an example where the retrieved sentence misleads the reader, because the reader currently only receives the textual input, and it fails to verify whether the pizza actually has a thin crust. Case (f) shows an example where the retriever properly focuses on the critical entity â€œNORWOODâ€ but fails to understand that this is the destination for the bus.</p>
</div>
<div id="S6.SS3.p3" class="ltx_para ltx_noindent">
<p id="S6.SS3.p3.2" class="ltx_p"><span id="S6.SS3.p3.2.1" class="ltx_text ltx_font_bold">Human evaluation:</span>
We also conducted a human evaluation on AMT of the retrieved entities and sentences to demonstrate that the knowledge retrieved by EnFoRe better supports the correct answers. We first randomly sampled 1,000 test questions that are correctly answered by both the original KAT-base model and our â€œKAT-base + EnFoReâ€ model. Next, we extracted the top-<math id="S6.SS3.p3.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.SS3.p3.1.m1.1a"><mn id="S6.SS3.p3.1.m1.1.1" xref="S6.SS3.p3.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS3.p3.1.m1.1b"><cn type="integer" id="S6.SS3.p3.1.m1.1.1.cmml" xref="S6.SS3.p3.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p3.1.m1.1c">3</annotation></semantics></math> sentences with the highest attention score averaged over all attention heads from the last decoder layer for both models. We also extracted the top-3 visual entities. For EnFoRe, the top-<math id="S6.SS3.p3.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.SS3.p3.2.m2.1a"><mn id="S6.SS3.p3.2.m2.1.1" xref="S6.SS3.p3.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS3.p3.2.m2.1b"><cn type="integer" id="S6.SS3.p3.2.m2.1.1.cmml" xref="S6.SS3.p3.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p3.2.m2.1c">3</annotation></semantics></math> entities with the highest attention scores in the input prompts are selected. For the original KAT model, we use the three entities from the three top retrieved sentences. Next, we show AMT workers the question, the predicted answer, the image with bounding boxes for the top entities, and the three retrieved sentences, for both systems randomly ordered. We present an example in the Appendix. Finally, workers are asked to judge which systemâ€™s set of highlighted entities and sentences best supports the given answer.
Experimental results show that judges pick our EnFoRe knowledge 61.8% of the time, indicating a clear preference over the original KAT knowledge. Such information can be considered an explanation or rationale for the systemâ€™s answer, and improved explanations can engender greater trust and acceptance from users and provide additional transparency of the systemâ€™s operation.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this work, we presented an Entity-Focused Retrieval (EnFoRe) model for retrieving knowledge for outside-knowledge visual questions. The goal is to retrieve question-relevant knowledge focused on critical entities. We first construct an entity set by parsing the question and the image. Then, EnFoRe predicts a query-entity score, predicting how likely it will lead to finding a correct answer, and a passage-entity score showing how likely the entity fits in the context of the passage. These two scores are combined to re-rank the conventional query-passage relevancy score. EnFoRe demonstrates the clear advantages of improved multi-modal knowledge retrieval and helps improve VQA performance with its improved retrieved knowledge.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Limitations</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">Our EnFoRe model is empowered by a comprehensive set of parsed entities from the question and the image. However, as shown in the failure cases in the experiment section, those entities may contain detection errors that lead to undesired results. In addition, during training, we adopt a fully automatic scheme for annotating critical entities assuming they can help a sparse retriever achieve better SRR results; however, explicit human annotation could potentially improve the quality of the critical entities identified.
While we have explored collecting both question-based and image-based entities in our current approach, they are not fully adequate in that ideally it could be beneficial to include not only the relevant objects for the visual question but other kinds of descriptors that may act as useful clues for knowledge retrieval. Another limitation of the current approach is that we encode each entity separately, ignoring the relationships between entities, which could be helpful for knowledge retrieval.</p>
</div>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>Acknowledgements</h2>

<div id="S9.p1" class="ltx_para">
<p id="S9.p1.1" class="ltx_p">The research was supported by the NSF-funded Institute for Foundations of Machine Learning (IFML) at UT Austin.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anderson etÂ al. (2018)</span>
<span class="ltx_bibblock">
Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen
Gould, and Lei Zhang. 2018.

</span>
<span class="ltx_bibblock">Bottom-Up and Top-Down Attention for Image Captioning and
VQA.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Antol etÂ al. (2015)</span>
<span class="ltx_bibblock">
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra,
CÂ LawrenceÂ Zitnick, and Devi Parikh. 2015.

</span>
<span class="ltx_bibblock">VQA: Visual Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">ICCV</em>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ben-Younes etÂ al. (2017)</span>
<span class="ltx_bibblock">
Hedi Ben-Younes, RÃ©mi Cadene, Matthieu Cord, and Nicolas Thome. 2017.

</span>
<span class="ltx_bibblock">MUTAN: Multimodal Tucker Fusion for Visual Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">ICCV</em>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown etÂ al. (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, JaredÂ D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
etÂ al. 2020.

</span>
<span class="ltx_bibblock">Language Models are Few-Shot Learners.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2021)</span>
<span class="ltx_bibblock">
Xilun Chen, Kushal Lakhotia, Barlas OÄŸuz, Anchit Gupta, Patrick Lewis,
Stan Peshterliev, Yashar Mehdad, Sonal Gupta, and Wen-tau Yih. 2021.

</span>
<span class="ltx_bibblock">Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate
a Sparse One?

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.06918</em>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin etÂ al. (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language
understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">NAACL-HLT</em>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">GardÃ¨res etÂ al. (2020)</span>
<span class="ltx_bibblock">
FranÃ§ois GardÃ¨res, Maryam Ziaeefard, Baptiste Abeloos, and Freddy
Lecue. 2020.

</span>
<span class="ltx_bibblock">ConceptBert: Concept-Aware Representation for Visual Question
Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gardner etÂ al. (2018)</span>
<span class="ltx_bibblock">
Matt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi,
NelsonÂ F. Liu, Matthew Peters, Michael Schmitz, and Luke Zettlemoyer. 2018.

</span>
<span class="ltx_bibblock">AllenNLP: A Deep Semantic Natural Language Processing Platform.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of Workshop for NLP Open Source Software
(NLP-OSS)</em>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gui etÂ al. (2021)</span>
<span class="ltx_bibblock">
Liangke Gui, Borui Wang, Qiuyuan Huang, Alex Hauptmann, Yonatan Bisk, and
Jianfeng Gao. 2021.

</span>
<span class="ltx_bibblock">KAT: A Knowledge Augmented Transformer for Vision-and-Language.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2112.08614</em>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gurari etÂ al. (2018)</span>
<span class="ltx_bibblock">
Danna Gurari, Qing Li, AbigaleÂ J Stangl, Anhong Guo, Chi Lin, Kristen Grauman,
Jiebo Luo, and JeffreyÂ P Bigham. 2018.

</span>
<span class="ltx_bibblock">Vizwiz Grand Challenge: Answering Visual Questions from Blind
People.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">ICCV</em>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. (2017)</span>
<span class="ltx_bibblock">
Kaiming He, Georgia Gkioxari, Piotr DollÃ¡r, and Ross Girshick. 2017.

</span>
<span class="ltx_bibblock">Mask R-CNN.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">ICCV</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hudson and Manning (2019)</span>
<span class="ltx_bibblock">
DrewÂ A Hudson and ChristopherÂ D Manning. 2019.

</span>
<span class="ltx_bibblock">GQA: a New Dataset for Compositional Question Answering over
Real-World Images.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard and Grave (2021)</span>
<span class="ltx_bibblock">
Gautier Izacard and Edouard Grave. 2021.

</span>
<span class="ltx_bibblock">Distilling Knowledge from Reader to Retriever for Question
Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang etÂ al. (2018)</span>
<span class="ltx_bibblock">
YuÂ Jiang, Vivek Natarajan, Xinlei Chen, Marcus Rohrbach, Dhruv Batra, and Devi
Parikh. 2018.

</span>
<span class="ltx_bibblock">Pythia v0. 1: the Winning Entry to the VQA Challenge 2018.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv</em>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpukhin etÂ al. (2020)</span>
<span class="ltx_bibblock">
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey
Edunov, Danqi Chen, and Wen-tau Yih. 2020.

</span>
<span class="ltx_bibblock">Dense Passage Retrieval for Open-Domain Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim etÂ al. (2018)</span>
<span class="ltx_bibblock">
Jin-Hwa Kim, Jaehyun Jun, and Byoung-Tak Zhang. 2018.

</span>
<span class="ltx_bibblock">Bilinear Attention Networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim etÂ al. (2020)</span>
<span class="ltx_bibblock">
Jungjun Kim, Hanbin Ko, and Jialin Wu. 2020.

</span>
<span class="ltx_bibblock">CoNAN: A complementary neighboring-based attention network for
referring expression generation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th International Conference on
Computational Linguistics</em>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee etÂ al. (2021)</span>
<span class="ltx_bibblock">
Jinhyuk Lee, Alexander Wettig, and Danqi Chen. 2021.

</span>
<span class="ltx_bibblock">Phrase Retrieval Learns Passage Retrieval, Too.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis etÂ al. (2022)</span>
<span class="ltx_bibblock">
Patrick Lewis, Barlas OÄŸuz, Wenhan Xiong, Fabio Petroni, Wen-tau Yih, and
Sebastian Riedel. 2022.

</span>
<span class="ltx_bibblock">Boosted Dense Retriever.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">NAACL</em>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2020)</span>
<span class="ltx_bibblock">
Guohao Li, Xin Wang, and Wenwu Zhu. 2020.

</span>
<span class="ltx_bibblock">Boosting Visual Question Answering with Context-aware Knowledge
Aggregation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">ACMMM</em>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2018)</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter. 2018.

</span>
<span class="ltx_bibblock">Decoupled Weight Decay Regularization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu etÂ al. (2019)</span>
<span class="ltx_bibblock">
Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee. 2019.

</span>
<span class="ltx_bibblock">ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations
for Vision-and-Language Tasks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu etÂ al. (2020)</span>
<span class="ltx_bibblock">
Jiasen Lu, Vedanuj Goswami, Marcus Rohrbach, Devi Parikh, and Stefan Lee. 2020.

</span>
<span class="ltx_bibblock">12-in-1: Multi-Task Vision and Language Representation Learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu etÂ al. (2016)</span>
<span class="ltx_bibblock">
Jiasen Lu, Jianwei Yang, Dhruv Batra, and Devi Parikh. 2016.

</span>
<span class="ltx_bibblock">Hierarchical Question-Image Co-attention for Visual Question
Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo etÂ al. (2021)</span>
<span class="ltx_bibblock">
Man Luo, Yankai Zeng, Pratyay Banerjee, and Chitta Baral. 2021.

</span>
<span class="ltx_bibblock">Weakly-Supervised Visual-Retriever-Reader for Knowledge-based
Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marino etÂ al. (2021)</span>
<span class="ltx_bibblock">
Kenneth Marino, Xinlei Chen, Devi Parikh, Abhinav Gupta, and Marcus Rohrbach.
2021.

</span>
<span class="ltx_bibblock">KRISP: Integrating Implicit and Symbolic Knowledge for Open-Domain
Knowledge-Based VQA.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marino etÂ al. (2019)</span>
<span class="ltx_bibblock">
Kenneth Marino, Mohammad Rastegari, Ali Farhadi, and Roozbeh Mottaghi. 2019.

</span>
<span class="ltx_bibblock">OK-VQA: A Visual Question Answering Benchmark Requiring External
Knowledge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Narasimhan etÂ al. (2018)</span>
<span class="ltx_bibblock">
Medhini Narasimhan, Svetlana Lazebnik, and Alexander Schwing. 2018.

</span>
<span class="ltx_bibblock">Out-of-The-Box: Reasoning with Graph Convolution Nets for
Factual Visual Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen etÂ al. (2021)</span>
<span class="ltx_bibblock">
Duy-Kien Nguyen, Vedanuj Goswami, and Xinlei Chen. 2021.

</span>
<span class="ltx_bibblock">Movie: Revisiting modulated convolutions for visual counting and
beyond.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu etÂ al. (2021)</span>
<span class="ltx_bibblock">
Chen Qu, Hamed Zamani, Liu Yang, WÂ Bruce Croft, and Erik Learned-Miller. 2021.

</span>
<span class="ltx_bibblock">Passage Retrieval for Outside-Knowledge Visual Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">SIGIR</em>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford etÂ al. (2021)</span>
<span class="ltx_bibblock">
Alec Radford, JongÂ Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
etÂ al. 2021.

</span>
<span class="ltx_bibblock">Learning Transferable Visual Models from Natural Language
Supervision.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel etÂ al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and PeterÂ J. Liu. 2020.

</span>
<span class="ltx_bibblock">Exploring the Limits of Transfer Learning with a Unified
Text-to-Text Transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">JMLR</em>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Robertson and Zaragoza (2009)</span>
<span class="ltx_bibblock">
Stephen Robertson and Hugo Zaragoza. 2009.

</span>
<span class="ltx_bibblock">The Probabilistic Relevance Framework: BM25 and Beyond.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Information Retrieval</em>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shevchenko etÂ al. (2021)</span>
<span class="ltx_bibblock">
Violetta Shevchenko, Damien Teney, Anthony Dick, and Anton vanÂ den Hengel.
2021.

</span>
<span class="ltx_bibblock">Reasoning over Vision and Language: Exploring the Benefits of
Supplemental Knowledge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Third Workshop on Beyond Vision and
LANguage: inTEgrating Real-world kNowledge (LANTERN)</em>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singh etÂ al. (2019)</span>
<span class="ltx_bibblock">
Amanpreet Singh, Vivek Natarajan, Meet Shah, YuÂ Jiang, Xinlei Chen, Dhruv
Batra, Devi Parikh, and Marcus Rohrbach. 2019.

</span>
<span class="ltx_bibblock">Towards VQA Models That Can Rread.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singh etÂ al. (2018)</span>
<span class="ltx_bibblock">
Jasdeep Singh, Vincent Ying, and Alex Nutkiewicz. 2018.

</span>
<span class="ltx_bibblock">Attention on Attention: Architectures for Visual Question Answering
(VQA).

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1803.07724</em>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan and Bansal (2019)</span>
<span class="ltx_bibblock">
Hao Tan and Mohit Bansal. 2019.

</span>
<span class="ltx_bibblock">LXMERT: Learning Cross-Modality Encoder Representations from
Transformers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2018)</span>
<span class="ltx_bibblock">
Peng Wang, QiÂ Wu, Chunhua Shen, Anthony Dick, and Anton vanÂ den Hengel. 2018.

</span>
<span class="ltx_bibblock">FVQA: Fact-based Visual Question Answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">TPAMI</em>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2022)</span>
<span class="ltx_bibblock">
Peng Wang, AnÂ Yang, Rui Men, Junyang Lin, Shuai Bai, Zhikang Li, Jianxin Ma,
Chang Zhou, Jingren Zhou, and Hongxia Yang. 2022.

</span>
<span class="ltx_bibblock">Unifying Architectures, Tasks, and Modalities through a Simple
Sequence-to-Sequence Learning Framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2202.03052</em>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. (2020)</span>
<span class="ltx_bibblock">
Jialin Wu, Liyan Chen, and RaymondÂ J Mooney. 2020.

</span>
<span class="ltx_bibblock">Improving VQA and its Explanations by Comparing Competing
Explanations.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.15631</em>.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. (2018)</span>
<span class="ltx_bibblock">
Jialin Wu, Zeyuan Hu, and RaymondÂ J Mooney. 2018.

</span>
<span class="ltx_bibblock">Joint Image Captioning and Question Answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1805.08389</em>.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. (2019)</span>
<span class="ltx_bibblock">
Jialin Wu, Zeyuan Hu, and RaymondÂ J Mooney. 2019.

</span>
<span class="ltx_bibblock">Generating Question Relevant Captions to Aid Visual Question
Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">ACL</em>.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. (2022)</span>
<span class="ltx_bibblock">
Jialin Wu, Jiasen Lu, Ashish Sabharwal, and Roozbeh Mottaghi. 2022.

</span>
<span class="ltx_bibblock">Multi-Modal Answer Validation for Knowledge-Based VQA.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">AAAI</em>.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu and Mooney (2019)</span>
<span class="ltx_bibblock">
Jialin Wu and RaymondÂ J Mooney. 2019.

</span>
<span class="ltx_bibblock">Self-Critical Reasoning for Robust Visual Question Answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al. (2022)</span>
<span class="ltx_bibblock">
Zhengyuan Yang, Zhe Gan, Jianfeng Wang, Xiaowei Hu, Yumao Lu, Zicheng Liu, and
Lijuan Wang. 2022.

</span>
<span class="ltx_bibblock">An Empirical Study of GPT-3 for Few-Shot Knowledge-Based VQA.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">AAAI</em>.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang* etÂ al. (2020)</span>
<span class="ltx_bibblock">
Tianyi Zhang*, Varsha Kishore*, Felix Wu*, KilianÂ Q. Weinberger, and Yoav
Artzi. 2020.

</span>
<span class="ltx_bibblock">BERTScore: Evaluating Text Generation with BERT.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu etÂ al. (2020)</span>
<span class="ltx_bibblock">
Zihao Zhu, Jing Yu, Yujing Wang, Yajing Sun, Yue Hu, and QiÂ Wu. 2020.

</span>
<span class="ltx_bibblock">Mucko: Multi-Layer Cross-Modal Knowledge Reasoning for Fact-based
Visual Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">IJCAI</em>.

</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Varying Weights during Re-Ranking</h3>

<figure id="A1.F4" class="ltx_figure"><img src="/html/2210.10176/assets/x4.png" id="A1.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="332" height="168" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>MRR and oracle-entity recall with different reranking weights.</figcaption>
</figure>
<div id="A1.SS1.p1" class="ltx_para">
<p id="A1.SS1.p1.1" class="ltx_p">In Figure <a href="#A1.F4" title="Figure 4 â€£ A.1 Varying Weights during Re-Ranking â€£ Appendix A Appendix â€£ Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we present the MRR (red line), and the oracle-entity recall (blue line) at a cut-off of 5, which is defined as the fraction of oracle entities appearing in the top-5 retrieved passages over the total number of the oracle entities. Our EnFoRe model not only improves the MRR results but also retrieves more oracle entities in the top passages, making the retrieved content more relevant. Also, the EnFoRe model is robust to the re-ranking weight, yielding consistent improvements for a broad range of weights.</p>
</div>
<figure id="A1.F5" class="ltx_figure"><img src="/html/2210.10176/assets/x5.png" id="A1.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="551" height="264" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Sample question for the human evaluation.</figcaption>
</figure>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Human Evaluation Details</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p id="A1.SS2.p1.1" class="ltx_p">We use Amazon Mechanical Turk (AMT) as our platform to perform human evaluation. We randomly sample 1,000 test questions that are correctly answered by both the original KAT-base model and our â€œKAT-base + EnFoReâ€ model in order to focus on evaluating the explanations for their answers rather than their correctness. In each HIT (Human Inference Task), we include four questions together with a quality control example, where the preference should be clear. We eliminate data where the quality control is not passed, but pay the workers 80 cents for finishing the HIT regardless of passing the quality control example. The average time workers spent on each HIT is 2 min and 33 sec. Figure <a href="#A1.F5" title="Figure 5 â€£ A.1 Varying Weights during Re-Ranking â€£ Appendix A Appendix â€£ Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows a sample question from a HIT.</p>
</div>
<figure id="A1.T5" class="ltx_table">
<table id="A1.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.T5.1.1.1" class="ltx_tr">
<th id="A1.T5.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt">Hyperparameters</th>
<td id="A1.T5.1.1.1.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt">Value</td>
</tr>
<tr id="A1.T5.1.2.2" class="ltx_tr">
<th id="A1.T5.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">BM25 Retriever k</th>
<td id="A1.T5.1.2.2.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">1.1</td>
</tr>
<tr id="A1.T5.1.3.3" class="ltx_tr">
<th id="A1.T5.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">BM25 Retriever b</th>
<td id="A1.T5.1.3.3.2" class="ltx_td ltx_nopad_r ltx_align_left">0.4</td>
</tr>
<tr id="A1.T5.1.4.4" class="ltx_tr">
<th id="A1.T5.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">CLIP</th>
<td id="A1.T5.1.4.4.2" class="ltx_td ltx_nopad_r ltx_align_left">ViT-B/16</td>
</tr>
<tr id="A1.T5.1.5.5" class="ltx_tr">
<th id="A1.T5.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Learning rate</th>
<td id="A1.T5.1.5.5.2" class="ltx_td ltx_nopad_r ltx_align_left">1e-5</td>
</tr>
<tr id="A1.T5.1.6.6" class="ltx_tr">
<th id="A1.T5.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Optimizer</th>
<td id="A1.T5.1.6.6.2" class="ltx_td ltx_nopad_r ltx_align_left">AdamW</td>
</tr>
<tr id="A1.T5.1.7.7" class="ltx_tr">
<th id="A1.T5.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Batch size</th>
<td id="A1.T5.1.7.7.2" class="ltx_td ltx_nopad_r ltx_align_left">6 per GPU</td>
</tr>
<tr id="A1.T5.1.8.8" class="ltx_tr">
<th id="A1.T5.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">#Gpus</th>
<td id="A1.T5.1.8.8.2" class="ltx_td ltx_nopad_r ltx_align_left">4</td>
</tr>
<tr id="A1.T5.1.9.9" class="ltx_tr">
<th id="A1.T5.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Retriever hidden states</th>
<td id="A1.T5.1.9.9.2" class="ltx_td ltx_nopad_r ltx_align_left">768</td>
</tr>
<tr id="A1.T5.1.10.10" class="ltx_tr">
<th id="A1.T5.1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Critical entity threshold</th>
<td id="A1.T5.1.10.10.2" class="ltx_td ltx_nopad_r ltx_align_left">0.8</td>
</tr>
<tr id="A1.T5.1.11.11" class="ltx_tr">
<th id="A1.T5.1.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">#Epochs</th>
<td id="A1.T5.1.11.11.2" class="ltx_td ltx_nopad_r ltx_align_left">8</td>
</tr>
<tr id="A1.T5.1.12.12" class="ltx_tr">
<th id="A1.T5.1.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Learning rate in KAT</th>
<td id="A1.T5.1.12.12.2" class="ltx_td ltx_nopad_r ltx_align_left">3e-5</td>
</tr>
<tr id="A1.T5.1.13.13" class="ltx_tr">
<th id="A1.T5.1.13.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Optimizer in KAT</th>
<td id="A1.T5.1.13.13.2" class="ltx_td ltx_nopad_r ltx_align_left">AdamW</td>
</tr>
<tr id="A1.T5.1.14.14" class="ltx_tr">
<th id="A1.T5.1.14.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">#Sentences in KAT</th>
<td id="A1.T5.1.14.14.2" class="ltx_td ltx_nopad_r ltx_align_left">10</td>
</tr>
<tr id="A1.T5.1.15.15" class="ltx_tr">
<th id="A1.T5.1.15.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">Batch size in KAT</th>
<td id="A1.T5.1.15.15.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">24</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Configurations for best-performing models.</figcaption>
</figure>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Hyperparameters</h3>

<div id="A1.SS3.p1" class="ltx_para">
<p id="A1.SS3.p1.2" class="ltx_p">We present details of the searching hyperparameters for the EnFoRe model in Table <a href="#A1.T5" title="Table 5 â€£ A.2 Human Evaluation Details â€£ Appendix A Appendix â€£ Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> . While most of the hyperparameters are set to the same as in <cite class="ltx_cite ltx_citemacro_cite">Qu etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite>, we tune the threshold <math id="A1.SS3.p1.1.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="A1.SS3.p1.1.m1.1a"><mi id="A1.SS3.p1.1.m1.1.1" xref="A1.SS3.p1.1.m1.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.1.m1.1b"><ci id="A1.SS3.p1.1.m1.1.1.cmml" xref="A1.SS3.p1.1.m1.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.1.m1.1c">\theta</annotation></semantics></math> for recognizing critical entities (0.6, 0.8, 1.0), batch size (2, 4, 6 per GPU), and the number of training epochs (2, 4, 6). We use a greedy approach <cite class="ltx_cite ltx_citemacro_cite">Singh etÂ al. (<a href="#bib.bib36" title="" class="ltx_ref">2018</a>)</cite> to search hyperparameters in the order of <math id="A1.SS3.p1.2.m2.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="A1.SS3.p1.2.m2.1a"><mi id="A1.SS3.p1.2.m2.1.1" xref="A1.SS3.p1.2.m2.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.2.m2.1b"><ci id="A1.SS3.p1.2.m2.1.1.cmml" xref="A1.SS3.p1.2.m2.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.2.m2.1c">\theta</annotation></semantics></math>, batch size, and training epochs. Maximizing MRR@5 is used as the objective.</p>
</div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2210.10175" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2210.10176" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2210.10176">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2210.10176" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2210.10177" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar 14 02:44:41 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
