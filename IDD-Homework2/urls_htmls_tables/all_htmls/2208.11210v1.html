<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2208.11210] Data augmentation on graphs for table type classification</title><meta property="og:description" content="Tables are widely used in documents because of their compact and structured representation of information.
In particular, in scientific papers, tables can sum up novel discoveries and summarize experimental results, maâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Data augmentation on graphs for table type classification">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Data augmentation on graphs for table type classification">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2208.11210">

<!--Generated on Wed Mar 13 18:28:26 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Graph Neural Network Data Augmentation Table Classification">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span id="id1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>University of Florence, Florence, Italy 
<br class="ltx_break">AI Lab, DINFO 
<br class="ltx_break"><span id="id1.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>davide.delbimbo@stud.unifi.it</span></span></span> 
<br class="ltx_break"><span id="id1.2" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>{andrea.gemelli, simone.marinai}@unifi.it</span></span></span></span></span></span>
<h1 class="ltx_title ltx_title_document">Data augmentation on graphs for table type classification</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Davide del Bimbo 
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/0000-0002-2834-1283" title="ORCID identifier" class="ltx_ref">0000-0002-2834-1283</a></span>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Andrea Gemelli
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/0000-0002-6149-8282" title="ORCID identifier" class="ltx_ref">0000-0002-6149-8282</a></span>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Simone Marinai
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/0000-0002-6702-2277" title="ORCID identifier" class="ltx_ref">0000-0002-6702-2277</a></span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Tables are widely used in documents because of their compact and structured representation of information.
In particular, in scientific papers, tables can sum up novel discoveries and summarize experimental results, making the research comparable and easily understandable by scholars.
Since the layout of tables is highly variable, it would be useful to interpret their content and classify them into categories. This could be helpful to directly extract information from scientific papers, for instance comparing performance of some models given their paper result tables.
In this work, we address the classification of tables using a Graph Neural Network, exploiting the table structure for the message passing algorithm in use. We evaluate our model on a subset of the Tab2Know dataset. Since it contains few examples manually annotated, we propose data augmentation techniques directly on the table graph structures.
We achieve promising preliminary results, proposing a data augmentation method suitable for graph-based table representation.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Graph Neural Network Data Augmentation Table Classification
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Tables within scientific documents represent an essential source of knowledge. Their use is necessary for the intelligibility of a document as they provide useful information in a structured and well-organized form, allowing the reader to understand the data through visual content.
In particular, in scientific documents, the tables can summarize data from experiments, observations and much more, providing essential information to reconstruct the state of the art of different fields of research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
Since different users write different documents, tables usually present different layouts: sometimes, they can be irregular or contain unique abbreviations that are difficult to disambiguate automatically.
It would be helpful if their contents were interpreted and transcribed into a Knowledge Base (KB), a database in which tables are translated using a single standard vocabulary. The use of the KB could be helpful to those who need to make use of the information and data contained in the tables without having to access the documents directly <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
In this scenario, it appears necessary to define a way to classify tables into entities that share common features.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In this work we present a model to classify scientific tables given their content and structure. The label of a table is related to its purpose within the paper and, as proposed in Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, we try to classify them into four different types: <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">Observation</em>, <em id="S1.p2.1.2" class="ltx_emph ltx_font_italic">Input</em>, <em id="S1.p2.1.3" class="ltx_emph ltx_font_italic">Example</em> and <em id="S1.p2.1.4" class="ltx_emph ltx_font_italic">Other</em>.
This classification is useful in areas such as the automatic comprehension of an article or the summarization of information in a document.
To address the task just described, we make use of Graph Neural Networks (GNNs), which have been widely considered recently in Document Analysis and Table Understanding. This choice is motivated by their ability to consider the structural information. In addition, we propose some data augmentation techniques working directly on the graph representation of tables, which led to promising preliminary results.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">This work is organized as follows. In SectionÂ <a href="#S2" title="2 Related Works â€£ Data augmentation on graphs for table type classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> works that mostly inspired our paper are explored, focusing on the most significant ones. The proposed approach<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Code available <a target="_blank" href="https://github.com/AILab-UniFI/DA-GraphTab" title="" class="ltx_ref ltx_href"><span id="footnote1.1.1" class="ltx_text ltx_framed ltx_framed_underline">here</span></a></span></span></span> is discussed in SectionÂ <a href="#S3" title="3 Method â€£ Data augmentation on graphs for table type classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> including the preprocessing of the tables of scientific papers, the data augmentation techniques and the
implementation of the GNN model. Experimental results on the Tab2Know dataset are presented in SectionÂ <a href="#S4" title="4 Experiments â€£ Data augmentation on graphs for table type classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, while conclusions are drawn in SectionÂ <a href="#S5" title="5 Conclusions â€£ Data augmentation on graphs for table type classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section we summarize previous work related to the proposed approach.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Table related tasks.</span>
Usually, to extract information from tables in documents two steps are used: first tables are detected, then their structure is described in terms of rows and columns.
As shown in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> different techniques have been used in the past to tackle these tasks, making use of both computer vision and natural language processing techniques.
Recently, two new approaches have beaten the state-of-the-art: combining vision, semantic and relations for layout analysis and table detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> and applying a soft pyramid mask learning mechanism in both the local and global feature maps for complicated table structure recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
In addition to Table Detection (TD) and Table Structure Recognition (TSS), the authors who released PubTables-1M <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> proposed to perform Functional Analysis (FA) to distinguish table headers from table cells.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> we proposed a Graph Neural Network method to perform FA along with TD, TSS and document layout analysis to enrich the information of extracted tables with a context.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Information extraction from scientific literature.</span>
Automatic extraction of table information can help scholars in several disciplines. In addition to values in table cells it is also useful to classify tables according to their type.
To track progresses in scientific research, authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> propose an automatic machine learning pipeline for extracting results from papers. The pipeline is split into three steps, the first one being table type classification. Since the focus is on results extraction, result and ablation tables are identified. The extracted information is summarized into a leaderboard, sorted by the best scores given certain metrics.
Another work, Tab2Know <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, proposes to classify tables in four types and recognize table headers and columns.
The aim is to extract and link tables into a knowledge base to answer user queries trying to identify relevant information over years of research in a given field.
Table classification is referred by the authors as table type detection.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Data Augmentation techniques.</span> The Tab2Know dataset can be used for performing table classification. However, the manually labeled subset is small and therefore we need to implement suitable Data Augmentation (DA) techniques. DA is widely used in machine learning in order to make models better generalize on unseen samples and unbalanced datasets.
In object detection, DA techniques involve color operations (contrast, brightness), geometric operations (translations, rotations), and bounding box operations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.
None of these can be used in our case since we are considering graphs to represent the tables and augmentation operations commonly used in vision and language have no analogs for graphs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.
Similarly to what we did for trees <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> and inspired by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, we applied some of their augmentations on table examples directly in the graph structure (Section <a href="#S3.SS2" title="3.2 Data Augmentation â€£ 3 Method â€£ Data augmentation on graphs for table type classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>).
Operations that can be performed on tables are random deletion of rows, row replication, column deletion and column replication. Instead of working directly on images, we therefore extract the table structure (Section <a href="#S3.SS1" title="3.1 Preprocessing â€£ 3 Method â€£ Data augmentation on graphs for table type classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>) and then apply DA on their graph representation, by means of node deletion, edge deletion and inversion of node contents (Section <a href="#S3.SS2" title="3.2 Data Augmentation â€£ 3 Method â€£ Data augmentation on graphs for table type classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>).</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section we present the main steps of the proposed approach.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Preprocessing</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The first step to apply a GNN for table classification is the conversion of tables in PDF papers in graphs.
To this purpose, we use PyMuPDF, a toolkit for viewing and rendering PDF and XPS files <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.
The library is used to extract words and their bounding boxes; by using the positions of the tables in the annotations, only the words within them can be considered (Fig. <a href="#S3.F1" title="Figure 1 â€£ 3.1 Preprocessing â€£ 3 Method â€£ Data augmentation on graphs for table type classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). One graph for each table is built, where words correspond to nodes.
A feature vector is associated to each word and contains information about its position and the embedding of the textual content, extracted using spaCy language models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.
Edges represent the mutual position of bounding boxes and are identified by a visibility graph, like the one described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> (e.g. see Fig. <a href="#S3.F1" title="Figure 1 â€£ 3.1 Preprocessing â€£ 3 Method â€£ Data augmentation on graphs for table type classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
Each node is connected to its nearest visible nodes when their bounding boxes intersect horizontally or vertically.
Each graph, representing a table, is associated with the annotation corresponding to its type.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2208.11210/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="398" height="182" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Words and bounding boxes extracted from one PDF paper using PyMuPDF. Nodes are connected through a visibility graph.</figcaption>
</figure>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Tables without annotation and those of which a graph cannot be built are discarded. At the end we obtain 320 graphs split into four classes:
Observation (235), Input (43), Example (13), and Other (29).
Examples of classes can be seen in Fig. <a href="#S3.F2" title="Figure 2 â€£ 3.1 Preprocessing â€£ 3 Method â€£ Data augmentation on graphs for table type classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a></p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2208.11210/assets/img/Confronto.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="300" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Different types of tables with their classes.</figcaption>
</figure>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">Each node in the graph corresponds to a feature vector. In addition to the geometric features of the nodes, such as position and size,
textual content embeddings are added using spaCy.
In particular, two spaCy models are used and compared: <span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_italic">en_core_web_lg</span> and <span id="S3.SS1.p3.1.2" class="ltx_text ltx_font_italic">en_core_sci_lg</span>.
The first one is the largest english vocabulary which associates each word with a numerical vector of 300 values; the other model, trained on a biomedical corpus, associates each word a numerical vector of 200 values.
The results obtained using the two models are compared in the experiments.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Data Augmentation</h3>

<figure id="S3.F3" class="ltx_figure"><img src="/html/2208.11210/assets/img/ColumnDetect.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="395" height="142" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Recognition of columns. Group of 1s in the projected vector indicate different columns.</figcaption>
</figure>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2208.11210/assets/img/RowDetect.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="299" height="95" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Recognition of rows. The blue bounding box is detected belonging to a new row since its <span id="S3.F4.2.1" class="ltx_text ltx_font_italic">x</span> coordinate is lower than the previous green block.</figcaption>
</figure>
<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Since the dataset (SectionÂ <a href="#S4.SS1" title="4.1 The Tab2Know dataset â€£ 4 Experiments â€£ Data augmentation on graphs for table type classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>) is unbalanced, a Data Augmentation strategy has been implemented to generate new training data from the available ones.
For DA, new graphs can be obtained by modifying their structure and the information associated with the nodes and edges.
Since the embedding for each table is evaluated through a message passing algorithm that strongly relies on the table structure and content, removing elements of the graph and changing node features helps to generate more variability of examples for each class. This not only improves the generalization capability of the model, but can help to reduce the class imbalance.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Random removal of nodes and edges</span>
In these operations, a random sample of nodes or arcs within the table is removed from the graph.
By doing so, it is possible to generate a new graph similar to the initial one, but with different information.</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">nodes removal: a random subset of node indexes is removed. The size of the sample depends on the number of nodes in the graph, a random number between 1% and 20% of the total number of nodes.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">edges removal: a random subset of edge indexes is removed. The size of the sample depends on the number of edges in the graph, a random number between 1% and 20% of the total number of edges.</p>
</div>
</li>
</ul>
<p id="S3.SS2.p2.2" class="ltx_p">The amount of randomly removed nodes/edges is an arbitrary choice. We did not want to: (i) discard too much information and (ii) introduce any bias in the decision.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p"><span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">Inversion of rows and columns</span>
The row and column inversion technique is more complex, due to the fact that the internal structure of the tables is not known. Therefore, it is necessary to define an approach to approximate this structure. Once identified, rows or columns can be inverted, by means of swapping their node features.</p>
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.2" class="ltx_p">Column inversion:
table columns identification is made with a projection-profile based approach which
defines a vector of size equal to the width of the table region. Each element of the vector is initialized to 0. Then, for each word, the coordinates <math id="S3.I2.i1.p1.1.m1.1" class="ltx_Math" alttext="x_{1}" display="inline"><semantics id="S3.I2.i1.p1.1.m1.1a"><msub id="S3.I2.i1.p1.1.m1.1.1" xref="S3.I2.i1.p1.1.m1.1.1.cmml"><mi id="S3.I2.i1.p1.1.m1.1.1.2" xref="S3.I2.i1.p1.1.m1.1.1.2.cmml">x</mi><mn id="S3.I2.i1.p1.1.m1.1.1.3" xref="S3.I2.i1.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i1.p1.1.m1.1b"><apply id="S3.I2.i1.p1.1.m1.1.1.cmml" xref="S3.I2.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I2.i1.p1.1.m1.1.1.1.cmml" xref="S3.I2.i1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I2.i1.p1.1.m1.1.1.2.cmml" xref="S3.I2.i1.p1.1.m1.1.1.2">ğ‘¥</ci><cn type="integer" id="S3.I2.i1.p1.1.m1.1.1.3.cmml" xref="S3.I2.i1.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.p1.1.m1.1c">x_{1}</annotation></semantics></math> and <math id="S3.I2.i1.p1.2.m2.1" class="ltx_Math" alttext="x_{2}" display="inline"><semantics id="S3.I2.i1.p1.2.m2.1a"><msub id="S3.I2.i1.p1.2.m2.1.1" xref="S3.I2.i1.p1.2.m2.1.1.cmml"><mi id="S3.I2.i1.p1.2.m2.1.1.2" xref="S3.I2.i1.p1.2.m2.1.1.2.cmml">x</mi><mn id="S3.I2.i1.p1.2.m2.1.1.3" xref="S3.I2.i1.p1.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i1.p1.2.m2.1b"><apply id="S3.I2.i1.p1.2.m2.1.1.cmml" xref="S3.I2.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.I2.i1.p1.2.m2.1.1.1.cmml" xref="S3.I2.i1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.I2.i1.p1.2.m2.1.1.2.cmml" xref="S3.I2.i1.p1.2.m2.1.1.2">ğ‘¥</ci><cn type="integer" id="S3.I2.i1.p1.2.m2.1.1.3.cmml" xref="S3.I2.i1.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.p1.2.m2.1c">x_{2}</annotation></semantics></math> of the corresponding bounding box are extracted and projected, setting to 1 the vector values whose indices correspond to these coordinates. The obtained result is shown in figure <a href="#S3.F3" title="Figure 3 â€£ 3.2 Data Augmentation â€£ 3 Method â€£ Data augmentation on graphs for table type classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>: adjacent 0s should identify column boundaries, while adjacent 1s the coordinates of each column. Thus, two columns can be inverted by swapping their contents, that is, the features of the nodes whose center of the bounding box belongs to those columns.
The limitation of this technique is visible whenever there is a space between words belonging to the same column.</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p">Rows inversion: To reverse rows, it is necessary to compare the positions of â€successiveâ€ bounding boxes. PyMuPDF reads and orders the content from left to right and from top to bottom. So, when a bounding box appears positioned ahead of the next one, it means that the latter is on a new row. In Fig. <a href="#S3.F4" title="Figure 4 â€£ 3.2 Data Augmentation â€£ 3 Method â€£ Data augmentation on graphs for table type classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> the orange, green and blue bounding boxes are successive ones: the last one is on a new row since its <span id="S3.I2.i2.p1.1.1" class="ltx_text ltx_font_italic">x</span> coordinate is lower than the green one. Once the structure of the rows has been identified, they can be reversed by swapping the features of the nodes belonging to them.
The limitation of this technique is visible in the case of multi-row tables.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Model</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.7" class="ltx_p">Our baseline model uses two Graph Convolutional layers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> and a Linear output one.
Each node embedding is updated through the message passing algorithm: (i) firstly each node collects the embeddings of connected nodes; in our case study, each cell of the tables collects the embeddings of the visible ones; (ii) then a weighted sum is applied to aggregate the collected information and to update each node vector. (iii) At the end, a fully connected layer is used to learn the new node representations between the layers of the network
We applied this procedure twice and then all the nodes of each graph are aggregated using a <span id="S3.SS3.p1.7.1" class="ltx_text ltx_font_italic">redout</span> function.
Every graph in the data may have its unique structure, as well as its node and edge features. In order to make a single prediction per each table, we aggregated and summarized over all the node information.
Given a graph, the average node feature readout we use is</p>
<table id="S3.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex1.m1.1" class="ltx_Math" alttext="h_{g}=\frac{1}{|V|}\sum_{v\in V}h_{v}" display="block"><semantics id="S3.Ex1.m1.1a"><mrow id="S3.Ex1.m1.1.2" xref="S3.Ex1.m1.1.2.cmml"><msub id="S3.Ex1.m1.1.2.2" xref="S3.Ex1.m1.1.2.2.cmml"><mi id="S3.Ex1.m1.1.2.2.2" xref="S3.Ex1.m1.1.2.2.2.cmml">h</mi><mi id="S3.Ex1.m1.1.2.2.3" xref="S3.Ex1.m1.1.2.2.3.cmml">g</mi></msub><mo id="S3.Ex1.m1.1.2.1" xref="S3.Ex1.m1.1.2.1.cmml">=</mo><mrow id="S3.Ex1.m1.1.2.3" xref="S3.Ex1.m1.1.2.3.cmml"><mfrac id="S3.Ex1.m1.1.1" xref="S3.Ex1.m1.1.1.cmml"><mn id="S3.Ex1.m1.1.1.3" xref="S3.Ex1.m1.1.1.3.cmml">1</mn><mrow id="S3.Ex1.m1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.2.cmml"><mo stretchy="false" id="S3.Ex1.m1.1.1.1.3.1" xref="S3.Ex1.m1.1.1.1.2.1.cmml">|</mo><mi id="S3.Ex1.m1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.cmml">V</mi><mo stretchy="false" id="S3.Ex1.m1.1.1.1.3.2" xref="S3.Ex1.m1.1.1.1.2.1.cmml">|</mo></mrow></mfrac><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.1.2.3.1" xref="S3.Ex1.m1.1.2.3.1.cmml">â€‹</mo><mrow id="S3.Ex1.m1.1.2.3.2" xref="S3.Ex1.m1.1.2.3.2.cmml"><munder id="S3.Ex1.m1.1.2.3.2.1" xref="S3.Ex1.m1.1.2.3.2.1.cmml"><mo movablelimits="false" id="S3.Ex1.m1.1.2.3.2.1.2" xref="S3.Ex1.m1.1.2.3.2.1.2.cmml">âˆ‘</mo><mrow id="S3.Ex1.m1.1.2.3.2.1.3" xref="S3.Ex1.m1.1.2.3.2.1.3.cmml"><mi id="S3.Ex1.m1.1.2.3.2.1.3.2" xref="S3.Ex1.m1.1.2.3.2.1.3.2.cmml">v</mi><mo id="S3.Ex1.m1.1.2.3.2.1.3.1" xref="S3.Ex1.m1.1.2.3.2.1.3.1.cmml">âˆˆ</mo><mi id="S3.Ex1.m1.1.2.3.2.1.3.3" xref="S3.Ex1.m1.1.2.3.2.1.3.3.cmml">V</mi></mrow></munder><msub id="S3.Ex1.m1.1.2.3.2.2" xref="S3.Ex1.m1.1.2.3.2.2.cmml"><mi id="S3.Ex1.m1.1.2.3.2.2.2" xref="S3.Ex1.m1.1.2.3.2.2.2.cmml">h</mi><mi id="S3.Ex1.m1.1.2.3.2.2.3" xref="S3.Ex1.m1.1.2.3.2.2.3.cmml">v</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.1b"><apply id="S3.Ex1.m1.1.2.cmml" xref="S3.Ex1.m1.1.2"><eq id="S3.Ex1.m1.1.2.1.cmml" xref="S3.Ex1.m1.1.2.1"></eq><apply id="S3.Ex1.m1.1.2.2.cmml" xref="S3.Ex1.m1.1.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.2.2.1.cmml" xref="S3.Ex1.m1.1.2.2">subscript</csymbol><ci id="S3.Ex1.m1.1.2.2.2.cmml" xref="S3.Ex1.m1.1.2.2.2">â„</ci><ci id="S3.Ex1.m1.1.2.2.3.cmml" xref="S3.Ex1.m1.1.2.2.3">ğ‘”</ci></apply><apply id="S3.Ex1.m1.1.2.3.cmml" xref="S3.Ex1.m1.1.2.3"><times id="S3.Ex1.m1.1.2.3.1.cmml" xref="S3.Ex1.m1.1.2.3.1"></times><apply id="S3.Ex1.m1.1.1.cmml" xref="S3.Ex1.m1.1.1"><divide id="S3.Ex1.m1.1.1.2.cmml" xref="S3.Ex1.m1.1.1"></divide><cn type="integer" id="S3.Ex1.m1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.3">1</cn><apply id="S3.Ex1.m1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.3"><abs id="S3.Ex1.m1.1.1.1.2.1.cmml" xref="S3.Ex1.m1.1.1.1.3.1"></abs><ci id="S3.Ex1.m1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1">ğ‘‰</ci></apply></apply><apply id="S3.Ex1.m1.1.2.3.2.cmml" xref="S3.Ex1.m1.1.2.3.2"><apply id="S3.Ex1.m1.1.2.3.2.1.cmml" xref="S3.Ex1.m1.1.2.3.2.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.2.3.2.1.1.cmml" xref="S3.Ex1.m1.1.2.3.2.1">subscript</csymbol><sum id="S3.Ex1.m1.1.2.3.2.1.2.cmml" xref="S3.Ex1.m1.1.2.3.2.1.2"></sum><apply id="S3.Ex1.m1.1.2.3.2.1.3.cmml" xref="S3.Ex1.m1.1.2.3.2.1.3"><in id="S3.Ex1.m1.1.2.3.2.1.3.1.cmml" xref="S3.Ex1.m1.1.2.3.2.1.3.1"></in><ci id="S3.Ex1.m1.1.2.3.2.1.3.2.cmml" xref="S3.Ex1.m1.1.2.3.2.1.3.2">ğ‘£</ci><ci id="S3.Ex1.m1.1.2.3.2.1.3.3.cmml" xref="S3.Ex1.m1.1.2.3.2.1.3.3">ğ‘‰</ci></apply></apply><apply id="S3.Ex1.m1.1.2.3.2.2.cmml" xref="S3.Ex1.m1.1.2.3.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.2.3.2.2.1.cmml" xref="S3.Ex1.m1.1.2.3.2.2">subscript</csymbol><ci id="S3.Ex1.m1.1.2.3.2.2.2.cmml" xref="S3.Ex1.m1.1.2.3.2.2.2">â„</ci><ci id="S3.Ex1.m1.1.2.3.2.2.3.cmml" xref="S3.Ex1.m1.1.2.3.2.2.3">ğ‘£</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.1c">h_{g}=\frac{1}{|V|}\sum_{v\in V}h_{v}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS3.p1.6" class="ltx_p">where <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="h_{g}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><msub id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">h</mi><mi id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">â„</ci><ci id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">h_{g}</annotation></semantics></math> is the representation of graph <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="g" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">ğ‘”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">g</annotation></semantics></math>, <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mi id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">ğ‘‰</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">V</annotation></semantics></math> is the set of nodes in <math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="g" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><mi id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><ci id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">ğ‘”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">g</annotation></semantics></math>, <math id="S3.SS3.p1.5.m5.1" class="ltx_Math" alttext="h_{n}" display="inline"><semantics id="S3.SS3.p1.5.m5.1a"><msub id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml"><mi id="S3.SS3.p1.5.m5.1.1.2" xref="S3.SS3.p1.5.m5.1.1.2.cmml">h</mi><mi id="S3.SS3.p1.5.m5.1.1.3" xref="S3.SS3.p1.5.m5.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.1b"><apply id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.5.m5.1.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.p1.5.m5.1.1.2.cmml" xref="S3.SS3.p1.5.m5.1.1.2">â„</ci><ci id="S3.SS3.p1.5.m5.1.1.3.cmml" xref="S3.SS3.p1.5.m5.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.1c">h_{n}</annotation></semantics></math> is the feature of node <math id="S3.SS3.p1.6.m6.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS3.p1.6.m6.1a"><mi id="S3.SS3.p1.6.m6.1.1" xref="S3.SS3.p1.6.m6.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m6.1b"><ci id="S3.SS3.p1.6.m6.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m6.1c">n</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we present the dataset used in the experiments that are subsequently discussed.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>The Tab2Know dataset</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The Tab2Know dataset, proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, contains information regarding tables extracted from scientific papers in the Semantic Scholar Open Research Corpus. Tables are extracted using PDFFigures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, a tool that finds figures, tables, and captions within PDF documents, and Tabula<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://github.com/tabulapdf/tabula" title="" class="ltx_ref ltx_href">https://github.com/tabulapdf/tabula</a></span></span></span>, that outputs a CSV per each table reflecting its structure and content. After the conversion, each table is saved as an RDF triple addressable by an unique URI. Each CSV is then analyzed to recognize headers, type of table and columns type.
The authors define an ontology of 27 different classes, 4 of which are defined as â€rootâ€ ones (Example, Input, Observation and Other): the others are given depending on the type of columns found inside each table (e.g. Recall is a subclass of Metric that is a subclass of Observation). Their training corpus is composed of 73k tables, labeled using Snorkel <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> and starting from a small pre-labeled set of tables obtained through human supervision using SPARQL queries. Human annotators then looked at 400 of them, checking their labeling correctness and, after resolving their conflicts when disagreeing, used this subset as the test set.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Using the dataset</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.4" class="ltx_p">To extract and group information on tables from Tab2Know, we built a conversion system to derive a JSON object for each available table.
The information is the table numbering in the document, the page number where the table is located, the number of rows that make up the header, the document URL, the table class definition, and the caption text. We also added some information not represented in the RDF graph, such as the position of the table and the location of the caption (the latter information is obtained using PDFFigures and Tabula). Then we downloaded tables corresponding PDF papers, accessed from the Semantic Scholar Open Research Corpus. From each paper, the pages containing the tables are extracted.
Unfortunately it is not possible to use the whole Tab2Know dataset. For instance, some papers are no longer available or an updated version do not match anymore the annotations provided. From the total, only the data whose annotations match are used, discarding the others. We obtained a subset containing 33,069 tables extracted from 11,800 scientific documents (45% of the original one). In addition, this dataset is very unbalanced (80% Observation, 10% Input, 7% Other, 3% Example) and it contains several missing or wrong annotations (55% of column classes have been labeled as â€™othersâ€™, across 22 different classes).
For these reasons, we only use in this preliminary work the test set that was manually classified and corrected by humans. Specifically, this dataset contains 361 tables extracted from 253 scientific papers. The distribution of tables according to the class is as follows: 235 <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="Observation" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.1a" xref="S4.SS2.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.1.m1.1.1.4" xref="S4.SS2.p1.1.m1.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.1b" xref="S4.SS2.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.1.m1.1.1.5" xref="S4.SS2.p1.1.m1.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.1c" xref="S4.SS2.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.1.m1.1.1.6" xref="S4.SS2.p1.1.m1.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.1d" xref="S4.SS2.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.1.m1.1.1.7" xref="S4.SS2.p1.1.m1.1.1.7.cmml">v</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.1e" xref="S4.SS2.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.1.m1.1.1.8" xref="S4.SS2.p1.1.m1.1.1.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.1f" xref="S4.SS2.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.1.m1.1.1.9" xref="S4.SS2.p1.1.m1.1.1.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.1g" xref="S4.SS2.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.1.m1.1.1.10" xref="S4.SS2.p1.1.m1.1.1.10.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.1h" xref="S4.SS2.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.1.m1.1.1.11" xref="S4.SS2.p1.1.m1.1.1.11.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.1i" xref="S4.SS2.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.1.m1.1.1.12" xref="S4.SS2.p1.1.m1.1.1.12.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><times id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></times><ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">ğ‘‚</ci><ci id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">ğ‘</ci><ci id="S4.SS2.p1.1.m1.1.1.4.cmml" xref="S4.SS2.p1.1.m1.1.1.4">ğ‘ </ci><ci id="S4.SS2.p1.1.m1.1.1.5.cmml" xref="S4.SS2.p1.1.m1.1.1.5">ğ‘’</ci><ci id="S4.SS2.p1.1.m1.1.1.6.cmml" xref="S4.SS2.p1.1.m1.1.1.6">ğ‘Ÿ</ci><ci id="S4.SS2.p1.1.m1.1.1.7.cmml" xref="S4.SS2.p1.1.m1.1.1.7">ğ‘£</ci><ci id="S4.SS2.p1.1.m1.1.1.8.cmml" xref="S4.SS2.p1.1.m1.1.1.8">ğ‘</ci><ci id="S4.SS2.p1.1.m1.1.1.9.cmml" xref="S4.SS2.p1.1.m1.1.1.9">ğ‘¡</ci><ci id="S4.SS2.p1.1.m1.1.1.10.cmml" xref="S4.SS2.p1.1.m1.1.1.10">ğ‘–</ci><ci id="S4.SS2.p1.1.m1.1.1.11.cmml" xref="S4.SS2.p1.1.m1.1.1.11">ğ‘œ</ci><ci id="S4.SS2.p1.1.m1.1.1.12.cmml" xref="S4.SS2.p1.1.m1.1.1.12">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">Observation</annotation></semantics></math>, 43 <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="Input" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.1a" xref="S4.SS2.p1.2.m2.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.2.m2.1.1.4" xref="S4.SS2.p1.2.m2.1.1.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.1b" xref="S4.SS2.p1.2.m2.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.2.m2.1.1.5" xref="S4.SS2.p1.2.m2.1.1.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.1c" xref="S4.SS2.p1.2.m2.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.2.m2.1.1.6" xref="S4.SS2.p1.2.m2.1.1.6.cmml">t</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><times id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1"></times><ci id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">ğ¼</ci><ci id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3">ğ‘›</ci><ci id="S4.SS2.p1.2.m2.1.1.4.cmml" xref="S4.SS2.p1.2.m2.1.1.4">ğ‘</ci><ci id="S4.SS2.p1.2.m2.1.1.5.cmml" xref="S4.SS2.p1.2.m2.1.1.5">ğ‘¢</ci><ci id="S4.SS2.p1.2.m2.1.1.6.cmml" xref="S4.SS2.p1.2.m2.1.1.6">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">Input</annotation></semantics></math>, 13 <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="Example" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mrow id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mi id="S4.SS2.p1.3.m3.1.1.2" xref="S4.SS2.p1.3.m3.1.1.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m3.1.1.1" xref="S4.SS2.p1.3.m3.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.3.m3.1.1.3" xref="S4.SS2.p1.3.m3.1.1.3.cmml">x</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m3.1.1.1a" xref="S4.SS2.p1.3.m3.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.3.m3.1.1.4" xref="S4.SS2.p1.3.m3.1.1.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m3.1.1.1b" xref="S4.SS2.p1.3.m3.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.3.m3.1.1.5" xref="S4.SS2.p1.3.m3.1.1.5.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m3.1.1.1c" xref="S4.SS2.p1.3.m3.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.3.m3.1.1.6" xref="S4.SS2.p1.3.m3.1.1.6.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m3.1.1.1d" xref="S4.SS2.p1.3.m3.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.3.m3.1.1.7" xref="S4.SS2.p1.3.m3.1.1.7.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.3.m3.1.1.1e" xref="S4.SS2.p1.3.m3.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.3.m3.1.1.8" xref="S4.SS2.p1.3.m3.1.1.8.cmml">e</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><times id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1.1"></times><ci id="S4.SS2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2">ğ¸</ci><ci id="S4.SS2.p1.3.m3.1.1.3.cmml" xref="S4.SS2.p1.3.m3.1.1.3">ğ‘¥</ci><ci id="S4.SS2.p1.3.m3.1.1.4.cmml" xref="S4.SS2.p1.3.m3.1.1.4">ğ‘</ci><ci id="S4.SS2.p1.3.m3.1.1.5.cmml" xref="S4.SS2.p1.3.m3.1.1.5">ğ‘š</ci><ci id="S4.SS2.p1.3.m3.1.1.6.cmml" xref="S4.SS2.p1.3.m3.1.1.6">ğ‘</ci><ci id="S4.SS2.p1.3.m3.1.1.7.cmml" xref="S4.SS2.p1.3.m3.1.1.7">ğ‘™</ci><ci id="S4.SS2.p1.3.m3.1.1.8.cmml" xref="S4.SS2.p1.3.m3.1.1.8">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">Example</annotation></semantics></math>, 29 <math id="S4.SS2.p1.4.m4.1" class="ltx_Math" alttext="Other" display="inline"><semantics id="S4.SS2.p1.4.m4.1a"><mrow id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml"><mi id="S4.SS2.p1.4.m4.1.1.2" xref="S4.SS2.p1.4.m4.1.1.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.4.m4.1.1.1" xref="S4.SS2.p1.4.m4.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.4.m4.1.1.3" xref="S4.SS2.p1.4.m4.1.1.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.4.m4.1.1.1a" xref="S4.SS2.p1.4.m4.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.4.m4.1.1.4" xref="S4.SS2.p1.4.m4.1.1.4.cmml">h</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.4.m4.1.1.1b" xref="S4.SS2.p1.4.m4.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.4.m4.1.1.5" xref="S4.SS2.p1.4.m4.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.4.m4.1.1.1c" xref="S4.SS2.p1.4.m4.1.1.1.cmml">â€‹</mo><mi id="S4.SS2.p1.4.m4.1.1.6" xref="S4.SS2.p1.4.m4.1.1.6.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><apply id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1"><times id="S4.SS2.p1.4.m4.1.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1.1"></times><ci id="S4.SS2.p1.4.m4.1.1.2.cmml" xref="S4.SS2.p1.4.m4.1.1.2">ğ‘‚</ci><ci id="S4.SS2.p1.4.m4.1.1.3.cmml" xref="S4.SS2.p1.4.m4.1.1.3">ğ‘¡</ci><ci id="S4.SS2.p1.4.m4.1.1.4.cmml" xref="S4.SS2.p1.4.m4.1.1.4">â„</ci><ci id="S4.SS2.p1.4.m4.1.1.5.cmml" xref="S4.SS2.p1.4.m4.1.1.5">ğ‘’</ci><ci id="S4.SS2.p1.4.m4.1.1.6.cmml" xref="S4.SS2.p1.4.m4.1.1.6">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">Other</annotation></semantics></math> (41 were â€™unclassifiedâ€™, and we do not consider them during training).
We retain 20% of this subset as training (randomly sampled keeping the same class occurrences) and, through the data augmentation techniques described before, we evaluated the generalization capabilities of the proposed model.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Results</h3>

<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Results without data augmentation (<em id="S4.T1.10.1" class="ltx_emph ltx_font_italic">No Aug.</em>); Data Augmentation with Rows and Columns inversion (<em id="S4.T1.11.2" class="ltx_emph ltx_font_italic">R/C</em>); Data Augmentation with Rows and Columns inversion and random removal of nodes and edges (<em id="S4.T1.12.3" class="ltx_emph ltx_font_italic">All</em>). <math id="S4.T1.4.m1.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S4.T1.4.m1.1b"><mi id="S4.T1.4.m1.1.1" xref="S4.T1.4.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.T1.4.m1.1c"><ci id="S4.T1.4.m1.1.1.cmml" xref="S4.T1.4.m1.1.1">ğ‘ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.m1.1d">P</annotation></semantics></math>, <math id="S4.T1.5.m2.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S4.T1.5.m2.1b"><mi id="S4.T1.5.m2.1.1" xref="S4.T1.5.m2.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S4.T1.5.m2.1c"><ci id="S4.T1.5.m2.1.1.cmml" xref="S4.T1.5.m2.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.m2.1d">R</annotation></semantics></math> and <math id="S4.T1.6.m3.1" class="ltx_Math" alttext="F1" display="inline"><semantics id="S4.T1.6.m3.1b"><mrow id="S4.T1.6.m3.1.1" xref="S4.T1.6.m3.1.1.cmml"><mi id="S4.T1.6.m3.1.1.2" xref="S4.T1.6.m3.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S4.T1.6.m3.1.1.1" xref="S4.T1.6.m3.1.1.1.cmml">â€‹</mo><mn id="S4.T1.6.m3.1.1.3" xref="S4.T1.6.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.6.m3.1c"><apply id="S4.T1.6.m3.1.1.cmml" xref="S4.T1.6.m3.1.1"><times id="S4.T1.6.m3.1.1.1.cmml" xref="S4.T1.6.m3.1.1.1"></times><ci id="S4.T1.6.m3.1.1.2.cmml" xref="S4.T1.6.m3.1.1.2">ğ¹</ci><cn type="integer" id="S4.T1.6.m3.1.1.3.cmml" xref="S4.T1.6.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.m3.1d">F1</annotation></semantics></math> correspond to Precision, Recall and F1 score.</figcaption>
<table id="S4.T1.13" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.13.1.1" class="ltx_tr">
<td id="S4.T1.13.1.1.1" class="ltx_td ltx_border_r"></td>
<td id="S4.T1.13.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="6"><em id="S4.T1.13.1.1.2.1" class="ltx_emph ltx_font_italic">No Aug.</em></td>
<td id="S4.T1.13.1.1.3" class="ltx_td" colspan="6"></td>
</tr>
<tr id="S4.T1.13.2.2" class="ltx_tr">
<td id="S4.T1.13.2.2.1" class="ltx_td ltx_border_r"></td>
<td id="S4.T1.13.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="6">train size: 63</td>
<td id="S4.T1.13.2.2.3" class="ltx_td" colspan="6"></td>
</tr>
<tr id="S4.T1.13.3.3" class="ltx_tr">
<td id="S4.T1.13.3.3.1" class="ltx_td ltx_border_r"></td>
<td id="S4.T1.13.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="S4.T1.13.3.3.2.1" class="ltx_text ltx_font_bold">web_lg</span></td>
<td id="S4.T1.13.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="S4.T1.13.3.3.3.1" class="ltx_text ltx_font_bold">sci_lg</span></td>
<td id="S4.T1.13.3.3.4" class="ltx_td" colspan="6"></td>
</tr>
<tr id="S4.T1.13.4.4" class="ltx_tr">
<td id="S4.T1.13.4.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t">
<em id="S4.T1.13.4.4.1.1" class="ltx_emph ltx_font_italic">Classes</em> (#)</td>
<td id="S4.T1.13.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.4.4.2.1" class="ltx_emph ltx_font_italic">P</em></td>
<td id="S4.T1.13.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.4.4.3.1" class="ltx_emph ltx_font_italic">R</em></td>
<td id="S4.T1.13.4.4.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><em id="S4.T1.13.4.4.4.1" class="ltx_emph ltx_font_italic">F1</em></td>
<td id="S4.T1.13.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.4.4.5.1" class="ltx_emph ltx_font_italic">P</em></td>
<td id="S4.T1.13.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.4.4.6.1" class="ltx_emph ltx_font_italic">R</em></td>
<td id="S4.T1.13.4.4.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><em id="S4.T1.13.4.4.7.1" class="ltx_emph ltx_font_italic">F1</em></td>
<td id="S4.T1.13.4.4.8" class="ltx_td" colspan="6"></td>
</tr>
<tr id="S4.T1.13.5.5" class="ltx_tr">
<td id="S4.T1.13.5.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t">Observation (185)</td>
<td id="S4.T1.13.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.85</td>
<td id="S4.T1.13.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.84</td>
<td id="S4.T1.13.5.5.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.84</td>
<td id="S4.T1.13.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.87</td>
<td id="S4.T1.13.5.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.92</td>
<td id="S4.T1.13.5.5.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.89</td>
<td id="S4.T1.13.5.5.8" class="ltx_td"></td>
<td id="S4.T1.13.5.5.9" class="ltx_td"></td>
<td id="S4.T1.13.5.5.10" class="ltx_td"></td>
<td id="S4.T1.13.5.5.11" class="ltx_td"></td>
<td id="S4.T1.13.5.5.12" class="ltx_td"></td>
<td id="S4.T1.13.5.5.13" class="ltx_td"></td>
</tr>
<tr id="S4.T1.13.6.6" class="ltx_tr">
<td id="S4.T1.13.6.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t">Input (35)</td>
<td id="S4.T1.13.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.37</td>
<td id="S4.T1.13.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.49</td>
<td id="S4.T1.13.6.6.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.42</td>
<td id="S4.T1.13.6.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.47</td>
<td id="S4.T1.13.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.54</td>
<td id="S4.T1.13.6.6.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.51</td>
<td id="S4.T1.13.6.6.8" class="ltx_td"></td>
<td id="S4.T1.13.6.6.9" class="ltx_td"></td>
<td id="S4.T1.13.6.6.10" class="ltx_td"></td>
<td id="S4.T1.13.6.6.11" class="ltx_td"></td>
<td id="S4.T1.13.6.6.12" class="ltx_td"></td>
<td id="S4.T1.13.6.6.13" class="ltx_td"></td>
</tr>
<tr id="S4.T1.13.7.7" class="ltx_tr">
<td id="S4.T1.13.7.7.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t">Example (10)</td>
<td id="S4.T1.13.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.42</td>
<td id="S4.T1.13.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.5</td>
<td id="S4.T1.13.7.7.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.45</td>
<td id="S4.T1.13.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.67</td>
<td id="S4.T1.13.7.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.2</td>
<td id="S4.T1.13.7.7.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.31</td>
<td id="S4.T1.13.7.7.8" class="ltx_td"></td>
<td id="S4.T1.13.7.7.9" class="ltx_td"></td>
<td id="S4.T1.13.7.7.10" class="ltx_td"></td>
<td id="S4.T1.13.7.7.11" class="ltx_td"></td>
<td id="S4.T1.13.7.7.12" class="ltx_td"></td>
<td id="S4.T1.13.7.7.13" class="ltx_td"></td>
</tr>
<tr id="S4.T1.13.8.8" class="ltx_tr">
<td id="S4.T1.13.8.8.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t">Other (23)</td>
<td id="S4.T1.13.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.00</td>
<td id="S4.T1.13.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.00</td>
<td id="S4.T1.13.8.8.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.00</td>
<td id="S4.T1.13.8.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.43</td>
<td id="S4.T1.13.8.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.26</td>
<td id="S4.T1.13.8.8.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.32</td>
<td id="S4.T1.13.8.8.8" class="ltx_td"></td>
<td id="S4.T1.13.8.8.9" class="ltx_td"></td>
<td id="S4.T1.13.8.8.10" class="ltx_td"></td>
<td id="S4.T1.13.8.8.11" class="ltx_td"></td>
<td id="S4.T1.13.8.8.12" class="ltx_td"></td>
<td id="S4.T1.13.8.8.13" class="ltx_td"></td>
</tr>
<tr id="S4.T1.13.9.9" class="ltx_tr">
<td id="S4.T1.13.9.9.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_tt">
<em id="S4.T1.13.9.9.1.1" class="ltx_emph ltx_font_italic">All</em> (253)</td>
<td id="S4.T1.13.9.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.41</td>
<td id="S4.T1.13.9.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.46</td>
<td id="S4.T1.13.9.9.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">0.43</td>
<td id="S4.T1.13.9.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.61</td>
<td id="S4.T1.13.9.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.48</td>
<td id="S4.T1.13.9.9.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span id="S4.T1.13.9.9.7.1" class="ltx_text ltx_font_bold">0.51</span></td>
<td id="S4.T1.13.9.9.8" class="ltx_td"></td>
<td id="S4.T1.13.9.9.9" class="ltx_td"></td>
<td id="S4.T1.13.9.9.10" class="ltx_td"></td>
<td id="S4.T1.13.9.9.11" class="ltx_td"></td>
<td id="S4.T1.13.9.9.12" class="ltx_td"></td>
<td id="S4.T1.13.9.9.13" class="ltx_td"></td>
</tr>
<tr id="S4.T1.13.10.10" class="ltx_tr">
<td id="S4.T1.13.10.10.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T1.13.10.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="12"><em id="S4.T1.13.10.10.2.1" class="ltx_emph ltx_font_italic">R/C</em></td>
</tr>
<tr id="S4.T1.13.11.11" class="ltx_tr">
<td id="S4.T1.13.11.11.1" class="ltx_td ltx_border_r"></td>
<td id="S4.T1.13.11.11.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" colspan="6">train size: 200</td>
<td id="S4.T1.13.11.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="6">train size: 400</td>
</tr>
<tr id="S4.T1.13.12.12" class="ltx_tr">
<td id="S4.T1.13.12.12.1" class="ltx_td ltx_border_r"></td>
<td id="S4.T1.13.12.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="S4.T1.13.12.12.2.1" class="ltx_text ltx_font_bold">web_lg</span></td>
<td id="S4.T1.13.12.12.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" colspan="3"><span id="S4.T1.13.12.12.3.1" class="ltx_text ltx_font_bold">sci_lg</span></td>
<td id="S4.T1.13.12.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="S4.T1.13.12.12.4.1" class="ltx_text ltx_font_bold">web_lg</span></td>
<td id="S4.T1.13.12.12.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="S4.T1.13.12.12.5.1" class="ltx_text ltx_font_bold">sci_lg</span></td>
</tr>
<tr id="S4.T1.13.13.13" class="ltx_tr">
<td id="S4.T1.13.13.13.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t">
<em id="S4.T1.13.13.13.1.1" class="ltx_emph ltx_font_italic">Classes</em> (#)</td>
<td id="S4.T1.13.13.13.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.13.13.2.1" class="ltx_emph ltx_font_italic">P</em></td>
<td id="S4.T1.13.13.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.13.13.3.1" class="ltx_emph ltx_font_italic">R</em></td>
<td id="S4.T1.13.13.13.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><em id="S4.T1.13.13.13.4.1" class="ltx_emph ltx_font_italic">F1</em></td>
<td id="S4.T1.13.13.13.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.13.13.5.1" class="ltx_emph ltx_font_italic">P</em></td>
<td id="S4.T1.13.13.13.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.13.13.6.1" class="ltx_emph ltx_font_italic">R</em></td>
<td id="S4.T1.13.13.13.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><em id="S4.T1.13.13.13.7.1" class="ltx_emph ltx_font_italic">F1</em></td>
<td id="S4.T1.13.13.13.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.13.13.8.1" class="ltx_emph ltx_font_italic">P</em></td>
<td id="S4.T1.13.13.13.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.13.13.9.1" class="ltx_emph ltx_font_italic">R</em></td>
<td id="S4.T1.13.13.13.10" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><em id="S4.T1.13.13.13.10.1" class="ltx_emph ltx_font_italic">F1</em></td>
<td id="S4.T1.13.13.13.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.13.13.11.1" class="ltx_emph ltx_font_italic">P</em></td>
<td id="S4.T1.13.13.13.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.13.13.12.1" class="ltx_emph ltx_font_italic">R</em></td>
<td id="S4.T1.13.13.13.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.13.13.13.1" class="ltx_emph ltx_font_italic">F1</em></td>
</tr>
<tr id="S4.T1.13.14.14" class="ltx_tr">
<td id="S4.T1.13.14.14.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t">Observation (185)</td>
<td id="S4.T1.13.14.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.82</td>
<td id="S4.T1.13.14.14.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.84</td>
<td id="S4.T1.13.14.14.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.83</td>
<td id="S4.T1.13.14.14.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.85</td>
<td id="S4.T1.13.14.14.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.92</td>
<td id="S4.T1.13.14.14.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.89</td>
<td id="S4.T1.13.14.14.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.82</td>
<td id="S4.T1.13.14.14.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.84</td>
<td id="S4.T1.13.14.14.10" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.84</td>
<td id="S4.T1.13.14.14.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.84</td>
<td id="S4.T1.13.14.14.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.94</td>
<td id="S4.T1.13.14.14.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.88</td>
</tr>
<tr id="S4.T1.13.15.15" class="ltx_tr">
<td id="S4.T1.13.15.15.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t">Input (35)</td>
<td id="S4.T1.13.15.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.37</td>
<td id="S4.T1.13.15.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.43</td>
<td id="S4.T1.13.15.15.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.39</td>
<td id="S4.T1.13.15.15.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.52</td>
<td id="S4.T1.13.15.15.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.46</td>
<td id="S4.T1.13.15.15.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.48</td>
<td id="S4.T1.13.15.15.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.34</td>
<td id="S4.T1.13.15.15.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.34</td>
<td id="S4.T1.13.15.15.10" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.34</td>
<td id="S4.T1.13.15.15.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.52</td>
<td id="S4.T1.13.15.15.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.40</td>
<td id="S4.T1.13.15.15.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.45</td>
</tr>
<tr id="S4.T1.13.16.16" class="ltx_tr">
<td id="S4.T1.13.16.16.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t">Example (10)</td>
<td id="S4.T1.13.16.16.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.80</td>
<td id="S4.T1.13.16.16.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.40</td>
<td id="S4.T1.13.16.16.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.53</td>
<td id="S4.T1.13.16.16.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.60</td>
<td id="S4.T1.13.16.16.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.30</td>
<td id="S4.T1.13.16.16.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.40</td>
<td id="S4.T1.13.16.16.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.57</td>
<td id="S4.T1.13.16.16.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.40</td>
<td id="S4.T1.13.16.16.10" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.47</td>
<td id="S4.T1.13.16.16.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.50</td>
<td id="S4.T1.13.16.16.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.30</td>
<td id="S4.T1.13.16.16.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.37</td>
</tr>
<tr id="S4.T1.13.17.17" class="ltx_tr">
<td id="S4.T1.13.17.17.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t">Other (23)</td>
<td id="S4.T1.13.17.17.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.06</td>
<td id="S4.T1.13.17.17.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.04</td>
<td id="S4.T1.13.17.17.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.05</td>
<td id="S4.T1.13.17.17.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.41</td>
<td id="S4.T1.13.17.17.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.30</td>
<td id="S4.T1.13.17.17.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.35</td>
<td id="S4.T1.13.17.17.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.05</td>
<td id="S4.T1.13.17.17.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.04</td>
<td id="S4.T1.13.17.17.10" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.05</td>
<td id="S4.T1.13.17.17.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.50</td>
<td id="S4.T1.13.17.17.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.30</td>
<td id="S4.T1.13.17.17.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.38</td>
</tr>
<tr id="S4.T1.13.18.18" class="ltx_tr">
<td id="S4.T1.13.18.18.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" colspan="13"><span class="ltx_rule" style="width:100%;height:2.0pt;background:black;display:inline-block;">Â </span></td>
</tr>
<tr id="S4.T1.13.19.19" class="ltx_tr">
<td id="S4.T1.13.19.19.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr">
<em id="S4.T1.13.19.19.1.1" class="ltx_emph ltx_font_italic">All</em> (253)</td>
<td id="S4.T1.13.19.19.2" class="ltx_td ltx_align_center ltx_border_r">0.51</td>
<td id="S4.T1.13.19.19.3" class="ltx_td ltx_align_center ltx_border_r">0.43</td>
<td id="S4.T1.13.19.19.4" class="ltx_td ltx_align_center ltx_border_rr">0.45</td>
<td id="S4.T1.13.19.19.5" class="ltx_td ltx_align_center ltx_border_r">0.60</td>
<td id="S4.T1.13.19.19.6" class="ltx_td ltx_align_center ltx_border_r">0.50</td>
<td id="S4.T1.13.19.19.7" class="ltx_td ltx_align_center ltx_border_rr"><span id="S4.T1.13.19.19.7.1" class="ltx_text ltx_font_bold">0.53</span></td>
<td id="S4.T1.13.19.19.8" class="ltx_td ltx_align_center ltx_border_r">0.45</td>
<td id="S4.T1.13.19.19.9" class="ltx_td ltx_align_center ltx_border_r">0.41</td>
<td id="S4.T1.13.19.19.10" class="ltx_td ltx_align_center ltx_border_rr">0.42</td>
<td id="S4.T1.13.19.19.11" class="ltx_td ltx_align_center ltx_border_r">0.59</td>
<td id="S4.T1.13.19.19.12" class="ltx_td ltx_align_center ltx_border_r">0.48</td>
<td id="S4.T1.13.19.19.13" class="ltx_td ltx_align_center ltx_border_r">0.52</td>
</tr>
<tr id="S4.T1.13.20.20" class="ltx_tr">
<td id="S4.T1.13.20.20.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T1.13.20.20.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="12"><em id="S4.T1.13.20.20.2.1" class="ltx_emph ltx_font_italic">All</em></td>
</tr>
<tr id="S4.T1.13.21.21" class="ltx_tr">
<td id="S4.T1.13.21.21.1" class="ltx_td ltx_border_r"></td>
<td id="S4.T1.13.21.21.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" colspan="6">train size: 200</td>
<td id="S4.T1.13.21.21.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="6">train size: 400</td>
</tr>
<tr id="S4.T1.13.22.22" class="ltx_tr">
<td id="S4.T1.13.22.22.1" class="ltx_td ltx_border_r"></td>
<td id="S4.T1.13.22.22.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="S4.T1.13.22.22.2.1" class="ltx_text ltx_font_bold">web_lg</span></td>
<td id="S4.T1.13.22.22.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" colspan="3"><span id="S4.T1.13.22.22.3.1" class="ltx_text ltx_font_bold">sci_lg</span></td>
<td id="S4.T1.13.22.22.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="S4.T1.13.22.22.4.1" class="ltx_text ltx_font_bold">web_lg</span></td>
<td id="S4.T1.13.22.22.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="S4.T1.13.22.22.5.1" class="ltx_text ltx_font_bold">sci_lg</span></td>
</tr>
<tr id="S4.T1.13.23.23" class="ltx_tr">
<td id="S4.T1.13.23.23.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t">
<em id="S4.T1.13.23.23.1.1" class="ltx_emph ltx_font_italic">Classes</em> (#)</td>
<td id="S4.T1.13.23.23.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.23.23.2.1" class="ltx_emph ltx_font_italic">P</em></td>
<td id="S4.T1.13.23.23.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.23.23.3.1" class="ltx_emph ltx_font_italic">R</em></td>
<td id="S4.T1.13.23.23.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><em id="S4.T1.13.23.23.4.1" class="ltx_emph ltx_font_italic">F1</em></td>
<td id="S4.T1.13.23.23.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.23.23.5.1" class="ltx_emph ltx_font_italic">P</em></td>
<td id="S4.T1.13.23.23.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.23.23.6.1" class="ltx_emph ltx_font_italic">R</em></td>
<td id="S4.T1.13.23.23.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><em id="S4.T1.13.23.23.7.1" class="ltx_emph ltx_font_italic">F1</em></td>
<td id="S4.T1.13.23.23.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.23.23.8.1" class="ltx_emph ltx_font_italic">P</em></td>
<td id="S4.T1.13.23.23.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.23.23.9.1" class="ltx_emph ltx_font_italic">R</em></td>
<td id="S4.T1.13.23.23.10" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><em id="S4.T1.13.23.23.10.1" class="ltx_emph ltx_font_italic">F1</em></td>
<td id="S4.T1.13.23.23.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.23.23.11.1" class="ltx_emph ltx_font_italic">P</em></td>
<td id="S4.T1.13.23.23.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.23.23.12.1" class="ltx_emph ltx_font_italic">R</em></td>
<td id="S4.T1.13.23.23.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><em id="S4.T1.13.23.23.13.1" class="ltx_emph ltx_font_italic">F1</em></td>
</tr>
<tr id="S4.T1.13.24.24" class="ltx_tr">
<td id="S4.T1.13.24.24.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t">Observation (185)</td>
<td id="S4.T1.13.24.24.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.81</td>
<td id="S4.T1.13.24.24.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.83</td>
<td id="S4.T1.13.24.24.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.82</td>
<td id="S4.T1.13.24.24.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.85</td>
<td id="S4.T1.13.24.24.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.94</td>
<td id="S4.T1.13.24.24.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.89</td>
<td id="S4.T1.13.24.24.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.81</td>
<td id="S4.T1.13.24.24.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.82</td>
<td id="S4.T1.13.24.24.10" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.81</td>
<td id="S4.T1.13.24.24.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.84</td>
<td id="S4.T1.13.24.24.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.93</td>
<td id="S4.T1.13.24.24.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.88</td>
</tr>
<tr id="S4.T1.13.25.25" class="ltx_tr">
<td id="S4.T1.13.25.25.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t">Input (35)</td>
<td id="S4.T1.13.25.25.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.32</td>
<td id="S4.T1.13.25.25.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.37</td>
<td id="S4.T1.13.25.25.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.34</td>
<td id="S4.T1.13.25.25.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.48</td>
<td id="S4.T1.13.25.25.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.40</td>
<td id="S4.T1.13.25.25.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.44</td>
<td id="S4.T1.13.25.25.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.33</td>
<td id="S4.T1.13.25.25.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.40</td>
<td id="S4.T1.13.25.25.10" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.36</td>
<td id="S4.T1.13.25.25.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.52</td>
<td id="S4.T1.13.25.25.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.43</td>
<td id="S4.T1.13.25.25.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.47</td>
</tr>
<tr id="S4.T1.13.26.26" class="ltx_tr">
<td id="S4.T1.13.26.26.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t">Example (10)</td>
<td id="S4.T1.13.26.26.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.80</td>
<td id="S4.T1.13.26.26.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.40</td>
<td id="S4.T1.13.26.26.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.53</td>
<td id="S4.T1.13.26.26.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.67</td>
<td id="S4.T1.13.26.26.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.40</td>
<td id="S4.T1.13.26.26.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.50</td>
<td id="S4.T1.13.26.26.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.60</td>
<td id="S4.T1.13.26.26.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.30</td>
<td id="S4.T1.13.26.26.10" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.40</td>
<td id="S4.T1.13.26.26.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.50</td>
<td id="S4.T1.13.26.26.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.30</td>
<td id="S4.T1.13.26.26.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.37</td>
</tr>
<tr id="S4.T1.13.27.27" class="ltx_tr">
<td id="S4.T1.13.27.27.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t">Other (23)</td>
<td id="S4.T1.13.27.27.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.06</td>
<td id="S4.T1.13.27.27.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.04</td>
<td id="S4.T1.13.27.27.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.05</td>
<td id="S4.T1.13.27.27.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.57</td>
<td id="S4.T1.13.27.27.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.35</td>
<td id="S4.T1.13.27.27.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.43</td>
<td id="S4.T1.13.27.27.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.05</td>
<td id="S4.T1.13.27.27.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.04</td>
<td id="S4.T1.13.27.27.10" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.05</td>
<td id="S4.T1.13.27.27.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.36</td>
<td id="S4.T1.13.27.27.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.22</td>
<td id="S4.T1.13.27.27.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.27</td>
</tr>
<tr id="S4.T1.13.28.28" class="ltx_tr">
<td id="S4.T1.13.28.28.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" colspan="13"><span class="ltx_rule" style="width:100%;height:2.0pt;background:black;display:inline-block;">Â </span></td>
</tr>
<tr id="S4.T1.13.29.29" class="ltx_tr">
<td id="S4.T1.13.29.29.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_rr">
<em id="S4.T1.13.29.29.1.1" class="ltx_emph ltx_font_italic">All</em> (253)</td>
<td id="S4.T1.13.29.29.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.50</td>
<td id="S4.T1.13.29.29.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.41</td>
<td id="S4.T1.13.29.29.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr">0.44</td>
<td id="S4.T1.13.29.29.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.64</td>
<td id="S4.T1.13.29.29.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.52</td>
<td id="S4.T1.13.29.29.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr"><span id="S4.T1.13.29.29.7.1" class="ltx_text ltx_font_bold">0.56</span></td>
<td id="S4.T1.13.29.29.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.45</td>
<td id="S4.T1.13.29.29.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.39</td>
<td id="S4.T1.13.29.29.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr"><span id="S4.T1.13.29.29.10.1" class="ltx_text ltx_font_bold">0.41</span></td>
<td id="S4.T1.13.29.29.11" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.55</td>
<td id="S4.T1.13.29.29.12" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.47</td>
<td id="S4.T1.13.29.29.13" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.50</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span> Summary of F1 score for different data augmentation approaches. <em id="S4.T2.4.1" class="ltx_emph ltx_font_italic">No Aug.</em> indicates no Data Augmentation technique was applied, <em id="S4.T2.5.2" class="ltx_emph ltx_font_italic">R/C</em> indicates row and column inversion technique and <em id="S4.T2.6.3" class="ltx_emph ltx_font_italic">All</em> indicates row and column inversion technique and random removal of nodes and arcs. </figcaption>
<table id="S4.T2.7" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.7.1.1" class="ltx_tr">
<th id="S4.T2.7.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_r"></th>
<th id="S4.T2.7.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t"><span id="S4.T2.7.1.1.2.1" class="ltx_text ltx_font_bold">No Aug.</span></th>
<th id="S4.T2.7.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t" colspan="2"><span id="S4.T2.7.1.1.3.1" class="ltx_text ltx_font_bold">R/C</span></th>
<th id="S4.T2.7.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2"><span id="S4.T2.7.1.1.4.1" class="ltx_text ltx_font_bold">All</span></th>
</tr>
<tr id="S4.T2.7.2.2" class="ltx_tr">
<th id="S4.T2.7.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_rr ltx_border_t">train size</th>
<th id="S4.T2.7.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t">64</th>
<th id="S4.T2.7.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">200</th>
<th id="S4.T2.7.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t">400</th>
<th id="S4.T2.7.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">200</th>
<th id="S4.T2.7.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">400</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.7.3.1" class="ltx_tr">
<td id="S4.T2.7.3.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t"><code id="S4.T2.7.3.1.1.1" class="ltx_verbatim ltx_font_typewriter">en_core_web_lg</code></td>
<td id="S4.T2.7.3.1.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.43</td>
<td id="S4.T2.7.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.7.3.1.3.1" class="ltx_text ltx_font_bold">0.45</span></td>
<td id="S4.T2.7.3.1.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.44</td>
<td id="S4.T2.7.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.7.3.1.5.1" class="ltx_text ltx_font_bold">0.49</span></td>
<td id="S4.T2.7.3.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.41</td>
</tr>
<tr id="S4.T2.7.4.2" class="ltx_tr">
<td id="S4.T2.7.4.2.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_rr ltx_border_t"><code id="S4.T2.7.4.2.1.1" class="ltx_verbatim ltx_font_typewriter">en_core_sci_lg</code></td>
<td id="S4.T2.7.4.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t">0.52</td>
<td id="S4.T2.7.4.2.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.7.4.2.3.1" class="ltx_text ltx_font_bold">0.53</span></td>
<td id="S4.T2.7.4.2.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t">0.52</td>
<td id="S4.T2.7.4.2.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.7.4.2.5.1" class="ltx_text ltx_font_bold">0.56</span></td>
<td id="S4.T2.7.4.2.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.51</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">The main experiments performed are summarized in TableÂ <a href="#S4.T1" title="Table 1 â€£ 4.3 Results â€£ 4 Experiments â€£ Data augmentation on graphs for table type classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> that compares results obtained by applying different Data Augmentation techniques and spaCy models <code id="S4.SS3.p1.1.1" class="ltx_verbatim ltx_font_typewriter">en_core_web_lg</code>
and <code id="S4.SS3.p1.1.2" class="ltx_verbatim ltx_font_typewriter">en_core_sci_lg</code> with baseline results.
In bold we highlight the most significant results of the F1 score for each technique applied. These values are also summarized in TableÂ <a href="#S4.T2" title="Table 2 â€£ 4.3 Results â€£ 4 Experiments â€£ Data augmentation on graphs for table type classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> to discuss the outcomes of the experiment. Table <a href="#S4.T2" title="Table 2 â€£ 4.3 Results â€£ 4 Experiments â€£ Data augmentation on graphs for table type classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> summarizes the best F1 score values obtained considering some DA combinations. We can observe that the models appear rather inaccurate. This is mainly caused by the dataset itself, that is unbalanced toward the Observation class and small in size.
It can also be seen that models using the <code id="S4.SS3.p1.1.3" class="ltx_verbatim ltx_font_typewriter">en_core_sci_lg</code> embedding show better results than those using <code id="S4.SS3.p1.1.4" class="ltx_verbatim ltx_font_typewriter">en_core_web_lg</code>, since the first one is a biomedical-based embedding that is most likely capable of appropriately characterizing and recognizing terms present in the tables extracted from scientific documents.
In particular, models that exploit <code id="S4.SS3.p1.1.5" class="ltx_verbatim ltx_font_typewriter">en_core_web_lg</code> and do not use data augmentation techniques turn out to be less accurate and fail to recognize any table of class Other.
In general, models that employ data augmentation result in higher F1 score values.
Furthermore, observing Table <a href="#S4.T2" title="Table 2 â€£ 4.3 Results â€£ 4 Experiments â€£ Data augmentation on graphs for table type classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, it can be seen that better values are obtained for the models in which data augmentation techniques are applied: particularly among these, the one obtained by alternating the inversion of rows and columns with random removal of nodes and arcs is preferable.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this work we presented a GNN model for classifying tables in scientific articles applying Data Augmentation techniques. The results achieved are promising but still show limitations.
In particular, the imbalance in the available data and a very low number of examples demonstrate that it is difficult to achieve good generalization. However, the use of Data Augmentation techniques made it possible to improve the results obtained by an increase in the F1-Score measure in the ablation studies presented.
The proposed solution has some aspects that could be deepened or improved to further develop the work started. First, it might be useful to test the implemented Data Augmentation techniques on other datasets to analyze their potential and efficiency. In addition, other Data Augmentation techniques could be implemented, such as adding or removing rows and columns to a table, or improving the techniques already implemented. For example, the row and column recognition techniques could be improved, especially in the case of multi-row tables.
We conclude by noting how such Data Augmentation techniques applied directly to graphs could prove to be an interesting clue for the application of Graph Neural Networks in the presence of resource-limited datasets, a very common situation in many application domains.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Baldi, S., Marinai, S., Soda, G.: Using tree-grammars for training set
expansion in page classification. In: Seventh International Conference on
Document Analysis and Recognition, 2003. Proceedings. pp. 829â€“833 (2003)

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Clark, C., Divvala, S.: Pdffigures 2.0: Mining figures from research papers.
In: Proc. 16th Joint Conference on Digital Libraries. p. 143â€“152. JCDL â€™16,
ACM (2016)

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Gemelli, A., Vivoli, E.V., Marinai, S.: Graph neural networks and
representation embedding for table extraction in PDF documents. In:
accepted for publication at ICPR22 (2022)

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Hashmi, K.A., Liwicki, M., Stricker, D., Afzal, M.A., Afzal, M.A., Afzal, M.Z.:
Current status and performance analysis of table recognition in document
images with deep neural networks. IEEE Access <span id="bib.bib4.1.1" class="ltx_text ltx_font_bold">9</span>, 87663â€“87685
(2021)

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Honnibal, M., Montani, I.: Natural language understanding with bloom
embeddings, convolutional neural networks and incremental parsing.
Unpublished software application. https://spacy. io (2017)

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Kardas, M., Czapla, P., Stenetorp, P., Ruder, S., Riedel, S., Taylor, R.,
Stojnic, R.: Axcell: Automatic extraction of results from machine learning
papers. arXiv preprint arXiv:2004.14356 (2020)

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Khan, U., Zahid, S., Ali, M.A., Ul-Hasan, A., Shafait, F.: Tabaug: Data driven
augmentation for enhanced table structure recognition. In: International
Conference on Document Analysis and Recognition. pp. 585â€“601. Springer
(2021)

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Kipf, T.N., Welling, M.: Semi-supervised classification with graph
convolutional networks. CoRR <span id="bib.bib8.1.1" class="ltx_text ltx_font_bold">abs/1609.02907</span> (2016),
<a target="_blank" href="http://arxiv.org/abs/1609.02907" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1609.02907</a>

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Kruit, B., He, H., Urbani, J.: Tab2Know: building a Knowledge Base from
tables in scientific papers. ArXiv <span id="bib.bib9.1.1" class="ltx_text ltx_font_bold">abs/2107.13306</span> (2020)

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
McKie, J.X.: PyMuPDF documentation. github (2022)

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Qiao, L., Li, Z., Cheng, Z., Zhang, P., Pu, S., Niu, Y., Ren, W., Tan, W., Wu,
F.: LGPMA: complicated table structure recognition with local and global
pyramid mask alignment. In: ICDAR. vol. 12821, pp. 99â€“114 (2021)

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Ratner, A., Bach, S.H., Ehrenberg, H., Fries, J., Wu, S., RÃ©, C.: Snorkel:
Rapid training data creation with weak supervision. In: Proceedings of the
VLDB Endowment. International Conference on Very Large Data Bases. vol.Â 11,
p.Â 269. NIH Public Access (2017)

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Riba, P., Dutta, A., Goldmann, L., FornÃ©s, A., Ramos, O., LladÃ³s, J.:
Table detection in invoice documents by graph neural networks. In: 2019
International Conference on Document Analysis and Recognition (ICDAR). pp.
122â€“127. IEEE (2019)

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Smock, B., Pesala, R., Abraham, R.: Pubtables-1m: Towards comprehensive table
extraction from unstructured documents. CoRR <span id="bib.bib14.1.1" class="ltx_text ltx_font_bold">abs/2110.00061</span> (2021),
<a target="_blank" href="https://arxiv.org/abs/2110.00061" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2110.00061</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Zhang, P., Li, C., Qiao, L., Cheng, Z., Pu, S., Niu, Y., Wu, F.: Vsr: A unified
framework for document layout analysis combining vision, semantics and
relations. In: ICDAR. vol. 12821, pp. 115â€“130 (2021)

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Zhao, T., Liu, Y., Neves, L., Woodford, O.J., Jiang, M., Shah, N.: Data
augmentation for graph neural networks. CoRR <span id="bib.bib16.1.1" class="ltx_text ltx_font_bold">abs/2006.06830</span> (2020),
<a target="_blank" href="https://arxiv.org/abs/2006.06830" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2006.06830</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Zoph, B., Cubuk, E.D., Ghiasi, G., Lin, T.Y., Shlens, J., Le, Q.V.: Learning
data augmentation strategies for object detection. In: European conference on
computer vision. pp. 566â€“583. Springer (2020)

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2208.11209" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2208.11210" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2208.11210">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2208.11210" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2208.11211" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Mar 13 18:28:26 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
