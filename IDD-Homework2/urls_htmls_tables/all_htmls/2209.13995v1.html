<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2209.13995] Revealing the Semantics of Data Wrangling Scripts With Comantics</title><meta property="og:description" content="Data workers usually seek to understand the semantics of data wrangling scripts in various scenarios, such as code debugging, reusing, and maintaining. However, the understanding is challenging for novice data workers …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Revealing the Semantics of Data Wrangling Scripts With Comantics">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Revealing the Semantics of Data Wrangling Scripts With Comantics">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2209.13995">

<!--Generated on Thu Mar 14 00:00:34 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\onlineid</span>
<p id="p1.2" class="ltx_p">1346
<span id="p1.2.1" class="ltx_ERROR undefined">\vgtccategory</span>Data Transformations
<span id="p1.2.2" class="ltx_ERROR undefined">\vgtcpapertype</span>Data Transformations




<span id="p1.2.3" class="ltx_ERROR undefined">\authorfooter</span>
K. Xiong and Y. Wu are with the State
Key Lab of CAD&amp;CG, Zhejiang University, Hangzhou, China, and with the Zhejiang Lab, Hangzhou, China.
E-mail: {kaixiong, ycwu}@zju.edu.cn.
Z. Luo is with Zhejiang University of Technology, Hangzhou, China, and with the Zhejiang Lab, Hangzhou, China. E-mail: rickyluozs@gmail.com.
S. Fu and Y. Wang are with the Zhejiang Lab, Hangzhou, China. E-mail: fusiwei339@gmail.com, wangyh@zhejianglab.com.
M. Xu is with the School of Computer and Artificial Intelligence, Zhengzhou University, Zhengzhou, China.
E-mail: iexumingliang@zzu.edu.cn.
Yongheng Wang and Siwei Fu are the co-corresponding authors.

<span id="p1.2.4" class="ltx_ERROR undefined">\shortauthortitle</span>Biv <span id="p1.2.5" class="ltx_text ltx_font_italic">et al.</span>: Global Illumination for Fun and Profit</p>
</div>
<h1 class="ltx_title ltx_title_document">Revealing the Semantics of Data Wrangling Scripts 
<br class="ltx_break">With <span id="2.1" class="ltx_text ltx_font_smallcaps">Comantics</span>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kai Xiong
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Zhongsu Luo
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Siwei Fu
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Yongheng Wang
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Mingliang Xu
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Yingcai Wu
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="1" class="ltx_p">Data workers usually seek to understand the semantics of data wrangling scripts in various scenarios, such as code debugging, reusing, and maintaining. However, the understanding is challenging for novice data workers due to the variety of programming languages, functions, and parameters. Based on the observation that differences between input and output tables highly relate to the type of data transformation, we outline a design space including <math id="1.m1.1" class="ltx_Math" alttext="103" display="inline"><semantics id="1.m1.1a"><mn id="1.m1.1.1" xref="1.m1.1.1.cmml">103</mn><annotation-xml encoding="MathML-Content" id="1.m1.1b"><cn type="integer" id="1.m1.1.1.cmml" xref="1.m1.1.1">103</cn></annotation-xml><annotation encoding="application/x-tex" id="1.m1.1c">103</annotation></semantics></math> characteristics to describe table differences. Then, we develop <span id="1.1" class="ltx_text ltx_font_smallcaps">Comantics</span>, a three-step pipeline that automatically detects the semantics of data transformation scripts. The first step focuses on the detection of table differences for each line of wrangling code.
Second, we incorporate a characteristic-based <span id="1.2" class="ltx_ERROR undefined">\kai</span>component and a Siamese convolutional neural network-based component for the detection of transformation types.
Third, we derive the parameters of each data transformation by employing a “slot filling” strategy.
We design experiments to evaluate the performance of <span id="1.3" class="ltx_text ltx_font_smallcaps">Comantics</span>. Further, we assess its <span id="1.4" class="ltx_ERROR undefined">\kai</span>flexibility using three example applications in different domains.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>Data Transformation, Semantic Inference, Program Understanding, Table Comparison
</div>
<div id="p2" class="ltx_para">
<span id="p2.2" class="ltx_ERROR undefined">\CCScatlist</span><span id="p2.3" class="ltx_ERROR undefined">\CCScat</span>
<p id="p2.1" class="ltx_p">K.6.1Management of Computing and Information SystemsProject and People ManagementLife Cycle;
<span id="p2.1.1" class="ltx_ERROR undefined">\CCScat</span>K.7.mThe Computing ProfessionMiscellaneousEthics

<span id="p2.1.2" class="ltx_ERROR undefined">\teaser</span>
<img src="/html/2209.13995/assets/x1.png" id="p2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="214" alt="[Uncaptioned image]">
<span id="p2.1.3" class="ltx_text ltx_caption ltx_align_center"><span id="p2.1.3.1" class="ltx_text ltx_font_smallcaps">Comantics</span> is a pipeline that reveals the semantics of wrangling code. (a) shows the input of the pipeline, <span id="p2.1.3.2" class="ltx_ERROR undefined">\ie</span>, a data table and a piece of wrangling script. (b) is the first step of <span id="p2.1.3.3" class="ltx_text ltx_font_smallcaps">Comantics</span>, aiming to generate intermediate tables for each code and detect changes between tables. (c) depicts the second step that identifies transformation type with characteristic-based and CNN-based components. (d) is the third step that infers parameters for the transformation. (e) shows the output of <span id="p2.1.3.4" class="ltx_text ltx_font_smallcaps">Comantics</span>. (f) shows that our pipeline is applied to three applications in different domains.</span>


<span id="p2.1.4" class="ltx_ERROR undefined">\vgtcinsertpkg</span></p>
</div>
<div id="p3" class="ltx_para">
<p id="p3.1" class="ltx_p">Introduction</p>
</div>
<div id="p4" class="ltx_para">
<p id="p4.1" class="ltx_p">Data wrangling is an arduous and time-consuming routine <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> for data workers who carry out data analysis tasks with different levels of expertise <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. A commonplace method of wrangling data is writing custom cleaning scripts in various programming languages <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, such as R and Python.
In this case, data workers usually seek to understand the semantics of wrangling scripts in various scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>, including debugging for potential code issues, reusing scripts for their data, and maintaining code that is not well-documented.
Here, the <span id="p4.1.1" class="ltx_text ltx_font_italic">semantics of wrangling scripts</span> means the <span id="p4.1.2" class="ltx_text ltx_font_bold" style="color:#70AD47;">type of data transformation</span> and its <span id="p4.1.3" class="ltx_text ltx_font_bold" style="color:#ED7D31;">parameters</span>.
For example, given a line of code written in R, <span id="p4.1.4" class="ltx_text ltx_lstlisting" style="background-color:#CCCCCC;"><span id="p4.1.4.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">tb2</span><span id="p4.1.4.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="p4.1.4.3" class="ltx_text ltx_font_typewriter">=<span id="p4.1.4.3.1" class="ltx_text ltx_lst_space"> </span><span id="p4.1.4.3.2" class="ltx_text ltx_lst_identifier">arrange</span>(<span id="p4.1.4.3.3" class="ltx_text ltx_lst_identifier">tb1</span>,<span id="p4.1.4.3.4" class="ltx_text ltx_lst_space"> </span>-<span id="p4.1.4.3.5" class="ltx_text ltx_lst_identifier">num</span>)</span></span>, the semantics of the code refers to <span id="p4.1.5" class="ltx_text ltx_font_bold" style="color:#70AD47;">sorting</span> the column <span id="p4.1.6" class="ltx_text ltx_font_bold" style="color:#ED7D31;">num</span> of the input table <span id="p4.1.7" class="ltx_text ltx_font_bold" style="color:#ED7D31;">tb1</span> in <span id="p4.1.8" class="ltx_text ltx_font_bold" style="color:#ED7D31;">descending</span> order, and returning the output table <span id="p4.1.9" class="ltx_text ltx_font_bold" style="color:#ED7D31;">tb2</span>.</p>
</div>
<div id="p5" class="ltx_para">
<p id="p5.1" class="ltx_p">However, understanding the semantics of intricate scripts requires advanced programming skills and is error-prone <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>.
Novice data workers may find it challenging for three reasons.
First, data workers need to work across programming languages in some scenarios, such as learning a new programming language and reusing code written in another language.
However, different scripting languages have diverse regulations in implementing data transformations.
For example, the <span id="p5.1.1" class="ltx_text ltx_font_italic">sort</span> transformation can be implemented by the function <span id="p5.1.2" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">arrange</span> in <span id="p5.1.3" class="ltx_ERROR undefined">\kai</span>dplyr <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> (R), and the descending order is represented by a minus sign or the <span id="p5.1.4" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">desc</span> function.
While in <span id="p5.1.5" class="ltx_ERROR undefined">\kai</span>Pandas <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> (Python), the same transformation is implemented by the function <span id="p5.1.6" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">sort_values</span>, and the descending order is noted as <span id="p5.1.7" class="ltx_text ltx_lstlisting" style="background-color:#CCCCCC;"><span id="p5.1.7.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">ascending</span><span id="p5.1.7.2" class="ltx_text ltx_font_typewriter">=<span id="p5.1.7.2.1" class="ltx_text ltx_lst_identifier">False</span></span></span>.
Second, in one language, there are different functions to implement the same data transformation.
For instance, both <span id="p5.1.8" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">gather</span> and <span id="p5.1.9" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">pivot_longer</span> in <span id="p5.1.10" class="ltx_ERROR undefined">\kai</span>tidyr <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> (R) can perform the <span id="p5.1.11" class="ltx_text ltx_font_italic">fold</span> transformation, and there is a subtle difference in their usage.
Third, some functions may omit important parameters for simplicity.
These functions either have default parameters (e.g., the <span id="p5.1.12" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">sort_values</span> function in <span id="p5.1.13" class="ltx_ERROR undefined">\kai</span>Pandas performs sorting in ascending order by default), or can extract parameters from the input data tables
(e.g., the <span id="p5.1.14" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">left_join</span> function in <span id="p5.1.15" class="ltx_ERROR undefined">\kai</span>dplyr has built-in rules to infer join keys from the two input tables).</p>
</div>
<div id="p6" class="ltx_para">
<p id="p6.1" class="ltx_p">A body of prior work has been proposed to understand wrangling scripts.
Some tools such as Unravel <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> and WrangleDoc <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> are used for exploring and debugging wrangling scripts.
These tools are useful for revealing changes in data tables after performing a data transformation.
However, they cannot directly inform data workers of the type of transformation.
Others, such as <span id="p6.1.1" class="ltx_text ltx_font_smallcaps">Somnus</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>, Datamations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>, and Data Tweening <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, illustrate the semantics of data transformations using well-designed visualization.
However, they rely on hand-crafted rules to parse scripts, resulting in poor generalizability and scalability.</p>
</div>
<div id="p7" class="ltx_para">
<p id="p7.1" class="ltx_p">In this paper, we propose a pipeline, called <span id="p7.1.1" class="ltx_text ltx_font_smallcaps">Comantics</span> meaning <span id="p7.1.2" class="ltx_text ltx_font_bold">co</span>de se<span id="p7.1.3" class="ltx_text ltx_font_bold">mantics</span>, that identifies the semantics of wrangling scripts.
We observe that, given a line of wrangling code, changes between input and output tables highly relate to the type of transformation.
To have an overview of the changes, we summarize the characteristics of table changes by analyzing a corpus containing <math id="p7.1.m1.1" class="ltx_Math" alttext="921" display="inline"><semantics id="p7.1.m1.1a"><mn id="p7.1.m1.1.1" xref="p7.1.m1.1.1.cmml">921</mn><annotation-xml encoding="MathML-Content" id="p7.1.m1.1b"><cn type="integer" id="p7.1.m1.1.1.cmml" xref="p7.1.m1.1.1">921</cn></annotation-xml><annotation encoding="application/x-tex" id="p7.1.m1.1c">921</annotation></semantics></math> lines of real-world wrangling code and present a design space comprising two primary dimensions, i.e., the types of data objects and the properties of data changes.
Then, we construct the pipeline consisting of three key steps, <span id="p7.1.4" class="ltx_ERROR undefined">\ie</span>, Data Preprocessing, Type Inference, and Parameter Inference.
For Data Preprocessing, <span id="p7.1.5" class="ltx_text ltx_font_smallcaps">Comantics</span> executes the script and obtains intermediate data tables for each line of wrangling code.
Then, the characteristics of table changes are identified automatically.
The Type Inference step consists of two components.
The first component infers transformation type based on the characteristics and obtains a list of candidate transformation types.
To identify the transformation with maximum possibility, we employ a Siamese convolutional neural network<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> to rank transformation candidates.
Based on the inferred transformation, Parameter Inference aims to identify parameters for transformations.
We borrow the “slot filling” strategy and detect parameters based on the wrangling script, table contents, and characteristics.
Finally, <span id="p7.1.6" class="ltx_text ltx_font_smallcaps">Comantics</span> outputs a data transformation with maximum likelihood and its parameters, which can be applied to a variety of downstream tasks.</p>
</div>
<div id="p8" class="ltx_para">
<p id="p8.1" class="ltx_p">We design experiments to evaluate the performance of <span id="p8.1.1" class="ltx_text ltx_font_smallcaps">Comantics</span>.
We first annotate the real-world corpus with data transformations. Then we assess the generalizability across different programming languages and the contribution of different components of <span id="p8.1.2" class="ltx_text ltx_font_smallcaps">Comantics</span> based on five experiment settings.
To evaluate the <span id="p8.1.3" class="ltx_ERROR undefined">\kai</span>flexibility of our pipeline, we apply it to three applications in different domains, <span id="p8.1.4" class="ltx_ERROR undefined">\ie</span>, improving Jupyter Notebook with automatic annotation, augmenting <span id="p8.1.5" class="ltx_text ltx_font_smallcaps">Somnus</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> with scalable backend, and enhancing TACO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> with additional information.</p>
</div>
<div id="p9" class="ltx_para">
<p id="p9.2" class="ltx_p">In summary, the contributions of this paper are four-fold:
First, we summarize a design space including <math id="p9.1.m1.1" class="ltx_Math" alttext="103" display="inline"><semantics id="p9.1.m1.1a"><mn id="p9.1.m1.1.1" xref="p9.1.m1.1.1.cmml">103</mn><annotation-xml encoding="MathML-Content" id="p9.1.m1.1b"><cn type="integer" id="p9.1.m1.1.1.cmml" xref="p9.1.m1.1.1">103</cn></annotation-xml><annotation encoding="application/x-tex" id="p9.1.m1.1c">103</annotation></semantics></math> characteristics of table changes.
Second, we construct a novel pipeline, <span id="p9.2.1" class="ltx_text ltx_font_smallcaps">Comantics</span>, for inferring semantics, <span id="p9.2.2" class="ltx_ERROR undefined">\ie</span>, the types of transformations and their parameters, of wrangling scripts.
Third, we evaluate the performance of our pipeline using quantitative experiments.
A sub-contribution is that we have built a real-world dataset including <math id="p9.2.m2.1" class="ltx_Math" alttext="921" display="inline"><semantics id="p9.2.m2.1a"><mn id="p9.2.m2.1.1" xref="p9.2.m2.1.1.cmml">921</mn><annotation-xml encoding="MathML-Content" id="p9.2.m2.1b"><cn type="integer" id="p9.2.m2.1.1.cmml" xref="p9.2.m2.1.1">921</cn></annotation-xml><annotation encoding="application/x-tex" id="p9.2.m2.1c">921</annotation></semantics></math> lines of wrangling code where each is annotated with a data transformation.
Fourth, to assess the <span id="p9.2.3" class="ltx_ERROR undefined">\kai</span>flexibility of <span id="p9.2.4" class="ltx_text ltx_font_smallcaps">Comantics</span>, we apply our pipeline to three example applications in different domains.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Related Work</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In this section, we discuss techniques from three aspects, <span id="S1.p1.1.1" class="ltx_ERROR undefined">\ie</span>, data wrangling, program understanding in data wrangling, and table comparison.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Data Wrangling</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">Data wrangling is a nontrivial activity of cleaning, transforming, and enriching data into the desired form palatable for downstream tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.
Data wrangling often involves a significant number of data transformations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>.
Kasica <span id="S1.SS1.p1.1.1" class="ltx_text ltx_font_italic">et al.<cite class="ltx_cite ltx_citemacro_cite"><span id="S1.SS1.p1.1.1.1.1" class="ltx_text ltx_font_upright">[</span><a href="#bib.bib30" title="" class="ltx_ref">30</a><span id="S1.SS1.p1.1.1.2.2" class="ltx_text ltx_font_upright">]</span></cite></span> developed a concise and actionable framework describing multi-table transformation operations.</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">There are two kinds of approaches for facilitating the process of data wrangling.
On the one hand, a plethora of interactive applications has been proposed.
Tools for wrangling tabular data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> like Microsoft Excel, Tableau Prep Builder <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, OpenRefine <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, and Trifacta <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> provide an interactive menu for selecting the desired transformation.
Further, Trifacta and its predecessor Data Wrangler <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> integrate an inference engine that generates a ranked list of suggested transformations.
Others aim to address wrangling graph <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> and website <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> data.
Some of the above tools <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> support recording the process of data transformations through a domain-specific language, and provide textual descriptions of transformations.
On the other hand, numerous scripting languages (e.g., Python and R) with data manipulation libraries (e.g., Pandas <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>, dplyr <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>, tidyr <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>, and tidyverse <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>) have been commonly used to wrangle data for their flexibility.
However, programming is a complicated and burdensome activity, requiring developers to master specialized skills <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>.
To reduce this barrier, increasing research work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> is motivated by <span id="S1.SS1.p2.1.1" class="ltx_text ltx_font_italic">programming by example</span> that synthesizes target code given examples provided by data workers.
Compared to the aforementioned approaches, our pipeline has different goals, which focus on helping data workers understand wrangling scripts.</p>
</div>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span>Program Understanding in Data Wrangling</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p">Program understanding in data wrangling is a hot research topic that aims to help data workers comprehend code.
Prior work roughly falls into two categories.
Firstly, some tools are designed for debugging.
For example, WrangleDoc <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> is a JupyterLab extension that leverages program synthesis techniques to automatically generate summaries of code fragments to find subtle bugs.
Unravel <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> provides summaries for data transformation functions and an always-on visualization for fluent code to explore and debug the chain of expressions in R.
Besides, TweakIt <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> is a system implemented as an extension to Microsoft Excel that applies live interactions to help data workers explore and understand the effects of unfamiliar code.
<span id="S1.SS2.p1.1.1" class="ltx_text ltx_font_smallcaps">Comantics</span> shares the same design goal of facilitating the comprehension of wrangling scripts.
However, we focus on the semantics of data wrangling, which consists of the types of data transformations and their parameters.</p>
</div>
<div id="S1.SS2.p2" class="ltx_para">
<p id="S1.SS2.p2.1" class="ltx_p">Secondly, some tools are proposed to visualize the semantics of data wrangling.
For instance, Datamations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> creates animated transitions for data transformations to explain the entire data analysis pipeline.
<span id="S1.SS2.p2.1.1" class="ltx_text ltx_font_smallcaps">Somnus</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> supports transformation inference based on function information and generates a glyph-based provenance graph to visualize the evolution of tables.
These visualization tools are useful and effective in depicting the semantics of data processing workflow.
However, they rely on a rule-based engine to parse the semantics of the wrangling process, which can hardly scale to different programming languages and a variety of functions.
In addition, crafting rules is a laborious process and is limited in real-world applications.
<span id="S1.SS2.p2.1.2" class="ltx_text ltx_font_smallcaps">Comantics</span>, on the other hand, infers the semantics of wrangling scripts from input/output tables and individual lines of code. It is independent of programming languages, libraries, and functions, resulting in better scalability and generalizability.
We have successfully applied <span id="S1.SS2.p2.1.3" class="ltx_text ltx_font_smallcaps">Comantics</span> to three applications (see Sec. <a href="#S5" title="5 Example Applications ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>) to assess its <span id="S1.SS2.p2.1.4" class="ltx_ERROR undefined">\kai</span>flexibility.</p>
</div>
</section>
<section id="S1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.3 </span>Table Comparison</h3>

<div id="S1.SS3.p1" class="ltx_para">
<p id="S1.SS3.p1.1" class="ltx_p">Data comparison techniques are widely used to investigate differences between multiple versions of data.
Although plenty of work aims to compare time series data, image data, graphs, etc., there are few techniques designed to compare tabular data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>.
Available table comparison tools, such as ExcelCompare <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, AQT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, DiffKit <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, Daff <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, Ridom SeqSphere+ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, and Compare <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, identify and compute differences between two input tables according to metrics including table size differences, cell content differences, the number of unique records and fields, etc., and output statistical results, textual summaries, or visualizations.
Sutton <span id="S1.SS3.p1.1.1" class="ltx_text ltx_font_italic">et al.<cite class="ltx_cite ltx_citemacro_cite"><span id="S1.SS3.p1.1.1.1.1" class="ltx_text ltx_font_upright">[</span><a href="#bib.bib61" title="" class="ltx_ref">61</a><span id="S1.SS3.p1.1.1.2.2" class="ltx_text ltx_font_upright">]</span></cite></span> presented a tool to detect and explain the differences between two tables and formulate executable patches that can transform one table to be compatible with the other.
In addition, Niederer <span id="S1.SS3.p1.1.2" class="ltx_text ltx_font_italic">et al.<cite class="ltx_cite ltx_citemacro_cite"><span id="S1.SS3.p1.1.2.1.1" class="ltx_text ltx_font_upright">[</span><a href="#bib.bib47" title="" class="ltx_ref">47</a><span id="S1.SS3.p1.1.2.2.2" class="ltx_text ltx_font_upright">]</span></cite></span> developed TACO, a visual comparison tool for tabular data. It encodes table differences through interactive visualizations to illustrate different types of changes. The aforementioned approaches are successful in comparing differences between tables.
<span id="S1.SS3.p1.1.3" class="ltx_text ltx_font_smallcaps">Comantics</span> goes one step forward in which table differences are identified to infer the semantics of wrangling scripts.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>A Design Space for Table Changes</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The semantics of wrangling scripts consists of transformation types and their parameters.
According to Xiong <span id="S2.p1.1.1" class="ltx_text ltx_font_italic">et al.<cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p1.1.1.1.1" class="ltx_text ltx_font_upright">[</span><a href="#bib.bib69" title="" class="ltx_ref">69</a><span id="S2.p1.1.1.2.2" class="ltx_text ltx_font_upright">]</span></cite></span>, identifying the transformation type is the key challenge.
We observe that differences between input and output tables of a line of wrangling code can reveal the transformation type to some extent.
For example, if some rows are deleted while the others remain unchanged, the transformation seems to belong to <span id="S2.p1.1.2" class="ltx_text ltx_font_italic">delete rows</span>.
Further, if all deleted rows contain missing values while the remaining do not, the transformation type is likely to be <span id="S2.p1.1.3" class="ltx_text ltx_font_italic">delete rows with missing values</span>.
Motivated by this observation, we explore the characteristics of table changes and present a design space to understand how a table is changed based on data transformations.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Methodology</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.4" class="ltx_p">To understand the characteristics of table changes, we collect real-world corpus and analyze how wrangling scripts transform input data tables into outputs.
The corpus is collected from GitHub<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com</a></span></span></span> and Kaggle<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://www.kaggle.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kaggle.com</a></span></span></span>.
We use keywords such as data wrangling and data cleaning to find target scripts.
Furthermore, we collect corpus from prior work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.
<span id="S2.SS1.p1.4.1" class="ltx_ERROR undefined">\kai</span>The collection procedure is based on two inclusion criteria. First, as our approach relies on table changes, we focus on scripts with data tables.
Second, due to our expertise in programming, we keep scripts written in Python and R, and balance the number of scripts in both languages.
<span id="S2.SS1.p1.4.2" class="ltx_ERROR undefined">\kai</span>After collecting the corpus, we manually “clean” these scripts to meet the requirement of <span id="S2.SS1.p1.4.3" class="ltx_text ltx_font_smallcaps">Comantics</span>.
Besides data wrangling, the scripts usually include code for other purposes, such as visualization and machine learning.
We carefully remove these code and ensure that the remaining can run and process the input data correctly.
Then, we deal with function chaining, where multiple functions are executed consecutively on the same variable.
An example is shown in Fig. <a href="#S2.F1" title="Figure 1 ‣ 2.1 Methodology ‣ 2 A Design Space for Table Changes ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(a), four functions (<span id="S2.SS1.p1.4.4" class="ltx_ERROR undefined">\ie</span>, <span id="S2.SS1.p1.4.5" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">filter</span>, <span id="S2.SS1.p1.4.6" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">mutate</span>, <span id="S2.SS1.p1.4.7" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">select</span>, and <span id="S2.SS1.p1.4.8" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">arrange</span>) are called in sequence on the dataset <span id="S2.SS1.p1.4.9" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">mtcars</span>.
This language pattern is efficient for developers. However, it is not supported in <span id="S2.SS1.p1.4.10" class="ltx_text ltx_font_smallcaps">Comantics</span> because we can hardly obtain intermediate tables.
Hence, we rewrite chained functions into individual lines of transformations (Fig. <a href="#S2.F1" title="Figure 1 ‣ 2.1 Methodology ‣ 2 A Design Space for Table Changes ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(b)).
Finally, our corpus contains <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="74" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mn id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">74</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><cn type="integer" id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">74</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">74</annotation></semantics></math> curated scripts, where <math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="42" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><mn id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">42</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><cn type="integer" id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">42</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">42</annotation></semantics></math> of them are written in Python and <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="32" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><mn id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><cn type="integer" id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">32</annotation></semantics></math> are in R, adding up to <math id="S2.SS1.p1.4.m4.1" class="ltx_Math" alttext="921" display="inline"><semantics id="S2.SS1.p1.4.m4.1a"><mn id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml">921</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><cn type="integer" id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1">921</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">921</annotation></semantics></math> lines of wrangling code.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2209.13995/assets/x2.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="178" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An example of unraveling (a) a chained syntax into (b) a sequence of statements in the R programming language.</figcaption>
</figure>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">To code the characteristics of table changes, we first execute these scripts to obtain the intermediate tables for each line of wrangling code.
Then we record the differences between tables in detail from various aspects as much as possible.
Next, we apply a qualitative method, open coding and axial coding <span id="S2.SS1.p2.1.1" class="ltx_ERROR undefined">\kai</span>rooted in grounded theory, to these table differences.
Specifically, we label each difference with a descriptive code and draw connections between these codes.
Based on our observations and wrangling experiences, we adopt the codes which are conducive to distinguishing between different transformations.
After frequent discussions with two data scientists, we group and condense related codes into broader categories.
Finally, we derive five properties of data changes and four data objects from these categories.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Dimensions of the Design Space</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.5" class="ltx_p">By analyzing the characteristics of table changes, we construct the design space consisting of two primary dimensions, <span id="S2.SS2.p1.5.1" class="ltx_ERROR undefined">\ie</span>, data objects and the property of data changes.
Data objects include four different types, <span id="S2.SS2.p1.5.2" class="ltx_ERROR undefined">\ie</span>, Tables, Columns, Rows, and Cells.
The first three data objects are recognized in various prior work in data wrangling<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> and table comparison<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>.
We introduce Cells additionally because it relates to a wide range of transformations including editing the text of a cell and filling empty cells with adjacent cells.
The second dimension is the property of data change.
We identify five high-level properties, <span id="S2.SS2.p1.5.3" class="ltx_ERROR undefined">\ie</span>, Number, Order, Relation, Value, and Type.
Intersections between data objects and properties mean a set of characteristics, which are described by inequalities.
For example, the intersection between Tables and Number includes five characteristics, <span id="S2.SS2.p1.5.4" class="ltx_ERROR undefined">\ie</span>, the number of input and output tables goes from “<math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="0\rightarrow 1" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><mrow id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml"><mn id="S2.SS2.p1.1.m1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.2.cmml">0</mn><mo stretchy="false" id="S2.SS2.p1.1.m1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.1.cmml">→</mo><mn id="S2.SS2.p1.1.m1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><apply id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1"><ci id="S2.SS2.p1.1.m1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1">→</ci><cn type="integer" id="S2.SS2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.2">0</cn><cn type="integer" id="S2.SS2.p1.1.m1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">0\rightarrow 1</annotation></semantics></math>”, “<math id="S2.SS2.p1.2.m2.1" class="ltx_Math" alttext="1\rightarrow 0" display="inline"><semantics id="S2.SS2.p1.2.m2.1a"><mrow id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml"><mn id="S2.SS2.p1.2.m2.1.1.2" xref="S2.SS2.p1.2.m2.1.1.2.cmml">1</mn><mo stretchy="false" id="S2.SS2.p1.2.m2.1.1.1" xref="S2.SS2.p1.2.m2.1.1.1.cmml">→</mo><mn id="S2.SS2.p1.2.m2.1.1.3" xref="S2.SS2.p1.2.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><apply id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1"><ci id="S2.SS2.p1.2.m2.1.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1.1">→</ci><cn type="integer" id="S2.SS2.p1.2.m2.1.1.2.cmml" xref="S2.SS2.p1.2.m2.1.1.2">1</cn><cn type="integer" id="S2.SS2.p1.2.m2.1.1.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">1\rightarrow 0</annotation></semantics></math>”, “<math id="S2.SS2.p1.3.m3.1" class="ltx_Math" alttext="1\rightarrow 1" display="inline"><semantics id="S2.SS2.p1.3.m3.1a"><mrow id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml"><mn id="S2.SS2.p1.3.m3.1.1.2" xref="S2.SS2.p1.3.m3.1.1.2.cmml">1</mn><mo stretchy="false" id="S2.SS2.p1.3.m3.1.1.1" xref="S2.SS2.p1.3.m3.1.1.1.cmml">→</mo><mn id="S2.SS2.p1.3.m3.1.1.3" xref="S2.SS2.p1.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><apply id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1"><ci id="S2.SS2.p1.3.m3.1.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1.1">→</ci><cn type="integer" id="S2.SS2.p1.3.m3.1.1.2.cmml" xref="S2.SS2.p1.3.m3.1.1.2">1</cn><cn type="integer" id="S2.SS2.p1.3.m3.1.1.3.cmml" xref="S2.SS2.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">1\rightarrow 1</annotation></semantics></math>”, “<math id="S2.SS2.p1.4.m4.1" class="ltx_Math" alttext="1\rightarrow\textmd{many}" display="inline"><semantics id="S2.SS2.p1.4.m4.1a"><mrow id="S2.SS2.p1.4.m4.1.1" xref="S2.SS2.p1.4.m4.1.1.cmml"><mn id="S2.SS2.p1.4.m4.1.1.2" xref="S2.SS2.p1.4.m4.1.1.2.cmml">1</mn><mo stretchy="false" id="S2.SS2.p1.4.m4.1.1.1" xref="S2.SS2.p1.4.m4.1.1.1.cmml">→</mo><mtext id="S2.SS2.p1.4.m4.1.1.3" xref="S2.SS2.p1.4.m4.1.1.3a.cmml">many</mtext></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.1b"><apply id="S2.SS2.p1.4.m4.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1"><ci id="S2.SS2.p1.4.m4.1.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1.1">→</ci><cn type="integer" id="S2.SS2.p1.4.m4.1.1.2.cmml" xref="S2.SS2.p1.4.m4.1.1.2">1</cn><ci id="S2.SS2.p1.4.m4.1.1.3a.cmml" xref="S2.SS2.p1.4.m4.1.1.3"><mtext id="S2.SS2.p1.4.m4.1.1.3.cmml" xref="S2.SS2.p1.4.m4.1.1.3">many</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.1c">1\rightarrow\textmd{many}</annotation></semantics></math>”, and “<math id="S2.SS2.p1.5.m5.1" class="ltx_Math" alttext="\textmd{many}\rightarrow 1" display="inline"><semantics id="S2.SS2.p1.5.m5.1a"><mrow id="S2.SS2.p1.5.m5.1.1" xref="S2.SS2.p1.5.m5.1.1.cmml"><mtext id="S2.SS2.p1.5.m5.1.1.2" xref="S2.SS2.p1.5.m5.1.1.2a.cmml">many</mtext><mo stretchy="false" id="S2.SS2.p1.5.m5.1.1.1" xref="S2.SS2.p1.5.m5.1.1.1.cmml">→</mo><mn id="S2.SS2.p1.5.m5.1.1.3" xref="S2.SS2.p1.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m5.1b"><apply id="S2.SS2.p1.5.m5.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1"><ci id="S2.SS2.p1.5.m5.1.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1.1">→</ci><ci id="S2.SS2.p1.5.m5.1.1.2a.cmml" xref="S2.SS2.p1.5.m5.1.1.2"><mtext id="S2.SS2.p1.5.m5.1.1.2.cmml" xref="S2.SS2.p1.5.m5.1.1.2">many</mtext></ci><cn type="integer" id="S2.SS2.p1.5.m5.1.1.3.cmml" xref="S2.SS2.p1.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m5.1c">\textmd{many}\rightarrow 1</annotation></semantics></math>”, as illustrated in Fig. <a href="#S2.F2" title="Figure 2 ‣ 2.2 Dimensions of the Design Space ‣ 2 A Design Space for Table Changes ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
We notice that the mapping between data objects and properties is not complete, meaning that some properties are only applicable to specific data objects.
In the following paragraphs, we describe the five properties in detail.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2209.13995/assets/x3.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="452" height="592" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>
The design space describes characteristics of table changes that consist of two dimensions, <span id="S2.F2.4.1" class="ltx_ERROR undefined">\ie</span>, data objects and properties of data changes.
<math id="S2.F2.2.m1.1" class="ltx_Math" alttext="103" display="inline"><semantics id="S2.F2.2.m1.1b"><mn id="S2.F2.2.m1.1.1" xref="S2.F2.2.m1.1.1.cmml">103</mn><annotation-xml encoding="MathML-Content" id="S2.F2.2.m1.1c"><cn type="integer" id="S2.F2.2.m1.1.1.cmml" xref="S2.F2.2.m1.1.1">103</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.2.m1.1d">103</annotation></semantics></math> characteristics are included in the space.
The blue and orange square indicates data objects in the output and input table, respectively. A detailed description of each characteristic is provided in the supplemental material.</figcaption>
</figure>
<section id="S2.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.1 </span>Number</h4>

<div id="S2.SS2.SSS1.p1" class="ltx_para">
<p id="S2.SS2.SSS1.p1.7" class="ltx_p">Numerous transformations can result in a change in the number of data objects including <span id="S2.SS2.SSS1.p1.7.1" class="ltx_text ltx_font_italic">create tables</span>, <span id="S2.SS2.SSS1.p1.7.2" class="ltx_text ltx_font_italic">delete columns</span>, etc.
Number is applicable to tables, columns, and rows, as shown in Fig. <a href="#S2.F2" title="Figure 2 ‣ 2.2 Dimensions of the Design Space ‣ 2 A Design Space for Table Changes ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>,
For tables, the comparison between the number of inputs and outputs is critical.
For example, the <span id="S2.SS2.SSS1.p1.7.3" class="ltx_text ltx_font_italic">create tables</span> transformation may increase the number of tables from <math id="S2.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S2.SS2.SSS1.p1.1.m1.1a"><mn id="S2.SS2.SSS1.p1.1.m1.1.1" xref="S2.SS2.SSS1.p1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.1.m1.1b"><cn type="integer" id="S2.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1">0</cn></annotation-xml></semantics></math> to <math id="S2.SS2.SSS1.p1.2.m2.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S2.SS2.SSS1.p1.2.m2.1a"><mn id="S2.SS2.SSS1.p1.2.m2.1.1" xref="S2.SS2.SSS1.p1.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.2.m2.1b"><cn type="integer" id="S2.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS1.p1.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.2.m2.1c">1</annotation></semantics></math>.
Meanwhile, the <span id="S2.SS2.SSS1.p1.7.4" class="ltx_text ltx_font_italic">separate tables</span> may generate more tables based on one input table.
Therefore, we include five characteristics in this category, <span id="S2.SS2.SSS1.p1.7.5" class="ltx_ERROR undefined">\ie</span>, the number of input and output tables goes from “<math id="S2.SS2.SSS1.p1.3.m3.1" class="ltx_Math" alttext="0\rightarrow 1" display="inline"><semantics id="S2.SS2.SSS1.p1.3.m3.1a"><mrow id="S2.SS2.SSS1.p1.3.m3.1.1" xref="S2.SS2.SSS1.p1.3.m3.1.1.cmml"><mn id="S2.SS2.SSS1.p1.3.m3.1.1.2" xref="S2.SS2.SSS1.p1.3.m3.1.1.2.cmml">0</mn><mo stretchy="false" id="S2.SS2.SSS1.p1.3.m3.1.1.1" xref="S2.SS2.SSS1.p1.3.m3.1.1.1.cmml">→</mo><mn id="S2.SS2.SSS1.p1.3.m3.1.1.3" xref="S2.SS2.SSS1.p1.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.3.m3.1b"><apply id="S2.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS1.p1.3.m3.1.1"><ci id="S2.SS2.SSS1.p1.3.m3.1.1.1.cmml" xref="S2.SS2.SSS1.p1.3.m3.1.1.1">→</ci><cn type="integer" id="S2.SS2.SSS1.p1.3.m3.1.1.2.cmml" xref="S2.SS2.SSS1.p1.3.m3.1.1.2">0</cn><cn type="integer" id="S2.SS2.SSS1.p1.3.m3.1.1.3.cmml" xref="S2.SS2.SSS1.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.3.m3.1c">0\rightarrow 1</annotation></semantics></math>”, “<math id="S2.SS2.SSS1.p1.4.m4.1" class="ltx_Math" alttext="1\rightarrow 0" display="inline"><semantics id="S2.SS2.SSS1.p1.4.m4.1a"><mrow id="S2.SS2.SSS1.p1.4.m4.1.1" xref="S2.SS2.SSS1.p1.4.m4.1.1.cmml"><mn id="S2.SS2.SSS1.p1.4.m4.1.1.2" xref="S2.SS2.SSS1.p1.4.m4.1.1.2.cmml">1</mn><mo stretchy="false" id="S2.SS2.SSS1.p1.4.m4.1.1.1" xref="S2.SS2.SSS1.p1.4.m4.1.1.1.cmml">→</mo><mn id="S2.SS2.SSS1.p1.4.m4.1.1.3" xref="S2.SS2.SSS1.p1.4.m4.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.4.m4.1b"><apply id="S2.SS2.SSS1.p1.4.m4.1.1.cmml" xref="S2.SS2.SSS1.p1.4.m4.1.1"><ci id="S2.SS2.SSS1.p1.4.m4.1.1.1.cmml" xref="S2.SS2.SSS1.p1.4.m4.1.1.1">→</ci><cn type="integer" id="S2.SS2.SSS1.p1.4.m4.1.1.2.cmml" xref="S2.SS2.SSS1.p1.4.m4.1.1.2">1</cn><cn type="integer" id="S2.SS2.SSS1.p1.4.m4.1.1.3.cmml" xref="S2.SS2.SSS1.p1.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.4.m4.1c">1\rightarrow 0</annotation></semantics></math>”, “<math id="S2.SS2.SSS1.p1.5.m5.1" class="ltx_Math" alttext="1\rightarrow 1" display="inline"><semantics id="S2.SS2.SSS1.p1.5.m5.1a"><mrow id="S2.SS2.SSS1.p1.5.m5.1.1" xref="S2.SS2.SSS1.p1.5.m5.1.1.cmml"><mn id="S2.SS2.SSS1.p1.5.m5.1.1.2" xref="S2.SS2.SSS1.p1.5.m5.1.1.2.cmml">1</mn><mo stretchy="false" id="S2.SS2.SSS1.p1.5.m5.1.1.1" xref="S2.SS2.SSS1.p1.5.m5.1.1.1.cmml">→</mo><mn id="S2.SS2.SSS1.p1.5.m5.1.1.3" xref="S2.SS2.SSS1.p1.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.5.m5.1b"><apply id="S2.SS2.SSS1.p1.5.m5.1.1.cmml" xref="S2.SS2.SSS1.p1.5.m5.1.1"><ci id="S2.SS2.SSS1.p1.5.m5.1.1.1.cmml" xref="S2.SS2.SSS1.p1.5.m5.1.1.1">→</ci><cn type="integer" id="S2.SS2.SSS1.p1.5.m5.1.1.2.cmml" xref="S2.SS2.SSS1.p1.5.m5.1.1.2">1</cn><cn type="integer" id="S2.SS2.SSS1.p1.5.m5.1.1.3.cmml" xref="S2.SS2.SSS1.p1.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.5.m5.1c">1\rightarrow 1</annotation></semantics></math>”, “<math id="S2.SS2.SSS1.p1.6.m6.1" class="ltx_Math" alttext="1\rightarrow\textmd{many}" display="inline"><semantics id="S2.SS2.SSS1.p1.6.m6.1a"><mrow id="S2.SS2.SSS1.p1.6.m6.1.1" xref="S2.SS2.SSS1.p1.6.m6.1.1.cmml"><mn id="S2.SS2.SSS1.p1.6.m6.1.1.2" xref="S2.SS2.SSS1.p1.6.m6.1.1.2.cmml">1</mn><mo stretchy="false" id="S2.SS2.SSS1.p1.6.m6.1.1.1" xref="S2.SS2.SSS1.p1.6.m6.1.1.1.cmml">→</mo><mtext id="S2.SS2.SSS1.p1.6.m6.1.1.3" xref="S2.SS2.SSS1.p1.6.m6.1.1.3a.cmml">many</mtext></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.6.m6.1b"><apply id="S2.SS2.SSS1.p1.6.m6.1.1.cmml" xref="S2.SS2.SSS1.p1.6.m6.1.1"><ci id="S2.SS2.SSS1.p1.6.m6.1.1.1.cmml" xref="S2.SS2.SSS1.p1.6.m6.1.1.1">→</ci><cn type="integer" id="S2.SS2.SSS1.p1.6.m6.1.1.2.cmml" xref="S2.SS2.SSS1.p1.6.m6.1.1.2">1</cn><ci id="S2.SS2.SSS1.p1.6.m6.1.1.3a.cmml" xref="S2.SS2.SSS1.p1.6.m6.1.1.3"><mtext id="S2.SS2.SSS1.p1.6.m6.1.1.3.cmml" xref="S2.SS2.SSS1.p1.6.m6.1.1.3">many</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.6.m6.1c">1\rightarrow\textmd{many}</annotation></semantics></math>”, and “<math id="S2.SS2.SSS1.p1.7.m7.1" class="ltx_Math" alttext="\textmd{many}\rightarrow 1" display="inline"><semantics id="S2.SS2.SSS1.p1.7.m7.1a"><mrow id="S2.SS2.SSS1.p1.7.m7.1.1" xref="S2.SS2.SSS1.p1.7.m7.1.1.cmml"><mtext id="S2.SS2.SSS1.p1.7.m7.1.1.2" xref="S2.SS2.SSS1.p1.7.m7.1.1.2a.cmml">many</mtext><mo stretchy="false" id="S2.SS2.SSS1.p1.7.m7.1.1.1" xref="S2.SS2.SSS1.p1.7.m7.1.1.1.cmml">→</mo><mn id="S2.SS2.SSS1.p1.7.m7.1.1.3" xref="S2.SS2.SSS1.p1.7.m7.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.7.m7.1b"><apply id="S2.SS2.SSS1.p1.7.m7.1.1.cmml" xref="S2.SS2.SSS1.p1.7.m7.1.1"><ci id="S2.SS2.SSS1.p1.7.m7.1.1.1.cmml" xref="S2.SS2.SSS1.p1.7.m7.1.1.1">→</ci><ci id="S2.SS2.SSS1.p1.7.m7.1.1.2a.cmml" xref="S2.SS2.SSS1.p1.7.m7.1.1.2"><mtext id="S2.SS2.SSS1.p1.7.m7.1.1.2.cmml" xref="S2.SS2.SSS1.p1.7.m7.1.1.2">many</mtext></ci><cn type="integer" id="S2.SS2.SSS1.p1.7.m7.1.1.3.cmml" xref="S2.SS2.SSS1.p1.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.7.m7.1c">\textmd{many}\rightarrow 1</annotation></semantics></math>”, which corresponds to characteristics 1—5 in Fig. <a href="#S2.F2" title="Figure 2 ‣ 2.2 Dimensions of the Design Space ‣ 2 A Design Space for Table Changes ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S2.SS2.SSS1.p2" class="ltx_para">
<p id="S2.SS2.SSS1.p2.7" class="ltx_p">For columns and rows, we summarize characteristics based on single- or multiple-table operations.
In terms of single-table transformations, we focus on whether the number of columns/rows in the output table is greater than (<span id="S2.SS2.SSS1.p2.7.1" class="ltx_ERROR undefined">\ie</span>, <math id="S2.SS2.SSS1.p2.1.m1.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="S2.SS2.SSS1.p2.1.m1.1a"><mo id="S2.SS2.SSS1.p2.1.m1.1.1" xref="S2.SS2.SSS1.p2.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p2.1.m1.1b"><gt id="S2.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S2.SS2.SSS1.p2.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p2.1.m1.1c">&gt;</annotation></semantics></math>, the <span id="S2.SS2.SSS1.p2.7.2" class="ltx_ERROR undefined">\nth</span>8 characteristic in Fig. <a href="#S2.F2" title="Figure 2 ‣ 2.2 Dimensions of the Design Space ‣ 2 A Design Space for Table Changes ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), equal to (<math id="S2.SS2.SSS1.p2.2.m2.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S2.SS2.SSS1.p2.2.m2.1a"><mo id="S2.SS2.SSS1.p2.2.m2.1.1" xref="S2.SS2.SSS1.p2.2.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p2.2.m2.1b"><eq id="S2.SS2.SSS1.p2.2.m2.1.1.cmml" xref="S2.SS2.SSS1.p2.2.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p2.2.m2.1c">=</annotation></semantics></math>), or smaller than (<math id="S2.SS2.SSS1.p2.3.m3.1" class="ltx_Math" alttext="&lt;" display="inline"><semantics id="S2.SS2.SSS1.p2.3.m3.1a"><mo id="S2.SS2.SSS1.p2.3.m3.1.1" xref="S2.SS2.SSS1.p2.3.m3.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p2.3.m3.1b"><lt id="S2.SS2.SSS1.p2.3.m3.1.1.cmml" xref="S2.SS2.SSS1.p2.3.m3.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p2.3.m3.1c">&lt;</annotation></semantics></math>) the number in the input table.
In terms of multiple-table transformations, changes in the number of columns/rows may vary.
For example, considering the <span id="S2.SS2.SSS1.p2.7.3" class="ltx_text ltx_font_italic">inner join</span> transformation, the number of rows in the output table is smaller than or equal to the minimum number of rows in the input tables.
On the contrary, the <span id="S2.SS2.SSS1.p2.7.4" class="ltx_text ltx_font_italic">split table by groups</span> transformation may split a table row-wise.
And the number of rows in the input table equals the sum of rows in the output tables.
For detailed categorization, we further divide multiple-table transformations into two cases, <span id="S2.SS2.SSS1.p2.7.5" class="ltx_ERROR undefined">\ie</span>, <math id="S2.SS2.SSS1.p2.4.m4.1" class="ltx_Math" alttext="1\rightarrow\textmd{many}" display="inline"><semantics id="S2.SS2.SSS1.p2.4.m4.1a"><mrow id="S2.SS2.SSS1.p2.4.m4.1.1" xref="S2.SS2.SSS1.p2.4.m4.1.1.cmml"><mn id="S2.SS2.SSS1.p2.4.m4.1.1.2" xref="S2.SS2.SSS1.p2.4.m4.1.1.2.cmml">1</mn><mo stretchy="false" id="S2.SS2.SSS1.p2.4.m4.1.1.1" xref="S2.SS2.SSS1.p2.4.m4.1.1.1.cmml">→</mo><mtext id="S2.SS2.SSS1.p2.4.m4.1.1.3" xref="S2.SS2.SSS1.p2.4.m4.1.1.3a.cmml">many</mtext></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p2.4.m4.1b"><apply id="S2.SS2.SSS1.p2.4.m4.1.1.cmml" xref="S2.SS2.SSS1.p2.4.m4.1.1"><ci id="S2.SS2.SSS1.p2.4.m4.1.1.1.cmml" xref="S2.SS2.SSS1.p2.4.m4.1.1.1">→</ci><cn type="integer" id="S2.SS2.SSS1.p2.4.m4.1.1.2.cmml" xref="S2.SS2.SSS1.p2.4.m4.1.1.2">1</cn><ci id="S2.SS2.SSS1.p2.4.m4.1.1.3a.cmml" xref="S2.SS2.SSS1.p2.4.m4.1.1.3"><mtext id="S2.SS2.SSS1.p2.4.m4.1.1.3.cmml" xref="S2.SS2.SSS1.p2.4.m4.1.1.3">many</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p2.4.m4.1c">1\rightarrow\textmd{many}</annotation></semantics></math> (one input table and many output tables) and <math id="S2.SS2.SSS1.p2.5.m5.1" class="ltx_Math" alttext="\textmd{many}\rightarrow 1" display="inline"><semantics id="S2.SS2.SSS1.p2.5.m5.1a"><mrow id="S2.SS2.SSS1.p2.5.m5.1.1" xref="S2.SS2.SSS1.p2.5.m5.1.1.cmml"><mtext id="S2.SS2.SSS1.p2.5.m5.1.1.2" xref="S2.SS2.SSS1.p2.5.m5.1.1.2a.cmml">many</mtext><mo stretchy="false" id="S2.SS2.SSS1.p2.5.m5.1.1.1" xref="S2.SS2.SSS1.p2.5.m5.1.1.1.cmml">→</mo><mn id="S2.SS2.SSS1.p2.5.m5.1.1.3" xref="S2.SS2.SSS1.p2.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p2.5.m5.1b"><apply id="S2.SS2.SSS1.p2.5.m5.1.1.cmml" xref="S2.SS2.SSS1.p2.5.m5.1.1"><ci id="S2.SS2.SSS1.p2.5.m5.1.1.1.cmml" xref="S2.SS2.SSS1.p2.5.m5.1.1.1">→</ci><ci id="S2.SS2.SSS1.p2.5.m5.1.1.2a.cmml" xref="S2.SS2.SSS1.p2.5.m5.1.1.2"><mtext id="S2.SS2.SSS1.p2.5.m5.1.1.2.cmml" xref="S2.SS2.SSS1.p2.5.m5.1.1.2">many</mtext></ci><cn type="integer" id="S2.SS2.SSS1.p2.5.m5.1.1.3.cmml" xref="S2.SS2.SSS1.p2.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p2.5.m5.1c">\textmd{many}\rightarrow 1</annotation></semantics></math>.
For the <math id="S2.SS2.SSS1.p2.6.m6.1" class="ltx_Math" alttext="1\rightarrow\textmd{many}" display="inline"><semantics id="S2.SS2.SSS1.p2.6.m6.1a"><mrow id="S2.SS2.SSS1.p2.6.m6.1.1" xref="S2.SS2.SSS1.p2.6.m6.1.1.cmml"><mn id="S2.SS2.SSS1.p2.6.m6.1.1.2" xref="S2.SS2.SSS1.p2.6.m6.1.1.2.cmml">1</mn><mo stretchy="false" id="S2.SS2.SSS1.p2.6.m6.1.1.1" xref="S2.SS2.SSS1.p2.6.m6.1.1.1.cmml">→</mo><mtext id="S2.SS2.SSS1.p2.6.m6.1.1.3" xref="S2.SS2.SSS1.p2.6.m6.1.1.3a.cmml">many</mtext></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p2.6.m6.1b"><apply id="S2.SS2.SSS1.p2.6.m6.1.1.cmml" xref="S2.SS2.SSS1.p2.6.m6.1.1"><ci id="S2.SS2.SSS1.p2.6.m6.1.1.1.cmml" xref="S2.SS2.SSS1.p2.6.m6.1.1.1">→</ci><cn type="integer" id="S2.SS2.SSS1.p2.6.m6.1.1.2.cmml" xref="S2.SS2.SSS1.p2.6.m6.1.1.2">1</cn><ci id="S2.SS2.SSS1.p2.6.m6.1.1.3a.cmml" xref="S2.SS2.SSS1.p2.6.m6.1.1.3"><mtext id="S2.SS2.SSS1.p2.6.m6.1.1.3.cmml" xref="S2.SS2.SSS1.p2.6.m6.1.1.3">many</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p2.6.m6.1c">1\rightarrow\textmd{many}</annotation></semantics></math> case, we compute the minimum, maximum, and sum of the number of columns/rows in all output tables, and compare them to the number in the input table (e.g., characteristics 9—15).
For the <math id="S2.SS2.SSS1.p2.7.m7.1" class="ltx_Math" alttext="\textmd{many}\rightarrow 1" display="inline"><semantics id="S2.SS2.SSS1.p2.7.m7.1a"><mrow id="S2.SS2.SSS1.p2.7.m7.1.1" xref="S2.SS2.SSS1.p2.7.m7.1.1.cmml"><mtext id="S2.SS2.SSS1.p2.7.m7.1.1.2" xref="S2.SS2.SSS1.p2.7.m7.1.1.2a.cmml">many</mtext><mo stretchy="false" id="S2.SS2.SSS1.p2.7.m7.1.1.1" xref="S2.SS2.SSS1.p2.7.m7.1.1.1.cmml">→</mo><mn id="S2.SS2.SSS1.p2.7.m7.1.1.3" xref="S2.SS2.SSS1.p2.7.m7.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p2.7.m7.1b"><apply id="S2.SS2.SSS1.p2.7.m7.1.1.cmml" xref="S2.SS2.SSS1.p2.7.m7.1.1"><ci id="S2.SS2.SSS1.p2.7.m7.1.1.1.cmml" xref="S2.SS2.SSS1.p2.7.m7.1.1.1">→</ci><ci id="S2.SS2.SSS1.p2.7.m7.1.1.2a.cmml" xref="S2.SS2.SSS1.p2.7.m7.1.1.2"><mtext id="S2.SS2.SSS1.p2.7.m7.1.1.2.cmml" xref="S2.SS2.SSS1.p2.7.m7.1.1.2">many</mtext></ci><cn type="integer" id="S2.SS2.SSS1.p2.7.m7.1.1.3.cmml" xref="S2.SS2.SSS1.p2.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p2.7.m7.1c">\textmd{many}\rightarrow 1</annotation></semantics></math> case, the same computation is performed for input tables, which is compared to the number of outputs (e.g., characteristics 16—22).
Each case includes seven characteristics, which are described in Fig. <a href="#S2.F2" title="Figure 2 ‣ 2.2 Dimensions of the Design Space ‣ 2 A Design Space for Table Changes ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</section>
<section id="S2.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.2 </span>Order</h4>

<div id="S2.SS2.SSS2.p1" class="ltx_para">
<p id="S2.SS2.SSS2.p1.1" class="ltx_p">The order property describes the position change of columns and rows, which can be performed manually or be sorted according to criteria including disorder, ascending, and descending <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>.
When performed manually, the index of columns/rows is changed (e.g., characteristics 40 and 41).
When sorted based on criteria, the content of the output column/row may be ordered (e.g., characteristics 42—44).</p>
</div>
</section>
<section id="S2.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.3 </span>Relation</h4>

<div id="S2.SS2.SSS3.p1" class="ltx_para">
<p id="S2.SS2.SSS3.p1.4" class="ltx_p">Some data transformations involve relations between data objects (e.g., columns, rows, and cells).
Taking the <span id="S2.SS2.SSS3.p1.4.1" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">unite</span> function in <span id="S2.SS2.SSS3.p1.4.2" class="ltx_ERROR undefined">\kai</span>tidyr as an example,
<span id="S2.SS2.SSS3.p1.4.3" class="ltx_text ltx_lstlisting" style="background-color:#CCCCCC;"><span id="S2.SS2.SSS3.p1.4.3.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">df2</span><span id="S2.SS2.SSS3.p1.4.3.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="S2.SS2.SSS3.p1.4.3.3" class="ltx_text ltx_font_typewriter">=<span id="S2.SS2.SSS3.p1.4.3.3.1" class="ltx_text ltx_lst_space"> </span><span id="S2.SS2.SSS3.p1.4.3.3.2" class="ltx_text ltx_lst_identifier">unite</span>(<span id="S2.SS2.SSS3.p1.4.3.3.3" class="ltx_text ltx_lst_identifier">df1</span>,‘<span id="S2.SS2.SSS3.p1.4.3.3.4" class="ltx_text ltx_lst_identifier">Z</span>’,<span id="S2.SS2.SSS3.p1.4.3.3.5" class="ltx_text ltx_lst_space"> </span><span id="S2.SS2.SSS3.p1.4.3.3.6" class="ltx_text ltx_lst_identifier">X</span>,<span id="S2.SS2.SSS3.p1.4.3.3.7" class="ltx_text ltx_lst_space"> </span><span id="S2.SS2.SSS3.p1.4.3.3.8" class="ltx_text ltx_lst_identifier">Y</span>)</span></span> forms the column <span id="S2.SS2.SSS3.p1.4.4" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">Z</span> in <span id="S2.SS2.SSS3.p1.4.5" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">df2</span> by concatenating strings of columns <span id="S2.SS2.SSS3.p1.4.6" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">X</span> and <span id="S2.SS2.SSS3.p1.4.7" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">Y</span> in <span id="S2.SS2.SSS3.p1.4.8" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">df1</span>.
Relations can be triggered by mathematical formulas and functions.
However, the relation space between data objects is too large to be exhausted.
By analyzing real-world wrangling scripts, we focus on four commonly-used set relations, <span id="S2.SS2.SSS3.p1.4.9" class="ltx_ERROR undefined">\ie</span>, subset (<math id="S2.SS2.SSS3.p1.1.m1.1" class="ltx_Math" alttext="\subset" display="inline"><semantics id="S2.SS2.SSS3.p1.1.m1.1a"><mo id="S2.SS2.SSS3.p1.1.m1.1.1" xref="S2.SS2.SSS3.p1.1.m1.1.1.cmml">⊂</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p1.1.m1.1b"><subset id="S2.SS2.SSS3.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS3.p1.1.m1.1.1"></subset></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p1.1.m1.1c">\subset</annotation></semantics></math>), superset (<math id="S2.SS2.SSS3.p1.2.m2.1" class="ltx_Math" alttext="\supset" display="inline"><semantics id="S2.SS2.SSS3.p1.2.m2.1a"><mo id="S2.SS2.SSS3.p1.2.m2.1.1" xref="S2.SS2.SSS3.p1.2.m2.1.1.cmml">⊃</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p1.2.m2.1b"><csymbol cd="latexml" id="S2.SS2.SSS3.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS3.p1.2.m2.1.1">superset-of</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p1.2.m2.1c">\supset</annotation></semantics></math>), equal (<math id="S2.SS2.SSS3.p1.3.m3.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S2.SS2.SSS3.p1.3.m3.1a"><mo id="S2.SS2.SSS3.p1.3.m3.1.1" xref="S2.SS2.SSS3.p1.3.m3.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p1.3.m3.1b"><eq id="S2.SS2.SSS3.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS3.p1.3.m3.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p1.3.m3.1c">=</annotation></semantics></math>), and <span id="S2.SS2.SSS3.p1.4.10" class="ltx_ERROR undefined">\kai</span>others (<span id="S2.SS2.SSS3.p1.4.11" class="ltx_ERROR undefined">\ie</span>, apart from these three relations, <math id="S2.SS2.SSS3.p1.4.m4.1" class="ltx_Math" alttext="\neq" display="inline"><semantics id="S2.SS2.SSS3.p1.4.m4.1a"><mo id="S2.SS2.SSS3.p1.4.m4.1.1" xref="S2.SS2.SSS3.p1.4.m4.1.1.cmml">≠</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p1.4.m4.1b"><neq id="S2.SS2.SSS3.p1.4.m4.1.1.cmml" xref="S2.SS2.SSS3.p1.4.m4.1.1"></neq></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p1.4.m4.1c">\neq</annotation></semantics></math>).</p>
</div>
<div id="S2.SS2.SSS3.p2" class="ltx_para">
<p id="S2.SS2.SSS3.p2.9" class="ltx_p">For relations between columns (or rows), we summarize within- and between-table characteristics, respectively.
In terms of between-table characteristics, we focus on whether the content of columns in the input table is a subset (<math id="S2.SS2.SSS3.p2.1.m1.1" class="ltx_Math" alttext="\subset" display="inline"><semantics id="S2.SS2.SSS3.p2.1.m1.1a"><mo id="S2.SS2.SSS3.p2.1.m1.1.1" xref="S2.SS2.SSS3.p2.1.m1.1.1.cmml">⊂</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.1.m1.1b"><subset id="S2.SS2.SSS3.p2.1.m1.1.1.cmml" xref="S2.SS2.SSS3.p2.1.m1.1.1"></subset></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.1.m1.1c">\subset</annotation></semantics></math>), superset (<math id="S2.SS2.SSS3.p2.2.m2.1" class="ltx_Math" alttext="\supset" display="inline"><semantics id="S2.SS2.SSS3.p2.2.m2.1a"><mo id="S2.SS2.SSS3.p2.2.m2.1.1" xref="S2.SS2.SSS3.p2.2.m2.1.1.cmml">⊃</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.2.m2.1b"><csymbol cd="latexml" id="S2.SS2.SSS3.p2.2.m2.1.1.cmml" xref="S2.SS2.SSS3.p2.2.m2.1.1">superset-of</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.2.m2.1c">\supset</annotation></semantics></math>), identical (<math id="S2.SS2.SSS3.p2.3.m3.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S2.SS2.SSS3.p2.3.m3.1a"><mo id="S2.SS2.SSS3.p2.3.m3.1.1" xref="S2.SS2.SSS3.p2.3.m3.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.3.m3.1b"><eq id="S2.SS2.SSS3.p2.3.m3.1.1.cmml" xref="S2.SS2.SSS3.p2.3.m3.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.3.m3.1c">=</annotation></semantics></math>), or <span id="S2.SS2.SSS3.p2.9.1" class="ltx_ERROR undefined">\kai</span>others (<math id="S2.SS2.SSS3.p2.4.m4.1" class="ltx_Math" alttext="\neq" display="inline"><semantics id="S2.SS2.SSS3.p2.4.m4.1a"><mo id="S2.SS2.SSS3.p2.4.m4.1.1" xref="S2.SS2.SSS3.p2.4.m4.1.1.cmml">≠</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.4.m4.1b"><neq id="S2.SS2.SSS3.p2.4.m4.1.1.cmml" xref="S2.SS2.SSS3.p2.4.m4.1.1"></neq></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.4.m4.1c">\neq</annotation></semantics></math>) to that of the output table (e.g., characteristics 50—53).
In terms of within-table characteristics, we mainly focus on identical (<math id="S2.SS2.SSS3.p2.5.m5.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S2.SS2.SSS3.p2.5.m5.1a"><mo id="S2.SS2.SSS3.p2.5.m5.1.1" xref="S2.SS2.SSS3.p2.5.m5.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.5.m5.1b"><eq id="S2.SS2.SSS3.p2.5.m5.1.1.cmml" xref="S2.SS2.SSS3.p2.5.m5.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.5.m5.1c">=</annotation></semantics></math>) relations.
That is, we first identify the existence of identical columns within input and output tables, and compare them using boolean operators (e.g., characteristics 54—57).
For relations between cells, the characteristics are described by whether the values are equal (<math id="S2.SS2.SSS3.p2.6.m6.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S2.SS2.SSS3.p2.6.m6.1a"><mo id="S2.SS2.SSS3.p2.6.m6.1.1" xref="S2.SS2.SSS3.p2.6.m6.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.6.m6.1b"><eq id="S2.SS2.SSS3.p2.6.m6.1.1.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.6.m6.1c">=</annotation></semantics></math>), substring (e.g., <math id="S2.SS2.SSS3.p2.7.m7.1" class="ltx_Math" alttext="\subset" display="inline"><semantics id="S2.SS2.SSS3.p2.7.m7.1a"><mo id="S2.SS2.SSS3.p2.7.m7.1.1" xref="S2.SS2.SSS3.p2.7.m7.1.1.cmml">⊂</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.7.m7.1b"><subset id="S2.SS2.SSS3.p2.7.m7.1.1.cmml" xref="S2.SS2.SSS3.p2.7.m7.1.1"></subset></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.7.m7.1c">\subset</annotation></semantics></math> and <math id="S2.SS2.SSS3.p2.8.m8.1" class="ltx_Math" alttext="\supset" display="inline"><semantics id="S2.SS2.SSS3.p2.8.m8.1a"><mo id="S2.SS2.SSS3.p2.8.m8.1.1" xref="S2.SS2.SSS3.p2.8.m8.1.1.cmml">⊃</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.8.m8.1b"><csymbol cd="latexml" id="S2.SS2.SSS3.p2.8.m8.1.1.cmml" xref="S2.SS2.SSS3.p2.8.m8.1.1">superset-of</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.8.m8.1c">\supset</annotation></semantics></math>), or <span id="S2.SS2.SSS3.p2.9.2" class="ltx_ERROR undefined">\kai</span>others (<math id="S2.SS2.SSS3.p2.9.m9.1" class="ltx_Math" alttext="\neq" display="inline"><semantics id="S2.SS2.SSS3.p2.9.m9.1a"><mo id="S2.SS2.SSS3.p2.9.m9.1.1" xref="S2.SS2.SSS3.p2.9.m9.1.1.cmml">≠</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.9.m9.1b"><neq id="S2.SS2.SSS3.p2.9.m9.1.1.cmml" xref="S2.SS2.SSS3.p2.9.m9.1.1"></neq></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.9.m9.1c">\neq</annotation></semantics></math>) to each other (e.g., characteristics 66—69).
<span id="S2.SS2.SSS3.p2.9.3" class="ltx_ERROR undefined">\kai</span>Besides, we check whether cells in the same column or row have identical values in the input and output tables (e.g., characteristics 70—77).</p>
</div>
</section>
<section id="S2.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.4 </span>Value</h4>

<div id="S2.SS2.SSS4.p1" class="ltx_para">
<p id="S2.SS2.SSS4.p1.2" class="ltx_p">Some transformations relate to special values, e.g., missing values and user-defined values.
For example, the <span id="S2.SS2.SSS4.p1.2.1" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">dropna</span> function in Pandas detects and removes rows with missing values.
Meanwhile, the <span id="S2.SS2.SSS4.p1.2.2" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">replace</span> function replaces cells with user-defined values.
The value property is applicable to all data objects.
For tables, columns, and rows, we establish characteristics by identifying the existence of missing values within input and output data objects, and compare them using boolean operators (e.g., characteristics 78—81).
In addition, we detect whether the data objects include (<math id="S2.SS2.SSS4.p1.1.m1.1" class="ltx_Math" alttext="\supseteq" display="inline"><semantics id="S2.SS2.SSS4.p1.1.m1.1a"><mo id="S2.SS2.SSS4.p1.1.m1.1.1" xref="S2.SS2.SSS4.p1.1.m1.1.1.cmml">⊇</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS4.p1.1.m1.1b"><csymbol cd="latexml" id="S2.SS2.SSS4.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS4.p1.1.m1.1.1">superset-of-or-equals</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS4.p1.1.m1.1c">\supseteq</annotation></semantics></math>) a user-defined value or not (<math id="S2.SS2.SSS4.p1.2.m2.1" class="ltx_Math" alttext="\nsupseteq" display="inline"><semantics id="S2.SS2.SSS4.p1.2.m2.1a"><mo id="S2.SS2.SSS4.p1.2.m2.1.1" xref="S2.SS2.SSS4.p1.2.m2.1.1.cmml">⊉</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS4.p1.2.m2.1b"><csymbol cd="latexml" id="S2.SS2.SSS4.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS4.p1.2.m2.1.1">not-superset-of-nor-equals</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS4.p1.2.m2.1c">\nsupseteq</annotation></semantics></math>).
As for cells, the characteristics are described by whether a cell is a missing value, and whether a cell has changed from one value to another.</p>
</div>
</section>
<section id="S2.SS2.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.5 </span>Type</h4>

<div id="S2.SS2.SSS5.p1" class="ltx_para">
<p id="S2.SS2.SSS5.p1.1" class="ltx_p">This property, which describes changes in data type, is applicable to columns.
We focus on three types of columns, <span id="S2.SS2.SSS5.p1.1.1" class="ltx_ERROR undefined">\ie</span>, nominal, quantitative, and temporal.
The characteristics are described as, given a column in the input table, whether its data type is changed in the output table.</p>
</div>
</section>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Inferring Transformations With Characteristics</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">We summarize the characteristic space for the purpose of inferring the type of data transformation.
We begin with collecting a set of transformations.
Then we discuss the principles of type inference.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">Kasica <span id="S2.SS3.p2.1.1" class="ltx_text ltx_font_italic">et al.<cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS3.p2.1.1.1.1" class="ltx_text ltx_font_upright">[</span><a href="#bib.bib30" title="" class="ltx_ref">30</a><span id="S2.SS3.p2.1.1.2.2" class="ltx_text ltx_font_upright">]</span></cite></span> presented a design space encompassing <math id="S2.SS3.p2.1.m1.1" class="ltx_Math" alttext="15" display="inline"><semantics id="S2.SS3.p2.1.m1.1a"><mn id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><cn type="integer" id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">15</annotation></semantics></math> high-level transformations, which provides a good start for our investigation.
However, some transformations are too rough to distinguish detailed semantics. For example, constructing columns manually, mutating values from existing columns, and merging multiple columns, are all summarized by <span id="S2.SS3.p2.1.2" class="ltx_text ltx_font_italic">Create Columns</span> without distinction. <span id="S2.SS3.p2.1.3" class="ltx_ERROR undefined">\kai</span>On the other hand, Wrangler<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> and Trifacta <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> provide vocabularies describing low-level operations, such as <span id="S2.SS3.p2.1.4" class="ltx_text ltx_font_italic">Extract</span>, <span id="S2.SS3.p2.1.5" class="ltx_text ltx_font_italic">Merge</span>, and <span id="S2.SS3.p2.1.6" class="ltx_text ltx_font_italic">Replace</span>.
To support finer-grained semantics, we manually annotate each line of code in our corpus (see Sec. <a href="#S2.SS1" title="2.1 Methodology ‣ 2 A Design Space for Table Changes ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>) by linking one high-level transformation and one low-level operation.
Taking the above three transformations as examples, the new vocabularies of them are <span id="S2.SS3.p2.1.7" class="ltx_text ltx_font_italic">create_columns_create</span>, <span id="S2.SS3.p2.1.8" class="ltx_text ltx_font_italic">create_columns_mutate</span>, and <span id="S2.SS3.p2.1.9" class="ltx_text ltx_font_italic">create_columns_merge</span>, respectively.
This strategy is effective in generating a large number of low-level transformations.
In addition, we observe that some wrangling code does not change data tables, such as <span id="S2.SS3.p2.1.10" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">group</span>, <span id="S2.SS3.p2.1.11" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">ungroup</span>, and <span id="S2.SS3.p2.1.12" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">reset_index</span> functions in Pandas.
Though not changing data tables immediately, these functions usually act as prerequisites for the following transformations.
Hence, we include an <span id="S2.SS3.p2.1.13" class="ltx_text ltx_font_italic">identical_operation</span> transformation to describe these functions.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">To infer transformation type, we establish a mapping between transformations and characteristics.
For each transformation, we categorize characteristics into three groups, <span id="S2.SS3.p3.1.1" class="ltx_ERROR undefined">\ie</span>, impossible, possible, and inevitable.
Impossible characteristics refer to those that should not appear when performing a transformation.
Inevitable characteristics, on the other hand, will definitely exist after a transformation.
The above two sets play major roles in characteristic-based inference (see Sec. <a href="#S3.SS2.SSS1" title="3.2.1 Characteristic-Based Inference ‣ 3.2 Type Inference ‣ 3 The Comantics Pipeline ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.1</span></a>).
Possible characteristics are those that may or may not appear.
For example, given a line of code, <span id="S2.SS3.p3.1.2" class="ltx_text ltx_lstlisting" style="background-color:#CCCCCC;"><span id="S2.SS3.p3.1.2.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">df</span><span id="S2.SS3.p3.1.2.2" class="ltx_text ltx_font_typewriter">=<span id="S2.SS3.p3.1.2.2.1" class="ltx_text ltx_lst_identifier">df</span>[<span id="S2.SS3.p3.1.2.2.2" class="ltx_text ltx_lst_identifier">df</span>.<span id="S2.SS3.p3.1.2.2.3" class="ltx_text ltx_lst_identifier">num</span>&gt;1]</span></span>, which removes rows not meeting the condition <span id="S2.SS3.p3.1.3" class="ltx_text ltx_lstlisting" style="background-color:#CCCCCC;"><span id="S2.SS3.p3.1.3.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">df</span><span id="S2.SS3.p3.1.3.2" class="ltx_text ltx_font_typewriter">.<span id="S2.SS3.p3.1.3.2.1" class="ltx_text ltx_lst_identifier">num</span>&gt;1</span></span>, the number of columns will not change (e.g., the characteristic 6 is inevitable), and the number of rows in the output table can be smaller or equal to that in the input table (e.g., characteristics 23 and 24 are possible).
However, changes in the number of columns (e.g., characteristics 7 and 8) are impossible.
As a result, the problem of inferring transformation type is turned into detecting a set of impossible, possible, and inevitable characteristics.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>The <span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Comantics</span> Pipeline</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">This section introduces <span id="S3.p1.1.1" class="ltx_text ltx_font_smallcaps">Comantics</span>, an automatic pipeline for inferring semantics for data wrangling scripts.
Our pipeline takes data tables and a wrangling script as input, and generates a sequence of data transformations with parameters.
As illustrated in Fig. <span class="ltx_ref ltx_ref_self"><span class="ltx_text ltx_ref_title">Revealing the Semantics of Data Wrangling Scripts <span class="ltx_text"> </span>With <span class="ltx_text ltx_font_smallcaps">Comantics</span></span></span>, <span id="S3.p1.1.2" class="ltx_text ltx_font_smallcaps">Comantics</span> consists of three key steps, <span id="S3.p1.1.3" class="ltx_ERROR undefined">\ie</span>, Data Preprocessing (Fig. <span class="ltx_ref ltx_ref_self"><span class="ltx_text ltx_ref_title">Revealing the Semantics of Data Wrangling Scripts <span class="ltx_text"> </span>With <span class="ltx_text ltx_font_smallcaps">Comantics</span></span></span>(b)), Type Inference (Fig. <span class="ltx_ref ltx_ref_self"><span class="ltx_text ltx_ref_title">Revealing the Semantics of Data Wrangling Scripts <span class="ltx_text"> </span>With <span class="ltx_text ltx_font_smallcaps">Comantics</span></span></span>(c)), and Parameter Inference (Fig. <span class="ltx_ref ltx_ref_self"><span class="ltx_text ltx_ref_title">Revealing the Semantics of Data Wrangling Scripts <span class="ltx_text"> </span>With <span class="ltx_text ltx_font_smallcaps">Comantics</span></span></span>(d)).</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Data Preprocessing</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Since table changes highly relate to the semantics of transformation, the goal of this step is to identify a set of characteristics of table changes.
To this end, we first execute the wrangling script on the given source table, and obtain intermediate input and output tables for each line of code, which are saved as CSV files for further analysis.
<span id="S3.SS1.p1.1.1" class="ltx_ERROR undefined">\kai</span>These input tables are critical for type inference as one line of wrangling code could have different semantics given different input tables <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>.
<span id="S3.SS1.p1.1.2" class="ltx_ERROR undefined">\kai</span>Second, we detect table changes based on the design space for each wrangling code and output a set of characteristics.
We notice that the detection is time-consuming since some characteristics require content-based comparison between two tables.
For example, detecting the relation of two columns involves a pair-wise comparison of the content in each cell.
Therefore, we employ two pruning strategies to facilitate the detection.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_italic">Characteristics Pruning</span>:
Most detection relies on the existence of input and output tables.
Hence, a number of characteristics can be pruned if the prerequisite does not stand.
For example, if only output tables exist, the transformation is likely to be
<span id="S3.SS1.p2.1.2" class="ltx_text ltx_font_italic">Create Tables</span>, and the detection of other characteristics, such as changes in order and relation, is not applicable.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p"><span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_italic">Data Objects Pruning</span>:
We observe that, given new data objects in the output table, characteristics are mainly caused by the new ones.
Hence, we prune the remaining objects for content-based comparison.
For example, after detecting new columns in the output table, we focus on the detection of characteristics based on the new columns.
Other columns in the output tables, however, will not be involved in the content-based comparison.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Type Inference</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">To infer the transformation type of a line of wrangling code, the Type Inference step includes two components, <span id="S3.SS2.p1.1.1" class="ltx_ERROR undefined">\ie</span>, characteristic-based inference and model-based inference.
As the space of transformations could be large, the first component filters out impossible transformations and results in a smaller number of candidates.
The second component utilizes a Siamese convolutional neural network to assess the possibility of each candidate and returns a sorted list based on possibilities.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2209.13995/assets/x4.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="101" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Examples of the two ambiguities in characteristic-based inference. (a) The output table is identical to the input table, which can be caused by <span id="S3.F3.6.1" class="ltx_text ltx_font_italic">Remove Duplicate Rows</span>, <span id="S3.F3.7.2" class="ltx_text ltx_font_italic">Remove Rows with Missing Values</span>, <span id="S3.F3.8.3" class="ltx_text ltx_font_italic">Sort Age in Ascending Order</span>, etc. (b) The second row has been deleted, which can be caused by performing <span id="S3.F3.9.4" class="ltx_text ltx_font_italic">Filter Rows Where Gender is Male</span>, <span id="S3.F3.10.5" class="ltx_text ltx_font_italic">Remove Rows with Missing Values</span>, etc.</figcaption>
</figure>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Characteristic-Based Inference</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<span id="S3.SS2.SSS1.p1.1" class="ltx_ERROR undefined">\kai</span>
<p id="S3.SS2.SSS1.p1.2" class="ltx_p">Given a collection of characteristics,
we filter out impossible transformations based on the mapping described in Sec. <a href="#S2.SS3" title="2.3 Inferring Transformations With Characteristics ‣ 2 A Design Space for Table Changes ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>.
We establish two main strategies.
First, we identify whether characteristics fall into the <span id="S3.SS2.SSS1.p1.2.1" class="ltx_text ltx_font_italic">impossible</span> set of each transformation.
If true, the transformation is not included in the candidate list.
Second, we filter out transformations whose <span id="S3.SS2.SSS1.p1.2.2" class="ltx_text ltx_font_italic">inevitable</span> set is not a subset of the set of characteristics.
In this component, the type of transformation can hardly be uniquely identified because of two kinds of ambiguities.
First, the output table may be identical to the input one.
This may be because the conditions of transformations do not meet.
An example is shown in Fig. <a href="#S3.F3" title="Figure 3 ‣ 3.2 Type Inference ‣ 3 The Comantics Pipeline ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>(a), the input table may be unchanged after <span id="S3.SS2.SSS1.p1.2.3" class="ltx_text ltx_font_italic">Remove Duplicate Rows</span> because no duplicates exist in the input.
However, the same result may be caused by <span id="S3.SS2.SSS1.p1.2.4" class="ltx_text ltx_font_italic">Remove Rows with Missing Values</span> or <span id="S3.SS2.SSS1.p1.2.5" class="ltx_text ltx_font_italic">Sort Age in Ascending Order</span>, etc.
Second, more than two transformations lead to the same changes between tables.
As Fig. <a href="#S3.F3" title="Figure 3 ‣ 3.2 Type Inference ‣ 3 The Comantics Pipeline ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>(b) shows, changes between two tables may be caused by <span id="S3.SS2.SSS1.p1.2.6" class="ltx_text ltx_font_italic">Filter Rows Where Gender is Male</span>, <span id="S3.SS2.SSS1.p1.2.7" class="ltx_text ltx_font_italic">Remove Rows with Missing Values</span>, etc.
Hence, this component results in a set of transformation candidates.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Model-Based Inference</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<span id="S3.SS2.SSS2.p1.1" class="ltx_ERROR undefined">\kai</span>
<p id="S3.SS2.SSS2.p1.2" class="ltx_p">To resolve the ambiguities in characteristic-based inference, the analysis of scripting code seems a feasible solution.
However, due to the variety of programming languages, functions, and parameters in data wrangling, crafting rules to parse code is time-consuming and limited in generalizability and scalability.
Besides table changes, we observe that the semantics of a transformation is usually implied in the code.
For example, some functions, e.g., <span id="S3.SS2.SSS2.p1.2.1" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">drop_duplicates</span> in Pandas, <span id="S3.SS2.SSS2.p1.2.2" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">distinct</span> in dplyr, and <span id="S3.SS2.SSS2.p1.2.3" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">unique</span> in R, perform <span id="S3.SS2.SSS2.p1.2.4" class="ltx_text ltx_font_italic">Removing Duplicate Rows</span>, which can be inferred from the function name to some extent.
It is also true for some parameters, such as <span id="S3.SS2.SSS2.p1.2.5" class="ltx_text ltx_lstlisting" style="background-color:#CCCCCC;"><span id="S3.SS2.SSS2.p1.2.5.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">ascending</span><span id="S3.SS2.SSS2.p1.2.5.2" class="ltx_text ltx_font_typewriter">=<span id="S3.SS2.SSS2.p1.2.5.2.1" class="ltx_text ltx_lst_identifier">False</span></span></span>, <span id="S3.SS2.SSS2.p1.2.6" class="ltx_text ltx_lstlisting" style="background-color:#CCCCCC;"><span id="S3.SS2.SSS2.p1.2.6.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">remove</span><span id="S3.SS2.SSS2.p1.2.6.2" class="ltx_text ltx_font_typewriter">=<span id="S3.SS2.SSS2.p1.2.6.2.1" class="ltx_text ltx_lst_identifier">TRUE</span></span></span>, etc.
Therefore, we employ a machine learning model to alleviate ambiguities and compute the possibilities for each transformation candidate.
One key step in machine learning is feature engineering, which identifies critical information and generates vectors for it.
Here we incorporate the characteristics, function names, and parameters as key information for feature engineering.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.3" class="ltx_p">To reveal the semantics of function names and parameters, we vectorize them using text embedding approaches.
The embedding, however, is not straightforward.
To be specific, some wrangling code does not include a function name.
Fig. <a href="#S5.F5" title="Figure 5 ‣ 5.2 Somnus Re-visited ‣ 5 Example Applications ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>(c) presents an example where a new column in the output table is created by an addition statement.
In this case, we set <span id="S3.SS2.SSS2.p2.3.1" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">None</span> as its function name.
In addition, function names and parameters usually contain out-of-vocabulary (OOV) words.
For example, some functions are named <span id="S3.SS2.SSS2.p2.3.2" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">drop_duplicates</span>, <span id="S3.SS2.SSS2.p2.3.3" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">inner_join</span>, and <span id="S3.SS2.SSS2.p2.3.4" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">fillna</span>, and some parameters are called <span id="S3.SS2.SSS2.p2.3.5" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">by_group</span>, <span id="S3.SS2.SSS2.p2.3.6" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">to_replace</span>, and <span id="S3.SS2.SSS2.p2.3.7" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">skipna</span>.
To tackle this problem, we adopt FastText <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> for text embedding because it can handle the OOV words by considering subword information.
Finally, we obtain two <math id="S3.SS2.SSS2.p2.1.m1.1" class="ltx_Math" alttext="1\times 300" display="inline"><semantics id="S3.SS2.SSS2.p2.1.m1.1a"><mrow id="S3.SS2.SSS2.p2.1.m1.1.1" xref="S3.SS2.SSS2.p2.1.m1.1.1.cmml"><mn id="S3.SS2.SSS2.p2.1.m1.1.1.2" xref="S3.SS2.SSS2.p2.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS2.p2.1.m1.1.1.1" xref="S3.SS2.SSS2.p2.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS2.SSS2.p2.1.m1.1.1.3" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.cmml">300</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.1.m1.1b"><apply id="S3.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1"><times id="S3.SS2.SSS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1.1"></times><cn type="integer" id="S3.SS2.SSS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1.2">1</cn><cn type="integer" id="S3.SS2.SSS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1.3">300</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.1.m1.1c">1\times 300</annotation></semantics></math> vectors capturing the semantics of function names and parameters, respectively.
Similarly, we present each characteristic using natural language, and use FastText to vectorize each characteristic.
After obtaining all feature vectors of characteristics, we average all vectors to form one with dimension <math id="S3.SS2.SSS2.p2.2.m2.1" class="ltx_Math" alttext="1\times 300" display="inline"><semantics id="S3.SS2.SSS2.p2.2.m2.1a"><mrow id="S3.SS2.SSS2.p2.2.m2.1.1" xref="S3.SS2.SSS2.p2.2.m2.1.1.cmml"><mn id="S3.SS2.SSS2.p2.2.m2.1.1.2" xref="S3.SS2.SSS2.p2.2.m2.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS2.p2.2.m2.1.1.1" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.cmml">×</mo><mn id="S3.SS2.SSS2.p2.2.m2.1.1.3" xref="S3.SS2.SSS2.p2.2.m2.1.1.3.cmml">300</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.2.m2.1b"><apply id="S3.SS2.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1"><times id="S3.SS2.SSS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.1"></times><cn type="integer" id="S3.SS2.SSS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.2">1</cn><cn type="integer" id="S3.SS2.SSS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.3">300</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.2.m2.1c">1\times 300</annotation></semantics></math>.
Finally, we linearly combine these vectors to obtain a semantic vector with dimension <math id="S3.SS2.SSS2.p2.3.m3.1" class="ltx_Math" alttext="3\times 300" display="inline"><semantics id="S3.SS2.SSS2.p2.3.m3.1a"><mrow id="S3.SS2.SSS2.p2.3.m3.1.1" xref="S3.SS2.SSS2.p2.3.m3.1.1.cmml"><mn id="S3.SS2.SSS2.p2.3.m3.1.1.2" xref="S3.SS2.SSS2.p2.3.m3.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS2.p2.3.m3.1.1.1" xref="S3.SS2.SSS2.p2.3.m3.1.1.1.cmml">×</mo><mn id="S3.SS2.SSS2.p2.3.m3.1.1.3" xref="S3.SS2.SSS2.p2.3.m3.1.1.3.cmml">300</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.3.m3.1b"><apply id="S3.SS2.SSS2.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p2.3.m3.1.1"><times id="S3.SS2.SSS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.SSS2.p2.3.m3.1.1.1"></times><cn type="integer" id="S3.SS2.SSS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.SSS2.p2.3.m3.1.1.2">3</cn><cn type="integer" id="S3.SS2.SSS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.SSS2.p2.3.m3.1.1.3">300</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.3.m3.1c">3\times 300</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<p id="S3.SS2.SSS2.p3.1" class="ltx_p">To calculate the likelihood of each transformation, we employ a Siamese Convolutional Neural Network (CNN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> which can address two challenges.
First, the problem of inferring transformation type is relatively new, and training samples are hard to find in the existing corpus.
Second, the data transformation space could be large.
However, only a few of them are used commonly in practice (details are described in Sec. <a href="#S4.SS1" title="4.1 Dataset ‣ 4 Experiments ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>).
That means training samples from the real-world corpus are likely to be imbalanced.
CNN is a kind of flexible classification architecture that is suitable for few shot problems and imbalanced data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.
We acknowledge that <span id="S3.SS2.SSS2.p3.1.1" class="ltx_text ltx_font_smallcaps">Comantics</span> does not rely on one model architecture, and the CNN model can be replaced by others.
In this paper, we use CNN to verify the idea of <span id="S3.SS2.SSS2.p3.1.2" class="ltx_text ltx_font_smallcaps">Comantics</span>.</p>
</div>
<div id="S3.SS2.SSS2.p4" class="ltx_para">
<p id="S3.SS2.SSS2.p4.2" class="ltx_p">The Siamese network model comprises two identical subnetworks, and each utilizes five convolutional layers followed by a flatten layer.
The input of each subnetwork is a semantic vector encompassing three types of information, <span id="S3.SS2.SSS2.p4.2.1" class="ltx_ERROR undefined">\ie</span>, the characteristics of changes, the function name, and the function parameters.
In this model, we refer to Hadsell <span id="S3.SS2.SSS2.p4.2.2" class="ltx_text ltx_font_italic">et al.<cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.SSS2.p4.2.2.1.1" class="ltx_text ltx_font_upright">[</span><a href="#bib.bib18" title="" class="ltx_ref">18</a><span id="S3.SS2.SSS2.p4.2.2.2.2" class="ltx_text ltx_font_upright">]</span></cite></span> to define and optimize the contrastive loss.
After a pair of semantic vectors is fed into the model, the similarity of the two vectors is computed based on Euclidean distance.
The output of the model is <math id="S3.SS2.SSS2.p4.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.SS2.SSS2.p4.1.m1.1a"><mn id="S3.SS2.SSS2.p4.1.m1.1.1" xref="S3.SS2.SSS2.p4.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.1.m1.1b"><cn type="integer" id="S3.SS2.SSS2.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.1.m1.1c">1</annotation></semantics></math> or <math id="S3.SS2.SSS2.p4.2.m2.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S3.SS2.SSS2.p4.2.m2.1a"><mn id="S3.SS2.SSS2.p4.2.m2.1.1" xref="S3.SS2.SSS2.p4.2.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.2.m2.1b"><cn type="integer" id="S3.SS2.SSS2.p4.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1">0</cn></annotation-xml></semantics></math>, which means whether the two inputs belong to the same transformation type.
<span id="S3.SS2.SSS2.p4.2.3" class="ltx_ERROR undefined">\kai</span>After training the model on the labeled dataset (see Sec. <a href="#S4.SS1" title="4.1 Dataset ‣ 4 Experiments ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>), we apply it to obtain the likelihood of each transformation in the candidate set.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Parameter Inference</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Parameters define how a transformation performs.
<span id="S3.SS3.p1.1.1" class="ltx_ERROR undefined">\kai</span>Taking the set of transformation candidates with likelihood as input, this step aims to infer parameters for transformations.
Borrowing the idea of slot filling in task-based dialog systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>, we first manually define a set of parameters, <span id="S3.SS3.p1.1.2" class="ltx_ERROR undefined">\ie</span>, slots, that a transformation should include.
Then, we detect these parameters, <span id="S3.SS3.p1.1.3" class="ltx_ERROR undefined">\ie</span>, filling slots, based on the wrangling code, characteristics of table changes, and the content of input/output tables.
For example, given a piece of code, <span id="S3.SS3.p1.1.4" class="ltx_text ltx_lstlisting" style="background-color:#CCCCCC;"><span id="S3.SS3.p1.1.4.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">df2</span><span id="S3.SS3.p1.1.4.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="S3.SS3.p1.1.4.3" class="ltx_text ltx_font_typewriter">=<span id="S3.SS3.p1.1.4.3.1" class="ltx_text ltx_lst_space"> </span><span id="S3.SS3.p1.1.4.3.2" class="ltx_text ltx_lst_identifier">unite</span>(<span id="S3.SS3.p1.1.4.3.3" class="ltx_text ltx_lst_identifier">df1</span>,<span id="S3.SS3.p1.1.4.3.4" class="ltx_text ltx_lst_space"> </span>‘<span id="S3.SS3.p1.1.4.3.5" class="ltx_text ltx_lst_identifier">Z</span>’,<span id="S3.SS3.p1.1.4.3.6" class="ltx_text ltx_lst_space"> </span><span id="S3.SS3.p1.1.4.3.7" class="ltx_text ltx_lst_identifier">X</span>,<span id="S3.SS3.p1.1.4.3.8" class="ltx_text ltx_lst_space"> </span><span id="S3.SS3.p1.1.4.3.9" class="ltx_text ltx_lst_identifier">Y</span>)</span></span>,
<span id="S3.SS3.p1.1.5" class="ltx_text ltx_font_smallcaps">Comantics</span> infers that the transformation <span id="S3.SS3.p1.1.6" class="ltx_text ltx_font_italic">merge columns</span> has the maximum likelihood.
Then, we detect parameters of <span id="S3.SS3.p1.1.7" class="ltx_text ltx_font_italic">merge columns</span>, which are pre-defined as one input table, multiple columns in the input, one output table, the merged column in the output, and a separator.
The input and output tables can be obtained from the Data Preprocessing step.
To fill other slots, we first extract column names from the code, <span id="S3.SS3.p1.1.8" class="ltx_ERROR undefined">\ie</span>, <span id="S3.SS3.p1.1.9" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">Z</span>, <span id="S3.SS3.p1.1.10" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">X</span>, and <span id="S3.SS3.p1.1.11" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">Y</span>.
Then, we obtain relations between the three columns using characteristics of table differences, and fill the two slots, <span id="S3.SS3.p1.1.12" class="ltx_ERROR undefined">\ie</span>, multiple columns in the input and the merged column in the output.
Since the separator is not available in the code, we extract it from the table content.
Note that <span id="S3.SS3.p1.1.13" class="ltx_text ltx_font_smallcaps">Comantics</span> only supports the inference of a limited number of separators, and can be easily extended.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">However, the slot filling process <span id="S3.SS3.p2.1.1" class="ltx_ERROR undefined">\kai</span>may fail.
If so, <span id="S3.SS3.p2.1.2" class="ltx_text ltx_font_smallcaps">Comantics</span> will filter out the transformation and turn to the one with the second maximum likelihood and detect whether parameters meet the transformation, and so forth.
<span id="S3.SS3.p2.1.3" class="ltx_text ltx_font_smallcaps">Comantics</span> stops detection until parameters match the transformation type.
Following the above example, if relations between columns cannot be detected, the transformation type, e.g., <span id="S3.SS3.p2.1.4" class="ltx_text ltx_font_italic">merge</span>, does not stand.
Then, <span id="S3.SS3.p2.1.5" class="ltx_text ltx_font_smallcaps">Comantics</span> will turn to the next transformation and continue the slot filling process.
This step can also filter out impossible transformations to some extent, which is beneficial to the overall accuracy of <span id="S3.SS3.p2.1.6" class="ltx_text ltx_font_smallcaps">Comantics</span>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<span id="S4.p1.1" class="ltx_ERROR undefined">\kai</span>
<p id="S4.p1.2" class="ltx_p">We design experiments to evaluate <span id="S4.p1.2.1" class="ltx_text ltx_font_smallcaps">Comantics</span> from two aspects.
First, since characteristic-based inference is independent of programming languages, we assess whether the pipeline trained in one programming language can be generalized to the other. Second, we evaluate how each part of <span id="S4.p1.2.2" class="ltx_text ltx_font_smallcaps">Comantics</span> contributes to the overall performance.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>
<span id="S4.T1.2.1" class="ltx_ERROR undefined">\kai</span>Statistical analysis of the dataset on five metrics, including the total lines of wrangling code (#Instances), the average lines of wrangling code in scripts (Avg #Inst), the number of distinct data transformation types (#Trans),
the number of distinct functions (#Func), and the average number of implementations for each data transformation (Avg #Imps).
</figcaption>
<div id="S4.T1.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:99.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(60.4pt,-13.9pt) scale(1.38598002380156,1.38598002380156) ;">
<table id="S4.T1.3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.3.1.1.1" class="ltx_tr">
<th id="S4.T1.3.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S4.T1.3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.3.1.1.1.2.1" class="ltx_text ltx_font_bold">#Instances</span></th>
<th id="S4.T1.3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.3.1.1.1.3.1" class="ltx_text ltx_font_bold">Avg #Inst</span></th>
<th id="S4.T1.3.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.3.1.1.1.4.1" class="ltx_text ltx_font_bold">#Trans</span></th>
<th id="S4.T1.3.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.3.1.1.1.5.1" class="ltx_text ltx_font_bold">#Func</span></th>
<th id="S4.T1.3.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.3.1.1.1.6.1" class="ltx_text ltx_font_bold">Avg #Imps</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.3.1.2.1" class="ltx_tr">
<th id="S4.T1.3.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Python</th>
<td id="S4.T1.3.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">606</td>
<td id="S4.T1.3.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">14.43</td>
<td id="S4.T1.3.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">29</td>
<td id="S4.T1.3.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">52</td>
<td id="S4.T1.3.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">3.86</td>
</tr>
<tr id="S4.T1.3.1.3.2" class="ltx_tr">
<th id="S4.T1.3.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">R</th>
<td id="S4.T1.3.1.3.2.2" class="ltx_td ltx_align_center">315</td>
<td id="S4.T1.3.1.3.2.3" class="ltx_td ltx_align_center">9.84</td>
<td id="S4.T1.3.1.3.2.4" class="ltx_td ltx_align_center">28</td>
<td id="S4.T1.3.1.3.2.5" class="ltx_td ltx_align_center">47</td>
<td id="S4.T1.3.1.3.2.6" class="ltx_td ltx_align_center">2.14</td>
</tr>
<tr id="S4.T1.3.1.4.3" class="ltx_tr">
<th id="S4.T1.3.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t">Sum</th>
<td id="S4.T1.3.1.4.3.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">921</td>
<td id="S4.T1.3.1.4.3.3" class="ltx_td ltx_border_bb ltx_border_t"></td>
<td id="S4.T1.3.1.4.3.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">30</td>
<td id="S4.T1.3.1.4.3.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">99</td>
<td id="S4.T1.3.1.4.3.6" class="ltx_td ltx_border_bb ltx_border_t"></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Dataset</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.3" class="ltx_p">Based on the corpus described in Sec. <a href="#S2.SS1" title="2.1 Methodology ‣ 2 A Design Space for Table Changes ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>, we manually annotate the transformation type for each line of code.
To ensure the accuracy, the labeling process is based on the documentation of each function describing its usage.
After that, we verify the labeling results using the characteristics between the input and output tables.
Finally, we have labeled and verified <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="74" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mn id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">74</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><cn type="integer" id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">74</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">74</annotation></semantics></math> script files including <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="921" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mn id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">921</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><cn type="integer" id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">921</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">921</annotation></semantics></math> lines of code.
We distinguish scripts written in Python and R, and report the statistical results of our dataset on five metrics (see Table <a href="#S4.T1" title="Table 1 ‣ 4 Experiments ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
<span id="S4.SS1.p1.3.1" class="ltx_ERROR undefined">\kai</span>
Here we define the number of implementations (#Imps) as how many methods (including different functions or the non-functional equation) can be utilized to perform a data transformation.
For example, there are two functions (<span id="S4.SS1.p1.3.2" class="ltx_ERROR undefined">\ie</span>, <span id="S4.SS1.p1.3.3" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">pivot_longer</span> and <span id="S4.SS1.p1.3.4" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">gather</span>) in tidyr that can be used to fulfil <span id="S4.SS1.p1.3.5" class="ltx_text ltx_font_italic">transform_tables_fold</span>, so its #Imps is <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mn id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><cn type="integer" id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">2</annotation></semantics></math>.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.9" class="ltx_p">From Table <a href="#S4.T1" title="Table 1 ‣ 4 Experiments ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we have some interesting findings.
Though we have tried to balance the number of scripts (<math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="42" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mn id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">42</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><cn type="integer" id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">42</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">42</annotation></semantics></math> for Python and <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="32" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mn id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><cn type="integer" id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">32</annotation></semantics></math> for R), the number of instances between the two languages varies (<math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="606" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><mn id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml">606</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><cn type="integer" id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">606</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">606</annotation></semantics></math> versus <math id="S4.SS1.p2.4.m4.1" class="ltx_Math" alttext="315" display="inline"><semantics id="S4.SS1.p2.4.m4.1a"><mn id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml">315</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><cn type="integer" id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1">315</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">315</annotation></semantics></math>). It is because Python scripts are usually longer than those of R (<math id="S4.SS1.p2.5.m5.1" class="ltx_Math" alttext="14.43" display="inline"><semantics id="S4.SS1.p2.5.m5.1a"><mn id="S4.SS1.p2.5.m5.1.1" xref="S4.SS1.p2.5.m5.1.1.cmml">14.43</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.1b"><cn type="float" id="S4.SS1.p2.5.m5.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1">14.43</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.1c">14.43</annotation></semantics></math> Avg #Inst for Python versus <math id="S4.SS1.p2.6.m6.1" class="ltx_Math" alttext="9.84" display="inline"><semantics id="S4.SS1.p2.6.m6.1a"><mn id="S4.SS1.p2.6.m6.1.1" xref="S4.SS1.p2.6.m6.1.1.cmml">9.84</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.6.m6.1b"><cn type="float" id="S4.SS1.p2.6.m6.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1">9.84</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.6.m6.1c">9.84</annotation></semantics></math> for R).
The number of transformations and functions that appeared in the corpus is similar.
<span id="S4.SS1.p2.9.1" class="ltx_text ltx_font_smallcaps">Comantics</span> can support <math id="S4.SS1.p2.7.m7.1" class="ltx_Math" alttext="99" display="inline"><semantics id="S4.SS1.p2.7.m7.1a"><mn id="S4.SS1.p2.7.m7.1.1" xref="S4.SS1.p2.7.m7.1.1.cmml">99</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.7.m7.1b"><cn type="integer" id="S4.SS1.p2.7.m7.1.1.cmml" xref="S4.SS1.p2.7.m7.1.1">99</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.7.m7.1c">99</annotation></semantics></math> functions in total, which is significantly more than previous work including Datamations<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> and Sonmus<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>.
We argue that our pipeline is scalable in terms of the number of functions.
However, we notice that the Avg #Imps in Python (<math id="S4.SS1.p2.8.m8.1" class="ltx_Math" alttext="3.86" display="inline"><semantics id="S4.SS1.p2.8.m8.1a"><mn id="S4.SS1.p2.8.m8.1.1" xref="S4.SS1.p2.8.m8.1.1.cmml">3.86</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.8.m8.1b"><cn type="float" id="S4.SS1.p2.8.m8.1.1.cmml" xref="S4.SS1.p2.8.m8.1.1">3.86</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.8.m8.1c">3.86</annotation></semantics></math>) is greater than that in R (<math id="S4.SS1.p2.9.m9.1" class="ltx_Math" alttext="2.14" display="inline"><semantics id="S4.SS1.p2.9.m9.1a"><mn id="S4.SS1.p2.9.m9.1.1" xref="S4.SS1.p2.9.m9.1.1.cmml">2.14</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.9.m9.1b"><cn type="float" id="S4.SS1.p2.9.m9.1.1.cmml" xref="S4.SS1.p2.9.m9.1.1">2.14</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.9.m9.1c">2.14</annotation></semantics></math>), meaning that Python is more flexible in implementing data transformations.
<span id="S4.SS1.p2.9.2" class="ltx_ERROR undefined">\kai</span>The dataset and its statistical analysis are provided in the supplemental material.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Metrics</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.2" class="ltx_p">Following the previous work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, we adopt Top-N accuracy metrics to evaluate the performance of <span id="S4.SS2.p1.2.1" class="ltx_text ltx_font_smallcaps">Comantics</span>.
These metrics are usually used for multi-class classification models.
Top-1 accuracy is a conventional classification metric that measures the proportion of samples where the highest probability prediction matches the target label.
However, due to a large number of categories (<span id="S4.SS2.p1.2.2" class="ltx_ERROR undefined">\ie</span>, <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mn id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><cn type="integer" id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">30</annotation></semantics></math> distinct transformations) and a few training/testing samples (<span id="S4.SS2.p1.2.3" class="ltx_ERROR undefined">\ie</span>, <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="921" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mn id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">921</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><cn type="integer" id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">921</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">921</annotation></semantics></math> instances), Top-1 accuracy may limit our understanding of <span id="S4.SS2.p1.2.4" class="ltx_text ltx_font_smallcaps">Comantics</span>.
Hence, we employ Top-3 accuracy, which measures the possibility that the top three predictions include the correct answer.
<span id="S4.SS2.p1.2.5" class="ltx_ERROR undefined">\kai</span>We also report the training times in minutes for each experiment to get a rough idea about how computationally-demanding the training process is.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Methods and Apparatus</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">To evaluate how each component contributes to the performance, we prepare two techniques, <span id="S4.SS3.p1.1.1" class="ltx_ERROR undefined">\ie</span>, the entire pipeline and the Siamese Convolutional Neural Network (CNN).
Similar to <span id="S4.SS3.p1.1.2" class="ltx_text ltx_font_smallcaps">Comantics</span>, the CNN technique includes three steps.
The difference between them is that the second step of the CNN technique does not include a characteristic-based inference component.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.3" class="ltx_p">We split the dataset using four strategies.
<span id="S4.SS3.p2.3.1" class="ltx_ERROR undefined">\kai</span>Firstly, to evaluate how each technique performs across Python and R,
we use the scripts in Python as the train set and R as the test set, and vice versa.
To ensure that the space of data transformations is consistent between the train and test, we select common transformations (<math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="27" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mn id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">27</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><cn type="integer" id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">27</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">27</annotation></semantics></math> types in total) in both sets.
Secondly, we split the Python instances by random selection in each transformation type at a ratio of <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="80:20" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mrow id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml"><mn id="S4.SS3.p2.2.m2.1.1.2" xref="S4.SS3.p2.2.m2.1.1.2.cmml">80</mn><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.p2.2.m2.1.1.1" xref="S4.SS3.p2.2.m2.1.1.1.cmml">:</mo><mn id="S4.SS3.p2.2.m2.1.1.3" xref="S4.SS3.p2.2.m2.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><apply id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1"><ci id="S4.SS3.p2.2.m2.1.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1.1">:</ci><cn type="integer" id="S4.SS3.p2.2.m2.1.1.2.cmml" xref="S4.SS3.p2.2.m2.1.1.2">80</cn><cn type="integer" id="S4.SS3.p2.2.m2.1.1.3.cmml" xref="S4.SS3.p2.2.m2.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">80:20</annotation></semantics></math>, which are used as the train and test sets, respectively.
Based on the Python test set, we form the third strategy where we include R scripts into the train set.
Finally, we combine all Python and R instances and randomly split them at a ratio of <math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="80:20" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mrow id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml"><mn id="S4.SS3.p2.3.m3.1.1.2" xref="S4.SS3.p2.3.m3.1.1.2.cmml">80</mn><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.p2.3.m3.1.1.1" xref="S4.SS3.p2.3.m3.1.1.1.cmml">:</mo><mn id="S4.SS3.p2.3.m3.1.1.3" xref="S4.SS3.p2.3.m3.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><apply id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"><ci id="S4.SS3.p2.3.m3.1.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1.1">:</ci><cn type="integer" id="S4.SS3.p2.3.m3.1.1.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2">80</cn><cn type="integer" id="S4.SS3.p2.3.m3.1.1.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">80:20</annotation></semantics></math>.
The experiments are performed on a Windows 10 desktop with a 3.20GHz Intel Core i7-8700 CPU and 32 GB RAM.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Results and Analysis</h3>

<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>The training time, Top-1, and Top-3 performances of <span id="S4.T2.2.1" class="ltx_text ltx_font_smallcaps">Comantics</span> and its CNN-based component in different experiment settings.</figcaption>
<div id="S4.T2.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:127.8pt;vertical-align:-2.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-0.3pt,0.1pt) scale(0.998483848227976,0.998483848227976) ;">
<table id="S4.T2.3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.3.1.1.1" class="ltx_tr">
<th id="S4.T2.3.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt" rowspan="2"></th>
<th id="S4.T2.3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">Setting</th>
<th id="S4.T2.3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">CNN</th>
<th id="S4.T2.3.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S4.T2.3.1.1.1.4.1" class="ltx_text ltx_font_smallcaps">Comantics</span></th>
<th id="S4.T2.3.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Time</th>
</tr>
<tr id="S4.T2.3.1.2.2" class="ltx_tr">
<th id="S4.T2.3.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Train</th>
<th id="S4.T2.3.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Test</th>
<th id="S4.T2.3.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Top-1</th>
<th id="S4.T2.3.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Top-3</th>
<th id="S4.T2.3.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Top-1</th>
<th id="S4.T2.3.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Top-3</th>
<th id="S4.T2.3.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">(minutes)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.3.1.3.1" class="ltx_tr">
<th id="S4.T2.3.1.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">
<span id="S4.T2.3.1.3.1.1.1" class="ltx_ERROR undefined">\nth</span>1</th>
<td id="S4.T2.3.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t">Python</td>
<td id="S4.T2.3.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">R</td>
<td id="S4.T2.3.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">19.1</td>
<td id="S4.T2.3.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">30.3</td>
<td id="S4.T2.3.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">53.8</td>
<td id="S4.T2.3.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t">76.1</td>
<td id="S4.T2.3.1.3.1.8" class="ltx_td ltx_align_center ltx_border_t">19.5</td>
</tr>
<tr id="S4.T2.3.1.4.2" class="ltx_tr">
<th id="S4.T2.3.1.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">
<span id="S4.T2.3.1.4.2.1.1" class="ltx_ERROR undefined">\nth</span>2</th>
<td id="S4.T2.3.1.4.2.2" class="ltx_td ltx_align_center">R</td>
<td id="S4.T2.3.1.4.2.3" class="ltx_td ltx_align_center">Python</td>
<td id="S4.T2.3.1.4.2.4" class="ltx_td ltx_align_center">23.2</td>
<td id="S4.T2.3.1.4.2.5" class="ltx_td ltx_align_center">32.3</td>
<td id="S4.T2.3.1.4.2.6" class="ltx_td ltx_align_center">44.5</td>
<td id="S4.T2.3.1.4.2.7" class="ltx_td ltx_align_center">82.6</td>
<td id="S4.T2.3.1.4.2.8" class="ltx_td ltx_align_center">15.1</td>
</tr>
<tr id="S4.T2.3.1.5.3" class="ltx_tr">
<th id="S4.T2.3.1.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">
<span id="S4.T2.3.1.5.3.1.1" class="ltx_ERROR undefined">\nth</span>3</th>
<td id="S4.T2.3.1.5.3.2" class="ltx_td ltx_align_center">Python</td>
<td id="S4.T2.3.1.5.3.3" class="ltx_td ltx_align_center">Python</td>
<td id="S4.T2.3.1.5.3.4" class="ltx_td ltx_align_center">62.1</td>
<td id="S4.T2.3.1.5.3.5" class="ltx_td ltx_align_center">83.3</td>
<td id="S4.T2.3.1.5.3.6" class="ltx_td ltx_align_center">80.3</td>
<td id="S4.T2.3.1.5.3.7" class="ltx_td ltx_align_center">94.7</td>
<td id="S4.T2.3.1.5.3.8" class="ltx_td ltx_align_center">18.3</td>
</tr>
<tr id="S4.T2.3.1.6.4" class="ltx_tr">
<th id="S4.T2.3.1.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">
<span id="S4.T2.3.1.6.4.1.1" class="ltx_ERROR undefined">\nth</span>4</th>
<td id="S4.T2.3.1.6.4.2" class="ltx_td ltx_align_center">All</td>
<td id="S4.T2.3.1.6.4.3" class="ltx_td ltx_align_center">Python</td>
<td id="S4.T2.3.1.6.4.4" class="ltx_td ltx_align_center">72.0</td>
<td id="S4.T2.3.1.6.4.5" class="ltx_td ltx_align_center">90.9</td>
<td id="S4.T2.3.1.6.4.6" class="ltx_td ltx_align_center">90.2</td>
<td id="S4.T2.3.1.6.4.7" class="ltx_td ltx_align_center">98.5</td>
<td id="S4.T2.3.1.6.4.8" class="ltx_td ltx_align_center">21.9</td>
</tr>
<tr id="S4.T2.3.1.7.5" class="ltx_tr">
<th id="S4.T2.3.1.7.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">
<span id="S4.T2.3.1.7.5.1.1" class="ltx_ERROR undefined">\nth</span>5</th>
<td id="S4.T2.3.1.7.5.2" class="ltx_td ltx_align_center ltx_border_bb">All</td>
<td id="S4.T2.3.1.7.5.3" class="ltx_td ltx_align_center ltx_border_bb">All</td>
<td id="S4.T2.3.1.7.5.4" class="ltx_td ltx_align_center ltx_border_bb">78.0</td>
<td id="S4.T2.3.1.7.5.5" class="ltx_td ltx_align_center ltx_border_bb">92.2</td>
<td id="S4.T2.3.1.7.5.6" class="ltx_td ltx_align_center ltx_border_bb">92.2</td>
<td id="S4.T2.3.1.7.5.7" class="ltx_td ltx_align_center ltx_border_bb">99.0</td>
<td id="S4.T2.3.1.7.5.8" class="ltx_td ltx_align_center ltx_border_bb">19.6</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.2" class="ltx_p"><span id="S4.SS4.p1.2.1" class="ltx_text ltx_font_italic">Contribution of each component:</span>
The Type Inference step of <span id="S4.SS4.p1.2.2" class="ltx_text ltx_font_smallcaps">Comantics</span> consists of two components, <span id="S4.SS4.p1.2.3" class="ltx_ERROR undefined">\ie</span>, characteristic-based inference and CNN-based inference.
By incorporating the characteristic-based inference component, the pipeline results in better accuracy compared to the CNN-based model on both Top-1 and Top-3 accuracies.
<span id="S4.SS4.p1.2.4" class="ltx_ERROR undefined">\kai</span>Specifically, based on the Top-1 accuracy, the accuracy increases by <math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="21.32\%" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><mrow id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml"><mn id="S4.SS4.p1.1.m1.1.1.2" xref="S4.SS4.p1.1.m1.1.1.2.cmml">21.32</mn><mo id="S4.SS4.p1.1.m1.1.1.1" xref="S4.SS4.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><apply id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS4.p1.1.m1.1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p1.1.m1.1.1.2.cmml" xref="S4.SS4.p1.1.m1.1.1.2">21.32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">21.32\%</annotation></semantics></math> on average (<math id="S4.SS4.p1.2.m2.1" class="ltx_Math" alttext="\sigma=7.06" display="inline"><semantics id="S4.SS4.p1.2.m2.1a"><mrow id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml"><mi id="S4.SS4.p1.2.m2.1.1.2" xref="S4.SS4.p1.2.m2.1.1.2.cmml">σ</mi><mo id="S4.SS4.p1.2.m2.1.1.1" xref="S4.SS4.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS4.p1.2.m2.1.1.3" xref="S4.SS4.p1.2.m2.1.1.3.cmml">7.06</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><apply id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1"><eq id="S4.SS4.p1.2.m2.1.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1.1"></eq><ci id="S4.SS4.p1.2.m2.1.1.2.cmml" xref="S4.SS4.p1.2.m2.1.1.2">𝜎</ci><cn type="float" id="S4.SS4.p1.2.m2.1.1.3.cmml" xref="S4.SS4.p1.2.m2.1.1.3">7.06</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">\sigma=7.06</annotation></semantics></math>) for the five data splits.
It is also notable that CNN-based inference achieves acceptable performance for the last three data splits, indicating that both components have a great contribution to the pipeline.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.4" class="ltx_p"><span id="S4.SS4.p2.4.1" class="ltx_text ltx_font_italic">Generalizability to different languages:</span>
To understand the generalizability, we focus on the <span id="S4.SS4.p2.4.2" class="ltx_ERROR undefined">\kai</span>first two experiment settings.
<span id="S4.SS4.p2.4.3" class="ltx_ERROR undefined">\kai</span>Generalization across Python and R is a hard task.
<span id="S4.SS4.p2.4.4" class="ltx_text ltx_font_smallcaps">Comantics</span> achieves <math id="S4.SS4.p2.1.m1.1" class="ltx_Math" alttext="53.8\%" display="inline"><semantics id="S4.SS4.p2.1.m1.1a"><mrow id="S4.SS4.p2.1.m1.1.1" xref="S4.SS4.p2.1.m1.1.1.cmml"><mn id="S4.SS4.p2.1.m1.1.1.2" xref="S4.SS4.p2.1.m1.1.1.2.cmml">53.8</mn><mo id="S4.SS4.p2.1.m1.1.1.1" xref="S4.SS4.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.1.m1.1b"><apply id="S4.SS4.p2.1.m1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS4.p2.1.m1.1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p2.1.m1.1.1.2.cmml" xref="S4.SS4.p2.1.m1.1.1.2">53.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.1.m1.1c">53.8\%</annotation></semantics></math> and <math id="S4.SS4.p2.2.m2.1" class="ltx_Math" alttext="44.5\%" display="inline"><semantics id="S4.SS4.p2.2.m2.1a"><mrow id="S4.SS4.p2.2.m2.1.1" xref="S4.SS4.p2.2.m2.1.1.cmml"><mn id="S4.SS4.p2.2.m2.1.1.2" xref="S4.SS4.p2.2.m2.1.1.2.cmml">44.5</mn><mo id="S4.SS4.p2.2.m2.1.1.1" xref="S4.SS4.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.2.m2.1b"><apply id="S4.SS4.p2.2.m2.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.SS4.p2.2.m2.1.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p2.2.m2.1.1.2.cmml" xref="S4.SS4.p2.2.m2.1.1.2">44.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.2.m2.1c">44.5\%</annotation></semantics></math> Top-1 accuracy for Python-R and R-Python, respectively,
while the accuracy of CNN-based model is lower, merely <math id="S4.SS4.p2.3.m3.1" class="ltx_Math" alttext="19.1\%" display="inline"><semantics id="S4.SS4.p2.3.m3.1a"><mrow id="S4.SS4.p2.3.m3.1.1" xref="S4.SS4.p2.3.m3.1.1.cmml"><mn id="S4.SS4.p2.3.m3.1.1.2" xref="S4.SS4.p2.3.m3.1.1.2.cmml">19.1</mn><mo id="S4.SS4.p2.3.m3.1.1.1" xref="S4.SS4.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.3.m3.1b"><apply id="S4.SS4.p2.3.m3.1.1.cmml" xref="S4.SS4.p2.3.m3.1.1"><csymbol cd="latexml" id="S4.SS4.p2.3.m3.1.1.1.cmml" xref="S4.SS4.p2.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p2.3.m3.1.1.2.cmml" xref="S4.SS4.p2.3.m3.1.1.2">19.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.3.m3.1c">19.1\%</annotation></semantics></math> and <math id="S4.SS4.p2.4.m4.1" class="ltx_Math" alttext="23.2\%" display="inline"><semantics id="S4.SS4.p2.4.m4.1a"><mrow id="S4.SS4.p2.4.m4.1.1" xref="S4.SS4.p2.4.m4.1.1.cmml"><mn id="S4.SS4.p2.4.m4.1.1.2" xref="S4.SS4.p2.4.m4.1.1.2.cmml">23.2</mn><mo id="S4.SS4.p2.4.m4.1.1.1" xref="S4.SS4.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.4.m4.1b"><apply id="S4.SS4.p2.4.m4.1.1.cmml" xref="S4.SS4.p2.4.m4.1.1"><csymbol cd="latexml" id="S4.SS4.p2.4.m4.1.1.1.cmml" xref="S4.SS4.p2.4.m4.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p2.4.m4.1.1.2.cmml" xref="S4.SS4.p2.4.m4.1.1.2">23.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.4.m4.1c">23.2\%</annotation></semantics></math>, respectively.
We speculate the low accuracy is due to the small number of train samples which are not enough for the model to capture features.
</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p"><span id="S4.SS4.p3.1.1" class="ltx_text ltx_font_italic">Rationality of semantic vector:</span>
By comparing the results of the <span id="S4.SS4.p3.1.2" class="ltx_ERROR undefined">\nth</span>3 and <span id="S4.SS4.p3.1.3" class="ltx_ERROR undefined">\nth</span>4 data splits, we infer that the embedding of function names and parameters is significant in type inference.
Specifically, by incorporating R scripts into the train set, the semantics in R has joined for inference,
which improves the Top-1 accuracy of both CNN-based model and <span id="S4.SS4.p3.1.4" class="ltx_text ltx_font_smallcaps">Comantics</span> by <math id="S4.SS4.p3.1.m1.1" class="ltx_Math" alttext="9.9\%" display="inline"><semantics id="S4.SS4.p3.1.m1.1a"><mrow id="S4.SS4.p3.1.m1.1.1" xref="S4.SS4.p3.1.m1.1.1.cmml"><mn id="S4.SS4.p3.1.m1.1.1.2" xref="S4.SS4.p3.1.m1.1.1.2.cmml">9.9</mn><mo id="S4.SS4.p3.1.m1.1.1.1" xref="S4.SS4.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.1.m1.1b"><apply id="S4.SS4.p3.1.m1.1.1.cmml" xref="S4.SS4.p3.1.m1.1.1"><csymbol cd="latexml" id="S4.SS4.p3.1.m1.1.1.1.cmml" xref="S4.SS4.p3.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p3.1.m1.1.1.2.cmml" xref="S4.SS4.p3.1.m1.1.1.2">9.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.1.m1.1c">9.9\%</annotation></semantics></math>.
This finding inspires us for improving the pipeline design in future research, where we plan to include synonyms for each transformation in model training.</p>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.1" class="ltx_p"><span id="S4.SS4.p4.1.1" class="ltx_text ltx_font_italic">Analysis of Confusion Matrix:</span>
Referring to the normalized confusion matrix (provided in the supplemental material), we observe that
<span id="S4.SS4.p4.1.2" class="ltx_text ltx_font_italic">create_rows_summarize</span> (<span id="S4.SS4.p4.1.3" class="ltx_ERROR undefined">\ie</span>, creating rows by summarizing other rows with aggregate operations such as mean, sum, and max) tends to be predicted as <span id="S4.SS4.p4.1.4" class="ltx_text ltx_font_italic">create_rows_create</span>, which means rows are created manually.
Another case is that some <span id="S4.SS4.p4.1.5" class="ltx_text ltx_font_italic">transform_columns_extract</span> (<span id="S4.SS4.p4.1.6" class="ltx_ERROR undefined">\ie</span>, transforming columns by extracting values from one column) are classified as <span id="S4.SS4.p4.1.7" class="ltx_text ltx_font_italic">transform_columns_mutate</span>.
We infer two reasons for the two cases.
First, characteristics in our design space cannot describe complex relations such as summarization and regular expressions.
Second, the instances of these transformations are few, making it difficult for <span id="S4.SS4.p4.1.8" class="ltx_text ltx_font_smallcaps">Comantics</span> to learn their features.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Potential Improvements</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">Although <span id="S4.SS5.p1.1.1" class="ltx_text ltx_font_smallcaps">Comantics</span> has achieved <math id="S4.SS5.p1.1.m1.1" class="ltx_Math" alttext="92.2\%" display="inline"><semantics id="S4.SS5.p1.1.m1.1a"><mrow id="S4.SS5.p1.1.m1.1.1" xref="S4.SS5.p1.1.m1.1.1.cmml"><mn id="S4.SS5.p1.1.m1.1.1.2" xref="S4.SS5.p1.1.m1.1.1.2.cmml">92.2</mn><mo id="S4.SS5.p1.1.m1.1.1.1" xref="S4.SS5.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.1.m1.1b"><apply id="S4.SS5.p1.1.m1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS5.p1.1.m1.1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS5.p1.1.m1.1.1.2.cmml" xref="S4.SS5.p1.1.m1.1.1.2">92.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.1.m1.1c">92.2\%</annotation></semantics></math> of the Top-1 accuracy when combining R and Python scripts in the train and test sets, the analysis of failure cases informs us of potential improvements in our pipeline.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p">First, the semantics of parameters should be investigated by advanced approaches.
Currently, we use FastText to convert all parameters into one feature vector, which may overlook key semantics.
For example, by analyzing a failure case, <span id="S4.SS5.p2.1.1" class="ltx_text ltx_lstlisting" style="background-color:#CCCCCC;"><span id="S4.SS5.p2.1.1.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">df4</span><span id="S4.SS5.p2.1.1.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="S4.SS5.p2.1.1.3" class="ltx_text ltx_font_typewriter">=<span id="S4.SS5.p2.1.1.3.1" class="ltx_text ltx_lst_space"> </span><span id="S4.SS5.p2.1.1.3.2" class="ltx_text ltx_lst_identifier">filter</span>(<span id="S4.SS5.p2.1.1.3.3" class="ltx_text ltx_lst_identifier">df3</span>,!<span id="S4.SS5.p2.1.1.3.4" class="ltx_text ltx_lst_identifier">is</span>.<span id="S4.SS5.p2.1.1.3.5" class="ltx_text ltx_lst_identifier">na</span>(<span id="S4.SS5.p2.1.1.3.6" class="ltx_text ltx_lst_identifier">ST</span>))</span></span>, it should be classified as <span id="S4.SS5.p2.1.2" class="ltx_text ltx_font_italic">delete_rows_dropna</span>, while <span id="S4.SS5.p2.1.3" class="ltx_text ltx_font_smallcaps">Comantics</span> incorrectly predicted it as <span id="S4.SS5.p2.1.4" class="ltx_text ltx_font_italic">delete_rows_filter</span>.
This case is “difficult” because the two transformations are semantically similar, <span id="S4.SS5.p2.1.5" class="ltx_ERROR undefined">\ie</span>, deleting rows with missing value is a kind of deleting rows using filtering conditions.
By analyzing the code, we note that the parameter <span id="S4.SS5.p2.1.6" class="ltx_text ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">!<span id="S4.SS5.p2.1.6.1" class="ltx_text ltx_lst_identifier">is</span>.<span id="S4.SS5.p2.1.6.2" class="ltx_text ltx_lst_identifier">na</span>(<span id="S4.SS5.p2.1.6.3" class="ltx_text ltx_lst_identifier">ST</span>)</span> is a key factor to distinguish it from <span id="S4.SS5.p2.1.7" class="ltx_text ltx_font_italic">delete_rows_filter</span>.
The failure case indicates that the Type Inference step of <span id="S4.SS5.p2.1.8" class="ltx_text ltx_font_smallcaps">Comantics</span> has not fully revealed the semantics of parameters.
<span id="S4.SS5.p2.1.9" class="ltx_ERROR undefined">\kai</span>We plan to investigate natural language processing techniques such as tokenization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> to address this issue.</p>
</div>
<div id="S4.SS5.p3" class="ltx_para">
<p id="S4.SS5.p3.1" class="ltx_p">Second, characteristics detection can be further augmented.
The characteristic-based inference component is powerful in improving the performance of the pipeline.
However, given a pair of input and output tables, characteristics detected in the current prototype are sometimes ambiguous for type inference (as described in Fig. <a href="#S3.F3" title="Figure 3 ‣ 3.2 Type Inference ‣ 3 The Comantics Pipeline ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).
We observe that the detection of characteristics highly relies on the input data tables.
<span id="S4.SS5.p3.1.1" class="ltx_ERROR undefined">\kai</span>Thus, to resolve ambiguity, we plan to employ well-crafted data tables to verify each transformation candidate. For example, if <span id="S4.SS5.p3.1.2" class="ltx_text ltx_font_italic">delete_rows_deduplicate</span> is one of the candidates, a well-designed input table with duplicate rows would be constructed to check whether <span id="S4.SS5.p3.1.3" class="ltx_text ltx_font_italic">delete_rows_deduplicate</span> stands for the line of code.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Example Applications</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this section, we demonstrate the <span id="S5.p1.1.1" class="ltx_ERROR undefined">\kai</span>flexibility of <span id="S5.p1.1.2" class="ltx_text ltx_font_smallcaps">Comantics</span> through three applications in different domains.
First, we show how <span id="S5.p1.1.3" class="ltx_text ltx_font_smallcaps">Comantics</span> supports semantic annotation for scripts in Jupyter Notebooks.
Second, we integrate <span id="S5.p1.1.4" class="ltx_text ltx_font_smallcaps">Comantics</span> into an existing program visualization system to augment its ability to parse wrangling scripts.
Third, we demonstrate an idea of improving an existing visualization system with additional information obtained from <span id="S5.p1.1.5" class="ltx_text ltx_font_smallcaps">Comantics</span>.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Code Annotation in Jupyter Notebook</h3>

<figure id="S5.F4" class="ltx_figure"><img src="/html/2209.13995/assets/x5.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="341" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>An instance of generating annotations for data wrangling code in Jupyter Notebook. After wrangling code has been written <span id="S5.F4.4.1" class="ltx_ERROR undefined">\kai</span>in two code cells (a, b), the annotations <span id="S5.F4.5.2" class="ltx_ERROR undefined">\kai</span>(d) describing transformation semantics are appended to the original code by clicking the extension button <span id="S5.F4.6.3" class="ltx_ERROR undefined">\kai</span>(c).</figcaption>
</figure>
<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Computational notebooks leverage an interactive literate programming <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> paradigm that combines code, natural language text, and execution results of code cells in a single document.
Nowadays, increasing data workers adopt them for exploratory data analysis and sharing of computational narratives <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>.
However, writing comments for each line of code could be burdensome.
To assist the processing of documenting for data workers, we implement <span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_smallcaps">Comantics</span> as a Jupyter Notebook extension to generate semantic annotations for wrangling code snippets.
Specifically, to obtain intermediate input and output tables, we utilize the Variable Inspector <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> to collect all variables with their types, sizes, and values.
After <span id="S5.SS1.p1.1.2" class="ltx_text ltx_font_smallcaps">Comantics</span> infers the transformation type and its parameters of a line of wrangling code, the extension employs a template-based approach to generate a natural language sentence describing the semantics.
And the sentence will be appended above to the original code as a comment.
As presented in Fig. <a href="#S5.F4" title="Figure 4 ‣ 5.1 Code Annotation in Jupyter Notebook ‣ 5 Example Applications ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>(a) and (b), there are five lines of wrangling code in the script, which are distributed in two different code cells.
After clicking the extension button (Fig. <a href="#S5.F4" title="Figure 4 ‣ 5.1 Code Annotation in Jupyter Notebook ‣ 5 Example Applications ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>(c)), comments will be automatically inserted above each line of code (Fig. <a href="#S5.F4" title="Figure 4 ‣ 5.1 Code Annotation in Jupyter Notebook ‣ 5 Example Applications ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>(d)).
As code annotation is a hot topic in the domain of software engineering <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, <span id="S5.SS1.p1.1.3" class="ltx_text ltx_font_smallcaps">Comantics</span> shows potential for code annotation in data wrangling.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span><span id="S5.SS2.1.1" class="ltx_text ltx_font_smallcaps">Somnus</span> Re-visited</h3>

<figure id="S5.F5" class="ltx_figure"><img src="/html/2209.13995/assets/x6.png" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="86" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Three examples that <span id="S5.F5.6.1" class="ltx_text ltx_font_smallcaps">Somnus</span> can support with the help of <span id="S5.F5.7.2" class="ltx_text ltx_font_smallcaps">Comantics</span>. Before integrating <span id="S5.F5.8.3" class="ltx_text ltx_font_smallcaps">Comantics</span>, <span id="S5.F5.9.4" class="ltx_text ltx_font_smallcaps">Somnus</span> does not support (a) the <span id="S5.F5.10.5" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">extract</span> function, (b) non-assignment statements, and (c) non-functional assignments.</figcaption>
</figure>
<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p"><span id="S5.SS2.p1.1.1" class="ltx_text ltx_font_smallcaps">Comantics</span> can also be used to expand the capacity of existing visualization systems that reveal the semantics of transformations.
For example, <span id="S5.SS2.p1.1.2" class="ltx_text ltx_font_smallcaps">Somnus</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> is a program visualization system that generates a provenance graph to visualize a script of data wrangling.
However, it relies on hand-crafted rules to parse code and infer transformation types.
Hence, the backend of the system is limited in scalability.
To augment <span id="S5.SS2.p1.1.3" class="ltx_text ltx_font_smallcaps">Somnus</span>, <span id="S5.SS2.p1.1.4" class="ltx_text ltx_font_smallcaps">Comantics</span> replaces its Program Adaptor module that parses code and infers the type of transformation.
As a result, <span id="S5.SS2.p1.1.5" class="ltx_text ltx_font_smallcaps">Somnus</span> supports a larger number of functions, and more types of statements (e.g., non-functional assignments and non-assignment statements).
Fig. <a href="#S5.F5" title="Figure 5 ‣ 5.2 Somnus Re-visited ‣ 5 Example Applications ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows three examples that <span id="S5.SS2.p1.1.6" class="ltx_text ltx_font_smallcaps">Somnus</span> can support with the help of <span id="S5.SS2.p1.1.7" class="ltx_text ltx_font_smallcaps">Comantics</span>.
In Fig. <a href="#S5.F5" title="Figure 5 ‣ 5.2 Somnus Re-visited ‣ 5 Example Applications ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>(a), the <span id="S5.SS2.p1.1.8" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">extract</span> function was not supported in <span id="S5.SS2.p1.1.9" class="ltx_text ltx_font_smallcaps">Somnus</span>, and establishing rules for new functions is time-consuming.
Fig. <a href="#S5.F5" title="Figure 5 ‣ 5.2 Somnus Re-visited ‣ 5 Example Applications ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>(b) shows that the non-assignment statement was not supported because the input and output table is not explicitly presented.
Fig. <a href="#S5.F5" title="Figure 5 ‣ 5.2 Somnus Re-visited ‣ 5 Example Applications ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>(c) depicts a non-functional assignment that can be hardly mapped to manually-crafted rules.
<span id="S5.SS2.p1.1.10" class="ltx_ERROR undefined">\kai</span>Our corpus (see Sec. <a href="#S2.SS1" title="2.1 Methodology ‣ 2 A Design Space for Table Changes ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>) shows that 507 out of 921 (<math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="55.05\%" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><mrow id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mn id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml">55.05</mn><mo id="S5.SS2.p1.1.m1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">55.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">55.05\%</annotation></semantics></math>) instances match the above three scenarios.
By incorporating <span id="S5.SS2.p1.1.11" class="ltx_text ltx_font_smallcaps">Comantics</span>, <span id="S5.SS2.p1.1.12" class="ltx_text ltx_font_smallcaps">Somnus</span> extends its ability to deal with a wider range of functions and statements.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>TACO Re-visited</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">TACO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> is a visual analytics system that facilitates table comparison.
It presented four types of changes between two tables including 1) <span id="S5.SS3.p1.1.1" class="ltx_text ltx_font_italic">structural changes</span> where rows or columns are added or removed, 2) <span id="S5.SS3.p1.1.2" class="ltx_text ltx_font_italic">content changes</span> where the values of cells are modified, 3) <span id="S5.SS3.p1.1.3" class="ltx_text ltx_font_italic">reorder changes</span> where rows or columns are shifted to other positions, and 4) <span id="S5.SS3.p1.1.4" class="ltx_text ltx_font_italic">merge/split changes</span> where multiple rows or columns are combined into a single one or vice versa.
Though similar, our design space is the superset.
That is, our space includes characteristics that are not supported in TACO, such as inclusion relationships between columns/rows (e.g., characteristics 50—53), ordering states (e.g., characteristics 42—44), and data types (e.g., characteristics 102 and 103).
Therefore, <span id="S5.SS3.p1.1.5" class="ltx_text ltx_font_smallcaps">Comantics</span> can assist TACO to reveal more characteristics of table changes.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">We express this idea using a simplified but extended version of TACO.
In this version, we use additional visual channels to represent two relationships, <span id="S5.SS3.p2.1.1" class="ltx_ERROR undefined">\ie</span>, green markers on the left side encode duplicate rows, and brown markers on top of the heatmap to display the superset relations between two columns.
Fig. <a href="#S5.F6" title="Figure 6 ‣ 5.3 TACO Re-visited ‣ 5 Example Applications ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows an example.
Based on the original visual encodings, we observe two red rows, which indicate that they are deleted.
However, it is not clear why they are removed.
With the help of <span id="S5.SS3.p2.1.2" class="ltx_text ltx_font_smallcaps">Comantics</span>, we can infer the reason with relation information between columns and rows.
For example, we can observe that there are three green markers on the left side, meaning that there are identical rows in the input table.
Combining with the two red rows, we may infer that a <span id="S5.SS3.p2.1.3" class="ltx_text ltx_font_italic">deduplicate</span> transformation is performed to remove the two rows.
Besides, two brown markers appear on the top side, which indicates the <span id="S5.SS3.p2.1.4" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">id</span> between input and output tables have superset relation.
A descending symbol is placed close to <span id="S5.SS3.p2.1.5" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">total</span>, which indicates that the <span id="S5.SS3.p2.1.6" class="ltx_text ltx_lst_identifier ltx_lstlisting ltx_font_typewriter" style="background-color:#CCCCCC;">total</span> column is sorted in descending order.
By extending TACO, we can observe detailed relations between two tables.
An exciting research direction is exploring visual encodings or novel designs to reveal richer characteristics of table changes effectively and intuitively.</p>
</div>
<figure id="S5.F6" class="ltx_figure"><img src="/html/2209.13995/assets/x7.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="296" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>A diff heatmap visualization of table differences generated by a modified version of TACO based on the characteristics of table changes detected from <span id="S5.F6.2.1" class="ltx_text ltx_font_smallcaps">Comantics</span>. The visual encodings enclosed by the dashed box in the legend are from TACO.</figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this section, we first discuss the limitations of our pipeline and the experiments. Then we present potential usage for future exploration.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Limitations</h3>

<div id="S6.SS1.p1" class="ltx_para">
<span id="S6.SS1.p1.1" class="ltx_ERROR undefined">\kai</span>
<p id="S6.SS1.p1.2" class="ltx_p"><span id="S6.SS1.p1.2.1" class="ltx_text ltx_font_bold">Evaluation.</span> The evaluation of <span id="S6.SS1.p1.2.2" class="ltx_text ltx_font_smallcaps">Comantics</span> is limited in three aspects.
To begin with, the quantitative experiments show that our pipeline could infer the transformation type with high Top-N accuracy. However, we did not assess the quality of the inferred parameters, which are critical in understanding semantics as well.
In addition, we have not tried models other than the Siamese Convolutional Neural Network in Model-Based Inference.
Lastly, the design space of table changes has not been explicitly evaluated in terms of descriptive, evaluative, and generative power.
In future research, we plan to design comprehensive experiments to assess the quality of <span id="S6.SS1.p1.2.3" class="ltx_text ltx_font_smallcaps">Comantics</span> and the design space, and investigate how <span id="S6.SS1.p1.2.4" class="ltx_text ltx_font_smallcaps">Comantics</span> performs with different multi-class classification models.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<span id="S6.SS1.p2.3" class="ltx_ERROR undefined">\kai</span>
<p id="S6.SS1.p2.2" class="ltx_p"><span id="S6.SS1.p2.2.1" class="ltx_text ltx_font_bold">Generalizability.</span>
Generalization across <span id="S6.SS1.p2.2.2" class="ltx_ERROR undefined">\kai</span>Python and R is difficult, and the current prototype only achieves
<span id="S6.SS1.p2.2.3" class="ltx_ERROR undefined">\kai</span><math id="S6.SS1.p2.1.m1.1" class="ltx_Math" alttext="53.8\%" display="inline"><semantics id="S6.SS1.p2.1.m1.1a"><mrow id="S6.SS1.p2.1.m1.1.1" xref="S6.SS1.p2.1.m1.1.1.cmml"><mn id="S6.SS1.p2.1.m1.1.1.2" xref="S6.SS1.p2.1.m1.1.1.2.cmml">53.8</mn><mo id="S6.SS1.p2.1.m1.1.1.1" xref="S6.SS1.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.1.m1.1b"><apply id="S6.SS1.p2.1.m1.1.1.cmml" xref="S6.SS1.p2.1.m1.1.1"><csymbol cd="latexml" id="S6.SS1.p2.1.m1.1.1.1.cmml" xref="S6.SS1.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="S6.SS1.p2.1.m1.1.1.2.cmml" xref="S6.SS1.p2.1.m1.1.1.2">53.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.1.m1.1c">53.8\%</annotation></semantics></math> accuracy for Python/training and R/test, and <math id="S6.SS1.p2.2.m2.1" class="ltx_Math" alttext="44.5\%" display="inline"><semantics id="S6.SS1.p2.2.m2.1a"><mrow id="S6.SS1.p2.2.m2.1.1" xref="S6.SS1.p2.2.m2.1.1.cmml"><mn id="S6.SS1.p2.2.m2.1.1.2" xref="S6.SS1.p2.2.m2.1.1.2.cmml">44.5</mn><mo id="S6.SS1.p2.2.m2.1.1.1" xref="S6.SS1.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.2.m2.1b"><apply id="S6.SS1.p2.2.m2.1.1.cmml" xref="S6.SS1.p2.2.m2.1.1"><csymbol cd="latexml" id="S6.SS1.p2.2.m2.1.1.1.cmml" xref="S6.SS1.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S6.SS1.p2.2.m2.1.1.2.cmml" xref="S6.SS1.p2.2.m2.1.1.2">44.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.2.m2.1c">44.5\%</annotation></semantics></math> for R/training and Python/test.
When performing the same transformation, function names and parameters in different languages may vary while characteristics between tables are the same.
We anticipate that the key factor to improve the generalizability is to align the semantics of function names and parameters among different languages.
In addition, a large number of training and test samples are also critical for models to parse the semantics.
</p>
</div>
<div id="S6.SS1.p3" class="ltx_para">
<span id="S6.SS1.p3.2" class="ltx_ERROR undefined">\kai</span>
<p id="S6.SS1.p3.1" class="ltx_p"><span id="S6.SS1.p3.1.1" class="ltx_text ltx_font_bold">Scalability.</span>
Compared to prior work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>, <span id="S6.SS1.p3.1.2" class="ltx_text ltx_font_smallcaps">Comantics</span> scales well in terms of the number of functions and parameters.
However, our pipeline does not scale well in the number of transformation types.
The mapping between transformation types and characteristics (described in Sec. <a href="#S2.SS3" title="2.3 Inferring Transformations With Characteristics ‣ 2 A Design Space for Table Changes ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>) and rules for parameter inference (see Sec. <a href="#S3.SS3" title="3.3 Parameter Inference ‣ 3 The Comantics Pipeline ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>) are crafted manually for each transformation.
Our pipeline currently supports <math id="S6.SS1.p3.1.m1.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S6.SS1.p3.1.m1.1a"><mn id="S6.SS1.p3.1.m1.1.1" xref="S6.SS1.p3.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.1.m1.1b"><cn type="integer" id="S6.SS1.p3.1.m1.1.1.cmml" xref="S6.SS1.p3.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.1.m1.1c">30</annotation></semantics></math> types of transformations that are derived from the collected dataset.
However, the transformation space has <span id="S6.SS1.p3.1.3" class="ltx_ERROR undefined">\kai</span>not yet been fully explored.
Crafting rules for the entire space could be tedious and error-prone.
In future iterations, we plan to investigate automatic approaches to build rules for the pipeline.</p>
</div>
<div id="S6.SS1.p4" class="ltx_para">
<span id="S6.SS1.p4.1" class="ltx_ERROR undefined">\kai</span>
<p id="S6.SS1.p4.2" class="ltx_p"><span id="S6.SS1.p4.2.1" class="ltx_text ltx_font_bold">Capability.</span> The limitations of <span id="S6.SS1.p4.2.2" class="ltx_text ltx_font_smallcaps">Comantics</span> in capability are three-fold.
First, <span id="S6.SS1.p4.2.3" class="ltx_text ltx_font_smallcaps">Comantics</span> infers one transformation with its parameters for a line of wrangling code.
It is unable to reveal the semantics of a line of code containing multiple transformations.
<span id="S6.SS1.p4.2.4" class="ltx_ERROR undefined">\kai</span>Second, it is not applicable to scripts with some imperative programming constructs, such as conditional statements and loops, which are commonly used in data wrangling.
Third, it does not support function chaining due to the difficulty of obtaining intermediate data tables.
Temporarily, this issue could be addressed by automatically converting the chained functions into individual lines.
The three capability issues are critical to production usage, and we plan to address them in our future work.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Opportunities for New Usage</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">With the ability to infer the semantics of wrangling scripts, <span id="S6.SS2.p1.1.1" class="ltx_text ltx_font_smallcaps">Comantics</span> can introduce opportunities for practical applications in various domains.
<span id="S6.SS2.p1.1.2" class="ltx_ERROR undefined">\kai</span>Apart from the three example applications described in Sec. <a href="#S5" title="5 Example Applications ‣ Revealing the Semantics of Data Wrangling Scripts With Comantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we anticipate that our work can be integrated into productivity spreadsheet software and interactive data wrangling systems, including Microsoft Excel <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> and OpenRefine <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, to automatically record the history of table operation.
This is helpful for documenting and sharing the transformation process and the table changes, and the history can be presented to augment the “undo” operation and used for auditing transformations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.
In such a scenario, wrangling code is not explicitly generated.
To adapt to these systems, feature engineering for function names and parameters should be transformed to the understanding of operation history in the interface.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p">Another possible usage of <span id="S6.SS2.p2.1.1" class="ltx_text ltx_font_smallcaps">Comantics</span> is to support a source-to-source compiler that converts code from one programming language to another <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>.
Numerous source-to-source compilers have been proposed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>, which usually require large amounts of samples for training and testing.
These techniques, however, can hardly support code translation in the domain of data wrangling for two reasons.
First, samples for data wrangling are usually not well-documented, and manual annotation is laborious and time-consuming.
Hence, learning-based approaches may result in poor performance without enough training samples.
Second, subtle differences in the wrangling code may lead to different transformations.
Learning the mapping among numerous functions and parameters across different languages is infeasible.
<span id="S6.SS2.p2.1.2" class="ltx_text ltx_font_smallcaps">Comantics</span> narrows the gulf by aligning wrangling code with semantics.
To be specific, we first infer the semantics for individual wrangling functions and their parameters using <span id="S6.SS2.p2.1.3" class="ltx_text ltx_font_smallcaps">Comantics</span>.
Then, we establish bi-directional mappings between functions/parameters and semantics for different programming languages.
Finally, the semantics act as bonds connecting functions in two languages.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion and Future Work</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this paper, we have presented <span id="S7.p1.1.1" class="ltx_text ltx_font_smallcaps">Comantics</span>, a three-step pipeline that infers semantics for wrangling scripts.
<span id="S7.p1.1.2" class="ltx_text ltx_font_smallcaps">Comantics</span> takes a piece of wrangling script and data tables as input, and outputs the semantics of each line of code consisting of the type of transformation and its parameters.
Based on the observation that differences between input and output tables highly relate to the transformation type.
We summarize a design space presenting characteristics of table changes, which further guides the design of <span id="S7.p1.1.3" class="ltx_text ltx_font_smallcaps">Comantics</span>.
Experiments suggest that <span id="S7.p1.1.4" class="ltx_text ltx_font_smallcaps">Comantics</span> performs well in type inference.
Further, three applications in different domains indicate that <span id="S7.p1.1.5" class="ltx_text ltx_font_smallcaps">Comantics</span> has good <span id="S7.p1.1.6" class="ltx_ERROR undefined">\kai</span>flexibility.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">In the future, we plan to explore four promising research directions.
First, we plan to improve the performance of <span id="S7.p2.1.1" class="ltx_text ltx_font_smallcaps">Comantics</span> by refining the Data Preprocessing step and Type Inference module.
Second, we want to enhance its capability to meet the need for production usage.
Third, we would like to incorporate <span id="S7.p2.1.2" class="ltx_text ltx_font_smallcaps">Comantics</span> in a broad range of applications, including spreadsheet software, data wrangling tool, and source-to-source compiler in the domain of data wrangling.
Fourth, we plan to further evaluate <span id="S7.p2.1.3" class="ltx_text ltx_font_smallcaps">Comantics</span> with <span id="S7.p2.1.4" class="ltx_ERROR undefined">\kai</span>comprehensive experiments.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
The work was supported by NSFC (62072400, 62002331) and the Collaborative Innovation Center of Artificial Intelligence by MOE and Zhejiang Provincial Government (ZJU). This work was also partially funded by the Zhejiang Lab (2021KE0AC02).


</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
AQT - Advanced query tool - database query tool for DB2, Oracle, Sybase, SQL
Server, MySQL.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://querytool.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://querytool.com/</a>.

</span>
<span class="ltx_bibblock">Accessed: Feb 12, 2022.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
daff - data diffs in javascript, ruby, python, php, …

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://paulfitz.github.io/daff/" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://paulfitz.github.io/daff/</a>.

</span>
<span class="ltx_bibblock">Accessed: Feb 12, 2022.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
DiffKit.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://www.diffkit.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.diffkit.org/</a>.

</span>
<span class="ltx_bibblock">Accessed: Feb 12, 2022.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
ExcelCompare.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/na-ka-na/ExcelCompare/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/na-ka-na/ExcelCompare/</a>.

</span>
<span class="ltx_bibblock">Accessed: Feb 12, 2022.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Ridom SeqSphere+.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.ridom.de/u/Comparison_Table.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.ridom.de/u/Comparison_Table.html</a>.

</span>
<span class="ltx_bibblock">Accessed: Feb 12, 2022.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Variable Inspector.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/varInspector" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/varInspector</a>.

</span>
<span class="ltx_bibblock">Accessed: Feb 20, 2022.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Z. Abedjan, J. Morcos, I. F. Ilyas, M. Ouzzani, P. Papotti, and M. Stonebraker.

</span>
<span class="ltx_bibblock">DataXFormer: A robust transformation discovery system.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Proceedings of IEEE International Conference on Data
Engineering</span>, pp. 1134–1145, 2016.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
A. Aditya and B. Akshit.

</span>
<span class="ltx_bibblock">Siamese Network Tensorflow.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/ardiya/siamesenetwork-tensorflow" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/ardiya/siamesenetwork-tensorflow</a>, 2019.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
L. Bartram, M. Correll, and M. Tory.

</span>
<span class="ltx_bibblock">Untidy Data: The unreasonable effectiveness of tables.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>,
28(01):686–696, 2022.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
A. Bigelow, C. Nobre, M. Meyer, and A. Lex.

</span>
<span class="ltx_bibblock">Origraph: Interactive network wrangling.

</span>
<span class="ltx_bibblock">In <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Proceedings of IEEE Conference on Visual Analytics Science
and Technology</span>, pp. 81–92, 2019.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov.

</span>
<span class="ltx_bibblock">Enriching word vectors with subword information, 2017.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
R. Chen, D. Weng, Y. Huang, X. Shu, J. Zhou, G. Sun, and Y. Wu.

</span>
<span class="ltx_bibblock">Rigel: Transforming tabular data by declarative mapping.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>, 2022.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
T. Dasu and T. Johnson.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">Exploratory data mining and data cleaning</span>, vol. 479.

</span>
<span class="ltx_bibblock">John Wiley &amp; Sons, 2003.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
L. E. R. Domingues, J. R. Ponciano, L. G. Nonato, and J. Poco.

</span>
<span class="ltx_bibblock">LegalVis: Exploring and inferring precedent citations in legal
documents.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>, 2022.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
I. Drosos, T. Barik, P. J. Guo, R. DeLine, and S. Gulwani.

</span>
<span class="ltx_bibblock">Wrex: A unified programming-by-example interaction for synthesizing
readable code for data scientists.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM Conference on Human Factors in
Computing Systems (CHI)</span>, pp. 1–12, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Y. Feng, R. Martins, J. Van Geffen, I. Dillig, and S. Chaudhuri.

</span>
<span class="ltx_bibblock">Component-based synthesis of table consolidation and transformation
tasks from examples.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">ACM SIGPLAN Notices</span>, 52(6):422–436, 2017.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
P. J. Guo, S. Kandel, J. M. Hellerstein, and J. Heer.

</span>
<span class="ltx_bibblock">Proactive wrangling: Mixed-initiative end-user programming of data
transformation scripts.

</span>
<span class="ltx_bibblock">In <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM Symposium on User Interface Software
and Technology</span>, pp. 65–74, 2011.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
R. Hadsell, S. Chopra, and Y. LeCun.

</span>
<span class="ltx_bibblock">Dimensionality reduction by learning an invariant mapping.

</span>
<span class="ltx_bibblock">In <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Proceedings of IEEE Computer Society Conference on Computer
Vision and Pattern Recognition</span>, pp. 1735–1742, 2006.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Y. He, K. Ganjam, K. Lee, Y. Wang, V. Narasayya, S. Chaudhuri, X. Chu, and
Y. Zheng.

</span>
<span class="ltx_bibblock">Transform-data-by-example (TDE) extensible data transformation in
excel.

</span>
<span class="ltx_bibblock">In <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM SIGMOD International Conference on
Management of Data</span>, pp. 1785–1788, 2018.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
J. Heer and A. Perer.

</span>
<span class="ltx_bibblock">Orion: A system for modeling, transformation and visualization of
multidimensional heterogeneous networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Information Visualization</span>, 13(2):111–133, 2014.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
X. Hu, G. Li, X. Xia, D. Lo, and Z. Jin.

</span>
<span class="ltx_bibblock">Deep code comment generation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Proceedings of IEEE/ACM International Conference on Program
Comprehension</span>, pp. 200–210, 2018.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Y. T. Hu, M. Burch, and H. v. d. Wetering.

</span>
<span class="ltx_bibblock">Visualizing dynamic data with heat triangles.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">Journal of Visualization</span>, 25(1):15–29, 2022.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
D. Huynh.

</span>
<span class="ltx_bibblock">OpenRefine.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openrefine.org" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openrefine.org</a>.

</span>
<span class="ltx_bibblock">Accessed: Jan 29, 2022.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
J. P. Inala and R. Singh.

</span>
<span class="ltx_bibblock">WebRelate: integrating web data with spreadsheets using examples.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM on Programming Languages</span>, 2(POPL):1–28,
2017.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
D. Integration.

</span>
<span class="ltx_bibblock">Compare: A powerful data comparison tool.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://dispatchintegration.com/data-integration-software/compare/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://dispatchintegration.com/data-integration-software/compare/</a>.

</span>
<span class="ltx_bibblock">Accessed: Feb 12, 2022.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Z. Jin, M. R. Anderson, M. Cafarella, and H. Jagadish.

</span>
<span class="ltx_bibblock">Foofah: Transforming data by example.

</span>
<span class="ltx_bibblock">In <span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM SIGMOD International Conference on
Management of Data</span>, pp. 683–698, 2017.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
K. Kagkelidis, I. Dimitriadis, and A. Vakali.

</span>
<span class="ltx_bibblock">Lumina: an adaptive, automated and extensible prototype for
exploring, enriching and visualizing data.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">Journal of Visualization</span>, 24(3):631–655, 2021.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
S. Kandel, J. Heer, C. Plaisant, J. Kennedy, F. Van Ham, N. H. Riche,
C. Weaver, B. Lee, D. Brodbeck, and P. Buono.

</span>
<span class="ltx_bibblock">Research directions in data wrangling: Visualizations and
transformations for usable and credible data.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Information Visualization</span>, 10(4):271–288, 2011.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
S. Kandel, A. Paepcke, J. Hellerstein, and J. Heer.

</span>
<span class="ltx_bibblock">Wrangler: Interactive visual specification of data transformation
scripts.

</span>
<span class="ltx_bibblock">In <span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM Conference on Human Factors in
Computing Systems (CHI)</span>, pp. 3363–3372, 2011.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
S. Kasica, C. Berret, and T. Munzner.

</span>
<span class="ltx_bibblock">Table Scraps: An actionable framework for multi-table data
wrangling from an artifact study of computational journalism.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>,
27(2):957–966, 2021.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
M. Khan, L. Xu, A. Nandi, and J. M. Hellerstein.

</span>
<span class="ltx_bibblock">Data tweening: incremental visualization of data transforms.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">Proceedings of the VLDB Endowment</span>, 10(6):661–672, 2017.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
D. E. Knuth.

</span>
<span class="ltx_bibblock">Literate programming.

</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">The Computer Journal</span>, 27(2):97–111, 1984.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
G. Koch, R. Zemel, and R. Salakhutdinov.

</span>
<span class="ltx_bibblock">Siamese neural networks for one-shot image recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">Proceedings of International Conference on Machine Learning</span>,
2015.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
S. Krishnan, M. J. Franklin, K. Goldberg, and E. Wu.

</span>
<span class="ltx_bibblock">BoostClean: Automated error detection and repair for machine
learning, 2017.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
S. Lau, S. S. Srinivasa Ragavan, K. Milne, T. Barik, and A. Sarkar.

</span>
<span class="ltx_bibblock">TweakIt: Supporting end-user programmers who transmogrify code.

</span>
<span class="ltx_bibblock">In <span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM Conference on Human Factors in
Computing Systems (CHI)</span>, pp. 1–12, 2021.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
C. Lewis and G. M. Olson.

</span>
<span class="ltx_bibblock">Can principles of cognition lower the barriers to programming?

</span>
<span class="ltx_bibblock">In <span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">Proceedings of Empirical studies of programmers: second
workshop</span>, pp. 248–263, 1987.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
B. Li, M. Yan, X. Xia, X. Hu, G. Li, and D. Lo.

</span>
<span class="ltx_bibblock">DeepCommenter: A deep code comment generation tool with hybrid
lexical and syntactical information.

</span>
<span class="ltx_bibblock">In <span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM Joint Meeting on European Software
Engineering Conference and Symposium on the Foundations of Software
Engineering</span>, pp. 1571–1575, 2020.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
G. Li, R. Li, Z. Wang, H. C. Liu, M. Lu, and G. Wang.

</span>
<span class="ltx_bibblock">HiTailor: Interactive transformation and visualization for
hierarchical tabular data.

</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>, 2022.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
J. Lin, J. Wong, J. Nichols, A. Cypher, and T. A. Lau.

</span>
<span class="ltx_bibblock">End-user programming of mashups with vegemite.

</span>
<span class="ltx_bibblock">In <span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">Proceedings of the International Conference on Intelligent
User Interfaces</span>, pp. 97–106, 2009.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
J. Liu, N. Boukhelifa, and J. R. Eagan.

</span>
<span class="ltx_bibblock">Understanding the role of alternatives in data analysis practices.

</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>,
26(1):66–76, 2020.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
S. Liu, D. Peng, H. Zhu, X. Wen, X. Zhang, Z. Zhou, and M. Zhu.

</span>
<span class="ltx_bibblock">MulUBA: multi-level visual analytics of user behaviors for
improving online shopping advertising.

</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">Journal of Visualization</span>, 24(6):1287–1301, 2021.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Z. Liu, S. B. Navathe, and J. T. Stasko.

</span>
<span class="ltx_bibblock">Network-based visual analysis of tabular data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">Proceedings of IEEE Conference on Visual Analytics Science
and Technology</span>, pp. 41–50, 2011.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Y. Luo, N. Tang, G. Li, J. Tang, C. Chai, and X. Qin.

</span>
<span class="ltx_bibblock">Natural language to visualization by neural machine translation.

</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>,
28(1):217–226, 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
H. Mei, H. Guan, C. Xin, X. Wen, and W. Chen.

</span>
<span class="ltx_bibblock">DataV: Data Visualization on large high-resolution displays.

</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">Visual Informatics</span>, 4(3):12–23, 2020.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Microsoft.

</span>
<span class="ltx_bibblock">Microsoft Excel.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://office.microsoft.com/en-us/excel" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://office.microsoft.com/en-us/excel</a>.

</span>
<span class="ltx_bibblock">Accessed: Feb 12, 2022.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
J. Morcos, Z. Abedjan, I. F. Ilyas, M. Ouzzani, P. Papotti, and M. Stonebraker.

</span>
<span class="ltx_bibblock">DataXFormer: An interactive data transformation tool.

</span>
<span class="ltx_bibblock">In <span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM SIGMOD International Conference on
Management of Data</span>, pp. 883–888, 2015.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
C. Niederer, H. Stitz, R. Hourieh, F. Grassinger, W. Aigner, and M. Streit.

</span>
<span class="ltx_bibblock">TACO: visualizing changes in tables over time.

</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>,
24(1):677–686, 2018.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
J. F. Pane.

</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">A programming system for children that is designed for
usability</span>.

</span>
<span class="ltx_bibblock">Carnegie Mellon University, 2002.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
F. Perez and B. E. Granger.

</span>
<span class="ltx_bibblock">Project Jupyter: Computational narratives as the engine of
collaborative data science.

</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">Retrieved September</span>, 11(207):108, 2015.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
X. Pu, S. Kross, J. M. Hofman, and D. G. Goldstein.

</span>
<span class="ltx_bibblock">Datamations: Animated explanations of data analysis pipelines.

</span>
<span class="ltx_bibblock">In <span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM Conference on Human Factors in
Computing Systems (CHI)</span>, pp. 1–14, 2021.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Y. Qian and J. Lehman.

</span>
<span class="ltx_bibblock">Students’ misconceptions and other difficulties in introductory
programming: A literature review.

</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">ACM Transactions on Computing Education</span>, 18(1):1–24, 2017.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
T. Rattenbury, J. M. Hellerstein, J. Heer, S. Kandel, and C. Carreras.

</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">Principles of data wrangling: Practical techniques for data
preparation</span>.

</span>
<span class="ltx_bibblock">” O’Reilly Media, Inc.”, 2017.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
J. Reback, jbrockmendel, W. McKinney, J. V. den Bossche, T. Augspurger,
P. Cloud, S. Hawkins, M. Roeschke, gfyoung, Sinhrks, A. Klein, P. Hoefler,
T. Petersen, J. Tratner, C. She, W. Ayd, S. Naveh, M. Garcia, J. Darbyshire,
J. Schendel, R. Shadrach, A. Hayden, D. Saxton, M. E. Gorelli, F. Li,
M. Zeitlin, V. Jancauskas, A. McMaster, P. Battiston, and S. Seabold.

</span>
<span class="ltx_bibblock">pandas-dev/pandas: Pandas 1.4.0, Jan 2022.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
B. Roziere, M.-A. Lachaux, L. Chanussot, and G. Lample.

</span>
<span class="ltx_bibblock">Unsupervised translation of programming languages.

</span>
<span class="ltx_bibblock">In <span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, pp.
20601–20611, 2020.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
V. Shankar, R. Roelofs, H. Mania, A. Fang, B. Recht, and L. Schmidt.

</span>
<span class="ltx_bibblock">Evaluating machine accuracy on ImageNet.

</span>
<span class="ltx_bibblock">In <span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">Proceedings of International Conference on Machine Learning</span>,
pp. 8634–8644, 2020.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
H. Shi.

</span>
<span class="ltx_bibblock">A Sequence-to-sequence Approach for Numerical Slot-filling Dialog
Systems.

</span>
<span class="ltx_bibblock">In <span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">Proceedings of the Annual Meeting of the Special Interest
Group on Discourse and Dialogue</span>, pp. 272–277, 2020.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
N. Shrestha, T. Barik, and C. Parnin.

</span>
<span class="ltx_bibblock">Unravel: A fluent code explorer for data wrangling.

</span>
<span class="ltx_bibblock">In <span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM Symposium on User Interface Software
and Technology</span>, pp. 198–207, 2021.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
T. Software.

</span>
<span class="ltx_bibblock">Tableau prep builder.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.tableau.com/products/prep" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.tableau.com/products/prep</a>.

</span>
<span class="ltx_bibblock">Accessed: Jan 29, 2022.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
T. S. Solutions.

</span>
<span class="ltx_bibblock">The Most Accurate and Reliable Source Code Converters.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.tangiblesoftwaresolutions.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.tangiblesoftwaresolutions.com/</a>.

</span>
<span class="ltx_bibblock">Accessed: Feb 12, 2022.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
J. Sorva, V. Karavirta, and L. Malmi.

</span>
<span class="ltx_bibblock">A review of generic program visualization systems for introductory
programming education.

</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">ACM Transactions on Computing Education</span>, 13(4):1–64, 2013.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
C. Sutton, T. Hobson, J. Geddes, and R. Caruana.

</span>
<span class="ltx_bibblock">Data diff: Interpretable, executable summaries of changes in
distributions for data wrangling.

</span>
<span class="ltx_bibblock">In <span id="bib.bib61.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM SIGKDD International Conference on
Knowledge Discovery &amp; Data Mining</span>, pp. 2279–2288, 2018.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
C. Tominski, G. Andrienko, N. Andrienko, S. Bleisch, S. I. Fabrikant, E. Mayr,
S. Miksch, M. Pohl, and A. Skupin.

</span>
<span class="ltx_bibblock">Toward flexible visual analytics augmented through smooth display
transitions.

</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text ltx_font_italic">Visual Informatics</span>, 5(3):28–38, 2021.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
transpiler.

</span>
<span class="ltx_bibblock">Universal-transpiler.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://jarble.github.io/transpiler/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://jarble.github.io/transpiler/</a>.

</span>
<span class="ltx_bibblock">Accessed: Feb 12, 2022.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Trifacta.

</span>
<span class="ltx_bibblock">Data Wrangling Software and Tools - Trifacta.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.trifacta.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.trifacta.com/</a>.

</span>
<span class="ltx_bibblock">Accessed: Jan 29, 2022.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Y. Wang, M. Yu, G. Shan, H.-W. Shen, and Z. Lu.

</span>
<span class="ltx_bibblock">VISPubComPAS: a comparative analytical system for visualization
publication data.

</span>
<span class="ltx_bibblock"><span id="bib.bib65.1.1" class="ltx_text ltx_font_italic">Journal of Visualization</span>, 22(5):941–953, 2019.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
H. Wickham.

</span>
<span class="ltx_bibblock"><span id="bib.bib66.1.1" class="ltx_text ltx_font_italic">tidyr: Tidy Messy Data</span>, 2020.

</span>
<span class="ltx_bibblock">R package version 1.1.2.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
H. Wickham, M. Averick, J. Bryan, W. Chang, L. McGowan, R. François,
G. Grolemund, A. Hayes, L. Henry, J. Hester, M. Kuhn, T. Pedersen, E. Miller,
S. Bache, K. Müller, J. Ooms, D. Robinson, D. Seidel, V. Spinu,
K. Takahashi, D. Vaughan, C. Wilke, K. Woo, and H. Yutani.

</span>
<span class="ltx_bibblock">Welcome to the tidyverse.

</span>
<span class="ltx_bibblock"><span id="bib.bib67.1.1" class="ltx_text ltx_font_italic">Journal of Open Source Software</span>, 4(43):1686, 2019.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
H. Wickham, R. François, L. Henry, and K. Müller.

</span>
<span class="ltx_bibblock"><span id="bib.bib68.1.1" class="ltx_text ltx_font_italic">dplyr: A Grammar of Data Manipulation</span>, 2021.

</span>
<span class="ltx_bibblock">R package version 1.0.4.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
K. Xiong, S. Fu, G. Ding, Z. Luo, R. Yu, W. Chen, H. Bao, and Y. Wu.

</span>
<span class="ltx_bibblock">Visualizing the scripts of data wrangling with SOMNUS.

</span>
<span class="ltx_bibblock"><span id="bib.bib69.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</span>, 2022.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
C. Yang, S. Zhou, J. L. Guo, and C. Kästner.

</span>
<span class="ltx_bibblock">Subtle bugs everywhere: Generating documentation for data wrangling
code.

</span>
<span class="ltx_bibblock">In <span id="bib.bib70.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/ACM International Conference on
Automated Software Engineering</span>, pp. 304–316, 2021.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2209.13994" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2209.13995" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2209.13995">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2209.13995" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2209.13996" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar 14 00:00:34 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
