<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2109.04269] Asynchronous Federated Learning on Heterogeneous Devices: A Survey</title><meta property="og:description" content="Federated learning (FL) is a kind of distributed machine learning framework, where the global model is generated on the centralized aggregation server based on the parameters of local models, addressing concerns about …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Asynchronous Federated Learning on Heterogeneous Devices: A Survey">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Asynchronous Federated Learning on Heterogeneous Devices: A Survey">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2109.04269">

<!--Generated on Sat Mar  2 03:48:02 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_fleqn">
<h1 class="ltx_title ltx_title_document">Asynchronous Federated Learning on Heterogeneous Devices: A Survey</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chenhao Xu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_address">
Deakin Blockchain Innovation Lab, School of Information Technology, Deakin University, Geelong, VIC, Australia

</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Youyang Qu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_address">
Shandong Computer Science Center; Qilu University of Technology, China

</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yong Xiang
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Longxiang Gao
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<span id="id1.id1" class="ltx_ERROR undefined">\add</span>
<p id="id2.id2" class="ltx_p">Federated learning (FL) is a kind of distributed machine learning framework, where the global model is generated on the centralized aggregation server based on the parameters of local models, addressing concerns about privacy leakage caused by the collection of local training data. With the growing computational and communication capacities of edge and IoT devices, applying FL on heterogeneous devices to train machine learning models is becoming a prevailing trend. Nonetheless, the synchronous aggregation strategy in the classic FL paradigm, particularly on heterogeneous devices, encounters limitations in resource utilization due to the need to wait for slow devices before aggregation in each training round. Furthermore, the uneven distribution of data across devices (i.e. data heterogeneity) in real-world scenarios adversely impacts the accuracy of the global model. Consequently, many asynchronous FL (AFL) approaches have been introduced across various application contexts to enhance efficiency, performance, privacy, and security. This survey comprehensively analyzes and summarizes existing AFL variations using a novel classification scheme, including device heterogeneity, data heterogeneity, privacy, and security on heterogeneous devices, as well as applications on heterogeneous devices. Finally, this survey reveals rising challenges and presents potentially promising research directions in this under-investigated domain.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>
Asynchronous Federated Learning , Device Heterogeneity , Data Heterogeneity , Privacy , Security

</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journal"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journal: </span>Computer Science Review</span></span></span>
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\setreviewsoff</span>
</div>
<span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">aff1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">aff1</sup><span class="ltx_note_type">footnotetext: </span>Youyang Qu and Longxiang Gao are the corresponding authors.</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<span id="S1.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S1.p1.2" class="ltx_p">In recent years, the rapid expansion of computational capabilities coupled with the swift evolution of communication infrastructures has directly contributed to the flourishing of machine learning (ML), a pivotal driving force behind numerous contemporary technologies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Nonetheless, the training of ML models necessitates a substantial volume of high-quality data, a crucial requirement for model trainers operating in real-world scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Notably, the emphasis on preserving privacy during data sharing continues to persist, with newly enacted legislation and regulations further complicating the process of data acquisition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Furthermore, industries exhibit hesitancy in sharing their local data due to competitive pressures, privacy concerns, and other potential considerations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. All these factors jointly give rise to the challenge of <span id="S1.p1.2.1" class="ltx_text ltx_font_italic">isolated data islands</span>. As a result, gathering data from diverse reliable sources becomes a near-impossible task, often accompanied by prohibitively high costs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<span id="S1.p2.1" class="ltx_ERROR undefined">\add</span>
<p id="S1.p2.2" class="ltx_p">Federated learning (FL) presents an innovative framework facilitating collaborative ML model training among multiple entities without requiring direct access to their respective local training data. Initially introduced by Google in 2016, FL emerges as a promising ML approach that effectively addresses the imperatives of data privacy and communication efficiency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. The fundamental objective of FL revolves around ensuring personal data privacy and engendering robust ML models across multiple participants or computational nodes while upholding legal mandates <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. Consequently, FL has found its way into numerous research papers, employing a central server to collect parameters of local models from nodes (referred to as “local models” henceforth) prior to aggregating them into a global model during each round of training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<span id="S1.p3.1" class="ltx_ERROR undefined">\add</span>
<p id="S1.p3.2" class="ltx_p">Amidst the extensive rollout of the 5G network and the swift evolution of hardware capabilities, heterogeneous devices, encompassing both edge and IoT devices, are experiencing augmented communication and computational capabilities, paving the way for an expanded array of applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. Compared with classic ML approaches, FL presents a range of merits specifically tailored to edge applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>: (1) Enhanced preservation of local data privacy, facilitated by the gradients-based aggregation of the global model; (2) Reduced network transmission latency, as the training data remains localized instead of being transmitted to cloud servers; (3) Elevated model quality, owing to the incorporation of learned features from other devices. Consequently, FL serves as a catalyst for collaborative ML model training across heterogeneous devices, a phenomenon well-documented in numerous research publications.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparison with Existing Surveys</figcaption>
<table id="S1.T1.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S1.T1.3.1.1" class="ltx_tr">
<td id="S1.T1.3.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Surveys</span></td>
<td id="S1.T1.3.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Topics</span></td>
<td id="S1.T1.3.1.1.3" class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Limitations</span></td>
</tr>
<tr id="S1.T1.3.2.2" class="ltx_tr">
<td id="S1.T1.3.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.T1.3.2.2.1.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib16" title="" class="ltx_ref">16</a><span id="S1.T1.3.2.2.1.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S1.T1.3.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.2.2.2.1" class="ltx_text" style="font-size:80%;">FL</span></td>
<td id="S1.T1.3.2.2.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.2.2.3.1" class="ltx_text" style="font-size:80%;">Multi-level classification of FL without a detailed classification of AFL.</span></td>
</tr>
<tr id="S1.T1.3.3.3" class="ltx_tr">
<td id="S1.T1.3.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.T1.3.3.3.1.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib14" title="" class="ltx_ref">14</a><span id="S1.T1.3.3.3.1.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S1.T1.3.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.3.3.2.1" class="ltx_text" style="font-size:80%;">FL on edge</span></td>
<td id="S1.T1.3.3.3.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.3.3.3.1" class="ltx_text" style="font-size:80%;">Treat AFL as a promising solution without comparing different AFL schemes.</span></td>
</tr>
<tr id="S1.T1.3.4.4" class="ltx_tr">
<td id="S1.T1.3.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.T1.3.4.4.1.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib17" title="" class="ltx_ref">17</a><span id="S1.T1.3.4.4.1.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S1.T1.3.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.4.4.2.1" class="ltx_text" style="font-size:80%;">FL on IoT</span></td>
<td id="S1.T1.3.4.4.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.4.4.3.1" class="ltx_text" style="font-size:80%;">Only 7 papers related to AFL are gathered with an investigation on the convergence. No detailed classification on AFL.</span></td>
</tr>
<tr id="S1.T1.3.5.5" class="ltx_tr">
<td id="S1.T1.3.5.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.T1.3.5.5.1.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib18" title="" class="ltx_ref">18</a><span id="S1.T1.3.5.5.1.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S1.T1.3.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.5.5.2.1" class="ltx_text" style="font-size:80%;">FL on IoT</span></td>
<td id="S1.T1.3.5.5.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.5.5.3.1" class="ltx_text" style="font-size:80%;">Explain the concept of AFL without comparing different AFL schemes.</span></td>
</tr>
<tr id="S1.T1.3.6.6" class="ltx_tr">
<td id="S1.T1.3.6.6.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.T1.3.6.6.1.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib15" title="" class="ltx_ref">15</a><span id="S1.T1.3.6.6.1.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S1.T1.3.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.6.6.2.1" class="ltx_text" style="font-size:80%;">FL privacy</span></td>
<td id="S1.T1.3.6.6.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.6.6.3.1" class="ltx_text" style="font-size:80%;">Focus on privacy-preserving in FL, no discussion related to AFL.</span></td>
</tr>
<tr id="S1.T1.3.7.7" class="ltx_tr">
<td id="S1.T1.3.7.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.T1.3.7.7.1.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="S1.T1.3.7.7.1.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S1.T1.3.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.7.7.2.1" class="ltx_text" style="font-size:80%;">FL security</span></td>
<td id="S1.T1.3.7.7.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.7.7.3.1" class="ltx_text" style="font-size:80%;">AFL not mentioned.</span></td>
</tr>
<tr id="S1.T1.3.8.8" class="ltx_tr">
<td id="S1.T1.3.8.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.T1.3.8.8.1.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib20" title="" class="ltx_ref">20</a><span id="S1.T1.3.8.8.1.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S1.T1.3.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.8.8.2.1" class="ltx_text" style="font-size:80%;">FL privacy</span></td>
<td id="S1.T1.3.8.8.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.8.8.3.1" class="ltx_text" style="font-size:80%;">Focus on privacy-preserving in FL on IoT, no detailed classification of AFL.</span></td>
</tr>
<tr id="S1.T1.3.9.9" class="ltx_tr">
<td id="S1.T1.3.9.9.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.9.9.1.1" class="ltx_text" style="font-size:80%;">This Survey</span></td>
<td id="S1.T1.3.9.9.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.9.9.2.1" class="ltx_text" style="font-size:80%;">AFL</span></td>
<td id="S1.T1.3.9.9.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S1.T1.3.9.9.3.1" class="ltx_text" style="font-size:80%;">Classify and analyze the challenges faced by AFL and summarize the application scenarios of AFL.</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S1.p4" class="ltx_para">
<span id="S1.p4.1" class="ltx_ERROR undefined">\add</span>
<p id="S1.p4.2" class="ltx_p">When employing classical FL on devices with limited resources, several drawbacks become apparent <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>: (1) Device Unreliability. The presence of heterogeneous devices introduces a challenge as the aggregation server must wait for updated local gradients from chosen heterogeneous devices. These devices, however, might unexpectedly go offline due to their inherent unreliability. (2) Aggregation Efficiency Reduction. In each training round, faster devices are forced to wait for stale local models from slower devices (stragglers). This delay results from the dual factors of device heterogeneity (resource variation among devices) and data heterogeneity (uneven training data distribution across devices). (3) Low Resource Utilization. The current inefficiencies in node selection algorithms often cause multiple competent devices to be rarely chosen for participation. (4) Security and Privacy Vulnerabilities. The classic FL approach is susceptible to various security threats, such as poisoning and backdoor attacks. Moreover, concerns about privacy arise due to potential data leaks during the training process.</p>
</div>
<div id="S1.p5" class="ltx_para">
<span id="S1.p5.1" class="ltx_ERROR undefined">\add</span>
<p id="S1.p5.2" class="ltx_p">To address the challenges of device unreliability, aggregation efficiency reduction, and low resource utilization, asynchronous federated learning (AFL) emerges as a promising solution. In AFL, the central server promptly initiates global model aggregation upon the reception of a local model. As the devices unexpectedly going offline are ignorable to AFL, the concerns about device unreliability are mitigated. By removing the necessity to await slow devices for local model uploads before aggregation, AFL enhances aggregation efficiency. AFL also improves the utilization of computing resources across heterogeneous devices by allowing devices with varying operational efficiency to train their respective local models at their own pace.</p>
</div>
<div id="S1.p6" class="ltx_para">
<span id="S1.p6.1" class="ltx_ERROR undefined">\add</span>
<p id="S1.p6.2" class="ltx_p">While there have been survey papers on the subject of FL, none of them have undertaken an exhaustive investigation, classification, or summary of AFL. Consequently, the primary significance of this study lies in its comprehensive classification, summarization, and analysis of AFL. A comparative overview between this survey paper and other relevant surveys is provided in Table <a href="#S1.T1" title="Table 1 ‣ 1 Introduction ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S1.p7" class="ltx_para">
<span id="S1.p7.1" class="ltx_ERROR undefined">\add</span>
<p id="S1.p7.2" class="ltx_p">The contributions of this survey paper are summarized as follows. Firstly, this comprehensive survey reviews and analyzes 125 research papers spanning the years 2019 to 2022, including 7 relative survey papers. Secondly, the existing papers of AFL are categorized and summarized innovatively from the perspective of device heterogeneity, data heterogeneity, privacy and security, and application scenarios. Thirdly, the survey identifies a number of promising research topics that deserve more investigation and discussion.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">The subsequent sections of this paper are organized as follows: In Section <a href="#S2" title="2 Background Knowledge ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the preliminary knowledge requisite for this survey is briefly introduced. Then, the AFL approaches addressing various challenges, including device heterogeneity, data heterogeneity, as well as privacy and security on heterogeneous devices, are then summarized and analyzed in Section <a href="#S3" title="3 Device Heterogeneity ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, Section <a href="#S4" title="4 Data Heterogeneity ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, and Section <a href="#S5" title="5 Privacy and Security on Heterogeneous Devices ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, respectively. Following this, Section <a href="#S6" title="6 Applications on Heterogeneous Devices ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> offers a comprehensive portrayal of the diverse applications of AFL with heterogeneous devices. Building upon the comprehensive analysis and discourse, Section <a href="#S7" title="7 Research Challenges and Future Directions ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> outlines potential avenues for promising research directions, followed by a conclusion in Section <a href="#S8" title="8 Conclusion ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background Knowledge</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">This section provides an explanation of the foundational knowledge essential for this survey, covering three key perspectives: federated learning, blockchain, and differential privacy.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Federated Learning</h3>

<div id="S2.SS1.p1" class="ltx_para">
<span id="S2.SS1.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S2.SS1.p1.2" class="ltx_p">Distributed ML (DML) is a research topic that investigates different structures or topologies of the computer cluster for better training machine learning models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. Typically, DML can be categorized as centralized, decentralized, and fully distributed, along with various types of communication protocols. FL is a kind of DML where local models are trained on distributed nodes, and the global model is generated on an aggregation server by averaging the local models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. Nevertheless, there is a difference between FL and DML. FL is designed for scenarios where data resides on multiple devices or servers and is not centralized. It is typical in environments where data privacy is crucial, such as on mobile devices. By contrast, DML often assumes cloud or data center environments. While data can be distributed across multiple servers or nodes, these nodes are typically co-located or part of a single infrastructure, and there is more flexibility in data sharing. Therefore, FL serves as an ML framework designed to dismantle the barrier of the data silo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, primarily attributed to its privacy-preserving characteristic for local training data within each node. The conventional FL process encompasses the following key steps.</p>
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.3" class="ltx_p">Initialization: <span id="S2.I1.i1.p1.3.1" class="ltx_ERROR undefined">\add</span>Once the training task is defined according to the specific application scenario, the aggregation server prepares the initial global model <math id="S2.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="w_{G}^{0}" display="inline"><semantics id="S2.I1.i1.p1.1.m1.1a"><msubsup id="S2.I1.i1.p1.1.m1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.cmml"><mi id="S2.I1.i1.p1.1.m1.1.1.2.2" xref="S2.I1.i1.p1.1.m1.1.1.2.2.cmml">w</mi><mi id="S2.I1.i1.p1.1.m1.1.1.2.3" xref="S2.I1.i1.p1.1.m1.1.1.2.3.cmml">G</mi><mn id="S2.I1.i1.p1.1.m1.1.1.3" xref="S2.I1.i1.p1.1.m1.1.1.3.cmml">0</mn></msubsup><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.1b"><apply id="S2.I1.i1.p1.1.m1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.1.m1.1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1">superscript</csymbol><apply id="S2.I1.i1.p1.1.m1.1.1.2.cmml" xref="S2.I1.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.1.m1.1.1.2.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I1.i1.p1.1.m1.1.1.2.2.cmml" xref="S2.I1.i1.p1.1.m1.1.1.2.2">𝑤</ci><ci id="S2.I1.i1.p1.1.m1.1.1.2.3.cmml" xref="S2.I1.i1.p1.1.m1.1.1.2.3">𝐺</ci></apply><cn type="integer" id="S2.I1.i1.p1.1.m1.1.1.3.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.1c">w_{G}^{0}</annotation></semantics></math>, alongside training parameters like learning rate, batch size, and iteration count. Following the selection process, the aggregation server broadcasts <math id="S2.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="w_{G}^{0}" display="inline"><semantics id="S2.I1.i1.p1.2.m2.1a"><msubsup id="S2.I1.i1.p1.2.m2.1.1" xref="S2.I1.i1.p1.2.m2.1.1.cmml"><mi id="S2.I1.i1.p1.2.m2.1.1.2.2" xref="S2.I1.i1.p1.2.m2.1.1.2.2.cmml">w</mi><mi id="S2.I1.i1.p1.2.m2.1.1.2.3" xref="S2.I1.i1.p1.2.m2.1.1.2.3.cmml">G</mi><mn id="S2.I1.i1.p1.2.m2.1.1.3" xref="S2.I1.i1.p1.2.m2.1.1.3.cmml">0</mn></msubsup><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.2.m2.1b"><apply id="S2.I1.i1.p1.2.m2.1.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.1.1.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1">superscript</csymbol><apply id="S2.I1.i1.p1.2.m2.1.1.2.cmml" xref="S2.I1.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.1.1.2.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1">subscript</csymbol><ci id="S2.I1.i1.p1.2.m2.1.1.2.2.cmml" xref="S2.I1.i1.p1.2.m2.1.1.2.2">𝑤</ci><ci id="S2.I1.i1.p1.2.m2.1.1.2.3.cmml" xref="S2.I1.i1.p1.2.m2.1.1.2.3">𝐺</ci></apply><cn type="integer" id="S2.I1.i1.p1.2.m2.1.1.3.cmml" xref="S2.I1.i1.p1.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.2.m2.1c">w_{G}^{0}</annotation></semantics></math> to a designated number of nodes (denoted as <math id="S2.I1.i1.p1.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.I1.i1.p1.3.m3.1a"><mi id="S2.I1.i1.p1.3.m3.1.1" xref="S2.I1.i1.p1.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.3.m3.1b"><ci id="S2.I1.i1.p1.3.m3.1.1.cmml" xref="S2.I1.i1.p1.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.3.m3.1c">K</annotation></semantics></math>).</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.5" class="ltx_p">Local Model Training: Assume <math id="S2.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.I1.i2.p1.1.m1.1a"><mi id="S2.I1.i2.p1.1.m1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.1.m1.1b"><ci id="S2.I1.i2.p1.1.m1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.1.m1.1c">t</annotation></semantics></math> stands for the current iteration number. Based on global model <math id="S2.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="w_{G}^{t}" display="inline"><semantics id="S2.I1.i2.p1.2.m2.1a"><msubsup id="S2.I1.i2.p1.2.m2.1.1" xref="S2.I1.i2.p1.2.m2.1.1.cmml"><mi id="S2.I1.i2.p1.2.m2.1.1.2.2" xref="S2.I1.i2.p1.2.m2.1.1.2.2.cmml">w</mi><mi id="S2.I1.i2.p1.2.m2.1.1.2.3" xref="S2.I1.i2.p1.2.m2.1.1.2.3.cmml">G</mi><mi id="S2.I1.i2.p1.2.m2.1.1.3" xref="S2.I1.i2.p1.2.m2.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.2.m2.1b"><apply id="S2.I1.i2.p1.2.m2.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.1.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1">superscript</csymbol><apply id="S2.I1.i2.p1.2.m2.1.1.2.cmml" xref="S2.I1.i2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.1.1.2.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.2.m2.1.1.2.2.cmml" xref="S2.I1.i2.p1.2.m2.1.1.2.2">𝑤</ci><ci id="S2.I1.i2.p1.2.m2.1.1.2.3.cmml" xref="S2.I1.i2.p1.2.m2.1.1.2.3">𝐺</ci></apply><ci id="S2.I1.i2.p1.2.m2.1.1.3.cmml" xref="S2.I1.i2.p1.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.2.m2.1c">w_{G}^{t}</annotation></semantics></math>, each node trains its respective local model <math id="S2.I1.i2.p1.3.m3.1" class="ltx_Math" alttext="w_{k}^{t}" display="inline"><semantics id="S2.I1.i2.p1.3.m3.1a"><msubsup id="S2.I1.i2.p1.3.m3.1.1" xref="S2.I1.i2.p1.3.m3.1.1.cmml"><mi id="S2.I1.i2.p1.3.m3.1.1.2.2" xref="S2.I1.i2.p1.3.m3.1.1.2.2.cmml">w</mi><mi id="S2.I1.i2.p1.3.m3.1.1.2.3" xref="S2.I1.i2.p1.3.m3.1.1.2.3.cmml">k</mi><mi id="S2.I1.i2.p1.3.m3.1.1.3" xref="S2.I1.i2.p1.3.m3.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.3.m3.1b"><apply id="S2.I1.i2.p1.3.m3.1.1.cmml" xref="S2.I1.i2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.3.m3.1.1.1.cmml" xref="S2.I1.i2.p1.3.m3.1.1">superscript</csymbol><apply id="S2.I1.i2.p1.3.m3.1.1.2.cmml" xref="S2.I1.i2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.3.m3.1.1.2.1.cmml" xref="S2.I1.i2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.3.m3.1.1.2.2.cmml" xref="S2.I1.i2.p1.3.m3.1.1.2.2">𝑤</ci><ci id="S2.I1.i2.p1.3.m3.1.1.2.3.cmml" xref="S2.I1.i2.p1.3.m3.1.1.2.3">𝑘</ci></apply><ci id="S2.I1.i2.p1.3.m3.1.1.3.cmml" xref="S2.I1.i2.p1.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.3.m3.1c">w_{k}^{t}</annotation></semantics></math>, where <math id="S2.I1.i2.p1.4.m4.2" class="ltx_Math" alttext="k\in[1,K]" display="inline"><semantics id="S2.I1.i2.p1.4.m4.2a"><mrow id="S2.I1.i2.p1.4.m4.2.3" xref="S2.I1.i2.p1.4.m4.2.3.cmml"><mi id="S2.I1.i2.p1.4.m4.2.3.2" xref="S2.I1.i2.p1.4.m4.2.3.2.cmml">k</mi><mo id="S2.I1.i2.p1.4.m4.2.3.1" xref="S2.I1.i2.p1.4.m4.2.3.1.cmml">∈</mo><mrow id="S2.I1.i2.p1.4.m4.2.3.3.2" xref="S2.I1.i2.p1.4.m4.2.3.3.1.cmml"><mo stretchy="false" id="S2.I1.i2.p1.4.m4.2.3.3.2.1" xref="S2.I1.i2.p1.4.m4.2.3.3.1.cmml">[</mo><mn id="S2.I1.i2.p1.4.m4.1.1" xref="S2.I1.i2.p1.4.m4.1.1.cmml">1</mn><mo id="S2.I1.i2.p1.4.m4.2.3.3.2.2" xref="S2.I1.i2.p1.4.m4.2.3.3.1.cmml">,</mo><mi id="S2.I1.i2.p1.4.m4.2.2" xref="S2.I1.i2.p1.4.m4.2.2.cmml">K</mi><mo stretchy="false" id="S2.I1.i2.p1.4.m4.2.3.3.2.3" xref="S2.I1.i2.p1.4.m4.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.4.m4.2b"><apply id="S2.I1.i2.p1.4.m4.2.3.cmml" xref="S2.I1.i2.p1.4.m4.2.3"><in id="S2.I1.i2.p1.4.m4.2.3.1.cmml" xref="S2.I1.i2.p1.4.m4.2.3.1"></in><ci id="S2.I1.i2.p1.4.m4.2.3.2.cmml" xref="S2.I1.i2.p1.4.m4.2.3.2">𝑘</ci><interval closure="closed" id="S2.I1.i2.p1.4.m4.2.3.3.1.cmml" xref="S2.I1.i2.p1.4.m4.2.3.3.2"><cn type="integer" id="S2.I1.i2.p1.4.m4.1.1.cmml" xref="S2.I1.i2.p1.4.m4.1.1">1</cn><ci id="S2.I1.i2.p1.4.m4.2.2.cmml" xref="S2.I1.i2.p1.4.m4.2.2">𝐾</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.4.m4.2c">k\in[1,K]</annotation></semantics></math>. These local models, <math id="S2.I1.i2.p1.5.m5.1" class="ltx_Math" alttext="w_{k}^{t}" display="inline"><semantics id="S2.I1.i2.p1.5.m5.1a"><msubsup id="S2.I1.i2.p1.5.m5.1.1" xref="S2.I1.i2.p1.5.m5.1.1.cmml"><mi id="S2.I1.i2.p1.5.m5.1.1.2.2" xref="S2.I1.i2.p1.5.m5.1.1.2.2.cmml">w</mi><mi id="S2.I1.i2.p1.5.m5.1.1.2.3" xref="S2.I1.i2.p1.5.m5.1.1.2.3.cmml">k</mi><mi id="S2.I1.i2.p1.5.m5.1.1.3" xref="S2.I1.i2.p1.5.m5.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.5.m5.1b"><apply id="S2.I1.i2.p1.5.m5.1.1.cmml" xref="S2.I1.i2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.5.m5.1.1.1.cmml" xref="S2.I1.i2.p1.5.m5.1.1">superscript</csymbol><apply id="S2.I1.i2.p1.5.m5.1.1.2.cmml" xref="S2.I1.i2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.5.m5.1.1.2.1.cmml" xref="S2.I1.i2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.5.m5.1.1.2.2.cmml" xref="S2.I1.i2.p1.5.m5.1.1.2.2">𝑤</ci><ci id="S2.I1.i2.p1.5.m5.1.1.2.3.cmml" xref="S2.I1.i2.p1.5.m5.1.1.2.3">𝑘</ci></apply><ci id="S2.I1.i2.p1.5.m5.1.1.3.cmml" xref="S2.I1.i2.p1.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.5.m5.1c">w_{k}^{t}</annotation></semantics></math>, are subsequently transmitted back to the aggregation server.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.3" class="ltx_p">Global Model Aggregation: <span id="S2.I1.i3.p1.3.1" class="ltx_ERROR undefined">\add</span>Assuming the training samples on node <math id="S2.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.I1.i3.p1.1.m1.1a"><mi id="S2.I1.i3.p1.1.m1.1.1" xref="S2.I1.i3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.1.m1.1b"><ci id="S2.I1.i3.p1.1.m1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.1.m1.1c">k</annotation></semantics></math> amount to <math id="S2.I1.i3.p1.2.m2.1" class="ltx_Math" alttext="n_{k}" display="inline"><semantics id="S2.I1.i3.p1.2.m2.1a"><msub id="S2.I1.i3.p1.2.m2.1.1" xref="S2.I1.i3.p1.2.m2.1.1.cmml"><mi id="S2.I1.i3.p1.2.m2.1.1.2" xref="S2.I1.i3.p1.2.m2.1.1.2.cmml">n</mi><mi id="S2.I1.i3.p1.2.m2.1.1.3" xref="S2.I1.i3.p1.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.2.m2.1b"><apply id="S2.I1.i3.p1.2.m2.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.1.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1">subscript</csymbol><ci id="S2.I1.i3.p1.2.m2.1.1.2.cmml" xref="S2.I1.i3.p1.2.m2.1.1.2">𝑛</ci><ci id="S2.I1.i3.p1.2.m2.1.1.3.cmml" xref="S2.I1.i3.p1.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.2.m2.1c">n_{k}</annotation></semantics></math>, and the total of training samples is represented as <math id="S2.I1.i3.p1.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.I1.i3.p1.3.m3.1a"><mi id="S2.I1.i3.p1.3.m3.1.1" xref="S2.I1.i3.p1.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.3.m3.1b"><ci id="S2.I1.i3.p1.3.m3.1.1.cmml" xref="S2.I1.i3.p1.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.3.m3.1c">n</annotation></semantics></math>, the server generates a new global model by taking a weighted average of the local models, as given in Eq. <a href="#S2.E1" title="In item 3 ‣ 2.1 Federated Learning ‣ 2 Background Knowledge ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S2.E1.m1.1" class="ltx_Math" alttext="w_{G}^{t+1}=\sum^{K}_{k=1}\frac{n_{k}}{n}w^{t}_{k}" display="block"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><msubsup id="S2.E1.m1.1.1.2" xref="S2.E1.m1.1.1.2.cmml"><mi id="S2.E1.m1.1.1.2.2.2" xref="S2.E1.m1.1.1.2.2.2.cmml">w</mi><mi id="S2.E1.m1.1.1.2.2.3" xref="S2.E1.m1.1.1.2.2.3.cmml">G</mi><mrow id="S2.E1.m1.1.1.2.3" xref="S2.E1.m1.1.1.2.3.cmml"><mi id="S2.E1.m1.1.1.2.3.2" xref="S2.E1.m1.1.1.2.3.2.cmml">t</mi><mo id="S2.E1.m1.1.1.2.3.1" xref="S2.E1.m1.1.1.2.3.1.cmml">+</mo><mn id="S2.E1.m1.1.1.2.3.3" xref="S2.E1.m1.1.1.2.3.3.cmml">1</mn></mrow></msubsup><mo rspace="0.111em" id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.cmml">=</mo><mrow id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.3.cmml"><munderover id="S2.E1.m1.1.1.3.1" xref="S2.E1.m1.1.1.3.1.cmml"><mo movablelimits="false" id="S2.E1.m1.1.1.3.1.2.2" xref="S2.E1.m1.1.1.3.1.2.2.cmml">∑</mo><mrow id="S2.E1.m1.1.1.3.1.3" xref="S2.E1.m1.1.1.3.1.3.cmml"><mi id="S2.E1.m1.1.1.3.1.3.2" xref="S2.E1.m1.1.1.3.1.3.2.cmml">k</mi><mo id="S2.E1.m1.1.1.3.1.3.1" xref="S2.E1.m1.1.1.3.1.3.1.cmml">=</mo><mn id="S2.E1.m1.1.1.3.1.3.3" xref="S2.E1.m1.1.1.3.1.3.3.cmml">1</mn></mrow><mi id="S2.E1.m1.1.1.3.1.2.3" xref="S2.E1.m1.1.1.3.1.2.3.cmml">K</mi></munderover><mrow id="S2.E1.m1.1.1.3.2" xref="S2.E1.m1.1.1.3.2.cmml"><mfrac id="S2.E1.m1.1.1.3.2.2" xref="S2.E1.m1.1.1.3.2.2.cmml"><msub id="S2.E1.m1.1.1.3.2.2.2" xref="S2.E1.m1.1.1.3.2.2.2.cmml"><mi id="S2.E1.m1.1.1.3.2.2.2.2" xref="S2.E1.m1.1.1.3.2.2.2.2.cmml">n</mi><mi id="S2.E1.m1.1.1.3.2.2.2.3" xref="S2.E1.m1.1.1.3.2.2.2.3.cmml">k</mi></msub><mi id="S2.E1.m1.1.1.3.2.2.3" xref="S2.E1.m1.1.1.3.2.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.2.1" xref="S2.E1.m1.1.1.3.2.1.cmml">​</mo><msubsup id="S2.E1.m1.1.1.3.2.3" xref="S2.E1.m1.1.1.3.2.3.cmml"><mi id="S2.E1.m1.1.1.3.2.3.2.2" xref="S2.E1.m1.1.1.3.2.3.2.2.cmml">w</mi><mi id="S2.E1.m1.1.1.3.2.3.3" xref="S2.E1.m1.1.1.3.2.3.3.cmml">k</mi><mi id="S2.E1.m1.1.1.3.2.3.2.3" xref="S2.E1.m1.1.1.3.2.3.2.3.cmml">t</mi></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1"><eq id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"></eq><apply id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.2">superscript</csymbol><apply id="S2.E1.m1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.2.2.1.cmml" xref="S2.E1.m1.1.1.2">subscript</csymbol><ci id="S2.E1.m1.1.1.2.2.2.cmml" xref="S2.E1.m1.1.1.2.2.2">𝑤</ci><ci id="S2.E1.m1.1.1.2.2.3.cmml" xref="S2.E1.m1.1.1.2.2.3">𝐺</ci></apply><apply id="S2.E1.m1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.2.3"><plus id="S2.E1.m1.1.1.2.3.1.cmml" xref="S2.E1.m1.1.1.2.3.1"></plus><ci id="S2.E1.m1.1.1.2.3.2.cmml" xref="S2.E1.m1.1.1.2.3.2">𝑡</ci><cn type="integer" id="S2.E1.m1.1.1.2.3.3.cmml" xref="S2.E1.m1.1.1.2.3.3">1</cn></apply></apply><apply id="S2.E1.m1.1.1.3.cmml" xref="S2.E1.m1.1.1.3"><apply id="S2.E1.m1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.1.1.cmml" xref="S2.E1.m1.1.1.3.1">subscript</csymbol><apply id="S2.E1.m1.1.1.3.1.2.cmml" xref="S2.E1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.1.2.1.cmml" xref="S2.E1.m1.1.1.3.1">superscript</csymbol><sum id="S2.E1.m1.1.1.3.1.2.2.cmml" xref="S2.E1.m1.1.1.3.1.2.2"></sum><ci id="S2.E1.m1.1.1.3.1.2.3.cmml" xref="S2.E1.m1.1.1.3.1.2.3">𝐾</ci></apply><apply id="S2.E1.m1.1.1.3.1.3.cmml" xref="S2.E1.m1.1.1.3.1.3"><eq id="S2.E1.m1.1.1.3.1.3.1.cmml" xref="S2.E1.m1.1.1.3.1.3.1"></eq><ci id="S2.E1.m1.1.1.3.1.3.2.cmml" xref="S2.E1.m1.1.1.3.1.3.2">𝑘</ci><cn type="integer" id="S2.E1.m1.1.1.3.1.3.3.cmml" xref="S2.E1.m1.1.1.3.1.3.3">1</cn></apply></apply><apply id="S2.E1.m1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.3.2"><times id="S2.E1.m1.1.1.3.2.1.cmml" xref="S2.E1.m1.1.1.3.2.1"></times><apply id="S2.E1.m1.1.1.3.2.2.cmml" xref="S2.E1.m1.1.1.3.2.2"><divide id="S2.E1.m1.1.1.3.2.2.1.cmml" xref="S2.E1.m1.1.1.3.2.2"></divide><apply id="S2.E1.m1.1.1.3.2.2.2.cmml" xref="S2.E1.m1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.2.2.1.cmml" xref="S2.E1.m1.1.1.3.2.2.2">subscript</csymbol><ci id="S2.E1.m1.1.1.3.2.2.2.2.cmml" xref="S2.E1.m1.1.1.3.2.2.2.2">𝑛</ci><ci id="S2.E1.m1.1.1.3.2.2.2.3.cmml" xref="S2.E1.m1.1.1.3.2.2.2.3">𝑘</ci></apply><ci id="S2.E1.m1.1.1.3.2.2.3.cmml" xref="S2.E1.m1.1.1.3.2.2.3">𝑛</ci></apply><apply id="S2.E1.m1.1.1.3.2.3.cmml" xref="S2.E1.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.3.1.cmml" xref="S2.E1.m1.1.1.3.2.3">subscript</csymbol><apply id="S2.E1.m1.1.1.3.2.3.2.cmml" xref="S2.E1.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.3.2.1.cmml" xref="S2.E1.m1.1.1.3.2.3">superscript</csymbol><ci id="S2.E1.m1.1.1.3.2.3.2.2.cmml" xref="S2.E1.m1.1.1.3.2.3.2.2">𝑤</ci><ci id="S2.E1.m1.1.1.3.2.3.2.3.cmml" xref="S2.E1.m1.1.1.3.2.3.2.3">𝑡</ci></apply><ci id="S2.E1.m1.1.1.3.2.3.3.cmml" xref="S2.E1.m1.1.1.3.2.3.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">w_{G}^{t+1}=\sum^{K}_{k=1}\frac{n_{k}}{n}w^{t}_{k}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.I1.i3.p1.4" class="ltx_p">Subsequently, <math id="S2.I1.i3.p1.4.m1.1" class="ltx_Math" alttext="w_{G}^{t+1}" display="inline"><semantics id="S2.I1.i3.p1.4.m1.1a"><msubsup id="S2.I1.i3.p1.4.m1.1.1" xref="S2.I1.i3.p1.4.m1.1.1.cmml"><mi id="S2.I1.i3.p1.4.m1.1.1.2.2" xref="S2.I1.i3.p1.4.m1.1.1.2.2.cmml">w</mi><mi id="S2.I1.i3.p1.4.m1.1.1.2.3" xref="S2.I1.i3.p1.4.m1.1.1.2.3.cmml">G</mi><mrow id="S2.I1.i3.p1.4.m1.1.1.3" xref="S2.I1.i3.p1.4.m1.1.1.3.cmml"><mi id="S2.I1.i3.p1.4.m1.1.1.3.2" xref="S2.I1.i3.p1.4.m1.1.1.3.2.cmml">t</mi><mo id="S2.I1.i3.p1.4.m1.1.1.3.1" xref="S2.I1.i3.p1.4.m1.1.1.3.1.cmml">+</mo><mn id="S2.I1.i3.p1.4.m1.1.1.3.3" xref="S2.I1.i3.p1.4.m1.1.1.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.4.m1.1b"><apply id="S2.I1.i3.p1.4.m1.1.1.cmml" xref="S2.I1.i3.p1.4.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i3.p1.4.m1.1.1.1.cmml" xref="S2.I1.i3.p1.4.m1.1.1">superscript</csymbol><apply id="S2.I1.i3.p1.4.m1.1.1.2.cmml" xref="S2.I1.i3.p1.4.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i3.p1.4.m1.1.1.2.1.cmml" xref="S2.I1.i3.p1.4.m1.1.1">subscript</csymbol><ci id="S2.I1.i3.p1.4.m1.1.1.2.2.cmml" xref="S2.I1.i3.p1.4.m1.1.1.2.2">𝑤</ci><ci id="S2.I1.i3.p1.4.m1.1.1.2.3.cmml" xref="S2.I1.i3.p1.4.m1.1.1.2.3">𝐺</ci></apply><apply id="S2.I1.i3.p1.4.m1.1.1.3.cmml" xref="S2.I1.i3.p1.4.m1.1.1.3"><plus id="S2.I1.i3.p1.4.m1.1.1.3.1.cmml" xref="S2.I1.i3.p1.4.m1.1.1.3.1"></plus><ci id="S2.I1.i3.p1.4.m1.1.1.3.2.cmml" xref="S2.I1.i3.p1.4.m1.1.1.3.2">𝑡</ci><cn type="integer" id="S2.I1.i3.p1.4.m1.1.1.3.3.cmml" xref="S2.I1.i3.p1.4.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.4.m1.1c">w_{G}^{t+1}</annotation></semantics></math> is sent back to the nodes in preparation for the next training iteration.</p>
</div>
</li>
</ol>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Generally, datasets across nodes in FL are expected to be independent and identically distributed (IID). <span id="S2.SS1.p2.1.1" class="ltx_ERROR undefined">\add</span>This entails an identical distribution of samples among nodes, with each training round independently selecting training samples. In practice, however, the training data samples collected by nodes usually deviate from this IID condition, named as non-independent and identically distributed (non-IID), posing challenges for both classic FL and AFL. Taking the smart hospital scenario as an example, IID data implies that disease cases across various hospitals exhibit similarity. Non-IID data, on the other hand, implies the diversity of disease cases among different hospitals, a portrayal more aligned with real-world scenarios. Under non-IID conditions, gradients learned and updated in one hospital provide limited utility in predicting patient conditions within another hospital.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">In several application scenarios, the datasets kept at different parties include diverse feature sets but the same entities. <span id="S2.SS1.p3.1.1" class="ltx_ERROR undefined">\add</span>For instance, the investment details and deposit records of a single user are usually held by a financial institution and a bank, respectively. Identifying the credit risk of an investor proves to be challenging for the financial institution due to the absence of crucial user-specific data such as deposit information. The datasets, featuring common entities but differing feature sets, fall under the category of vertically partitioned (VP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> datasets. Vertical FL is the method employed to train models across such VP datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, as shown in Fig. <a href="#S2.F1" title="Figure 1 ‣ 2.1 Federated Learning ‣ 2 Background Knowledge ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Through vertical FL, financial institutions can leverage updated gradients from banks to assess investment risks without the need for access to the user’s sensitive information.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2109.04269/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="107" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The comparison of horizontal and vertical federated learning.</figcaption>
</figure>
<div id="S2.SS1.p4" class="ltx_para">
<span id="S2.SS1.p4.1" class="ltx_ERROR undefined">\add</span>
<p id="S2.SS1.p4.2" class="ltx_p">The proliferation of 5G networks and the integration of advanced hardware have led to enhanced computation and communication capabilities for IoT and edge devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Researchers progressively deploy ML tasks on heterogeneous devices to enable intelligent human interactions while aiming to curtail communication costs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. Nevertheless, the diversity in computational and communication capabilities among these heterogeneous devices remains inescapable. Moreover, the discrepant data sizes across nodes introduce notable discrepancies in the time required for training on each node. This often results in the generation of stale local models on slower nodes (stragglers), reducing the accuracy of the global model after aggregating.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2109.04269/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="266" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The comparison of workflows in asynchronous and synchronous federated learning on heterogeneous devices.</figcaption>
</figure>
<div id="S2.SS1.p5" class="ltx_para">
<p id="S2.SS1.p5.1" class="ltx_p">AFL is proposed to alleviate the impact of stale nodes and improve the efficiency of FL. <span id="S2.SS1.p5.1.1" class="ltx_ERROR undefined">\add</span>Within the AFL framework, global model aggregation takes place immediately once the aggregation server receives a new local model. A comparison of workflows in asynchronous and synchronous FL on heterogeneous devices is depicted in Fig. <a href="#S2.F2" title="Figure 2 ‣ 2.1 Federated Learning ‣ 2 Background Knowledge ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The principal steps of AFL are outlined as follows.</p>
</div>
<div id="S2.SS1.p6" class="ltx_para">
<ol id="S2.I2" class="ltx_enumerate">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.2" class="ltx_p">Initialization: Similar to classic FL, the aggregation server broadcasts the initial global model <math id="S2.I2.i1.p1.1.m1.1" class="ltx_Math" alttext="w_{G}^{0}" display="inline"><semantics id="S2.I2.i1.p1.1.m1.1a"><msubsup id="S2.I2.i1.p1.1.m1.1.1" xref="S2.I2.i1.p1.1.m1.1.1.cmml"><mi id="S2.I2.i1.p1.1.m1.1.1.2.2" xref="S2.I2.i1.p1.1.m1.1.1.2.2.cmml">w</mi><mi id="S2.I2.i1.p1.1.m1.1.1.2.3" xref="S2.I2.i1.p1.1.m1.1.1.2.3.cmml">G</mi><mn id="S2.I2.i1.p1.1.m1.1.1.3" xref="S2.I2.i1.p1.1.m1.1.1.3.cmml">0</mn></msubsup><annotation-xml encoding="MathML-Content" id="S2.I2.i1.p1.1.m1.1b"><apply id="S2.I2.i1.p1.1.m1.1.1.cmml" xref="S2.I2.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I2.i1.p1.1.m1.1.1.1.cmml" xref="S2.I2.i1.p1.1.m1.1.1">superscript</csymbol><apply id="S2.I2.i1.p1.1.m1.1.1.2.cmml" xref="S2.I2.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I2.i1.p1.1.m1.1.1.2.1.cmml" xref="S2.I2.i1.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I2.i1.p1.1.m1.1.1.2.2.cmml" xref="S2.I2.i1.p1.1.m1.1.1.2.2">𝑤</ci><ci id="S2.I2.i1.p1.1.m1.1.1.2.3.cmml" xref="S2.I2.i1.p1.1.m1.1.1.2.3">𝐺</ci></apply><cn type="integer" id="S2.I2.i1.p1.1.m1.1.1.3.cmml" xref="S2.I2.i1.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i1.p1.1.m1.1c">w_{G}^{0}</annotation></semantics></math> to all <math id="S2.I2.i1.p1.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.I2.i1.p1.2.m2.1a"><mi id="S2.I2.i1.p1.2.m2.1.1" xref="S2.I2.i1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.I2.i1.p1.2.m2.1b"><ci id="S2.I2.i1.p1.2.m2.1.1.cmml" xref="S2.I2.i1.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i1.p1.2.m2.1c">K</annotation></semantics></math> nodes.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p">Local Model Training: <span id="S2.I2.i2.p1.1.1" class="ltx_ERROR undefined">\add</span>Nodes undertake the training of their respective local models based on the most recent global model. Due to the heterogeneity in computing capabilities among devices, the completion of local model training (<math id="S2.I2.i2.p1.1.m1.5" class="ltx_Math" alttext="\{w_{1}^{t},w_{2}^{t+1},w_{3}^{t+2},\dots,w_{k}^{t+k}\}" display="inline"><semantics id="S2.I2.i2.p1.1.m1.5a"><mrow id="S2.I2.i2.p1.1.m1.5.5.4" xref="S2.I2.i2.p1.1.m1.5.5.5.cmml"><mo stretchy="false" id="S2.I2.i2.p1.1.m1.5.5.4.5" xref="S2.I2.i2.p1.1.m1.5.5.5.cmml">{</mo><msubsup id="S2.I2.i2.p1.1.m1.2.2.1.1" xref="S2.I2.i2.p1.1.m1.2.2.1.1.cmml"><mi id="S2.I2.i2.p1.1.m1.2.2.1.1.2.2" xref="S2.I2.i2.p1.1.m1.2.2.1.1.2.2.cmml">w</mi><mn id="S2.I2.i2.p1.1.m1.2.2.1.1.2.3" xref="S2.I2.i2.p1.1.m1.2.2.1.1.2.3.cmml">1</mn><mi id="S2.I2.i2.p1.1.m1.2.2.1.1.3" xref="S2.I2.i2.p1.1.m1.2.2.1.1.3.cmml">t</mi></msubsup><mo id="S2.I2.i2.p1.1.m1.5.5.4.6" xref="S2.I2.i2.p1.1.m1.5.5.5.cmml">,</mo><msubsup id="S2.I2.i2.p1.1.m1.3.3.2.2" xref="S2.I2.i2.p1.1.m1.3.3.2.2.cmml"><mi id="S2.I2.i2.p1.1.m1.3.3.2.2.2.2" xref="S2.I2.i2.p1.1.m1.3.3.2.2.2.2.cmml">w</mi><mn id="S2.I2.i2.p1.1.m1.3.3.2.2.2.3" xref="S2.I2.i2.p1.1.m1.3.3.2.2.2.3.cmml">2</mn><mrow id="S2.I2.i2.p1.1.m1.3.3.2.2.3" xref="S2.I2.i2.p1.1.m1.3.3.2.2.3.cmml"><mi id="S2.I2.i2.p1.1.m1.3.3.2.2.3.2" xref="S2.I2.i2.p1.1.m1.3.3.2.2.3.2.cmml">t</mi><mo id="S2.I2.i2.p1.1.m1.3.3.2.2.3.1" xref="S2.I2.i2.p1.1.m1.3.3.2.2.3.1.cmml">+</mo><mn id="S2.I2.i2.p1.1.m1.3.3.2.2.3.3" xref="S2.I2.i2.p1.1.m1.3.3.2.2.3.3.cmml">1</mn></mrow></msubsup><mo id="S2.I2.i2.p1.1.m1.5.5.4.7" xref="S2.I2.i2.p1.1.m1.5.5.5.cmml">,</mo><msubsup id="S2.I2.i2.p1.1.m1.4.4.3.3" xref="S2.I2.i2.p1.1.m1.4.4.3.3.cmml"><mi id="S2.I2.i2.p1.1.m1.4.4.3.3.2.2" xref="S2.I2.i2.p1.1.m1.4.4.3.3.2.2.cmml">w</mi><mn id="S2.I2.i2.p1.1.m1.4.4.3.3.2.3" xref="S2.I2.i2.p1.1.m1.4.4.3.3.2.3.cmml">3</mn><mrow id="S2.I2.i2.p1.1.m1.4.4.3.3.3" xref="S2.I2.i2.p1.1.m1.4.4.3.3.3.cmml"><mi id="S2.I2.i2.p1.1.m1.4.4.3.3.3.2" xref="S2.I2.i2.p1.1.m1.4.4.3.3.3.2.cmml">t</mi><mo id="S2.I2.i2.p1.1.m1.4.4.3.3.3.1" xref="S2.I2.i2.p1.1.m1.4.4.3.3.3.1.cmml">+</mo><mn id="S2.I2.i2.p1.1.m1.4.4.3.3.3.3" xref="S2.I2.i2.p1.1.m1.4.4.3.3.3.3.cmml">2</mn></mrow></msubsup><mo id="S2.I2.i2.p1.1.m1.5.5.4.8" xref="S2.I2.i2.p1.1.m1.5.5.5.cmml">,</mo><mi mathvariant="normal" id="S2.I2.i2.p1.1.m1.1.1" xref="S2.I2.i2.p1.1.m1.1.1.cmml">…</mi><mo id="S2.I2.i2.p1.1.m1.5.5.4.9" xref="S2.I2.i2.p1.1.m1.5.5.5.cmml">,</mo><msubsup id="S2.I2.i2.p1.1.m1.5.5.4.4" xref="S2.I2.i2.p1.1.m1.5.5.4.4.cmml"><mi id="S2.I2.i2.p1.1.m1.5.5.4.4.2.2" xref="S2.I2.i2.p1.1.m1.5.5.4.4.2.2.cmml">w</mi><mi id="S2.I2.i2.p1.1.m1.5.5.4.4.2.3" xref="S2.I2.i2.p1.1.m1.5.5.4.4.2.3.cmml">k</mi><mrow id="S2.I2.i2.p1.1.m1.5.5.4.4.3" xref="S2.I2.i2.p1.1.m1.5.5.4.4.3.cmml"><mi id="S2.I2.i2.p1.1.m1.5.5.4.4.3.2" xref="S2.I2.i2.p1.1.m1.5.5.4.4.3.2.cmml">t</mi><mo id="S2.I2.i2.p1.1.m1.5.5.4.4.3.1" xref="S2.I2.i2.p1.1.m1.5.5.4.4.3.1.cmml">+</mo><mi id="S2.I2.i2.p1.1.m1.5.5.4.4.3.3" xref="S2.I2.i2.p1.1.m1.5.5.4.4.3.3.cmml">k</mi></mrow></msubsup><mo stretchy="false" id="S2.I2.i2.p1.1.m1.5.5.4.10" xref="S2.I2.i2.p1.1.m1.5.5.5.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I2.i2.p1.1.m1.5b"><set id="S2.I2.i2.p1.1.m1.5.5.5.cmml" xref="S2.I2.i2.p1.1.m1.5.5.4"><apply id="S2.I2.i2.p1.1.m1.2.2.1.1.cmml" xref="S2.I2.i2.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S2.I2.i2.p1.1.m1.2.2.1.1.1.cmml" xref="S2.I2.i2.p1.1.m1.2.2.1.1">superscript</csymbol><apply id="S2.I2.i2.p1.1.m1.2.2.1.1.2.cmml" xref="S2.I2.i2.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S2.I2.i2.p1.1.m1.2.2.1.1.2.1.cmml" xref="S2.I2.i2.p1.1.m1.2.2.1.1">subscript</csymbol><ci id="S2.I2.i2.p1.1.m1.2.2.1.1.2.2.cmml" xref="S2.I2.i2.p1.1.m1.2.2.1.1.2.2">𝑤</ci><cn type="integer" id="S2.I2.i2.p1.1.m1.2.2.1.1.2.3.cmml" xref="S2.I2.i2.p1.1.m1.2.2.1.1.2.3">1</cn></apply><ci id="S2.I2.i2.p1.1.m1.2.2.1.1.3.cmml" xref="S2.I2.i2.p1.1.m1.2.2.1.1.3">𝑡</ci></apply><apply id="S2.I2.i2.p1.1.m1.3.3.2.2.cmml" xref="S2.I2.i2.p1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S2.I2.i2.p1.1.m1.3.3.2.2.1.cmml" xref="S2.I2.i2.p1.1.m1.3.3.2.2">superscript</csymbol><apply id="S2.I2.i2.p1.1.m1.3.3.2.2.2.cmml" xref="S2.I2.i2.p1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S2.I2.i2.p1.1.m1.3.3.2.2.2.1.cmml" xref="S2.I2.i2.p1.1.m1.3.3.2.2">subscript</csymbol><ci id="S2.I2.i2.p1.1.m1.3.3.2.2.2.2.cmml" xref="S2.I2.i2.p1.1.m1.3.3.2.2.2.2">𝑤</ci><cn type="integer" id="S2.I2.i2.p1.1.m1.3.3.2.2.2.3.cmml" xref="S2.I2.i2.p1.1.m1.3.3.2.2.2.3">2</cn></apply><apply id="S2.I2.i2.p1.1.m1.3.3.2.2.3.cmml" xref="S2.I2.i2.p1.1.m1.3.3.2.2.3"><plus id="S2.I2.i2.p1.1.m1.3.3.2.2.3.1.cmml" xref="S2.I2.i2.p1.1.m1.3.3.2.2.3.1"></plus><ci id="S2.I2.i2.p1.1.m1.3.3.2.2.3.2.cmml" xref="S2.I2.i2.p1.1.m1.3.3.2.2.3.2">𝑡</ci><cn type="integer" id="S2.I2.i2.p1.1.m1.3.3.2.2.3.3.cmml" xref="S2.I2.i2.p1.1.m1.3.3.2.2.3.3">1</cn></apply></apply><apply id="S2.I2.i2.p1.1.m1.4.4.3.3.cmml" xref="S2.I2.i2.p1.1.m1.4.4.3.3"><csymbol cd="ambiguous" id="S2.I2.i2.p1.1.m1.4.4.3.3.1.cmml" xref="S2.I2.i2.p1.1.m1.4.4.3.3">superscript</csymbol><apply id="S2.I2.i2.p1.1.m1.4.4.3.3.2.cmml" xref="S2.I2.i2.p1.1.m1.4.4.3.3"><csymbol cd="ambiguous" id="S2.I2.i2.p1.1.m1.4.4.3.3.2.1.cmml" xref="S2.I2.i2.p1.1.m1.4.4.3.3">subscript</csymbol><ci id="S2.I2.i2.p1.1.m1.4.4.3.3.2.2.cmml" xref="S2.I2.i2.p1.1.m1.4.4.3.3.2.2">𝑤</ci><cn type="integer" id="S2.I2.i2.p1.1.m1.4.4.3.3.2.3.cmml" xref="S2.I2.i2.p1.1.m1.4.4.3.3.2.3">3</cn></apply><apply id="S2.I2.i2.p1.1.m1.4.4.3.3.3.cmml" xref="S2.I2.i2.p1.1.m1.4.4.3.3.3"><plus id="S2.I2.i2.p1.1.m1.4.4.3.3.3.1.cmml" xref="S2.I2.i2.p1.1.m1.4.4.3.3.3.1"></plus><ci id="S2.I2.i2.p1.1.m1.4.4.3.3.3.2.cmml" xref="S2.I2.i2.p1.1.m1.4.4.3.3.3.2">𝑡</ci><cn type="integer" id="S2.I2.i2.p1.1.m1.4.4.3.3.3.3.cmml" xref="S2.I2.i2.p1.1.m1.4.4.3.3.3.3">2</cn></apply></apply><ci id="S2.I2.i2.p1.1.m1.1.1.cmml" xref="S2.I2.i2.p1.1.m1.1.1">…</ci><apply id="S2.I2.i2.p1.1.m1.5.5.4.4.cmml" xref="S2.I2.i2.p1.1.m1.5.5.4.4"><csymbol cd="ambiguous" id="S2.I2.i2.p1.1.m1.5.5.4.4.1.cmml" xref="S2.I2.i2.p1.1.m1.5.5.4.4">superscript</csymbol><apply id="S2.I2.i2.p1.1.m1.5.5.4.4.2.cmml" xref="S2.I2.i2.p1.1.m1.5.5.4.4"><csymbol cd="ambiguous" id="S2.I2.i2.p1.1.m1.5.5.4.4.2.1.cmml" xref="S2.I2.i2.p1.1.m1.5.5.4.4">subscript</csymbol><ci id="S2.I2.i2.p1.1.m1.5.5.4.4.2.2.cmml" xref="S2.I2.i2.p1.1.m1.5.5.4.4.2.2">𝑤</ci><ci id="S2.I2.i2.p1.1.m1.5.5.4.4.2.3.cmml" xref="S2.I2.i2.p1.1.m1.5.5.4.4.2.3">𝑘</ci></apply><apply id="S2.I2.i2.p1.1.m1.5.5.4.4.3.cmml" xref="S2.I2.i2.p1.1.m1.5.5.4.4.3"><plus id="S2.I2.i2.p1.1.m1.5.5.4.4.3.1.cmml" xref="S2.I2.i2.p1.1.m1.5.5.4.4.3.1"></plus><ci id="S2.I2.i2.p1.1.m1.5.5.4.4.3.2.cmml" xref="S2.I2.i2.p1.1.m1.5.5.4.4.3.2">𝑡</ci><ci id="S2.I2.i2.p1.1.m1.5.5.4.4.3.3.cmml" xref="S2.I2.i2.p1.1.m1.5.5.4.4.3.3">𝑘</ci></apply></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i2.p1.1.m1.5c">\{w_{1}^{t},w_{2}^{t+1},w_{3}^{t+2},\dots,w_{k}^{t+k}\}</annotation></semantics></math>) does not occur concurrently. The local models are then sent back to the aggregation server separately.</p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.2" class="ltx_p">Global Model Aggregation: <span id="S2.I2.i3.p1.2.1" class="ltx_ERROR undefined">\add</span>The server aggregates the newly collected local model with the latest global model by using Eq. <a href="#S2.E2" title="In item 3 ‣ 2.1 Federated Learning ‣ 2 Background Knowledge ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S2.E2.m1.1" class="ltx_Math" alttext="w_{G}^{t+k}=\frac{w^{t+k-1}_{G}+w^{t+k}_{k}}{2}" display="block"><semantics id="S2.E2.m1.1a"><mrow id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml"><msubsup id="S2.E2.m1.1.1.2" xref="S2.E2.m1.1.1.2.cmml"><mi id="S2.E2.m1.1.1.2.2.2" xref="S2.E2.m1.1.1.2.2.2.cmml">w</mi><mi id="S2.E2.m1.1.1.2.2.3" xref="S2.E2.m1.1.1.2.2.3.cmml">G</mi><mrow id="S2.E2.m1.1.1.2.3" xref="S2.E2.m1.1.1.2.3.cmml"><mi id="S2.E2.m1.1.1.2.3.2" xref="S2.E2.m1.1.1.2.3.2.cmml">t</mi><mo id="S2.E2.m1.1.1.2.3.1" xref="S2.E2.m1.1.1.2.3.1.cmml">+</mo><mi id="S2.E2.m1.1.1.2.3.3" xref="S2.E2.m1.1.1.2.3.3.cmml">k</mi></mrow></msubsup><mo id="S2.E2.m1.1.1.1" xref="S2.E2.m1.1.1.1.cmml">=</mo><mfrac id="S2.E2.m1.1.1.3" xref="S2.E2.m1.1.1.3.cmml"><mrow id="S2.E2.m1.1.1.3.2" xref="S2.E2.m1.1.1.3.2.cmml"><msubsup id="S2.E2.m1.1.1.3.2.2" xref="S2.E2.m1.1.1.3.2.2.cmml"><mi id="S2.E2.m1.1.1.3.2.2.2.2" xref="S2.E2.m1.1.1.3.2.2.2.2.cmml">w</mi><mi id="S2.E2.m1.1.1.3.2.2.3" xref="S2.E2.m1.1.1.3.2.2.3.cmml">G</mi><mrow id="S2.E2.m1.1.1.3.2.2.2.3" xref="S2.E2.m1.1.1.3.2.2.2.3.cmml"><mrow id="S2.E2.m1.1.1.3.2.2.2.3.2" xref="S2.E2.m1.1.1.3.2.2.2.3.2.cmml"><mi id="S2.E2.m1.1.1.3.2.2.2.3.2.2" xref="S2.E2.m1.1.1.3.2.2.2.3.2.2.cmml">t</mi><mo id="S2.E2.m1.1.1.3.2.2.2.3.2.1" xref="S2.E2.m1.1.1.3.2.2.2.3.2.1.cmml">+</mo><mi id="S2.E2.m1.1.1.3.2.2.2.3.2.3" xref="S2.E2.m1.1.1.3.2.2.2.3.2.3.cmml">k</mi></mrow><mo id="S2.E2.m1.1.1.3.2.2.2.3.1" xref="S2.E2.m1.1.1.3.2.2.2.3.1.cmml">−</mo><mn id="S2.E2.m1.1.1.3.2.2.2.3.3" xref="S2.E2.m1.1.1.3.2.2.2.3.3.cmml">1</mn></mrow></msubsup><mo id="S2.E2.m1.1.1.3.2.1" xref="S2.E2.m1.1.1.3.2.1.cmml">+</mo><msubsup id="S2.E2.m1.1.1.3.2.3" xref="S2.E2.m1.1.1.3.2.3.cmml"><mi id="S2.E2.m1.1.1.3.2.3.2.2" xref="S2.E2.m1.1.1.3.2.3.2.2.cmml">w</mi><mi id="S2.E2.m1.1.1.3.2.3.3" xref="S2.E2.m1.1.1.3.2.3.3.cmml">k</mi><mrow id="S2.E2.m1.1.1.3.2.3.2.3" xref="S2.E2.m1.1.1.3.2.3.2.3.cmml"><mi id="S2.E2.m1.1.1.3.2.3.2.3.2" xref="S2.E2.m1.1.1.3.2.3.2.3.2.cmml">t</mi><mo id="S2.E2.m1.1.1.3.2.3.2.3.1" xref="S2.E2.m1.1.1.3.2.3.2.3.1.cmml">+</mo><mi id="S2.E2.m1.1.1.3.2.3.2.3.3" xref="S2.E2.m1.1.1.3.2.3.2.3.3.cmml">k</mi></mrow></msubsup></mrow><mn id="S2.E2.m1.1.1.3.3" xref="S2.E2.m1.1.1.3.3.cmml">2</mn></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.1b"><apply id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1"><eq id="S2.E2.m1.1.1.1.cmml" xref="S2.E2.m1.1.1.1"></eq><apply id="S2.E2.m1.1.1.2.cmml" xref="S2.E2.m1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.2.1.cmml" xref="S2.E2.m1.1.1.2">superscript</csymbol><apply id="S2.E2.m1.1.1.2.2.cmml" xref="S2.E2.m1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.2.2.1.cmml" xref="S2.E2.m1.1.1.2">subscript</csymbol><ci id="S2.E2.m1.1.1.2.2.2.cmml" xref="S2.E2.m1.1.1.2.2.2">𝑤</ci><ci id="S2.E2.m1.1.1.2.2.3.cmml" xref="S2.E2.m1.1.1.2.2.3">𝐺</ci></apply><apply id="S2.E2.m1.1.1.2.3.cmml" xref="S2.E2.m1.1.1.2.3"><plus id="S2.E2.m1.1.1.2.3.1.cmml" xref="S2.E2.m1.1.1.2.3.1"></plus><ci id="S2.E2.m1.1.1.2.3.2.cmml" xref="S2.E2.m1.1.1.2.3.2">𝑡</ci><ci id="S2.E2.m1.1.1.2.3.3.cmml" xref="S2.E2.m1.1.1.2.3.3">𝑘</ci></apply></apply><apply id="S2.E2.m1.1.1.3.cmml" xref="S2.E2.m1.1.1.3"><divide id="S2.E2.m1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.3"></divide><apply id="S2.E2.m1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.3.2"><plus id="S2.E2.m1.1.1.3.2.1.cmml" xref="S2.E2.m1.1.1.3.2.1"></plus><apply id="S2.E2.m1.1.1.3.2.2.cmml" xref="S2.E2.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.3.2.2.1.cmml" xref="S2.E2.m1.1.1.3.2.2">subscript</csymbol><apply id="S2.E2.m1.1.1.3.2.2.2.cmml" xref="S2.E2.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.3.2.2.2.1.cmml" xref="S2.E2.m1.1.1.3.2.2">superscript</csymbol><ci id="S2.E2.m1.1.1.3.2.2.2.2.cmml" xref="S2.E2.m1.1.1.3.2.2.2.2">𝑤</ci><apply id="S2.E2.m1.1.1.3.2.2.2.3.cmml" xref="S2.E2.m1.1.1.3.2.2.2.3"><minus id="S2.E2.m1.1.1.3.2.2.2.3.1.cmml" xref="S2.E2.m1.1.1.3.2.2.2.3.1"></minus><apply id="S2.E2.m1.1.1.3.2.2.2.3.2.cmml" xref="S2.E2.m1.1.1.3.2.2.2.3.2"><plus id="S2.E2.m1.1.1.3.2.2.2.3.2.1.cmml" xref="S2.E2.m1.1.1.3.2.2.2.3.2.1"></plus><ci id="S2.E2.m1.1.1.3.2.2.2.3.2.2.cmml" xref="S2.E2.m1.1.1.3.2.2.2.3.2.2">𝑡</ci><ci id="S2.E2.m1.1.1.3.2.2.2.3.2.3.cmml" xref="S2.E2.m1.1.1.3.2.2.2.3.2.3">𝑘</ci></apply><cn type="integer" id="S2.E2.m1.1.1.3.2.2.2.3.3.cmml" xref="S2.E2.m1.1.1.3.2.2.2.3.3">1</cn></apply></apply><ci id="S2.E2.m1.1.1.3.2.2.3.cmml" xref="S2.E2.m1.1.1.3.2.2.3">𝐺</ci></apply><apply id="S2.E2.m1.1.1.3.2.3.cmml" xref="S2.E2.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.3.2.3.1.cmml" xref="S2.E2.m1.1.1.3.2.3">subscript</csymbol><apply id="S2.E2.m1.1.1.3.2.3.2.cmml" xref="S2.E2.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.3.2.3.2.1.cmml" xref="S2.E2.m1.1.1.3.2.3">superscript</csymbol><ci id="S2.E2.m1.1.1.3.2.3.2.2.cmml" xref="S2.E2.m1.1.1.3.2.3.2.2">𝑤</ci><apply id="S2.E2.m1.1.1.3.2.3.2.3.cmml" xref="S2.E2.m1.1.1.3.2.3.2.3"><plus id="S2.E2.m1.1.1.3.2.3.2.3.1.cmml" xref="S2.E2.m1.1.1.3.2.3.2.3.1"></plus><ci id="S2.E2.m1.1.1.3.2.3.2.3.2.cmml" xref="S2.E2.m1.1.1.3.2.3.2.3.2">𝑡</ci><ci id="S2.E2.m1.1.1.3.2.3.2.3.3.cmml" xref="S2.E2.m1.1.1.3.2.3.2.3.3">𝑘</ci></apply></apply><ci id="S2.E2.m1.1.1.3.2.3.3.cmml" xref="S2.E2.m1.1.1.3.2.3.3">𝑘</ci></apply></apply><cn type="integer" id="S2.E2.m1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.1c">w_{G}^{t+k}=\frac{w^{t+k-1}_{G}+w^{t+k}_{k}}{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.I2.i3.p1.1" class="ltx_p">Following this process, the global model <math id="S2.I2.i3.p1.1.m1.1" class="ltx_Math" alttext="w_{G}^{t+k}" display="inline"><semantics id="S2.I2.i3.p1.1.m1.1a"><msubsup id="S2.I2.i3.p1.1.m1.1.1" xref="S2.I2.i3.p1.1.m1.1.1.cmml"><mi id="S2.I2.i3.p1.1.m1.1.1.2.2" xref="S2.I2.i3.p1.1.m1.1.1.2.2.cmml">w</mi><mi id="S2.I2.i3.p1.1.m1.1.1.2.3" xref="S2.I2.i3.p1.1.m1.1.1.2.3.cmml">G</mi><mrow id="S2.I2.i3.p1.1.m1.1.1.3" xref="S2.I2.i3.p1.1.m1.1.1.3.cmml"><mi id="S2.I2.i3.p1.1.m1.1.1.3.2" xref="S2.I2.i3.p1.1.m1.1.1.3.2.cmml">t</mi><mo id="S2.I2.i3.p1.1.m1.1.1.3.1" xref="S2.I2.i3.p1.1.m1.1.1.3.1.cmml">+</mo><mi id="S2.I2.i3.p1.1.m1.1.1.3.3" xref="S2.I2.i3.p1.1.m1.1.1.3.3.cmml">k</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.I2.i3.p1.1.m1.1b"><apply id="S2.I2.i3.p1.1.m1.1.1.cmml" xref="S2.I2.i3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I2.i3.p1.1.m1.1.1.1.cmml" xref="S2.I2.i3.p1.1.m1.1.1">superscript</csymbol><apply id="S2.I2.i3.p1.1.m1.1.1.2.cmml" xref="S2.I2.i3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I2.i3.p1.1.m1.1.1.2.1.cmml" xref="S2.I2.i3.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I2.i3.p1.1.m1.1.1.2.2.cmml" xref="S2.I2.i3.p1.1.m1.1.1.2.2">𝑤</ci><ci id="S2.I2.i3.p1.1.m1.1.1.2.3.cmml" xref="S2.I2.i3.p1.1.m1.1.1.2.3">𝐺</ci></apply><apply id="S2.I2.i3.p1.1.m1.1.1.3.cmml" xref="S2.I2.i3.p1.1.m1.1.1.3"><plus id="S2.I2.i3.p1.1.m1.1.1.3.1.cmml" xref="S2.I2.i3.p1.1.m1.1.1.3.1"></plus><ci id="S2.I2.i3.p1.1.m1.1.1.3.2.cmml" xref="S2.I2.i3.p1.1.m1.1.1.3.2">𝑡</ci><ci id="S2.I2.i3.p1.1.m1.1.1.3.3.cmml" xref="S2.I2.i3.p1.1.m1.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i3.p1.1.m1.1c">w_{G}^{t+k}</annotation></semantics></math> becomes available to the nodes and serves for their next iteration of local model training.</p>
</div>
</li>
</ol>
</div>
<div id="S2.SS1.p7" class="ltx_para">
<span id="S2.SS1.p7.3" class="ltx_ERROR undefined">\add</span>
<p id="S2.SS1.p7.2" class="ltx_p">The iteration count in AFL, denoted as <math id="S2.SS1.p7.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p7.1.m1.1a"><mi id="S2.SS1.p7.1.m1.1.1" xref="S2.SS1.p7.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p7.1.m1.1b"><ci id="S2.SS1.p7.1.m1.1.1.cmml" xref="S2.SS1.p7.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p7.1.m1.1c">t</annotation></semantics></math>, increases by <math id="S2.SS1.p7.2.m2.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S2.SS1.p7.2.m2.1a"><mn id="S2.SS1.p7.2.m2.1.1" xref="S2.SS1.p7.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p7.2.m2.1b"><cn type="integer" id="S2.SS1.p7.2.m2.1.1.cmml" xref="S2.SS1.p7.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p7.2.m2.1c">1</annotation></semantics></math> upon the completion of one iteration of local training by a device. The immediate model aggregation strategy in AFL reduces the waiting time for aggregation and thereby improves overall efficiency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Blockchain</h3>

<div id="S2.SS2.p1" class="ltx_para">
<span id="S2.SS2.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S2.SS2.p1.2" class="ltx_p">Blockchain, the backbone of Bitcoin <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, is a distributed ledger technology (DLT) that sustains the uniformity and immutability of transactional data across various nodes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. In blockchain, nodes are responsible for maintaining the shared ledger and executing a globally unified program referred to as the smart contract. The self-verifiability and tamper-resistant attributes of the smart contract ensure the security and reliability of the shared ledger. Every node carries out the validation and execution of received transactions via the smart contract. Upon consensus attainment through the consensus algorithm, all nodes arrange transactional data into blocks and append these blocks to the shared ledger. Proof of Work (PoW) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, Proof of Stake (PoS) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, and PBFT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> stand as the three most prevalent consensus algorithms. Generally, a consensus algorithm with better security or fault tolerance tends to have diminished efficiency.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Blockchain is typically treated as a distributed database for saving the models generated during the training process. Some researchers also utilize the reputation system of blockchain to motivate nodes to contribute their local models. <span id="S2.SS2.p2.1.1" class="ltx_ERROR undefined">\add</span>In the context of AFL, blockchain yields multiple advantages. Firstly, the immutability of shared ledgers prevents malicious node behavior, such as uploading plagiarized updated gradients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. Secondly, the consensus algorithm fosters trust between unfamiliar devices, given the decentralized and unmanipulable nature of the aggregation process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. Thirdly, the smart contract validates the authenticity of models and nodes, thus deterring malicious nodes from introducing poisoned gradients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. Fourthly, the decentralized aggregation strategy on the blockchain helps the aggregation server to resist DDoS attacks and reduces the risk of single-point failures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. However, the adoption of blockchain in AFL entails trade-offs in scalability and efficiency to a certain degree.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Differential Privacy</h3>

<div id="S2.SS3.p1" class="ltx_para">
<span id="S2.SS3.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S2.SS3.p1.2" class="ltx_p">Differential privacy is a privacy-preserving technique that has experienced fast growth for over ten years. Originating from the concept of differential attack, differential privacy entails concealing a solitary sensitive data point within a particular dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. The central objective of differential privacy is to render each data point non-discriminatory while upholding specific statistical attributes required for data analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<span id="S2.SS3.p2.2" class="ltx_ERROR undefined">\add</span>
<p id="S2.SS3.p2.1" class="ltx_p">Various differential privacy mechanisms have been created, each serving a crucial role in its specific application context. Prominent among these are the Laplace mechanism <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, exponential mechanism <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, and Gaussian mechanism <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. By infusing controllable randomized noise, differential privacy is able to return sanitized and privacy-preserving responses to data requesters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. However, this data sanitization process in differential privacy comes at the cost of diminishing data utility <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Thus, a parameter known as the privacy budget (<math id="S2.SS3.p2.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S2.SS3.p2.1.m1.1a"><mi id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><ci id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">\epsilon</annotation></semantics></math>) is introduced to measure the balance between privacy protection and data utility.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<span id="S2.SS3.p3.1" class="ltx_ERROR undefined">\add</span>
<p id="S2.SS3.p3.2" class="ltx_p">To cater to the requirements of flexible privacy protection in practical scenarios, personalized privacy protection models have been introduced. From this perspective, an index (e.g. social distance within social networks) is introduced to determine the level of personalized privacy protection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. By fine-tuning personalized parameters, the data utility could be improved further <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>.</p>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<span id="S2.SS3.p4.1" class="ltx_ERROR undefined">\add</span>
<p id="S2.SS3.p4.2" class="ltx_p">While being efficient and scalable, differential privacy encounters the challenge of diminished data utility, especially when the introduced noise is subject to randomization and lacks proper control <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. Given that the training process in federated learning (FL) typically involves numerous local devices, sometimes numbering in the dozens or even thousands, these concerns can be mitigated by setting the mean value of the Laplace distribution to zero <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>. Consequently, differential privacy has a great potential to be applied in FL or even AFL.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Device Heterogeneity</h2>

<div id="S3.p1" class="ltx_para">
<span id="S3.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.p1.2" class="ltx_p">The primary obstacle of AFL revolves around optimizing resource utilization across heterogeneous devices to enhance training efficiency. Concurrently, there exists the obstacle of stale local models resulting from device heterogeneity, a factor that is detrimental to the performance of the global model. The present study encapsulates several dimensions, encompassing node selection, weighted aggregation, gradient compression, semi-asynchronous FL, cluster FL, and model splitting. A comprehensive overview and comparison of the related work are presented in Table <a href="#S3.T2" title="Table 2 ‣ 3 Device Heterogeneity ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Improve Model Performance on Heterogeneous Devices</figcaption>
<table id="S3.T2.3" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T2.3.1.1" class="ltx_tr">
<td id="S3.T2.3.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.1.1.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Ref.<span id="footnotex2" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex2.1.1.1" class="ltx_text ltx_font_medium" style="font-size:125%;">1</span></span></span></span></span></span></td>
<td id="S3.T2.3.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.1.1.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.1.1.3.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Detail</span></span>
</span>
</td>
<td id="S3.T2.3.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Data Dist.<span id="footnotex3" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex3.1.1.1" class="ltx_text ltx_font_medium" style="font-size:125%;">2</span></span></span></span></span></span></td>
<td id="S3.T2.3.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.1.1.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.1.1.5.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Model &amp; Dataset</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.2.2" class="ltx_tr">
<td id="S3.T2.3.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.2.2.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.2.2.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib46" title="" class="ltx_ref">46</a><span id="S3.T2.3.2.2.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.2.2.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.2.2.3.1.1.1" class="ltx_text" style="font-size:80%;">Heuristic greedy node selection according to local computation and communication resources.</span></span>
</span>
</td>
<td id="S3.T2.3.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.2.2.4.1" class="ltx_text" style="font-size:80%;">H, I, N</span></td>
<td id="S3.T2.3.2.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.2.2.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.2.2.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN &amp; MNIST </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.2.2.5.1.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib25" title="" class="ltx_ref">25</a><span id="S3.T2.3.2.2.5.1.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S3.T2.3.2.2.5.1.1.4" class="ltx_text" style="font-size:80%;">, FMNIST </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.2.2.5.1.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib47" title="" class="ltx_ref">47</a><span id="S3.T2.3.2.2.5.1.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S3.T2.3.2.2.5.1.1.7" class="ltx_text" style="font-size:80%;">, EMNIST </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.2.2.5.1.1.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib48" title="" class="ltx_ref">48</a><span id="S3.T2.3.2.2.5.1.1.9.2" class="ltx_text" style="font-size:80%;">]</span></cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.3.3" class="ltx_tr">
<td id="S3.T2.3.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.3.3.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.3.3.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib49" title="" class="ltx_ref">49</a><span id="S3.T2.3.3.3.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.3.3.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.3.3.3.1.1.1" class="ltx_text" style="font-size:80%;">Limit the number of devices training together.</span></span>
</span>
</td>
<td id="S3.T2.3.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.3.3.4.1" class="ltx_text" style="font-size:80%;">H, I, N</span></td>
<td id="S3.T2.3.3.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.3.3.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.3.3.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN &amp; FMNIST</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.4.4" class="ltx_tr">
<td id="S3.T2.3.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.4.4.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.4.4.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib50" title="" class="ltx_ref">50</a><span id="S3.T2.3.4.4.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.4.4.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.4.4.3.1.1.1" class="ltx_text" style="font-size:80%;">A prioritized node-selection function based on computing power and accuracy change.</span></span>
</span>
</td>
<td id="S3.T2.3.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.4.4.4.1" class="ltx_text" style="font-size:80%;">H, I, N</span></td>
<td id="S3.T2.3.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.4.4.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.4.4.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN &amp; MNIST, FMNIST, CIFAR10 </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.4.4.5.1.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib25" title="" class="ltx_ref">25</a><span id="S3.T2.3.4.4.5.1.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.5.5" class="ltx_tr">
<td id="S3.T2.3.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.5.5.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.5.5.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib51" title="" class="ltx_ref">51</a><span id="S3.T2.3.5.5.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.5.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.5.5.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.5.5.3.1.1.1" class="ltx_text" style="font-size:80%;">Assign a trust score to each node based on its activities.</span></span>
</span>
</td>
<td id="S3.T2.3.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.5.5.4.1" class="ltx_text" style="font-size:80%;">H, I, N</span></td>
<td id="S3.T2.3.5.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.5.5.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.5.5.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN &amp; MNIST</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.6.6" class="ltx_tr">
<td id="S3.T2.3.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.6.6.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.6.6.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib21" title="" class="ltx_ref">21</a><span id="S3.T2.3.6.6.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.6.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.6.6.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.6.6.3.1.1.1" class="ltx_text" style="font-size:80%;">Select nodes with a lower crash probability.</span></span>
</span>
</td>
<td id="S3.T2.3.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.6.6.4.1" class="ltx_text" style="font-size:80%;">H, I</span></td>
<td id="S3.T2.3.6.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.6.6.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.6.6.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN, SVM &amp; Boston </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.6.6.5.1.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib52" title="" class="ltx_ref">52</a><span id="S3.T2.3.6.6.5.1.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S3.T2.3.6.6.5.1.1.4" class="ltx_text" style="font-size:80%;">, MNIST, KDD Cup ’99 </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.6.6.5.1.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib53" title="" class="ltx_ref">53</a><span id="S3.T2.3.6.6.5.1.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.7.7" class="ltx_tr">
<td id="S3.T2.3.7.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.7.7.1.1.1" class="ltx_p" style="width:26.0pt;"><span id="S3.T2.3.7.7.1.1.1.1" class="ltx_text" style="font-size:80%;">
<span id="S3.T2.3.7.7.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:5.6pt;height:52pt;vertical-align:-23.2pt;"><span class="ltx_transformed_inner" style="width:52.0pt;transform:translate(-23.22pt,0pt) rotate(-90deg) ;">
<span id="S3.T2.3.7.7.1.1.1.1.1.1" class="ltx_p">Node Selection</span>
</span></span></span></span>
</span>
</td>
<td id="S3.T2.3.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.7.7.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib54" title="" class="ltx_ref">54</a><span id="S3.T2.3.7.7.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.7.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.7.7.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.7.7.3.1.1.1" class="ltx_text" style="font-size:80%;">Random, significance-based, and frequency-based scheduling are analyzed.</span></span>
</span>
</td>
<td id="S3.T2.3.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.7.7.4.1" class="ltx_text" style="font-size:80%;">H, I, N</span></td>
<td id="S3.T2.3.7.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.7.7.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.7.7.5.1.1.1" class="ltx_text" style="font-size:80%;">MNIST</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.8.8" class="ltx_tr">
<td id="S3.T2.3.8.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.8.8.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.8.8.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib55" title="" class="ltx_ref">55</a><span id="S3.T2.3.8.8.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.8.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.8.8.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.8.8.3.1.1.1" class="ltx_text" style="font-size:80%;">A mixing hyperparameter that balances the convergence rate with variance reduction according to the staleness.</span></span>
</span>
</td>
<td id="S3.T2.3.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.8.8.4.1" class="ltx_text" style="font-size:80%;">H, N</span></td>
<td id="S3.T2.3.8.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.8.8.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.8.8.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN &amp; CIFAR10, WikiText-2 </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.8.8.5.1.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib56" title="" class="ltx_ref">56</a><span id="S3.T2.3.8.8.5.1.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.9.9" class="ltx_tr">
<td id="S3.T2.3.9.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.9.9.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.9.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.9.9.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib57" title="" class="ltx_ref">57</a><span id="S3.T2.3.9.9.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.9.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.9.9.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.9.9.3.1.1.1" class="ltx_text" style="font-size:80%;">Increase the weight of recently updated local models.</span></span>
</span>
</td>
<td id="S3.T2.3.9.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.9.9.4.1" class="ltx_text" style="font-size:80%;">H, N</span></td>
<td id="S3.T2.3.9.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.9.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.9.9.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.9.9.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN, LSTM &amp; MNIST, HAR </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.9.9.5.1.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib58" title="" class="ltx_ref">58</a><span id="S3.T2.3.9.9.5.1.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.10.10" class="ltx_tr">
<td id="S3.T2.3.10.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.10.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.10.10.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.10.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.10.10.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib59" title="" class="ltx_ref">59</a><span id="S3.T2.3.10.10.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.10.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.10.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.10.10.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.10.10.3.1.1.1" class="ltx_text" style="font-size:80%;">The weight assigned to the updated gradients decreases as the staleness value increases.</span></span>
</span>
</td>
<td id="S3.T2.3.10.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.10.10.4.1" class="ltx_text" style="font-size:80%;">H, I, N</span></td>
<td id="S3.T2.3.10.10.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.10.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.10.10.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.10.10.5.1.1.1" class="ltx_text" style="font-size:80%;">MLP &amp; MNIST</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.11.11" class="ltx_tr">
<td id="S3.T2.3.11.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.11.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.11.11.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.11.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.11.11.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib49" title="" class="ltx_ref">49</a><span id="S3.T2.3.11.11.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.11.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.11.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.11.11.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.11.11.3.1.1.1" class="ltx_text" style="font-size:80%;">A caching mechanism with weighted averaging according to the staleness of the model.</span></span>
</span>
</td>
<td id="S3.T2.3.11.11.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.11.11.4.1" class="ltx_text" style="font-size:80%;">H, I, N</span></td>
<td id="S3.T2.3.11.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.11.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.11.11.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.11.11.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN &amp; FMNIST</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.12.12" class="ltx_tr">
<td id="S3.T2.3.12.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.12.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.12.12.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.12.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.12.12.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib60" title="" class="ltx_ref">60</a><span id="S3.T2.3.12.12.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.12.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.12.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.12.12.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.12.12.3.1.1.1" class="ltx_text" style="font-size:80%;">A decay coefficient that is responsible for balancing the previous and the current model.</span></span>
</span>
</td>
<td id="S3.T2.3.12.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.12.12.4.1" class="ltx_text" style="font-size:80%;">H, N</span></td>
<td id="S3.T2.3.12.12.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.12.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.12.12.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.12.12.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN, LSTM &amp; FMNIST, FitRec </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.12.12.5.1.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib61" title="" class="ltx_ref">61</a><span id="S3.T2.3.12.12.5.1.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S3.T2.3.12.12.5.1.1.4" class="ltx_text" style="font-size:80%;">, Air Qlt. </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.12.12.5.1.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib62" title="" class="ltx_ref">62</a><span id="S3.T2.3.12.12.5.1.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S3.T2.3.12.12.5.1.1.7" class="ltx_text" style="font-size:80%;">, ExtraSensory </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.12.12.5.1.1.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib63" title="" class="ltx_ref">63</a><span id="S3.T2.3.12.12.5.1.1.9.2" class="ltx_text" style="font-size:80%;">]</span></cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.13.13" class="ltx_tr">
<td id="S3.T2.3.13.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.13.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.13.13.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.13.13.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.13.13.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib64" title="" class="ltx_ref">64</a><span id="S3.T2.3.13.13.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.13.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.13.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.13.13.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.13.13.3.1.1.1" class="ltx_text" style="font-size:80%;">A duel-weighted gradient update scheme.</span></span>
</span>
</td>
<td id="S3.T2.3.13.13.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.13.13.4.1" class="ltx_text" style="font-size:80%;">H, I</span></td>
<td id="S3.T2.3.13.13.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.13.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.13.13.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.13.13.5.1.1.1" class="ltx_text" style="font-size:80%;">MLP, CNN &amp; MNIST, CIFAR10</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.14.14" class="ltx_tr">
<td id="S3.T2.3.14.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.14.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.14.14.1.1.1" class="ltx_p" style="width:26.0pt;"><span id="S3.T2.3.14.14.1.1.1.1" class="ltx_text" style="font-size:80%;">
<span id="S3.T2.3.14.14.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:7.1pt;height:77.8pt;vertical-align:-36.9pt;"><span class="ltx_transformed_inner" style="width:77.8pt;transform:translate(-35.34pt,2.33pt) rotate(-90deg) ;">
<span id="S3.T2.3.14.14.1.1.1.1.1.1" class="ltx_p">Weighted Aggregation</span>
</span></span></span></span>
</span>
</td>
<td id="S3.T2.3.14.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.14.14.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib65" title="" class="ltx_ref">65</a><span id="S3.T2.3.14.14.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.14.14.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.14.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.14.14.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.14.14.3.1.1.1" class="ltx_text" style="font-size:80%;">Dynamically adjust aggregation weight of branches based on accuracy.</span></span>
</span>
</td>
<td id="S3.T2.3.14.14.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.14.14.4.1" class="ltx_text" style="font-size:80%;">H, I</span></td>
<td id="S3.T2.3.14.14.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.14.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.14.14.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.14.14.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN, MBNN &amp; Bearing </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.14.14.5.1.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib66" title="" class="ltx_ref">66</a><span id="S3.T2.3.14.14.5.1.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S3.T2.3.14.14.5.1.1.4" class="ltx_text" style="font-size:80%;">, Gear Fault </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.14.14.5.1.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib67" title="" class="ltx_ref">67</a><span id="S3.T2.3.14.14.5.1.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.15.15" class="ltx_tr">
<td id="S3.T2.3.15.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.15.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.15.15.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.15.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.15.15.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib68" title="" class="ltx_ref">68</a><span id="S3.T2.3.15.15.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.15.15.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.15.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.15.15.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.15.15.3.1.1.1" class="ltx_text" style="font-size:80%;">Self-adaptive threshold computation and gradient communication compression.</span></span>
</span>
</td>
<td id="S3.T2.3.15.15.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.15.15.4.1" class="ltx_text" style="font-size:80%;">H, I</span></td>
<td id="S3.T2.3.15.15.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.15.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.15.15.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.15.15.5.1.1.1" class="ltx_text" style="font-size:80%;">MLP &amp; MNIST</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.16.16" class="ltx_tr">
<td id="S3.T2.3.16.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.16.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.16.16.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.16.16.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.16.16.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib69" title="" class="ltx_ref">69</a><span id="S3.T2.3.16.16.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.16.16.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.16.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.16.16.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.16.16.3.1.1.1" class="ltx_text" style="font-size:80%;">A double-end sparse compression based on Top-K AllReduce sparse compression.</span></span>
</span>
</td>
<td id="S3.T2.3.16.16.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.16.16.4.1" class="ltx_text" style="font-size:80%;">H, I</span></td>
<td id="S3.T2.3.16.16.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.16.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.16.16.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.16.16.5.1.1.1" class="ltx_text" style="font-size:80%;">LR, MLP &amp; Insurance </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.16.16.5.1.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib70" title="" class="ltx_ref">70</a><span id="S3.T2.3.16.16.5.1.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S3.T2.3.16.16.5.1.1.4" class="ltx_text" style="font-size:80%;">, Credit Card </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.16.16.5.1.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib71" title="" class="ltx_ref">71</a><span id="S3.T2.3.16.16.5.1.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.17.17" class="ltx_tr">
<td id="S3.T2.3.17.17.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.17.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.17.17.1.1.1" class="ltx_p" style="width:26.0pt;"><span id="S3.T2.3.17.17.1.1.1.1" class="ltx_text" style="font-size:80%;">
<span id="S3.T2.3.17.17.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:17.3pt;height:57pt;vertical-align:-25.7pt;"><span class="ltx_transformed_inner" style="width:56.9pt;transform:translate(-19.78pt,8.81pt) rotate(-90deg) ;">
<span id="S3.T2.3.17.17.1.1.1.1.1.1" class="ltx_p ltx_parbox ltx_align_middle" style="width:56.9pt;">Gradient Compression</span>
</span></span></span></span>
</span>
</td>
<td id="S3.T2.3.17.17.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.17.17.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib72" title="" class="ltx_ref">72</a><span id="S3.T2.3.17.17.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.17.17.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.17.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.17.17.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.17.17.3.1.1.1" class="ltx_text" style="font-size:80%;">Three transmission scheduling algorithms for stragglers under different circumstances.</span></span>
</span>
</td>
<td id="S3.T2.3.17.17.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.17.17.4.1" class="ltx_text" style="font-size:80%;">H, I</span></td>
<td id="S3.T2.3.17.17.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.17.17.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.17.17.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.17.17.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN &amp; MNIST, CIFAR10</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.18.18" class="ltx_tr">
<td id="S3.T2.3.18.18.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.18.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.18.18.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.18.18.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.18.18.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib50" title="" class="ltx_ref">50</a><span id="S3.T2.3.18.18.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.18.18.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.18.18.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.18.18.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.18.18.3.1.1.1" class="ltx_text" style="font-size:80%;">Local models on unselected nodes will be cached for several iterations before uploading.</span></span>
</span>
</td>
<td id="S3.T2.3.18.18.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.18.18.4.1" class="ltx_text" style="font-size:80%;">H, I, N</span></td>
<td id="S3.T2.3.18.18.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.18.18.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.18.18.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.18.18.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN &amp; MNIST, FMNIST, CIFAR10</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.19.19" class="ltx_tr">
<td id="S3.T2.3.19.19.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.19.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.19.19.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.19.19.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.19.19.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib21" title="" class="ltx_ref">21</a><span id="S3.T2.3.19.19.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.19.19.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.19.19.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.19.19.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.19.19.3.1.1.1" class="ltx_text" style="font-size:80%;">Nodes are classified into three classes with tolerable nodes working asynchronously.</span></span>
</span>
</td>
<td id="S3.T2.3.19.19.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.19.19.4.1" class="ltx_text" style="font-size:80%;">H, I</span></td>
<td id="S3.T2.3.19.19.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.19.19.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.19.19.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.19.19.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN, SVM &amp; Boston, MNIST, KDD Cup ’99</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.20.20" class="ltx_tr">
<td id="S3.T2.3.20.20.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.20.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.20.20.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.20.20.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.20.20.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib28" title="" class="ltx_ref">28</a><span id="S3.T2.3.20.20.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.20.20.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.20.20.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.20.20.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.20.20.3.1.1.1" class="ltx_text" style="font-size:80%;">A private buffer on the aggregation server.</span></span>
</span>
</td>
<td id="S3.T2.3.20.20.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.20.20.4.1" class="ltx_text" style="font-size:80%;">H, N</span></td>
<td id="S3.T2.3.20.20.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.20.20.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.20.20.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.20.20.5.1.1.1" class="ltx_text" style="font-size:80%;">LSTM, CNN &amp; Sent140 </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.20.20.5.1.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib73" title="" class="ltx_ref">73</a><span id="S3.T2.3.20.20.5.1.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S3.T2.3.20.20.5.1.1.4" class="ltx_text" style="font-size:80%;">, CelebA </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.20.20.5.1.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib74" title="" class="ltx_ref">74</a><span id="S3.T2.3.20.20.5.1.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.21.21" class="ltx_tr">
<td id="S3.T2.3.21.21.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.21.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.21.21.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.21.21.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.21.21.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib75" title="" class="ltx_ref">75</a><span id="S3.T2.3.21.21.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.21.21.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.21.21.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.21.21.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.21.21.3.1.1.1" class="ltx_text" style="font-size:80%;">The aggregation time interval depends on the slowest node.</span></span>
</span>
</td>
<td id="S3.T2.3.21.21.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.21.21.4.1" class="ltx_text" style="font-size:80%;">H, I, N</span></td>
<td id="S3.T2.3.21.21.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.21.21.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.21.21.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.21.21.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN &amp; CIFAR10, CIFAR100</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.22.22" class="ltx_tr">
<td id="S3.T2.3.22.22.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.22.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.22.22.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.22.22.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.22.22.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib59" title="" class="ltx_ref">59</a><span id="S3.T2.3.22.22.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.22.22.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.22.22.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.22.22.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.22.22.3.1.1.1" class="ltx_text" style="font-size:80%;">The local models received in a time window are cached.</span></span>
</span>
</td>
<td id="S3.T2.3.22.22.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.22.22.4.1" class="ltx_text" style="font-size:80%;">H, I, N</span></td>
<td id="S3.T2.3.22.22.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.22.22.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.22.22.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.22.22.5.1.1.1" class="ltx_text" style="font-size:80%;">MLP &amp; MNIST</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.23.23" class="ltx_tr">
<td id="S3.T2.3.23.23.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.23.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.23.23.1.1.1" class="ltx_p" style="width:26.0pt;"><span id="S3.T2.3.23.23.1.1.1.1" class="ltx_text" style="font-size:80%;">
<span id="S3.T2.3.23.23.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:7.1pt;height:68.4pt;vertical-align:-32.2pt;"><span class="ltx_transformed_inner" style="width:68.3pt;transform:translate(-30.61pt,2.33pt) rotate(-90deg) ;">
<span id="S3.T2.3.23.23.1.1.1.1.1.1" class="ltx_p">Semi-Asynchronous</span>
</span></span></span></span>
</span>
</td>
<td id="S3.T2.3.23.23.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.23.23.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib76" title="" class="ltx_ref">76</a><span id="S3.T2.3.23.23.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.23.23.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.23.23.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.23.23.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.23.23.3.1.1.1" class="ltx_text" style="font-size:80%;">The server stores local models in a buffer of size K.</span></span>
</span>
</td>
<td id="S3.T2.3.23.23.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.23.23.4.1" class="ltx_text" style="font-size:80%;">H, I</span></td>
<td id="S3.T2.3.23.23.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.23.23.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.23.23.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.23.23.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN &amp; MNIST, CIFAR10</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.24.24" class="ltx_tr">
<td id="S3.T2.3.24.24.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.24.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.24.24.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.24.24.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.24.24.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib77" title="" class="ltx_ref">77</a><span id="S3.T2.3.24.24.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.24.24.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.24.24.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.24.24.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.24.24.3.1.1.1" class="ltx_text" style="font-size:80%;">Nodes are clustered into faster tiers and slower tiers.</span></span>
</span>
</td>
<td id="S3.T2.3.24.24.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.24.24.4.1" class="ltx_text" style="font-size:80%;">H, I, N</span></td>
<td id="S3.T2.3.24.24.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.24.24.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.24.24.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.24.24.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN &amp; CIFAR10, FMNIST, Sent140</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.25.25" class="ltx_tr">
<td id="S3.T2.3.25.25.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.25.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.25.25.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.25.25.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.25.25.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib78" title="" class="ltx_ref">78</a><span id="S3.T2.3.25.25.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.25.25.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.25.25.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.25.25.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.25.25.3.1.1.1" class="ltx_text" style="font-size:80%;">A metric for grouping nodes according to the gradient direction and the latency.</span></span>
</span>
</td>
<td id="S3.T2.3.25.25.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.25.25.4.1" class="ltx_text" style="font-size:80%;">H, N</span></td>
<td id="S3.T2.3.25.25.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.25.25.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.25.25.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.25.25.5.1.1.1" class="ltx_text" style="font-size:80%;">MCLR, LSTM &amp; MNIST, FMNIST, Synthetic </span><cite class="ltx_cite ltx_align_left ltx_citemacro_cite"><span id="S3.T2.3.25.25.5.1.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib79" title="" class="ltx_ref">79</a><span id="S3.T2.3.25.25.5.1.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S3.T2.3.25.25.5.1.1.4" class="ltx_text" style="font-size:80%;">, Sent140</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.26.26" class="ltx_tr">
<td id="S3.T2.3.26.26.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.26.26.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.26.26.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.26.26.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.26.26.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib80" title="" class="ltx_ref">80</a><span id="S3.T2.3.26.26.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.26.26.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.26.26.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.26.26.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.26.26.3.1.1.1" class="ltx_text" style="font-size:80%;">A cascade training scheme including bottom subnetworks and top subnetworks.</span></span>
</span>
</td>
<td id="S3.T2.3.26.26.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.26.26.4.1" class="ltx_text" style="font-size:80%;">V</span></td>
<td id="S3.T2.3.26.26.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.26.26.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.26.26.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.26.26.5.1.1.1" class="ltx_text" style="font-size:80%;">MLP, CNN &amp; MNIST, FMNIST, CIFAR10</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.27.27" class="ltx_tr">
<td id="S3.T2.3.27.27.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.27.27.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.27.27.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.27.27.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.27.27.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib81" title="" class="ltx_ref">81</a><span id="S3.T2.3.27.27.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.27.27.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.27.27.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.27.27.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.27.27.3.1.1.1" class="ltx_text" style="font-size:80%;">Nodes are grouped based on data distributions and physical locations.</span></span>
</span>
</td>
<td id="S3.T2.3.27.27.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.27.27.4.1" class="ltx_text" style="font-size:80%;">H, I, N</span></td>
<td id="S3.T2.3.27.27.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.27.27.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.27.27.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.27.27.5.1.1.1" class="ltx_text" style="font-size:80%;">SR, MLP, CNN &amp; MNIST, FMNIST, EMNIST, CelebA</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.28.28" class="ltx_tr">
<td id="S3.T2.3.28.28.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.28.28.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.28.28.1.1.1" class="ltx_p" style="width:26.0pt;"><span id="S3.T2.3.28.28.1.1.1.1" class="ltx_text" style="font-size:80%;">
<span id="S3.T2.3.28.28.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:5.6pt;height:38.3pt;vertical-align:-16.4pt;"><span class="ltx_transformed_inner" style="width:38.3pt;transform:translate(-16.37pt,0pt) rotate(-90deg) ;">
<span id="S3.T2.3.28.28.1.1.1.1.1.1" class="ltx_p">Cluster FL</span>
</span></span></span></span>
</span>
</td>
<td id="S3.T2.3.28.28.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.28.28.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib82" title="" class="ltx_ref">82</a><span id="S3.T2.3.28.28.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.28.28.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.28.28.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.28.28.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.28.28.3.1.1.1" class="ltx_text" style="font-size:80%;">Adjust the aggregation frequency among groups.</span></span>
</span>
</td>
<td id="S3.T2.3.28.28.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.28.28.4.1" class="ltx_text" style="font-size:80%;">H, I</span></td>
<td id="S3.T2.3.28.28.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.28.28.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.28.28.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.28.28.5.1.1.1" class="ltx_text" style="font-size:80%;">MNIST</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.29.29" class="ltx_tr">
<td id="S3.T2.3.29.29.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.29.29.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.29.29.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.29.29.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.29.29.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib57" title="" class="ltx_ref">57</a><span id="S3.T2.3.29.29.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.29.29.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.29.29.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.29.29.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.29.29.3.1.1.1" class="ltx_text" style="font-size:80%;">The parameters in shallow layers are updated more frequently than those in deep layers.</span></span>
</span>
</td>
<td id="S3.T2.3.29.29.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.29.29.4.1" class="ltx_text" style="font-size:80%;">H, N</span></td>
<td id="S3.T2.3.29.29.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.29.29.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.29.29.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.29.29.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN, LSTM &amp; MNIST, HAR</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.30.30" class="ltx_tr">
<td id="S3.T2.3.30.30.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.30.30.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.30.30.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S3.T2.3.30.30.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.30.30.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib83" title="" class="ltx_ref">83</a><span id="S3.T2.3.30.30.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.30.30.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.30.30.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.30.30.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.30.30.3.1.1.1" class="ltx_text" style="font-size:80%;">The parameters in shallow layers are updated more frequently than those in deep layers on UAVs.</span></span>
</span>
</td>
<td id="S3.T2.3.30.30.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.30.30.4.1" class="ltx_text" style="font-size:80%;">H, I</span></td>
<td id="S3.T2.3.30.30.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.30.30.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.30.30.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.30.30.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN &amp; Real-World Movie Ratings</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.31.31" class="ltx_tr">
<td id="S3.T2.3.31.31.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.31.31.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.31.31.1.1.1" class="ltx_p" style="width:26.0pt;"><span id="S3.T2.3.31.31.1.1.1.1" class="ltx_text" style="font-size:80%;">
<span id="S3.T2.3.31.31.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:19.1pt;height:28.4pt;vertical-align:-11.4pt;"><span class="ltx_transformed_inner" style="width:28.5pt;transform:translate(-4.67pt,10.13pt) rotate(-90deg) ;">
<span id="S3.T2.3.31.31.1.1.1.1.1.1" class="ltx_p ltx_parbox ltx_align_middle" style="width:28.5pt;">Model Splitting</span>
</span></span></span></span>
</span>
</td>
<td id="S3.T2.3.31.31.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.31.31.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib65" title="" class="ltx_ref">65</a><span id="S3.T2.3.31.31.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S3.T2.3.31.31.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.31.31.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.31.31.3.1.1" class="ltx_p" style="width:177.8pt;"><span id="S3.T2.3.31.31.3.1.1.1" class="ltx_text" style="font-size:80%;">Allow nodes to select a branch of the global model based on local data distribution.</span></span>
</span>
</td>
<td id="S3.T2.3.31.31.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S3.T2.3.31.31.4.1" class="ltx_text" style="font-size:80%;">H, I</span></td>
<td id="S3.T2.3.31.31.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S3.T2.3.31.31.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.31.31.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T2.3.31.31.5.1.1.1" class="ltx_text" style="font-size:80%;">CNN, MBNN &amp; Bearing, Gear Fault</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.32.32" class="ltx_tr">
<td id="S3.T2.3.32.32.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;" colspan="5">
<sup id="S3.T2.3.32.32.1.1" class="ltx_sup"><span id="S3.T2.3.32.32.1.1.1" class="ltx_text" style="font-size:80%;">1</span></sup><span id="S3.T2.3.32.32.1.2" class="ltx_text" style="font-size:80%;"> Reference paper that belongs to the specific group.</span>
</td>
</tr>
<tr id="S3.T2.3.33.33" class="ltx_tr">
<td id="S3.T2.3.33.33.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:0.8pt;padding-bottom:0.8pt;" colspan="5">
<sup id="S3.T2.3.33.33.1.1" class="ltx_sup"><span id="S3.T2.3.33.33.1.1.1" class="ltx_text" style="font-size:80%;">2</span></sup><span id="S3.T2.3.33.33.1.2" class="ltx_text" style="font-size:80%;"> Data distribution across nodes. H: horizontal, V: Vertical, I: IID, N: non-IID.</span>
</td>
</tr>
</tbody>
</table>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Node Selection</h3>

<div id="S3.SS1.p1" class="ltx_para">
<span id="S3.SS1.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS1.p1.2" class="ltx_p">Numerous algorithms for node selection are proposed to improve the training efficiency of AFL across heterogeneous devices. In contrast to classic FL selecting nodes with more training data, AFL leans towards prioritizing nodes with heightened resilience and computational capacity. However, it is challenging to strike a balance between robustness and overfitting of the global model.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">For instance, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>, the authors present a heuristic greedy node selection strategy that iteratively selects heterogeneous IoT nodes to participate in global learning aggregation based on their local computing and communication resources. Experiments are conducted on both IID and non-IID datasets to verify the effectiveness of their approach.
Apart from that, considering the large number of edge devices involved, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, the authors limit the number of devices training simultaneously in the AFL network. A limit-size cache with a weighted averaging mechanism is introduced onto the server to reduce the impact of model staleness. Experiment results back up the improved convergence speed and model accuracy. <span id="S3.SS1.p2.1.1" class="ltx_ERROR undefined">\add</span>These schemes are simple to improve aggregation efficiency but lack the sense of non-IID data across different nodes.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">In order to select nodes more reasonably, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>, a prioritized node-selecting function is designed according to the computing power and accuracy change of local models on each node. Other unselected nodes continue the iterations locally at the same time. As a result of the node-selecting function, the experiment results show a higher accuracy growth rate with a faster convergence speed. <span id="S3.SS1.p3.1.1" class="ltx_ERROR undefined">\add</span>Nevertheless, this prioritized node-selection method does not consider the device unreliability of IoT devices. Thus, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> propose an idea that assigns a trust score to each node based on its activities. ML tasks with resource requirements and a minimum trust score are published in the FL network. Any candidates who do not meet the task requirement are filtered out before the training round begins. Clients who complete tasks will be rewarded, while those who do not will have their trust value decreased.
Similarly, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, a node with a lower probability to crash is more likely to be selected in an iteration. The straggling nodes that training models that are too stale will be tagged as deprecated and forced to synchronize with the server. The tolerable nodes are those training on the acceptable stale models, who work asynchronously with the server. After updated gradients from a fraction of nodes are received, the central server ends a round of training. As a result, the waste of computation resources is minimized, and communication expenses are kept at a relatively low level.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<span id="S3.SS1.p4.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS1.p4.2" class="ltx_p">For a more comprehensive assessment of diverse device scheduling and update aggregation strategies, a study conducted by the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> involves experiments encompassing both IID and non-IID datasets. These experiments are conducted across a spectrum of computational resources and training data distributions, considering scenarios where a subset of IoT devices is permitted to upload local models. Specifically, the device scheduling policies include random scheduling, significance-based scheduling, and frequency-based scheduling; the update aggregation policies include equal weight aggregation and age-aware aggregation. The simulation results demonstrate that the random scheduling policy outperforms others while training on non-IID datasets. Besides, an appropriate age-aware aggregation policy performs better.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Weighted Aggregation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<span id="S3.SS2.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS2.p1.2" class="ltx_p">Numerous weighted aggregation algorithms have been introduced to lessen the influence of slow devices and increase learning efficiency. In conventional FL, weighted aggregation aims to amplify the influence of local models trained with more data. However, in AFL, the objective shifts toward alleviating the effects of stale local models, which does not exist in classic FL.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<span id="S3.SS2.p2.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS2.p2.2" class="ltx_p">One primary idea is introducing a parameter that accounts for staleness, which reduces the influence of stale local models and elevates the influence of the most recent local models during the aggregation procedure. There are several papers that adopt this method. For example, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, a mixing hyperparameter is introduced based on staleness to balance the convergence rate and variance reduction. The experiments conducted on CIFAR-10 and WikiText-2 validate both fast convergence and staleness tolerance.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, a temporally weighted aggregation strategy is proposed, which increases the weight of recently updated local models when aggregating on shallow and deep layers. Experiment results on CNN and LSTM neural networks show that the global model accuracy and convergence are improved.
Another time-based weighted aggregation algorithm is proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>. The weight assigned to the updated gradients decreases as the staleness value increases.
Similarly, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, a staleness-based weighted aggregation algorithm with cache is proposed.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>, a decay coefficient is proposed with similar effects, balancing the previous and current models. With the dynamic learning step size, the nodes with more data or poor communication status are compensated. Experiments across three real-world datasets are conducted with results showing that their scheme converges fast and enables higher model accuracy.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<span id="S3.SS2.p3.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS2.p3.2" class="ltx_p">Nevertheless, the aforementioned methods only focus on the staleness of local models, which is a one-sided view. Thus, a duel-weighted gradient updating strategy is proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>, which takes into account the size of the dataset as well as the similarity between the local and global gradients. The updated gradients submitted by edge devices are aggregated after the duel-weight correction. The experiment results reveal that the model accuracy remains high even after gradient compression.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<span id="S3.SS2.p4.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS2.p4.2" class="ltx_p">Apart from setting more factors of weighted aggregation, to enable more fine-grained weighted aggregation, an idea is to aggregate branches in a model with weights.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>, the global model is split into branches with the aggregation procedure transformed into a branch-weighted merging process. The aggregation weight is dynamically adjusted depending on the training accuracy of all nodes to prevent the global model from overfitting to nodes that upload gradients frequently. To evaluate the effectiveness of the proposed scheme, a prototype is implemented on heterogeneous devices based on two industrial cases: (1) Fault diagnosis of motor bearings and (2) Fault diagnosis of the gearbox. The experiment results demonstrate that their scheme converges faster, achieves higher accuracy, and consumes less energy than the classic CNN model.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Gradient Compression</h3>

<div id="S3.SS3.p1" class="ltx_para">
<span id="S3.SS3.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS3.p1.2" class="ltx_p">As gradient compression stands as a widely applicable tactic for improving the efficiency of FL, its incorporation into AFL commonly aims to achieve an additional reduction in communication expenses. Nevertheless, AFL introduces new challenges to gradient compression, primarily within the resource-restricted computing environments of edge and IoT devices, along with a higher frequency of aggregation operations. Specifically, the disparity in computational capabilities among nodes is much more significant. Besides, AFL incurs larger computational demand on the server side compared to classic FL due to the intensified frequency of aggregation and compression operations. To address these challenges, several efficient gradient compression algorithms tailored for AFL have been presented.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<span id="S3.SS3.p2.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS3.p2.2" class="ltx_p">For instance, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>, two sub-modules are presented for self-adaptive threshold gradient compression: (1) self-adaptive threshold computation and (2) gradient communication compression. The former is in charge of computing the threshold based on recent parameter changes, while the latter is in charge of compressing redundant gradient communications based on the threshold. The accuracies of the generated models after gradient compression are verified when training the MLP model on the MNIST dataset. Besides, the proposed scheme allows the node to join or quit freely, which is suitable to highly mobile edge computing scenarios. Another similar paper is published in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> by the same authors.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<span id="S3.SS3.p3.2" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS3.p3.1" class="ltx_p">From the perspective of vertical FL, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>, based on the Top-K AllReduce sparse compression technique, the authors present a double-end sparse compression algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>. Specifically, the compression process happens on both the server and local sides to reduce the transmission cost. Experiment results demonstrate that <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="86.90\%" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><mrow id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mn id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">86.90</mn><mo id="S3.SS3.p3.1.m1.1.1.1" xref="S3.SS3.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><csymbol cd="latexml" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1">percent</csymbol><cn type="float" id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">86.90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">86.90\%</annotation></semantics></math> of information exchange is minimized during the training process, revealing that their scheme is suitable for edge computing scenarios with low-bandwidth or metered networks. Furthermore, the training data is protected securely against gradients leakage attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.1" class="ltx_p">Another approach to improve communication efficiency is to design a new communication protocol that more efficiently schedules model upload and download. For example, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>, three transmission scheduling algorithms that account for slow nodes are proposed to improve the efficiency of AFL in wireless networks, where statistical information regarding uncertainty is known, unknown, or limited. The experiment results show their outperformance in terms of accuracy, convergence speed, and robustness.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Semi-Asynchronous FL</h3>

<div id="S3.SS4.p1" class="ltx_para">
<span id="S3.SS4.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS4.p1.2" class="ltx_p">In AFL, the inclusion of stale local models from slow nodes during aggregation diminishes the accuracy of the global model to a certain extent. To alleviate the effects of these slow devices, semi-asynchronous FL schemes have been introduced. Typically, semi-asynchronous FL serves as a hybrid approach that combines elements from both classic FL and AFL, where the aggregation server captures and stores local models that arrive earlier, subsequently aggregating them following a certain timeframe. Depending on the magnitude of staleness, the subsequent arrivals of local models either take part in the following training rounds or are discarded. Notably, the aggregation frequency of semi-asynchronous FL falls between that of AFL and classic FL. Similar to classic FL, a training round is defined as the process spanning from one global aggregation to the next.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<span id="S3.SS4.p2.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS4.p2.2" class="ltx_p">For example, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>, a priority function is introduced to accurately select nodes with large amounts of data or high computation power. Meanwhile, local models on unselected nodes will be cached for a specific number of iterations before being submitted to the aggregation server. Besides, a restriction on the local training round number is set to prevent specific nodes from being unselected for a lengthy period of time, leading the global model to overfit certain nodes. The effectiveness of the scheme is evidenced by experiments conducted on IID and non-IID datasets. <span id="S3.SS4.p2.2.1" class="ltx_ERROR undefined">\add</span>However, the restriction in this scheme will amplify the influence of stale local models after numerous aggregations.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p">On the contrary, a cache-based lag-tolerant mechanism on the aggregation server is introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> to mitigate the impacts of stragglers, crashes, and model staleness. In their scheme, all nodes are classified into three categories: up-to-date, deprecated, and tolerable. Only the up-to-date and deprecated nodes are forced to synchronize with the server, while the tolerable nodes work asynchronously. The nodes will be labeled picked, undrafted, or crashed after training. Specifically, local models from undrafted nodes are not aggregated in this round but retained in the cache for aggregation with local models in the next round. As a result, the tradeoff between faster convergence and lower communication overhead is properly addressed, which is verified by experiments.
Similarly, a private buffer on the aggregation server holding a certain number of model updates is designed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, with convergence ensured by math. To evaluate the scalability and efficiency of their scheme under various staleness distributions, the authors train an LSTM classifier on text and image classification tasks. The results reveal that their approach is more resistant to diverse distributions and converges faster than classic synchronous and asynchronous FL schemes. <span id="S3.SS4.p3.1.1" class="ltx_ERROR undefined">\add</span>However, the aforementioned schemes do not take the security of the cache into account. To further improve cache security, a scheme that adopts a secure buffer on the server is proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite>, where a secure aggregation protocol is designed to prevent the server from learning any information about the local updates.</p>
</div>
<div id="S3.SS4.p4" class="ltx_para">
<span id="S3.SS4.p4.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS4.p4.2" class="ltx_p">From the perspective of time, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite> aggregate local models at a specific time interval determined by the slowest node. More exact control over the training nodes is allowed, especially in edge computing networks with non-IID data distribution. The authors then compare classic synchronous, asynchronous, and semi-synchronous schemes across heterogeneous devices in experiments. The results show that their approach is faster and more accurate than other schemes.</p>
</div>
<div id="S3.SS4.p5" class="ltx_para">
<span id="S3.SS4.p5.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS4.p5.2" class="ltx_p">For AFL, there is a good chance that a significant number of local model updates come in a short period of time. Considering this issue, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>, after caching the first several local models received within a given time window, a synchronous aggregation strategy is adopted. The experiment results reveal that compared with the classic FL scheme, the time window enables their scheme many more nodes.</p>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Cluster FL</h3>

<div id="S3.SS5.p1" class="ltx_para">
<span id="S3.SS5.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS5.p1.2" class="ltx_p">Clustered FL is an approach geared towards augmenting training efficiency through the formation of clusters comprising devices exhibiting similar performance, functionalities, or datasets. The asynchronous update strategy has the potential to bring advantageous to inner-group updates, inter-group updates, or both</p>
</div>
<div id="S3.SS5.p2" class="ltx_para">
<p id="S3.SS5.p2.1" class="ltx_p">For instance, an idea is grouping nodes into tiers based on their response latency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>. Faster tiers are responsible for faster convergence, while slower tiers aid in the model accuracy improvement. Furthermore, a polyline-encoding-based compression algorithm is adopted in their scheme to improve communication efficiency. Experiments are conducted across multiple datasets and models, confirming that their scheme has a low communication cost and high prediction accuracy. <span id="S3.SS5.p2.1.1" class="ltx_ERROR undefined">\add</span>However, grouping nodes by only considering the factor of response latency is circumscribed.
By contrast, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>, a grouping metric is proposed, where the gradient direction and the latency of model update are taken into account. The local update latency is composed of computation latency and communication latency. Experiments conducted on four imbalanced non-IID datasets assess the improvement in test accuracy.</p>
</div>
<div id="S3.SS5.p3" class="ltx_para">
<span id="S3.SS5.p3.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS5.p3.2" class="ltx_p">From the aspect of grouping architecture, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>, a cascade training scheme with bottom and top subnetworks is proposed to fully exploit all horizontally partitioned labels. Specifically, the bottom subnetworks are responsible for extracting embedding vectors from features, while the top subnetworks are for prediction. The nodes in FL are classified into three types, including active party, passive party, and collaborator. Each active party is connected to other passive parties so that it is able to gather embedding vectors and return gradients to them. The collaborator is connected to all active parties in order to aggregate the returned gradients. The experiment results reveal that their scheme effectively addresses the straggler problem with minimum performance loss.</p>
</div>
<div id="S3.SS5.p4" class="ltx_para">
<span id="S3.SS5.p4.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS5.p4.2" class="ltx_p">Another advantage of cluster FL is improving communication efficiency. For example, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>, nodes are grouped based on data distributions and physical locations to reduce global model loss and communication delay. The authors designed a control algorithm that reduces communication costs while examining the convergence of the proposed scheme in IID settings. The outperformed accuracy and efficiency of their scheme are evidenced by the experiment results. <span id="S3.SS5.p4.2.1" class="ltx_ERROR undefined">\add</span>Additionally, Cluster FL allows different groups of nodes to aggregate at different frequencies, which also reduces communication costs. For example, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>, the authors adaptively modify the aggregation frequency among groups to minimize the loss of FL. Under an environment with limited resources, a dynamic trade-off between computation and communication cost is formulated by Markov Decision Process (MDP) and optimized by deep reinforcement learning (DRL). Numerical results validate the accuracy, convergence, and energy-saving features of their proposed scheme.</p>
</div>
</section>
<section id="S3.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.6 </span>Model Splitting</h3>

<div id="S3.SS6.p1" class="ltx_para">
<span id="S3.SS6.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS6.p1.2" class="ltx_p">Following the splitting of the deep neural network model, each node is responsible for training a certain part rather than the whole model. Thus, the model-splitting strategy curtails the number of parameters necessitating transmission, consequently leading to an enhancement in communication efficiency. Upon integrating the model-splitting strategy into AFL, nodes bypass the need to await other nodes and fully utilize their computing resources to train the model for subsequent rounds. Therefore, the model-splitting strategy expedites the convergence of the global model to a certain extent.</p>
</div>
<div id="S3.SS6.p2" class="ltx_para">
<span id="S3.SS6.p2.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS6.p2.2" class="ltx_p">For instance, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, a layerwise asynchronous model updating strategy is proposed, in which shallow layer parameters are updated more frequently than deep layer parameters. When aggregating, the most recently updated local models have the highest weight with the help of timestamps. The experiment results support the improved communication cost and model accuracy of the proposed scheme.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite>, a similar idea is achieved by using cache and communication capabilities on UAVs and terrestrial base stations. The parameters in shallow layers are updated more frequently than those in deep layers. To predict the content caching placement, the proposed scheme employs a two-stage AFL algorithm. The efficiency of the proposed scheme is validated by experiments conducted on real-world datasets and numerical analysis.</p>
</div>
<div id="S3.SS6.p3" class="ltx_para">
<span id="S3.SS6.p3.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS6.p3.2" class="ltx_p">Apart from splitting models into deep and shallow layers, an approach is to divide the global model into branches according to the sample category <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>. The splitting process involves acquiring a branch from the entire model. The aggregation process is performed on branches with different weights dynamically adjusted by the aggregation server. Besides, it allows nodes to select parts of the model according to local data distribution and update asynchronously reduces calculation and communication costs, enhancing FL efficiency.</p>
</div>
<div id="S3.SS6.p4" class="ltx_para">
<span id="S3.SS6.p4.1" class="ltx_ERROR undefined">\add</span>
<p id="S3.SS6.p4.2" class="ltx_p">In contrast to the node selection strategy, the model-splitting strategy reduces the computational demands placed upon nodes, affords greater flexibility in updating distinct layers of the global model, and alleviates biases present within the global model. Nonetheless, the extendability of this strategy to different models is constrained, primarily due to the requisite implementation of customized splitting and aggregation algorithms for every model across various datasets.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Data Heterogeneity</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In practice, the data across nodes is usually non-IID. Besides, the amount of data distributed on each node is always imbalanced. <span id="S4.p1.1.1" class="ltx_ERROR undefined">\add</span>Consequently, the frequent uploading of models on particular nodes has the potential to attract divergence to the global model and result in overfitting to specific datasets.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Non-Independent and Identically Distributed Data</h3>

<div id="S4.SS1.p1" class="ltx_para">
<span id="S4.SS1.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S4.SS1.p1.2" class="ltx_p">The presence of non-IID data among nodes tends to cause a biased global model in AFL. To tackle the issues posed by this non-IID data, the research domain primarily encompasses four avenues of exploration, including constraint terms for aggregation, clustered FL, distributed validation strategy, and mathematically optimizing parameters.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<span id="S4.SS1.p2.1" class="ltx_ERROR undefined">\add</span>
<p id="S4.SS1.p2.2" class="ltx_p">A typical example of constraint terms for aggregation is <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>, where a constraint term is presented to limit local updates to be closer to the global model. Besides, nodes with similar updating frequencies are grouped into the same tier through synchronous and asynchronous training strategies to prevent local models from diverging. The effectiveness of the scheme is supported by mathematical analysis and experiment results.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<span id="S4.SS1.p3.1" class="ltx_ERROR undefined">\add</span>
<p id="S4.SS1.p3.2" class="ltx_p">Clustered FL is also a strategy to alleviate the effects of divergent data distributions by grouping training nodes. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite>, the geometric properties of the FL loss surface are used to group nodes into clusters. The quality of clusters is ensured by math and validated by experiments. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>, the data distribution on nodes in a group is optimized to be closer to the global data distribution. To better group nodes in general situations, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite> propose a spectral clustering approach, where nodes are grouped based on an affinity matrix derived from model update latency and direction. Non-IID dataset settings are also applied in their experiments, with the results showing that their scheme enhances test accuracy and convergence speed.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<span id="S4.SS1.p4.2" class="ltx_ERROR undefined">\add</span>
<p id="S4.SS1.p4.1" class="ltx_p">An example of distributed validation strategy is <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite>, where the authors propose a distributed validation scheme that evaluates model performance across nodes. A small percentage (<math id="S4.SS1.p4.1.m1.1" class="ltx_Math" alttext="5\%" display="inline"><semantics id="S4.SS1.p4.1.m1.1a"><mrow id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml"><mn id="S4.SS1.p4.1.m1.1.1.2" xref="S4.SS1.p4.1.m1.1.1.2.cmml">5</mn><mo id="S4.SS1.p4.1.m1.1.1.1" xref="S4.SS1.p4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><apply id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1"><csymbol cd="latexml" id="S4.SS1.p4.1.m1.1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS1.p4.1.m1.1.1.2.cmml" xref="S4.SS1.p4.1.m1.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">5\%</annotation></semantics></math>) of local training data samples is reserved on each node to evaluate models from other nodes. As a result, a better generalized global model is obtained. By adopting both synchronous and asynchronous communication protocols, models trained on heterogeneous data and compute environments demonstrate the superior performance of the proposed scheme.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<span id="S4.SS1.p5.1" class="ltx_ERROR undefined">\add</span>
<p id="S4.SS1.p5.2" class="ltx_p">From the perspective of mathematical analysis, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite>, a training strategy with pre-determined initial weight parameters is proposed to mitigate the global model divergence. By using the Taylor Expansion formula, higher precision gradients are achieved on their AFL scheme, which is validated by experiments conducted across many real-world datasets. Another mathematical solution of non-IID data is choosing optimal hyper-parameters for the novel two-stage training strategy in AFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite>.</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<span id="S4.SS1.p6.1" class="ltx_ERROR undefined">\add</span>
<p id="S4.SS1.p6.2" class="ltx_p">In addition to the aforementioned methods, a number of research papers analyze the effects of stale or imbalanced non-IID data on AFL. For example, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>, an AFL scheme is proposed, where the authors focus on how staleness and data imbalance affect AFL by performing various levels of experiments. The results reveal that AFL works effectively on balanced data distribution when the server update frequency is unequal. Considering the effects of smooth strongly convex and smooth nonconvex functions when the data distribution is non-IID, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite> investigate the convergence theoretically and conduct several experiments. The results show that AFL has the same convergence rate as traditional FL while lowering communication requirements. By implementing the AFL scheme and conducting experiments on six Raspberry Pi 3B+ devices, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite> investigate the impact of heterogeneous devices. The results of experiments conducted on the MNIST dataset with non-IID data distribution reveal that AFL outperforms classic FL, especially when computing resources and input data sizes are disparate.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Vertical Distributed Data</h3>

<div id="S4.SS2.p1" class="ltx_para">
<span id="S4.SS2.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S4.SS2.p1.2" class="ltx_p">In contrast to horizontal FL, vertical FL focuses on datasets where distinct subsets of features are spread across various nodes, as elaborated upon in Section <a href="#S2.SS1" title="2.1 Federated Learning ‣ 2 Background Knowledge ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>. Given that the creation of the global model depends on the aggregation of local models, there exists a requirement for collaborative updating of these local models. Such skewed feature distribution and heightened model interdependence consequently present challenges to vertical AFL. To tackle these challenges, the state-of-the-art schemes mainly focus on improving communication and training efficiency.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<span id="S4.SS2.p2.1" class="ltx_ERROR undefined">\add</span>
<p id="S4.SS2.p2.2" class="ltx_p">One research direction is to improve the communication efficiency of vertical FL. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>, apart from the flexible FL algorithm that allows random client participation, the authors utilize a local embedding model for each client to convert raw input to compact features, reducing the communication parameters in AFL. The feasibility and effectiveness of the proposed scheme are confirmed by rigorous convergence analysis and numerical experiments on multiple datasets.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<span id="S4.SS2.p3.1" class="ltx_ERROR undefined">\add</span>
<p id="S4.SS2.p3.2" class="ltx_p">In addition to communication efficiency, the training efficiency also needs to be optimized in vertical FL. For example, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> propose an asynchronous federated stochastic gradient descent (AFSGD-VP) algorithm with two variance reduction variants: stochastic variance reduced gradient (SVRG) and SAGA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>. When the objective function is strongly convex, the convergence rate of AFSGD-VP is derived. Besides, the security and complexity of the proposed algorithm are provided. Experiment results on several vertical distributed datasets verify the theoretical analysis and prove the efficiency of their proposed scheme. <span id="S4.SS2.p3.2.1" class="ltx_ERROR undefined">\add</span>Apart from the stochastic gradient descent, backward updating is also a key stage of training. A vertical AFL scheme with a backward updating mechanism and a bilevel asynchronous parallel architecture is proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>. Specifically, the backward updating mechanism enables all parties to update the model in a secure manner. The bilevel asynchronous parallel architecture improves the efficiency of the backward updating process. As the name implies, the parallel architecture is divided into two levels: the inner-party parallel between active parties and the intra-party parallel within each party. Both levels of the update are performed asynchronously to improve efficiency and scalability. The authors demonstrate the feasibility and security of the proposed strategy through theoretical and security analysis. Experiments on real financial datasets are conducted, whose results demonstrate efficiency, scalability, and losslessness.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<span id="S4.SS2.p4.1" class="ltx_ERROR undefined">\add</span>
<p id="S4.SS2.p4.2" class="ltx_p">Upon the aforementioned strategies, a hybrid approach that improves both training and communication efficiency is proposed. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>, the authors propose a vertical AFL scheme with gradient prediction and double-end sparse compression algorithm. In particular, the gradient prediction presents the timely renewal of participants by using second-order Taylor expansion, reducing training time while retaining a sufficient degree of accuracy. The double-end sparse compression algorithm reduces the amount of data exchanged across the network during the training process. Experiment results obtained by training models on two public datasets reveal the outperformed efficiency of the scheme without degrading the accuracy and convergence speed.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Privacy and Security on Heterogeneous Devices</h2>

<div id="S5.p1" class="ltx_para">
<span id="S5.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S5.p1.2" class="ltx_p">While FL is initially introduced to protect the privacy of local training data, new attack vectors have emerged, causing privacy concerns, such as membership inference attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite>, property inference attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite>, model inversion attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>, and deep leakage from gradients attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>. Several attacks, like poisoning attacks or backdoor attacks, pose a significant threat to the integrity of the global model. Remedial measures for privacy and security concerns within FL include leveraging techniques like differential privacy and blockchain. Since AFL operates as a variant of FL, it is vulnerable to these attacks when training models across heterogeneous devices. However, the current solutions addressing privacy and security issues are often computationally demanding, rendering them less viable for deployment on resource-constrained heterogeneous devices and time-sensitive application scenarios. To confront these obstacles, many studies have come forward, presenting flexible differential-privacy models or highly efficient blockchain-based solutions tailored to AFL. A comparative analysis of these papers is presented in Table <a href="#S5.T3" title="Table 3 ‣ 5 Privacy and Security on Heterogeneous Devices ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>Attack Resistance Comparison on Heterogeneous Devices</figcaption>
<table id="S5.T3.81" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T3.81.82.1" class="ltx_tr">
<th id="S5.T3.81.82.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S5.T3.81.82.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Ref.<span id="footnotex4" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex4.1.1.1" class="ltx_text ltx_font_medium" style="font-size:125%;">1</span></span></span></span></span></span></th>
<td id="S5.T3.81.82.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S5.T3.81.82.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">BKG<span id="footnotex5" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex5.1.1.1" class="ltx_text ltx_font_medium" style="font-size:125%;">2</span></span></span></span></span> Attack</span></td>
<td id="S5.T3.81.82.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S5.T3.81.82.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Collusion Attack</span></td>
<td id="S5.T3.81.82.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S5.T3.81.82.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Inference Attack</span></td>
<td id="S5.T3.81.82.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S5.T3.81.82.1.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Poisoning Attack</span></td>
<td id="S5.T3.81.82.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S5.T3.81.82.1.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Byzantine Attack</span></td>
<td id="S5.T3.81.82.1.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S5.T3.81.82.1.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">DDoS Attack</span></td>
</tr>
<tr id="S5.T3.6.6" class="ltx_tr">
<th id="S5.T3.6.6.7" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T3.6.6.7.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib93" title="" class="ltx_ref">93</a><span id="S5.T3.6.6.7.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S5.T3.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.1.1.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.1.1.1.m1.1a"><mo mathsize="80%" id="S5.T3.1.1.1.m1.1.1" xref="S5.T3.1.1.1.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.m1.1b"><csymbol cd="latexml" id="S5.T3.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S5.T3.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.2.2.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.2.2.2.m1.1a"><mo mathsize="80%" id="S5.T3.2.2.2.m1.1.1" xref="S5.T3.2.2.2.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.m1.1b"><csymbol cd="latexml" id="S5.T3.2.2.2.m1.1.1.cmml" xref="S5.T3.2.2.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.2.m1.1c">\surd</annotation></semantics></math></td>
<td id="S5.T3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.3.3.3.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.3.3.3.m1.1a"><mo mathsize="80%" id="S5.T3.3.3.3.m1.1.1" xref="S5.T3.3.3.3.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.3.m1.1b"><csymbol cd="latexml" id="S5.T3.3.3.3.m1.1.1.cmml" xref="S5.T3.3.3.3.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.3.m1.1c">\surd</annotation></semantics></math></td>
<td id="S5.T3.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.4.4.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.4.4.4.m1.1a"><mo mathsize="80%" id="S5.T3.4.4.4.m1.1.1" xref="S5.T3.4.4.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.4.4.4.m1.1b"><times id="S5.T3.4.4.4.m1.1.1.cmml" xref="S5.T3.4.4.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.4.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.5.5.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.5.5.5.m1.1a"><mo mathsize="80%" id="S5.T3.5.5.5.m1.1.1" xref="S5.T3.5.5.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.5.5.5.m1.1b"><times id="S5.T3.5.5.5.m1.1.1.cmml" xref="S5.T3.5.5.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.5.5.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.6.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.6.6.6.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.6.6.6.m1.1a"><mo mathsize="80%" id="S5.T3.6.6.6.m1.1.1" xref="S5.T3.6.6.6.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.6.6.6.m1.1b"><ci id="S5.T3.6.6.6.m1.1.1.cmml" xref="S5.T3.6.6.6.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.6.6.m1.1c">\bigcirc</annotation></semantics></math></td>
</tr>
<tr id="S5.T3.12.12" class="ltx_tr">
<th id="S5.T3.12.12.7" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T3.12.12.7.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib99" title="" class="ltx_ref">99</a><span id="S5.T3.12.12.7.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S5.T3.7.7.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.7.7.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.7.7.1.m1.1a"><mo mathsize="80%" id="S5.T3.7.7.1.m1.1.1" xref="S5.T3.7.7.1.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.7.7.1.m1.1b"><csymbol cd="latexml" id="S5.T3.7.7.1.m1.1.1.cmml" xref="S5.T3.7.7.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.7.7.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S5.T3.8.8.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.8.8.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.8.8.2.m1.1a"><mo mathsize="80%" id="S5.T3.8.8.2.m1.1.1" xref="S5.T3.8.8.2.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.8.8.2.m1.1b"><csymbol cd="latexml" id="S5.T3.8.8.2.m1.1.1.cmml" xref="S5.T3.8.8.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.8.8.2.m1.1c">\surd</annotation></semantics></math></td>
<td id="S5.T3.9.9.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.9.9.3.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.9.9.3.m1.1a"><mo mathsize="80%" id="S5.T3.9.9.3.m1.1.1" xref="S5.T3.9.9.3.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.9.9.3.m1.1b"><csymbol cd="latexml" id="S5.T3.9.9.3.m1.1.1.cmml" xref="S5.T3.9.9.3.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.9.9.3.m1.1c">\surd</annotation></semantics></math></td>
<td id="S5.T3.10.10.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.10.10.4.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.10.10.4.m1.1a"><mo mathsize="80%" id="S5.T3.10.10.4.m1.1.1" xref="S5.T3.10.10.4.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.10.10.4.m1.1b"><ci id="S5.T3.10.10.4.m1.1.1.cmml" xref="S5.T3.10.10.4.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.10.10.4.m1.1c">\bigcirc</annotation></semantics></math></td>
<td id="S5.T3.11.11.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.11.11.5.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.11.11.5.m1.1a"><mo mathsize="80%" id="S5.T3.11.11.5.m1.1.1" xref="S5.T3.11.11.5.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.11.11.5.m1.1b"><ci id="S5.T3.11.11.5.m1.1.1.cmml" xref="S5.T3.11.11.5.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.11.11.5.m1.1c">\bigcirc</annotation></semantics></math></td>
<td id="S5.T3.12.12.6" class="ltx_td ltx_align_center" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.12.12.6.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.12.12.6.m1.1a"><mo mathsize="80%" id="S5.T3.12.12.6.m1.1.1" xref="S5.T3.12.12.6.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.12.12.6.m1.1b"><ci id="S5.T3.12.12.6.m1.1.1.cmml" xref="S5.T3.12.12.6.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.12.12.6.m1.1c">\bigcirc</annotation></semantics></math></td>
</tr>
<tr id="S5.T3.18.18" class="ltx_tr">
<th id="S5.T3.18.18.7" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T3.18.18.7.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib100" title="" class="ltx_ref">100</a><span id="S5.T3.18.18.7.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S5.T3.13.13.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.13.13.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.13.13.1.m1.1a"><mo mathsize="80%" id="S5.T3.13.13.1.m1.1.1" xref="S5.T3.13.13.1.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.13.13.1.m1.1b"><csymbol cd="latexml" id="S5.T3.13.13.1.m1.1.1.cmml" xref="S5.T3.13.13.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.13.13.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S5.T3.14.14.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.14.14.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.14.14.2.m1.1a"><mo mathsize="80%" id="S5.T3.14.14.2.m1.1.1" xref="S5.T3.14.14.2.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.14.14.2.m1.1b"><csymbol cd="latexml" id="S5.T3.14.14.2.m1.1.1.cmml" xref="S5.T3.14.14.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.14.14.2.m1.1c">\surd</annotation></semantics></math></td>
<td id="S5.T3.15.15.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.15.15.3.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.15.15.3.m1.1a"><mo mathsize="80%" id="S5.T3.15.15.3.m1.1.1" xref="S5.T3.15.15.3.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.15.15.3.m1.1b"><csymbol cd="latexml" id="S5.T3.15.15.3.m1.1.1.cmml" xref="S5.T3.15.15.3.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.15.15.3.m1.1c">\surd</annotation></semantics></math></td>
<td id="S5.T3.16.16.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.16.16.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.16.16.4.m1.1a"><mo mathsize="80%" id="S5.T3.16.16.4.m1.1.1" xref="S5.T3.16.16.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.16.16.4.m1.1b"><times id="S5.T3.16.16.4.m1.1.1.cmml" xref="S5.T3.16.16.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.16.16.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.17.17.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.17.17.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.17.17.5.m1.1a"><mo mathsize="80%" id="S5.T3.17.17.5.m1.1.1" xref="S5.T3.17.17.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.17.17.5.m1.1b"><times id="S5.T3.17.17.5.m1.1.1.cmml" xref="S5.T3.17.17.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.17.17.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.18.18.6" class="ltx_td ltx_align_center" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.18.18.6.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.18.18.6.m1.1a"><mo mathsize="80%" id="S5.T3.18.18.6.m1.1.1" xref="S5.T3.18.18.6.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.18.18.6.m1.1b"><ci id="S5.T3.18.18.6.m1.1.1.cmml" xref="S5.T3.18.18.6.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.18.18.6.m1.1c">\bigcirc</annotation></semantics></math></td>
</tr>
<tr id="S5.T3.24.24" class="ltx_tr">
<th id="S5.T3.24.24.7" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T3.24.24.7.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib101" title="" class="ltx_ref">101</a><span id="S5.T3.24.24.7.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S5.T3.19.19.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.19.19.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.19.19.1.m1.1a"><mo mathsize="80%" id="S5.T3.19.19.1.m1.1.1" xref="S5.T3.19.19.1.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.19.19.1.m1.1b"><csymbol cd="latexml" id="S5.T3.19.19.1.m1.1.1.cmml" xref="S5.T3.19.19.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.19.19.1.m1.1c">\surd</annotation></semantics></math></td>
<td id="S5.T3.20.20.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.20.20.2.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.20.20.2.m1.1a"><mo mathsize="80%" id="S5.T3.20.20.2.m1.1.1" xref="S5.T3.20.20.2.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.20.20.2.m1.1b"><csymbol cd="latexml" id="S5.T3.20.20.2.m1.1.1.cmml" xref="S5.T3.20.20.2.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.20.20.2.m1.1c">\surd</annotation></semantics></math></td>
<td id="S5.T3.21.21.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.21.21.3.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.21.21.3.m1.1a"><mo mathsize="80%" id="S5.T3.21.21.3.m1.1.1" xref="S5.T3.21.21.3.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.21.21.3.m1.1b"><csymbol cd="latexml" id="S5.T3.21.21.3.m1.1.1.cmml" xref="S5.T3.21.21.3.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.21.21.3.m1.1c">\surd</annotation></semantics></math></td>
<td id="S5.T3.22.22.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.22.22.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.22.22.4.m1.1a"><mo mathsize="80%" id="S5.T3.22.22.4.m1.1.1" xref="S5.T3.22.22.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.22.22.4.m1.1b"><times id="S5.T3.22.22.4.m1.1.1.cmml" xref="S5.T3.22.22.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.22.22.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.23.23.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.23.23.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.23.23.5.m1.1a"><mo mathsize="80%" id="S5.T3.23.23.5.m1.1.1" xref="S5.T3.23.23.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.23.23.5.m1.1b"><times id="S5.T3.23.23.5.m1.1.1.cmml" xref="S5.T3.23.23.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.23.23.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.24.24.6" class="ltx_td ltx_align_center" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.24.24.6.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.24.24.6.m1.1a"><mo mathsize="80%" id="S5.T3.24.24.6.m1.1.1" xref="S5.T3.24.24.6.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.24.24.6.m1.1b"><ci id="S5.T3.24.24.6.m1.1.1.cmml" xref="S5.T3.24.24.6.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.24.24.6.m1.1c">\bigcirc</annotation></semantics></math></td>
</tr>
<tr id="S5.T3.30.30" class="ltx_tr">
<th id="S5.T3.30.30.7" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T3.30.30.7.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib102" title="" class="ltx_ref">102</a><span id="S5.T3.30.30.7.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S5.T3.25.25.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.25.25.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.25.25.1.m1.1a"><mo mathsize="80%" id="S5.T3.25.25.1.m1.1.1" xref="S5.T3.25.25.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.25.25.1.m1.1b"><times id="S5.T3.25.25.1.m1.1.1.cmml" xref="S5.T3.25.25.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.25.25.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.26.26.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.26.26.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.26.26.2.m1.1a"><mo mathsize="80%" id="S5.T3.26.26.2.m1.1.1" xref="S5.T3.26.26.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.26.26.2.m1.1b"><times id="S5.T3.26.26.2.m1.1.1.cmml" xref="S5.T3.26.26.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.26.26.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.27.27.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.27.27.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.27.27.3.m1.1a"><mo mathsize="80%" id="S5.T3.27.27.3.m1.1.1" xref="S5.T3.27.27.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.27.27.3.m1.1b"><times id="S5.T3.27.27.3.m1.1.1.cmml" xref="S5.T3.27.27.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.27.27.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.28.28.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.28.28.4.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.28.28.4.m1.1a"><mo mathsize="80%" id="S5.T3.28.28.4.m1.1.1" xref="S5.T3.28.28.4.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.28.28.4.m1.1b"><ci id="S5.T3.28.28.4.m1.1.1.cmml" xref="S5.T3.28.28.4.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.28.28.4.m1.1c">\bigcirc</annotation></semantics></math></td>
<td id="S5.T3.29.29.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.29.29.5.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.29.29.5.m1.1a"><mo mathsize="80%" id="S5.T3.29.29.5.m1.1.1" xref="S5.T3.29.29.5.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.29.29.5.m1.1b"><ci id="S5.T3.29.29.5.m1.1.1.cmml" xref="S5.T3.29.29.5.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.29.29.5.m1.1c">\bigcirc</annotation></semantics></math></td>
<td id="S5.T3.30.30.6" class="ltx_td ltx_align_center" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.30.30.6.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.30.30.6.m1.1a"><mo mathsize="80%" id="S5.T3.30.30.6.m1.1.1" xref="S5.T3.30.30.6.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.30.30.6.m1.1b"><ci id="S5.T3.30.30.6.m1.1.1.cmml" xref="S5.T3.30.30.6.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.30.30.6.m1.1c">\bigcirc</annotation></semantics></math></td>
</tr>
<tr id="S5.T3.36.36" class="ltx_tr">
<th id="S5.T3.36.36.7" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T3.36.36.7.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib103" title="" class="ltx_ref">103</a><span id="S5.T3.36.36.7.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S5.T3.31.31.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.31.31.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.31.31.1.m1.1a"><mo mathsize="80%" id="S5.T3.31.31.1.m1.1.1" xref="S5.T3.31.31.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.31.31.1.m1.1b"><times id="S5.T3.31.31.1.m1.1.1.cmml" xref="S5.T3.31.31.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.31.31.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.32.32.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.32.32.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.32.32.2.m1.1a"><mo mathsize="80%" id="S5.T3.32.32.2.m1.1.1" xref="S5.T3.32.32.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.32.32.2.m1.1b"><times id="S5.T3.32.32.2.m1.1.1.cmml" xref="S5.T3.32.32.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.32.32.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.33.33.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.33.33.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.33.33.3.m1.1a"><mo mathsize="80%" id="S5.T3.33.33.3.m1.1.1" xref="S5.T3.33.33.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.33.33.3.m1.1b"><times id="S5.T3.33.33.3.m1.1.1.cmml" xref="S5.T3.33.33.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.33.33.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.34.34.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.34.34.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.34.34.4.m1.1a"><mo mathsize="80%" id="S5.T3.34.34.4.m1.1.1" xref="S5.T3.34.34.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.34.34.4.m1.1b"><times id="S5.T3.34.34.4.m1.1.1.cmml" xref="S5.T3.34.34.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.34.34.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.35.35.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.35.35.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.35.35.5.m1.1a"><mo mathsize="80%" id="S5.T3.35.35.5.m1.1.1" xref="S5.T3.35.35.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.35.35.5.m1.1b"><times id="S5.T3.35.35.5.m1.1.1.cmml" xref="S5.T3.35.35.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.35.35.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.36.36.6" class="ltx_td ltx_align_center" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.36.36.6.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.36.36.6.m1.1a"><mo mathsize="80%" id="S5.T3.36.36.6.m1.1.1" xref="S5.T3.36.36.6.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.36.36.6.m1.1b"><csymbol cd="latexml" id="S5.T3.36.36.6.m1.1.1.cmml" xref="S5.T3.36.36.6.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.36.36.6.m1.1c">\surd</annotation></semantics></math></td>
</tr>
<tr id="S5.T3.42.42" class="ltx_tr">
<th id="S5.T3.42.42.7" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T3.42.42.7.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib104" title="" class="ltx_ref">104</a><span id="S5.T3.42.42.7.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S5.T3.37.37.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.37.37.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.37.37.1.m1.1a"><mo mathsize="80%" id="S5.T3.37.37.1.m1.1.1" xref="S5.T3.37.37.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.37.37.1.m1.1b"><times id="S5.T3.37.37.1.m1.1.1.cmml" xref="S5.T3.37.37.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.37.37.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.38.38.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.38.38.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.38.38.2.m1.1a"><mo mathsize="80%" id="S5.T3.38.38.2.m1.1.1" xref="S5.T3.38.38.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.38.38.2.m1.1b"><times id="S5.T3.38.38.2.m1.1.1.cmml" xref="S5.T3.38.38.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.38.38.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.39.39.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.39.39.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.39.39.3.m1.1a"><mo mathsize="80%" id="S5.T3.39.39.3.m1.1.1" xref="S5.T3.39.39.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.39.39.3.m1.1b"><times id="S5.T3.39.39.3.m1.1.1.cmml" xref="S5.T3.39.39.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.39.39.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.40.40.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.40.40.4.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.40.40.4.m1.1a"><mo mathsize="80%" id="S5.T3.40.40.4.m1.1.1" xref="S5.T3.40.40.4.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.40.40.4.m1.1b"><ci id="S5.T3.40.40.4.m1.1.1.cmml" xref="S5.T3.40.40.4.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.40.40.4.m1.1c">\bigcirc</annotation></semantics></math></td>
<td id="S5.T3.41.41.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.41.41.5.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.41.41.5.m1.1a"><mo mathsize="80%" id="S5.T3.41.41.5.m1.1.1" xref="S5.T3.41.41.5.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.41.41.5.m1.1b"><ci id="S5.T3.41.41.5.m1.1.1.cmml" xref="S5.T3.41.41.5.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.41.41.5.m1.1c">\bigcirc</annotation></semantics></math></td>
<td id="S5.T3.42.42.6" class="ltx_td ltx_align_center" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.42.42.6.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.42.42.6.m1.1a"><mo mathsize="80%" id="S5.T3.42.42.6.m1.1.1" xref="S5.T3.42.42.6.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.42.42.6.m1.1b"><csymbol cd="latexml" id="S5.T3.42.42.6.m1.1.1.cmml" xref="S5.T3.42.42.6.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.42.42.6.m1.1c">\surd</annotation></semantics></math></td>
</tr>
<tr id="S5.T3.48.48" class="ltx_tr">
<th id="S5.T3.48.48.7" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T3.48.48.7.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib29" title="" class="ltx_ref">29</a><span id="S5.T3.48.48.7.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S5.T3.43.43.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.43.43.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.43.43.1.m1.1a"><mo mathsize="80%" id="S5.T3.43.43.1.m1.1.1" xref="S5.T3.43.43.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.43.43.1.m1.1b"><times id="S5.T3.43.43.1.m1.1.1.cmml" xref="S5.T3.43.43.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.43.43.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.44.44.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.44.44.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.44.44.2.m1.1a"><mo mathsize="80%" id="S5.T3.44.44.2.m1.1.1" xref="S5.T3.44.44.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.44.44.2.m1.1b"><times id="S5.T3.44.44.2.m1.1.1.cmml" xref="S5.T3.44.44.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.44.44.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.45.45.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.45.45.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.45.45.3.m1.1a"><mo mathsize="80%" id="S5.T3.45.45.3.m1.1.1" xref="S5.T3.45.45.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.45.45.3.m1.1b"><times id="S5.T3.45.45.3.m1.1.1.cmml" xref="S5.T3.45.45.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.45.45.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.46.46.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.46.46.4.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.46.46.4.m1.1a"><mo mathsize="80%" id="S5.T3.46.46.4.m1.1.1" xref="S5.T3.46.46.4.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.46.46.4.m1.1b"><csymbol cd="latexml" id="S5.T3.46.46.4.m1.1.1.cmml" xref="S5.T3.46.46.4.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.46.46.4.m1.1c">\surd</annotation></semantics></math></td>
<td id="S5.T3.47.47.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.47.47.5.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.47.47.5.m1.1a"><mo mathsize="80%" id="S5.T3.47.47.5.m1.1.1" xref="S5.T3.47.47.5.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.47.47.5.m1.1b"><ci id="S5.T3.47.47.5.m1.1.1.cmml" xref="S5.T3.47.47.5.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.47.47.5.m1.1c">\bigcirc</annotation></semantics></math></td>
<td id="S5.T3.48.48.6" class="ltx_td ltx_align_center" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.48.48.6.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.48.48.6.m1.1a"><mo mathsize="80%" id="S5.T3.48.48.6.m1.1.1" xref="S5.T3.48.48.6.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.48.48.6.m1.1b"><ci id="S5.T3.48.48.6.m1.1.1.cmml" xref="S5.T3.48.48.6.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.48.48.6.m1.1c">\bigcirc</annotation></semantics></math></td>
</tr>
<tr id="S5.T3.54.54" class="ltx_tr">
<th id="S5.T3.54.54.7" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T3.54.54.7.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib105" title="" class="ltx_ref">105</a><span id="S5.T3.54.54.7.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S5.T3.49.49.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.49.49.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.49.49.1.m1.1a"><mo mathsize="80%" id="S5.T3.49.49.1.m1.1.1" xref="S5.T3.49.49.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.49.49.1.m1.1b"><times id="S5.T3.49.49.1.m1.1.1.cmml" xref="S5.T3.49.49.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.49.49.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.50.50.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.50.50.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.50.50.2.m1.1a"><mo mathsize="80%" id="S5.T3.50.50.2.m1.1.1" xref="S5.T3.50.50.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.50.50.2.m1.1b"><times id="S5.T3.50.50.2.m1.1.1.cmml" xref="S5.T3.50.50.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.50.50.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.51.51.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.51.51.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.51.51.3.m1.1a"><mo mathsize="80%" id="S5.T3.51.51.3.m1.1.1" xref="S5.T3.51.51.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.51.51.3.m1.1b"><times id="S5.T3.51.51.3.m1.1.1.cmml" xref="S5.T3.51.51.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.51.51.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.52.52.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.52.52.4.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.52.52.4.m1.1a"><mo mathsize="80%" id="S5.T3.52.52.4.m1.1.1" xref="S5.T3.52.52.4.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.52.52.4.m1.1b"><csymbol cd="latexml" id="S5.T3.52.52.4.m1.1.1.cmml" xref="S5.T3.52.52.4.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.52.52.4.m1.1c">\surd</annotation></semantics></math></td>
<td id="S5.T3.53.53.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.53.53.5.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.53.53.5.m1.1a"><mo mathsize="80%" id="S5.T3.53.53.5.m1.1.1" xref="S5.T3.53.53.5.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.53.53.5.m1.1b"><ci id="S5.T3.53.53.5.m1.1.1.cmml" xref="S5.T3.53.53.5.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.53.53.5.m1.1c">\bigcirc</annotation></semantics></math></td>
<td id="S5.T3.54.54.6" class="ltx_td ltx_align_center" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.54.54.6.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.54.54.6.m1.1a"><mo mathsize="80%" id="S5.T3.54.54.6.m1.1.1" xref="S5.T3.54.54.6.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.54.54.6.m1.1b"><ci id="S5.T3.54.54.6.m1.1.1.cmml" xref="S5.T3.54.54.6.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.54.54.6.m1.1c">\bigcirc</annotation></semantics></math></td>
</tr>
<tr id="S5.T3.60.60" class="ltx_tr">
<th id="S5.T3.60.60.7" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T3.60.60.7.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib106" title="" class="ltx_ref">106</a><span id="S5.T3.60.60.7.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S5.T3.55.55.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.55.55.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.55.55.1.m1.1a"><mo mathsize="80%" id="S5.T3.55.55.1.m1.1.1" xref="S5.T3.55.55.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.55.55.1.m1.1b"><times id="S5.T3.55.55.1.m1.1.1.cmml" xref="S5.T3.55.55.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.55.55.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.56.56.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.56.56.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.56.56.2.m1.1a"><mo mathsize="80%" id="S5.T3.56.56.2.m1.1.1" xref="S5.T3.56.56.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.56.56.2.m1.1b"><times id="S5.T3.56.56.2.m1.1.1.cmml" xref="S5.T3.56.56.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.56.56.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.57.57.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.57.57.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.57.57.3.m1.1a"><mo mathsize="80%" id="S5.T3.57.57.3.m1.1.1" xref="S5.T3.57.57.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.57.57.3.m1.1b"><times id="S5.T3.57.57.3.m1.1.1.cmml" xref="S5.T3.57.57.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.57.57.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.58.58.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.58.58.4.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.58.58.4.m1.1a"><mo mathsize="80%" id="S5.T3.58.58.4.m1.1.1" xref="S5.T3.58.58.4.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.58.58.4.m1.1b"><ci id="S5.T3.58.58.4.m1.1.1.cmml" xref="S5.T3.58.58.4.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.58.58.4.m1.1c">\bigcirc</annotation></semantics></math></td>
<td id="S5.T3.59.59.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.59.59.5.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.59.59.5.m1.1a"><mo mathsize="80%" id="S5.T3.59.59.5.m1.1.1" xref="S5.T3.59.59.5.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.59.59.5.m1.1b"><ci id="S5.T3.59.59.5.m1.1.1.cmml" xref="S5.T3.59.59.5.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.59.59.5.m1.1c">\bigcirc</annotation></semantics></math></td>
<td id="S5.T3.60.60.6" class="ltx_td ltx_align_center" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.60.60.6.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.60.60.6.m1.1a"><mo mathsize="80%" id="S5.T3.60.60.6.m1.1.1" xref="S5.T3.60.60.6.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.60.60.6.m1.1b"><ci id="S5.T3.60.60.6.m1.1.1.cmml" xref="S5.T3.60.60.6.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.60.60.6.m1.1c">\bigcirc</annotation></semantics></math></td>
</tr>
<tr id="S5.T3.66.66" class="ltx_tr">
<th id="S5.T3.66.66.7" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T3.66.66.7.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib107" title="" class="ltx_ref">107</a><span id="S5.T3.66.66.7.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S5.T3.61.61.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.61.61.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.61.61.1.m1.1a"><mo mathsize="80%" id="S5.T3.61.61.1.m1.1.1" xref="S5.T3.61.61.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.61.61.1.m1.1b"><times id="S5.T3.61.61.1.m1.1.1.cmml" xref="S5.T3.61.61.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.61.61.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.62.62.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.62.62.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.62.62.2.m1.1a"><mo mathsize="80%" id="S5.T3.62.62.2.m1.1.1" xref="S5.T3.62.62.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.62.62.2.m1.1b"><times id="S5.T3.62.62.2.m1.1.1.cmml" xref="S5.T3.62.62.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.62.62.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.63.63.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.63.63.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.63.63.3.m1.1a"><mo mathsize="80%" id="S5.T3.63.63.3.m1.1.1" xref="S5.T3.63.63.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.63.63.3.m1.1b"><times id="S5.T3.63.63.3.m1.1.1.cmml" xref="S5.T3.63.63.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.63.63.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.64.64.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.64.64.4.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.64.64.4.m1.1a"><mo mathsize="80%" id="S5.T3.64.64.4.m1.1.1" xref="S5.T3.64.64.4.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.64.64.4.m1.1b"><csymbol cd="latexml" id="S5.T3.64.64.4.m1.1.1.cmml" xref="S5.T3.64.64.4.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.64.64.4.m1.1c">\surd</annotation></semantics></math></td>
<td id="S5.T3.65.65.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.65.65.5.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.65.65.5.m1.1a"><mo mathsize="80%" id="S5.T3.65.65.5.m1.1.1" xref="S5.T3.65.65.5.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.65.65.5.m1.1b"><ci id="S5.T3.65.65.5.m1.1.1.cmml" xref="S5.T3.65.65.5.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.65.65.5.m1.1c">\bigcirc</annotation></semantics></math></td>
<td id="S5.T3.66.66.6" class="ltx_td ltx_align_center" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.66.66.6.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.66.66.6.m1.1a"><mo mathsize="80%" id="S5.T3.66.66.6.m1.1.1" xref="S5.T3.66.66.6.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.66.66.6.m1.1b"><csymbol cd="latexml" id="S5.T3.66.66.6.m1.1.1.cmml" xref="S5.T3.66.66.6.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.66.66.6.m1.1c">\surd</annotation></semantics></math></td>
</tr>
<tr id="S5.T3.72.72" class="ltx_tr">
<th id="S5.T3.72.72.7" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T3.72.72.7.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib108" title="" class="ltx_ref">108</a><span id="S5.T3.72.72.7.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S5.T3.67.67.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.67.67.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.67.67.1.m1.1a"><mo mathsize="80%" id="S5.T3.67.67.1.m1.1.1" xref="S5.T3.67.67.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.67.67.1.m1.1b"><times id="S5.T3.67.67.1.m1.1.1.cmml" xref="S5.T3.67.67.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.67.67.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.68.68.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.68.68.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.68.68.2.m1.1a"><mo mathsize="80%" id="S5.T3.68.68.2.m1.1.1" xref="S5.T3.68.68.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.68.68.2.m1.1b"><times id="S5.T3.68.68.2.m1.1.1.cmml" xref="S5.T3.68.68.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.68.68.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.69.69.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.69.69.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.69.69.3.m1.1a"><mo mathsize="80%" id="S5.T3.69.69.3.m1.1.1" xref="S5.T3.69.69.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.69.69.3.m1.1b"><times id="S5.T3.69.69.3.m1.1.1.cmml" xref="S5.T3.69.69.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.69.69.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T3.70.70.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.70.70.4.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.70.70.4.m1.1a"><mo mathsize="80%" id="S5.T3.70.70.4.m1.1.1" xref="S5.T3.70.70.4.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.70.70.4.m1.1b"><csymbol cd="latexml" id="S5.T3.70.70.4.m1.1.1.cmml" xref="S5.T3.70.70.4.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.70.70.4.m1.1c">\surd</annotation></semantics></math></td>
<td id="S5.T3.71.71.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.71.71.5.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.71.71.5.m1.1a"><mo mathsize="80%" id="S5.T3.71.71.5.m1.1.1" xref="S5.T3.71.71.5.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.71.71.5.m1.1b"><ci id="S5.T3.71.71.5.m1.1.1.cmml" xref="S5.T3.71.71.5.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.71.71.5.m1.1c">\bigcirc</annotation></semantics></math></td>
<td id="S5.T3.72.72.6" class="ltx_td ltx_align_center" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.72.72.6.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.72.72.6.m1.1a"><mo mathsize="80%" id="S5.T3.72.72.6.m1.1.1" xref="S5.T3.72.72.6.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.72.72.6.m1.1b"><csymbol cd="latexml" id="S5.T3.72.72.6.m1.1.1.cmml" xref="S5.T3.72.72.6.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.72.72.6.m1.1c">\surd</annotation></semantics></math></td>
</tr>
<tr id="S5.T3.78.78" class="ltx_tr">
<th id="S5.T3.78.78.7" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T3.78.78.7.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib109" title="" class="ltx_ref">109</a><span id="S5.T3.78.78.7.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S5.T3.73.73.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.73.73.1.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.73.73.1.m1.1a"><mo mathsize="80%" id="S5.T3.73.73.1.m1.1.1" xref="S5.T3.73.73.1.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.73.73.1.m1.1b"><ci id="S5.T3.73.73.1.m1.1.1.cmml" xref="S5.T3.73.73.1.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.73.73.1.m1.1c">\bigcirc</annotation></semantics></math></td>
<td id="S5.T3.74.74.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.74.74.2.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.74.74.2.m1.1a"><mo mathsize="80%" id="S5.T3.74.74.2.m1.1.1" xref="S5.T3.74.74.2.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.74.74.2.m1.1b"><ci id="S5.T3.74.74.2.m1.1.1.cmml" xref="S5.T3.74.74.2.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.74.74.2.m1.1c">\bigcirc</annotation></semantics></math></td>
<td id="S5.T3.75.75.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.75.75.3.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.75.75.3.m1.1a"><mo mathsize="80%" id="S5.T3.75.75.3.m1.1.1" xref="S5.T3.75.75.3.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.75.75.3.m1.1b"><ci id="S5.T3.75.75.3.m1.1.1.cmml" xref="S5.T3.75.75.3.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.75.75.3.m1.1c">\bigcirc</annotation></semantics></math></td>
<td id="S5.T3.76.76.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.76.76.4.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.76.76.4.m1.1a"><mo mathsize="80%" id="S5.T3.76.76.4.m1.1.1" xref="S5.T3.76.76.4.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.76.76.4.m1.1b"><csymbol cd="latexml" id="S5.T3.76.76.4.m1.1.1.cmml" xref="S5.T3.76.76.4.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.76.76.4.m1.1c">\surd</annotation></semantics></math></td>
<td id="S5.T3.77.77.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.77.77.5.m1.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.77.77.5.m1.1a"><mo mathsize="80%" id="S5.T3.77.77.5.m1.1.1" xref="S5.T3.77.77.5.m1.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.77.77.5.m1.1b"><ci id="S5.T3.77.77.5.m1.1.1.cmml" xref="S5.T3.77.77.5.m1.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.77.77.5.m1.1c">\bigcirc</annotation></semantics></math></td>
<td id="S5.T3.78.78.6" class="ltx_td ltx_align_center" style="padding-top:0.8pt;padding-bottom:0.8pt;"><math id="S5.T3.78.78.6.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.78.78.6.m1.1a"><mo mathsize="80%" id="S5.T3.78.78.6.m1.1.1" xref="S5.T3.78.78.6.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.78.78.6.m1.1b"><csymbol cd="latexml" id="S5.T3.78.78.6.m1.1.1.cmml" xref="S5.T3.78.78.6.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.78.78.6.m1.1c">\surd</annotation></semantics></math></td>
</tr>
</tbody>
<tfoot class="ltx_tfoot">
<tr id="S5.T3.81.81" class="ltx_tr">
<th id="S5.T3.81.81.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;" colspan="7">
<math id="S5.T3.79.79.1.m1.1" class="ltx_Math" alttext="\surd" display="inline"><semantics id="S5.T3.79.79.1.m1.1a"><mo mathsize="80%" id="S5.T3.79.79.1.m1.1.1" xref="S5.T3.79.79.1.m1.1.1.cmml">√</mo><annotation-xml encoding="MathML-Content" id="S5.T3.79.79.1.m1.1b"><csymbol cd="latexml" id="S5.T3.79.79.1.m1.1.1.cmml" xref="S5.T3.79.79.1.m1.1.1">square-root</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.79.79.1.m1.1c">\surd</annotation></semantics></math><span id="S5.T3.81.81.3.1" class="ltx_text" style="font-size:80%;"> Fully resistant to the attack; </span><math id="S5.T3.80.80.2.m2.1" class="ltx_Math" alttext="\bigcirc" display="inline"><semantics id="S5.T3.80.80.2.m2.1a"><mo mathsize="80%" id="S5.T3.80.80.2.m2.1.1" xref="S5.T3.80.80.2.m2.1.1.cmml">○</mo><annotation-xml encoding="MathML-Content" id="S5.T3.80.80.2.m2.1b"><ci id="S5.T3.80.80.2.m2.1.1.cmml" xref="S5.T3.80.80.2.m2.1.1">○</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.80.80.2.m2.1c">\bigcirc</annotation></semantics></math><span id="S5.T3.81.81.3.2" class="ltx_text" style="font-size:80%;"> Partially resistant to the attack; </span><math id="S5.T3.81.81.3.m3.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T3.81.81.3.m3.1a"><mo mathsize="80%" id="S5.T3.81.81.3.m3.1.1" xref="S5.T3.81.81.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.81.81.3.m3.1b"><times id="S5.T3.81.81.3.m3.1.1.cmml" xref="S5.T3.81.81.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.81.81.3.m3.1c">\times</annotation></semantics></math><span id="S5.T3.81.81.3.3" class="ltx_text" style="font-size:80%;"> Not resistant to the attack.</span>
</th>
</tr>
<tr id="S5.T3.81.83.1" class="ltx_tr">
<th id="S5.T3.81.83.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:0.8pt;padding-bottom:0.8pt;" colspan="7">
<sup id="S5.T3.81.83.1.1.1" class="ltx_sup"><span id="S5.T3.81.83.1.1.1.1" class="ltx_text" style="font-size:80%;">1</span></sup><span id="S5.T3.81.83.1.1.2" class="ltx_text" style="font-size:80%;"> Reference paper that belongs to the specific group.</span>
</th>
</tr>
<tr id="S5.T3.81.84.2" class="ltx_tr">
<th id="S5.T3.81.84.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:0.8pt;padding-bottom:0.8pt;" colspan="7">
<sup id="S5.T3.81.84.2.1.1" class="ltx_sup"><span id="S5.T3.81.84.2.1.1.1" class="ltx_text" style="font-size:80%;">2</span></sup><span id="S5.T3.81.84.2.1.2" class="ltx_text" style="font-size:80%;"> Background Knowledge Attack.</span>
</th>
</tr>
</tfoot>
</table>
</figure>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Privacy on Heterogeneous Devices</h3>

<div id="S5.SS1.p1" class="ltx_para">
<span id="S5.SS1.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S5.SS1.p1.2" class="ltx_p">Differential privacy stands as a promising methodology embraced within various AFL schemes to protect the privacy of local models, consequently mitigating the risk of local training data leakage on heterogeneous devices.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<span id="S5.SS1.p2.1" class="ltx_ERROR undefined">\add</span>
<p id="S5.SS1.p2.2" class="ltx_p">For instance, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>, a flexible FL scheme with differential privacy is proposed to avoid disclosing local training data. Each node employs Gaussian differential privacy to achieve a better trade-off between data privacy and data utility. <span id="S5.SS1.p2.2.1" class="ltx_ERROR undefined">\add</span>However, a universal differential privacy setting lacks flexibility across heterogeneous devices. Consequently, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite>, the authors proposed an AFL scheme adopting local differential privacy for secure resource sharing in vehicular networks. Particularly, a tree-based gradient descent model is adopted on nodes to achieve high global model accuracy in a short amount of time. To protect the privacy of local models, a distributed local model updating approach with Gaussian noise is introduced to nodes in the regression tree. By offering rewards, nodes are encouraged to provide good models, thereby accelerating the convergence process. The experiment carried out on three real-world datasets demonstrates the high accuracy and efficiency of the scheme.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<span id="S5.SS1.p3.1" class="ltx_ERROR undefined">\add</span>
<p id="S5.SS1.p3.2" class="ltx_p">Apart from investigating personalized differential privacy, some researchers focus on the balance between model utility and privacy protection. For example, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>, the convergence of AFL while adopting differential privacy is analyzed. Based on the analysis, a multi-stage adjustable algorithm is proposed to optimize the trade-off between model utility and privacy by dynamically changing the noise size and the learning rate. Experiments are conducted on edge servers and a cloud server with three different ML models, including logistic regression (LR), support vector machine (SVM), and convolutional neural network (CNN). The results reveal that MAPA achieves high model utilities and accuracy at the same time.
Furthermore, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite>, differential privacy is introduced into AFL by adding Gaussian noise. The authors begin AFL training with a high learning rate and gradually reduce it to achieve optimum accuracy. The theoretical analysis and simulation results prove that their scheme reduces the network communication cost on heterogeneous devices.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Security on Heterogeneous Devices</h3>

<div id="S5.SS2.p1" class="ltx_para">
<span id="S5.SS2.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S5.SS2.p1.2" class="ltx_p">When training ML models on heterogeneous devices, the blockchain is typically leveraged as a secure distributed database to ensure the secure storage or transmission of local models within AFL. The advantages of the integration include privacy protection and trust promotion among heterogeneous devices. For example, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite>, blockchain and digital twin edge network are integrated to store all local gradient updates in AFL. Specifically, the blockchain is adopted to track the aggregation progress by maintaining a global iteration index in AFL. A lightweight DPoS-based verification mechanism is developed, where stakes are earned based on the computing contribution to the global model. The mechanism is accomplished through the verification algorithm, which verifies the quality of the models against the historical model. In addition, a reinforcement learning-based algorithm is designed for efficient user scheduling and bandwidth allocation. A series of experiments are conducted to evaluate the performance of the scheme in terms of learning accuracy and resource cost. Another similar idea proposed by the same authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite> is to integrate blockchain, FL, and an asynchronous model update scheme in digital twin edge networks. The objective of lowering communication costs includes two parts: reducing transmission data size and optimizing communication resource allocation. Finally, the communication resource allocation approach is implemented by using deep neural networks. Numerical results reveal that this scheme improves communication efficiency and reduces the cost of resources. <span id="S5.SS2.p1.2.1" class="ltx_ERROR undefined">\add</span>Apart from improving communication efficiency, some researchers focus on improving learning efficiency when integrating AFL with blockchain. The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite> present an AFL scheme coupled with the Directed Acyclic Graph (DAG) blockchain for the Internet of Vehicles (IoV). The participating nodes are selected by Deep Reinforcement Learning (DRL) to improve the learning efficiency. Besides, a two-stage verification mechanism is developed, which comprises periodic validation of blockchain transactions and validation of local model quality. Experimental results show the excellent learning accuracy and rapid convergence speed of the scheme.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<span id="S5.SS2.p2.1" class="ltx_ERROR undefined">\add</span>
<p id="S5.SS2.p2.2" class="ltx_p">Another advantage of the integration is mitigating the risk of single-point failure caused by the centralized aggregation server. For instance, a blockchain-based AFL scheme with a staleness coefficient is proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. Specifically, the staleness coefficient reduces the contribution from the latency device to the global model by comparing the version of the global model with the stale local model. The Proof-of-Work (PoW) consensus algorithm is adopted, where the miners are responsible for generating candidate blocks that include trained models. The block generation rate is positively correlated with the forking frequency. The experiments carried out on a variety of IoT devices demonstrate high accuracy on both horizontal and vertical FL frameworks. Another similar idea with a staleness coefficient is proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>, <a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite>. Instead of using PoW, a committee-based consensus algorithm is adopted to improve efficiency further. The convergence speed and model accuracy are both validated by experiments on heterogeneous devices. <span id="S5.SS2.p2.2.1" class="ltx_ERROR undefined">\add</span>Instead of staleness coefficient, some researchers pay attention to the architecture of the integration. For instance, to mitigate the risk of single-point failure and malicious nodes attacks, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite> propose a two-layer blockchain-driven FL framework composed of multiple Raft-based shard networks (layer-1) and a DAG-based main chain (layer-2). Layer-1 is a small group for information exchange, while layer-2 is responsible for storing and sharing models trained by layer-1 asynchronously. Furthermore, to avoid the impact of stale models, a virtual pruning procedure with a specific waiting time is presented. Models not approved by other models for a long time or with low accuracy will be pruned from the DAG blockchain. The experiment results show that this scheme is resilient against malicious nodes while maintaining acceptable convergence rates.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<span id="S5.SS2.p3.1" class="ltx_ERROR undefined">\add</span>
<p id="S5.SS2.p3.2" class="ltx_p">Additionally, the reputation of nodes is an important factor to be considered to improve the stability and security of AFL, which is easily handled by the blockchain by its built-in reputation and reward systems. For example, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite>, a blockchain-based AFL scheme is proposed, where an entropy weight method determines the participant rank by the proportion of local models trained on nodes. The metrics are all maintained in the blockchain, including the training time, training sample size, local update correlation, and global update cheating times.
The resource cost and training efficiency are well balanced by optimizing local training delays and the block generation rate. The experiment results show the superiority of the scheme in terms of efficiency and preventing poisoning attacks.</p>
</div>
<div id="S5.SS2.p4" class="ltx_para">
<span id="S5.SS2.p4.1" class="ltx_ERROR undefined">\add</span>
<p id="S5.SS2.p4.2" class="ltx_p">Moreover, some researchers investigate the effect of the gradient compression algorithm on the integration of blockchain and AFL, aiming at improving security and efficiency simultaneously. For example, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite>, the authors propose a SignSGD-based asynchronous federated learning paradigm (BASS) that only uploads the signs of the gradients of local models to the aggregation server, mitigating the risks of poisoning attacks. Theoretically, their paradigm is able to resist both privacy and security attacks at the cost of model convergence speed or accuracy. However, they fails to validate the performance of their paradigm in privacy preserving.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Applications on Heterogeneous Devices</h2>

<div id="S6.p1" class="ltx_para">
<span id="S6.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S6.p1.2" class="ltx_p">AFL is adopted in various application scenarios, offering an efficient and adaptable training procedure on heterogeneous devices while upholding the privacy of local training data. The application scenarios of AFL and correlated research endeavors are summarized and compared in Table <a href="#S6.T4" title="Table 4 ‣ 6 Applications on Heterogeneous Devices ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S6.T4" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>The Applications on Heterogeneous Devices</figcaption>
<table id="S6.T4.3" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T4.3.1.1" class="ltx_tr">
<td id="S6.T4.3.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.1.1.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S6.T4.3.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Ref.<span id="footnotex6" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex6.1.1.1" class="ltx_text ltx_font_medium" style="font-size:125%;">1</span></span></span></span></span></span></td>
<td id="S6.T4.3.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Use Case</span></td>
<td id="S6.T4.3.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">FL Client &amp; Server</span></td>
<td id="S6.T4.3.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.1.1.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.1.1.5.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Key Contributions</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.2.2" class="ltx_tr">
<td id="S6.T4.3.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.2.2.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S6.T4.3.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.T4.3.2.2.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib104" title="" class="ltx_ref">104</a><span id="S6.T4.3.2.2.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S6.T4.3.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.2.2.3.1" class="ltx_text" style="font-size:80%;">IoV</span></td>
<td id="S6.T4.3.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.2.2.4.1" class="ltx_text" style="font-size:80%;">Vehicle &amp; MBS</span></td>
<td id="S6.T4.3.2.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.2.2.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.2.2.5.1.1.1" class="ltx_text" style="font-size:80%;">Improve reliability and efficiency of data sharing and traffic prediction among vehicles.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.3.3" class="ltx_tr">
<td id="S6.T4.3.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.3.3.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S6.T4.3.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.T4.3.3.3.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib99" title="" class="ltx_ref">99</a><span id="S6.T4.3.3.3.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S6.T4.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.3.3.3.1" class="ltx_text" style="font-size:80%;">IoV</span></td>
<td id="S6.T4.3.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.3.3.4.1" class="ltx_text" style="font-size:80%;">Vehicle &amp; MBS, RSU</span></td>
<td id="S6.T4.3.3.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.3.3.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.3.3.5.1.1.1" class="ltx_text" style="font-size:80%;">Efficiently and securely allocate resources for vehicles.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.4.4" class="ltx_tr">
<td id="S6.T4.3.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.4.4.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S6.T4.3.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.T4.3.4.4.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib102" title="" class="ltx_ref">102</a><span id="S6.T4.3.4.4.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S6.T4.3.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.4.4.3.1" class="ltx_text" style="font-size:80%;">IoV</span></td>
<td id="S6.T4.3.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.4.4.4.1" class="ltx_text" style="font-size:80%;">IoT &amp; Base Station</span></td>
<td id="S6.T4.3.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.4.4.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.4.4.5.1.1.1" class="ltx_text" style="font-size:80%;">Provide high-quality services with optimized network and resources allocation.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.5.5" class="ltx_tr">
<td id="S6.T4.3.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.5.5.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S6.T4.3.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.T4.3.5.5.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib110" title="" class="ltx_ref">110</a><span id="S6.T4.3.5.5.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S6.T4.3.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.5.5.3.1" class="ltx_text" style="font-size:80%;">IoV</span></td>
<td id="S6.T4.3.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.5.5.4.1" class="ltx_text" style="font-size:80%;">Vehicle &amp; Server</span></td>
<td id="S6.T4.3.5.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.5.5.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.5.5.5.1.1.1" class="ltx_text" style="font-size:80%;">Predict real-time steering wheel angle for autonomous driving.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.6.6" class="ltx_tr">
<td id="S6.T4.3.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.6.6.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S6.T4.3.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.T4.3.6.6.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib68" title="" class="ltx_ref">68</a><span id="S6.T4.3.6.6.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S6.T4.3.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.6.6.3.1" class="ltx_text" style="font-size:80%;">IoV</span></td>
<td id="S6.T4.3.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.6.6.4.1" class="ltx_text" style="font-size:80%;">Camera &amp; Server</span></td>
<td id="S6.T4.3.6.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.6.6.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.6.6.5.1.1.1" class="ltx_text" style="font-size:80%;">Monitor, predict, and adjust traffic by controlling signal lights.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.7.7" class="ltx_tr">
<td id="S6.T4.3.7.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.7.7.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S6.T4.3.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.T4.3.7.7.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib64" title="" class="ltx_ref">64</a><span id="S6.T4.3.7.7.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S6.T4.3.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.7.7.3.1" class="ltx_text" style="font-size:80%;">IoV</span></td>
<td id="S6.T4.3.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.7.7.4.1" class="ltx_text" style="font-size:80%;">Camera &amp; Server</span></td>
<td id="S6.T4.3.7.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.7.7.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.7.7.5.1.1.1" class="ltx_text" style="font-size:80%;">Monitor, predict, and adjust traffic by controlling signal lights.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.8.8" class="ltx_tr">
<td id="S6.T4.3.8.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.8.8.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S6.T4.3.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.T4.3.8.8.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib111" title="" class="ltx_ref">111</a><span id="S6.T4.3.8.8.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S6.T4.3.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.8.8.3.1" class="ltx_text" style="font-size:80%;">UAV</span></td>
<td id="S6.T4.3.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.8.8.4.1" class="ltx_text" style="font-size:80%;">Mobile &amp; UAV</span></td>
<td id="S6.T4.3.8.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.8.8.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.8.8.5.1.1.1" class="ltx_text" style="font-size:80%;">Provide efficient communication and computation services for ground mobile devices in outdoor events.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.9.9" class="ltx_tr">
<td id="S6.T4.3.9.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.9.9.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S6.T4.3.9.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.T4.3.9.9.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib83" title="" class="ltx_ref">83</a><span id="S6.T4.3.9.9.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S6.T4.3.9.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.9.9.3.1" class="ltx_text" style="font-size:80%;">UAV</span></td>
<td id="S6.T4.3.9.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.9.9.4.1" class="ltx_text" style="font-size:80%;">Mobile &amp; UAV</span></td>
<td id="S6.T4.3.9.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.9.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.9.9.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.9.9.5.1.1.1" class="ltx_text" style="font-size:80%;">Provide a content caching system in UAV networks to extend the service coverage and reduce the communication delay of the 6G network.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.10.10" class="ltx_tr">
<td id="S6.T4.3.10.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.10.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.10.10.1.1.1" class="ltx_p" style="width:26.0pt;"><span id="S6.T4.3.10.10.1.1.1.1" class="ltx_text" style="font-size:80%;">
<span id="S6.T4.3.10.10.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:7.0pt;height:76.5pt;vertical-align:-36.3pt;"><span class="ltx_transformed_inner" style="width:76.6pt;transform:translate(-34.77pt,2.33pt) rotate(-90deg) ;">
<span id="S6.T4.3.10.10.1.1.1.1.1.1" class="ltx_p">Smart Transportation</span>
</span></span></span></span>
</span>
</td>
<td id="S6.T4.3.10.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.T4.3.10.10.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib51" title="" class="ltx_ref">51</a><span id="S6.T4.3.10.10.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S6.T4.3.10.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.10.10.3.1" class="ltx_text" style="font-size:80%;">Mobile Robot</span></td>
<td id="S6.T4.3.10.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.10.10.4.1" class="ltx_text" style="font-size:80%;">Robot &amp; Server</span></td>
<td id="S6.T4.3.10.10.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.10.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.10.10.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.10.10.5.1.1.1" class="ltx_text" style="font-size:80%;">Improve the performance of the ML models on mobile robots with low communication costs.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.11.11" class="ltx_tr">
<td id="S6.T4.3.11.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.11.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.11.11.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S6.T4.3.11.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.T4.3.11.11.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib112" title="" class="ltx_ref">112</a><span id="S6.T4.3.11.11.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S6.T4.3.11.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.11.11.3.1" class="ltx_text" style="font-size:80%;">Fault Diagnosis</span></td>
<td id="S6.T4.3.11.11.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.11.11.4.1" class="ltx_text" style="font-size:80%;">Edge &amp; Server</span></td>
<td id="S6.T4.3.11.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.11.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.11.11.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.11.11.5.1.1.1" class="ltx_text" style="font-size:80%;">Track actual system changes in real-time and improve the diagnostic rate of the devices.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.12.12" class="ltx_tr">
<td id="S6.T4.3.12.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.12.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.12.12.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S6.T4.3.12.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.T4.3.12.12.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib88" title="" class="ltx_ref">88</a><span id="S6.T4.3.12.12.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S6.T4.3.12.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.12.12.3.1" class="ltx_text" style="font-size:80%;">Fault Diagnosis</span></td>
<td id="S6.T4.3.12.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.12.12.4.1" class="ltx_text" style="font-size:80%;">Edge &amp; Server</span></td>
<td id="S6.T4.3.12.12.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.12.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.12.12.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.12.12.5.1.1.1" class="ltx_text" style="font-size:80%;">Train the denoising autoencoder model for anomaly detection.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.13.13" class="ltx_tr">
<td id="S6.T4.3.13.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.13.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.13.13.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S6.T4.3.13.13.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.T4.3.13.13.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib113" title="" class="ltx_ref">113</a><span id="S6.T4.3.13.13.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S6.T4.3.13.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.13.13.3.1" class="ltx_text" style="font-size:80%;">Code Security</span></td>
<td id="S6.T4.3.13.13.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.13.13.4.1" class="ltx_text" style="font-size:80%;">Edge &amp; Server</span></td>
<td id="S6.T4.3.13.13.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.13.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.13.13.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.13.13.5.1.1.1" class="ltx_text" style="font-size:80%;">Effectively and securely review and identify sensitive information in code before publishing.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.14.14" class="ltx_tr">
<td id="S6.T4.3.14.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.14.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.14.14.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S6.T4.3.14.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.T4.3.14.14.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib65" title="" class="ltx_ref">65</a><span id="S6.T4.3.14.14.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S6.T4.3.14.14.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.14.14.3.1" class="ltx_text" style="font-size:80%;">Fault Diagnosis</span></td>
<td id="S6.T4.3.14.14.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.14.14.4.1" class="ltx_text" style="font-size:80%;">Edge &amp; Server</span></td>
<td id="S6.T4.3.14.14.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.14.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.14.14.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.14.14.5.1.1.1" class="ltx_text" style="font-size:80%;">Efficiently identify possible faults in edge nodes while reducing the resource requirements and communication overhead.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.15.15" class="ltx_tr">
<td id="S6.T4.3.15.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.15.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.15.15.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S6.T4.3.15.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.T4.3.15.15.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib82" title="" class="ltx_ref">82</a><span id="S6.T4.3.15.15.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S6.T4.3.15.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.15.15.3.1" class="ltx_text" style="font-size:80%;">IIoT</span></td>
<td id="S6.T4.3.15.15.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.15.15.4.1" class="ltx_text" style="font-size:80%;">IoT &amp; Edge</span></td>
<td id="S6.T4.3.15.15.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.15.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.15.15.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.15.15.5.1.1.1" class="ltx_text" style="font-size:80%;">Address the data island problem in IIoT for dynamic perception and intelligent decision.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.16.16" class="ltx_tr">
<td id="S6.T4.3.16.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.16.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.16.16.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S6.T4.3.16.16.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.T4.3.16.16.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib103" title="" class="ltx_ref">103</a><span id="S6.T4.3.16.16.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S6.T4.3.16.16.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.16.16.3.1" class="ltx_text" style="font-size:80%;">IIoT</span></td>
<td id="S6.T4.3.16.16.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.16.16.4.1" class="ltx_text" style="font-size:80%;">IoT &amp; Edge</span></td>
<td id="S6.T4.3.16.16.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.16.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.16.16.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.16.16.5.1.1.1" class="ltx_text" style="font-size:80%;">Improve the quality of services and implement real-time interactions in IIoT while reducing the communication cost.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.17.17" class="ltx_tr">
<td id="S6.T4.3.17.17.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.17.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.17.17.1.1.1" class="ltx_p" style="width:26.0pt;"></span>
</span>
</td>
<td id="S6.T4.3.17.17.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.T4.3.17.17.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib114" title="" class="ltx_ref">114</a><span id="S6.T4.3.17.17.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S6.T4.3.17.17.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.17.17.3.1" class="ltx_text" style="font-size:80%;">Concept Drift</span></td>
<td id="S6.T4.3.17.17.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.17.17.4.1" class="ltx_text" style="font-size:80%;">Edge &amp; Server</span></td>
<td id="S6.T4.3.17.17.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.17.17.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.17.17.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.17.17.5.1.1.1" class="ltx_text" style="font-size:80%;">Speed up model convergence for detecting and dealing with the concept drift on edge.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.18.18" class="ltx_tr">
<td id="S6.T4.3.18.18.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.18.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.18.18.1.1.1" class="ltx_p" style="width:26.0pt;"><span id="S6.T4.3.18.18.1.1.1.1" class="ltx_text" style="font-size:80%;">
<span id="S6.T4.3.18.18.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:7.1pt;height:53.8pt;vertical-align:-24.9pt;"><span class="ltx_transformed_inner" style="width:53.9pt;transform:translate(-23.38pt,2.33pt) rotate(-90deg) ;">
<span id="S6.T4.3.18.18.1.1.1.1.1.1" class="ltx_p">Smart Industry</span>
</span></span></span></span>
</span>
</td>
<td id="S6.T4.3.18.18.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.T4.3.18.18.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib115" title="" class="ltx_ref">115</a><span id="S6.T4.3.18.18.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></td>
<td id="S6.T4.3.18.18.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.18.18.3.1" class="ltx_text" style="font-size:80%;">Geo-location</span></td>
<td id="S6.T4.3.18.18.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span id="S6.T4.3.18.18.4.1" class="ltx_text" style="font-size:80%;">Edge &amp; Server</span></td>
<td id="S6.T4.3.18.18.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.8pt;padding-bottom:0.8pt;">
<span id="S6.T4.3.18.18.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.18.18.5.1.1" class="ltx_p" style="width:195.1pt;"><span id="S6.T4.3.18.18.5.1.1.1" class="ltx_text" style="font-size:80%;">Predict the position and orientation of the camera for end-to-end localization.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.19.19" class="ltx_tr">
<td id="S6.T4.3.19.19.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" style="padding-top:0.8pt;padding-bottom:0.8pt;" colspan="5">
<sup id="S6.T4.3.19.19.1.1" class="ltx_sup"><span id="S6.T4.3.19.19.1.1.1" class="ltx_text" style="font-size:80%;">1</span></sup><span id="S6.T4.3.19.19.1.2" class="ltx_text" style="font-size:80%;"> Reference paper that belongs to the specific group.</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">Smart transportation is a viable situation for AFL due to its efficient utilization of computing resources that bridges the gap between training delay and time-sensitive requirements to a certain extent.
For instance, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite>, AFL is introduced to enhance the reliability and efficiency of data sharing among vehicles. The experiments conducted in a vehicular network evaluate their scheme, including one MBS and 10 RSUs covered. The results reveal that the DAG blockchain architecture in the scheme ensures both performance and security.
Similarly, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>, <a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite>, AFL is adopted in urban vehicular networks to allocate resources more efficiently and securely. The experiment results verify the effectiveness of their scheme in terms of distributed data sharing and resource caching in urban vehicular networks.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite>, a real-time end-to-end AFL scheme is applied in IoV and focuses on steering wheel angle prediction for autonomous driving. To conduct angle prediction, the authors utilize a two-stream deep CNN model with two separate neural branches that consume spatial and temporal information, respectively. To consume real-time streaming data, a sliding training window is introduced to reduce computation and communication latency. The experiments are carried out on real-world datasets, with the results showing that their scheme improves model prediction accuracy while reducing computation and communication latency.
AFL is also adopted in cameras to monitor, predict, and adjust traffic by controlling signal lights in the smart transportation scenario <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>. By adjusting the hyper-parameter in the scheme, an optimal balance between the model accuracy and convergence speed is achieved.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite>, AFL is adopted in unmanned aerial vehicle (UAV) networks. In order to improve the convergence speed and model accuracy, an actor-critic-based AFL scheme is proposed, including equipment selection, drone placement, resource management, local training, and global aggregation. Specifically, to prevent low-quality devices from compromising learning efficiency and model accuracy, a device selection strategy is proposed, in which nodes with high processing capability, communication capabilities, and model accuracy are selected. The selection problem is modeled as a Markov Decision Process and optimized through reinforcement learning. The scheme is evaluated by experiments, whose results show a higher learning accuracy and lower time cost.
Similarly, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite>, an intelligent content caching system in UAV networks based on AFL is proposed to extend the service coverage and reduce the communication delay of the 6G network. In the scheme, UAVs collaborate to forecast where content caching should be placed by taking real-time traffic distribution into account.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>, AFL is applied to mobile robots that collect real-time data and perform training in a distributed and resource-constrained environment to reduce communication costs. Experiments conducted on 12 mobile robots with limited resources demonstrate that the performance of the model is guaranteed by selecting competent and reliable mobile robots.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">Fault diagnosis is another application scenario for AFL.
For instance, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite>, AFL is utilized to identify the local modes in real-time. To completely track actual system changes in real-time and increase the diagnostic rate of the nodes, each node turns private data into local models using an Extended Kalman Filter before transmitting. A sequential filter approach based on Sequential Kalman Filter is adopted to perform the asynchronous aggregation for uploaded local models. Experiments conducted on real-world collected fault datasets demonstrate high accuracy compared with benchmarks.
Similarly, in order to improve model accuracy and convergence speed in anomaly detection while preserving privacy, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite> train the denoising autoencoder model based on labeled benign samples in AFL. Asynchronous update strategy improves the accuracy and stability of the model by reducing the impacts from the stragglers.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite>, the authors adopt AFL in the sensitive code review field to address privacy concerns. On leaks gathered from the code-sharing network Github, a prototype is developed and tested. When compared with local and centralized training, the proposed scheme improves model accuracy while preserving the privacy of the local training data.
Another AFL-based fault diagnosis scheme proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> allows nodes to adaptively select branches of the model for further training according to their local datasets. Their scheme creates an effective diagnostic model for detecting potential defects while reducing resource requirements and communication overhead. Experiments conducted across heterogeneous devices verify the feasibility of their scheme.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p">The AFL paradigm is also applied to IIoT environments for real-time analysis and decision-making. For example, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>, the authors break down the barrier of data island in IIoT with the help of AFL. In their scheme, the effect of slow devices is mitigated by adaptively adjusting aggregation frequency. The experiment results validate the feasibility and efficiency of their scheme.
Similarly, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite>, AFL is utilized to preserve data privacy and improve the quality of services in IIoT. Besides, by adopting digital-twin technology, real-time interactions requirements in Industry 4.0 are fulfilled. The communication cost is optimized as evidenced by experiment results.</p>
</div>
<div id="S6.p5" class="ltx_para">
<span id="S6.p5.3" class="ltx_ERROR undefined">\add</span>
<p id="S6.p5.2" class="ltx_p">There are also some other application scenarios that adopt AFL, such as concept drift and geolocation service. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite>, an AFL scheme is designed to detect and handle the data distribution changes (concept drift) across edge devices. Specifically, the proposed scheme improves the predictive performance of the worst <math id="S6.p5.1.m1.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S6.p5.1.m1.1a"><mrow id="S6.p5.1.m1.1.1" xref="S6.p5.1.m1.1.1.cmml"><mn id="S6.p5.1.m1.1.1.2" xref="S6.p5.1.m1.1.1.2.cmml">20</mn><mo id="S6.p5.1.m1.1.1.1" xref="S6.p5.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.p5.1.m1.1b"><apply id="S6.p5.1.m1.1.1.cmml" xref="S6.p5.1.m1.1.1"><csymbol cd="latexml" id="S6.p5.1.m1.1.1.1.cmml" xref="S6.p5.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S6.p5.1.m1.1.1.2.cmml" xref="S6.p5.1.m1.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p5.1.m1.1c">20\%</annotation></semantics></math> of devices while also maintaining the best test performance for the top <math id="S6.p5.2.m2.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S6.p5.2.m2.1a"><mrow id="S6.p5.2.m2.1.1" xref="S6.p5.2.m2.1.1.cmml"><mn id="S6.p5.2.m2.1.1.2" xref="S6.p5.2.m2.1.1.2.cmml">20</mn><mo id="S6.p5.2.m2.1.1.1" xref="S6.p5.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.p5.2.m2.1b"><apply id="S6.p5.2.m2.1.1.cmml" xref="S6.p5.2.m2.1.1"><csymbol cd="latexml" id="S6.p5.2.m2.1.1.1.cmml" xref="S6.p5.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S6.p5.2.m2.1.1.2.cmml" xref="S6.p5.2.m2.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p5.2.m2.1c">20\%</annotation></semantics></math> of devices. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite>, the authors apply AFL to the image-based geolocation service for end-to-end localization. AFL improves the accuracy of prediction of the position and orientation of the camera while preserving the privacy of user local training data and mitigating the effects of slow devices. Experiments conducted on the CNN model across several datasets validate the feasibility.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Research Challenges and Future Directions</h2>

<div id="S7.p1" class="ltx_para">
<span id="S7.p1.1" class="ltx_ERROR undefined">\add</span>
<p id="S7.p1.2" class="ltx_p">Emerging as a trending research topic, recent studies have brought to light a collection of challenges within AFL. These challenges encompass device heterogeneity, data heterogeneity, privacy and security on heterogeneous devices, as well as applications on heterogeneous devices. To deal with these challenges, in this section, several potential research directions are identified and summarized.</p>
</div>
<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span>Device Heterogeneity</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p"><span id="S7.SS1.p1.1.1" class="ltx_text ltx_font_bold">Optimization towards balanced time cost and performance improvement: </span>
As summarized in section <a href="#S3" title="3 Device Heterogeneity ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, for AFL, the existing performance improvement strategies on heterogeneous devices, such as node selection, weighted aggregation, and cluster FL, are effective in various ways. Some of the works even adopt several strategies at the same time to improve the efficiency of AFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>. However, utilizing too many strategies in AFL results in a decline in efficiency to a certain extent. For instance, if selecting a range of nodes and then compressing the gradients on resource-limited devices takes longer than uploading local gradients, it is preferable to skip one of them. So far, there has been no comprehensive analysis of the balance between multiple performance improvement strategies and time consumption, which is a potential research direction. To derive the optimized trade-off, it is possible to establish a dynamic gaming model by Markov Decision Process, which can adapt to various scenarios based on the constraints. Moreover, other lightweight convex optimization methods can be considered, such as quadratic minimization with convex quadratic constraints, semidefinite programming, and convex quadratic minimization with linear constraints.</p>
</div>
<div id="S7.SS1.p2" class="ltx_para">
<p id="S7.SS1.p2.1" class="ltx_p"><span id="S7.SS1.p2.1.1" class="ltx_text ltx_font_bold">Optimization towards generalized AFL solution: </span>
Usually, different performance improvement strategies have different application scenarios. For example, when the disparity in computing capabilities between heterogeneous devices is extremely high, semi-asynchronous FL with suitable weighted aggregation strategies could be an optimal solution. If the dataset distribution is IID across nodes, the local models from fast nodes should be selected and compressed, while those from slow devices should be discarded. The local models deserve higher weight if they bring a positive effect to the global model. Therefore, designing a generalized and flexible optimization framework for AFL for diverse application scenarios is a viable research field. It is expected to achieve this by integrating existing and future techniques minimally.</p>
</div>
<div id="S7.SS1.p3" class="ltx_para">
<p id="S7.SS1.p3.1" class="ltx_p"><span id="S7.SS1.p3.1.1" class="ltx_text ltx_font_bold">Optimization towards dynamic resource allocation: </span>
Intuitively, AFL requires more communication resources when compared with classic FL due to more global model aggregation operations. Therefore, it is expected to consider dynamic resource allocation algorithms, including transmit power, computation frequency for model training, and model selection strategy, to maximize the long-term time average (LTA) training data size with an LTA energy consumption constraint. Specifically, a possible solution is to first define the Lyapunov drift by converting the LTA energy consumption to a queue stability constraint. Then, a Lyapunov drift-plus-penalty ratio function can be constructed to decouple the original stochastic problem into multiple deterministic optimizations along the timeline. The construction is capable of dealing with uneven durations of communication rounds. To make the one-shot deterministic optimization problem of combinatorial fractional form tractable, the fractional problem is reformulated into a subtractive-form one by the Dinkelbach method, which leads to the asymptotically optimal solution in an iterative way. By doing so, there is a potential for both higher learning accuracy and faster convergence with limited time and energy consumption.</p>
</div>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span>Data Heterogeneity</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p"><span id="S7.SS2.p1.1.1" class="ltx_text ltx_font_bold">Optimization towards heterogeneous data distribution: </span>
Since the data distribution across nodes is usually non-IID in the real world <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, it is meaningful to obtain a generalized model while maintaining the accuracy for each local data in AFL. There are several solutions for non-IID data challenges in classic FL, such as localized independent training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite>, personalized local model training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, and cluster training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite>. However, it is hard to transplant these solutions into AFL, since the global model prefers to convergence to nodes with higher model upload frequency (i.e. fast nodes) in AFL and result in a biased global model. Such a biased global model decreases the effects of localized independent training and personalized local model training to a certain extent. Although cluster training has been utilized in several AFL schemes, it is hard to arrange a general cluster strategy for all application scenarios. For instance, a location-based cluster strategy is not ideal for traffic prediction among smart vehicles with non-IID datasets due to the randomness of vehicle movement. Cluster training based on data distribution similarity is a potential research topic <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>, but it requires the development of an appropriate similarity evaluation algorithm. Besides, based on transfer learning or meta-learning, asynchronous personalized local model training is potentially an effective and accurate solution.</p>
</div>
<div id="S7.SS2.p2" class="ltx_para">
<p id="S7.SS2.p2.1" class="ltx_p"><span id="S7.SS2.p2.1.1" class="ltx_text ltx_font_bold">Optimization towards heterogeneous data size: </span>
Dataset sizes among nodes are usually unequal since each node gathers its own local data independently in most AFL application scenarios. Even all nodes have identical computing resources, the imbalanced datasets across nodes lead to varying update frequencies of local models. The weighted aggregation strategy based on local dataset size is a possible solution as the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>, but how to verify the validity of the dataset size on each node is another security problem. The smart contract in the blockchain offers self-verifying and self-executing capabilities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, alleviating data fraud in AFL to some extent at a cost of low efficiency.</p>
</div>
<div id="S7.SS2.p3" class="ltx_para">
<p id="S7.SS2.p3.1" class="ltx_p"><span id="S7.SS2.p3.1.1" class="ltx_text ltx_font_bold">Optimization towards vertical data distribution: </span>
Vertical data distribution is prevalent in economic scenarios, where each node possesses different feature sets of the dataset. In a heterogeneous computing environment, the lack of local models uploaded from some slow nodes causes the global model to be biased and unable to predict certain features, unlike the accuracy decline in horizontal FL. Therefore, the lagging local models are non-ignorable in vertical AFL. So far, only relatively few researches have been conducted in the vertical AFL area <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>, <a href="#bib.bib93" title="" class="ltx_ref">93</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib95" title="" class="ltx_ref">95</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> compared with horizontal AFL. Moreover, none of these works analyzed the effects of extreme stragglers caused by computing resources or communication resources. A possible research direction is semi-asynchronous FL. With a server-side cache, it is possible to store stale local models and increase their effectiveness while keeping other local models up to date. Besides, another potential research direction is model splitting, which splits the global model according to the feature distribution on nodes and transforms to clustered horizontal AFL, as the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>. However, without knowing the local dataset on each node, it is hard to identify the distribution of features among nodes by the local models.</p>
</div>
</section>
<section id="S7.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.3 </span>Privacy and Security on Heterogeneous Devices</h3>

<div id="S7.SS3.p1" class="ltx_para">
<p id="S7.SS3.p1.1" class="ltx_p"><span id="S7.SS3.p1.1.1" class="ltx_text ltx_font_bold">Optimization towards privacy protection using differential privacy: </span>
Differential privacy prevents AFL from a variety of privacy attacks, including background knowledge, collusion, and inference attacks. However, as the utility of local models falls, differential privacy leads global model accuracy to decline. Therefore, the trade-off between privacy and utility is hard to achieve in AFL. There are several strategies for optimizing the trade-off in classic differential privacy, such as Static Bayesian Games <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite>, Markov Decision Processes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, and Generative Adversarial Nets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite>. However, in AFL, the publishing process for local models is dynamic and distributed, which is hard to balance through a trusted third party. Local differential privacy (LDP) is an approach that users randomly perturb their inputs without the necessity for a trusted party and is treated as a solution for the privacy issues in FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. Nevertheless, the trade-off between the privacy of local models and the utility of the global model is hard to achieve. Especially in AFL, it necessitates asynchronous macro control for the LDP in a distributed manner. The smart contract in the blockchain is a viable approach for manipulating LDP in a distributed manner. However, an asynchronous consensus algorithm needs to be designed to balance the privacy of local models and the utility of the global model.</p>
</div>
<div id="S7.SS3.p2" class="ltx_para">
<p id="S7.SS3.p2.1" class="ltx_p"><span id="S7.SS3.p2.1.1" class="ltx_text ltx_font_bold">Optimization towards security enhancement using blockchain: </span>
Blockchain can be utilized to address security challenges in AFL, such as the single point of failure, Byzantine attacks, and poisoning attacks. At the same time, blockchain declines the efficiency of AFL to some extent due to its low communication efficiency and high computing resource consumption <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. Therefore, the trade-off between security and efficiency of blockchain-based AFL is also challenging. To improve the scalability of blockchain, several improved consensus algorithms are designed to replace PoW, such as Proof-of-Stake (PoS) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, Proof-of-Reputation (PoR) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>]</cite>, PBFT, and RAFT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite>. However, generally, the higher the performance of the consensus algorithm reaches, the worse the security level is. For instance, compared with PBFT, RAFT is not resistant to Byzantine attacks but has higher data throughput. A promising solution is to develop an efficient and secure consensus algorithm. For example, Algorand <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite> is a byzantine-tolerant consensus algorithm with excellent scalability while maintaining a high level of security. A group of committees is randomly selected in each iteration to verify and ensure the security of the transactions. During training, the committees verify the local models in each iteration. However, it is difficult to select committees asynchronously without compromising security. In this situation, it is possible to separate the consensus process and the training process with a tailor-made blockchain structure that records the training models periodically.</p>
</div>
<div id="S7.SS3.p3" class="ltx_para">
<p id="S7.SS3.p3.1" class="ltx_p"><span id="S7.SS3.p3.1.1" class="ltx_text ltx_font_bold">Optimization towards security enhancement using lightweight distributed cryptography: </span>
Another research direction is to apply lightweight distributed cryptography to AFL to protect security. Traditional cryptography approaches, such as public-key encryption <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite>, homomorphic encryption <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite>, and attribute-based encryption <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>, have several limitations in this case. Public-key encryption and homomorphic encryption are resource-consuming and unsuitable for resource-limited devices in AFL. Attribute-based encryption is not flexible enough, due to its necessity for a trusted third-party authority. A possible research area is to design a flexible and efficient attribute-based encryption algorithm for AFL with dynamical attribute adjustment that allows participants to join or leave freely.</p>
</div>
</section>
<section id="S7.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.4 </span>Applications on Heterogeneous Devices</h3>

<div id="S7.SS4.p1" class="ltx_para">
<p id="S7.SS4.p1.1" class="ltx_p"><span id="S7.SS4.p1.1.1" class="ltx_text ltx_font_bold">Expansion of real-world applications: </span>
As summarized in section <a href="#S6" title="6 Applications on Heterogeneous Devices ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, there are few real-world application scenarios for AFL for the time being, including IoV, fault diagnosis, IIoT, and so on. Compared with synchronous FL, AFL is more efficient and is better suited to time-sensitive scenarios with limited computing resources. Therefore, a possible applied research area is to apply dedicated AFL systems to a wide range of real-world scenarios. For example, in a smart hospital, ML models trained by AFL based on electronic healthcare records (EHR) predict the situation of patients. In a smart grid, AFL trains ML models on heterogeneous devices to anticipate the energy consumption in various areas and accomplish smart power dispatch. In a smart farm, the growth situation of plants is well monitored, diagnosed, and predicted by IoT with the help of ML models trained by AFL.</p>
</div>
<div id="S7.SS4.p2" class="ltx_para">
<p id="S7.SS4.p2.1" class="ltx_p"><span id="S7.SS4.p2.1.1" class="ltx_text ltx_font_bold">Development of real-world evaluation testbeds: </span>
As summarized in Table <a href="#S3.T2" title="Table 2 ‣ 3 Device Heterogeneity ‣ Asynchronous Federated Learning on Heterogeneous Devices: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, most of the experiments of AFL are conducted in simulation mode, without demonstrating the feasibility of ALF in the real world. More experiments are expected to be conducted on IoT or edge devices to evaluate the efficiency, security, and privacy of AFL schemes. Thus, it would be a promising research direction to develop scalable and flexible testbeds deployed on heterogeneous devices and accessible from a standardized interface. The development of testbeds includes the issues of architecture design, inclusiveness of heterogeneous devices, structure-wise efficiency and performance fine-tuning, etc.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Conclusion</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">AFL has been attracting increasing attention due to its multiple advantageous features. To mitigate the drawbacks of existing works, three fundamental challenges in AFL are primarily studied, including device heterogeneity, data heterogeneity, as well as security and privacy issues on heterogeneous devices. By conducting an in-depth exploration of state-of-the-art research, corresponding application scenarios of AFL that potentially increase its impact and popularization on heterogeneous devices are summarized. It is pleasing to observe that the number of novel AFL schemes grows by the month. But even so, it is believed this survey is sufficiently comprehensive that new schemes can be appended and categorized correspondingly. This survey provides legible insights into the picture of AFL from a brand-new perspective, which is helpful to the community by providing potentially promising directions, and simplifying future designs, including but not limited to motivating coherent compositions uncovered by the proposed categorization and analysis.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Z. Ghahramani, Probabilistic machine learning and artificial intelligence,
Nature 521 (7553) (2015) 452–459.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
H. Xu, X. Liu, W. Yu, D. Griffith, N. Golmie, Reinforcement learning-based
control and networking co-design for industrial internet of things, IEEE
Journal on Selected Areas in Communications 38 (5) (2020) 885–898.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
W. Nie, T. Karras, A. Garg, S. Debnath, A. Patney, A. Patel, A. Anandkumar,
Semi-supervised stylegan for disentanglement learning, in: International
Conference on Machine Learning, PMLR, 2020, pp. 7360–7369.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
P. Voigt, A. Von dem Bussche, The eu general data protection regulation (gdpr),
A Practical Guide, 1st Ed., Cham: Springer International Publishing 10 (2017)
3152676.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
J. Andrew, M. Baker, The general data protection regulation in the age of
surveillance capitalism, Journal of Business Ethics 168 (3) (2021) 565–578.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
S. Wachter, B. Mittelstadt, A right to reasonable inferences: re-thinking data
protection law in the age of big data and ai, Colum. Bus. L. Rev. (2019) 494.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Y. Qu, S. Yu, W. Zhou, S. Peng, G. Wang, K. Xiao, Privacy of things: Emerging
challenges and opportunities in wireless internet of things, IEEE Wireless
Communications 25 (6) (2018) 91–97.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
H. Xiong, H. Zhang, J. Sun, Attribute-based privacy-preserving data sharing for
dynamic groups in cloud computing, IEEE Systems Journal 13 (3) (2018)
2739–2750.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
J. Xiong, R. Bi, M. Zhao, J. Guo, Q. Yang, Edge-assisted privacy-preserving raw
data sharing framework for connected autonomous vehicles, IEEE Wireless
Communications 27 (3) (2020) 24–30.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
H. Xie, Z. Yan, Z. Yao, M. Atiquzzaman, Data collection for security
measurement in wireless sensor networks: A survey, IEEE Internet of Things
Journal 6 (2) (2018) 2205–2224.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Z. Su, Y. Wang, Q. Xu, N. Zhang, Lvbs: Lightweight vehicular blockchain for
secure data sharing in disaster rescue, IEEE Transactions on dependable and
secure computing (2020).

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
J. Konečnỳ, H. B. McMahan, F. X. Yu, P. Richtárik, A. T. Suresh,
D. Bacon, Federated learning: Strategies for improving communication
efficiency, arXiv preprint arXiv:1610.05492 (2016).

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J. Konečnỳ, H. B. McMahan, D. Ramage, P. Richtárik, Federated
optimization: Distributed machine learning for on-device intelligence, arXiv
preprint arXiv:1610.02527 (2016).

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
W. Y. B. Lim, N. C. Luong, D. T. Hoang, Y. Jiao, Y.-C. Liang, Q. Yang,
D. Niyato, C. Miao, Federated learning in mobile edge networks: A
comprehensive survey, IEEE Communications Surveys &amp; Tutorials 22 (3) (2020)
2031–2063.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
X. Yin, Y. Zhu, J. Hu, A comprehensive survey of privacy-preserving federated
learning: A taxonomy, review, and future directions, ACM Computing Surveys
(CSUR) 54 (6) (2021) 1–36.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
O. A. Wahab, A. Mourad, H. Otrok, T. Taleb, Federated machine learning: Survey,
multi-level classification, desirable criteria and future directions in
communication and networking systems, IEEE Communications Surveys &amp;
Tutorials 23 (2) (2021) 1342–1397.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
A. Imteaj, U. Thakker, S. Wang, J. Li, M. H. Amini, A survey on federated
learning for resource-constrained iot devices, IEEE Internet of Things
Journal (2021).

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
L. U. Khan, W. Saad, Z. Han, E. Hossain, C. S. Hong, Federated learning for
internet of things: Recent advances, taxonomy, and open challenges, IEEE
Communications Surveys &amp; Tutorials (2021).

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
L. Lyu, H. Yu, Q. Yang, Threats to federated learning: A survey, arXiv preprint
arXiv:2003.02133 (2020).

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
M. Abdel-Basset, N. Moustafa, H. Hawash, W. Ding, Federated learning for
privacy-preserving internet of things, in: Deep Learning Techniques for IoT
Security and Privacy, Springer, 2022, pp. 215–228.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
W. Wu, L. He, W. Lin, R. Mao, C. Maple, S. Jarvis, Safa: A semi-asynchronous
protocol for fast federated learning with low overhead, IEEE Transactions on
Computers 70 (5) (2020) 655–668.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
J. Verbraeken, M. Wolting, J. Katzy, J. Kloppenburg, T. Verbelen, J. S.
Rellermeyer, A survey on distributed machine learning, Acm computing surveys
(csur) 53 (2) (2020) 1–33.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, B. A. y Arcas,
Communication-efficient learning of deep networks from decentralized data,
in: Artificial intelligence and statistics, PMLR, 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
J. Liu, J. Huang, Y. Zhou, X. Li, S. Ji, H. Xiong, D. Dou, From distributed
machine learning to federated learning: A survey, Knowledge and Information
Systems 64 (4) (2022) 885–917.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
C. Xu, J. Ge, Y. Li, Y. Deng, L. Gao, M. Zhang, Y. Xiang, X. Zheng, Scei: A
smart-contract driven edge intelligence framework for iot systems, IEEE
Transactions on Mobile Computing (2023).

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
B. Gu, A. Xu, Z. Huo, C. Deng, H. Huang, Privacy-preserving asynchronous
vertical federated learning algorithms for multiparty collaborative learning,
IEEE Transactions on Neural Networks and Learning Systems (2021).

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
S. Trindade, L. F. Bittencourt, N. L. da Fonseca, Management of resource at the
network edge for federated learning, arXiv preprint arXiv:2107.03428 (2021).

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
J. Nguyen, K. Malik, H. Zhan, A. Yousefpour, M. Rabbat, M. Malek, D. Huba,
Federated learning with buffered asynchronous aggregation, in: International
Conference on Artificial Intelligence and Statistics, PMLR, 2022, pp.
3581–3607.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Y. Liu, Y. Qu, C. Xu, Z. Hao, B. Gu, Blockchain-enabled asynchronous federated
learning in edge computing, Sensors 21 (10) (2021) 3335.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
S. Nakamoto, Bitcoin: A peer-to-peer electronic cash system, Decentralized
Business Review (2008) 21260.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
C. Xu, Y. Qu, T. H. Luan, P. W. Eklund, Y. Xiang, L. Gao, A lightweight and
attack-proof bidirectional blockchain paradigm for internet of things, IEEE
Internet of Things Journal 9 (6) (2021) 4371–4384.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
A. Kiayias, A. Russell, B. David, R. Oliynykov, Ouroboros: A provably secure
proof-of-stake blockchain protocol, in: Annual International Cryptology
Conference, Springer, 2017, pp. 357–388.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
H. Sukhwani, J. M. Martínez, X. Chang, K. S. Trivedi, A. Rindos,
Performance modeling of pbft consensus process for permissioned blockchain
network (hyperledger fabric), in: 2017 IEEE 36th Symposium on Reliable
Distributed Systems (SRDS), IEEE, 2017, pp. 253–255.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Y. Qu, S. R. Pokhrel, S. Garg, L. Gao, Y. Xiang, A blockchained federated
learning framework for cognitive computing in industry 4.0 networks, IEEE
Transactions on Industrial Informatics 17 (4) (2020) 2964–2973.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Y. Qu, L. Gao, T. H. Luan, Y. Xiang, S. Yu, B. Li, G. Zheng, Decentralized
privacy using blockchain-enabled federated learning in fog computing, IEEE
Internet of Things Journal 7 (6) (2020) 5171–5183.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
C. Dwork, Differential privacy: A survey of results, in: International
conference on theory and applications of models of computation, Springer,
2008, pp. 1–19.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
C. Dwork, A. Roth, et al., The algorithmic foundations of differential
privacy., Found. Trends Theor. Comput. Sci. 9 (3-4) (2014) 211–407.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
X. Cao, J. Jia, N. Z. Gong, Data poisoning attacks to local differential
privacy protocols, in: 30th USENIX Security Symposium (USENIX Security 21),
2021, pp. 947–964.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
J. Dong, D. Durfee, R. Rogers, Optimal differential privacy composition for
exponential mechanisms, in: International Conference on Machine Learning,
PMLR, 2020, pp. 2597–2606.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Y. Zhu, X. Yu, M. Chandraker, Y.-X. Wang, Private-knn: Practical differential
privacy for computer vision, in: Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, 2020, pp. 11854–11862.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Y. Qu, M. R. Nosouhi, L. Cui, S. Yu, Personalized privacy protection in big
data (2021).

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Y. Qu, S. Yu, W. Zhou, S. Chen, J. Wu, Customizable reliable privacy-preserving
data sharing in cyber-physical social networks, IEEE Transactions on Network
Science and Engineering 8 (1) (2020) 269–281.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
J. Soria-Comas, J. Domingo-Ferrer, D. Sánchez, D. Megías, Individual
differential privacy: A utility-preserving formulation of differential
privacy guarantees, IEEE Transactions on Information Forensics and Security
12 (6) (2017) 1418–1429.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
K. Wei, J. Li, M. Ding, C. Ma, H. H. Yang, F. Farokhi, S. Jin, T. Q. Quek,
H. V. Poor, Federated learning with differential privacy: Algorithms and
performance analysis, IEEE Transactions on Information Forensics and Security
15 (2020) 3454–3469.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Y. Liu, J. Peng, J. Kang, A. M. Iliyasu, D. Niyato, A. A. Abd El-Latif, A
secure federated learning framework for 5g networks, IEEE Wireless
Communications 27 (4) (2020) 24–31.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Z. Chen, W. Liao, K. Hua, C. Lu, W. Yu, Towards asynchronous federated learning
for heterogeneous edge-powered internet of things, Digital Communications and
Networks (2021).

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
H. Xiao, K. Rasul, R. Vollgraf, Fashion-mnist: a novel image dataset for
benchmarking machine learning algorithms, arXiv preprint arXiv:1708.07747
(2017).

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
G. Cohen, S. Afshar, J. Tapson, A. Van Schaik, Emnist: Extending mnist to
handwritten letters, in: 2017 International Joint Conference on Neural
Networks (IJCNN), IEEE, 2017, pp. 2921–2926.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
C. Zhou, H. Tian, H. Zhang, J. Zhang, M. Dong, J. Jia, Tea-fed: time-efficient
asynchronous federated learning for edge computing, in: Proceedings of the
18th ACM International Conference on Computing Frontiers, 2021, pp. 30–37.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
J. Hao, Y. Zhao, J. Zhang, Time efficient federated learning with
semi-asynchronous communication, in: 2020 IEEE 26th International Conference
on Parallel and Distributed Systems (ICPADS), IEEE, 2020, pp. 156–163.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
A. Imteaj, M. H. Amini, Fedar: Activity and resource-aware federated learning
model for distributed mobile robots, in: 2020 19th IEEE International
Conference on Machine Learning and Applications (ICMLA), IEEE, 2020, pp.
1153–1160.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
D. Harrison Jr, D. L. Rubinfeld, Hedonic housing prices and the demand for
clean air, Journal of environmental economics and management 5 (1) (1978)
81–102.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
J. Stolfo, W. Fan, W. Lee, A. Prodromidis, P. K. Chan, Cost-based modeling and
evaluation for data mining with application to fraud and intrusion detection,
Results from the JAM Project by Salvatore (2000) 1–15.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
C.-H. Hu, Z. Chen, E. G. Larsson, Scheduling and aggregation design for
asynchronous federated learning over wireless networks, IEEE Journal on
Selected Areas in Communications 41 (4) (2023) 874–886.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/JSAC.2023.3242719" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/JSAC.2023.3242719</span></a>.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
C. Xie, S. Koyejo, I. Gupta, Asynchronous federated optimization, arXiv
preprint arXiv:1903.03934 (2019).

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
S. Merity, C. Xiong, J. Bradbury, R. Socher, Pointer sentinel mixture models,
arXiv preprint arXiv:1609.07843 (2016).

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Y. Chen, X. Sun, Y. Jin, Communication-efficient federated deep learning with
layerwise asynchronous model update and temporally weighted aggregation, IEEE
transactions on neural networks and learning systems 31 (10) (2019)
4229–4238.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
D. Anguita, A. Ghio, L. Oneto, X. Parra, J. L. Reyes-Ortiz, et al., A public
domain dataset for human activity recognition using smartphones., in: Esann,
Vol. 3, 2013, p. 3.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
G. Shi, L. Li, J. Wang, W. Chen, K. Ye, C. Xu, Hysync: Hybrid federated
learning with effective synchronization, in: 2020 IEEE 22nd International
Conference on High Performance Computing and Communications; IEEE 18th
International Conference on Smart City; IEEE 6th International Conference on
Data Science and Systems (HPCC/SmartCity/DSS), IEEE, 2020, pp. 628–633.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Y. Chen, Y. Ning, M. Slawski, H. Rangwala, Asynchronous online federated
learning for edge devices with non-iid data, in: 2020 IEEE International
Conference on Big Data (Big Data), IEEE, 2020, pp. 15–24.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
J. Ni, L. Muhlstein, J. McAuley, Modeling heart rate and activity data for
personalized fitness recommendation, in: The World Wide Web Conference, 2019,
pp. 1343–1353.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Z. Luo, J. Huang, K. Hu, X. Li, P. Zhang, Accuair: Winning solution to air
quality prediction for kdd cup 2018, in: Proceedings of the 25th ACM SIGKDD
International Conference on Knowledge Discovery &amp; Data Mining, 2019, pp.
1842–1850.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Y. Vaizman, K. Ellis, G. Lanckriet, Recognizing detailed human context in the
wild from smartphones and smartwatches, IEEE pervasive computing 16 (4)
(2017) 62–74.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
L. Xiaofeng, L. Yuying, P. Lio, P. Hui, An asynchronous federated learning
mechanism for edge network computing, Journal of Computer Research and
Development 57 (12) (2020) 2571.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Q. Wang, Q. Li, K. Wang, H. Wang, P. Zeng, Efficient federated learning for
fault diagnosis in industrial cloud-edge computing, Computing (2021) 1–19.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
K. A. Loparo, Bearing data center, Case Western Reserve University 338 (2013).

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
P. Cao, S. Zhang, J. Tang, Gear fault data,
FigshareDoi:10.6084/m9.figshare.6127874.v1 (2018).

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
X. Lu, Y. Liao, P. Lio, P. Hui, Privacy-preserving asynchronous federated
learning mechanism for edge network computing, IEEE Access 8 (2020)
48970–48981.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
M. Li, Y. Chen, Y. Wang, Y. Pan, Efficient asynchronous vertical federated
learning via gradient prediction and double-end sparse compression, in: 2020
16th International Conference on Control, Automation, Robotics and Vision
(ICARCV), IEEE, 2020, pp. 291–296.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
K. C. Dewi, H. Murfi, S. Abdullah, Analysis accuracy of random forest model for
big data–a case study of claim severity prediction in car insurance, in:
2019 5th International Conference on Science in Information Technology
(ICSITech), IEEE, 2019, pp. 60–65.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
I.-C. Yeh, C.-h. Lien, The comparisons of data mining techniques for the
predictive accuracy of probability of default of credit card clients, Expert
Systems with Applications 36 (2) (2009) 2473–2480.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
H.-S. Lee, J.-W. Lee, Adaptive transmission scheduling in wireless networks for
asynchronous federated learning, arXiv preprint arXiv:2103.01422 (2021).

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
A. Go, R. Bhayani, L. Huang, Twitter sentiment classification using distant
supervision, CS224N project report, Stanford 1 (12) (2009) 2009.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Z. Liu, P. Luo, X. Wang, X. Tang, Deep learning face attributes in the wild,
in: Proceedings of the IEEE international conference on computer vision,
2015, pp. 3730–3738.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
D. Stripelis, J. L. Ambite, Semi-synchronous federated learning, arXiv preprint
arXiv:2102.02849 (2021).

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
J. So, R. E. Ali, B. Güler, A. S. Avestimehr, Secure aggregation for
buffered asynchronous federated learning, arXiv preprint arXiv:2110.02177
(2021).

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
Z. Chai, Y. Chen, L. Zhao, Y. Cheng, H. Rangwala, Fedat: A
communication-efficient federated learning method with asynchronous tiers
under non-iid data, arXiv preprint arXiv:2010.05958 (2020).

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Y. Zhang, M. Duan, D. Liu, L. Li, A. Ren, X. Chen, Y. Tan, C. Wang, Csafl: A
clustered semi-asynchronous federated learning framework, arXiv preprint
arXiv:2104.08184 (2021).

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
O. Shamir, N. Srebro, T. Zhang, Communication-efficient distributed
optimization using an approximate newton-type method, in: International
conference on machine learning, PMLR, 2014, pp. 1000–1008.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
W. Xia, Y. Li, L. Zhang, Z. Wu, X. Yuan, A vertical federated learning
framework for horizontally partitioned labels, arXiv preprint
arXiv:2106.10056 (2021).

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
J.-w. Lee, J. Oh, Y. Shin, J.-G. Lee, S.-Y. Yoon, Accurate and fast federated
learning via iid and communication-aware grouping, arXiv preprint
arXiv:2012.04857 (2020).

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
W. Sun, S. Lei, L. Wang, Z. Liu, Y. Zhang, Adaptive federated learning and
digital twin for industrial internet of things, IEEE Transactions on
Industrial Informatics 17 (8) (2020) 5605–5614.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
Z. M. Fadlullah, N. Kato, Hcp: Heterogeneous computing platform for federated
learning based collaborative content caching towards 6g networks, IEEE
Transactions on Emerging Topics in Computing (2020).

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
A. F. Aji, K. Heafield, Sparse communication for distributed gradient descent,
arXiv preprint arXiv:1704.05021 (2017).

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
L. Zhu, S. Han, Deep leakage from gradients, in: Federated learning, Springer,
2020, pp. 17–31.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
F. Sattler, K.-R. Müller, W. Samek, Clustered federated learning:
Model-agnostic distributed multitask optimization under privacy constraints,
IEEE transactions on neural networks and learning systems (2020).

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
D. Stripelis, J. L. Ambite, Accelerating federated learning in heterogeneous
data and computational environments, arXiv preprint arXiv:2008.11281 (2020).

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
P. Tian, Z. Chen, W. Yu, W. Liao, Towards asynchronous federated learning based
threat detection: a dc-adam approach, Computers &amp; Security (2021) 102344.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
M. Chen, B. Mao, T. Ma, Fedsa: A staleness-aware asynchronous federated
learning algorithm with non-iid data, Future Generation Computer Systems 120
(2021) 1–12.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
S. S. Diwangkara, A. I. Kistijantoro, Study of data imbalance and asynchronous
aggregation algorithm on federated learning system, in: 2020 International
Conference on Information Technology Systems and Innovation (ICITSI), IEEE,
2020, pp. 276–281.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
D. Avdiukhin, S. Kasiviswanathan, Federated learning under arbitrary
communication patterns, in: International Conference on Machine Learning,
PMLR, 2021, pp. 425–435.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
J. Yang, Y. Duan, T. Qiao, H. Zhou, J. Wang, W. Zhao, Prototyping federated
learning on edge computing systems., Frontiers Comput. Sci. 14 (6) (2020)
146318.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
T. Chen, X. Jin, Y. Sun, W. Yin, Vafl: a method of vertical asynchronous
federated learning, arXiv preprint arXiv:2007.06081 (2020).

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
A. Defazio, F. Bach, S. Lacoste-Julien, Saga: A fast incremental gradient
method with support for non-strongly convex composite objectives, in:
Advances in neural information processing systems, 2014, pp. 1646–1654.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
Q. Zhang, B. Gu, C. Deng, H. Huang, Secure bilevel asynchronous vertical
federated learning with backward updating, Proceedings of the AAAI Conference
on Artificial Intelligence 35 (12) (2021) 10896–10904.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
R. Shokri, M. Stronati, C. Song, V. Shmatikov, Membership inference attacks
against machine learning models, in: 2017 IEEE Symposium on Security and
Privacy (SP), IEEE, 2017, pp. 3–18.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
L. Melis, C. Song, E. De Cristofaro, V. Shmatikov, Exploiting unintended
feature leakage in collaborative learning, in: 2019 IEEE Symposium on
Security and Privacy (SP), IEEE, 2019, pp. 691–706.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
M. Fredrikson, S. Jha, T. Ristenpart, Model inversion attacks that exploit
confidence information and basic countermeasures, in: Proceedings of the 22nd
ACM SIGSAC conference on computer and communications security, 2015, pp.
1322–1333.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
Y. Lu, X. Huang, Y. Dai, S. Maharjan, Y. Zhang, Differentially private
asynchronous federated learning for mobile edge computing in urban
informatics, IEEE Transactions on Industrial Informatics 16 (3) (2019)
2134–2143.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
Y. Li, S. Yang, X. Ren, C. Zhao, Asynchronous federated learning with
differential privacy for edge intelligence, arXiv preprint arXiv:1912.07902
(2019).

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
M. van Dijk, N. V. Nguyen, T. N. Nguyen, L. M. Nguyen, Q. Tran-Dinh, P. H.
Nguyen, Asynchronous federated learning with reduced number of rounds and
with differential privacy from less aggregated gaussian noise, arXiv preprint
arXiv:2007.09208 (2020).

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
Y. Lu, X. Huang, K. Zhang, S. Maharjan, Y. Zhang, Communication-efficient
federated learning and permissioned blockchain for digital twin edge
networks, IEEE Internet of Things Journal 8 (4) (2020) 2276–2288.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
Y. Lu, X. Huang, K. Zhang, S. Maharjan, Y. Zhang, Communication-efficient
federated learning for digital twin edge networks in industrial iot, IEEE
Transactions on Industrial Informatics 17 (8) (2020) 5709–5718.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
Y. Lu, X. Huang, K. Zhang, S. Maharjan, Y. Zhang, Blockchain empowered
asynchronous federated learning for secure data sharing in internet of
vehicles, IEEE Transactions on Vehicular Technology 69 (4) (2020) 4298–4311.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
L. Feng, Y. Zhao, S. Guo, X. Qiu, W. Li, P. Yu, Blockchain-based asynchronous
federated learning for internet of things, IEEE Transactions on Computers
(2021).

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
S. Yuan, B. Cao, M. Peng, Y. Sun, Chainsfl: Blockchain-driven federated
learning from design to realization, in: 2021 IEEE Wireless Communications
and Networking Conference (WCNC), IEEE, 2021, pp. 1–6.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
C. Xu, Y. Qu, P. W. Eklund, Y. Xiang, L. Gao, Bafl: An efficient
blockchain-based asynchronous federated learning framework, in: 2021 IEEE
Symposium on Computers and Communications (ISCC), IEEE, 2021, pp. 1–6.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
C. Xu, Y. Qu, T. H. Luan, P. W. Eklund, Y. Xiang, L. Gao, An efficient and
reliable asynchronous federated learning scheme for smart public
transportation, IEEE Transactions on Vehicular Technology (2022).

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
C. Xu, Y. Qu, Y. Xiang, L. Gao, D. Smith, S. Yu, Bass: Blockchain-based
asynchronous signsgd for robust collaborative data mining, in: 2022 IEEE 9th
International Conference on Data Science and Advanced Analytics (DSAA), IEEE,
2022, pp. 1–7.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
H. Zhang, J. Bosch, H. H. Olsson, Real-time end-to-end federated learning: An
automotive case study, arXiv preprint arXiv:2103.11879 (2021).

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
H. Yang, J. Zhao, Z. Xiong, K.-Y. Lam, S. Sun, L. Xiao, Privacy-preserving
federated learning for uav-enabled networks: Learning-based joint scheduling
and resource management, IEEE Journal on Selected Areas in Communications
(2021).

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
X. Ma, C. Wen, T. Wen, An asynchronous and real-time update paradigm of
federated learning diagnosisfor fault, IEEE Transactions on Industrial
Informatics (2021).

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
S. Kall, S. Trabelsi, An asynchronous federated learning approach for a
security source code scanner., in: ICISSP, 2021, pp. 572–579.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
Y. Chen, Z. Chai, Y. Cheng, H. Rangwala, Asynchronous federated learning for
sensor data with concept drift, arXiv preprint arXiv:2109.00151 (2021).

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
M. R. Sprague, A. Jalalirad, M. Scavuzzo, C. Capota, M. Neun, L. Do, M. Kopp,
Asynchronous federated learning for geospatial applications, in: Joint
European Conference on Machine Learning and Knowledge Discovery in Databases,
Springer, 2018, pp. 21–28.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
M. Khodak, M.-F. F. Balcan, A. S. Talwalkar, Adaptive gradient-based
meta-learning methods, Advances in Neural Information Processing Systems 32
(2019).

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
V. Smith, C.-K. Chiang, M. Sanjabi, A. S. Talwalkar, Federated multi-task
learning, Advances in neural information processing systems 30 (2017).

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
Y. Qu, L. Cui, S. Yu, W. Zhou, J. Wu, Improving data utility through game
theory in personalized differential privacy, in: 2018 IEEE International
Conference on Communications (ICC), IEEE, 2018, pp. 1–6.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
Y. Qu, S. Yu, W. Zhou, Y. Tian, Gan-driven personalized spatial-temporal
private data sharing in cyber-physical social systems, IEEE Transactions on
Network Science and Engineering 7 (4) (2020) 2576–2586.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
F. Gai, B. Wang, W. Deng, W. Peng, Proof of reputation: A reputation-based
consensus protocol for peer-to-peer network, in: International Conference on
Database Systems for Advanced Applications, Springer, 2018, pp. 666–681.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
D. Huang, X. Ma, S. Zhang, Performance analysis of the raft consensus algorithm
for private blockchains, IEEE Transactions on Systems, Man, and Cybernetics:
Systems 50 (1) (2019) 172–181.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
Y. Gilad, R. Hemo, S. Micali, G. Vlachos, N. Zeldovich, Algorand: Scaling
byzantine agreements for cryptocurrencies, in: Proceedings of the 26th
symposium on operating systems principles, 2017, pp. 51–68.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
S. Hohenberger, A. Lysyanskaya, How to securely outsource cryptographic
computations, in: Theory of cryptography conference, Springer, 2005, pp.
264–282.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
F. Armknecht, C. Boyd, C. Carr, K. Gjøsteen, A. Jäschke, C. A. Reuter,
M. Strand, A guide to fully homomorphic encryption., IACR Cryptol. ePrint
Arch. 2015 (2015) 1192.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock">
J. Li, Y. Ren, S. Fang, K. Li, M. Sun, Federated learning-based ultra-short
term load forecasting in power internet of things, in: 2020 IEEE
International Conference on Energy Internet (ICEI), IEEE, 2020, pp. 63–68.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2109.04268" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2109.04269" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2109.04269">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2109.04269" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2109.04270" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  2 03:48:02 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
