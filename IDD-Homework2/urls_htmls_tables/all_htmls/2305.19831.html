<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2305.19831] An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity</title><meta property="og:description" content="Nowadays, billions of phones, IoT and edge devices around the world generate data continuously, enabling many Machine Learning (ML)-based products and applications. However, due to increasing privacy concerns and regul…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2305.19831">

<!--Generated on Thu Feb 29 04:15:26 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated Learning,  IoT-Edge Devices,  On-Device Training,  Empirical Study.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Kok-Seng Wong<sup id="id9.9.id1" class="ltx_sup"><span id="id9.9.id1.1" class="ltx_text ltx_font_italic">∗</span></sup> <a target="_blank" href="https://orcid.org/0000-0002-2029-7644" title="" class="ltx_ref ltx_href"><span id="id10.10.7.id1" class="ltx_ERROR undefined">\scalerel</span>*
 <svg id="id2.2.1.1.pic1" class="ltx_picture" height="354.23" overflow="visible" version="1.1" width="354.23"><g transform="translate(0,354.23) matrix(1 0 0 -1 0 0) translate(0,354.23)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#A6CE39" fill="#A6CE39" color="#A6CE39"><path d="M 354.23 -177.11 C 354.23 -274.94 274.94 -354.23 177.11 -354.23 C 79.29 -354.23 0 -274.94 0 -177.11 C 0 -79.29 79.29 0 177.11 0 C 274.94 0 354.23 -79.29 354.23 -177.11 Z" style="stroke:none"></path></g><g stroke="#FFFFFF" fill="#FFFFFF" color="#FFFFFF"><path d="M 119.41 -257.64 L 98.1 -257.64 L 98.1 -109.45 L 119.41 -109.45 L 119.41 -176.42 L 119.41 -257.64 Z M 150.68 -109.45 L 208.25 -109.45 C 263.04 -109.45 287.12 -148.61 287.12 -183.62 C 287.12 -221.67 257.37 -257.78 208.52 -257.78 L 150.68 -257.78 L 150.68 -109.45 Z M 171.99 -238.55 L 205.89 -238.55 C 254.19 -238.55 265.26 -201.88 265.26 -183.62 C 265.26 -153.87 246.3 -128.68 204.79 -128.68 L 171.99 -128.68 L 171.99 -238.55 Z M 122.73 -78.59 C 122.73 -86.2 116.51 -92.57 108.76 -92.57 C 101.01 -92.57 94.78 -86.2 94.78 -78.59 C 94.78 -70.85 101.01 -64.62 108.76 -64.62 C 116.51 -64.62 122.73 -70.98 122.73 -78.59 Z" style="stroke:none"></path></g></g></svg>
—</a>, <span id="id11.11.id2" class="ltx_text ltx_font_italic">Member, IEEE</span>, Manh Nguyen-Duc <a target="_blank" href="https://orcid.org/0000-0002-9668-4974" title="" class="ltx_ref ltx_href"><span id="id12.12.8.id1" class="ltx_ERROR undefined">\scalerel</span>*
 <svg id="id3.3.2.1.pic1" class="ltx_picture" height="354.23" overflow="visible" version="1.1" width="354.23"><g transform="translate(0,354.23) matrix(1 0 0 -1 0 0) translate(0,354.23)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#A6CE39" fill="#A6CE39" color="#A6CE39"><path d="M 354.23 -177.11 C 354.23 -274.94 274.94 -354.23 177.11 -354.23 C 79.29 -354.23 0 -274.94 0 -177.11 C 0 -79.29 79.29 0 177.11 0 C 274.94 0 354.23 -79.29 354.23 -177.11 Z" style="stroke:none"></path></g><g stroke="#FFFFFF" fill="#FFFFFF" color="#FFFFFF"><path d="M 119.41 -257.64 L 98.1 -257.64 L 98.1 -109.45 L 119.41 -109.45 L 119.41 -176.42 L 119.41 -257.64 Z M 150.68 -109.45 L 208.25 -109.45 C 263.04 -109.45 287.12 -148.61 287.12 -183.62 C 287.12 -221.67 257.37 -257.78 208.52 -257.78 L 150.68 -257.78 L 150.68 -109.45 Z M 171.99 -238.55 L 205.89 -238.55 C 254.19 -238.55 265.26 -201.88 265.26 -183.62 C 265.26 -153.87 246.3 -128.68 204.79 -128.68 L 171.99 -128.68 L 171.99 -238.55 Z M 122.73 -78.59 C 122.73 -86.2 116.51 -92.57 108.76 -92.57 C 101.01 -92.57 94.78 -86.2 94.78 -78.59 C 94.78 -70.85 101.01 -64.62 108.76 -64.62 C 116.51 -64.62 122.73 -70.98 122.73 -78.59 Z" style="stroke:none"></path></g></g></svg>
—</a>, Khiem Le-Huy <a target="_blank" href="https://orcid.org/0000-0001-8625-6864" title="" class="ltx_ref ltx_href"><span id="id13.13.9.id1" class="ltx_ERROR undefined">\scalerel</span>*
 <svg id="id4.4.3.1.pic1" class="ltx_picture" height="354.23" overflow="visible" version="1.1" width="354.23"><g transform="translate(0,354.23) matrix(1 0 0 -1 0 0) translate(0,354.23)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#A6CE39" fill="#A6CE39" color="#A6CE39"><path d="M 354.23 -177.11 C 354.23 -274.94 274.94 -354.23 177.11 -354.23 C 79.29 -354.23 0 -274.94 0 -177.11 C 0 -79.29 79.29 0 177.11 0 C 274.94 0 354.23 -79.29 354.23 -177.11 Z" style="stroke:none"></path></g><g stroke="#FFFFFF" fill="#FFFFFF" color="#FFFFFF"><path d="M 119.41 -257.64 L 98.1 -257.64 L 98.1 -109.45 L 119.41 -109.45 L 119.41 -176.42 L 119.41 -257.64 Z M 150.68 -109.45 L 208.25 -109.45 C 263.04 -109.45 287.12 -148.61 287.12 -183.62 C 287.12 -221.67 257.37 -257.78 208.52 -257.78 L 150.68 -257.78 L 150.68 -109.45 Z M 171.99 -238.55 L 205.89 -238.55 C 254.19 -238.55 265.26 -201.88 265.26 -183.62 C 265.26 -153.87 246.3 -128.68 204.79 -128.68 L 171.99 -128.68 L 171.99 -238.55 Z M 122.73 -78.59 C 122.73 -86.2 116.51 -92.57 108.76 -92.57 C 101.01 -92.57 94.78 -86.2 94.78 -78.59 C 94.78 -70.85 101.01 -64.62 108.76 -64.62 C 116.51 -64.62 122.73 -70.98 122.73 -78.59 Z" style="stroke:none"></path></g></g></svg>
—</a>, Long Ho-Tuan <a target="_blank" href="https://orcid.org/0009-0003-4948-5395" title="" class="ltx_ref ltx_href"><span id="id14.14.10.id1" class="ltx_ERROR undefined">\scalerel</span>*
 <svg id="id5.5.4.1.pic1" class="ltx_picture" height="354.23" overflow="visible" version="1.1" width="354.23"><g transform="translate(0,354.23) matrix(1 0 0 -1 0 0) translate(0,354.23)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#A6CE39" fill="#A6CE39" color="#A6CE39"><path d="M 354.23 -177.11 C 354.23 -274.94 274.94 -354.23 177.11 -354.23 C 79.29 -354.23 0 -274.94 0 -177.11 C 0 -79.29 79.29 0 177.11 0 C 274.94 0 354.23 -79.29 354.23 -177.11 Z" style="stroke:none"></path></g><g stroke="#FFFFFF" fill="#FFFFFF" color="#FFFFFF"><path d="M 119.41 -257.64 L 98.1 -257.64 L 98.1 -109.45 L 119.41 -109.45 L 119.41 -176.42 L 119.41 -257.64 Z M 150.68 -109.45 L 208.25 -109.45 C 263.04 -109.45 287.12 -148.61 287.12 -183.62 C 287.12 -221.67 257.37 -257.78 208.52 -257.78 L 150.68 -257.78 L 150.68 -109.45 Z M 171.99 -238.55 L 205.89 -238.55 C 254.19 -238.55 265.26 -201.88 265.26 -183.62 C 265.26 -153.87 246.3 -128.68 204.79 -128.68 L 171.99 -128.68 L 171.99 -238.55 Z M 122.73 -78.59 C 122.73 -86.2 116.51 -92.57 108.76 -92.57 C 101.01 -92.57 94.78 -86.2 94.78 -78.59 C 94.78 -70.85 101.01 -64.62 108.76 -64.62 C 116.51 -64.62 122.73 -70.98 122.73 -78.59 Z" style="stroke:none"></path></g></g></svg>
—</a>, 
<br class="ltx_break">Cuong Do-Danh <a target="_blank" href="https://orcid.org/0000-0003-4785-4524" title="" class="ltx_ref ltx_href"><span id="id15.15.11.id1" class="ltx_ERROR undefined">\scalerel</span>*
 <svg id="id6.6.5.1.pic1" class="ltx_picture" height="354.23" overflow="visible" version="1.1" width="354.23"><g transform="translate(0,354.23) matrix(1 0 0 -1 0 0) translate(0,354.23)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#A6CE39" fill="#A6CE39" color="#A6CE39"><path d="M 354.23 -177.11 C 354.23 -274.94 274.94 -354.23 177.11 -354.23 C 79.29 -354.23 0 -274.94 0 -177.11 C 0 -79.29 79.29 0 177.11 0 C 274.94 0 354.23 -79.29 354.23 -177.11 Z" style="stroke:none"></path></g><g stroke="#FFFFFF" fill="#FFFFFF" color="#FFFFFF"><path d="M 119.41 -257.64 L 98.1 -257.64 L 98.1 -109.45 L 119.41 -109.45 L 119.41 -176.42 L 119.41 -257.64 Z M 150.68 -109.45 L 208.25 -109.45 C 263.04 -109.45 287.12 -148.61 287.12 -183.62 C 287.12 -221.67 257.37 -257.78 208.52 -257.78 L 150.68 -257.78 L 150.68 -109.45 Z M 171.99 -238.55 L 205.89 -238.55 C 254.19 -238.55 265.26 -201.88 265.26 -183.62 C 265.26 -153.87 246.3 -128.68 204.79 -128.68 L 171.99 -128.68 L 171.99 -238.55 Z M 122.73 -78.59 C 122.73 -86.2 116.51 -92.57 108.76 -92.57 C 101.01 -92.57 94.78 -86.2 94.78 -78.59 C 94.78 -70.85 101.01 -64.62 108.76 -64.62 C 116.51 -64.62 122.73 -70.98 122.73 -78.59 Z" style="stroke:none"></path></g></g></svg>
—</a>, <span id="id16.16.id3" class="ltx_text ltx_font_italic">Member, IEEE</span>, and Danh Le-Phuoc <a target="_blank" href="https://orcid.org/0000-0003-2480-9261" title="" class="ltx_ref ltx_href"><span id="id17.17.12.id1" class="ltx_ERROR undefined">\scalerel</span>*
 <svg id="id7.7.6.1.pic1" class="ltx_picture" height="354.23" overflow="visible" version="1.1" width="354.23"><g transform="translate(0,354.23) matrix(1 0 0 -1 0 0) translate(0,354.23)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#A6CE39" fill="#A6CE39" color="#A6CE39"><path d="M 354.23 -177.11 C 354.23 -274.94 274.94 -354.23 177.11 -354.23 C 79.29 -354.23 0 -274.94 0 -177.11 C 0 -79.29 79.29 0 177.11 0 C 274.94 0 354.23 -79.29 354.23 -177.11 Z" style="stroke:none"></path></g><g stroke="#FFFFFF" fill="#FFFFFF" color="#FFFFFF"><path d="M 119.41 -257.64 L 98.1 -257.64 L 98.1 -109.45 L 119.41 -109.45 L 119.41 -176.42 L 119.41 -257.64 Z M 150.68 -109.45 L 208.25 -109.45 C 263.04 -109.45 287.12 -148.61 287.12 -183.62 C 287.12 -221.67 257.37 -257.78 208.52 -257.78 L 150.68 -257.78 L 150.68 -109.45 Z M 171.99 -238.55 L 205.89 -238.55 C 254.19 -238.55 265.26 -201.88 265.26 -183.62 C 265.26 -153.87 246.3 -128.68 204.79 -128.68 L 171.99 -128.68 L 171.99 -238.55 Z M 122.73 -78.59 C 122.73 -86.2 116.51 -92.57 108.76 -92.57 C 101.01 -92.57 94.78 -86.2 94.78 -78.59 C 94.78 -70.85 101.01 -64.62 108.76 -64.62 C 116.51 -64.62 122.73 -70.98 122.73 -78.59 Z" style="stroke:none"></path></g></g></svg>
—</a>, <span id="id18.18.id4" class="ltx_text ltx_font_italic">Member, IEEE</span>
</span><span class="ltx_author_notes">Manuscript received X 2023; revised X 2023; accepted X 2023. Date of publication X 2023; date of current version X 2023. Kok-Seng Wong, Khiem Le-Huy, Long Ho-Tuan, and Cuong Do-Danh are with the College of Engineering and Computer Science, VinUniversity, Hanoi, Vietnam. (e-mail:{wong.ks, khiem.lh, long.ht, cuong.dd}@vinuni.edu.vn)Manh Nguyen-Duc, and Danh Le-Phuoc are with the Technische Universität Berlin Straße des 17. Juni 135, 10623 Berlin, Germany. (e-mail: manh.nguyenduc@campus.tu-berlin.de, danh.lephuoc@tu-berlin.de)Kok-Seng Wong, Manh Nguyen-Duc, and Khiem Le-Huy contributed equally to this work. <math id="id8.8.m1.1" class="ltx_Math" alttext="*" display="inline"><semantics id="id8.8.m1.1a"><mo id="id8.8.m1.1.1" xref="id8.8.m1.1.1.cmml">∗</mo><annotation-xml encoding="MathML-Content" id="id8.8.m1.1b"><times id="id8.8.m1.1.1.cmml" xref="id8.8.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="id8.8.m1.1c">*</annotation></semantics></math> Corresponding author: wong.ks@vinuni.edu.vn (Kok-Seng Wong)</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id19.id1" class="ltx_p">Nowadays, billions of phones, IoT and edge devices around the world generate data continuously, enabling many Machine Learning (ML)-based products and applications. However, due to increasing privacy concerns and regulations, these data tend to reside on devices (clients) instead of being centralized for performing traditional ML model training. Federated Learning (FL) is a distributed approach in which a single server and multiple clients collaboratively build an ML model without moving data away from clients. Whereas existing studies on FL have their own experimental evaluations, most experiments were conducted using a simulation setting or a small-scale testbed. This might limit the understanding of FL implementation in realistic environments. In this empirical study, we systematically conduct extensive experiments on a large network of IoT and edge devices (called IoT-Edge devices) to present FL real-world characteristics, including learning performance and operation (computation and communication) costs. Moreover, we mainly concentrate on heterogeneous scenarios, which is the most challenging issue of FL. By investigating the feasibility of on-device implementation, our study provides valuable insights for researchers and practitioners, promoting the practicality of FL and assisting in improving the current design of real FL systems.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated Learning, IoT-Edge Devices, On-Device Training, Empirical Study.

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">By the end of 2018, there were an estimated 22 billion IoT devices in use around the world and this number is increasing fast. Forecasts suggest that by 2030 the number of IoT devices will increase to around 50 billion  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Also, 100 billion ARM CPUs currently dominate the IoT market have been shipped so far  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. This installation base is a key enabler for many industrial and societal domains, especially Artificial Intelligence (AI) and Machine Learning (ML) powered applications  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. However, due to increasing privacy concerns and regulations  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, especially in sensitive domains like healthcare or finance, these valuable assets mostly remain inaccessible and cannot be centralized for conducting traditional ML model training.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To address this issue, Federated Learning (FL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> was proposed, which allows multiple parties (clients) to train a shared global model collaboratively in a decentralized fashion without sharing any private dataset. In general, a standard FL framework, as illustrated in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, consists of two main steps: (1) Client training, in which clients train models on their local data for several epochs and send their trained models to a central server, and (2) Model aggregation, in which the server aggregates those models to establish a global model and distributes this global model back to the clients. This 2-step procedure is repeated for numerous rounds until the global model converges or a target level of accuracy is reached.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2305.19831/assets/figs/fl.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="299" height="227" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The standard FL framework. </figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Although FL recently has received considerable attention from the research community <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> thanks to several advantages such as scalability or data privacy protection, it still has many serious challenges which lead to difficulties for real-world implementation. Specifically, clients in a federation differ from each other in terms of computational and communication capacity. For instance, the hardware resources (memory, CPU/GPU, or connectivity) of various IoT and edge devices (IoT-Edge devices) like Raspberry Pi devices or NVIDIA Jetson devices are much different. Therefore, considering all clients equally might lead to suboptimal efficiency. Furthermore, the training data owned by each client can be non-independent, identically distributed (Non-IID), and with different quality and quantity. These challenges make FL impractical and limit the motivation of parties to join the federation for training.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Despite the aforementioned real-world issues, most existing studies on FL heavily rely on simulation settings or small-scale testbeds of devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> to examine the behavior of their systems. While simulation settings are useful for controlled testing and development of FL models, they face significant challenges in adequately covering all operational aspects of real-world deployments. Specifically, existing simulators cannot emulate crucial aspects of realistic execution environments, such as resource consumption (e.g., memory, CPU/GPU usage, battery life) and network connectivity (e.g., bandwidth and network congestion). These factors significantly impact the performance of FL systems, as demonstrated in Section <a href="#S4" title="IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>. Additionally, other realistic environment aspects such as data distribution, underlying software libraries, and executing settings introduce further challenges that can affect FL performance. Therefore, this motivates us to conduct more comprehensive evaluations of such aspects to ensure their effectiveness and scalability.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In Section <a href="#S2" title="II Preliminaries and Related Works ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, we observe a lack of experimental studies that systematically investigate the implementation of FL on real devices and assess the impact of intrinsic heterogeneity on performance and costs. Although there have been some attempts to implement FL on IoT-Edge devices at small scales with simplistic settings, it is desirable to have more reproducible experiments in larger and more realistic settings. Hence, to the best of our knowledge, our study pushed the experiment scale and complexity to a new level.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS1.5.1.1" class="ltx_text">I-A</span> </span><span id="S1.SS1.6.2" class="ltx_text ltx_font_italic"> Objectives, Research Questions and Scope</span>
</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">To identify potential issues and limitations on real devices that may not be apparent in simulated environments, we focus our study on the impact of resource allocations and heterogeneity independently and their combined effects in realistic environments. To achieve this, we focus on the following research questions (RQ):
</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">RQ1: What are the behaviors of FL implementation in realistic environments compared to a simulation setting?</span> In this RQ, we compare many simulation and on-device deployment aspects. We want to see how simulation results can represent reality because FL experiments conducted in a controlled laboratory setting may not accurately reflect the challenges and complexities of realistic device-based environments.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">RQ2: How do resource allocation and heterogeneity affect the learning performance and operation costs?</span> There are several factors that can affect FL deployment. This RQ focuses on the client participation rate, communication bandwidth, device and data heterogeneity. We test each factor independently to learn their impact on the behaviors of FL. Specifically, we want to observe the impact of varying the number and type of devices, bandwidth, and data distribution on the FL process for each factor.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">RQ3: How do these two factors, resource allocation and heterogeneity, simultaneously affect the learning performance and operation costs?</span> This RQ is an essential study on understanding the impact of combined factors as specified in RQ2. Additionally, we aim to find the dominant factor towards the behaviors of FL in a real-world deployment.</p>
</div>
</li>
</ul>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">To answer these questions, we need stable FL systems that can be deployed our targeted hardware, i.e., Raspberry Pi 3 (Pi3), Raspberry Pi 4 (Pi4), Jetson Nano (Nano) and Jetson TX2 (TX2) and can support GPUs on edge computing boards. While many algorithms are accompanied by source code, only Federated Averaging (FedAvg) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> can satisfy our requirements due to its popularity.
FedAvg has been extensively studied and evaluated in the literature with a large number of works reporting its performance characteristics and limitations in simulations. However, understanding its behavior on real devices is still limited (c.f. Secion <a href="#S2" title="II Preliminaries and Related Works ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>. Hence, we will focus on FedAvg for our studies in this paper and leave others for future work. However, our experiment design in Section <a href="#S3" title="III Experimental Design ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> is general enough to be replicated in other algorithms, given that their implementations are stable enough to run on targeted devices.</p>
</div>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS2.5.1.1" class="ltx_text">I-B</span> </span><span id="S1.SS2.6.2" class="ltx_text ltx_font_italic">Our Key Findings</span>
</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p">Along this light, our extensive set of experiments reported in Section <a href="#S4" title="IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> reveal the following key findings:</p>
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p">The on-device settings can achieve similar training accuracy to the simulation counterparts with similar convergence behaviors.
But when it comes to operational behaviours related to computation and communication, the on-device ones show much more complicated behavior patterns for realistic IoT-Edge deployments.</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p">The disparity in computational and networking resources among the participating devices leads to longer model update (local and global) exchange times because high computational devices need to wait for the server to receive and aggregate local updates from low computational devices. This hints that an oversimplified emulation of these aspects in simulation setting highly likely lead to unexpected outcomes of a FL algorithm at the deployment phase.</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p id="S1.I2.i3.p1.1" class="ltx_p">Data heterogeneity is the most dominant factor in FL performance, followed by the number of clients. The performance of the global model is affected most by the data distribution (i.e., Non-IID and Extreme Non-IID) of each participating client, especially for challenging learning tasks. Hence, combining with the disparity in computational and networking resources, FL on diverse IoT-Edge devices in realistic deployment settings need further understanding on-device behaviours in terms combining all these factors in tandem.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS3.5.1.1" class="ltx_text">I-C</span> </span><span id="S1.SS3.6.2" class="ltx_text ltx_font_italic">Paper Outline</span>
</h3>

<div id="S1.SS3.p1" class="ltx_para">
<p id="S1.SS3.p1.1" class="ltx_p">The rest of this article is organized as follows. Section <a href="#S2" title="II Preliminaries and Related Works ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> presents preliminaries to our work and discusses some existing surveys and empirical studies on FL. In Section <a href="#S3" title="III Experimental Design ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, we show our experimental designs and followed by our results and findings in Section <a href="#S4" title="IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>. Finally, we give further discussions in Section <a href="#S5" title="V Discussions ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> and conclude this empirical study in Section <a href="#S6" title="VI Conclusions and Future Works ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Preliminaries and Related Works</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Federated Learning</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">In the standard FL framework, data for learning tasks is acquired and processed locally at the IoT-Edge nodes, and only the trained model parameters are transmitted to the central server for aggregation. In general, along with an initialization stage, FL involves the following stages:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.4" class="ltx_p"><span id="S2.I1.i1.p1.4.1" class="ltx_text ltx_font_italic">Stage 0 (Initialization</span>): The aggregation server <math id="S2.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.I1.i1.p1.1.m1.1a"><mi id="S2.I1.i1.p1.1.m1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.1b"><ci id="S2.I1.i1.p1.1.m1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.1c">S</annotation></semantics></math> first initiates the weight <math id="S2.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="w_{0}" display="inline"><semantics id="S2.I1.i1.p1.2.m2.1a"><msub id="S2.I1.i1.p1.2.m2.1.1" xref="S2.I1.i1.p1.2.m2.1.1.cmml"><mi id="S2.I1.i1.p1.2.m2.1.1.2" xref="S2.I1.i1.p1.2.m2.1.1.2.cmml">w</mi><mn id="S2.I1.i1.p1.2.m2.1.1.3" xref="S2.I1.i1.p1.2.m2.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.2.m2.1b"><apply id="S2.I1.i1.p1.2.m2.1.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.1.1.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1">subscript</csymbol><ci id="S2.I1.i1.p1.2.m2.1.1.2.cmml" xref="S2.I1.i1.p1.2.m2.1.1.2">𝑤</ci><cn type="integer" id="S2.I1.i1.p1.2.m2.1.1.3.cmml" xref="S2.I1.i1.p1.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.2.m2.1c">w_{0}</annotation></semantics></math> of the global model and hyperparameters such as the number of communication rounds <math id="S2.I1.i1.p1.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.I1.i1.p1.3.m3.1a"><mi id="S2.I1.i1.p1.3.m3.1.1" xref="S2.I1.i1.p1.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.3.m3.1b"><ci id="S2.I1.i1.p1.3.m3.1.1.cmml" xref="S2.I1.i1.p1.3.m3.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.3.m3.1c">T</annotation></semantics></math>, size of the selected clients for each round <math id="S2.I1.i1.p1.4.m4.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.I1.i1.p1.4.m4.1a"><mi id="S2.I1.i1.p1.4.m4.1.1" xref="S2.I1.i1.p1.4.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.4.m4.1b"><ci id="S2.I1.i1.p1.4.m4.1.1.cmml" xref="S2.I1.i1.p1.4.m4.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.4.m4.1c">N</annotation></semantics></math>, and local training details.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.10" class="ltx_p"><span id="S2.I1.i2.p1.10.1" class="ltx_text ltx_font_italic">Stage 1 (Client training</span>): All selected clients <math id="S2.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="C_{1}" display="inline"><semantics id="S2.I1.i2.p1.1.m1.1a"><msub id="S2.I1.i2.p1.1.m1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.cmml"><mi id="S2.I1.i2.p1.1.m1.1.1.2" xref="S2.I1.i2.p1.1.m1.1.1.2.cmml">C</mi><mn id="S2.I1.i2.p1.1.m1.1.1.3" xref="S2.I1.i2.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.1.m1.1b"><apply id="S2.I1.i2.p1.1.m1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.1.m1.1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.1.m1.1.1.2.cmml" xref="S2.I1.i2.p1.1.m1.1.1.2">𝐶</ci><cn type="integer" id="S2.I1.i2.p1.1.m1.1.1.3.cmml" xref="S2.I1.i2.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.1.m1.1c">C_{1}</annotation></semantics></math>, <math id="S2.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="C_{2}" display="inline"><semantics id="S2.I1.i2.p1.2.m2.1a"><msub id="S2.I1.i2.p1.2.m2.1.1" xref="S2.I1.i2.p1.2.m2.1.1.cmml"><mi id="S2.I1.i2.p1.2.m2.1.1.2" xref="S2.I1.i2.p1.2.m2.1.1.2.cmml">C</mi><mn id="S2.I1.i2.p1.2.m2.1.1.3" xref="S2.I1.i2.p1.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.2.m2.1b"><apply id="S2.I1.i2.p1.2.m2.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.1.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.2.m2.1.1.2.cmml" xref="S2.I1.i2.p1.2.m2.1.1.2">𝐶</ci><cn type="integer" id="S2.I1.i2.p1.2.m2.1.1.3.cmml" xref="S2.I1.i2.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.2.m2.1c">C_{2}</annotation></semantics></math>, <math id="S2.I1.i2.p1.3.m3.1" class="ltx_Math" alttext="C_{3}" display="inline"><semantics id="S2.I1.i2.p1.3.m3.1a"><msub id="S2.I1.i2.p1.3.m3.1.1" xref="S2.I1.i2.p1.3.m3.1.1.cmml"><mi id="S2.I1.i2.p1.3.m3.1.1.2" xref="S2.I1.i2.p1.3.m3.1.1.2.cmml">C</mi><mn id="S2.I1.i2.p1.3.m3.1.1.3" xref="S2.I1.i2.p1.3.m3.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.3.m3.1b"><apply id="S2.I1.i2.p1.3.m3.1.1.cmml" xref="S2.I1.i2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.3.m3.1.1.1.cmml" xref="S2.I1.i2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.3.m3.1.1.2.cmml" xref="S2.I1.i2.p1.3.m3.1.1.2">𝐶</ci><cn type="integer" id="S2.I1.i2.p1.3.m3.1.1.3.cmml" xref="S2.I1.i2.p1.3.m3.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.3.m3.1c">C_{3}</annotation></semantics></math>, …, <math id="S2.I1.i2.p1.4.m4.1" class="ltx_Math" alttext="C_{N}" display="inline"><semantics id="S2.I1.i2.p1.4.m4.1a"><msub id="S2.I1.i2.p1.4.m4.1.1" xref="S2.I1.i2.p1.4.m4.1.1.cmml"><mi id="S2.I1.i2.p1.4.m4.1.1.2" xref="S2.I1.i2.p1.4.m4.1.1.2.cmml">C</mi><mi id="S2.I1.i2.p1.4.m4.1.1.3" xref="S2.I1.i2.p1.4.m4.1.1.3.cmml">N</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.4.m4.1b"><apply id="S2.I1.i2.p1.4.m4.1.1.cmml" xref="S2.I1.i2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.4.m4.1.1.1.cmml" xref="S2.I1.i2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.4.m4.1.1.2.cmml" xref="S2.I1.i2.p1.4.m4.1.1.2">𝐶</ci><ci id="S2.I1.i2.p1.4.m4.1.1.3.cmml" xref="S2.I1.i2.p1.4.m4.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.4.m4.1c">C_{N}</annotation></semantics></math> receive the current global weight from <math id="S2.I1.i2.p1.5.m5.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.I1.i2.p1.5.m5.1a"><mi id="S2.I1.i2.p1.5.m5.1.1" xref="S2.I1.i2.p1.5.m5.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.5.m5.1b"><ci id="S2.I1.i2.p1.5.m5.1.1.cmml" xref="S2.I1.i2.p1.5.m5.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.5.m5.1c">S</annotation></semantics></math>. Next, each <math id="S2.I1.i2.p1.6.m6.1" class="ltx_Math" alttext="C_{i}" display="inline"><semantics id="S2.I1.i2.p1.6.m6.1a"><msub id="S2.I1.i2.p1.6.m6.1.1" xref="S2.I1.i2.p1.6.m6.1.1.cmml"><mi id="S2.I1.i2.p1.6.m6.1.1.2" xref="S2.I1.i2.p1.6.m6.1.1.2.cmml">C</mi><mi id="S2.I1.i2.p1.6.m6.1.1.3" xref="S2.I1.i2.p1.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.6.m6.1b"><apply id="S2.I1.i2.p1.6.m6.1.1.cmml" xref="S2.I1.i2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.6.m6.1.1.1.cmml" xref="S2.I1.i2.p1.6.m6.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.6.m6.1.1.2.cmml" xref="S2.I1.i2.p1.6.m6.1.1.2">𝐶</ci><ci id="S2.I1.i2.p1.6.m6.1.1.3.cmml" xref="S2.I1.i2.p1.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.6.m6.1c">C_{i}</annotation></semantics></math> updates its local model parameters <math id="S2.I1.i2.p1.7.m7.1" class="ltx_Math" alttext="w_{i}^{t}" display="inline"><semantics id="S2.I1.i2.p1.7.m7.1a"><msubsup id="S2.I1.i2.p1.7.m7.1.1" xref="S2.I1.i2.p1.7.m7.1.1.cmml"><mi id="S2.I1.i2.p1.7.m7.1.1.2.2" xref="S2.I1.i2.p1.7.m7.1.1.2.2.cmml">w</mi><mi id="S2.I1.i2.p1.7.m7.1.1.2.3" xref="S2.I1.i2.p1.7.m7.1.1.2.3.cmml">i</mi><mi id="S2.I1.i2.p1.7.m7.1.1.3" xref="S2.I1.i2.p1.7.m7.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.7.m7.1b"><apply id="S2.I1.i2.p1.7.m7.1.1.cmml" xref="S2.I1.i2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.7.m7.1.1.1.cmml" xref="S2.I1.i2.p1.7.m7.1.1">superscript</csymbol><apply id="S2.I1.i2.p1.7.m7.1.1.2.cmml" xref="S2.I1.i2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.7.m7.1.1.2.1.cmml" xref="S2.I1.i2.p1.7.m7.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.7.m7.1.1.2.2.cmml" xref="S2.I1.i2.p1.7.m7.1.1.2.2">𝑤</ci><ci id="S2.I1.i2.p1.7.m7.1.1.2.3.cmml" xref="S2.I1.i2.p1.7.m7.1.1.2.3">𝑖</ci></apply><ci id="S2.I1.i2.p1.7.m7.1.1.3.cmml" xref="S2.I1.i2.p1.7.m7.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.7.m7.1c">w_{i}^{t}</annotation></semantics></math> using its local dataset <math id="S2.I1.i2.p1.8.m8.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S2.I1.i2.p1.8.m8.1a"><msub id="S2.I1.i2.p1.8.m8.1.1" xref="S2.I1.i2.p1.8.m8.1.1.cmml"><mi id="S2.I1.i2.p1.8.m8.1.1.2" xref="S2.I1.i2.p1.8.m8.1.1.2.cmml">D</mi><mi id="S2.I1.i2.p1.8.m8.1.1.3" xref="S2.I1.i2.p1.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.8.m8.1b"><apply id="S2.I1.i2.p1.8.m8.1.1.cmml" xref="S2.I1.i2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.8.m8.1.1.1.cmml" xref="S2.I1.i2.p1.8.m8.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.8.m8.1.1.2.cmml" xref="S2.I1.i2.p1.8.m8.1.1.2">𝐷</ci><ci id="S2.I1.i2.p1.8.m8.1.1.3.cmml" xref="S2.I1.i2.p1.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.8.m8.1c">D_{i}</annotation></semantics></math>, where <math id="S2.I1.i2.p1.9.m9.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.I1.i2.p1.9.m9.1a"><mi id="S2.I1.i2.p1.9.m9.1.1" xref="S2.I1.i2.p1.9.m9.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.9.m9.1b"><ci id="S2.I1.i2.p1.9.m9.1.1.cmml" xref="S2.I1.i2.p1.9.m9.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.9.m9.1c">t</annotation></semantics></math> denotes the current communication round. Upon the completion of the local training, all selected clients send the local weight to <math id="S2.I1.i2.p1.10.m10.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.I1.i2.p1.10.m10.1a"><mi id="S2.I1.i2.p1.10.m10.1.1" xref="S2.I1.i2.p1.10.m10.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.10.m10.1b"><ci id="S2.I1.i2.p1.10.m10.1.1.cmml" xref="S2.I1.i2.p1.10.m10.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.10.m10.1c">S</annotation></semantics></math> for model aggregation.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">Stage 2 (Model Aggregation)</span>: <math id="S2.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.I1.i3.p1.1.m1.1a"><mi id="S2.I1.i3.p1.1.m1.1.1" xref="S2.I1.i3.p1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.1.m1.1b"><ci id="S2.I1.i3.p1.1.m1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.1.m1.1c">S</annotation></semantics></math> aggregates the received local weights based on a certain mechanism and then sends back the aggregated weights to the clients for the next round of local training.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Federated Averaging Algorithm</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.2" class="ltx_p">Federated Averaging (FedAvg) is the de facto FL algorithm that is included in most FL systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. As shown in Algorithm <a href="#alg1" title="Algorithm 1 ‣ II-B Federated Averaging Algorithm ‣ II Preliminaries and Related Works ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, FedAvg aggregates the locally trained model parameters by weighted averaging proportional to the amount of local dataset <math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><msub id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml"><mi id="S2.SS2.p1.1.m1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.2.cmml">D</mi><mi id="S2.SS2.p1.1.m1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><apply id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.2">𝐷</ci><ci id="S2.SS2.p1.1.m1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">D_{i}</annotation></semantics></math>, that each client <math id="S2.SS2.p1.2.m2.1" class="ltx_Math" alttext="C_{i}" display="inline"><semantics id="S2.SS2.p1.2.m2.1a"><msub id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml"><mi id="S2.SS2.p1.2.m2.1.1.2" xref="S2.SS2.p1.2.m2.1.1.2.cmml">C</mi><mi id="S2.SS2.p1.2.m2.1.1.3" xref="S2.SS2.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><apply id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.1.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS2.p1.2.m2.1.1.2.cmml" xref="S2.SS2.p1.2.m2.1.1.2">𝐶</ci><ci id="S2.SS2.p1.2.m2.1.1.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">C_{i}</annotation></semantics></math> had (corresponding to the above Stage 2). Note that there are many advanced FL algorithms were introduced (e.g., FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and FedMA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>), with different purposes in the last few years <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</p>
</div>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.2.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> FedAvg Algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. </figcaption>
<div id="alg1.3" class="ltx_listing ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l1.1.1.1" class="ltx_text" style="font-size:80%;">1:</span></span>  <span id="alg1.l1.2" class="ltx_text ltx_font_bold">Aggregation Server executes:</span>

</div>
<div id="alg1.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l2.1.1.1" class="ltx_text" style="font-size:80%;">2:</span></span>  initialize: <math id="alg1.l2.m1.1" class="ltx_Math" alttext="w\leftarrow w_{0}" display="inline"><semantics id="alg1.l2.m1.1a"><mrow id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml"><mi id="alg1.l2.m1.1.1.2" xref="alg1.l2.m1.1.1.2.cmml">w</mi><mo stretchy="false" id="alg1.l2.m1.1.1.1" xref="alg1.l2.m1.1.1.1.cmml">←</mo><msub id="alg1.l2.m1.1.1.3" xref="alg1.l2.m1.1.1.3.cmml"><mi id="alg1.l2.m1.1.1.3.2" xref="alg1.l2.m1.1.1.3.2.cmml">w</mi><mn id="alg1.l2.m1.1.1.3.3" xref="alg1.l2.m1.1.1.3.3.cmml">0</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><apply id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1"><ci id="alg1.l2.m1.1.1.1.cmml" xref="alg1.l2.m1.1.1.1">←</ci><ci id="alg1.l2.m1.1.1.2.cmml" xref="alg1.l2.m1.1.1.2">𝑤</ci><apply id="alg1.l2.m1.1.1.3.cmml" xref="alg1.l2.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l2.m1.1.1.3.1.cmml" xref="alg1.l2.m1.1.1.3">subscript</csymbol><ci id="alg1.l2.m1.1.1.3.2.cmml" xref="alg1.l2.m1.1.1.3.2">𝑤</ci><cn type="integer" id="alg1.l2.m1.1.1.3.3.cmml" xref="alg1.l2.m1.1.1.3.3">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">w\leftarrow w_{0}</annotation></semantics></math>

</div>
<div id="alg1.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l3.1.1.1" class="ltx_text" style="font-size:80%;">3:</span></span>  <span id="alg1.l3.2" class="ltx_text ltx_font_bold">for</span> each round <math id="alg1.l3.m1.5" class="ltx_Math" alttext="t=1,2,3,\dots,T" display="inline"><semantics id="alg1.l3.m1.5a"><mrow id="alg1.l3.m1.5.6" xref="alg1.l3.m1.5.6.cmml"><mi id="alg1.l3.m1.5.6.2" xref="alg1.l3.m1.5.6.2.cmml">t</mi><mo id="alg1.l3.m1.5.6.1" xref="alg1.l3.m1.5.6.1.cmml">=</mo><mrow id="alg1.l3.m1.5.6.3.2" xref="alg1.l3.m1.5.6.3.1.cmml"><mn id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml">1</mn><mo id="alg1.l3.m1.5.6.3.2.1" xref="alg1.l3.m1.5.6.3.1.cmml">,</mo><mn id="alg1.l3.m1.2.2" xref="alg1.l3.m1.2.2.cmml">2</mn><mo id="alg1.l3.m1.5.6.3.2.2" xref="alg1.l3.m1.5.6.3.1.cmml">,</mo><mn id="alg1.l3.m1.3.3" xref="alg1.l3.m1.3.3.cmml">3</mn><mo id="alg1.l3.m1.5.6.3.2.3" xref="alg1.l3.m1.5.6.3.1.cmml">,</mo><mi mathvariant="normal" id="alg1.l3.m1.4.4" xref="alg1.l3.m1.4.4.cmml">…</mi><mo id="alg1.l3.m1.5.6.3.2.4" xref="alg1.l3.m1.5.6.3.1.cmml">,</mo><mi id="alg1.l3.m1.5.5" xref="alg1.l3.m1.5.5.cmml">T</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.5b"><apply id="alg1.l3.m1.5.6.cmml" xref="alg1.l3.m1.5.6"><eq id="alg1.l3.m1.5.6.1.cmml" xref="alg1.l3.m1.5.6.1"></eq><ci id="alg1.l3.m1.5.6.2.cmml" xref="alg1.l3.m1.5.6.2">𝑡</ci><list id="alg1.l3.m1.5.6.3.1.cmml" xref="alg1.l3.m1.5.6.3.2"><cn type="integer" id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1">1</cn><cn type="integer" id="alg1.l3.m1.2.2.cmml" xref="alg1.l3.m1.2.2">2</cn><cn type="integer" id="alg1.l3.m1.3.3.cmml" xref="alg1.l3.m1.3.3">3</cn><ci id="alg1.l3.m1.4.4.cmml" xref="alg1.l3.m1.4.4">…</ci><ci id="alg1.l3.m1.5.5.cmml" xref="alg1.l3.m1.5.5">𝑇</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.5c">t=1,2,3,\dots,T</annotation></semantics></math> <span id="alg1.l3.3" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l4.1.1.1" class="ltx_text" style="font-size:80%;">4:</span></span>     <span id="alg1.l4.2" class="ltx_text ltx_font_bold">for</span> each client <math id="alg1.l4.m1.5" class="ltx_Math" alttext="i=1,2,3,\dots,N" display="inline"><semantics id="alg1.l4.m1.5a"><mrow id="alg1.l4.m1.5.6" xref="alg1.l4.m1.5.6.cmml"><mi id="alg1.l4.m1.5.6.2" xref="alg1.l4.m1.5.6.2.cmml">i</mi><mo id="alg1.l4.m1.5.6.1" xref="alg1.l4.m1.5.6.1.cmml">=</mo><mrow id="alg1.l4.m1.5.6.3.2" xref="alg1.l4.m1.5.6.3.1.cmml"><mn id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml">1</mn><mo id="alg1.l4.m1.5.6.3.2.1" xref="alg1.l4.m1.5.6.3.1.cmml">,</mo><mn id="alg1.l4.m1.2.2" xref="alg1.l4.m1.2.2.cmml">2</mn><mo id="alg1.l4.m1.5.6.3.2.2" xref="alg1.l4.m1.5.6.3.1.cmml">,</mo><mn id="alg1.l4.m1.3.3" xref="alg1.l4.m1.3.3.cmml">3</mn><mo id="alg1.l4.m1.5.6.3.2.3" xref="alg1.l4.m1.5.6.3.1.cmml">,</mo><mi mathvariant="normal" id="alg1.l4.m1.4.4" xref="alg1.l4.m1.4.4.cmml">…</mi><mo id="alg1.l4.m1.5.6.3.2.4" xref="alg1.l4.m1.5.6.3.1.cmml">,</mo><mi id="alg1.l4.m1.5.5" xref="alg1.l4.m1.5.5.cmml">N</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.5b"><apply id="alg1.l4.m1.5.6.cmml" xref="alg1.l4.m1.5.6"><eq id="alg1.l4.m1.5.6.1.cmml" xref="alg1.l4.m1.5.6.1"></eq><ci id="alg1.l4.m1.5.6.2.cmml" xref="alg1.l4.m1.5.6.2">𝑖</ci><list id="alg1.l4.m1.5.6.3.1.cmml" xref="alg1.l4.m1.5.6.3.2"><cn type="integer" id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1">1</cn><cn type="integer" id="alg1.l4.m1.2.2.cmml" xref="alg1.l4.m1.2.2">2</cn><cn type="integer" id="alg1.l4.m1.3.3.cmml" xref="alg1.l4.m1.3.3">3</cn><ci id="alg1.l4.m1.4.4.cmml" xref="alg1.l4.m1.4.4">…</ci><ci id="alg1.l4.m1.5.5.cmml" xref="alg1.l4.m1.5.5">𝑁</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.5c">i=1,2,3,\dots,N</annotation></semantics></math> <span id="alg1.l4.3" class="ltx_text ltx_font_bold">in parallel</span> <span id="alg1.l4.4" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l5.1.1.1" class="ltx_text" style="font-size:80%;">5:</span></span>        <math id="alg1.l5.m1.1" class="ltx_Math" alttext="w_{i}^{t}\leftarrow w^{t-1}" display="inline"><semantics id="alg1.l5.m1.1a"><mrow id="alg1.l5.m1.1.1" xref="alg1.l5.m1.1.1.cmml"><msubsup id="alg1.l5.m1.1.1.2" xref="alg1.l5.m1.1.1.2.cmml"><mi id="alg1.l5.m1.1.1.2.2.2" xref="alg1.l5.m1.1.1.2.2.2.cmml">w</mi><mi id="alg1.l5.m1.1.1.2.2.3" xref="alg1.l5.m1.1.1.2.2.3.cmml">i</mi><mi id="alg1.l5.m1.1.1.2.3" xref="alg1.l5.m1.1.1.2.3.cmml">t</mi></msubsup><mo stretchy="false" id="alg1.l5.m1.1.1.1" xref="alg1.l5.m1.1.1.1.cmml">←</mo><msup id="alg1.l5.m1.1.1.3" xref="alg1.l5.m1.1.1.3.cmml"><mi id="alg1.l5.m1.1.1.3.2" xref="alg1.l5.m1.1.1.3.2.cmml">w</mi><mrow id="alg1.l5.m1.1.1.3.3" xref="alg1.l5.m1.1.1.3.3.cmml"><mi id="alg1.l5.m1.1.1.3.3.2" xref="alg1.l5.m1.1.1.3.3.2.cmml">t</mi><mo id="alg1.l5.m1.1.1.3.3.1" xref="alg1.l5.m1.1.1.3.3.1.cmml">−</mo><mn id="alg1.l5.m1.1.1.3.3.3" xref="alg1.l5.m1.1.1.3.3.3.cmml">1</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.1b"><apply id="alg1.l5.m1.1.1.cmml" xref="alg1.l5.m1.1.1"><ci id="alg1.l5.m1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1">←</ci><apply id="alg1.l5.m1.1.1.2.cmml" xref="alg1.l5.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.2.1.cmml" xref="alg1.l5.m1.1.1.2">superscript</csymbol><apply id="alg1.l5.m1.1.1.2.2.cmml" xref="alg1.l5.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.2.2.1.cmml" xref="alg1.l5.m1.1.1.2">subscript</csymbol><ci id="alg1.l5.m1.1.1.2.2.2.cmml" xref="alg1.l5.m1.1.1.2.2.2">𝑤</ci><ci id="alg1.l5.m1.1.1.2.2.3.cmml" xref="alg1.l5.m1.1.1.2.2.3">𝑖</ci></apply><ci id="alg1.l5.m1.1.1.2.3.cmml" xref="alg1.l5.m1.1.1.2.3">𝑡</ci></apply><apply id="alg1.l5.m1.1.1.3.cmml" xref="alg1.l5.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.3.1.cmml" xref="alg1.l5.m1.1.1.3">superscript</csymbol><ci id="alg1.l5.m1.1.1.3.2.cmml" xref="alg1.l5.m1.1.1.3.2">𝑤</ci><apply id="alg1.l5.m1.1.1.3.3.cmml" xref="alg1.l5.m1.1.1.3.3"><minus id="alg1.l5.m1.1.1.3.3.1.cmml" xref="alg1.l5.m1.1.1.3.3.1"></minus><ci id="alg1.l5.m1.1.1.3.3.2.cmml" xref="alg1.l5.m1.1.1.3.3.2">𝑡</ci><cn type="integer" id="alg1.l5.m1.1.1.3.3.3.cmml" xref="alg1.l5.m1.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">w_{i}^{t}\leftarrow w^{t-1}</annotation></semantics></math>

</div>
<div id="alg1.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l6.1.1.1" class="ltx_text" style="font-size:80%;">6:</span></span>        <math id="alg1.l6.m1.1" class="ltx_Math" alttext="w_{i}^{t}\leftarrow" display="inline"><semantics id="alg1.l6.m1.1a"><mrow id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><msubsup id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2.cmml"><mi id="alg1.l6.m1.1.1.2.2.2" xref="alg1.l6.m1.1.1.2.2.2.cmml">w</mi><mi id="alg1.l6.m1.1.1.2.2.3" xref="alg1.l6.m1.1.1.2.2.3.cmml">i</mi><mi id="alg1.l6.m1.1.1.2.3" xref="alg1.l6.m1.1.1.2.3.cmml">t</mi></msubsup><mo stretchy="false" id="alg1.l6.m1.1.1.1" xref="alg1.l6.m1.1.1.1.cmml">←</mo><mi id="alg1.l6.m1.1.1.3" xref="alg1.l6.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><ci id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1.1">←</ci><apply id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.2.1.cmml" xref="alg1.l6.m1.1.1.2">superscript</csymbol><apply id="alg1.l6.m1.1.1.2.2.cmml" xref="alg1.l6.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.2.2.1.cmml" xref="alg1.l6.m1.1.1.2">subscript</csymbol><ci id="alg1.l6.m1.1.1.2.2.2.cmml" xref="alg1.l6.m1.1.1.2.2.2">𝑤</ci><ci id="alg1.l6.m1.1.1.2.2.3.cmml" xref="alg1.l6.m1.1.1.2.2.3">𝑖</ci></apply><ci id="alg1.l6.m1.1.1.2.3.cmml" xref="alg1.l6.m1.1.1.2.3">𝑡</ci></apply><csymbol cd="latexml" id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">w_{i}^{t}\leftarrow</annotation></semantics></math> <span id="alg1.l6.2" class="ltx_text ltx_font_bold">ClientTraining</span>(<math id="alg1.l6.m2.1" class="ltx_Math" alttext="w_{i}^{t}" display="inline"><semantics id="alg1.l6.m2.1a"><msubsup id="alg1.l6.m2.1.1" xref="alg1.l6.m2.1.1.cmml"><mi id="alg1.l6.m2.1.1.2.2" xref="alg1.l6.m2.1.1.2.2.cmml">w</mi><mi id="alg1.l6.m2.1.1.2.3" xref="alg1.l6.m2.1.1.2.3.cmml">i</mi><mi id="alg1.l6.m2.1.1.3" xref="alg1.l6.m2.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l6.m2.1b"><apply id="alg1.l6.m2.1.1.cmml" xref="alg1.l6.m2.1.1"><csymbol cd="ambiguous" id="alg1.l6.m2.1.1.1.cmml" xref="alg1.l6.m2.1.1">superscript</csymbol><apply id="alg1.l6.m2.1.1.2.cmml" xref="alg1.l6.m2.1.1"><csymbol cd="ambiguous" id="alg1.l6.m2.1.1.2.1.cmml" xref="alg1.l6.m2.1.1">subscript</csymbol><ci id="alg1.l6.m2.1.1.2.2.cmml" xref="alg1.l6.m2.1.1.2.2">𝑤</ci><ci id="alg1.l6.m2.1.1.2.3.cmml" xref="alg1.l6.m2.1.1.2.3">𝑖</ci></apply><ci id="alg1.l6.m2.1.1.3.cmml" xref="alg1.l6.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m2.1c">w_{i}^{t}</annotation></semantics></math>, <math id="alg1.l6.m3.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="alg1.l6.m3.1a"><msub id="alg1.l6.m3.1.1" xref="alg1.l6.m3.1.1.cmml"><mi id="alg1.l6.m3.1.1.2" xref="alg1.l6.m3.1.1.2.cmml">D</mi><mi id="alg1.l6.m3.1.1.3" xref="alg1.l6.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l6.m3.1b"><apply id="alg1.l6.m3.1.1.cmml" xref="alg1.l6.m3.1.1"><csymbol cd="ambiguous" id="alg1.l6.m3.1.1.1.cmml" xref="alg1.l6.m3.1.1">subscript</csymbol><ci id="alg1.l6.m3.1.1.2.cmml" xref="alg1.l6.m3.1.1.2">𝐷</ci><ci id="alg1.l6.m3.1.1.3.cmml" xref="alg1.l6.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m3.1c">D_{i}</annotation></semantics></math>)

</div>
<div id="alg1.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l7.1.1.1" class="ltx_text" style="font-size:80%;">7:</span></span>     <span id="alg1.l7.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l7.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l8.1.1.1" class="ltx_text" style="font-size:80%;">8:</span></span>     // ModelAggregation

</div>
<div id="alg1.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l9.1.1.1" class="ltx_text" style="font-size:80%;">9:</span></span>     <math id="alg1.l9.m1.1" class="ltx_Math" alttext="w^{t+1}\leftarrow\frac{1}{\sum_{i=1}^{N}n_{i}}\sum_{i=1}^{N}n_{i}w_{i}^{t}" display="inline"><semantics id="alg1.l9.m1.1a"><mrow id="alg1.l9.m1.1.1" xref="alg1.l9.m1.1.1.cmml"><msup id="alg1.l9.m1.1.1.2" xref="alg1.l9.m1.1.1.2.cmml"><mi id="alg1.l9.m1.1.1.2.2" xref="alg1.l9.m1.1.1.2.2.cmml">w</mi><mrow id="alg1.l9.m1.1.1.2.3" xref="alg1.l9.m1.1.1.2.3.cmml"><mi id="alg1.l9.m1.1.1.2.3.2" xref="alg1.l9.m1.1.1.2.3.2.cmml">t</mi><mo id="alg1.l9.m1.1.1.2.3.1" xref="alg1.l9.m1.1.1.2.3.1.cmml">+</mo><mn id="alg1.l9.m1.1.1.2.3.3" xref="alg1.l9.m1.1.1.2.3.3.cmml">1</mn></mrow></msup><mo stretchy="false" id="alg1.l9.m1.1.1.1" xref="alg1.l9.m1.1.1.1.cmml">←</mo><mrow id="alg1.l9.m1.1.1.3" xref="alg1.l9.m1.1.1.3.cmml"><mfrac id="alg1.l9.m1.1.1.3.2" xref="alg1.l9.m1.1.1.3.2.cmml"><mn id="alg1.l9.m1.1.1.3.2.2" xref="alg1.l9.m1.1.1.3.2.2.cmml">1</mn><mrow id="alg1.l9.m1.1.1.3.2.3" xref="alg1.l9.m1.1.1.3.2.3.cmml"><mstyle displaystyle="false" id="alg1.l9.m1.1.1.3.2.3.1" xref="alg1.l9.m1.1.1.3.2.3.1.cmml"><msubsup id="alg1.l9.m1.1.1.3.2.3.1a" xref="alg1.l9.m1.1.1.3.2.3.1.cmml"><mo id="alg1.l9.m1.1.1.3.2.3.1.2.2" xref="alg1.l9.m1.1.1.3.2.3.1.2.2.cmml">∑</mo><mrow id="alg1.l9.m1.1.1.3.2.3.1.2.3" xref="alg1.l9.m1.1.1.3.2.3.1.2.3.cmml"><mi id="alg1.l9.m1.1.1.3.2.3.1.2.3.2" xref="alg1.l9.m1.1.1.3.2.3.1.2.3.2.cmml">i</mi><mo id="alg1.l9.m1.1.1.3.2.3.1.2.3.1" xref="alg1.l9.m1.1.1.3.2.3.1.2.3.1.cmml">=</mo><mn id="alg1.l9.m1.1.1.3.2.3.1.2.3.3" xref="alg1.l9.m1.1.1.3.2.3.1.2.3.3.cmml">1</mn></mrow><mi id="alg1.l9.m1.1.1.3.2.3.1.3" xref="alg1.l9.m1.1.1.3.2.3.1.3.cmml">N</mi></msubsup></mstyle><msub id="alg1.l9.m1.1.1.3.2.3.2" xref="alg1.l9.m1.1.1.3.2.3.2.cmml"><mi id="alg1.l9.m1.1.1.3.2.3.2.2" xref="alg1.l9.m1.1.1.3.2.3.2.2.cmml">n</mi><mi id="alg1.l9.m1.1.1.3.2.3.2.3" xref="alg1.l9.m1.1.1.3.2.3.2.3.cmml">i</mi></msub></mrow></mfrac><mo lspace="0em" rspace="0em" id="alg1.l9.m1.1.1.3.1" xref="alg1.l9.m1.1.1.3.1.cmml">​</mo><mrow id="alg1.l9.m1.1.1.3.3" xref="alg1.l9.m1.1.1.3.3.cmml"><msubsup id="alg1.l9.m1.1.1.3.3.1" xref="alg1.l9.m1.1.1.3.3.1.cmml"><mo id="alg1.l9.m1.1.1.3.3.1.2.2" xref="alg1.l9.m1.1.1.3.3.1.2.2.cmml">∑</mo><mrow id="alg1.l9.m1.1.1.3.3.1.2.3" xref="alg1.l9.m1.1.1.3.3.1.2.3.cmml"><mi id="alg1.l9.m1.1.1.3.3.1.2.3.2" xref="alg1.l9.m1.1.1.3.3.1.2.3.2.cmml">i</mi><mo id="alg1.l9.m1.1.1.3.3.1.2.3.1" xref="alg1.l9.m1.1.1.3.3.1.2.3.1.cmml">=</mo><mn id="alg1.l9.m1.1.1.3.3.1.2.3.3" xref="alg1.l9.m1.1.1.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="alg1.l9.m1.1.1.3.3.1.3" xref="alg1.l9.m1.1.1.3.3.1.3.cmml">N</mi></msubsup><mrow id="alg1.l9.m1.1.1.3.3.2" xref="alg1.l9.m1.1.1.3.3.2.cmml"><msub id="alg1.l9.m1.1.1.3.3.2.2" xref="alg1.l9.m1.1.1.3.3.2.2.cmml"><mi id="alg1.l9.m1.1.1.3.3.2.2.2" xref="alg1.l9.m1.1.1.3.3.2.2.2.cmml">n</mi><mi id="alg1.l9.m1.1.1.3.3.2.2.3" xref="alg1.l9.m1.1.1.3.3.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="alg1.l9.m1.1.1.3.3.2.1" xref="alg1.l9.m1.1.1.3.3.2.1.cmml">​</mo><msubsup id="alg1.l9.m1.1.1.3.3.2.3" xref="alg1.l9.m1.1.1.3.3.2.3.cmml"><mi id="alg1.l9.m1.1.1.3.3.2.3.2.2" xref="alg1.l9.m1.1.1.3.3.2.3.2.2.cmml">w</mi><mi id="alg1.l9.m1.1.1.3.3.2.3.2.3" xref="alg1.l9.m1.1.1.3.3.2.3.2.3.cmml">i</mi><mi id="alg1.l9.m1.1.1.3.3.2.3.3" xref="alg1.l9.m1.1.1.3.3.2.3.3.cmml">t</mi></msubsup></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.1b"><apply id="alg1.l9.m1.1.1.cmml" xref="alg1.l9.m1.1.1"><ci id="alg1.l9.m1.1.1.1.cmml" xref="alg1.l9.m1.1.1.1">←</ci><apply id="alg1.l9.m1.1.1.2.cmml" xref="alg1.l9.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.2.1.cmml" xref="alg1.l9.m1.1.1.2">superscript</csymbol><ci id="alg1.l9.m1.1.1.2.2.cmml" xref="alg1.l9.m1.1.1.2.2">𝑤</ci><apply id="alg1.l9.m1.1.1.2.3.cmml" xref="alg1.l9.m1.1.1.2.3"><plus id="alg1.l9.m1.1.1.2.3.1.cmml" xref="alg1.l9.m1.1.1.2.3.1"></plus><ci id="alg1.l9.m1.1.1.2.3.2.cmml" xref="alg1.l9.m1.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.l9.m1.1.1.2.3.3.cmml" xref="alg1.l9.m1.1.1.2.3.3">1</cn></apply></apply><apply id="alg1.l9.m1.1.1.3.cmml" xref="alg1.l9.m1.1.1.3"><times id="alg1.l9.m1.1.1.3.1.cmml" xref="alg1.l9.m1.1.1.3.1"></times><apply id="alg1.l9.m1.1.1.3.2.cmml" xref="alg1.l9.m1.1.1.3.2"><divide id="alg1.l9.m1.1.1.3.2.1.cmml" xref="alg1.l9.m1.1.1.3.2"></divide><cn type="integer" id="alg1.l9.m1.1.1.3.2.2.cmml" xref="alg1.l9.m1.1.1.3.2.2">1</cn><apply id="alg1.l9.m1.1.1.3.2.3.cmml" xref="alg1.l9.m1.1.1.3.2.3"><apply id="alg1.l9.m1.1.1.3.2.3.1.cmml" xref="alg1.l9.m1.1.1.3.2.3.1"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.2.3.1.1.cmml" xref="alg1.l9.m1.1.1.3.2.3.1">superscript</csymbol><apply id="alg1.l9.m1.1.1.3.2.3.1.2.cmml" xref="alg1.l9.m1.1.1.3.2.3.1"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.2.3.1.2.1.cmml" xref="alg1.l9.m1.1.1.3.2.3.1">subscript</csymbol><sum id="alg1.l9.m1.1.1.3.2.3.1.2.2.cmml" xref="alg1.l9.m1.1.1.3.2.3.1.2.2"></sum><apply id="alg1.l9.m1.1.1.3.2.3.1.2.3.cmml" xref="alg1.l9.m1.1.1.3.2.3.1.2.3"><eq id="alg1.l9.m1.1.1.3.2.3.1.2.3.1.cmml" xref="alg1.l9.m1.1.1.3.2.3.1.2.3.1"></eq><ci id="alg1.l9.m1.1.1.3.2.3.1.2.3.2.cmml" xref="alg1.l9.m1.1.1.3.2.3.1.2.3.2">𝑖</ci><cn type="integer" id="alg1.l9.m1.1.1.3.2.3.1.2.3.3.cmml" xref="alg1.l9.m1.1.1.3.2.3.1.2.3.3">1</cn></apply></apply><ci id="alg1.l9.m1.1.1.3.2.3.1.3.cmml" xref="alg1.l9.m1.1.1.3.2.3.1.3">𝑁</ci></apply><apply id="alg1.l9.m1.1.1.3.2.3.2.cmml" xref="alg1.l9.m1.1.1.3.2.3.2"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.2.3.2.1.cmml" xref="alg1.l9.m1.1.1.3.2.3.2">subscript</csymbol><ci id="alg1.l9.m1.1.1.3.2.3.2.2.cmml" xref="alg1.l9.m1.1.1.3.2.3.2.2">𝑛</ci><ci id="alg1.l9.m1.1.1.3.2.3.2.3.cmml" xref="alg1.l9.m1.1.1.3.2.3.2.3">𝑖</ci></apply></apply></apply><apply id="alg1.l9.m1.1.1.3.3.cmml" xref="alg1.l9.m1.1.1.3.3"><apply id="alg1.l9.m1.1.1.3.3.1.cmml" xref="alg1.l9.m1.1.1.3.3.1"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.3.1.1.cmml" xref="alg1.l9.m1.1.1.3.3.1">superscript</csymbol><apply id="alg1.l9.m1.1.1.3.3.1.2.cmml" xref="alg1.l9.m1.1.1.3.3.1"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.3.1.2.1.cmml" xref="alg1.l9.m1.1.1.3.3.1">subscript</csymbol><sum id="alg1.l9.m1.1.1.3.3.1.2.2.cmml" xref="alg1.l9.m1.1.1.3.3.1.2.2"></sum><apply id="alg1.l9.m1.1.1.3.3.1.2.3.cmml" xref="alg1.l9.m1.1.1.3.3.1.2.3"><eq id="alg1.l9.m1.1.1.3.3.1.2.3.1.cmml" xref="alg1.l9.m1.1.1.3.3.1.2.3.1"></eq><ci id="alg1.l9.m1.1.1.3.3.1.2.3.2.cmml" xref="alg1.l9.m1.1.1.3.3.1.2.3.2">𝑖</ci><cn type="integer" id="alg1.l9.m1.1.1.3.3.1.2.3.3.cmml" xref="alg1.l9.m1.1.1.3.3.1.2.3.3">1</cn></apply></apply><ci id="alg1.l9.m1.1.1.3.3.1.3.cmml" xref="alg1.l9.m1.1.1.3.3.1.3">𝑁</ci></apply><apply id="alg1.l9.m1.1.1.3.3.2.cmml" xref="alg1.l9.m1.1.1.3.3.2"><times id="alg1.l9.m1.1.1.3.3.2.1.cmml" xref="alg1.l9.m1.1.1.3.3.2.1"></times><apply id="alg1.l9.m1.1.1.3.3.2.2.cmml" xref="alg1.l9.m1.1.1.3.3.2.2"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.3.2.2.1.cmml" xref="alg1.l9.m1.1.1.3.3.2.2">subscript</csymbol><ci id="alg1.l9.m1.1.1.3.3.2.2.2.cmml" xref="alg1.l9.m1.1.1.3.3.2.2.2">𝑛</ci><ci id="alg1.l9.m1.1.1.3.3.2.2.3.cmml" xref="alg1.l9.m1.1.1.3.3.2.2.3">𝑖</ci></apply><apply id="alg1.l9.m1.1.1.3.3.2.3.cmml" xref="alg1.l9.m1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.3.2.3.1.cmml" xref="alg1.l9.m1.1.1.3.3.2.3">superscript</csymbol><apply id="alg1.l9.m1.1.1.3.3.2.3.2.cmml" xref="alg1.l9.m1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.3.2.3.2.1.cmml" xref="alg1.l9.m1.1.1.3.3.2.3">subscript</csymbol><ci id="alg1.l9.m1.1.1.3.3.2.3.2.2.cmml" xref="alg1.l9.m1.1.1.3.3.2.3.2.2">𝑤</ci><ci id="alg1.l9.m1.1.1.3.3.2.3.2.3.cmml" xref="alg1.l9.m1.1.1.3.3.2.3.2.3">𝑖</ci></apply><ci id="alg1.l9.m1.1.1.3.3.2.3.3.cmml" xref="alg1.l9.m1.1.1.3.3.2.3.3">𝑡</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.1c">w^{t+1}\leftarrow\frac{1}{\sum_{i=1}^{N}n_{i}}\sum_{i=1}^{N}n_{i}w_{i}^{t}</annotation></semantics></math>

</div>
<div id="alg1.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l10.1.1.1" class="ltx_text" style="font-size:80%;">10:</span></span>  <span id="alg1.l10.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l10.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l11.1.1.1" class="ltx_text" style="font-size:80%;">11:</span></span>  return: <math id="alg1.l11.m1.1" class="ltx_Math" alttext="w^{T}" display="inline"><semantics id="alg1.l11.m1.1a"><msup id="alg1.l11.m1.1.1" xref="alg1.l11.m1.1.1.cmml"><mi id="alg1.l11.m1.1.1.2" xref="alg1.l11.m1.1.1.2.cmml">w</mi><mi id="alg1.l11.m1.1.1.3" xref="alg1.l11.m1.1.1.3.cmml">T</mi></msup><annotation-xml encoding="MathML-Content" id="alg1.l11.m1.1b"><apply id="alg1.l11.m1.1.1.cmml" xref="alg1.l11.m1.1.1"><csymbol cd="ambiguous" id="alg1.l11.m1.1.1.1.cmml" xref="alg1.l11.m1.1.1">superscript</csymbol><ci id="alg1.l11.m1.1.1.2.cmml" xref="alg1.l11.m1.1.1.2">𝑤</ci><ci id="alg1.l11.m1.1.1.3.cmml" xref="alg1.l11.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m1.1c">w^{T}</annotation></semantics></math>

</div>
<div id="alg1.l12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l12.1.1.1" class="ltx_text" style="font-size:80%;">12:</span></span>  
</div>
<div id="alg1.l13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l13.1.1.1" class="ltx_text" style="font-size:80%;">13:</span></span>  <span id="alg1.l13.2" class="ltx_text ltx_font_bold">ClientTraining</span>(<math id="alg1.l13.m1.1" class="ltx_Math" alttext="w_{i}" display="inline"><semantics id="alg1.l13.m1.1a"><msub id="alg1.l13.m1.1.1" xref="alg1.l13.m1.1.1.cmml"><mi id="alg1.l13.m1.1.1.2" xref="alg1.l13.m1.1.1.2.cmml">w</mi><mi id="alg1.l13.m1.1.1.3" xref="alg1.l13.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l13.m1.1b"><apply id="alg1.l13.m1.1.1.cmml" xref="alg1.l13.m1.1.1"><csymbol cd="ambiguous" id="alg1.l13.m1.1.1.1.cmml" xref="alg1.l13.m1.1.1">subscript</csymbol><ci id="alg1.l13.m1.1.1.2.cmml" xref="alg1.l13.m1.1.1.2">𝑤</ci><ci id="alg1.l13.m1.1.1.3.cmml" xref="alg1.l13.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l13.m1.1c">w_{i}</annotation></semantics></math>, <math id="alg1.l13.m2.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="alg1.l13.m2.1a"><msub id="alg1.l13.m2.1.1" xref="alg1.l13.m2.1.1.cmml"><mi id="alg1.l13.m2.1.1.2" xref="alg1.l13.m2.1.1.2.cmml">D</mi><mi id="alg1.l13.m2.1.1.3" xref="alg1.l13.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l13.m2.1b"><apply id="alg1.l13.m2.1.1.cmml" xref="alg1.l13.m2.1.1"><csymbol cd="ambiguous" id="alg1.l13.m2.1.1.1.cmml" xref="alg1.l13.m2.1.1">subscript</csymbol><ci id="alg1.l13.m2.1.1.2.cmml" xref="alg1.l13.m2.1.1.2">𝐷</ci><ci id="alg1.l13.m2.1.1.3.cmml" xref="alg1.l13.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l13.m2.1c">D_{i}</annotation></semantics></math>)<span id="alg1.l13.3" class="ltx_text ltx_font_bold">:</span> // Run on client <math id="alg1.l13.m3.1" class="ltx_Math" alttext="C_{i}" display="inline"><semantics id="alg1.l13.m3.1a"><msub id="alg1.l13.m3.1.1" xref="alg1.l13.m3.1.1.cmml"><mi id="alg1.l13.m3.1.1.2" xref="alg1.l13.m3.1.1.2.cmml">C</mi><mi id="alg1.l13.m3.1.1.3" xref="alg1.l13.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l13.m3.1b"><apply id="alg1.l13.m3.1.1.cmml" xref="alg1.l13.m3.1.1"><csymbol cd="ambiguous" id="alg1.l13.m3.1.1.1.cmml" xref="alg1.l13.m3.1.1">subscript</csymbol><ci id="alg1.l13.m3.1.1.2.cmml" xref="alg1.l13.m3.1.1.2">𝐶</ci><ci id="alg1.l13.m3.1.1.3.cmml" xref="alg1.l13.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l13.m3.1c">C_{i}</annotation></semantics></math>

</div>
<div id="alg1.l14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l14.1.1.1" class="ltx_text" style="font-size:80%;">14:</span></span>  <span id="alg1.l14.2" class="ltx_text ltx_font_bold">for</span> each epoch <math id="alg1.l14.m1.5" class="ltx_Math" alttext="e=1,2,3,\dots,E" display="inline"><semantics id="alg1.l14.m1.5a"><mrow id="alg1.l14.m1.5.6" xref="alg1.l14.m1.5.6.cmml"><mi id="alg1.l14.m1.5.6.2" xref="alg1.l14.m1.5.6.2.cmml">e</mi><mo id="alg1.l14.m1.5.6.1" xref="alg1.l14.m1.5.6.1.cmml">=</mo><mrow id="alg1.l14.m1.5.6.3.2" xref="alg1.l14.m1.5.6.3.1.cmml"><mn id="alg1.l14.m1.1.1" xref="alg1.l14.m1.1.1.cmml">1</mn><mo id="alg1.l14.m1.5.6.3.2.1" xref="alg1.l14.m1.5.6.3.1.cmml">,</mo><mn id="alg1.l14.m1.2.2" xref="alg1.l14.m1.2.2.cmml">2</mn><mo id="alg1.l14.m1.5.6.3.2.2" xref="alg1.l14.m1.5.6.3.1.cmml">,</mo><mn id="alg1.l14.m1.3.3" xref="alg1.l14.m1.3.3.cmml">3</mn><mo id="alg1.l14.m1.5.6.3.2.3" xref="alg1.l14.m1.5.6.3.1.cmml">,</mo><mi mathvariant="normal" id="alg1.l14.m1.4.4" xref="alg1.l14.m1.4.4.cmml">…</mi><mo id="alg1.l14.m1.5.6.3.2.4" xref="alg1.l14.m1.5.6.3.1.cmml">,</mo><mi id="alg1.l14.m1.5.5" xref="alg1.l14.m1.5.5.cmml">E</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l14.m1.5b"><apply id="alg1.l14.m1.5.6.cmml" xref="alg1.l14.m1.5.6"><eq id="alg1.l14.m1.5.6.1.cmml" xref="alg1.l14.m1.5.6.1"></eq><ci id="alg1.l14.m1.5.6.2.cmml" xref="alg1.l14.m1.5.6.2">𝑒</ci><list id="alg1.l14.m1.5.6.3.1.cmml" xref="alg1.l14.m1.5.6.3.2"><cn type="integer" id="alg1.l14.m1.1.1.cmml" xref="alg1.l14.m1.1.1">1</cn><cn type="integer" id="alg1.l14.m1.2.2.cmml" xref="alg1.l14.m1.2.2">2</cn><cn type="integer" id="alg1.l14.m1.3.3.cmml" xref="alg1.l14.m1.3.3">3</cn><ci id="alg1.l14.m1.4.4.cmml" xref="alg1.l14.m1.4.4">…</ci><ci id="alg1.l14.m1.5.5.cmml" xref="alg1.l14.m1.5.5">𝐸</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m1.5c">e=1,2,3,\dots,E</annotation></semantics></math> <span id="alg1.l14.3" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l15.1.1.1" class="ltx_text" style="font-size:80%;">15:</span></span>     <math id="alg1.l15.m1.2" class="ltx_Math" alttext="w_{i}\leftarrow w_{i}-\eta\nabla l(w_{i};D_{i})" display="inline"><semantics id="alg1.l15.m1.2a"><mrow id="alg1.l15.m1.2.2" xref="alg1.l15.m1.2.2.cmml"><msub id="alg1.l15.m1.2.2.4" xref="alg1.l15.m1.2.2.4.cmml"><mi id="alg1.l15.m1.2.2.4.2" xref="alg1.l15.m1.2.2.4.2.cmml">w</mi><mi id="alg1.l15.m1.2.2.4.3" xref="alg1.l15.m1.2.2.4.3.cmml">i</mi></msub><mo stretchy="false" id="alg1.l15.m1.2.2.3" xref="alg1.l15.m1.2.2.3.cmml">←</mo><mrow id="alg1.l15.m1.2.2.2" xref="alg1.l15.m1.2.2.2.cmml"><msub id="alg1.l15.m1.2.2.2.4" xref="alg1.l15.m1.2.2.2.4.cmml"><mi id="alg1.l15.m1.2.2.2.4.2" xref="alg1.l15.m1.2.2.2.4.2.cmml">w</mi><mi id="alg1.l15.m1.2.2.2.4.3" xref="alg1.l15.m1.2.2.2.4.3.cmml">i</mi></msub><mo id="alg1.l15.m1.2.2.2.3" xref="alg1.l15.m1.2.2.2.3.cmml">−</mo><mrow id="alg1.l15.m1.2.2.2.2" xref="alg1.l15.m1.2.2.2.2.cmml"><mi id="alg1.l15.m1.2.2.2.2.4" xref="alg1.l15.m1.2.2.2.2.4.cmml">η</mi><mo lspace="0.167em" rspace="0em" id="alg1.l15.m1.2.2.2.2.3" xref="alg1.l15.m1.2.2.2.2.3.cmml">​</mo><mrow id="alg1.l15.m1.2.2.2.2.5" xref="alg1.l15.m1.2.2.2.2.5.cmml"><mo rspace="0.167em" id="alg1.l15.m1.2.2.2.2.5.1" xref="alg1.l15.m1.2.2.2.2.5.1.cmml">∇</mo><mi id="alg1.l15.m1.2.2.2.2.5.2" xref="alg1.l15.m1.2.2.2.2.5.2.cmml">l</mi></mrow><mo lspace="0em" rspace="0em" id="alg1.l15.m1.2.2.2.2.3a" xref="alg1.l15.m1.2.2.2.2.3.cmml">​</mo><mrow id="alg1.l15.m1.2.2.2.2.2.2" xref="alg1.l15.m1.2.2.2.2.2.3.cmml"><mo stretchy="false" id="alg1.l15.m1.2.2.2.2.2.2.3" xref="alg1.l15.m1.2.2.2.2.2.3.cmml">(</mo><msub id="alg1.l15.m1.1.1.1.1.1.1.1" xref="alg1.l15.m1.1.1.1.1.1.1.1.cmml"><mi id="alg1.l15.m1.1.1.1.1.1.1.1.2" xref="alg1.l15.m1.1.1.1.1.1.1.1.2.cmml">w</mi><mi id="alg1.l15.m1.1.1.1.1.1.1.1.3" xref="alg1.l15.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="alg1.l15.m1.2.2.2.2.2.2.4" xref="alg1.l15.m1.2.2.2.2.2.3.cmml">;</mo><msub id="alg1.l15.m1.2.2.2.2.2.2.2" xref="alg1.l15.m1.2.2.2.2.2.2.2.cmml"><mi id="alg1.l15.m1.2.2.2.2.2.2.2.2" xref="alg1.l15.m1.2.2.2.2.2.2.2.2.cmml">D</mi><mi id="alg1.l15.m1.2.2.2.2.2.2.2.3" xref="alg1.l15.m1.2.2.2.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="alg1.l15.m1.2.2.2.2.2.2.5" xref="alg1.l15.m1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l15.m1.2b"><apply id="alg1.l15.m1.2.2.cmml" xref="alg1.l15.m1.2.2"><ci id="alg1.l15.m1.2.2.3.cmml" xref="alg1.l15.m1.2.2.3">←</ci><apply id="alg1.l15.m1.2.2.4.cmml" xref="alg1.l15.m1.2.2.4"><csymbol cd="ambiguous" id="alg1.l15.m1.2.2.4.1.cmml" xref="alg1.l15.m1.2.2.4">subscript</csymbol><ci id="alg1.l15.m1.2.2.4.2.cmml" xref="alg1.l15.m1.2.2.4.2">𝑤</ci><ci id="alg1.l15.m1.2.2.4.3.cmml" xref="alg1.l15.m1.2.2.4.3">𝑖</ci></apply><apply id="alg1.l15.m1.2.2.2.cmml" xref="alg1.l15.m1.2.2.2"><minus id="alg1.l15.m1.2.2.2.3.cmml" xref="alg1.l15.m1.2.2.2.3"></minus><apply id="alg1.l15.m1.2.2.2.4.cmml" xref="alg1.l15.m1.2.2.2.4"><csymbol cd="ambiguous" id="alg1.l15.m1.2.2.2.4.1.cmml" xref="alg1.l15.m1.2.2.2.4">subscript</csymbol><ci id="alg1.l15.m1.2.2.2.4.2.cmml" xref="alg1.l15.m1.2.2.2.4.2">𝑤</ci><ci id="alg1.l15.m1.2.2.2.4.3.cmml" xref="alg1.l15.m1.2.2.2.4.3">𝑖</ci></apply><apply id="alg1.l15.m1.2.2.2.2.cmml" xref="alg1.l15.m1.2.2.2.2"><times id="alg1.l15.m1.2.2.2.2.3.cmml" xref="alg1.l15.m1.2.2.2.2.3"></times><ci id="alg1.l15.m1.2.2.2.2.4.cmml" xref="alg1.l15.m1.2.2.2.2.4">𝜂</ci><apply id="alg1.l15.m1.2.2.2.2.5.cmml" xref="alg1.l15.m1.2.2.2.2.5"><ci id="alg1.l15.m1.2.2.2.2.5.1.cmml" xref="alg1.l15.m1.2.2.2.2.5.1">∇</ci><ci id="alg1.l15.m1.2.2.2.2.5.2.cmml" xref="alg1.l15.m1.2.2.2.2.5.2">𝑙</ci></apply><list id="alg1.l15.m1.2.2.2.2.2.3.cmml" xref="alg1.l15.m1.2.2.2.2.2.2"><apply id="alg1.l15.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l15.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l15.m1.1.1.1.1.1.1.1.1.cmml" xref="alg1.l15.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l15.m1.1.1.1.1.1.1.1.2.cmml" xref="alg1.l15.m1.1.1.1.1.1.1.1.2">𝑤</ci><ci id="alg1.l15.m1.1.1.1.1.1.1.1.3.cmml" xref="alg1.l15.m1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="alg1.l15.m1.2.2.2.2.2.2.2.cmml" xref="alg1.l15.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l15.m1.2.2.2.2.2.2.2.1.cmml" xref="alg1.l15.m1.2.2.2.2.2.2.2">subscript</csymbol><ci id="alg1.l15.m1.2.2.2.2.2.2.2.2.cmml" xref="alg1.l15.m1.2.2.2.2.2.2.2.2">𝐷</ci><ci id="alg1.l15.m1.2.2.2.2.2.2.2.3.cmml" xref="alg1.l15.m1.2.2.2.2.2.2.2.3">𝑖</ci></apply></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l15.m1.2c">w_{i}\leftarrow w_{i}-\eta\nabla l(w_{i};D_{i})</annotation></semantics></math>

</div>
<div id="alg1.l16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l16.1.1.1" class="ltx_text" style="font-size:80%;">16:</span></span>  <span id="alg1.l16.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l16.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l17.1.1.1" class="ltx_text" style="font-size:80%;">17:</span></span>  return: <math id="alg1.l17.m1.1" class="ltx_Math" alttext="w_{i}" display="inline"><semantics id="alg1.l17.m1.1a"><msub id="alg1.l17.m1.1.1" xref="alg1.l17.m1.1.1.cmml"><mi id="alg1.l17.m1.1.1.2" xref="alg1.l17.m1.1.1.2.cmml">w</mi><mi id="alg1.l17.m1.1.1.3" xref="alg1.l17.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l17.m1.1b"><apply id="alg1.l17.m1.1.1.cmml" xref="alg1.l17.m1.1.1"><csymbol cd="ambiguous" id="alg1.l17.m1.1.1.1.cmml" xref="alg1.l17.m1.1.1">subscript</csymbol><ci id="alg1.l17.m1.1.1.2.cmml" xref="alg1.l17.m1.1.1.2">𝑤</ci><ci id="alg1.l17.m1.1.1.3.cmml" xref="alg1.l17.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l17.m1.1c">w_{i}</annotation></semantics></math>

</div>
</div>
</figure>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.5.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.6.2" class="ltx_text ltx_font_italic">Related Works</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Several available theoretical surveys and simulation-based empirical studies on FL are available in the literature. Dinh et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> explore and analyze the potential of FL for enabling a wide range of IoT services, including IoT data sharing, data offloading and caching, attack detection, localization, mobile crowdsensing, and IoT privacy and security. Ahmed et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> discuss the implementation challenges and issues when applying FL to an IoT environment. Zhu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> provides a detailed analysis of the influence of Non-IID data on different types of ML models in both horizontal and vertical FL. Li et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> conduct extensive experiments to evaluate state-of-the-art FL algorithms on Non-IID data silos and find that Non-IID does bring significant challenges in learning accuracy of FL algorithms, and none of the existing state-of-the-art FL algorithms outperforms others in all cases. Recently, Matsuda et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> benchmark the performance of existing personalized FL through comprehensive experiments to evaluate the characteristics of each method and find that there are no champion methods. Caldas et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> propose LEAF, a modular benchmarking simulation-based framework for learning in federated settings. LEAF includes a suite of open-source federated datasets, a rigorous evaluation framework, and a set of reference implementations. To the best of our knowledge, we are the first ones that consider an empirical study of FL on IoT-Edge devices.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">For real-world FL implementation, Di et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> present FedAdapt, an adaptive offloading FL framework based on reinforcement learning and clustering to identify which layers of the DNN should be offloaded for each device onto a server. Experiments are carried out on a lab-based testbed, including two Pi3s, two Pi4s, and one Jetson Xavier. Sun et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> propose a model selection and adaptation system for FL (FedMSA), which includes a hardware-aware model selection algorithm, then demonstrate the effectiveness of their method on a network of two Pi4s and five Nanos. Mills et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> propose adapting FedAvg to use a distributed form of Adam optimization, then test their method on a small testbed of five Pi2s and five Pi3s. Furthermore, Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> build the FedIoT platform for on-device anomaly data detection and evaluate their platform on a network of ten Pi4s. However, these attempts are still on a small scale and do not represent real-world environments.</p>
</div>
<figure id="S2.T1" class="ltx_table">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Comparison between our work and others. </figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S2.T1.1" class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T1.1.1.1" class="ltx_tr">
<th id="S2.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;" rowspan="2"><span id="S2.T1.1.1.1.1.1" class="ltx_text">
<span id="S2.T1.1.1.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.1.1.1.1.1" class="ltx_tr">
<span id="S2.T1.1.1.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 3.7pt;">Empirical</span></span>
<span id="S2.T1.1.1.1.1.1.1.2" class="ltx_tr">
<span id="S2.T1.1.1.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 3.7pt;">Studies</span></span>
</span></span></th>
<th id="S2.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;" rowspan="2"><span id="S2.T1.1.1.1.2.1" class="ltx_text">
<span id="S2.T1.1.1.1.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.1.2.1.1.1" class="ltx_tr">
<span id="S2.T1.1.1.1.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 3.7pt;">Simulation</span></span>
<span id="S2.T1.1.1.1.2.1.1.2" class="ltx_tr">
<span id="S2.T1.1.1.1.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 3.7pt;">-based</span></span>
</span></span></th>
<td id="S2.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;" colspan="3">Device-based</td>
</tr>
<tr id="S2.T1.1.2.2" class="ltx_tr">
<td id="S2.T1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;">
<table id="S2.T1.1.2.2.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.2.2.1.1.1" class="ltx_tr">
<td id="S2.T1.1.2.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 3.7pt;">Small-scale</td>
</tr>
<tr id="S2.T1.1.2.2.1.1.2" class="ltx_tr">
<td id="S2.T1.1.2.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 3.7pt;">(up to 10)</td>
</tr>
</table>
</td>
<td id="S2.T1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;">
<table id="S2.T1.1.2.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.2.2.2.1.1" class="ltx_tr">
<td id="S2.T1.1.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 3.7pt;">Large-scale</td>
</tr>
<tr id="S2.T1.1.2.2.2.1.2" class="ltx_tr">
<td id="S2.T1.1.2.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 3.7pt;">(up to 64)</td>
</tr>
</table>
</td>
<td id="S2.T1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;">
<table id="S2.T1.1.2.2.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.2.2.3.1.1" class="ltx_tr">
<td id="S2.T1.1.2.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 3.7pt;">Device</td>
</tr>
<tr id="S2.T1.1.2.2.3.1.2" class="ltx_tr">
<td id="S2.T1.1.2.2.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 3.7pt;">Heter.<sup id="S2.T1.1.2.2.3.1.2.1.1" class="ltx_sup">*</sup>
</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T1.1.3.3" class="ltx_tr">
<th id="S2.T1.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite></th>
<th id="S2.T1.1.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;">✓</th>
<td id="S2.T1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;">✗</td>
<td id="S2.T1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;">✗</td>
<td id="S2.T1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;">✗</td>
</tr>
<tr id="S2.T1.1.4.4" class="ltx_tr">
<th id="S2.T1.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite></th>
<th id="S2.T1.1.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;">✓</th>
<td id="S2.T1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;">✓</td>
<td id="S2.T1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;">✗</td>
<td id="S2.T1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;">✗</td>
</tr>
<tr id="S2.T1.1.5.5" class="ltx_tr">
<th id="S2.T1.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;">Ours</th>
<th id="S2.T1.1.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;">✓</th>
<td id="S2.T1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;">✓</td>
<td id="S2.T1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;">✓</td>
<td id="S2.T1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 3.7pt;">✓</td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul id="S2.I2" class="ltx_itemize ltx_figure_panel">
<li id="S2.I2.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">*</span> 
<div id="S2.I2.ix1.p1" class="ltx_para">
<p id="S2.I2.ix1.p1.1" class="ltx_p">Device Heterogeneity: Study of different types of IoT devices</p>
</div>
</li>
</ul>
</div>
<div class="ltx_flex_break"></div>
</div>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Experimental Design</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">This section describes how we designed our experiments to answer our research questions in Section <a href="#S1.SS1" title="I-A Objectives, Research Questions and Scope ‣ I Introduction ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">I-A</span></span></a>. Starting with data preparation, we then implement FL on IoT-Edge devices with different settings based on the evaluation factors we defined. After that, we use a bag of metrics to analyze the impact of these factors individually and their combined effects in different aspects. Fig. <a href="#S3.F2" title="Figure 2 ‣ III Experimental Design ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates this workflow in detail.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2305.19831/assets/figs/metho2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="142" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Our Methodology. </figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Data Preparation and Models</span>
</h3>

<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS1.5.1.1" class="ltx_text">III-A</span>1 </span>Datasets</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p">We use two datasets in this work : CIFAR10 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> and CIFAR100 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, which are commonly used in previous studies on FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. CIFAR10 consists of 60000 32x32 color images and is the simple one. The images are labeled with one of 10 exclusive classes. There are 6000 images per class with 5000 training and 1000 testing images. CIFAR100 also consists of 60000 32x32 color images and is more challenging to train, however, each image comes with one of 100 fine-grained labels. There are 600 images per class with 500 training and 100 testing images.</p>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS2.5.1.1" class="ltx_text">III-A</span>2 </span>Data Partitioning</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">The CIFAR10 and CIFAR100 datasets are not separated for FL originally, we need to divide these two datasets synthetically. While the test sets are kept at the server for testing the aggregated model, we divide the training set of each dataset into 64 disjoint partitions with an equal number of samples in three different ways to simulate three scenarios of heterogeneity that are IID, Non-IID, and Extreme Non-IID (ExNon-IID). The IID strategy adapts independent and random division, as shown in Fig. <a href="#S3.F3" title="Figure 3 ‣ III-A2 Data Partitioning ‣ III-A Data Preparation and Models ‣ III Experimental Design ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>(a) and <a href="#S3.F3" title="Figure 3 ‣ III-A2 Data Partitioning ‣ III-A Data Preparation and Models ‣ III Experimental Design ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>(b), the data distribution in each client is basically the same. The Non-IID and ExNon-IID strategies use biased divisions proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. Specifically, the whole dataset is sorted according to the labels and divided into different chunks, then these chunks are randomly assigned to different clients. The number of chunks affects the degree of heterogeneity across clients. As shown in Fig. <a href="#S3.F3" title="Figure 3 ‣ III-A2 Data Partitioning ‣ III-A Data Preparation and Models ‣ III Experimental Design ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>(c)-(f), while each client in Non-IID contains approximately four and ten data classes in CIFAR10 and CIFAR100, respectively, each client in ExNon-IID contains only one and two data classes in CIFAR10 and CIFAR100 respectively, which simulates the extreme data heterogeneity across clients.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2305.19831/assets/figs/cifar.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="592" height="373" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Data distribution of the first 24 clients in the CIFAR10 and CIFAR100 datasets. </figcaption>
</figure>
</section>
<section id="S3.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS3.5.1.1" class="ltx_text">III-A</span>3 </span>Model Architecture</h4>

<div id="S3.SS1.SSS3.p1" class="ltx_para">
<p id="S3.SS1.SSS3.p1.1" class="ltx_p">Following previous works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, we study a popular CNN model designed for image classification tasks, called CNN3 on the two datasets. The model only includes two 5x5 convolution layers (the first with 32 channels, the second with 64), each followed by a ReLU activation function and a 2x2 max pooling. After that, one fully connected layer with 512 units and ReLu activation is added, followed by a softmax layer as a classifier. The number of output units is 10 for CIFAR10 and 100 for CIFAR100. By its simple architecture, the model does not need massive resources for training, making it suitable for deployment on IoT-Edge devices.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Hardware and Software Specifications</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">In the past few years, many IoT-Edge devices have entered the market with different prices and abilities. In this work, we use the most popular ones such as Pi3, Pi4, Nano, and TX2. Different types of devices with different generations have different resources and processing capabilities. A diverse pool of devices helps us more accurately represent the real world. Our devices are connected to a workstation, which is used as the server, via a network of IoT-Edge devices and switches. Fig. <a href="#S3.F4" title="Figure 4 ‣ III-B Hardware and Software Specifications ‣ III Experimental Design ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> is a snapshot of our infrastructure. In more detail, Table <a href="#S3.T2" title="TABLE II ‣ III-B Hardware and Software Specifications ‣ III Experimental Design ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> provides specifications of these devices, and the server machine and simulation machine are also described.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">For software specifications, we use the PyTorch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> framework version 1.13.1 to implement deep learning components and use the Flower <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> framework version 1.11.0 FedAvg algorithm. Additionally, we use Docker technology to create a separate container on each device to perform local training.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2305.19831/assets/figs/infras.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="287" height="287" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>IoT-Edge Federated Learning Testbed. </figcaption>
</figure>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Hardware Specifications. </figcaption>
<table id="S3.T2.1" class="ltx_tabular ltx_guessed_headers ltx_align_top">
<tbody class="ltx_tbody">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">Machine</th>
<td id="S3.T2.1.1.1.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">Memory</td>
<td id="S3.T2.1.1.1.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">CPU</td>
<td id="S3.T2.1.1.1.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">GPU</td>
<td id="S3.T2.1.1.1.5" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">Connectivity</td>
</tr>
<tr id="S3.T2.1.2.2" class="ltx_tr">
<th id="S3.T2.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">Pi 3</th>
<td id="S3.T2.1.2.2.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">1GB LPDDR2   900 MHz (32 bit)</td>
<td id="S3.T2.1.2.2.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">4-Core ARM-A53 1.20 GHz</td>
<td id="S3.T2.1.2.2.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">–</td>
<td id="S3.T2.1.2.2.5" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">100 Mbps</td>
</tr>
<tr id="S3.T2.1.3.3" class="ltx_tr">
<th id="S3.T2.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">Pi 4</th>
<td id="S3.T2.1.3.3.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">8GB LPDDR4 3200 MHz (32 bit)</td>
<td id="S3.T2.1.3.3.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">4-Core ARM-A72 1.50 GHz</td>
<td id="S3.T2.1.3.3.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">–</td>
<td id="S3.T2.1.3.3.5" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">1 Gbps</td>
</tr>
<tr id="S3.T2.1.4.4" class="ltx_tr">
<th id="S3.T2.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">Jetson Nano</th>
<td id="S3.T2.1.4.4.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">4GB LPDDR4 1600 MHz (64 bit)</td>
<td id="S3.T2.1.4.4.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">4-Core ARM-A57 1.43 GHz</td>
<td id="S3.T2.1.4.4.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">Maxwell   4GB x1</td>
<td id="S3.T2.1.4.4.5" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">1 Gbps</td>
</tr>
<tr id="S3.T2.1.5.5" class="ltx_tr">
<th id="S3.T2.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">Jetson TX2</th>
<td id="S3.T2.1.5.5.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">8GB LPDDR4 1866 MHz (64 bit)</td>
<td id="S3.T2.1.5.5.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">
<table id="S3.T2.1.5.5.3.1" class="ltx_tabular ltx_align_top">
<tr id="S3.T2.1.5.5.3.1.1" class="ltx_tr">
<td id="S3.T2.1.5.5.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_right" style="padding:0.5pt 7.3pt;">4-Core ARM-A57 2.00 GHz</td>
</tr>
<tr id="S3.T2.1.5.5.3.1.2" class="ltx_tr">
<td id="S3.T2.1.5.5.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_right" style="padding:0.5pt 7.3pt;">&amp; 2-Core    Denver2 2.00 GHz</td>
</tr>
</table>
</td>
<td id="S3.T2.1.5.5.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">Pascal   8GB x1</td>
<td id="S3.T2.1.5.5.5" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">1 Gbps</td>
</tr>
<tr id="S3.T2.1.6.6" class="ltx_tr">
<th id="S3.T2.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">Server</th>
<td id="S3.T2.1.6.6.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">2048GB DDR4 2666 MHz (64 bit)</td>
<td id="S3.T2.1.6.6.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">Intel Xeon Gold 5117 2.00 GHz</td>
<td id="S3.T2.1.6.6.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">Tesla V100 16GB x2</td>
<td id="S3.T2.1.6.6.5" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">1 Gbps</td>
</tr>
<tr id="S3.T2.1.7.7" class="ltx_tr">
<th id="S3.T2.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">Simulation</th>
<td id="S3.T2.1.7.7.2" class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">256GB LPDDR4 2666 MHz (64 bit)</td>
<td id="S3.T2.1.7.7.3" class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">Intel Xeon Gold 6242 2.80 GHz</td>
<td id="S3.T2.1.7.7.4" class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">RTX 3090 24GB x4</td>
<td id="S3.T2.1.7.7.5" class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 7.3pt;">–</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Evaluation Metrics</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In this study, we use a comprehensive set of metrics to characterize and quantify the impact of heterogeneity factors on the behaviors of FL implementation in realistic environments. Specifically, test accuracy and convergence speed are used to evaluate the learning performance. Averaged training time, memory, and GPU/CPU utilization are used to measure computational costs. Finally, we use the averaged model update (local and global) exchange time between the clients and the aggregation server to measure the communication cost. Table <a href="#S3.T3" title="TABLE III ‣ III-C Evaluation Metrics ‣ III Experimental Design ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> provides concise definitions of all our used metrics.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Evaluation Metric Definitions. </figcaption>
<table id="S3.T3.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T3.1.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;" colspan="3">Metrics</td>
<td id="S3.T3.1.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">Unit</td>
<td id="S3.T3.1.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">Definition</td>
</tr>
<tr id="S3.T3.1.2.2" class="ltx_tr">
<td id="S3.T3.1.2.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;" colspan="2" rowspan="2"><span id="S3.T3.1.2.2.1.1" class="ltx_text">Performance</span></td>
<td id="S3.T3.1.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">Test Accuracy</td>
<td id="S3.T3.1.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">Percentage</td>
<td id="S3.T3.1.2.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">Accuracy of the global model on the test set at the server</td>
</tr>
<tr id="S3.T3.1.3.3" class="ltx_tr">
<td id="S3.T3.1.3.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">
<table id="S3.T3.1.3.3.1.1" class="ltx_tabular ltx_align_top">
<tr id="S3.T3.1.3.3.1.1.1" class="ltx_tr">
<td id="S3.T3.1.3.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 2.4pt;">Convergence</td>
</tr>
<tr id="S3.T3.1.3.3.1.1.2" class="ltx_tr">
<td id="S3.T3.1.3.3.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 2.4pt;">Speed</td>
</tr>
</table>
</td>
<td id="S3.T3.1.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">No. Rounds</td>
<td id="S3.T3.1.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">
<table id="S3.T3.1.3.3.3.1" class="ltx_tabular ltx_align_top">
<tr id="S3.T3.1.3.3.3.1.1" class="ltx_tr">
<td id="S3.T3.1.3.3.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 2.4pt;">The number of communication rounds that</td>
</tr>
<tr id="S3.T3.1.3.3.3.1.2" class="ltx_tr">
<td id="S3.T3.1.3.3.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 2.4pt;">the global model needs to converge</td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T3.1.4.4" class="ltx_tr">
<td id="S3.T3.1.4.4.1" class="ltx_td ltx_align_left ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;" rowspan="4"><span id="S3.T3.1.4.4.1.1" class="ltx_text">Cost</span></td>
<td id="S3.T3.1.4.4.2" class="ltx_td ltx_align_left ltx_align_top ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;" rowspan="3"><span id="S3.T3.1.4.4.2.1" class="ltx_text">Computational Cost</span></td>
<td id="S3.T3.1.4.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">
<table id="S3.T3.1.4.4.3.1" class="ltx_tabular ltx_align_top">
<tr id="S3.T3.1.4.4.3.1.1" class="ltx_tr">
<td id="S3.T3.1.4.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 2.4pt;">Avg Training</td>
</tr>
<tr id="S3.T3.1.4.4.3.1.2" class="ltx_tr">
<td id="S3.T3.1.4.4.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 2.4pt;">Time</td>
</tr>
</table>
</td>
<td id="S3.T3.1.4.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">Second</td>
<td id="S3.T3.1.4.4.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">Average local training time per round for all clients</td>
</tr>
<tr id="S3.T3.1.5.5" class="ltx_tr">
<td id="S3.T3.1.5.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">
<table id="S3.T3.1.5.5.1.1" class="ltx_tabular ltx_align_top">
<tr id="S3.T3.1.5.5.1.1.1" class="ltx_tr">
<td id="S3.T3.1.5.5.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 2.4pt;">Avg Memory</td>
</tr>
<tr id="S3.T3.1.5.5.1.1.2" class="ltx_tr">
<td id="S3.T3.1.5.5.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 2.4pt;">Utilization</td>
</tr>
</table>
</td>
<td id="S3.T3.1.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">Percentage</td>
<td id="S3.T3.1.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">Average memory utilization during training for all clients</td>
</tr>
<tr id="S3.T3.1.6.6" class="ltx_tr">
<td id="S3.T3.1.6.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">
<table id="S3.T3.1.6.6.1.1" class="ltx_tabular ltx_align_top">
<tr id="S3.T3.1.6.6.1.1.1" class="ltx_tr">
<td id="S3.T3.1.6.6.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 2.4pt;">Avg GPU/CPU</td>
</tr>
<tr id="S3.T3.1.6.6.1.1.2" class="ltx_tr">
<td id="S3.T3.1.6.6.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 2.4pt;">Utilization</td>
</tr>
</table>
</td>
<td id="S3.T3.1.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">Percentage</td>
<td id="S3.T3.1.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">Average GPU/CPU utilization during training for all clients</td>
</tr>
<tr id="S3.T3.1.7.7" class="ltx_tr">
<td id="S3.T3.1.7.7.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">Communication Cost</td>
<td id="S3.T3.1.7.7.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">
<table id="S3.T3.1.7.7.2.1" class="ltx_tabular ltx_align_top">
<tr id="S3.T3.1.7.7.2.1.1" class="ltx_tr">
<td id="S3.T3.1.7.7.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 2.4pt;">Avg Update Exchange</td>
</tr>
<tr id="S3.T3.1.7.7.2.1.2" class="ltx_tr">
<td id="S3.T3.1.7.7.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 2.4pt;">Time</td>
</tr>
</table>
</td>
<td id="S3.T3.1.7.7.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">Second</td>
<td id="S3.T3.1.7.7.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 2.4pt;">
<table id="S3.T3.1.7.7.4.1" class="ltx_tabular ltx_align_top">
<tr id="S3.T3.1.7.7.4.1.1" class="ltx_tr">
<td id="S3.T3.1.7.7.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 2.4pt;">Averaged time interval per round when</td>
</tr>
<tr id="S3.T3.1.7.7.4.1.2" class="ltx_tr">
<td id="S3.T3.1.7.7.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 2.4pt;">clients send the model to the server until receiving it back</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.5.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.6.2" class="ltx_text ltx_font_italic">Experiments Setup</span>
</h3>

<section id="S3.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS4.SSS1.5.1.1" class="ltx_text">III-D</span>1 </span>Behaviors of On-Device FL Implementation (RQ1)</h4>

<div id="S3.SS4.SSS1.p1" class="ltx_para">
<p id="S3.SS4.SSS1.p1.1" class="ltx_p">First of all, we conduct a baseline experiment on the simulation. Particularly, we simulate eight clients in which each client holds one of the first eight partitions (12.5 % of total partitions) in the CIFAR10 IID dataset. For the training settings, we train a simple CNN3 model described above for 500 communication rounds, at each round, the model is trained for 2 local epochs at the clients, SGD optimizer is used with a learning rate of 0.01, and the batch size is set to 16. To answer the RQ1 described in Section <a href="#S1.SS1" title="I-A Objectives, Research Questions and Scope ‣ I Introduction ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">I-A</span></span></a>, we then turn the simulation environment in the above experiment into realistic environments by sequentially using eight Pi3s, eight Pi4s, and eight Nanos as clients. These devices are connected to a server machine via ethernet connections. For comparison, all training settings are maintained as in the baseline. We use all metrics defined in Table <a href="#S3.T3" title="TABLE III ‣ III-C Evaluation Metrics ‣ III Experimental Design ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> to describe the behaviors of FL implementation. The results and conclusions are shown in Section <a href="#S4.SS1" title="IV-A Behaviors of On-Device FL Implementation (RQ1) ‣ IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span></span></a>.</p>
</div>
</section>
<section id="S3.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS4.SSS2.5.1.1" class="ltx_text">III-D</span>2 </span>Impact of Single Factor (RQ2)</h4>

<div id="S3.SS4.SSS2.p1" class="ltx_para">
<p id="S3.SS4.SSS2.p1.1" class="ltx_p">For the RQ2, we consider two critical factors in FL, namely resource allocation and heterogeneity. Resource allocation includes the number of participating clients and the connection’s communication bandwidth, and heterogeneity includes device heterogeneity and data heterogeneity (statistical heterogeneity). To explore the impact of these factors, we conduct extensive experiments that are shown in detail in Fig. <a href="#S3.F5" title="Figure 5 ‣ III-D2 Impact of Single Factor (RQ2) ‣ III-D Experiments Setup ‣ III Experimental Design ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. Training settings are the same as in the baseline experiment in RQ1. By conducting experiments defined in Fig. <a href="#S3.F5" title="Figure 5 ‣ III-D2 Impact of Single Factor (RQ2) ‣ III-D Experiments Setup ‣ III Experimental Design ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we can observe what happens when the number of participating clients increases, the communication bandwidth is saturated, and when intrinsic heterogeneity is introduced across clients. The results and conclusions for RQ2 experiments are provided in Section <a href="#S4.SS2" title="IV-B Impact of Single Factor On FL Implementation (RQ2) ‣ IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-B</span></span></a>.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2305.19831/assets/figs/Exps-rq2.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="228" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Experiments Setup for Studying the Impact of Single Factor (RQ2). </figcaption>
</figure>
</section>
<section id="S3.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS4.SSS3.5.1.1" class="ltx_text">III-D</span>3 </span>Impact of Combined Factors (RQ3)</h4>

<div id="S3.SS4.SSS3.p1" class="ltx_para">
<p id="S3.SS4.SSS3.p1.1" class="ltx_p">After observing the impact of resource allocation and heterogeneity individually by addressing RQ2, we aim to explore more realistic scenarios where these two factors appear simultaneously. First, we vary the number of participating clients and increase the degree of heterogeneity in client devices concurrently. Second, we still vary the number of participating clients in different data heterogeneity settings (IID, Non-IID, and ExNon-IID) to observe the accuracy and convergence speed. Fig. <a href="#S3.F6" title="Figure 6 ‣ III-D3 Impact of Combined Factors (RQ3) ‣ III-D Experiments Setup ‣ III Experimental Design ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows these experiments in detail. Additionally, training settings are the same as in the baseline experiment in RQ1. By conducting these experiments, we expect to gain more valuable insights beyond those gained from the RQ2. Also, we aim to figure out the dominant factors towards the behaviors of FL in real-device deployment. The results and conclusions for RQ3 experiments are provided in Section <a href="#S4.SS3" title="IV-C Impact of Combined Factors On FL Implementation (RQ3) ‣ IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-C</span></span></a>.</p>
</div>
<figure id="S3.F6" class="ltx_figure"><img src="/html/2305.19831/assets/figs/Exps-rq3.png" id="S3.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="450" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Experiments Setup for Studying the Impact of Combined Factors (RQ3). </figcaption>
</figure>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experimental Results</span>
</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Behaviors of On-Device FL Implementation (RQ1)</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Table <a href="#S4.T4" title="TABLE IV ‣ IV-A Behaviors of On-Device FL Implementation (RQ1) ‣ IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> provides detailed results of experiments in RQ1 where we compare real-device FL implementations to the baseline of simulation. Details of the experimental setup are described in <a href="#S3.SS4.SSS1" title="III-D1 Behaviors of On-Device FL Implementation (RQ1) ‣ III-D Experiments Setup ‣ III Experimental Design ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-D</span>1</span></a>. All four experiments use the same eight partitions of the CIFAR10 IID dataset and the same training details, it is reasonable that test accuracy and convergence speed in these experiments are consistent. In terms of computational cost, training time exponentially increases when we change the devices from TX2 and Nano to Pi4, then Pi3. From resource utilization, Pi3 devices seem to be overloaded when training a small model like CNN3, while Nano devices can handle the task easier due to the support of GPU. Additionally, update exchange time roughly doubles when we change the devices from Nano to Pi4, then Pi3. These observations raise a need for more efficient FL frameworks which are suitable for low-end devices like Pi3, and even for weaker, lower-cost IoT devices or sensors which were introduced more and more with extremely limited computational capacity.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>Behaviors of On-Device FL Implementation (RQ1). </figcaption>
<table id="S4.T4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.1.1.1" class="ltx_tr">
<th id="S4.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;" rowspan="3"><span id="S4.T4.1.1.1.1.1" class="ltx_text">Hardware</span></th>
<th id="S4.T4.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;" colspan="2" rowspan="2"><span id="S4.T4.1.1.1.2.1" class="ltx_text">Performance</span></th>
<th id="S4.T4.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;" colspan="4">Operation Cost</th>
</tr>
<tr id="S4.T4.1.2.2" class="ltx_tr">
<th id="S4.T4.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;" colspan="3">Computational Cost</th>
<th id="S4.T4.1.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">Communication Cost</th>
</tr>
<tr id="S4.T4.1.3.3" class="ltx_tr">
<th id="S4.T4.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">Test Accuracy</th>
<th id="S4.T4.1.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">
<table id="S4.T4.1.3.3.2.1" class="ltx_tabular ltx_align_top">
<tr id="S4.T4.1.3.3.2.1.1" class="ltx_tr">
<td id="S4.T4.1.3.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 4.4pt;">Convergence</td>
</tr>
<tr id="S4.T4.1.3.3.2.1.2" class="ltx_tr">
<td id="S4.T4.1.3.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 4.4pt;">Speed (no. rounds)</td>
</tr>
</table>
</th>
<th id="S4.T4.1.3.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">
<table id="S4.T4.1.3.3.3.1" class="ltx_tabular ltx_align_top">
<tr id="S4.T4.1.3.3.3.1.1" class="ltx_tr">
<td id="S4.T4.1.3.3.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 4.4pt;">Avg Training</td>
</tr>
<tr id="S4.T4.1.3.3.3.1.2" class="ltx_tr">
<td id="S4.T4.1.3.3.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 4.4pt;">Time (s)</td>
</tr>
</table>
</th>
<th id="S4.T4.1.3.3.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">
<table id="S4.T4.1.3.3.4.1" class="ltx_tabular ltx_align_top">
<tr id="S4.T4.1.3.3.4.1.1" class="ltx_tr">
<td id="S4.T4.1.3.3.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 4.4pt;">Avg Memory</td>
</tr>
<tr id="S4.T4.1.3.3.4.1.2" class="ltx_tr">
<td id="S4.T4.1.3.3.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 4.4pt;">Utilization (%)</td>
</tr>
</table>
</th>
<th id="S4.T4.1.3.3.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">
<table id="S4.T4.1.3.3.5.1" class="ltx_tabular ltx_align_top">
<tr id="S4.T4.1.3.3.5.1.1" class="ltx_tr">
<td id="S4.T4.1.3.3.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 4.4pt;">Avg GPU/CPU</td>
</tr>
<tr id="S4.T4.1.3.3.5.1.2" class="ltx_tr">
<td id="S4.T4.1.3.3.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 4.4pt;">Utilization (%)</td>
</tr>
</table>
</th>
<th id="S4.T4.1.3.3.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">
<table id="S4.T4.1.3.3.6.1" class="ltx_tabular ltx_align_top">
<tr id="S4.T4.1.3.3.6.1.1" class="ltx_tr">
<td id="S4.T4.1.3.3.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 4.4pt;">Avg Update Exchange</td>
</tr>
<tr id="S4.T4.1.3.3.6.1.2" class="ltx_tr">
<td id="S4.T4.1.3.3.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 4.4pt;">Time (s)</td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.1.4.1" class="ltx_tr">
<th id="S4.T4.1.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">Pi 3</th>
<th id="S4.T4.1.4.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">0.662</th>
<th id="S4.T4.1.4.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">322</th>
<td id="S4.T4.1.4.1.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">161.148</td>
<td id="S4.T4.1.4.1.5" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">40.851</td>
<td id="S4.T4.1.4.1.6" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">– / 73.188</td>
<td id="S4.T4.1.4.1.7" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">52.471</td>
</tr>
<tr id="S4.T4.1.5.2" class="ltx_tr">
<th id="S4.T4.1.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">Pi 4</th>
<th id="S4.T4.1.5.2.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">0.664</th>
<th id="S4.T4.1.5.2.3" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">338</th>
<td id="S4.T4.1.5.2.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">22.739</td>
<td id="S4.T4.1.5.2.5" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">11.414</td>
<td id="S4.T4.1.5.2.6" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">– / 42.312</td>
<td id="S4.T4.1.5.2.7" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">25.523</td>
</tr>
<tr id="S4.T4.1.6.3" class="ltx_tr">
<th id="S4.T4.1.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">Nano</th>
<th id="S4.T4.1.6.3.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">0.660</th>
<th id="S4.T4.1.6.3.3" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">339</th>
<td id="S4.T4.1.6.3.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">5.211</td>
<td id="S4.T4.1.6.3.5" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">77.213</td>
<td id="S4.T4.1.6.3.6" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">56.177 / 11.309</td>
<td id="S4.T4.1.6.3.7" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">12.915</td>
</tr>
<tr id="S4.T4.1.7.4" class="ltx_tr">
<th id="S4.T4.1.7.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">Simulation</th>
<th id="S4.T4.1.7.4.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">0.667</th>
<th id="S4.T4.1.7.4.3" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">314</th>
<td id="S4.T4.1.7.4.4" class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">1.524</td>
<td id="S4.T4.1.7.4.5" class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">13.363</td>
<td id="S4.T4.1.7.4.6" class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">11.118 /   0.578</td>
<td id="S4.T4.1.7.4.7" class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 4.4pt;">3.949</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Impact of Single Factor On FL Implementation (RQ2)</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In this set of experiments, we observe the results of experiments in RQ2 and analyze what happens when the number of participating clients increases, the communication bandwidth is constrained, and when intrinsic heterogeneity is introduced across clients.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS1.5.1.1" class="ltx_text">IV-B</span>1 </span>Impact of the Resource Allocation</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p"><span id="S4.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_bold">Impact of the Number of Clients</span>. Fig. <a href="#S4.F7" title="Figure 7 ‣ IV-B1 Impact of the Resource Allocation ‣ IV-B Impact of Single Factor On FL Implementation (RQ2) ‣ IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> and Fig. <a href="#S4.F8" title="Figure 8 ‣ IV-B1 Impact of the Resource Allocation ‣ IV-B Impact of Single Factor On FL Implementation (RQ2) ‣ IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> show the effect of the number of participating clients on the learning performance of communication cost. Generally, increasing the number of clients means more data involved in training the global model, resulting in an improvement in test accuracy. However, this also leads to a high diversity across client model parameters which can slow down the convergence process. We also observe that <em id="S4.SS2.SSS1.p1.1.2" class="ltx_emph ltx_font_italic">when the number of clients increases from 32 to 64, the improvement in test accuracy is <span id="S4.SS2.SSS1.p1.1.2.1" class="ltx_text ltx_font_bold">negligible</span>, however, the update exchange time goes up dramatically</em>. From this observation, we can empirically verify an assumption that more participating clients do not guarantee better accuracy but can lead to large congestion in communication and increase the update exchange time. In this setting, it is easy to observe that 32 is the optimal number of participating clients. Therefore, we only use 32 clients in the remaining experiments in RQ2.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2305.19831/assets/figs/num_clients-accuracy.jpg" id="S4.F7.g1" class="ltx_graphics ltx_align_right ltx_img_landscape" width="293" height="219" alt="Refer to caption">
<figcaption class="ltx_caption ltx_align_right"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Impact of the Number of Clients on Test Accuracy. </figcaption>
</figure>
<figure id="S4.F8" class="ltx_figure"><img src="/html/2305.19831/assets/figs/num_clients-comm_time.jpg" id="S4.F8.g1" class="ltx_graphics ltx_align_right ltx_img_landscape" width="293" height="87" alt="Refer to caption">
<figcaption class="ltx_caption ltx_align_right"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Impact of the Number of Clients on Update Exchange Time. </figcaption>
</figure>
<div id="S4.SS2.SSS1.p2" class="ltx_para">
<p id="S4.SS2.SSS1.p2.1" class="ltx_p"><span id="S4.SS2.SSS1.p2.1.1" class="ltx_text ltx_font_bold">Impact of the Communication Bandwidth</span>. Next, we investigate the effect of connection bandwidth on update exchange time. One interesting point obtained from Fig. <a href="#S4.F9" title="Figure 9 ‣ IV-B1 Impact of the Resource Allocation ‣ IV-B Impact of Single Factor On FL Implementation (RQ2) ‣ IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> is that update exchange time increase linearly when we decrease the bandwidth. Specifically, when we halve the bandwidth from 100Mbps to 50Mbps, the update exchange time increases approximately by 4 times. Furthermore, it increases about by 8 times when the bandwidth is constrained four times from 100Mbps to 25Mbps. This observation promotes FL algorithms that are suitable for low-bandwidth systems.</p>
</div>
<figure id="S4.F9" class="ltx_figure"><img src="/html/2305.19831/assets/figs/bandwidth-comm_time.jpg" id="S4.F9.g1" class="ltx_graphics ltx_align_right ltx_img_landscape" width="293" height="76" alt="Refer to caption">
<figcaption class="ltx_caption ltx_align_right"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Impact of the Bandwidth on Update Exchange Time. </figcaption>
</figure>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS2.5.1.1" class="ltx_text">IV-B</span>2 </span>Impact of the Heterogeneity</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p"><span id="S4.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_bold">Impact of the Device Heterogeneity</span>. Following the experiments in Fig. <a href="#S3.F5" title="Figure 5 ‣ III-D2 Impact of Single Factor (RQ2) ‣ III-D Experiments Setup ‣ III Experimental Design ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we investigate the impact of heterogeneity across client devices. From Table <a href="#S4.T5" title="TABLE V ‣ IV-B2 Impact of the Heterogeneity ‣ IV-B Impact of Single Factor On FL Implementation (RQ2) ‣ IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> below, we can observe that in a federation of heterogeneous devices, more powerful devices such as Nano or TX2 only need a couple of seconds to finish local training while weaker devices like Pi3 and Pi4 need much longer. However, in a naive FedAvg framework, the server needs to wait for all clients regardless of their strengths which is the reason why the update exchange time of more powerful devices is higher than weaker devices, this diminishes all benefits that high-end devices bring. This observation suggests <em id="S4.SS2.SSS2.p1.1.2" class="ltx_emph ltx_font_italic">a need for better client selection strategies based on the client’s computational power in realistic systems to leverage the presence of high-end devices</em>.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE V: </span>Impact of the Device Heterogeneity. </figcaption>
<table id="S4.T5.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.1.1.1" class="ltx_tr">
<th id="S4.T5.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">Exps</th>
<th id="S4.T5.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">Devices</th>
<th id="S4.T5.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">
<table id="S4.T5.1.1.1.3.1" class="ltx_tabular ltx_align_top">
<tr id="S4.T5.1.1.1.3.1.1" class="ltx_tr">
<td id="S4.T5.1.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 4.1pt;">Avg Training</td>
</tr>
<tr id="S4.T5.1.1.1.3.1.2" class="ltx_tr">
<td id="S4.T5.1.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 4.1pt;">Time (s)</td>
</tr>
</table>
</th>
<th id="S4.T5.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">
<table id="S4.T5.1.1.1.4.1" class="ltx_tabular ltx_align_top">
<tr id="S4.T5.1.1.1.4.1.1" class="ltx_tr">
<td id="S4.T5.1.1.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 4.1pt;">Avg Update Exchange</td>
</tr>
<tr id="S4.T5.1.1.1.4.1.2" class="ltx_tr">
<td id="S4.T5.1.1.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 4.1pt;">Time (s)</td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.1.2.1" class="ltx_tr">
<th id="S4.T5.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">Exp 2.1.3</th>
<td id="S4.T5.1.2.1.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">32 Pi 3</td>
<td id="S4.T5.1.2.1.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">161.872</td>
<td id="S4.T5.1.2.1.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">87.090</td>
</tr>
<tr id="S4.T5.1.3.2" class="ltx_tr">
<th id="S4.T5.1.3.2.1" class="ltx_td ltx_align_left ltx_align_top ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;" rowspan="2"><span id="S4.T5.1.3.2.1.1" class="ltx_text">Exp 2.3.1</span></th>
<td id="S4.T5.1.3.2.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">16 Pi 3</td>
<td id="S4.T5.1.3.2.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">166.641</td>
<td id="S4.T5.1.3.2.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">72.826</td>
</tr>
<tr id="S4.T5.1.4.3" class="ltx_tr">
<td id="S4.T5.1.4.3.1" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">16 Pi 4</td>
<td id="S4.T5.1.4.3.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">22.715</td>
<td id="S4.T5.1.4.3.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">216.448</td>
</tr>
<tr id="S4.T5.1.5.4" class="ltx_tr">
<th id="S4.T5.1.5.4.1" class="ltx_td ltx_align_left ltx_align_top ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;" rowspan="4"><span id="S4.T5.1.5.4.1.1" class="ltx_text">Exp 2.3.2</span></th>
<td id="S4.T5.1.5.4.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">12 Pi 3</td>
<td id="S4.T5.1.5.4.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">170.227</td>
<td id="S4.T5.1.5.4.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">65.391</td>
</tr>
<tr id="S4.T5.1.6.5" class="ltx_tr">
<td id="S4.T5.1.6.5.1" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">12 Pi 4</td>
<td id="S4.T5.1.6.5.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">22.687</td>
<td id="S4.T5.1.6.5.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">215.620</td>
</tr>
<tr id="S4.T5.1.7.6" class="ltx_tr">
<td id="S4.T5.1.7.6.1" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">4 Nano</td>
<td id="S4.T5.1.7.6.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">4.971</td>
<td id="S4.T5.1.7.6.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">233.224</td>
</tr>
<tr id="S4.T5.1.8.7" class="ltx_tr">
<td id="S4.T5.1.8.7.1" class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">4  TX2</td>
<td id="S4.T5.1.8.7.2" class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">4.126</td>
<td id="S4.T5.1.8.7.3" class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" style="padding:0.5pt 4.1pt;">234.161</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS2.SSS2.p2" class="ltx_para">
<p id="S4.SS2.SSS2.p2.1" class="ltx_p"><span id="S4.SS2.SSS2.p2.1.1" class="ltx_text ltx_font_bold">Impact of the Data Heterogeneity</span>. Heterogeneous data or distribution shift is the most challenging issue in FL. Most existing works on this issue only consider conventional Non-IID data scenarios. As discussed above, in this study, we further explore extreme cases of heterogeneity, i.e., ExNon-IID. Figs. <a href="#S4.F10" title="Figure 10 ‣ IV-B2 Impact of the Heterogeneity ‣ IV-B Impact of Single Factor On FL Implementation (RQ2) ‣ IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>(a) and <a href="#S4.F10" title="Figure 10 ‣ IV-B2 Impact of the Heterogeneity ‣ IV-B Impact of Single Factor On FL Implementation (RQ2) ‣ IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>(b) to show the effect of data heterogeneity on FL for CIFAR10 and CIFAR100 datasets, respectively. As observed from these results, ExNon-IID scenarios degrade the accuracy on test sets significantly compared to IID and Non-IID cases. Additionally, ExNon-IID scenarios tend to cause some fluctuation periods during training and slow down the convergence process. This suggests that the development of FL algorithms needs to tackle not only Non-IID cases but also ExNon-IID.</p>
</div>
<figure id="S4.F10" class="ltx_figure"><img src="/html/2305.19831/assets/figs/data-heterogeneity.png" id="S4.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="219" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Impact of the Data Heterogeneity. </figcaption>
</figure>
<div id="S4.SS2.SSS2.p3" class="ltx_para">
<p id="S4.SS2.SSS2.p3.1" class="ltx_p">In summary, we have figured out that increasing the number of participating clients generally leads to an improvement in accuracy due to the increase in data samples used for training. However, when we substantially increase the number of clients (i.e., from 32 to 64), the improvement is not significant but the update exchange time goes up dramatically. Moreover, the data heterogeneity also affects the global model’s accuracy significantly, especially in ExNon-IID cases. Besides heterogeneity in labels of local datasets, other types of data heterogeneity such as quantity heterogeneity or distribution heterogeneity are also important and might degrade the model’s accuracy much further, however, these types of data heterogeneity are still under-explored. In addition, the update exchange time is linearly affected by communication bandwidth. Also, we show that better client selection strategies are essential when dealing with heterogeneous devices to leverage the presence of high-end devices and reduce the update exchange time. However, <em id="S4.SS2.SSS2.p3.1.1" class="ltx_emph ltx_font_italic">it is quite challenging on a real deployment when the distributions of computing power and data are not known as a prior and can not be simulated in a controlled setting</em>.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Impact of Combined Factors On FL Implementation (RQ3)</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">This part reports the experimental results of RQ3 and draws insights when two factors, resource allocation, and heterogeneity, appear simultaneously. Also, we aim to figure out dominant factors towards the FL behaviors in real-device deployment.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p"><span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_bold">Combined Impact of the Number of Clients and Device Heterogeneity</span>. We focus on investigating the effect of the number of clients and device heterogeneity across clients on the update exchange time. Fig. <a href="#S4.F11" title="Figure 11 ‣ IV-C Impact of Combined Factors On FL Implementation (RQ3) ‣ IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> shows the average update exchange time of each type of device used in experiments 3.1.4 to 3.1.6. By comparing these results with results in Fig. <a href="#S4.F8" title="Figure 8 ‣ IV-B1 Impact of the Resource Allocation ‣ IV-B Impact of Single Factor On FL Implementation (RQ2) ‣ IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> and Table <a href="#S4.T5" title="TABLE V ‣ IV-B2 Impact of the Heterogeneity ‣ IV-B Impact of Single Factor On FL Implementation (RQ2) ‣ IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a>, we can draw a fascinating insight that with the same number of clients, heterogeneity in the federation can help reduce the overall update exchange time, and this gap seems more significant with a smaller number of clients. Unlike in homogenous scenarios where clients mostly finish local training and update their local models to the server simultaneously, which causes considerable congestion, in heterogeneous scenarios, clients with more powerful devices complete their work earlier, followed by weaker devices sequentially. This helps reduce the congestion in communication. These observations also suggest that a large number of clients and the congestion have a significantly negative effect on the update exchange time and raise a need for novel FL algorithms capable of handling situations with massive clients.</p>
</div>
<figure id="S4.F11" class="ltx_figure"><img src="/html/2305.19831/assets/figs/combined-comm-time.jpg" id="S4.F11.g1" class="ltx_graphics ltx_align_right ltx_img_landscape" width="293" height="220" alt="Refer to caption">
<figcaption class="ltx_caption ltx_align_right"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Combined Impact of the Number of Clients and Device Heterogeneity on Update Exchange Time. </figcaption>
</figure>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p"><span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_bold">Combined Impact of the Number of Clients and Data Heterogeneity</span>. We continue to study simultaneously the effect of the number of clients and data heterogeneity. Fig. <a href="#S4.F12" title="Figure 12 ‣ IV-C Impact of Combined Factors On FL Implementation (RQ3) ‣ IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a> shows the test accuracy of the global model in experiments 3.2.1 to 3.2.16. From Fig. <a href="#S4.F12" title="Figure 12 ‣ IV-C Impact of Combined Factors On FL Implementation (RQ3) ‣ IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>(a), <a href="#S4.F12" title="Figure 12 ‣ IV-C Impact of Combined Factors On FL Implementation (RQ3) ‣ IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>(c), and <a href="#S4.F12" title="Figure 12 ‣ IV-C Impact of Combined Factors On FL Implementation (RQ3) ‣ IV Experimental Results ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>(e), we can see that when increasing the number of clients from 32 to 64, the improvement in IID case is negligible. However, the improvement is more significant in cases of Non-IID and ExNon-IID which means that a large number of participating clients is essential in heterogenous data scenarios. Moreover, the negative effect of ExNon-IID data on the more challenging dataset, CIFAR100, seems more serious. Therefore, we can conclude that <em id="S4.SS3.p3.1.2" class="ltx_emph ltx_font_italic"> data heterogeneity is the most dominant factor in the model’s test accuracy, especially in challenging datasets</em>.</p>
</div>
<figure id="S4.F12" class="ltx_figure"><img src="/html/2305.19831/assets/figs/num_clients-heterogeneity-data.png" id="S4.F12.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="577" height="307" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Combined Impact of the Number of Clients and Data Heterogeneity. </figcaption>
</figure>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p">In summary, we have figured out that the communication congestion caused by a large number of clients has a significant negative effect on the update exchange time. However, increasing the number of clients leads to improvements in accuracy, especially in heterogenous data scenarios. Also, data heterogeneity is the most dominant factor that affects the model’s test accuracy, especially in challenging datasets. Going beyond the fundamental image classification task, data heterogeneity might further hurt the model’s performance in other advanced tasks, such as object detection or segmentation, which are under-explored in current literature. Interestingly, we also observe that some homogeneous devices can behave differently. This may be caused by various implicit factors such as power supply, network conditions, hardware and software variations, or user behavior.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Discussions</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this section, we first discuss the practicality of FL on IoT-Edge devices (based on our experimental results) and then discuss other essential factors to consider while designing an FL system for IoT devices.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">Practicality of FL on IoT-Edge Devices</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">FL requires local processing on the device, which can be challenging on lightweight devices with limited processing power. In addition, storing the model updates locally can be challenging due to the limited storage capacity. Another challenge is the unreliable connectivity of IoT devices. Federated learning requires a stable and reliable network connection for devices to communicate with each other and the aggregation server. However, IoT-Edge devices are often deployed in remote locations with limited network connectivity.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">In this study, we observed that the practicality of FL on IoT-Edge devices depends on combined effects from various factors such as device availability (number of participating clients), communication constraints (bandwidth availability), and heterogeneity of data (data distribution) and devices (computational capability and hardware configuration). These factors are interdependent and affect each other, and hence, a comprehensive analysis of the practicality of FL on IoT devices should consider all these factors together. For example, the computational capability of devices can affect communication overhead, as devices with lower computational capability may take longer to process and transmit data, resulting in higher communication latency and overhead. Similarly, the heterogeneity of devices can affect the robustness of FL algorithms, as the presence of devices with varying characteristics can introduce heterogeneity in the data and make it challenging to train accurate models.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">To address the processing power and storage capacity issues, we need to design models that are optimized for lightweight devices and implement compression or distillation techniques to reduce the size of the updates. There is also a need to implement techniques such as asynchronous updates and checkpointing to ensure that the training process can continue even when devices are disconnected due to network connectivity issues.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">Other Considerable Factors</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Besides the factors studied in this work, it is essential to consider other factors that can cause IoT devices not to perform well in FL, such as the power supply of devices and specifications of memory cards, and the performance of the aggregation server when designing FL systems.</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS2.SSS1.5.1.1" class="ltx_text">V-B</span>1 </span>Power Supply</h4>

<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.1" class="ltx_p">The amount of power available to the device can impact its processing capability. If the device has a limited power supply, it may not be able to perform complex computations or transmit large amounts of data efficiently. Furthermore, the quality and reliability of the power supply can affect the device’s stability and longevity. Power surges or outages can cause damage to the device’s components, leading to reduced performance and potentially even complete failure. As shown in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, when the battery life of the devices decreased, the accuracy of the global model also decreased significantly. Hence, it is crucial to ensure that devices used in FL have access to a reliable power supply with sufficient capacity to handle the demands of the learning process.</p>
</div>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS2.SSS2.5.1.1" class="ltx_text">V-B</span>2 </span>Memory Card Usage</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.1" class="ltx_p">The speed and capacity of the memory card can indirectly affect the overall performance of the IoT device itself. If the memory card is slow or has limited capacity, it may result in slower data processing and storage, slowing down the overall FL process. Also, the reliability and durability of the memory card can impact FL performance. For instance, if the memory card fails or becomes corrupted, it can result in the loss of data, which can negatively impact the accuracy and effectiveness of the FL model.</p>
</div>
</section>
<section id="S5.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS2.SSS3.5.1.1" class="ltx_text">V-B</span>3 </span>Performance of the Aggregation Server</h4>

<div id="S5.SS2.SSS3.p1" class="ltx_para">
<p id="S5.SS2.SSS3.p1.1" class="ltx_p">The performance of the aggregation server is crucial to the success of the FL process and can bring a significant impact on the participating IoT devices. The aggregation server needs to have sufficient computational resources to process the incoming model updates from IoT devices. If the server is overloaded, this can cause delays or even crashes in the system, affecting the IoT devices involved. This can be particularly problematic if the IoT devices have limited resources themselves, as they may not be able to handle the increased workload.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusions and Future Works</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">The results of our experiment have revealed several important findings: (1) our simulation of FL has shown that it can be a valuable tool for algorithm testing and evaluation, but its effectiveness in accurately representing the reality of IoT-Edge deployment is very limited, (2) the disparity in computational resources among IoT devices can significantly impact the update exchange time, and (3) data heterogeneity is the most dominant factor in the presence of other factors, especially working in tandem with computation and network factors.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">Moving forward, several areas could be explored to expand on the findings of this study. Firstly, considering the diversity of devices used in FL, it would be valuable to test the approach on a more comprehensive range of devices with different hardware, operating systems, and network connections to ensure the effectiveness and robustness of the approach. Secondly, the dataset selection process used for training the FL model could be further optimized to increase accuracy and efficiency and ensure that the results represent all potential use cases. Additionally, to expand the scope of the study’s findings, exploring other FL algorithms beyond the standard FedAvg algorithm could be beneficial. These alternative algorithms could be better suited for specific scenarios or applications and may provide insights into how to improve the performance of FL in IoT-Edge devices. Lastly, the study may miss out on the potential benefits of other FL algorithms that are better suited for specific scenarios or applications. For instance, FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> is designed to handle heterogeneity in data across devices and can improve the convergence rate of the FL process. It is important to note that these future improvements do not affect the objectives and scopes of the current study.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">Particularly, we plan to extend our study to a broader range of scenarios by examining the impact of varying network conditions, communication protocols, and resource usage of FL. In addition, we want to conduct a comprehensive analysis to measure the resource consumption of FL, including battery life and network bandwidth usage. We also want to focus on real-world applications of FL on IoT devices, including developing FL-based solutions for specific IoT use cases such as environmental monitoring, predictive maintenance, and evaluating their performance in realistic environments.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Internet of Things (IoT) And Non-IoT Active Device Connections Worldwide From
2010 to 2025.

</span>
<span class="ltx_bibblock">https://www.statista.com/statistics/1101442/iot-number-of-connected-devices-worldwide.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Enabling Mass IoT Connectivity as Arm Partners Ship 100 Billion Chips.

</span>
<span class="ltx_bibblock">https://community.arm.com/arm-community-blogs/b/internet-of-things-blog/posts/enabling-mass-iot-connectivity-as-arm-partners-ship-100-billion-chips.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Christoph Gröger.

</span>
<span class="ltx_bibblock">There Is No AI Without Data.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Commun. ACM</span>, 64(11):98–108, 2021.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Axel von dem Bussche Paul Voigt.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">The EU General Data Protection Regulation (GDPR)</span>.

</span>
<span class="ltx_bibblock">Springer Cham, 2017.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
Blaise Agüera y Arcas.

</span>
<span class="ltx_bibblock">Communication-Efficient Learning of Deep Networks From Decentralized
Data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Proceedings of the 20th International Conference on
Artificial Intelligence and Statistics, Aistats 2017</span>, 2017.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong.

</span>
<span class="ltx_bibblock">Federated Machine Learning: Concept and Applications.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">ACM Trans. on Intelligent Systems and Technology</span>, 2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Qinbin Li, Zeyi Wen, Zhaomin Wu, Sixu Hu, Naibo Wang, Yuan Li, Xu Liu, and
Bingsheng He.

</span>
<span class="ltx_bibblock">A Survey on Federated Learning Systems: Vision, Hype and Reality for
Data Privacy and Protection.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">IEEE Trans. on Knowledge and Data Engineering</span>, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Di Wu, Rehmat Ullah, Paul Harvey, Peter Kilpatrick, Ivor Spence, and Blesson
Varghese.

</span>
<span class="ltx_bibblock">FedAdapt: Adaptive Offloading for IoT Devices in Federated
Learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 9(21):20889–20901, 2022.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Rui Sun, Yinhao Li, Tejal Shah, Ringo W. H. Sham, Tomasz Szydlo, Bin Qian,
Dhaval Thakker, and Rajiv Ranjan.

</span>
<span class="ltx_bibblock">FedMSA: Fedmsa: A Model Selection and Adaptation System for
Federated Learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Sensors</span>, 22(19), 2022.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Jed Mills, Jia Hu, and Geyong Min.

</span>
<span class="ltx_bibblock">Communication-Efficient Federated Learning for Wireless Edge
Intelligence in IoT.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 7(7):5986–5994, 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
Virginia Smith.

</span>
<span class="ltx_bibblock">Federated Optimization in Heterogeneous Networks.

</span>
<span class="ltx_bibblock">In I. Dhillon, D. Papailiopoulos, and V. Sze, editors, <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Proceedings of Machine Learning and Systems</span>, pages 429–450, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, and
Yasaman Khazaeni.

</span>
<span class="ltx_bibblock">Federated Learning with Matched Averaging.

</span>
<span class="ltx_bibblock">In <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>,
2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Huiming Chen, Huandong Wang, Qingyue Long, Depeng Jin, and Yong Li.

</span>
<span class="ltx_bibblock">Advancements in Federated Learning: Models, Methods, and Privacy.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">arXiv</span>, 2023.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Bingyan Liu, Nuoyan Lv, Yuanchun Guo, and Yawen Li.

</span>
<span class="ltx_bibblock">Recent Advances on Federated Learning: A Systematic Survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">arXiv</span>, 2023.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Dinh C. Nguyen, Ming Ding, Pubudu N. Pathirana, Aruna Seneviratne, Jun Li, and
H. Vincent Poor.

</span>
<span class="ltx_bibblock">Federated Learning for Internet of Things: A Comprehensive Survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">IEEE Communications Surveys and Tutorials</span>, 23, 2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Ahmed Imteaj, Urmish Thakker, Shiqiang Wang, Jian Li, and M. Hadi Amini.

</span>
<span class="ltx_bibblock">A Survey on Federated Learning for Resource-Constrained IoT
Devices.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 9, 2022.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Hangyu Zhu, Jinjin Xu, Shiqing Liu, and Yaochu Jin.

</span>
<span class="ltx_bibblock">Federated Learning on Non-iid Data: A Survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Neurocomputing</span>, 465:371–390, 2021.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Qinbin Li, Yiqun Diao, Quan Chen, and Bingsheng He.

</span>
<span class="ltx_bibblock">Federated Learning on Non-IID Data Silos: An Experimental Study.

</span>
<span class="ltx_bibblock">In <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">2022 IEEE 38th International Conference on Data Engineering
(ICDE)</span>, 2022.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Koji Matsuda, Yuya Sasaki, Chuan Xiao, and Makoto Onizuka.

</span>
<span class="ltx_bibblock">An Empirical Study of Personalized Federated Learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">arXiv</span>, 2022.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Sebastian Caldas, Sai Meher Karthik Duddu, Peter Wu, Tian Li, Jakub Konečný,
H. Brendan McMahan, Virginia Smith, and Ameet Talwalkar.

</span>
<span class="ltx_bibblock">LEAF: A Benchmark for Federated Settings.

</span>
<span class="ltx_bibblock">In <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Workshop on Federated Learning for Data Privacy and
Confidentiality</span>, 2019.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Tuo Zhang, Chaoyang He, Tianhao Ma, Lei Gao, Mark Ma, and Salman Avestimehr.

</span>
<span class="ltx_bibblock">Federated Learning for Internet of Things.

</span>
<span class="ltx_bibblock">In <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Proceedings of the 19th ACM Conference on Embedded Networked
Sensor Systems</span>, SenSys ’21, page 413–419, New York, NY, USA, 2021.
Association for Computing Machinery.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Alex Krizhevsky.

</span>
<span class="ltx_bibblock">Learning Multiple Layers of Features from Tiny Images.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">Science Department, University of Toronto, Tech</span>, 2009.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra.

</span>
<span class="ltx_bibblock">Federated Learning with Non-IID Data.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">arXiv</span>, 2018.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al.

</span>
<span class="ltx_bibblock">PyTorch: An Imperative Style, High-Performance Deep Learning
Library.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 32, 2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Daniel J Beutel, Taner Topal, Akhil Mathur, Xinchi Qiu, Javier
Fernandez-Marques, Yan Gao, Lorenzo Sani, Kwing Hei Li, Titouan Parcollet,
Pedro Porto Buarque de Gusmão, et al.

</span>
<span class="ltx_bibblock">Flower: A Friendly Federated Learning Research Framework.

</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">arXiv:2007.14390</span>, 2020.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex
Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Konečnỳ, Stefano
Mazzocchi, Brendan McMahan, et al.

</span>
<span class="ltx_bibblock">Towards Federated Learning at Scale: System Design.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">Proceedings of Machine Learning and Systems</span>, 1:374–388,
2019.

</span>
</li>
</ul>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Biography Section</h2>

<figure id="Sx1.1" class="ltx_float biography">
<table id="Sx1.1.1" class="ltx_tabular">
<tr id="Sx1.1.1.1" class="ltx_tr">
<td id="Sx1.1.1.1.1" class="ltx_td"><img src="/html/2305.19831/assets/imgs/kswong.png" id="Sx1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="98" height="125" alt="[Uncaptioned image]"></td>
<td id="Sx1.1.1.1.2" class="ltx_td">
<span id="Sx1.1.1.1.2.1" class="ltx_inline-block">
<span id="Sx1.1.1.1.2.1.1" class="ltx_p"><span id="Sx1.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Kok-Seng Wong</span> (Member, IEEE)
received his first degree in Computer Science (Software Engineering) from the University of Malaya, Malaysia in 2002, and an M.Sc. (Information Technology) degree from Malaysia University of Science and Technology (in collaboration with MIT) in 2004. He obtained his Ph.D. from Soongsil University, South Korea, in 2012. He is currently an Associate Professor in the College of Engineering and Computer Science, VinUniversity. To this end, he conducts research that spans areas of security, data privacy, and AI security while maintaining a strong relevance to the privacy-preserving framework.
</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="Sx1.2" class="ltx_float biography">
<table id="Sx1.2.1" class="ltx_tabular">
<tr id="Sx1.2.1.1" class="ltx_tr">
<td id="Sx1.2.1.1.1" class="ltx_td"><img src="/html/2305.19831/assets/imgs/manh.png" id="Sx1.2.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="94" height="125" alt="[Uncaptioned image]"></td>
<td id="Sx1.2.1.1.2" class="ltx_td">
<span id="Sx1.2.1.1.2.1" class="ltx_inline-block">
<span id="Sx1.2.1.1.2.1.1" class="ltx_p"><span id="Sx1.2.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Duc-Manh Nguyen</span>  got a Master in Information Science and Technology from University of Information Science and Technology, North Macedonia. Currently, he is a PhD candidate and a research assistant at the Technical University of Berlin. His research focuses on Robotics and Edge Computing with Machine Learning, partially Cooperative Perception for Autonomous Vehicles.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="Sx1.3" class="ltx_float biography">
<table id="Sx1.3.1" class="ltx_tabular">
<tr id="Sx1.3.1.1" class="ltx_tr">
<td id="Sx1.3.1.1.1" class="ltx_td"><img src="/html/2305.19831/assets/figs/khiem.jpg" id="Sx1.3.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="100" height="125" alt="[Uncaptioned image]"></td>
<td id="Sx1.3.1.1.2" class="ltx_td">
<span id="Sx1.3.1.1.2.1" class="ltx_inline-block">
<span id="Sx1.3.1.1.2.1.1" class="ltx_p"><span id="Sx1.3.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Khiem Le-Huy</span> 
got the Honors Bachelor Degree in Mathematics and Computer Science from the Vietnam National University, Ho Chi Minh City. He was a Research Intern at Smart Health Center, VinBigData JSC, and currently is a Research Assistant at the College of Engineering and Computer Science, VinUniversity, Hanoi, Vietnam. His research interests include Efficient Machine Learning and AI for Biomedical Applications.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="Sx1.4" class="ltx_float biography">
<table id="Sx1.4.1" class="ltx_tabular">
<tr id="Sx1.4.1.1" class="ltx_tr">
<td id="Sx1.4.1.1.1" class="ltx_td"><img src="/html/2305.19831/assets/imgs/long.jpg" id="Sx1.4.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="93" height="125" alt="[Uncaptioned image]"></td>
<td id="Sx1.4.1.1.2" class="ltx_td">
<span id="Sx1.4.1.1.2.1" class="ltx_inline-block">
<span id="Sx1.4.1.1.2.1.1" class="ltx_p"><span id="Sx1.4.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Long Ho-Tuan</span> 
got the Honors Bachelor Degree in Computer Science from the Vietnam National University, Hanoi, Vietnam. Currently, he is a Research Assistant at the College of Engineering and Computer Science, VinUniversity, Hanoi, Vietnam. His research interests include Federated Learning and AI for Biomedical Applications.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="Sx1.5" class="ltx_float biography">
<table id="Sx1.5.1" class="ltx_tabular">
<tr id="Sx1.5.1.1" class="ltx_tr">
<td id="Sx1.5.1.1.1" class="ltx_td"><img src="/html/2305.19831/assets/imgs/cuong_do.jpg" id="Sx1.5.1.1.1.g1" class="ltx_graphics ltx_img_square" width="100" height="100" alt="[Uncaptioned image]"></td>
<td id="Sx1.5.1.1.2" class="ltx_td">
<span id="Sx1.5.1.1.2.1" class="ltx_inline-block">
<span id="Sx1.5.1.1.2.1.1" class="ltx_p"><span id="Sx1.5.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Cuong Do-Danh</span> (Member, IEEE)
received his B.Sc. degree in electronics and telecommunication from Vietnam National University, Hanoi, Vietnam, in 2004, M.Eng. degree in electronics from Chungbuk National University, Korea, in 2007, and a Ph.D. degree in electronics from Cork Institute of Technology, Ireland, in 2012. He had more than four years working as a postdoc researcher at the University of Cambridge, U.K in both fields of MEMS and CMOS circuits for low-power sensors and timing applications. He is now an Assistant Professor at VinUniversity. His research interests include sensors for medical applications and sensor fusion.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="Sx1.6" class="ltx_float biography">
<table id="Sx1.6.1" class="ltx_tabular">
<tr id="Sx1.6.1.1" class="ltx_tr">
<td id="Sx1.6.1.1.1" class="ltx_td"><img src="/html/2305.19831/assets/figs/danhlephuoc.jpg" id="Sx1.6.1.1.1.g1" class="ltx_graphics ltx_img_square" width="100" height="103" alt="[Uncaptioned image]"></td>
<td id="Sx1.6.1.1.2" class="ltx_td">
<span id="Sx1.6.1.1.2.1" class="ltx_inline-block">
<span id="Sx1.6.1.1.2.1.1" class="ltx_p"><span id="Sx1.6.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Danh Le-Phuoc</span> (Member, IEEE) is a DFG Principle Investigator at the Technical University
of Berlin. His research interests include
linked data and the Semantic Computing for IoT-Edge-Cloud continuum, neural-symbolic AI, databases, pervasive
computing, semantic stream processing and reasoning. Le Phuoc received a PhD
in computer science from the National
University of Ireland. Contact him at danh@danhlephuoc.info.</span>
</span>
</td>
</tr>
</table>
</figure>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Appendix A: Power and Storage</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">The testbed utilized in this research project consists of a diverse array of devices, including Raspberry Pi 3, Raspberry Pi 4, and various models from the NVIDIA Jetson family. These devices are equipped with different types of storage, which come in varying capacities and speeds. Additionally, the devices are powered by a variety of power supplies, with power outputs ranging from 7.5W to 15W. The detailed specification is shown in Figure <a href="#S7.F13" title="Figure 13 ‣ VII Appendix A: Power and Storage ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a></p>
</div>
<figure id="S7.F13" class="ltx_figure"><img src="/html/2305.19831/assets/figs/sdcard-report.png" id="S7.F13.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Devices power and storage specification</figcaption>
</figure>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VIII </span><span id="S8.1.1" class="ltx_text ltx_font_smallcaps">Appendix B: Compare Convergence Time of Different hardware profile</span>
</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">This appendix presents the results of an experiment conducted to compare the convergence time of different hardware profiles in Federated Learning. The experiment involved training models on three distinct sets of devices: 8 Raspberry Pi 3 devices, 8 Raspberry Pi 4 devices, and 8 simulation threads on a high-end computer. The experiment used CIFAR10 IID data and monitored the progress of the models on different metrics which is test accuracy, test loss, and convergence speed. Three sub-figures in Figure <a href="#S8.F14" title="Figure 14 ‣ VIII Appendix B: Compare Convergence Time of Different hardware profile ‣ An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a> provide a visual representation of the performance differences observed among the hardware profiles.</p>
</div>
<figure id="S8.F14" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S8.F14.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.19831/assets/Appendix-figs/Acc-pi34S-8-C10.png" id="S8.F14.sf1.g1" class="ltx_graphics ltx_img_square" width="180" height="180" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Test Accuracy</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S8.F14.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.19831/assets/Appendix-figs/Loss-pi34S-8-C10.png" id="S8.F14.sf2.g1" class="ltx_graphics ltx_img_square" width="180" height="180" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Test Loss</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S8.F14.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.19831/assets/Appendix-figs/Acc-pi34S-8-C10-time.png" id="S8.F14.sf3.g1" class="ltx_graphics ltx_img_square" width="180" height="180" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Convergence Time</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>Experiment of Federated Learning on different set of devices. Setup with 8 Raspberry Pi 3 vs 8 Raspberry Pi 4 vs 8 simulation threads of high-end computer on CIFAR10 IID data.</figcaption>
</figure>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IX </span><span id="S9.1.1" class="ltx_text ltx_font_smallcaps">Appendix C: The impact for the number of client</span>
</h2>

<div id="S9.p1" class="ltx_para">
<p id="S9.p1.1" class="ltx_p">This appendix presents the findings from an experiment conducted to examine the impact of the number of clients on Federated Learning. The experiment involved training models on Raspberry Pi 3 devices using CIFAR10 IID data, with the number of clients gradually increasing from 8 to 16, 32, and finally 64.</p>
</div>
<figure id="S9.F15" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S9.F15.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.19831/assets/Appendix-figs/Acc-pi3-8163264-c10.png" id="S9.F15.sf1.g1" class="ltx_graphics ltx_img_square" width="180" height="180" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Test Accuracy</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S9.F15.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.19831/assets/Appendix-figs/Loss-pi3-8163264-c10.png" id="S9.F15.sf2.g1" class="ltx_graphics ltx_img_square" width="180" height="180" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Test Loss</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S9.F15.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.19831/assets/Appendix-figs/Acc-pi3-8163264-c10-time.png" id="S9.F15.sf3.g1" class="ltx_graphics ltx_img_square" width="180" height="180" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Convergence Time</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 15: </span>Experiment of Federated Learning on incremental from 8, 16, 32 to 64 clients. Setup on Raspberry Pi 3 using CIFAR10 IID data.</figcaption>
</figure>
</section>
<section id="S10" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">X </span><span id="S10.1.1" class="ltx_text ltx_font_smallcaps">Appendix D: Heterogeneity in Data and Device profiles</span>
</h2>

<div id="S10.p1" class="ltx_para">
<p id="S10.p1.1" class="ltx_p">This appendix examines how differences in both data and device profiles impact Federated Learning. The first figure compares the performance of models trained on different types of data: identical, non-identical, and extremely non-identical. We used 32 Raspberry Pi 4 devices and CIFAR 100 data for this experiment. The figure shows how the models perform under these varying data distributions, highlighting the challenges posed by diverse data.</p>
</div>
<div id="S10.p2" class="ltx_para">
<p id="S10.p2.1" class="ltx_p">The second figure explores the performance differences among diverse device profiles. We used a setup with 32 devices, including 32 Raspberry Pi 3, 32 Raspberry Pi 4, and a mix up of 32 devices from different type of devices. The models were trained on CIFAR 10 identical data. This figure compares the performance achieved by these different device profiles, giving insights into the advantages and limitations of diversity in Federated Learning scenarios.</p>
</div>
<figure id="S10.F16" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S10.F16.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.19831/assets/Appendix-figs/Acc-Pi4-32-C10.png" id="S10.F16.sf1.g1" class="ltx_graphics ltx_img_square" width="180" height="180" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Test Accuracy</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S10.F16.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.19831/assets/Appendix-figs/Loss-Pi4-32-C10.png" id="S10.F16.sf2.g1" class="ltx_graphics ltx_img_square" width="180" height="180" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Test Loss</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S10.F16.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.19831/assets/Appendix-figs/Acc-Pi4-32-C10-time.png" id="S10.F16.sf3.g1" class="ltx_graphics ltx_img_square" width="180" height="180" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Convergence Time</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 16: </span>Comparision between IID, Non-IID, and extreme Non-IID data. Setup on 32 Raspberry Pi 4, and CIFAR 100 data.</figcaption>
</figure>
<figure id="S10.F17" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S10.F17.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.19831/assets/Appendix-figs/Acc-mix-P34.png" id="S10.F17.sf1.g1" class="ltx_graphics ltx_img_square" width="240" height="240" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Test Accuracy</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S10.F17.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.19831/assets/Appendix-figs/Acc-mix-P34-time.png" id="S10.F17.sf2.g1" class="ltx_graphics ltx_img_square" width="240" height="240" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Convergence Time</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 17: </span>Heterogeneous devices comparison. Setup on 32 Raspberry Pi 3 vs 32 Raspberry Pi 4 vs 32 devices that mix up of 12 Raspberry Pi 3 + 12 Raspberry Pi 4 + 4 NVIDIA Jetson TX2 + 4 NVIDIA Jetson NaNo using CIFAR 10 IID data.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2305.19830" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2305.19831" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2305.19831">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2305.19831" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2305.19833" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 04:15:26 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
