<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_title_document">
  ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning
  <span class="ltx_note ltx_role_thanks" id="id1.id1">
   <sup class="ltx_note_mark">
    †
   </sup>
   <span class="ltx_note_outer">
    <span class="ltx_note_content">
     <sup class="ltx_note_mark">
      †
     </sup>
     <span class="ltx_note_type">
      thanks:
     </span>
     <span class="ltx_text ltx_font_italic ltx_framed ltx_framed_underline" id="id1.id1.1">
      Citation
     </span>
     :
     <span class="ltx_text ltx_font_bold" id="id1.id1.2">
      A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024
     </span>
    </span>
   </span>
  </span>
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Alireza Ghafarollahi
    <br class="ltx_break"/>
    Laboratory for Atomistic and Molecular Mechanics (LAMM)
    <br class="ltx_break"/>
    Massachusetts Institute of Technology
    <br class="ltx_break"/>
    77 Massachusetts Ave.
    <br class="ltx_break"/>
    Cambridge, MA 02139, USA
    <br class="ltx_break"/>
    <br class="ltx_break"/>
    <span class="ltx_ERROR undefined" id="id2.1.id1">
     \And
    </span>
    Markus J. Buehler
    <br class="ltx_break"/>
    Laboratory for Atomistic and Molecular Mechanics (LAMM)
    <br class="ltx_break"/>
    Center for Computational Science and Engineering
    <br class="ltx_break"/>
    Schwarzman College of Computing,
    <br class="ltx_break"/>
    Massachusetts Institute of Technology
    <br class="ltx_break"/>
    77 Massachusetts Ave.
    <br class="ltx_break"/>
    Cambridge, MA 02139, USA
    <br class="ltx_break"/>
    <br class="ltx_break"/>
    Correspondence:
    <span class="ltx_text ltx_font_typewriter" id="id3.2.id2">
     mbuehler@MIT.EDU
    </span>
    <br class="ltx_break"/>
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id4.id1">
   Designing
   <span class="ltx_text ltx_font_italic" id="id4.id1.1">
    de novo
   </span>
   proteins beyond those found in nature holds significant promise for advancements in both scientific and engineering applications. Current methodologies for protein design often rely on AI-based models, such as surrogate models that address end-to-end problems by linking protein structure to material properties or vice versa. However, these models frequently focus on specific material objectives or structural properties, limiting their flexibility when incorporating out-of-domain knowledge into the design process or comprehensive data analysis is required. In this study, we introduce ProtAgents, a platform for
   <span class="ltx_text ltx_font_italic" id="id4.id1.2">
    de novo
   </span>
   protein design based on Large Language Models (LLMs), where multiple AI agents with distinct capabilities collaboratively address complex tasks within a dynamic environment. The versatility in agent development allows for expertise in diverse domains, including knowledge retrieval, protein structure analysis, physics-based simulations, and results analysis. The dynamic collaboration between agents, empowered by LLMs, provides a versatile approach to tackling protein design and analysis problems, as demonstrated through diverse examples in this study. The problems of interest encompass designing new proteins, analyzing protein structures and obtaining new first-principles data – natural vibrational frequencies – via physics simulations. The concerted effort of the system allows for powerful automated and synergistic design of
   <span class="ltx_text ltx_font_italic" id="id4.id1.3">
    de novo
   </span>
   proteins with targeted mechanical properties. The flexibility in designing the agents, on one hand, and their capacity in autonomous collaboration through the dynamic LLM-based multi-agent environment on the other hand, unleashes great potentials of LLMs in addressing multi-objective materials problems and opens up new avenues for autonomous materials discovery and design.
  </p>
 </div>
 <div class="ltx_para ltx_noindent" id="p1">
  <p class="ltx_p" id="p1.3">
   <em class="ltx_emph ltx_font_bold ltx_font_italic" id="p1.3.1">
    K
   </em>
   <span class="ltx_text ltx_font_bold" id="p1.3.2">
    eywords
   </span>
   Multi-agent modeling
   <math alttext="\cdot" class="ltx_Math" display="inline" id="p1.1.m1.1">
    <semantics id="p1.1.m1.1a">
     <mo id="p1.1.m1.1.1" xref="p1.1.m1.1.1.cmml">
      ⋅
     </mo>
     <annotation-xml encoding="MathML-Content" id="p1.1.m1.1b">
      <ci id="p1.1.m1.1.1.cmml" xref="p1.1.m1.1.1">
       ⋅
      </ci>
     </annotation-xml>
     <annotation encoding="application/x-tex" id="p1.1.m1.1c">
      \cdot
     </annotation>
    </semantics>
   </math>
   large language model (LLM)
   <math alttext="\cdot" class="ltx_Math" display="inline" id="p1.2.m2.1">
    <semantics id="p1.2.m2.1a">
     <mo id="p1.2.m2.1.1" xref="p1.2.m2.1.1.cmml">
      ⋅
     </mo>
     <annotation-xml encoding="MathML-Content" id="p1.2.m2.1b">
      <ci id="p1.2.m2.1.1.cmml" xref="p1.2.m2.1.1">
       ⋅
      </ci>
     </annotation-xml>
     <annotation encoding="application/x-tex" id="p1.2.m2.1c">
      \cdot
     </annotation>
    </semantics>
   </math>
   physics-inspired machine learning
   <math alttext="\cdot" class="ltx_Math" display="inline" id="p1.3.m3.1">
    <semantics id="p1.3.m3.1a">
     <mo id="p1.3.m3.1.1" xref="p1.3.m3.1.1.cmml">
      ⋅
     </mo>
     <annotation-xml encoding="MathML-Content" id="p1.3.m3.1b">
      <ci id="p1.3.m3.1.1.cmml" xref="p1.3.m3.1.1">
       ⋅
      </ci>
     </annotation-xml>
     <annotation encoding="application/x-tex" id="p1.3.m3.1c">
      \cdot
     </annotation>
    </semantics>
   </math>
   protein design
  </p>
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <div class="ltx_para ltx_noindent" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Proteins, the building blocks of life, serve as the fundamental elements of many biological materials emerging from natural evolution over the span of 300 million years. Protein-base biomaterials like silk, collagen and tissue assemblies such as skin exhibit diverse structural features and showcase unique combinations of material properties. The underlying sequences of amino acids (AAs) in a protein determines its unique there-dimensional structure, which, in turn, dictates its specific biological activity and associated outstanding properties. This inherent relationship has inspired scientists in the field of materials design and optimization to draw valuable insights from nature for creating novel protein-based materials. The diversity in protein design is immense, with over
    <math alttext="20^{100}" class="ltx_Math" display="inline" id="S1.p1.1.m1.1">
     <semantics id="S1.p1.1.m1.1a">
      <msup id="S1.p1.1.m1.1.1" xref="S1.p1.1.m1.1.1.cmml">
       <mn id="S1.p1.1.m1.1.1.2" xref="S1.p1.1.m1.1.1.2.cmml">
        20
       </mn>
       <mn id="S1.p1.1.m1.1.1.3" xref="S1.p1.1.m1.1.1.3.cmml">
        100
       </mn>
      </msup>
      <annotation-xml encoding="MathML-Content" id="S1.p1.1.m1.1b">
       <apply id="S1.p1.1.m1.1.1.cmml" xref="S1.p1.1.m1.1.1">
        <csymbol cd="ambiguous" id="S1.p1.1.m1.1.1.1.cmml" xref="S1.p1.1.m1.1.1">
         superscript
        </csymbol>
        <cn id="S1.p1.1.m1.1.1.2.cmml" type="integer" xref="S1.p1.1.m1.1.1.2">
         20
        </cn>
        <cn id="S1.p1.1.m1.1.1.3.cmml" type="integer" xref="S1.p1.1.m1.1.1.3">
         100
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S1.p1.1.m1.1c">
       20^{100}
      </annotation>
     </semantics>
    </math>
    possible AA sequences for just a relatively small 100-residue protein. However, the natural evolutionary process has sampled only a fraction of this vast sequence space. This leaves a substantial portion uncharted, presenting a significant opportunity for the
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">
     de novo
    </span>
    design of proteins with potentially remarkable properties.
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib1" title="">
      1
     </a>
     ]
    </cite>
    Despite this potential, the extensive design space, coupled with the costs associated with experimental testing, poses formidable challenges in
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.2">
     de novo
    </span>
    protein design. Navigating this intricate landscape necessitates the development of a diverse set of effective tools enabling the targeted design of
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.3">
     de novo
    </span>
    proteins with specific structural features or properties.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    Over the past years, in the field of
    <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">
     de novo
    </span>
    protein design, data-driven and machine learning methods have emerged as powerful tools, offering valuable insights and accelerating the discovery of novel proteins with desired properties
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib2" title="">
      2
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib3" title="">
      3
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib4" title="">
      4
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib5" title="">
      5
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib6" title="">
      6
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib7" title="">
      7
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib8" title="">
      8
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib9" title="">
      9
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib10" title="">
      10
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib11" title="">
      11
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib12" title="">
      12
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib13" title="">
      13
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib14" title="">
      14
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib15" title="">
      15
     </a>
     ]
    </cite>
    . These methods have opened great avenues for predicting structure, properties, and functions of proteins solely based on their underlying AA sequence. For instance, the development of deep learning (DL)-based AlphaFold 2 marked a significant breakthrough in the field of 3D folding protein prediction with a level of accuracy that in some cases rivaled expensive and time-consuming experimental techniques.
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib16" title="">
      16
     </a>
     ]
    </cite>
    Moreover, deep learning-based models have been developed to explore structure-property relationships in the analysis and design of proteins. These models encompass a broad spectrum of structural and mechanical properties, serving either as constraints or target values. For example, various DL-models developed predict the secondary structure of proteins from their primary sequences. Prediction of mechanical properties of spider silk protein sequences have been enabled by DL models
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib17" title="">
      17
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib18" title="">
      18
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib19" title="">
      19
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib20" title="">
      20
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib21" title="">
      21
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib22" title="">
      22
     </a>
     ]
    </cite>
    . Moreover, DL-based models such as graph neural networks
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib23" title="">
      23
     </a>
     ]
    </cite>
    and transformer-based language models
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib24" title="">
      24
     </a>
     ]
    </cite>
    show enhanced accuracy in predicting the protein natural frequencies compared to physics-based all-atom molecular simulations. The development of such DL models significantly reduces the cost of screening the vast sequence space to target proteins with improved or optimized mechanical performance.
In the field of
    <span class="ltx_text ltx_font_italic" id="S1.p2.1.2">
     de novo
    </span>
    protein design, data-driven and machine learning methods have emerged as powerful tools, offering valuable insights and accelerating the discovery of novel proteins with desired properties
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib2" title="">
      2
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib3" title="">
      3
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib4" title="">
      4
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib5" title="">
      5
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib6" title="">
      6
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib7" title="">
      7
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib8" title="">
      8
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib9" title="">
      9
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib10" title="">
      10
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib11" title="">
      11
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib12" title="">
      12
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib13" title="">
      13
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib14" title="">
      14
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib15" title="">
      15
     </a>
     ]
    </cite>
    . These methods have opened great avenues for predicting structure, properties, and functions of proteins solely based on their underlying AA sequence. For instance, the development of deep learning (DL)-based AlphaFold 2 marked a significant breakthrough in the field of 3D folding protein prediction with a level of accuracy that in some cases rivaled expensive and time-consuming experimental techniques.
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib16" title="">
      16
     </a>
     ]
    </cite>
    Moreover, deep learning-based models have been developed to explore structure-property relationships in the analysis and design of proteins. These models encompass a broad spectrum of structural and mechanical properties, serving either as constraints or target values. For example, various DL-models developed predict the secondary structure of proteins from their primary sequences. Prediction of mechanical properties of spider silk protein sequences have been enabled by DL models
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib17" title="">
      17
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib18" title="">
      18
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib19" title="">
      19
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib20" title="">
      20
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib21" title="">
      21
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib22" title="">
      22
     </a>
     ]
    </cite>
    . Moreover, DL-based models such as graph neural networks
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib23" title="">
      23
     </a>
     ]
    </cite>
    and transformer-based language models
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib24" title="">
      24
     </a>
     ]
    </cite>
    show enhanced accuracy in predicting the protein natural frequencies compared to physics-based all atomistic simulations. The development of such DL models significantly reduces the cost of screening the vast sequence space to target proteins with improved or optimized mechanical performance.
   </p>
  </div>
  <figure class="ltx_figure" id="S1.F1">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="480" id="S1.F1.g1" src="/html/2402.04268/assets/image_agents.png" width="598"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 1:
    </span>
    <span class="ltx_text ltx_font_bold" id="S1.F1.9.1">
     Multi-agent AI framework for automating protein discovery and analysis.
    </span>
    <span class="ltx_text ltx_font_bold" id="S1.F1.10.2">
     a
    </span>
    , A genetic agent structure in a multi-agent modeling environment that can communicate via language, has a focus defined by a profile, and has access to custom functions.
    <span class="ltx_text ltx_font_bold" id="S1.F1.11.3">
     b
    </span>
    , A function is customized by a profile and a set of parameters.
    <span class="ltx_text ltx_font_bold" id="S1.F1.12.4">
     c
    </span>
    , The structure of a team of agents, each with special expertise, that communicate to each other and allow for mutual correction and a division of labor. Given different profiles for each agent, agents are designed that are expert on describing the problem (
    <span class="ltx_text ltx_font_italic" id="S1.F1.13.5">
     user_proxy
    </span>
    ), plan making (
    <span class="ltx_text ltx_font_italic" id="S1.F1.14.6">
     planner
    </span>
    ), function executing (
    <span class="ltx_text ltx_font_italic" id="S1.F1.15.7">
     assistant
    </span>
    ), and result evaluation (
    <span class="ltx_text ltx_font_italic" id="S1.F1.16.8">
     critic
    </span>
    ). The whole process is automated via a dynamic group chat under the leading chat manager, offering a versatile approach in solving challenging tasks in the context of protein design and analysis without human intervention.
   </figcaption>
  </figure>
  <div class="ltx_para ltx_noindent" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    A frontier, however, that still exists is how we can create intelligent tools that can solve complex tasks and draw upon a diverse set of knowledge, tools and abilities. Another critical issue is that the combination of purely data-driven tools with physics-based modeling is important for accurate predictions. Moreover, such tools should ideally also be able to retrieve knowledge from, for instance, the literature or the internet. All these aspects must be combined in a nonlinear manner where multiple dependent steps in the iteration towards and answer are necessary to ultimately provide the solution to a task. As we will discuss in this study, such an integration of tools, methods, logic, reasoning and iterative solution can be implemented through the deployment of a multi-agent system driven by sophisticated Large Language Models (LLMs).
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    LLMs
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib25" title="">
      25
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib26" title="">
      26
     </a>
     ]
    </cite>
    have represented a paradigm shift in modeling problems across a spectrum of scientific and engineering domains
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib27" title="">
      27
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib28" title="">
      28
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib29" title="">
      29
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib30" title="">
      30
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib8" title="">
      8
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib31" title="">
      31
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib32" title="">
      32
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib33" title="">
      33
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib34" title="">
      34
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib35" title="">
      35
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib36" title="">
      36
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib37" title="">
      37
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib38" title="">
      38
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib39" title="">
      39
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib40" title="">
      40
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib41" title="">
      41
     </a>
     ]
    </cite>
    . Such models, built upon attention mechanism and transformer architectures
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib42" title="">
      42
     </a>
     ]
    </cite>
    , have emerged as powerful tools recently in the field of materials science and related areas, contributing to various aspects ranging from knowledge retrieval to modeling, design, and analysis. For example, models such as ChatGPT and the underlying GPT-4 architecture
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib43" title="">
      43
     </a>
     ]
    </cite>
    , part of the Generative Pretrained Transformer (GPT) class, demonstrate exceptional proficiency in mastering human language, coding
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib44" title="">
      44
     </a>
     ]
    </cite>
    , logic and reasoning
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib45" title="">
      45
     </a>
     ]
    </cite>
    . Recent studies highlight their ability to proficiently program numerical algorithms and troubleshoot code errors across several programming languages like Python, MATLAB, Julia, C, and C++
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib46" title="">
      46
     </a>
     ]
    </cite>
    . The GPT class of LLMs has also represented a new paradigm in simulating and predicting the materials behavior under different conditions
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib28" title="">
      28
     </a>
     ]
    </cite>
    , a field of materials science often reserved for conventional deep learning frameworks
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib47" title="">
      47
     </a>
     ]
    </cite>
    such as Convolutional Neural Networks
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib48" title="">
      48
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib49" title="">
      49
     </a>
     ]
    </cite>
    , Generative Adversarial Networks
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib50" title="">
      50
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib51" title="">
      51
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib52" title="">
      52
     </a>
     ]
    </cite>
    , Recurrent Neural Networks22,54,55
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib20" title="">
      20
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib53" title="">
      53
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib54" title="">
      54
     </a>
     ]
    </cite>
    ,and Graph Neural Networks
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib23" title="">
      23
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib55" title="">
      55
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib56" title="">
      56
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib57" title="">
      57
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib58" title="">
      58
     </a>
     ]
    </cite>
    . Moreover, due to their proficiency in processing and comprehending vast amount of different types of multimodal data, LLMs show promising capabilities in materials analysis and prediction application including key knowledge retrieval
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib35" title="">
      35
     </a>
     ]
    </cite>
    , general language tasks, hypothesis generation
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib29" title="">
      29
     </a>
     ]
    </cite>
    , and structure-to-property mapping
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib28" title="">
      28
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib59" title="">
      59
     </a>
     ]
    </cite>
    .
   </p>
  </div>
  <figure class="ltx_figure" id="S1.F2">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="838" id="S1.F2.g1" src="/html/2402.04268/assets/image_generic.png" width="1635"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 2:
    </span>
    <span class="ltx_text ltx_font_bold" id="S1.F2.2.1">
     A generic flowchart showing the dynamic interaction between the multi-agent team members organized by the group chat manager to solve protein design and analysis problems.
    </span>
    The manager selects the working agents to collaborate in the team work based on the current context of the chat, thus forming close interactions and enabling mutual corrections.
   </figcaption>
  </figure>
  <div class="ltx_para ltx_noindent" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    At the same time, LLMs are typically not best equipped to solve specific physics-based forward and inverse design tasks, and are often focused on leveraging their conversational capabilities. Here, LLMs have been instrumental in powering conversable AI agents, facilitating the transition from AI-human conversations to AI-AI or AI-tools interactions for increased autonomy.
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib31" title="">
      31
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib35" title="">
      35
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib60" title="">
      60
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib61" title="">
      61
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib62" title="">
      62
     </a>
     ]
    </cite>
    This capability represents a significant advancement, enabling intelligent mediation, fostering interdisciplinary collaboration, and driving innovation across disparate domains, including materials analysis, design, and manufacturing. The overall process could be deemed as adapting a problem-solving strategy dictated and directed by the AI system comprised of different agents. Thereby, the entire process can be AI automated with reduced or little human intervention. Depending on the complexity of the problem, using the idea of labor division, the agents have the capability to break the overall task into subtasks for which different agents or tools are used consecutively to iteratively solve the problem until all subtasks have accomplished and the solution has achieved. There is no intrinsic limitation in defining the type of tools, making the multi-agent model a versatile approach in addressing problems across scales and disciplines. The tools could range from a simple linear mathematical function to sophisticated deep neural network architectures. The multi-agent strategy has been explored in materials and mechanics applications through in earlier work
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib29" title="">
      29
     </a>
     ]
    </cite>
    and was further explored in the context of molecular modeling tasks
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib35" title="">
      35
     </a>
     ]
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p6">
   <p class="ltx_p" id="S1.p6.1">
    In this paper, we propose a multi-agent strategy to the protein design problems by introducing ProtAgents, a multi-agent modeling framework to solve protein-related analysis and design problems by leveraging customized functions across domains and disciplines. The core underpinning concept of the multi-agent systems is the use state-of-the-art LLMs combined with a series of other tools. The LLM backbone demonstrate exceptional abilities in analysis, rational thinking, and strategic planning, essential for complex problem-solving. Leveraged by these capabilities, the proposed model aims to reduce the need for human intervention and intelligence at different stages of protein design. The agent model consists a suite of AI and physics based components such as:
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p7">
   <ul class="ltx_itemize" id="S1.I1">
    <li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i1.p1">
      <p class="ltx_p" id="S1.I1.i1.p1.1">
       Physics simulators: obtain new physical data from simulations, specifically normal modes and vibrational properties by solving partial differential equations (PDEs)
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i2.p1">
      <p class="ltx_p" id="S1.I1.i2.p1.1">
       Generative AI model: conditional/unconditional
       <span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.1">
        de novo
       </span>
       protein design, based on a denoising diffusion model
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i3.p1">
      <p class="ltx_p" id="S1.I1.i3.p1.1">
       Fine-tuned transformer model: predict mechanical properties of proteins from their sequence
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para ltx_noindent" id="S1.I1.i4.p1">
      <p class="ltx_p" id="S1.I1.i4.p1.1">
       Retrieval agent: retrieve new data from a knowledge database of scientific literature
      </p>
     </div>
    </li>
   </ul>
   <p class="ltx_p" id="S1.p7.1">
    The resulting model has the ability to go beyond the conventional DL models by integrating new physical data or information across disciplines, for instance via writing and executing code that solves differential equations or other physics-based numerical methods, or that conducts retrieval augmented generation (RAG)
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib63" title="">
      63
     </a>
     ]
    </cite>
    . A tool-baked agent has access to various tools and functions with different functionalities that may be called upon, for instance, to predict a specific protein property or to obtain new physical data such as natural frequency from physics-based simulations. The versatility of the approach in solving complex tasks is exhibited by providing a series of experiments in the context of proteins design, modeling, and data analysis.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p8">
   <p class="ltx_p" id="S1.p8.1">
    The plan of this paper is as follows. In Section
    <a class="ltx_ref" href="#S2" title="2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    , we present an overview of the multi-agent framework developed to tackle multi-objective complex tasks. Subsequently, we delve into a series of experiments where each task is initially introduced, followed by a detailed examination of various aspects throughout the problem-solving process by the multi-agent teamwork. A comprehensive discussion regarding the multi-agent framework and future prospects is provided in Section
    <a class="ltx_ref" href="#S3" title="3 Conclusions ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
     <span class="ltx_text ltx_ref_tag">
      3
     </span>
    </a>
    .
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Results and Discussion
  </h2>
  <div class="ltx_para ltx_noindent" id="S2.p1">
   <p class="ltx_p" id="S2.p1.1">
    We present a series of computational experiments aimed at evaluating the effectiveness and potential of a multi-agent modeling framework for various challenges within the domain of protein modeling, design, and analysis. The multi-agent framework consists of a team of agents, each powered by a state-of-the-art general purpose large language model, GPT-4,
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib43" title="">
      43
     </a>
     ]
    </cite>
    accessed via the OpenAI API
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib64" title="">
      64
     </a>
     ]
    </cite>
    and characterized by a unique profile that details its role, and communication protocols, such as sharing information and engaging with humans via language as shown in Figure
    <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    a. Furthermore, agents are given access to a set of tools with various functionalities across domains. As shown in Figure
    <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    b each function is characterized by a descriptive profile and input parameters. The outline of the proposed multi-agent framework is shown in Figure
    <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    c, illustrating the collaborative efforts of a team of agents with the following entities
   </p>
  </div>
  <figure class="ltx_figure" id="S2.F3">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="170" id="S2.F3.g1" src="/html/2402.04268/assets/image_exp2.png" width="598"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 3:
    </span>
    <span class="ltx_text ltx_font_bold" id="S2.F3.4.1">
     Overview of the multi-agent work to solve the complex task posed in experiment II, Section
     <a class="ltx_ref" href="#S2.SS2" title="2.2 Experiment II: De novo protein design using Chroma ‣ 2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
      <span class="ltx_text ltx_ref_tag">
       2.2
      </span>
     </a>
    </span>
    . First the multi-agent uses Chroma to generate
    <span class="ltx_text ltx_font_italic" id="S2.F3.5.2">
     de novo
    </span>
    protein sequences and then computes natural frequencies and secondary structures content for the generated structures. Next, from
    <span class="ltx_text ltx_font_italic" id="S2.F3.6.3">
     de novo
    </span>
    AA sequences, the model finds the 3D folded structures using OmegaFold and finally computes the frequencies and secondary structure content for the protein structures. The results obtained from the Chroma and OmegaFold 3D protein structures are compared in Figure
    <a class="ltx_ref" href="#S2.F5" title="Figure 5 ‣ 2.3 Experiment III: Protein design conditioned on the protein CATH class ‣ 2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
     <span class="ltx_text ltx_ref_tag">
      5
     </span>
    </a>
    .
   </figcaption>
  </figure>
  <div class="ltx_para ltx_noindent" id="S2.p2">
   <ul class="ltx_itemize" id="S2.I1">
    <li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S2.I1.i1.p1">
      <p class="ltx_p" id="S2.I1.i1.p1.1">
       “User”: human that poses the question
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S2.I1.i2.p1">
      <p class="ltx_p" id="S2.I1.i2.p1.1">
       “Planner”: develops a plan to solve the task. Also suggests the functions to be executed.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S2.I1.i3.p1">
      <p class="ltx_p" id="S2.I1.i3.p1.1">
       “Assistant”: who has access to all the customized functions, methods, and APIs and executes them to find or compute the relevant data necessary to solve the task
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S2.I1.i4" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para ltx_noindent" id="S2.I1.i4.p1">
      <p class="ltx_p" id="S2.I1.i4.p1.1">
       “Critic”: Responsible for providing feedback about the plan developed by “planner” as well as analyzing the results and handling the possible mistakes and providing the output to the user.
      </p>
     </div>
    </li>
   </ul>
   <p class="ltx_p" id="S2.p2.1">
    The agents are organized into a team structure, overseen by a manager who coordinates overall communication among the agents. A generic structure showing the dynamic collaboration between the team of agents proposed in the current study is depicted in Figure
    <a class="ltx_ref" href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    . Moreover, Table
    <a class="ltx_ref" href="#S2.T1" title="Table 1 ‣ 2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    lists the full profile for the agents recruited in our multi-agent framework. Further details can be found in the
    <span class="ltx_text ltx_font_bold" id="S2.p2.1.1">
     Materials and Methods
    </span>
    section
    <a class="ltx_ref" href="#S4" title="4 Materials and Methods ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
     <span class="ltx_text ltx_ref_tag">
      4
     </span>
    </a>
    .
   </p>
  </div>
  <figure class="ltx_table" id="S2.T1">
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 1:
    </span>
    <span class="ltx_text ltx_font_bold" id="S2.T1.2.1">
     The profiles of the agents implemented in the current study to solve multi-objective tasks in the context of protein design and analysis.
    </span>
   </figcaption>
   <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S2.T1.3">
    <thead class="ltx_thead">
     <tr class="ltx_tr" id="S2.T1.3.1.1">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T1.3.1.1.1">
       <span class="ltx_text ltx_font_bold" id="S2.T1.3.1.1.1.1">
        Agent #
       </span>
      </th>
      <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T1.3.1.1.2">
       <span class="ltx_text ltx_font_bold" id="S2.T1.3.1.1.2.1">
        Agent role
       </span>
      </th>
      <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="S2.T1.3.1.1.3">
       <span class="ltx_inline-block ltx_align_top" id="S2.T1.3.1.1.3.1">
        <span class="ltx_p" id="S2.T1.3.1.1.3.1.1">
         <span class="ltx_text ltx_font_bold" id="S2.T1.3.1.1.3.1.1.1">
          Agent profile
         </span>
        </span>
       </span>
      </th>
     </tr>
    </thead>
    <tbody class="ltx_tbody">
     <tr class="ltx_tr" id="S2.T1.3.2.1">
      <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.3.2.1.1">
       1
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.3.2.1.2">
       user_proxy
      </td>
      <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T1.3.2.1.3">
       <span class="ltx_inline-block ltx_align_top" id="S2.T1.3.2.1.3.1">
        <span class="ltx_p" id="S2.T1.3.2.1.3.1.1">
         user_proxy. Plan execution needs to be approved by user_proxy
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S2.T1.3.3.2">
      <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.3.3.2.1">
       2
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.3.3.2.2">
       Planner
      </td>
      <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T1.3.3.2.3">
       <span class="ltx_inline-block ltx_align_top" id="S2.T1.3.3.2.3.1">
        <span class="ltx_p" id="S2.T1.3.3.2.3.1.1">
         Planner. You develop a plan. Begin by explaining the plan. Revise the plan based on feedback from the critic and user_proxy, until user_proxy approval.
The plan may involve calling custom function for retrieving knowledge, designing proteins, and computing and analyzing protein properties. You include the function names in the plan and the necessary parameters.
If the plan involves retrieving knowledge, retain all the key points of the query asked by the user for the input message.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S2.T1.3.4.3">
      <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.3.4.3.1">
       3
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.3.4.3.2">
       Assistant
      </td>
      <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T1.3.4.3.3">
       <span class="ltx_inline-block ltx_align_top" id="S2.T1.3.4.3.3.1">
        <span class="ltx_p" id="S2.T1.3.4.3.3.1.1">
         Assistant. You have access to all the custom functions. You focus on executing the functions suggested by the planner or the critic. You also have the ability to prepare the required input parameters for the functions.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S2.T1.3.5.4">
      <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.3.5.4.1">
       4
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.3.5.4.2">
       Critic
      </td>
      <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T1.3.5.4.3">
       <span class="ltx_inline-block ltx_align_top" id="S2.T1.3.5.4.3.1">
        <span class="ltx_p" id="S2.T1.3.5.4.3.1.1">
         user_proxy. You double-check the plan, especially the functions and function parameters. Check whether the plan included all the necessary parameters for the suggested function. You provide feedback.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S2.T1.3.6.5">
      <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T1.3.6.5.1">
       5
      </td>
      <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T1.3.6.5.2">
       Group chat manager
      </td>
      <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="S2.T1.3.6.5.3">
       <span class="ltx_inline-block ltx_align_top" id="S2.T1.3.6.5.3.1">
        <span class="ltx_p" id="S2.T1.3.6.5.3.1.1">
         You repeat the following steps: Dynamically selecting a speaker, collecting responses, and broadcasting the message to the group.
        </span>
       </span>
      </td>
     </tr>
    </tbody>
   </table>
  </figure>
  <div class="ltx_para ltx_noindent" id="S2.p3">
   <p class="ltx_p" id="S2.p3.1">
    It is noteworthy that critical issues in the realm of protein design surpass the capabilities of mere Python code writing and execution. Instead, addressing these challenges necessitates the utilization of external tools specifically tailored for protein design and analysis, and the writing, adaptation, correction and execution of code depends nonlinearly on the progression of the solution strategy that is developed by the system.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S2.p4">
   <p class="ltx_p" id="S2.p4.1">
    The tools are incorporated into the model via the Assistant agent who oversees executing the tools. To assess the performance of the multi-agent framework in handling complex interdisciplinary tasks, we have defined a rich library of functions each with special powers in solving the protein problems. Each function has a distinct profile describing its functionally and takes one or more required entities as the input. The functions provide the ability to, for instance, retrieve knowledge, perform protein folding, analyze the secondary structure, and predict some parameters through a pre-trained autoregressive language model. Additionally, a function can carry out simulations to compute the protein natural frequencies, thus allowing the model to integrate the new physics-based data. A full list of functions implemented in the current study is provided in
    <span class="ltx_text ltx_font_bold" id="S2.p4.1.1">
     Table S1
    </span>
    in the supplementary material.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S2.p5">
   <p class="ltx_p" id="S2.p5.1">
    Given the complexities residing in the protein design problems, the primary contribution of our multi-agent framework lies in assessing whether the team of agents can discern the requisite tools for a given query and evaluating the framework’s capability to initiate the execution of these tools, along with providing the necessary inputs. The designated tasks are intentionally designed to be sufficiently complex, involving multiple subtasks where, for some cases, the execution of each depends on the successful completion of the preceding ones. This design showcases the model’s capacity for the automated handling of intricate tasks, eliminating or substantially reducing the need for human intervention. Although the multi-agent framework allows for the human intervention at different stages, we skip that to further examine the team’s capability in handling different possible situations, for instance in case of a failure.
   </p>
  </div>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1
    </span>
    Experiment I: Knowledge retrieval, computations, and analysis
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     As the first example, we pose a task which involves a multi-step knowledge retrieval, analysis, and computations for a set of protein PDB identifiers. We start the first round of conversation by posing the following question:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p2">
    <blockquote class="ltx_quote" id="S2.SS1.p2.1">
     <p class="ltx_p" id="S2.SS1.p2.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS1.p2.1.1.1">
       user_proxy (to chat_manager):
      </span>
     </p>
     <p class="ltx_p" id="S2.SS1.p2.1.2">
      <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.2.1">
       Can you provide examples of protein names whose mechanical properties have been studied through experiments?
      </span>
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS1.p2.2">
     The planer then correctly suggests the function “retrieve_content” to be executed with the argument “examples of protein names whose mechanical properties have been studied through experiments”. Upon execution of the function, the assistant provides us with a list of protein names. Upon inspection, we find that the agent has successfully identified experimentally studied proteins, despite an abundance of information on proteins studied theoretically, for instance, through coarse-grain simulations. Since we are interested in the PDB ids, we continue the chat by a follow-up question “Can you provide me with the PDB ids for these proteins?” when “user_proxy” is being asked to provide feedback to chat manager. Again, the planner suggests “retrieve_content” function with the following message
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p3">
    <blockquote class="ltx_quote" id="S2.SS1.p3.1">
     <p class="ltx_p" id="S2.SS1.p3.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS1.p3.1.1.1">
       Planner (to chat_manager):
       <br class="ltx_break"/>
      </span>
     </p>
     <p class="ltx_p" id="S2.SS1.p3.1.2">
      <span class="ltx_text ltx_font_italic" id="S2.SS1.p3.1.2.1">
       ***** Suggested function Call: retrieve_content *****
Arguments:
      </span>
      {
      <span class="ltx_text ltx_font_italic" id="S2.SS1.p3.1.2.2">
       "message": "PDB ids for I27 domain from titin, fibronectin type III domains, E2lip3, T4 lysozyme, ubiquitin, titin immunoglobulin domains, cell adhesion molecule, spectrin repeats, and tenascin"
      </span>
      }
      <span class="ltx_text ltx_font_italic" id="S2.SS1.p3.1.2.3">
      </span>
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS1.p3.2">
     The “
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p3.2.1">
      Assistant
     </span>
     ” agent then calls the function and gives the following output:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p4">
    <blockquote class="ltx_quote" id="S2.SS1.p4.1">
     <p class="ltx_p" id="S2.SS1.p4.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS1.p4.1.1.1">
       Assistant (to chat_manager):
       <br class="ltx_break"/>
      </span>
     </p>
     <p class="ltx_p" id="S2.SS1.p4.1.2">
      <span class="ltx_text ltx_font_italic" id="S2.SS1.p4.1.2.1">
       Here are the PDB IDs for the proteins you mentioned:
       <br class="ltx_break"/>
       <br class="ltx_break"/>
       1. I27 domain from titin: 1wit
       <br class="ltx_break"/>
       2. Ubiquitin: 1ubq
       <br class="ltx_break"/>
       3. T4 lysozyme: 1nct
       <br class="ltx_break"/>
       4. Titin immunoglobulin domains: 1tit, 1qjo
       <br class="ltx_break"/>
       5. E2lip3: 1hz6/2ptl
       <br class="ltx_break"/>
       6. Tenascin: 1ten
       <br class="ltx_break"/>
       7. Spectrin repeats: 1emb
       <br class="ltx_break"/>
       8. FnIII: 1g1c, 1fnh, 1vsc, 1cfc, 1fnf/1ttf/1ttg
       <br class="ltx_break"/>
       9. Cell adhesion molecule: 1bni/1bnr, 1b6i, 1rsy/1dqv, 1aj3, 1ksr/1whl, 1u4q, 1hci, 1n11
      </span>
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS1.p4.2">
     Upon careful examination of the results, we observe that, despite all the PDB ids exist in the source database, the PDB ids do not quite match with the protein names except for a few cases. Nevertheless, note that the error is caused by the poor performance of the “
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p4.2.1">
      retrieve_content
     </span>
     ” function and the team of agents cannot mitigate that as they have no access to the knowledge database. As such, we continue to test the agent-team capability in more challenging queries centered around computational tasks and physics-based simulations by assigning the following task in the next round of conversation
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p5">
    <blockquote class="ltx_quote" id="S2.SS1.p5.1">
     <p class="ltx_p" id="S2.SS1.p5.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS1.p5.1.1.1">
       user_proxy (to chat_manager):
       <br class="ltx_break"/>
      </span>
     </p>
     <p class="ltx_p" id="S2.SS1.p5.1.2">
      <span class="ltx_text ltx_font_italic" id="S2.SS1.p5.1.2.1">
       For the first 10 protein PDB ids in the list, if the AA sequence length of the protein is less than 128, do the following: (a) analyze the secondary structure of the protein, (b) compute its first 13 natural frequencies, (c) determine its structure classification.
      </span>
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS1.p5.2">
     The above is a complex multi-step analysis and computation task encompasses aspects such as secondary structures analysis, natural frequency calculations, and structure classification. Additionally, the task is subject to an initial condition that must be satisfied before proceeding through the next sequence of steps, adding an extra layer of complexity. In response, the planner comes up with a detailed plan which consists of all the actions that need to be taken to complete the task. Moreover, the plan mentions all the corresponding functions that need to be executed to accomplish the task. More importantly, the “
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p5.2.1">
      planner
     </span>
     ” perfectly realizes to fetch the protein structures first before starting to analyze the secondary structure, although it was not explicitly mentioned in the task query.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p6">
    <p class="ltx_p" id="S2.SS1.p6.1">
     The teamwork proceeds by a follow-up feedback provided by the “
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p6.1.1">
      critic
     </span>
     ” agent about all the plan steps and functions which is concluded by the following statement
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p7">
    <blockquote class="ltx_quote" id="S2.SS1.p7.1">
     <p class="ltx_p" id="S2.SS1.p7.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS1.p7.1.1.1">
       critic (to chat_manager):
       <br class="ltx_break"/>
      </span>
     </p>
     <p class="ltx_p" id="S2.SS1.p7.1.2">
      <span class="ltx_text ltx_font_italic" id="S2.SS1.p7.1.2.1">
       Overall, the plan rightly identifies all the necessary functions and respective parameters for each step. It illustrates a good understanding of what needs to be done to fulfill the user request. Good job!
      </span>
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS1.p7.2">
     Therefore, the positive feedback from the “
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p7.2.1">
      critic
     </span>
     ” further supports the good performance of the planner in addressing all the critical steps required to accomplish the tasks.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p8">
    <p class="ltx_p" id="S2.SS1.p8.1">
     The “
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p8.1.1">
      assistant
     </span>
     ” agent then follows the plan by calling and executing the corresponding functions, starting with AA length calculation, until all the steps have been undertaken. The results show that all the inputs to the functions are properly identified and provided and the functions are executed without any error. The conditional statement included in the tasks is also correctly satisfied for each protein, that is the computations are conducted only if the sequence length is less than 128 and are emitted otherwise. For instance, for the protein with PDB id “
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p8.1.2">
      1hz6
     </span>
     ” the AA length is returned as 216 by the “
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p8.1.3">
      assistant
     </span>
     ” which is then followed by the following message from the “
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p8.1.4">
      critic
     </span>
     ”
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p9">
    <blockquote class="ltx_quote" id="S2.SS1.p9.1">
     <p class="ltx_p" id="S2.SS1.p9.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS1.p9.1.1.1">
       critic (to chat_manager):
       <br class="ltx_break"/>
      </span>
     </p>
     <p class="ltx_p" id="S2.SS1.p9.1.2">
      <span class="ltx_text ltx_font_italic" id="S2.SS1.p9.1.2.1">
       The length of the amino-acid sequence for the PDB id ’1hz6’ is 216, which is greater than 128. Therefore, we will not perform the steps (a) analyze the secondary structure of the protein, (b) compute its first 13 natural frequencies, and (c) determine its structure classification for the ’1hz6’.
       <br class="ltx_break"/>
       <br class="ltx_break"/>
       Moving to the next PDB id in the list…
      </span>
     </p>
    </blockquote>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p10">
    <p class="ltx_p" id="S2.SS1.p10.1">
     After completion of all the tasks, the assistant returns a summary of all the results for each protein as representatively shown below for PDB id “
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p10.1.1">
      1wit
     </span>
     ”:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p11">
    <blockquote class="ltx_quote" id="S2.SS1.p11.1">
     <p class="ltx_p" id="S2.SS1.p11.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS1.p11.1.1.1">
       assistant (to chat_manager):
       <br class="ltx_break"/>
      </span>
     </p>
     <p class="ltx_p" id="S2.SS1.p11.1.2">
      <span class="ltx_text ltx_font_italic" id="S2.SS1.p11.1.2.1">
       For PDB id ’1wit’:
       <br class="ltx_break"/>
       - It has an amino acid sequence length of 93.
       <br class="ltx_break"/>
       - The analysis of its secondary structure yielded the following composition: H: 0%, B: 3.23%, E: 51.61%, G: 3.23%, I: 0%, T: 13.98%, S: 5.38%, P: 0%, -: 22.58%.
       <br class="ltx_break"/>
       - Its first 13 natural frequencies are [4.3755, 5.0866, 5.5052, 6.7967, 7.908, 8.1947, 9.0166, 9.8528, 11.0632, 11.3968, 11.7355, 12.1279, 12.3498].
       <br class="ltx_break"/>
       - Its CATH classification is 2.60.40.10.
       <br class="ltx_break"/>
      </span>
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS1.p11.2">
     The results suggest that the framework effectively retains all outputs, demonstrating its strong memory even in the face of diverse and extended results. As the last round of conversation, we ask to save all the results which allows us to load them at later time for other purposes:
    </p>
    <blockquote class="ltx_quote" id="S2.SS1.p11.3">
     <p class="ltx_p" id="S2.SS1.p11.3.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS1.p11.3.1.1">
       user_proxy (to chat_manager):
       <br class="ltx_break"/>
      </span>
     </p>
     <p class="ltx_p" id="S2.SS1.p11.3.2">
      <span class="ltx_text ltx_font_italic" id="S2.SS1.p11.3.2.1">
       Save all the results into a csv file where each row corresponds to a protein and each column represent a protein property, utilizing proper identifiers.
      </span>
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS1.p11.4">
     In response, the planner suggests to call the python function “
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p11.4.1">
      save_to_csv_file
     </span>
     ”. The main task here is to generate the dictionary of results in JSON and with appropriate structure as instructed by the user. However, we see that upon generating the JSON data and inputting it into the function by the "
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p11.4.2">
      assistant
     </span>
     " agent, the following error occurs:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p12">
    <blockquote class="ltx_quote" id="S2.SS1.p12.1">
     <p class="ltx_p" id="S2.SS1.p12.1.1">
      <span class="ltx_text ltx_font_italic" id="S2.SS1.p12.1.1.1">
       ***** Response from calling function "save_to_csv_file" *****
       <br class="ltx_break"/>
       Error: Expecting ’,’ delimiter: line 1 column 141 (char 140)
      </span>
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS1.p12.2">
     Without any human intervention, the agent team is able to resolve the issue by mutual correction. In particular, the “
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p12.2.1">
      critic
     </span>
     ” identifies the cause of error by writing
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p13">
    <blockquote class="ltx_quote" id="S2.SS1.p13.1">
     <p class="ltx_p" id="S2.SS1.p13.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS1.p13.1.1.1">
       Critic (to chat_manager):
       <br class="ltx_break"/>
      </span>
     </p>
     <p class="ltx_p" id="S2.SS1.p13.1.2">
      <span class="ltx_text ltx_font_italic" id="S2.SS1.p13.1.2.1">
       It seems like there is an error in the JSON format being used to feed data into the csv conversion function. The JSON string appears to be improperly formed leading the function to fail. The values for "Secondary Structure" and "First 13 Frequencies" are stringified JSON objects themselves, which maybe causing
      </span>
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS1.p13.2">
     The “
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p13.2.1">
      assistant
     </span>
     ” then reconstructs the JSON file from the output results and is able to successfully execute the function and thus save the results in a csv file as shown in
     <span class="ltx_text ltx_font_bold" id="S2.SS1.p13.2.2">
      Table
      <a class="ltx_ref" href="#S2.T2" title="Table 2 ‣ 2.1 Experiment I: Knowledge retrieval, computations, and analysis ‣ 2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
     </span>
     . The complete group chat records can be found in
     <span class="ltx_text ltx_font_bold" id="S2.SS1.p13.2.3">
      Table S2
     </span>
     of the Supplementary material.
    </p>
   </div>
   <figure class="ltx_table" id="S2.T2">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 2:
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.T2.2.1">
      The results generated by the group chat in the form of a CSV file, without human intervention, for the experiment I, Section
      <a class="ltx_ref" href="#S2.SS1" title="2.1 Experiment I: Knowledge retrieval, computations, and analysis ‣ 2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
       <span class="ltx_text ltx_ref_tag">
        2.1
       </span>
      </a>
      .
     </span>
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S2.T2.3">
     <thead class="ltx_thead">
      <tr class="ltx_tr" id="S2.T2.3.1.1">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T2.3.1.1.1">
        <span class="ltx_text ltx_font_bold" id="S2.T2.3.1.1.1.1">
         Protein ID #
        </span>
       </th>
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T2.3.1.1.2">
        <span class="ltx_text ltx_font_bold" id="S2.T2.3.1.1.2.1">
         Amino Acid Length
        </span>
       </th>
       <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="S2.T2.3.1.1.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T2.3.1.1.3.1">
         <span class="ltx_p" id="S2.T2.3.1.1.3.1.1">
          <span class="ltx_text ltx_font_bold" id="S2.T2.3.1.1.3.1.1.1">
           Secondary Structure
          </span>
         </span>
        </span>
       </th>
       <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="S2.T2.3.1.1.4">
        <span class="ltx_inline-block ltx_align_top" id="S2.T2.3.1.1.4.1">
         <span class="ltx_p" id="S2.T2.3.1.1.4.1.1">
          <span class="ltx_text ltx_font_bold" id="S2.T2.3.1.1.4.1.1.1">
           First 13 Frequencies
          </span>
         </span>
        </span>
       </th>
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T2.3.1.1.5">
        <span class="ltx_text ltx_font_bold" id="S2.T2.3.1.1.5.1">
         CATH Classification
        </span>
       </th>
      </tr>
     </thead>
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S2.T2.3.2.1">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.3.2.1.1">
        1wit
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.3.2.1.2">
        93
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T2.3.2.1.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T2.3.2.1.3.1">
         <span class="ltx_p" id="S2.T2.3.2.1.3.1.1">
          [’H’: 0.0, ’B’: 3.23, ’E’: 51.61, ’G’: 3.23, ’I’: 0.0, ’T’: 13.98, ’S’: 5.38, ’P’: 0.0, ’-’: 22.58]
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T2.3.2.1.4">
        <span class="ltx_inline-block ltx_align_top" id="S2.T2.3.2.1.4.1">
         <span class="ltx_p" id="S2.T2.3.2.1.4.1.1">
          [4.3755, 5.0866, 5.5052, 6.7967, 7.908, 8.1947, 9.0166, 9.8528, 11.0632, 11.3968, 11.7355, 12.1279, 12.3498]
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.3.2.1.5">
        2.60.40.10
       </td>
      </tr>
      <tr class="ltx_tr" id="S2.T2.3.3.2">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.3.3.2.1">
        1ubq
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.3.3.2.2">
        76
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T2.3.3.2.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T2.3.3.2.3.1">
         <span class="ltx_p" id="S2.T2.3.3.2.3.1.1">
          [’H’: 15.79, ’B’: 2.63, ’E’: 31.58, ’G’: 7.89, ’I’: 0.0, ’T’: 15.79, ’S’: 5.26, ’P’: 5.26, ’-’: 15.79]
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T2.3.3.2.4">
        <span class="ltx_inline-block ltx_align_top" id="S2.T2.3.3.2.4.1">
         <span class="ltx_p" id="S2.T2.3.3.2.4.1.1">
          [0.7722, 1.0376, 1.5225, 1.6534, 2.5441, 2.9513, 3.2873, 3.7214, 4.1792, 4.3437, 4.3908, 4.6551, 5.1631]
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.3.3.2.5">
        3.10.20.90
       </td>
      </tr>
      <tr class="ltx_tr" id="S2.T2.3.4.3">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.3.4.3.1">
        1nct
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.3.4.3.2">
        106
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T2.3.4.3.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T2.3.4.3.3.1">
         <span class="ltx_p" id="S2.T2.3.4.3.3.1.1">
          [’H’: 0.0, ’B’: 4.08, ’E’: 35.71, ’G’: 0.0, ’I’: 0.0, ’T’: 2.04, ’S’: 21.43, ’P’: 0.0, ’-’: 36.73]
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T2.3.4.3.4">
        <span class="ltx_inline-block ltx_align_top" id="S2.T2.3.4.3.4.1">
         <span class="ltx_p" id="S2.T2.3.4.3.4.1.1">
          [3.6644, 4.425, 6.5351, 6.7432, 7.1409, 7.1986, 9.0207, 9.2223, 10.3163, 10.7313, 11.5299, 11.6373, 12.5606]
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.3.4.3.5">
        2.60.40.10
       </td>
      </tr>
      <tr class="ltx_tr" id="S2.T2.3.5.4">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.3.5.4.1">
        1tit
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.3.5.4.2">
        98
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T2.3.5.4.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T2.3.5.4.3.1">
         <span class="ltx_p" id="S2.T2.3.5.4.3.1.1">
          [’H’: 0.0, ’B’: 1.12, ’E’: 35.96, ’G’: 0.0, ’I’: 0.0, ’T’: 6.74, ’S’: 17.98, ’P’: 0.0, ’-’: 38.2]
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T2.3.5.4.4">
        <span class="ltx_inline-block ltx_align_top" id="S2.T2.3.5.4.4.1">
         <span class="ltx_p" id="S2.T2.3.5.4.4.1.1">
          [5.5288, 5.9092, 8.2775, 8.6267, 9.3391, 9.8783, 10.1607, 11.451, 11.5896, 11.7052, 12.1498, 12.6082, 13.8622]
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.3.5.4.5">
        2.60.40.10
       </td>
      </tr>
      <tr class="ltx_tr" id="S2.T2.3.6.5">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.3.6.5.1">
        1qjo
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.3.6.5.2">
        80
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T2.3.6.5.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T2.3.6.5.3.1">
         <span class="ltx_p" id="S2.T2.3.6.5.3.1.1">
          [’H’: 0.0, ’B’: 2.5, ’E’: 40.0, ’G’: 0.0, ’I’: 0.0, ’T’: 8.75, ’S’: 13.75, ’P’: 0.0, ’-’: 35.0]
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T2.3.6.5.4">
        <span class="ltx_inline-block ltx_align_top" id="S2.T2.3.6.5.4.1">
         <span class="ltx_p" id="S2.T2.3.6.5.4.1.1">
          [3.8578, 4.4398, 5.4886, 5.7815, 6.6332, 6.9269, 7.2329, 7.6453, 8.2545, 8.3076, 8.6118, 8.7135, 8.8546]
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.3.6.5.5">
        2.40.50.100
       </td>
      </tr>
      <tr class="ltx_tr" id="S2.T2.3.7.6">
       <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T2.3.7.6.1">
        2ptl
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T2.3.7.6.2">
        78
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="S2.T2.3.7.6.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T2.3.7.6.3.1">
         <span class="ltx_p" id="S2.T2.3.7.6.3.1.1">
          [’H’: 15.38, ’B’: 1.28, ’E’: 30.77, ’G’: 0.0, ’I’: 0.0, ’T’: 7.69, ’S’: 19.23, ’P’: 0.0, ’-’: 25.64]
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="S2.T2.3.7.6.4">
        <span class="ltx_inline-block ltx_align_top" id="S2.T2.3.7.6.4.1">
         <span class="ltx_p" id="S2.T2.3.7.6.4.1.1">
          [0.0386, 0.1161, 0.2502, 0.5921, 1.1515, 1.5257, 2.0924, 2.6793, 3.4292, 3.9289, 4.2172, 4.6878, 4.8022]
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T2.3.7.6.5">
        3.10.20.10
       </td>
      </tr>
     </tbody>
    </table>
   </figure>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2
    </span>
    Experiment II:
    <span class="ltx_text ltx_font_italic" id="S2.SS2.1.1">
     De novo
    </span>
    protein design using Chroma
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     An important characteristic of the multi-agent model is its capability in handling very complex tasks in the context of protein design and analysis. This partly stems from the possibility of incorporating customized functions in the model for various purposes from knowledge retrieval to performing physics-based simulations. In this example, we explore the model’s performance in using the state-of-the art models in
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.1">
      de novo
     </span>
     protein design, Chroma
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib15" title="">
       15
      </a>
      ]
     </cite>
     , and protein folding, OmegaFold
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib4" title="">
       4
      </a>
      ]
     </cite>
     . Chroma offers a unified approach for protein design that can directly sample novel protein structures and sequences with the possibility to direct the generative design towards the desired functions and properties by appropriate conditioning. OmegaFold is a state-of-the-art folding method without the need of using multiple sequence alignments (MSA) to predict the three-dimensional folded protein structure given its AA sequence.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p2">
    <p class="ltx_p" id="S2.SS2.p2.1">
     In this experiment, we formulate a complex multi-step task with the objective of comparing the two models based on various structural and physical features derived from the folded structures obtained through Chroma and OmegaFold2. We pose the following task through the “
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p2.1.1">
      user_proxy
     </span>
     ” agent:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p3">
    <blockquote class="ltx_quote" id="S2.SS2.p3.1">
     <p class="ltx_p" id="S2.SS2.p3.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS2.p3.1.1.1">
       user_proxy (to chat_manager):
       <br class="ltx_break"/>
      </span>
     </p>
     <p class="ltx_p" id="S2.SS2.p3.1.2">
      <span class="ltx_text ltx_font_italic" id="S2.SS2.p3.1.2.1">
       Design three proteins with sequence length of 120 and analyze their secondary structure and first 10 frequencies. Then fold the proteins and repeat the analysis. Save all the results (including the AA sequences) into a csv file where each row corresponds to a protein and each column represents a protein property, utilizing proper identifiers.
      </span>
     </p>
    </blockquote>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p4">
    <p class="ltx_p" id="S2.SS2.p4.1">
     The “
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p4.1.1">
      planner
     </span>
     ” then suggests the following plan
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p5">
    <blockquote class="ltx_quote" id="S2.SS2.p5.1">
     <p class="ltx_p" id="S2.SS2.p5.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS2.p5.1.1.1">
       Planner (to chat_manager):
       <br class="ltx_break"/>
      </span>
      <span class="ltx_text ltx_font_italic" id="S2.SS2.p5.1.1.2">
       Plan:
1. Use the ‘design_protein_from_length‘ function three times to design three proteins each with a sequence length of 120. I will use 1, 2, 3 as names for the proteins. Save the amino acid sequences and PDB filenames.
       <br class="ltx_break"/>
       2. Use the ‘analyze_protein_structure‘ function to analyze the secondary structure of the proteins. Store the results.
       <br class="ltx_break"/>
       3. Use the ‘calc_protein_ANM‘ function to calculate the first 10 frequencies of the proteins. Store the results.
4. Use the ‘fold_protein‘ function to fold the proteins.
       <br class="ltx_break"/>
       5. Repeat steps 2 and 3 with the folded proteins.
       <br class="ltx_break"/>
       6. Use the ‘save_to_csv_file‘ function to save all results into a csv file where each row corresponds to a protein and each column represents a protein property.
       <br class="ltx_break"/>
       7. The identifiers will be named as follows:
       <br class="ltx_break"/>
       - Protein Name
       <br class="ltx_break"/>
       - Amino Acid Sequence (Pre-Fold)
       <br class="ltx_break"/>
       - Secondary Structure (Pre-Fold)
       <br class="ltx_break"/>
       - Frequencies (Pre-Fold)
       <br class="ltx_break"/>
       - Amino Acid Sequence (Post-Fold)
       <br class="ltx_break"/>
       - Secondary Structure (Post-Fold)
       <br class="ltx_break"/>
       - Frequencies (Post-Fold)
       <br class="ltx_break"/>
      </span>
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS2.p5.2">
     At the first glance, the plan seems to cover all the details necessary to accomplish the tasks included in the problem statement. However, the “
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p5.2.1">
      critic
     </span>
     ” agent who is responsible in giving feedback about the plan spots a minuscule error in the saving part of the plan as follows:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p6">
    <blockquote class="ltx_quote" id="S2.SS2.p6.1">
     <p class="ltx_p" id="S2.SS2.p6.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS2.p6.1.1.1">
       Critic (to chat_manager):
       <br class="ltx_break"/>
      </span>
     </p>
     <p class="ltx_p" id="S2.SS2.p6.1.2">
      <span class="ltx_text ltx_font_italic" id="S2.SS2.p6.1.2.1">
       Your plan is almost perfect. However, when a protein is folded, the protein sequence doesn’t change, only the structure does, which then affects the secondary structure and possible frequencies you can calculate. So you need to only save Amino Acid Sequence once after designing the proteins. Each protein should have the following column properties:
      </span>
      <br class="ltx_break"/>
      <br class="ltx_break"/>
      <span class="ltx_text ltx_font_italic" id="S2.SS2.p6.1.2.2">
       - Protein Number
       <br class="ltx_break"/>
       - Amino Acid Sequence
       <br class="ltx_break"/>
       - Secondary Structure (Pre-Fold)
       <br class="ltx_break"/>
       - Frequencies (Pre-Fold)
       <br class="ltx_break"/>
       - Secondary Structure (Post-Fold)
       <br class="ltx_break"/>
       - Frequencies (Post-Fold)
       <br class="ltx_break"/>
       <br class="ltx_break"/>
       Other than that, your plan works perfectly. So steps will be as follows:
       <br class="ltx_break"/>
      </span>
      …
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS2.p6.2">
     The correction made by the “
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p6.2.1">
      critic
     </span>
     ”concerning the sequence length underscores its notable proficiency in comprehending how diverse functions and parameters influence various aspects within the realm of protein design.
     <br class="ltx_break"/>
     The “
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p6.2.2">
      user_proxy
     </span>
     ” agent is then asked to confirm the plan. The “
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p6.2.3">
      assistant
     </span>
     ” then takes the stage and starts following the plan by calling and executing the functions until all the steps have been undertaken. An overview of the work performed by the “
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p6.2.4">
      assistant
     </span>
     ” is depicted in Figure
     <a class="ltx_ref" href="#S2.F3" title="Figure 3 ‣ 2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     . At the end of the computations, the results are formatted into a JSON dictionary to fed into the “save_to_csv_file” function. However, an error related to the JSON dictionary format occurs when executing the function as follows:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p7">
    <blockquote class="ltx_quote" id="S2.SS2.p7.1">
     <p class="ltx_p" id="S2.SS2.p7.1.1">
      <span class="ltx_text ltx_font_italic" id="S2.SS2.p7.1.1.1">
       ***** Response from calling function "save_to_csv_file" *****
       <br class="ltx_break"/>
       Error: Expecting property name enclosed in double quotes: line 2 column 5 (char 6)
       <br class="ltx_break"/>
       *************************************************************
      </span>
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS2.p7.2">
     The “
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p7.2.1">
      critic
     </span>
     ” then steps in by making the following comment and suggesting a plan to fix the error as follows:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p8">
    <blockquote class="ltx_quote" id="S2.SS2.p8.1">
     <p class="ltx_p" id="S2.SS2.p8.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS2.p8.1.1.1">
       Critic (to chat_manager):
       <br class="ltx_break"/>
      </span>
      <span class="ltx_text ltx_font_italic" id="S2.SS2.p8.1.1.2">
       I apologize for the mistake. It seems there was an issue with the formatting of the input JSON dictionary for saving to the CSV file. Let’s try again with properly formatted JSON.
      </span>
      <br class="ltx_break"/>
      <br class="ltx_break"/>
      <span class="ltx_text ltx_font_italic" id="S2.SS2.p8.1.1.3">
       Plan to fix the error:
      </span>
      <br class="ltx_break"/>
      <br class="ltx_break"/>
      <span class="ltx_text ltx_font_italic" id="S2.SS2.p8.1.1.4">
       1. Correctly format JSON with double quotes instead of single quotations.
       <br class="ltx_break"/>
       2. Call ’save_to_csv_file’ function again with correctly formatted JSON dictionary.
      </span>
      <br class="ltx_break"/>
      <br class="ltx_break"/>
      <span class="ltx_text ltx_font_italic" id="S2.SS2.p8.1.1.5">
       I’ll directly proceed with this plan as the error was due to syntax not plan.
      </span>
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS2.p8.2">
     The critic makes the necessary corrections and suggest the corrected JSON dictionary for the “assistant” to execute the “save_to_csv_file” function. This time, the function is successfully executed and the results are saved into a csv file as shown in
     <span class="ltx_text ltx_font_bold" id="S2.SS2.p8.2.1">
      Table
      <a class="ltx_ref" href="#S2.T3" title="Table 3 ‣ 2.2 Experiment II: De novo protein design using Chroma ‣ 2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
       <span class="ltx_text ltx_ref_tag">
        3
       </span>
      </a>
     </span>
     . At last, the “
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p8.2.2">
      critic
     </span>
     ” gives an evolution about the whole process:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p9">
    <blockquote class="ltx_quote" id="S2.SS2.p9.1">
     <p class="ltx_p" id="S2.SS2.p9.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS2.p9.1.1.1">
       Critic (to chat_manager):
       <br class="ltx_break"/>
      </span>
     </p>
     <p class="ltx_p" id="S2.SS2.p9.1.2">
      <span class="ltx_text ltx_font_italic" id="S2.SS2.p9.1.2.1">
       The plan was executed successfully and all data including Amino Acid Sequence, Secondary Structure (Pre-Fold and Post-Fold), and Frequencies (Pre-Fold and Post-Fold) for three proteins have been saved into a CSV file named ’protein_data.csv’. Each row of the file corresponds to a protein and each column represents a protein property.
      </span>
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS2.p9.2">
     This experiment showcases a good example of multi-agent collaboration in solving complex tasks in the context of
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p9.2.1">
      de novo
     </span>
     protein design and analysis. It specially shows the great capability of the “
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p9.2.2">
      critic
     </span>
     ” agent in providing valuable feedback to other working agents at different stages of the problem solving endeavor, further assisting the team of agents in handling possible errors without the need for human involvement. Figure
     <a class="ltx_ref" href="#S2.F5" title="Figure 5 ‣ 2.3 Experiment III: Protein design conditioned on the protein CATH class ‣ 2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     shows the plots of the generated results including the 3D folded structures. The full conversations can be found in
     <span class="ltx_text ltx_font_bold" id="S2.SS2.p9.2.3">
      Table S3
     </span>
     of the Supplementary material.
    </p>
   </div>
   <figure class="ltx_table" id="S2.T3">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 3:
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.T3.2.1">
      The final results generated by the group chat in the form of a CSV file, without human intervention, for the second experiment II, Section
      <a class="ltx_ref" href="#S2.SS2" title="2.2 Experiment II: De novo protein design using Chroma ‣ 2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
       <span class="ltx_text ltx_ref_tag">
        2.2
       </span>
      </a>
      .
     </span>
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S2.T3.3">
     <thead class="ltx_thead">
      <tr class="ltx_tr" id="S2.T3.3.1.1">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S2.T3.3.1.1.1">
        <span class="ltx_text ltx_font_bold" id="S2.T3.3.1.1.1.1">
         Protein Number #
        </span>
       </th>
       <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="S2.T3.3.1.1.2">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.1.1.2.1">
         <span class="ltx_p" id="S2.T3.3.1.1.2.1.1">
          <span class="ltx_text ltx_font_bold" id="S2.T3.3.1.1.2.1.1.1">
           Amino Acid Sequence
          </span>
         </span>
        </span>
       </th>
       <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="S2.T3.3.1.1.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.1.1.3.1">
         <span class="ltx_p" id="S2.T3.3.1.1.3.1.1">
          <span class="ltx_text ltx_font_bold" id="S2.T3.3.1.1.3.1.1.1">
           Secondary Structure (Pre-Fold)
          </span>
         </span>
        </span>
       </th>
       <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="S2.T3.3.1.1.4">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.1.1.4.1">
         <span class="ltx_p" id="S2.T3.3.1.1.4.1.1">
          <span class="ltx_text ltx_font_bold" id="S2.T3.3.1.1.4.1.1.1">
           Frequencies (Pre-Fold)
          </span>
         </span>
        </span>
       </th>
       <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="S2.T3.3.1.1.5">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.1.1.5.1">
         <span class="ltx_p" id="S2.T3.3.1.1.5.1.1">
          <span class="ltx_text ltx_font_bold" id="S2.T3.3.1.1.5.1.1.1">
           Secondary Structure (Post-Fold)
          </span>
         </span>
        </span>
       </th>
       <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="S2.T3.3.1.1.6">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.1.1.6.1">
         <span class="ltx_p" id="S2.T3.3.1.1.6.1.1">
          <span class="ltx_text ltx_font_bold" id="S2.T3.3.1.1.6.1.1.1">
           Frequencies (Post-Fold)
          </span>
         </span>
        </span>
       </th>
      </tr>
     </thead>
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S2.T3.3.2.1">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T3.3.2.1.1">
        1
       </th>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T3.3.2.1.2">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.2.1.2.1">
         <span class="ltx_ERROR undefined" id="S2.T3.3.2.1.2.1.1">
          \seqsplit
         </span>
         <span class="ltx_p" id="S2.T3.3.2.1.2.1.2">
          MIIINIKTENGLSITYNSDEKKLELKYTPVKSPEDFKFPEDAKATISEVEYKGKKV IKIDAKLYVSPDLSKAKLTIEVNADISQEEADKIIDEFIKLLESLGNIKLKVTKD GNKYTIEVE
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T3.3.2.1.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.2.1.3.1">
         <span class="ltx_p" id="S2.T3.3.2.1.3.1.1">
          ’H’: 13.3333333333, ’B’: 0.0, ’E’: 46.6666666666, ’G’: 0.0, ’I’: 0.0, ’T’: 14.1666666666, ’S’: 7.5, ’P’: 0.0, ’-’: 18.33333333333
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T3.3.2.1.4">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.2.1.4.1">
         <span class="ltx_p" id="S2.T3.3.2.1.4.1.1">
          [2.0337, 2.8678, 3.3843, 3.6263, 3.9904, 4.5381, 4.8373, 4.8956, 5.1492, 5.4416]
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T3.3.2.1.5">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.2.1.5.1">
         <span class="ltx_p" id="S2.T3.3.2.1.5.1.1">
          ’H’: 15.8333333333, ’B’: 0.0, ’E’: 46.666666666, ’G’: 2.5, ’I’: 0.0, ’T’: 14.1666666666, ’S’: 4.1666666666, ’P’: 0.0, ’-’: 16.666666666
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T3.3.2.1.6">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.2.1.6.1">
         <span class="ltx_p" id="S2.T3.3.2.1.6.1.1">
          [1.8739, 2.1563, 2.7611, 3.1086, 3.8712, 4.0481, 4.3759, 4.6717, 4.8183, 4.9126]
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S2.T3.3.3.2">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T3.3.3.2.1">
        2
       </th>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T3.3.3.2.2">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.3.2.2.1">
         <span class="ltx_ERROR undefined" id="S2.T3.3.3.2.2.1.1">
          \seqsplit
         </span>
         <span class="ltx_p" id="S2.T3.3.3.2.2.1.2">
          GSPLPRPPLSPEEQEALRKKAQEKYNEFVSKIKELLRRAADRVRRGEPVELIEKTIKIGDYEYKIVATSPEEAKELENLIKEMIDLGFKPSKEFSDKLVEAARLIREGRVDEALRLLDEM
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T3.3.3.2.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.3.2.3.1">
         <span class="ltx_p" id="S2.T3.3.3.2.3.1.1">
          ’H’: 61.666666666, ’B’: 0.0, ’E’: 11.6666666666, ’G’: 0.0, ’I’: 0.0, ’T’: 7.5, ’S’: 3.33333333333, ’P’: 3.33333333333, ’-’: 12.5
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T3.3.3.2.4">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.3.2.4.1">
         <span class="ltx_p" id="S2.T3.3.3.2.4.1.1">
          [0.0207, 0.1058, 0.1782, 0.4189, 0.49, 0.9015, 1.1832, 1.8257, 2.1212, 2.8726]
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T3.3.3.2.5">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.3.2.5.1">
         <span class="ltx_p" id="S2.T3.3.3.2.5.1.1">
          ’H’: 62.5, ’B’: 0.0, ’E’: 11.6666666666, ’G’: 0.0, ’I’: 0.0, ’T’: 6.6666666666, ’S’: 1.66666666666, ’P’: 4.1666666666, ’-’: 13.3333333333
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T3.3.3.2.6">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.3.2.6.1">
         <span class="ltx_p" id="S2.T3.3.3.2.6.1.1">
          [0.0444, 0.1641, 0.3379, 0.5724, 0.765, 0.9568, 1.4306, 1.5344, 1.6834, 1.8099]
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S2.T3.3.4.3">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S2.T3.3.4.3.1">
        3
       </th>
       <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="S2.T3.3.4.3.2">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.4.3.2.1">
         <span class="ltx_ERROR undefined" id="S2.T3.3.4.3.2.1.1">
          \seqsplit
         </span>
         <span class="ltx_p" id="S2.T3.3.4.3.2.1.2">
          APLDPDDLSAQLRAAIDELVRLGYEEEVSKPEFIEALRLYALDLGLKEVVLRRVTPAPASQPGVYTVED VTVDLEALRKQELSPEEQARLEKIRAKYDEMLADPEFQALLDEVLARARAA
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="S2.T3.3.4.3.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.4.3.3.1">
         <span class="ltx_p" id="S2.T3.3.4.3.3.1.1">
          ’H’: 57.499999999, ’B’: 0.0, ’E’: 13.3333333333, ’G’: 0.0, ’I’: 4.1666666666, ’T’: 8.3333333333, ’S’: 3.33333333333, ’P’: 6.6666666666, ’-’: 6.6666666666
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="S2.T3.3.4.3.4">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.4.3.4.1">
         <span class="ltx_p" id="S2.T3.3.4.3.4.1.1">
          [0.7546, 1.0836, 1.5026, 1.8874, 2.0844, 2.3192, 2.7975, 3.0199, 3.0669, 3.1382]
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="S2.T3.3.4.3.5">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.4.3.5.1">
         <span class="ltx_p" id="S2.T3.3.4.3.5.1.1">
          ’H’: 61.666666666, ’B’: 0.0, ’E’: 15.0, ’G’: 0.0, ’I’: 0.0, ’T’: 8.3333333333, ’S’: 3.33333333333, ’P’: 1.66666666666, ’-’: 10.0
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="S2.T3.3.4.3.6">
        <span class="ltx_inline-block ltx_align_top" id="S2.T3.3.4.3.6.1">
         <span class="ltx_p" id="S2.T3.3.4.3.6.1.1">
          [0.5256, 1.0278, 1.1566, 1.2877, 1.5521, 1.9111, 2.1887, 2.4664, 2.734, 2.8731]
         </span>
        </span>
       </td>
      </tr>
     </tbody>
    </table>
   </figure>
  </section>
  <section class="ltx_subsection" id="S2.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.3
    </span>
    Experiment III: Protein design conditioned on the protein CATH class
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p1">
    <p class="ltx_p" id="S2.SS3.p1.14">
     CATH is a hierarchical classification system for protein structures that consists of four main levels. The highest level in this hierarchy is the “
     <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.14.1">
      Class
     </span>
     ” which primarily characterizes the secondary structure content of the protein. For example,
     <math alttext="C_{1}" class="ltx_Math" display="inline" id="S2.SS3.p1.1.m1.1">
      <semantics id="S2.SS3.p1.1.m1.1a">
       <msub id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml">
        <mi id="S2.SS3.p1.1.m1.1.1.2" xref="S2.SS3.p1.1.m1.1.1.2.cmml">
         C
        </mi>
        <mn id="S2.SS3.p1.1.m1.1.1.3" xref="S2.SS3.p1.1.m1.1.1.3.cmml">
         1
        </mn>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b">
        <apply id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">
         <csymbol cd="ambiguous" id="S2.SS3.p1.1.m1.1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="S2.SS3.p1.1.m1.1.1.2.cmml" xref="S2.SS3.p1.1.m1.1.1.2">
          𝐶
         </ci>
         <cn id="S2.SS3.p1.1.m1.1.1.3.cmml" type="integer" xref="S2.SS3.p1.1.m1.1.1.3">
          1
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">
        C_{1}
       </annotation>
      </semantics>
     </math>
     ,
     <math alttext="C_{2}" class="ltx_Math" display="inline" id="S2.SS3.p1.2.m2.1">
      <semantics id="S2.SS3.p1.2.m2.1a">
       <msub id="S2.SS3.p1.2.m2.1.1" xref="S2.SS3.p1.2.m2.1.1.cmml">
        <mi id="S2.SS3.p1.2.m2.1.1.2" xref="S2.SS3.p1.2.m2.1.1.2.cmml">
         C
        </mi>
        <mn id="S2.SS3.p1.2.m2.1.1.3" xref="S2.SS3.p1.2.m2.1.1.3.cmml">
         2
        </mn>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.1b">
        <apply id="S2.SS3.p1.2.m2.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1">
         <csymbol cd="ambiguous" id="S2.SS3.p1.2.m2.1.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1">
          subscript
         </csymbol>
         <ci id="S2.SS3.p1.2.m2.1.1.2.cmml" xref="S2.SS3.p1.2.m2.1.1.2">
          𝐶
         </ci>
         <cn id="S2.SS3.p1.2.m2.1.1.3.cmml" type="integer" xref="S2.SS3.p1.2.m2.1.1.3">
          2
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.1c">
        C_{2}
       </annotation>
      </semantics>
     </math>
     , and
     <math alttext="C_{3}" class="ltx_Math" display="inline" id="S2.SS3.p1.3.m3.1">
      <semantics id="S2.SS3.p1.3.m3.1a">
       <msub id="S2.SS3.p1.3.m3.1.1" xref="S2.SS3.p1.3.m3.1.1.cmml">
        <mi id="S2.SS3.p1.3.m3.1.1.2" xref="S2.SS3.p1.3.m3.1.1.2.cmml">
         C
        </mi>
        <mn id="S2.SS3.p1.3.m3.1.1.3" xref="S2.SS3.p1.3.m3.1.1.3.cmml">
         3
        </mn>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.3.m3.1b">
        <apply id="S2.SS3.p1.3.m3.1.1.cmml" xref="S2.SS3.p1.3.m3.1.1">
         <csymbol cd="ambiguous" id="S2.SS3.p1.3.m3.1.1.1.cmml" xref="S2.SS3.p1.3.m3.1.1">
          subscript
         </csymbol>
         <ci id="S2.SS3.p1.3.m3.1.1.2.cmml" xref="S2.SS3.p1.3.m3.1.1.2">
          𝐶
         </ci>
         <cn id="S2.SS3.p1.3.m3.1.1.3.cmml" type="integer" xref="S2.SS3.p1.3.m3.1.1.3">
          3
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.3.m3.1c">
        C_{3}
       </annotation>
      </semantics>
     </math>
     correspond to proteins predominantly composed of
     <math alttext="\alpha" class="ltx_Math" display="inline" id="S2.SS3.p1.4.m4.1">
      <semantics id="S2.SS3.p1.4.m4.1a">
       <mi id="S2.SS3.p1.4.m4.1.1" xref="S2.SS3.p1.4.m4.1.1.cmml">
        α
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.4.m4.1b">
        <ci id="S2.SS3.p1.4.m4.1.1.cmml" xref="S2.SS3.p1.4.m4.1.1">
         𝛼
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.4.m4.1c">
        \alpha
       </annotation>
      </semantics>
     </math>
     -helix, mainly
     <math alttext="\beta" class="ltx_Math" display="inline" id="S2.SS3.p1.5.m5.1">
      <semantics id="S2.SS3.p1.5.m5.1a">
       <mi id="S2.SS3.p1.5.m5.1.1" xref="S2.SS3.p1.5.m5.1.1.cmml">
        β
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.5.m5.1b">
        <ci id="S2.SS3.p1.5.m5.1.1.cmml" xref="S2.SS3.p1.5.m5.1.1">
         𝛽
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.5.m5.1c">
        \beta
       </annotation>
      </semantics>
     </math>
     -sheet, and a combination of
     <math alttext="\alpha" class="ltx_Math" display="inline" id="S2.SS3.p1.6.m6.1">
      <semantics id="S2.SS3.p1.6.m6.1a">
       <mi id="S2.SS3.p1.6.m6.1.1" xref="S2.SS3.p1.6.m6.1.1.cmml">
        α
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.6.m6.1b">
        <ci id="S2.SS3.p1.6.m6.1.1.cmml" xref="S2.SS3.p1.6.m6.1.1">
         𝛼
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.6.m6.1c">
        \alpha
       </annotation>
      </semantics>
     </math>
     and
     <math alttext="\beta" class="ltx_Math" display="inline" id="S2.SS3.p1.7.m7.1">
      <semantics id="S2.SS3.p1.7.m7.1a">
       <mi id="S2.SS3.p1.7.m7.1.1" xref="S2.SS3.p1.7.m7.1.1.cmml">
        β
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.7.m7.1b">
        <ci id="S2.SS3.p1.7.m7.1.1.cmml" xref="S2.SS3.p1.7.m7.1.1">
         𝛽
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.7.m7.1c">
        \beta
       </annotation>
      </semantics>
     </math>
     secondary structures. Consequently, designing proteins based on the CATH class number, i.e.
     <math alttext="C_{1}" class="ltx_Math" display="inline" id="S2.SS3.p1.8.m8.1">
      <semantics id="S2.SS3.p1.8.m8.1a">
       <msub id="S2.SS3.p1.8.m8.1.1" xref="S2.SS3.p1.8.m8.1.1.cmml">
        <mi id="S2.SS3.p1.8.m8.1.1.2" xref="S2.SS3.p1.8.m8.1.1.2.cmml">
         C
        </mi>
        <mn id="S2.SS3.p1.8.m8.1.1.3" xref="S2.SS3.p1.8.m8.1.1.3.cmml">
         1
        </mn>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.8.m8.1b">
        <apply id="S2.SS3.p1.8.m8.1.1.cmml" xref="S2.SS3.p1.8.m8.1.1">
         <csymbol cd="ambiguous" id="S2.SS3.p1.8.m8.1.1.1.cmml" xref="S2.SS3.p1.8.m8.1.1">
          subscript
         </csymbol>
         <ci id="S2.SS3.p1.8.m8.1.1.2.cmml" xref="S2.SS3.p1.8.m8.1.1.2">
          𝐶
         </ci>
         <cn id="S2.SS3.p1.8.m8.1.1.3.cmml" type="integer" xref="S2.SS3.p1.8.m8.1.1.3">
          1
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.8.m8.1c">
        C_{1}
       </annotation>
      </semantics>
     </math>
     ,
     <math alttext="C_{2}" class="ltx_Math" display="inline" id="S2.SS3.p1.9.m9.1">
      <semantics id="S2.SS3.p1.9.m9.1a">
       <msub id="S2.SS3.p1.9.m9.1.1" xref="S2.SS3.p1.9.m9.1.1.cmml">
        <mi id="S2.SS3.p1.9.m9.1.1.2" xref="S2.SS3.p1.9.m9.1.1.2.cmml">
         C
        </mi>
        <mn id="S2.SS3.p1.9.m9.1.1.3" xref="S2.SS3.p1.9.m9.1.1.3.cmml">
         2
        </mn>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.9.m9.1b">
        <apply id="S2.SS3.p1.9.m9.1.1.cmml" xref="S2.SS3.p1.9.m9.1.1">
         <csymbol cd="ambiguous" id="S2.SS3.p1.9.m9.1.1.1.cmml" xref="S2.SS3.p1.9.m9.1.1">
          subscript
         </csymbol>
         <ci id="S2.SS3.p1.9.m9.1.1.2.cmml" xref="S2.SS3.p1.9.m9.1.1.2">
          𝐶
         </ci>
         <cn id="S2.SS3.p1.9.m9.1.1.3.cmml" type="integer" xref="S2.SS3.p1.9.m9.1.1.3">
          2
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.9.m9.1c">
        C_{2}
       </annotation>
      </semantics>
     </math>
     ,
     <math alttext="C_{3}" class="ltx_Math" display="inline" id="S2.SS3.p1.10.m10.1">
      <semantics id="S2.SS3.p1.10.m10.1a">
       <msub id="S2.SS3.p1.10.m10.1.1" xref="S2.SS3.p1.10.m10.1.1.cmml">
        <mi id="S2.SS3.p1.10.m10.1.1.2" xref="S2.SS3.p1.10.m10.1.1.2.cmml">
         C
        </mi>
        <mn id="S2.SS3.p1.10.m10.1.1.3" xref="S2.SS3.p1.10.m10.1.1.3.cmml">
         3
        </mn>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.10.m10.1b">
        <apply id="S2.SS3.p1.10.m10.1.1.cmml" xref="S2.SS3.p1.10.m10.1.1">
         <csymbol cd="ambiguous" id="S2.SS3.p1.10.m10.1.1.1.cmml" xref="S2.SS3.p1.10.m10.1.1">
          subscript
         </csymbol>
         <ci id="S2.SS3.p1.10.m10.1.1.2.cmml" xref="S2.SS3.p1.10.m10.1.1.2">
          𝐶
         </ci>
         <cn id="S2.SS3.p1.10.m10.1.1.3.cmml" type="integer" xref="S2.SS3.p1.10.m10.1.1.3">
          3
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.10.m10.1c">
        C_{3}
       </annotation>
      </semantics>
     </math>
     , can be understood as creating proteins with a specific fractional content of the secondary structure. Previous studies have demonstrated the importance of the protein secondary structures content, specially
     <math alttext="\alpha" class="ltx_Math" display="inline" id="S2.SS3.p1.11.m11.1">
      <semantics id="S2.SS3.p1.11.m11.1a">
       <mi id="S2.SS3.p1.11.m11.1.1" xref="S2.SS3.p1.11.m11.1.1.cmml">
        α
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.11.m11.1b">
        <ci id="S2.SS3.p1.11.m11.1.1.cmml" xref="S2.SS3.p1.11.m11.1.1">
         𝛼
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.11.m11.1c">
        \alpha
       </annotation>
      </semantics>
     </math>
     -helix/
     <math alttext="\beta" class="ltx_Math" display="inline" id="S2.SS3.p1.12.m12.1">
      <semantics id="S2.SS3.p1.12.m12.1a">
       <mi id="S2.SS3.p1.12.m12.1.1" xref="S2.SS3.p1.12.m12.1.1.cmml">
        β
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.12.m12.1b">
        <ci id="S2.SS3.p1.12.m12.1.1.cmml" xref="S2.SS3.p1.12.m12.1.1">
         𝛽
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.12.m12.1c">
        \beta
       </annotation>
      </semantics>
     </math>
     -sheet ratio, on the mechanical properties of the protein materials
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib65" title="">
       65
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib66" title="">
       66
      </a>
      ]
     </cite>
     . For instance,
     <math alttext="\alpha" class="ltx_Math" display="inline" id="S2.SS3.p1.13.m13.1">
      <semantics id="S2.SS3.p1.13.m13.1a">
       <mi id="S2.SS3.p1.13.m13.1.1" xref="S2.SS3.p1.13.m13.1.1.cmml">
        α
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.13.m13.1b">
        <ci id="S2.SS3.p1.13.m13.1.1.cmml" xref="S2.SS3.p1.13.m13.1.1">
         𝛼
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.13.m13.1c">
        \alpha
       </annotation>
      </semantics>
     </math>
     -helix-rich proteins tend to yield stretchy materials
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib67" title="">
       67
      </a>
      ]
     </cite>
     , while
     <math alttext="\beta" class="ltx_Math" display="inline" id="S2.SS3.p1.14.m14.1">
      <semantics id="S2.SS3.p1.14.m14.1a">
       <mi id="S2.SS3.p1.14.m14.1.1" xref="S2.SS3.p1.14.m14.1.1.cmml">
        β
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.14.m14.1b">
        <ci id="S2.SS3.p1.14.m14.1.1.cmml" xref="S2.SS3.p1.14.m14.1.1">
         𝛽
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.14.m14.1c">
        \beta
       </annotation>
      </semantics>
     </math>
     -sheet-rich ones produce rigid materials.
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib68" title="">
       68
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib69" title="">
       69
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib70" title="">
       70
      </a>
      ]
     </cite>
     Chroma has the potential to conditionally generate proteins with specified folds according to CATH class annotations at three levels.
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib15" title="">
       15
      </a>
      ]
     </cite>
    </p>
   </div>
   <figure class="ltx_figure" id="S2.F4">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="176" id="S2.F4.g1" src="/html/2402.04268/assets/image_exp3.png" width="598"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 4:
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.F4.4.1">
      Overview of the multi-agent work to solve the complex task posed in experiment III, Section
      <a class="ltx_ref" href="#S2.SS3" title="2.3 Experiment III: Protein design conditioned on the protein CATH class ‣ 2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
       <span class="ltx_text ltx_ref_tag">
        2.3
       </span>
      </a>
      .
     </span>
     First the multi-agent uses Chroma to generate
     <span class="ltx_text ltx_font_italic" id="S2.F4.5.2">
      de novo
     </span>
     protein sequences and structures conditioned on the input CATH class. Then using the generated protein structures, the natural frequencies and secondary structures content are computed. Next, the force (maximum force along the unfolding force-extension curve) and energy (the area under the force-extension curve) are computed from
     <span class="ltx_text ltx_font_italic" id="S2.F4.6.3">
      de novo
     </span>
     AA sequences using ProteinForceGPT.
    </figcaption>
   </figure>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p2">
    <p class="ltx_p" id="S2.SS3.p2.1">
     In this example, we task the multi-agent team with generating proteins based on their fractional content of the secondary structure and subsequently performing computational and structural analysis tasks. Specifically, in addition to secondary structure analysis and natural frequency calculations, as covered in previous examples, we instruct the team to compute the maximum unfolding force (maximum force in the unfolding force-separation curve) and unfolding energy (the area under the unfolding force-separation curve) for each generated protein. To accomplish the latter, we have equipped the multi-agent team with a custom function that utilizes a trained autoregressive transformer generative AI model,
     <span class="ltx_text ltx_font_italic" id="S2.SS3.p2.1.1">
      ForceGPT
     </span>
     . In addition to maximum unfolding force and energy, the trained generative model is able to predict the entire unfolding force-separation curve based solely on the protein amino acid sequence. Furthermore, the model has the capability to perform inverse design tasks by generating protein AA sequences that yield desired unfolding behavior. Detailed information about the training of the model can be found in
     <span class="ltx_text ltx_font_bold" id="S2.SS3.p2.1.2">
      Materials and Methods
     </span>
     section
     <a class="ltx_ref" href="#S4" title="4 Materials and Methods ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     . The task given is:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p3">
    <blockquote class="ltx_quote" id="S2.SS3.p3.1">
     <p class="ltx_p" id="S2.SS3.p3.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS3.p3.1.1.1">
       user_proxy (to chat_manager):
       <br class="ltx_break"/>
      </span>
     </p>
     <p class="ltx_p" id="S2.SS3.p3.1.2">
      <span class="ltx_text ltx_font_italic" id="S2.SS3.p3.1.2.1">
       Design two proteins of length 100 for each family of mainly beta, mainly alpha, and alpha beta proteins. Then compute the maximum force and unfolding energy, analyze the secondary structure and compute the first 10 frequencies for these proteins.
      </span>
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS3.p3.2">
     Note that, as before, we do not specify any particular function or offer hints for selecting the appropriate function to accomplish the tasks. Instead, we empower the agents to formulate a plan, wherein they decide which functions to select and determine the input parameters. The planner outlines the following plan for the given task:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p4">
    <blockquote class="ltx_quote" id="S2.SS3.p4.1">
     <p class="ltx_p" id="S2.SS3.p4.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS3.p4.1.1.1">
       Planner (to chat_manager):
       <br class="ltx_break"/>
      </span>
     </p>
     <p class="ltx_p" id="S2.SS3.p4.1.2">
      <span class="ltx_text ltx_font_italic" id="S2.SS3.p4.1.2.1">
       1. Use the "design_protein_from_CATH" function with inputs of length of 100, CATH_ANNOTATION of 1 (mainly alpha), and a protein name for the first mainly alpha protein. Repeat with a different name for the second protein.
       <br class="ltx_break"/>
       2. Use the same function again with inputs of length 100, CATH_ANNOTATION of 2 (mainly beta), and a protein name for the first mainly beta protein. Repeat with a different name for the second protein.
       <br class="ltx_break"/>
       3. Use the function once more with inputs of length 100, CATH_ANNOTATION of 3 (alpha beta), and a protein name for the first alpha beta protein. Repeat with a different name for the second protein.
       <br class="ltx_break"/>
       4. Use the "analyze_protein_structure" function on each of the protein structures obtained.
       <br class="ltx_break"/>
       5. Use the "calucalte_force_energy_from_seq" function to compute the maximum force and unfolding energy for each of the proteins.
       <br class="ltx_break"/>
       6. Use the "calc_protein_ANM" function to compute the first 10 frequencies for each protein.
      </span>
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS3.p4.2">
     It can be seen that the planner demonstrates good performance in breaking the task into sub-tasks to be accomplished step by step. Moreover, it has identified and suggested the correct functions and corresponding input parameters for each sub-task. The plan is further supported by the “
     <span class="ltx_text ltx_font_italic" id="S2.SS3.p4.2.1">
      critic
     </span>
     ” who provides positive feedback as follows:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p5">
    <blockquote class="ltx_quote" id="S2.SS3.p5.1">
     <p class="ltx_p" id="S2.SS3.p5.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS3.p5.1.1.1">
       Critic (to chat_manager):
       <br class="ltx_break"/>
      </span>
     </p>
     <p class="ltx_p" id="S2.SS3.p5.1.2">
      <span class="ltx_text ltx_font_italic" id="S2.SS3.p5.1.2.1">
       Yes, this plan sounds good. It covers each step required for the task. The parameter inputs for each function match with the required parameters as stated in their function definitions. Thus, this plan should successfully accomplish the task.
      </span>
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS3.p5.2">
     The multi-agent team then proceeds to execute the different steps outlined in the plan by calling and executing the functions. Specifically, the function ’design_protein_from_CATH’ is executed with the appropriate ’CATH_ANNOTATION’ for a specific protein structure design, as outlined in the plan. Following the generation of all proteins, the executions are followed by structural analysis and force and energy computations. It’s noteworthy that the model exhibits good performance in restoring and memorizing the sequences of the generated proteins, which are essential for the force and energy calculations. Finally, the team successfully completes the task by computing the first 10 frequencies for each protein. An overview of the computations performed by the team of agents for this experiment is shown in Figure
     <a class="ltx_ref" href="#S2.F4" title="Figure 4 ‣ 2.3 Experiment III: Protein design conditioned on the protein CATH class ‣ 2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     .
    </p>
   </div>
   <figure class="ltx_figure" id="S2.F5">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="471" id="S2.F5.g1" src="/html/2402.04268/assets/image_Chroma_fold.png" width="598"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 5:
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.F5.2.1">
      The results generated by the multi-agent collaboration for the experiment II, Section
      <a class="ltx_ref" href="#S2.SS2" title="2.2 Experiment II: De novo protein design using Chroma ‣ 2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
       <span class="ltx_text ltx_ref_tag">
        2.2
       </span>
      </a>
      .
     </span>
     The first and second columns depict the 3D folded structures of proteins generated by Chroma and OmegaFold2, respectively, while the third and fourth columns represent the fractional content of secondary structures, and first ten natural frequencies for the generated proteins.
    </figcaption>
   </figure>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p6">
    <p class="ltx_p" id="S2.SS3.p6.1">
     Given the complexity of the problem involving numerous computational tasks, a decent number of results have been generated in the first round of the conversation. In the next round, to evaluate the team’s ability to memorize and restore the results, we present the following task:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p7">
    <blockquote class="ltx_quote" id="S2.SS3.p7.1">
     <p class="ltx_p" id="S2.SS3.p7.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS3.p7.1.1.1">
       user_proxy (to chat_manager):
       <br class="ltx_break"/>
      </span>
     </p>
     <p class="ltx_p" id="S2.SS3.p7.1.2">
      <span class="ltx_text ltx_font_italic" id="S2.SS3.p7.1.2.1">
       Could you save the results in a CSV file named "protein_analysis.csv," where each row corresponds to a protein, and each column represents a specific property? Include the AA sequence in the results and use suitable identifiers for the columns.
      </span>
     </p>
    </blockquote>
    <p class="ltx_p" id="S2.SS3.p7.2">
     In this task, we not only request the team to save the data but also require them to adhere to a customized format when storing the results. The model is proficient in creating a JSON dictionary that satisfies the specified format and saving the results to a CSV file, as illustrated in
     <span class="ltx_text ltx_font_bold" id="S2.SS3.p7.2.1">
      Table
      <a class="ltx_ref" href="#S2.T4" title="Table 4 ‣ 2.3 Experiment III: Protein design conditioned on the protein CATH class ‣ 2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
     </span>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p8">
    <p class="ltx_p" id="S2.SS3.p8.2">
     The plots of the obtained results are shown in Figure
     <a class="ltx_ref" href="#S2.F4" title="Figure 4 ‣ 2.3 Experiment III: Protein design conditioned on the protein CATH class ‣ 2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     . The results indicate that Chroma has done a poor performance in creating
     <math alttext="\beta" class="ltx_Math" display="inline" id="S2.SS3.p8.1.m1.1">
      <semantics id="S2.SS3.p8.1.m1.1a">
       <mi id="S2.SS3.p8.1.m1.1.1" xref="S2.SS3.p8.1.m1.1.1.cmml">
        β
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p8.1.m1.1b">
        <ci id="S2.SS3.p8.1.m1.1.1.cmml" xref="S2.SS3.p8.1.m1.1.1">
         𝛽
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p8.1.m1.1c">
        \beta
       </annotation>
      </semantics>
     </math>
     -rich protein named
     <span class="ltx_text ltx_font_italic" id="S2.SS3.p8.2.1">
      mainly_beta_protein_2
     </span>
     which its structure is dominant in
     <math alttext="\alpha" class="ltx_Math" display="inline" id="S2.SS3.p8.2.m2.1">
      <semantics id="S2.SS3.p8.2.m2.1a">
       <mi id="S2.SS3.p8.2.m2.1.1" xref="S2.SS3.p8.2.m2.1.1.cmml">
        α
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p8.2.m2.1b">
        <ci id="S2.SS3.p8.2.m2.1.1.cmml" xref="S2.SS3.p8.2.m2.1.1">
         𝛼
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p8.2.m2.1c">
        \alpha
       </annotation>
      </semantics>
     </math>
     -helix. As an attempt to test the capability of the multi-agent model in analyzing the results, in the last round of the conversation, we ask the model to assess Chroma’s performance in generating the proteins conditioned on the secondary structure by posing the following question:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p9">
    <blockquote class="ltx_quote" id="S2.SS3.p9.1">
     <p class="ltx_p" id="S2.SS3.p9.1.1">
      <span class="ltx_text ltx_font_bold" id="S2.SS3.p9.1.1.1">
       user_proxy (to chat_manager):
       <br class="ltx_break"/>
      </span>
     </p>
     <p class="ltx_p" id="S2.SS3.p9.1.2">
      <span class="ltx_text ltx_font_italic" id="S2.SS3.p9.1.2.1">
       Based on the results of this example, can you check if the protein generator (Chroma) has been successful in creating proteins with desired structure?
      </span>
     </p>
    </blockquote>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p10">
    <p class="ltx_p" id="S2.SS3.p10.1">
     The “
     <span class="ltx_text ltx_font_italic" id="S2.SS3.p10.1.1">
      critic
     </span>
     ” agent conducts a thorough evaluation of Chroma’s performance in generating proteins with targeted secondary structure content. Through a detailed analysis of each CATH structure, it reveals the inherent strengths and weaknesses in Chroma’s capabilities. Specifically, addressing the limitations of Chroma’s performance, the critic’s evaluation provides the following observations for the mainly beta proteins:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p11">
    <blockquote class="ltx_quote" id="S2.SS3.p11.1">
     <p class="ltx_p" id="S2.SS3.p11.1.1">
      <span class="ltx_text ltx_font_italic" id="S2.SS3.p11.1.1.1">
       - The mainly beta proteins showed higher percentages of extended strand/beta-sheet secondary structure (’E’). Though, the percentages varied quite a bit (64% for mainly_beta_protein_1 and only 8% for mainly_beta_protein_2), which could be due to the complex nature of beta-structures.
      </span>
     </p>
    </blockquote>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p12">
    <p class="ltx_p" id="S2.SS3.p12.1">
     This illustration not only highlights the multi-agent model’s proficiency in computational tasks but also underscores its intelligence in handling intricate data analyses—an aspect traditionally reserved for human. The full conversations for this experiment can be found in Table S4 of the Supplementary material.
    </p>
   </div>
   <figure class="ltx_figure" id="S2.F6">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="571" id="S2.F6.g1" src="/html/2402.04268/assets/image_Chroma_CATH.png" width="598"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 6:
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.F6.2.1">
      The results generated by the multi-agent collaboration for the experiment III, Section
      <a class="ltx_ref" href="#S2.SS3" title="2.3 Experiment III: Protein design conditioned on the protein CATH class ‣ 2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
       <span class="ltx_text ltx_ref_tag">
        2.3
       </span>
      </a>
      .
     </span>
     The first and second columns depict the 3d folded structures and the last column represents the fractional content of secondary structures for the two proteins generated by Chroma conditioned on the CATH class of (a) 1: mainly alpha protein, (b) 2: mainly beta protein, and (c) 3: alpha beta protein.
    </figcaption>
   </figure>
   <figure class="ltx_table" id="S2.T4">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 4:
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.T4.2.1">
      The final results generated by the group chat in the form of a CSV file, without human intervention, for the third experiment III, Section
      <a class="ltx_ref" href="#S2.SS3" title="2.3 Experiment III: Protein design conditioned on the protein CATH class ‣ 2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
       <span class="ltx_text ltx_ref_tag">
        2.3
       </span>
      </a>
      .
     </span>
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S2.T4.3">
     <thead class="ltx_thead">
      <tr class="ltx_tr" id="S2.T4.3.1.1">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T4.3.1.1.1">
        <span class="ltx_text ltx_font_bold" id="S2.T4.3.1.1.1.1">
         Protein Name #
        </span>
       </th>
       <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="S2.T4.3.1.1.2">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.1.1.2.1">
         <span class="ltx_p" id="S2.T4.3.1.1.2.1.1">
          <span class="ltx_text ltx_font_bold" id="S2.T4.3.1.1.2.1.1.1">
           AA Sequence
          </span>
         </span>
        </span>
       </th>
       <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="S2.T4.3.1.1.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.1.1.3.1">
         <span class="ltx_p" id="S2.T4.3.1.1.3.1.1">
          <span class="ltx_text ltx_font_bold" id="S2.T4.3.1.1.3.1.1.1">
           Secondary Structure
          </span>
         </span>
        </span>
       </th>
       <th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S2.T4.3.1.1.4">
        <span class="ltx_text ltx_font_bold" id="S2.T4.3.1.1.4.1">
         Unfolding Energy
        </span>
       </th>
       <th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S2.T4.3.1.1.5">
        <span class="ltx_text ltx_font_bold" id="S2.T4.3.1.1.5.1">
         Max Force
        </span>
       </th>
       <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="S2.T4.3.1.1.6">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.1.1.6.1">
         <span class="ltx_p" id="S2.T4.3.1.1.6.1.1">
          <span class="ltx_text ltx_font_bold" id="S2.T4.3.1.1.6.1.1.1">
           First 10 Frequencies
          </span>
         </span>
        </span>
       </th>
      </tr>
     </thead>
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S2.T4.3.2.1">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T4.3.2.1.1">
        mainly_alpha_protein_1
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T4.3.2.1.2">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.2.1.2.1">
         <span class="ltx_ERROR undefined" id="S2.T4.3.2.1.2.1.1">
          \seqsplit
         </span>
         <span class="ltx_p" id="S2.T4.3.2.1.2.1.2">
          SMKKIEDYIREKLKALGLSDEEIEERVKQLMEGIKNPKKFE KELQKRNDRESLLIFKEAYALYEASKDKEKGKKLINKVQSERDKWETEQAEAARAAAAA
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T4.3.2.1.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.2.1.3.1">
         <span class="ltx_p" id="S2.T4.3.2.1.3.1.1">
          ’H’: 89.0, ’B’: 0.0, ’E’: 0.0, ’G’: 0.0, ’I’: 0.0, ’T’: 4.0, ’S’: 1.0, ’P’: 0.0, ’-’: 6.0
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_right ltx_border_t" id="S2.T4.3.2.1.4">
        0.381
       </td>
       <td class="ltx_td ltx_align_right ltx_border_t" id="S2.T4.3.2.1.5">
        0.444
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T4.3.2.1.6">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.2.1.6.1">
         <span class="ltx_ERROR undefined" id="S2.T4.3.2.1.6.1.1">
          \seqsplit
         </span>
         <span class="ltx_p" id="S2.T4.3.2.1.6.1.2">
          [0.2329, 0.4901, 0.9331, 1.3741, 1.7347, 2.1598, 2.3686, 2.6359, 2.8555, 3.0364]
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S2.T4.3.3.2">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T4.3.3.2.1">
        mainly_alpha_protein_2
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T4.3.3.2.2">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.3.2.2.1">
         <span class="ltx_ERROR undefined" id="S2.T4.3.3.2.2.1.1">
          \seqsplit
         </span>
         <span class="ltx_p" id="S2.T4.3.3.2.2.1.2">
          MSKKEIEELKKKLDEIVETLKEYARQGDDACKKAADLIEEVKKALEEGNPEKYSQLKKKLTDAINKAIEEYRKRFE AEGKPEEAQKVIDKLKKILDEITN
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T4.3.3.2.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.3.2.3.1">
         <span class="ltx_ERROR undefined" id="S2.T4.3.3.2.3.1.1">
          \seqsplit
         </span>
         <span class="ltx_p" id="S2.T4.3.3.2.3.1.2">
          ’H’: 89.0, ’B’: 0.0, ’E’: 0.0, ’G’: 0.0, ’I’: 0.0, ’T’: 5.0, ’S’: 0.0, ’P’: 0.0, ’-’: 6.0
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_right ltx_border_t" id="S2.T4.3.3.2.4">
        0.376
       </td>
       <td class="ltx_td ltx_align_right ltx_border_t" id="S2.T4.3.3.2.5">
        0.536
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T4.3.3.2.6">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.3.2.6.1">
         <span class="ltx_ERROR undefined" id="S2.T4.3.3.2.6.1.1">
          \seqsplit
         </span>
         <span class="ltx_p" id="S2.T4.3.3.2.6.1.2">
          [1.6126, 2.0783, 2.3073, 2.4565, 3.399, 3.475, 4.1377, 4.7104, 4.8864, 5.2187]
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S2.T4.3.4.3">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T4.3.4.3.1">
        mainly_beta_protein_1
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T4.3.4.3.2">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.4.3.2.1">
         <span class="ltx_ERROR undefined" id="S2.T4.3.4.3.2.1.1">
          \seqsplit
         </span>
         <span class="ltx_p" id="S2.T4.3.4.3.2.1.2">
          TTVTVTPPVADADGNEHSTVTAYGNKVTITITCPSNCTVTETVDGVAKTLGTVSGNQTITETRTIAPDEVVTRTYTCTPNASATSSK TQTVTIKGSQPAP
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T4.3.4.3.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.4.3.3.1">
         <span class="ltx_p" id="S2.T4.3.4.3.3.1.1">
          ’H’: 0.0, ’B’: 0.0, ’E’: 64.0, ’G’: 0.0, ’I’: 0.0, ’T’: 10.0, ’S’: 6.0, ’P’: 0.0, ’-’: 20.0
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_right ltx_border_t" id="S2.T4.3.4.3.4">
        0.462
       </td>
       <td class="ltx_td ltx_align_right ltx_border_t" id="S2.T4.3.4.3.5">
        0.533
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T4.3.4.3.6">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.4.3.6.1">
         <span class="ltx_ERROR undefined" id="S2.T4.3.4.3.6.1.1">
          \seqsplit
         </span>
         <span class="ltx_p" id="S2.T4.3.4.3.6.1.2">
          [1.2806, 1.5057, 1.9846, 2.1025, 2.4723, 2.702, 2.9931, 3.1498, 3.4432, 4.1685]
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S2.T4.3.5.4">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T4.3.5.4.1">
        mainly_beta_protein_2
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T4.3.5.4.2">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.5.4.2.1">
         <span class="ltx_ERROR undefined" id="S2.T4.3.5.4.2.1.1">
          \seqsplit
         </span>
         <span class="ltx_p" id="S2.T4.3.5.4.2.1.2">
          SLKAKNLEEMIKEAEKLGYSRDEVEKIINEIRDKFKKLGVKISEKTLAYIAYLRLLGVKIDWDKIKKVKKATPADFRVSEEDLKKP EIQKILEKIKKEIN
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T4.3.5.4.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.5.4.3.1">
         <span class="ltx_p" id="S2.T4.3.5.4.3.1.1">
          ’H’: 57.99, ’B’: 0.0, ’E’: 8.0, ’G’: 6.0, ’I’: 0.0, ’T’: 8.0, ’S’: 4.0, ’P’: 3.0, ’-’: 13.0
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_right ltx_border_t" id="S2.T4.3.5.4.4">
        0.371
       </td>
       <td class="ltx_td ltx_align_right ltx_border_t" id="S2.T4.3.5.4.5">
        0.548
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T4.3.5.4.6">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.5.4.6.1">
         <span class="ltx_p" id="S2.T4.3.5.4.6.1.1">
          [2.8864, 4.3752, 4.5928, 4.8295, 5.0854, 5.5618, 5.8646, 6.007, 6.3847, 7.1246]
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S2.T4.3.6.5">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S2.T4.3.6.5.1">
        alpha_beta_protein_1
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T4.3.6.5.2">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.6.5.2.1">
         <span class="ltx_ERROR undefined" id="S2.T4.3.6.5.2.1.1">
          \seqsplit
         </span>
         <span class="ltx_p" id="S2.T4.3.6.5.2.1.2">
          APTVKTFEDTINGQKVTVTVTASPGGKITIKTSPGYGDEVAKAFIEELKKQNVLESYKVESAPGKETTISDVKVKSGATVTFYVINN GKKGKEYSVTVDA
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T4.3.6.5.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.6.5.3.1">
         <span class="ltx_p" id="S2.T4.3.6.5.3.1.1">
          ’H’: 15.0, ’B’: 0.0, ’E’: 59.0, ’G’: 3.0, ’I’: 0.0, ’T’: 12.0, ’S’: 1.0, ’P’: 0.0, ’-’: 10.0
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_right ltx_border_t" id="S2.T4.3.6.5.4">
        0.424
       </td>
       <td class="ltx_td ltx_align_right ltx_border_t" id="S2.T4.3.6.5.5">
        0.535
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T4.3.6.5.6">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.6.5.6.1">
         <span class="ltx_ERROR undefined" id="S2.T4.3.6.5.6.1.1">
          \seqsplit
         </span>
         <span class="ltx_p" id="S2.T4.3.6.5.6.1.2">
          [2.4383, 2.5651, 3.3175, 3.8231, 3.9673, 4.2655, 4.6393, 5.1509, 5.6023, 5.9555]
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S2.T4.3.7.6">
       <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T4.3.7.6.1">
        alpha_beta_protein_2
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="S2.T4.3.7.6.2">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.7.6.2.1">
         <span class="ltx_ERROR undefined" id="S2.T4.3.7.6.2.1.1">
          \seqsplit
         </span>
         <span class="ltx_p" id="S2.T4.3.7.6.2.1.2">
          MELKVTEKKGKGDYKVKVIELNTPDKRYIIIESDASRESLIKAAEALLQGKEVEPTPVNEKNVVLFEDEDVKTSIERSKKLFKSDNPEE NIKKALEYLLK
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="S2.T4.3.7.6.3">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.7.6.3.1">
         <span class="ltx_p" id="S2.T4.3.7.6.3.1.1">
          ’H’: 35.0, ’B’: 0.0, ’E’: 28.999999999999996, ’G’: 0.0, ’I’: 0.0, ’T’: 3.0, ’S’: 12.0, ’P’: 3.0, ’-’: 18.0
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S2.T4.3.7.6.4">
        0.376
       </td>
       <td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S2.T4.3.7.6.5">
        0.543
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="S2.T4.3.7.6.6">
        <span class="ltx_inline-block ltx_align_top" id="S2.T4.3.7.6.6.1">
         <span class="ltx_ERROR undefined" id="S2.T4.3.7.6.6.1.1">
          \seqsplit
         </span>
         <span class="ltx_p" id="S2.T4.3.7.6.6.1.2">
          [2.8756, 3.8895, 4.0594, 4.2831, 4.5542, 5.171, 5.3661, 5.4312, 6.1964, 6.3066]
         </span>
        </span>
       </td>
      </tr>
     </tbody>
    </table>
   </figure>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   Conclusions
  </h2>
  <div class="ltx_para ltx_noindent" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    Large Language Models (LLMs) have made remarkable strides, revealing their immense potential to potentially replicate human-like intelligence across diverse domains and modalities, demonstrating proficiency in comprehending extensive collective knowledge and proving adept at effectively applying this information. However, to reach intelligent problem-solving systems, these types of models are not yet sufficient and require integration with other methods. In this study we explored the capability of AI agents to solve protein design problems in an autonomous manner without the need for human intervention. The agents have been powered by a general purpose LLM model, GPT-4, which allows them to communicate via conversation. It should be noted that the general capabilities of the AI agents powered by the LLM plays an important role at different stages of the problem solving. In our case, GPT-4-powered agents showed excellent proficiency specially in problem understanding, strategy development, and criticizing the outcomes. Such an AI system is not limited to mere linguistic interactions between agents; they have the capacity to incorporate a variety of special-purpose modeling and simulation tools, human input, tools for knowledge retrieval, and even deep learning-based surrogate models to solve particular tasks. Furthermore, additional tools can be integrated into the multi-agent system with popular external APIs and up-to-date knowledge about special topics can be retrieved by searching and browsing the web through specialized API interfaces. By harnessing the collective abilities of agents, including reasoning, tool usage, criticism, mutual correction, adaptation to new observations, and communication this framework has proven highly effective in navigating intricate challenges including protein design.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S3.p2">
   <p class="ltx_p" id="S3.p2.1">
    To achieve this goal we constructed a group of agents, each assigned a unique profile through initial prompts, to dynamically interact in a group chat via conversations and make decisions and take actions based on their observations. The agents profile outlines their attributes, roles, and functionalities within the system and describe communication protocols to exchange information with other agents in the system. Our team of agents include a user proxy to pose the query, a planner to formulate a plan, an function-baked assistant to execute the functions, and a critic to evaluate the outcome and criticizing the performance. We also use a chat manager to lead the group chat by dynamically choosing the working agent based on the current outcome and the agents’ roles. Through a series of experiments, we unleashed the power of agents in not only conducting the roles they were assigned to, but to autonomously collaborate by discussion powered by the all-purpose LLM. For example, the agent playing the role of a planner successfully identified all the tasks in the query and suggested a details plan including the necessary functions to accomplish them. Furthermore, the agent assigned the critic role, is able to give constructive feedback about the plan or provide suggestions in case of failure, to correct errors that may emerge. Our experiments have showcased the great potential of the multi-agent modeling framework in tackling complex tasks as well as integrating AI-agents into physics-based modeling.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S3.p3">
   <p class="ltx_p" id="S3.p3.1">
    Multi-agent modeling is a powerful technique that offers enhanced problem-solving capacity as shown here in various computational experiments in the realm of protein design, physics modeling, and analysis.
Given a complex query comprising multi-objective tasks, using the idea of division of labor, the model excels at developing a strategy to break the task into sub-tasks and then, recruiting a set of agents to effectively engage in problem solving tasks in an autonomous fashion. Tool-backed agents have the capacity to execute tools via function execution. We equipped an agent with a rich library of tools that span a broad spectrum of functionalities including
    <span class="ltx_text ltx_font_italic" id="S3.p3.1.1">
     de novo
    </span>
    protein design, protein folding, and protein secondary structure analysis among others. The fact that there is no intrinsic limitation in customizing the functions, allows us to integrate knowledge across different disciplines into our model and analysis, for instance by integrating knowledge retrieval systems or retrieving physical data via simulations. For instance, here we utilized coarse grained simulations to obtain natural frequencies of proteins but the model offers a high flexibility in defining functions that focus on other particular area simulation (e.g. an expert in performing Density Functional Theory, Molecular Dynamics, or even physics-inspired neural network solvers
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib71" title="">
      71
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib72" title="">
      72
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib37" title="">
      37
     </a>
     ]
    </cite>
    ). Multi-agent framework can also accelerate the discovery of
    <span class="ltx_text ltx_font_italic" id="S3.p3.1.2">
     de novo
    </span>
    proteins with targeted mechanical properties by embracing the power of robust end-to-end deep models solving forward and inverse protein design problems
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib24" title="">
      24
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib59" title="">
      59
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib17" title="">
      17
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib73" title="">
      73
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib74" title="">
      74
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib75" title="">
      75
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib76" title="">
      76
     </a>
     ]
    </cite>
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S3.p4">
   <p class="ltx_p" id="S3.p4.1">
    Developing these models that connect some structural protein features, such as secondary structure, to a material property, such as toughness or strength have gained a lot of attention recently. Here, we used a pre-trained autoregressive transformer model to predict the maximum force and energy of protein unfolding, but other end-to-end models could also be utilized. In the context of inverse protein design problems, a team of two agents, one expert in the forward tasks and the other in the inverse task, can be collaborated to assist the cycle check wherein the
    <span class="ltx_text ltx_font_italic" id="S3.p4.1.1">
     de novo
    </span>
    proteins certainly meet the specified property criteria. Along the same line, one could benefit from the multi-agent collaboration in evaluating the accuracy of generative models in conditional designing of proteins or compare the created 3D structures with the state-of-the art folding tools
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib16" title="">
      16
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib77" title="">
      77
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib78" title="">
      78
     </a>
     ]
    </cite>
    . For example, through an automated process of protein generation and structure analysis, our ProtAgents framework revealed the shortcomings of Chroma in designing
    <math alttext="\beta" class="ltx_Math" display="inline" id="S3.p4.1.m1.1">
     <semantics id="S3.p4.1.m1.1a">
      <mi id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml">
       β
      </mi>
      <annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b">
       <ci id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1">
        𝛽
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">
       \beta
      </annotation>
     </semantics>
    </math>
    -sheet-rich proteins. In another example, the folded 3D structures of Chroma were compared with those obtained by OmegaFold2. All these examples, demonstrate the capacity of multi-agent framework in a wide range of applications in the context of protein design and analysis. Lastly, the model enables integrating various information across scales, whether new protein sequences or physics simulations output in form of rich data structures, for inclusion in easily readable file formats (like JSON) to be used by other agents or to be stored for future analysis.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S3.p5">
   <p class="ltx_p" id="S3.p5.1">
    Designing
    <span class="ltx_text ltx_font_italic" id="S3.p5.1.1">
     de novo
    </span>
    proteins that meet special objectives in term of mechanical or structural properties present unique challenges calling for new strategies. The prevailing strategies often rely on developing data-driven end-to-end deep learning models to find the complex mapping from protein constitutive structure to property or vice versa. However, these models often focus on specific properties, limiting their functionality in multi-objective design purposes where several criteria needs to be met. To overcome these challenges and propel the field forward, future research endeavors could revolve around the development of an integrated system of agents designed to automate the entire lifecycle of training deep neural networks for protein design. Each agent within this system could be assigned specific responsibilities, such as data generation through simulations, data curation for ensuring quality and relevance, and the execution of the code required for model training. Additionally, a critic agent could monitor and critique the training process, making decisions like early stopping or tuning hyperparameters to enhance the model’s accuracy. This collaborative and automated approach would not only streamline the design process but also contribute to achieving higher or desired levels of accuracy in the generated models. Furthermore, this agent-based strategy can extend to on-the-fly active learning, where agents dynamically adapt the model based on real-time feedback, improving its performance iteratively. By incorporating intelligent agents at every stage of the process, the proposed system aims to revolutionize the landscape of
    <span class="ltx_text ltx_font_italic" id="S3.p5.1.2">
     de novo
    </span>
    protein design, making it more efficient, adaptive, and capable of meeting diverse and complex design objectives, offering a new paradigm in materials design workflows.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Materials and Methods
  </h2>
  <section class="ltx_subsection" id="S4.SSx1">
   <h3 class="ltx_title ltx_title_subsection">
    Agent design
   </h3>
   <div class="ltx_para ltx_noindent" id="S4.SSx1.p1">
    <p class="ltx_p" id="S4.SSx1.p1.1">
     As shown in Figure
     <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     a, we design AI agents using the state-of-the-art all-purpose LLM GPT-4 and dynamic multi-agent collaboration is implemented in AutoGen framework
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib79" title="">
       79
      </a>
      ]
     </cite>
     , an open-source ecosystem for agent-based AI modeling. Additional agents are introduced as described below, including some based on generative AI as well as physics modeling.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SSx1.p2">
    <p class="ltx_p" id="S4.SSx1.p2.1">
     In our multi-agent system, the human
     <span class="ltx_text ltx_font_italic" id="S4.SSx1.p2.1.1">
      user_proxy
     </span>
     agent is constructed using UserProxyAgent class from Autogen, and
     <span class="ltx_text ltx_font_italic" id="S4.SSx1.p2.1.2">
      Assistant
     </span>
     ,
     <span class="ltx_text ltx_font_italic" id="S4.SSx1.p2.1.3">
      Planner
     </span>
     ,
     <span class="ltx_text ltx_font_italic" id="S4.SSx1.p2.1.4">
      Critic
     </span>
     agents are created via AssistantAgent class from Autogen; and the group chat manager is created using GroupChatManager class. Each agent is assigned a role through a profile description listed in
     <span class="ltx_text ltx_font_bold" id="S4.SSx1.p2.1.5">
      Table
      <a class="ltx_ref" href="#S2.T1" title="Table 1 ‣ 2 Results and Discussion ‣ ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning Citation: A. Ghafarollahi, M.J. Buehler. arXiv, DOI:000000/11111., 2024">
       <span class="ltx_text ltx_ref_tag">
        1
       </span>
      </a>
     </span>
     , included as
     <span class="ltx_text ltx_font_italic" id="S4.SSx1.p2.1.6">
      system_message
     </span>
     at their creation.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SSx2">
   <h3 class="ltx_title ltx_title_subsection">
    Function and tool design
   </h3>
   <div class="ltx_para ltx_noindent" id="S4.SSx2.p1">
    <p class="ltx_p" id="S4.SSx2.p1.1">
     All the tools implemented in this work are defined as python functions. Each function is characterized by a name, a description, and input properties with a description as tabulated in
     <span class="ltx_text ltx_font_bold" id="S4.SSx2.p1.1.1">
      Table S1
     </span>
     of the Supplementary Material. The list of functions are incorporated into the multi-agent system, included as the
     <span class="ltx_text ltx_font_italic" id="S4.SSx2.p1.1.2">
      function_map
     </span>
     parameter in the Assistant agent at its creation.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SSx3">
   <h3 class="ltx_title ltx_title_subsection">
    Autoregressive transformer model to predict protein unfolding force-extension from sequences
   </h3>
   <div class="ltx_para ltx_noindent" id="S4.SSx3.p1">
    <p class="ltx_p" id="S4.SSx3.p1.1">
     We use a special-purpose GPT-style model denoted as ProteinForceGPT, similar as in , here trained to predict force-extension curves from sequences along with other mechanical properties, and vice versa (
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/lamm-mit/ProteinForceGPT" target="_blank" title="">
      https://huggingface.co/lamm-mit/ProteinForceGPT
     </a>
     ). The protein language model is based on the NeoGPT-X architecture and uses rotary positional embeddings (RoPE)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib80" title="">
       80
      </a>
      ]
     </cite>
     . The model has 16 attention heads, 36 hidden layers and a hidden size of 1024, an intermediate size of 4096 and uses GeLU activation functions.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SSx3.p2">
    <p class="ltx_p" id="S4.SSx3.p2.1">
     Pre-training was conducted based on a dataset of
     <math alttext="\sim 800,000" class="ltx_Math" display="inline" id="S4.SSx3.p2.1.m1.2">
      <semantics id="S4.SSx3.p2.1.m1.2a">
       <mrow id="S4.SSx3.p2.1.m1.2.3" xref="S4.SSx3.p2.1.m1.2.3.cmml">
        <mi id="S4.SSx3.p2.1.m1.2.3.2" xref="S4.SSx3.p2.1.m1.2.3.2.cmml">
        </mi>
        <mo id="S4.SSx3.p2.1.m1.2.3.1" xref="S4.SSx3.p2.1.m1.2.3.1.cmml">
         ∼
        </mo>
        <mrow id="S4.SSx3.p2.1.m1.2.3.3.2" xref="S4.SSx3.p2.1.m1.2.3.3.1.cmml">
         <mn id="S4.SSx3.p2.1.m1.1.1" xref="S4.SSx3.p2.1.m1.1.1.cmml">
          800
         </mn>
         <mo id="S4.SSx3.p2.1.m1.2.3.3.2.1" xref="S4.SSx3.p2.1.m1.2.3.3.1.cmml">
          ,
         </mo>
         <mn id="S4.SSx3.p2.1.m1.2.2" xref="S4.SSx3.p2.1.m1.2.2.cmml">
          000
         </mn>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SSx3.p2.1.m1.2b">
        <apply id="S4.SSx3.p2.1.m1.2.3.cmml" xref="S4.SSx3.p2.1.m1.2.3">
         <csymbol cd="latexml" id="S4.SSx3.p2.1.m1.2.3.1.cmml" xref="S4.SSx3.p2.1.m1.2.3.1">
          similar-to
         </csymbol>
         <csymbol cd="latexml" id="S4.SSx3.p2.1.m1.2.3.2.cmml" xref="S4.SSx3.p2.1.m1.2.3.2">
          absent
         </csymbol>
         <list id="S4.SSx3.p2.1.m1.2.3.3.1.cmml" xref="S4.SSx3.p2.1.m1.2.3.3.2">
          <cn id="S4.SSx3.p2.1.m1.1.1.cmml" type="integer" xref="S4.SSx3.p2.1.m1.1.1">
           800
          </cn>
          <cn id="S4.SSx3.p2.1.m1.2.2.cmml" type="integer" xref="S4.SSx3.p2.1.m1.2.2">
           000
          </cn>
         </list>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SSx3.p2.1.m1.2c">
        \sim 800,000
       </annotation>
      </semantics>
     </math>
     amino acid sequences, using next-token predictions using a “Sequence” task
(
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/lamm-mit/GPTProteinPretrained" target="_blank" title="">
      https://huggingface.co/datasets/lamm-mit/GPTProteinPretrained
     </a>
     ):
    </p>
    <blockquote class="ltx_quote" id="S4.SSx3.p2.2">
     <p class="ltx_p" id="S4.SSx3.p2.2.1">
      <span class="ltx_text ltx_font_typewriter" id="S4.SSx3.p2.2.1.1">
       Sequence&lt;GEECDCGSPSNPCCDAATCKLRPGAQCADGLCCDQCRFKKKRTICRIARGDFPDDRCTGQSADCPRWN&gt;
      </span>
     </p>
    </blockquote>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SSx3.p3">
    <p class="ltx_p" id="S4.SSx3.p3.1">
     The ProteinForceGPT model was then fine-tuned bidirectionally, to predict mechanical properties of proteins from their sequence, as well as sequence candidates that meet a required force-extension behavior and various other properties. Fine-tuning is conducted using a dataset derived from molecular dynamics (MD) simulations
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib81" title="">
       81
      </a>
      ]
     </cite>
     . Sample tasks for the model include:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SSx3.p4">
    <blockquote class="ltx_quote" id="S4.SSx3.p4.1">
     <p class="ltx_p" id="S4.SSx3.p4.1.1">
      <span class="ltx_text ltx_font_typewriter" id="S4.SSx3.p4.1.1.1">
       CalculateForce&lt;GEECDCGSPSNPCCDAATCKLRPGAQCADGLCCDQCRFKKKRTICRIARGDFPDDRCTGQSADCPRWN&gt; [0.262]
       <br class="ltx_break"/>
       CalculateEnergy&lt;GEECDCGSPSNPCCDAATCKLRPGAQCADGLCCDQCRFKKKRTICRIARGDFPDDRCTGQSADCPRWN&gt; [0.220]
       <br class="ltx_break"/>
       CalculateForceEnergy&lt;GEECDCGSPSNPCCDAATCKLRPGAQCADGLCCDQCRFKKKRTICRIARGDFPDDRCTGQSADCPRWN&gt; [0.262,0.220]
       <br class="ltx_break"/>
       CalculateForceHistory&lt;GEECDCGSPSNPCCDAATCKLRPGAQCADGLCCDQCRFKKKRTICRIARGDFPDDRCTGQSADCPRWN&gt;
[0.004,0.034,0.125,0.142,0.159,0.102,0.079,0.073, 0.131,0.105,0.071,0.058,0.072,0.060,0.049,0.114, 0.122,0.108,0.173,0.192,0.208,0.153,0.212,0.222,
0.244]
       <br class="ltx_break"/>
       GenerateForce&lt;0.262&gt; [GEECDCGSPSNPCCDAATCKLRPGAQCADGLCCDQCRFKKKRTICRIARGDFPDDRCTGQSADCPRWN]
       <br class="ltx_break"/>
       GenerateForce&lt;0.220&gt; [GEECDCGSPSNPCCDAATCKL RPGAQCADGLCCDQCRFKKKRTICRIARGDFPDDRCTGQSADCPRWN]
       <br class="ltx_break"/>
       GenerateForceEnergy&lt;0.262,0.220&gt; [GEECDCGSPSNPCCDAATCKLRPGAQCADGLCCDQCRFKKKRTICRIARGDFPDDRCT 
GQSADCPRWN]
       <br class="ltx_break"/>
       GenerateForceHistory&lt;0.004,0.034,0.125,0.142,0.159, 0.102,0.079,0.073,0.131,0.105,0.071,0.058,0.072,
0.060, 0.049,0.114,0.122,0.108,0.173,0.192,0.208,
0.153,0.212, 
0.222,0.244&gt;
[GEECDCGSPSNPCCDAATCKLR
PGAQCADGLCCDQCRFKKKRTICRIARGDFPDDRCTGQSADCPRWN]
      </span>
     </p>
    </blockquote>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SSx3.p5">
    <p class="ltx_p" id="S4.SSx3.p5.1">
     Sample results from validation of the model are shown in
     <span class="ltx_text ltx_font_bold" id="S4.SSx3.p5.1.1">
      Figure S2
     </span>
     . We only use forward predictions for use in the agent model reported here.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SSx4">
   <h3 class="ltx_title ltx_title_subsection">
    Software versions and hardware
   </h3>
   <div class="ltx_para ltx_noindent" id="S4.SSx4.p1">
    <p class="ltx_p" id="S4.SSx4.p1.1">
     We develop our multi-agent models using local workstations with NVIDIA GPUs. We use Python 3.10 and pyautogen-0.2.2
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib82" title="">
       82
      </a>
      ]
     </cite>
     . Additional implementation details are included in the code.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SSx5">
   <h3 class="ltx_title ltx_title_subsection">
    Visualization
   </h3>
   <div class="ltx_para ltx_noindent" id="S4.SSx5.p1">
    <p class="ltx_p" id="S4.SSx5.p1.1">
     We use Py3DMol
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib83" title="">
       83
      </a>
      ]
     </cite>
     for visualization of the protein structures.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SSx6">
   <h3 class="ltx_title ltx_title_subsection">
    Secondary Structure Analysis
   </h3>
   <div class="ltx_para ltx_noindent" id="S4.SSx6.p1">
    <p class="ltx_p" id="S4.SSx6.p1.1">
     We use the dictionary of protein secondary structure (DSSP)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib84" title="">
       84
      </a>
      ]
     </cite>
     module via BioPython
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib85" title="">
       85
      </a>
      ]
     </cite>
     to analyze the secondary structure content of the proteins from its geometry.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SSx7">
   <h3 class="ltx_title ltx_title_subsection">
    Natural Vibrational Frequency Calculations
   </h3>
   <div class="ltx_para ltx_noindent" id="S4.SSx7.p1">
    <p class="ltx_p" id="S4.SSx7.p1.1">
     We perform Anisotropic Network Model (ANM)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib86" title="">
       86
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib87" title="">
       87
      </a>
      ]
     </cite>
     calculations as implemented in ProDy
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib88" title="">
       88
      </a>
      ]
     </cite>
     for normal mode analysis. The problem is solved by considering the protein as a network of interactions, defined within a cutoff distance for which spring-like potentials are assumed to define molecular interactions.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SSx8">
   <h3 class="ltx_title ltx_title_subsection">
    Retrieval Augmented Generation
   </h3>
   <div class="ltx_para ltx_noindent" id="S4.SSx8.p1">
    <p class="ltx_p" id="S4.SSx8.p1.1">
     We use Llama Index
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib89" title="">
       89
      </a>
      ]
     </cite>
     as a tool to implement RAG where the full text of papers cited as references
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib65" title="">
       65
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib66" title="">
       66
      </a>
      ]
     </cite>
     are used as external sources from which information can be retrieved by the system in real-time.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SSx9">
   <h3 class="ltx_title ltx_title_subsection">
    Conflict of interest
   </h3>
   <div class="ltx_para ltx_noindent" id="S4.SSx9.p1">
    <p class="ltx_p" id="S4.SSx9.p1.1">
     The author declares no conflict of interest.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SSx10">
   <h3 class="ltx_title ltx_title_subsection">
    Data and code availability
   </h3>
   <div class="ltx_para ltx_noindent" id="S4.SSx10.p1">
    <p class="ltx_p" id="S4.SSx10.p1.1">
     All data and codes are available on GitHub at
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/lamm-mit/ProtAgents" target="_blank" title="">
      https://github.com/lamm-mit/ProtAgents
     </a>
     . Alternatively, they will be provided by the corresponding author based on reasonable request.
     <br class="ltx_break"/>
     <br class="ltx_break"/>
     <span class="ltx_text ltx_font_bold" id="S4.SSx10.p1.1.1">
      Author Contributions:
     </span>
     MJB and AG conceived the study and developed the multi-agent models. AG performed the tests for various problems, analyzed the results and prepared the first draft of the paper. MJB supported the analysis, revised and finalized the paper with AG.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SSx11">
   <h3 class="ltx_title ltx_title_subsection">
    Supplementary Materials
   </h3>
   <div class="ltx_para ltx_noindent" id="S4.SSx11.p1">
    <p class="ltx_p" id="S4.SSx11.p1.1">
     The full records of different conversation experiments along with additional materials are provided as Supplementary Materials.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="Sx1">
  <h2 class="ltx_title ltx_title_section">
   Acknowledgements
  </h2>
  <div class="ltx_para ltx_noindent" id="Sx1.p1">
   <p class="ltx_p" id="Sx1.p1.1">
    We acknowledge support from USDA (2021-69012-35978), DOE-SERDP (WP22-S1-3475), ARO (79058LSCSB, W911NF-22-2-0213 and W911NF2120130) as well as the MIT-IBM Watson AI Lab, MIT’s Generative AI Initiative, and Google. Additional support from NIH (U01EB014976 and R01AR077793) ONR (N00014-19-1-2375 and N00014-20-1-2189) is acknowledged. AG gratefully acknowledges the financial support from the Swiss National Science Foundation (#P500PT_214448).
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_tag_bibitem">
     [1]
    </span>
    <span class="ltx_bibblock">
     Po Ssu Huang, Scott E. Boyken, and David Baker.
    </span>
    <span class="ltx_bibblock">
     The coming of age of de novo protein design.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">
      Nature 2016 537:7620
     </span>
     , 537:320–327, 9 2016.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_tag_bibitem">
     [2]
    </span>
    <span class="ltx_bibblock">
     Pascal Notin, Mafalda Dias, Jonathan Frazer, Javier Marchena Hurtado, Aidan N Gomez, Debora Marks, and Yarin Gal.
    </span>
    <span class="ltx_bibblock">
     Tranception: Protein fitness prediction with autoregressive transformers and inference-time retrieval, 6 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_tag_bibitem">
     [3]
    </span>
    <span class="ltx_bibblock">
     John Ingraham, Vikas K Garg, Regina Barzilay, and Tommi Jaakkola.
    </span>
    <span class="ltx_bibblock">
     Generative models for graph-based protein design.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">
      Advances in Neural Information Processing Systems
     </span>
     , 32, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_tag_bibitem">
     [4]
    </span>
    <span class="ltx_bibblock">
     Kevin E. Wu, Kevin K. Yang, Rianne van den Berg, James Y. Zou, Alex X. Lu, and Ava P. Amini.
    </span>
    <span class="ltx_bibblock">
     Protein structure generation via folding diffusion.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">
      https://arxiv.org/abs/2209.15611v2
     </span>
     , 9 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_tag_bibitem">
     [5]
    </span>
    <span class="ltx_bibblock">
     Namrata Anand and Tudor Achim.
    </span>
    <span class="ltx_bibblock">
     Protein structure and sequence generation with equivariant denoising diffusion probabilistic models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">
      https://arxiv.org/abs/2205.15019v1
     </span>
     , 5 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_tag_bibitem">
     [6]
    </span>
    <span class="ltx_bibblock">
     Raphael R. Eguchi, Christian A. Choe, and Po Ssu Huang.
    </span>
    <span class="ltx_bibblock">
     Ig-vae: Generative modeling of protein structure by direct 3d coordinate generation.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">
      PLOS Computational Biology
     </span>
     , 18:e1010271, 6 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_tag_bibitem">
     [7]
    </span>
    <span class="ltx_bibblock">
     Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus.
    </span>
    <span class="ltx_bibblock">
     Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">
      Proceedings of the National Academy of Sciences of the United States of America
     </span>
     , 118:e2016239118, 4 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_tag_bibitem">
     [8]
    </span>
    <span class="ltx_bibblock">
     Ali Madani, Bryan McCann, Nikhil Naik, Nitish Shirish Keskar, Namrata Anand, Raphael R. Eguchi, Po-Ssu Huang, and Richard Socher.
    </span>
    <span class="ltx_bibblock">
     Progen: Language modeling for protein generation.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">
      https://arxiv.org/abs/2004.03497v1
     </span>
     , 3 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_tag_bibitem">
     [9]
    </span>
    <span class="ltx_bibblock">
     Namrata Anand, Raphael Eguchi, Irimpan I. Mathews, Carla P. Perez, Alexander Derry, Russ B. Altman, and Po Ssu Huang.
    </span>
    <span class="ltx_bibblock">
     Protein sequence design with a learned potential.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">
      Nature Communications 2022 13:1
     </span>
     , 13:1–11, 2 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_tag_bibitem">
     [10]
    </span>
    <span class="ltx_bibblock">
     Joe G. Greener, Lewis Moffat, and David T. Jones.
    </span>
    <span class="ltx_bibblock">
     Design of metalloproteins and novel protein folds using variational autoencoders.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">
      Scientific Reports 2018 8:1
     </span>
     , 8:1–12, 11 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_tag_bibitem">
     [11]
    </span>
    <span class="ltx_bibblock">
     Adam J. Riesselman, John B. Ingraham, and Debora S. Marks.
    </span>
    <span class="ltx_bibblock">
     Deep generative models of genetic variation capture the effects of mutations.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">
      Nature Methods 2018 15:10
     </span>
     , 15:816–822, 9 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_tag_bibitem">
     [12]
    </span>
    <span class="ltx_bibblock">
     Ethan C. Alley, Grigory Khimulya, Surojit Biswas, Mohammed AlQuraishi, and George M. Church.
    </span>
    <span class="ltx_bibblock">
     Unified rational protein engineering with sequence-based deep representation learning.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">
      Nature Methods 2019 16:12
     </span>
     , 16:1315–1322, 10 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_tag_bibitem">
     [13]
    </span>
    <span class="ltx_bibblock">
     Joseph L. Watson, David Juergens, Nathaniel R. Bennett, Brian L. Trippe, Jason Yim, Helen E. Eisenach, Woody Ahern, Andrew J. Borst, Robert J. Ragotte, Lukas F. Milles, Basile I.M. Wicky, Nikita Hanikel, Samuel J. Pellock, Alexis Courbet, William Sheffler, Jue Wang, Preetham Venkatesh, Isaac Sappington, Susana Vázquez Torres, Anna Lauko, Valentin De Bortoli, Emile Mathieu, Sergey Ovchinnikov, Regina Barzilay, Tommi S. Jaakkola, Frank DiMaio, Minkyung Baek, and David Baker.
    </span>
    <span class="ltx_bibblock">
     De novo design of protein structure and function with rfdiffusion.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">
      Nature 2023 620:7976
     </span>
     , 620:1089–1100, 7 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_tag_bibitem">
     [14]
    </span>
    <span class="ltx_bibblock">
     Ivan Anishchenko, Samuel J. Pellock, Tamuka M. Chidyausiku, Theresa A. Ramelot, Sergey Ovchinnikov, Jingzhou Hao, Khushboo Bafna, Christoffer Norn, Alex Kang, Asim K. Bera, Frank DiMaio, Lauren Carter, Cameron M. Chow, Gaetano T. Montelione, and David Baker.
    </span>
    <span class="ltx_bibblock">
     De novo protein design by deep network hallucination.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">
      Nature 2021 600:7889
     </span>
     , 600:547–552, 12 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_tag_bibitem">
     [15]
    </span>
    <span class="ltx_bibblock">
     John B. Ingraham, Max Baranov, Zak Costello, Karl W. Barber, Wujie Wang, Ahmed Ismail, Vincent Frappier, Dana M. Lord, Christopher Ng-Thow-Hing, Erik R. Van Vlack, Shan Tie, Vincent Xue, Sarah C. Cowles, Alan Leung, João V. Rodrigues, Claudio L. Morales-Perez, Alex M. Ayoub, Robin Green, Katherine Puentes, Frank Oplinger, Nishant V. Panwar, Fritz Obermeyer, Adam R. Root, Andrew L. Beam, Frank J. Poelwijk, and Gevorg Grigoryan.
    </span>
    <span class="ltx_bibblock">
     Illuminating protein space with a programmable generative model.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">
      Nature 2023 623:7989
     </span>
     , 623:1070–1078, 11 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_tag_bibitem">
     [16]
    </span>
    <span class="ltx_bibblock">
     John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Žídek, Anna Potapenko, Alex Bridgland, Clemens Meyer, Simon A.A. Kohl, Andrew J. Ballard, Andrew Cowie, Bernardino Romera-Paredes, Stanislav Nikolov, Rishub Jain, Jonas Adler, Trevor Back, Stig Petersen, David Reiman, Ellen Clancy, Michal Zielinski, Martin Steinegger, Michalina Pacholska, Tamas Berghammer, Sebastian Bodenstein, David Silver, Oriol Vinyals, Andrew W. Senior, Koray Kavukcuoglu, Pushmeet Kohli, and Demis Hassabis.
    </span>
    <span class="ltx_bibblock">
     Highly accurate protein structure prediction with alphafold.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">
      Nature 2021 596:7873
     </span>
     , 596:583–589, 7 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_tag_bibitem">
     [17]
    </span>
    <span class="ltx_bibblock">
     Chi Hua Yu, Wei Chen, Yu Hsuan Chiang, Kai Guo, Zaira Martin Moldes, David L. Kaplan, and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     End-to-end deep learning model to predict and design secondary structure content of structural proteins.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">
      ACS Biomaterials Science and Engineering
     </span>
     , 8:1156–1165, 3 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_tag_bibitem">
     [18]
    </span>
    <span class="ltx_bibblock">
     Ahmed Elnaggar, Michael Heinzinger, Christian Dallago, Ghalia Rehawi, Yu Wang, Llion Jones, Tom Gibbs, Tamas Feher, Christoph Angerer, Martin Steinegger, Debsindhu Bhowmik, and Burkhard Rost.
    </span>
    <span class="ltx_bibblock">
     Prottrans: Toward understanding the language of life through self-supervised learning.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">
      IEEE Transactions on Pattern Analysis and Machine Intelligence
     </span>
     , 44:7112–7127, 10 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_tag_bibitem">
     [19]
    </span>
    <span class="ltx_bibblock">
     Claudio Mirabello and Gianluca Pollastri.
    </span>
    <span class="ltx_bibblock">
     Porter, paleale 4.0: high-accuracy prediction of protein secondary structure and relative solvent accessibility.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">
      Bioinformatics
     </span>
     , 29:2056–2058, 8 2013.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_tag_bibitem">
     [20]
    </span>
    <span class="ltx_bibblock">
     Gianluca Pollastri, Darisz Przybylski, Burkhard Rost, and Pierre Baldi.
    </span>
    <span class="ltx_bibblock">
     Improving the prediction of protein secondary structure in three and eight classes using recurrent neural networks and profiles.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">
      Proteins: Structure, Function, and Bioinformatics
     </span>
     , 47:228–235, 5 2002.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_tag_bibitem">
     [21]
    </span>
    <span class="ltx_bibblock">
     Buzhong Zhang, Jinyan Li, and Qiang Lü.
    </span>
    <span class="ltx_bibblock">
     Prediction of 8-state protein secondary structures by a novel deep learning architecture.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">
      BMC Bioinformatics
     </span>
     , 19:1–13, 8 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_tag_bibitem">
     [22]
    </span>
    <span class="ltx_bibblock">
     Gianluca Pollastri and Aoife McLysaght.
    </span>
    <span class="ltx_bibblock">
     Porter: a new, accurate server for protein secondary structure prediction.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">
      Bioinformatics
     </span>
     , 21:1719–1720, 4 2005.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_tag_bibitem">
     [23]
    </span>
    <span class="ltx_bibblock">
     Kai Guo and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Rapid prediction of protein natural frequencies using graph neural networks.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">
      Digital Discovery
     </span>
     , 1:277–285, 6 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_tag_bibitem">
     [24]
    </span>
    <span class="ltx_bibblock">
     Yiwen Hu and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     End-to-end protein normal mode frequency predictions using language and graph models and application to sonification.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">
      ACS Nano
     </span>
     , 16:20656–20670, 12 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_tag_bibitem">
     [25]
    </span>
    <span class="ltx_bibblock">
     Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus.
    </span>
    <span class="ltx_bibblock">
     Emergent abilities of large language models.
    </span>
    <span class="ltx_bibblock">
     6 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_tag_bibitem">
     [26]
    </span>
    <span class="ltx_bibblock">
     Yupeng Chang, X U Wang, Yuan Wu, Hao Chen, Wei Ye, Yue Zhang, Y I Chang, Philip S Yu, Xiaoyuan Yi, Yi Chang, Qiang Yang, Hong Kong, Xu Wang, Jindong Wang, Linyi Yang, Kaijie Zhu, Cunxiang Wang, Yidong Wang, and Xing Xie.
    </span>
    <span class="ltx_bibblock">
     A survey on evaluation of large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib26.1.1">
      J. ACM
     </span>
     , 37:42, 7 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_tag_bibitem">
     [27]
    </span>
    <span class="ltx_bibblock">
     Kevin Maik Jablonka, Qianxiang Ai, Alexander Al-Feghali, Shruti Badhwar, Joshua D. Bocarsly, Andres M. Bran, Stefan Bringuier, L. Catherine Brinson, Kamal Choudhary, Defne Circi, Sam Cox, Wibe A. de Jong, Matthew L. Evans, Nicolas Gastellu, Jerome Genzling, María Victoria Gil, Ankur K. Gupta, Zhi Hong, Alishba Imran, Sabine Kruschwitz, Anne Labarre, Jakub Lála, Tao Liu, Steven Ma, Sauradeep Majumdar, Garrett W. Merz, Nicolas Moitessier, Elias Moubarak, Beatriz Mouriño, Brenden Pelkie, Michael Pieler, Mayk Caldas Ramos, Bojana Ranković, Samuel G. Rodriques, Jacob N. Sanders, Philippe Schwaller, Marcus Schwarting, Jiale Shi, Berend Smit, Ben E. Smith, Joren Van Herck, Christoph Völker, Logan Ward, Sean Warren, Benjamin Weiser, Sylvester Zhang, Xiaoqi Zhang, Ghezal Ahmad Zia, Aristana Scourtas, K. J. Schmidt, Ian Foster, Andrew D. White, and Ben Blaiszik.
    </span>
    <span class="ltx_bibblock">
     14 examples of how LLMs can transform materials science and chemistry: a reflection on a large language model hackathon.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib27.1.1">
      Digital Discovery
     </span>
     , 2:1233–1250, 10 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_tag_bibitem">
     [28]
    </span>
    <span class="ltx_bibblock">
     Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Melm, a generative pretrained language modeling framework that solves forward and inverse mechanics problems.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib28.1.1">
      Journal of the Mechanics and Physics of Solids
     </span>
     , 181:105454, 12 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_tag_bibitem">
     [29]
    </span>
    <span class="ltx_bibblock">
     Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Mechgpt, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib29.1.1">
      Applied Mechanics Reviews
     </span>
     , pages 1–82, 10 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_tag_bibitem">
     [30]
    </span>
    <span class="ltx_bibblock">
     James Boyko, Joseph Cohen, Nathan Fox, Maria Han Veiga, Jennifer I-Hsiu Li, Jing Liu, Bernardo Modenesi, Andreas H. Rauch, Kenneth N. Reid, Soumi Tribedi, Anastasia Visheratina, and Xin Xie.
    </span>
    <span class="ltx_bibblock">
     An interdisciplinary outlook on large language models for scientific research.
    </span>
    <span class="ltx_bibblock">
     11 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_tag_bibitem">
     [31]
    </span>
    <span class="ltx_bibblock">
     Bo Ni and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Mechagents: Large language model multi-agent collaborations can solve mechanics problems, generate new data, and integrate knowledge.
    </span>
    <span class="ltx_bibblock">
     2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_tag_bibitem">
     [32]
    </span>
    <span class="ltx_bibblock">
     Neal R. Brodnik, Samuel Carton, Caelin Muir, Satanu Ghosh, Doug Downey, McLean P. Echlin, Tresa M. Pollock, and Samantha Daly.
    </span>
    <span class="ltx_bibblock">
     Perspective: Large language models in applied mechanics.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib32.1.1">
      Journal of Applied Mechanics
     </span>
     , 90, 10 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_tag_bibitem">
     [33]
    </span>
    <span class="ltx_bibblock">
     Robert Tinn, Hao Cheng, Yu Gu, Tristan Naumann, Jianfeng Gao, Hoifung Poon Correspondence, Naoto Usuyama, Xiaodong Liu, and Hoifung Poon.
    </span>
    <span class="ltx_bibblock">
     Fine-tuning large neural language models for biomedical natural language processing highlights d systematic exploration of fine-tuning stability in biomedical nlp d domain-specific vocabulary and pretraining facilitate robust models for fine-tuning d pubmedbert-large and pubmedelectra models advance state-of-the-art in biomedical nlp in brief fine-tuning large neural language models for biomedical natural language processing.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib33.1.1">
      Patterns
     </span>
     , 4:100729, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_tag_bibitem">
     [34]
    </span>
    <span class="ltx_bibblock">
     Yiwen Hu and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Deep language models for interpretative and predictive materials science.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib34.1.1">
      APL Machine Learning
     </span>
     , 1:10901, 3 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_tag_bibitem">
     [35]
    </span>
    <span class="ltx_bibblock">
     Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Generative retrieval-augmented ontologic graph and multi-agent strategies for interpretive large language model-based materials design.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib35.1.1">
      ACS Engineering AU
     </span>
     , 10 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_tag_bibitem">
     [36]
    </span>
    <span class="ltx_bibblock">
     Rachel K. Luu and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Materials informatics tools in the context of bio-inspired material mechanics.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib36.1.1">
      Journal of Applied Mechanics
     </span>
     , 90, 9 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_tag_bibitem">
     [37]
    </span>
    <span class="ltx_bibblock">
     Grace C.Y. Peng, Mark Alber, Adrian Buganza Tepole, William R. Cannon, Suvranu De, Savador Dura-Bernal, Krishna Garikipati, George Karniadakis, William W. Lytton, Paris Perdikaris, Linda Petzold, and Ellen Kuhl.
    </span>
    <span class="ltx_bibblock">
     Multiscale modeling meets machine learning: What can we learn?
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib37.1.1">
      Archives of Computational Methods in Engineering
     </span>
     , 28:1017–1037, 5 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_tag_bibitem">
     [38]
    </span>
    <span class="ltx_bibblock">
     Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam Mccandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.
    </span>
    <span class="ltx_bibblock">
     Language models are few-shot learners.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib38.1.1">
      Advances in Neural Information Processing Systems
     </span>
     , 33:1877–1901, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_tag_bibitem">
     [39]
    </span>
    <span class="ltx_bibblock">
     Madeleine Bates.
    </span>
    <span class="ltx_bibblock">
     Models of natural language understanding.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib39.1.1">
      Proceedings of the National Academy of Sciences
     </span>
     , 92:9977–9982, 10 1995.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_tag_bibitem">
     [40]
    </span>
    <span class="ltx_bibblock">
     Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Vincent Zhao, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Pranesh Srinivasan, Laichee Man, Kathleen Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak, Ed Chi, and Quoc Le.
    </span>
    <span class="ltx_bibblock">
     Lamda: Language models for dialog applications.
    </span>
    <span class="ltx_bibblock">
     1 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_tag_bibitem">
     [41]
    </span>
    <span class="ltx_bibblock">
     Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel.
    </span>
    <span class="ltx_bibblock">
     Palm: Scaling language modeling with pathways.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib41.1.1">
      Journal of Machine Learning Research
     </span>
     , 24:1–113, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_tag_bibitem">
     [42]
    </span>
    <span class="ltx_bibblock">
     Ashish Vaswani, Google Brain, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin.
    </span>
    <span class="ltx_bibblock">
     Attention is all you need.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib42.1.1">
      Advances in Neural Information Processing Systems
     </span>
     , 30, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_tag_bibitem">
     [43]
    </span>
    <span class="ltx_bibblock">
     OpenAI and: Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mo Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu, Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Simón Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao,
Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kaftan, Łukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, Nitish Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong Wook Kim, Christina Kim, Yongjik Kim, Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo, Łukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung, Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin, Theresa Lopez, Ryan Lowe,
Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, Scott Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David Mély, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Long Ouyang, Cullen O’Keefe, Jakub Pachocki, Alex Paino, Joe Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita, Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de Avila Belbute Peres, Michael Petrov, Henrique Ponde de Oliveira Pinto, Michael, Pokorny, Michelle Pokrass, Vitchyr Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob Rotsted, Henri Roussez, Nick Ryder,
Mario Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Felipe Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan Felipe Cerón Uribe, Andrea Vallone, Arun Vijayvergiya, Chelsea Voss, Carroll Wainwright, Justin Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, CJ Weinmann, Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia Zhao, Tianhao
Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph.
    </span>
    <span class="ltx_bibblock">
     Gpt-4 technical report.
    </span>
    <span class="ltx_bibblock">
     3 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_tag_bibitem">
     [44]
    </span>
    <span class="ltx_bibblock">
     Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba.
    </span>
    <span class="ltx_bibblock">
     Evaluating large language models trained on code.
    </span>
    <span class="ltx_bibblock">
     7 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_tag_bibitem">
     [45]
    </span>
    <span class="ltx_bibblock">
     Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, and Yi Zhang.
    </span>
    <span class="ltx_bibblock">
     Sparks of Artificial General Intelligence: Early experiments with GPT-4.
    </span>
    <span class="ltx_bibblock">
     3 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_tag_bibitem">
     [46]
    </span>
    <span class="ltx_bibblock">
     Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al.
    </span>
    <span class="ltx_bibblock">
     Program synthesis with large language models.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib46.1.1">
      arXiv preprint arXiv:2108.07732
     </span>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_tag_bibitem">
     [47]
    </span>
    <span class="ltx_bibblock">
     Kai Guo, Zhenze Yang, Chi Hua Yu, and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Artificial intelligence and machine learning in design of mechanical materials.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib47.1.1">
      Materials Horizons
     </span>
     , 8:1153–1172, 4 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_tag_bibitem">
     [48]
    </span>
    <span class="ltx_bibblock">
     Zewen Li, Fan Liu, Wenjie Yang, Shouheng Peng, and Jun Zhou.
    </span>
    <span class="ltx_bibblock">
     A survey of convolutional neural networks: Analysis, applications, and prospects.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib48.1.1">
      IEEE Transactions on Neural Networks and Learning Systems
     </span>
     , 33:6999–7019, 12 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_tag_bibitem">
     [49]
    </span>
    <span class="ltx_bibblock">
     Keiron O’Shea and Ryan Nash.
    </span>
    <span class="ltx_bibblock">
     An introduction to convolutional neural networks.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib49.1.1">
      International Journal for Research in Applied Science and Engineering Technology
     </span>
     , 10:943–947, 11 2015.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_tag_bibitem">
     [50]
    </span>
    <span class="ltx_bibblock">
     Eric L. Buehler and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     End-to-end prediction of multimaterial stress fields and fracture patterns using cycle-consistent adversarial and transformer neural networks.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib50.1.1">
      Biomedical Engineering Advances
     </span>
     , 4:100038, 12 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_tag_bibitem">
     [51]
    </span>
    <span class="ltx_bibblock">
     Zhenze Yang, Chi Hua Yu, and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Deep learning model to predict complex stress and strain fields in hierarchical composites.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib51.1.1">
      Science Advances
     </span>
     , 7, 4 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_tag_bibitem">
     [52]
    </span>
    <span class="ltx_bibblock">
     Donatas Repecka, Vykintas Jauniskis, Laurynas Karpus, Elzbieta Rembeza, Irmantas Rokaitis, Jan Zrimec, Simona Poviloniene, Audrius Laurynenas, Sandra Viknander, Wissam Abuajwa, Otto Savolainen, Rolandas Meskys, Martin K.M. Engqvist, and Aleksej Zelezniak.
    </span>
    <span class="ltx_bibblock">
     Expanding functional protein sequence spaces using generative adversarial networks.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib52.1.1">
      Nature Machine Intelligence 2021 3:4
     </span>
     , 3:324–333, 3 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_tag_bibitem">
     [53]
    </span>
    <span class="ltx_bibblock">
     Renzhi Cao, Colton Freitas, Leong Chan, Miao Sun, Haiqing Jiang, and Zhangxin Chen.
    </span>
    <span class="ltx_bibblock">
     Prolango: Protein function prediction using neural machine translation based on a recurrent neural network.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib53.1.1">
      Molecules 2017, Vol. 22, Page 1732
     </span>
     , 22:1732, 10 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib54">
    <span class="ltx_tag ltx_tag_bibitem">
     [54]
    </span>
    <span class="ltx_bibblock">
     Yu-Chuan Hsu, Chi-Hua Yu, and Markus J Buehler.
    </span>
    <span class="ltx_bibblock">
     Using deep learning to predict fracture patterns in crystalline solids.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib54.1.1">
      Matter
     </span>
     , 3:197–211, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib55">
    <span class="ltx_tag ltx_tag_bibitem">
     [55]
    </span>
    <span class="ltx_bibblock">
     Wei Lu, Zhenze Yang, and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Rapid mechanical property prediction and de novo design of three-dimensional spider webs through graph and graphperceiver neural networks.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib55.1.1">
      Journal of Applied Physics
     </span>
     , 132:74703, 8 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib56">
    <span class="ltx_tag ltx_tag_bibitem">
     [56]
    </span>
    <span class="ltx_bibblock">
     Alexey Strokach, David Becerra, Carles Corbi-Verge, Albert Perez-Riba, and Philip M Kim.
    </span>
    <span class="ltx_bibblock">
     Fast and flexible protein design using deep graph neural networks.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib56.1.1">
      Cell Systems
     </span>
     , 11:402–411.e4, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib57">
    <span class="ltx_tag ltx_tag_bibitem">
     [57]
    </span>
    <span class="ltx_bibblock">
     Ronghui You, Shuwei Yao, Hiroshi Mamitsuka, and Shanfeng Zhu.
    </span>
    <span class="ltx_bibblock">
     Deepgraphgo: graph neural network for large-scale, multispecies protein function prediction.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib57.1.1">
      Bioinformatics
     </span>
     , 37:i262–i271, 7 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib58">
    <span class="ltx_tag ltx_tag_bibitem">
     [58]
    </span>
    <span class="ltx_bibblock">
     Zhenze Yang and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Linking atomic structural defects to mesoscale properties in crystalline solids using graph neural networks.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib58.1.1">
      npj Computational Materials 2022 8:1
     </span>
     , 8:1–13, 9 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib59">
    <span class="ltx_tag ltx_tag_bibitem">
     [59]
    </span>
    <span class="ltx_bibblock">
     Wei Lu, David L. Kaplan, and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Generative modeling, design, and analysis of spider silk protein sequences for enhanced mechanical properties.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib59.1.1">
      Advanced Functional Materials
     </span>
     , page 2311324, 12 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib60">
    <span class="ltx_tag ltx_tag_bibitem">
     [60]
    </span>
    <span class="ltx_bibblock">
     Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B. Tenenbaum, Tianmin Shu, and Chuang Gan.
    </span>
    <span class="ltx_bibblock">
     Building cooperative embodied agents modularly with large language models.
    </span>
    <span class="ltx_bibblock">
     7 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib61">
    <span class="ltx_tag ltx_tag_bibitem">
     [61]
    </span>
    <span class="ltx_bibblock">
     Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, and Ji-Rong Wen.
    </span>
    <span class="ltx_bibblock">
     A survey on large language model based autonomous agents.
    </span>
    <span class="ltx_bibblock">
     8 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib62">
    <span class="ltx_tag ltx_tag_bibitem">
     [62]
    </span>
    <span class="ltx_bibblock">
     Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing Huang, and Tao Gui.
    </span>
    <span class="ltx_bibblock">
     The rise and potential of large language model based agents: A survey.
    </span>
    <span class="ltx_bibblock">
     9 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib63">
    <span class="ltx_tag ltx_tag_bibitem">
     [63]
    </span>
    <span class="ltx_bibblock">
     Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela.
    </span>
    <span class="ltx_bibblock">
     Retrieval-augmented generation for knowledge-intensive nlp tasks.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib63.1.1">
      Advances in Neural Information Processing Systems
     </span>
     , 33:9459–9474, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib64">
    <span class="ltx_tag ltx_tag_bibitem">
     [64]
    </span>
    <span class="ltx_bibblock">
     Openai api.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib65">
    <span class="ltx_tag ltx_tag_bibitem">
     [65]
    </span>
    <span class="ltx_bibblock">
     Mateusz Sikora, Joanna I. Sułkowska, and Marek Cieplak.
    </span>
    <span class="ltx_bibblock">
     Mechanical strength of 17 134 model proteins and cysteine slipknots.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib65.1.1">
      PLOS Computational Biology
     </span>
     , 5:e1000547, 2009.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib66">
    <span class="ltx_tag ltx_tag_bibitem">
     [66]
    </span>
    <span class="ltx_bibblock">
     Arata Nakajo, Zacharie Wuillemin, Patrick Metzger, al, Yuxiu Liu, Michael W Murphy, Daniel R Baker, Ana Marija Damjanovi, Burak Koyutürk, Yan-Sheng Li, Joanna I Sułkowska, and Marek Cieplak.
    </span>
    <span class="ltx_bibblock">
     Mechanical stretching of proteins—a theoretical survey of the protein data bank.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib66.1.1">
      Journal of Physics: Condensed Matter
     </span>
     , 19:283201, 6 2007.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib67">
    <span class="ltx_tag ltx_tag_bibitem">
     [67]
    </span>
    <span class="ltx_bibblock">
     Theodor Ackbarow, Xuefeng Chen, Sinan Keten, and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Hierarchies, multiple energy barriers, and robustness govern the fracture mechanics of
     <math alttext="\alpha" class="ltx_Math" display="inline" id="bib.bib67.1.m1.1">
      <semantics id="bib.bib67.1.m1.1a">
       <mi id="bib.bib67.1.m1.1.1" xref="bib.bib67.1.m1.1.1.cmml">
        α
       </mi>
       <annotation-xml encoding="MathML-Content" id="bib.bib67.1.m1.1b">
        <ci id="bib.bib67.1.m1.1.1.cmml" xref="bib.bib67.1.m1.1.1">
         𝛼
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="bib.bib67.1.m1.1c">
        \alpha
       </annotation>
      </semantics>
     </math>
     -helical and
     <math alttext="\beta" class="ltx_Math" display="inline" id="bib.bib67.2.m2.1">
      <semantics id="bib.bib67.2.m2.1a">
       <mi id="bib.bib67.2.m2.1.1" xref="bib.bib67.2.m2.1.1.cmml">
        β
       </mi>
       <annotation-xml encoding="MathML-Content" id="bib.bib67.2.m2.1b">
        <ci id="bib.bib67.2.m2.1.1.cmml" xref="bib.bib67.2.m2.1.1">
         𝛽
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="bib.bib67.2.m2.1c">
        \beta
       </annotation>
      </semantics>
     </math>
     -sheet protein domains.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib67.3.1">
      Proceedings of the National Academy of Sciences of the United States of America
     </span>
     , 104:16410–16415, 10 2007.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib68">
    <span class="ltx_tag ltx_tag_bibitem">
     [68]
    </span>
    <span class="ltx_bibblock">
     Tuomas P.J. Knowles and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Nanomechanics of functional and pathological amyloid materials.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib68.1.1">
      Nature Nanotechnology 2011 6:8
     </span>
     , 6:469–479, 7 2011.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib69">
    <span class="ltx_tag ltx_tag_bibitem">
     [69]
    </span>
    <span class="ltx_bibblock">
     Zhiping Xu and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Mechanical energy transfer and dissipation in fibrous beta-sheet-rich proteins.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib69.1.1">
      Physical Review E - Statistical, Nonlinear, and Soft Matter Physics
     </span>
     , 81:061910, 6 2010.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib70">
    <span class="ltx_tag ltx_tag_bibitem">
     [70]
    </span>
    <span class="ltx_bibblock">
     Zhao Qin and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Cooperative deformation of hydrogen bonds in beta-strands and beta-sheet nanocrystals.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib70.1.1">
      Physical Review E - Statistical, Nonlinear, and Soft Matter Physics
     </span>
     , 82:061906, 12 2010.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib71">
    <span class="ltx_tag ltx_tag_bibitem">
     [71]
    </span>
    <span class="ltx_bibblock">
     Isaac Elias Lagaris, Aristidis Likas, and Dimitrios I. Fotiadis.
    </span>
    <span class="ltx_bibblock">
     Artificial neural networks for solving ordinary and partial differential equations.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib71.1.1">
      IEEE Transactions on Neural Networks
     </span>
     , 9:987–1000, 1998.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib72">
    <span class="ltx_tag ltx_tag_bibitem">
     [72]
    </span>
    <span class="ltx_bibblock">
     M. Raissi, P. Perdikaris, and G. E. Karniadakis.
    </span>
    <span class="ltx_bibblock">
     Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib72.1.1">
      Journal of Computational Physics
     </span>
     , 378:686–707, 2 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib73">
    <span class="ltx_tag ltx_tag_bibitem">
     [73]
    </span>
    <span class="ltx_bibblock">
     Frank Y.C. Liu, Bo Ni, and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Presto: Rapid protein mechanical strength prediction with an end-to-end deep learning model.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib73.1.1">
      Extreme Mechanics Letters
     </span>
     , 55:101803, 8 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib74">
    <span class="ltx_tag ltx_tag_bibitem">
     [74]
    </span>
    <span class="ltx_bibblock">
     Chi Hua Yu and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Sonification based de novo protein design using artificial intelligence, structure prediction, and analysis using molecular modeling.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib74.1.1">
      APL Bioengineering
     </span>
     , 4:16108, 3 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib75">
    <span class="ltx_tag ltx_tag_bibitem">
     [75]
    </span>
    <span class="ltx_bibblock">
     Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Generative pretrained autoregressive transformer graph neural network applied to the analysis and discovery of novel proteins.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib75.1.1">
      Journal of Applied Physics
     </span>
     , 134, 5 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib76">
    <span class="ltx_tag ltx_tag_bibitem">
     [76]
    </span>
    <span class="ltx_bibblock">
     Bo Ni, David L Kaplan, and Markus J Buehler.
    </span>
    <span class="ltx_bibblock">
     Generative design of de novo proteins based on secondary-structure constraints using an attention-based diffusion model.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib76.1.1">
      Chem
     </span>
     , 9:1828–1849, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib77">
    <span class="ltx_tag ltx_tag_bibitem">
     [77]
    </span>
    <span class="ltx_bibblock">
     Mohammed AlQuraishi.
    </span>
    <span class="ltx_bibblock">
     Machine learning in protein structure prediction.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib77.1.1">
      Current Opinion in Chemical Biology
     </span>
     , 65:1–8, 12 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib78">
    <span class="ltx_tag ltx_tag_bibitem">
     [78]
    </span>
    <span class="ltx_bibblock">
     Wenhao Gao, Sai Pooja Mahajan, Jeremias Sulam, and Jeffrey J Gray.
    </span>
    <span class="ltx_bibblock">
     Deep learning in protein structural modeling and design.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib78.1.1">
      Patterns
     </span>
     , 1:100142, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib79">
    <span class="ltx_tag ltx_tag_bibitem">
     [79]
    </span>
    <span class="ltx_bibblock">
     Chenxu Zhu, Bo Chen, Huifeng Guo, Hang Xu, Xiangyang Li, Xiangyu Zhao, Weinan Zhang, Yong Yu, and Ruiming Tang.
    </span>
    <span class="ltx_bibblock">
     Autogen: An automated dynamic model generation framework for recommender system.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib79.1.1">
      WSDM 2023 - Proceedings of the 16th ACM International Conference on Web Search and Data Mining
     </span>
     , pages 598–606, 2 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib80">
    <span class="ltx_tag ltx_tag_bibitem">
     [80]
    </span>
    <span class="ltx_bibblock">
     Jianlin Su, Murtadha Ahmed, Yu Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu.
    </span>
    <span class="ltx_bibblock">
     Roformer: Enhanced transformer with rotary position embedding.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib80.1.1">
      Neurocomputing
     </span>
     , 568:127063, 2024.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib81">
    <span class="ltx_tag ltx_tag_bibitem">
     [81]
    </span>
    <span class="ltx_bibblock">
     Bo Ni, David L. Kaplan, and Markus J. Buehler.
    </span>
    <span class="ltx_bibblock">
     Forcegen: End-to-end de novo protein generation based on nonlinear mechanical unfolding responses using a protein language diffusion model.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib81.1.1">
      Science Advances
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib82">
    <span class="ltx_tag ltx_tag_bibitem">
     [82]
    </span>
    <span class="ltx_bibblock">
     Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed Awadallah, Ryen W White, Doug Burger, and Chi Wang.
    </span>
    <span class="ltx_bibblock">
     Autogen: Enabling next-gen LLM applications via multi-agent conversation.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib82.1.1">
      https://arxiv.org/abs/2308.08155
     </span>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib83">
    <span class="ltx_tag ltx_tag_bibitem">
     [83]
    </span>
    <span class="ltx_bibblock">
     Nicholas Rego and David Koes.
    </span>
    <span class="ltx_bibblock">
     3dmol.js: molecular visualization with webgl.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib83.1.1">
      Bioinformatics
     </span>
     , 31:1322–1324, 4 2015.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib84">
    <span class="ltx_tag ltx_tag_bibitem">
     [84]
    </span>
    <span class="ltx_bibblock">
     Wolfgang Kabsch and Christian Sander.
    </span>
    <span class="ltx_bibblock">
     Dictionary of protein secondary structure: Pattern recognition of hydrogen-bonded and geometrical features.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib84.1.1">
      Biopolymers
     </span>
     , 22(12):2577–2637, 12 1983.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib85">
    <span class="ltx_tag ltx_tag_bibitem">
     [85]
    </span>
    <span class="ltx_bibblock">
     Peter J.A. Cock, Tiago Antao, Jeffrey T. Chang, Brad A. Chapman, Cymon J. Cox, Andrew Dalke, Iddo Friedberg, Thomas Hamelryck, Frank Kauff, Bartek Wilczynski, and Michiel J.L. De Hoon.
    </span>
    <span class="ltx_bibblock">
     Biopython: freely available python tools for computational molecular biology and bioinformatics.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib85.1.1">
      Bioinformatics
     </span>
     , 25:1422, 6 2009.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib86">
    <span class="ltx_tag ltx_tag_bibitem">
     [86]
    </span>
    <span class="ltx_bibblock">
     A R Atilgan, S R Durell, R L Jernigan, M C Demirel, O Keskin, and I Bahar.
    </span>
    <span class="ltx_bibblock">
     Anisotropy of fluctuation dynamics of proteins with an elastic network model.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib86.1.1">
      Biophys. J.
     </span>
     , 2001.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib87">
    <span class="ltx_tag ltx_tag_bibitem">
     [87]
    </span>
    <span class="ltx_bibblock">
     Pemra Doruker, Ali Rana Atilgan, and Ivet Bahar.
    </span>
    <span class="ltx_bibblock">
     Dynamics of proteins predicted by molecular dynamics simulations and analytical approaches: Application to-amylase inhibitor.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib87.1.1">
      PROTEINS: Structure, Function, and Bioinformatics
     </span>
     , 2000.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib88">
    <span class="ltx_tag ltx_tag_bibitem">
     [88]
    </span>
    <span class="ltx_bibblock">
     Ahmet Bakan, Lidio M. Meireles, and Ivet Bahar.
    </span>
    <span class="ltx_bibblock">
     Prody: Protein dynamics inferred from theory and experiments.
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text ltx_font_italic" id="bib.bib88.1.1">
      Bioinformatics
     </span>
     , 27:1575–1577, 6 2011.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib89">
    <span class="ltx_tag ltx_tag_bibitem">
     [89]
    </span>
    <span class="ltx_bibblock">
     LlamaIndex (formerly GPT index), a data framework for LLM applications.
    </span>
   </li>
  </ul>
 </section>
</article>
