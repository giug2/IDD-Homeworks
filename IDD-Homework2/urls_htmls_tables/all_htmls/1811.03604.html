<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[1811.03604] Federated learning for mobile keyboard prediction</title><meta property="og:description" content="We train a recurrent neural network language model using a distributed,
on-device learning framework called federated learning for the purpose of
next-word prediction in a virtual keyboard for smartphones. Server-based…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated learning for mobile keyboard prediction">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated learning for mobile keyboard prediction">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/1811.03604">

<!--Generated on Sat Mar 16 09:01:09 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Federated learning for mobile keyboard prediction</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">We train a recurrent neural network language model using a distributed,
on-device learning framework called federated learning for the purpose of
next-word prediction in a virtual keyboard for smartphones. Server-based
training using stochastic gradient descent is compared with training on client
devices using the <span id="id1.id1.1" class="ltx_text ltx_font_typewriter">FederatedAveraging</span> algorithm. The federated
algorithm, which enables training on a higher-quality dataset for this use case,
is shown to achieve better prediction recall. This work demonstrates the
feasibility and benefit of training language models on client devices without
exporting sensitive user data to servers. The federated learning environment
gives users greater control over the use of their data and simplifies the task
of incorporating privacy by default with distributed training and aggregation
across a population of client devices.</p>
</div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Index Terms<span id="p1.1.1.1" class="ltx_text ltx_font_upright">— </span></span>
Federated learning, keyboard, language modeling, NLP, CIFG.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Gboard — the Google keyboard<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>gboard.app.goo.gl/get</span></span></span>— is a virtual keyboard for
touchscreen mobile devices with support for more than 600 language varieties and
over 1 billion installs as of 2019. In addition to decoding noisy signals from
input modalities including tap and word-gesture typing, Gboard provides
auto-correction, word completion, and next-word prediction features.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/1811.03604/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="392" height="328" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text ltx_font_bold">Fig. 1</span>: </span>Next word predictions in Gboard. Based on the context “I love you”,
the keyboard predicts “and”, “too”, and “so much”.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">As users increasingly shift to mobile devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, reliable and
fast mobile input methods become more important. Next-word predictions provide a
tool for facilitating text entry. Based on a small amount of user-generated
preceding text, language models (LMs) can predict the most probable next word or
phrase. Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> provides an example: given the text,
“I love you”, Gboard predicts the user is likely to type “and”, “too”, or
“so much” next. The center position in the suggestion strip is reserved for
the highest-probability candidate, while the second and third most likely
candidates occupy the left and right positions, respectively.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Prior to this work, predictions were generated with a word n-gram finite state
transducer (FST) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. The mechanics of the FST decoder in Gboard —
including the role of the FST in literal decoding, corrections, and completions
— are described in Ref. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Next word predictions are built by
searching for the highest-order n-gram state that matches the preceding text.
The <math id="S1.p3.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S1.p3.1.m1.1a"><mi id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><ci id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">n</annotation></semantics></math>-best output labels from this state are returned. Paths containing
back-off transitions to lower-orders are also considered. The primary (static)
language model for the English language in Gboard is a Katz smoothed Bayesian
interpolated <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> 5-gram LM containing 1.25 million n-grams, including
164,000 unigrams. Personalized user history, contacts, and email n-gram models
augment the primary LM.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Mobile keyboard models are constrained in multiple ways. In order to run on both
low and high-end devices, models should be small and inference-time latency
should be low. Users typically expect a visible keyboard response within 20
milliseconds of an input event. Given the frequency with which mobile keyboard
apps are used, client device batteries could be quickly depleted if CPU
consumption were not constrained. As a result, language models are usually
limited to tens of megabytes in size with vocabularies of hundreds of thousands
of words.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Neural models — in particular word and character-level recurrent neural
networks (RNNs) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> — have been shown to perform well on language
modeling tasks  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. Unlike n-gram models
and feed-forward neural networks that rely on a fixed historical context window,
RNNs utilize an arbitrary and dynamically-sized context window. Exploding and
vanishing gradients in the back-propagation through time algorithm can be
resolved with the Long Short-Term Memory (LSTM) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. As of writing,
state-of-the art perplexities on the 1 billion word benchmark <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>
have been achieved with LSTM variants <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Training a prediction model requires a large data sample that is representative
of the text that users will commit. Publicly available datasets can be used,
though the training distribution often does not match the population’s
distribution. Another option is to sample user-generated text. This requires
logging, infrastructure, dedicated storage on a server, and security. Even with
data cleaning protocols and strict access controls, users might be uncomfortable
with the collection and remote storage of their personal data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">In this paper, we show that federated learning provides an alternative to the
server-based data collection and training paradigm in a commercial setting. We
train an RNN model from scratch in the server and federated environments and
achieve recall improvements with respect to the FST decoder baseline.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">The paper is organized in the following manner. Section <a href="#S2" title="2 Related Work ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>
summarizes prior work related to mobile input decoding, language modeling with
RNNs, and federated learning. Coupled Input-Forget Gates (CIFG) — the RNN
variant utilized for next-word prediction — are described in
Section <a href="#S3" title="3 Model Architecture ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Section <a href="#S4" title="4 Federated Learning ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> discusses the federated
averaging algorithm in more depth. Section <a href="#S5" title="5 Experiments ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> summarizes
experiments with federated and server-based training of the models. The results
of the studies are presented in Section <a href="#S6" title="6 Results ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, followed by
concluding remarks in Section <a href="#S7" title="7 Conclusion ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">FSTs have been explored in the context of mobile keyboard input decoding,
correction, and prediction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. LSTMs have greatly improved the
decoding of gestured inputs on mobile keyboards <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. RNN language models
optimized for word prediction rate and keystroke savings within inference-time
latency and memory constraints have also been published <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Research into distributed training for neural models has gained relevance with
the recent increased focus on privacy and government regulation. In particular,
federated learning has proved to be a useful extension of server-based
distributed training to client device-based training using locally stored
data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. Language models have been trained using the
federated algorithm combined with differential
privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. And Gboard has previously used
federated learning to train a model to suggest search queries based on typing
context <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, though the results have not been published yet. To the
best of our knowledge, there are no existing publications that train a neural
language model for a mobile keyboard with federated learning.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Model Architecture</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.3" class="ltx_p">The next-word prediction model uses a variant of the Long Short-Term Memory
(LSTM) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> recurrent neural network called the Coupled Input and Forget
Gate (CIFG) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. As with Gated Recurrent Units <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, the CIFG uses
a single gate to control both the input and recurrent cell self-connections,
reducing the number of parameters per cell by 25%. For timestep <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">t</annotation></semantics></math>, the input
gate <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="{i}_{t}" display="inline"><semantics id="S3.p1.2.m2.1a"><msub id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><mi id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">i</mi><mi id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2">𝑖</ci><ci id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">{i}_{t}</annotation></semantics></math> and forget gate <math id="S3.p1.3.m3.1" class="ltx_Math" alttext="{f}_{t}" display="inline"><semantics id="S3.p1.3.m3.1a"><msub id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml"><mi id="S3.p1.3.m3.1.1.2" xref="S3.p1.3.m3.1.1.2.cmml">f</mi><mi id="S3.p1.3.m3.1.1.3" xref="S3.p1.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><apply id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p1.3.m3.1.1.1.cmml" xref="S3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.p1.3.m3.1.1.2.cmml" xref="S3.p1.3.m3.1.1.2">𝑓</ci><ci id="S3.p1.3.m3.1.1.3.cmml" xref="S3.p1.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">{f}_{t}</annotation></semantics></math> have the relation:</p>
</div>
<div id="S3.p2" class="ltx_para">
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="{f}_{t}=1-{i}_{t}." display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.2.2.cmml">f</mi><mi id="S3.E1.m1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.2.3.cmml">t</mi></msub><mo id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml"><mn id="S3.E1.m1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.3.2.cmml">1</mn><mo id="S3.E1.m1.1.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.3.1.cmml">−</mo><msub id="S3.E1.m1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.3.2" xref="S3.E1.m1.1.1.1.1.3.3.2.cmml">i</mi><mi id="S3.E1.m1.1.1.1.1.3.3.3" xref="S3.E1.m1.1.1.1.1.3.3.3.cmml">t</mi></msub></mrow></mrow><mo lspace="0em" id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"></eq><apply id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2">𝑓</ci><ci id="S3.E1.m1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.3">𝑡</ci></apply><apply id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"><minus id="S3.E1.m1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.1"></minus><cn type="integer" id="S3.E1.m1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2">1</cn><apply id="S3.E1.m1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.2">𝑖</ci><ci id="S3.E1.m1.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">{f}_{t}=1-{i}_{t}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">The CIFG architecture is advantageous for the mobile device environment because
the number of computations and the parameter set size are reduced with no impact
on model performance. The model is trained using TensorFlow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>
without peephole connections. On-device inference is supported by TensorFlow
Lite<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://www.tensorflow.org/lite/</span></span></span>.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.7" class="ltx_p">Tied input embedding and output projection matrices are used to reduce the model
size and accelerate training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. Given a vocabulary of
size <math id="S3.p4.1.m1.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.p4.1.m1.1a"><mi id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><ci id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">V</annotation></semantics></math>, a one-hot encoding <math id="S3.p4.2.m2.1" class="ltx_Math" alttext="v\in{\mathbb{R}}^{V}" display="inline"><semantics id="S3.p4.2.m2.1a"><mrow id="S3.p4.2.m2.1.1" xref="S3.p4.2.m2.1.1.cmml"><mi id="S3.p4.2.m2.1.1.2" xref="S3.p4.2.m2.1.1.2.cmml">v</mi><mo id="S3.p4.2.m2.1.1.1" xref="S3.p4.2.m2.1.1.1.cmml">∈</mo><msup id="S3.p4.2.m2.1.1.3" xref="S3.p4.2.m2.1.1.3.cmml"><mi id="S3.p4.2.m2.1.1.3.2" xref="S3.p4.2.m2.1.1.3.2.cmml">ℝ</mi><mi id="S3.p4.2.m2.1.1.3.3" xref="S3.p4.2.m2.1.1.3.3.cmml">V</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.2.m2.1b"><apply id="S3.p4.2.m2.1.1.cmml" xref="S3.p4.2.m2.1.1"><in id="S3.p4.2.m2.1.1.1.cmml" xref="S3.p4.2.m2.1.1.1"></in><ci id="S3.p4.2.m2.1.1.2.cmml" xref="S3.p4.2.m2.1.1.2">𝑣</ci><apply id="S3.p4.2.m2.1.1.3.cmml" xref="S3.p4.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.p4.2.m2.1.1.3.1.cmml" xref="S3.p4.2.m2.1.1.3">superscript</csymbol><ci id="S3.p4.2.m2.1.1.3.2.cmml" xref="S3.p4.2.m2.1.1.3.2">ℝ</ci><ci id="S3.p4.2.m2.1.1.3.3.cmml" xref="S3.p4.2.m2.1.1.3.3">𝑉</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.2.m2.1c">v\in{\mathbb{R}}^{V}</annotation></semantics></math> is mapped to a dense
embedding vector <math id="S3.p4.3.m3.1" class="ltx_Math" alttext="d\in{\mathbb{R}}^{D}" display="inline"><semantics id="S3.p4.3.m3.1a"><mrow id="S3.p4.3.m3.1.1" xref="S3.p4.3.m3.1.1.cmml"><mi id="S3.p4.3.m3.1.1.2" xref="S3.p4.3.m3.1.1.2.cmml">d</mi><mo id="S3.p4.3.m3.1.1.1" xref="S3.p4.3.m3.1.1.1.cmml">∈</mo><msup id="S3.p4.3.m3.1.1.3" xref="S3.p4.3.m3.1.1.3.cmml"><mi id="S3.p4.3.m3.1.1.3.2" xref="S3.p4.3.m3.1.1.3.2.cmml">ℝ</mi><mi id="S3.p4.3.m3.1.1.3.3" xref="S3.p4.3.m3.1.1.3.3.cmml">D</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.3.m3.1b"><apply id="S3.p4.3.m3.1.1.cmml" xref="S3.p4.3.m3.1.1"><in id="S3.p4.3.m3.1.1.1.cmml" xref="S3.p4.3.m3.1.1.1"></in><ci id="S3.p4.3.m3.1.1.2.cmml" xref="S3.p4.3.m3.1.1.2">𝑑</ci><apply id="S3.p4.3.m3.1.1.3.cmml" xref="S3.p4.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.p4.3.m3.1.1.3.1.cmml" xref="S3.p4.3.m3.1.1.3">superscript</csymbol><ci id="S3.p4.3.m3.1.1.3.2.cmml" xref="S3.p4.3.m3.1.1.3.2">ℝ</ci><ci id="S3.p4.3.m3.1.1.3.3.cmml" xref="S3.p4.3.m3.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.3.m3.1c">d\in{\mathbb{R}}^{D}</annotation></semantics></math> by <math id="S3.p4.4.m4.1" class="ltx_Math" alttext="d=Wv" display="inline"><semantics id="S3.p4.4.m4.1a"><mrow id="S3.p4.4.m4.1.1" xref="S3.p4.4.m4.1.1.cmml"><mi id="S3.p4.4.m4.1.1.2" xref="S3.p4.4.m4.1.1.2.cmml">d</mi><mo id="S3.p4.4.m4.1.1.1" xref="S3.p4.4.m4.1.1.1.cmml">=</mo><mrow id="S3.p4.4.m4.1.1.3" xref="S3.p4.4.m4.1.1.3.cmml"><mi id="S3.p4.4.m4.1.1.3.2" xref="S3.p4.4.m4.1.1.3.2.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.p4.4.m4.1.1.3.1" xref="S3.p4.4.m4.1.1.3.1.cmml">​</mo><mi id="S3.p4.4.m4.1.1.3.3" xref="S3.p4.4.m4.1.1.3.3.cmml">v</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.4.m4.1b"><apply id="S3.p4.4.m4.1.1.cmml" xref="S3.p4.4.m4.1.1"><eq id="S3.p4.4.m4.1.1.1.cmml" xref="S3.p4.4.m4.1.1.1"></eq><ci id="S3.p4.4.m4.1.1.2.cmml" xref="S3.p4.4.m4.1.1.2">𝑑</ci><apply id="S3.p4.4.m4.1.1.3.cmml" xref="S3.p4.4.m4.1.1.3"><times id="S3.p4.4.m4.1.1.3.1.cmml" xref="S3.p4.4.m4.1.1.3.1"></times><ci id="S3.p4.4.m4.1.1.3.2.cmml" xref="S3.p4.4.m4.1.1.3.2">𝑊</ci><ci id="S3.p4.4.m4.1.1.3.3.cmml" xref="S3.p4.4.m4.1.1.3.3">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.4.m4.1c">d=Wv</annotation></semantics></math> with an embedding matrix
<math id="S3.p4.5.m5.1" class="ltx_Math" alttext="W\in{\mathbb{R}}^{D\times V}" display="inline"><semantics id="S3.p4.5.m5.1a"><mrow id="S3.p4.5.m5.1.1" xref="S3.p4.5.m5.1.1.cmml"><mi id="S3.p4.5.m5.1.1.2" xref="S3.p4.5.m5.1.1.2.cmml">W</mi><mo id="S3.p4.5.m5.1.1.1" xref="S3.p4.5.m5.1.1.1.cmml">∈</mo><msup id="S3.p4.5.m5.1.1.3" xref="S3.p4.5.m5.1.1.3.cmml"><mi id="S3.p4.5.m5.1.1.3.2" xref="S3.p4.5.m5.1.1.3.2.cmml">ℝ</mi><mrow id="S3.p4.5.m5.1.1.3.3" xref="S3.p4.5.m5.1.1.3.3.cmml"><mi id="S3.p4.5.m5.1.1.3.3.2" xref="S3.p4.5.m5.1.1.3.3.2.cmml">D</mi><mo lspace="0.222em" rspace="0.222em" id="S3.p4.5.m5.1.1.3.3.1" xref="S3.p4.5.m5.1.1.3.3.1.cmml">×</mo><mi id="S3.p4.5.m5.1.1.3.3.3" xref="S3.p4.5.m5.1.1.3.3.3.cmml">V</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.5.m5.1b"><apply id="S3.p4.5.m5.1.1.cmml" xref="S3.p4.5.m5.1.1"><in id="S3.p4.5.m5.1.1.1.cmml" xref="S3.p4.5.m5.1.1.1"></in><ci id="S3.p4.5.m5.1.1.2.cmml" xref="S3.p4.5.m5.1.1.2">𝑊</ci><apply id="S3.p4.5.m5.1.1.3.cmml" xref="S3.p4.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.p4.5.m5.1.1.3.1.cmml" xref="S3.p4.5.m5.1.1.3">superscript</csymbol><ci id="S3.p4.5.m5.1.1.3.2.cmml" xref="S3.p4.5.m5.1.1.3.2">ℝ</ci><apply id="S3.p4.5.m5.1.1.3.3.cmml" xref="S3.p4.5.m5.1.1.3.3"><times id="S3.p4.5.m5.1.1.3.3.1.cmml" xref="S3.p4.5.m5.1.1.3.3.1"></times><ci id="S3.p4.5.m5.1.1.3.3.2.cmml" xref="S3.p4.5.m5.1.1.3.3.2">𝐷</ci><ci id="S3.p4.5.m5.1.1.3.3.3.cmml" xref="S3.p4.5.m5.1.1.3.3.3">𝑉</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.5.m5.1c">W\in{\mathbb{R}}^{D\times V}</annotation></semantics></math>. The output projection of the CIFG, also in
<math id="S3.p4.6.m6.1" class="ltx_Math" alttext="{\mathbb{R}}^{D}" display="inline"><semantics id="S3.p4.6.m6.1a"><msup id="S3.p4.6.m6.1.1" xref="S3.p4.6.m6.1.1.cmml"><mi id="S3.p4.6.m6.1.1.2" xref="S3.p4.6.m6.1.1.2.cmml">ℝ</mi><mi id="S3.p4.6.m6.1.1.3" xref="S3.p4.6.m6.1.1.3.cmml">D</mi></msup><annotation-xml encoding="MathML-Content" id="S3.p4.6.m6.1b"><apply id="S3.p4.6.m6.1.1.cmml" xref="S3.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S3.p4.6.m6.1.1.1.cmml" xref="S3.p4.6.m6.1.1">superscript</csymbol><ci id="S3.p4.6.m6.1.1.2.cmml" xref="S3.p4.6.m6.1.1.2">ℝ</ci><ci id="S3.p4.6.m6.1.1.3.cmml" xref="S3.p4.6.m6.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.6.m6.1c">{\mathbb{R}}^{D}</annotation></semantics></math>, is mapped to the output vector <math id="S3.p4.7.m7.1" class="ltx_Math" alttext="{W}^{\mathsf{T}}h\in{\mathbb{R}}^{V}" display="inline"><semantics id="S3.p4.7.m7.1a"><mrow id="S3.p4.7.m7.1.1" xref="S3.p4.7.m7.1.1.cmml"><mrow id="S3.p4.7.m7.1.1.2" xref="S3.p4.7.m7.1.1.2.cmml"><msup id="S3.p4.7.m7.1.1.2.2" xref="S3.p4.7.m7.1.1.2.2.cmml"><mi id="S3.p4.7.m7.1.1.2.2.2" xref="S3.p4.7.m7.1.1.2.2.2.cmml">W</mi><mi id="S3.p4.7.m7.1.1.2.2.3" xref="S3.p4.7.m7.1.1.2.2.3.cmml">𝖳</mi></msup><mo lspace="0em" rspace="0em" id="S3.p4.7.m7.1.1.2.1" xref="S3.p4.7.m7.1.1.2.1.cmml">​</mo><mi id="S3.p4.7.m7.1.1.2.3" xref="S3.p4.7.m7.1.1.2.3.cmml">h</mi></mrow><mo id="S3.p4.7.m7.1.1.1" xref="S3.p4.7.m7.1.1.1.cmml">∈</mo><msup id="S3.p4.7.m7.1.1.3" xref="S3.p4.7.m7.1.1.3.cmml"><mi id="S3.p4.7.m7.1.1.3.2" xref="S3.p4.7.m7.1.1.3.2.cmml">ℝ</mi><mi id="S3.p4.7.m7.1.1.3.3" xref="S3.p4.7.m7.1.1.3.3.cmml">V</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.7.m7.1b"><apply id="S3.p4.7.m7.1.1.cmml" xref="S3.p4.7.m7.1.1"><in id="S3.p4.7.m7.1.1.1.cmml" xref="S3.p4.7.m7.1.1.1"></in><apply id="S3.p4.7.m7.1.1.2.cmml" xref="S3.p4.7.m7.1.1.2"><times id="S3.p4.7.m7.1.1.2.1.cmml" xref="S3.p4.7.m7.1.1.2.1"></times><apply id="S3.p4.7.m7.1.1.2.2.cmml" xref="S3.p4.7.m7.1.1.2.2"><csymbol cd="ambiguous" id="S3.p4.7.m7.1.1.2.2.1.cmml" xref="S3.p4.7.m7.1.1.2.2">superscript</csymbol><ci id="S3.p4.7.m7.1.1.2.2.2.cmml" xref="S3.p4.7.m7.1.1.2.2.2">𝑊</ci><ci id="S3.p4.7.m7.1.1.2.2.3.cmml" xref="S3.p4.7.m7.1.1.2.2.3">𝖳</ci></apply><ci id="S3.p4.7.m7.1.1.2.3.cmml" xref="S3.p4.7.m7.1.1.2.3">ℎ</ci></apply><apply id="S3.p4.7.m7.1.1.3.cmml" xref="S3.p4.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.p4.7.m7.1.1.3.1.cmml" xref="S3.p4.7.m7.1.1.3">superscript</csymbol><ci id="S3.p4.7.m7.1.1.3.2.cmml" xref="S3.p4.7.m7.1.1.3.2">ℝ</ci><ci id="S3.p4.7.m7.1.1.3.3.cmml" xref="S3.p4.7.m7.1.1.3.3">𝑉</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.7.m7.1c">{W}^{\mathsf{T}}h\in{\mathbb{R}}^{V}</annotation></semantics></math>. A softmax function over the output vector converts the raw
logits into normalized probabilities. Cross-entropy loss over the output and
target labels is used for training.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.3" class="ltx_p">The client device requirements alluded to in Section <a href="#S1" title="1 Introduction ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>
limit the vocabulary and model sizes. A dictionary of <math id="S3.p5.1.m1.1" class="ltx_Math" alttext="V=\text{10,000}" display="inline"><semantics id="S3.p5.1.m1.1a"><mrow id="S3.p5.1.m1.1.1" xref="S3.p5.1.m1.1.1.cmml"><mi id="S3.p5.1.m1.1.1.2" xref="S3.p5.1.m1.1.1.2.cmml">V</mi><mo id="S3.p5.1.m1.1.1.1" xref="S3.p5.1.m1.1.1.1.cmml">=</mo><mtext id="S3.p5.1.m1.1.1.3" xref="S3.p5.1.m1.1.1.3a.cmml">10,000</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.p5.1.m1.1b"><apply id="S3.p5.1.m1.1.1.cmml" xref="S3.p5.1.m1.1.1"><eq id="S3.p5.1.m1.1.1.1.cmml" xref="S3.p5.1.m1.1.1.1"></eq><ci id="S3.p5.1.m1.1.1.2.cmml" xref="S3.p5.1.m1.1.1.2">𝑉</ci><ci id="S3.p5.1.m1.1.1.3a.cmml" xref="S3.p5.1.m1.1.1.3"><mtext id="S3.p5.1.m1.1.1.3.cmml" xref="S3.p5.1.m1.1.1.3">10,000</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.1.m1.1c">V=\text{10,000}</annotation></semantics></math> words is
used for the input and output vocabularies. Input tokens include special
beginning of sentence, end of sentence, and out-of-vocabulary tokens. During
network evaluation and inference, the logits corresponding to these special
tokens are ignored. The input embedding and CIFG output projection dimension <math id="S3.p5.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.p5.2.m2.1a"><mi id="S3.p5.2.m2.1.1" xref="S3.p5.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.p5.2.m2.1b"><ci id="S3.p5.2.m2.1.1.cmml" xref="S3.p5.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.2.m2.1c">D</annotation></semantics></math>
is set to 96. A single layer CIFG with 670 units is used. Overall, 1.4 million
parameters comprise the network — more than two thirds of which are associated
with the embedding matrix <math id="S3.p5.3.m3.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.p5.3.m3.1a"><mi id="S3.p5.3.m3.1.1" xref="S3.p5.3.m3.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.p5.3.m3.1b"><ci id="S3.p5.3.m3.1.1.cmml" xref="S3.p5.3.m3.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.3.m3.1c">W</annotation></semantics></math>. After weight quantization, the model shipped to
Gboard devices is 1.4 megabytes in size.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Federated Learning</h2>

<figure id="S4.F2" class="ltx_figure"><img src="/html/1811.03604/assets/fl_illustration.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="592" height="334" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.2.1.1" class="ltx_text ltx_font_bold">Fig. 2</span>: </span>An illustration of the federated learning process from
Ref. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>: (A) client devices compute SGD updates on
locally-stored data, (B) a server aggregates the client updates
to build a new global model, (C) the new model is sent back to
clients, and the process is repeated.</figcaption>
</figure>
<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> provides a decentralized
computation strategy that can be employed to train a neural model. Mobile
devices, referred to as clients, generate large volumes of personal data that
can be used for training. Instead of uploading data to servers for centralized
training, clients process their local data and share model updates with the
server. Weights from a large population of clients are aggregated by the server
and combined to create an improved global model.
Figure <a href="#S4.F2" title="Figure 2 ‣ 4 Federated Learning ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> provides an illustration of the process. The
distributed approach has been shown to work with unbalanced datasets and data
that are not independent or identically distributed across clients.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.8" class="ltx_p">The <span id="S4.p2.8.1" class="ltx_text ltx_font_typewriter">FederatedAveraging</span> algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> is used on the server
to combine client updates and produce a new global model. At training round <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.p2.1.m1.1a"><mi id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><ci id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">t</annotation></semantics></math>,
a global model <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="{w}_{t}" display="inline"><semantics id="S4.p2.2.m2.1a"><msub id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml"><mi id="S4.p2.2.m2.1.1.2" xref="S4.p2.2.m2.1.1.2.cmml">w</mi><mi id="S4.p2.2.m2.1.1.3" xref="S4.p2.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><apply id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.1.cmml" xref="S4.p2.2.m2.1.1">subscript</csymbol><ci id="S4.p2.2.m2.1.1.2.cmml" xref="S4.p2.2.m2.1.1.2">𝑤</ci><ci id="S4.p2.2.m2.1.1.3.cmml" xref="S4.p2.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">{w}_{t}</annotation></semantics></math> is sent to a subset <math id="S4.p2.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.p2.3.m3.1a"><mi id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><ci id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">K</annotation></semantics></math> of client devices. In the
special case of <math id="S4.p2.4.m4.1" class="ltx_Math" alttext="t=0" display="inline"><semantics id="S4.p2.4.m4.1a"><mrow id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml"><mi id="S4.p2.4.m4.1.1.2" xref="S4.p2.4.m4.1.1.2.cmml">t</mi><mo id="S4.p2.4.m4.1.1.1" xref="S4.p2.4.m4.1.1.1.cmml">=</mo><mn id="S4.p2.4.m4.1.1.3" xref="S4.p2.4.m4.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.1b"><apply id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1"><eq id="S4.p2.4.m4.1.1.1.cmml" xref="S4.p2.4.m4.1.1.1"></eq><ci id="S4.p2.4.m4.1.1.2.cmml" xref="S4.p2.4.m4.1.1.2">𝑡</ci><cn type="integer" id="S4.p2.4.m4.1.1.3.cmml" xref="S4.p2.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.1c">t=0</annotation></semantics></math>, client devices start from the same global model that has
either been randomly initialized or pre-trained on proxy data. Each of the
clients participating in a given round has a local dataset consisting of
<math id="S4.p2.5.m5.1" class="ltx_Math" alttext="{n}_{k}" display="inline"><semantics id="S4.p2.5.m5.1a"><msub id="S4.p2.5.m5.1.1" xref="S4.p2.5.m5.1.1.cmml"><mi id="S4.p2.5.m5.1.1.2" xref="S4.p2.5.m5.1.1.2.cmml">n</mi><mi id="S4.p2.5.m5.1.1.3" xref="S4.p2.5.m5.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.5.m5.1b"><apply id="S4.p2.5.m5.1.1.cmml" xref="S4.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S4.p2.5.m5.1.1.1.cmml" xref="S4.p2.5.m5.1.1">subscript</csymbol><ci id="S4.p2.5.m5.1.1.2.cmml" xref="S4.p2.5.m5.1.1.2">𝑛</ci><ci id="S4.p2.5.m5.1.1.3.cmml" xref="S4.p2.5.m5.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.5.m5.1c">{n}_{k}</annotation></semantics></math> examples, where <math id="S4.p2.6.m6.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.p2.6.m6.1a"><mi id="S4.p2.6.m6.1.1" xref="S4.p2.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.p2.6.m6.1b"><ci id="S4.p2.6.m6.1.1.cmml" xref="S4.p2.6.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.6.m6.1c">k</annotation></semantics></math> is an index of participating clients. <math id="S4.p2.7.m7.1" class="ltx_Math" alttext="{n}_{k}" display="inline"><semantics id="S4.p2.7.m7.1a"><msub id="S4.p2.7.m7.1.1" xref="S4.p2.7.m7.1.1.cmml"><mi id="S4.p2.7.m7.1.1.2" xref="S4.p2.7.m7.1.1.2.cmml">n</mi><mi id="S4.p2.7.m7.1.1.3" xref="S4.p2.7.m7.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.7.m7.1b"><apply id="S4.p2.7.m7.1.1.cmml" xref="S4.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S4.p2.7.m7.1.1.1.cmml" xref="S4.p2.7.m7.1.1">subscript</csymbol><ci id="S4.p2.7.m7.1.1.2.cmml" xref="S4.p2.7.m7.1.1.2">𝑛</ci><ci id="S4.p2.7.m7.1.1.3.cmml" xref="S4.p2.7.m7.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.7.m7.1c">{n}_{k}</annotation></semantics></math>
varies from device to device. For studies in Gboard, <math id="S4.p2.8.m8.1" class="ltx_Math" alttext="{n}_{k}" display="inline"><semantics id="S4.p2.8.m8.1a"><msub id="S4.p2.8.m8.1.1" xref="S4.p2.8.m8.1.1.cmml"><mi id="S4.p2.8.m8.1.1.2" xref="S4.p2.8.m8.1.1.2.cmml">n</mi><mi id="S4.p2.8.m8.1.1.3" xref="S4.p2.8.m8.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.8.m8.1b"><apply id="S4.p2.8.m8.1.1.cmml" xref="S4.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S4.p2.8.m8.1.1.1.cmml" xref="S4.p2.8.m8.1.1">subscript</csymbol><ci id="S4.p2.8.m8.1.1.2.cmml" xref="S4.p2.8.m8.1.1.2">𝑛</ci><ci id="S4.p2.8.m8.1.1.3.cmml" xref="S4.p2.8.m8.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.8.m8.1c">{n}_{k}</annotation></semantics></math> is related to the
user’s typing volume.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.4" class="ltx_p">Every client computes the average gradient, <math id="S4.p3.1.m1.1" class="ltx_Math" alttext="{g}_{k}" display="inline"><semantics id="S4.p3.1.m1.1a"><msub id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml"><mi id="S4.p3.1.m1.1.1.2" xref="S4.p3.1.m1.1.1.2.cmml">g</mi><mi id="S4.p3.1.m1.1.1.3" xref="S4.p3.1.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><apply id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p3.1.m1.1.1.1.cmml" xref="S4.p3.1.m1.1.1">subscript</csymbol><ci id="S4.p3.1.m1.1.1.2.cmml" xref="S4.p3.1.m1.1.1.2">𝑔</ci><ci id="S4.p3.1.m1.1.1.3.cmml" xref="S4.p3.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">{g}_{k}</annotation></semantics></math>, on its local data with
the current model <math id="S4.p3.2.m2.1" class="ltx_Math" alttext="{w}_{t}" display="inline"><semantics id="S4.p3.2.m2.1a"><msub id="S4.p3.2.m2.1.1" xref="S4.p3.2.m2.1.1.cmml"><mi id="S4.p3.2.m2.1.1.2" xref="S4.p3.2.m2.1.1.2.cmml">w</mi><mi id="S4.p3.2.m2.1.1.3" xref="S4.p3.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.1b"><apply id="S4.p3.2.m2.1.1.cmml" xref="S4.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p3.2.m2.1.1.1.cmml" xref="S4.p3.2.m2.1.1">subscript</csymbol><ci id="S4.p3.2.m2.1.1.2.cmml" xref="S4.p3.2.m2.1.1.2">𝑤</ci><ci id="S4.p3.2.m2.1.1.3.cmml" xref="S4.p3.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.1c">{w}_{t}</annotation></semantics></math> using one or more steps of stochastic gradient
descent (SGD). For a client learning rate <math id="S4.p3.3.m3.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.p3.3.m3.1a"><mi id="S4.p3.3.m3.1.1" xref="S4.p3.3.m3.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.p3.3.m3.1b"><ci id="S4.p3.3.m3.1.1.cmml" xref="S4.p3.3.m3.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.3.m3.1c">\epsilon</annotation></semantics></math>, the local client update,
<math id="S4.p3.4.m4.1" class="ltx_Math" alttext="{w}_{t+1}^{k}" display="inline"><semantics id="S4.p3.4.m4.1a"><msubsup id="S4.p3.4.m4.1.1" xref="S4.p3.4.m4.1.1.cmml"><mi id="S4.p3.4.m4.1.1.2.2" xref="S4.p3.4.m4.1.1.2.2.cmml">w</mi><mrow id="S4.p3.4.m4.1.1.2.3" xref="S4.p3.4.m4.1.1.2.3.cmml"><mi id="S4.p3.4.m4.1.1.2.3.2" xref="S4.p3.4.m4.1.1.2.3.2.cmml">t</mi><mo id="S4.p3.4.m4.1.1.2.3.1" xref="S4.p3.4.m4.1.1.2.3.1.cmml">+</mo><mn id="S4.p3.4.m4.1.1.2.3.3" xref="S4.p3.4.m4.1.1.2.3.3.cmml">1</mn></mrow><mi id="S4.p3.4.m4.1.1.3" xref="S4.p3.4.m4.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.p3.4.m4.1b"><apply id="S4.p3.4.m4.1.1.cmml" xref="S4.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S4.p3.4.m4.1.1.1.cmml" xref="S4.p3.4.m4.1.1">superscript</csymbol><apply id="S4.p3.4.m4.1.1.2.cmml" xref="S4.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S4.p3.4.m4.1.1.2.1.cmml" xref="S4.p3.4.m4.1.1">subscript</csymbol><ci id="S4.p3.4.m4.1.1.2.2.cmml" xref="S4.p3.4.m4.1.1.2.2">𝑤</ci><apply id="S4.p3.4.m4.1.1.2.3.cmml" xref="S4.p3.4.m4.1.1.2.3"><plus id="S4.p3.4.m4.1.1.2.3.1.cmml" xref="S4.p3.4.m4.1.1.2.3.1"></plus><ci id="S4.p3.4.m4.1.1.2.3.2.cmml" xref="S4.p3.4.m4.1.1.2.3.2">𝑡</ci><cn type="integer" id="S4.p3.4.m4.1.1.2.3.3.cmml" xref="S4.p3.4.m4.1.1.2.3.3">1</cn></apply></apply><ci id="S4.p3.4.m4.1.1.3.cmml" xref="S4.p3.4.m4.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.4.m4.1c">{w}_{t+1}^{k}</annotation></semantics></math>, is given by:</p>
</div>
<div id="S4.p4" class="ltx_para">
<table id="S4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E2.m1.1" class="ltx_Math" alttext="{w}_{t}-\epsilon{g}_{k}\rightarrow{w}_{t+1}^{k}." display="block"><semantics id="S4.E2.m1.1a"><mrow id="S4.E2.m1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml"><mrow id="S4.E2.m1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml"><mrow id="S4.E2.m1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.2.cmml"><msub id="S4.E2.m1.1.1.1.1.2.2" xref="S4.E2.m1.1.1.1.1.2.2.cmml"><mi id="S4.E2.m1.1.1.1.1.2.2.2" xref="S4.E2.m1.1.1.1.1.2.2.2.cmml">w</mi><mi id="S4.E2.m1.1.1.1.1.2.2.3" xref="S4.E2.m1.1.1.1.1.2.2.3.cmml">t</mi></msub><mo id="S4.E2.m1.1.1.1.1.2.1" xref="S4.E2.m1.1.1.1.1.2.1.cmml">−</mo><mrow id="S4.E2.m1.1.1.1.1.2.3" xref="S4.E2.m1.1.1.1.1.2.3.cmml"><mi id="S4.E2.m1.1.1.1.1.2.3.2" xref="S4.E2.m1.1.1.1.1.2.3.2.cmml">ϵ</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.2.3.1" xref="S4.E2.m1.1.1.1.1.2.3.1.cmml">​</mo><msub id="S4.E2.m1.1.1.1.1.2.3.3" xref="S4.E2.m1.1.1.1.1.2.3.3.cmml"><mi id="S4.E2.m1.1.1.1.1.2.3.3.2" xref="S4.E2.m1.1.1.1.1.2.3.3.2.cmml">g</mi><mi id="S4.E2.m1.1.1.1.1.2.3.3.3" xref="S4.E2.m1.1.1.1.1.2.3.3.3.cmml">k</mi></msub></mrow></mrow><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.cmml">→</mo><msubsup id="S4.E2.m1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.3.cmml"><mi id="S4.E2.m1.1.1.1.1.3.2.2" xref="S4.E2.m1.1.1.1.1.3.2.2.cmml">w</mi><mrow id="S4.E2.m1.1.1.1.1.3.2.3" xref="S4.E2.m1.1.1.1.1.3.2.3.cmml"><mi id="S4.E2.m1.1.1.1.1.3.2.3.2" xref="S4.E2.m1.1.1.1.1.3.2.3.2.cmml">t</mi><mo id="S4.E2.m1.1.1.1.1.3.2.3.1" xref="S4.E2.m1.1.1.1.1.3.2.3.1.cmml">+</mo><mn id="S4.E2.m1.1.1.1.1.3.2.3.3" xref="S4.E2.m1.1.1.1.1.3.2.3.3.cmml">1</mn></mrow><mi id="S4.E2.m1.1.1.1.1.3.3" xref="S4.E2.m1.1.1.1.1.3.3.cmml">k</mi></msubsup></mrow><mo lspace="0em" id="S4.E2.m1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.1b"><apply id="S4.E2.m1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1"><ci id="S4.E2.m1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1">→</ci><apply id="S4.E2.m1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.2"><minus id="S4.E2.m1.1.1.1.1.2.1.cmml" xref="S4.E2.m1.1.1.1.1.2.1"></minus><apply id="S4.E2.m1.1.1.1.1.2.2.cmml" xref="S4.E2.m1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.2.2.1.cmml" xref="S4.E2.m1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.2.2.2.cmml" xref="S4.E2.m1.1.1.1.1.2.2.2">𝑤</ci><ci id="S4.E2.m1.1.1.1.1.2.2.3.cmml" xref="S4.E2.m1.1.1.1.1.2.2.3">𝑡</ci></apply><apply id="S4.E2.m1.1.1.1.1.2.3.cmml" xref="S4.E2.m1.1.1.1.1.2.3"><times id="S4.E2.m1.1.1.1.1.2.3.1.cmml" xref="S4.E2.m1.1.1.1.1.2.3.1"></times><ci id="S4.E2.m1.1.1.1.1.2.3.2.cmml" xref="S4.E2.m1.1.1.1.1.2.3.2">italic-ϵ</ci><apply id="S4.E2.m1.1.1.1.1.2.3.3.cmml" xref="S4.E2.m1.1.1.1.1.2.3.3"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.2.3.3.1.cmml" xref="S4.E2.m1.1.1.1.1.2.3.3">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.2.3.3.2.cmml" xref="S4.E2.m1.1.1.1.1.2.3.3.2">𝑔</ci><ci id="S4.E2.m1.1.1.1.1.2.3.3.3.cmml" xref="S4.E2.m1.1.1.1.1.2.3.3.3">𝑘</ci></apply></apply></apply><apply id="S4.E2.m1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.3.1.cmml" xref="S4.E2.m1.1.1.1.1.3">superscript</csymbol><apply id="S4.E2.m1.1.1.1.1.3.2.cmml" xref="S4.E2.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.3.2.1.cmml" xref="S4.E2.m1.1.1.1.1.3">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.3.2.2.cmml" xref="S4.E2.m1.1.1.1.1.3.2.2">𝑤</ci><apply id="S4.E2.m1.1.1.1.1.3.2.3.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3"><plus id="S4.E2.m1.1.1.1.1.3.2.3.1.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3.1"></plus><ci id="S4.E2.m1.1.1.1.1.3.2.3.2.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3.2">𝑡</ci><cn type="integer" id="S4.E2.m1.1.1.1.1.3.2.3.3.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3.3">1</cn></apply></apply><ci id="S4.E2.m1.1.1.1.1.3.3.cmml" xref="S4.E2.m1.1.1.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.1c">{w}_{t}-\epsilon{g}_{k}\rightarrow{w}_{t+1}^{k}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">The server then does a weighted aggregation of the client models to obtain a new
global model, <math id="S4.p5.1.m1.1" class="ltx_Math" alttext="{w}_{t+1}" display="inline"><semantics id="S4.p5.1.m1.1a"><msub id="S4.p5.1.m1.1.1" xref="S4.p5.1.m1.1.1.cmml"><mi id="S4.p5.1.m1.1.1.2" xref="S4.p5.1.m1.1.1.2.cmml">w</mi><mrow id="S4.p5.1.m1.1.1.3" xref="S4.p5.1.m1.1.1.3.cmml"><mi id="S4.p5.1.m1.1.1.3.2" xref="S4.p5.1.m1.1.1.3.2.cmml">t</mi><mo id="S4.p5.1.m1.1.1.3.1" xref="S4.p5.1.m1.1.1.3.1.cmml">+</mo><mn id="S4.p5.1.m1.1.1.3.3" xref="S4.p5.1.m1.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p5.1.m1.1b"><apply id="S4.p5.1.m1.1.1.cmml" xref="S4.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p5.1.m1.1.1.1.cmml" xref="S4.p5.1.m1.1.1">subscript</csymbol><ci id="S4.p5.1.m1.1.1.2.cmml" xref="S4.p5.1.m1.1.1.2">𝑤</ci><apply id="S4.p5.1.m1.1.1.3.cmml" xref="S4.p5.1.m1.1.1.3"><plus id="S4.p5.1.m1.1.1.3.1.cmml" xref="S4.p5.1.m1.1.1.3.1"></plus><ci id="S4.p5.1.m1.1.1.3.2.cmml" xref="S4.p5.1.m1.1.1.3.2">𝑡</ci><cn type="integer" id="S4.p5.1.m1.1.1.3.3.cmml" xref="S4.p5.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.1.m1.1c">{w}_{t+1}</annotation></semantics></math>:</p>
</div>
<div id="S4.p6" class="ltx_para">
<table id="S4.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E3.m1.1" class="ltx_Math" alttext="\sum_{k=1}^{K}\frac{{n}_{k}}{N}{w}_{t+1}^{k}\rightarrow{w}_{t+1}," display="block"><semantics id="S4.E3.m1.1a"><mrow id="S4.E3.m1.1.1.1" xref="S4.E3.m1.1.1.1.1.cmml"><mrow id="S4.E3.m1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.cmml"><mrow id="S4.E3.m1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.2.cmml"><munderover id="S4.E3.m1.1.1.1.1.2.1" xref="S4.E3.m1.1.1.1.1.2.1.cmml"><mo movablelimits="false" id="S4.E3.m1.1.1.1.1.2.1.2.2" xref="S4.E3.m1.1.1.1.1.2.1.2.2.cmml">∑</mo><mrow id="S4.E3.m1.1.1.1.1.2.1.2.3" xref="S4.E3.m1.1.1.1.1.2.1.2.3.cmml"><mi id="S4.E3.m1.1.1.1.1.2.1.2.3.2" xref="S4.E3.m1.1.1.1.1.2.1.2.3.2.cmml">k</mi><mo id="S4.E3.m1.1.1.1.1.2.1.2.3.1" xref="S4.E3.m1.1.1.1.1.2.1.2.3.1.cmml">=</mo><mn id="S4.E3.m1.1.1.1.1.2.1.2.3.3" xref="S4.E3.m1.1.1.1.1.2.1.2.3.3.cmml">1</mn></mrow><mi id="S4.E3.m1.1.1.1.1.2.1.3" xref="S4.E3.m1.1.1.1.1.2.1.3.cmml">K</mi></munderover><mrow id="S4.E3.m1.1.1.1.1.2.2" xref="S4.E3.m1.1.1.1.1.2.2.cmml"><mfrac id="S4.E3.m1.1.1.1.1.2.2.2" xref="S4.E3.m1.1.1.1.1.2.2.2.cmml"><msub id="S4.E3.m1.1.1.1.1.2.2.2.2" xref="S4.E3.m1.1.1.1.1.2.2.2.2.cmml"><mi id="S4.E3.m1.1.1.1.1.2.2.2.2.2" xref="S4.E3.m1.1.1.1.1.2.2.2.2.2.cmml">n</mi><mi id="S4.E3.m1.1.1.1.1.2.2.2.2.3" xref="S4.E3.m1.1.1.1.1.2.2.2.2.3.cmml">k</mi></msub><mi id="S4.E3.m1.1.1.1.1.2.2.2.3" xref="S4.E3.m1.1.1.1.1.2.2.2.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.1.1.2.2.1" xref="S4.E3.m1.1.1.1.1.2.2.1.cmml">​</mo><msubsup id="S4.E3.m1.1.1.1.1.2.2.3" xref="S4.E3.m1.1.1.1.1.2.2.3.cmml"><mi id="S4.E3.m1.1.1.1.1.2.2.3.2.2" xref="S4.E3.m1.1.1.1.1.2.2.3.2.2.cmml">w</mi><mrow id="S4.E3.m1.1.1.1.1.2.2.3.2.3" xref="S4.E3.m1.1.1.1.1.2.2.3.2.3.cmml"><mi id="S4.E3.m1.1.1.1.1.2.2.3.2.3.2" xref="S4.E3.m1.1.1.1.1.2.2.3.2.3.2.cmml">t</mi><mo id="S4.E3.m1.1.1.1.1.2.2.3.2.3.1" xref="S4.E3.m1.1.1.1.1.2.2.3.2.3.1.cmml">+</mo><mn id="S4.E3.m1.1.1.1.1.2.2.3.2.3.3" xref="S4.E3.m1.1.1.1.1.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S4.E3.m1.1.1.1.1.2.2.3.3" xref="S4.E3.m1.1.1.1.1.2.2.3.3.cmml">k</mi></msubsup></mrow></mrow><mo stretchy="false" id="S4.E3.m1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.cmml">→</mo><msub id="S4.E3.m1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.3.cmml"><mi id="S4.E3.m1.1.1.1.1.3.2" xref="S4.E3.m1.1.1.1.1.3.2.cmml">w</mi><mrow id="S4.E3.m1.1.1.1.1.3.3" xref="S4.E3.m1.1.1.1.1.3.3.cmml"><mi id="S4.E3.m1.1.1.1.1.3.3.2" xref="S4.E3.m1.1.1.1.1.3.3.2.cmml">t</mi><mo id="S4.E3.m1.1.1.1.1.3.3.1" xref="S4.E3.m1.1.1.1.1.3.3.1.cmml">+</mo><mn id="S4.E3.m1.1.1.1.1.3.3.3" xref="S4.E3.m1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="S4.E3.m1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.1b"><apply id="S4.E3.m1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1"><ci id="S4.E3.m1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1">→</ci><apply id="S4.E3.m1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.2"><apply id="S4.E3.m1.1.1.1.1.2.1.cmml" xref="S4.E3.m1.1.1.1.1.2.1"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.2.1.1.cmml" xref="S4.E3.m1.1.1.1.1.2.1">superscript</csymbol><apply id="S4.E3.m1.1.1.1.1.2.1.2.cmml" xref="S4.E3.m1.1.1.1.1.2.1"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.2.1.2.1.cmml" xref="S4.E3.m1.1.1.1.1.2.1">subscript</csymbol><sum id="S4.E3.m1.1.1.1.1.2.1.2.2.cmml" xref="S4.E3.m1.1.1.1.1.2.1.2.2"></sum><apply id="S4.E3.m1.1.1.1.1.2.1.2.3.cmml" xref="S4.E3.m1.1.1.1.1.2.1.2.3"><eq id="S4.E3.m1.1.1.1.1.2.1.2.3.1.cmml" xref="S4.E3.m1.1.1.1.1.2.1.2.3.1"></eq><ci id="S4.E3.m1.1.1.1.1.2.1.2.3.2.cmml" xref="S4.E3.m1.1.1.1.1.2.1.2.3.2">𝑘</ci><cn type="integer" id="S4.E3.m1.1.1.1.1.2.1.2.3.3.cmml" xref="S4.E3.m1.1.1.1.1.2.1.2.3.3">1</cn></apply></apply><ci id="S4.E3.m1.1.1.1.1.2.1.3.cmml" xref="S4.E3.m1.1.1.1.1.2.1.3">𝐾</ci></apply><apply id="S4.E3.m1.1.1.1.1.2.2.cmml" xref="S4.E3.m1.1.1.1.1.2.2"><times id="S4.E3.m1.1.1.1.1.2.2.1.cmml" xref="S4.E3.m1.1.1.1.1.2.2.1"></times><apply id="S4.E3.m1.1.1.1.1.2.2.2.cmml" xref="S4.E3.m1.1.1.1.1.2.2.2"><divide id="S4.E3.m1.1.1.1.1.2.2.2.1.cmml" xref="S4.E3.m1.1.1.1.1.2.2.2"></divide><apply id="S4.E3.m1.1.1.1.1.2.2.2.2.cmml" xref="S4.E3.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S4.E3.m1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S4.E3.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S4.E3.m1.1.1.1.1.2.2.2.2.2">𝑛</ci><ci id="S4.E3.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S4.E3.m1.1.1.1.1.2.2.2.2.3">𝑘</ci></apply><ci id="S4.E3.m1.1.1.1.1.2.2.2.3.cmml" xref="S4.E3.m1.1.1.1.1.2.2.2.3">𝑁</ci></apply><apply id="S4.E3.m1.1.1.1.1.2.2.3.cmml" xref="S4.E3.m1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.2.2.3.1.cmml" xref="S4.E3.m1.1.1.1.1.2.2.3">superscript</csymbol><apply id="S4.E3.m1.1.1.1.1.2.2.3.2.cmml" xref="S4.E3.m1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.2.2.3.2.1.cmml" xref="S4.E3.m1.1.1.1.1.2.2.3">subscript</csymbol><ci id="S4.E3.m1.1.1.1.1.2.2.3.2.2.cmml" xref="S4.E3.m1.1.1.1.1.2.2.3.2.2">𝑤</ci><apply id="S4.E3.m1.1.1.1.1.2.2.3.2.3.cmml" xref="S4.E3.m1.1.1.1.1.2.2.3.2.3"><plus id="S4.E3.m1.1.1.1.1.2.2.3.2.3.1.cmml" xref="S4.E3.m1.1.1.1.1.2.2.3.2.3.1"></plus><ci id="S4.E3.m1.1.1.1.1.2.2.3.2.3.2.cmml" xref="S4.E3.m1.1.1.1.1.2.2.3.2.3.2">𝑡</ci><cn type="integer" id="S4.E3.m1.1.1.1.1.2.2.3.2.3.3.cmml" xref="S4.E3.m1.1.1.1.1.2.2.3.2.3.3">1</cn></apply></apply><ci id="S4.E3.m1.1.1.1.1.2.2.3.3.cmml" xref="S4.E3.m1.1.1.1.1.2.2.3.3">𝑘</ci></apply></apply></apply><apply id="S4.E3.m1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.3.1.cmml" xref="S4.E3.m1.1.1.1.1.3">subscript</csymbol><ci id="S4.E3.m1.1.1.1.1.3.2.cmml" xref="S4.E3.m1.1.1.1.1.3.2">𝑤</ci><apply id="S4.E3.m1.1.1.1.1.3.3.cmml" xref="S4.E3.m1.1.1.1.1.3.3"><plus id="S4.E3.m1.1.1.1.1.3.3.1.cmml" xref="S4.E3.m1.1.1.1.1.3.3.1"></plus><ci id="S4.E3.m1.1.1.1.1.3.3.2.cmml" xref="S4.E3.m1.1.1.1.1.3.3.2">𝑡</ci><cn type="integer" id="S4.E3.m1.1.1.1.1.3.3.3.cmml" xref="S4.E3.m1.1.1.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.1c">\sum_{k=1}^{K}\frac{{n}_{k}}{N}{w}_{t+1}^{k}\rightarrow{w}_{t+1},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.p7" class="ltx_para ltx_noindent">
<p id="S4.p7.1" class="ltx_p">where <math id="S4.p7.1.m1.1" class="ltx_Math" alttext="N=\sum_{k}{n}_{k}" display="inline"><semantics id="S4.p7.1.m1.1a"><mrow id="S4.p7.1.m1.1.1" xref="S4.p7.1.m1.1.1.cmml"><mi id="S4.p7.1.m1.1.1.2" xref="S4.p7.1.m1.1.1.2.cmml">N</mi><mo rspace="0.111em" id="S4.p7.1.m1.1.1.1" xref="S4.p7.1.m1.1.1.1.cmml">=</mo><mrow id="S4.p7.1.m1.1.1.3" xref="S4.p7.1.m1.1.1.3.cmml"><msub id="S4.p7.1.m1.1.1.3.1" xref="S4.p7.1.m1.1.1.3.1.cmml"><mo id="S4.p7.1.m1.1.1.3.1.2" xref="S4.p7.1.m1.1.1.3.1.2.cmml">∑</mo><mi id="S4.p7.1.m1.1.1.3.1.3" xref="S4.p7.1.m1.1.1.3.1.3.cmml">k</mi></msub><msub id="S4.p7.1.m1.1.1.3.2" xref="S4.p7.1.m1.1.1.3.2.cmml"><mi id="S4.p7.1.m1.1.1.3.2.2" xref="S4.p7.1.m1.1.1.3.2.2.cmml">n</mi><mi id="S4.p7.1.m1.1.1.3.2.3" xref="S4.p7.1.m1.1.1.3.2.3.cmml">k</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p7.1.m1.1b"><apply id="S4.p7.1.m1.1.1.cmml" xref="S4.p7.1.m1.1.1"><eq id="S4.p7.1.m1.1.1.1.cmml" xref="S4.p7.1.m1.1.1.1"></eq><ci id="S4.p7.1.m1.1.1.2.cmml" xref="S4.p7.1.m1.1.1.2">𝑁</ci><apply id="S4.p7.1.m1.1.1.3.cmml" xref="S4.p7.1.m1.1.1.3"><apply id="S4.p7.1.m1.1.1.3.1.cmml" xref="S4.p7.1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S4.p7.1.m1.1.1.3.1.1.cmml" xref="S4.p7.1.m1.1.1.3.1">subscript</csymbol><sum id="S4.p7.1.m1.1.1.3.1.2.cmml" xref="S4.p7.1.m1.1.1.3.1.2"></sum><ci id="S4.p7.1.m1.1.1.3.1.3.cmml" xref="S4.p7.1.m1.1.1.3.1.3">𝑘</ci></apply><apply id="S4.p7.1.m1.1.1.3.2.cmml" xref="S4.p7.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S4.p7.1.m1.1.1.3.2.1.cmml" xref="S4.p7.1.m1.1.1.3.2">subscript</csymbol><ci id="S4.p7.1.m1.1.1.3.2.2.cmml" xref="S4.p7.1.m1.1.1.3.2.2">𝑛</ci><ci id="S4.p7.1.m1.1.1.3.2.3.cmml" xref="S4.p7.1.m1.1.1.3.2.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.1.m1.1c">N=\sum_{k}{n}_{k}</annotation></semantics></math>. In essence, the clients compute SGD updates
locally, which are communicated to the server and aggregated. Hyperparameters
including the client batch size, the number of client epochs, and the number of
clients per round (global batch size) are tuned to improve performance.</p>
</div>
<div id="S4.p8" class="ltx_para">
<p id="S4.p8.1" class="ltx_p">Decentralized on-device computation offers fewer security and privacy risks than
server storage, even when the server-hosted data are anonymized. Keeping
personal data on client devices gives users more direct and physical control of
their own data. The model updates communicated to the server by each client are
ephemeral, focused, and aggregated. Client updates are never stored on the
server; updates are processed in memory and are immediately discarded after
accumulation in a weight vector. Following the principle of data
minimization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, uploaded content is limited to model weights.
Finally, the results are only used in aggregate: the global model is improved
by combining updates from many client devices. The federated learning procedure
discussed here requires users to trust that the aggregation server will not
scrutinize individual weight uploads. This is still preferable to server
training because the server is never entrusted with user data. Additional
techniques are being explored to relax the trust requirement. Federated learning
has previously been shown to be complementary to privacy-preserving techniques
such as secure aggregation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> and differential
privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Federated learning and server-based stochastic gradient descent are used to
train the CIFG language model described in Section <a href="#S3" title="3 Model Architecture ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> starting from
random weight initializations. The performance of both models is evaluated on
server-hosted logs data, client-held data, and in live production experiments.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Server-based training with logs data</h3>

<figure id="S5.F3" class="ltx_figure"><img src="/html/1811.03604/assets/server_comparison.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="393" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.2.1.1" class="ltx_text ltx_font_bold">Fig. 3</span>: </span>Top-1 recall of the CIFG as a function of SGD step during server
training. The recall of the n-gram FST baseline model is shown for
comparison, but the FST model is not trained in this study.</figcaption>
</figure>
<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Server-based training of the CIFG next-word prediction model relies on data
logged from Gboard users who have opted to share snippets of text while typing
in Google apps. The text is truncated to contain short phrases of a few words,
and snippets are only sporadically logged from individual users. Prior to
training, logs are anonymized and stripped of personally identifiable
information. Additionally, snippets are only used for training if they begin
with a start of sentence token.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">For this study, logs are collected from the English speaking population of
Gboard users in the United States. Approximately 7.5 billion sentences are used
for training, while the test and evaluation samples each contain 25,000
sentences. The average sentence length in the dataset is 4.1 words. A breakdown
of the logs data by app type is provided in Table <a href="#S5.T1" title="Table 1 ‣ 5.1 Server-based training with logs data ‣ 5 Experiments ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Chat apps
generate the majority of logged text.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">Asynchronous stochastic gradient descent with a learning rate equal to
<math id="S5.SS1.p3.1.m1.1" class="ltx_Math" alttext="{10}^{-3}" display="inline"><semantics id="S5.SS1.p3.1.m1.1a"><msup id="S5.SS1.p3.1.m1.1.1" xref="S5.SS1.p3.1.m1.1.1.cmml"><mn id="S5.SS1.p3.1.m1.1.1.2" xref="S5.SS1.p3.1.m1.1.1.2.cmml">10</mn><mrow id="S5.SS1.p3.1.m1.1.1.3" xref="S5.SS1.p3.1.m1.1.1.3.cmml"><mo id="S5.SS1.p3.1.m1.1.1.3a" xref="S5.SS1.p3.1.m1.1.1.3.cmml">−</mo><mn id="S5.SS1.p3.1.m1.1.1.3.2" xref="S5.SS1.p3.1.m1.1.1.3.2.cmml">3</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.m1.1b"><apply id="S5.SS1.p3.1.m1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p3.1.m1.1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1">superscript</csymbol><cn type="integer" id="S5.SS1.p3.1.m1.1.1.2.cmml" xref="S5.SS1.p3.1.m1.1.1.2">10</cn><apply id="S5.SS1.p3.1.m1.1.1.3.cmml" xref="S5.SS1.p3.1.m1.1.1.3"><minus id="S5.SS1.p3.1.m1.1.1.3.1.cmml" xref="S5.SS1.p3.1.m1.1.1.3"></minus><cn type="integer" id="S5.SS1.p3.1.m1.1.1.3.2.cmml" xref="S5.SS1.p3.1.m1.1.1.3.2">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.m1.1c">{10}^{-3}</annotation></semantics></math> and no weight decay or momentum is used to train the server CIFG.
Adaptive gradient methods including Adam <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> and AdaGrad <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>
are not found to improve the convergence. Sentences are processed in batches of
50. The network converges after 150 million steps of SGD.
Figure <a href="#S5.F3" title="Figure 3 ‣ 5.1 Server-based training with logs data ‣ 5 Experiments ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the top-1 recall of the CIFG during
network training, compared with the performance of the n-gram baseline model.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<table id="S5.T1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.2.1.1" class="ltx_tr">
<th id="S5.T1.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">App type</th>
<th id="S5.T1.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Share of data</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.2.2.1" class="ltx_tr">
<th id="S5.T1.2.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Chat</th>
<td id="S5.T1.2.2.1.2" class="ltx_td ltx_align_center ltx_border_tt">60%</td>
</tr>
<tr id="S5.T1.2.3.2" class="ltx_tr">
<th id="S5.T1.2.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Web input</th>
<td id="S5.T1.2.3.2.2" class="ltx_td ltx_align_center">35%</td>
</tr>
<tr id="S5.T1.2.4.3" class="ltx_tr">
<th id="S5.T1.2.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Long form text</th>
<td id="S5.T1.2.4.3.2" class="ltx_td ltx_align_center ltx_border_bb">5%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T1.3.1.1" class="ltx_text ltx_font_bold">Table 1</span>: </span>The composition of logs data by mobile app type.</figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Federated training with client caches</h3>

<figure id="S5.F4" class="ltx_figure"><img src="/html/1811.03604/assets/federated_comparison.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="393" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.2.1.1" class="ltx_text ltx_font_bold">Fig. 4</span>: </span>Top-1 recall of the CIFG as a function of training round during
federated training. The performance of the n-gram FST baseline model
is evaluated on the client caches along with the CIFG, but it is not
trained in this study.</figcaption>
</figure>
<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Data for the federated training of the CIFG next-word prediction model are
stored in local caches on Gboard client devices. As with the logs data, each
client cache stores text belonging to the device owner, as well as prediction
candidates generated by the decoder.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">Client devices must meet a number of requirements in order to be eligible for
federated training participation. In terms of hardware requirements, the devices
must have at least 2 gigabytes of memory available. Additionally, the clients
are only allowed to participate if they are charging, connected to an un-metered
network, and idle. These criteria are chosen specifically for the Gboard
implementation of federated learning and are not inherent to the federated
learning platform. Clients for this study are also required to be located in
North America while running Gboard release 7.3 or greater with the US English
language model enabled.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">Unlike server-based training, where train, test, and eval samples are obtained
via explicit splits of the data, the federated train, test, and eval samples are
obtained by defining separate computation tasks. While there is no explicit
separation of client devices into three distinct populations, the probability of
client reuse in both the training and test or eval tasks is minimal in a
sufficiently large client population. The composition of the client cache data
by app type is shown in Table <a href="#S5.T2" title="Table 2 ‣ 5.2 Federated training with client caches ‣ 5 Experiments ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. As with the logs data, the
client caches are also dominated by chat apps. Social media apps have an
increased presence in the client cache sample, while long-form communication is
represented less.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<table id="S5.T2.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.2.1.1" class="ltx_tr">
<th id="S5.T2.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">App type</th>
<th id="S5.T2.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Share of data</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.2.2.1" class="ltx_tr">
<th id="S5.T2.2.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Chat</th>
<td id="S5.T2.2.2.1.2" class="ltx_td ltx_align_center ltx_border_tt">66%</td>
</tr>
<tr id="S5.T2.2.3.2" class="ltx_tr">
<th id="S5.T2.2.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Social</th>
<td id="S5.T2.2.3.2.2" class="ltx_td ltx_align_center">16%</td>
</tr>
<tr id="S5.T2.2.4.3" class="ltx_tr">
<th id="S5.T2.2.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Web input</th>
<td id="S5.T2.2.4.3.2" class="ltx_td ltx_align_center">5%</td>
</tr>
<tr id="S5.T2.2.5.4" class="ltx_tr">
<th id="S5.T2.2.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Other</th>
<td id="S5.T2.2.5.4.2" class="ltx_td ltx_align_center ltx_border_bb">12%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T2.3.1.1" class="ltx_text ltx_font_bold">Table 2</span>: </span>The composition of client cache data by mobile app type.</figcaption>
</figure>
<div id="S5.SS2.p4" class="ltx_para">
<p id="S5.SS2.p4.1" class="ltx_p">The <span id="S5.SS2.p4.1.1" class="ltx_text ltx_font_typewriter">FederatedAveraging</span> algorithm described in
Section <a href="#S4" title="4 Federated Learning ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> is used to aggregate distributed client SGD updates.
Between 100 and 500 client updates are required to close each round of federated
training in Gboard. The server update in Equation <a href="#S4.E3" title="In 4 Federated Learning ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> is
achieved via the Momentum optimizer, using Nesterov accelerated
gradient <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, a momentum hyperparameter of 0.9, and a server
learning rate of 1.0. This technique is found to reduce training time with
respect to alternatives including pure SGD. On average, each client processes
approximately 400 example sentences during a single training epoch. The
federated CIFG converges after 3000 training rounds, over the course of which
600 million sentences are processed by 1.5 million clients. Training typically
takes 4-5 days. The top-1 recall of the federated CIFG is shown as a function of
training round in Figure <a href="#S5.F4" title="Figure 4 ‣ 5.2 Federated training with client caches ‣ 5 Experiments ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. The performance of the n-gram
baseline model is also measured in the federated eval tasks to provide a
comparison for the CIFG, though the decoder is not trained in this study. N-gram
model recall is measured by comparing the decoder candidates stored in the
on-device training cache to the actual user-entered text.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Results</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">The performance of each model is evaluated using the recall metric, defined as
the ratio of the number of correct predictions to the total number of tokens.
Recall for the highest-likelihood candidate is important for Gboard because
users are more prone to read and utilize predictions in the center suggestion
spot. Since Gboard includes three candidates in the suggestion strip, top-3
recall is also of interest.</p>
</div>
<figure id="S6.T3" class="ltx_table">
<table id="S6.T3.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T3.2.1.1" class="ltx_tr">
<th id="S6.T3.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Model</th>
<th id="S6.T3.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Top-1 recall</th>
<th id="S6.T3.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Top-3 recall</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T3.2.2.1" class="ltx_tr">
<th id="S6.T3.2.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">N-gram</th>
<td id="S6.T3.2.2.1.2" class="ltx_td ltx_align_center ltx_border_tt">13.0%</td>
<td id="S6.T3.2.2.1.3" class="ltx_td ltx_align_center ltx_border_tt">22.1%</td>
</tr>
<tr id="S6.T3.2.3.2" class="ltx_tr">
<th id="S6.T3.2.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Server CIFG</th>
<td id="S6.T3.2.3.2.2" class="ltx_td ltx_align_center">16.5%</td>
<td id="S6.T3.2.3.2.3" class="ltx_td ltx_align_center">27.1%</td>
</tr>
<tr id="S6.T3.2.4.3" class="ltx_tr">
<th id="S6.T3.2.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Federated CIFG</th>
<td id="S6.T3.2.4.3.2" class="ltx_td ltx_align_center ltx_border_bb">16.4%</td>
<td id="S6.T3.2.4.3.3" class="ltx_td ltx_align_center ltx_border_bb">27.0%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T3.3.1.1" class="ltx_text ltx_font_bold">Table 3</span>: </span>Prediction recall for the server and federated CIFG models compared
with the n-gram baseline, evaluated on server-hosted logs data.</figcaption>
</figure>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">Server-hosted logs data and client device-owned caches are used to measure
prediction recall. Although each contain snippets of data from actual users, the
client caches are believed to more accurately represent the true typing data
distribution. Cache data, unlike logs, are not truncated in length and are not
restricted to keyboard usage in Google-owned apps. Thus, federated learning
enables the use of higher-quality training data in the case of Gboard.
Table <a href="#S6.T3" title="Table 3 ‣ 6 Results ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> summarizes the recall performance as measured on
server-hosted logs data, while Table <a href="#S6.T4" title="Table 4 ‣ 6 Results ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the performance
evaluated with client-owned caches. The quoted errors are directly related to
the number of clients used for federated evaluation.</p>
</div>
<figure id="S6.T4" class="ltx_table">
<table id="S6.T4.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T4.3.4.1" class="ltx_tr">
<th id="S6.T4.3.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Model</th>
<th id="S6.T4.3.4.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Top-1 recall [%]</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T4.1.1" class="ltx_tr">
<th id="S6.T4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">N-gram</th>
<td id="S6.T4.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><math id="S6.T4.1.1.1.m1.1" class="ltx_Math" alttext="12.5\pm 0.2" display="inline"><semantics id="S6.T4.1.1.1.m1.1a"><mrow id="S6.T4.1.1.1.m1.1.1" xref="S6.T4.1.1.1.m1.1.1.cmml"><mn id="S6.T4.1.1.1.m1.1.1.2" xref="S6.T4.1.1.1.m1.1.1.2.cmml">12.5</mn><mo id="S6.T4.1.1.1.m1.1.1.1" xref="S6.T4.1.1.1.m1.1.1.1.cmml">±</mo><mn id="S6.T4.1.1.1.m1.1.1.3" xref="S6.T4.1.1.1.m1.1.1.3.cmml">0.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T4.1.1.1.m1.1b"><apply id="S6.T4.1.1.1.m1.1.1.cmml" xref="S6.T4.1.1.1.m1.1.1"><csymbol cd="latexml" id="S6.T4.1.1.1.m1.1.1.1.cmml" xref="S6.T4.1.1.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T4.1.1.1.m1.1.1.2.cmml" xref="S6.T4.1.1.1.m1.1.1.2">12.5</cn><cn type="float" id="S6.T4.1.1.1.m1.1.1.3.cmml" xref="S6.T4.1.1.1.m1.1.1.3">0.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.1.1.1.m1.1c">12.5\pm 0.2</annotation></semantics></math></td>
</tr>
<tr id="S6.T4.2.2" class="ltx_tr">
<th id="S6.T4.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Server CIFG</th>
<td id="S6.T4.2.2.1" class="ltx_td ltx_align_center"><math id="S6.T4.2.2.1.m1.1" class="ltx_Math" alttext="15.0\pm 0.5" display="inline"><semantics id="S6.T4.2.2.1.m1.1a"><mrow id="S6.T4.2.2.1.m1.1.1" xref="S6.T4.2.2.1.m1.1.1.cmml"><mn id="S6.T4.2.2.1.m1.1.1.2" xref="S6.T4.2.2.1.m1.1.1.2.cmml">15.0</mn><mo id="S6.T4.2.2.1.m1.1.1.1" xref="S6.T4.2.2.1.m1.1.1.1.cmml">±</mo><mn id="S6.T4.2.2.1.m1.1.1.3" xref="S6.T4.2.2.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T4.2.2.1.m1.1b"><apply id="S6.T4.2.2.1.m1.1.1.cmml" xref="S6.T4.2.2.1.m1.1.1"><csymbol cd="latexml" id="S6.T4.2.2.1.m1.1.1.1.cmml" xref="S6.T4.2.2.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T4.2.2.1.m1.1.1.2.cmml" xref="S6.T4.2.2.1.m1.1.1.2">15.0</cn><cn type="float" id="S6.T4.2.2.1.m1.1.1.3.cmml" xref="S6.T4.2.2.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.2.2.1.m1.1c">15.0\pm 0.5</annotation></semantics></math></td>
</tr>
<tr id="S6.T4.3.3" class="ltx_tr">
<th id="S6.T4.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Federated CIFG</th>
<td id="S6.T4.3.3.1" class="ltx_td ltx_align_center ltx_border_bb"><math id="S6.T4.3.3.1.m1.1" class="ltx_Math" alttext="15.8\pm 0.3" display="inline"><semantics id="S6.T4.3.3.1.m1.1a"><mrow id="S6.T4.3.3.1.m1.1.1" xref="S6.T4.3.3.1.m1.1.1.cmml"><mn id="S6.T4.3.3.1.m1.1.1.2" xref="S6.T4.3.3.1.m1.1.1.2.cmml">15.8</mn><mo id="S6.T4.3.3.1.m1.1.1.1" xref="S6.T4.3.3.1.m1.1.1.1.cmml">±</mo><mn id="S6.T4.3.3.1.m1.1.1.3" xref="S6.T4.3.3.1.m1.1.1.3.cmml">0.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T4.3.3.1.m1.1b"><apply id="S6.T4.3.3.1.m1.1.1.cmml" xref="S6.T4.3.3.1.m1.1.1"><csymbol cd="latexml" id="S6.T4.3.3.1.m1.1.1.1.cmml" xref="S6.T4.3.3.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T4.3.3.1.m1.1.1.2.cmml" xref="S6.T4.3.3.1.m1.1.1.2">15.8</cn><cn type="float" id="S6.T4.3.3.1.m1.1.1.3.cmml" xref="S6.T4.3.3.1.m1.1.1.3">0.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.3.3.1.m1.1c">15.8\pm 0.3</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T4.5.1.1" class="ltx_text ltx_font_bold">Table 4</span>: </span>Prediction recall for the server and federated CIFG models compared
with the n-gram baseline, evaluated on client-owned data caches.</figcaption>
</figure>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">Model performance is also measured in live production experiments with a subset
of Gboard users. Similar to top-1 recall, prediction impression recall is
measured by dividing the number of predictions that match the user-entered text
by the number of times users are shown prediction candidates. The prediction
impression recall metric is typically lower than the standard recall metric.
Zero-state prediction events (in which users open the Gboard app but do not
commit any text) increase the number of impressions but not matches.
Table <a href="#S6.T5" title="Table 5 ‣ 6 Results ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> summarizes the impression recall performance in live
experiments. The prediction click-through rate (CTR), defined as the ratio of
the number of clicks on prediction candidates to the number of proposed
prediction candidates, is also provided in Table <a href="#S6.T6" title="Table 6 ‣ 6 Results ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Quoted 95%
CI errors for all results are derived using the jackknife method with user
buckets.</p>
</div>
<figure id="S6.T5" class="ltx_table">
<table id="S6.T5.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T5.6.7.1" class="ltx_tr">
<th id="S6.T5.6.7.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Model</th>
<th id="S6.T5.6.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Top-1 recall [%]</th>
<th id="S6.T5.6.7.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Top-3 recall [%]</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T5.2.2" class="ltx_tr">
<th id="S6.T5.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">N-gram</th>
<td id="S6.T5.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><math id="S6.T5.1.1.1.m1.1" class="ltx_Math" alttext="5.24\pm 0.02" display="inline"><semantics id="S6.T5.1.1.1.m1.1a"><mrow id="S6.T5.1.1.1.m1.1.1" xref="S6.T5.1.1.1.m1.1.1.cmml"><mn id="S6.T5.1.1.1.m1.1.1.2" xref="S6.T5.1.1.1.m1.1.1.2.cmml">5.24</mn><mo id="S6.T5.1.1.1.m1.1.1.1" xref="S6.T5.1.1.1.m1.1.1.1.cmml">±</mo><mn id="S6.T5.1.1.1.m1.1.1.3" xref="S6.T5.1.1.1.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T5.1.1.1.m1.1b"><apply id="S6.T5.1.1.1.m1.1.1.cmml" xref="S6.T5.1.1.1.m1.1.1"><csymbol cd="latexml" id="S6.T5.1.1.1.m1.1.1.1.cmml" xref="S6.T5.1.1.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T5.1.1.1.m1.1.1.2.cmml" xref="S6.T5.1.1.1.m1.1.1.2">5.24</cn><cn type="float" id="S6.T5.1.1.1.m1.1.1.3.cmml" xref="S6.T5.1.1.1.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.1.1.1.m1.1c">5.24\pm 0.02</annotation></semantics></math></td>
<td id="S6.T5.2.2.2" class="ltx_td ltx_align_center ltx_border_tt"><math id="S6.T5.2.2.2.m1.1" class="ltx_Math" alttext="11.05\pm 0.03" display="inline"><semantics id="S6.T5.2.2.2.m1.1a"><mrow id="S6.T5.2.2.2.m1.1.1" xref="S6.T5.2.2.2.m1.1.1.cmml"><mn id="S6.T5.2.2.2.m1.1.1.2" xref="S6.T5.2.2.2.m1.1.1.2.cmml">11.05</mn><mo id="S6.T5.2.2.2.m1.1.1.1" xref="S6.T5.2.2.2.m1.1.1.1.cmml">±</mo><mn id="S6.T5.2.2.2.m1.1.1.3" xref="S6.T5.2.2.2.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T5.2.2.2.m1.1b"><apply id="S6.T5.2.2.2.m1.1.1.cmml" xref="S6.T5.2.2.2.m1.1.1"><csymbol cd="latexml" id="S6.T5.2.2.2.m1.1.1.1.cmml" xref="S6.T5.2.2.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T5.2.2.2.m1.1.1.2.cmml" xref="S6.T5.2.2.2.m1.1.1.2">11.05</cn><cn type="float" id="S6.T5.2.2.2.m1.1.1.3.cmml" xref="S6.T5.2.2.2.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.2.2.2.m1.1c">11.05\pm 0.03</annotation></semantics></math></td>
</tr>
<tr id="S6.T5.4.4" class="ltx_tr">
<th id="S6.T5.4.4.3" class="ltx_td ltx_align_left ltx_th ltx_th_row">Server CIFG</th>
<td id="S6.T5.3.3.1" class="ltx_td ltx_align_center"><math id="S6.T5.3.3.1.m1.1" class="ltx_Math" alttext="5.76\pm 0.03" display="inline"><semantics id="S6.T5.3.3.1.m1.1a"><mrow id="S6.T5.3.3.1.m1.1.1" xref="S6.T5.3.3.1.m1.1.1.cmml"><mn id="S6.T5.3.3.1.m1.1.1.2" xref="S6.T5.3.3.1.m1.1.1.2.cmml">5.76</mn><mo id="S6.T5.3.3.1.m1.1.1.1" xref="S6.T5.3.3.1.m1.1.1.1.cmml">±</mo><mn id="S6.T5.3.3.1.m1.1.1.3" xref="S6.T5.3.3.1.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T5.3.3.1.m1.1b"><apply id="S6.T5.3.3.1.m1.1.1.cmml" xref="S6.T5.3.3.1.m1.1.1"><csymbol cd="latexml" id="S6.T5.3.3.1.m1.1.1.1.cmml" xref="S6.T5.3.3.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T5.3.3.1.m1.1.1.2.cmml" xref="S6.T5.3.3.1.m1.1.1.2">5.76</cn><cn type="float" id="S6.T5.3.3.1.m1.1.1.3.cmml" xref="S6.T5.3.3.1.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.3.3.1.m1.1c">5.76\pm 0.03</annotation></semantics></math></td>
<td id="S6.T5.4.4.2" class="ltx_td ltx_align_center"><math id="S6.T5.4.4.2.m1.1" class="ltx_Math" alttext="13.63\pm 0.04" display="inline"><semantics id="S6.T5.4.4.2.m1.1a"><mrow id="S6.T5.4.4.2.m1.1.1" xref="S6.T5.4.4.2.m1.1.1.cmml"><mn id="S6.T5.4.4.2.m1.1.1.2" xref="S6.T5.4.4.2.m1.1.1.2.cmml">13.63</mn><mo id="S6.T5.4.4.2.m1.1.1.1" xref="S6.T5.4.4.2.m1.1.1.1.cmml">±</mo><mn id="S6.T5.4.4.2.m1.1.1.3" xref="S6.T5.4.4.2.m1.1.1.3.cmml">0.04</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T5.4.4.2.m1.1b"><apply id="S6.T5.4.4.2.m1.1.1.cmml" xref="S6.T5.4.4.2.m1.1.1"><csymbol cd="latexml" id="S6.T5.4.4.2.m1.1.1.1.cmml" xref="S6.T5.4.4.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T5.4.4.2.m1.1.1.2.cmml" xref="S6.T5.4.4.2.m1.1.1.2">13.63</cn><cn type="float" id="S6.T5.4.4.2.m1.1.1.3.cmml" xref="S6.T5.4.4.2.m1.1.1.3">0.04</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.4.4.2.m1.1c">13.63\pm 0.04</annotation></semantics></math></td>
</tr>
<tr id="S6.T5.6.6" class="ltx_tr">
<th id="S6.T5.6.6.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Federated CIFG</th>
<td id="S6.T5.5.5.1" class="ltx_td ltx_align_center ltx_border_bb"><math id="S6.T5.5.5.1.m1.1" class="ltx_Math" alttext="5.82\pm 0.03" display="inline"><semantics id="S6.T5.5.5.1.m1.1a"><mrow id="S6.T5.5.5.1.m1.1.1" xref="S6.T5.5.5.1.m1.1.1.cmml"><mn id="S6.T5.5.5.1.m1.1.1.2" xref="S6.T5.5.5.1.m1.1.1.2.cmml">5.82</mn><mo id="S6.T5.5.5.1.m1.1.1.1" xref="S6.T5.5.5.1.m1.1.1.1.cmml">±</mo><mn id="S6.T5.5.5.1.m1.1.1.3" xref="S6.T5.5.5.1.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T5.5.5.1.m1.1b"><apply id="S6.T5.5.5.1.m1.1.1.cmml" xref="S6.T5.5.5.1.m1.1.1"><csymbol cd="latexml" id="S6.T5.5.5.1.m1.1.1.1.cmml" xref="S6.T5.5.5.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T5.5.5.1.m1.1.1.2.cmml" xref="S6.T5.5.5.1.m1.1.1.2">5.82</cn><cn type="float" id="S6.T5.5.5.1.m1.1.1.3.cmml" xref="S6.T5.5.5.1.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.5.5.1.m1.1c">5.82\pm 0.03</annotation></semantics></math></td>
<td id="S6.T5.6.6.2" class="ltx_td ltx_align_center ltx_border_bb"><math id="S6.T5.6.6.2.m1.1" class="ltx_Math" alttext="13.75\pm 0.03" display="inline"><semantics id="S6.T5.6.6.2.m1.1a"><mrow id="S6.T5.6.6.2.m1.1.1" xref="S6.T5.6.6.2.m1.1.1.cmml"><mn id="S6.T5.6.6.2.m1.1.1.2" xref="S6.T5.6.6.2.m1.1.1.2.cmml">13.75</mn><mo id="S6.T5.6.6.2.m1.1.1.1" xref="S6.T5.6.6.2.m1.1.1.1.cmml">±</mo><mn id="S6.T5.6.6.2.m1.1.1.3" xref="S6.T5.6.6.2.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T5.6.6.2.m1.1b"><apply id="S6.T5.6.6.2.m1.1.1.cmml" xref="S6.T5.6.6.2.m1.1.1"><csymbol cd="latexml" id="S6.T5.6.6.2.m1.1.1.1.cmml" xref="S6.T5.6.6.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T5.6.6.2.m1.1.1.2.cmml" xref="S6.T5.6.6.2.m1.1.1.2">13.75</cn><cn type="float" id="S6.T5.6.6.2.m1.1.1.3.cmml" xref="S6.T5.6.6.2.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.6.6.2.m1.1c">13.75\pm 0.03</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T5.8.1.1" class="ltx_text ltx_font_bold">Table 5</span>: </span>Prediction impression recall for the server and federated CIFG models
compared with the n-gram baseline, evaluated in experiments on live
user traffic.</figcaption>
</figure>
<figure id="S6.T6" class="ltx_table">
<table id="S6.T6.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T6.3.4.1" class="ltx_tr">
<th id="S6.T6.3.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Model</th>
<th id="S6.T6.3.4.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Prediction CTR [%]</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T6.1.1" class="ltx_tr">
<th id="S6.T6.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">N-gram</th>
<td id="S6.T6.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><math id="S6.T6.1.1.1.m1.1" class="ltx_Math" alttext="2.13\pm 0.03" display="inline"><semantics id="S6.T6.1.1.1.m1.1a"><mrow id="S6.T6.1.1.1.m1.1.1" xref="S6.T6.1.1.1.m1.1.1.cmml"><mn id="S6.T6.1.1.1.m1.1.1.2" xref="S6.T6.1.1.1.m1.1.1.2.cmml">2.13</mn><mo id="S6.T6.1.1.1.m1.1.1.1" xref="S6.T6.1.1.1.m1.1.1.1.cmml">±</mo><mn id="S6.T6.1.1.1.m1.1.1.3" xref="S6.T6.1.1.1.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T6.1.1.1.m1.1b"><apply id="S6.T6.1.1.1.m1.1.1.cmml" xref="S6.T6.1.1.1.m1.1.1"><csymbol cd="latexml" id="S6.T6.1.1.1.m1.1.1.1.cmml" xref="S6.T6.1.1.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T6.1.1.1.m1.1.1.2.cmml" xref="S6.T6.1.1.1.m1.1.1.2">2.13</cn><cn type="float" id="S6.T6.1.1.1.m1.1.1.3.cmml" xref="S6.T6.1.1.1.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.1.1.1.m1.1c">2.13\pm 0.03</annotation></semantics></math></td>
</tr>
<tr id="S6.T6.2.2" class="ltx_tr">
<th id="S6.T6.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Server CIFG</th>
<td id="S6.T6.2.2.1" class="ltx_td ltx_align_center"><math id="S6.T6.2.2.1.m1.1" class="ltx_Math" alttext="2.36\pm 0.03" display="inline"><semantics id="S6.T6.2.2.1.m1.1a"><mrow id="S6.T6.2.2.1.m1.1.1" xref="S6.T6.2.2.1.m1.1.1.cmml"><mn id="S6.T6.2.2.1.m1.1.1.2" xref="S6.T6.2.2.1.m1.1.1.2.cmml">2.36</mn><mo id="S6.T6.2.2.1.m1.1.1.1" xref="S6.T6.2.2.1.m1.1.1.1.cmml">±</mo><mn id="S6.T6.2.2.1.m1.1.1.3" xref="S6.T6.2.2.1.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T6.2.2.1.m1.1b"><apply id="S6.T6.2.2.1.m1.1.1.cmml" xref="S6.T6.2.2.1.m1.1.1"><csymbol cd="latexml" id="S6.T6.2.2.1.m1.1.1.1.cmml" xref="S6.T6.2.2.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T6.2.2.1.m1.1.1.2.cmml" xref="S6.T6.2.2.1.m1.1.1.2">2.36</cn><cn type="float" id="S6.T6.2.2.1.m1.1.1.3.cmml" xref="S6.T6.2.2.1.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.2.2.1.m1.1c">2.36\pm 0.03</annotation></semantics></math></td>
</tr>
<tr id="S6.T6.3.3" class="ltx_tr">
<th id="S6.T6.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Federated CIFG</th>
<td id="S6.T6.3.3.1" class="ltx_td ltx_align_center ltx_border_bb"><math id="S6.T6.3.3.1.m1.1" class="ltx_Math" alttext="2.35\pm 0.03" display="inline"><semantics id="S6.T6.3.3.1.m1.1a"><mrow id="S6.T6.3.3.1.m1.1.1" xref="S6.T6.3.3.1.m1.1.1.cmml"><mn id="S6.T6.3.3.1.m1.1.1.2" xref="S6.T6.3.3.1.m1.1.1.2.cmml">2.35</mn><mo id="S6.T6.3.3.1.m1.1.1.1" xref="S6.T6.3.3.1.m1.1.1.1.cmml">±</mo><mn id="S6.T6.3.3.1.m1.1.1.3" xref="S6.T6.3.3.1.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T6.3.3.1.m1.1b"><apply id="S6.T6.3.3.1.m1.1.1.cmml" xref="S6.T6.3.3.1.m1.1.1"><csymbol cd="latexml" id="S6.T6.3.3.1.m1.1.1.1.cmml" xref="S6.T6.3.3.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S6.T6.3.3.1.m1.1.1.2.cmml" xref="S6.T6.3.3.1.m1.1.1.2">2.35</cn><cn type="float" id="S6.T6.3.3.1.m1.1.1.3.cmml" xref="S6.T6.3.3.1.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.3.3.1.m1.1c">2.35\pm 0.03</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T6.5.1.1" class="ltx_text ltx_font_bold">Table 6</span>: </span>Prediction CTR for the server and federated CIFG models compared with
the n-gram baseline, evaluated in experiments on live user traffic.</figcaption>
</figure>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p">For both server training and federated training, the CIFG model improves the
top-1 and top-3 recall with respect to the baseline n-gram FST model. These
gains are impressive given that the n-gram model uses an order of magnitude
larger vocabulary and includes personalized components such as user history and
contacts LMs. Live user experiments show that the CIFG model also generates
predictions that are 10% more likely to be clicked than n-gram predictions.</p>
</div>
<div id="S6.p5" class="ltx_para">
<p id="S6.p5.2" class="ltx_p">The results also demonstrate that the federated CIFG performs better on recall
metrics than the server-trained CIFG. Table <a href="#S6.T4" title="Table 4 ‣ 6 Results ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows that, when
evaluating on client cache data, the federated CIFG improves the top-1 recall by
a relative <math id="S6.p5.1.m1.1" class="ltx_Math" alttext="5\%" display="inline"><semantics id="S6.p5.1.m1.1a"><mrow id="S6.p5.1.m1.1.1" xref="S6.p5.1.m1.1.1.cmml"><mn id="S6.p5.1.m1.1.1.2" xref="S6.p5.1.m1.1.1.2.cmml">5</mn><mo id="S6.p5.1.m1.1.1.1" xref="S6.p5.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.p5.1.m1.1b"><apply id="S6.p5.1.m1.1.1.cmml" xref="S6.p5.1.m1.1.1"><csymbol cd="latexml" id="S6.p5.1.m1.1.1.1.cmml" xref="S6.p5.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S6.p5.1.m1.1.1.2.cmml" xref="S6.p5.1.m1.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p5.1.m1.1c">5\%</annotation></semantics></math> (<math id="S6.p5.2.m2.1" class="ltx_Math" alttext="0.8\%" display="inline"><semantics id="S6.p5.2.m2.1a"><mrow id="S6.p5.2.m2.1.1" xref="S6.p5.2.m2.1.1.cmml"><mn id="S6.p5.2.m2.1.1.2" xref="S6.p5.2.m2.1.1.2.cmml">0.8</mn><mo id="S6.p5.2.m2.1.1.1" xref="S6.p5.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.p5.2.m2.1b"><apply id="S6.p5.2.m2.1.1.cmml" xref="S6.p5.2.m2.1.1"><csymbol cd="latexml" id="S6.p5.2.m2.1.1.1.cmml" xref="S6.p5.2.m2.1.1.1">percent</csymbol><cn type="float" id="S6.p5.2.m2.1.1.2.cmml" xref="S6.p5.2.m2.1.1.2">0.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p5.2.m2.1c">0.8\%</annotation></semantics></math> absolute) with respect to the server-trained CIFG.
Comparisons on server-hosted logs data show the recall of the two models is
comparable, though the logs are not as representative of the true typing
distribution. Most importantly, Table <a href="#S6.T5" title="Table 5 ‣ 6 Results ‣ Federated learning for mobile keyboard prediction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows that the
federated CIFG improves the top-1 and top-3 prediction impression recall by 1%
relative to the server CIFG for real Gboard users. While the comparison is not
exactly apples to apples — different flavors of SGD are used in each training
context — the results show that federated learning provides a preferable
alternative to server-based training of neural language models.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">We show that a CIFG language model trained from scratch using federated learning
can outperform an identical server-trained CIFG model and baseline n-gram model
on the keyboard next-word prediction task. To our knowledge, this represents one
of the first applications of federated language modeling in a commercial
setting. Federated learning offers security and privacy advantages for users by
training across a population of highly distributed computing devices while
simultaneously improving language model quality.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Acknowledgements</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">The authors would like to thank colleagues on the Google AI team for providing
the federated learning framework and for many helpful discussions.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Monica Anderson,

</span>
<span class="ltx_bibblock">“Technology device ownership: 2015,”
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://www.pewinternet.org/2015/10/29/technology-device-ownership-2015/</span>,

</span>
<span class="ltx_bibblock">Accessed: 2018-10-02.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Mehryar Mohri,

</span>
<span class="ltx_bibblock">“Finite-state transducers in language and speech processing,”

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Computational Linguistics</span>, vol. 23, no. 2, pp. 269–311, June
1997.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Tom Ouyang, David Rybach, Françoise Beaufays, and Michael Riley,

</span>
<span class="ltx_bibblock">“Mobile keyboard input decoding with finite-state transducers,”

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">CoRR</span>, vol. abs/1704.03987, 2017.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Cyril Allauzen and Michael Riley,

</span>
<span class="ltx_bibblock">“Bayesian language model interpolation for mobile speech input,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Interspeech 2011</span>, 2011, pp. 1429–1432.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
R. J. Williams and D. Zipser,

</span>
<span class="ltx_bibblock">“A learning algorithm for continually running fully recurrent neural
networks,”

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Neural Computation</span>, vol. 1, no. 2, pp. 270–280, June 1989.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
S. Hochreiter and J. Schmidhuber,

</span>
<span class="ltx_bibblock">“Long short-term memory,”

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Neural Computation</span>, vol. 9, no. 8, pp. 1735–1780, Nov 1997.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Yoshua Bengio, Réjean Ducharme, Pascal Vincent, and Christian Janvin,

</span>
<span class="ltx_bibblock">“A neural probabilistic language model,”

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">J. Mach. Learn. Res.</span>, vol. 3, pp. 1137–1155, Mar. 2003.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Yoon Kim, Yacine Jernite, David Sontag, and Alexander M. Rush,

</span>
<span class="ltx_bibblock">“Character-aware neural language models,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Proceedings of the Thirtieth AAAI Conference on Artificial
Intelligence</span>. 2016, AAAI’16, pp. 2741–2749, AAAI Press.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Ciprian Chelba, Tomas Mikolov, Mike Schuster, Qi Ge, Thorsten Brants, Phillipp
Koehn, and Tony Robinson,

</span>
<span class="ltx_bibblock">“One billion word benchmark for measuring progress in statistical
language modeling,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">INTERSPEECH 2014, 15th Annual Conference of the
International Speech Communication Association, Singapore, September 14-18,
2014</span>, Haizhou Li, Helen M. Meng, Bin Ma, Engsiong Chng, and Lei Xie, Eds.
2014, pp. 2635–2639, ISCA.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu,

</span>
<span class="ltx_bibblock">“Exploring the limits of language modeling,” 2016.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc V. Le,
Geoffrey E. Hinton, and Jeff Dean,

</span>
<span class="ltx_bibblock">“Outrageously large neural networks: The sparsely-gated
mixture-of-experts layer,”

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">CoRR</span>, vol. abs/1701.06538, 2017.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
Blaise Agüera y Arcas,

</span>
<span class="ltx_bibblock">“Communication-efficient learning of deep networks from
decentralized data,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Proceedings of the 20th International Conference on
Artificial Intelligence and Statistics, AISTATS 2017, 20-22 April 2017,
Fort Lauderdale, FL, USA</span>, Aarti Singh and Xiaojin (Jerry) Zhu, Eds. 2017,
vol. 54 of <span id="bib.bib12.2.2" class="ltx_text ltx_font_italic">Proceedings of Machine Learning Research</span>, pp. 1273–1282,
PMLR.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Ouais Alsharif, Tom Ouyang, Françoise Beaufays, Shumin Zhai, Thomas Breuel,
and Johan Schalkwyk,

</span>
<span class="ltx_bibblock">“Long short term memory neural network for keyboard gesture
decoding,”

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">2015 IEEE International Conference on Acoustics, Speech and
Signal Processing (ICASSP)</span>, pp. 2076–2080, 2015.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Seunghak Yu, Nilesh Kulkarni, Haejun Lee, and Jihie Kim,

</span>
<span class="ltx_bibblock">“On-device neural language model based word prediction,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">COLING 2018, The 27th International Conference on
Computational Linguistics: System Demonstrations, Santa Fe, New Mexico,
August 20-26, 2018</span>, Dongyan Zhao, Ed. 2018, pp. 128–131, Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Shaona Ghosh and Per Ola Kristensson,

</span>
<span class="ltx_bibblock">“Neural networks for text correction and completion in keyboard
decoding,”

</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">CoRR</span>, vol. abs/1709.06429, 2017.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Reza Shokri and Vitaly Shmatikov,

</span>
<span class="ltx_bibblock">“Privacy-preserving deep learning,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Proceedings of the 22Nd ACM SIGSAC Conference on Computer and
Communications Security</span>, New York, NY, USA, 2015, CCS ’15, pp. 1310–1321,
ACM.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Cynthia Dwork,

</span>
<span class="ltx_bibblock">“Differential privacy,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">33rd International Colloquium on Automata, Languages and
Programming, part II (ICALP 2006)</span>, Venice, Italy, July 2006, vol. 4052, pp.
1–12, Springer Verlag.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
H. Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang,

</span>
<span class="ltx_bibblock">“Learning differentially private language models without losing
accuracy,”

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">CoRR</span>, vol. abs/1710.06963, 2017.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Brendan McMahan and Daniel Ramage,

</span>
<span class="ltx_bibblock">“Federated learning: Collaborative machine learning without
centralized training data,”
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://ai.googleblog.com/2017/04/federated-learning-collaborative.html</span>,

</span>
<span class="ltx_bibblock">Accessed: 2018-10-04.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Klaus Greff, Rupesh Kumar Srivastava, Jan Koutník, Bas R. Steunebrink,
and Jürgen Schmidhuber,

</span>
<span class="ltx_bibblock">“LSTM: A search space odyssey,”

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">IEEE Trans. Neural Netw. Learning Syst.</span>, vol. 28, no. 10, pp.
2222–2232, 2017.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Kyunghyun Cho, Bart van Merrienboer, Çaglar Gülçehre, Dzmitry
Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio,

</span>
<span class="ltx_bibblock">“Learning phrase representations using RNN encoder-decoder for
statistical machine translation,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2014 Conference on Empirical Methods in
Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar,
A meeting of SIGDAT, a Special Interest Group of the ACL</span>, Alessandro
Moschitti, Bo Pang, and Walter Daelemans, Eds. 2014, pp. 1724–1734, ACL.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis,
Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael
Isard, Manjunath Kudlur, Josh Levenberg, Rajat Monga, Sherry Moore,
Derek Gordon Murray, Benoit Steiner, Paul A. Tucker, Vijay Vasudevan, Pete
Warden, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng,

</span>
<span class="ltx_bibblock">“Tensorflow: A system for large-scale machine learning,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">12th USENIX Symposium on Operating Systems Design and
Implementation, OSDI 2016, Savannah, GA, USA, November 2-4, 2016.</span>,
Kimberly Keeton and Timothy Roscoe, Eds. 2016, pp. 265–283, USENIX
Association.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Ofir Press and Lior Wolf,

</span>
<span class="ltx_bibblock">“Using the output embedding to improve language models,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Proceedings of the 15th Conference of the European Chapter of
the Association for Computational Linguistics, EACL 2017, Valencia, Spain,
April 3-7, 2017, Volume 2: Short Papers</span>, Mirella Lapata, Phil Blunsom, and
Alexander Koller, Eds. 2017, pp. 157–163, Association for Computational
Linguistics.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Hakan Inan, Khashayar Khosravi, and Richard Socher,

</span>
<span class="ltx_bibblock">“Tying word vectors and word classifiers: A loss framework for
language modeling,”

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">CoRR</span>, vol. abs/1611.01462, 2016.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
The White House,

</span>
<span class="ltx_bibblock">“Consumer data privacy in a networked world: A framework for
protecting privacy and promoting innovation in the global digital economy,”
01 2013.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H. Brendan
McMahan, Sarvar Patel, Daniel Ramage, Aaron Segal, and Karn Seth,

</span>
<span class="ltx_bibblock">“Practical secure aggregation for federated learning on user-held
data,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">NIPS Workshop on Private Multi-Party Machine Learning</span>, 2016.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
D. P. Kingma and J. Ba,

</span>
<span class="ltx_bibblock">“Adam: A Method for Stochastic Optimization,”

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">ArXiv e-prints</span>, Dec. 2014.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
John Duchi, Elad Hazan, and Yoram Singer,

</span>
<span class="ltx_bibblock">“Adaptive subgradient methods for online learning and stochastic
optimization,”

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">J. Mach. Learn. Res.</span>, vol. 12, pp. 2121–2159, July 2011.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Yurii Nesterov,

</span>
<span class="ltx_bibblock">“A method for solving the convex programming problem with
convergence rate <math id="bib.bib29.1.m1.1" class="ltx_Math" alttext="o(1/{k}^{2})" display="inline"><semantics id="bib.bib29.1.m1.1a"><mrow id="bib.bib29.1.m1.1.1" xref="bib.bib29.1.m1.1.1.cmml"><mi id="bib.bib29.1.m1.1.1.3" xref="bib.bib29.1.m1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="bib.bib29.1.m1.1.1.2" xref="bib.bib29.1.m1.1.1.2.cmml">​</mo><mrow id="bib.bib29.1.m1.1.1.1.1" xref="bib.bib29.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="bib.bib29.1.m1.1.1.1.1.2" xref="bib.bib29.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="bib.bib29.1.m1.1.1.1.1.1" xref="bib.bib29.1.m1.1.1.1.1.1.cmml"><mn id="bib.bib29.1.m1.1.1.1.1.1.2" xref="bib.bib29.1.m1.1.1.1.1.1.2.cmml">1</mn><mo id="bib.bib29.1.m1.1.1.1.1.1.1" xref="bib.bib29.1.m1.1.1.1.1.1.1.cmml">/</mo><msup id="bib.bib29.1.m1.1.1.1.1.1.3" xref="bib.bib29.1.m1.1.1.1.1.1.3.cmml"><mi id="bib.bib29.1.m1.1.1.1.1.1.3.2" xref="bib.bib29.1.m1.1.1.1.1.1.3.2.cmml">k</mi><mn id="bib.bib29.1.m1.1.1.1.1.1.3.3" xref="bib.bib29.1.m1.1.1.1.1.1.3.3.cmml">2</mn></msup></mrow><mo stretchy="false" id="bib.bib29.1.m1.1.1.1.1.3" xref="bib.bib29.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="bib.bib29.1.m1.1b"><apply id="bib.bib29.1.m1.1.1.cmml" xref="bib.bib29.1.m1.1.1"><times id="bib.bib29.1.m1.1.1.2.cmml" xref="bib.bib29.1.m1.1.1.2"></times><ci id="bib.bib29.1.m1.1.1.3.cmml" xref="bib.bib29.1.m1.1.1.3">𝑜</ci><apply id="bib.bib29.1.m1.1.1.1.1.1.cmml" xref="bib.bib29.1.m1.1.1.1.1"><divide id="bib.bib29.1.m1.1.1.1.1.1.1.cmml" xref="bib.bib29.1.m1.1.1.1.1.1.1"></divide><cn type="integer" id="bib.bib29.1.m1.1.1.1.1.1.2.cmml" xref="bib.bib29.1.m1.1.1.1.1.1.2">1</cn><apply id="bib.bib29.1.m1.1.1.1.1.1.3.cmml" xref="bib.bib29.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="bib.bib29.1.m1.1.1.1.1.1.3.1.cmml" xref="bib.bib29.1.m1.1.1.1.1.1.3">superscript</csymbol><ci id="bib.bib29.1.m1.1.1.1.1.1.3.2.cmml" xref="bib.bib29.1.m1.1.1.1.1.1.3.2">𝑘</ci><cn type="integer" id="bib.bib29.1.m1.1.1.1.1.1.3.3.cmml" xref="bib.bib29.1.m1.1.1.1.1.1.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="bib.bib29.1.m1.1c">o(1/{k}^{2})</annotation></semantics></math>,”

</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text ltx_font_italic">Dokl. Akad. Nauk SSSR</span>, vol. 269, pp. 543–547, 1983.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/1811.03603" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/1811.03604" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+1811.03604">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/1811.03604" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/1811.03605" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar 16 09:01:09 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
