<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2003.11844] P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)</title><meta property="og:description" content="In recent years, progress in the Visual Question Answering (VQA) field has largely been driven by public challenges and large datasets.
One of the most widely-used of these is the VQA 2.0 dataset, consisting of polar (…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2003.11844">

<!--Generated on Sun Mar 17 07:49:05 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">P <math id="id1.m1.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="id1.m1.1b"><mo id="id1.m1.1.1" xref="id1.m1.1.1.cmml">≈</mo><annotation-xml encoding="MathML-Content" id="id1.m1.1c"><approx id="id1.m1.1.1.cmml" xref="id1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="id1.m1.1d">\approx</annotation></semantics></math> NP, at least in Visual Question Answering
<span id="id5.id1" class="ltx_note ltx_role_thanks"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks: </span>This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)</span></span></span>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">


Shailza Jolly1<sup id="id6.1.id1" class="ltx_sup">,1,2</sup>,
Sebastian Palacio1<sup id="id7.2.id2" class="ltx_sup">,1,2</sup>,
Joachim Folz<sup id="id8.3.id3" class="ltx_sup">1,2</sup>,
Federico Raue<sup id="id9.4.id4" class="ltx_sup">2</sup>,
Jörn Hees<sup id="id10.5.id5" class="ltx_sup">2</sup>,
Andreas Dengel<sup id="id11.6.id6" class="ltx_sup">1,2</sup>
</span><span class="ltx_author_notes">1 Authors contributed equally
<span class="ltx_contact ltx_role_affiliation"><sup id="id12.7.id1" class="ltx_sup">1</sup>DFKI GmbH
<br class="ltx_break"><sup id="id13.8.id2" class="ltx_sup">2</sup>TU Kaiserslautern 
<br class="ltx_break">Kaiserslautern, Germany 
<br class="ltx_break"><a href="firstname.lastname@dfki.de" title="" class="ltx_ref ltx_url ltx_font_typewriter">firstname.lastname@dfki.de</a>
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id14.id1" class="ltx_p">In recent years, progress in the Visual Question Answering (VQA) field has largely been driven by public challenges and large datasets.
One of the most widely-used of these is the VQA 2.0 dataset, consisting of polar (“yes/no”) and non-polar questions.
Looking at the question distribution over all answers, we find that the answers “yes” and “no” account for 38 % of the questions, while the remaining 62 % are spread over the more than 3000 remaining answers.
While several sources of biases have already been investigated in the field, the effects of such an over-representation of polar vs. non-polar questions remain unclear.</p>
<p id="id15.id2" class="ltx_p">In this paper, we measure the potential confounding factors when polar and non-polar samples are used jointly to train a baseline VQA classifier, and compare it to an upper bound where the over-representation of polar questions is excluded from the training.
Further, we perform cross-over experiments to analyze how well the feature spaces align.</p>
<p id="id4.3" class="ltx_p">Contrary to expectations, we find no evidence of counterproductive effects in the joint training of unbalanced classes.
In fact, by exploring the intermediate feature space of visual-text embeddings, we find that the feature space of polar questions already encodes sufficient structure to answer many non-polar questions.
Our results indicate that the polar (<math id="id2.1.m1.1" class="ltx_Math" alttext="\bm{P}" display="inline"><semantics id="id2.1.m1.1a"><mi id="id2.1.m1.1.1" xref="id2.1.m1.1.1.cmml">𝑷</mi><annotation-xml encoding="MathML-Content" id="id2.1.m1.1b"><ci id="id2.1.m1.1.1.cmml" xref="id2.1.m1.1.1">𝑷</ci></annotation-xml><annotation encoding="application/x-tex" id="id2.1.m1.1c">\bm{P}</annotation></semantics></math>) and the non-polar (<math id="id3.2.m2.1" class="ltx_Math" alttext="\bm{NP}" display="inline"><semantics id="id3.2.m2.1a"><mrow id="id3.2.m2.1.1" xref="id3.2.m2.1.1.cmml"><mi id="id3.2.m2.1.1.2" xref="id3.2.m2.1.1.2.cmml">𝑵</mi><mo lspace="0em" rspace="0em" id="id3.2.m2.1.1.1" xref="id3.2.m2.1.1.1.cmml">​</mo><mi id="id3.2.m2.1.1.3" xref="id3.2.m2.1.1.3.cmml">𝑷</mi></mrow><annotation-xml encoding="MathML-Content" id="id3.2.m2.1b"><apply id="id3.2.m2.1.1.cmml" xref="id3.2.m2.1.1"><times id="id3.2.m2.1.1.1.cmml" xref="id3.2.m2.1.1.1"></times><ci id="id3.2.m2.1.1.2.cmml" xref="id3.2.m2.1.1.2">𝑵</ci><ci id="id3.2.m2.1.1.3.cmml" xref="id3.2.m2.1.1.3">𝑷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id3.2.m2.1c">\bm{NP}</annotation></semantics></math>) feature spaces are strongly aligned, hence the expression <math id="id4.3.m3.1" class="ltx_Math" alttext="\bm{P}\bm{\approx}\bm{NP}" display="inline"><semantics id="id4.3.m3.1a"><mrow id="id4.3.m3.1.1" xref="id4.3.m3.1.1.cmml"><mi id="id4.3.m3.1.1.2" xref="id4.3.m3.1.1.2.cmml">𝑷</mi><mo class="ltx_mathvariant_bold" mathvariant="bold" id="id4.3.m3.1.1.1" xref="id4.3.m3.1.1.1.cmml">≈</mo><mrow id="id4.3.m3.1.1.3" xref="id4.3.m3.1.1.3.cmml"><mi id="id4.3.m3.1.1.3.2" xref="id4.3.m3.1.1.3.2.cmml">𝑵</mi><mo lspace="0em" rspace="0em" id="id4.3.m3.1.1.3.1" xref="id4.3.m3.1.1.3.1.cmml">​</mo><mi id="id4.3.m3.1.1.3.3" xref="id4.3.m3.1.1.3.3.cmml">𝑷</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="id4.3.m3.1b"><apply id="id4.3.m3.1.1.cmml" xref="id4.3.m3.1.1"><approx id="id4.3.m3.1.1.1.cmml" xref="id4.3.m3.1.1.1"></approx><ci id="id4.3.m3.1.1.2.cmml" xref="id4.3.m3.1.1.2">𝑷</ci><apply id="id4.3.m3.1.1.3.cmml" xref="id4.3.m3.1.1.3"><times id="id4.3.m3.1.1.3.1.cmml" xref="id4.3.m3.1.1.3.1"></times><ci id="id4.3.m3.1.1.3.2.cmml" xref="id4.3.m3.1.1.3.2">𝑵</ci><ci id="id4.3.m3.1.1.3.3.cmml" xref="id4.3.m3.1.1.3.3">𝑷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id4.3.m3.1c">\bm{P}\bm{\approx}\bm{NP}</annotation></semantics></math>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The task of Visual Question Answering (VQA) is highly interesting as it requires machine learning (ML) models to concurrently optimize multi-modal objectives related to natural language processing, object detection, and instance segmentation. As initial advancements in the field were quickly made, some research started analyzing the extent to which good results were merely achieved by exploiting low level biases in the datasets themselves. Not long after the release of several VQA datasets, a single study already found consistent significant sources of bias for at least six of them <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
Said biases are found primarily on the questions, and more precisely, on the way certain questions strongly correlate with the correct answer (e.g., questions that start with “<span id="S1.p1.1.1" class="ltx_text ltx_font_italic">what sport…</span>” can be answered with “<span id="S1.p1.1.2" class="ltx_text ltx_font_italic">tennis</span>” more often than not).
Imbalances like these have been widely studied and have even resulted in new metrics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>,
regularizers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> or re-balanced partitions for existing datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.5" class="ltx_p">In this paper, we explore a different, potential source of bias in datasets that include both polar (<math id="S1.p2.1.m1.1" class="ltx_Math" alttext="\operatorname{P}" display="inline"><semantics id="S1.p2.1.m1.1a"><mi mathvariant="normal" id="S1.p2.1.m1.1.1" xref="S1.p2.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><ci id="S1.p2.1.m1.1.1.cmml" xref="S1.p2.1.m1.1.1">P</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">\operatorname{P}</annotation></semantics></math>) and non-polar (<math id="S1.p2.2.m2.1" class="ltx_Math" alttext="\operatorname{NP}" display="inline"><semantics id="S1.p2.2.m2.1a"><mi id="S1.p2.2.m2.1.1" xref="S1.p2.2.m2.1.1.cmml">NP</mi><annotation-xml encoding="MathML-Content" id="S1.p2.2.m2.1b"><ci id="S1.p2.2.m2.1.1.cmml" xref="S1.p2.2.m2.1.1">NP</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.2.m2.1c">\operatorname{NP}</annotation></semantics></math>) questions together.
Polar questions are those with answer <span id="S1.p2.5.1" class="ltx_text ltx_font_italic">yes</span> or <span id="S1.p2.5.2" class="ltx_text ltx_font_italic">no</span> (commonly referred to as “yes/no” questions).
By extension, non-polar questions are the complement of the set of polar questions, i.e., questions with an answer that is something other than <span id="S1.p2.5.3" class="ltx_text ltx_font_italic">yes</span> or <span id="S1.p2.5.4" class="ltx_text ltx_font_italic">no</span>.
Polar questions have been criticized for their simplicity and often excluded in favor of questions that are richer in complexity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.
In fact, datasets like COCO-QA, VQA 1.0 or VQA 2.0 that make use of polar questions show an imbalance of the answer distribution where polar questions are significantly over-represented.
For the case of VQA 2.0, polar questions comprise <math id="S1.p2.3.m3.1" class="ltx_Math" alttext="38\,\%" display="inline"><semantics id="S1.p2.3.m3.1a"><mrow id="S1.p2.3.m3.1.1" xref="S1.p2.3.m3.1.1.cmml"><mn id="S1.p2.3.m3.1.1.2" xref="S1.p2.3.m3.1.1.2.cmml">38</mn><mo lspace="0.170em" id="S1.p2.3.m3.1.1.1" xref="S1.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.p2.3.m3.1b"><apply id="S1.p2.3.m3.1.1.cmml" xref="S1.p2.3.m3.1.1"><csymbol cd="latexml" id="S1.p2.3.m3.1.1.1.cmml" xref="S1.p2.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S1.p2.3.m3.1.1.2.cmml" xref="S1.p2.3.m3.1.1.2">38</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.3.m3.1c">38\,\%</annotation></semantics></math> of the available corpus.
This means that the answer <span id="S1.p2.5.5" class="ltx_text ltx_font_italic">yes</span> appears roughly <math id="S1.p2.4.m4.1" class="ltx_Math" alttext="19\,\%" display="inline"><semantics id="S1.p2.4.m4.1a"><mrow id="S1.p2.4.m4.1.1" xref="S1.p2.4.m4.1.1.cmml"><mn id="S1.p2.4.m4.1.1.2" xref="S1.p2.4.m4.1.1.2.cmml">19</mn><mo lspace="0.170em" id="S1.p2.4.m4.1.1.1" xref="S1.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.p2.4.m4.1b"><apply id="S1.p2.4.m4.1.1.cmml" xref="S1.p2.4.m4.1.1"><csymbol cd="latexml" id="S1.p2.4.m4.1.1.1.cmml" xref="S1.p2.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S1.p2.4.m4.1.1.2.cmml" xref="S1.p2.4.m4.1.1.2">19</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.4.m4.1c">19\,\%</annotation></semantics></math> of the time, and so does the answer <span id="S1.p2.5.6" class="ltx_text ltx_font_italic">no</span>.
In contrast, each of the remaining 3127 classes (answers) occur, on average, <math id="S1.p2.5.m5.1" class="ltx_Math" alttext="2\,\%" display="inline"><semantics id="S1.p2.5.m5.1a"><mrow id="S1.p2.5.m5.1.1" xref="S1.p2.5.m5.1.1.cmml"><mn id="S1.p2.5.m5.1.1.2" xref="S1.p2.5.m5.1.1.2.cmml">2</mn><mo lspace="0.170em" id="S1.p2.5.m5.1.1.1" xref="S1.p2.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.p2.5.m5.1b"><apply id="S1.p2.5.m5.1.1.cmml" xref="S1.p2.5.m5.1.1"><csymbol cd="latexml" id="S1.p2.5.m5.1.1.1.cmml" xref="S1.p2.5.m5.1.1.1">percent</csymbol><cn type="integer" id="S1.p2.5.m5.1.1.2.cmml" xref="S1.p2.5.m5.1.1.2">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.5.m5.1c">2\,\%</annotation></semantics></math> of the time (see Figure <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2003.11844/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="159" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Distribution of polar (P) and non-polar (NP) samples in VQA 2.0.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">So far, the over-representation of polar samples has been approached in isolation, mainly in two different ways:
First, polar questions are either excluded entirely form the corpus or used exclusively <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.
Second, for datasets with a mix of polar and non-polar questions, evaluation protocol dictates that the accuracy has to be reported separately for polar samples.
Despite this strict separation of the second scenario, VQA models are frequently trained jointly, treating each unique answer independently, regardless of polarity, and under i.i.d. conditions.
Moreover, state-of-the-art approaches do not make any specific mention about balancing techniques like class regularization or mini-batch resampling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.
This simple imbalance can cause severe performance issues, as proposed models could allocate more capacity to answering polar questions just because they appear more often during training.
In fact, we see how performance of polar questions is consistently superior to that of other non-polar sub-categories for the popular VQA challenge<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="http://visualqa.org" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://visualqa.org</a></span></span></span>.
Even after compensating for the number of classes per group, the expected mean accuracy of any random pair of non-polar classes is a lot lower than the one of polar questions.
The question we ask is if there is any measurable impact (positive or negative) stemming from the over-representation of polar questions in VQA datasets.
Are there confounding factors between polar and non-polar questions when projected into a common feature space?
Are polar questions occupying a non-overlapping region of the feature space w.r.t. their non-polar counterparts?
We investigate these questions and their implications by conducting a series of experiments on a high-performance VQA classifier.
By comparing its behaviour when data distribution changes during training and testing, we conclude, contrary to intuition, that there is a considerable overlap between features from polar questions and non-polar questions.
Moreover, this overlap is favorable to the overall optimization objective such that non-polar questions can be successfully answered based purely on polar features and vice versa.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The contributions of this paper are thereby two-fold:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">An evaluation of the potential confounding factors (i.e. bias) that polar questions induce due to over-representation during training.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Empirical evidence indicating that the feature space from polar features can be used to answer non-polar questions and vice versa (<math id="S1.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="\operatorname{P}\approx\operatorname{NP}" display="inline"><semantics id="S1.I1.i2.p1.1.m1.1a"><mrow id="S1.I1.i2.p1.1.m1.1.1" xref="S1.I1.i2.p1.1.m1.1.1.cmml"><mi mathvariant="normal" id="S1.I1.i2.p1.1.m1.1.1.2" xref="S1.I1.i2.p1.1.m1.1.1.2.cmml">P</mi><mo id="S1.I1.i2.p1.1.m1.1.1.1" xref="S1.I1.i2.p1.1.m1.1.1.1.cmml">≈</mo><mi id="S1.I1.i2.p1.1.m1.1.1.3" xref="S1.I1.i2.p1.1.m1.1.1.3.cmml">NP</mi></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i2.p1.1.m1.1b"><apply id="S1.I1.i2.p1.1.m1.1.1.cmml" xref="S1.I1.i2.p1.1.m1.1.1"><approx id="S1.I1.i2.p1.1.m1.1.1.1.cmml" xref="S1.I1.i2.p1.1.m1.1.1.1"></approx><ci id="S1.I1.i2.p1.1.m1.1.1.2.cmml" xref="S1.I1.i2.p1.1.m1.1.1.2">P</ci><ci id="S1.I1.i2.p1.1.m1.1.1.3.cmml" xref="S1.I1.i2.p1.1.m1.1.1.3">NP</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i2.p1.1.m1.1c">\operatorname{P}\approx\operatorname{NP}</annotation></semantics></math>).</p>
</div>
</li>
</ul>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The rest of the paper is organized as follows.
Section <a href="#S2" title="II Related Work ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> goes over previous work related to the study of polar and non-polar questions, as well as biases in VQA datasets.
Section <a href="#S3" title="III Methods ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> outlines the experimental setup and training regimes.
Section <a href="#S4" title="IV Results ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> describes the experimental results and Section <a href="#S5" title="V Discussion ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> brings results into perspective, discussing the implications in the context of the joint feature space of polar and non-polar questions.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Work</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Current developments in the field of deep learning have demanded large amounts of data for training and evaluation.
Models rely on the usefulness of these carefully curated corpuses, often taking for granted how representative a training set is.
Datasets being permeable to biases (spurious, undesired patterns) can drastically undermine the novelty and usefulness of certain ML models, as well as their claimed performance.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Problems dealing with natural text often struggle with issues of this nature.
For example, a strong gender bias has been reported for imSitu, a visual semantic role labeling dataset where activities like “<span id="S2.p2.1.1" class="ltx_text ltx_font_italic">cooking</span>” were strongly biased towards women <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
Not only was the bias present in the dataset but trained models were amplifying the bias during testing as well.
The widely used MS-COCO dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> presents biases for image captioning because objects and background often co-occur e.g., giraffes appear next to a tree with grass in the background <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.
Being largely based on MS-COCO, the VQA 1.0 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> was therefore affected by this bias too, with the now infamous example of “<span id="S2.p2.1.2" class="ltx_text ltx_font_italic">tennis</span>” being the correct answer to 41% of questions starting with “<span id="S2.p2.1.3" class="ltx_text ltx_font_italic">what sport…</span>”.
Not long after, a study focusing on the limitations of current VQA datasets found that six of the most commonly used corpuses contained some sort of bias related to the textual domain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
The ubiquity of said imbalances results in an inability to measure the extent by which VQA models are indeed capable of extracting meaningful, and visually grounded semantics.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">From this point on, several advances in VQA were directly addressing biases in the existing datasets.
Alternative training and testing splits for VQA 1.0 and 2.0 were introduced in order to measure the extend by which VQA models can cope with unseen composition of concepts e.g., after learning about “green plate” and “white shirt” the network is then evaluated on “white plates” or “green shirts” <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
Simultaneously, the emergence of several regularization techniques helped models compensate or at least mitigate the effects of biases picked up by language models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">On the behavior of polar and non-polar questions, research has focused, among other things, on the importance of having polar questions balanced, i.e., having the same number of questions with “<span id="S2.p4.1.1" class="ltx_text ltx_font_italic">yes</span>” and “<span id="S2.p4.1.2" class="ltx_text ltx_font_italic">no</span>” as an answer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.
Moreover, a polar-only dataset was proposed to measure the extent by which logic reasoning can be solved by a VQA system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.
So far, these experiments only analyze effects of imbalances within the polar space in isolation, disregarding the interactions that polar and non-polar questions may have in a joint feature space.
A recapitulation of good practices for training models using VQA 2.0 recommends balancing each mini-batch w.r.t. opposite questions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.
This policy ensures that there is always a balance between samples with “<span id="S2.p4.1.3" class="ltx_text ltx_font_italic">yes</span>” and “<span id="S2.p4.1.4" class="ltx_text ltx_font_italic">no</span>” answers, but does not consider the balance between polar and non-polar questions.
An explicit separation of polar and non-polar questions was proposed for the GVQA model, which processes polar questions separately from non-polar ones, using the former as a verification mechanism for the non polar concepts contained within <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">Since polar questions can be obtained easier than non-polar ones, datasets relying on human annotators end up with a distribution of question types that is heavily skewed towards polar questions.
Some synthetically generated datasets like CLEVR compensate for such over-representation, having a more uniform distribution along different answer types <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
On the other side of the spectrum, synthetic and natural datasets have outright dismissed the use of polar questions to alleviate such over-representation issues <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, and because of this restriction, more complex questions can be attained <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">In this paper, we are concerned with the influence that over-represented polar questions exert on the non-polar counterparts when trained jointly, as it is the case for a majority of modern VQA models.
Experiments that eliminate confounding factors between the two categories are conducted in order to assess the upper bound of a VQA model when using only one or the other kind of question.
Furthermore, we find a strong alignment between the feature space of polar questions and that of non-polar questions, indicating that polar questions can be used to answer non-polar answers and vice versa.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Methods</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we present the main model and variations thereof used for all the experiments, motivate the use of the dataset, and describe the metrics to be compared afterwards.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Dataset</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.2" class="ltx_p">We use the VQA 2.0 dataset for all experiments.
With <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="443\,757" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mn id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">443 757</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><cn type="integer" id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">443757</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">443\,757</annotation></semantics></math> training samples and <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="214\,354" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mn id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">214 354</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><cn type="integer" id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">214354</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">214\,354</annotation></semantics></math> for validation, it is currently the largest available non-synthetic corpus for VQA containing both polar and non-polar questions.
Additional properties that make this dataset suitable for our analysis include a uniform distribution between questions with “<span id="S3.SS1.p1.2.1" class="ltx_text ltx_font_italic">yes</span>” and “<span id="S3.SS1.p1.2.2" class="ltx_text ltx_font_italic">no</span>” as ground-truth, as well as an adjusted distribution of non-polar answers w.r.t. VQA 1.0.
We split the VQA 2.0 corpus into two disjoint sets corresponding to the polar and non-polar questions.
Notwithstanding, samples also remain in the training and validation set as originally assigned.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">VQA Reference Model</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.9" class="ltx_p">For our experiments, we use a high-performance VQA system with region-based attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.
Figure <a href="#S3.F2" title="Figure 2 ‣ III-B VQA Reference Model ‣ III Methods ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows an overview of the model which, at its core, consists of three modules: an image embedding, a text embedding and a joint classification module.
To model the joint visual-text space, both image and text embeddings are first projected to a 512-dimensional space, and then fused together through an element-wise product.
Subsequently, the joint embedding passes through a sequence of fully connected layers before reaching the output layer, where the output is normalized by a softmax operation.
In this paper, we refer to the first part of the network (up until the point-wise multiplication of the 512-dimensional projection of the visual-text space) as the <span id="S3.SS2.p1.9.1" class="ltx_text ltx_font_bold">base VQA network</span>, denoted as <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\Phi" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi mathvariant="normal" id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">Φ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">Φ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\Phi</annotation></semantics></math>.
The remaining part of the network consisting of two fully connected layers and the output layer is referred to as <span id="S3.SS2.p1.9.2" class="ltx_text ltx_font_bold">the classifier</span> and denoted as <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">f</annotation></semantics></math>.
This way, a prediction by the network can be written as <math id="S3.SS2.p1.3.m3.2" class="ltx_Math" alttext="\hat{y}=f(\Phi(x))" display="inline"><semantics id="S3.SS2.p1.3.m3.2a"><mrow id="S3.SS2.p1.3.m3.2.2" xref="S3.SS2.p1.3.m3.2.2.cmml"><mover accent="true" id="S3.SS2.p1.3.m3.2.2.3" xref="S3.SS2.p1.3.m3.2.2.3.cmml"><mi id="S3.SS2.p1.3.m3.2.2.3.2" xref="S3.SS2.p1.3.m3.2.2.3.2.cmml">y</mi><mo id="S3.SS2.p1.3.m3.2.2.3.1" xref="S3.SS2.p1.3.m3.2.2.3.1.cmml">^</mo></mover><mo id="S3.SS2.p1.3.m3.2.2.2" xref="S3.SS2.p1.3.m3.2.2.2.cmml">=</mo><mrow id="S3.SS2.p1.3.m3.2.2.1" xref="S3.SS2.p1.3.m3.2.2.1.cmml"><mi id="S3.SS2.p1.3.m3.2.2.1.3" xref="S3.SS2.p1.3.m3.2.2.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.3.m3.2.2.1.2" xref="S3.SS2.p1.3.m3.2.2.1.2.cmml">​</mo><mrow id="S3.SS2.p1.3.m3.2.2.1.1.1" xref="S3.SS2.p1.3.m3.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p1.3.m3.2.2.1.1.1.2" xref="S3.SS2.p1.3.m3.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p1.3.m3.2.2.1.1.1.1" xref="S3.SS2.p1.3.m3.2.2.1.1.1.1.cmml"><mi mathvariant="normal" id="S3.SS2.p1.3.m3.2.2.1.1.1.1.2" xref="S3.SS2.p1.3.m3.2.2.1.1.1.1.2.cmml">Φ</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.3.m3.2.2.1.1.1.1.1" xref="S3.SS2.p1.3.m3.2.2.1.1.1.1.1.cmml">​</mo><mrow id="S3.SS2.p1.3.m3.2.2.1.1.1.1.3.2" xref="S3.SS2.p1.3.m3.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p1.3.m3.2.2.1.1.1.1.3.2.1" xref="S3.SS2.p1.3.m3.2.2.1.1.1.1.cmml">(</mo><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">x</mi><mo stretchy="false" id="S3.SS2.p1.3.m3.2.2.1.1.1.1.3.2.2" xref="S3.SS2.p1.3.m3.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS2.p1.3.m3.2.2.1.1.1.3" xref="S3.SS2.p1.3.m3.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.2b"><apply id="S3.SS2.p1.3.m3.2.2.cmml" xref="S3.SS2.p1.3.m3.2.2"><eq id="S3.SS2.p1.3.m3.2.2.2.cmml" xref="S3.SS2.p1.3.m3.2.2.2"></eq><apply id="S3.SS2.p1.3.m3.2.2.3.cmml" xref="S3.SS2.p1.3.m3.2.2.3"><ci id="S3.SS2.p1.3.m3.2.2.3.1.cmml" xref="S3.SS2.p1.3.m3.2.2.3.1">^</ci><ci id="S3.SS2.p1.3.m3.2.2.3.2.cmml" xref="S3.SS2.p1.3.m3.2.2.3.2">𝑦</ci></apply><apply id="S3.SS2.p1.3.m3.2.2.1.cmml" xref="S3.SS2.p1.3.m3.2.2.1"><times id="S3.SS2.p1.3.m3.2.2.1.2.cmml" xref="S3.SS2.p1.3.m3.2.2.1.2"></times><ci id="S3.SS2.p1.3.m3.2.2.1.3.cmml" xref="S3.SS2.p1.3.m3.2.2.1.3">𝑓</ci><apply id="S3.SS2.p1.3.m3.2.2.1.1.1.1.cmml" xref="S3.SS2.p1.3.m3.2.2.1.1.1"><times id="S3.SS2.p1.3.m3.2.2.1.1.1.1.1.cmml" xref="S3.SS2.p1.3.m3.2.2.1.1.1.1.1"></times><ci id="S3.SS2.p1.3.m3.2.2.1.1.1.1.2.cmml" xref="S3.SS2.p1.3.m3.2.2.1.1.1.1.2">Φ</ci><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝑥</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.2c">\hat{y}=f(\Phi(x))</annotation></semantics></math>.
When only using polar questions for training the model, we use <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="\Phi_{\operatorname{P}}" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><msub id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml"><mi mathvariant="normal" id="S3.SS2.p1.4.m4.1.1.2" xref="S3.SS2.p1.4.m4.1.1.2.cmml">Φ</mi><mi mathvariant="normal" id="S3.SS2.p1.4.m4.1.1.3" xref="S3.SS2.p1.4.m4.1.1.3.cmml">P</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><apply id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1.2">Φ</ci><ci id="S3.SS2.p1.4.m4.1.1.3.cmml" xref="S3.SS2.p1.4.m4.1.1.3">P</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">\Phi_{\operatorname{P}}</annotation></semantics></math> and <math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="f_{\operatorname{P}}" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><msub id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml"><mi id="S3.SS2.p1.5.m5.1.1.2" xref="S3.SS2.p1.5.m5.1.1.2.cmml">f</mi><mi mathvariant="normal" id="S3.SS2.p1.5.m5.1.1.3" xref="S3.SS2.p1.5.m5.1.1.3.cmml">P</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><apply id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.2">𝑓</ci><ci id="S3.SS2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3">P</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">f_{\operatorname{P}}</annotation></semantics></math> to denote the corresponding modules.
Similarly, <math id="S3.SS2.p1.6.m6.1" class="ltx_Math" alttext="\Phi_{\operatorname{NP}}" display="inline"><semantics id="S3.SS2.p1.6.m6.1a"><msub id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml"><mi mathvariant="normal" id="S3.SS2.p1.6.m6.1.1.2" xref="S3.SS2.p1.6.m6.1.1.2.cmml">Φ</mi><mi id="S3.SS2.p1.6.m6.1.1.3" xref="S3.SS2.p1.6.m6.1.1.3.cmml">NP</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><apply id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.1.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p1.6.m6.1.1.2.cmml" xref="S3.SS2.p1.6.m6.1.1.2">Φ</ci><ci id="S3.SS2.p1.6.m6.1.1.3.cmml" xref="S3.SS2.p1.6.m6.1.1.3">NP</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">\Phi_{\operatorname{NP}}</annotation></semantics></math> and <math id="S3.SS2.p1.7.m7.1" class="ltx_Math" alttext="f_{\operatorname{NP}}" display="inline"><semantics id="S3.SS2.p1.7.m7.1a"><msub id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml"><mi id="S3.SS2.p1.7.m7.1.1.2" xref="S3.SS2.p1.7.m7.1.1.2.cmml">f</mi><mi id="S3.SS2.p1.7.m7.1.1.3" xref="S3.SS2.p1.7.m7.1.1.3.cmml">NP</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.1b"><apply id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.7.m7.1.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.p1.7.m7.1.1.2.cmml" xref="S3.SS2.p1.7.m7.1.1.2">𝑓</ci><ci id="S3.SS2.p1.7.m7.1.1.3.cmml" xref="S3.SS2.p1.7.m7.1.1.3">NP</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.1c">f_{\operatorname{NP}}</annotation></semantics></math> refer to modules that have been trained using non-polar samples only.
For completeness, <math id="S3.SS2.p1.8.m8.1" class="ltx_Math" alttext="\Phi_{\Omega}" display="inline"><semantics id="S3.SS2.p1.8.m8.1a"><msub id="S3.SS2.p1.8.m8.1.1" xref="S3.SS2.p1.8.m8.1.1.cmml"><mi mathvariant="normal" id="S3.SS2.p1.8.m8.1.1.2" xref="S3.SS2.p1.8.m8.1.1.2.cmml">Φ</mi><mi mathvariant="normal" id="S3.SS2.p1.8.m8.1.1.3" xref="S3.SS2.p1.8.m8.1.1.3.cmml">Ω</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m8.1b"><apply id="S3.SS2.p1.8.m8.1.1.cmml" xref="S3.SS2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.8.m8.1.1.1.cmml" xref="S3.SS2.p1.8.m8.1.1">subscript</csymbol><ci id="S3.SS2.p1.8.m8.1.1.2.cmml" xref="S3.SS2.p1.8.m8.1.1.2">Φ</ci><ci id="S3.SS2.p1.8.m8.1.1.3.cmml" xref="S3.SS2.p1.8.m8.1.1.3">Ω</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m8.1c">\Phi_{\Omega}</annotation></semantics></math> and <math id="S3.SS2.p1.9.m9.1" class="ltx_Math" alttext="f_{\Omega}" display="inline"><semantics id="S3.SS2.p1.9.m9.1a"><msub id="S3.SS2.p1.9.m9.1.1" xref="S3.SS2.p1.9.m9.1.1.cmml"><mi id="S3.SS2.p1.9.m9.1.1.2" xref="S3.SS2.p1.9.m9.1.1.2.cmml">f</mi><mi mathvariant="normal" id="S3.SS2.p1.9.m9.1.1.3" xref="S3.SS2.p1.9.m9.1.1.3.cmml">Ω</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.9.m9.1b"><apply id="S3.SS2.p1.9.m9.1.1.cmml" xref="S3.SS2.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.9.m9.1.1.1.cmml" xref="S3.SS2.p1.9.m9.1.1">subscript</csymbol><ci id="S3.SS2.p1.9.m9.1.1.2.cmml" xref="S3.SS2.p1.9.m9.1.1.2">𝑓</ci><ci id="S3.SS2.p1.9.m9.1.1.3.cmml" xref="S3.SS2.p1.9.m9.1.1.3">Ω</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.9.m9.1c">f_{\Omega}</annotation></semantics></math> denote modules trained on both polar and non-polar questions.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2003.11844/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_img_landscape" width="460" height="304" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Overview of the VQA model used throughout this paper. This is an re-implementation from the winning entry of the 2017 VQA challenge. It is composed by two main modules: a textual-visual joint embedding (base VQA model denoted as <math id="S3.F2.3.m1.1" class="ltx_Math" alttext="\Phi_{\Omega}" display="inline"><semantics id="S3.F2.3.m1.1b"><msub id="S3.F2.3.m1.1.1" xref="S3.F2.3.m1.1.1.cmml"><mi mathvariant="normal" id="S3.F2.3.m1.1.1.2" xref="S3.F2.3.m1.1.1.2.cmml">Φ</mi><mi mathvariant="normal" id="S3.F2.3.m1.1.1.3" xref="S3.F2.3.m1.1.1.3.cmml">Ω</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.3.m1.1c"><apply id="S3.F2.3.m1.1.1.cmml" xref="S3.F2.3.m1.1.1"><csymbol cd="ambiguous" id="S3.F2.3.m1.1.1.1.cmml" xref="S3.F2.3.m1.1.1">subscript</csymbol><ci id="S3.F2.3.m1.1.1.2.cmml" xref="S3.F2.3.m1.1.1.2">Φ</ci><ci id="S3.F2.3.m1.1.1.3.cmml" xref="S3.F2.3.m1.1.1.3">Ω</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.3.m1.1d">\Phi_{\Omega}</annotation></semantics></math>) and a shallow 2-layer classifier (denoted as <math id="S3.F2.4.m2.1" class="ltx_Math" alttext="f_{\Omega}" display="inline"><semantics id="S3.F2.4.m2.1b"><msub id="S3.F2.4.m2.1.1" xref="S3.F2.4.m2.1.1.cmml"><mi id="S3.F2.4.m2.1.1.2" xref="S3.F2.4.m2.1.1.2.cmml">f</mi><mi mathvariant="normal" id="S3.F2.4.m2.1.1.3" xref="S3.F2.4.m2.1.1.3.cmml">Ω</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.4.m2.1c"><apply id="S3.F2.4.m2.1.1.cmml" xref="S3.F2.4.m2.1.1"><csymbol cd="ambiguous" id="S3.F2.4.m2.1.1.1.cmml" xref="S3.F2.4.m2.1.1">subscript</csymbol><ci id="S3.F2.4.m2.1.1.2.cmml" xref="S3.F2.4.m2.1.1.2">𝑓</ci><ci id="S3.F2.4.m2.1.1.3.cmml" xref="S3.F2.4.m2.1.1.3">Ω</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.4.m2.1d">f_{\Omega}</annotation></semantics></math>).</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Experiments</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">There are three main experiments in this work, and they can be summarized as follows:</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p"><span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_bold">Baseline:</span> We train the entire model on VQA 2.0 without any additional considerations regarding polar and non-polar questions.
As in the original work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, we make use of samples from VQA 2.0 containing answers that appear at least eight times in the entire dataset.
This yields an answer space of 3129 dimensions, two of which correspond to the classes “<span id="S3.SS3.p2.1.2" class="ltx_text ltx_font_italic">yes</span>” and “<span id="S3.SS3.p2.1.3" class="ltx_text ltx_font_italic">no</span>” (i.e., the polar space).
No additional pre-training from Visual Genome is used to avoid potential effects of biases coming from another dataset.
The number of regions used for the image embedding is fixed at 36.
Our final implementation uses ReLUs instead of the originally proposed GatedTanh, since it saves computation and produces similar results.
The model is trained using Adamax <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> with an initial learning rate of <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="2\times 10^{-3}" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mrow id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mn id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.1.m1.1.1.1" xref="S3.SS3.p2.1.m1.1.1.1.cmml">×</mo><msup id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml"><mn id="S3.SS3.p2.1.m1.1.1.3.2" xref="S3.SS3.p2.1.m1.1.1.3.2.cmml">10</mn><mrow id="S3.SS3.p2.1.m1.1.1.3.3" xref="S3.SS3.p2.1.m1.1.1.3.3.cmml"><mo id="S3.SS3.p2.1.m1.1.1.3.3a" xref="S3.SS3.p2.1.m1.1.1.3.3.cmml">−</mo><mn id="S3.SS3.p2.1.m1.1.1.3.3.2" xref="S3.SS3.p2.1.m1.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><times id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1.1"></times><cn type="integer" id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">2</cn><apply id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S3.SS3.p2.1.m1.1.1.3.2.cmml" xref="S3.SS3.p2.1.m1.1.1.3.2">10</cn><apply id="S3.SS3.p2.1.m1.1.1.3.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3"><minus id="S3.SS3.p2.1.m1.1.1.3.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3"></minus><cn type="integer" id="S3.SS3.p2.1.m1.1.1.3.3.2.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3.2">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">2\times 10^{-3}</annotation></semantics></math> on the full training set, and the standard VQA accuracy is reported for the validation set <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.
We report the VQA accuracy of the baseline w.r.t. three splits of the validation set: 1) using only the polar questions in the validation set, 2) using only the non-polar questions and 3) passing the entire validation set which contains both polar and non-polar questions (see Figure <a href="#S3.F3" title="Figure 3 ‣ III-C Experiments ‣ III Methods ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).
The baseline is used as a reference to quantify the impact of polar and non-polar questions when used together during training (this experiment) or separately (following experiments).</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2003.11844/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_img_landscape" width="461" height="122" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Outline of the baseline experiment: The full VQA model is trained on the full VQA 2.0 training set. Accuracy is reported on the full validation set <math id="S3.F3.4.m1.1" class="ltx_Math" alttext="\Omega" display="inline"><semantics id="S3.F3.4.m1.1b"><mi mathvariant="normal" id="S3.F3.4.m1.1.1" xref="S3.F3.4.m1.1.1.cmml">Ω</mi><annotation-xml encoding="MathML-Content" id="S3.F3.4.m1.1c"><ci id="S3.F3.4.m1.1.1.cmml" xref="S3.F3.4.m1.1.1">Ω</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.4.m1.1d">\Omega</annotation></semantics></math>, on the polar questions in the validation set <math id="S3.F3.5.m2.1" class="ltx_Math" alttext="\operatorname{P}" display="inline"><semantics id="S3.F3.5.m2.1b"><mi mathvariant="normal" id="S3.F3.5.m2.1.1" xref="S3.F3.5.m2.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.F3.5.m2.1c"><ci id="S3.F3.5.m2.1.1.cmml" xref="S3.F3.5.m2.1.1">P</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.5.m2.1d">\operatorname{P}</annotation></semantics></math> and on the non-polar counterparts <math id="S3.F3.6.m3.1" class="ltx_Math" alttext="\operatorname{NP}" display="inline"><semantics id="S3.F3.6.m3.1b"><mi id="S3.F3.6.m3.1.1" xref="S3.F3.6.m3.1.1.cmml">NP</mi><annotation-xml encoding="MathML-Content" id="S3.F3.6.m3.1c"><ci id="S3.F3.6.m3.1.1.cmml" xref="S3.F3.6.m3.1.1">NP</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.6.m3.1d">\operatorname{NP}</annotation></semantics></math>.</figcaption>
</figure>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.5" class="ltx_p"><span id="S3.SS3.p3.5.1" class="ltx_text ltx_font_bold">Unbiased Upper Bound:</span> To get an empirical upper bound of the model, where the issue of over-representation does not play a role, we train two separate versions of the same model from scratch.
First, we train a model only using the polar questions.
Then we train a second model only using the non-polar questions.
We refer to these two models as <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="f_{\operatorname{P}}\circ\Phi_{\operatorname{P}}" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><mrow id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><msub id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2.2" xref="S3.SS3.p3.1.m1.1.1.2.2.cmml">f</mi><mi mathvariant="normal" id="S3.SS3.p3.1.m1.1.1.2.3" xref="S3.SS3.p3.1.m1.1.1.2.3.cmml">P</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p3.1.m1.1.1.1" xref="S3.SS3.p3.1.m1.1.1.1.cmml">∘</mo><msub id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml"><mi mathvariant="normal" id="S3.SS3.p3.1.m1.1.1.3.2" xref="S3.SS3.p3.1.m1.1.1.3.2.cmml">Φ</mi><mi mathvariant="normal" id="S3.SS3.p3.1.m1.1.1.3.3" xref="S3.SS3.p3.1.m1.1.1.3.3.cmml">P</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><compose id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1"></compose><apply id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.2.1.cmml" xref="S3.SS3.p3.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2.2">𝑓</ci><ci id="S3.SS3.p3.1.m1.1.1.2.3.cmml" xref="S3.SS3.p3.1.m1.1.1.2.3">P</ci></apply><apply id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.3.1.cmml" xref="S3.SS3.p3.1.m1.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.3.2.cmml" xref="S3.SS3.p3.1.m1.1.1.3.2">Φ</ci><ci id="S3.SS3.p3.1.m1.1.1.3.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3.3">P</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">f_{\operatorname{P}}\circ\Phi_{\operatorname{P}}</annotation></semantics></math> and <math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="f_{\operatorname{NP}}\circ\Phi_{\operatorname{NP}}" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><mrow id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml"><msub id="S3.SS3.p3.2.m2.1.1.2" xref="S3.SS3.p3.2.m2.1.1.2.cmml"><mi id="S3.SS3.p3.2.m2.1.1.2.2" xref="S3.SS3.p3.2.m2.1.1.2.2.cmml">f</mi><mi id="S3.SS3.p3.2.m2.1.1.2.3" xref="S3.SS3.p3.2.m2.1.1.2.3.cmml">NP</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p3.2.m2.1.1.1" xref="S3.SS3.p3.2.m2.1.1.1.cmml">∘</mo><msub id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml"><mi mathvariant="normal" id="S3.SS3.p3.2.m2.1.1.3.2" xref="S3.SS3.p3.2.m2.1.1.3.2.cmml">Φ</mi><mi id="S3.SS3.p3.2.m2.1.1.3.3" xref="S3.SS3.p3.2.m2.1.1.3.3.cmml">NP</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1"><compose id="S3.SS3.p3.2.m2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1.1"></compose><apply id="S3.SS3.p3.2.m2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.2.1.cmml" xref="S3.SS3.p3.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS3.p3.2.m2.1.1.2.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2.2">𝑓</ci><ci id="S3.SS3.p3.2.m2.1.1.2.3.cmml" xref="S3.SS3.p3.2.m2.1.1.2.3">NP</ci></apply><apply id="S3.SS3.p3.2.m2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.3.1.cmml" xref="S3.SS3.p3.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.2.m2.1.1.3.2.cmml" xref="S3.SS3.p3.2.m2.1.1.3.2">Φ</ci><ci id="S3.SS3.p3.2.m2.1.1.3.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3.3">NP</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">f_{\operatorname{NP}}\circ\Phi_{\operatorname{NP}}</annotation></semantics></math> respectively.
For these two models, their corresponding VQA accuracy is reported (see Figure <a href="#S3.F4" title="Figure 4 ‣ III-C Experiments ‣ III Methods ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>): <math id="S3.SS3.p3.3.m3.1" class="ltx_Math" alttext="f_{\operatorname{P}}\circ\Phi_{\operatorname{P}}" display="inline"><semantics id="S3.SS3.p3.3.m3.1a"><mrow id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><msub id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml"><mi id="S3.SS3.p3.3.m3.1.1.2.2" xref="S3.SS3.p3.3.m3.1.1.2.2.cmml">f</mi><mi mathvariant="normal" id="S3.SS3.p3.3.m3.1.1.2.3" xref="S3.SS3.p3.3.m3.1.1.2.3.cmml">P</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p3.3.m3.1.1.1" xref="S3.SS3.p3.3.m3.1.1.1.cmml">∘</mo><msub id="S3.SS3.p3.3.m3.1.1.3" xref="S3.SS3.p3.3.m3.1.1.3.cmml"><mi mathvariant="normal" id="S3.SS3.p3.3.m3.1.1.3.2" xref="S3.SS3.p3.3.m3.1.1.3.2.cmml">Φ</mi><mi mathvariant="normal" id="S3.SS3.p3.3.m3.1.1.3.3" xref="S3.SS3.p3.3.m3.1.1.3.3.cmml">P</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><compose id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1.1"></compose><apply id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.2.1.cmml" xref="S3.SS3.p3.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS3.p3.3.m3.1.1.2.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2.2">𝑓</ci><ci id="S3.SS3.p3.3.m3.1.1.2.3.cmml" xref="S3.SS3.p3.3.m3.1.1.2.3">P</ci></apply><apply id="S3.SS3.p3.3.m3.1.1.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.3.1.cmml" xref="S3.SS3.p3.3.m3.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.3.m3.1.1.3.2.cmml" xref="S3.SS3.p3.3.m3.1.1.3.2">Φ</ci><ci id="S3.SS3.p3.3.m3.1.1.3.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3.3">P</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">f_{\operatorname{P}}\circ\Phi_{\operatorname{P}}</annotation></semantics></math> is evaluated on the polar questions of the validation set, and <math id="S3.SS3.p3.4.m4.1" class="ltx_Math" alttext="f_{\operatorname{NP}}\circ\Phi_{\operatorname{NP}}" display="inline"><semantics id="S3.SS3.p3.4.m4.1a"><mrow id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml"><msub id="S3.SS3.p3.4.m4.1.1.2" xref="S3.SS3.p3.4.m4.1.1.2.cmml"><mi id="S3.SS3.p3.4.m4.1.1.2.2" xref="S3.SS3.p3.4.m4.1.1.2.2.cmml">f</mi><mi id="S3.SS3.p3.4.m4.1.1.2.3" xref="S3.SS3.p3.4.m4.1.1.2.3.cmml">NP</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p3.4.m4.1.1.1" xref="S3.SS3.p3.4.m4.1.1.1.cmml">∘</mo><msub id="S3.SS3.p3.4.m4.1.1.3" xref="S3.SS3.p3.4.m4.1.1.3.cmml"><mi mathvariant="normal" id="S3.SS3.p3.4.m4.1.1.3.2" xref="S3.SS3.p3.4.m4.1.1.3.2.cmml">Φ</mi><mi id="S3.SS3.p3.4.m4.1.1.3.3" xref="S3.SS3.p3.4.m4.1.1.3.3.cmml">NP</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b"><apply id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1"><compose id="S3.SS3.p3.4.m4.1.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1.1"></compose><apply id="S3.SS3.p3.4.m4.1.1.2.cmml" xref="S3.SS3.p3.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p3.4.m4.1.1.2.1.cmml" xref="S3.SS3.p3.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS3.p3.4.m4.1.1.2.2.cmml" xref="S3.SS3.p3.4.m4.1.1.2.2">𝑓</ci><ci id="S3.SS3.p3.4.m4.1.1.2.3.cmml" xref="S3.SS3.p3.4.m4.1.1.2.3">NP</ci></apply><apply id="S3.SS3.p3.4.m4.1.1.3.cmml" xref="S3.SS3.p3.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.4.m4.1.1.3.1.cmml" xref="S3.SS3.p3.4.m4.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.4.m4.1.1.3.2.cmml" xref="S3.SS3.p3.4.m4.1.1.3.2">Φ</ci><ci id="S3.SS3.p3.4.m4.1.1.3.3.cmml" xref="S3.SS3.p3.4.m4.1.1.3.3">NP</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">f_{\operatorname{NP}}\circ\Phi_{\operatorname{NP}}</annotation></semantics></math> on the non-polar ones.
The purpose of this setup is to compare the capacity of the same VQA model used for the baseline, when dealing only with one kind of question.
By training on polar or non-polar questions only, the network can use <math id="S3.SS3.p3.5.m5.1" class="ltx_Math" alttext="100\,\%" display="inline"><semantics id="S3.SS3.p3.5.m5.1a"><mrow id="S3.SS3.p3.5.m5.1.1" xref="S3.SS3.p3.5.m5.1.1.cmml"><mn id="S3.SS3.p3.5.m5.1.1.2" xref="S3.SS3.p3.5.m5.1.1.2.cmml">100</mn><mo lspace="0.170em" id="S3.SS3.p3.5.m5.1.1.1" xref="S3.SS3.p3.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m5.1b"><apply id="S3.SS3.p3.5.m5.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1"><csymbol cd="latexml" id="S3.SS3.p3.5.m5.1.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1.1">percent</csymbol><cn type="integer" id="S3.SS3.p3.5.m5.1.1.2.cmml" xref="S3.SS3.p3.5.m5.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m5.1c">100\,\%</annotation></semantics></math> of its capacity to extract the necessary semantics without the burden of modeling features to distinguish between polar and non-polar questions.
In other words, any bias caused by the imbalance of polar and non-polar questions is excluded for these two models.
The accuracy for both variants is thereby expected to be higher than the corresponding value for the baseline experiment.
If small or no deviations arise w.r.t. the baseline, then we can conclude that the confounding factors between polar and non-polar questions are not affecting the baseline VQA model negatively.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2003.11844/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_img_landscape" width="461" height="216" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Unbiased Upper Bound experiment: two copies of the same architecture for the baseline is used. One copy is trained only on polar questions and the second copy is trained only on non-polar questions. Accuracy for both is reported independently.</figcaption>
</figure>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.11" class="ltx_p"><span id="S3.SS3.p4.11.1" class="ltx_text ltx_font_bold">Cross-Polarity Evaluation:</span> Independent of the potential confounding factors between polar and non-polar samples, there is still the question on how the distribution of polar features overlap with that of the non-polar ones.
As the feature projections from <math id="S3.SS3.p4.1.m1.1" class="ltx_Math" alttext="\Phi_{\operatorname{P}}" display="inline"><semantics id="S3.SS3.p4.1.m1.1a"><msub id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml"><mi mathvariant="normal" id="S3.SS3.p4.1.m1.1.1.2" xref="S3.SS3.p4.1.m1.1.1.2.cmml">Φ</mi><mi mathvariant="normal" id="S3.SS3.p4.1.m1.1.1.3" xref="S3.SS3.p4.1.m1.1.1.3.cmml">P</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><apply id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p4.1.m1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.1.1.2">Φ</ci><ci id="S3.SS3.p4.1.m1.1.1.3.cmml" xref="S3.SS3.p4.1.m1.1.1.3">P</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">\Phi_{\operatorname{P}}</annotation></semantics></math> and <math id="S3.SS3.p4.2.m2.1" class="ltx_Math" alttext="\Phi_{\operatorname{NP}}" display="inline"><semantics id="S3.SS3.p4.2.m2.1a"><msub id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml"><mi mathvariant="normal" id="S3.SS3.p4.2.m2.1.1.2" xref="S3.SS3.p4.2.m2.1.1.2.cmml">Φ</mi><mi id="S3.SS3.p4.2.m2.1.1.3" xref="S3.SS3.p4.2.m2.1.1.3.cmml">NP</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><apply id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p4.2.m2.1.1.2.cmml" xref="S3.SS3.p4.2.m2.1.1.2">Φ</ci><ci id="S3.SS3.p4.2.m2.1.1.3.cmml" xref="S3.SS3.p4.2.m2.1.1.3">NP</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">\Phi_{\operatorname{NP}}</annotation></semantics></math> share the same dimensional space, an experiment using transfer learning can be performed.
The outline of this experiment is shown in Figure <a href="#S3.F5" title="Figure 5 ‣ III-C Experiments ‣ III Methods ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
First, we use <math id="S3.SS3.p4.3.m3.1" class="ltx_Math" alttext="\Phi_{\operatorname{P}}" display="inline"><semantics id="S3.SS3.p4.3.m3.1a"><msub id="S3.SS3.p4.3.m3.1.1" xref="S3.SS3.p4.3.m3.1.1.cmml"><mi mathvariant="normal" id="S3.SS3.p4.3.m3.1.1.2" xref="S3.SS3.p4.3.m3.1.1.2.cmml">Φ</mi><mi mathvariant="normal" id="S3.SS3.p4.3.m3.1.1.3" xref="S3.SS3.p4.3.m3.1.1.3.cmml">P</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m3.1b"><apply id="S3.SS3.p4.3.m3.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.3.m3.1.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p4.3.m3.1.1.2.cmml" xref="S3.SS3.p4.3.m3.1.1.2">Φ</ci><ci id="S3.SS3.p4.3.m3.1.1.3.cmml" xref="S3.SS3.p4.3.m3.1.1.3">P</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.3.m3.1c">\Phi_{\operatorname{P}}</annotation></semantics></math> and <math id="S3.SS3.p4.4.m4.1" class="ltx_Math" alttext="\Phi_{\operatorname{NP}}" display="inline"><semantics id="S3.SS3.p4.4.m4.1a"><msub id="S3.SS3.p4.4.m4.1.1" xref="S3.SS3.p4.4.m4.1.1.cmml"><mi mathvariant="normal" id="S3.SS3.p4.4.m4.1.1.2" xref="S3.SS3.p4.4.m4.1.1.2.cmml">Φ</mi><mi id="S3.SS3.p4.4.m4.1.1.3" xref="S3.SS3.p4.4.m4.1.1.3.cmml">NP</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.4.m4.1b"><apply id="S3.SS3.p4.4.m4.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.4.m4.1.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p4.4.m4.1.1.2.cmml" xref="S3.SS3.p4.4.m4.1.1.2">Φ</ci><ci id="S3.SS3.p4.4.m4.1.1.3.cmml" xref="S3.SS3.p4.4.m4.1.1.3">NP</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.4.m4.1c">\Phi_{\operatorname{NP}}</annotation></semantics></math> from the previous experiment as fixed pre-trained feature extractors.
Then, we train a new polar classifier <math id="S3.SS3.p4.5.m5.1" class="ltx_Math" alttext="f_{\operatorname{P}}" display="inline"><semantics id="S3.SS3.p4.5.m5.1a"><msub id="S3.SS3.p4.5.m5.1.1" xref="S3.SS3.p4.5.m5.1.1.cmml"><mi id="S3.SS3.p4.5.m5.1.1.2" xref="S3.SS3.p4.5.m5.1.1.2.cmml">f</mi><mi mathvariant="normal" id="S3.SS3.p4.5.m5.1.1.3" xref="S3.SS3.p4.5.m5.1.1.3.cmml">P</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.5.m5.1b"><apply id="S3.SS3.p4.5.m5.1.1.cmml" xref="S3.SS3.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.5.m5.1.1.1.cmml" xref="S3.SS3.p4.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.p4.5.m5.1.1.2.cmml" xref="S3.SS3.p4.5.m5.1.1.2">𝑓</ci><ci id="S3.SS3.p4.5.m5.1.1.3.cmml" xref="S3.SS3.p4.5.m5.1.1.3">P</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.5.m5.1c">f_{\operatorname{P}}</annotation></semantics></math> using features from the fixed pre-trained non-polar module <math id="S3.SS3.p4.6.m6.1" class="ltx_Math" alttext="\Phi_{\operatorname{NP}}" display="inline"><semantics id="S3.SS3.p4.6.m6.1a"><msub id="S3.SS3.p4.6.m6.1.1" xref="S3.SS3.p4.6.m6.1.1.cmml"><mi mathvariant="normal" id="S3.SS3.p4.6.m6.1.1.2" xref="S3.SS3.p4.6.m6.1.1.2.cmml">Φ</mi><mi id="S3.SS3.p4.6.m6.1.1.3" xref="S3.SS3.p4.6.m6.1.1.3.cmml">NP</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.6.m6.1b"><apply id="S3.SS3.p4.6.m6.1.1.cmml" xref="S3.SS3.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.6.m6.1.1.1.cmml" xref="S3.SS3.p4.6.m6.1.1">subscript</csymbol><ci id="S3.SS3.p4.6.m6.1.1.2.cmml" xref="S3.SS3.p4.6.m6.1.1.2">Φ</ci><ci id="S3.SS3.p4.6.m6.1.1.3.cmml" xref="S3.SS3.p4.6.m6.1.1.3">NP</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.6.m6.1c">\Phi_{\operatorname{NP}}</annotation></semantics></math>.
Similarly, we train a new non-polar classifier <math id="S3.SS3.p4.7.m7.1" class="ltx_Math" alttext="f_{\operatorname{NP}}" display="inline"><semantics id="S3.SS3.p4.7.m7.1a"><msub id="S3.SS3.p4.7.m7.1.1" xref="S3.SS3.p4.7.m7.1.1.cmml"><mi id="S3.SS3.p4.7.m7.1.1.2" xref="S3.SS3.p4.7.m7.1.1.2.cmml">f</mi><mi id="S3.SS3.p4.7.m7.1.1.3" xref="S3.SS3.p4.7.m7.1.1.3.cmml">NP</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.7.m7.1b"><apply id="S3.SS3.p4.7.m7.1.1.cmml" xref="S3.SS3.p4.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.7.m7.1.1.1.cmml" xref="S3.SS3.p4.7.m7.1.1">subscript</csymbol><ci id="S3.SS3.p4.7.m7.1.1.2.cmml" xref="S3.SS3.p4.7.m7.1.1.2">𝑓</ci><ci id="S3.SS3.p4.7.m7.1.1.3.cmml" xref="S3.SS3.p4.7.m7.1.1.3">NP</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.7.m7.1c">f_{\operatorname{NP}}</annotation></semantics></math> with features coming from <math id="S3.SS3.p4.8.m8.1" class="ltx_Math" alttext="\Phi_{\operatorname{P}}" display="inline"><semantics id="S3.SS3.p4.8.m8.1a"><msub id="S3.SS3.p4.8.m8.1.1" xref="S3.SS3.p4.8.m8.1.1.cmml"><mi mathvariant="normal" id="S3.SS3.p4.8.m8.1.1.2" xref="S3.SS3.p4.8.m8.1.1.2.cmml">Φ</mi><mi mathvariant="normal" id="S3.SS3.p4.8.m8.1.1.3" xref="S3.SS3.p4.8.m8.1.1.3.cmml">P</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.8.m8.1b"><apply id="S3.SS3.p4.8.m8.1.1.cmml" xref="S3.SS3.p4.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.8.m8.1.1.1.cmml" xref="S3.SS3.p4.8.m8.1.1">subscript</csymbol><ci id="S3.SS3.p4.8.m8.1.1.2.cmml" xref="S3.SS3.p4.8.m8.1.1.2">Φ</ci><ci id="S3.SS3.p4.8.m8.1.1.3.cmml" xref="S3.SS3.p4.8.m8.1.1.3">P</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.8.m8.1c">\Phi_{\operatorname{P}}</annotation></semantics></math>.
In order to be able to compare the results, we use the same architecture for <math id="S3.SS3.p4.9.m9.1" class="ltx_Math" alttext="f_{\operatorname{P}}" display="inline"><semantics id="S3.SS3.p4.9.m9.1a"><msub id="S3.SS3.p4.9.m9.1.1" xref="S3.SS3.p4.9.m9.1.1.cmml"><mi id="S3.SS3.p4.9.m9.1.1.2" xref="S3.SS3.p4.9.m9.1.1.2.cmml">f</mi><mi mathvariant="normal" id="S3.SS3.p4.9.m9.1.1.3" xref="S3.SS3.p4.9.m9.1.1.3.cmml">P</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.9.m9.1b"><apply id="S3.SS3.p4.9.m9.1.1.cmml" xref="S3.SS3.p4.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.9.m9.1.1.1.cmml" xref="S3.SS3.p4.9.m9.1.1">subscript</csymbol><ci id="S3.SS3.p4.9.m9.1.1.2.cmml" xref="S3.SS3.p4.9.m9.1.1.2">𝑓</ci><ci id="S3.SS3.p4.9.m9.1.1.3.cmml" xref="S3.SS3.p4.9.m9.1.1.3">P</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.9.m9.1c">f_{\operatorname{P}}</annotation></semantics></math> and <math id="S3.SS3.p4.10.m10.1" class="ltx_Math" alttext="f_{\operatorname{NP}}" display="inline"><semantics id="S3.SS3.p4.10.m10.1a"><msub id="S3.SS3.p4.10.m10.1.1" xref="S3.SS3.p4.10.m10.1.1.cmml"><mi id="S3.SS3.p4.10.m10.1.1.2" xref="S3.SS3.p4.10.m10.1.1.2.cmml">f</mi><mi id="S3.SS3.p4.10.m10.1.1.3" xref="S3.SS3.p4.10.m10.1.1.3.cmml">NP</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.10.m10.1b"><apply id="S3.SS3.p4.10.m10.1.1.cmml" xref="S3.SS3.p4.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.10.m10.1.1.1.cmml" xref="S3.SS3.p4.10.m10.1.1">subscript</csymbol><ci id="S3.SS3.p4.10.m10.1.1.2.cmml" xref="S3.SS3.p4.10.m10.1.1.2">𝑓</ci><ci id="S3.SS3.p4.10.m10.1.1.3.cmml" xref="S3.SS3.p4.10.m10.1.1.3">NP</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.10.m10.1c">f_{\operatorname{NP}}</annotation></semantics></math> as in the previous unbiased upper bound experiments.
Intuitively, this cross-over experiment helps us measuring how descriptive the feature space of polar questions is, so that non-polar questions can also be answered, and vice versa.
At a semantic level, this is theoretically possible since non-polar questions can be asked using a polar structure.
E.g., the question “<span id="S3.SS3.p4.11.2" class="ltx_text ltx_font_italic">What color are the bird’s tail feathers?</span>” with answer “<span id="S3.SS3.p4.11.3" class="ltx_text ltx_font_italic">white</span>” can be transformed into the polar question “<span id="S3.SS3.p4.11.4" class="ltx_text ltx_font_italic">Are the bird’s tail feathers white?</span>”.
Intuitively, it is expected that the space of non-polar concepts (i.e., the joint visual-text projection trained on the non-polar questions <math id="S3.SS3.p4.11.m11.1" class="ltx_Math" alttext="\Phi_{\operatorname{NP}}" display="inline"><semantics id="S3.SS3.p4.11.m11.1a"><msub id="S3.SS3.p4.11.m11.1.1" xref="S3.SS3.p4.11.m11.1.1.cmml"><mi mathvariant="normal" id="S3.SS3.p4.11.m11.1.1.2" xref="S3.SS3.p4.11.m11.1.1.2.cmml">Φ</mi><mi id="S3.SS3.p4.11.m11.1.1.3" xref="S3.SS3.p4.11.m11.1.1.3.cmml">NP</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.11.m11.1b"><apply id="S3.SS3.p4.11.m11.1.1.cmml" xref="S3.SS3.p4.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.11.m11.1.1.1.cmml" xref="S3.SS3.p4.11.m11.1.1">subscript</csymbol><ci id="S3.SS3.p4.11.m11.1.1.2.cmml" xref="S3.SS3.p4.11.m11.1.1.2">Φ</ci><ci id="S3.SS3.p4.11.m11.1.1.3.cmml" xref="S3.SS3.p4.11.m11.1.1.3">NP</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.11.m11.1c">\Phi_{\operatorname{NP}}</annotation></semantics></math> covering more than 3000 answer classes) represents a rich enough structure that can be condensed and reused to answer polar questions (just 2 answer classes).
However, it is not expected that the set of polar-questions yields a rich enough embedding space covering the wide spectrum of non-polar concepts found in VQA 2.0.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2003.11844/assets/x5.png" id="S3.F5.g1" class="ltx_graphics ltx_img_landscape" width="461" height="124" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Cross-Polarity evaluation:
a) We project polar inputs <math id="S3.F5.5.m1.1" class="ltx_Math" alttext="x_{\operatorname{P}}" display="inline"><semantics id="S3.F5.5.m1.1b"><msub id="S3.F5.5.m1.1.1" xref="S3.F5.5.m1.1.1.cmml"><mi id="S3.F5.5.m1.1.1.2" xref="S3.F5.5.m1.1.1.2.cmml">x</mi><mi mathvariant="normal" id="S3.F5.5.m1.1.1.3" xref="S3.F5.5.m1.1.1.3.cmml">P</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F5.5.m1.1c"><apply id="S3.F5.5.m1.1.1.cmml" xref="S3.F5.5.m1.1.1"><csymbol cd="ambiguous" id="S3.F5.5.m1.1.1.1.cmml" xref="S3.F5.5.m1.1.1">subscript</csymbol><ci id="S3.F5.5.m1.1.1.2.cmml" xref="S3.F5.5.m1.1.1.2">𝑥</ci><ci id="S3.F5.5.m1.1.1.3.cmml" xref="S3.F5.5.m1.1.1.3">P</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F5.5.m1.1d">x_{\operatorname{P}}</annotation></semantics></math> using a pre-trained base network <math id="S3.F5.6.m2.1" class="ltx_Math" alttext="\Phi_{\operatorname{NP}}" display="inline"><semantics id="S3.F5.6.m2.1b"><msub id="S3.F5.6.m2.1.1" xref="S3.F5.6.m2.1.1.cmml"><mi mathvariant="normal" id="S3.F5.6.m2.1.1.2" xref="S3.F5.6.m2.1.1.2.cmml">Φ</mi><mi id="S3.F5.6.m2.1.1.3" xref="S3.F5.6.m2.1.1.3.cmml">NP</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F5.6.m2.1c"><apply id="S3.F5.6.m2.1.1.cmml" xref="S3.F5.6.m2.1.1"><csymbol cd="ambiguous" id="S3.F5.6.m2.1.1.1.cmml" xref="S3.F5.6.m2.1.1">subscript</csymbol><ci id="S3.F5.6.m2.1.1.2.cmml" xref="S3.F5.6.m2.1.1.2">Φ</ci><ci id="S3.F5.6.m2.1.1.3.cmml" xref="S3.F5.6.m2.1.1.3">NP</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F5.6.m2.1d">\Phi_{\operatorname{NP}}</annotation></semantics></math>, which has only seen non-polar samples during its training, into non-polar feature space <math id="S3.F5.7.m3.1" class="ltx_Math" alttext="\Phi_{\operatorname{NP}}(x_{\operatorname{P}})" display="inline"><semantics id="S3.F5.7.m3.1b"><mrow id="S3.F5.7.m3.1.1" xref="S3.F5.7.m3.1.1.cmml"><msub id="S3.F5.7.m3.1.1.3" xref="S3.F5.7.m3.1.1.3.cmml"><mi mathvariant="normal" id="S3.F5.7.m3.1.1.3.2" xref="S3.F5.7.m3.1.1.3.2.cmml">Φ</mi><mi id="S3.F5.7.m3.1.1.3.3" xref="S3.F5.7.m3.1.1.3.3.cmml">NP</mi></msub><mo lspace="0em" rspace="0em" id="S3.F5.7.m3.1.1.2" xref="S3.F5.7.m3.1.1.2.cmml">​</mo><mrow id="S3.F5.7.m3.1.1.1.1" xref="S3.F5.7.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.F5.7.m3.1.1.1.1.2" xref="S3.F5.7.m3.1.1.1.1.1.cmml">(</mo><msub id="S3.F5.7.m3.1.1.1.1.1" xref="S3.F5.7.m3.1.1.1.1.1.cmml"><mi id="S3.F5.7.m3.1.1.1.1.1.2" xref="S3.F5.7.m3.1.1.1.1.1.2.cmml">x</mi><mi mathvariant="normal" id="S3.F5.7.m3.1.1.1.1.1.3" xref="S3.F5.7.m3.1.1.1.1.1.3.cmml">P</mi></msub><mo stretchy="false" id="S3.F5.7.m3.1.1.1.1.3" xref="S3.F5.7.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F5.7.m3.1c"><apply id="S3.F5.7.m3.1.1.cmml" xref="S3.F5.7.m3.1.1"><times id="S3.F5.7.m3.1.1.2.cmml" xref="S3.F5.7.m3.1.1.2"></times><apply id="S3.F5.7.m3.1.1.3.cmml" xref="S3.F5.7.m3.1.1.3"><csymbol cd="ambiguous" id="S3.F5.7.m3.1.1.3.1.cmml" xref="S3.F5.7.m3.1.1.3">subscript</csymbol><ci id="S3.F5.7.m3.1.1.3.2.cmml" xref="S3.F5.7.m3.1.1.3.2">Φ</ci><ci id="S3.F5.7.m3.1.1.3.3.cmml" xref="S3.F5.7.m3.1.1.3.3">NP</ci></apply><apply id="S3.F5.7.m3.1.1.1.1.1.cmml" xref="S3.F5.7.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.F5.7.m3.1.1.1.1.1.1.cmml" xref="S3.F5.7.m3.1.1.1.1">subscript</csymbol><ci id="S3.F5.7.m3.1.1.1.1.1.2.cmml" xref="S3.F5.7.m3.1.1.1.1.1.2">𝑥</ci><ci id="S3.F5.7.m3.1.1.1.1.1.3.cmml" xref="S3.F5.7.m3.1.1.1.1.1.3">P</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F5.7.m3.1d">\Phi_{\operatorname{NP}}(x_{\operatorname{P}})</annotation></semantics></math> and train a shallow polar classifier <math id="S3.F5.8.m4.1" class="ltx_Math" alttext="f_{\operatorname{P}}(\Phi_{\operatorname{NP}}(x_{\operatorname{P}}))" display="inline"><semantics id="S3.F5.8.m4.1b"><mrow id="S3.F5.8.m4.1.1" xref="S3.F5.8.m4.1.1.cmml"><msub id="S3.F5.8.m4.1.1.3" xref="S3.F5.8.m4.1.1.3.cmml"><mi id="S3.F5.8.m4.1.1.3.2" xref="S3.F5.8.m4.1.1.3.2.cmml">f</mi><mi mathvariant="normal" id="S3.F5.8.m4.1.1.3.3" xref="S3.F5.8.m4.1.1.3.3.cmml">P</mi></msub><mo lspace="0em" rspace="0em" id="S3.F5.8.m4.1.1.2" xref="S3.F5.8.m4.1.1.2.cmml">​</mo><mrow id="S3.F5.8.m4.1.1.1.1" xref="S3.F5.8.m4.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.F5.8.m4.1.1.1.1.2" xref="S3.F5.8.m4.1.1.1.1.1.cmml">(</mo><mrow id="S3.F5.8.m4.1.1.1.1.1" xref="S3.F5.8.m4.1.1.1.1.1.cmml"><msub id="S3.F5.8.m4.1.1.1.1.1.3" xref="S3.F5.8.m4.1.1.1.1.1.3.cmml"><mi mathvariant="normal" id="S3.F5.8.m4.1.1.1.1.1.3.2" xref="S3.F5.8.m4.1.1.1.1.1.3.2.cmml">Φ</mi><mi id="S3.F5.8.m4.1.1.1.1.1.3.3" xref="S3.F5.8.m4.1.1.1.1.1.3.3.cmml">NP</mi></msub><mo lspace="0em" rspace="0em" id="S3.F5.8.m4.1.1.1.1.1.2" xref="S3.F5.8.m4.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.F5.8.m4.1.1.1.1.1.1.1" xref="S3.F5.8.m4.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.F5.8.m4.1.1.1.1.1.1.1.2" xref="S3.F5.8.m4.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.F5.8.m4.1.1.1.1.1.1.1.1" xref="S3.F5.8.m4.1.1.1.1.1.1.1.1.cmml"><mi id="S3.F5.8.m4.1.1.1.1.1.1.1.1.2" xref="S3.F5.8.m4.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi mathvariant="normal" id="S3.F5.8.m4.1.1.1.1.1.1.1.1.3" xref="S3.F5.8.m4.1.1.1.1.1.1.1.1.3.cmml">P</mi></msub><mo stretchy="false" id="S3.F5.8.m4.1.1.1.1.1.1.1.3" xref="S3.F5.8.m4.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.F5.8.m4.1.1.1.1.3" xref="S3.F5.8.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F5.8.m4.1c"><apply id="S3.F5.8.m4.1.1.cmml" xref="S3.F5.8.m4.1.1"><times id="S3.F5.8.m4.1.1.2.cmml" xref="S3.F5.8.m4.1.1.2"></times><apply id="S3.F5.8.m4.1.1.3.cmml" xref="S3.F5.8.m4.1.1.3"><csymbol cd="ambiguous" id="S3.F5.8.m4.1.1.3.1.cmml" xref="S3.F5.8.m4.1.1.3">subscript</csymbol><ci id="S3.F5.8.m4.1.1.3.2.cmml" xref="S3.F5.8.m4.1.1.3.2">𝑓</ci><ci id="S3.F5.8.m4.1.1.3.3.cmml" xref="S3.F5.8.m4.1.1.3.3">P</ci></apply><apply id="S3.F5.8.m4.1.1.1.1.1.cmml" xref="S3.F5.8.m4.1.1.1.1"><times id="S3.F5.8.m4.1.1.1.1.1.2.cmml" xref="S3.F5.8.m4.1.1.1.1.1.2"></times><apply id="S3.F5.8.m4.1.1.1.1.1.3.cmml" xref="S3.F5.8.m4.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.F5.8.m4.1.1.1.1.1.3.1.cmml" xref="S3.F5.8.m4.1.1.1.1.1.3">subscript</csymbol><ci id="S3.F5.8.m4.1.1.1.1.1.3.2.cmml" xref="S3.F5.8.m4.1.1.1.1.1.3.2">Φ</ci><ci id="S3.F5.8.m4.1.1.1.1.1.3.3.cmml" xref="S3.F5.8.m4.1.1.1.1.1.3.3">NP</ci></apply><apply id="S3.F5.8.m4.1.1.1.1.1.1.1.1.cmml" xref="S3.F5.8.m4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.F5.8.m4.1.1.1.1.1.1.1.1.1.cmml" xref="S3.F5.8.m4.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.F5.8.m4.1.1.1.1.1.1.1.1.2.cmml" xref="S3.F5.8.m4.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.F5.8.m4.1.1.1.1.1.1.1.1.3.cmml" xref="S3.F5.8.m4.1.1.1.1.1.1.1.1.3">P</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F5.8.m4.1d">f_{\operatorname{P}}(\Phi_{\operatorname{NP}}(x_{\operatorname{P}}))</annotation></semantics></math> on this representation.
b) Vice-versa.
Intuitively, the experiment measures the extent by which non-polar questions can be answered based on features extracted from a polar space and vice versa.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Results</span>
</h2>

<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Summary of experimental results. The second column indicates the data used to train each of the VQA modules <math id="S4.T1.4.m1.1" class="ltx_Math" alttext="\Phi" display="inline"><semantics id="S4.T1.4.m1.1b"><mi mathvariant="normal" id="S4.T1.4.m1.1.1" xref="S4.T1.4.m1.1.1.cmml">Φ</mi><annotation-xml encoding="MathML-Content" id="S4.T1.4.m1.1c"><ci id="S4.T1.4.m1.1.1.cmml" xref="S4.T1.4.m1.1.1">Φ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.m1.1d">\Phi</annotation></semantics></math> and <math id="S4.T1.5.m2.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.T1.5.m2.1b"><mi id="S4.T1.5.m2.1.1" xref="S4.T1.5.m2.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.T1.5.m2.1c"><ci id="S4.T1.5.m2.1.1.cmml" xref="S4.T1.5.m2.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.m2.1d">f</annotation></semantics></math>. The column “<span id="S4.T1.32.1" class="ltx_text ltx_font_italic">Input</span>” indicates the data used during evaluation of the ensemble <math id="S4.T1.6.m3.2" class="ltx_Math" alttext="f(\Phi(x))" display="inline"><semantics id="S4.T1.6.m3.2b"><mrow id="S4.T1.6.m3.2.2" xref="S4.T1.6.m3.2.2.cmml"><mi id="S4.T1.6.m3.2.2.3" xref="S4.T1.6.m3.2.2.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.T1.6.m3.2.2.2" xref="S4.T1.6.m3.2.2.2.cmml">​</mo><mrow id="S4.T1.6.m3.2.2.1.1" xref="S4.T1.6.m3.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.T1.6.m3.2.2.1.1.2" xref="S4.T1.6.m3.2.2.1.1.1.cmml">(</mo><mrow id="S4.T1.6.m3.2.2.1.1.1" xref="S4.T1.6.m3.2.2.1.1.1.cmml"><mi mathvariant="normal" id="S4.T1.6.m3.2.2.1.1.1.2" xref="S4.T1.6.m3.2.2.1.1.1.2.cmml">Φ</mi><mo lspace="0em" rspace="0em" id="S4.T1.6.m3.2.2.1.1.1.1" xref="S4.T1.6.m3.2.2.1.1.1.1.cmml">​</mo><mrow id="S4.T1.6.m3.2.2.1.1.1.3.2" xref="S4.T1.6.m3.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.T1.6.m3.2.2.1.1.1.3.2.1" xref="S4.T1.6.m3.2.2.1.1.1.cmml">(</mo><mi id="S4.T1.6.m3.1.1" xref="S4.T1.6.m3.1.1.cmml">x</mi><mo stretchy="false" id="S4.T1.6.m3.2.2.1.1.1.3.2.2" xref="S4.T1.6.m3.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.T1.6.m3.2.2.1.1.3" xref="S4.T1.6.m3.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.6.m3.2c"><apply id="S4.T1.6.m3.2.2.cmml" xref="S4.T1.6.m3.2.2"><times id="S4.T1.6.m3.2.2.2.cmml" xref="S4.T1.6.m3.2.2.2"></times><ci id="S4.T1.6.m3.2.2.3.cmml" xref="S4.T1.6.m3.2.2.3">𝑓</ci><apply id="S4.T1.6.m3.2.2.1.1.1.cmml" xref="S4.T1.6.m3.2.2.1.1"><times id="S4.T1.6.m3.2.2.1.1.1.1.cmml" xref="S4.T1.6.m3.2.2.1.1.1.1"></times><ci id="S4.T1.6.m3.2.2.1.1.1.2.cmml" xref="S4.T1.6.m3.2.2.1.1.1.2">Φ</ci><ci id="S4.T1.6.m3.1.1.cmml" xref="S4.T1.6.m3.1.1">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.m3.2d">f(\Phi(x))</annotation></semantics></math>, and the column “<span id="S4.T1.33.2" class="ltx_text ltx_font_italic">Accuracy</span>” reports the corresponding single-model VQA accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> from the validation set.</figcaption>
<table id="S4.T1.29" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.29.24.1" class="ltx_tr">
<td id="S4.T1.29.24.1.1" class="ltx_td ltx_align_left ltx_border_tt">Task</td>
<td id="S4.T1.29.24.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Model</td>
<td id="S4.T1.29.24.1.3" class="ltx_td ltx_align_left ltx_border_tt">Input</td>
<td id="S4.T1.29.24.1.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt">Accuracy</td>
</tr>
<tr id="S4.T1.9.3" class="ltx_tr">
<td id="S4.T1.9.3.4" class="ltx_td"></td>
<td id="S4.T1.7.1.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T1.7.1.1.m1.1" class="ltx_Math" alttext="\Phi" display="inline"><semantics id="S4.T1.7.1.1.m1.1a"><mi mathvariant="normal" id="S4.T1.7.1.1.m1.1.1" xref="S4.T1.7.1.1.m1.1.1.cmml">Φ</mi><annotation-xml encoding="MathML-Content" id="S4.T1.7.1.1.m1.1b"><ci id="S4.T1.7.1.1.m1.1.1.cmml" xref="S4.T1.7.1.1.m1.1.1">Φ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.1.1.m1.1c">\Phi</annotation></semantics></math></td>
<td id="S4.T1.8.2.2" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T1.8.2.2.m1.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.T1.8.2.2.m1.1a"><mi id="S4.T1.8.2.2.m1.1.1" xref="S4.T1.8.2.2.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.T1.8.2.2.m1.1b"><ci id="S4.T1.8.2.2.m1.1.1.cmml" xref="S4.T1.8.2.2.m1.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.2.2.m1.1c">f</annotation></semantics></math></td>
<td id="S4.T1.9.3.3" class="ltx_td ltx_align_left"><math id="S4.T1.9.3.3.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S4.T1.9.3.3.m1.1a"><mi id="S4.T1.9.3.3.m1.1.1" xref="S4.T1.9.3.3.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.T1.9.3.3.m1.1b"><ci id="S4.T1.9.3.3.m1.1.1.cmml" xref="S4.T1.9.3.3.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.3.3.m1.1c">x</annotation></semantics></math></td>
<td id="S4.T1.9.3.5" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T1.10.4" class="ltx_tr">
<td id="S4.T1.10.4.2" class="ltx_td ltx_align_left ltx_border_t">Random Choice</td>
<td id="S4.T1.10.4.3" class="ltx_td ltx_align_left ltx_border_t">–</td>
<td id="S4.T1.10.4.4" class="ltx_td ltx_align_left ltx_border_t">–</td>
<td id="S4.T1.10.4.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T1.10.4.1.m1.1" class="ltx_Math" alttext="\operatorname{P}" display="inline"><semantics id="S4.T1.10.4.1.m1.1a"><mi mathvariant="normal" id="S4.T1.10.4.1.m1.1.1" xref="S4.T1.10.4.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.T1.10.4.1.m1.1b"><ci id="S4.T1.10.4.1.m1.1.1.cmml" xref="S4.T1.10.4.1.m1.1.1">P</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.4.1.m1.1c">\operatorname{P}</annotation></semantics></math></td>
<td id="S4.T1.10.4.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">0.5</td>
</tr>
<tr id="S4.T1.12.6" class="ltx_tr">
<td id="S4.T1.12.6.3" class="ltx_td"></td>
<td id="S4.T1.12.6.4" class="ltx_td ltx_align_left">–</td>
<td id="S4.T1.12.6.5" class="ltx_td ltx_align_left">–</td>
<td id="S4.T1.11.5.1" class="ltx_td ltx_align_left"><math id="S4.T1.11.5.1.m1.1" class="ltx_Math" alttext="\operatorname{NP}" display="inline"><semantics id="S4.T1.11.5.1.m1.1a"><mi id="S4.T1.11.5.1.m1.1.1" xref="S4.T1.11.5.1.m1.1.1.cmml">NP</mi><annotation-xml encoding="MathML-Content" id="S4.T1.11.5.1.m1.1b"><ci id="S4.T1.11.5.1.m1.1.1.cmml" xref="S4.T1.11.5.1.m1.1.1">NP</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.5.1.m1.1c">\operatorname{NP}</annotation></semantics></math></td>
<td id="S4.T1.12.6.2" class="ltx_td ltx_nopad_r ltx_align_left"><math id="S4.T1.12.6.2.m1.1" class="ltx_Math" alttext="0.0003" display="inline"><semantics id="S4.T1.12.6.2.m1.1a"><mn id="S4.T1.12.6.2.m1.1.1" xref="S4.T1.12.6.2.m1.1.1.cmml">0.0003</mn><annotation-xml encoding="MathML-Content" id="S4.T1.12.6.2.m1.1b"><cn type="float" id="S4.T1.12.6.2.m1.1.1.cmml" xref="S4.T1.12.6.2.m1.1.1">0.0003</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.12.6.2.m1.1c">0.0003</annotation></semantics></math></td>
</tr>
<tr id="S4.T1.15.9" class="ltx_tr">
<td id="S4.T1.15.9.4" class="ltx_td ltx_border_t"></td>
<td id="S4.T1.13.7.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="3"><span id="S4.T1.13.7.1.1" class="ltx_text"><math id="S4.T1.13.7.1.1.m1.1" class="ltx_Math" alttext="\Omega" display="inline"><semantics id="S4.T1.13.7.1.1.m1.1a"><mi mathvariant="normal" id="S4.T1.13.7.1.1.m1.1.1" xref="S4.T1.13.7.1.1.m1.1.1.cmml">Ω</mi><annotation-xml encoding="MathML-Content" id="S4.T1.13.7.1.1.m1.1b"><ci id="S4.T1.13.7.1.1.m1.1.1.cmml" xref="S4.T1.13.7.1.1.m1.1.1">Ω</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.13.7.1.1.m1.1c">\Omega</annotation></semantics></math></span></td>
<td id="S4.T1.14.8.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="3"><span id="S4.T1.14.8.2.1" class="ltx_text"><math id="S4.T1.14.8.2.1.m1.1" class="ltx_Math" alttext="\Omega" display="inline"><semantics id="S4.T1.14.8.2.1.m1.1a"><mi mathvariant="normal" id="S4.T1.14.8.2.1.m1.1.1" xref="S4.T1.14.8.2.1.m1.1.1.cmml">Ω</mi><annotation-xml encoding="MathML-Content" id="S4.T1.14.8.2.1.m1.1b"><ci id="S4.T1.14.8.2.1.m1.1.1.cmml" xref="S4.T1.14.8.2.1.m1.1.1">Ω</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.14.8.2.1.m1.1c">\Omega</annotation></semantics></math></span></td>
<td id="S4.T1.15.9.3" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T1.15.9.3.m1.1" class="ltx_Math" alttext="\Omega" display="inline"><semantics id="S4.T1.15.9.3.m1.1a"><mi mathvariant="normal" id="S4.T1.15.9.3.m1.1.1" xref="S4.T1.15.9.3.m1.1.1.cmml">Ω</mi><annotation-xml encoding="MathML-Content" id="S4.T1.15.9.3.m1.1b"><ci id="S4.T1.15.9.3.m1.1.1.cmml" xref="S4.T1.15.9.3.m1.1.1">Ω</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.15.9.3.m1.1c">\Omega</annotation></semantics></math></td>
<td id="S4.T1.15.9.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">0.624</td>
</tr>
<tr id="S4.T1.16.10" class="ltx_tr">
<td id="S4.T1.16.10.2" class="ltx_td ltx_align_left">Baseline</td>
<td id="S4.T1.16.10.1" class="ltx_td ltx_align_left"><math id="S4.T1.16.10.1.m1.1" class="ltx_Math" alttext="\operatorname{P}" display="inline"><semantics id="S4.T1.16.10.1.m1.1a"><mi mathvariant="normal" id="S4.T1.16.10.1.m1.1.1" xref="S4.T1.16.10.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.T1.16.10.1.m1.1b"><ci id="S4.T1.16.10.1.m1.1.1.cmml" xref="S4.T1.16.10.1.m1.1.1">P</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.16.10.1.m1.1c">\operatorname{P}</annotation></semantics></math></td>
<td id="S4.T1.16.10.3" class="ltx_td ltx_nopad_r ltx_align_left">0.804</td>
</tr>
<tr id="S4.T1.17.11" class="ltx_tr">
<td id="S4.T1.17.11.2" class="ltx_td"></td>
<td id="S4.T1.17.11.1" class="ltx_td ltx_align_left"><math id="S4.T1.17.11.1.m1.1" class="ltx_Math" alttext="\operatorname{NP}" display="inline"><semantics id="S4.T1.17.11.1.m1.1a"><mi id="S4.T1.17.11.1.m1.1.1" xref="S4.T1.17.11.1.m1.1.1.cmml">NP</mi><annotation-xml encoding="MathML-Content" id="S4.T1.17.11.1.m1.1b"><ci id="S4.T1.17.11.1.m1.1.1.cmml" xref="S4.T1.17.11.1.m1.1.1">NP</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.17.11.1.m1.1c">\operatorname{NP}</annotation></semantics></math></td>
<td id="S4.T1.17.11.3" class="ltx_td ltx_nopad_r ltx_align_left">0.514</td>
</tr>
<tr id="S4.T1.20.14" class="ltx_tr">
<td id="S4.T1.20.14.4" class="ltx_td ltx_align_left ltx_border_t">Upper bound</td>
<td id="S4.T1.18.12.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T1.18.12.1.m1.1" class="ltx_Math" alttext="\operatorname{P}" display="inline"><semantics id="S4.T1.18.12.1.m1.1a"><mi mathvariant="normal" id="S4.T1.18.12.1.m1.1.1" xref="S4.T1.18.12.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.T1.18.12.1.m1.1b"><ci id="S4.T1.18.12.1.m1.1.1.cmml" xref="S4.T1.18.12.1.m1.1.1">P</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.18.12.1.m1.1c">\operatorname{P}</annotation></semantics></math></td>
<td id="S4.T1.19.13.2" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T1.19.13.2.m1.1" class="ltx_Math" alttext="\operatorname{P}" display="inline"><semantics id="S4.T1.19.13.2.m1.1a"><mi mathvariant="normal" id="S4.T1.19.13.2.m1.1.1" xref="S4.T1.19.13.2.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.T1.19.13.2.m1.1b"><ci id="S4.T1.19.13.2.m1.1.1.cmml" xref="S4.T1.19.13.2.m1.1.1">P</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.19.13.2.m1.1c">\operatorname{P}</annotation></semantics></math></td>
<td id="S4.T1.20.14.3" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T1.20.14.3.m1.1" class="ltx_Math" alttext="\operatorname{P}" display="inline"><semantics id="S4.T1.20.14.3.m1.1a"><mi mathvariant="normal" id="S4.T1.20.14.3.m1.1.1" xref="S4.T1.20.14.3.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.T1.20.14.3.m1.1b"><ci id="S4.T1.20.14.3.m1.1.1.cmml" xref="S4.T1.20.14.3.m1.1.1">P</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.20.14.3.m1.1c">\operatorname{P}</annotation></semantics></math></td>
<td id="S4.T1.20.14.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">0.796</td>
</tr>
<tr id="S4.T1.23.17" class="ltx_tr">
<td id="S4.T1.23.17.4" class="ltx_td"></td>
<td id="S4.T1.21.15.1" class="ltx_td ltx_align_left"><math id="S4.T1.21.15.1.m1.1" class="ltx_Math" alttext="\operatorname{NP}" display="inline"><semantics id="S4.T1.21.15.1.m1.1a"><mi id="S4.T1.21.15.1.m1.1.1" xref="S4.T1.21.15.1.m1.1.1.cmml">NP</mi><annotation-xml encoding="MathML-Content" id="S4.T1.21.15.1.m1.1b"><ci id="S4.T1.21.15.1.m1.1.1.cmml" xref="S4.T1.21.15.1.m1.1.1">NP</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.21.15.1.m1.1c">\operatorname{NP}</annotation></semantics></math></td>
<td id="S4.T1.22.16.2" class="ltx_td ltx_align_left"><math id="S4.T1.22.16.2.m1.1" class="ltx_Math" alttext="\operatorname{NP}" display="inline"><semantics id="S4.T1.22.16.2.m1.1a"><mi id="S4.T1.22.16.2.m1.1.1" xref="S4.T1.22.16.2.m1.1.1.cmml">NP</mi><annotation-xml encoding="MathML-Content" id="S4.T1.22.16.2.m1.1b"><ci id="S4.T1.22.16.2.m1.1.1.cmml" xref="S4.T1.22.16.2.m1.1.1">NP</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.22.16.2.m1.1c">\operatorname{NP}</annotation></semantics></math></td>
<td id="S4.T1.23.17.3" class="ltx_td ltx_align_left"><math id="S4.T1.23.17.3.m1.1" class="ltx_Math" alttext="\operatorname{NP}" display="inline"><semantics id="S4.T1.23.17.3.m1.1a"><mi id="S4.T1.23.17.3.m1.1.1" xref="S4.T1.23.17.3.m1.1.1.cmml">NP</mi><annotation-xml encoding="MathML-Content" id="S4.T1.23.17.3.m1.1b"><ci id="S4.T1.23.17.3.m1.1.1.cmml" xref="S4.T1.23.17.3.m1.1.1">NP</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.23.17.3.m1.1c">\operatorname{NP}</annotation></semantics></math></td>
<td id="S4.T1.23.17.5" class="ltx_td ltx_nopad_r ltx_align_left">0.516</td>
</tr>
<tr id="S4.T1.26.20" class="ltx_tr">
<td id="S4.T1.26.20.4" class="ltx_td ltx_align_left ltx_border_t">Cross-Polarity</td>
<td id="S4.T1.24.18.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T1.24.18.1.m1.1" class="ltx_Math" alttext="\operatorname{NP}" display="inline"><semantics id="S4.T1.24.18.1.m1.1a"><mi id="S4.T1.24.18.1.m1.1.1" xref="S4.T1.24.18.1.m1.1.1.cmml">NP</mi><annotation-xml encoding="MathML-Content" id="S4.T1.24.18.1.m1.1b"><ci id="S4.T1.24.18.1.m1.1.1.cmml" xref="S4.T1.24.18.1.m1.1.1">NP</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.24.18.1.m1.1c">\operatorname{NP}</annotation></semantics></math></td>
<td id="S4.T1.25.19.2" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T1.25.19.2.m1.1" class="ltx_Math" alttext="\operatorname{P}" display="inline"><semantics id="S4.T1.25.19.2.m1.1a"><mi mathvariant="normal" id="S4.T1.25.19.2.m1.1.1" xref="S4.T1.25.19.2.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.T1.25.19.2.m1.1b"><ci id="S4.T1.25.19.2.m1.1.1.cmml" xref="S4.T1.25.19.2.m1.1.1">P</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.25.19.2.m1.1c">\operatorname{P}</annotation></semantics></math></td>
<td id="S4.T1.26.20.3" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T1.26.20.3.m1.1" class="ltx_Math" alttext="\operatorname{P}" display="inline"><semantics id="S4.T1.26.20.3.m1.1a"><mi mathvariant="normal" id="S4.T1.26.20.3.m1.1.1" xref="S4.T1.26.20.3.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.T1.26.20.3.m1.1b"><ci id="S4.T1.26.20.3.m1.1.1.cmml" xref="S4.T1.26.20.3.m1.1.1">P</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.26.20.3.m1.1c">\operatorname{P}</annotation></semantics></math></td>
<td id="S4.T1.26.20.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">0.758</td>
</tr>
<tr id="S4.T1.29.23" class="ltx_tr">
<td id="S4.T1.29.23.4" class="ltx_td ltx_border_bb"></td>
<td id="S4.T1.27.21.1" class="ltx_td ltx_align_left ltx_border_bb"><math id="S4.T1.27.21.1.m1.1" class="ltx_Math" alttext="\operatorname{P}" display="inline"><semantics id="S4.T1.27.21.1.m1.1a"><mi mathvariant="normal" id="S4.T1.27.21.1.m1.1.1" xref="S4.T1.27.21.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.T1.27.21.1.m1.1b"><ci id="S4.T1.27.21.1.m1.1.1.cmml" xref="S4.T1.27.21.1.m1.1.1">P</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.27.21.1.m1.1c">\operatorname{P}</annotation></semantics></math></td>
<td id="S4.T1.28.22.2" class="ltx_td ltx_align_left ltx_border_bb"><math id="S4.T1.28.22.2.m1.1" class="ltx_Math" alttext="\operatorname{NP}" display="inline"><semantics id="S4.T1.28.22.2.m1.1a"><mi id="S4.T1.28.22.2.m1.1.1" xref="S4.T1.28.22.2.m1.1.1.cmml">NP</mi><annotation-xml encoding="MathML-Content" id="S4.T1.28.22.2.m1.1b"><ci id="S4.T1.28.22.2.m1.1.1.cmml" xref="S4.T1.28.22.2.m1.1.1">NP</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.28.22.2.m1.1c">\operatorname{NP}</annotation></semantics></math></td>
<td id="S4.T1.29.23.3" class="ltx_td ltx_align_left ltx_border_bb"><math id="S4.T1.29.23.3.m1.1" class="ltx_Math" alttext="\operatorname{NP}" display="inline"><semantics id="S4.T1.29.23.3.m1.1a"><mi id="S4.T1.29.23.3.m1.1.1" xref="S4.T1.29.23.3.m1.1.1.cmml">NP</mi><annotation-xml encoding="MathML-Content" id="S4.T1.29.23.3.m1.1b"><ci id="S4.T1.29.23.3.m1.1.1.cmml" xref="S4.T1.29.23.3.m1.1.1">NP</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.29.23.3.m1.1c">\operatorname{NP}</annotation></semantics></math></td>
<td id="S4.T1.29.23.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">0.287</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we report the results from experiments described in Section <a href="#S3" title="III Methods ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.7" class="ltx_p">Table <a href="#S4.T1" title="TABLE I ‣ IV Results ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> gives an aggregated overview of the main experimental results from all three proposed experiments.
The columns show, from left to right, the name of the experiment, the subset (<math id="S4.p2.1.m1.1" class="ltx_Math" alttext="\operatorname{P}" display="inline"><semantics id="S4.p2.1.m1.1a"><mi mathvariant="normal" id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><ci id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">P</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">\operatorname{P}</annotation></semantics></math>: Polar; <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="\operatorname{NP}" display="inline"><semantics id="S4.p2.2.m2.1a"><mi id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml">NP</mi><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><ci id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1">NP</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">\operatorname{NP}</annotation></semantics></math>: Non-polar; <math id="S4.p2.3.m3.1" class="ltx_Math" alttext="\Omega" display="inline"><semantics id="S4.p2.3.m3.1a"><mi mathvariant="normal" id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml">Ω</mi><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><ci id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1">Ω</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">\Omega</annotation></semantics></math>: All) of the set of samples used for training the corresponding module of the whole VQA ensemble (<math id="S4.p2.4.m4.1" class="ltx_Math" alttext="\Phi" display="inline"><semantics id="S4.p2.4.m4.1a"><mi mathvariant="normal" id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml">Φ</mi><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.1b"><ci id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1">Φ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.1c">\Phi</annotation></semantics></math> or <math id="S4.p2.5.m5.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.p2.5.m5.1a"><mi id="S4.p2.5.m5.1.1" xref="S4.p2.5.m5.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.p2.5.m5.1b"><ci id="S4.p2.5.m5.1.1.cmml" xref="S4.p2.5.m5.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.5.m5.1c">f</annotation></semantics></math>), the subset of the validation set used for evaluation, and the resulting VQA accuracy.
For the cross-polarity experiments, <math id="S4.p2.6.m6.1" class="ltx_Math" alttext="\Phi" display="inline"><semantics id="S4.p2.6.m6.1a"><mi mathvariant="normal" id="S4.p2.6.m6.1.1" xref="S4.p2.6.m6.1.1.cmml">Φ</mi><annotation-xml encoding="MathML-Content" id="S4.p2.6.m6.1b"><ci id="S4.p2.6.m6.1.1.cmml" xref="S4.p2.6.m6.1.1">Φ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.6.m6.1c">\Phi</annotation></semantics></math> is assumed to be pre-trained and fixed, and only the corresponding <math id="S4.p2.7.m7.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.p2.7.m7.1a"><mi id="S4.p2.7.m7.1.1" xref="S4.p2.7.m7.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.p2.7.m7.1b"><ci id="S4.p2.7.m7.1.1.cmml" xref="S4.p2.7.m7.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.7.m7.1c">f</annotation></semantics></math> has been trained from scratch.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">We observe that the baseline experiment reaches an accuracy that is within one percentage point of the one reported by the original authors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.
The decisions to not involve another dataset for pre-training (e.g., the Visual Genome as in the original work) naturally affects the overall accuracy, but allows the results presented here to reflect more closely the behavior of the polar and non-polar disparity, while ruling out other potential sources of bias.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.2" class="ltx_p">For the characterization of the upper bound, we see that the reached accuracy falls almost exactly within the range of the baseline.
Upper bound results show an increase of <math id="S4.p4.1.m1.1" class="ltx_Math" alttext="0.2\,pp" display="inline"><semantics id="S4.p4.1.m1.1a"><mrow id="S4.p4.1.m1.1.1" xref="S4.p4.1.m1.1.1.cmml"><mn id="S4.p4.1.m1.1.1.2" xref="S4.p4.1.m1.1.1.2.cmml">0.2</mn><mo lspace="0.170em" rspace="0em" id="S4.p4.1.m1.1.1.1" xref="S4.p4.1.m1.1.1.1.cmml">​</mo><mi id="S4.p4.1.m1.1.1.3" xref="S4.p4.1.m1.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.p4.1.m1.1.1.1a" xref="S4.p4.1.m1.1.1.1.cmml">​</mo><mi id="S4.p4.1.m1.1.1.4" xref="S4.p4.1.m1.1.1.4.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><apply id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1"><times id="S4.p4.1.m1.1.1.1.cmml" xref="S4.p4.1.m1.1.1.1"></times><cn type="float" id="S4.p4.1.m1.1.1.2.cmml" xref="S4.p4.1.m1.1.1.2">0.2</cn><ci id="S4.p4.1.m1.1.1.3.cmml" xref="S4.p4.1.m1.1.1.3">𝑝</ci><ci id="S4.p4.1.m1.1.1.4.cmml" xref="S4.p4.1.m1.1.1.4">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">0.2\,pp</annotation></semantics></math> for a system trained on non-polar questions while training with polar questions decreases accuracy by <math id="S4.p4.2.m2.1" class="ltx_Math" alttext="0.8\,pp" display="inline"><semantics id="S4.p4.2.m2.1a"><mrow id="S4.p4.2.m2.1.1" xref="S4.p4.2.m2.1.1.cmml"><mn id="S4.p4.2.m2.1.1.2" xref="S4.p4.2.m2.1.1.2.cmml">0.8</mn><mo lspace="0.170em" rspace="0em" id="S4.p4.2.m2.1.1.1" xref="S4.p4.2.m2.1.1.1.cmml">​</mo><mi id="S4.p4.2.m2.1.1.3" xref="S4.p4.2.m2.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.p4.2.m2.1.1.1a" xref="S4.p4.2.m2.1.1.1.cmml">​</mo><mi id="S4.p4.2.m2.1.1.4" xref="S4.p4.2.m2.1.1.4.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.2.m2.1b"><apply id="S4.p4.2.m2.1.1.cmml" xref="S4.p4.2.m2.1.1"><times id="S4.p4.2.m2.1.1.1.cmml" xref="S4.p4.2.m2.1.1.1"></times><cn type="float" id="S4.p4.2.m2.1.1.2.cmml" xref="S4.p4.2.m2.1.1.2">0.8</cn><ci id="S4.p4.2.m2.1.1.3.cmml" xref="S4.p4.2.m2.1.1.3">𝑝</ci><ci id="S4.p4.2.m2.1.1.4.cmml" xref="S4.p4.2.m2.1.1.4">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.2.m2.1c">0.8\,pp</annotation></semantics></math>.
These negligible fluctuations between the upper bound and the baseline strongly suggest that no confounding factors exist between polar and non-polar samples when trained jointly.
In fact, we see that polar questions rarely get confused with any non-polar alternative (Table <a href="#S4.T2" title="TABLE II ‣ IV Results ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>).
Similarly, non-polar questions are not frequently mistaken for any of the two polar answers.
For further in-depth analysis, please refer to the discussion in Section <a href="#S5" title="V Discussion ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a>.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Confusion matrix of predictions for the baseline model, grouped by polarity (all numbers in percent). Polar predictions are rarely confused by any of the non-polar alternatives and vice versa.</figcaption>
<table id="S4.T2.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.4.5.1" class="ltx_tr">
<th id="S4.T2.4.5.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row"></th>
<th id="S4.T2.4.5.1.2" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S4.T2.4.5.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row" colspan="2">Predicted Answer</th>
</tr>
<tr id="S4.T2.2.2" class="ltx_tr">
<th id="S4.T2.2.2.3" class="ltx_td ltx_th ltx_th_column ltx_th_row"></th>
<th id="S4.T2.2.2.4" class="ltx_td ltx_th ltx_th_column ltx_border_r"></th>
<th id="S4.T2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row"><math id="S4.T2.1.1.1.m1.1" class="ltx_Math" alttext="\operatorname{P}" display="inline"><semantics id="S4.T2.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T2.1.1.1.m1.1.1" xref="S4.T2.1.1.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1">P</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">\operatorname{P}</annotation></semantics></math></th>
<th id="S4.T2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><math id="S4.T2.2.2.2.m1.1" class="ltx_Math" alttext="\operatorname{NP}" display="inline"><semantics id="S4.T2.2.2.2.m1.1a"><mi id="S4.T2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.m1.1.1.cmml">NP</mi><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.m1.1b"><ci id="S4.T2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.m1.1.1">NP</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.m1.1c">\operatorname{NP}</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.3.3" class="ltx_tr">
<th id="S4.T2.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-bottom:6.45831pt;" rowspan="2"><span id="S4.T2.3.3.2.1" class="ltx_text">True Answer</span></th>
<td id="S4.T2.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:6.45831pt;"><math id="S4.T2.3.3.1.m1.1" class="ltx_Math" alttext="\operatorname{P}" display="inline"><semantics id="S4.T2.3.3.1.m1.1a"><mi mathvariant="normal" id="S4.T2.3.3.1.m1.1.1" xref="S4.T2.3.3.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.1.m1.1b"><ci id="S4.T2.3.3.1.m1.1.1.cmml" xref="S4.T2.3.3.1.m1.1.1">P</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.1.m1.1c">\operatorname{P}</annotation></semantics></math></td>
<th id="S4.T2.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-bottom:6.45831pt;">37.59</th>
<td id="S4.T2.3.3.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="padding-bottom:6.45831pt;">
<span id="S4.T2.3.3.4.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>0.11</td>
</tr>
<tr id="S4.T2.4.4" class="ltx_tr">
<td id="S4.T2.4.4.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><math id="S4.T2.4.4.1.m1.1" class="ltx_Math" alttext="\operatorname{NP}" display="inline"><semantics id="S4.T2.4.4.1.m1.1a"><mi id="S4.T2.4.4.1.m1.1.1" xref="S4.T2.4.4.1.m1.1.1.cmml">NP</mi><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.1.m1.1b"><ci id="S4.T2.4.4.1.m1.1.1.cmml" xref="S4.T2.4.4.1.m1.1.1">NP</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.1.m1.1c">\operatorname{NP}</annotation></semantics></math></td>
<th id="S4.T2.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b">
<span id="S4.T2.4.4.2.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>0.77</th>
<td id="S4.T2.4.4.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_b">61.53</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.13" class="ltx_p">The cross-polarity experiments exhibit a slightly different behaviour.
First, training a polar classifier <math id="S4.p5.1.m1.1" class="ltx_Math" alttext="f_{\operatorname{P}}" display="inline"><semantics id="S4.p5.1.m1.1a"><msub id="S4.p5.1.m1.1.1" xref="S4.p5.1.m1.1.1.cmml"><mi id="S4.p5.1.m1.1.1.2" xref="S4.p5.1.m1.1.1.2.cmml">f</mi><mi mathvariant="normal" id="S4.p5.1.m1.1.1.3" xref="S4.p5.1.m1.1.1.3.cmml">P</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p5.1.m1.1b"><apply id="S4.p5.1.m1.1.1.cmml" xref="S4.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p5.1.m1.1.1.1.cmml" xref="S4.p5.1.m1.1.1">subscript</csymbol><ci id="S4.p5.1.m1.1.1.2.cmml" xref="S4.p5.1.m1.1.1.2">𝑓</ci><ci id="S4.p5.1.m1.1.1.3.cmml" xref="S4.p5.1.m1.1.1.3">P</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.1.m1.1c">f_{\operatorname{P}}</annotation></semantics></math> based on non-polar features from <math id="S4.p5.2.m2.1" class="ltx_Math" alttext="\Phi_{\operatorname{NP}}" display="inline"><semantics id="S4.p5.2.m2.1a"><msub id="S4.p5.2.m2.1.1" xref="S4.p5.2.m2.1.1.cmml"><mi mathvariant="normal" id="S4.p5.2.m2.1.1.2" xref="S4.p5.2.m2.1.1.2.cmml">Φ</mi><mi id="S4.p5.2.m2.1.1.3" xref="S4.p5.2.m2.1.1.3.cmml">NP</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p5.2.m2.1b"><apply id="S4.p5.2.m2.1.1.cmml" xref="S4.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p5.2.m2.1.1.1.cmml" xref="S4.p5.2.m2.1.1">subscript</csymbol><ci id="S4.p5.2.m2.1.1.2.cmml" xref="S4.p5.2.m2.1.1.2">Φ</ci><ci id="S4.p5.2.m2.1.1.3.cmml" xref="S4.p5.2.m2.1.1.3">NP</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.2.m2.1c">\Phi_{\operatorname{NP}}</annotation></semantics></math> yields results almost as high as when <math id="S4.p5.3.m3.1" class="ltx_Math" alttext="\Phi_{\operatorname{P}}" display="inline"><semantics id="S4.p5.3.m3.1a"><msub id="S4.p5.3.m3.1.1" xref="S4.p5.3.m3.1.1.cmml"><mi mathvariant="normal" id="S4.p5.3.m3.1.1.2" xref="S4.p5.3.m3.1.1.2.cmml">Φ</mi><mi mathvariant="normal" id="S4.p5.3.m3.1.1.3" xref="S4.p5.3.m3.1.1.3.cmml">P</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p5.3.m3.1b"><apply id="S4.p5.3.m3.1.1.cmml" xref="S4.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S4.p5.3.m3.1.1.1.cmml" xref="S4.p5.3.m3.1.1">subscript</csymbol><ci id="S4.p5.3.m3.1.1.2.cmml" xref="S4.p5.3.m3.1.1.2">Φ</ci><ci id="S4.p5.3.m3.1.1.3.cmml" xref="S4.p5.3.m3.1.1.3">P</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.3.m3.1c">\Phi_{\operatorname{P}}</annotation></semantics></math> is used.
Only <math id="S4.p5.4.m4.1" class="ltx_Math" alttext="3.8\,pp" display="inline"><semantics id="S4.p5.4.m4.1a"><mrow id="S4.p5.4.m4.1.1" xref="S4.p5.4.m4.1.1.cmml"><mn id="S4.p5.4.m4.1.1.2" xref="S4.p5.4.m4.1.1.2.cmml">3.8</mn><mo lspace="0.170em" rspace="0em" id="S4.p5.4.m4.1.1.1" xref="S4.p5.4.m4.1.1.1.cmml">​</mo><mi id="S4.p5.4.m4.1.1.3" xref="S4.p5.4.m4.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.p5.4.m4.1.1.1a" xref="S4.p5.4.m4.1.1.1.cmml">​</mo><mi id="S4.p5.4.m4.1.1.4" xref="S4.p5.4.m4.1.1.4.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p5.4.m4.1b"><apply id="S4.p5.4.m4.1.1.cmml" xref="S4.p5.4.m4.1.1"><times id="S4.p5.4.m4.1.1.1.cmml" xref="S4.p5.4.m4.1.1.1"></times><cn type="float" id="S4.p5.4.m4.1.1.2.cmml" xref="S4.p5.4.m4.1.1.2">3.8</cn><ci id="S4.p5.4.m4.1.1.3.cmml" xref="S4.p5.4.m4.1.1.3">𝑝</ci><ci id="S4.p5.4.m4.1.1.4.cmml" xref="S4.p5.4.m4.1.1.4">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.4.m4.1c">3.8\,pp</annotation></semantics></math> of accuracy separate the cross polar model <math id="S4.p5.5.m5.1" class="ltx_Math" alttext="f_{\operatorname{P}}\circ\Phi_{\operatorname{NP}}" display="inline"><semantics id="S4.p5.5.m5.1a"><mrow id="S4.p5.5.m5.1.1" xref="S4.p5.5.m5.1.1.cmml"><msub id="S4.p5.5.m5.1.1.2" xref="S4.p5.5.m5.1.1.2.cmml"><mi id="S4.p5.5.m5.1.1.2.2" xref="S4.p5.5.m5.1.1.2.2.cmml">f</mi><mi mathvariant="normal" id="S4.p5.5.m5.1.1.2.3" xref="S4.p5.5.m5.1.1.2.3.cmml">P</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S4.p5.5.m5.1.1.1" xref="S4.p5.5.m5.1.1.1.cmml">∘</mo><msub id="S4.p5.5.m5.1.1.3" xref="S4.p5.5.m5.1.1.3.cmml"><mi mathvariant="normal" id="S4.p5.5.m5.1.1.3.2" xref="S4.p5.5.m5.1.1.3.2.cmml">Φ</mi><mi id="S4.p5.5.m5.1.1.3.3" xref="S4.p5.5.m5.1.1.3.3.cmml">NP</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.p5.5.m5.1b"><apply id="S4.p5.5.m5.1.1.cmml" xref="S4.p5.5.m5.1.1"><compose id="S4.p5.5.m5.1.1.1.cmml" xref="S4.p5.5.m5.1.1.1"></compose><apply id="S4.p5.5.m5.1.1.2.cmml" xref="S4.p5.5.m5.1.1.2"><csymbol cd="ambiguous" id="S4.p5.5.m5.1.1.2.1.cmml" xref="S4.p5.5.m5.1.1.2">subscript</csymbol><ci id="S4.p5.5.m5.1.1.2.2.cmml" xref="S4.p5.5.m5.1.1.2.2">𝑓</ci><ci id="S4.p5.5.m5.1.1.2.3.cmml" xref="S4.p5.5.m5.1.1.2.3">P</ci></apply><apply id="S4.p5.5.m5.1.1.3.cmml" xref="S4.p5.5.m5.1.1.3"><csymbol cd="ambiguous" id="S4.p5.5.m5.1.1.3.1.cmml" xref="S4.p5.5.m5.1.1.3">subscript</csymbol><ci id="S4.p5.5.m5.1.1.3.2.cmml" xref="S4.p5.5.m5.1.1.3.2">Φ</ci><ci id="S4.p5.5.m5.1.1.3.3.cmml" xref="S4.p5.5.m5.1.1.3.3">NP</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.5.m5.1c">f_{\operatorname{P}}\circ\Phi_{\operatorname{NP}}</annotation></semantics></math> and the polar upper bound <math id="S4.p5.6.m6.1" class="ltx_Math" alttext="f_{\operatorname{P}}\circ\Phi_{\operatorname{P}}" display="inline"><semantics id="S4.p5.6.m6.1a"><mrow id="S4.p5.6.m6.1.1" xref="S4.p5.6.m6.1.1.cmml"><msub id="S4.p5.6.m6.1.1.2" xref="S4.p5.6.m6.1.1.2.cmml"><mi id="S4.p5.6.m6.1.1.2.2" xref="S4.p5.6.m6.1.1.2.2.cmml">f</mi><mi mathvariant="normal" id="S4.p5.6.m6.1.1.2.3" xref="S4.p5.6.m6.1.1.2.3.cmml">P</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S4.p5.6.m6.1.1.1" xref="S4.p5.6.m6.1.1.1.cmml">∘</mo><msub id="S4.p5.6.m6.1.1.3" xref="S4.p5.6.m6.1.1.3.cmml"><mi mathvariant="normal" id="S4.p5.6.m6.1.1.3.2" xref="S4.p5.6.m6.1.1.3.2.cmml">Φ</mi><mi mathvariant="normal" id="S4.p5.6.m6.1.1.3.3" xref="S4.p5.6.m6.1.1.3.3.cmml">P</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.p5.6.m6.1b"><apply id="S4.p5.6.m6.1.1.cmml" xref="S4.p5.6.m6.1.1"><compose id="S4.p5.6.m6.1.1.1.cmml" xref="S4.p5.6.m6.1.1.1"></compose><apply id="S4.p5.6.m6.1.1.2.cmml" xref="S4.p5.6.m6.1.1.2"><csymbol cd="ambiguous" id="S4.p5.6.m6.1.1.2.1.cmml" xref="S4.p5.6.m6.1.1.2">subscript</csymbol><ci id="S4.p5.6.m6.1.1.2.2.cmml" xref="S4.p5.6.m6.1.1.2.2">𝑓</ci><ci id="S4.p5.6.m6.1.1.2.3.cmml" xref="S4.p5.6.m6.1.1.2.3">P</ci></apply><apply id="S4.p5.6.m6.1.1.3.cmml" xref="S4.p5.6.m6.1.1.3"><csymbol cd="ambiguous" id="S4.p5.6.m6.1.1.3.1.cmml" xref="S4.p5.6.m6.1.1.3">subscript</csymbol><ci id="S4.p5.6.m6.1.1.3.2.cmml" xref="S4.p5.6.m6.1.1.3.2">Φ</ci><ci id="S4.p5.6.m6.1.1.3.3.cmml" xref="S4.p5.6.m6.1.1.3.3">P</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.6.m6.1c">f_{\operatorname{P}}\circ\Phi_{\operatorname{P}}</annotation></semantics></math>.
Taking into account that both results are above <math id="S4.p5.7.m7.1" class="ltx_Math" alttext="75\,\%" display="inline"><semantics id="S4.p5.7.m7.1a"><mrow id="S4.p5.7.m7.1.1" xref="S4.p5.7.m7.1.1.cmml"><mn id="S4.p5.7.m7.1.1.2" xref="S4.p5.7.m7.1.1.2.cmml">75</mn><mo lspace="0.170em" id="S4.p5.7.m7.1.1.1" xref="S4.p5.7.m7.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p5.7.m7.1b"><apply id="S4.p5.7.m7.1.1.cmml" xref="S4.p5.7.m7.1.1"><csymbol cd="latexml" id="S4.p5.7.m7.1.1.1.cmml" xref="S4.p5.7.m7.1.1.1">percent</csymbol><cn type="integer" id="S4.p5.7.m7.1.1.2.cmml" xref="S4.p5.7.m7.1.1.2">75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.7.m7.1c">75\,\%</annotation></semantics></math> accuracy, their difference can be considered low, especially when compared against the probability of randomly guessing which lies at <math id="S4.p5.8.m8.1" class="ltx_Math" alttext="50\,\%" display="inline"><semantics id="S4.p5.8.m8.1a"><mrow id="S4.p5.8.m8.1.1" xref="S4.p5.8.m8.1.1.cmml"><mn id="S4.p5.8.m8.1.1.2" xref="S4.p5.8.m8.1.1.2.cmml">50</mn><mo lspace="0.170em" id="S4.p5.8.m8.1.1.1" xref="S4.p5.8.m8.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p5.8.m8.1b"><apply id="S4.p5.8.m8.1.1.cmml" xref="S4.p5.8.m8.1.1"><csymbol cd="latexml" id="S4.p5.8.m8.1.1.1.cmml" xref="S4.p5.8.m8.1.1.1">percent</csymbol><cn type="integer" id="S4.p5.8.m8.1.1.2.cmml" xref="S4.p5.8.m8.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.8.m8.1c">50\,\%</annotation></semantics></math>.
Second, the inverse cross-polar experiment, where non-polar questions are classified using a polar-only feature space <math id="S4.p5.9.m9.1" class="ltx_Math" alttext="f_{\operatorname{NP}}\circ\Phi_{\operatorname{P}}" display="inline"><semantics id="S4.p5.9.m9.1a"><mrow id="S4.p5.9.m9.1.1" xref="S4.p5.9.m9.1.1.cmml"><msub id="S4.p5.9.m9.1.1.2" xref="S4.p5.9.m9.1.1.2.cmml"><mi id="S4.p5.9.m9.1.1.2.2" xref="S4.p5.9.m9.1.1.2.2.cmml">f</mi><mi id="S4.p5.9.m9.1.1.2.3" xref="S4.p5.9.m9.1.1.2.3.cmml">NP</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S4.p5.9.m9.1.1.1" xref="S4.p5.9.m9.1.1.1.cmml">∘</mo><msub id="S4.p5.9.m9.1.1.3" xref="S4.p5.9.m9.1.1.3.cmml"><mi mathvariant="normal" id="S4.p5.9.m9.1.1.3.2" xref="S4.p5.9.m9.1.1.3.2.cmml">Φ</mi><mi mathvariant="normal" id="S4.p5.9.m9.1.1.3.3" xref="S4.p5.9.m9.1.1.3.3.cmml">P</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.p5.9.m9.1b"><apply id="S4.p5.9.m9.1.1.cmml" xref="S4.p5.9.m9.1.1"><compose id="S4.p5.9.m9.1.1.1.cmml" xref="S4.p5.9.m9.1.1.1"></compose><apply id="S4.p5.9.m9.1.1.2.cmml" xref="S4.p5.9.m9.1.1.2"><csymbol cd="ambiguous" id="S4.p5.9.m9.1.1.2.1.cmml" xref="S4.p5.9.m9.1.1.2">subscript</csymbol><ci id="S4.p5.9.m9.1.1.2.2.cmml" xref="S4.p5.9.m9.1.1.2.2">𝑓</ci><ci id="S4.p5.9.m9.1.1.2.3.cmml" xref="S4.p5.9.m9.1.1.2.3">NP</ci></apply><apply id="S4.p5.9.m9.1.1.3.cmml" xref="S4.p5.9.m9.1.1.3"><csymbol cd="ambiguous" id="S4.p5.9.m9.1.1.3.1.cmml" xref="S4.p5.9.m9.1.1.3">subscript</csymbol><ci id="S4.p5.9.m9.1.1.3.2.cmml" xref="S4.p5.9.m9.1.1.3.2">Φ</ci><ci id="S4.p5.9.m9.1.1.3.3.cmml" xref="S4.p5.9.m9.1.1.3.3">P</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.9.m9.1c">f_{\operatorname{NP}}\circ\Phi_{\operatorname{P}}</annotation></semantics></math> shows an accuracy of <math id="S4.p5.10.m10.1" class="ltx_Math" alttext="28.7\,\%" display="inline"><semantics id="S4.p5.10.m10.1a"><mrow id="S4.p5.10.m10.1.1" xref="S4.p5.10.m10.1.1.cmml"><mn id="S4.p5.10.m10.1.1.2" xref="S4.p5.10.m10.1.1.2.cmml">28.7</mn><mo lspace="0.170em" id="S4.p5.10.m10.1.1.1" xref="S4.p5.10.m10.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p5.10.m10.1b"><apply id="S4.p5.10.m10.1.1.cmml" xref="S4.p5.10.m10.1.1"><csymbol cd="latexml" id="S4.p5.10.m10.1.1.1.cmml" xref="S4.p5.10.m10.1.1.1">percent</csymbol><cn type="float" id="S4.p5.10.m10.1.1.2.cmml" xref="S4.p5.10.m10.1.1.2">28.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.10.m10.1c">28.7\,\%</annotation></semantics></math>.
This presents a loss of <math id="S4.p5.11.m11.1" class="ltx_Math" alttext="-22.9\,pp" display="inline"><semantics id="S4.p5.11.m11.1a"><mrow id="S4.p5.11.m11.1.1" xref="S4.p5.11.m11.1.1.cmml"><mo id="S4.p5.11.m11.1.1a" xref="S4.p5.11.m11.1.1.cmml">−</mo><mrow id="S4.p5.11.m11.1.1.2" xref="S4.p5.11.m11.1.1.2.cmml"><mn id="S4.p5.11.m11.1.1.2.2" xref="S4.p5.11.m11.1.1.2.2.cmml">22.9</mn><mo lspace="0.170em" rspace="0em" id="S4.p5.11.m11.1.1.2.1" xref="S4.p5.11.m11.1.1.2.1.cmml">​</mo><mi id="S4.p5.11.m11.1.1.2.3" xref="S4.p5.11.m11.1.1.2.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.p5.11.m11.1.1.2.1a" xref="S4.p5.11.m11.1.1.2.1.cmml">​</mo><mi id="S4.p5.11.m11.1.1.2.4" xref="S4.p5.11.m11.1.1.2.4.cmml">p</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p5.11.m11.1b"><apply id="S4.p5.11.m11.1.1.cmml" xref="S4.p5.11.m11.1.1"><minus id="S4.p5.11.m11.1.1.1.cmml" xref="S4.p5.11.m11.1.1"></minus><apply id="S4.p5.11.m11.1.1.2.cmml" xref="S4.p5.11.m11.1.1.2"><times id="S4.p5.11.m11.1.1.2.1.cmml" xref="S4.p5.11.m11.1.1.2.1"></times><cn type="float" id="S4.p5.11.m11.1.1.2.2.cmml" xref="S4.p5.11.m11.1.1.2.2">22.9</cn><ci id="S4.p5.11.m11.1.1.2.3.cmml" xref="S4.p5.11.m11.1.1.2.3">𝑝</ci><ci id="S4.p5.11.m11.1.1.2.4.cmml" xref="S4.p5.11.m11.1.1.2.4">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.11.m11.1c">-22.9\,pp</annotation></semantics></math> w.r.t. the upper bound <math id="S4.p5.12.m12.1" class="ltx_Math" alttext="f_{\operatorname{NP}}\circ\Phi_{\operatorname{NP}}" display="inline"><semantics id="S4.p5.12.m12.1a"><mrow id="S4.p5.12.m12.1.1" xref="S4.p5.12.m12.1.1.cmml"><msub id="S4.p5.12.m12.1.1.2" xref="S4.p5.12.m12.1.1.2.cmml"><mi id="S4.p5.12.m12.1.1.2.2" xref="S4.p5.12.m12.1.1.2.2.cmml">f</mi><mi id="S4.p5.12.m12.1.1.2.3" xref="S4.p5.12.m12.1.1.2.3.cmml">NP</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S4.p5.12.m12.1.1.1" xref="S4.p5.12.m12.1.1.1.cmml">∘</mo><msub id="S4.p5.12.m12.1.1.3" xref="S4.p5.12.m12.1.1.3.cmml"><mi mathvariant="normal" id="S4.p5.12.m12.1.1.3.2" xref="S4.p5.12.m12.1.1.3.2.cmml">Φ</mi><mi id="S4.p5.12.m12.1.1.3.3" xref="S4.p5.12.m12.1.1.3.3.cmml">NP</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.p5.12.m12.1b"><apply id="S4.p5.12.m12.1.1.cmml" xref="S4.p5.12.m12.1.1"><compose id="S4.p5.12.m12.1.1.1.cmml" xref="S4.p5.12.m12.1.1.1"></compose><apply id="S4.p5.12.m12.1.1.2.cmml" xref="S4.p5.12.m12.1.1.2"><csymbol cd="ambiguous" id="S4.p5.12.m12.1.1.2.1.cmml" xref="S4.p5.12.m12.1.1.2">subscript</csymbol><ci id="S4.p5.12.m12.1.1.2.2.cmml" xref="S4.p5.12.m12.1.1.2.2">𝑓</ci><ci id="S4.p5.12.m12.1.1.2.3.cmml" xref="S4.p5.12.m12.1.1.2.3">NP</ci></apply><apply id="S4.p5.12.m12.1.1.3.cmml" xref="S4.p5.12.m12.1.1.3"><csymbol cd="ambiguous" id="S4.p5.12.m12.1.1.3.1.cmml" xref="S4.p5.12.m12.1.1.3">subscript</csymbol><ci id="S4.p5.12.m12.1.1.3.2.cmml" xref="S4.p5.12.m12.1.1.3.2">Φ</ci><ci id="S4.p5.12.m12.1.1.3.3.cmml" xref="S4.p5.12.m12.1.1.3.3">NP</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.12.m12.1c">f_{\operatorname{NP}}\circ\Phi_{\operatorname{NP}}</annotation></semantics></math>.
Note that this result still lies notably above random chance (which corresponds to <math id="S4.p5.13.m13.1" class="ltx_Math" alttext="0.03\,\%" display="inline"><semantics id="S4.p5.13.m13.1a"><mrow id="S4.p5.13.m13.1.1" xref="S4.p5.13.m13.1.1.cmml"><mn id="S4.p5.13.m13.1.1.2" xref="S4.p5.13.m13.1.1.2.cmml">0.03</mn><mo lspace="0.170em" id="S4.p5.13.m13.1.1.1" xref="S4.p5.13.m13.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p5.13.m13.1b"><apply id="S4.p5.13.m13.1.1.cmml" xref="S4.p5.13.m13.1.1"><csymbol cd="latexml" id="S4.p5.13.m13.1.1.1.cmml" xref="S4.p5.13.m13.1.1.1">percent</csymbol><cn type="float" id="S4.p5.13.m13.1.1.2.cmml" xref="S4.p5.13.m13.1.1.2">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.13.m13.1c">0.03\,\%</annotation></semantics></math>), and will be discussed further in the next section.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Discussion</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this section, we analyze the results from all conducted experiments and their implications, in the context of the joint space shared by polar and non-polar features.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">The first observation comes from comparing the baseline experiments against their corresponding empirical upper bound for both polar and non-polar features.
Having almost indistinguishable results when the model is being trained with non-polar and over-represented polar samples together, indicates that the model is capable of coping with both question types simultaneously, without compromising performance.
In essence, this simple comparison shows no measurable confounding factors (i.e., source of bias) by populating the visual-text feature space with polar and non-polar questions at the same time.
The need for balancing strategies, commonly used for long tail datasets like mini-batch resampling or weighted labels <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> are thereby unlikely to improve the performance of typical VQA model architectures like the one used in this work.
Regarding the distribution of polar and non-polar questions in the joint feature space <math id="S5.p2.1.m1.1" class="ltx_Math" alttext="\Phi_{\Omega}" display="inline"><semantics id="S5.p2.1.m1.1a"><msub id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml"><mi mathvariant="normal" id="S5.p2.1.m1.1.1.2" xref="S5.p2.1.m1.1.1.2.cmml">Φ</mi><mi mathvariant="normal" id="S5.p2.1.m1.1.1.3" xref="S5.p2.1.m1.1.1.3.cmml">Ω</mi></msub><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><apply id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.p2.1.m1.1.1.1.cmml" xref="S5.p2.1.m1.1.1">subscript</csymbol><ci id="S5.p2.1.m1.1.1.2.cmml" xref="S5.p2.1.m1.1.1.2">Φ</ci><ci id="S5.p2.1.m1.1.1.3.cmml" xref="S5.p2.1.m1.1.1.3">Ω</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">\Phi_{\Omega}</annotation></semantics></math>, we are left with two possible scenarios: either each distribution occupies a different (disjoint) sub-region of the feature space or they overlap and hence, they (at least partially) model the same semantic concepts.
An analysis of the remaining experiments will help identifying which of these two conjectures can be verified.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.2" class="ltx_p">The second observation comes from the first cross-polarity experiment.
Here, by training a classifier on polar questions that are first projected to a feature manifold of non-polar concepts, we measure how possible it is to answer polar questions by using the feature space of non-polar concepts.
This scenario is intuitively simple, because of the vast complexity of topics covered by non-polar questions (3127 answer classes in our experiments).
Also, by reducing the number of classes from 3127 to 2, the chance level of the classification problem increases from <math id="S5.p3.1.m1.1" class="ltx_Math" alttext="\tfrac{1}{3127}" display="inline"><semantics id="S5.p3.1.m1.1a"><mfrac id="S5.p3.1.m1.1.1" xref="S5.p3.1.m1.1.1.cmml"><mn id="S5.p3.1.m1.1.1.2" xref="S5.p3.1.m1.1.1.2.cmml">1</mn><mn id="S5.p3.1.m1.1.1.3" xref="S5.p3.1.m1.1.1.3.cmml">3127</mn></mfrac><annotation-xml encoding="MathML-Content" id="S5.p3.1.m1.1b"><apply id="S5.p3.1.m1.1.1.cmml" xref="S5.p3.1.m1.1.1"><divide id="S5.p3.1.m1.1.1.1.cmml" xref="S5.p3.1.m1.1.1"></divide><cn type="integer" id="S5.p3.1.m1.1.1.2.cmml" xref="S5.p3.1.m1.1.1.2">1</cn><cn type="integer" id="S5.p3.1.m1.1.1.3.cmml" xref="S5.p3.1.m1.1.1.3">3127</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.1.m1.1c">\tfrac{1}{3127}</annotation></semantics></math> to <math id="S5.p3.2.m2.1" class="ltx_Math" alttext="\tfrac{1}{2}" display="inline"><semantics id="S5.p3.2.m2.1a"><mfrac id="S5.p3.2.m2.1.1" xref="S5.p3.2.m2.1.1.cmml"><mn id="S5.p3.2.m2.1.1.2" xref="S5.p3.2.m2.1.1.2.cmml">1</mn><mn id="S5.p3.2.m2.1.1.3" xref="S5.p3.2.m2.1.1.3.cmml">2</mn></mfrac><annotation-xml encoding="MathML-Content" id="S5.p3.2.m2.1b"><apply id="S5.p3.2.m2.1.1.cmml" xref="S5.p3.2.m2.1.1"><divide id="S5.p3.2.m2.1.1.1.cmml" xref="S5.p3.2.m2.1.1"></divide><cn type="integer" id="S5.p3.2.m2.1.1.2.cmml" xref="S5.p3.2.m2.1.1.2">1</cn><cn type="integer" id="S5.p3.2.m2.1.1.3.cmml" xref="S5.p3.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.2.m2.1c">\tfrac{1}{2}</annotation></semantics></math>, which makes the problem much easier.
Hence, the observed result is not really surprising: with only a minor drop in performance, we can say that most polar questions can be answered even by using a non-polar feature space representation.
Looking for the alignment between a non-polar concept (e.g., “<span id="S5.p3.2.1" class="ltx_text ltx_font_italic">green</span>” or “<span id="S5.p3.2.2" class="ltx_text ltx_font_italic">bicycle</span>”) and the occurrence of that concept in the question embedding, makes polar questions straightforward to answer, even by a simple classifier.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.4" class="ltx_p">The third, and perhaps most interesting observation comes from the other direction of the cross-polarity experiments.
In this experiment we trained a classifier on non-polar questions while relying on a polar feature space.
Unlike before, we are now going up from 2 to 3127 classes, intuitively making the problem much more challenging.
Also it is unclear to what extent we can expect the polar feature space to be able to express the intricacies of non-polar questions.
As mentioned in Section <a href="#S2" title="II Related Work ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, several VQA datasets have decided to entirely leave out polar samples to favor the more complex questions arising from only allowing non-polar queries.
According to these premises, we expect the non-polar classifier based on features from a polar embedding space to perform poorly.
Recall that the reported accuracy for this setup is <math id="S5.p4.1.m1.1" class="ltx_Math" alttext="28.7\,\%" display="inline"><semantics id="S5.p4.1.m1.1a"><mrow id="S5.p4.1.m1.1.1" xref="S5.p4.1.m1.1.1.cmml"><mn id="S5.p4.1.m1.1.1.2" xref="S5.p4.1.m1.1.1.2.cmml">28.7</mn><mo lspace="0.170em" id="S5.p4.1.m1.1.1.1" xref="S5.p4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p4.1.m1.1b"><apply id="S5.p4.1.m1.1.1.cmml" xref="S5.p4.1.m1.1.1"><csymbol cd="latexml" id="S5.p4.1.m1.1.1.1.cmml" xref="S5.p4.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.p4.1.m1.1.1.2.cmml" xref="S5.p4.1.m1.1.1.2">28.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.1.m1.1c">28.7\,\%</annotation></semantics></math> which is indeed lower than the upper bound of <math id="S5.p4.2.m2.1" class="ltx_Math" alttext="51.6\,\%" display="inline"><semantics id="S5.p4.2.m2.1a"><mrow id="S5.p4.2.m2.1.1" xref="S5.p4.2.m2.1.1.cmml"><mn id="S5.p4.2.m2.1.1.2" xref="S5.p4.2.m2.1.1.2.cmml">51.6</mn><mo lspace="0.170em" id="S5.p4.2.m2.1.1.1" xref="S5.p4.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p4.2.m2.1b"><apply id="S5.p4.2.m2.1.1.cmml" xref="S5.p4.2.m2.1.1"><csymbol cd="latexml" id="S5.p4.2.m2.1.1.1.cmml" xref="S5.p4.2.m2.1.1.1">percent</csymbol><cn type="float" id="S5.p4.2.m2.1.1.2.cmml" xref="S5.p4.2.m2.1.1.2">51.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.2.m2.1c">51.6\,\%</annotation></semantics></math>.
However, we note that this value is still significantly higher than random chance of <math id="S5.p4.3.m3.1" class="ltx_Math" alttext="\tfrac{1}{3127}" display="inline"><semantics id="S5.p4.3.m3.1a"><mfrac id="S5.p4.3.m3.1.1" xref="S5.p4.3.m3.1.1.cmml"><mn id="S5.p4.3.m3.1.1.2" xref="S5.p4.3.m3.1.1.2.cmml">1</mn><mn id="S5.p4.3.m3.1.1.3" xref="S5.p4.3.m3.1.1.3.cmml">3127</mn></mfrac><annotation-xml encoding="MathML-Content" id="S5.p4.3.m3.1b"><apply id="S5.p4.3.m3.1.1.cmml" xref="S5.p4.3.m3.1.1"><divide id="S5.p4.3.m3.1.1.1.cmml" xref="S5.p4.3.m3.1.1"></divide><cn type="integer" id="S5.p4.3.m3.1.1.2.cmml" xref="S5.p4.3.m3.1.1.2">1</cn><cn type="integer" id="S5.p4.3.m3.1.1.3.cmml" xref="S5.p4.3.m3.1.1.3">3127</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.3.m3.1c">\tfrac{1}{3127}</annotation></semantics></math>.
This behavior suggests that there is a notable subset of non-polar questions that can be answered with high accuracy based only on the feature space of polar questions, immediately leading to the question:
How to find the subset of non-polar questions that can be answered through the polar feature space?
The cross-polarity experiments already show that non-polar questions with numeric answers are well conveyed by the polar feature space (accuracy of <math id="S5.p4.4.m4.1" class="ltx_Math" alttext="f_{\operatorname{NP}}\circ\Phi_{\operatorname{P}}" display="inline"><semantics id="S5.p4.4.m4.1a"><mrow id="S5.p4.4.m4.1.1" xref="S5.p4.4.m4.1.1.cmml"><msub id="S5.p4.4.m4.1.1.2" xref="S5.p4.4.m4.1.1.2.cmml"><mi id="S5.p4.4.m4.1.1.2.2" xref="S5.p4.4.m4.1.1.2.2.cmml">f</mi><mi id="S5.p4.4.m4.1.1.2.3" xref="S5.p4.4.m4.1.1.2.3.cmml">NP</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S5.p4.4.m4.1.1.1" xref="S5.p4.4.m4.1.1.1.cmml">∘</mo><msub id="S5.p4.4.m4.1.1.3" xref="S5.p4.4.m4.1.1.3.cmml"><mi mathvariant="normal" id="S5.p4.4.m4.1.1.3.2" xref="S5.p4.4.m4.1.1.3.2.cmml">Φ</mi><mi mathvariant="normal" id="S5.p4.4.m4.1.1.3.3" xref="S5.p4.4.m4.1.1.3.3.cmml">P</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.p4.4.m4.1b"><apply id="S5.p4.4.m4.1.1.cmml" xref="S5.p4.4.m4.1.1"><compose id="S5.p4.4.m4.1.1.1.cmml" xref="S5.p4.4.m4.1.1.1"></compose><apply id="S5.p4.4.m4.1.1.2.cmml" xref="S5.p4.4.m4.1.1.2"><csymbol cd="ambiguous" id="S5.p4.4.m4.1.1.2.1.cmml" xref="S5.p4.4.m4.1.1.2">subscript</csymbol><ci id="S5.p4.4.m4.1.1.2.2.cmml" xref="S5.p4.4.m4.1.1.2.2">𝑓</ci><ci id="S5.p4.4.m4.1.1.2.3.cmml" xref="S5.p4.4.m4.1.1.2.3">NP</ci></apply><apply id="S5.p4.4.m4.1.1.3.cmml" xref="S5.p4.4.m4.1.1.3"><csymbol cd="ambiguous" id="S5.p4.4.m4.1.1.3.1.cmml" xref="S5.p4.4.m4.1.1.3">subscript</csymbol><ci id="S5.p4.4.m4.1.1.3.2.cmml" xref="S5.p4.4.m4.1.1.3.2">Φ</ci><ci id="S5.p4.4.m4.1.1.3.3.cmml" xref="S5.p4.4.m4.1.1.3.3">P</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.4.m4.1c">f_{\operatorname{NP}}\circ\Phi_{\operatorname{P}}</annotation></semantics></math> for numeric labels such as “0”, “1” and “2” is high).
We theorize that a general alignment between polar questions <em id="S5.p4.4.1" class="ltx_emph ltx_font_italic">about</em> non-polar concepts and the corresponding non-polar questions exists.</p>
</div>
<figure id="S5.F6" class="ltx_figure"><img src="/html/2003.11844/assets/x6.png" id="S5.F6.g1" class="ltx_graphics ltx_img_landscape" width="461" height="127" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Polar questions can be used to answer non-polar questions with high accuracy as long as the polar questions relate to an existing non-polar concept. Given the image in the center, a polar question (right) and a non-polar question (left) can be asked about a common non-polar concept, namely “<span id="S5.F6.2.1" class="ltx_text ltx_font_italic">glass</span>”.</figcaption>
</figure>
<section id="S5.SS0.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS0.SSS1.5.1.1" class="ltx_text">V-</span>1 </span>Polar Questions About Non-Polar Concepts</h4>

<div id="S5.SS0.SSS1.p1" class="ltx_para">
<p id="S5.SS0.SSS1.p1.6" class="ltx_p">Take the example in Figure <a href="#S5.F6" title="Figure 6 ‣ V Discussion ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>: The non-polar question “<span id="S5.SS0.SSS1.p1.6.1" class="ltx_text ltx_font_italic">What is the woman holding?</span>” and the the polar question “<span id="S5.SS0.SSS1.p1.6.2" class="ltx_text ltx_font_italic">Is the woman holding a glass?</span>” relate to the same semantic concept, namely “<span id="S5.SS0.SSS1.p1.6.3" class="ltx_text ltx_font_italic">glass</span>”.
By counting the number of polar questions that talk about each of the non-polar concepts, we can focus on the non-polar concepts which appear in most polar questions.
We call this category of non-polar answers “well covered”.
We use the notation <math id="S5.SS0.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{X}_{\operatorname{NP}^{\prime}}" display="inline"><semantics id="S5.SS0.SSS1.p1.1.m1.1a"><msub id="S5.SS0.SSS1.p1.1.m1.1.1" xref="S5.SS0.SSS1.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS0.SSS1.p1.1.m1.1.1.2" xref="S5.SS0.SSS1.p1.1.m1.1.1.2.cmml">𝒳</mi><msup id="S5.SS0.SSS1.p1.1.m1.1.1.3" xref="S5.SS0.SSS1.p1.1.m1.1.1.3.cmml"><mi id="S5.SS0.SSS1.p1.1.m1.1.1.3.2" xref="S5.SS0.SSS1.p1.1.m1.1.1.3.2.cmml">NP</mi><mo id="S5.SS0.SSS1.p1.1.m1.1.1.3.3" xref="S5.SS0.SSS1.p1.1.m1.1.1.3.3.cmml">′</mo></msup></msub><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS1.p1.1.m1.1b"><apply id="S5.SS0.SSS1.p1.1.m1.1.1.cmml" xref="S5.SS0.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p1.1.m1.1.1.1.cmml" xref="S5.SS0.SSS1.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS0.SSS1.p1.1.m1.1.1.2.cmml" xref="S5.SS0.SSS1.p1.1.m1.1.1.2">𝒳</ci><apply id="S5.SS0.SSS1.p1.1.m1.1.1.3.cmml" xref="S5.SS0.SSS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p1.1.m1.1.1.3.1.cmml" xref="S5.SS0.SSS1.p1.1.m1.1.1.3">superscript</csymbol><ci id="S5.SS0.SSS1.p1.1.m1.1.1.3.2.cmml" xref="S5.SS0.SSS1.p1.1.m1.1.1.3.2">NP</ci><ci id="S5.SS0.SSS1.p1.1.m1.1.1.3.3.cmml" xref="S5.SS0.SSS1.p1.1.m1.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS1.p1.1.m1.1c">\mathcal{X}_{\operatorname{NP}^{\prime}}</annotation></semantics></math> to refer to non-polar samples (i.e., questions and answers) with answers that are well covered by polar questions.
The complement of <math id="S5.SS0.SSS1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{X}_{\operatorname{NP}^{\prime}}" display="inline"><semantics id="S5.SS0.SSS1.p1.2.m2.1a"><msub id="S5.SS0.SSS1.p1.2.m2.1.1" xref="S5.SS0.SSS1.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS0.SSS1.p1.2.m2.1.1.2" xref="S5.SS0.SSS1.p1.2.m2.1.1.2.cmml">𝒳</mi><msup id="S5.SS0.SSS1.p1.2.m2.1.1.3" xref="S5.SS0.SSS1.p1.2.m2.1.1.3.cmml"><mi id="S5.SS0.SSS1.p1.2.m2.1.1.3.2" xref="S5.SS0.SSS1.p1.2.m2.1.1.3.2.cmml">NP</mi><mo id="S5.SS0.SSS1.p1.2.m2.1.1.3.3" xref="S5.SS0.SSS1.p1.2.m2.1.1.3.3.cmml">′</mo></msup></msub><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS1.p1.2.m2.1b"><apply id="S5.SS0.SSS1.p1.2.m2.1.1.cmml" xref="S5.SS0.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p1.2.m2.1.1.1.cmml" xref="S5.SS0.SSS1.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS0.SSS1.p1.2.m2.1.1.2.cmml" xref="S5.SS0.SSS1.p1.2.m2.1.1.2">𝒳</ci><apply id="S5.SS0.SSS1.p1.2.m2.1.1.3.cmml" xref="S5.SS0.SSS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p1.2.m2.1.1.3.1.cmml" xref="S5.SS0.SSS1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S5.SS0.SSS1.p1.2.m2.1.1.3.2.cmml" xref="S5.SS0.SSS1.p1.2.m2.1.1.3.2">NP</ci><ci id="S5.SS0.SSS1.p1.2.m2.1.1.3.3.cmml" xref="S5.SS0.SSS1.p1.2.m2.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS1.p1.2.m2.1c">\mathcal{X}_{\operatorname{NP}^{\prime}}</annotation></semantics></math> (i.e., non-polar samples whose answers are not well covered by polar questions) is denoted by <math id="S5.SS0.SSS1.p1.3.m3.1" class="ltx_Math" alttext="\overline{\mathcal{X}_{\operatorname{NP}^{\prime}}}" display="inline"><semantics id="S5.SS0.SSS1.p1.3.m3.1a"><mover accent="true" id="S5.SS0.SSS1.p1.3.m3.1.1" xref="S5.SS0.SSS1.p1.3.m3.1.1.cmml"><msub id="S5.SS0.SSS1.p1.3.m3.1.1.2" xref="S5.SS0.SSS1.p1.3.m3.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS0.SSS1.p1.3.m3.1.1.2.2" xref="S5.SS0.SSS1.p1.3.m3.1.1.2.2.cmml">𝒳</mi><msup id="S5.SS0.SSS1.p1.3.m3.1.1.2.3" xref="S5.SS0.SSS1.p1.3.m3.1.1.2.3.cmml"><mi id="S5.SS0.SSS1.p1.3.m3.1.1.2.3.2" xref="S5.SS0.SSS1.p1.3.m3.1.1.2.3.2.cmml">NP</mi><mo id="S5.SS0.SSS1.p1.3.m3.1.1.2.3.3" xref="S5.SS0.SSS1.p1.3.m3.1.1.2.3.3.cmml">′</mo></msup></msub><mo id="S5.SS0.SSS1.p1.3.m3.1.1.1" xref="S5.SS0.SSS1.p1.3.m3.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS1.p1.3.m3.1b"><apply id="S5.SS0.SSS1.p1.3.m3.1.1.cmml" xref="S5.SS0.SSS1.p1.3.m3.1.1"><ci id="S5.SS0.SSS1.p1.3.m3.1.1.1.cmml" xref="S5.SS0.SSS1.p1.3.m3.1.1.1">¯</ci><apply id="S5.SS0.SSS1.p1.3.m3.1.1.2.cmml" xref="S5.SS0.SSS1.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p1.3.m3.1.1.2.1.cmml" xref="S5.SS0.SSS1.p1.3.m3.1.1.2">subscript</csymbol><ci id="S5.SS0.SSS1.p1.3.m3.1.1.2.2.cmml" xref="S5.SS0.SSS1.p1.3.m3.1.1.2.2">𝒳</ci><apply id="S5.SS0.SSS1.p1.3.m3.1.1.2.3.cmml" xref="S5.SS0.SSS1.p1.3.m3.1.1.2.3"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p1.3.m3.1.1.2.3.1.cmml" xref="S5.SS0.SSS1.p1.3.m3.1.1.2.3">superscript</csymbol><ci id="S5.SS0.SSS1.p1.3.m3.1.1.2.3.2.cmml" xref="S5.SS0.SSS1.p1.3.m3.1.1.2.3.2">NP</ci><ci id="S5.SS0.SSS1.p1.3.m3.1.1.2.3.3.cmml" xref="S5.SS0.SSS1.p1.3.m3.1.1.2.3.3">′</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS1.p1.3.m3.1c">\overline{\mathcal{X}_{\operatorname{NP}^{\prime}}}</annotation></semantics></math>.
We can then test the <math id="S5.SS0.SSS1.p1.4.m4.1" class="ltx_Math" alttext="f_{\operatorname{NP}}\circ\Phi_{\operatorname{P}}" display="inline"><semantics id="S5.SS0.SSS1.p1.4.m4.1a"><mrow id="S5.SS0.SSS1.p1.4.m4.1.1" xref="S5.SS0.SSS1.p1.4.m4.1.1.cmml"><msub id="S5.SS0.SSS1.p1.4.m4.1.1.2" xref="S5.SS0.SSS1.p1.4.m4.1.1.2.cmml"><mi id="S5.SS0.SSS1.p1.4.m4.1.1.2.2" xref="S5.SS0.SSS1.p1.4.m4.1.1.2.2.cmml">f</mi><mi id="S5.SS0.SSS1.p1.4.m4.1.1.2.3" xref="S5.SS0.SSS1.p1.4.m4.1.1.2.3.cmml">NP</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S5.SS0.SSS1.p1.4.m4.1.1.1" xref="S5.SS0.SSS1.p1.4.m4.1.1.1.cmml">∘</mo><msub id="S5.SS0.SSS1.p1.4.m4.1.1.3" xref="S5.SS0.SSS1.p1.4.m4.1.1.3.cmml"><mi mathvariant="normal" id="S5.SS0.SSS1.p1.4.m4.1.1.3.2" xref="S5.SS0.SSS1.p1.4.m4.1.1.3.2.cmml">Φ</mi><mi mathvariant="normal" id="S5.SS0.SSS1.p1.4.m4.1.1.3.3" xref="S5.SS0.SSS1.p1.4.m4.1.1.3.3.cmml">P</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS1.p1.4.m4.1b"><apply id="S5.SS0.SSS1.p1.4.m4.1.1.cmml" xref="S5.SS0.SSS1.p1.4.m4.1.1"><compose id="S5.SS0.SSS1.p1.4.m4.1.1.1.cmml" xref="S5.SS0.SSS1.p1.4.m4.1.1.1"></compose><apply id="S5.SS0.SSS1.p1.4.m4.1.1.2.cmml" xref="S5.SS0.SSS1.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p1.4.m4.1.1.2.1.cmml" xref="S5.SS0.SSS1.p1.4.m4.1.1.2">subscript</csymbol><ci id="S5.SS0.SSS1.p1.4.m4.1.1.2.2.cmml" xref="S5.SS0.SSS1.p1.4.m4.1.1.2.2">𝑓</ci><ci id="S5.SS0.SSS1.p1.4.m4.1.1.2.3.cmml" xref="S5.SS0.SSS1.p1.4.m4.1.1.2.3">NP</ci></apply><apply id="S5.SS0.SSS1.p1.4.m4.1.1.3.cmml" xref="S5.SS0.SSS1.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p1.4.m4.1.1.3.1.cmml" xref="S5.SS0.SSS1.p1.4.m4.1.1.3">subscript</csymbol><ci id="S5.SS0.SSS1.p1.4.m4.1.1.3.2.cmml" xref="S5.SS0.SSS1.p1.4.m4.1.1.3.2">Φ</ci><ci id="S5.SS0.SSS1.p1.4.m4.1.1.3.3.cmml" xref="S5.SS0.SSS1.p1.4.m4.1.1.3.3">P</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS1.p1.4.m4.1c">f_{\operatorname{NP}}\circ\Phi_{\operatorname{P}}</annotation></semantics></math> model used in the last experiment of the cross-polarity evaluation w.r.t. <math id="S5.SS0.SSS1.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{X}_{\operatorname{NP}^{\prime}}" display="inline"><semantics id="S5.SS0.SSS1.p1.5.m5.1a"><msub id="S5.SS0.SSS1.p1.5.m5.1.1" xref="S5.SS0.SSS1.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS0.SSS1.p1.5.m5.1.1.2" xref="S5.SS0.SSS1.p1.5.m5.1.1.2.cmml">𝒳</mi><msup id="S5.SS0.SSS1.p1.5.m5.1.1.3" xref="S5.SS0.SSS1.p1.5.m5.1.1.3.cmml"><mi id="S5.SS0.SSS1.p1.5.m5.1.1.3.2" xref="S5.SS0.SSS1.p1.5.m5.1.1.3.2.cmml">NP</mi><mo id="S5.SS0.SSS1.p1.5.m5.1.1.3.3" xref="S5.SS0.SSS1.p1.5.m5.1.1.3.3.cmml">′</mo></msup></msub><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS1.p1.5.m5.1b"><apply id="S5.SS0.SSS1.p1.5.m5.1.1.cmml" xref="S5.SS0.SSS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p1.5.m5.1.1.1.cmml" xref="S5.SS0.SSS1.p1.5.m5.1.1">subscript</csymbol><ci id="S5.SS0.SSS1.p1.5.m5.1.1.2.cmml" xref="S5.SS0.SSS1.p1.5.m5.1.1.2">𝒳</ci><apply id="S5.SS0.SSS1.p1.5.m5.1.1.3.cmml" xref="S5.SS0.SSS1.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p1.5.m5.1.1.3.1.cmml" xref="S5.SS0.SSS1.p1.5.m5.1.1.3">superscript</csymbol><ci id="S5.SS0.SSS1.p1.5.m5.1.1.3.2.cmml" xref="S5.SS0.SSS1.p1.5.m5.1.1.3.2">NP</ci><ci id="S5.SS0.SSS1.p1.5.m5.1.1.3.3.cmml" xref="S5.SS0.SSS1.p1.5.m5.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS1.p1.5.m5.1c">\mathcal{X}_{\operatorname{NP}^{\prime}}</annotation></semantics></math> and <math id="S5.SS0.SSS1.p1.6.m6.1" class="ltx_Math" alttext="\overline{\mathcal{X}_{\operatorname{NP}^{\prime}}}" display="inline"><semantics id="S5.SS0.SSS1.p1.6.m6.1a"><mover accent="true" id="S5.SS0.SSS1.p1.6.m6.1.1" xref="S5.SS0.SSS1.p1.6.m6.1.1.cmml"><msub id="S5.SS0.SSS1.p1.6.m6.1.1.2" xref="S5.SS0.SSS1.p1.6.m6.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS0.SSS1.p1.6.m6.1.1.2.2" xref="S5.SS0.SSS1.p1.6.m6.1.1.2.2.cmml">𝒳</mi><msup id="S5.SS0.SSS1.p1.6.m6.1.1.2.3" xref="S5.SS0.SSS1.p1.6.m6.1.1.2.3.cmml"><mi id="S5.SS0.SSS1.p1.6.m6.1.1.2.3.2" xref="S5.SS0.SSS1.p1.6.m6.1.1.2.3.2.cmml">NP</mi><mo id="S5.SS0.SSS1.p1.6.m6.1.1.2.3.3" xref="S5.SS0.SSS1.p1.6.m6.1.1.2.3.3.cmml">′</mo></msup></msub><mo id="S5.SS0.SSS1.p1.6.m6.1.1.1" xref="S5.SS0.SSS1.p1.6.m6.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS1.p1.6.m6.1b"><apply id="S5.SS0.SSS1.p1.6.m6.1.1.cmml" xref="S5.SS0.SSS1.p1.6.m6.1.1"><ci id="S5.SS0.SSS1.p1.6.m6.1.1.1.cmml" xref="S5.SS0.SSS1.p1.6.m6.1.1.1">¯</ci><apply id="S5.SS0.SSS1.p1.6.m6.1.1.2.cmml" xref="S5.SS0.SSS1.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p1.6.m6.1.1.2.1.cmml" xref="S5.SS0.SSS1.p1.6.m6.1.1.2">subscript</csymbol><ci id="S5.SS0.SSS1.p1.6.m6.1.1.2.2.cmml" xref="S5.SS0.SSS1.p1.6.m6.1.1.2.2">𝒳</ci><apply id="S5.SS0.SSS1.p1.6.m6.1.1.2.3.cmml" xref="S5.SS0.SSS1.p1.6.m6.1.1.2.3"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p1.6.m6.1.1.2.3.1.cmml" xref="S5.SS0.SSS1.p1.6.m6.1.1.2.3">superscript</csymbol><ci id="S5.SS0.SSS1.p1.6.m6.1.1.2.3.2.cmml" xref="S5.SS0.SSS1.p1.6.m6.1.1.2.3.2">NP</ci><ci id="S5.SS0.SSS1.p1.6.m6.1.1.2.3.3.cmml" xref="S5.SS0.SSS1.p1.6.m6.1.1.2.3.3">′</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS1.p1.6.m6.1c">\overline{\mathcal{X}_{\operatorname{NP}^{\prime}}}</annotation></semantics></math> separately.</p>
</div>
<figure id="S5.F7" class="ltx_figure"><img src="/html/2003.11844/assets/x7.png" id="S5.F7.g1" class="ltx_graphics ltx_img_landscape" width="461" height="306" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Histogram of non-polar concepts that appear in polar questions within the VQA 2.0 dataset. The 500 non-polar concepts with most matching polar questions define the set <math id="S5.F7.3.m1.1" class="ltx_Math" alttext="\mathcal{X}_{\operatorname{NP}^{\prime}}" display="inline"><semantics id="S5.F7.3.m1.1b"><msub id="S5.F7.3.m1.1.1" xref="S5.F7.3.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.F7.3.m1.1.1.2" xref="S5.F7.3.m1.1.1.2.cmml">𝒳</mi><msup id="S5.F7.3.m1.1.1.3" xref="S5.F7.3.m1.1.1.3.cmml"><mi id="S5.F7.3.m1.1.1.3.2" xref="S5.F7.3.m1.1.1.3.2.cmml">NP</mi><mo id="S5.F7.3.m1.1.1.3.3" xref="S5.F7.3.m1.1.1.3.3.cmml">′</mo></msup></msub><annotation-xml encoding="MathML-Content" id="S5.F7.3.m1.1c"><apply id="S5.F7.3.m1.1.1.cmml" xref="S5.F7.3.m1.1.1"><csymbol cd="ambiguous" id="S5.F7.3.m1.1.1.1.cmml" xref="S5.F7.3.m1.1.1">subscript</csymbol><ci id="S5.F7.3.m1.1.1.2.cmml" xref="S5.F7.3.m1.1.1.2">𝒳</ci><apply id="S5.F7.3.m1.1.1.3.cmml" xref="S5.F7.3.m1.1.1.3"><csymbol cd="ambiguous" id="S5.F7.3.m1.1.1.3.1.cmml" xref="S5.F7.3.m1.1.1.3">superscript</csymbol><ci id="S5.F7.3.m1.1.1.3.2.cmml" xref="S5.F7.3.m1.1.1.3.2">NP</ci><ci id="S5.F7.3.m1.1.1.3.3.cmml" xref="S5.F7.3.m1.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.3.m1.1d">\mathcal{X}_{\operatorname{NP}^{\prime}}</annotation></semantics></math> (plotted in blue). In other words, the set <math id="S5.F7.4.m2.1" class="ltx_Math" alttext="\mathcal{X}_{\operatorname{NP}^{\prime}}" display="inline"><semantics id="S5.F7.4.m2.1b"><msub id="S5.F7.4.m2.1.1" xref="S5.F7.4.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.F7.4.m2.1.1.2" xref="S5.F7.4.m2.1.1.2.cmml">𝒳</mi><msup id="S5.F7.4.m2.1.1.3" xref="S5.F7.4.m2.1.1.3.cmml"><mi id="S5.F7.4.m2.1.1.3.2" xref="S5.F7.4.m2.1.1.3.2.cmml">NP</mi><mo id="S5.F7.4.m2.1.1.3.3" xref="S5.F7.4.m2.1.1.3.3.cmml">′</mo></msup></msub><annotation-xml encoding="MathML-Content" id="S5.F7.4.m2.1c"><apply id="S5.F7.4.m2.1.1.cmml" xref="S5.F7.4.m2.1.1"><csymbol cd="ambiguous" id="S5.F7.4.m2.1.1.1.cmml" xref="S5.F7.4.m2.1.1">subscript</csymbol><ci id="S5.F7.4.m2.1.1.2.cmml" xref="S5.F7.4.m2.1.1.2">𝒳</ci><apply id="S5.F7.4.m2.1.1.3.cmml" xref="S5.F7.4.m2.1.1.3"><csymbol cd="ambiguous" id="S5.F7.4.m2.1.1.3.1.cmml" xref="S5.F7.4.m2.1.1.3">superscript</csymbol><ci id="S5.F7.4.m2.1.1.3.2.cmml" xref="S5.F7.4.m2.1.1.3.2">NP</ci><ci id="S5.F7.4.m2.1.1.3.3.cmml" xref="S5.F7.4.m2.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.4.m2.1d">\mathcal{X}_{\operatorname{NP}^{\prime}}</annotation></semantics></math> contains all non-polar samples whose answers have the highest textual occurrences in polar questions.</figcaption>
</figure>
<div id="S5.SS0.SSS1.p2" class="ltx_para">
<p id="S5.SS0.SSS1.p2.5" class="ltx_p">To populate the subset <math id="S5.SS0.SSS1.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{X}_{\operatorname{NP}^{\prime}}" display="inline"><semantics id="S5.SS0.SSS1.p2.1.m1.1a"><msub id="S5.SS0.SSS1.p2.1.m1.1.1" xref="S5.SS0.SSS1.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS0.SSS1.p2.1.m1.1.1.2" xref="S5.SS0.SSS1.p2.1.m1.1.1.2.cmml">𝒳</mi><msup id="S5.SS0.SSS1.p2.1.m1.1.1.3" xref="S5.SS0.SSS1.p2.1.m1.1.1.3.cmml"><mi id="S5.SS0.SSS1.p2.1.m1.1.1.3.2" xref="S5.SS0.SSS1.p2.1.m1.1.1.3.2.cmml">NP</mi><mo id="S5.SS0.SSS1.p2.1.m1.1.1.3.3" xref="S5.SS0.SSS1.p2.1.m1.1.1.3.3.cmml">′</mo></msup></msub><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS1.p2.1.m1.1b"><apply id="S5.SS0.SSS1.p2.1.m1.1.1.cmml" xref="S5.SS0.SSS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p2.1.m1.1.1.1.cmml" xref="S5.SS0.SSS1.p2.1.m1.1.1">subscript</csymbol><ci id="S5.SS0.SSS1.p2.1.m1.1.1.2.cmml" xref="S5.SS0.SSS1.p2.1.m1.1.1.2">𝒳</ci><apply id="S5.SS0.SSS1.p2.1.m1.1.1.3.cmml" xref="S5.SS0.SSS1.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p2.1.m1.1.1.3.1.cmml" xref="S5.SS0.SSS1.p2.1.m1.1.1.3">superscript</csymbol><ci id="S5.SS0.SSS1.p2.1.m1.1.1.3.2.cmml" xref="S5.SS0.SSS1.p2.1.m1.1.1.3.2">NP</ci><ci id="S5.SS0.SSS1.p2.1.m1.1.1.3.3.cmml" xref="S5.SS0.SSS1.p2.1.m1.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS1.p2.1.m1.1c">\mathcal{X}_{\operatorname{NP}^{\prime}}</annotation></semantics></math>, we start by selecting polar questions in which any of the 3127 non-polar answers occur textually using a simple regular expression.
We then count the number of polar question occurrences for each non-polar answer (with replacement) and sort them in ascending order.
The resulting histogram is shown in Figure <a href="#S5.F7" title="Figure 7 ‣ V-1 Polar Questions About Non-Polar Concepts ‣ V Discussion ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.
The x-axis represents the 3127 non-polar answers and the y-axis represents the number of polar questions matching the non-polar answer.
We see that 73.87% of non-polar concepts are matched by at least 1 polar question.
To guarantee that each non-polar concept in the subset is covered by a large number of polar questions, we select the top 500 non-polar answers that occur the most often within polar questions (i.e., the 500 best covered non-polar answers) to assign non-polar samples to <math id="S5.SS0.SSS1.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{X}_{\operatorname{NP}^{\prime}}" display="inline"><semantics id="S5.SS0.SSS1.p2.2.m2.1a"><msub id="S5.SS0.SSS1.p2.2.m2.1.1" xref="S5.SS0.SSS1.p2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS0.SSS1.p2.2.m2.1.1.2" xref="S5.SS0.SSS1.p2.2.m2.1.1.2.cmml">𝒳</mi><msup id="S5.SS0.SSS1.p2.2.m2.1.1.3" xref="S5.SS0.SSS1.p2.2.m2.1.1.3.cmml"><mi id="S5.SS0.SSS1.p2.2.m2.1.1.3.2" xref="S5.SS0.SSS1.p2.2.m2.1.1.3.2.cmml">NP</mi><mo id="S5.SS0.SSS1.p2.2.m2.1.1.3.3" xref="S5.SS0.SSS1.p2.2.m2.1.1.3.3.cmml">′</mo></msup></msub><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS1.p2.2.m2.1b"><apply id="S5.SS0.SSS1.p2.2.m2.1.1.cmml" xref="S5.SS0.SSS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p2.2.m2.1.1.1.cmml" xref="S5.SS0.SSS1.p2.2.m2.1.1">subscript</csymbol><ci id="S5.SS0.SSS1.p2.2.m2.1.1.2.cmml" xref="S5.SS0.SSS1.p2.2.m2.1.1.2">𝒳</ci><apply id="S5.SS0.SSS1.p2.2.m2.1.1.3.cmml" xref="S5.SS0.SSS1.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p2.2.m2.1.1.3.1.cmml" xref="S5.SS0.SSS1.p2.2.m2.1.1.3">superscript</csymbol><ci id="S5.SS0.SSS1.p2.2.m2.1.1.3.2.cmml" xref="S5.SS0.SSS1.p2.2.m2.1.1.3.2">NP</ci><ci id="S5.SS0.SSS1.p2.2.m2.1.1.3.3.cmml" xref="S5.SS0.SSS1.p2.2.m2.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS1.p2.2.m2.1c">\mathcal{X}_{\operatorname{NP}^{\prime}}</annotation></semantics></math> (shown in blue in Figure <a href="#S5.F7" title="Figure 7 ‣ V-1 Polar Questions About Non-Polar Concepts ‣ V Discussion ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>).
Once <math id="S5.SS0.SSS1.p2.3.m3.1" class="ltx_Math" alttext="\mathcal{X}_{\operatorname{NP}^{\prime}}" display="inline"><semantics id="S5.SS0.SSS1.p2.3.m3.1a"><msub id="S5.SS0.SSS1.p2.3.m3.1.1" xref="S5.SS0.SSS1.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS0.SSS1.p2.3.m3.1.1.2" xref="S5.SS0.SSS1.p2.3.m3.1.1.2.cmml">𝒳</mi><msup id="S5.SS0.SSS1.p2.3.m3.1.1.3" xref="S5.SS0.SSS1.p2.3.m3.1.1.3.cmml"><mi id="S5.SS0.SSS1.p2.3.m3.1.1.3.2" xref="S5.SS0.SSS1.p2.3.m3.1.1.3.2.cmml">NP</mi><mo id="S5.SS0.SSS1.p2.3.m3.1.1.3.3" xref="S5.SS0.SSS1.p2.3.m3.1.1.3.3.cmml">′</mo></msup></msub><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS1.p2.3.m3.1b"><apply id="S5.SS0.SSS1.p2.3.m3.1.1.cmml" xref="S5.SS0.SSS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p2.3.m3.1.1.1.cmml" xref="S5.SS0.SSS1.p2.3.m3.1.1">subscript</csymbol><ci id="S5.SS0.SSS1.p2.3.m3.1.1.2.cmml" xref="S5.SS0.SSS1.p2.3.m3.1.1.2">𝒳</ci><apply id="S5.SS0.SSS1.p2.3.m3.1.1.3.cmml" xref="S5.SS0.SSS1.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p2.3.m3.1.1.3.1.cmml" xref="S5.SS0.SSS1.p2.3.m3.1.1.3">superscript</csymbol><ci id="S5.SS0.SSS1.p2.3.m3.1.1.3.2.cmml" xref="S5.SS0.SSS1.p2.3.m3.1.1.3.2">NP</ci><ci id="S5.SS0.SSS1.p2.3.m3.1.1.3.3.cmml" xref="S5.SS0.SSS1.p2.3.m3.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS1.p2.3.m3.1c">\mathcal{X}_{\operatorname{NP}^{\prime}}</annotation></semantics></math> (500 classes), and thereby <math id="S5.SS0.SSS1.p2.4.m4.1" class="ltx_Math" alttext="\overline{\mathcal{X}_{\operatorname{NP}^{\prime}}}" display="inline"><semantics id="S5.SS0.SSS1.p2.4.m4.1a"><mover accent="true" id="S5.SS0.SSS1.p2.4.m4.1.1" xref="S5.SS0.SSS1.p2.4.m4.1.1.cmml"><msub id="S5.SS0.SSS1.p2.4.m4.1.1.2" xref="S5.SS0.SSS1.p2.4.m4.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS0.SSS1.p2.4.m4.1.1.2.2" xref="S5.SS0.SSS1.p2.4.m4.1.1.2.2.cmml">𝒳</mi><msup id="S5.SS0.SSS1.p2.4.m4.1.1.2.3" xref="S5.SS0.SSS1.p2.4.m4.1.1.2.3.cmml"><mi id="S5.SS0.SSS1.p2.4.m4.1.1.2.3.2" xref="S5.SS0.SSS1.p2.4.m4.1.1.2.3.2.cmml">NP</mi><mo id="S5.SS0.SSS1.p2.4.m4.1.1.2.3.3" xref="S5.SS0.SSS1.p2.4.m4.1.1.2.3.3.cmml">′</mo></msup></msub><mo id="S5.SS0.SSS1.p2.4.m4.1.1.1" xref="S5.SS0.SSS1.p2.4.m4.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS1.p2.4.m4.1b"><apply id="S5.SS0.SSS1.p2.4.m4.1.1.cmml" xref="S5.SS0.SSS1.p2.4.m4.1.1"><ci id="S5.SS0.SSS1.p2.4.m4.1.1.1.cmml" xref="S5.SS0.SSS1.p2.4.m4.1.1.1">¯</ci><apply id="S5.SS0.SSS1.p2.4.m4.1.1.2.cmml" xref="S5.SS0.SSS1.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p2.4.m4.1.1.2.1.cmml" xref="S5.SS0.SSS1.p2.4.m4.1.1.2">subscript</csymbol><ci id="S5.SS0.SSS1.p2.4.m4.1.1.2.2.cmml" xref="S5.SS0.SSS1.p2.4.m4.1.1.2.2">𝒳</ci><apply id="S5.SS0.SSS1.p2.4.m4.1.1.2.3.cmml" xref="S5.SS0.SSS1.p2.4.m4.1.1.2.3"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p2.4.m4.1.1.2.3.1.cmml" xref="S5.SS0.SSS1.p2.4.m4.1.1.2.3">superscript</csymbol><ci id="S5.SS0.SSS1.p2.4.m4.1.1.2.3.2.cmml" xref="S5.SS0.SSS1.p2.4.m4.1.1.2.3.2">NP</ci><ci id="S5.SS0.SSS1.p2.4.m4.1.1.2.3.3.cmml" xref="S5.SS0.SSS1.p2.4.m4.1.1.2.3.3">′</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS1.p2.4.m4.1c">\overline{\mathcal{X}_{\operatorname{NP}^{\prime}}}</annotation></semantics></math> (2627 classes) have been defined, we use them to evaluate <math id="S5.SS0.SSS1.p2.5.m5.1" class="ltx_Math" alttext="f_{\operatorname{NP}}\circ\Phi_{\operatorname{P}}" display="inline"><semantics id="S5.SS0.SSS1.p2.5.m5.1a"><mrow id="S5.SS0.SSS1.p2.5.m5.1.1" xref="S5.SS0.SSS1.p2.5.m5.1.1.cmml"><msub id="S5.SS0.SSS1.p2.5.m5.1.1.2" xref="S5.SS0.SSS1.p2.5.m5.1.1.2.cmml"><mi id="S5.SS0.SSS1.p2.5.m5.1.1.2.2" xref="S5.SS0.SSS1.p2.5.m5.1.1.2.2.cmml">f</mi><mi id="S5.SS0.SSS1.p2.5.m5.1.1.2.3" xref="S5.SS0.SSS1.p2.5.m5.1.1.2.3.cmml">NP</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S5.SS0.SSS1.p2.5.m5.1.1.1" xref="S5.SS0.SSS1.p2.5.m5.1.1.1.cmml">∘</mo><msub id="S5.SS0.SSS1.p2.5.m5.1.1.3" xref="S5.SS0.SSS1.p2.5.m5.1.1.3.cmml"><mi mathvariant="normal" id="S5.SS0.SSS1.p2.5.m5.1.1.3.2" xref="S5.SS0.SSS1.p2.5.m5.1.1.3.2.cmml">Φ</mi><mi mathvariant="normal" id="S5.SS0.SSS1.p2.5.m5.1.1.3.3" xref="S5.SS0.SSS1.p2.5.m5.1.1.3.3.cmml">P</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS1.p2.5.m5.1b"><apply id="S5.SS0.SSS1.p2.5.m5.1.1.cmml" xref="S5.SS0.SSS1.p2.5.m5.1.1"><compose id="S5.SS0.SSS1.p2.5.m5.1.1.1.cmml" xref="S5.SS0.SSS1.p2.5.m5.1.1.1"></compose><apply id="S5.SS0.SSS1.p2.5.m5.1.1.2.cmml" xref="S5.SS0.SSS1.p2.5.m5.1.1.2"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p2.5.m5.1.1.2.1.cmml" xref="S5.SS0.SSS1.p2.5.m5.1.1.2">subscript</csymbol><ci id="S5.SS0.SSS1.p2.5.m5.1.1.2.2.cmml" xref="S5.SS0.SSS1.p2.5.m5.1.1.2.2">𝑓</ci><ci id="S5.SS0.SSS1.p2.5.m5.1.1.2.3.cmml" xref="S5.SS0.SSS1.p2.5.m5.1.1.2.3">NP</ci></apply><apply id="S5.SS0.SSS1.p2.5.m5.1.1.3.cmml" xref="S5.SS0.SSS1.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S5.SS0.SSS1.p2.5.m5.1.1.3.1.cmml" xref="S5.SS0.SSS1.p2.5.m5.1.1.3">subscript</csymbol><ci id="S5.SS0.SSS1.p2.5.m5.1.1.3.2.cmml" xref="S5.SS0.SSS1.p2.5.m5.1.1.3.2">Φ</ci><ci id="S5.SS0.SSS1.p2.5.m5.1.1.3.3.cmml" xref="S5.SS0.SSS1.p2.5.m5.1.1.3.3">P</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS1.p2.5.m5.1c">f_{\operatorname{NP}}\circ\Phi_{\operatorname{P}}</annotation></semantics></math> separately.
Results of this experiment are shown in Table <a href="#S5.T3" title="TABLE III ‣ V-1 Polar Questions About Non-Polar Concepts ‣ V Discussion ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Accuracy on a cross-polarity experiment where the base VQA feature extractor is either pre-trained on <math id="S5.T3.4.m1.1" class="ltx_Math" alttext="\mathcal{X}_{\operatorname{P}^{\prime}}" display="inline"><semantics id="S5.T3.4.m1.1b"><msub id="S5.T3.4.m1.1.1" xref="S5.T3.4.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.T3.4.m1.1.1.2" xref="S5.T3.4.m1.1.1.2.cmml">𝒳</mi><msup id="S5.T3.4.m1.1.1.3" xref="S5.T3.4.m1.1.1.3.cmml"><mi mathvariant="normal" id="S5.T3.4.m1.1.1.3.2" xref="S5.T3.4.m1.1.1.3.2.cmml">P</mi><mo id="S5.T3.4.m1.1.1.3.3" xref="S5.T3.4.m1.1.1.3.3.cmml">′</mo></msup></msub><annotation-xml encoding="MathML-Content" id="S5.T3.4.m1.1c"><apply id="S5.T3.4.m1.1.1.cmml" xref="S5.T3.4.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.4.m1.1.1.1.cmml" xref="S5.T3.4.m1.1.1">subscript</csymbol><ci id="S5.T3.4.m1.1.1.2.cmml" xref="S5.T3.4.m1.1.1.2">𝒳</ci><apply id="S5.T3.4.m1.1.1.3.cmml" xref="S5.T3.4.m1.1.1.3"><csymbol cd="ambiguous" id="S5.T3.4.m1.1.1.3.1.cmml" xref="S5.T3.4.m1.1.1.3">superscript</csymbol><ci id="S5.T3.4.m1.1.1.3.2.cmml" xref="S5.T3.4.m1.1.1.3.2">P</ci><ci id="S5.T3.4.m1.1.1.3.3.cmml" xref="S5.T3.4.m1.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.m1.1d">\mathcal{X}_{\operatorname{P}^{\prime}}</annotation></semantics></math> (the set of polar questions matching the 500 non-polar concepts) or <math id="S5.T3.5.m2.1" class="ltx_Math" alttext="\overline{\mathcal{X}_{\operatorname{P}^{\prime}}}" display="inline"><semantics id="S5.T3.5.m2.1b"><mover accent="true" id="S5.T3.5.m2.1.1" xref="S5.T3.5.m2.1.1.cmml"><msub id="S5.T3.5.m2.1.1.2" xref="S5.T3.5.m2.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.T3.5.m2.1.1.2.2" xref="S5.T3.5.m2.1.1.2.2.cmml">𝒳</mi><msup id="S5.T3.5.m2.1.1.2.3" xref="S5.T3.5.m2.1.1.2.3.cmml"><mi mathvariant="normal" id="S5.T3.5.m2.1.1.2.3.2" xref="S5.T3.5.m2.1.1.2.3.2.cmml">P</mi><mo id="S5.T3.5.m2.1.1.2.3.3" xref="S5.T3.5.m2.1.1.2.3.3.cmml">′</mo></msup></msub><mo id="S5.T3.5.m2.1.1.1" xref="S5.T3.5.m2.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S5.T3.5.m2.1c"><apply id="S5.T3.5.m2.1.1.cmml" xref="S5.T3.5.m2.1.1"><ci id="S5.T3.5.m2.1.1.1.cmml" xref="S5.T3.5.m2.1.1.1">¯</ci><apply id="S5.T3.5.m2.1.1.2.cmml" xref="S5.T3.5.m2.1.1.2"><csymbol cd="ambiguous" id="S5.T3.5.m2.1.1.2.1.cmml" xref="S5.T3.5.m2.1.1.2">subscript</csymbol><ci id="S5.T3.5.m2.1.1.2.2.cmml" xref="S5.T3.5.m2.1.1.2.2">𝒳</ci><apply id="S5.T3.5.m2.1.1.2.3.cmml" xref="S5.T3.5.m2.1.1.2.3"><csymbol cd="ambiguous" id="S5.T3.5.m2.1.1.2.3.1.cmml" xref="S5.T3.5.m2.1.1.2.3">superscript</csymbol><ci id="S5.T3.5.m2.1.1.2.3.2.cmml" xref="S5.T3.5.m2.1.1.2.3.2">P</ci><ci id="S5.T3.5.m2.1.1.2.3.3.cmml" xref="S5.T3.5.m2.1.1.2.3.3">′</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.5.m2.1d">\overline{\mathcal{X}_{\operatorname{P}^{\prime}}}</annotation></semantics></math> (the complement of <math id="S5.T3.6.m3.1" class="ltx_Math" alttext="\mathcal{X}_{\operatorname{P}^{\prime}}" display="inline"><semantics id="S5.T3.6.m3.1b"><msub id="S5.T3.6.m3.1.1" xref="S5.T3.6.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.T3.6.m3.1.1.2" xref="S5.T3.6.m3.1.1.2.cmml">𝒳</mi><msup id="S5.T3.6.m3.1.1.3" xref="S5.T3.6.m3.1.1.3.cmml"><mi mathvariant="normal" id="S5.T3.6.m3.1.1.3.2" xref="S5.T3.6.m3.1.1.3.2.cmml">P</mi><mo id="S5.T3.6.m3.1.1.3.3" xref="S5.T3.6.m3.1.1.3.3.cmml">′</mo></msup></msub><annotation-xml encoding="MathML-Content" id="S5.T3.6.m3.1c"><apply id="S5.T3.6.m3.1.1.cmml" xref="S5.T3.6.m3.1.1"><csymbol cd="ambiguous" id="S5.T3.6.m3.1.1.1.cmml" xref="S5.T3.6.m3.1.1">subscript</csymbol><ci id="S5.T3.6.m3.1.1.2.cmml" xref="S5.T3.6.m3.1.1.2">𝒳</ci><apply id="S5.T3.6.m3.1.1.3.cmml" xref="S5.T3.6.m3.1.1.3"><csymbol cd="ambiguous" id="S5.T3.6.m3.1.1.3.1.cmml" xref="S5.T3.6.m3.1.1.3">superscript</csymbol><ci id="S5.T3.6.m3.1.1.3.2.cmml" xref="S5.T3.6.m3.1.1.3.2">P</ci><ci id="S5.T3.6.m3.1.1.3.3.cmml" xref="S5.T3.6.m3.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.m3.1d">\mathcal{X}_{\operatorname{P}^{\prime}}</annotation></semantics></math>).</figcaption>
<table id="S5.T3.15" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T3.15.10.1" class="ltx_tr">
<th id="S5.T3.15.10.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Task</th>
<th id="S5.T3.15.10.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">Model</th>
<th id="S5.T3.15.10.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Input</th>
<th id="S5.T3.15.10.1.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt">Accuracy</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T3.9.3" class="ltx_tr">
<td id="S5.T3.9.3.4" class="ltx_td"></td>
<th id="S5.T3.7.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><math id="S5.T3.7.1.1.m1.1" class="ltx_Math" alttext="\Phi" display="inline"><semantics id="S5.T3.7.1.1.m1.1a"><mi mathvariant="normal" id="S5.T3.7.1.1.m1.1.1" xref="S5.T3.7.1.1.m1.1.1.cmml">Φ</mi><annotation-xml encoding="MathML-Content" id="S5.T3.7.1.1.m1.1b"><ci id="S5.T3.7.1.1.m1.1.1.cmml" xref="S5.T3.7.1.1.m1.1.1">Φ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.7.1.1.m1.1c">\Phi</annotation></semantics></math></th>
<th id="S5.T3.8.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><math id="S5.T3.8.2.2.m1.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S5.T3.8.2.2.m1.1a"><mi id="S5.T3.8.2.2.m1.1.1" xref="S5.T3.8.2.2.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S5.T3.8.2.2.m1.1b"><ci id="S5.T3.8.2.2.m1.1.1.cmml" xref="S5.T3.8.2.2.m1.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.8.2.2.m1.1c">f</annotation></semantics></math></th>
<th id="S5.T3.9.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_column"><math id="S5.T3.9.3.3.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S5.T3.9.3.3.m1.1a"><mi id="S5.T3.9.3.3.m1.1.1" xref="S5.T3.9.3.3.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S5.T3.9.3.3.m1.1b"><ci id="S5.T3.9.3.3.m1.1.1.cmml" xref="S5.T3.9.3.3.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.9.3.3.m1.1c">x</annotation></semantics></math></th>
<td id="S5.T3.9.3.5" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S5.T3.12.6" class="ltx_tr">
<td id="S5.T3.12.6.4" class="ltx_td ltx_align_left ltx_border_t">Cross-Polarity</td>
<td id="S5.T3.10.4.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S5.T3.10.4.1.m1.1" class="ltx_Math" alttext="\operatorname{P}" display="inline"><semantics id="S5.T3.10.4.1.m1.1a"><mi mathvariant="normal" id="S5.T3.10.4.1.m1.1.1" xref="S5.T3.10.4.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S5.T3.10.4.1.m1.1b"><ci id="S5.T3.10.4.1.m1.1.1.cmml" xref="S5.T3.10.4.1.m1.1.1">P</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.10.4.1.m1.1c">\operatorname{P}</annotation></semantics></math></td>
<td id="S5.T3.11.5.2" class="ltx_td ltx_align_left ltx_border_t"><math id="S5.T3.11.5.2.m1.1" class="ltx_Math" alttext="\operatorname{NP}" display="inline"><semantics id="S5.T3.11.5.2.m1.1a"><mi id="S5.T3.11.5.2.m1.1.1" xref="S5.T3.11.5.2.m1.1.1.cmml">NP</mi><annotation-xml encoding="MathML-Content" id="S5.T3.11.5.2.m1.1b"><ci id="S5.T3.11.5.2.m1.1.1.cmml" xref="S5.T3.11.5.2.m1.1.1">NP</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.11.5.2.m1.1c">\operatorname{NP}</annotation></semantics></math></td>
<td id="S5.T3.12.6.3" class="ltx_td ltx_align_left ltx_border_t"><math id="S5.T3.12.6.3.m1.1" class="ltx_Math" alttext="\operatorname{NP}^{\prime}" display="inline"><semantics id="S5.T3.12.6.3.m1.1a"><msup id="S5.T3.12.6.3.m1.1.1" xref="S5.T3.12.6.3.m1.1.1.cmml"><mi id="S5.T3.12.6.3.m1.1.1.2" xref="S5.T3.12.6.3.m1.1.1.2.cmml">NP</mi><mo id="S5.T3.12.6.3.m1.1.1.3" xref="S5.T3.12.6.3.m1.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S5.T3.12.6.3.m1.1b"><apply id="S5.T3.12.6.3.m1.1.1.cmml" xref="S5.T3.12.6.3.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.12.6.3.m1.1.1.1.cmml" xref="S5.T3.12.6.3.m1.1.1">superscript</csymbol><ci id="S5.T3.12.6.3.m1.1.1.2.cmml" xref="S5.T3.12.6.3.m1.1.1.2">NP</ci><ci id="S5.T3.12.6.3.m1.1.1.3.cmml" xref="S5.T3.12.6.3.m1.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.12.6.3.m1.1c">\operatorname{NP}^{\prime}</annotation></semantics></math></td>
<td id="S5.T3.12.6.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">0.40</td>
</tr>
<tr id="S5.T3.15.9" class="ltx_tr">
<td id="S5.T3.15.9.4" class="ltx_td ltx_border_bb"></td>
<td id="S5.T3.13.7.1" class="ltx_td ltx_align_left ltx_border_bb"><math id="S5.T3.13.7.1.m1.1" class="ltx_Math" alttext="\operatorname{P}" display="inline"><semantics id="S5.T3.13.7.1.m1.1a"><mi mathvariant="normal" id="S5.T3.13.7.1.m1.1.1" xref="S5.T3.13.7.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S5.T3.13.7.1.m1.1b"><ci id="S5.T3.13.7.1.m1.1.1.cmml" xref="S5.T3.13.7.1.m1.1.1">P</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.13.7.1.m1.1c">\operatorname{P}</annotation></semantics></math></td>
<td id="S5.T3.14.8.2" class="ltx_td ltx_align_left ltx_border_bb"><math id="S5.T3.14.8.2.m1.1" class="ltx_Math" alttext="\operatorname{NP}" display="inline"><semantics id="S5.T3.14.8.2.m1.1a"><mi id="S5.T3.14.8.2.m1.1.1" xref="S5.T3.14.8.2.m1.1.1.cmml">NP</mi><annotation-xml encoding="MathML-Content" id="S5.T3.14.8.2.m1.1b"><ci id="S5.T3.14.8.2.m1.1.1.cmml" xref="S5.T3.14.8.2.m1.1.1">NP</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.14.8.2.m1.1c">\operatorname{NP}</annotation></semantics></math></td>
<td id="S5.T3.15.9.3" class="ltx_td ltx_align_left ltx_border_bb"><math id="S5.T3.15.9.3.m1.1" class="ltx_Math" alttext="\overline{\operatorname{NP}^{\prime}}" display="inline"><semantics id="S5.T3.15.9.3.m1.1a"><mover accent="true" id="S5.T3.15.9.3.m1.1.1" xref="S5.T3.15.9.3.m1.1.1.cmml"><msup id="S5.T3.15.9.3.m1.1.1.2" xref="S5.T3.15.9.3.m1.1.1.2.cmml"><mi id="S5.T3.15.9.3.m1.1.1.2.2" xref="S5.T3.15.9.3.m1.1.1.2.2.cmml">NP</mi><mo id="S5.T3.15.9.3.m1.1.1.2.3" xref="S5.T3.15.9.3.m1.1.1.2.3.cmml">′</mo></msup><mo id="S5.T3.15.9.3.m1.1.1.1" xref="S5.T3.15.9.3.m1.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S5.T3.15.9.3.m1.1b"><apply id="S5.T3.15.9.3.m1.1.1.cmml" xref="S5.T3.15.9.3.m1.1.1"><ci id="S5.T3.15.9.3.m1.1.1.1.cmml" xref="S5.T3.15.9.3.m1.1.1.1">¯</ci><apply id="S5.T3.15.9.3.m1.1.1.2.cmml" xref="S5.T3.15.9.3.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T3.15.9.3.m1.1.1.2.1.cmml" xref="S5.T3.15.9.3.m1.1.1.2">superscript</csymbol><ci id="S5.T3.15.9.3.m1.1.1.2.2.cmml" xref="S5.T3.15.9.3.m1.1.1.2.2">NP</ci><ci id="S5.T3.15.9.3.m1.1.1.2.3.cmml" xref="S5.T3.15.9.3.m1.1.1.2.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.15.9.3.m1.1c">\overline{\operatorname{NP}^{\prime}}</annotation></semantics></math></td>
<td id="S5.T3.15.9.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">0.14</td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.SS0.SSS1.p3" class="ltx_para">
<p id="S5.SS0.SSS1.p3.4" class="ltx_p">When evaluating the polar feature space w.r.t. well-covered non-polar questions, the VQA model exhibits an ample improvement (from <math id="S5.SS0.SSS1.p3.1.m1.1" class="ltx_Math" alttext="28.7\,\%" display="inline"><semantics id="S5.SS0.SSS1.p3.1.m1.1a"><mrow id="S5.SS0.SSS1.p3.1.m1.1.1" xref="S5.SS0.SSS1.p3.1.m1.1.1.cmml"><mn id="S5.SS0.SSS1.p3.1.m1.1.1.2" xref="S5.SS0.SSS1.p3.1.m1.1.1.2.cmml">28.7</mn><mo lspace="0.170em" id="S5.SS0.SSS1.p3.1.m1.1.1.1" xref="S5.SS0.SSS1.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS1.p3.1.m1.1b"><apply id="S5.SS0.SSS1.p3.1.m1.1.1.cmml" xref="S5.SS0.SSS1.p3.1.m1.1.1"><csymbol cd="latexml" id="S5.SS0.SSS1.p3.1.m1.1.1.1.cmml" xref="S5.SS0.SSS1.p3.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.SS0.SSS1.p3.1.m1.1.1.2.cmml" xref="S5.SS0.SSS1.p3.1.m1.1.1.2">28.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS1.p3.1.m1.1c">28.7\,\%</annotation></semantics></math> to <math id="S5.SS0.SSS1.p3.2.m2.1" class="ltx_Math" alttext="40\,\%" display="inline"><semantics id="S5.SS0.SSS1.p3.2.m2.1a"><mrow id="S5.SS0.SSS1.p3.2.m2.1.1" xref="S5.SS0.SSS1.p3.2.m2.1.1.cmml"><mn id="S5.SS0.SSS1.p3.2.m2.1.1.2" xref="S5.SS0.SSS1.p3.2.m2.1.1.2.cmml">40</mn><mo lspace="0.170em" id="S5.SS0.SSS1.p3.2.m2.1.1.1" xref="S5.SS0.SSS1.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS1.p3.2.m2.1b"><apply id="S5.SS0.SSS1.p3.2.m2.1.1.cmml" xref="S5.SS0.SSS1.p3.2.m2.1.1"><csymbol cd="latexml" id="S5.SS0.SSS1.p3.2.m2.1.1.1.cmml" xref="S5.SS0.SSS1.p3.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S5.SS0.SSS1.p3.2.m2.1.1.2.cmml" xref="S5.SS0.SSS1.p3.2.m2.1.1.2">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS1.p3.2.m2.1c">40\,\%</annotation></semantics></math>) compared to the initial cross-polar experiment from Section <a href="#S4" title="IV Results ‣ P ≈ NP, at least in Visual Question Answering This work was supported by NVIDIA’s NVAIL program and the BMBF project DeFuseNN (Grant 01IW17002)" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>.
These results are in turn, closer to the upper bound of non-polar questions that can be answered with the VQA model used throughout all experiments.
In contrast, the polar feature space of poorly covered non-polar concepts presents a steep decrease in accuracy, from <math id="S5.SS0.SSS1.p3.3.m3.1" class="ltx_Math" alttext="28.7\,\%" display="inline"><semantics id="S5.SS0.SSS1.p3.3.m3.1a"><mrow id="S5.SS0.SSS1.p3.3.m3.1.1" xref="S5.SS0.SSS1.p3.3.m3.1.1.cmml"><mn id="S5.SS0.SSS1.p3.3.m3.1.1.2" xref="S5.SS0.SSS1.p3.3.m3.1.1.2.cmml">28.7</mn><mo lspace="0.170em" id="S5.SS0.SSS1.p3.3.m3.1.1.1" xref="S5.SS0.SSS1.p3.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS1.p3.3.m3.1b"><apply id="S5.SS0.SSS1.p3.3.m3.1.1.cmml" xref="S5.SS0.SSS1.p3.3.m3.1.1"><csymbol cd="latexml" id="S5.SS0.SSS1.p3.3.m3.1.1.1.cmml" xref="S5.SS0.SSS1.p3.3.m3.1.1.1">percent</csymbol><cn type="float" id="S5.SS0.SSS1.p3.3.m3.1.1.2.cmml" xref="S5.SS0.SSS1.p3.3.m3.1.1.2">28.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS1.p3.3.m3.1c">28.7\,\%</annotation></semantics></math> to <math id="S5.SS0.SSS1.p3.4.m4.1" class="ltx_Math" alttext="14\,\%" display="inline"><semantics id="S5.SS0.SSS1.p3.4.m4.1a"><mrow id="S5.SS0.SSS1.p3.4.m4.1.1" xref="S5.SS0.SSS1.p3.4.m4.1.1.cmml"><mn id="S5.SS0.SSS1.p3.4.m4.1.1.2" xref="S5.SS0.SSS1.p3.4.m4.1.1.2.cmml">14</mn><mo lspace="0.170em" id="S5.SS0.SSS1.p3.4.m4.1.1.1" xref="S5.SS0.SSS1.p3.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS1.p3.4.m4.1b"><apply id="S5.SS0.SSS1.p3.4.m4.1.1.cmml" xref="S5.SS0.SSS1.p3.4.m4.1.1"><csymbol cd="latexml" id="S5.SS0.SSS1.p3.4.m4.1.1.1.cmml" xref="S5.SS0.SSS1.p3.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S5.SS0.SSS1.p3.4.m4.1.1.2.cmml" xref="S5.SS0.SSS1.p3.4.m4.1.1.2">14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS1.p3.4.m4.1c">14\,\%</annotation></semantics></math>.
These results give a strong indication that non-polar questions can be answered by using a feature space based on polar samples.
The caveat is, quite naturally, that the set of polar questions used for training, has to convey enough semantics about the corresponding non-polar questions.</p>
</div>
<div id="S5.SS0.SSS1.p4" class="ltx_para">
<p id="S5.SS0.SSS1.p4.1" class="ltx_p">In light of these results, we construct a logical argument, where a sufficient condition for modeling a non-polar questions with a polar feature space depends on having polar questions that deal with the corresponding non-polar concepts.
Therefore, we arrive at the conclusion that the polar feature space <span id="S5.SS0.SSS1.p4.1.1" class="ltx_text ltx_font_italic">can</span> carry an equivalent semantic value as the non-polar feature space, hence <math id="S5.SS0.SSS1.p4.1.m1.1" class="ltx_Math" alttext="\operatorname{P}\approx\operatorname{NP}" display="inline"><semantics id="S5.SS0.SSS1.p4.1.m1.1a"><mrow id="S5.SS0.SSS1.p4.1.m1.1.1" xref="S5.SS0.SSS1.p4.1.m1.1.1.cmml"><mi mathvariant="normal" id="S5.SS0.SSS1.p4.1.m1.1.1.2" xref="S5.SS0.SSS1.p4.1.m1.1.1.2.cmml">P</mi><mo id="S5.SS0.SSS1.p4.1.m1.1.1.1" xref="S5.SS0.SSS1.p4.1.m1.1.1.1.cmml">≈</mo><mi id="S5.SS0.SSS1.p4.1.m1.1.1.3" xref="S5.SS0.SSS1.p4.1.m1.1.1.3.cmml">NP</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS1.p4.1.m1.1b"><apply id="S5.SS0.SSS1.p4.1.m1.1.1.cmml" xref="S5.SS0.SSS1.p4.1.m1.1.1"><approx id="S5.SS0.SSS1.p4.1.m1.1.1.1.cmml" xref="S5.SS0.SSS1.p4.1.m1.1.1.1"></approx><ci id="S5.SS0.SSS1.p4.1.m1.1.1.2.cmml" xref="S5.SS0.SSS1.p4.1.m1.1.1.2">P</ci><ci id="S5.SS0.SSS1.p4.1.m1.1.1.3.cmml" xref="S5.SS0.SSS1.p4.1.m1.1.1.3">NP</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS1.p4.1.m1.1c">\operatorname{P}\approx\operatorname{NP}</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion and Future Work</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this paper, we have presented an in-depth evaluation of the influence that polar and non-polar questions exert on each other when used jointly for training a VQA system.
The over-representation of polar samples w.r.t. the non-polar counterparts poses two main questions which we developed throughout this work: (1) Are there any source of bias stemming from the polar and non-polar imbalance and (2) what relationship exists between polar and non-polar samples when projected into the joint feature space that they are usually represented in?</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">On the first question, we found no confounding factors from the imbalance of polar and non-polar questions, and thereby no detrimental source of bias which may require special attention by doing class weighting or mini-batch re-sampling.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.3" class="ltx_p">On the second question, we establish a clear correlation between the distribution of polar and non-polar feature embeddings.
We show that polar features can be used to answer non-polar questions, provided that the polar questions used for training refer to the semantic concepts being considered in the non-polar questions.
Based on these findings we conclude that the space of polar features (<math id="S6.p3.1.m1.1" class="ltx_Math" alttext="\operatorname{P}" display="inline"><semantics id="S6.p3.1.m1.1a"><mi mathvariant="normal" id="S6.p3.1.m1.1.1" xref="S6.p3.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S6.p3.1.m1.1b"><ci id="S6.p3.1.m1.1.1.cmml" xref="S6.p3.1.m1.1.1">P</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.1.m1.1c">\operatorname{P}</annotation></semantics></math>) provides a rich semantic structure, similar to that of the non-polar counterparts (<math id="S6.p3.2.m2.1" class="ltx_Math" alttext="\operatorname{NP}" display="inline"><semantics id="S6.p3.2.m2.1a"><mi id="S6.p3.2.m2.1.1" xref="S6.p3.2.m2.1.1.cmml">NP</mi><annotation-xml encoding="MathML-Content" id="S6.p3.2.m2.1b"><ci id="S6.p3.2.m2.1.1.cmml" xref="S6.p3.2.m2.1.1">NP</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.2.m2.1c">\operatorname{NP}</annotation></semantics></math>).
We use the expression <math id="S6.p3.3.m3.1" class="ltx_Math" alttext="\operatorname{P}\approx\operatorname{NP}" display="inline"><semantics id="S6.p3.3.m3.1a"><mrow id="S6.p3.3.m3.1.1" xref="S6.p3.3.m3.1.1.cmml"><mi mathvariant="normal" id="S6.p3.3.m3.1.1.2" xref="S6.p3.3.m3.1.1.2.cmml">P</mi><mo id="S6.p3.3.m3.1.1.1" xref="S6.p3.3.m3.1.1.1.cmml">≈</mo><mi id="S6.p3.3.m3.1.1.3" xref="S6.p3.3.m3.1.1.3.cmml">NP</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.p3.3.m3.1b"><apply id="S6.p3.3.m3.1.1.cmml" xref="S6.p3.3.m3.1.1"><approx id="S6.p3.3.m3.1.1.1.cmml" xref="S6.p3.3.m3.1.1.1"></approx><ci id="S6.p3.3.m3.1.1.2.cmml" xref="S6.p3.3.m3.1.1.2">P</ci><ci id="S6.p3.3.m3.1.1.3.cmml" xref="S6.p3.3.m3.1.1.3">NP</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.3.m3.1c">\operatorname{P}\approx\operatorname{NP}</annotation></semantics></math> to refer to this alignment.</p>
</div>
<section id="S6.SS0.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S6.SS0.SSS1.5.1.1" class="ltx_text">VI-</span>1 </span>Future Work</h4>

<div id="S6.SS0.SSS1.p1" class="ltx_para">
<p id="S6.SS0.SSS1.p1.1" class="ltx_p">the results of this work indicate that the problem of visual question answering for non-polar concepts can be solved using polar questions, as long as polar questions cover the relevant non-polar topics.
We are interested in measuring the empirical extent by which this phenomenon holds.
The usefulness of a feature space based on polar samples for answering non-polar questions is not only surprising, but also potentially ground-breaking because it can change the way future VQA datasets are compiled.
Given the reduced cost of collecting polar questions (compared to non-polar questions), crowd sourcing efforts to amass a critical amount of polar questions for VQA 2.0 could benefit from our findings.
This will allow us to bridge the gap between non-polar concepts that are not well covered by polar questions and complement today’s training data.
We also want to explore automatic means to turn non-polar questions into polar ones using natural-language-processing tools.</p>
</div>
<div id="S6.SS0.SSS1.p2" class="ltx_para">
<p id="S6.SS0.SSS1.p2.1" class="ltx_p">Furthermore, we are interested in measuring the extent to which a growing number of non-polar concepts can be modeled in the joint visual-text space by only using polar input samples.
Therefore, an arbitrary number of concepts could be explicitly imposed in the joint feature space while keeping a fixed 2-dimensional classification objective.
This training regime, resembles the conditions of generative adversarial networks (GANs), and could open the possibility to learn new classes over time, which has potential applications in the field of continuous learning.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"> Anderson, Peter, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen Gould, and Lei Zhang. ”Bottom-up and top-down attention for image captioning and visual question answering.” In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6077-6086. 2018.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"> Teney, Damien, Peter Anderson, Xiaodong He, and Anton van den Hengel. ”Tips and tricks for visual question answering: Learnings from the 2017 challenge.” In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4223-4232. 2018.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"> Antol, Stanislaw, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C. Lawrence Zitnick, and Devi Parikh. ”Vqa: Visual question answering.” In Proceedings of the IEEE international conference on computer vision, pp. 2425-2433. 2015.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"> Agrawal, Aishwarya, Dhruv Batra, Devi Parikh, and Aniruddha Kembhavi. ”Don’t just assume; look and answer: Overcoming priors for visual question answering.” In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4971-4980. 2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"> Ramakrishnan, Sainandan, Aishwarya Agrawal, and Stefan Lee. ”Overcoming language priors in visual question answering with adversarial regularization.” In Advances in Neural Information Processing Systems, pp. 1541-1551. 2018.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"> Zhao, Jieyu, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. ”Men also like shopping: Reducing gender bias amplification using corpus-level constraints.” arXiv preprint arXiv:1707.09457 (2017).

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"> Agrawal, Aishwarya, Aniruddha Kembhavi, Dhruv Batra, and Devi Parikh. ”C-vqa: A compositional split of the visual question answering (vqa) v1. 0 dataset.” arXiv preprint arXiv:1704.08243 (2017).

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"> Lin, Tsung-Yi, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollár. ”Focal loss for dense object detection.” In Proceedings of the IEEE international conference on computer vision, pp. 2980-2988. 2017.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"> Kafle, Kushal, and Christopher Kanan. ”An analysis of visual question answering algorithms.” In Proceedings of the IEEE International Conference on Computer Vision, pp. 1965-1973. 2017.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"> Krishna, Ranjay, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua Kravitz, Stephanie Chen et al. ”Visual genome: Connecting language and vision using crowdsourced dense image annotations.” International Journal of Computer Vision 123, no. 1 (2017): 32-73.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"> Johnson, Justin, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C. Lawrence Zitnick, and Ross Girshick. ”Clevr: A diagnostic dataset for compositional language and elementary visual reasoning.” In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2901-2910. 2017.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"> Suhr, Alane, Mike Lewis, James Yeh, and Yoav Artzi. ”A corpus of natural language for visual reasoning.” In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pp. 217-223. 2017.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"> Zhang, Peng, Yash Goyal, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh. ”Yin and yang: Balancing and answering binary visual questions.” In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5014-5022. 2016.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"> Zhu, Yuke, Oliver Groth, Michael Bernstein, and Li Fei-Fei. ”Visual7w: Grounded question answering in images.” In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4995-5004. 2016.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"> Andreas, Jacob, Marcus Rohrbach, Trevor Darrell, and Dan Klein. ”Neural module networks.” In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 39-48. 2016.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"> Lin, Tsung-Yi, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C. Lawrence Zitnick. ”Microsoft coco: Common objects in context.” In European conference on computer vision, pp. 740-755. Springer, Cham, 2014.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"> Kingma, Diederik P., and Jimmy Ba. ”Adam: A method for stochastic optimization.” arXiv preprint arXiv:1412.6980 (2014).

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2003.11843" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2003.11844" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2003.11844">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2003.11844" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2003.11845" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Mar 17 07:49:05 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
