<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2108.07960] SynFace: Face Recognition with Synthetic Data</title><meta property="og:description" content="With the recent success of deep neural networks, remarkable progress has been achieved on face recognition. However, collecting large-scale real-world training data for face recognition has turned out to be challengingâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SynFace: Face Recognition with Synthetic Data">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="SynFace: Face Recognition with Synthetic Data">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2108.07960">

<!--Generated on Tue Mar 19 10:33:40 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">SynFace: Face Recognition with Synthetic Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Haibo Qiu<sup id="id10.10.id1" class="ltx_sup"><span id="id10.10.id1.1" class="ltx_text ltx_font_italic">1</span></sup>, Â Baosheng Yu<sup id="id11.11.id2" class="ltx_sup"><span id="id11.11.id2.1" class="ltx_text ltx_font_italic">2</span></sup><span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>, Â Dihong Gong<sup id="id12.12.id3" class="ltx_sup">3</sup>, Â Zhifeng Li<sup id="id13.13.id4" class="ltx_sup">3</sup>, Â Wei Liu<sup id="id14.14.id5" class="ltx_sup">3</sup>, Â Dacheng Tao<sup id="id15.15.id6" class="ltx_sup"><span id="id15.15.id6.1" class="ltx_text ltx_font_italic">1,2</span></sup>
<br class="ltx_break"><sup id="id16.16.id7" class="ltx_sup">1</sup> JD Explore Academy, China â€ƒ<sup id="id17.17.id8" class="ltx_sup">2</sup> The University of Sydney, Australia 
<br class="ltx_break"><sup id="id18.18.id9" class="ltx_sup">3</sup> Tencent Data Platform, China
<br class="ltx_break"><span id="id19.19.id10" class="ltx_text ltx_font_typewriter" style="font-size:90%;">qiuhaibo1@jd.com, baosheng.yu@sydney.edu.au, gongdihong@gmail.com,</span> 
<br class="ltx_break"><span id="id20.20.id11" class="ltx_text ltx_font_typewriter" style="font-size:90%;">michaelzfli@tencent.com, wl2223@columbia.edu, dacheng.tao@gmail.com</span>

</span><span class="ltx_author_notes">Equal contribution</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id21.id1" class="ltx_p">With the recent success of deep neural networks, remarkable progress has been achieved on face recognition. However, collecting large-scale real-world training data for face recognition has turned out to be challenging, especially due to the label noise and privacy issues. Meanwhile, existing face recognition datasets are usually collected from web images, lacking detailed annotations on attributes (e.g., pose and expression), so the influences of different attributes on face recognition have been poorly investigated. In this paper, we address the above-mentioned issues in face recognition using synthetic face images, i.e., SynFace. Specifically, we first explore the performance gap between recent state-of-the-art face recognition models trained with synthetic and real face images. We then analyze the underlying causes behind the performance gap, e.g., the poor intra-class variations and the domain gap between synthetic and real face images. Inspired by this, we devise the SynFace with identity mixup (IM) and domain mixup (DM) to mitigate the above performance gap, demonstrating the great potentials of synthetic data for face recognition. Furthermore, with the controllable face synthesis model, we can easily manage different factors of synthetic face generation, including pose, expression, illumination, the number of identities, and samples per identity. Therefore, we also perform a systematically empirical analysis on synthetic face images to provide some insights on how to effectively utilize synthetic data for face recognition. Code is available at <a target="_blank" href="https://github.com/haibo-qiu/SynFace" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/haibo-qiu/SynFace</a></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<figure id="S1.F1" class="ltx_figure"><img src="/html/2108.07960/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="180" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Examples of real/synthetic face images. The first row indicates real face images from CASIA-WebFace, and the second row shows synthetic face images generated by DiscoFaceGANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> with the proposed identity mixup module.</figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In the last few years, face recognition has achieved extraordinary progress in a wide range of challenging problems including pose-robust face recognitionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>, matching faces across agesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>, across modalitiesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, and occlusionsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>. Among these progresses, not only the very deep neural networksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> and sophisticated design of loss functionsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>, but also large-scale training datasetsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> played important roles. However, it has turned out to be very difficult to further boost the performance of face recognition with the increasing number of training images collected from the Internet, especially due to the severe label noise and privacy issuesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>. For example, several large-scale face recognition datasets are struggling with the consent of all involved person/identities, or even have to close the access of face data from the websiteÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. Meanwhile, many face training datasets also suffer from the long-tailed problem, <em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S1.p1.1.2" class="ltx_text"></span>, head classes with a large number of samples and tail classes with a few number of samplesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>. To utilize these datasets for face recognition, people need to carefully design the network architectures and/or loss functions to alleviate the degradation on model generalizability brought by the long-tailed problem. Furthermore, the above-mentioned issues also make it difficult for people to explore the influences of different attributes (<em id="S1.p1.1.3" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S1.p1.1.4" class="ltx_text"></span>, expression, pose and illumination).</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To address the aforementioned issues, we explore the potentials of synthetic images for face recognition in this paper. Recently, face synthesis using GANsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> and 3DMMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> have received increasing attention from the computer vision community, and existing methods usually focus on generating high-quality identity-preserving face imagesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>. Some synthetic and real face images are demonstrated in FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. However, the problem of face recognition using synthetic face images has not been well-investigatedÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>. Specifically, Trigueros <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S1.p2.1.2" class="ltx_text"></span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> investigated the feasibility of data augmentation with photo-realistic synthetic images. Kortylewski <em id="S1.p2.1.3" class="ltx_emph ltx_font_italic">et al</em>.<span id="S1.p2.1.4" class="ltx_text"></span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> further explored the pose-varying synthetic images to reduce the negative effects of dataset bias. Lately, disentangled face generation has become popularÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, which can provide the precise control of targeted face properties such as identity, pose, expression, and illumination, thus making it possible for us to systematically explore the impacts of facial properties on face recognition. Specifically, with a controllable face synthesis model, we are then capable of 1) collecting large-scale face images of non-existing identities without the risk of privacy issues; 2) exploring the impacts of different face dataset properties, such as the depth (the number of samples per identity) and the width (the number of identities); 3) analyzing the influences of different facial attributes (<em id="S1.p2.1.5" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S1.p2.1.6" class="ltx_text"></span>, expression, pose, and illumination).</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">However, there is usually a significant performance gap between the models trained on synthetic and real face datasets. Through the empirical analysis, we find that 1) the poor intra-class variations in synthetic face images and 2) the domain gap between synthetic and real face datasets are the main reasons of the performance degradation. To address the above issues, we introduce identity mixup (IM) into the disentangled face generator to enlarge the intra-class variations of generated face images. Specifically, we use a convex combination of the coefficients from two different identities to form a new intermediate identity coefficient for synthetic face generation. Experimental results in Sec.Â <a href="#S4" title="4 Experiments â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> show that the identity mixup significantly improves the performance of the model trained on synthetic face images. Furthermore, we observe a significant domain gap via cross-domain evaluation: 1) training on synthetic face images and testing on real face images; 2) training on real face images and testing on synthetic face images (see more details in Sec.Â <a href="#S3.SS2" title="3.2 SynFace vs. RealFace â€£ 3 Method â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>). Therefore, we further introduce the domain mixup (DM) to alleviate the domain gap, <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S1.p3.1.2" class="ltx_text"></span>, by using a convex combination of images from a large-scale synthetic dataset and a relatively small number of real face images during training. With the proposed identity mixup and domain mixup, we achieve a significant improvement over the vanilla SynFace, further pushing the boundary of face recognition performance using synthetic data. The main contributions of this paper are as follows:</p>
</div>
<div id="S1.p4" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We observe a performance gap between the models trained on real and synthetic face images, which can be effectively narrowed by 1) enlarging the intra-class variations via identity mixup; 2) leveraging a few real face images for domain adaption via domain mixup.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We discuss the impacts of synthetic datasets with different properties for face recognition, <em id="S1.I1.i2.p1.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S1.I1.i2.p1.1.2" class="ltx_text"></span>, depth (the number of samples per identity) and width (the number of identities), and reveal that the width plays a more important role.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We analyze the influences of different facial attributes on face recognition (<em id="S1.I1.i3.p1.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S1.I1.i3.p1.1.2" class="ltx_text"></span>, facial pose, expression, and illumination).</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<figure id="S2.F2" class="ltx_figure"><img src="/html/2108.07960/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="523" height="135" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>An overview of the proposed SynFace. Firstly, the identity mixup is introduced into DiscoFaceGANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> to form the Mixup Face Generator, which can generate face images with different identities and their intermediate states. Next, the synthetic face images are cooperating with a few real face images via domain mixup to alleviate the domain gap. Then, the feature extractor takes the mixed face images as input and extracts the corresponding features. The extracted features are either utilized to calculate the margin-based softmax loss (where <math id="S2.F2.3.m1.2" class="ltx_Math" alttext="W_{1},W_{2}" display="inline"><semantics id="S2.F2.3.m1.2b"><mrow id="S2.F2.3.m1.2.2.2" xref="S2.F2.3.m1.2.2.3.cmml"><msub id="S2.F2.3.m1.1.1.1.1" xref="S2.F2.3.m1.1.1.1.1.cmml"><mi id="S2.F2.3.m1.1.1.1.1.2" xref="S2.F2.3.m1.1.1.1.1.2.cmml">W</mi><mn id="S2.F2.3.m1.1.1.1.1.3" xref="S2.F2.3.m1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.F2.3.m1.2.2.2.3" xref="S2.F2.3.m1.2.2.3.cmml">,</mo><msub id="S2.F2.3.m1.2.2.2.2" xref="S2.F2.3.m1.2.2.2.2.cmml"><mi id="S2.F2.3.m1.2.2.2.2.2" xref="S2.F2.3.m1.2.2.2.2.2.cmml">W</mi><mn id="S2.F2.3.m1.2.2.2.2.3" xref="S2.F2.3.m1.2.2.2.2.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.F2.3.m1.2c"><list id="S2.F2.3.m1.2.2.3.cmml" xref="S2.F2.3.m1.2.2.2"><apply id="S2.F2.3.m1.1.1.1.1.cmml" xref="S2.F2.3.m1.1.1.1.1"><csymbol cd="ambiguous" id="S2.F2.3.m1.1.1.1.1.1.cmml" xref="S2.F2.3.m1.1.1.1.1">subscript</csymbol><ci id="S2.F2.3.m1.1.1.1.1.2.cmml" xref="S2.F2.3.m1.1.1.1.1.2">ğ‘Š</ci><cn type="integer" id="S2.F2.3.m1.1.1.1.1.3.cmml" xref="S2.F2.3.m1.1.1.1.1.3">1</cn></apply><apply id="S2.F2.3.m1.2.2.2.2.cmml" xref="S2.F2.3.m1.2.2.2.2"><csymbol cd="ambiguous" id="S2.F2.3.m1.2.2.2.2.1.cmml" xref="S2.F2.3.m1.2.2.2.2">subscript</csymbol><ci id="S2.F2.3.m1.2.2.2.2.2.cmml" xref="S2.F2.3.m1.2.2.2.2.2">ğ‘Š</ci><cn type="integer" id="S2.F2.3.m1.2.2.2.2.3.cmml" xref="S2.F2.3.m1.2.2.2.2.3">2</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.3.m1.2d">W_{1},W_{2}</annotation></semantics></math> are the center weight vectors for two different classes and <math id="S2.F2.4.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.F2.4.m2.1b"><mi id="S2.F2.4.m2.1.1" xref="S2.F2.4.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.F2.4.m2.1c"><ci id="S2.F2.4.m2.1.1.cmml" xref="S2.F2.4.m2.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.4.m2.1d">x</annotation></semantics></math> is the feature vector) for model training, or employed as the face representations to perform face identification and verification tasks.</figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We first briefly introduce visual tasks using synthetic data. Then recent face synthesis and recognition methods are reviewed. Lastly, we discuss the mixup and its variants to indicate their similarities/differences with the proposed identity mixup and domain mixup.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Synthetic Data.</span> Synthetic data for computer vision tasks has been widely explored, <em id="S2.p2.1.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S2.p2.1.3" class="ltx_text"></span>, crowd countingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, vehicle re-identificationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>, semantic segmentationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>, 3D face reconstructionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> and face recognitionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>. According to the motivation, existing methods can be categorized into three groups: (1) It is time-consuming and expensive to collect and annotate large-scale training dataÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>; (2) It can be used to further improve the model trained on a real datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>; (3) It can be used to systematically analyze the impacts of different dataset attributesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. Among these works, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> is the most related one to our work, while it only discusses the impacts of different head poses. Apart from facial attributes (<em id="S2.p2.1.4" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S2.p2.1.5" class="ltx_text"></span>, pose, expression, and illumination), we also explore the impacts of the width and the depth of training dataset. Furthermore, we introduce identity mixup (IM) and domain mixup (DM) to increase the intra-class variations and narrow down the domain gap, leading to a significant improvement.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Face Synthesis.</span> With the great success of GANsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>, face synthesis has received increasing attention and several methods have been proposed to generate identity-preserving face imagesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>. Specifically, FF-GANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> utilizes 3D priors (<em id="S2.p3.1.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S2.p3.1.3" class="ltx_text"></span>, 3DMMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>) for high-quality face frontalization. Bao <em id="S2.p3.1.4" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p3.1.5" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> first disentangled identity/attributes from the face image, and then recombined different identities/attributes for identity-preserving face synthesis. FaceID-GANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> aims to generate identity-preserving faces by using a classifier (C) as the third player, competing with the generator (G) and cooperating with the discriminator (D). However, unlike exploring the identity-preserving property, generating face images from multiple disentangled latent spaces (<em id="S2.p3.1.6" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S2.p3.1.7" class="ltx_text"></span>, different facial attributes) have not been well-investigated. Recently, DiscoFaceGANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> introduces a novel disentangled learning scheme for face image generation via an imitative-contrastive paradigm using 3D priors. Thus, it further enables precise control of targeted face properties such as unknown identities, pose, expression, and illumination, yielding the flexible and high-quality face image generation.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Deep Face Recognition.</span> Recent face recognition methods mainly focus on delivering novel loss functions for robust face recognition in the wild. The main idea is to maximize the inter-class variations and minimize the intra-class variations. For example, 1) contrastive lossÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> and triplet lossÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> are usually utilized to increase the Euclidean margin for better feature embedding; 2) center lossÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> aims to learn a center for each identity and then minimizes the center-aware intra-class variations; 3) Large-margin softmax lossÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> and its variants such as CosFaceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> and ArcFaceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> improve the feature discrimination by adding marginal constraints to each identity.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p"><span id="S2.p5.1.1" class="ltx_text ltx_font_bold">Mixup.</span> MixupÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> uses the convex combinations of two data samples as a new sample for training, regularizing deep neural networks to favor a simple linear behavior in-between training samples. Vanilla mixup is usually employed on image pixels, while the generated data samples are not consistent with the real images, <em id="S2.p5.1.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S2.p5.1.3" class="ltx_text"></span>, a mixup of two face images in the pixel level does not always form a proper new face image. Inspired by this, we introduce identity mixup to face generator via the identity coefficients, where a convex combination of two identities forms a new identity in the disentangled latent space. With the proposed identity mixup, we are also able to generate high-fidelity face images correspondingly. Recently, several mixup variants have been proposed to perform feature-level interpolationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib51" title="" class="ltx_ref">51</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>, while <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> further leverages domain mixup to perform adversarial domain adaptation. Inspired by this, we perform domain adaption via domain mixup between real and synthetic face images, while the main difference is that <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> uses the mixup ratio to guide the model training, but we utilize the identity labels of both synthetic and real face images as the supervision for face recognition.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we introduce face recognition with synthetic data, <em id="S3.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.p1.1.2" class="ltx_text"></span>, SynFace, and the overall pipeline is illustrated in FigureÂ <a href="#S2.F2" title="Figure 2 â€£ 2 Related Work â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. We first introduce deep face recognition using margin-based softmax loss functions. We then explore the performance gap between the models trained on synthetic and real datasets (SynFace and RealFace). Lastly, we introduce 1) identity mixup to enlarge the intra-class variations and 2) domain mixup to mitigate the domain gap between synthetic and real faces images.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Deep Face Recognition</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.12" class="ltx_p">With the great success of deep neural networks, deep learning-based embedding learning has become the mainstream technology for face recognition to maximize the inter-class variations and minimize the intra-class variationsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. Recently, margin-based softmax loss functions have been very popular in face recognition due to their simplicity and excellent performance, which explicitly explore the margin penalty between inter- and intra-class variations via a reformulation of softmax-based loss functionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>. Similar toÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, we use a unified formulation for margin-based softmax loss functions as follows:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.13" class="ltx_Math" alttext="\begin{split}&amp;\mathcal{L}_{margin}=-\frac{1}{N}\sum_{i=1}^{N}\log\frac{e^{s\cdot\delta}}{e^{s\cdot\delta}+\sum_{j\neq y_{i}}^{n}e^{s\cos\theta_{j}}},\end{split}" display="block"><semantics id="S3.E1.m1.13a"><mtable columnspacing="0pt" displaystyle="true" id="S3.E1.m1.13.13.2"><mtr id="S3.E1.m1.13.13.2a"><mtd id="S3.E1.m1.13.13.2b" xref="S3.E1.m1.12.12.1.1.1.cmml"></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.13.13.2c"><mrow id="S3.E1.m1.13.13.2.12.12.12.12"><mrow id="S3.E1.m1.13.13.2.12.12.12.12.1"><msub id="S3.E1.m1.13.13.2.12.12.12.12.1.1"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml">â„’</mi><mrow id="S3.E1.m1.2.2.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.2.2.1.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2.1.2" xref="S3.E1.m1.2.2.2.2.2.2.1.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.2.2.1.1" xref="S3.E1.m1.2.2.2.2.2.2.1.1.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.2.2.2.2.1.3" xref="S3.E1.m1.2.2.2.2.2.2.1.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.2.2.1.1a" xref="S3.E1.m1.2.2.2.2.2.2.1.1.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.2.2.2.2.1.4" xref="S3.E1.m1.2.2.2.2.2.2.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.2.2.1.1b" xref="S3.E1.m1.2.2.2.2.2.2.1.1.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.2.2.2.2.1.5" xref="S3.E1.m1.2.2.2.2.2.2.1.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.2.2.1.1c" xref="S3.E1.m1.2.2.2.2.2.2.1.1.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.2.2.2.2.1.6" xref="S3.E1.m1.2.2.2.2.2.2.1.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.2.2.1.1d" xref="S3.E1.m1.2.2.2.2.2.2.1.1.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.2.2.2.2.1.7" xref="S3.E1.m1.2.2.2.2.2.2.1.7.cmml">n</mi></mrow></msub><mo id="S3.E1.m1.3.3.3.3.3.3" xref="S3.E1.m1.3.3.3.3.3.3.cmml">=</mo><mrow id="S3.E1.m1.13.13.2.12.12.12.12.1.2"><mo id="S3.E1.m1.13.13.2.12.12.12.12.1.2a" xref="S3.E1.m1.12.12.1.1.1.cmml">âˆ’</mo><mrow id="S3.E1.m1.13.13.2.12.12.12.12.1.2.1"><mfrac id="S3.E1.m1.5.5.5.5.5.5" xref="S3.E1.m1.5.5.5.5.5.5.cmml"><mn id="S3.E1.m1.5.5.5.5.5.5.2" xref="S3.E1.m1.5.5.5.5.5.5.2.cmml">1</mn><mi id="S3.E1.m1.5.5.5.5.5.5.3" xref="S3.E1.m1.5.5.5.5.5.5.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E1.m1.13.13.2.12.12.12.12.1.2.1.1" xref="S3.E1.m1.12.12.1.1.1.cmml">â€‹</mo><mrow id="S3.E1.m1.13.13.2.12.12.12.12.1.2.1.2"><munderover id="S3.E1.m1.13.13.2.12.12.12.12.1.2.1.2.1"><mo movablelimits="false" id="S3.E1.m1.6.6.6.6.6.6" xref="S3.E1.m1.6.6.6.6.6.6.cmml">âˆ‘</mo><mrow id="S3.E1.m1.7.7.7.7.7.7.1" xref="S3.E1.m1.7.7.7.7.7.7.1.cmml"><mi id="S3.E1.m1.7.7.7.7.7.7.1.2" xref="S3.E1.m1.7.7.7.7.7.7.1.2.cmml">i</mi><mo id="S3.E1.m1.7.7.7.7.7.7.1.1" xref="S3.E1.m1.7.7.7.7.7.7.1.1.cmml">=</mo><mn id="S3.E1.m1.7.7.7.7.7.7.1.3" xref="S3.E1.m1.7.7.7.7.7.7.1.3.cmml">1</mn></mrow><mi id="S3.E1.m1.8.8.8.8.8.8.1" xref="S3.E1.m1.8.8.8.8.8.8.1.cmml">N</mi></munderover><mrow id="S3.E1.m1.13.13.2.12.12.12.12.1.2.1.2.2"><mi id="S3.E1.m1.9.9.9.9.9.9" xref="S3.E1.m1.9.9.9.9.9.9.cmml">log</mi><mo lspace="0.167em" id="S3.E1.m1.13.13.2.12.12.12.12.1.2.1.2.2a" xref="S3.E1.m1.12.12.1.1.1.cmml">â¡</mo><mfrac id="S3.E1.m1.10.10.10.10.10.10" xref="S3.E1.m1.10.10.10.10.10.10.cmml"><msup id="S3.E1.m1.10.10.10.10.10.10.2" xref="S3.E1.m1.10.10.10.10.10.10.2.cmml"><mi id="S3.E1.m1.10.10.10.10.10.10.2.2" xref="S3.E1.m1.10.10.10.10.10.10.2.2.cmml">e</mi><mrow id="S3.E1.m1.10.10.10.10.10.10.2.3" xref="S3.E1.m1.10.10.10.10.10.10.2.3.cmml"><mi id="S3.E1.m1.10.10.10.10.10.10.2.3.2" xref="S3.E1.m1.10.10.10.10.10.10.2.3.2.cmml">s</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.10.10.10.10.10.10.2.3.1" xref="S3.E1.m1.10.10.10.10.10.10.2.3.1.cmml">â‹…</mo><mi id="S3.E1.m1.10.10.10.10.10.10.2.3.3" xref="S3.E1.m1.10.10.10.10.10.10.2.3.3.cmml">Î´</mi></mrow></msup><mrow id="S3.E1.m1.10.10.10.10.10.10.3" xref="S3.E1.m1.10.10.10.10.10.10.3.cmml"><msup id="S3.E1.m1.10.10.10.10.10.10.3.2" xref="S3.E1.m1.10.10.10.10.10.10.3.2.cmml"><mi id="S3.E1.m1.10.10.10.10.10.10.3.2.2" xref="S3.E1.m1.10.10.10.10.10.10.3.2.2.cmml">e</mi><mrow id="S3.E1.m1.10.10.10.10.10.10.3.2.3" xref="S3.E1.m1.10.10.10.10.10.10.3.2.3.cmml"><mi id="S3.E1.m1.10.10.10.10.10.10.3.2.3.2" xref="S3.E1.m1.10.10.10.10.10.10.3.2.3.2.cmml">s</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.10.10.10.10.10.10.3.2.3.1" xref="S3.E1.m1.10.10.10.10.10.10.3.2.3.1.cmml">â‹…</mo><mi id="S3.E1.m1.10.10.10.10.10.10.3.2.3.3" xref="S3.E1.m1.10.10.10.10.10.10.3.2.3.3.cmml">Î´</mi></mrow></msup><mo rspace="0.055em" id="S3.E1.m1.10.10.10.10.10.10.3.1" xref="S3.E1.m1.10.10.10.10.10.10.3.1.cmml">+</mo><mrow id="S3.E1.m1.10.10.10.10.10.10.3.3" xref="S3.E1.m1.10.10.10.10.10.10.3.3.cmml"><msubsup id="S3.E1.m1.10.10.10.10.10.10.3.3.1" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.cmml"><mo id="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.2" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.cmml"><mi id="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.2" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.2.cmml">j</mi><mo id="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.1" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.1.cmml">â‰ </mo><msub id="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.3" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.3.cmml"><mi id="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.3.2" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.3.2.cmml">y</mi><mi id="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.3.3" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.3.3.cmml">i</mi></msub></mrow><mi id="S3.E1.m1.10.10.10.10.10.10.3.3.1.3" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.3.cmml">n</mi></msubsup><msup id="S3.E1.m1.10.10.10.10.10.10.3.3.2" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.cmml"><mi id="S3.E1.m1.10.10.10.10.10.10.3.3.2.2" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.2.cmml">e</mi><mrow id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.cmml"><mi id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.2" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.2.cmml">s</mi><mo lspace="0.167em" rspace="0em" id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.1" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.1.cmml">â€‹</mo><mrow id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.cmml"><mi id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.1" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.1.cmml">cos</mi><mo lspace="0.167em" id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3a" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.cmml">â¡</mo><msub id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.2" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.2.cmml"><mi id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.2.2" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.2.2.cmml">Î¸</mi><mi id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.2.3" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.2.3.cmml">j</mi></msub></mrow></mrow></msup></mrow></mrow></mfrac></mrow></mrow></mrow></mrow></mrow><mo id="S3.E1.m1.11.11.11.11.11.11" xref="S3.E1.m1.12.12.1.1.1.cmml">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E1.m1.13b"><apply id="S3.E1.m1.12.12.1.1.1.cmml" xref="S3.E1.m1.13.13.2b"><eq id="S3.E1.m1.3.3.3.3.3.3.cmml" xref="S3.E1.m1.3.3.3.3.3.3"></eq><apply id="S3.E1.m1.12.12.1.1.1.2.cmml" xref="S3.E1.m1.13.13.2b"><csymbol cd="ambiguous" id="S3.E1.m1.12.12.1.1.1.2.1.cmml" xref="S3.E1.m1.13.13.2b">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1">â„’</ci><apply id="S3.E1.m1.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1"><times id="S3.E1.m1.2.2.2.2.2.2.1.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1"></times><ci id="S3.E1.m1.2.2.2.2.2.2.1.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.2">ğ‘š</ci><ci id="S3.E1.m1.2.2.2.2.2.2.1.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.3">ğ‘</ci><ci id="S3.E1.m1.2.2.2.2.2.2.1.4.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.4">ğ‘Ÿ</ci><ci id="S3.E1.m1.2.2.2.2.2.2.1.5.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.5">ğ‘”</ci><ci id="S3.E1.m1.2.2.2.2.2.2.1.6.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.6">ğ‘–</ci><ci id="S3.E1.m1.2.2.2.2.2.2.1.7.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.7">ğ‘›</ci></apply></apply><apply id="S3.E1.m1.12.12.1.1.1.3.cmml" xref="S3.E1.m1.13.13.2b"><minus id="S3.E1.m1.4.4.4.4.4.4.cmml" xref="S3.E1.m1.13.13.2b"></minus><apply id="S3.E1.m1.12.12.1.1.1.3.2.cmml" xref="S3.E1.m1.13.13.2b"><times id="S3.E1.m1.12.12.1.1.1.3.2.1.cmml" xref="S3.E1.m1.13.13.2b"></times><apply id="S3.E1.m1.5.5.5.5.5.5.cmml" xref="S3.E1.m1.5.5.5.5.5.5"><divide id="S3.E1.m1.5.5.5.5.5.5.1.cmml" xref="S3.E1.m1.5.5.5.5.5.5"></divide><cn type="integer" id="S3.E1.m1.5.5.5.5.5.5.2.cmml" xref="S3.E1.m1.5.5.5.5.5.5.2">1</cn><ci id="S3.E1.m1.5.5.5.5.5.5.3.cmml" xref="S3.E1.m1.5.5.5.5.5.5.3">ğ‘</ci></apply><apply id="S3.E1.m1.12.12.1.1.1.3.2.3.cmml" xref="S3.E1.m1.13.13.2b"><apply id="S3.E1.m1.12.12.1.1.1.3.2.3.1.cmml" xref="S3.E1.m1.13.13.2b"><csymbol cd="ambiguous" id="S3.E1.m1.12.12.1.1.1.3.2.3.1.1.cmml" xref="S3.E1.m1.13.13.2b">superscript</csymbol><apply id="S3.E1.m1.12.12.1.1.1.3.2.3.1.2.cmml" xref="S3.E1.m1.13.13.2b"><csymbol cd="ambiguous" id="S3.E1.m1.12.12.1.1.1.3.2.3.1.2.1.cmml" xref="S3.E1.m1.13.13.2b">subscript</csymbol><sum id="S3.E1.m1.6.6.6.6.6.6.cmml" xref="S3.E1.m1.6.6.6.6.6.6"></sum><apply id="S3.E1.m1.7.7.7.7.7.7.1.cmml" xref="S3.E1.m1.7.7.7.7.7.7.1"><eq id="S3.E1.m1.7.7.7.7.7.7.1.1.cmml" xref="S3.E1.m1.7.7.7.7.7.7.1.1"></eq><ci id="S3.E1.m1.7.7.7.7.7.7.1.2.cmml" xref="S3.E1.m1.7.7.7.7.7.7.1.2">ğ‘–</ci><cn type="integer" id="S3.E1.m1.7.7.7.7.7.7.1.3.cmml" xref="S3.E1.m1.7.7.7.7.7.7.1.3">1</cn></apply></apply><ci id="S3.E1.m1.8.8.8.8.8.8.1.cmml" xref="S3.E1.m1.8.8.8.8.8.8.1">ğ‘</ci></apply><apply id="S3.E1.m1.12.12.1.1.1.3.2.3.2.cmml" xref="S3.E1.m1.13.13.2b"><log id="S3.E1.m1.9.9.9.9.9.9.cmml" xref="S3.E1.m1.9.9.9.9.9.9"></log><apply id="S3.E1.m1.10.10.10.10.10.10.cmml" xref="S3.E1.m1.10.10.10.10.10.10"><divide id="S3.E1.m1.10.10.10.10.10.10.1.cmml" xref="S3.E1.m1.10.10.10.10.10.10"></divide><apply id="S3.E1.m1.10.10.10.10.10.10.2.cmml" xref="S3.E1.m1.10.10.10.10.10.10.2"><csymbol cd="ambiguous" id="S3.E1.m1.10.10.10.10.10.10.2.1.cmml" xref="S3.E1.m1.10.10.10.10.10.10.2">superscript</csymbol><ci id="S3.E1.m1.10.10.10.10.10.10.2.2.cmml" xref="S3.E1.m1.10.10.10.10.10.10.2.2">ğ‘’</ci><apply id="S3.E1.m1.10.10.10.10.10.10.2.3.cmml" xref="S3.E1.m1.10.10.10.10.10.10.2.3"><ci id="S3.E1.m1.10.10.10.10.10.10.2.3.1.cmml" xref="S3.E1.m1.10.10.10.10.10.10.2.3.1">â‹…</ci><ci id="S3.E1.m1.10.10.10.10.10.10.2.3.2.cmml" xref="S3.E1.m1.10.10.10.10.10.10.2.3.2">ğ‘ </ci><ci id="S3.E1.m1.10.10.10.10.10.10.2.3.3.cmml" xref="S3.E1.m1.10.10.10.10.10.10.2.3.3">ğ›¿</ci></apply></apply><apply id="S3.E1.m1.10.10.10.10.10.10.3.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3"><plus id="S3.E1.m1.10.10.10.10.10.10.3.1.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.1"></plus><apply id="S3.E1.m1.10.10.10.10.10.10.3.2.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.10.10.10.10.10.10.3.2.1.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.2">superscript</csymbol><ci id="S3.E1.m1.10.10.10.10.10.10.3.2.2.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.2.2">ğ‘’</ci><apply id="S3.E1.m1.10.10.10.10.10.10.3.2.3.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.2.3"><ci id="S3.E1.m1.10.10.10.10.10.10.3.2.3.1.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.2.3.1">â‹…</ci><ci id="S3.E1.m1.10.10.10.10.10.10.3.2.3.2.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.2.3.2">ğ‘ </ci><ci id="S3.E1.m1.10.10.10.10.10.10.3.2.3.3.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.2.3.3">ğ›¿</ci></apply></apply><apply id="S3.E1.m1.10.10.10.10.10.10.3.3.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3"><apply id="S3.E1.m1.10.10.10.10.10.10.3.3.1.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.10.10.10.10.10.10.3.3.1.1.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1">superscript</csymbol><apply id="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.1.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1">subscript</csymbol><sum id="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.2.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.2"></sum><apply id="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3"><neq id="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.1.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.1"></neq><ci id="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.2.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.2">ğ‘—</ci><apply id="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.3.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.3.1.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.3">subscript</csymbol><ci id="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.3.2.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.3.2">ğ‘¦</ci><ci id="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.3.3.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.2.3.3.3">ğ‘–</ci></apply></apply></apply><ci id="S3.E1.m1.10.10.10.10.10.10.3.3.1.3.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.1.3">ğ‘›</ci></apply><apply id="S3.E1.m1.10.10.10.10.10.10.3.3.2.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.10.10.10.10.10.10.3.3.2.1.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2">superscript</csymbol><ci id="S3.E1.m1.10.10.10.10.10.10.3.3.2.2.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.2">ğ‘’</ci><apply id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3"><times id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.1.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.1"></times><ci id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.2.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.2">ğ‘ </ci><apply id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3"><cos id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.1.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.1"></cos><apply id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.2.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.2.1.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.2">subscript</csymbol><ci id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.2.2.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.2.2">ğœƒ</ci><ci id="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.2.3.cmml" xref="S3.E1.m1.10.10.10.10.10.10.3.3.2.3.3.2.3">ğ‘—</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.13c">\begin{split}&amp;\mathcal{L}_{margin}=-\frac{1}{N}\sum_{i=1}^{N}\log\frac{e^{s\cdot\delta}}{e^{s\cdot\delta}+\sum_{j\neq y_{i}}^{n}e^{s\cos\theta_{j}}},\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.11" class="ltx_p">where <math id="S3.SS1.p1.1.m1.2" class="ltx_Math" alttext="\delta=\cos(m_{1}\theta_{y_{i}}+m_{2})-m_{3}" display="inline"><semantics id="S3.SS1.p1.1.m1.2a"><mrow id="S3.SS1.p1.1.m1.2.2" xref="S3.SS1.p1.1.m1.2.2.cmml"><mi id="S3.SS1.p1.1.m1.2.2.3" xref="S3.SS1.p1.1.m1.2.2.3.cmml">Î´</mi><mo id="S3.SS1.p1.1.m1.2.2.2" xref="S3.SS1.p1.1.m1.2.2.2.cmml">=</mo><mrow id="S3.SS1.p1.1.m1.2.2.1" xref="S3.SS1.p1.1.m1.2.2.1.cmml"><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.2.cmml"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">cos</mi><mo id="S3.SS1.p1.1.m1.2.2.1.1.1a" xref="S3.SS1.p1.1.m1.2.2.1.1.2.cmml">â¡</mo><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.2" xref="S3.SS1.p1.1.m1.2.2.1.1.2.cmml">(</mo><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.cmml"><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.cmml"><msub id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.2.cmml"><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.2.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.2.2.cmml">m</mi><mn id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.2.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.2.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.1.cmml">â€‹</mo><msub id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.cmml"><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.2.cmml">Î¸</mi><msub id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.3.cmml"><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.3.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.3.2.cmml">y</mi><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.3.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.3.3.cmml">i</mi></msub></msub></mrow><mo id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.cmml">+</mo><msub id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.3.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.3.2.cmml">m</mi><mn id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.3.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.3.3.cmml">2</mn></msub></mrow><mo stretchy="false" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.3" xref="S3.SS1.p1.1.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.SS1.p1.1.m1.2.2.1.2" xref="S3.SS1.p1.1.m1.2.2.1.2.cmml">âˆ’</mo><msub id="S3.SS1.p1.1.m1.2.2.1.3" xref="S3.SS1.p1.1.m1.2.2.1.3.cmml"><mi id="S3.SS1.p1.1.m1.2.2.1.3.2" xref="S3.SS1.p1.1.m1.2.2.1.3.2.cmml">m</mi><mn id="S3.SS1.p1.1.m1.2.2.1.3.3" xref="S3.SS1.p1.1.m1.2.2.1.3.3.cmml">3</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.2b"><apply id="S3.SS1.p1.1.m1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2"><eq id="S3.SS1.p1.1.m1.2.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.2"></eq><ci id="S3.SS1.p1.1.m1.2.2.3.cmml" xref="S3.SS1.p1.1.m1.2.2.3">ğ›¿</ci><apply id="S3.SS1.p1.1.m1.2.2.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1"><minus id="S3.SS1.p1.1.m1.2.2.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.2"></minus><apply id="S3.SS1.p1.1.m1.2.2.1.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1"><cos id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"></cos><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1"><plus id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1"></plus><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2"><times id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.1"></times><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.2.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.2.2">ğ‘š</ci><cn type="integer" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.2.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.2.3">1</cn></apply><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.2">ğœƒ</ci><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.3.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.3">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.3.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.3.2">ğ‘¦</ci><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.3.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.2.3.3.3">ğ‘–</ci></apply></apply></apply><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.3.2">ğ‘š</ci><cn type="integer" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.3.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.3.3">2</cn></apply></apply></apply><apply id="S3.SS1.p1.1.m1.2.2.1.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.3.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.3">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.3.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.3.2">ğ‘š</ci><cn type="integer" id="S3.SS1.p1.1.m1.2.2.1.3.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.3.3">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.2c">\delta=\cos(m_{1}\theta_{y_{i}}+m_{2})-m_{3}</annotation></semantics></math>, <math id="S3.SS1.p1.2.m2.3" class="ltx_Math" alttext="m_{1,2,3}" display="inline"><semantics id="S3.SS1.p1.2.m2.3a"><msub id="S3.SS1.p1.2.m2.3.4" xref="S3.SS1.p1.2.m2.3.4.cmml"><mi id="S3.SS1.p1.2.m2.3.4.2" xref="S3.SS1.p1.2.m2.3.4.2.cmml">m</mi><mrow id="S3.SS1.p1.2.m2.3.3.3.5" xref="S3.SS1.p1.2.m2.3.3.3.4.cmml"><mn id="S3.SS1.p1.2.m2.1.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.1.cmml">1</mn><mo id="S3.SS1.p1.2.m2.3.3.3.5.1" xref="S3.SS1.p1.2.m2.3.3.3.4.cmml">,</mo><mn id="S3.SS1.p1.2.m2.2.2.2.2" xref="S3.SS1.p1.2.m2.2.2.2.2.cmml">2</mn><mo id="S3.SS1.p1.2.m2.3.3.3.5.2" xref="S3.SS1.p1.2.m2.3.3.3.4.cmml">,</mo><mn id="S3.SS1.p1.2.m2.3.3.3.3" xref="S3.SS1.p1.2.m2.3.3.3.3.cmml">3</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.3b"><apply id="S3.SS1.p1.2.m2.3.4.cmml" xref="S3.SS1.p1.2.m2.3.4"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.3.4.1.cmml" xref="S3.SS1.p1.2.m2.3.4">subscript</csymbol><ci id="S3.SS1.p1.2.m2.3.4.2.cmml" xref="S3.SS1.p1.2.m2.3.4.2">ğ‘š</ci><list id="S3.SS1.p1.2.m2.3.3.3.4.cmml" xref="S3.SS1.p1.2.m2.3.3.3.5"><cn type="integer" id="S3.SS1.p1.2.m2.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1">1</cn><cn type="integer" id="S3.SS1.p1.2.m2.2.2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2">2</cn><cn type="integer" id="S3.SS1.p1.2.m2.3.3.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3.3.3">3</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.3c">m_{1,2,3}</annotation></semantics></math> are margins, <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">N</annotation></semantics></math> is the number of training samples, <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="\theta_{j}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><msub id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">Î¸</mi><mi id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">ğœƒ</ci><ci id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">\theta_{j}</annotation></semantics></math> indicates the angle between the weight <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="W_{j}" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><msub id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml">W</mi><mi id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2">ğ‘Š</ci><ci id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">W_{j}</annotation></semantics></math> and the feature <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><msub id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">x</mi><mi id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">x_{i}</annotation></semantics></math>, <math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><msub id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml"><mi id="S3.SS1.p1.7.m7.1.1.2" xref="S3.SS1.p1.7.m7.1.1.2.cmml">y</mi><mi id="S3.SS1.p1.7.m7.1.1.3" xref="S3.SS1.p1.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2">ğ‘¦</ci><ci id="S3.SS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">y_{i}</annotation></semantics></math> represents the ground-truth class, and <math id="S3.SS1.p1.8.m8.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS1.p1.8.m8.1a"><mi id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><ci id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">s</annotation></semantics></math> is the scale factor. Specifically, for SphereFaceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, ArcFaceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and CosFaceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, we have the coefficients <math id="S3.SS1.p1.9.m9.3" class="ltx_Math" alttext="(m_{1},0,0)" display="inline"><semantics id="S3.SS1.p1.9.m9.3a"><mrow id="S3.SS1.p1.9.m9.3.3.1" xref="S3.SS1.p1.9.m9.3.3.2.cmml"><mo stretchy="false" id="S3.SS1.p1.9.m9.3.3.1.2" xref="S3.SS1.p1.9.m9.3.3.2.cmml">(</mo><msub id="S3.SS1.p1.9.m9.3.3.1.1" xref="S3.SS1.p1.9.m9.3.3.1.1.cmml"><mi id="S3.SS1.p1.9.m9.3.3.1.1.2" xref="S3.SS1.p1.9.m9.3.3.1.1.2.cmml">m</mi><mn id="S3.SS1.p1.9.m9.3.3.1.1.3" xref="S3.SS1.p1.9.m9.3.3.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.9.m9.3.3.1.3" xref="S3.SS1.p1.9.m9.3.3.2.cmml">,</mo><mn id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml">0</mn><mo id="S3.SS1.p1.9.m9.3.3.1.4" xref="S3.SS1.p1.9.m9.3.3.2.cmml">,</mo><mn id="S3.SS1.p1.9.m9.2.2" xref="S3.SS1.p1.9.m9.2.2.cmml">0</mn><mo stretchy="false" id="S3.SS1.p1.9.m9.3.3.1.5" xref="S3.SS1.p1.9.m9.3.3.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.3b"><vector id="S3.SS1.p1.9.m9.3.3.2.cmml" xref="S3.SS1.p1.9.m9.3.3.1"><apply id="S3.SS1.p1.9.m9.3.3.1.1.cmml" xref="S3.SS1.p1.9.m9.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m9.3.3.1.1.1.cmml" xref="S3.SS1.p1.9.m9.3.3.1.1">subscript</csymbol><ci id="S3.SS1.p1.9.m9.3.3.1.1.2.cmml" xref="S3.SS1.p1.9.m9.3.3.1.1.2">ğ‘š</ci><cn type="integer" id="S3.SS1.p1.9.m9.3.3.1.1.3.cmml" xref="S3.SS1.p1.9.m9.3.3.1.1.3">1</cn></apply><cn type="integer" id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">0</cn><cn type="integer" id="S3.SS1.p1.9.m9.2.2.cmml" xref="S3.SS1.p1.9.m9.2.2">0</cn></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.3c">(m_{1},0,0)</annotation></semantics></math>, <math id="S3.SS1.p1.10.m10.3" class="ltx_Math" alttext="(0,m_{2},0)" display="inline"><semantics id="S3.SS1.p1.10.m10.3a"><mrow id="S3.SS1.p1.10.m10.3.3.1" xref="S3.SS1.p1.10.m10.3.3.2.cmml"><mo stretchy="false" id="S3.SS1.p1.10.m10.3.3.1.2" xref="S3.SS1.p1.10.m10.3.3.2.cmml">(</mo><mn id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml">0</mn><mo id="S3.SS1.p1.10.m10.3.3.1.3" xref="S3.SS1.p1.10.m10.3.3.2.cmml">,</mo><msub id="S3.SS1.p1.10.m10.3.3.1.1" xref="S3.SS1.p1.10.m10.3.3.1.1.cmml"><mi id="S3.SS1.p1.10.m10.3.3.1.1.2" xref="S3.SS1.p1.10.m10.3.3.1.1.2.cmml">m</mi><mn id="S3.SS1.p1.10.m10.3.3.1.1.3" xref="S3.SS1.p1.10.m10.3.3.1.1.3.cmml">2</mn></msub><mo id="S3.SS1.p1.10.m10.3.3.1.4" xref="S3.SS1.p1.10.m10.3.3.2.cmml">,</mo><mn id="S3.SS1.p1.10.m10.2.2" xref="S3.SS1.p1.10.m10.2.2.cmml">0</mn><mo stretchy="false" id="S3.SS1.p1.10.m10.3.3.1.5" xref="S3.SS1.p1.10.m10.3.3.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.3b"><vector id="S3.SS1.p1.10.m10.3.3.2.cmml" xref="S3.SS1.p1.10.m10.3.3.1"><cn type="integer" id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1">0</cn><apply id="S3.SS1.p1.10.m10.3.3.1.1.cmml" xref="S3.SS1.p1.10.m10.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m10.3.3.1.1.1.cmml" xref="S3.SS1.p1.10.m10.3.3.1.1">subscript</csymbol><ci id="S3.SS1.p1.10.m10.3.3.1.1.2.cmml" xref="S3.SS1.p1.10.m10.3.3.1.1.2">ğ‘š</ci><cn type="integer" id="S3.SS1.p1.10.m10.3.3.1.1.3.cmml" xref="S3.SS1.p1.10.m10.3.3.1.1.3">2</cn></apply><cn type="integer" id="S3.SS1.p1.10.m10.2.2.cmml" xref="S3.SS1.p1.10.m10.2.2">0</cn></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.3c">(0,m_{2},0)</annotation></semantics></math>, and <math id="S3.SS1.p1.11.m11.3" class="ltx_Math" alttext="(0,0,m_{3})" display="inline"><semantics id="S3.SS1.p1.11.m11.3a"><mrow id="S3.SS1.p1.11.m11.3.3.1" xref="S3.SS1.p1.11.m11.3.3.2.cmml"><mo stretchy="false" id="S3.SS1.p1.11.m11.3.3.1.2" xref="S3.SS1.p1.11.m11.3.3.2.cmml">(</mo><mn id="S3.SS1.p1.11.m11.1.1" xref="S3.SS1.p1.11.m11.1.1.cmml">0</mn><mo id="S3.SS1.p1.11.m11.3.3.1.3" xref="S3.SS1.p1.11.m11.3.3.2.cmml">,</mo><mn id="S3.SS1.p1.11.m11.2.2" xref="S3.SS1.p1.11.m11.2.2.cmml">0</mn><mo id="S3.SS1.p1.11.m11.3.3.1.4" xref="S3.SS1.p1.11.m11.3.3.2.cmml">,</mo><msub id="S3.SS1.p1.11.m11.3.3.1.1" xref="S3.SS1.p1.11.m11.3.3.1.1.cmml"><mi id="S3.SS1.p1.11.m11.3.3.1.1.2" xref="S3.SS1.p1.11.m11.3.3.1.1.2.cmml">m</mi><mn id="S3.SS1.p1.11.m11.3.3.1.1.3" xref="S3.SS1.p1.11.m11.3.3.1.1.3.cmml">3</mn></msub><mo stretchy="false" id="S3.SS1.p1.11.m11.3.3.1.5" xref="S3.SS1.p1.11.m11.3.3.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m11.3b"><vector id="S3.SS1.p1.11.m11.3.3.2.cmml" xref="S3.SS1.p1.11.m11.3.3.1"><cn type="integer" id="S3.SS1.p1.11.m11.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1">0</cn><cn type="integer" id="S3.SS1.p1.11.m11.2.2.cmml" xref="S3.SS1.p1.11.m11.2.2">0</cn><apply id="S3.SS1.p1.11.m11.3.3.1.1.cmml" xref="S3.SS1.p1.11.m11.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.11.m11.3.3.1.1.1.cmml" xref="S3.SS1.p1.11.m11.3.3.1.1">subscript</csymbol><ci id="S3.SS1.p1.11.m11.3.3.1.1.2.cmml" xref="S3.SS1.p1.11.m11.3.3.1.1.2">ğ‘š</ci><cn type="integer" id="S3.SS1.p1.11.m11.3.3.1.1.3.cmml" xref="S3.SS1.p1.11.m11.3.3.1.1.3">3</cn></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m11.3c">(0,0,m_{3})</annotation></semantics></math>, respectively, and we use ArcFaceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> as our baseline.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>SynFace <em id="S3.SS2.1.1" class="ltx_emph ltx_font_italic">vs</em>.<span id="S3.SS2.2.2" class="ltx_text"></span> RealFace</h3>

<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.3.1.1" class="ltx_tr">
<th id="S3.T1.3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Method</th>
<th id="S3.T1.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Training Dataset</th>
<th id="S3.T1.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">LFW</th>
<th id="S3.T1.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Syn-LFW</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.3.2.1" class="ltx_tr">
<td id="S3.T1.3.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt">RealFace</td>
<td id="S3.T1.3.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">CASIA-WebFace</td>
<td id="S3.T1.3.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">99.18</td>
<td id="S3.T1.3.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">98.85</td>
</tr>
<tr id="S3.T1.3.3.2" class="ltx_tr">
<td id="S3.T1.3.3.2.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r">SynFace</td>
<td id="S3.T1.3.3.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">Syn_10K_50</td>
<td id="S3.T1.3.3.2.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">88.98</td>
<td id="S3.T1.3.3.2.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">99.98</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>The cross-domain evaluation of SynFace and RealFace using the metric of face verification accuracy (<math id="S3.T1.2.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S3.T1.2.m1.1b"><mo id="S3.T1.2.m1.1.1" xref="S3.T1.2.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S3.T1.2.m1.1c"><csymbol cd="latexml" id="S3.T1.2.m1.1.1.cmml" xref="S3.T1.2.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.m1.1d">\%</annotation></semantics></math>).</figcaption>
</figure>
<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.6" class="ltx_p">To explore the performance gap between SynFace and RealFace, as well as the underlying causes, we perform experiments on real-world face datasets and synthetic face datasets generated by DiscoFaceGANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. Specifically, for real-world face datasets, we use CASIA-WebFaceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> for training and LFWÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> for testing. For the fair comparison, we generate the synthetic version of the LFW dataset, Syn-LFW, using the same parameters (the number of samples, the number of identities, distributions of expression, pose, and illumination). For synthetic training data, we generate <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="10K" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mn id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">10</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><times id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">10</cn><ci id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">ğ¾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">10K</annotation></semantics></math> different identities with <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mn id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><cn type="integer" id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">50</annotation></semantics></math> samples per identity to form a comparable training dataset to CASIA-WebFace (containing 494,414 images from 10,575 subjects) and we refer to it as Syn_10K_50. More details of synthetic dataset construction can be found in Sec.Â <a href="#S4.SS1" title="4.1 Datasets â€£ 4 Experiments â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>. With both synthetic and real face images, we then perform the cross-domain evaluation as follows. We train two face recognition models on CASIA-WebFace and Syn_10K_50, and test them on LFW and Syn-LFW, respectively. As shown in TableÂ <a href="#S3.T1" title="Table 1 â€£ 3.2 SynFace vs. RealFace â€£ 3 Method â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, there is a clear performance gap (<math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="88.98\%" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mrow id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mn id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml">88.98</mn><mo id="S3.SS2.p1.3.m3.1.1.1" xref="S3.SS2.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><csymbol cd="latexml" id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1.1">percent</csymbol><cn type="float" id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2">88.98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">88.98\%</annotation></semantics></math> <em id="S3.SS2.p1.6.1" class="ltx_emph ltx_font_italic">vs</em>.<span id="S3.SS2.p1.6.2" class="ltx_text"></span> <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="99.18\%" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mrow id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml"><mn id="S3.SS2.p1.4.m4.1.1.2" xref="S3.SS2.p1.4.m4.1.1.2.cmml">99.18</mn><mo id="S3.SS2.p1.4.m4.1.1.1" xref="S3.SS2.p1.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><apply id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1"><csymbol cd="latexml" id="S3.SS2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1.1">percent</csymbol><cn type="float" id="S3.SS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1.2">99.18</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">99.18\%</annotation></semantics></math>) when testing on LFW, while SynFace outperforms RealFace on Syn-LFW (<math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="99.98\%" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><mrow id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml"><mn id="S3.SS2.p1.5.m5.1.1.2" xref="S3.SS2.p1.5.m5.1.1.2.cmml">99.98</mn><mo id="S3.SS2.p1.5.m5.1.1.1" xref="S3.SS2.p1.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><apply id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1"><csymbol cd="latexml" id="S3.SS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1">percent</csymbol><cn type="float" id="S3.SS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.2">99.98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">99.98\%</annotation></semantics></math> <em id="S3.SS2.p1.6.3" class="ltx_emph ltx_font_italic">vs</em>.<span id="S3.SS2.p1.6.4" class="ltx_text"></span> <math id="S3.SS2.p1.6.m6.1" class="ltx_Math" alttext="98.85\%" display="inline"><semantics id="S3.SS2.p1.6.m6.1a"><mrow id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml"><mn id="S3.SS2.p1.6.m6.1.1.2" xref="S3.SS2.p1.6.m6.1.1.2.cmml">98.85</mn><mo id="S3.SS2.p1.6.m6.1.1.1" xref="S3.SS2.p1.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><apply id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1"><csymbol cd="latexml" id="S3.SS2.p1.6.m6.1.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1.1">percent</csymbol><cn type="float" id="S3.SS2.p1.6.m6.1.1.2.cmml" xref="S3.SS2.p1.6.m6.1.1.2">98.85</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">98.85\%</annotation></semantics></math>). These observations suggest that the domain gap between synthetic and real face images contributes to the performance gap between SynFace and RealFace.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">We compare the face images between Syn_10K_50 and CASIA-WebFace, and find that the synthetic face images usually lack the intra-class variations, which may be one of the reasons for the performance degradation (please refer to the supplementary materials for more illuminations). Furthermore, we also visualize the distributions of feature embeddings by using multidimensional scaling (MDSÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>) to convert the 512-dimensional feature vector into 2D space. As shown in FigureÂ <a href="#S3.F3" title="Figure 3 â€£ 3.2 SynFace vs. RealFace â€£ 3 Method â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we randomly select 50 samples from two different classes of Syn_10K_50 and CASIA-WebFace, respectively. In particular, we observe that the cyan triangles have a much more compact distribution than the green pentagons, suggesting the poor intra-class variations in Syn_10K_50.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2108.07960/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="311" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Visualization of the feature distributions (using MDSÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>) for the samples from three different synthetic datasets (Syn1, Syn2 and Syn3) and CASIA-WebFace, which are illustrated by the cyan triangles, blue square, red circle and green pentagon, respectively. Note that the intra-class variations of Syn1, Syn2 and Syn3 are increasing, which lead to the consistent improvements on accuracy (<math id="S3.F3.2.m1.1" class="ltx_Math" alttext="88.75\%\rightarrow 89.47\%\rightarrow 90.95\%" display="inline"><semantics id="S3.F3.2.m1.1b"><mrow id="S3.F3.2.m1.1.1" xref="S3.F3.2.m1.1.1.cmml"><mrow id="S3.F3.2.m1.1.1.2" xref="S3.F3.2.m1.1.1.2.cmml"><mn id="S3.F3.2.m1.1.1.2.2" xref="S3.F3.2.m1.1.1.2.2.cmml">88.75</mn><mo id="S3.F3.2.m1.1.1.2.1" xref="S3.F3.2.m1.1.1.2.1.cmml">%</mo></mrow><mo stretchy="false" id="S3.F3.2.m1.1.1.3" xref="S3.F3.2.m1.1.1.3.cmml">â†’</mo><mrow id="S3.F3.2.m1.1.1.4" xref="S3.F3.2.m1.1.1.4.cmml"><mn id="S3.F3.2.m1.1.1.4.2" xref="S3.F3.2.m1.1.1.4.2.cmml">89.47</mn><mo id="S3.F3.2.m1.1.1.4.1" xref="S3.F3.2.m1.1.1.4.1.cmml">%</mo></mrow><mo stretchy="false" id="S3.F3.2.m1.1.1.5" xref="S3.F3.2.m1.1.1.5.cmml">â†’</mo><mrow id="S3.F3.2.m1.1.1.6" xref="S3.F3.2.m1.1.1.6.cmml"><mn id="S3.F3.2.m1.1.1.6.2" xref="S3.F3.2.m1.1.1.6.2.cmml">90.95</mn><mo id="S3.F3.2.m1.1.1.6.1" xref="S3.F3.2.m1.1.1.6.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.2.m1.1c"><apply id="S3.F3.2.m1.1.1.cmml" xref="S3.F3.2.m1.1.1"><and id="S3.F3.2.m1.1.1a.cmml" xref="S3.F3.2.m1.1.1"></and><apply id="S3.F3.2.m1.1.1b.cmml" xref="S3.F3.2.m1.1.1"><ci id="S3.F3.2.m1.1.1.3.cmml" xref="S3.F3.2.m1.1.1.3">â†’</ci><apply id="S3.F3.2.m1.1.1.2.cmml" xref="S3.F3.2.m1.1.1.2"><csymbol cd="latexml" id="S3.F3.2.m1.1.1.2.1.cmml" xref="S3.F3.2.m1.1.1.2.1">percent</csymbol><cn type="float" id="S3.F3.2.m1.1.1.2.2.cmml" xref="S3.F3.2.m1.1.1.2.2">88.75</cn></apply><apply id="S3.F3.2.m1.1.1.4.cmml" xref="S3.F3.2.m1.1.1.4"><csymbol cd="latexml" id="S3.F3.2.m1.1.1.4.1.cmml" xref="S3.F3.2.m1.1.1.4.1">percent</csymbol><cn type="float" id="S3.F3.2.m1.1.1.4.2.cmml" xref="S3.F3.2.m1.1.1.4.2">89.47</cn></apply></apply><apply id="S3.F3.2.m1.1.1c.cmml" xref="S3.F3.2.m1.1.1"><ci id="S3.F3.2.m1.1.1.5.cmml" xref="S3.F3.2.m1.1.1.5">â†’</ci><share href="#S3.F3.2.m1.1.1.4.cmml" id="S3.F3.2.m1.1.1d.cmml" xref="S3.F3.2.m1.1.1"></share><apply id="S3.F3.2.m1.1.1.6.cmml" xref="S3.F3.2.m1.1.1.6"><csymbol cd="latexml" id="S3.F3.2.m1.1.1.6.1.cmml" xref="S3.F3.2.m1.1.1.6.1">percent</csymbol><cn type="float" id="S3.F3.2.m1.1.1.6.2.cmml" xref="S3.F3.2.m1.1.1.6.2">90.95</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.2.m1.1d">88.75\%\rightarrow 89.47\%\rightarrow 90.95\%</annotation></semantics></math>). Best viewed in color.</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>SynFace with Identity Mixup</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">To increase the intra-class variations of synthetic face images, we incorporate the identity mixup into DiscoFaceGANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> to form a new face generator for face recognition, <em id="S3.SS3.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS3.p1.1.2" class="ltx_text"></span>, the Mixup Face Generator, which is capable of generating different identities and their intermediate states. In this subsection, we first briefly discuss the mechanism of DiscoFaceGAN, and we then introduce how to incorporate the proposed identity mixup into the face generator.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.14" class="ltx_p"><span id="S3.SS3.p2.14.1" class="ltx_text ltx_font_bold">Face Generator</span>. DiscoFaceGANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> can provide the disentangled, precisely-controllable latent representations for the identity of non-existing people, expression, pose, and illumination to generated face images. Specifically, it generates realistic face images <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mi id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><ci id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">x</annotation></semantics></math> from random noise <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><mi id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><ci id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">z</annotation></semantics></math>, which consists of five independent variables <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="z_{i}\in\mathbb{R}^{N_{i}}" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><mrow id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml"><msub id="S3.SS3.p2.3.m3.1.1.2" xref="S3.SS3.p2.3.m3.1.1.2.cmml"><mi id="S3.SS3.p2.3.m3.1.1.2.2" xref="S3.SS3.p2.3.m3.1.1.2.2.cmml">z</mi><mi id="S3.SS3.p2.3.m3.1.1.2.3" xref="S3.SS3.p2.3.m3.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS3.p2.3.m3.1.1.1" xref="S3.SS3.p2.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS3.p2.3.m3.1.1.3" xref="S3.SS3.p2.3.m3.1.1.3.cmml"><mi id="S3.SS3.p2.3.m3.1.1.3.2" xref="S3.SS3.p2.3.m3.1.1.3.2.cmml">â„</mi><msub id="S3.SS3.p2.3.m3.1.1.3.3" xref="S3.SS3.p2.3.m3.1.1.3.3.cmml"><mi id="S3.SS3.p2.3.m3.1.1.3.3.2" xref="S3.SS3.p2.3.m3.1.1.3.3.2.cmml">N</mi><mi id="S3.SS3.p2.3.m3.1.1.3.3.3" xref="S3.SS3.p2.3.m3.1.1.3.3.3.cmml">i</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><apply id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1"><in id="S3.SS3.p2.3.m3.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1.1"></in><apply id="S3.SS3.p2.3.m3.1.1.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.1.1.2.1.cmml" xref="S3.SS3.p2.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS3.p2.3.m3.1.1.2.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2.2">ğ‘§</ci><ci id="S3.SS3.p2.3.m3.1.1.2.3.cmml" xref="S3.SS3.p2.3.m3.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS3.p2.3.m3.1.1.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.1.1.3.1.cmml" xref="S3.SS3.p2.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS3.p2.3.m3.1.1.3.2.cmml" xref="S3.SS3.p2.3.m3.1.1.3.2">â„</ci><apply id="S3.SS3.p2.3.m3.1.1.3.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.1.1.3.3.1.cmml" xref="S3.SS3.p2.3.m3.1.1.3.3">subscript</csymbol><ci id="S3.SS3.p2.3.m3.1.1.3.3.2.cmml" xref="S3.SS3.p2.3.m3.1.1.3.3.2">ğ‘</ci><ci id="S3.SS3.p2.3.m3.1.1.3.3.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3.3.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">z_{i}\in\mathbb{R}^{N_{i}}</annotation></semantics></math> and each of them follows a standard normal distribution. The above five independent variables indicate independent factors for face generation: identity, expression, illumination, pose, and random noise accounting for other properties such as the background. Let <math id="S3.SS3.p2.4.m4.4" class="ltx_Math" alttext="\lambda\doteq[\alpha,\beta,\gamma,\theta]" display="inline"><semantics id="S3.SS3.p2.4.m4.4a"><mrow id="S3.SS3.p2.4.m4.4.5" xref="S3.SS3.p2.4.m4.4.5.cmml"><mi id="S3.SS3.p2.4.m4.4.5.2" xref="S3.SS3.p2.4.m4.4.5.2.cmml">Î»</mi><mo id="S3.SS3.p2.4.m4.4.5.1" xref="S3.SS3.p2.4.m4.4.5.1.cmml">â‰</mo><mrow id="S3.SS3.p2.4.m4.4.5.3.2" xref="S3.SS3.p2.4.m4.4.5.3.1.cmml"><mo stretchy="false" id="S3.SS3.p2.4.m4.4.5.3.2.1" xref="S3.SS3.p2.4.m4.4.5.3.1.cmml">[</mo><mi id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml">Î±</mi><mo id="S3.SS3.p2.4.m4.4.5.3.2.2" xref="S3.SS3.p2.4.m4.4.5.3.1.cmml">,</mo><mi id="S3.SS3.p2.4.m4.2.2" xref="S3.SS3.p2.4.m4.2.2.cmml">Î²</mi><mo id="S3.SS3.p2.4.m4.4.5.3.2.3" xref="S3.SS3.p2.4.m4.4.5.3.1.cmml">,</mo><mi id="S3.SS3.p2.4.m4.3.3" xref="S3.SS3.p2.4.m4.3.3.cmml">Î³</mi><mo id="S3.SS3.p2.4.m4.4.5.3.2.4" xref="S3.SS3.p2.4.m4.4.5.3.1.cmml">,</mo><mi id="S3.SS3.p2.4.m4.4.4" xref="S3.SS3.p2.4.m4.4.4.cmml">Î¸</mi><mo stretchy="false" id="S3.SS3.p2.4.m4.4.5.3.2.5" xref="S3.SS3.p2.4.m4.4.5.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.4b"><apply id="S3.SS3.p2.4.m4.4.5.cmml" xref="S3.SS3.p2.4.m4.4.5"><csymbol cd="latexml" id="S3.SS3.p2.4.m4.4.5.1.cmml" xref="S3.SS3.p2.4.m4.4.5.1">approaches-limit</csymbol><ci id="S3.SS3.p2.4.m4.4.5.2.cmml" xref="S3.SS3.p2.4.m4.4.5.2">ğœ†</ci><list id="S3.SS3.p2.4.m4.4.5.3.1.cmml" xref="S3.SS3.p2.4.m4.4.5.3.2"><ci id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">ğ›¼</ci><ci id="S3.SS3.p2.4.m4.2.2.cmml" xref="S3.SS3.p2.4.m4.2.2">ğ›½</ci><ci id="S3.SS3.p2.4.m4.3.3.cmml" xref="S3.SS3.p2.4.m4.3.3">ğ›¾</ci><ci id="S3.SS3.p2.4.m4.4.4.cmml" xref="S3.SS3.p2.4.m4.4.4">ğœƒ</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.4c">\lambda\doteq[\alpha,\beta,\gamma,\theta]</annotation></semantics></math> denote the latent factors, where <math id="S3.SS3.p2.5.m5.3" class="ltx_Math" alttext="\alpha,\beta,\gamma" display="inline"><semantics id="S3.SS3.p2.5.m5.3a"><mrow id="S3.SS3.p2.5.m5.3.4.2" xref="S3.SS3.p2.5.m5.3.4.1.cmml"><mi id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml">Î±</mi><mo id="S3.SS3.p2.5.m5.3.4.2.1" xref="S3.SS3.p2.5.m5.3.4.1.cmml">,</mo><mi id="S3.SS3.p2.5.m5.2.2" xref="S3.SS3.p2.5.m5.2.2.cmml">Î²</mi><mo id="S3.SS3.p2.5.m5.3.4.2.2" xref="S3.SS3.p2.5.m5.3.4.1.cmml">,</mo><mi id="S3.SS3.p2.5.m5.3.3" xref="S3.SS3.p2.5.m5.3.3.cmml">Î³</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.3b"><list id="S3.SS3.p2.5.m5.3.4.1.cmml" xref="S3.SS3.p2.5.m5.3.4.2"><ci id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1">ğ›¼</ci><ci id="S3.SS3.p2.5.m5.2.2.cmml" xref="S3.SS3.p2.5.m5.2.2">ğ›½</ci><ci id="S3.SS3.p2.5.m5.3.3.cmml" xref="S3.SS3.p2.5.m5.3.3">ğ›¾</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.3c">\alpha,\beta,\gamma</annotation></semantics></math> and <math id="S3.SS3.p2.6.m6.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS3.p2.6.m6.1a"><mi id="S3.SS3.p2.6.m6.1.1" xref="S3.SS3.p2.6.m6.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m6.1b"><ci id="S3.SS3.p2.6.m6.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m6.1c">\theta</annotation></semantics></math> indicate the identity, expression, illumination, and pose coefficient, respectively. Four simple VAEsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> of <math id="S3.SS3.p2.7.m7.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS3.p2.7.m7.1a"><mi id="S3.SS3.p2.7.m7.1.1" xref="S3.SS3.p2.7.m7.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m7.1b"><ci id="S3.SS3.p2.7.m7.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m7.1c">\alpha</annotation></semantics></math>, <math id="S3.SS3.p2.8.m8.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S3.SS3.p2.8.m8.1a"><mi id="S3.SS3.p2.8.m8.1.1" xref="S3.SS3.p2.8.m8.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m8.1b"><ci id="S3.SS3.p2.8.m8.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m8.1c">\beta</annotation></semantics></math>, <math id="S3.SS3.p2.9.m9.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S3.SS3.p2.9.m9.1a"><mi id="S3.SS3.p2.9.m9.1.1" xref="S3.SS3.p2.9.m9.1.1.cmml">Î³</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.9.m9.1b"><ci id="S3.SS3.p2.9.m9.1.1.cmml" xref="S3.SS3.p2.9.m9.1.1">ğ›¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.9.m9.1c">\gamma</annotation></semantics></math> and <math id="S3.SS3.p2.10.m10.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS3.p2.10.m10.1a"><mi id="S3.SS3.p2.10.m10.1.1" xref="S3.SS3.p2.10.m10.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.10.m10.1b"><ci id="S3.SS3.p2.10.m10.1.1.cmml" xref="S3.SS3.p2.10.m10.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.10.m10.1c">\theta</annotation></semantics></math> are then trained for <math id="S3.SS3.p2.11.m11.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS3.p2.11.m11.1a"><mi id="S3.SS3.p2.11.m11.1.1" xref="S3.SS3.p2.11.m11.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.11.m11.1b"><ci id="S3.SS3.p2.11.m11.1.1.cmml" xref="S3.SS3.p2.11.m11.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.11.m11.1c">z</annotation></semantics></math>-space to <math id="S3.SS3.p2.12.m12.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS3.p2.12.m12.1a"><mi id="S3.SS3.p2.12.m12.1.1" xref="S3.SS3.p2.12.m12.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.12.m12.1b"><ci id="S3.SS3.p2.12.m12.1.1.cmml" xref="S3.SS3.p2.12.m12.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.12.m12.1c">\lambda</annotation></semantics></math>-space mapping, which enables training the generator to imitate the rendered faces from 3DMMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. The pipeline of generating a face image is to 1) first randomly sample latent variables from the standard normal distribution, 2) then feed them into the trained VAEs to obtain <math id="S3.SS3.p2.13.m13.3" class="ltx_Math" alttext="\alpha,\beta,\gamma" display="inline"><semantics id="S3.SS3.p2.13.m13.3a"><mrow id="S3.SS3.p2.13.m13.3.4.2" xref="S3.SS3.p2.13.m13.3.4.1.cmml"><mi id="S3.SS3.p2.13.m13.1.1" xref="S3.SS3.p2.13.m13.1.1.cmml">Î±</mi><mo id="S3.SS3.p2.13.m13.3.4.2.1" xref="S3.SS3.p2.13.m13.3.4.1.cmml">,</mo><mi id="S3.SS3.p2.13.m13.2.2" xref="S3.SS3.p2.13.m13.2.2.cmml">Î²</mi><mo id="S3.SS3.p2.13.m13.3.4.2.2" xref="S3.SS3.p2.13.m13.3.4.1.cmml">,</mo><mi id="S3.SS3.p2.13.m13.3.3" xref="S3.SS3.p2.13.m13.3.3.cmml">Î³</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.13.m13.3b"><list id="S3.SS3.p2.13.m13.3.4.1.cmml" xref="S3.SS3.p2.13.m13.3.4.2"><ci id="S3.SS3.p2.13.m13.1.1.cmml" xref="S3.SS3.p2.13.m13.1.1">ğ›¼</ci><ci id="S3.SS3.p2.13.m13.2.2.cmml" xref="S3.SS3.p2.13.m13.2.2">ğ›½</ci><ci id="S3.SS3.p2.13.m13.3.3.cmml" xref="S3.SS3.p2.13.m13.3.3">ğ›¾</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.13.m13.3c">\alpha,\beta,\gamma</annotation></semantics></math> and <math id="S3.SS3.p2.14.m14.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS3.p2.14.m14.1a"><mi id="S3.SS3.p2.14.m14.1.1" xref="S3.SS3.p2.14.m14.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.14.m14.1b"><ci id="S3.SS3.p2.14.m14.1.1.cmml" xref="S3.SS3.p2.14.m14.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.14.m14.1c">\theta</annotation></semantics></math> coefficients, and 3) the corresponding face image is synthesized by the generator using these coefficients.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2108.07960/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="415" height="335" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span> Examples of an identity gradually and smoothly varying to another identity as the weighted ratio <math id="S3.F4.2.m1.1" class="ltx_Math" alttext="\varphi" display="inline"><semantics id="S3.F4.2.m1.1b"><mi id="S3.F4.2.m1.1.1" xref="S3.F4.2.m1.1.1.cmml">Ï†</mi><annotation-xml encoding="MathML-Content" id="S3.F4.2.m1.1c"><ci id="S3.F4.2.m1.1.1.cmml" xref="S3.F4.2.m1.1.1">ğœ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.2.m1.1d">\varphi</annotation></semantics></math> varies from 0 to 1.</figcaption>
</figure>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p"><span id="S3.SS3.p3.1.1" class="ltx_text ltx_font_bold">Identity Mixup (IM)</span>. Inspired by the reenactment of face imagesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>, we propose to enlarge the intra-class variations by interpolating two different identities as a new intermediate one with changing the label correspondingly. Recalling that the coefficient <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><mi id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><ci id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">\alpha</annotation></semantics></math> controls the identity characteristic, we thus interpolate two different identity coefficients to generate a new intermediate identity coefficient. Mathematically, it can be formulated as follows:</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.35" class="ltx_Math" alttext="\begin{split}\alpha&amp;=\varphi\cdot\alpha_{1}+(1-\varphi)\cdot\alpha_{2},\\
\eta&amp;=\varphi\cdot\eta_{1}+(1-\varphi)\cdot\eta_{2},\end{split}" display="block"><semantics id="S3.E2.m1.35a"><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt" id="S3.E2.m1.35.35.3"><mtr id="S3.E2.m1.35.35.3a"><mtd class="ltx_align_right" columnalign="right" id="S3.E2.m1.35.35.3b"><mi id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml">Î±</mi></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E2.m1.35.35.3c"><mrow id="S3.E2.m1.34.34.2.33.17.16.16"><mrow id="S3.E2.m1.34.34.2.33.17.16.16.1"><mi id="S3.E2.m1.34.34.2.33.17.16.16.1.2"></mi><mo id="S3.E2.m1.2.2.2.2.1.1" xref="S3.E2.m1.2.2.2.2.1.1.cmml">=</mo><mrow id="S3.E2.m1.34.34.2.33.17.16.16.1.1"><mrow id="S3.E2.m1.34.34.2.33.17.16.16.1.1.2"><mi id="S3.E2.m1.3.3.3.3.2.2" xref="S3.E2.m1.3.3.3.3.2.2.cmml">Ï†</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E2.m1.4.4.4.4.3.3" xref="S3.E2.m1.4.4.4.4.3.3.cmml">â‹…</mo><msub id="S3.E2.m1.34.34.2.33.17.16.16.1.1.2.1"><mi id="S3.E2.m1.5.5.5.5.4.4" xref="S3.E2.m1.5.5.5.5.4.4.cmml">Î±</mi><mn id="S3.E2.m1.6.6.6.6.5.5.1" xref="S3.E2.m1.6.6.6.6.5.5.1.cmml">1</mn></msub></mrow><mo id="S3.E2.m1.7.7.7.7.6.6" xref="S3.E2.m1.7.7.7.7.6.6.cmml">+</mo><mrow id="S3.E2.m1.34.34.2.33.17.16.16.1.1.1"><mrow id="S3.E2.m1.34.34.2.33.17.16.16.1.1.1.1.1"><mo stretchy="false" id="S3.E2.m1.8.8.8.8.7.7">(</mo><mrow id="S3.E2.m1.34.34.2.33.17.16.16.1.1.1.1.1.1"><mn id="S3.E2.m1.9.9.9.9.8.8" xref="S3.E2.m1.9.9.9.9.8.8.cmml">1</mn><mo id="S3.E2.m1.10.10.10.10.9.9" xref="S3.E2.m1.10.10.10.10.9.9.cmml">âˆ’</mo><mi id="S3.E2.m1.11.11.11.11.10.10" xref="S3.E2.m1.11.11.11.11.10.10.cmml">Ï†</mi></mrow><mo rspace="0.055em" stretchy="false" id="S3.E2.m1.12.12.12.12.11.11">)</mo></mrow><mo rspace="0.222em" id="S3.E2.m1.13.13.13.13.12.12" xref="S3.E2.m1.13.13.13.13.12.12.cmml">â‹…</mo><msub id="S3.E2.m1.34.34.2.33.17.16.16.1.1.1.2"><mi id="S3.E2.m1.14.14.14.14.13.13" xref="S3.E2.m1.14.14.14.14.13.13.cmml">Î±</mi><mn id="S3.E2.m1.15.15.15.15.14.14.1" xref="S3.E2.m1.15.15.15.15.14.14.1.cmml">2</mn></msub></mrow></mrow></mrow><mo id="S3.E2.m1.16.16.16.16.15.15">,</mo></mrow></mtd></mtr><mtr id="S3.E2.m1.35.35.3d"><mtd class="ltx_align_right" columnalign="right" id="S3.E2.m1.35.35.3e"><mi id="S3.E2.m1.17.17.17.1.1.1" xref="S3.E2.m1.17.17.17.1.1.1.cmml">Î·</mi></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E2.m1.35.35.3f"><mrow id="S3.E2.m1.35.35.3.34.17.16.16"><mrow id="S3.E2.m1.35.35.3.34.17.16.16.1"><mi id="S3.E2.m1.35.35.3.34.17.16.16.1.2"></mi><mo id="S3.E2.m1.18.18.18.2.1.1" xref="S3.E2.m1.18.18.18.2.1.1.cmml">=</mo><mrow id="S3.E2.m1.35.35.3.34.17.16.16.1.1"><mrow id="S3.E2.m1.35.35.3.34.17.16.16.1.1.2"><mi id="S3.E2.m1.19.19.19.3.2.2" xref="S3.E2.m1.19.19.19.3.2.2.cmml">Ï†</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E2.m1.20.20.20.4.3.3" xref="S3.E2.m1.20.20.20.4.3.3.cmml">â‹…</mo><msub id="S3.E2.m1.35.35.3.34.17.16.16.1.1.2.1"><mi id="S3.E2.m1.21.21.21.5.4.4" xref="S3.E2.m1.21.21.21.5.4.4.cmml">Î·</mi><mn id="S3.E2.m1.22.22.22.6.5.5.1" xref="S3.E2.m1.22.22.22.6.5.5.1.cmml">1</mn></msub></mrow><mo id="S3.E2.m1.23.23.23.7.6.6" xref="S3.E2.m1.23.23.23.7.6.6.cmml">+</mo><mrow id="S3.E2.m1.35.35.3.34.17.16.16.1.1.1"><mrow id="S3.E2.m1.35.35.3.34.17.16.16.1.1.1.1.1"><mo stretchy="false" id="S3.E2.m1.24.24.24.8.7.7">(</mo><mrow id="S3.E2.m1.35.35.3.34.17.16.16.1.1.1.1.1.1"><mn id="S3.E2.m1.25.25.25.9.8.8" xref="S3.E2.m1.25.25.25.9.8.8.cmml">1</mn><mo id="S3.E2.m1.26.26.26.10.9.9" xref="S3.E2.m1.26.26.26.10.9.9.cmml">âˆ’</mo><mi id="S3.E2.m1.27.27.27.11.10.10" xref="S3.E2.m1.27.27.27.11.10.10.cmml">Ï†</mi></mrow><mo rspace="0.055em" stretchy="false" id="S3.E2.m1.28.28.28.12.11.11">)</mo></mrow><mo rspace="0.222em" id="S3.E2.m1.29.29.29.13.12.12" xref="S3.E2.m1.29.29.29.13.12.12.cmml">â‹…</mo><msub id="S3.E2.m1.35.35.3.34.17.16.16.1.1.1.2"><mi id="S3.E2.m1.30.30.30.14.13.13" xref="S3.E2.m1.30.30.30.14.13.13.cmml">Î·</mi><mn id="S3.E2.m1.31.31.31.15.14.14.1" xref="S3.E2.m1.31.31.31.15.14.14.1.cmml">2</mn></msub></mrow></mrow></mrow><mo id="S3.E2.m1.32.32.32.16.15.15">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E2.m1.35b"><apply id="S3.E2.m1.33.33.1.1.1.3.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.33.33.1.1.1.3a.cmml">formulae-sequence</csymbol><apply id="S3.E2.m1.33.33.1.1.1.1.1.cmml"><eq id="S3.E2.m1.2.2.2.2.1.1.cmml" xref="S3.E2.m1.2.2.2.2.1.1"></eq><ci id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1">ğ›¼</ci><apply id="S3.E2.m1.33.33.1.1.1.1.1.1.cmml"><plus id="S3.E2.m1.7.7.7.7.6.6.cmml" xref="S3.E2.m1.7.7.7.7.6.6"></plus><apply id="S3.E2.m1.33.33.1.1.1.1.1.1.3.cmml"><ci id="S3.E2.m1.4.4.4.4.3.3.cmml" xref="S3.E2.m1.4.4.4.4.3.3">â‹…</ci><ci id="S3.E2.m1.3.3.3.3.2.2.cmml" xref="S3.E2.m1.3.3.3.3.2.2">ğœ‘</ci><apply id="S3.E2.m1.33.33.1.1.1.1.1.1.3.3.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.33.33.1.1.1.1.1.1.3.3.1.cmml">subscript</csymbol><ci id="S3.E2.m1.5.5.5.5.4.4.cmml" xref="S3.E2.m1.5.5.5.5.4.4">ğ›¼</ci><cn type="integer" id="S3.E2.m1.6.6.6.6.5.5.1.cmml" xref="S3.E2.m1.6.6.6.6.5.5.1">1</cn></apply></apply><apply id="S3.E2.m1.33.33.1.1.1.1.1.1.1.cmml"><ci id="S3.E2.m1.13.13.13.13.12.12.cmml" xref="S3.E2.m1.13.13.13.13.12.12">â‹…</ci><apply id="S3.E2.m1.33.33.1.1.1.1.1.1.1.1.1.1.cmml"><minus id="S3.E2.m1.10.10.10.10.9.9.cmml" xref="S3.E2.m1.10.10.10.10.9.9"></minus><cn type="integer" id="S3.E2.m1.9.9.9.9.8.8.cmml" xref="S3.E2.m1.9.9.9.9.8.8">1</cn><ci id="S3.E2.m1.11.11.11.11.10.10.cmml" xref="S3.E2.m1.11.11.11.11.10.10">ğœ‘</ci></apply><apply id="S3.E2.m1.33.33.1.1.1.1.1.1.1.3.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.33.33.1.1.1.1.1.1.1.3.1.cmml">subscript</csymbol><ci id="S3.E2.m1.14.14.14.14.13.13.cmml" xref="S3.E2.m1.14.14.14.14.13.13">ğ›¼</ci><cn type="integer" id="S3.E2.m1.15.15.15.15.14.14.1.cmml" xref="S3.E2.m1.15.15.15.15.14.14.1">2</cn></apply></apply></apply></apply><apply id="S3.E2.m1.33.33.1.1.1.2.2.cmml"><eq id="S3.E2.m1.18.18.18.2.1.1.cmml" xref="S3.E2.m1.18.18.18.2.1.1"></eq><ci id="S3.E2.m1.17.17.17.1.1.1.cmml" xref="S3.E2.m1.17.17.17.1.1.1">ğœ‚</ci><apply id="S3.E2.m1.33.33.1.1.1.2.2.1.cmml"><plus id="S3.E2.m1.23.23.23.7.6.6.cmml" xref="S3.E2.m1.23.23.23.7.6.6"></plus><apply id="S3.E2.m1.33.33.1.1.1.2.2.1.3.cmml"><ci id="S3.E2.m1.20.20.20.4.3.3.cmml" xref="S3.E2.m1.20.20.20.4.3.3">â‹…</ci><ci id="S3.E2.m1.19.19.19.3.2.2.cmml" xref="S3.E2.m1.19.19.19.3.2.2">ğœ‘</ci><apply id="S3.E2.m1.33.33.1.1.1.2.2.1.3.3.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.33.33.1.1.1.2.2.1.3.3.1.cmml">subscript</csymbol><ci id="S3.E2.m1.21.21.21.5.4.4.cmml" xref="S3.E2.m1.21.21.21.5.4.4">ğœ‚</ci><cn type="integer" id="S3.E2.m1.22.22.22.6.5.5.1.cmml" xref="S3.E2.m1.22.22.22.6.5.5.1">1</cn></apply></apply><apply id="S3.E2.m1.33.33.1.1.1.2.2.1.1.cmml"><ci id="S3.E2.m1.29.29.29.13.12.12.cmml" xref="S3.E2.m1.29.29.29.13.12.12">â‹…</ci><apply id="S3.E2.m1.33.33.1.1.1.2.2.1.1.1.1.1.cmml"><minus id="S3.E2.m1.26.26.26.10.9.9.cmml" xref="S3.E2.m1.26.26.26.10.9.9"></minus><cn type="integer" id="S3.E2.m1.25.25.25.9.8.8.cmml" xref="S3.E2.m1.25.25.25.9.8.8">1</cn><ci id="S3.E2.m1.27.27.27.11.10.10.cmml" xref="S3.E2.m1.27.27.27.11.10.10">ğœ‘</ci></apply><apply id="S3.E2.m1.33.33.1.1.1.2.2.1.1.3.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.33.33.1.1.1.2.2.1.1.3.1.cmml">subscript</csymbol><ci id="S3.E2.m1.30.30.30.14.13.13.cmml" xref="S3.E2.m1.30.30.30.14.13.13">ğœ‚</ci><cn type="integer" id="S3.E2.m1.31.31.31.15.14.14.1.cmml" xref="S3.E2.m1.31.31.31.15.14.14.1">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.35c">\begin{split}\alpha&amp;=\varphi\cdot\alpha_{1}+(1-\varphi)\cdot\alpha_{2},\\
\eta&amp;=\varphi\cdot\eta_{1}+(1-\varphi)\cdot\eta_{2},\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p4.9" class="ltx_p">where <math id="S3.SS3.p4.1.m1.1" class="ltx_Math" alttext="\alpha_{1}" display="inline"><semantics id="S3.SS3.p4.1.m1.1a"><msub id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml"><mi id="S3.SS3.p4.1.m1.1.1.2" xref="S3.SS3.p4.1.m1.1.1.2.cmml">Î±</mi><mn id="S3.SS3.p4.1.m1.1.1.3" xref="S3.SS3.p4.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><apply id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p4.1.m1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.1.1.2">ğ›¼</ci><cn type="integer" id="S3.SS3.p4.1.m1.1.1.3.cmml" xref="S3.SS3.p4.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">\alpha_{1}</annotation></semantics></math>, <math id="S3.SS3.p4.2.m2.1" class="ltx_Math" alttext="\alpha_{2}" display="inline"><semantics id="S3.SS3.p4.2.m2.1a"><msub id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml"><mi id="S3.SS3.p4.2.m2.1.1.2" xref="S3.SS3.p4.2.m2.1.1.2.cmml">Î±</mi><mn id="S3.SS3.p4.2.m2.1.1.3" xref="S3.SS3.p4.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><apply id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p4.2.m2.1.1.2.cmml" xref="S3.SS3.p4.2.m2.1.1.2">ğ›¼</ci><cn type="integer" id="S3.SS3.p4.2.m2.1.1.3.cmml" xref="S3.SS3.p4.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">\alpha_{2}</annotation></semantics></math> are two random identity coefficients from <math id="S3.SS3.p4.3.m3.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS3.p4.3.m3.1a"><mi id="S3.SS3.p4.3.m3.1.1" xref="S3.SS3.p4.3.m3.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m3.1b"><ci id="S3.SS3.p4.3.m3.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.3.m3.1c">\lambda</annotation></semantics></math>-space, and <math id="S3.SS3.p4.4.m4.1" class="ltx_Math" alttext="\eta_{1}" display="inline"><semantics id="S3.SS3.p4.4.m4.1a"><msub id="S3.SS3.p4.4.m4.1.1" xref="S3.SS3.p4.4.m4.1.1.cmml"><mi id="S3.SS3.p4.4.m4.1.1.2" xref="S3.SS3.p4.4.m4.1.1.2.cmml">Î·</mi><mn id="S3.SS3.p4.4.m4.1.1.3" xref="S3.SS3.p4.4.m4.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.4.m4.1b"><apply id="S3.SS3.p4.4.m4.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.4.m4.1.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p4.4.m4.1.1.2.cmml" xref="S3.SS3.p4.4.m4.1.1.2">ğœ‚</ci><cn type="integer" id="S3.SS3.p4.4.m4.1.1.3.cmml" xref="S3.SS3.p4.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.4.m4.1c">\eta_{1}</annotation></semantics></math>, <math id="S3.SS3.p4.5.m5.1" class="ltx_Math" alttext="\eta_{2}" display="inline"><semantics id="S3.SS3.p4.5.m5.1a"><msub id="S3.SS3.p4.5.m5.1.1" xref="S3.SS3.p4.5.m5.1.1.cmml"><mi id="S3.SS3.p4.5.m5.1.1.2" xref="S3.SS3.p4.5.m5.1.1.2.cmml">Î·</mi><mn id="S3.SS3.p4.5.m5.1.1.3" xref="S3.SS3.p4.5.m5.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.5.m5.1b"><apply id="S3.SS3.p4.5.m5.1.1.cmml" xref="S3.SS3.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.5.m5.1.1.1.cmml" xref="S3.SS3.p4.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.p4.5.m5.1.1.2.cmml" xref="S3.SS3.p4.5.m5.1.1.2">ğœ‚</ci><cn type="integer" id="S3.SS3.p4.5.m5.1.1.3.cmml" xref="S3.SS3.p4.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.5.m5.1c">\eta_{2}</annotation></semantics></math> are the corresponding class labels. Note that the weighted ratio <math id="S3.SS3.p4.6.m6.1" class="ltx_Math" alttext="\varphi" display="inline"><semantics id="S3.SS3.p4.6.m6.1a"><mi id="S3.SS3.p4.6.m6.1.1" xref="S3.SS3.p4.6.m6.1.1.cmml">Ï†</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.6.m6.1b"><ci id="S3.SS3.p4.6.m6.1.1.cmml" xref="S3.SS3.p4.6.m6.1.1">ğœ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.6.m6.1c">\varphi</annotation></semantics></math> is randomly sampled from the linear space which varies from <math id="S3.SS3.p4.7.m7.1" class="ltx_Math" alttext="0.0" display="inline"><semantics id="S3.SS3.p4.7.m7.1a"><mn id="S3.SS3.p4.7.m7.1.1" xref="S3.SS3.p4.7.m7.1.1.cmml">0.0</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.7.m7.1b"><cn type="float" id="S3.SS3.p4.7.m7.1.1.cmml" xref="S3.SS3.p4.7.m7.1.1">0.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.7.m7.1c">0.0</annotation></semantics></math> to <math id="S3.SS3.p4.8.m8.1" class="ltx_Math" alttext="1.0" display="inline"><semantics id="S3.SS3.p4.8.m8.1a"><mn id="S3.SS3.p4.8.m8.1.1" xref="S3.SS3.p4.8.m8.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.8.m8.1b"><cn type="float" id="S3.SS3.p4.8.m8.1.1.cmml" xref="S3.SS3.p4.8.m8.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.8.m8.1c">1.0</annotation></semantics></math> with interval being 0.05 (<em id="S3.SS3.p4.9.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS3.p4.9.2" class="ltx_text"></span>, <math id="S3.SS3.p4.9.m9.5" class="ltx_Math" alttext="np.linspace(0.0,1.0,21)" display="inline"><semantics id="S3.SS3.p4.9.m9.5a"><mrow id="S3.SS3.p4.9.m9.5.5.2" xref="S3.SS3.p4.9.m9.5.5.3.cmml"><mrow id="S3.SS3.p4.9.m9.4.4.1.1" xref="S3.SS3.p4.9.m9.4.4.1.1.cmml"><mi id="S3.SS3.p4.9.m9.4.4.1.1.2" xref="S3.SS3.p4.9.m9.4.4.1.1.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.9.m9.4.4.1.1.1" xref="S3.SS3.p4.9.m9.4.4.1.1.1.cmml">â€‹</mo><mi id="S3.SS3.p4.9.m9.4.4.1.1.3" xref="S3.SS3.p4.9.m9.4.4.1.1.3.cmml">p</mi></mrow><mo lspace="0em" rspace="0.167em" id="S3.SS3.p4.9.m9.5.5.2.3" xref="S3.SS3.p4.9.m9.5.5.3a.cmml">.</mo><mrow id="S3.SS3.p4.9.m9.5.5.2.2" xref="S3.SS3.p4.9.m9.5.5.2.2.cmml"><mi id="S3.SS3.p4.9.m9.5.5.2.2.2" xref="S3.SS3.p4.9.m9.5.5.2.2.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.9.m9.5.5.2.2.1" xref="S3.SS3.p4.9.m9.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS3.p4.9.m9.5.5.2.2.3" xref="S3.SS3.p4.9.m9.5.5.2.2.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.9.m9.5.5.2.2.1a" xref="S3.SS3.p4.9.m9.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS3.p4.9.m9.5.5.2.2.4" xref="S3.SS3.p4.9.m9.5.5.2.2.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.9.m9.5.5.2.2.1b" xref="S3.SS3.p4.9.m9.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS3.p4.9.m9.5.5.2.2.5" xref="S3.SS3.p4.9.m9.5.5.2.2.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.9.m9.5.5.2.2.1c" xref="S3.SS3.p4.9.m9.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS3.p4.9.m9.5.5.2.2.6" xref="S3.SS3.p4.9.m9.5.5.2.2.6.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.9.m9.5.5.2.2.1d" xref="S3.SS3.p4.9.m9.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS3.p4.9.m9.5.5.2.2.7" xref="S3.SS3.p4.9.m9.5.5.2.2.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.9.m9.5.5.2.2.1e" xref="S3.SS3.p4.9.m9.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS3.p4.9.m9.5.5.2.2.8" xref="S3.SS3.p4.9.m9.5.5.2.2.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.9.m9.5.5.2.2.1f" xref="S3.SS3.p4.9.m9.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS3.p4.9.m9.5.5.2.2.9" xref="S3.SS3.p4.9.m9.5.5.2.2.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.9.m9.5.5.2.2.1g" xref="S3.SS3.p4.9.m9.5.5.2.2.1.cmml">â€‹</mo><mrow id="S3.SS3.p4.9.m9.5.5.2.2.10.2" xref="S3.SS3.p4.9.m9.5.5.2.2.10.1.cmml"><mo stretchy="false" id="S3.SS3.p4.9.m9.5.5.2.2.10.2.1" xref="S3.SS3.p4.9.m9.5.5.2.2.10.1.cmml">(</mo><mn id="S3.SS3.p4.9.m9.1.1" xref="S3.SS3.p4.9.m9.1.1.cmml">0.0</mn><mo id="S3.SS3.p4.9.m9.5.5.2.2.10.2.2" xref="S3.SS3.p4.9.m9.5.5.2.2.10.1.cmml">,</mo><mn id="S3.SS3.p4.9.m9.2.2" xref="S3.SS3.p4.9.m9.2.2.cmml">1.0</mn><mo id="S3.SS3.p4.9.m9.5.5.2.2.10.2.3" xref="S3.SS3.p4.9.m9.5.5.2.2.10.1.cmml">,</mo><mn id="S3.SS3.p4.9.m9.3.3" xref="S3.SS3.p4.9.m9.3.3.cmml">21</mn><mo stretchy="false" id="S3.SS3.p4.9.m9.5.5.2.2.10.2.4" xref="S3.SS3.p4.9.m9.5.5.2.2.10.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.9.m9.5b"><apply id="S3.SS3.p4.9.m9.5.5.3.cmml" xref="S3.SS3.p4.9.m9.5.5.2"><csymbol cd="ambiguous" id="S3.SS3.p4.9.m9.5.5.3a.cmml" xref="S3.SS3.p4.9.m9.5.5.2.3">formulae-sequence</csymbol><apply id="S3.SS3.p4.9.m9.4.4.1.1.cmml" xref="S3.SS3.p4.9.m9.4.4.1.1"><times id="S3.SS3.p4.9.m9.4.4.1.1.1.cmml" xref="S3.SS3.p4.9.m9.4.4.1.1.1"></times><ci id="S3.SS3.p4.9.m9.4.4.1.1.2.cmml" xref="S3.SS3.p4.9.m9.4.4.1.1.2">ğ‘›</ci><ci id="S3.SS3.p4.9.m9.4.4.1.1.3.cmml" xref="S3.SS3.p4.9.m9.4.4.1.1.3">ğ‘</ci></apply><apply id="S3.SS3.p4.9.m9.5.5.2.2.cmml" xref="S3.SS3.p4.9.m9.5.5.2.2"><times id="S3.SS3.p4.9.m9.5.5.2.2.1.cmml" xref="S3.SS3.p4.9.m9.5.5.2.2.1"></times><ci id="S3.SS3.p4.9.m9.5.5.2.2.2.cmml" xref="S3.SS3.p4.9.m9.5.5.2.2.2">ğ‘™</ci><ci id="S3.SS3.p4.9.m9.5.5.2.2.3.cmml" xref="S3.SS3.p4.9.m9.5.5.2.2.3">ğ‘–</ci><ci id="S3.SS3.p4.9.m9.5.5.2.2.4.cmml" xref="S3.SS3.p4.9.m9.5.5.2.2.4">ğ‘›</ci><ci id="S3.SS3.p4.9.m9.5.5.2.2.5.cmml" xref="S3.SS3.p4.9.m9.5.5.2.2.5">ğ‘ </ci><ci id="S3.SS3.p4.9.m9.5.5.2.2.6.cmml" xref="S3.SS3.p4.9.m9.5.5.2.2.6">ğ‘</ci><ci id="S3.SS3.p4.9.m9.5.5.2.2.7.cmml" xref="S3.SS3.p4.9.m9.5.5.2.2.7">ğ‘</ci><ci id="S3.SS3.p4.9.m9.5.5.2.2.8.cmml" xref="S3.SS3.p4.9.m9.5.5.2.2.8">ğ‘</ci><ci id="S3.SS3.p4.9.m9.5.5.2.2.9.cmml" xref="S3.SS3.p4.9.m9.5.5.2.2.9">ğ‘’</ci><vector id="S3.SS3.p4.9.m9.5.5.2.2.10.1.cmml" xref="S3.SS3.p4.9.m9.5.5.2.2.10.2"><cn type="float" id="S3.SS3.p4.9.m9.1.1.cmml" xref="S3.SS3.p4.9.m9.1.1">0.0</cn><cn type="float" id="S3.SS3.p4.9.m9.2.2.cmml" xref="S3.SS3.p4.9.m9.2.2">1.0</cn><cn type="integer" id="S3.SS3.p4.9.m9.3.3.cmml" xref="S3.SS3.p4.9.m9.3.3">21</cn></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.9.m9.5c">np.linspace(0.0,1.0,21)</annotation></semantics></math>). Comparing to the vanilla mixupÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> which is employed at the pixel level, the proposed mixup is operating on the identity coefficient latent space, denoted as identity mixup (IM), which enlarges the intra-class variations by linearly interpolating different identities, forming the Mixup Face Generator. However, both of them can regularize the model to favor the simple linear behavior in-between training samples.</p>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<p id="S3.SS3.p5.6" class="ltx_p">As illustrated in FigureÂ <a href="#S2.F2" title="Figure 2 â€£ 2 Related Work â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the pipeline of Mixup Face Generator is first randomly sampling two different identity latent variables from the standard normal distribution, and then feeding them to the trained VAEs to obtain <math id="S3.SS3.p5.1.m1.2" class="ltx_Math" alttext="\alpha_{1},\alpha_{2}" display="inline"><semantics id="S3.SS3.p5.1.m1.2a"><mrow id="S3.SS3.p5.1.m1.2.2.2" xref="S3.SS3.p5.1.m1.2.2.3.cmml"><msub id="S3.SS3.p5.1.m1.1.1.1.1" xref="S3.SS3.p5.1.m1.1.1.1.1.cmml"><mi id="S3.SS3.p5.1.m1.1.1.1.1.2" xref="S3.SS3.p5.1.m1.1.1.1.1.2.cmml">Î±</mi><mn id="S3.SS3.p5.1.m1.1.1.1.1.3" xref="S3.SS3.p5.1.m1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.p5.1.m1.2.2.2.3" xref="S3.SS3.p5.1.m1.2.2.3.cmml">,</mo><msub id="S3.SS3.p5.1.m1.2.2.2.2" xref="S3.SS3.p5.1.m1.2.2.2.2.cmml"><mi id="S3.SS3.p5.1.m1.2.2.2.2.2" xref="S3.SS3.p5.1.m1.2.2.2.2.2.cmml">Î±</mi><mn id="S3.SS3.p5.1.m1.2.2.2.2.3" xref="S3.SS3.p5.1.m1.2.2.2.2.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.m1.2b"><list id="S3.SS3.p5.1.m1.2.2.3.cmml" xref="S3.SS3.p5.1.m1.2.2.2"><apply id="S3.SS3.p5.1.m1.1.1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.1.m1.1.1.1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p5.1.m1.1.1.1.1.2.cmml" xref="S3.SS3.p5.1.m1.1.1.1.1.2">ğ›¼</ci><cn type="integer" id="S3.SS3.p5.1.m1.1.1.1.1.3.cmml" xref="S3.SS3.p5.1.m1.1.1.1.1.3">1</cn></apply><apply id="S3.SS3.p5.1.m1.2.2.2.2.cmml" xref="S3.SS3.p5.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p5.1.m1.2.2.2.2.1.cmml" xref="S3.SS3.p5.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p5.1.m1.2.2.2.2.2.cmml" xref="S3.SS3.p5.1.m1.2.2.2.2.2">ğ›¼</ci><cn type="integer" id="S3.SS3.p5.1.m1.2.2.2.2.3.cmml" xref="S3.SS3.p5.1.m1.2.2.2.2.3">2</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.1.m1.2c">\alpha_{1},\alpha_{2}</annotation></semantics></math> coefficients. The mixed identity coefficient <math id="S3.SS3.p5.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS3.p5.2.m2.1a"><mi id="S3.SS3.p5.2.m2.1.1" xref="S3.SS3.p5.2.m2.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.2.m2.1b"><ci id="S3.SS3.p5.2.m2.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.2.m2.1c">\alpha</annotation></semantics></math> is obtained by identity mixup with <math id="S3.SS3.p5.3.m3.2" class="ltx_Math" alttext="\alpha_{1},\alpha_{2}" display="inline"><semantics id="S3.SS3.p5.3.m3.2a"><mrow id="S3.SS3.p5.3.m3.2.2.2" xref="S3.SS3.p5.3.m3.2.2.3.cmml"><msub id="S3.SS3.p5.3.m3.1.1.1.1" xref="S3.SS3.p5.3.m3.1.1.1.1.cmml"><mi id="S3.SS3.p5.3.m3.1.1.1.1.2" xref="S3.SS3.p5.3.m3.1.1.1.1.2.cmml">Î±</mi><mn id="S3.SS3.p5.3.m3.1.1.1.1.3" xref="S3.SS3.p5.3.m3.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.p5.3.m3.2.2.2.3" xref="S3.SS3.p5.3.m3.2.2.3.cmml">,</mo><msub id="S3.SS3.p5.3.m3.2.2.2.2" xref="S3.SS3.p5.3.m3.2.2.2.2.cmml"><mi id="S3.SS3.p5.3.m3.2.2.2.2.2" xref="S3.SS3.p5.3.m3.2.2.2.2.2.cmml">Î±</mi><mn id="S3.SS3.p5.3.m3.2.2.2.2.3" xref="S3.SS3.p5.3.m3.2.2.2.2.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.3.m3.2b"><list id="S3.SS3.p5.3.m3.2.2.3.cmml" xref="S3.SS3.p5.3.m3.2.2.2"><apply id="S3.SS3.p5.3.m3.1.1.1.1.cmml" xref="S3.SS3.p5.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.3.m3.1.1.1.1.1.cmml" xref="S3.SS3.p5.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p5.3.m3.1.1.1.1.2.cmml" xref="S3.SS3.p5.3.m3.1.1.1.1.2">ğ›¼</ci><cn type="integer" id="S3.SS3.p5.3.m3.1.1.1.1.3.cmml" xref="S3.SS3.p5.3.m3.1.1.1.1.3">1</cn></apply><apply id="S3.SS3.p5.3.m3.2.2.2.2.cmml" xref="S3.SS3.p5.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p5.3.m3.2.2.2.2.1.cmml" xref="S3.SS3.p5.3.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p5.3.m3.2.2.2.2.2.cmml" xref="S3.SS3.p5.3.m3.2.2.2.2.2">ğ›¼</ci><cn type="integer" id="S3.SS3.p5.3.m3.2.2.2.2.3.cmml" xref="S3.SS3.p5.3.m3.2.2.2.2.3">2</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.3.m3.2c">\alpha_{1},\alpha_{2}</annotation></semantics></math> according to Eq.Â (<a href="#S3.E2" title="In 3.3 SynFace with Identity Mixup â€£ 3 Method â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), the corresponding face image is finally synthesized by the generator with <math id="S3.SS3.p5.4.m4.2" class="ltx_Math" alttext="\alpha,\mu" display="inline"><semantics id="S3.SS3.p5.4.m4.2a"><mrow id="S3.SS3.p5.4.m4.2.3.2" xref="S3.SS3.p5.4.m4.2.3.1.cmml"><mi id="S3.SS3.p5.4.m4.1.1" xref="S3.SS3.p5.4.m4.1.1.cmml">Î±</mi><mo id="S3.SS3.p5.4.m4.2.3.2.1" xref="S3.SS3.p5.4.m4.2.3.1.cmml">,</mo><mi id="S3.SS3.p5.4.m4.2.2" xref="S3.SS3.p5.4.m4.2.2.cmml">Î¼</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.4.m4.2b"><list id="S3.SS3.p5.4.m4.2.3.1.cmml" xref="S3.SS3.p5.4.m4.2.3.2"><ci id="S3.SS3.p5.4.m4.1.1.cmml" xref="S3.SS3.p5.4.m4.1.1">ğ›¼</ci><ci id="S3.SS3.p5.4.m4.2.2.cmml" xref="S3.SS3.p5.4.m4.2.2">ğœ‡</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.4.m4.2c">\alpha,\mu</annotation></semantics></math> coefficients (where <math id="S3.SS3.p5.5.m5.3" class="ltx_Math" alttext="\mu\doteq[\beta,\gamma,\theta]" display="inline"><semantics id="S3.SS3.p5.5.m5.3a"><mrow id="S3.SS3.p5.5.m5.3.4" xref="S3.SS3.p5.5.m5.3.4.cmml"><mi id="S3.SS3.p5.5.m5.3.4.2" xref="S3.SS3.p5.5.m5.3.4.2.cmml">Î¼</mi><mo id="S3.SS3.p5.5.m5.3.4.1" xref="S3.SS3.p5.5.m5.3.4.1.cmml">â‰</mo><mrow id="S3.SS3.p5.5.m5.3.4.3.2" xref="S3.SS3.p5.5.m5.3.4.3.1.cmml"><mo stretchy="false" id="S3.SS3.p5.5.m5.3.4.3.2.1" xref="S3.SS3.p5.5.m5.3.4.3.1.cmml">[</mo><mi id="S3.SS3.p5.5.m5.1.1" xref="S3.SS3.p5.5.m5.1.1.cmml">Î²</mi><mo id="S3.SS3.p5.5.m5.3.4.3.2.2" xref="S3.SS3.p5.5.m5.3.4.3.1.cmml">,</mo><mi id="S3.SS3.p5.5.m5.2.2" xref="S3.SS3.p5.5.m5.2.2.cmml">Î³</mi><mo id="S3.SS3.p5.5.m5.3.4.3.2.3" xref="S3.SS3.p5.5.m5.3.4.3.1.cmml">,</mo><mi id="S3.SS3.p5.5.m5.3.3" xref="S3.SS3.p5.5.m5.3.3.cmml">Î¸</mi><mo stretchy="false" id="S3.SS3.p5.5.m5.3.4.3.2.4" xref="S3.SS3.p5.5.m5.3.4.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.5.m5.3b"><apply id="S3.SS3.p5.5.m5.3.4.cmml" xref="S3.SS3.p5.5.m5.3.4"><csymbol cd="latexml" id="S3.SS3.p5.5.m5.3.4.1.cmml" xref="S3.SS3.p5.5.m5.3.4.1">approaches-limit</csymbol><ci id="S3.SS3.p5.5.m5.3.4.2.cmml" xref="S3.SS3.p5.5.m5.3.4.2">ğœ‡</ci><list id="S3.SS3.p5.5.m5.3.4.3.1.cmml" xref="S3.SS3.p5.5.m5.3.4.3.2"><ci id="S3.SS3.p5.5.m5.1.1.cmml" xref="S3.SS3.p5.5.m5.1.1">ğ›½</ci><ci id="S3.SS3.p5.5.m5.2.2.cmml" xref="S3.SS3.p5.5.m5.2.2">ğ›¾</ci><ci id="S3.SS3.p5.5.m5.3.3.cmml" xref="S3.SS3.p5.5.m5.3.3">ğœƒ</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.5.m5.3c">\mu\doteq[\beta,\gamma,\theta]</annotation></semantics></math>). We also visualize two groups of identity interpolation with identity mixup in FigureÂ <a href="#S3.F4" title="Figure 4 â€£ 3.3 SynFace with Identity Mixup â€£ 3 Method â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. As we can see, one identity gradually and smoothly transforms to another identity as the weighted ratio <math id="S3.SS3.p5.6.m6.1" class="ltx_Math" alttext="\varphi" display="inline"><semantics id="S3.SS3.p5.6.m6.1a"><mi id="S3.SS3.p5.6.m6.1.1" xref="S3.SS3.p5.6.m6.1.1.cmml">Ï†</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.6.m6.1b"><ci id="S3.SS3.p5.6.m6.1.1.cmml" xref="S3.SS3.p5.6.m6.1.1">ğœ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.6.m6.1c">\varphi</annotation></semantics></math> varies from 0 to 1. Besides, from FigureÂ <a href="#S3.F4" title="Figure 4 â€£ 3.3 SynFace with Identity Mixup â€£ 3 Method â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, it is obvious that the face images generated with intermediate identity coefficients are also high-quality.</p>
</div>
<div id="S3.SS3.p6" class="ltx_para">
<p id="S3.SS3.p6.9" class="ltx_p">To evaluate the identity mixup for enlarging the intra-class variations, as illustrated in FigureÂ <a href="#S3.F3" title="Figure 3 â€£ 3.2 SynFace vs. RealFace â€£ 3 Method â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we visualize the feature embedding distributions of the same class in three synthetic datasets (containing <math id="S3.SS3.p6.1.m1.1" class="ltx_Math" alttext="5K" display="inline"><semantics id="S3.SS3.p6.1.m1.1a"><mrow id="S3.SS3.p6.1.m1.1.1" xref="S3.SS3.p6.1.m1.1.1.cmml"><mn id="S3.SS3.p6.1.m1.1.1.2" xref="S3.SS3.p6.1.m1.1.1.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="S3.SS3.p6.1.m1.1.1.1" xref="S3.SS3.p6.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.SS3.p6.1.m1.1.1.3" xref="S3.SS3.p6.1.m1.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.1.m1.1b"><apply id="S3.SS3.p6.1.m1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1"><times id="S3.SS3.p6.1.m1.1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1.1"></times><cn type="integer" id="S3.SS3.p6.1.m1.1.1.2.cmml" xref="S3.SS3.p6.1.m1.1.1.2">5</cn><ci id="S3.SS3.p6.1.m1.1.1.3.cmml" xref="S3.SS3.p6.1.m1.1.1.3">ğ¾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.1.m1.1c">5K</annotation></semantics></math> different identities with <math id="S3.SS3.p6.2.m2.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S3.SS3.p6.2.m2.1a"><mn id="S3.SS3.p6.2.m2.1.1" xref="S3.SS3.p6.2.m2.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.2.m2.1b"><cn type="integer" id="S3.SS3.p6.2.m2.1.1.cmml" xref="S3.SS3.p6.2.m2.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.2.m2.1c">50</annotation></semantics></math> samples per identity) with different levels of identity mixup (IM) by using multidimensional scaling (MDSÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>). Note that Syn1, Syn2 and Syn3 represent the weighted ratio <math id="S3.SS3.p6.3.m3.1" class="ltx_Math" alttext="\varphi" display="inline"><semantics id="S3.SS3.p6.3.m3.1a"><mi id="S3.SS3.p6.3.m3.1.1" xref="S3.SS3.p6.3.m3.1.1.cmml">Ï†</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.3.m3.1b"><ci id="S3.SS3.p6.3.m3.1.1.cmml" xref="S3.SS3.p6.3.m3.1.1">ğœ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.3.m3.1c">\varphi</annotation></semantics></math> is 1.0 (<em id="S3.SS3.p6.9.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS3.p6.9.2" class="ltx_text"></span>, no IM), 0.8 and randomly sampled from the linear space which varies from <math id="S3.SS3.p6.4.m4.1" class="ltx_Math" alttext="0.6" display="inline"><semantics id="S3.SS3.p6.4.m4.1a"><mn id="S3.SS3.p6.4.m4.1.1" xref="S3.SS3.p6.4.m4.1.1.cmml">0.6</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.4.m4.1b"><cn type="float" id="S3.SS3.p6.4.m4.1.1.cmml" xref="S3.SS3.p6.4.m4.1.1">0.6</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.4.m4.1c">0.6</annotation></semantics></math> to <math id="S3.SS3.p6.5.m5.1" class="ltx_Math" alttext="1.0" display="inline"><semantics id="S3.SS3.p6.5.m5.1a"><mn id="S3.SS3.p6.5.m5.1.1" xref="S3.SS3.p6.5.m5.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.5.m5.1b"><cn type="float" id="S3.SS3.p6.5.m5.1.1.cmml" xref="S3.SS3.p6.5.m5.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.5.m5.1c">1.0</annotation></semantics></math> with the interval being 0.05 (<em id="S3.SS3.p6.9.3" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS3.p6.9.4" class="ltx_text"></span>, <math id="S3.SS3.p6.6.m6.5" class="ltx_Math" alttext="np.linspace(0.6,1.0,11)" display="inline"><semantics id="S3.SS3.p6.6.m6.5a"><mrow id="S3.SS3.p6.6.m6.5.5.2" xref="S3.SS3.p6.6.m6.5.5.3.cmml"><mrow id="S3.SS3.p6.6.m6.4.4.1.1" xref="S3.SS3.p6.6.m6.4.4.1.1.cmml"><mi id="S3.SS3.p6.6.m6.4.4.1.1.2" xref="S3.SS3.p6.6.m6.4.4.1.1.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.6.m6.4.4.1.1.1" xref="S3.SS3.p6.6.m6.4.4.1.1.1.cmml">â€‹</mo><mi id="S3.SS3.p6.6.m6.4.4.1.1.3" xref="S3.SS3.p6.6.m6.4.4.1.1.3.cmml">p</mi></mrow><mo lspace="0em" rspace="0.167em" id="S3.SS3.p6.6.m6.5.5.2.3" xref="S3.SS3.p6.6.m6.5.5.3a.cmml">.</mo><mrow id="S3.SS3.p6.6.m6.5.5.2.2" xref="S3.SS3.p6.6.m6.5.5.2.2.cmml"><mi id="S3.SS3.p6.6.m6.5.5.2.2.2" xref="S3.SS3.p6.6.m6.5.5.2.2.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.6.m6.5.5.2.2.1" xref="S3.SS3.p6.6.m6.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS3.p6.6.m6.5.5.2.2.3" xref="S3.SS3.p6.6.m6.5.5.2.2.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.6.m6.5.5.2.2.1a" xref="S3.SS3.p6.6.m6.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS3.p6.6.m6.5.5.2.2.4" xref="S3.SS3.p6.6.m6.5.5.2.2.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.6.m6.5.5.2.2.1b" xref="S3.SS3.p6.6.m6.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS3.p6.6.m6.5.5.2.2.5" xref="S3.SS3.p6.6.m6.5.5.2.2.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.6.m6.5.5.2.2.1c" xref="S3.SS3.p6.6.m6.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS3.p6.6.m6.5.5.2.2.6" xref="S3.SS3.p6.6.m6.5.5.2.2.6.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.6.m6.5.5.2.2.1d" xref="S3.SS3.p6.6.m6.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS3.p6.6.m6.5.5.2.2.7" xref="S3.SS3.p6.6.m6.5.5.2.2.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.6.m6.5.5.2.2.1e" xref="S3.SS3.p6.6.m6.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS3.p6.6.m6.5.5.2.2.8" xref="S3.SS3.p6.6.m6.5.5.2.2.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.6.m6.5.5.2.2.1f" xref="S3.SS3.p6.6.m6.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS3.p6.6.m6.5.5.2.2.9" xref="S3.SS3.p6.6.m6.5.5.2.2.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.6.m6.5.5.2.2.1g" xref="S3.SS3.p6.6.m6.5.5.2.2.1.cmml">â€‹</mo><mrow id="S3.SS3.p6.6.m6.5.5.2.2.10.2" xref="S3.SS3.p6.6.m6.5.5.2.2.10.1.cmml"><mo stretchy="false" id="S3.SS3.p6.6.m6.5.5.2.2.10.2.1" xref="S3.SS3.p6.6.m6.5.5.2.2.10.1.cmml">(</mo><mn id="S3.SS3.p6.6.m6.1.1" xref="S3.SS3.p6.6.m6.1.1.cmml">0.6</mn><mo id="S3.SS3.p6.6.m6.5.5.2.2.10.2.2" xref="S3.SS3.p6.6.m6.5.5.2.2.10.1.cmml">,</mo><mn id="S3.SS3.p6.6.m6.2.2" xref="S3.SS3.p6.6.m6.2.2.cmml">1.0</mn><mo id="S3.SS3.p6.6.m6.5.5.2.2.10.2.3" xref="S3.SS3.p6.6.m6.5.5.2.2.10.1.cmml">,</mo><mn id="S3.SS3.p6.6.m6.3.3" xref="S3.SS3.p6.6.m6.3.3.cmml">11</mn><mo stretchy="false" id="S3.SS3.p6.6.m6.5.5.2.2.10.2.4" xref="S3.SS3.p6.6.m6.5.5.2.2.10.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.6.m6.5b"><apply id="S3.SS3.p6.6.m6.5.5.3.cmml" xref="S3.SS3.p6.6.m6.5.5.2"><csymbol cd="ambiguous" id="S3.SS3.p6.6.m6.5.5.3a.cmml" xref="S3.SS3.p6.6.m6.5.5.2.3">formulae-sequence</csymbol><apply id="S3.SS3.p6.6.m6.4.4.1.1.cmml" xref="S3.SS3.p6.6.m6.4.4.1.1"><times id="S3.SS3.p6.6.m6.4.4.1.1.1.cmml" xref="S3.SS3.p6.6.m6.4.4.1.1.1"></times><ci id="S3.SS3.p6.6.m6.4.4.1.1.2.cmml" xref="S3.SS3.p6.6.m6.4.4.1.1.2">ğ‘›</ci><ci id="S3.SS3.p6.6.m6.4.4.1.1.3.cmml" xref="S3.SS3.p6.6.m6.4.4.1.1.3">ğ‘</ci></apply><apply id="S3.SS3.p6.6.m6.5.5.2.2.cmml" xref="S3.SS3.p6.6.m6.5.5.2.2"><times id="S3.SS3.p6.6.m6.5.5.2.2.1.cmml" xref="S3.SS3.p6.6.m6.5.5.2.2.1"></times><ci id="S3.SS3.p6.6.m6.5.5.2.2.2.cmml" xref="S3.SS3.p6.6.m6.5.5.2.2.2">ğ‘™</ci><ci id="S3.SS3.p6.6.m6.5.5.2.2.3.cmml" xref="S3.SS3.p6.6.m6.5.5.2.2.3">ğ‘–</ci><ci id="S3.SS3.p6.6.m6.5.5.2.2.4.cmml" xref="S3.SS3.p6.6.m6.5.5.2.2.4">ğ‘›</ci><ci id="S3.SS3.p6.6.m6.5.5.2.2.5.cmml" xref="S3.SS3.p6.6.m6.5.5.2.2.5">ğ‘ </ci><ci id="S3.SS3.p6.6.m6.5.5.2.2.6.cmml" xref="S3.SS3.p6.6.m6.5.5.2.2.6">ğ‘</ci><ci id="S3.SS3.p6.6.m6.5.5.2.2.7.cmml" xref="S3.SS3.p6.6.m6.5.5.2.2.7">ğ‘</ci><ci id="S3.SS3.p6.6.m6.5.5.2.2.8.cmml" xref="S3.SS3.p6.6.m6.5.5.2.2.8">ğ‘</ci><ci id="S3.SS3.p6.6.m6.5.5.2.2.9.cmml" xref="S3.SS3.p6.6.m6.5.5.2.2.9">ğ‘’</ci><vector id="S3.SS3.p6.6.m6.5.5.2.2.10.1.cmml" xref="S3.SS3.p6.6.m6.5.5.2.2.10.2"><cn type="float" id="S3.SS3.p6.6.m6.1.1.cmml" xref="S3.SS3.p6.6.m6.1.1">0.6</cn><cn type="float" id="S3.SS3.p6.6.m6.2.2.cmml" xref="S3.SS3.p6.6.m6.2.2">1.0</cn><cn type="integer" id="S3.SS3.p6.6.m6.3.3.cmml" xref="S3.SS3.p6.6.m6.3.3">11</cn></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.6.m6.5c">np.linspace(0.6,1.0,11)</annotation></semantics></math>). It is clear that the cyan triangles (Syn1) have the smallest variations , while the red circles (Syn3) have the largest one and the blue squares (Syn2) are in the middle position. Accordingly, the accuracy is in an increasing trend (<em id="S3.SS3.p6.9.5" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS3.p6.9.6" class="ltx_text"></span>, <math id="S3.SS3.p6.7.m7.1" class="ltx_Math" alttext="88.75\%\rightarrow 89.47\%\rightarrow 90.95\%" display="inline"><semantics id="S3.SS3.p6.7.m7.1a"><mrow id="S3.SS3.p6.7.m7.1.1" xref="S3.SS3.p6.7.m7.1.1.cmml"><mrow id="S3.SS3.p6.7.m7.1.1.2" xref="S3.SS3.p6.7.m7.1.1.2.cmml"><mn id="S3.SS3.p6.7.m7.1.1.2.2" xref="S3.SS3.p6.7.m7.1.1.2.2.cmml">88.75</mn><mo id="S3.SS3.p6.7.m7.1.1.2.1" xref="S3.SS3.p6.7.m7.1.1.2.1.cmml">%</mo></mrow><mo stretchy="false" id="S3.SS3.p6.7.m7.1.1.3" xref="S3.SS3.p6.7.m7.1.1.3.cmml">â†’</mo><mrow id="S3.SS3.p6.7.m7.1.1.4" xref="S3.SS3.p6.7.m7.1.1.4.cmml"><mn id="S3.SS3.p6.7.m7.1.1.4.2" xref="S3.SS3.p6.7.m7.1.1.4.2.cmml">89.47</mn><mo id="S3.SS3.p6.7.m7.1.1.4.1" xref="S3.SS3.p6.7.m7.1.1.4.1.cmml">%</mo></mrow><mo stretchy="false" id="S3.SS3.p6.7.m7.1.1.5" xref="S3.SS3.p6.7.m7.1.1.5.cmml">â†’</mo><mrow id="S3.SS3.p6.7.m7.1.1.6" xref="S3.SS3.p6.7.m7.1.1.6.cmml"><mn id="S3.SS3.p6.7.m7.1.1.6.2" xref="S3.SS3.p6.7.m7.1.1.6.2.cmml">90.95</mn><mo id="S3.SS3.p6.7.m7.1.1.6.1" xref="S3.SS3.p6.7.m7.1.1.6.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.7.m7.1b"><apply id="S3.SS3.p6.7.m7.1.1.cmml" xref="S3.SS3.p6.7.m7.1.1"><and id="S3.SS3.p6.7.m7.1.1a.cmml" xref="S3.SS3.p6.7.m7.1.1"></and><apply id="S3.SS3.p6.7.m7.1.1b.cmml" xref="S3.SS3.p6.7.m7.1.1"><ci id="S3.SS3.p6.7.m7.1.1.3.cmml" xref="S3.SS3.p6.7.m7.1.1.3">â†’</ci><apply id="S3.SS3.p6.7.m7.1.1.2.cmml" xref="S3.SS3.p6.7.m7.1.1.2"><csymbol cd="latexml" id="S3.SS3.p6.7.m7.1.1.2.1.cmml" xref="S3.SS3.p6.7.m7.1.1.2.1">percent</csymbol><cn type="float" id="S3.SS3.p6.7.m7.1.1.2.2.cmml" xref="S3.SS3.p6.7.m7.1.1.2.2">88.75</cn></apply><apply id="S3.SS3.p6.7.m7.1.1.4.cmml" xref="S3.SS3.p6.7.m7.1.1.4"><csymbol cd="latexml" id="S3.SS3.p6.7.m7.1.1.4.1.cmml" xref="S3.SS3.p6.7.m7.1.1.4.1">percent</csymbol><cn type="float" id="S3.SS3.p6.7.m7.1.1.4.2.cmml" xref="S3.SS3.p6.7.m7.1.1.4.2">89.47</cn></apply></apply><apply id="S3.SS3.p6.7.m7.1.1c.cmml" xref="S3.SS3.p6.7.m7.1.1"><ci id="S3.SS3.p6.7.m7.1.1.5.cmml" xref="S3.SS3.p6.7.m7.1.1.5">â†’</ci><share href="#S3.SS3.p6.7.m7.1.1.4.cmml" id="S3.SS3.p6.7.m7.1.1d.cmml" xref="S3.SS3.p6.7.m7.1.1"></share><apply id="S3.SS3.p6.7.m7.1.1.6.cmml" xref="S3.SS3.p6.7.m7.1.1.6"><csymbol cd="latexml" id="S3.SS3.p6.7.m7.1.1.6.1.cmml" xref="S3.SS3.p6.7.m7.1.1.6.1">percent</csymbol><cn type="float" id="S3.SS3.p6.7.m7.1.1.6.2.cmml" xref="S3.SS3.p6.7.m7.1.1.6.2">90.95</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.7.m7.1c">88.75\%\rightarrow 89.47\%\rightarrow 90.95\%</annotation></semantics></math>). Besides, <math id="S3.SS3.p6.8.m8.1" class="ltx_Math" alttext="88.98\%" display="inline"><semantics id="S3.SS3.p6.8.m8.1a"><mrow id="S3.SS3.p6.8.m8.1.1" xref="S3.SS3.p6.8.m8.1.1.cmml"><mn id="S3.SS3.p6.8.m8.1.1.2" xref="S3.SS3.p6.8.m8.1.1.2.cmml">88.98</mn><mo id="S3.SS3.p6.8.m8.1.1.1" xref="S3.SS3.p6.8.m8.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.8.m8.1b"><apply id="S3.SS3.p6.8.m8.1.1.cmml" xref="S3.SS3.p6.8.m8.1.1"><csymbol cd="latexml" id="S3.SS3.p6.8.m8.1.1.1.cmml" xref="S3.SS3.p6.8.m8.1.1.1">percent</csymbol><cn type="float" id="S3.SS3.p6.8.m8.1.1.2.cmml" xref="S3.SS3.p6.8.m8.1.1.2">88.98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.8.m8.1c">88.98\%</annotation></semantics></math> (as in TableÂ <a href="#S3.T1" title="Table 1 â€£ 3.2 SynFace vs. RealFace â€£ 3 Method â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) is boosted to <math id="S3.SS3.p6.9.m9.1" class="ltx_Math" alttext="91.97\%" display="inline"><semantics id="S3.SS3.p6.9.m9.1a"><mrow id="S3.SS3.p6.9.m9.1.1" xref="S3.SS3.p6.9.m9.1.1.cmml"><mn id="S3.SS3.p6.9.m9.1.1.2" xref="S3.SS3.p6.9.m9.1.1.2.cmml">91.97</mn><mo id="S3.SS3.p6.9.m9.1.1.1" xref="S3.SS3.p6.9.m9.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.9.m9.1b"><apply id="S3.SS3.p6.9.m9.1.1.cmml" xref="S3.SS3.p6.9.m9.1.1"><csymbol cd="latexml" id="S3.SS3.p6.9.m9.1.1.1.cmml" xref="S3.SS3.p6.9.m9.1.1.1">percent</csymbol><cn type="float" id="S3.SS3.p6.9.m9.1.1.2.cmml" xref="S3.SS3.p6.9.m9.1.1.2">91.97</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.9.m9.1c">91.97\%</annotation></semantics></math> (as in TableÂ <a href="#S3.T2" title="Table 2 â€£ 3.4 SynFace with Domain Mixup â€£ 3 Method â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>) after utilizing identity mixup. In particular, when the baseline is weaker, the improvement brought by identity mixup is larger, which are shown in TableÂ <a href="#S4.T3" title="Table 3 â€£ 4.4 Effectiveness of â€œDepthâ€ and â€œWidthâ€ â€£ 4 Experiments â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and FigureÂ <a href="#S4.F7" title="Figure 7 â€£ 4.5 Impacts of Different Facial Attributes â€£ 4 Experiments â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2108.07960/assets/x5.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="215" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Face verification accuracy comparison between RealFace and SynFace_IM (<em id="S3.F5.5.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.F5.6.2" class="ltx_text"></span>, SynFace with Identity Mixup) on five different synthetic testing datasets. Syn-LFW is the synthetic version of the LFW dataset, while Syn-LFW-R (with R <math id="S3.F5.2.m1.4" class="ltx_Math" alttext="\in[0.6,0.7,0.8,0.9]" display="inline"><semantics id="S3.F5.2.m1.4b"><mrow id="S3.F5.2.m1.4.5" xref="S3.F5.2.m1.4.5.cmml"><mi id="S3.F5.2.m1.4.5.2" xref="S3.F5.2.m1.4.5.2.cmml"></mi><mo id="S3.F5.2.m1.4.5.1" xref="S3.F5.2.m1.4.5.1.cmml">âˆˆ</mo><mrow id="S3.F5.2.m1.4.5.3.2" xref="S3.F5.2.m1.4.5.3.1.cmml"><mo stretchy="false" id="S3.F5.2.m1.4.5.3.2.1" xref="S3.F5.2.m1.4.5.3.1.cmml">[</mo><mn id="S3.F5.2.m1.1.1" xref="S3.F5.2.m1.1.1.cmml">0.6</mn><mo id="S3.F5.2.m1.4.5.3.2.2" xref="S3.F5.2.m1.4.5.3.1.cmml">,</mo><mn id="S3.F5.2.m1.2.2" xref="S3.F5.2.m1.2.2.cmml">0.7</mn><mo id="S3.F5.2.m1.4.5.3.2.3" xref="S3.F5.2.m1.4.5.3.1.cmml">,</mo><mn id="S3.F5.2.m1.3.3" xref="S3.F5.2.m1.3.3.cmml">0.8</mn><mo id="S3.F5.2.m1.4.5.3.2.4" xref="S3.F5.2.m1.4.5.3.1.cmml">,</mo><mn id="S3.F5.2.m1.4.4" xref="S3.F5.2.m1.4.4.cmml">0.9</mn><mo stretchy="false" id="S3.F5.2.m1.4.5.3.2.5" xref="S3.F5.2.m1.4.5.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F5.2.m1.4c"><apply id="S3.F5.2.m1.4.5.cmml" xref="S3.F5.2.m1.4.5"><in id="S3.F5.2.m1.4.5.1.cmml" xref="S3.F5.2.m1.4.5.1"></in><csymbol cd="latexml" id="S3.F5.2.m1.4.5.2.cmml" xref="S3.F5.2.m1.4.5.2">absent</csymbol><list id="S3.F5.2.m1.4.5.3.1.cmml" xref="S3.F5.2.m1.4.5.3.2"><cn type="float" id="S3.F5.2.m1.1.1.cmml" xref="S3.F5.2.m1.1.1">0.6</cn><cn type="float" id="S3.F5.2.m1.2.2.cmml" xref="S3.F5.2.m1.2.2">0.7</cn><cn type="float" id="S3.F5.2.m1.3.3.cmml" xref="S3.F5.2.m1.3.3">0.8</cn><cn type="float" id="S3.F5.2.m1.4.4.cmml" xref="S3.F5.2.m1.4.4">0.9</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F5.2.m1.4d">\in[0.6,0.7,0.8,0.9]</annotation></semantics></math>) indicates introducing identity mixup with ratio R into Syn-LFW.</figcaption>
</figure>
<div id="S3.SS3.p7" class="ltx_para">
<p id="S3.SS3.p7.1" class="ltx_p">In addition to utilizing identity mixup in the training process, we also make an attempt of employing identity mixup on the synthetic testing dataset to evaluate the modelâ€™s robustness on the identity coefficient noises. Specifically, both RealFace (trained on CASIA-WebFace) and SynFace_IM (trained on Syn_10K_50 with identity mixup) are evaluated on five different synthetic testing datasets, as illustrated in FigureÂ <a href="#S3.F5" title="Figure 5 â€£ 3.3 SynFace with Identity Mixup â€£ 3 Method â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. Note that Syn-LFW is the synthetic version of the LFW dataset, while Syn-LFW-R (with R <math id="S3.SS3.p7.1.m1.4" class="ltx_Math" alttext="\in[0.6,0.7,0.8,0.9]" display="inline"><semantics id="S3.SS3.p7.1.m1.4a"><mrow id="S3.SS3.p7.1.m1.4.5" xref="S3.SS3.p7.1.m1.4.5.cmml"><mi id="S3.SS3.p7.1.m1.4.5.2" xref="S3.SS3.p7.1.m1.4.5.2.cmml"></mi><mo id="S3.SS3.p7.1.m1.4.5.1" xref="S3.SS3.p7.1.m1.4.5.1.cmml">âˆˆ</mo><mrow id="S3.SS3.p7.1.m1.4.5.3.2" xref="S3.SS3.p7.1.m1.4.5.3.1.cmml"><mo stretchy="false" id="S3.SS3.p7.1.m1.4.5.3.2.1" xref="S3.SS3.p7.1.m1.4.5.3.1.cmml">[</mo><mn id="S3.SS3.p7.1.m1.1.1" xref="S3.SS3.p7.1.m1.1.1.cmml">0.6</mn><mo id="S3.SS3.p7.1.m1.4.5.3.2.2" xref="S3.SS3.p7.1.m1.4.5.3.1.cmml">,</mo><mn id="S3.SS3.p7.1.m1.2.2" xref="S3.SS3.p7.1.m1.2.2.cmml">0.7</mn><mo id="S3.SS3.p7.1.m1.4.5.3.2.3" xref="S3.SS3.p7.1.m1.4.5.3.1.cmml">,</mo><mn id="S3.SS3.p7.1.m1.3.3" xref="S3.SS3.p7.1.m1.3.3.cmml">0.8</mn><mo id="S3.SS3.p7.1.m1.4.5.3.2.4" xref="S3.SS3.p7.1.m1.4.5.3.1.cmml">,</mo><mn id="S3.SS3.p7.1.m1.4.4" xref="S3.SS3.p7.1.m1.4.4.cmml">0.9</mn><mo stretchy="false" id="S3.SS3.p7.1.m1.4.5.3.2.5" xref="S3.SS3.p7.1.m1.4.5.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p7.1.m1.4b"><apply id="S3.SS3.p7.1.m1.4.5.cmml" xref="S3.SS3.p7.1.m1.4.5"><in id="S3.SS3.p7.1.m1.4.5.1.cmml" xref="S3.SS3.p7.1.m1.4.5.1"></in><csymbol cd="latexml" id="S3.SS3.p7.1.m1.4.5.2.cmml" xref="S3.SS3.p7.1.m1.4.5.2">absent</csymbol><list id="S3.SS3.p7.1.m1.4.5.3.1.cmml" xref="S3.SS3.p7.1.m1.4.5.3.2"><cn type="float" id="S3.SS3.p7.1.m1.1.1.cmml" xref="S3.SS3.p7.1.m1.1.1">0.6</cn><cn type="float" id="S3.SS3.p7.1.m1.2.2.cmml" xref="S3.SS3.p7.1.m1.2.2">0.7</cn><cn type="float" id="S3.SS3.p7.1.m1.3.3.cmml" xref="S3.SS3.p7.1.m1.3.3">0.8</cn><cn type="float" id="S3.SS3.p7.1.m1.4.4.cmml" xref="S3.SS3.p7.1.m1.4.4">0.9</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p7.1.m1.4c">\in[0.6,0.7,0.8,0.9]</annotation></semantics></math>) indicates employing the identity mixup with the weighted ratio R during the generation of Syn-LFW. Specifically, we mix the primary class with a random secondary class using the ratio R according to Eq.Â (<a href="#S3.E2" title="In 3.3 SynFace with Identity Mixup â€£ 3 Method â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), but we keep the original label unchanged. Apparently, when R is smaller (<em id="S3.SS3.p7.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS3.p7.1.2" class="ltx_text"></span>, the weight of the primary class is smaller), the corresponding testing dataset is more difficult to recognize because the secondary class impacts the identity information more heavily.</p>
</div>
<div id="S3.SS3.p8" class="ltx_para">
<p id="S3.SS3.p8.3" class="ltx_p">From the results of FigureÂ <a href="#S3.F5" title="Figure 5 â€£ 3.3 SynFace with Identity Mixup â€£ 3 Method â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we can find that our SynFace_IM achieves nearly perfect accuracy when R is larger than 0.6, and also obtains an impressive <math id="S3.SS3.p8.1.m1.1" class="ltx_Math" alttext="97.30\%" display="inline"><semantics id="S3.SS3.p8.1.m1.1a"><mrow id="S3.SS3.p8.1.m1.1.1" xref="S3.SS3.p8.1.m1.1.1.cmml"><mn id="S3.SS3.p8.1.m1.1.1.2" xref="S3.SS3.p8.1.m1.1.1.2.cmml">97.30</mn><mo id="S3.SS3.p8.1.m1.1.1.1" xref="S3.SS3.p8.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p8.1.m1.1b"><apply id="S3.SS3.p8.1.m1.1.1.cmml" xref="S3.SS3.p8.1.m1.1.1"><csymbol cd="latexml" id="S3.SS3.p8.1.m1.1.1.1.cmml" xref="S3.SS3.p8.1.m1.1.1.1">percent</csymbol><cn type="float" id="S3.SS3.p8.1.m1.1.1.2.cmml" xref="S3.SS3.p8.1.m1.1.1.2">97.30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p8.1.m1.1c">97.30\%</annotation></semantics></math> result which remarkably outperforms the <math id="S3.SS3.p8.2.m2.1" class="ltx_Math" alttext="87.83\%" display="inline"><semantics id="S3.SS3.p8.2.m2.1a"><mrow id="S3.SS3.p8.2.m2.1.1" xref="S3.SS3.p8.2.m2.1.1.cmml"><mn id="S3.SS3.p8.2.m2.1.1.2" xref="S3.SS3.p8.2.m2.1.1.2.cmml">87.83</mn><mo id="S3.SS3.p8.2.m2.1.1.1" xref="S3.SS3.p8.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p8.2.m2.1b"><apply id="S3.SS3.p8.2.m2.1.1.cmml" xref="S3.SS3.p8.2.m2.1.1"><csymbol cd="latexml" id="S3.SS3.p8.2.m2.1.1.1.cmml" xref="S3.SS3.p8.2.m2.1.1.1">percent</csymbol><cn type="float" id="S3.SS3.p8.2.m2.1.1.2.cmml" xref="S3.SS3.p8.2.m2.1.1.2">87.83</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p8.2.m2.1c">87.83\%</annotation></semantics></math> accuracy by RealFace when R is <math id="S3.SS3.p8.3.m3.1" class="ltx_Math" alttext="0.6" display="inline"><semantics id="S3.SS3.p8.3.m3.1a"><mn id="S3.SS3.p8.3.m3.1.1" xref="S3.SS3.p8.3.m3.1.1.cmml">0.6</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p8.3.m3.1b"><cn type="float" id="S3.SS3.p8.3.m3.1.1.cmml" xref="S3.SS3.p8.3.m3.1.1">0.6</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p8.3.m3.1c">0.6</annotation></semantics></math>. On the other hand, the accuracy of RealFace drops significantly on Syn-LFW-R when R becomes small, which suggests that the domain gap between real and synthetic face data is still large even after employing the identity mixup. Another interesting conclusion is that the current state-of-the-art face recognition model (<em id="S3.SS3.p8.3.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS3.p8.3.2" class="ltx_text"></span>, RealFace) cannot handle the identity mixup attack. In other words, if a face image is mixup with another identity, the model cannot recognize it well. However, the proposed SynFace with identity mixup can nearly keep the accuracy under the identity mixup attack. We prefer to explore how to make the RealFace handle such an attack in future work.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>SynFace with Domain Mixup</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.20" class="ltx_p">The lack of intra-class variation is an observable cause of the domain gap between synthetic and real faces, and SynFace can be significantly improved by the proposed identity mixup. To further narrow the performance gap between SynFace and RealFace, we introduce the domain mixup as a general domain adaptation method to alleviate the domain gap for face recognition. Specifically, we utilize large-scale synthetic face images with a small number of real-world face images with labels as the training data. When training, we perform mixup within a mini-batch of synthetic images and a mini-batch of real images, where the labels changed accordingly as the supervision. Mathematically, the domain mixup can be formulated as follows:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.35" class="ltx_Math" alttext="\begin{split}X&amp;=\psi\cdot X_{S}+(1-\psi)\cdot X_{R},\\
Y&amp;=\psi\cdot Y_{S}+(1-\psi)\cdot Y_{R},\end{split}" display="block"><semantics id="S3.E3.m1.35a"><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt" id="S3.E3.m1.35.35.3"><mtr id="S3.E3.m1.35.35.3a"><mtd class="ltx_align_right" columnalign="right" id="S3.E3.m1.35.35.3b"><mi id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml">X</mi></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E3.m1.35.35.3c"><mrow id="S3.E3.m1.34.34.2.33.17.16.16"><mrow id="S3.E3.m1.34.34.2.33.17.16.16.1"><mi id="S3.E3.m1.34.34.2.33.17.16.16.1.2"></mi><mo id="S3.E3.m1.2.2.2.2.1.1" xref="S3.E3.m1.2.2.2.2.1.1.cmml">=</mo><mrow id="S3.E3.m1.34.34.2.33.17.16.16.1.1"><mrow id="S3.E3.m1.34.34.2.33.17.16.16.1.1.2"><mi id="S3.E3.m1.3.3.3.3.2.2" xref="S3.E3.m1.3.3.3.3.2.2.cmml">Ïˆ</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E3.m1.4.4.4.4.3.3" xref="S3.E3.m1.4.4.4.4.3.3.cmml">â‹…</mo><msub id="S3.E3.m1.34.34.2.33.17.16.16.1.1.2.1"><mi id="S3.E3.m1.5.5.5.5.4.4" xref="S3.E3.m1.5.5.5.5.4.4.cmml">X</mi><mi id="S3.E3.m1.6.6.6.6.5.5.1" xref="S3.E3.m1.6.6.6.6.5.5.1.cmml">S</mi></msub></mrow><mo id="S3.E3.m1.7.7.7.7.6.6" xref="S3.E3.m1.7.7.7.7.6.6.cmml">+</mo><mrow id="S3.E3.m1.34.34.2.33.17.16.16.1.1.1"><mrow id="S3.E3.m1.34.34.2.33.17.16.16.1.1.1.1.1"><mo stretchy="false" id="S3.E3.m1.8.8.8.8.7.7">(</mo><mrow id="S3.E3.m1.34.34.2.33.17.16.16.1.1.1.1.1.1"><mn id="S3.E3.m1.9.9.9.9.8.8" xref="S3.E3.m1.9.9.9.9.8.8.cmml">1</mn><mo id="S3.E3.m1.10.10.10.10.9.9" xref="S3.E3.m1.10.10.10.10.9.9.cmml">âˆ’</mo><mi id="S3.E3.m1.11.11.11.11.10.10" xref="S3.E3.m1.11.11.11.11.10.10.cmml">Ïˆ</mi></mrow><mo rspace="0.055em" stretchy="false" id="S3.E3.m1.12.12.12.12.11.11">)</mo></mrow><mo rspace="0.222em" id="S3.E3.m1.13.13.13.13.12.12" xref="S3.E3.m1.13.13.13.13.12.12.cmml">â‹…</mo><msub id="S3.E3.m1.34.34.2.33.17.16.16.1.1.1.2"><mi id="S3.E3.m1.14.14.14.14.13.13" xref="S3.E3.m1.14.14.14.14.13.13.cmml">X</mi><mi id="S3.E3.m1.15.15.15.15.14.14.1" xref="S3.E3.m1.15.15.15.15.14.14.1.cmml">R</mi></msub></mrow></mrow></mrow><mo id="S3.E3.m1.16.16.16.16.15.15">,</mo></mrow></mtd></mtr><mtr id="S3.E3.m1.35.35.3d"><mtd class="ltx_align_right" columnalign="right" id="S3.E3.m1.35.35.3e"><mi id="S3.E3.m1.17.17.17.1.1.1" xref="S3.E3.m1.17.17.17.1.1.1.cmml">Y</mi></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E3.m1.35.35.3f"><mrow id="S3.E3.m1.35.35.3.34.17.16.16"><mrow id="S3.E3.m1.35.35.3.34.17.16.16.1"><mi id="S3.E3.m1.35.35.3.34.17.16.16.1.2"></mi><mo id="S3.E3.m1.18.18.18.2.1.1" xref="S3.E3.m1.18.18.18.2.1.1.cmml">=</mo><mrow id="S3.E3.m1.35.35.3.34.17.16.16.1.1"><mrow id="S3.E3.m1.35.35.3.34.17.16.16.1.1.2"><mi id="S3.E3.m1.19.19.19.3.2.2" xref="S3.E3.m1.19.19.19.3.2.2.cmml">Ïˆ</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E3.m1.20.20.20.4.3.3" xref="S3.E3.m1.20.20.20.4.3.3.cmml">â‹…</mo><msub id="S3.E3.m1.35.35.3.34.17.16.16.1.1.2.1"><mi id="S3.E3.m1.21.21.21.5.4.4" xref="S3.E3.m1.21.21.21.5.4.4.cmml">Y</mi><mi id="S3.E3.m1.22.22.22.6.5.5.1" xref="S3.E3.m1.22.22.22.6.5.5.1.cmml">S</mi></msub></mrow><mo id="S3.E3.m1.23.23.23.7.6.6" xref="S3.E3.m1.23.23.23.7.6.6.cmml">+</mo><mrow id="S3.E3.m1.35.35.3.34.17.16.16.1.1.1"><mrow id="S3.E3.m1.35.35.3.34.17.16.16.1.1.1.1.1"><mo stretchy="false" id="S3.E3.m1.24.24.24.8.7.7">(</mo><mrow id="S3.E3.m1.35.35.3.34.17.16.16.1.1.1.1.1.1"><mn id="S3.E3.m1.25.25.25.9.8.8" xref="S3.E3.m1.25.25.25.9.8.8.cmml">1</mn><mo id="S3.E3.m1.26.26.26.10.9.9" xref="S3.E3.m1.26.26.26.10.9.9.cmml">âˆ’</mo><mi id="S3.E3.m1.27.27.27.11.10.10" xref="S3.E3.m1.27.27.27.11.10.10.cmml">Ïˆ</mi></mrow><mo rspace="0.055em" stretchy="false" id="S3.E3.m1.28.28.28.12.11.11">)</mo></mrow><mo rspace="0.222em" id="S3.E3.m1.29.29.29.13.12.12" xref="S3.E3.m1.29.29.29.13.12.12.cmml">â‹…</mo><msub id="S3.E3.m1.35.35.3.34.17.16.16.1.1.1.2"><mi id="S3.E3.m1.30.30.30.14.13.13" xref="S3.E3.m1.30.30.30.14.13.13.cmml">Y</mi><mi id="S3.E3.m1.31.31.31.15.14.14.1" xref="S3.E3.m1.31.31.31.15.14.14.1.cmml">R</mi></msub></mrow></mrow></mrow><mo id="S3.E3.m1.32.32.32.16.15.15">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E3.m1.35b"><apply id="S3.E3.m1.33.33.1.1.1.3.cmml"><csymbol cd="ambiguous" id="S3.E3.m1.33.33.1.1.1.3a.cmml">formulae-sequence</csymbol><apply id="S3.E3.m1.33.33.1.1.1.1.1.cmml"><eq id="S3.E3.m1.2.2.2.2.1.1.cmml" xref="S3.E3.m1.2.2.2.2.1.1"></eq><ci id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1">ğ‘‹</ci><apply id="S3.E3.m1.33.33.1.1.1.1.1.1.cmml"><plus id="S3.E3.m1.7.7.7.7.6.6.cmml" xref="S3.E3.m1.7.7.7.7.6.6"></plus><apply id="S3.E3.m1.33.33.1.1.1.1.1.1.3.cmml"><ci id="S3.E3.m1.4.4.4.4.3.3.cmml" xref="S3.E3.m1.4.4.4.4.3.3">â‹…</ci><ci id="S3.E3.m1.3.3.3.3.2.2.cmml" xref="S3.E3.m1.3.3.3.3.2.2">ğœ“</ci><apply id="S3.E3.m1.33.33.1.1.1.1.1.1.3.3.cmml"><csymbol cd="ambiguous" id="S3.E3.m1.33.33.1.1.1.1.1.1.3.3.1.cmml">subscript</csymbol><ci id="S3.E3.m1.5.5.5.5.4.4.cmml" xref="S3.E3.m1.5.5.5.5.4.4">ğ‘‹</ci><ci id="S3.E3.m1.6.6.6.6.5.5.1.cmml" xref="S3.E3.m1.6.6.6.6.5.5.1">ğ‘†</ci></apply></apply><apply id="S3.E3.m1.33.33.1.1.1.1.1.1.1.cmml"><ci id="S3.E3.m1.13.13.13.13.12.12.cmml" xref="S3.E3.m1.13.13.13.13.12.12">â‹…</ci><apply id="S3.E3.m1.33.33.1.1.1.1.1.1.1.1.1.1.cmml"><minus id="S3.E3.m1.10.10.10.10.9.9.cmml" xref="S3.E3.m1.10.10.10.10.9.9"></minus><cn type="integer" id="S3.E3.m1.9.9.9.9.8.8.cmml" xref="S3.E3.m1.9.9.9.9.8.8">1</cn><ci id="S3.E3.m1.11.11.11.11.10.10.cmml" xref="S3.E3.m1.11.11.11.11.10.10">ğœ“</ci></apply><apply id="S3.E3.m1.33.33.1.1.1.1.1.1.1.3.cmml"><csymbol cd="ambiguous" id="S3.E3.m1.33.33.1.1.1.1.1.1.1.3.1.cmml">subscript</csymbol><ci id="S3.E3.m1.14.14.14.14.13.13.cmml" xref="S3.E3.m1.14.14.14.14.13.13">ğ‘‹</ci><ci id="S3.E3.m1.15.15.15.15.14.14.1.cmml" xref="S3.E3.m1.15.15.15.15.14.14.1">ğ‘…</ci></apply></apply></apply></apply><apply id="S3.E3.m1.33.33.1.1.1.2.2.cmml"><eq id="S3.E3.m1.18.18.18.2.1.1.cmml" xref="S3.E3.m1.18.18.18.2.1.1"></eq><ci id="S3.E3.m1.17.17.17.1.1.1.cmml" xref="S3.E3.m1.17.17.17.1.1.1">ğ‘Œ</ci><apply id="S3.E3.m1.33.33.1.1.1.2.2.1.cmml"><plus id="S3.E3.m1.23.23.23.7.6.6.cmml" xref="S3.E3.m1.23.23.23.7.6.6"></plus><apply id="S3.E3.m1.33.33.1.1.1.2.2.1.3.cmml"><ci id="S3.E3.m1.20.20.20.4.3.3.cmml" xref="S3.E3.m1.20.20.20.4.3.3">â‹…</ci><ci id="S3.E3.m1.19.19.19.3.2.2.cmml" xref="S3.E3.m1.19.19.19.3.2.2">ğœ“</ci><apply id="S3.E3.m1.33.33.1.1.1.2.2.1.3.3.cmml"><csymbol cd="ambiguous" id="S3.E3.m1.33.33.1.1.1.2.2.1.3.3.1.cmml">subscript</csymbol><ci id="S3.E3.m1.21.21.21.5.4.4.cmml" xref="S3.E3.m1.21.21.21.5.4.4">ğ‘Œ</ci><ci id="S3.E3.m1.22.22.22.6.5.5.1.cmml" xref="S3.E3.m1.22.22.22.6.5.5.1">ğ‘†</ci></apply></apply><apply id="S3.E3.m1.33.33.1.1.1.2.2.1.1.cmml"><ci id="S3.E3.m1.29.29.29.13.12.12.cmml" xref="S3.E3.m1.29.29.29.13.12.12">â‹…</ci><apply id="S3.E3.m1.33.33.1.1.1.2.2.1.1.1.1.1.cmml"><minus id="S3.E3.m1.26.26.26.10.9.9.cmml" xref="S3.E3.m1.26.26.26.10.9.9"></minus><cn type="integer" id="S3.E3.m1.25.25.25.9.8.8.cmml" xref="S3.E3.m1.25.25.25.9.8.8">1</cn><ci id="S3.E3.m1.27.27.27.11.10.10.cmml" xref="S3.E3.m1.27.27.27.11.10.10">ğœ“</ci></apply><apply id="S3.E3.m1.33.33.1.1.1.2.2.1.1.3.cmml"><csymbol cd="ambiguous" id="S3.E3.m1.33.33.1.1.1.2.2.1.1.3.1.cmml">subscript</csymbol><ci id="S3.E3.m1.30.30.30.14.13.13.cmml" xref="S3.E3.m1.30.30.30.14.13.13">ğ‘Œ</ci><ci id="S3.E3.m1.31.31.31.15.14.14.1.cmml" xref="S3.E3.m1.31.31.31.15.14.14.1">ğ‘…</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.35c">\begin{split}X&amp;=\psi\cdot X_{S}+(1-\psi)\cdot X_{R},\\
Y&amp;=\psi\cdot Y_{S}+(1-\psi)\cdot Y_{R},\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS4.p1.19" class="ltx_p">where <math id="S3.SS4.p1.1.m1.2" class="ltx_Math" alttext="X_{S},X_{R}" display="inline"><semantics id="S3.SS4.p1.1.m1.2a"><mrow id="S3.SS4.p1.1.m1.2.2.2" xref="S3.SS4.p1.1.m1.2.2.3.cmml"><msub id="S3.SS4.p1.1.m1.1.1.1.1" xref="S3.SS4.p1.1.m1.1.1.1.1.cmml"><mi id="S3.SS4.p1.1.m1.1.1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.1.1.2.cmml">X</mi><mi id="S3.SS4.p1.1.m1.1.1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.1.1.3.cmml">S</mi></msub><mo id="S3.SS4.p1.1.m1.2.2.2.3" xref="S3.SS4.p1.1.m1.2.2.3.cmml">,</mo><msub id="S3.SS4.p1.1.m1.2.2.2.2" xref="S3.SS4.p1.1.m1.2.2.2.2.cmml"><mi id="S3.SS4.p1.1.m1.2.2.2.2.2" xref="S3.SS4.p1.1.m1.2.2.2.2.2.cmml">X</mi><mi id="S3.SS4.p1.1.m1.2.2.2.2.3" xref="S3.SS4.p1.1.m1.2.2.2.2.3.cmml">R</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.2b"><list id="S3.SS4.p1.1.m1.2.2.3.cmml" xref="S3.SS4.p1.1.m1.2.2.2"><apply id="S3.SS4.p1.1.m1.1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.1.1.2">ğ‘‹</ci><ci id="S3.SS4.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.1.1.3">ğ‘†</ci></apply><apply id="S3.SS4.p1.1.m1.2.2.2.2.cmml" xref="S3.SS4.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.2.2.2.2.1.cmml" xref="S3.SS4.p1.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS4.p1.1.m1.2.2.2.2.2.cmml" xref="S3.SS4.p1.1.m1.2.2.2.2.2">ğ‘‹</ci><ci id="S3.SS4.p1.1.m1.2.2.2.2.3.cmml" xref="S3.SS4.p1.1.m1.2.2.2.2.3">ğ‘…</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.2c">X_{S},X_{R}</annotation></semantics></math> indicate the synthetic and real face images, respectively, and <math id="S3.SS4.p1.2.m2.2" class="ltx_Math" alttext="Y_{S},Y_{R}" display="inline"><semantics id="S3.SS4.p1.2.m2.2a"><mrow id="S3.SS4.p1.2.m2.2.2.2" xref="S3.SS4.p1.2.m2.2.2.3.cmml"><msub id="S3.SS4.p1.2.m2.1.1.1.1" xref="S3.SS4.p1.2.m2.1.1.1.1.cmml"><mi id="S3.SS4.p1.2.m2.1.1.1.1.2" xref="S3.SS4.p1.2.m2.1.1.1.1.2.cmml">Y</mi><mi id="S3.SS4.p1.2.m2.1.1.1.1.3" xref="S3.SS4.p1.2.m2.1.1.1.1.3.cmml">S</mi></msub><mo id="S3.SS4.p1.2.m2.2.2.2.3" xref="S3.SS4.p1.2.m2.2.2.3.cmml">,</mo><msub id="S3.SS4.p1.2.m2.2.2.2.2" xref="S3.SS4.p1.2.m2.2.2.2.2.cmml"><mi id="S3.SS4.p1.2.m2.2.2.2.2.2" xref="S3.SS4.p1.2.m2.2.2.2.2.2.cmml">Y</mi><mi id="S3.SS4.p1.2.m2.2.2.2.2.3" xref="S3.SS4.p1.2.m2.2.2.2.2.3.cmml">R</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.2b"><list id="S3.SS4.p1.2.m2.2.2.3.cmml" xref="S3.SS4.p1.2.m2.2.2.2"><apply id="S3.SS4.p1.2.m2.1.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.1.1.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p1.2.m2.1.1.1.1.2.cmml" xref="S3.SS4.p1.2.m2.1.1.1.1.2">ğ‘Œ</ci><ci id="S3.SS4.p1.2.m2.1.1.1.1.3.cmml" xref="S3.SS4.p1.2.m2.1.1.1.1.3">ğ‘†</ci></apply><apply id="S3.SS4.p1.2.m2.2.2.2.2.cmml" xref="S3.SS4.p1.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.2.2.2.2.1.cmml" xref="S3.SS4.p1.2.m2.2.2.2.2">subscript</csymbol><ci id="S3.SS4.p1.2.m2.2.2.2.2.2.cmml" xref="S3.SS4.p1.2.m2.2.2.2.2.2">ğ‘Œ</ci><ci id="S3.SS4.p1.2.m2.2.2.2.2.3.cmml" xref="S3.SS4.p1.2.m2.2.2.2.2.3">ğ‘…</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.2c">Y_{S},Y_{R}</annotation></semantics></math> indicate their corresponding labels. Note that <math id="S3.SS4.p1.3.m3.1" class="ltx_Math" alttext="\psi" display="inline"><semantics id="S3.SS4.p1.3.m3.1a"><mi id="S3.SS4.p1.3.m3.1.1" xref="S3.SS4.p1.3.m3.1.1.cmml">Ïˆ</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.1b"><ci id="S3.SS4.p1.3.m3.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1">ğœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.1c">\psi</annotation></semantics></math> is the mixup ratio which is randomly sampled from the linear space distribution from <math id="S3.SS4.p1.4.m4.1" class="ltx_Math" alttext="0.0" display="inline"><semantics id="S3.SS4.p1.4.m4.1a"><mn id="S3.SS4.p1.4.m4.1.1" xref="S3.SS4.p1.4.m4.1.1.cmml">0.0</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.4.m4.1b"><cn type="float" id="S3.SS4.p1.4.m4.1.1.cmml" xref="S3.SS4.p1.4.m4.1.1">0.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.4.m4.1c">0.0</annotation></semantics></math> to <math id="S3.SS4.p1.5.m5.1" class="ltx_Math" alttext="1.0" display="inline"><semantics id="S3.SS4.p1.5.m5.1a"><mn id="S3.SS4.p1.5.m5.1.1" xref="S3.SS4.p1.5.m5.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.5.m5.1b"><cn type="float" id="S3.SS4.p1.5.m5.1.1.cmml" xref="S3.SS4.p1.5.m5.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.5.m5.1c">1.0</annotation></semantics></math> with the interval being 0.05 (<em id="S3.SS4.p1.19.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS4.p1.19.2" class="ltx_text"></span>, <math id="S3.SS4.p1.6.m6.5" class="ltx_Math" alttext="np.linspace(0.0,1.0,21)" display="inline"><semantics id="S3.SS4.p1.6.m6.5a"><mrow id="S3.SS4.p1.6.m6.5.5.2" xref="S3.SS4.p1.6.m6.5.5.3.cmml"><mrow id="S3.SS4.p1.6.m6.4.4.1.1" xref="S3.SS4.p1.6.m6.4.4.1.1.cmml"><mi id="S3.SS4.p1.6.m6.4.4.1.1.2" xref="S3.SS4.p1.6.m6.4.4.1.1.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.6.m6.4.4.1.1.1" xref="S3.SS4.p1.6.m6.4.4.1.1.1.cmml">â€‹</mo><mi id="S3.SS4.p1.6.m6.4.4.1.1.3" xref="S3.SS4.p1.6.m6.4.4.1.1.3.cmml">p</mi></mrow><mo lspace="0em" rspace="0.167em" id="S3.SS4.p1.6.m6.5.5.2.3" xref="S3.SS4.p1.6.m6.5.5.3a.cmml">.</mo><mrow id="S3.SS4.p1.6.m6.5.5.2.2" xref="S3.SS4.p1.6.m6.5.5.2.2.cmml"><mi id="S3.SS4.p1.6.m6.5.5.2.2.2" xref="S3.SS4.p1.6.m6.5.5.2.2.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.6.m6.5.5.2.2.1" xref="S3.SS4.p1.6.m6.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS4.p1.6.m6.5.5.2.2.3" xref="S3.SS4.p1.6.m6.5.5.2.2.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.6.m6.5.5.2.2.1a" xref="S3.SS4.p1.6.m6.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS4.p1.6.m6.5.5.2.2.4" xref="S3.SS4.p1.6.m6.5.5.2.2.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.6.m6.5.5.2.2.1b" xref="S3.SS4.p1.6.m6.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS4.p1.6.m6.5.5.2.2.5" xref="S3.SS4.p1.6.m6.5.5.2.2.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.6.m6.5.5.2.2.1c" xref="S3.SS4.p1.6.m6.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS4.p1.6.m6.5.5.2.2.6" xref="S3.SS4.p1.6.m6.5.5.2.2.6.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.6.m6.5.5.2.2.1d" xref="S3.SS4.p1.6.m6.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS4.p1.6.m6.5.5.2.2.7" xref="S3.SS4.p1.6.m6.5.5.2.2.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.6.m6.5.5.2.2.1e" xref="S3.SS4.p1.6.m6.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS4.p1.6.m6.5.5.2.2.8" xref="S3.SS4.p1.6.m6.5.5.2.2.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.6.m6.5.5.2.2.1f" xref="S3.SS4.p1.6.m6.5.5.2.2.1.cmml">â€‹</mo><mi id="S3.SS4.p1.6.m6.5.5.2.2.9" xref="S3.SS4.p1.6.m6.5.5.2.2.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.6.m6.5.5.2.2.1g" xref="S3.SS4.p1.6.m6.5.5.2.2.1.cmml">â€‹</mo><mrow id="S3.SS4.p1.6.m6.5.5.2.2.10.2" xref="S3.SS4.p1.6.m6.5.5.2.2.10.1.cmml"><mo stretchy="false" id="S3.SS4.p1.6.m6.5.5.2.2.10.2.1" xref="S3.SS4.p1.6.m6.5.5.2.2.10.1.cmml">(</mo><mn id="S3.SS4.p1.6.m6.1.1" xref="S3.SS4.p1.6.m6.1.1.cmml">0.0</mn><mo id="S3.SS4.p1.6.m6.5.5.2.2.10.2.2" xref="S3.SS4.p1.6.m6.5.5.2.2.10.1.cmml">,</mo><mn id="S3.SS4.p1.6.m6.2.2" xref="S3.SS4.p1.6.m6.2.2.cmml">1.0</mn><mo id="S3.SS4.p1.6.m6.5.5.2.2.10.2.3" xref="S3.SS4.p1.6.m6.5.5.2.2.10.1.cmml">,</mo><mn id="S3.SS4.p1.6.m6.3.3" xref="S3.SS4.p1.6.m6.3.3.cmml">21</mn><mo stretchy="false" id="S3.SS4.p1.6.m6.5.5.2.2.10.2.4" xref="S3.SS4.p1.6.m6.5.5.2.2.10.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.6.m6.5b"><apply id="S3.SS4.p1.6.m6.5.5.3.cmml" xref="S3.SS4.p1.6.m6.5.5.2"><csymbol cd="ambiguous" id="S3.SS4.p1.6.m6.5.5.3a.cmml" xref="S3.SS4.p1.6.m6.5.5.2.3">formulae-sequence</csymbol><apply id="S3.SS4.p1.6.m6.4.4.1.1.cmml" xref="S3.SS4.p1.6.m6.4.4.1.1"><times id="S3.SS4.p1.6.m6.4.4.1.1.1.cmml" xref="S3.SS4.p1.6.m6.4.4.1.1.1"></times><ci id="S3.SS4.p1.6.m6.4.4.1.1.2.cmml" xref="S3.SS4.p1.6.m6.4.4.1.1.2">ğ‘›</ci><ci id="S3.SS4.p1.6.m6.4.4.1.1.3.cmml" xref="S3.SS4.p1.6.m6.4.4.1.1.3">ğ‘</ci></apply><apply id="S3.SS4.p1.6.m6.5.5.2.2.cmml" xref="S3.SS4.p1.6.m6.5.5.2.2"><times id="S3.SS4.p1.6.m6.5.5.2.2.1.cmml" xref="S3.SS4.p1.6.m6.5.5.2.2.1"></times><ci id="S3.SS4.p1.6.m6.5.5.2.2.2.cmml" xref="S3.SS4.p1.6.m6.5.5.2.2.2">ğ‘™</ci><ci id="S3.SS4.p1.6.m6.5.5.2.2.3.cmml" xref="S3.SS4.p1.6.m6.5.5.2.2.3">ğ‘–</ci><ci id="S3.SS4.p1.6.m6.5.5.2.2.4.cmml" xref="S3.SS4.p1.6.m6.5.5.2.2.4">ğ‘›</ci><ci id="S3.SS4.p1.6.m6.5.5.2.2.5.cmml" xref="S3.SS4.p1.6.m6.5.5.2.2.5">ğ‘ </ci><ci id="S3.SS4.p1.6.m6.5.5.2.2.6.cmml" xref="S3.SS4.p1.6.m6.5.5.2.2.6">ğ‘</ci><ci id="S3.SS4.p1.6.m6.5.5.2.2.7.cmml" xref="S3.SS4.p1.6.m6.5.5.2.2.7">ğ‘</ci><ci id="S3.SS4.p1.6.m6.5.5.2.2.8.cmml" xref="S3.SS4.p1.6.m6.5.5.2.2.8">ğ‘</ci><ci id="S3.SS4.p1.6.m6.5.5.2.2.9.cmml" xref="S3.SS4.p1.6.m6.5.5.2.2.9">ğ‘’</ci><vector id="S3.SS4.p1.6.m6.5.5.2.2.10.1.cmml" xref="S3.SS4.p1.6.m6.5.5.2.2.10.2"><cn type="float" id="S3.SS4.p1.6.m6.1.1.cmml" xref="S3.SS4.p1.6.m6.1.1">0.0</cn><cn type="float" id="S3.SS4.p1.6.m6.2.2.cmml" xref="S3.SS4.p1.6.m6.2.2">1.0</cn><cn type="integer" id="S3.SS4.p1.6.m6.3.3.cmml" xref="S3.SS4.p1.6.m6.3.3">21</cn></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.6.m6.5c">np.linspace(0.0,1.0,21)</annotation></semantics></math>). For the large-scale synthetic data, we synthesize the Syn_10K_50 dataset that has <math id="S3.SS4.p1.7.m7.1" class="ltx_Math" alttext="10K" display="inline"><semantics id="S3.SS4.p1.7.m7.1a"><mrow id="S3.SS4.p1.7.m7.1.1" xref="S3.SS4.p1.7.m7.1.1.cmml"><mn id="S3.SS4.p1.7.m7.1.1.2" xref="S3.SS4.p1.7.m7.1.1.2.cmml">10</mn><mo lspace="0em" rspace="0em" id="S3.SS4.p1.7.m7.1.1.1" xref="S3.SS4.p1.7.m7.1.1.1.cmml">â€‹</mo><mi id="S3.SS4.p1.7.m7.1.1.3" xref="S3.SS4.p1.7.m7.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.7.m7.1b"><apply id="S3.SS4.p1.7.m7.1.1.cmml" xref="S3.SS4.p1.7.m7.1.1"><times id="S3.SS4.p1.7.m7.1.1.1.cmml" xref="S3.SS4.p1.7.m7.1.1.1"></times><cn type="integer" id="S3.SS4.p1.7.m7.1.1.2.cmml" xref="S3.SS4.p1.7.m7.1.1.2">10</cn><ci id="S3.SS4.p1.7.m7.1.1.3.cmml" xref="S3.SS4.p1.7.m7.1.1.3">ğ¾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.7.m7.1c">10K</annotation></semantics></math> different identities with <math id="S3.SS4.p1.8.m8.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S3.SS4.p1.8.m8.1a"><mn id="S3.SS4.p1.8.m8.1.1" xref="S3.SS4.p1.8.m8.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.8.m8.1b"><cn type="integer" id="S3.SS4.p1.8.m8.1.1.cmml" xref="S3.SS4.p1.8.m8.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.8.m8.1c">50</annotation></semantics></math> samples per identity. For a small set of real-world data, we utilize the first <math id="S3.SS4.p1.9.m9.1" class="ltx_Math" alttext="2K" display="inline"><semantics id="S3.SS4.p1.9.m9.1a"><mrow id="S3.SS4.p1.9.m9.1.1" xref="S3.SS4.p1.9.m9.1.1.cmml"><mn id="S3.SS4.p1.9.m9.1.1.2" xref="S3.SS4.p1.9.m9.1.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.SS4.p1.9.m9.1.1.1" xref="S3.SS4.p1.9.m9.1.1.1.cmml">â€‹</mo><mi id="S3.SS4.p1.9.m9.1.1.3" xref="S3.SS4.p1.9.m9.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.9.m9.1b"><apply id="S3.SS4.p1.9.m9.1.1.cmml" xref="S3.SS4.p1.9.m9.1.1"><times id="S3.SS4.p1.9.m9.1.1.1.cmml" xref="S3.SS4.p1.9.m9.1.1.1"></times><cn type="integer" id="S3.SS4.p1.9.m9.1.1.2.cmml" xref="S3.SS4.p1.9.m9.1.1.2">2</cn><ci id="S3.SS4.p1.9.m9.1.1.3.cmml" xref="S3.SS4.p1.9.m9.1.1.3">ğ¾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.9.m9.1c">2K</annotation></semantics></math> identities of CASIA-WebFace. The experimental results are shown in TableÂ <a href="#S3.T2" title="Table 2 â€£ 3.4 SynFace with Domain Mixup â€£ 3 Method â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Specifically, the first row, Syn_10K_50, indicating the baseline method without using any real face images, achieves the accuracy <math id="S3.SS4.p1.10.m10.1" class="ltx_Math" alttext="91.97\%" display="inline"><semantics id="S3.SS4.p1.10.m10.1a"><mrow id="S3.SS4.p1.10.m10.1.1" xref="S3.SS4.p1.10.m10.1.1.cmml"><mn id="S3.SS4.p1.10.m10.1.1.2" xref="S3.SS4.p1.10.m10.1.1.2.cmml">91.97</mn><mo id="S3.SS4.p1.10.m10.1.1.1" xref="S3.SS4.p1.10.m10.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.10.m10.1b"><apply id="S3.SS4.p1.10.m10.1.1.cmml" xref="S3.SS4.p1.10.m10.1.1"><csymbol cd="latexml" id="S3.SS4.p1.10.m10.1.1.1.cmml" xref="S3.SS4.p1.10.m10.1.1.1">percent</csymbol><cn type="float" id="S3.SS4.p1.10.m10.1.1.2.cmml" xref="S3.SS4.p1.10.m10.1.1.2">91.97</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.10.m10.1c">91.97\%</annotation></semantics></math> using identity mixup. â€œReal_N_Sâ€ means the use of only real images, <math id="S3.SS4.p1.11.m11.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS4.p1.11.m11.1a"><mi id="S3.SS4.p1.11.m11.1.1" xref="S3.SS4.p1.11.m11.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.11.m11.1b"><ci id="S3.SS4.p1.11.m11.1.1.cmml" xref="S3.SS4.p1.11.m11.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.11.m11.1c">N</annotation></semantics></math> identities with <math id="S3.SS4.p1.12.m12.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS4.p1.12.m12.1a"><mi id="S3.SS4.p1.12.m12.1.1" xref="S3.SS4.p1.12.m12.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.12.m12.1b"><ci id="S3.SS4.p1.12.m12.1.1.cmml" xref="S3.SS4.p1.12.m12.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.12.m12.1c">S</annotation></semantics></math> samples per identity during training, while â€œMix_N_Sâ€ indicates a mixture of <math id="S3.SS4.p1.13.m13.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS4.p1.13.m13.1a"><mi id="S3.SS4.p1.13.m13.1.1" xref="S3.SS4.p1.13.m13.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.13.m13.1b"><ci id="S3.SS4.p1.13.m13.1.1.cmml" xref="S3.SS4.p1.13.m13.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.13.m13.1c">N</annotation></semantics></math> real identities with <math id="S3.SS4.p1.14.m14.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS4.p1.14.m14.1a"><mi id="S3.SS4.p1.14.m14.1.1" xref="S3.SS4.p1.14.m14.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.14.m14.1b"><ci id="S3.SS4.p1.14.m14.1.1.cmml" xref="S3.SS4.p1.14.m14.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.14.m14.1c">S</annotation></semantics></math> samples per identity with Syn_10K_50 during training. Both identity mixup and domain mixup are employed on all the â€˜Mix_N_Sâ€ datasets. As demonstrated in TableÂ <a href="#S3.T2" title="Table 2 â€£ 3.4 SynFace with Domain Mixup â€£ 3 Method â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, domain mixup brings a significant and consistent improvement over the baseline methods under different settings. For example, Mix_2K_10 obtains <math id="S3.SS4.p1.15.m15.1" class="ltx_Math" alttext="95.78\%" display="inline"><semantics id="S3.SS4.p1.15.m15.1a"><mrow id="S3.SS4.p1.15.m15.1.1" xref="S3.SS4.p1.15.m15.1.1.cmml"><mn id="S3.SS4.p1.15.m15.1.1.2" xref="S3.SS4.p1.15.m15.1.1.2.cmml">95.78</mn><mo id="S3.SS4.p1.15.m15.1.1.1" xref="S3.SS4.p1.15.m15.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.15.m15.1b"><apply id="S3.SS4.p1.15.m15.1.1.cmml" xref="S3.SS4.p1.15.m15.1.1"><csymbol cd="latexml" id="S3.SS4.p1.15.m15.1.1.1.cmml" xref="S3.SS4.p1.15.m15.1.1.1">percent</csymbol><cn type="float" id="S3.SS4.p1.15.m15.1.1.2.cmml" xref="S3.SS4.p1.15.m15.1.1.2">95.78</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.15.m15.1c">95.78\%</annotation></semantics></math> accuracy, which significantly surpasses <math id="S3.SS4.p1.16.m16.1" class="ltx_Math" alttext="91.97\%" display="inline"><semantics id="S3.SS4.p1.16.m16.1a"><mrow id="S3.SS4.p1.16.m16.1.1" xref="S3.SS4.p1.16.m16.1.1.cmml"><mn id="S3.SS4.p1.16.m16.1.1.2" xref="S3.SS4.p1.16.m16.1.1.2.cmml">91.97</mn><mo id="S3.SS4.p1.16.m16.1.1.1" xref="S3.SS4.p1.16.m16.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.16.m16.1b"><apply id="S3.SS4.p1.16.m16.1.1.cmml" xref="S3.SS4.p1.16.m16.1.1"><csymbol cd="latexml" id="S3.SS4.p1.16.m16.1.1.1.cmml" xref="S3.SS4.p1.16.m16.1.1.1">percent</csymbol><cn type="float" id="S3.SS4.p1.16.m16.1.1.2.cmml" xref="S3.SS4.p1.16.m16.1.1.2">91.97</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.16.m16.1c">91.97\%</annotation></semantics></math> achieved by Syn_10K_50 and <math id="S3.SS4.p1.17.m17.1" class="ltx_Math" alttext="91.22\%" display="inline"><semantics id="S3.SS4.p1.17.m17.1a"><mrow id="S3.SS4.p1.17.m17.1.1" xref="S3.SS4.p1.17.m17.1.1.cmml"><mn id="S3.SS4.p1.17.m17.1.1.2" xref="S3.SS4.p1.17.m17.1.1.2.cmml">91.22</mn><mo id="S3.SS4.p1.17.m17.1.1.1" xref="S3.SS4.p1.17.m17.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.17.m17.1b"><apply id="S3.SS4.p1.17.m17.1.1.cmml" xref="S3.SS4.p1.17.m17.1.1"><csymbol cd="latexml" id="S3.SS4.p1.17.m17.1.1.1.cmml" xref="S3.SS4.p1.17.m17.1.1.1">percent</csymbol><cn type="float" id="S3.SS4.p1.17.m17.1.1.2.cmml" xref="S3.SS4.p1.17.m17.1.1.2">91.22</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.17.m17.1c">91.22\%</annotation></semantics></math> achieved by Real_2K_10. We conjecture that mixup with the real images can bring the real-world appearance attributes (<em id="S3.SS4.p1.19.3" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S3.SS4.p1.19.4" class="ltx_text"></span>, blur and illumination) to synthetic images, which alleviate the domain gap. If we continue to increase the number of real images for training, <em id="S3.SS4.p1.19.5" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S3.SS4.p1.19.6" class="ltx_text"></span>, Mix_2K_20, the performance can be further boosted from <math id="S3.SS4.p1.18.m18.1" class="ltx_Math" alttext="95.78\%" display="inline"><semantics id="S3.SS4.p1.18.m18.1a"><mrow id="S3.SS4.p1.18.m18.1.1" xref="S3.SS4.p1.18.m18.1.1.cmml"><mn id="S3.SS4.p1.18.m18.1.1.2" xref="S3.SS4.p1.18.m18.1.1.2.cmml">95.78</mn><mo id="S3.SS4.p1.18.m18.1.1.1" xref="S3.SS4.p1.18.m18.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.18.m18.1b"><apply id="S3.SS4.p1.18.m18.1.1.cmml" xref="S3.SS4.p1.18.m18.1.1"><csymbol cd="latexml" id="S3.SS4.p1.18.m18.1.1.1.cmml" xref="S3.SS4.p1.18.m18.1.1.1">percent</csymbol><cn type="float" id="S3.SS4.p1.18.m18.1.1.2.cmml" xref="S3.SS4.p1.18.m18.1.1.2">95.78</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.18.m18.1c">95.78\%</annotation></semantics></math> to <math id="S3.SS4.p1.19.m19.1" class="ltx_Math" alttext="97.65\%" display="inline"><semantics id="S3.SS4.p1.19.m19.1a"><mrow id="S3.SS4.p1.19.m19.1.1" xref="S3.SS4.p1.19.m19.1.1.cmml"><mn id="S3.SS4.p1.19.m19.1.1.2" xref="S3.SS4.p1.19.m19.1.1.2.cmml">97.65</mn><mo id="S3.SS4.p1.19.m19.1.1.1" xref="S3.SS4.p1.19.m19.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.19.m19.1b"><apply id="S3.SS4.p1.19.m19.1.1.cmml" xref="S3.SS4.p1.19.m19.1.1"><csymbol cd="latexml" id="S3.SS4.p1.19.m19.1.1.1.cmml" xref="S3.SS4.p1.19.m19.1.1.1">percent</csymbol><cn type="float" id="S3.SS4.p1.19.m19.1.1.2.cmml" xref="S3.SS4.p1.19.m19.1.1.2">97.65</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.19.m19.1c">97.65\%</annotation></semantics></math>.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.3.1.1" class="ltx_tr">
<th id="S3.T2.3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Method</th>
<th id="S3.T2.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">R_ID</th>
<th id="S3.T2.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Samples per R_ID</th>
<th id="S3.T2.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Accuracy</th>
</tr>
<tr id="S3.T2.3.2.2" class="ltx_tr">
<th id="S3.T2.3.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Syn_10K_50</th>
<th id="S3.T2.3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">0</th>
<th id="S3.T2.3.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">0</th>
<th id="S3.T2.3.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">91.97</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.3.3.1" class="ltx_tr">
<td id="S3.T2.3.3.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Real_1K_10</td>
<td id="S3.T2.3.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1K</td>
<td id="S3.T2.3.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10</td>
<td id="S3.T2.3.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.50</td>
</tr>
<tr id="S3.T2.3.4.2" class="ltx_tr">
<td id="S3.T2.3.4.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">Mix_1K_10</td>
<td id="S3.T2.3.4.2.2" class="ltx_td ltx_align_center ltx_border_r">1K</td>
<td id="S3.T2.3.4.2.3" class="ltx_td ltx_align_center ltx_border_r">10</td>
<td id="S3.T2.3.4.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T2.3.4.2.4.1" class="ltx_text ltx_font_bold">92.28</span></td>
</tr>
<tr id="S3.T2.3.5.3" class="ltx_tr">
<td id="S3.T2.3.5.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Real_1K_20</td>
<td id="S3.T2.3.5.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1K</td>
<td id="S3.T2.3.5.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20</td>
<td id="S3.T2.3.5.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">92.53</td>
</tr>
<tr id="S3.T2.3.6.4" class="ltx_tr">
<td id="S3.T2.3.6.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">Mix_1K_20</td>
<td id="S3.T2.3.6.4.2" class="ltx_td ltx_align_center ltx_border_r">1K</td>
<td id="S3.T2.3.6.4.3" class="ltx_td ltx_align_center ltx_border_r">20</td>
<td id="S3.T2.3.6.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T2.3.6.4.4.1" class="ltx_text ltx_font_bold">95.05</span></td>
</tr>
<tr id="S3.T2.3.7.5" class="ltx_tr">
<td id="S3.T2.3.7.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Real_2K_10</td>
<td id="S3.T2.3.7.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2K</td>
<td id="S3.T2.3.7.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10</td>
<td id="S3.T2.3.7.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">91.22</td>
</tr>
<tr id="S3.T2.3.8.6" class="ltx_tr">
<td id="S3.T2.3.8.6.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">Mix_2K_10</td>
<td id="S3.T2.3.8.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">2K</td>
<td id="S3.T2.3.8.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">10</td>
<td id="S3.T2.3.8.6.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S3.T2.3.8.6.4.1" class="ltx_text ltx_font_bold">95.78</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Face verification accuracies (<math id="S3.T2.2.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S3.T2.2.m1.1b"><mo id="S3.T2.2.m1.1.1" xref="S3.T2.2.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S3.T2.2.m1.1c"><csymbol cd="latexml" id="S3.T2.2.m1.1.1.cmml" xref="S3.T2.2.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.m1.1d">\%</annotation></semantics></math>) of models trained on synthetic, real and mixed datasets on LFW. R_ID means the number of real identities.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">With the introduced Mixup Face Generator, we are able to generate large-scale face images with controllable facial attributes, including the identity, pose, expression, illumination, and other dataset characteristics such as the depth and the width. In this section, we perform empirical analysis using synthetic face images. Specifically, we first introduce the datasets (Sec.Â <a href="#S4.SS1" title="4.1 Datasets â€£ 4 Experiments â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>) and the implementation details (Sec.Â <a href="#S4.SS2" title="4.2 Implementation Details â€£ 4 Experiments â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>). Then the long-tailed problem is mitigated by employing the balanced synthetic face dataset and identity mixup (Sec.Â <a href="#S4.SS3" title="4.3 Long-tailed Face Recognition â€£ 4 Experiments â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>). Lastly, we analyze the impacts of depth, width (Sec.Â <a href="#S4.SS4" title="4.4 Effectiveness of â€œDepthâ€ and â€œWidthâ€ â€£ 4 Experiments â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>), and different facial attributes (Sec.Â <a href="#S4.SS5" title="4.5 Impacts of Different Facial Attributes â€£ 4 Experiments â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.5</span></a>).</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">Real Datasets.</span> We employ the CASIA-WebFaceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> and LFWÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> for training and testing, respectively. The CASIA-WebFace dataset contains around 500,000 web images, <em id="S4.SS1.p1.1.2" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS1.p1.1.3" class="ltx_text"></span>, 494,414 images from 10,575 subjects. The LFW dataset is a widely-used benchmark for face verification, which contains 13,233 face images from 5,749 identities. Following the protocol in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, we report the verification accuracy on 6,000 testing image pairs.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Synthetic Datasets.</span> We first generate a synthetic version of LFW, in which all synthetic face images share the same properties with LFW images, <em id="S4.SS1.p2.1.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S4.SS1.p2.1.3" class="ltx_text"></span>, expression, illumination, and pose. Specifically, for each image in LFW, we first use the 3D face reconstruction network inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> to obtain the attribute coefficients <math id="S4.SS1.p2.1.m1.3" class="ltx_Math" alttext="\mu\doteq[\beta,\gamma,\theta]" display="inline"><semantics id="S4.SS1.p2.1.m1.3a"><mrow id="S4.SS1.p2.1.m1.3.4" xref="S4.SS1.p2.1.m1.3.4.cmml"><mi id="S4.SS1.p2.1.m1.3.4.2" xref="S4.SS1.p2.1.m1.3.4.2.cmml">Î¼</mi><mo id="S4.SS1.p2.1.m1.3.4.1" xref="S4.SS1.p2.1.m1.3.4.1.cmml">â‰</mo><mrow id="S4.SS1.p2.1.m1.3.4.3.2" xref="S4.SS1.p2.1.m1.3.4.3.1.cmml"><mo stretchy="false" id="S4.SS1.p2.1.m1.3.4.3.2.1" xref="S4.SS1.p2.1.m1.3.4.3.1.cmml">[</mo><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">Î²</mi><mo id="S4.SS1.p2.1.m1.3.4.3.2.2" xref="S4.SS1.p2.1.m1.3.4.3.1.cmml">,</mo><mi id="S4.SS1.p2.1.m1.2.2" xref="S4.SS1.p2.1.m1.2.2.cmml">Î³</mi><mo id="S4.SS1.p2.1.m1.3.4.3.2.3" xref="S4.SS1.p2.1.m1.3.4.3.1.cmml">,</mo><mi id="S4.SS1.p2.1.m1.3.3" xref="S4.SS1.p2.1.m1.3.3.cmml">Î¸</mi><mo stretchy="false" id="S4.SS1.p2.1.m1.3.4.3.2.4" xref="S4.SS1.p2.1.m1.3.4.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.3b"><apply id="S4.SS1.p2.1.m1.3.4.cmml" xref="S4.SS1.p2.1.m1.3.4"><csymbol cd="latexml" id="S4.SS1.p2.1.m1.3.4.1.cmml" xref="S4.SS1.p2.1.m1.3.4.1">approaches-limit</csymbol><ci id="S4.SS1.p2.1.m1.3.4.2.cmml" xref="S4.SS1.p2.1.m1.3.4.2">ğœ‡</ci><list id="S4.SS1.p2.1.m1.3.4.3.1.cmml" xref="S4.SS1.p2.1.m1.3.4.3.2"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">ğ›½</ci><ci id="S4.SS1.p2.1.m1.2.2.cmml" xref="S4.SS1.p2.1.m1.2.2">ğ›¾</ci><ci id="S4.SS1.p2.1.m1.3.3.cmml" xref="S4.SS1.p2.1.m1.3.3">ğœƒ</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.3c">\mu\doteq[\beta,\gamma,\theta]</annotation></semantics></math>, which indicate the expression, illumination and pose coefficient, respectively. We then adopt the DiscoFaceGANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> to generate the face images according to these attribute coefficients with a random identity coefficient. Finally, we obtain a new dataset and refer to it as Syn-LFW, which has the same statistics as LFW with unknown identities (non-existing people). For synthetic training dataset (<em id="S4.SS1.p2.1.4" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S4.SS1.p2.1.5" class="ltx_text"></span>, Syn_10K_50), we construct it by randomly sampling latent variables from the standard normal distribution for identity, expression, pose and illumination coefficients, respectively, which leads to the same person with different expressions, poses and illuminations in the same class. Note that the identities of Syn-LFW do not have the overlap with any synthetic training datasets.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Implementation Details</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.7" class="ltx_p">We use the MTCNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> to detect face bounding boxes and five facial landmarks (two eyes, nose and two mouth corners). All face images are then cropped, aligned (similarity transformation), and resized to <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="112\times 96" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mn id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">112</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">Ã—</mo><mn id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">96</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><times id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></times><cn type="integer" id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">112</cn><cn type="integer" id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">96</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">112\times 96</annotation></semantics></math> pixel as illustrated in FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Similar toÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, we normalize the pixel values (in <math id="S4.SS2.p1.2.m2.2" class="ltx_Math" alttext="[0,255]" display="inline"><semantics id="S4.SS2.p1.2.m2.2a"><mrow id="S4.SS2.p1.2.m2.2.3.2" xref="S4.SS2.p1.2.m2.2.3.1.cmml"><mo stretchy="false" id="S4.SS2.p1.2.m2.2.3.2.1" xref="S4.SS2.p1.2.m2.2.3.1.cmml">[</mo><mn id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">0</mn><mo id="S4.SS2.p1.2.m2.2.3.2.2" xref="S4.SS2.p1.2.m2.2.3.1.cmml">,</mo><mn id="S4.SS2.p1.2.m2.2.2" xref="S4.SS2.p1.2.m2.2.2.cmml">255</mn><mo stretchy="false" id="S4.SS2.p1.2.m2.2.3.2.3" xref="S4.SS2.p1.2.m2.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.2b"><interval closure="closed" id="S4.SS2.p1.2.m2.2.3.1.cmml" xref="S4.SS2.p1.2.m2.2.3.2"><cn type="integer" id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">0</cn><cn type="integer" id="S4.SS2.p1.2.m2.2.2.cmml" xref="S4.SS2.p1.2.m2.2.2">255</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.2c">[0,255]</annotation></semantics></math>) in RGB images to <math id="S4.SS2.p1.3.m3.2" class="ltx_Math" alttext="[-1.0,1.0]" display="inline"><semantics id="S4.SS2.p1.3.m3.2a"><mrow id="S4.SS2.p1.3.m3.2.2.1" xref="S4.SS2.p1.3.m3.2.2.2.cmml"><mo stretchy="false" id="S4.SS2.p1.3.m3.2.2.1.2" xref="S4.SS2.p1.3.m3.2.2.2.cmml">[</mo><mrow id="S4.SS2.p1.3.m3.2.2.1.1" xref="S4.SS2.p1.3.m3.2.2.1.1.cmml"><mo id="S4.SS2.p1.3.m3.2.2.1.1a" xref="S4.SS2.p1.3.m3.2.2.1.1.cmml">âˆ’</mo><mn id="S4.SS2.p1.3.m3.2.2.1.1.2" xref="S4.SS2.p1.3.m3.2.2.1.1.2.cmml">1.0</mn></mrow><mo id="S4.SS2.p1.3.m3.2.2.1.3" xref="S4.SS2.p1.3.m3.2.2.2.cmml">,</mo><mn id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">1.0</mn><mo stretchy="false" id="S4.SS2.p1.3.m3.2.2.1.4" xref="S4.SS2.p1.3.m3.2.2.2.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.2b"><interval closure="closed" id="S4.SS2.p1.3.m3.2.2.2.cmml" xref="S4.SS2.p1.3.m3.2.2.1"><apply id="S4.SS2.p1.3.m3.2.2.1.1.cmml" xref="S4.SS2.p1.3.m3.2.2.1.1"><minus id="S4.SS2.p1.3.m3.2.2.1.1.1.cmml" xref="S4.SS2.p1.3.m3.2.2.1.1"></minus><cn type="float" id="S4.SS2.p1.3.m3.2.2.1.1.2.cmml" xref="S4.SS2.p1.3.m3.2.2.1.1.2">1.0</cn></apply><cn type="float" id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">1.0</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.2c">[-1.0,1.0]</annotation></semantics></math> for training and testing. To balance the trade-off between the performance and computational complexity, we adopt the variant of ResNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, LResNet50E-IR, as our backbone framework, which is devised in ArcFaceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. All models are implemented with PyTorchÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> and trained from scratch using Eight NVIDIA Tesla V100 GPUs. We use the additive angular margin loss defined in Eq.Â (<a href="#S3.E1" title="In 3.1 Deep Face Recognition â€£ 3 Method â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), <em id="S4.SS2.p1.7.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS2.p1.7.2" class="ltx_text"></span>, with <math id="S4.SS2.p1.4.m4.6" class="ltx_Math" alttext="(m_{1},m_{2},m_{3})=(0,0.5,0)" display="inline"><semantics id="S4.SS2.p1.4.m4.6a"><mrow id="S4.SS2.p1.4.m4.6.6" xref="S4.SS2.p1.4.m4.6.6.cmml"><mrow id="S4.SS2.p1.4.m4.6.6.3.3" xref="S4.SS2.p1.4.m4.6.6.3.4.cmml"><mo stretchy="false" id="S4.SS2.p1.4.m4.6.6.3.3.4" xref="S4.SS2.p1.4.m4.6.6.3.4.cmml">(</mo><msub id="S4.SS2.p1.4.m4.4.4.1.1.1" xref="S4.SS2.p1.4.m4.4.4.1.1.1.cmml"><mi id="S4.SS2.p1.4.m4.4.4.1.1.1.2" xref="S4.SS2.p1.4.m4.4.4.1.1.1.2.cmml">m</mi><mn id="S4.SS2.p1.4.m4.4.4.1.1.1.3" xref="S4.SS2.p1.4.m4.4.4.1.1.1.3.cmml">1</mn></msub><mo id="S4.SS2.p1.4.m4.6.6.3.3.5" xref="S4.SS2.p1.4.m4.6.6.3.4.cmml">,</mo><msub id="S4.SS2.p1.4.m4.5.5.2.2.2" xref="S4.SS2.p1.4.m4.5.5.2.2.2.cmml"><mi id="S4.SS2.p1.4.m4.5.5.2.2.2.2" xref="S4.SS2.p1.4.m4.5.5.2.2.2.2.cmml">m</mi><mn id="S4.SS2.p1.4.m4.5.5.2.2.2.3" xref="S4.SS2.p1.4.m4.5.5.2.2.2.3.cmml">2</mn></msub><mo id="S4.SS2.p1.4.m4.6.6.3.3.6" xref="S4.SS2.p1.4.m4.6.6.3.4.cmml">,</mo><msub id="S4.SS2.p1.4.m4.6.6.3.3.3" xref="S4.SS2.p1.4.m4.6.6.3.3.3.cmml"><mi id="S4.SS2.p1.4.m4.6.6.3.3.3.2" xref="S4.SS2.p1.4.m4.6.6.3.3.3.2.cmml">m</mi><mn id="S4.SS2.p1.4.m4.6.6.3.3.3.3" xref="S4.SS2.p1.4.m4.6.6.3.3.3.3.cmml">3</mn></msub><mo stretchy="false" id="S4.SS2.p1.4.m4.6.6.3.3.7" xref="S4.SS2.p1.4.m4.6.6.3.4.cmml">)</mo></mrow><mo id="S4.SS2.p1.4.m4.6.6.4" xref="S4.SS2.p1.4.m4.6.6.4.cmml">=</mo><mrow id="S4.SS2.p1.4.m4.6.6.5.2" xref="S4.SS2.p1.4.m4.6.6.5.1.cmml"><mo stretchy="false" id="S4.SS2.p1.4.m4.6.6.5.2.1" xref="S4.SS2.p1.4.m4.6.6.5.1.cmml">(</mo><mn id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml">0</mn><mo id="S4.SS2.p1.4.m4.6.6.5.2.2" xref="S4.SS2.p1.4.m4.6.6.5.1.cmml">,</mo><mn id="S4.SS2.p1.4.m4.2.2" xref="S4.SS2.p1.4.m4.2.2.cmml">0.5</mn><mo id="S4.SS2.p1.4.m4.6.6.5.2.3" xref="S4.SS2.p1.4.m4.6.6.5.1.cmml">,</mo><mn id="S4.SS2.p1.4.m4.3.3" xref="S4.SS2.p1.4.m4.3.3.cmml">0</mn><mo stretchy="false" id="S4.SS2.p1.4.m4.6.6.5.2.4" xref="S4.SS2.p1.4.m4.6.6.5.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.6b"><apply id="S4.SS2.p1.4.m4.6.6.cmml" xref="S4.SS2.p1.4.m4.6.6"><eq id="S4.SS2.p1.4.m4.6.6.4.cmml" xref="S4.SS2.p1.4.m4.6.6.4"></eq><vector id="S4.SS2.p1.4.m4.6.6.3.4.cmml" xref="S4.SS2.p1.4.m4.6.6.3.3"><apply id="S4.SS2.p1.4.m4.4.4.1.1.1.cmml" xref="S4.SS2.p1.4.m4.4.4.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.4.m4.4.4.1.1.1.1.cmml" xref="S4.SS2.p1.4.m4.4.4.1.1.1">subscript</csymbol><ci id="S4.SS2.p1.4.m4.4.4.1.1.1.2.cmml" xref="S4.SS2.p1.4.m4.4.4.1.1.1.2">ğ‘š</ci><cn type="integer" id="S4.SS2.p1.4.m4.4.4.1.1.1.3.cmml" xref="S4.SS2.p1.4.m4.4.4.1.1.1.3">1</cn></apply><apply id="S4.SS2.p1.4.m4.5.5.2.2.2.cmml" xref="S4.SS2.p1.4.m4.5.5.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p1.4.m4.5.5.2.2.2.1.cmml" xref="S4.SS2.p1.4.m4.5.5.2.2.2">subscript</csymbol><ci id="S4.SS2.p1.4.m4.5.5.2.2.2.2.cmml" xref="S4.SS2.p1.4.m4.5.5.2.2.2.2">ğ‘š</ci><cn type="integer" id="S4.SS2.p1.4.m4.5.5.2.2.2.3.cmml" xref="S4.SS2.p1.4.m4.5.5.2.2.2.3">2</cn></apply><apply id="S4.SS2.p1.4.m4.6.6.3.3.3.cmml" xref="S4.SS2.p1.4.m4.6.6.3.3.3"><csymbol cd="ambiguous" id="S4.SS2.p1.4.m4.6.6.3.3.3.1.cmml" xref="S4.SS2.p1.4.m4.6.6.3.3.3">subscript</csymbol><ci id="S4.SS2.p1.4.m4.6.6.3.3.3.2.cmml" xref="S4.SS2.p1.4.m4.6.6.3.3.3.2">ğ‘š</ci><cn type="integer" id="S4.SS2.p1.4.m4.6.6.3.3.3.3.cmml" xref="S4.SS2.p1.4.m4.6.6.3.3.3.3">3</cn></apply></vector><vector id="S4.SS2.p1.4.m4.6.6.5.1.cmml" xref="S4.SS2.p1.4.m4.6.6.5.2"><cn type="integer" id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1">0</cn><cn type="float" id="S4.SS2.p1.4.m4.2.2.cmml" xref="S4.SS2.p1.4.m4.2.2">0.5</cn><cn type="integer" id="S4.SS2.p1.4.m4.3.3.cmml" xref="S4.SS2.p1.4.m4.3.3">0</cn></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.6c">(m_{1},m_{2},m_{3})=(0,0.5,0)</annotation></semantics></math> and <math id="S4.SS2.p1.5.m5.1" class="ltx_Math" alttext="s=30" display="inline"><semantics id="S4.SS2.p1.5.m5.1a"><mrow id="S4.SS2.p1.5.m5.1.1" xref="S4.SS2.p1.5.m5.1.1.cmml"><mi id="S4.SS2.p1.5.m5.1.1.2" xref="S4.SS2.p1.5.m5.1.1.2.cmml">s</mi><mo id="S4.SS2.p1.5.m5.1.1.1" xref="S4.SS2.p1.5.m5.1.1.1.cmml">=</mo><mn id="S4.SS2.p1.5.m5.1.1.3" xref="S4.SS2.p1.5.m5.1.1.3.cmml">30</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m5.1b"><apply id="S4.SS2.p1.5.m5.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1"><eq id="S4.SS2.p1.5.m5.1.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1.1"></eq><ci id="S4.SS2.p1.5.m5.1.1.2.cmml" xref="S4.SS2.p1.5.m5.1.1.2">ğ‘ </ci><cn type="integer" id="S4.SS2.p1.5.m5.1.1.3.cmml" xref="S4.SS2.p1.5.m5.1.1.3">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m5.1c">s=30</annotation></semantics></math>. If not mentioned, we always set the batch size to 512. We use SGD with a momentum of <math id="S4.SS2.p1.6.m6.1" class="ltx_Math" alttext="0.9" display="inline"><semantics id="S4.SS2.p1.6.m6.1a"><mn id="S4.SS2.p1.6.m6.1.1" xref="S4.SS2.p1.6.m6.1.1.cmml">0.9</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.6.m6.1b"><cn type="float" id="S4.SS2.p1.6.m6.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1">0.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.6.m6.1c">0.9</annotation></semantics></math> and a weight decay of <math id="S4.SS2.p1.7.m7.1" class="ltx_Math" alttext="0.0005" display="inline"><semantics id="S4.SS2.p1.7.m7.1a"><mn id="S4.SS2.p1.7.m7.1.1" xref="S4.SS2.p1.7.m7.1.1.cmml">0.0005</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.7.m7.1b"><cn type="float" id="S4.SS2.p1.7.m7.1.1.cmml" xref="S4.SS2.p1.7.m7.1.1">0.0005</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.7.m7.1c">0.0005</annotation></semantics></math>. The learning rate starts from 0.1, and is divided by 10 at the 24, 30 and 36 epochs, with 40 epochs in total.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Long-tailed Face Recognition</h3>

<figure id="S4.F6" class="ltx_figure"><img src="/html/2108.07960/assets/x6.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="189" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Face verification accuracies (<math id="S4.F6.6.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.F6.6.m1.1b"><mo id="S4.F6.6.m1.1.1" xref="S4.F6.6.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.F6.6.m1.1c"><csymbol cd="latexml" id="S4.F6.6.m1.1.1.cmml" xref="S4.F6.6.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.6.m1.1d">\%</annotation></semantics></math>) on LFW using the training datasets with decreasing imbalance, <em id="S4.F6.13.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.F6.14.2" class="ltx_text"></span>, â€œ2K_UB1â€, â€œ2K_UB2â€, and â€œ2K_50â€, where we assign <math id="S4.F6.7.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.F6.7.m2.1b"><mi id="S4.F6.7.m2.1.1" xref="S4.F6.7.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.F6.7.m2.1c"><ci id="S4.F6.7.m2.1.1.cmml" xref="S4.F6.7.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.7.m2.1d">N</annotation></semantics></math> defined in Eq.(4) as <math id="S4.F6.8.m3.5" class="ltx_Math" alttext="[2,2,6,40,200]" display="inline"><semantics id="S4.F6.8.m3.5b"><mrow id="S4.F6.8.m3.5.6.2" xref="S4.F6.8.m3.5.6.1.cmml"><mo stretchy="false" id="S4.F6.8.m3.5.6.2.1" xref="S4.F6.8.m3.5.6.1.cmml">[</mo><mn id="S4.F6.8.m3.1.1" xref="S4.F6.8.m3.1.1.cmml">2</mn><mo id="S4.F6.8.m3.5.6.2.2" xref="S4.F6.8.m3.5.6.1.cmml">,</mo><mn id="S4.F6.8.m3.2.2" xref="S4.F6.8.m3.2.2.cmml">2</mn><mo id="S4.F6.8.m3.5.6.2.3" xref="S4.F6.8.m3.5.6.1.cmml">,</mo><mn id="S4.F6.8.m3.3.3" xref="S4.F6.8.m3.3.3.cmml">6</mn><mo id="S4.F6.8.m3.5.6.2.4" xref="S4.F6.8.m3.5.6.1.cmml">,</mo><mn id="S4.F6.8.m3.4.4" xref="S4.F6.8.m3.4.4.cmml">40</mn><mo id="S4.F6.8.m3.5.6.2.5" xref="S4.F6.8.m3.5.6.1.cmml">,</mo><mn id="S4.F6.8.m3.5.5" xref="S4.F6.8.m3.5.5.cmml">200</mn><mo stretchy="false" id="S4.F6.8.m3.5.6.2.6" xref="S4.F6.8.m3.5.6.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.8.m3.5c"><list id="S4.F6.8.m3.5.6.1.cmml" xref="S4.F6.8.m3.5.6.2"><cn type="integer" id="S4.F6.8.m3.1.1.cmml" xref="S4.F6.8.m3.1.1">2</cn><cn type="integer" id="S4.F6.8.m3.2.2.cmml" xref="S4.F6.8.m3.2.2">2</cn><cn type="integer" id="S4.F6.8.m3.3.3.cmml" xref="S4.F6.8.m3.3.3">6</cn><cn type="integer" id="S4.F6.8.m3.4.4.cmml" xref="S4.F6.8.m3.4.4">40</cn><cn type="integer" id="S4.F6.8.m3.5.5.cmml" xref="S4.F6.8.m3.5.5">200</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.8.m3.5d">[2,2,6,40,200]</annotation></semantics></math>, <math id="S4.F6.9.m4.5" class="ltx_Math" alttext="[4,16,30,80,120]" display="inline"><semantics id="S4.F6.9.m4.5b"><mrow id="S4.F6.9.m4.5.6.2" xref="S4.F6.9.m4.5.6.1.cmml"><mo stretchy="false" id="S4.F6.9.m4.5.6.2.1" xref="S4.F6.9.m4.5.6.1.cmml">[</mo><mn id="S4.F6.9.m4.1.1" xref="S4.F6.9.m4.1.1.cmml">4</mn><mo id="S4.F6.9.m4.5.6.2.2" xref="S4.F6.9.m4.5.6.1.cmml">,</mo><mn id="S4.F6.9.m4.2.2" xref="S4.F6.9.m4.2.2.cmml">16</mn><mo id="S4.F6.9.m4.5.6.2.3" xref="S4.F6.9.m4.5.6.1.cmml">,</mo><mn id="S4.F6.9.m4.3.3" xref="S4.F6.9.m4.3.3.cmml">30</mn><mo id="S4.F6.9.m4.5.6.2.4" xref="S4.F6.9.m4.5.6.1.cmml">,</mo><mn id="S4.F6.9.m4.4.4" xref="S4.F6.9.m4.4.4.cmml">80</mn><mo id="S4.F6.9.m4.5.6.2.5" xref="S4.F6.9.m4.5.6.1.cmml">,</mo><mn id="S4.F6.9.m4.5.5" xref="S4.F6.9.m4.5.5.cmml">120</mn><mo stretchy="false" id="S4.F6.9.m4.5.6.2.6" xref="S4.F6.9.m4.5.6.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.9.m4.5c"><list id="S4.F6.9.m4.5.6.1.cmml" xref="S4.F6.9.m4.5.6.2"><cn type="integer" id="S4.F6.9.m4.1.1.cmml" xref="S4.F6.9.m4.1.1">4</cn><cn type="integer" id="S4.F6.9.m4.2.2.cmml" xref="S4.F6.9.m4.2.2">16</cn><cn type="integer" id="S4.F6.9.m4.3.3.cmml" xref="S4.F6.9.m4.3.3">30</cn><cn type="integer" id="S4.F6.9.m4.4.4.cmml" xref="S4.F6.9.m4.4.4">80</cn><cn type="integer" id="S4.F6.9.m4.5.5.cmml" xref="S4.F6.9.m4.5.5">120</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.9.m4.5d">[4,16,30,80,120]</annotation></semantics></math>, and <math id="S4.F6.10.m5.5" class="ltx_Math" alttext="[50,50,50,50,50]" display="inline"><semantics id="S4.F6.10.m5.5b"><mrow id="S4.F6.10.m5.5.6.2" xref="S4.F6.10.m5.5.6.1.cmml"><mo stretchy="false" id="S4.F6.10.m5.5.6.2.1" xref="S4.F6.10.m5.5.6.1.cmml">[</mo><mn id="S4.F6.10.m5.1.1" xref="S4.F6.10.m5.1.1.cmml">50</mn><mo id="S4.F6.10.m5.5.6.2.2" xref="S4.F6.10.m5.5.6.1.cmml">,</mo><mn id="S4.F6.10.m5.2.2" xref="S4.F6.10.m5.2.2.cmml">50</mn><mo id="S4.F6.10.m5.5.6.2.3" xref="S4.F6.10.m5.5.6.1.cmml">,</mo><mn id="S4.F6.10.m5.3.3" xref="S4.F6.10.m5.3.3.cmml">50</mn><mo id="S4.F6.10.m5.5.6.2.4" xref="S4.F6.10.m5.5.6.1.cmml">,</mo><mn id="S4.F6.10.m5.4.4" xref="S4.F6.10.m5.4.4.cmml">50</mn><mo id="S4.F6.10.m5.5.6.2.5" xref="S4.F6.10.m5.5.6.1.cmml">,</mo><mn id="S4.F6.10.m5.5.5" xref="S4.F6.10.m5.5.5.cmml">50</mn><mo stretchy="false" id="S4.F6.10.m5.5.6.2.6" xref="S4.F6.10.m5.5.6.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.10.m5.5c"><list id="S4.F6.10.m5.5.6.1.cmml" xref="S4.F6.10.m5.5.6.2"><cn type="integer" id="S4.F6.10.m5.1.1.cmml" xref="S4.F6.10.m5.1.1">50</cn><cn type="integer" id="S4.F6.10.m5.2.2.cmml" xref="S4.F6.10.m5.2.2">50</cn><cn type="integer" id="S4.F6.10.m5.3.3.cmml" xref="S4.F6.10.m5.3.3">50</cn><cn type="integer" id="S4.F6.10.m5.4.4.cmml" xref="S4.F6.10.m5.4.4">50</cn><cn type="integer" id="S4.F6.10.m5.5.5.cmml" xref="S4.F6.10.m5.5.5">50</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.10.m5.5d">[50,50,50,50,50]</annotation></semantics></math>, respectively. w/ IM and w/o IM indicate whether identity mixup (IM) is used during training.</figcaption>
</figure>
<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.2" class="ltx_p"><span id="S4.SS3.p1.2.1" class="ltx_text ltx_font_bold">Experimental Setup.</span>
To explore the long-tailed problem, we construct multiple synthetic datasets with the purpose that each dataset has the same number of identities (<math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="2K" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mrow id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mn id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.SS3.p1.1.m1.1.1.1" xref="S4.SS3.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><times id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1.1"></times><cn type="integer" id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">2</cn><ci id="S4.SS3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3">ğ¾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">2K</annotation></semantics></math>) and total images (<math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="100K" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mrow id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml"><mn id="S4.SS3.p1.2.m2.1.1.2" xref="S4.SS3.p1.2.m2.1.1.2.cmml">100</mn><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1" xref="S4.SS3.p1.2.m2.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p1.2.m2.1.1.3" xref="S4.SS3.p1.2.m2.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><apply id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1"><times id="S4.SS3.p1.2.m2.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1.1"></times><cn type="integer" id="S4.SS3.p1.2.m2.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2">100</cn><ci id="S4.SS3.p1.2.m2.1.1.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3">ğ¾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">100K</annotation></semantics></math>) but different degrees of unbalance. Face images are generated using the equation:</p>
<table id="S4.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E4.m1.37" class="ltx_Math" alttext="\begin{split}N&amp;=[N_{1},N_{2},N_{3},N_{4},N_{5}],\\
ID&amp;=[400,400,400,400,400],\end{split}" display="block"><semantics id="S4.E4.m1.37a"><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt" id="S4.E4.m1.37.37.3"><mtr id="S4.E4.m1.37.37.3a"><mtd class="ltx_align_right" columnalign="right" id="S4.E4.m1.37.37.3b"><mi id="S4.E4.m1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.cmml">N</mi></mtd><mtd class="ltx_align_left" columnalign="left" id="S4.E4.m1.37.37.3c"><mrow id="S4.E4.m1.36.36.2.35.20.19.19"><mrow id="S4.E4.m1.36.36.2.35.20.19.19.1"><mi id="S4.E4.m1.36.36.2.35.20.19.19.1.6"></mi><mo id="S4.E4.m1.2.2.2.2.1.1" xref="S4.E4.m1.2.2.2.2.1.1.cmml">=</mo><mrow id="S4.E4.m1.36.36.2.35.20.19.19.1.5.5"><mo stretchy="false" id="S4.E4.m1.3.3.3.3.2.2">[</mo><msub id="S4.E4.m1.36.36.2.35.20.19.19.1.1.1.1"><mi id="S4.E4.m1.4.4.4.4.3.3" xref="S4.E4.m1.4.4.4.4.3.3.cmml">N</mi><mn id="S4.E4.m1.5.5.5.5.4.4.1" xref="S4.E4.m1.5.5.5.5.4.4.1.cmml">1</mn></msub><mo id="S4.E4.m1.6.6.6.6.5.5">,</mo><msub id="S4.E4.m1.36.36.2.35.20.19.19.1.2.2.2"><mi id="S4.E4.m1.7.7.7.7.6.6" xref="S4.E4.m1.7.7.7.7.6.6.cmml">N</mi><mn id="S4.E4.m1.8.8.8.8.7.7.1" xref="S4.E4.m1.8.8.8.8.7.7.1.cmml">2</mn></msub><mo id="S4.E4.m1.9.9.9.9.8.8">,</mo><msub id="S4.E4.m1.36.36.2.35.20.19.19.1.3.3.3"><mi id="S4.E4.m1.10.10.10.10.9.9" xref="S4.E4.m1.10.10.10.10.9.9.cmml">N</mi><mn id="S4.E4.m1.11.11.11.11.10.10.1" xref="S4.E4.m1.11.11.11.11.10.10.1.cmml">3</mn></msub><mo id="S4.E4.m1.12.12.12.12.11.11">,</mo><msub id="S4.E4.m1.36.36.2.35.20.19.19.1.4.4.4"><mi id="S4.E4.m1.13.13.13.13.12.12" xref="S4.E4.m1.13.13.13.13.12.12.cmml">N</mi><mn id="S4.E4.m1.14.14.14.14.13.13.1" xref="S4.E4.m1.14.14.14.14.13.13.1.cmml">4</mn></msub><mo id="S4.E4.m1.15.15.15.15.14.14">,</mo><msub id="S4.E4.m1.36.36.2.35.20.19.19.1.5.5.5"><mi id="S4.E4.m1.16.16.16.16.15.15" xref="S4.E4.m1.16.16.16.16.15.15.cmml">N</mi><mn id="S4.E4.m1.17.17.17.17.16.16.1" xref="S4.E4.m1.17.17.17.17.16.16.1.cmml">5</mn></msub><mo stretchy="false" id="S4.E4.m1.18.18.18.18.17.17">]</mo></mrow></mrow><mo id="S4.E4.m1.19.19.19.19.18.18">,</mo></mrow></mtd></mtr><mtr id="S4.E4.m1.37.37.3d"><mtd class="ltx_align_right" columnalign="right" id="S4.E4.m1.37.37.3e"><mrow id="S4.E4.m1.21.21.21.2.2"><mi id="S4.E4.m1.20.20.20.1.1.1" xref="S4.E4.m1.20.20.20.1.1.1.cmml">I</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.21.21.21.2.2.3">â€‹</mo><mi id="S4.E4.m1.21.21.21.2.2.2" xref="S4.E4.m1.21.21.21.2.2.2.cmml">D</mi></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S4.E4.m1.37.37.3f"><mrow id="S4.E4.m1.37.37.3.36.16.14.14"><mrow id="S4.E4.m1.37.37.3.36.16.14.14.1"><mi id="S4.E4.m1.37.37.3.36.16.14.14.1.1"></mi><mo id="S4.E4.m1.22.22.22.3.1.1" xref="S4.E4.m1.22.22.22.3.1.1.cmml">=</mo><mrow id="S4.E4.m1.37.37.3.36.16.14.14.1.2"><mo stretchy="false" id="S4.E4.m1.23.23.23.4.2.2">[</mo><mn id="S4.E4.m1.24.24.24.5.3.3" xref="S4.E4.m1.24.24.24.5.3.3.cmml">400</mn><mo id="S4.E4.m1.25.25.25.6.4.4">,</mo><mn id="S4.E4.m1.26.26.26.7.5.5" xref="S4.E4.m1.26.26.26.7.5.5.cmml">400</mn><mo id="S4.E4.m1.27.27.27.8.6.6">,</mo><mn id="S4.E4.m1.28.28.28.9.7.7" xref="S4.E4.m1.28.28.28.9.7.7.cmml">400</mn><mo id="S4.E4.m1.29.29.29.10.8.8">,</mo><mn id="S4.E4.m1.30.30.30.11.9.9" xref="S4.E4.m1.30.30.30.11.9.9.cmml">400</mn><mo id="S4.E4.m1.31.31.31.12.10.10">,</mo><mn id="S4.E4.m1.32.32.32.13.11.11" xref="S4.E4.m1.32.32.32.13.11.11.cmml">400</mn><mo stretchy="false" id="S4.E4.m1.33.33.33.14.12.12">]</mo></mrow></mrow><mo id="S4.E4.m1.34.34.34.15.13.13">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S4.E4.m1.37b"><apply id="S4.E4.m1.35.35.1.1.1.3.cmml"><csymbol cd="ambiguous" id="S4.E4.m1.35.35.1.1.1.3a.cmml">formulae-sequence</csymbol><apply id="S4.E4.m1.35.35.1.1.1.1.1.cmml"><eq id="S4.E4.m1.2.2.2.2.1.1.cmml" xref="S4.E4.m1.2.2.2.2.1.1"></eq><ci id="S4.E4.m1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1">ğ‘</ci><list id="S4.E4.m1.35.35.1.1.1.1.1.5.6.cmml"><apply id="S4.E4.m1.35.35.1.1.1.1.1.1.1.1.cmml"><csymbol cd="ambiguous" id="S4.E4.m1.35.35.1.1.1.1.1.1.1.1.1.cmml">subscript</csymbol><ci id="S4.E4.m1.4.4.4.4.3.3.cmml" xref="S4.E4.m1.4.4.4.4.3.3">ğ‘</ci><cn type="integer" id="S4.E4.m1.5.5.5.5.4.4.1.cmml" xref="S4.E4.m1.5.5.5.5.4.4.1">1</cn></apply><apply id="S4.E4.m1.35.35.1.1.1.1.1.2.2.2.cmml"><csymbol cd="ambiguous" id="S4.E4.m1.35.35.1.1.1.1.1.2.2.2.1.cmml">subscript</csymbol><ci id="S4.E4.m1.7.7.7.7.6.6.cmml" xref="S4.E4.m1.7.7.7.7.6.6">ğ‘</ci><cn type="integer" id="S4.E4.m1.8.8.8.8.7.7.1.cmml" xref="S4.E4.m1.8.8.8.8.7.7.1">2</cn></apply><apply id="S4.E4.m1.35.35.1.1.1.1.1.3.3.3.cmml"><csymbol cd="ambiguous" id="S4.E4.m1.35.35.1.1.1.1.1.3.3.3.1.cmml">subscript</csymbol><ci id="S4.E4.m1.10.10.10.10.9.9.cmml" xref="S4.E4.m1.10.10.10.10.9.9">ğ‘</ci><cn type="integer" id="S4.E4.m1.11.11.11.11.10.10.1.cmml" xref="S4.E4.m1.11.11.11.11.10.10.1">3</cn></apply><apply id="S4.E4.m1.35.35.1.1.1.1.1.4.4.4.cmml"><csymbol cd="ambiguous" id="S4.E4.m1.35.35.1.1.1.1.1.4.4.4.1.cmml">subscript</csymbol><ci id="S4.E4.m1.13.13.13.13.12.12.cmml" xref="S4.E4.m1.13.13.13.13.12.12">ğ‘</ci><cn type="integer" id="S4.E4.m1.14.14.14.14.13.13.1.cmml" xref="S4.E4.m1.14.14.14.14.13.13.1">4</cn></apply><apply id="S4.E4.m1.35.35.1.1.1.1.1.5.5.5.cmml"><csymbol cd="ambiguous" id="S4.E4.m1.35.35.1.1.1.1.1.5.5.5.1.cmml">subscript</csymbol><ci id="S4.E4.m1.16.16.16.16.15.15.cmml" xref="S4.E4.m1.16.16.16.16.15.15">ğ‘</ci><cn type="integer" id="S4.E4.m1.17.17.17.17.16.16.1.cmml" xref="S4.E4.m1.17.17.17.17.16.16.1">5</cn></apply></list></apply><apply id="S4.E4.m1.35.35.1.1.1.2.2.cmml"><eq id="S4.E4.m1.22.22.22.3.1.1.cmml" xref="S4.E4.m1.22.22.22.3.1.1"></eq><apply id="S4.E4.m1.35.35.1.1.1.2.2.2.cmml"><times id="S4.E4.m1.35.35.1.1.1.2.2.2.1.cmml"></times><ci id="S4.E4.m1.20.20.20.1.1.1.cmml" xref="S4.E4.m1.20.20.20.1.1.1">ğ¼</ci><ci id="S4.E4.m1.21.21.21.2.2.2.cmml" xref="S4.E4.m1.21.21.21.2.2.2">ğ·</ci></apply><list id="S4.E4.m1.35.35.1.1.1.2.2.3.cmml"><cn type="integer" id="S4.E4.m1.24.24.24.5.3.3.cmml" xref="S4.E4.m1.24.24.24.5.3.3">400</cn><cn type="integer" id="S4.E4.m1.26.26.26.7.5.5.cmml" xref="S4.E4.m1.26.26.26.7.5.5">400</cn><cn type="integer" id="S4.E4.m1.28.28.28.9.7.7.cmml" xref="S4.E4.m1.28.28.28.9.7.7">400</cn><cn type="integer" id="S4.E4.m1.30.30.30.11.9.9.cmml" xref="S4.E4.m1.30.30.30.11.9.9">400</cn><cn type="integer" id="S4.E4.m1.32.32.32.13.11.11.cmml" xref="S4.E4.m1.32.32.32.13.11.11">400</cn></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.37c">\begin{split}N&amp;=[N_{1},N_{2},N_{3},N_{4},N_{5}],\\
ID&amp;=[400,400,400,400,400],\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S4.SS3.p1.16" class="ltx_p">where <math id="S4.SS3.p1.3.m1.1" class="ltx_Math" alttext="ID" display="inline"><semantics id="S4.SS3.p1.3.m1.1a"><mrow id="S4.SS3.p1.3.m1.1.1" xref="S4.SS3.p1.3.m1.1.1.cmml"><mi id="S4.SS3.p1.3.m1.1.1.2" xref="S4.SS3.p1.3.m1.1.1.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m1.1.1.1" xref="S4.SS3.p1.3.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS3.p1.3.m1.1.1.3" xref="S4.SS3.p1.3.m1.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m1.1b"><apply id="S4.SS3.p1.3.m1.1.1.cmml" xref="S4.SS3.p1.3.m1.1.1"><times id="S4.SS3.p1.3.m1.1.1.1.cmml" xref="S4.SS3.p1.3.m1.1.1.1"></times><ci id="S4.SS3.p1.3.m1.1.1.2.cmml" xref="S4.SS3.p1.3.m1.1.1.2">ğ¼</ci><ci id="S4.SS3.p1.3.m1.1.1.3.cmml" xref="S4.SS3.p1.3.m1.1.1.3">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m1.1c">ID</annotation></semantics></math> indicates the number of identities in each of the five groups, and <math id="S4.SS3.p1.4.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS3.p1.4.m2.1a"><mi id="S4.SS3.p1.4.m2.1.1" xref="S4.SS3.p1.4.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m2.1b"><ci id="S4.SS3.p1.4.m2.1.1.cmml" xref="S4.SS3.p1.4.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m2.1c">N</annotation></semantics></math> means the number of samples of the five groups. For example, if <math id="S4.SS3.p1.5.m3.5" class="ltx_Math" alttext="N=[30,40,50,60,70]" display="inline"><semantics id="S4.SS3.p1.5.m3.5a"><mrow id="S4.SS3.p1.5.m3.5.6" xref="S4.SS3.p1.5.m3.5.6.cmml"><mi id="S4.SS3.p1.5.m3.5.6.2" xref="S4.SS3.p1.5.m3.5.6.2.cmml">N</mi><mo id="S4.SS3.p1.5.m3.5.6.1" xref="S4.SS3.p1.5.m3.5.6.1.cmml">=</mo><mrow id="S4.SS3.p1.5.m3.5.6.3.2" xref="S4.SS3.p1.5.m3.5.6.3.1.cmml"><mo stretchy="false" id="S4.SS3.p1.5.m3.5.6.3.2.1" xref="S4.SS3.p1.5.m3.5.6.3.1.cmml">[</mo><mn id="S4.SS3.p1.5.m3.1.1" xref="S4.SS3.p1.5.m3.1.1.cmml">30</mn><mo id="S4.SS3.p1.5.m3.5.6.3.2.2" xref="S4.SS3.p1.5.m3.5.6.3.1.cmml">,</mo><mn id="S4.SS3.p1.5.m3.2.2" xref="S4.SS3.p1.5.m3.2.2.cmml">40</mn><mo id="S4.SS3.p1.5.m3.5.6.3.2.3" xref="S4.SS3.p1.5.m3.5.6.3.1.cmml">,</mo><mn id="S4.SS3.p1.5.m3.3.3" xref="S4.SS3.p1.5.m3.3.3.cmml">50</mn><mo id="S4.SS3.p1.5.m3.5.6.3.2.4" xref="S4.SS3.p1.5.m3.5.6.3.1.cmml">,</mo><mn id="S4.SS3.p1.5.m3.4.4" xref="S4.SS3.p1.5.m3.4.4.cmml">60</mn><mo id="S4.SS3.p1.5.m3.5.6.3.2.5" xref="S4.SS3.p1.5.m3.5.6.3.1.cmml">,</mo><mn id="S4.SS3.p1.5.m3.5.5" xref="S4.SS3.p1.5.m3.5.5.cmml">70</mn><mo stretchy="false" id="S4.SS3.p1.5.m3.5.6.3.2.6" xref="S4.SS3.p1.5.m3.5.6.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.5.m3.5b"><apply id="S4.SS3.p1.5.m3.5.6.cmml" xref="S4.SS3.p1.5.m3.5.6"><eq id="S4.SS3.p1.5.m3.5.6.1.cmml" xref="S4.SS3.p1.5.m3.5.6.1"></eq><ci id="S4.SS3.p1.5.m3.5.6.2.cmml" xref="S4.SS3.p1.5.m3.5.6.2">ğ‘</ci><list id="S4.SS3.p1.5.m3.5.6.3.1.cmml" xref="S4.SS3.p1.5.m3.5.6.3.2"><cn type="integer" id="S4.SS3.p1.5.m3.1.1.cmml" xref="S4.SS3.p1.5.m3.1.1">30</cn><cn type="integer" id="S4.SS3.p1.5.m3.2.2.cmml" xref="S4.SS3.p1.5.m3.2.2">40</cn><cn type="integer" id="S4.SS3.p1.5.m3.3.3.cmml" xref="S4.SS3.p1.5.m3.3.3">50</cn><cn type="integer" id="S4.SS3.p1.5.m3.4.4.cmml" xref="S4.SS3.p1.5.m3.4.4">60</cn><cn type="integer" id="S4.SS3.p1.5.m3.5.5.cmml" xref="S4.SS3.p1.5.m3.5.5">70</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.5.m3.5c">N=[30,40,50,60,70]</annotation></semantics></math>, the corresponding synthetic dataset has <math id="S4.SS3.p1.6.m4.1" class="ltx_Math" alttext="400" display="inline"><semantics id="S4.SS3.p1.6.m4.1a"><mn id="S4.SS3.p1.6.m4.1.1" xref="S4.SS3.p1.6.m4.1.1.cmml">400</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.6.m4.1b"><cn type="integer" id="S4.SS3.p1.6.m4.1.1.cmml" xref="S4.SS3.p1.6.m4.1.1">400</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.6.m4.1c">400</annotation></semantics></math> identities with <math id="S4.SS3.p1.7.m5.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S4.SS3.p1.7.m5.1a"><mn id="S4.SS3.p1.7.m5.1.1" xref="S4.SS3.p1.7.m5.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.7.m5.1b"><cn type="integer" id="S4.SS3.p1.7.m5.1.1.cmml" xref="S4.SS3.p1.7.m5.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.7.m5.1c">30</annotation></semantics></math> samples per identity, and the rest <math id="S4.SS3.p1.8.m6.1" class="ltx_Math" alttext="1600" display="inline"><semantics id="S4.SS3.p1.8.m6.1a"><mn id="S4.SS3.p1.8.m6.1.1" xref="S4.SS3.p1.8.m6.1.1.cmml">1600</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.8.m6.1b"><cn type="integer" id="S4.SS3.p1.8.m6.1.1.cmml" xref="S4.SS3.p1.8.m6.1.1">1600</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.8.m6.1c">1600</annotation></semantics></math> identities with <math id="S4.SS3.p1.9.m7.4" class="ltx_Math" alttext="40,50,60,70" display="inline"><semantics id="S4.SS3.p1.9.m7.4a"><mrow id="S4.SS3.p1.9.m7.4.5.2" xref="S4.SS3.p1.9.m7.4.5.1.cmml"><mn id="S4.SS3.p1.9.m7.1.1" xref="S4.SS3.p1.9.m7.1.1.cmml">40</mn><mo id="S4.SS3.p1.9.m7.4.5.2.1" xref="S4.SS3.p1.9.m7.4.5.1.cmml">,</mo><mn id="S4.SS3.p1.9.m7.2.2" xref="S4.SS3.p1.9.m7.2.2.cmml">50</mn><mo id="S4.SS3.p1.9.m7.4.5.2.2" xref="S4.SS3.p1.9.m7.4.5.1.cmml">,</mo><mn id="S4.SS3.p1.9.m7.3.3" xref="S4.SS3.p1.9.m7.3.3.cmml">60</mn><mo id="S4.SS3.p1.9.m7.4.5.2.3" xref="S4.SS3.p1.9.m7.4.5.1.cmml">,</mo><mn id="S4.SS3.p1.9.m7.4.4" xref="S4.SS3.p1.9.m7.4.4.cmml">70</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.9.m7.4b"><list id="S4.SS3.p1.9.m7.4.5.1.cmml" xref="S4.SS3.p1.9.m7.4.5.2"><cn type="integer" id="S4.SS3.p1.9.m7.1.1.cmml" xref="S4.SS3.p1.9.m7.1.1">40</cn><cn type="integer" id="S4.SS3.p1.9.m7.2.2.cmml" xref="S4.SS3.p1.9.m7.2.2">50</cn><cn type="integer" id="S4.SS3.p1.9.m7.3.3.cmml" xref="S4.SS3.p1.9.m7.3.3">60</cn><cn type="integer" id="S4.SS3.p1.9.m7.4.4.cmml" xref="S4.SS3.p1.9.m7.4.4">70</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.9.m7.4c">40,50,60,70</annotation></semantics></math> samples per identity, respectively. We construct three different synthetic datasets by assigning <math id="S4.SS3.p1.10.m8.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS3.p1.10.m8.1a"><mi id="S4.SS3.p1.10.m8.1.1" xref="S4.SS3.p1.10.m8.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.10.m8.1b"><ci id="S4.SS3.p1.10.m8.1.1.cmml" xref="S4.SS3.p1.10.m8.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.10.m8.1c">N</annotation></semantics></math> to be <math id="S4.SS3.p1.11.m9.5" class="ltx_Math" alttext="[2,2,6,40,200]" display="inline"><semantics id="S4.SS3.p1.11.m9.5a"><mrow id="S4.SS3.p1.11.m9.5.6.2" xref="S4.SS3.p1.11.m9.5.6.1.cmml"><mo stretchy="false" id="S4.SS3.p1.11.m9.5.6.2.1" xref="S4.SS3.p1.11.m9.5.6.1.cmml">[</mo><mn id="S4.SS3.p1.11.m9.1.1" xref="S4.SS3.p1.11.m9.1.1.cmml">2</mn><mo id="S4.SS3.p1.11.m9.5.6.2.2" xref="S4.SS3.p1.11.m9.5.6.1.cmml">,</mo><mn id="S4.SS3.p1.11.m9.2.2" xref="S4.SS3.p1.11.m9.2.2.cmml">2</mn><mo id="S4.SS3.p1.11.m9.5.6.2.3" xref="S4.SS3.p1.11.m9.5.6.1.cmml">,</mo><mn id="S4.SS3.p1.11.m9.3.3" xref="S4.SS3.p1.11.m9.3.3.cmml">6</mn><mo id="S4.SS3.p1.11.m9.5.6.2.4" xref="S4.SS3.p1.11.m9.5.6.1.cmml">,</mo><mn id="S4.SS3.p1.11.m9.4.4" xref="S4.SS3.p1.11.m9.4.4.cmml">40</mn><mo id="S4.SS3.p1.11.m9.5.6.2.5" xref="S4.SS3.p1.11.m9.5.6.1.cmml">,</mo><mn id="S4.SS3.p1.11.m9.5.5" xref="S4.SS3.p1.11.m9.5.5.cmml">200</mn><mo stretchy="false" id="S4.SS3.p1.11.m9.5.6.2.6" xref="S4.SS3.p1.11.m9.5.6.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.11.m9.5b"><list id="S4.SS3.p1.11.m9.5.6.1.cmml" xref="S4.SS3.p1.11.m9.5.6.2"><cn type="integer" id="S4.SS3.p1.11.m9.1.1.cmml" xref="S4.SS3.p1.11.m9.1.1">2</cn><cn type="integer" id="S4.SS3.p1.11.m9.2.2.cmml" xref="S4.SS3.p1.11.m9.2.2">2</cn><cn type="integer" id="S4.SS3.p1.11.m9.3.3.cmml" xref="S4.SS3.p1.11.m9.3.3">6</cn><cn type="integer" id="S4.SS3.p1.11.m9.4.4.cmml" xref="S4.SS3.p1.11.m9.4.4">40</cn><cn type="integer" id="S4.SS3.p1.11.m9.5.5.cmml" xref="S4.SS3.p1.11.m9.5.5">200</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.11.m9.5c">[2,2,6,40,200]</annotation></semantics></math>, <math id="S4.SS3.p1.12.m10.5" class="ltx_Math" alttext="[4,16,30,80,120]" display="inline"><semantics id="S4.SS3.p1.12.m10.5a"><mrow id="S4.SS3.p1.12.m10.5.6.2" xref="S4.SS3.p1.12.m10.5.6.1.cmml"><mo stretchy="false" id="S4.SS3.p1.12.m10.5.6.2.1" xref="S4.SS3.p1.12.m10.5.6.1.cmml">[</mo><mn id="S4.SS3.p1.12.m10.1.1" xref="S4.SS3.p1.12.m10.1.1.cmml">4</mn><mo id="S4.SS3.p1.12.m10.5.6.2.2" xref="S4.SS3.p1.12.m10.5.6.1.cmml">,</mo><mn id="S4.SS3.p1.12.m10.2.2" xref="S4.SS3.p1.12.m10.2.2.cmml">16</mn><mo id="S4.SS3.p1.12.m10.5.6.2.3" xref="S4.SS3.p1.12.m10.5.6.1.cmml">,</mo><mn id="S4.SS3.p1.12.m10.3.3" xref="S4.SS3.p1.12.m10.3.3.cmml">30</mn><mo id="S4.SS3.p1.12.m10.5.6.2.4" xref="S4.SS3.p1.12.m10.5.6.1.cmml">,</mo><mn id="S4.SS3.p1.12.m10.4.4" xref="S4.SS3.p1.12.m10.4.4.cmml">80</mn><mo id="S4.SS3.p1.12.m10.5.6.2.5" xref="S4.SS3.p1.12.m10.5.6.1.cmml">,</mo><mn id="S4.SS3.p1.12.m10.5.5" xref="S4.SS3.p1.12.m10.5.5.cmml">120</mn><mo stretchy="false" id="S4.SS3.p1.12.m10.5.6.2.6" xref="S4.SS3.p1.12.m10.5.6.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.12.m10.5b"><list id="S4.SS3.p1.12.m10.5.6.1.cmml" xref="S4.SS3.p1.12.m10.5.6.2"><cn type="integer" id="S4.SS3.p1.12.m10.1.1.cmml" xref="S4.SS3.p1.12.m10.1.1">4</cn><cn type="integer" id="S4.SS3.p1.12.m10.2.2.cmml" xref="S4.SS3.p1.12.m10.2.2">16</cn><cn type="integer" id="S4.SS3.p1.12.m10.3.3.cmml" xref="S4.SS3.p1.12.m10.3.3">30</cn><cn type="integer" id="S4.SS3.p1.12.m10.4.4.cmml" xref="S4.SS3.p1.12.m10.4.4">80</cn><cn type="integer" id="S4.SS3.p1.12.m10.5.5.cmml" xref="S4.SS3.p1.12.m10.5.5">120</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.12.m10.5c">[4,16,30,80,120]</annotation></semantics></math> and <math id="S4.SS3.p1.13.m11.5" class="ltx_Math" alttext="[50,50,50,50,50]" display="inline"><semantics id="S4.SS3.p1.13.m11.5a"><mrow id="S4.SS3.p1.13.m11.5.6.2" xref="S4.SS3.p1.13.m11.5.6.1.cmml"><mo stretchy="false" id="S4.SS3.p1.13.m11.5.6.2.1" xref="S4.SS3.p1.13.m11.5.6.1.cmml">[</mo><mn id="S4.SS3.p1.13.m11.1.1" xref="S4.SS3.p1.13.m11.1.1.cmml">50</mn><mo id="S4.SS3.p1.13.m11.5.6.2.2" xref="S4.SS3.p1.13.m11.5.6.1.cmml">,</mo><mn id="S4.SS3.p1.13.m11.2.2" xref="S4.SS3.p1.13.m11.2.2.cmml">50</mn><mo id="S4.SS3.p1.13.m11.5.6.2.3" xref="S4.SS3.p1.13.m11.5.6.1.cmml">,</mo><mn id="S4.SS3.p1.13.m11.3.3" xref="S4.SS3.p1.13.m11.3.3.cmml">50</mn><mo id="S4.SS3.p1.13.m11.5.6.2.4" xref="S4.SS3.p1.13.m11.5.6.1.cmml">,</mo><mn id="S4.SS3.p1.13.m11.4.4" xref="S4.SS3.p1.13.m11.4.4.cmml">50</mn><mo id="S4.SS3.p1.13.m11.5.6.2.5" xref="S4.SS3.p1.13.m11.5.6.1.cmml">,</mo><mn id="S4.SS3.p1.13.m11.5.5" xref="S4.SS3.p1.13.m11.5.5.cmml">50</mn><mo stretchy="false" id="S4.SS3.p1.13.m11.5.6.2.6" xref="S4.SS3.p1.13.m11.5.6.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.13.m11.5b"><list id="S4.SS3.p1.13.m11.5.6.1.cmml" xref="S4.SS3.p1.13.m11.5.6.2"><cn type="integer" id="S4.SS3.p1.13.m11.1.1.cmml" xref="S4.SS3.p1.13.m11.1.1">50</cn><cn type="integer" id="S4.SS3.p1.13.m11.2.2.cmml" xref="S4.SS3.p1.13.m11.2.2">50</cn><cn type="integer" id="S4.SS3.p1.13.m11.3.3.cmml" xref="S4.SS3.p1.13.m11.3.3">50</cn><cn type="integer" id="S4.SS3.p1.13.m11.4.4.cmml" xref="S4.SS3.p1.13.m11.4.4">50</cn><cn type="integer" id="S4.SS3.p1.13.m11.5.5.cmml" xref="S4.SS3.p1.13.m11.5.5">50</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.13.m11.5c">[50,50,50,50,50]</annotation></semantics></math>, which are denoted as â€œ2K_UB1â€, â€œ2K_UB2â€ and â€œ2K_50â€, respectively. The detailed construction process can be found in Sec.Â <a href="#S4.SS1" title="4.1 Datasets â€£ 4 Experiments â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>. Note that all the three datasets have average <math id="S4.SS3.p1.14.m12.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S4.SS3.p1.14.m12.1a"><mn id="S4.SS3.p1.14.m12.1.1" xref="S4.SS3.p1.14.m12.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.14.m12.1b"><cn type="integer" id="S4.SS3.p1.14.m12.1.1.cmml" xref="S4.SS3.p1.14.m12.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.14.m12.1c">50</annotation></semantics></math> samples per identity, while the first two have unbalanced distributions with the standard deviations <math id="S4.SS3.p1.15.m13.1" class="ltx_Math" alttext="76.35" display="inline"><semantics id="S4.SS3.p1.15.m13.1a"><mn id="S4.SS3.p1.15.m13.1.1" xref="S4.SS3.p1.15.m13.1.1.cmml">76.35</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.15.m13.1b"><cn type="float" id="S4.SS3.p1.15.m13.1.1.cmml" xref="S4.SS3.p1.15.m13.1.1">76.35</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.15.m13.1c">76.35</annotation></semantics></math> and <math id="S4.SS3.p1.16.m14.1" class="ltx_Math" alttext="43.52" display="inline"><semantics id="S4.SS3.p1.16.m14.1a"><mn id="S4.SS3.p1.16.m14.1.1" xref="S4.SS3.p1.16.m14.1.1.cmml">43.52</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.16.m14.1b"><cn type="float" id="S4.SS3.p1.16.m14.1.1.cmml" xref="S4.SS3.p1.16.m14.1.1">43.52</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.16.m14.1c">43.52</annotation></semantics></math>, and the last one is the perfectly balanced dataset.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.2" class="ltx_p"><span id="S4.SS3.p2.2.1" class="ltx_text ltx_font_bold">Empirical Analysis.</span>
We train face recognition models on the above three different synthetic datasets and the experimental results are illustrated in FigureÂ <a href="#S4.F6" title="Figure 6 â€£ 4.3 Long-tailed Face Recognition â€£ 4 Experiments â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. We see that the model trained on the â€œ2K_UB1â€ achieves the worst performance (<math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="83.80\%" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mrow id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mn id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml">83.80</mn><mo id="S4.SS3.p2.1.m1.1.1.1" xref="S4.SS3.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS3.p2.1.m1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2">83.80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">83.80\%</annotation></semantics></math>), suggesting that the long-tailed problem or the unbalanced distribution leads to the degradation of the model performance. Comparing with the models trained on â€œ2K_UB1â€ and â€œ2K_UB2â€, we discover that decreasing the degree of unbalance leads to the improvement on the performance. Finally, when the model is trained on â€œ2K_50â€, <em id="S4.SS3.p2.2.2" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS3.p2.2.3" class="ltx_text"></span>, the perfectly balanced dataset, the accuracy is significantly improved to <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="86.18\%" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mrow id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml"><mn id="S4.SS3.p2.2.m2.1.1.2" xref="S4.SS3.p2.2.m2.1.1.2.cmml">86.18</mn><mo id="S4.SS3.p2.2.m2.1.1.1" xref="S4.SS3.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><apply id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.SS3.p2.2.m2.1.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p2.2.m2.1.1.2.cmml" xref="S4.SS3.p2.2.m2.1.1.2">86.18</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">86.18\%</annotation></semantics></math>. Therefore, with balanced synthetic data, the long-tailed problem can be intrinsically avoided. Besides, introducing the identity mixup for training can consistently and significantly improve the performance over all the settings.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Effectiveness of â€œDepthâ€ and â€œWidthâ€</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.8" class="ltx_p"><span id="S4.SS4.p1.8.1" class="ltx_text ltx_font_bold">Experimental Setup.</span>
We synthesize multiple face datasets with different width (the number of identities) and depth (the number of samples per identity). Let â€œ<math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="N\_S" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><mrow id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml"><mi id="S4.SS4.p1.1.m1.1.1.2" xref="S4.SS4.p1.1.m1.1.1.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.1.m1.1.1.1" xref="S4.SS4.p1.1.m1.1.1.1.cmml">â€‹</mo><mi mathvariant="normal" id="S4.SS4.p1.1.m1.1.1.3" xref="S4.SS4.p1.1.m1.1.1.3.cmml">_</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.1.m1.1.1.1a" xref="S4.SS4.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS4.p1.1.m1.1.1.4" xref="S4.SS4.p1.1.m1.1.1.4.cmml">S</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><apply id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1"><times id="S4.SS4.p1.1.m1.1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1.1"></times><ci id="S4.SS4.p1.1.m1.1.1.2.cmml" xref="S4.SS4.p1.1.m1.1.1.2">ğ‘</ci><ci id="S4.SS4.p1.1.m1.1.1.3.cmml" xref="S4.SS4.p1.1.m1.1.1.3">_</ci><ci id="S4.SS4.p1.1.m1.1.1.4.cmml" xref="S4.SS4.p1.1.m1.1.1.4">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">N\_S</annotation></semantics></math>â€ denote the synthetic dataset containing <math id="S4.SS4.p1.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS4.p1.2.m2.1a"><mi id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><ci id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">N</annotation></semantics></math> identities with <math id="S4.SS4.p1.3.m3.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.SS4.p1.3.m3.1a"><mi id="S4.SS4.p1.3.m3.1.1" xref="S4.SS4.p1.3.m3.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.3.m3.1b"><ci id="S4.SS4.p1.3.m3.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.3.m3.1c">S</annotation></semantics></math> samples per identity, <em id="S4.SS4.p1.8.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S4.SS4.p1.8.3" class="ltx_text"></span>, <math id="S4.SS4.p1.4.m4.1" class="ltx_Math" alttext="1K\_50" display="inline"><semantics id="S4.SS4.p1.4.m4.1a"><mrow id="S4.SS4.p1.4.m4.1.1" xref="S4.SS4.p1.4.m4.1.1.cmml"><mn id="S4.SS4.p1.4.m4.1.1.2" xref="S4.SS4.p1.4.m4.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS4.p1.4.m4.1.1.1" xref="S4.SS4.p1.4.m4.1.1.1.cmml">â€‹</mo><mi id="S4.SS4.p1.4.m4.1.1.3" xref="S4.SS4.p1.4.m4.1.1.3.cmml">K</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.4.m4.1.1.1a" xref="S4.SS4.p1.4.m4.1.1.1.cmml">â€‹</mo><mi mathvariant="normal" id="S4.SS4.p1.4.m4.1.1.4" xref="S4.SS4.p1.4.m4.1.1.4.cmml">_</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.4.m4.1.1.1b" xref="S4.SS4.p1.4.m4.1.1.1.cmml">â€‹</mo><mn id="S4.SS4.p1.4.m4.1.1.5" xref="S4.SS4.p1.4.m4.1.1.5.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.4.m4.1b"><apply id="S4.SS4.p1.4.m4.1.1.cmml" xref="S4.SS4.p1.4.m4.1.1"><times id="S4.SS4.p1.4.m4.1.1.1.cmml" xref="S4.SS4.p1.4.m4.1.1.1"></times><cn type="integer" id="S4.SS4.p1.4.m4.1.1.2.cmml" xref="S4.SS4.p1.4.m4.1.1.2">1</cn><ci id="S4.SS4.p1.4.m4.1.1.3.cmml" xref="S4.SS4.p1.4.m4.1.1.3">ğ¾</ci><ci id="S4.SS4.p1.4.m4.1.1.4.cmml" xref="S4.SS4.p1.4.m4.1.1.4">_</ci><cn type="integer" id="S4.SS4.p1.4.m4.1.1.5.cmml" xref="S4.SS4.p1.4.m4.1.1.5">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.4.m4.1c">1K\_50</annotation></semantics></math> indicates the dataset having <math id="S4.SS4.p1.5.m5.1" class="ltx_Math" alttext="1K" display="inline"><semantics id="S4.SS4.p1.5.m5.1a"><mrow id="S4.SS4.p1.5.m5.1.1" xref="S4.SS4.p1.5.m5.1.1.cmml"><mn id="S4.SS4.p1.5.m5.1.1.2" xref="S4.SS4.p1.5.m5.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS4.p1.5.m5.1.1.1" xref="S4.SS4.p1.5.m5.1.1.1.cmml">â€‹</mo><mi id="S4.SS4.p1.5.m5.1.1.3" xref="S4.SS4.p1.5.m5.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.5.m5.1b"><apply id="S4.SS4.p1.5.m5.1.1.cmml" xref="S4.SS4.p1.5.m5.1.1"><times id="S4.SS4.p1.5.m5.1.1.1.cmml" xref="S4.SS4.p1.5.m5.1.1.1"></times><cn type="integer" id="S4.SS4.p1.5.m5.1.1.2.cmml" xref="S4.SS4.p1.5.m5.1.1.2">1</cn><ci id="S4.SS4.p1.5.m5.1.1.3.cmml" xref="S4.SS4.p1.5.m5.1.1.3">ğ¾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.5.m5.1c">1K</annotation></semantics></math> different identities and <math id="S4.SS4.p1.6.m6.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S4.SS4.p1.6.m6.1a"><mn id="S4.SS4.p1.6.m6.1.1" xref="S4.SS4.p1.6.m6.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.6.m6.1b"><cn type="integer" id="S4.SS4.p1.6.m6.1.1.cmml" xref="S4.SS4.p1.6.m6.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.6.m6.1c">50</annotation></semantics></math> samples per identity. Obviously, <math id="S4.SS4.p1.7.m7.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS4.p1.7.m7.1a"><mi id="S4.SS4.p1.7.m7.1.1" xref="S4.SS4.p1.7.m7.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.7.m7.1b"><ci id="S4.SS4.p1.7.m7.1.1.cmml" xref="S4.SS4.p1.7.m7.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.7.m7.1c">N</annotation></semantics></math> and <math id="S4.SS4.p1.8.m8.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.SS4.p1.8.m8.1a"><mi id="S4.SS4.p1.8.m8.1.1" xref="S4.SS4.p1.8.m8.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.8.m8.1b"><ci id="S4.SS4.p1.8.m8.1.1.cmml" xref="S4.SS4.p1.8.m8.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.8.m8.1c">S</annotation></semantics></math> represent the datasetâ€™s width and depth. The details of dataset construction can be found in Sec.Â <a href="#S4.SS1" title="4.1 Datasets â€£ 4 Experiments â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.18" class="ltx_p"><span id="S4.SS4.p2.18.1" class="ltx_text ltx_font_bold">Empirical Analysis.</span>
We train the same face recognition model on these synthetic datasets, and the experimental results (both w/wo identity mixup) are shown in TableÂ <a href="#S4.T3" title="Table 3 â€£ 4.4 Effectiveness of â€œDepthâ€ and â€œWidthâ€ â€£ 4 Experiments â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Firstly, we analyze the influence of the width of the dataset by comparing the results of <math id="S4.SS4.p2.1.m1.8" class="ltx_Math" alttext="(a),~{}(b),~{}(c),~{}(i)" display="inline"><semantics id="S4.SS4.p2.1.m1.8a"><mrow id="S4.SS4.p2.1.m1.8.8.4" xref="S4.SS4.p2.1.m1.8.8.5.cmml"><mrow id="S4.SS4.p2.1.m1.5.5.1.1.2" xref="S4.SS4.p2.1.m1.8.8.5.cmml"><mo stretchy="false" id="S4.SS4.p2.1.m1.5.5.1.1.2.1" xref="S4.SS4.p2.1.m1.8.8.5.cmml">(</mo><mi id="S4.SS4.p2.1.m1.1.1" xref="S4.SS4.p2.1.m1.1.1.cmml">a</mi><mo stretchy="false" id="S4.SS4.p2.1.m1.5.5.1.1.2.2" xref="S4.SS4.p2.1.m1.8.8.5.cmml">)</mo></mrow><mo rspace="0.497em" id="S4.SS4.p2.1.m1.8.8.4.5" xref="S4.SS4.p2.1.m1.8.8.5.cmml">,</mo><mrow id="S4.SS4.p2.1.m1.6.6.2.2.2" xref="S4.SS4.p2.1.m1.8.8.5.cmml"><mo stretchy="false" id="S4.SS4.p2.1.m1.6.6.2.2.2.1" xref="S4.SS4.p2.1.m1.8.8.5.cmml">(</mo><mi id="S4.SS4.p2.1.m1.2.2" xref="S4.SS4.p2.1.m1.2.2.cmml">b</mi><mo stretchy="false" id="S4.SS4.p2.1.m1.6.6.2.2.2.2" xref="S4.SS4.p2.1.m1.8.8.5.cmml">)</mo></mrow><mo rspace="0.497em" id="S4.SS4.p2.1.m1.8.8.4.6" xref="S4.SS4.p2.1.m1.8.8.5.cmml">,</mo><mrow id="S4.SS4.p2.1.m1.7.7.3.3.2" xref="S4.SS4.p2.1.m1.8.8.5.cmml"><mo stretchy="false" id="S4.SS4.p2.1.m1.7.7.3.3.2.1" xref="S4.SS4.p2.1.m1.8.8.5.cmml">(</mo><mi id="S4.SS4.p2.1.m1.3.3" xref="S4.SS4.p2.1.m1.3.3.cmml">c</mi><mo stretchy="false" id="S4.SS4.p2.1.m1.7.7.3.3.2.2" xref="S4.SS4.p2.1.m1.8.8.5.cmml">)</mo></mrow><mo rspace="0.497em" id="S4.SS4.p2.1.m1.8.8.4.7" xref="S4.SS4.p2.1.m1.8.8.5.cmml">,</mo><mrow id="S4.SS4.p2.1.m1.8.8.4.4.2" xref="S4.SS4.p2.1.m1.8.8.5.cmml"><mo stretchy="false" id="S4.SS4.p2.1.m1.8.8.4.4.2.1" xref="S4.SS4.p2.1.m1.8.8.5.cmml">(</mo><mi id="S4.SS4.p2.1.m1.4.4" xref="S4.SS4.p2.1.m1.4.4.cmml">i</mi><mo stretchy="false" id="S4.SS4.p2.1.m1.8.8.4.4.2.2" xref="S4.SS4.p2.1.m1.8.8.5.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.1.m1.8b"><list id="S4.SS4.p2.1.m1.8.8.5.cmml" xref="S4.SS4.p2.1.m1.8.8.4"><ci id="S4.SS4.p2.1.m1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1">ğ‘</ci><ci id="S4.SS4.p2.1.m1.2.2.cmml" xref="S4.SS4.p2.1.m1.2.2">ğ‘</ci><ci id="S4.SS4.p2.1.m1.3.3.cmml" xref="S4.SS4.p2.1.m1.3.3">ğ‘</ci><ci id="S4.SS4.p2.1.m1.4.4.cmml" xref="S4.SS4.p2.1.m1.4.4">ğ‘–</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.1.m1.8c">(a),~{}(b),~{}(c),~{}(i)</annotation></semantics></math>. From <math id="S4.SS4.p2.2.m2.1" class="ltx_Math" alttext="(a)" display="inline"><semantics id="S4.SS4.p2.2.m2.1a"><mrow id="S4.SS4.p2.2.m2.1.2.2"><mo stretchy="false" id="S4.SS4.p2.2.m2.1.2.2.1">(</mo><mi id="S4.SS4.p2.2.m2.1.1" xref="S4.SS4.p2.2.m2.1.1.cmml">a</mi><mo stretchy="false" id="S4.SS4.p2.2.m2.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.2.m2.1b"><ci id="S4.SS4.p2.2.m2.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.2.m2.1c">(a)</annotation></semantics></math> to <math id="S4.SS4.p2.3.m3.1" class="ltx_Math" alttext="(c)" display="inline"><semantics id="S4.SS4.p2.3.m3.1a"><mrow id="S4.SS4.p2.3.m3.1.2.2"><mo stretchy="false" id="S4.SS4.p2.3.m3.1.2.2.1">(</mo><mi id="S4.SS4.p2.3.m3.1.1" xref="S4.SS4.p2.3.m3.1.1.cmml">c</mi><mo stretchy="false" id="S4.SS4.p2.3.m3.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.3.m3.1b"><ci id="S4.SS4.p2.3.m3.1.1.cmml" xref="S4.SS4.p2.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.3.m3.1c">(c)</annotation></semantics></math>, we see that the accuracy dramatically increases from <math id="S4.SS4.p2.4.m4.1" class="ltx_Math" alttext="83.85\%" display="inline"><semantics id="S4.SS4.p2.4.m4.1a"><mrow id="S4.SS4.p2.4.m4.1.1" xref="S4.SS4.p2.4.m4.1.1.cmml"><mn id="S4.SS4.p2.4.m4.1.1.2" xref="S4.SS4.p2.4.m4.1.1.2.cmml">83.85</mn><mo id="S4.SS4.p2.4.m4.1.1.1" xref="S4.SS4.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.4.m4.1b"><apply id="S4.SS4.p2.4.m4.1.1.cmml" xref="S4.SS4.p2.4.m4.1.1"><csymbol cd="latexml" id="S4.SS4.p2.4.m4.1.1.1.cmml" xref="S4.SS4.p2.4.m4.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p2.4.m4.1.1.2.cmml" xref="S4.SS4.p2.4.m4.1.1.2">83.85</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.4.m4.1c">83.85\%</annotation></semantics></math> to <math id="S4.SS4.p2.5.m5.1" class="ltx_Math" alttext="88.75\%" display="inline"><semantics id="S4.SS4.p2.5.m5.1a"><mrow id="S4.SS4.p2.5.m5.1.1" xref="S4.SS4.p2.5.m5.1.1.cmml"><mn id="S4.SS4.p2.5.m5.1.1.2" xref="S4.SS4.p2.5.m5.1.1.2.cmml">88.75</mn><mo id="S4.SS4.p2.5.m5.1.1.1" xref="S4.SS4.p2.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.5.m5.1b"><apply id="S4.SS4.p2.5.m5.1.1.cmml" xref="S4.SS4.p2.5.m5.1.1"><csymbol cd="latexml" id="S4.SS4.p2.5.m5.1.1.1.cmml" xref="S4.SS4.p2.5.m5.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p2.5.m5.1.1.2.cmml" xref="S4.SS4.p2.5.m5.1.1.2">88.75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.5.m5.1c">88.75\%</annotation></semantics></math>. However, the improvement is marginal from <math id="S4.SS4.p2.6.m6.1" class="ltx_Math" alttext="(c)" display="inline"><semantics id="S4.SS4.p2.6.m6.1a"><mrow id="S4.SS4.p2.6.m6.1.2.2"><mo stretchy="false" id="S4.SS4.p2.6.m6.1.2.2.1">(</mo><mi id="S4.SS4.p2.6.m6.1.1" xref="S4.SS4.p2.6.m6.1.1.cmml">c</mi><mo stretchy="false" id="S4.SS4.p2.6.m6.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.6.m6.1b"><ci id="S4.SS4.p2.6.m6.1.1.cmml" xref="S4.SS4.p2.6.m6.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.6.m6.1c">(c)</annotation></semantics></math> to <math id="S4.SS4.p2.7.m7.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S4.SS4.p2.7.m7.1a"><mrow id="S4.SS4.p2.7.m7.1.2.2"><mo stretchy="false" id="S4.SS4.p2.7.m7.1.2.2.1">(</mo><mi id="S4.SS4.p2.7.m7.1.1" xref="S4.SS4.p2.7.m7.1.1.cmml">i</mi><mo stretchy="false" id="S4.SS4.p2.7.m7.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.7.m7.1b"><ci id="S4.SS4.p2.7.m7.1.1.cmml" xref="S4.SS4.p2.7.m7.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.7.m7.1c">(i)</annotation></semantics></math>, which implies that the synthetic data may suffer from the lack of inter-class variations. Observing the results of <math id="S4.SS4.p2.8.m8.12" class="ltx_Math" alttext="(d),~{}(e),~{}(f),~{}(g),~{}(h),~{}(i)" display="inline"><semantics id="S4.SS4.p2.8.m8.12a"><mrow id="S4.SS4.p2.8.m8.12.12.6" xref="S4.SS4.p2.8.m8.12.12.7.cmml"><mrow id="S4.SS4.p2.8.m8.7.7.1.1.2" xref="S4.SS4.p2.8.m8.12.12.7.cmml"><mo stretchy="false" id="S4.SS4.p2.8.m8.7.7.1.1.2.1" xref="S4.SS4.p2.8.m8.12.12.7.cmml">(</mo><mi id="S4.SS4.p2.8.m8.1.1" xref="S4.SS4.p2.8.m8.1.1.cmml">d</mi><mo stretchy="false" id="S4.SS4.p2.8.m8.7.7.1.1.2.2" xref="S4.SS4.p2.8.m8.12.12.7.cmml">)</mo></mrow><mo rspace="0.497em" id="S4.SS4.p2.8.m8.12.12.6.7" xref="S4.SS4.p2.8.m8.12.12.7.cmml">,</mo><mrow id="S4.SS4.p2.8.m8.8.8.2.2.2" xref="S4.SS4.p2.8.m8.12.12.7.cmml"><mo stretchy="false" id="S4.SS4.p2.8.m8.8.8.2.2.2.1" xref="S4.SS4.p2.8.m8.12.12.7.cmml">(</mo><mi id="S4.SS4.p2.8.m8.2.2" xref="S4.SS4.p2.8.m8.2.2.cmml">e</mi><mo stretchy="false" id="S4.SS4.p2.8.m8.8.8.2.2.2.2" xref="S4.SS4.p2.8.m8.12.12.7.cmml">)</mo></mrow><mo rspace="0.497em" id="S4.SS4.p2.8.m8.12.12.6.8" xref="S4.SS4.p2.8.m8.12.12.7.cmml">,</mo><mrow id="S4.SS4.p2.8.m8.9.9.3.3.2" xref="S4.SS4.p2.8.m8.12.12.7.cmml"><mo stretchy="false" id="S4.SS4.p2.8.m8.9.9.3.3.2.1" xref="S4.SS4.p2.8.m8.12.12.7.cmml">(</mo><mi id="S4.SS4.p2.8.m8.3.3" xref="S4.SS4.p2.8.m8.3.3.cmml">f</mi><mo stretchy="false" id="S4.SS4.p2.8.m8.9.9.3.3.2.2" xref="S4.SS4.p2.8.m8.12.12.7.cmml">)</mo></mrow><mo rspace="0.497em" id="S4.SS4.p2.8.m8.12.12.6.9" xref="S4.SS4.p2.8.m8.12.12.7.cmml">,</mo><mrow id="S4.SS4.p2.8.m8.10.10.4.4.2" xref="S4.SS4.p2.8.m8.12.12.7.cmml"><mo stretchy="false" id="S4.SS4.p2.8.m8.10.10.4.4.2.1" xref="S4.SS4.p2.8.m8.12.12.7.cmml">(</mo><mi id="S4.SS4.p2.8.m8.4.4" xref="S4.SS4.p2.8.m8.4.4.cmml">g</mi><mo stretchy="false" id="S4.SS4.p2.8.m8.10.10.4.4.2.2" xref="S4.SS4.p2.8.m8.12.12.7.cmml">)</mo></mrow><mo rspace="0.497em" id="S4.SS4.p2.8.m8.12.12.6.10" xref="S4.SS4.p2.8.m8.12.12.7.cmml">,</mo><mrow id="S4.SS4.p2.8.m8.11.11.5.5.2" xref="S4.SS4.p2.8.m8.12.12.7.cmml"><mo stretchy="false" id="S4.SS4.p2.8.m8.11.11.5.5.2.1" xref="S4.SS4.p2.8.m8.12.12.7.cmml">(</mo><mi id="S4.SS4.p2.8.m8.5.5" xref="S4.SS4.p2.8.m8.5.5.cmml">h</mi><mo stretchy="false" id="S4.SS4.p2.8.m8.11.11.5.5.2.2" xref="S4.SS4.p2.8.m8.12.12.7.cmml">)</mo></mrow><mo rspace="0.497em" id="S4.SS4.p2.8.m8.12.12.6.11" xref="S4.SS4.p2.8.m8.12.12.7.cmml">,</mo><mrow id="S4.SS4.p2.8.m8.12.12.6.6.2" xref="S4.SS4.p2.8.m8.12.12.7.cmml"><mo stretchy="false" id="S4.SS4.p2.8.m8.12.12.6.6.2.1" xref="S4.SS4.p2.8.m8.12.12.7.cmml">(</mo><mi id="S4.SS4.p2.8.m8.6.6" xref="S4.SS4.p2.8.m8.6.6.cmml">i</mi><mo stretchy="false" id="S4.SS4.p2.8.m8.12.12.6.6.2.2" xref="S4.SS4.p2.8.m8.12.12.7.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.8.m8.12b"><list id="S4.SS4.p2.8.m8.12.12.7.cmml" xref="S4.SS4.p2.8.m8.12.12.6"><ci id="S4.SS4.p2.8.m8.1.1.cmml" xref="S4.SS4.p2.8.m8.1.1">ğ‘‘</ci><ci id="S4.SS4.p2.8.m8.2.2.cmml" xref="S4.SS4.p2.8.m8.2.2">ğ‘’</ci><ci id="S4.SS4.p2.8.m8.3.3.cmml" xref="S4.SS4.p2.8.m8.3.3">ğ‘“</ci><ci id="S4.SS4.p2.8.m8.4.4.cmml" xref="S4.SS4.p2.8.m8.4.4">ğ‘”</ci><ci id="S4.SS4.p2.8.m8.5.5.cmml" xref="S4.SS4.p2.8.m8.5.5">â„</ci><ci id="S4.SS4.p2.8.m8.6.6.cmml" xref="S4.SS4.p2.8.m8.6.6">ğ‘–</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.8.m8.12c">(d),~{}(e),~{}(f),~{}(g),~{}(h),~{}(i)</annotation></semantics></math>, we conclude that the accuracy significantly increases with the increasing of dataset depth, but it is quickly saturated when the depth is larger than <math id="S4.SS4.p2.9.m9.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S4.SS4.p2.9.m9.1a"><mn id="S4.SS4.p2.9.m9.1.1" xref="S4.SS4.p2.9.m9.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.9.m9.1b"><cn type="integer" id="S4.SS4.p2.9.m9.1.1.cmml" xref="S4.SS4.p2.9.m9.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.9.m9.1c">20</annotation></semantics></math>, which is in line with the observation on real data made by SchroffÂ <em id="S4.SS4.p2.18.2" class="ltx_emph ltx_font_italic">et al</em>.<span id="S4.SS4.p2.18.3" class="ltx_text"></span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>. Lastly, we see that <math id="S4.SS4.p2.10.m10.1" class="ltx_Math" alttext="(a)" display="inline"><semantics id="S4.SS4.p2.10.m10.1a"><mrow id="S4.SS4.p2.10.m10.1.2.2"><mo stretchy="false" id="S4.SS4.p2.10.m10.1.2.2.1">(</mo><mi id="S4.SS4.p2.10.m10.1.1" xref="S4.SS4.p2.10.m10.1.1.cmml">a</mi><mo stretchy="false" id="S4.SS4.p2.10.m10.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.10.m10.1b"><ci id="S4.SS4.p2.10.m10.1.1.cmml" xref="S4.SS4.p2.10.m10.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.10.m10.1c">(a)</annotation></semantics></math> and <math id="S4.SS4.p2.11.m11.1" class="ltx_Math" alttext="(e)" display="inline"><semantics id="S4.SS4.p2.11.m11.1a"><mrow id="S4.SS4.p2.11.m11.1.2.2"><mo stretchy="false" id="S4.SS4.p2.11.m11.1.2.2.1">(</mo><mi id="S4.SS4.p2.11.m11.1.1" xref="S4.SS4.p2.11.m11.1.1.cmml">e</mi><mo stretchy="false" id="S4.SS4.p2.11.m11.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.11.m11.1b"><ci id="S4.SS4.p2.11.m11.1.1.cmml" xref="S4.SS4.p2.11.m11.1.1">ğ‘’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.11.m11.1c">(e)</annotation></semantics></math> have the same number of total images (50K), while <math id="S4.SS4.p2.12.m12.1" class="ltx_Math" alttext="(a)" display="inline"><semantics id="S4.SS4.p2.12.m12.1a"><mrow id="S4.SS4.p2.12.m12.1.2.2"><mo stretchy="false" id="S4.SS4.p2.12.m12.1.2.2.1">(</mo><mi id="S4.SS4.p2.12.m12.1.1" xref="S4.SS4.p2.12.m12.1.1.cmml">a</mi><mo stretchy="false" id="S4.SS4.p2.12.m12.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.12.m12.1b"><ci id="S4.SS4.p2.12.m12.1.1.cmml" xref="S4.SS4.p2.12.m12.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.12.m12.1c">(a)</annotation></semantics></math> outperforms <math id="S4.SS4.p2.13.m13.1" class="ltx_Math" alttext="(e)" display="inline"><semantics id="S4.SS4.p2.13.m13.1a"><mrow id="S4.SS4.p2.13.m13.1.2.2"><mo stretchy="false" id="S4.SS4.p2.13.m13.1.2.2.1">(</mo><mi id="S4.SS4.p2.13.m13.1.1" xref="S4.SS4.p2.13.m13.1.1.cmml">e</mi><mo stretchy="false" id="S4.SS4.p2.13.m13.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.13.m13.1b"><ci id="S4.SS4.p2.13.m13.1.1.cmml" xref="S4.SS4.p2.13.m13.1.1">ğ‘’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.13.m13.1c">(e)</annotation></semantics></math> with a large margin, <em id="S4.SS4.p2.18.4" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS4.p2.18.5" class="ltx_text"></span>, <math id="S4.SS4.p2.14.m14.1" class="ltx_Math" alttext="4.37\%" display="inline"><semantics id="S4.SS4.p2.14.m14.1a"><mrow id="S4.SS4.p2.14.m14.1.1" xref="S4.SS4.p2.14.m14.1.1.cmml"><mn id="S4.SS4.p2.14.m14.1.1.2" xref="S4.SS4.p2.14.m14.1.1.2.cmml">4.37</mn><mo id="S4.SS4.p2.14.m14.1.1.1" xref="S4.SS4.p2.14.m14.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.14.m14.1b"><apply id="S4.SS4.p2.14.m14.1.1.cmml" xref="S4.SS4.p2.14.m14.1.1"><csymbol cd="latexml" id="S4.SS4.p2.14.m14.1.1.1.cmml" xref="S4.SS4.p2.14.m14.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p2.14.m14.1.1.2.cmml" xref="S4.SS4.p2.14.m14.1.1.2">4.37</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.14.m14.1c">4.37\%</annotation></semantics></math>, which reveals that the dataset width plays as the more important role than the dataset depth in term of the final face recognition accuracy. Similar observation can be found by comparing <math id="S4.SS4.p2.15.m15.1" class="ltx_Math" alttext="(b)" display="inline"><semantics id="S4.SS4.p2.15.m15.1a"><mrow id="S4.SS4.p2.15.m15.1.2.2"><mo stretchy="false" id="S4.SS4.p2.15.m15.1.2.2.1">(</mo><mi id="S4.SS4.p2.15.m15.1.1" xref="S4.SS4.p2.15.m15.1.1.cmml">b</mi><mo stretchy="false" id="S4.SS4.p2.15.m15.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.15.m15.1b"><ci id="S4.SS4.p2.15.m15.1.1.cmml" xref="S4.SS4.p2.15.m15.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.15.m15.1c">(b)</annotation></semantics></math> and <math id="S4.SS4.p2.16.m16.1" class="ltx_Math" alttext="(f)" display="inline"><semantics id="S4.SS4.p2.16.m16.1a"><mrow id="S4.SS4.p2.16.m16.1.2.2"><mo stretchy="false" id="S4.SS4.p2.16.m16.1.2.2.1">(</mo><mi id="S4.SS4.p2.16.m16.1.1" xref="S4.SS4.p2.16.m16.1.1.cmml">f</mi><mo stretchy="false" id="S4.SS4.p2.16.m16.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.16.m16.1b"><ci id="S4.SS4.p2.16.m16.1.1.cmml" xref="S4.SS4.p2.16.m16.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.16.m16.1c">(f)</annotation></semantics></math>. Importantly, employing the identity mixup (IM) for training consistently improves the performance over all the datasets, which confirms the effectiveness of IM. The best accuracy <math id="S4.SS4.p2.17.m17.1" class="ltx_Math" alttext="91.97\%" display="inline"><semantics id="S4.SS4.p2.17.m17.1a"><mrow id="S4.SS4.p2.17.m17.1.1" xref="S4.SS4.p2.17.m17.1.1.cmml"><mn id="S4.SS4.p2.17.m17.1.1.2" xref="S4.SS4.p2.17.m17.1.1.2.cmml">91.97</mn><mo id="S4.SS4.p2.17.m17.1.1.1" xref="S4.SS4.p2.17.m17.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.17.m17.1b"><apply id="S4.SS4.p2.17.m17.1.1.cmml" xref="S4.SS4.p2.17.m17.1.1"><csymbol cd="latexml" id="S4.SS4.p2.17.m17.1.1.1.cmml" xref="S4.SS4.p2.17.m17.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p2.17.m17.1.1.2.cmml" xref="S4.SS4.p2.17.m17.1.1.2">91.97</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.17.m17.1c">91.97\%</annotation></semantics></math> brought by IM significantly outperforms the original <math id="S4.SS4.p2.18.m18.1" class="ltx_Math" alttext="88.98\%" display="inline"><semantics id="S4.SS4.p2.18.m18.1a"><mrow id="S4.SS4.p2.18.m18.1.1" xref="S4.SS4.p2.18.m18.1.1.cmml"><mn id="S4.SS4.p2.18.m18.1.1.2" xref="S4.SS4.p2.18.m18.1.1.2.cmml">88.98</mn><mo id="S4.SS4.p2.18.m18.1.1.1" xref="S4.SS4.p2.18.m18.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.18.m18.1b"><apply id="S4.SS4.p2.18.m18.1.1.cmml" xref="S4.SS4.p2.18.m18.1.1"><csymbol cd="latexml" id="S4.SS4.p2.18.m18.1.1.1.cmml" xref="S4.SS4.p2.18.m18.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p2.18.m18.1.1.2.cmml" xref="S4.SS4.p2.18.m18.1.1.2">88.98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.18.m18.1c">88.98\%</annotation></semantics></math>.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.9.9" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.9.9.10.1" class="ltx_tr">
<th id="S4.T3.9.9.10.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Method</th>
<th id="S4.T3.9.9.10.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">ID</th>
<th id="S4.T3.9.9.10.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Samples</th>
<th id="S4.T3.9.9.10.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">LFW</th>
<th id="S4.T3.9.9.10.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">LFW(w/ IM)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<td id="S4.T3.1.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt">
<math id="S4.T3.1.1.1.1.m1.1" class="ltx_Math" alttext="(a)" display="inline"><semantics id="S4.T3.1.1.1.1.m1.1a"><mrow id="S4.T3.1.1.1.1.m1.1.2.2"><mo stretchy="false" id="S4.T3.1.1.1.1.m1.1.2.2.1">(</mo><mi id="S4.T3.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.m1.1.1.cmml">a</mi><mo stretchy="false" id="S4.T3.1.1.1.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.m1.1c">(a)</annotation></semantics></math> 1K_50</td>
<td id="S4.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">1K</td>
<td id="S4.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">50</td>
<td id="S4.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">83.85</td>
<td id="S4.T3.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T3.1.1.1.5.1" class="ltx_text ltx_font_bold">87.53</span></td>
</tr>
<tr id="S4.T3.2.2.2" class="ltx_tr">
<td id="S4.T3.2.2.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">
<math id="S4.T3.2.2.2.1.m1.1" class="ltx_Math" alttext="(b)" display="inline"><semantics id="S4.T3.2.2.2.1.m1.1a"><mrow id="S4.T3.2.2.2.1.m1.1.2.2"><mo stretchy="false" id="S4.T3.2.2.2.1.m1.1.2.2.1">(</mo><mi id="S4.T3.2.2.2.1.m1.1.1" xref="S4.T3.2.2.2.1.m1.1.1.cmml">b</mi><mo stretchy="false" id="S4.T3.2.2.2.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.1.m1.1b"><ci id="S4.T3.2.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.1.m1.1c">(b)</annotation></semantics></math> 2K_50</td>
<td id="S4.T3.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r">2K</td>
<td id="S4.T3.2.2.2.3" class="ltx_td ltx_align_center ltx_border_r">50</td>
<td id="S4.T3.2.2.2.4" class="ltx_td ltx_align_center ltx_border_r">86.18</td>
<td id="S4.T3.2.2.2.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.2.2.2.5.1" class="ltx_text ltx_font_bold">89.28</span></td>
</tr>
<tr id="S4.T3.3.3.3" class="ltx_tr">
<td id="S4.T3.3.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">
<math id="S4.T3.3.3.3.1.m1.1" class="ltx_Math" alttext="(c)" display="inline"><semantics id="S4.T3.3.3.3.1.m1.1a"><mrow id="S4.T3.3.3.3.1.m1.1.2.2"><mo stretchy="false" id="S4.T3.3.3.3.1.m1.1.2.2.1">(</mo><mi id="S4.T3.3.3.3.1.m1.1.1" xref="S4.T3.3.3.3.1.m1.1.1.cmml">c</mi><mo stretchy="false" id="S4.T3.3.3.3.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.1.m1.1b"><ci id="S4.T3.3.3.3.1.m1.1.1.cmml" xref="S4.T3.3.3.3.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.1.m1.1c">(c)</annotation></semantics></math> 5K_50</td>
<td id="S4.T3.3.3.3.2" class="ltx_td ltx_align_center ltx_border_r">5K</td>
<td id="S4.T3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r">50</td>
<td id="S4.T3.3.3.3.4" class="ltx_td ltx_align_center ltx_border_r">88.75</td>
<td id="S4.T3.3.3.3.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.3.3.3.5.1" class="ltx_text ltx_font_bold">90.95</span></td>
</tr>
<tr id="S4.T3.4.4.4" class="ltx_tr">
<td id="S4.T3.4.4.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<math id="S4.T3.4.4.4.1.m1.1" class="ltx_Math" alttext="(d)" display="inline"><semantics id="S4.T3.4.4.4.1.m1.1a"><mrow id="S4.T3.4.4.4.1.m1.1.2.2"><mo stretchy="false" id="S4.T3.4.4.4.1.m1.1.2.2.1">(</mo><mi id="S4.T3.4.4.4.1.m1.1.1" xref="S4.T3.4.4.4.1.m1.1.1.cmml">d</mi><mo stretchy="false" id="S4.T3.4.4.4.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.1.m1.1b"><ci id="S4.T3.4.4.4.1.m1.1.1.cmml" xref="S4.T3.4.4.4.1.m1.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.1.m1.1c">(d)</annotation></semantics></math> 10K_2</td>
<td id="S4.T3.4.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10K</td>
<td id="S4.T3.4.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td id="S4.T3.4.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">78.85</td>
<td id="S4.T3.4.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.4.4.5.1" class="ltx_text ltx_font_bold">80.30</span></td>
</tr>
<tr id="S4.T3.5.5.5" class="ltx_tr">
<td id="S4.T3.5.5.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">
<math id="S4.T3.5.5.5.1.m1.1" class="ltx_Math" alttext="(e)" display="inline"><semantics id="S4.T3.5.5.5.1.m1.1a"><mrow id="S4.T3.5.5.5.1.m1.1.2.2"><mo stretchy="false" id="S4.T3.5.5.5.1.m1.1.2.2.1">(</mo><mi id="S4.T3.5.5.5.1.m1.1.1" xref="S4.T3.5.5.5.1.m1.1.1.cmml">e</mi><mo stretchy="false" id="S4.T3.5.5.5.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.1.m1.1b"><ci id="S4.T3.5.5.5.1.m1.1.1.cmml" xref="S4.T3.5.5.5.1.m1.1.1">ğ‘’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.1.m1.1c">(e)</annotation></semantics></math> 10K_5</td>
<td id="S4.T3.5.5.5.2" class="ltx_td ltx_align_center ltx_border_r">10K</td>
<td id="S4.T3.5.5.5.3" class="ltx_td ltx_align_center ltx_border_r">5</td>
<td id="S4.T3.5.5.5.4" class="ltx_td ltx_align_center ltx_border_r">88.22</td>
<td id="S4.T3.5.5.5.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.5.5.5.5.1" class="ltx_text ltx_font_bold">88.32</span></td>
</tr>
<tr id="S4.T3.6.6.6" class="ltx_tr">
<td id="S4.T3.6.6.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">
<math id="S4.T3.6.6.6.1.m1.1" class="ltx_Math" alttext="(f)" display="inline"><semantics id="S4.T3.6.6.6.1.m1.1a"><mrow id="S4.T3.6.6.6.1.m1.1.2.2"><mo stretchy="false" id="S4.T3.6.6.6.1.m1.1.2.2.1">(</mo><mi id="S4.T3.6.6.6.1.m1.1.1" xref="S4.T3.6.6.6.1.m1.1.1.cmml">f</mi><mo stretchy="false" id="S4.T3.6.6.6.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.1.m1.1b"><ci id="S4.T3.6.6.6.1.m1.1.1.cmml" xref="S4.T3.6.6.6.1.m1.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.1.m1.1c">(f)</annotation></semantics></math> 10K_10</td>
<td id="S4.T3.6.6.6.2" class="ltx_td ltx_align_center ltx_border_r">10K</td>
<td id="S4.T3.6.6.6.3" class="ltx_td ltx_align_center ltx_border_r">10</td>
<td id="S4.T3.6.6.6.4" class="ltx_td ltx_align_center ltx_border_r">89.48</td>
<td id="S4.T3.6.6.6.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.6.6.6.5.1" class="ltx_text ltx_font_bold">90.28</span></td>
</tr>
<tr id="S4.T3.7.7.7" class="ltx_tr">
<td id="S4.T3.7.7.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">
<math id="S4.T3.7.7.7.1.m1.1" class="ltx_Math" alttext="(g)" display="inline"><semantics id="S4.T3.7.7.7.1.m1.1a"><mrow id="S4.T3.7.7.7.1.m1.1.2.2"><mo stretchy="false" id="S4.T3.7.7.7.1.m1.1.2.2.1">(</mo><mi id="S4.T3.7.7.7.1.m1.1.1" xref="S4.T3.7.7.7.1.m1.1.1.cmml">g</mi><mo stretchy="false" id="S4.T3.7.7.7.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.7.1.m1.1b"><ci id="S4.T3.7.7.7.1.m1.1.1.cmml" xref="S4.T3.7.7.7.1.m1.1.1">ğ‘”</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.7.1.m1.1c">(g)</annotation></semantics></math> 10K_20</td>
<td id="S4.T3.7.7.7.2" class="ltx_td ltx_align_center ltx_border_r">10K</td>
<td id="S4.T3.7.7.7.3" class="ltx_td ltx_align_center ltx_border_r">20</td>
<td id="S4.T3.7.7.7.4" class="ltx_td ltx_align_center ltx_border_r">89.90</td>
<td id="S4.T3.7.7.7.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.7.7.7.5.1" class="ltx_text ltx_font_bold">90.87</span></td>
</tr>
<tr id="S4.T3.8.8.8" class="ltx_tr">
<td id="S4.T3.8.8.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">
<math id="S4.T3.8.8.8.1.m1.1" class="ltx_Math" alttext="(h)" display="inline"><semantics id="S4.T3.8.8.8.1.m1.1a"><mrow id="S4.T3.8.8.8.1.m1.1.2.2"><mo stretchy="false" id="S4.T3.8.8.8.1.m1.1.2.2.1">(</mo><mi id="S4.T3.8.8.8.1.m1.1.1" xref="S4.T3.8.8.8.1.m1.1.1.cmml">h</mi><mo stretchy="false" id="S4.T3.8.8.8.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.8.8.8.1.m1.1b"><ci id="S4.T3.8.8.8.1.m1.1.1.cmml" xref="S4.T3.8.8.8.1.m1.1.1">â„</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.8.8.1.m1.1c">(h)</annotation></semantics></math> 10K_30</td>
<td id="S4.T3.8.8.8.2" class="ltx_td ltx_align_center ltx_border_r">10K</td>
<td id="S4.T3.8.8.8.3" class="ltx_td ltx_align_center ltx_border_r">30</td>
<td id="S4.T3.8.8.8.4" class="ltx_td ltx_align_center ltx_border_r">89.73</td>
<td id="S4.T3.8.8.8.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.8.8.8.5.1" class="ltx_text ltx_font_bold">91.17</span></td>
</tr>
<tr id="S4.T3.9.9.9" class="ltx_tr">
<td id="S4.T3.9.9.9.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">
<math id="S4.T3.9.9.9.1.m1.1" class="ltx_Math" alttext="(i)" display="inline"><semantics id="S4.T3.9.9.9.1.m1.1a"><mrow id="S4.T3.9.9.9.1.m1.1.2.2"><mo stretchy="false" id="S4.T3.9.9.9.1.m1.1.2.2.1">(</mo><mi id="S4.T3.9.9.9.1.m1.1.1" xref="S4.T3.9.9.9.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S4.T3.9.9.9.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.9.9.9.1.m1.1b"><ci id="S4.T3.9.9.9.1.m1.1.1.cmml" xref="S4.T3.9.9.9.1.m1.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.9.9.9.1.m1.1c">(i)</annotation></semantics></math> 10K_50</td>
<td id="S4.T3.9.9.9.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">10K</td>
<td id="S4.T3.9.9.9.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">50</td>
<td id="S4.T3.9.9.9.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">88.98</td>
<td id="S4.T3.9.9.9.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T3.9.9.9.5.1" class="ltx_text ltx_font_bold">91.97</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Face verification accuracies (<math id="S4.T3.16.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T3.16.m1.1b"><mo id="S4.T3.16.m1.1.1" xref="S4.T3.16.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T3.16.m1.1c"><csymbol cd="latexml" id="S4.T3.16.m1.1.1.cmml" xref="S4.T3.16.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.16.m1.1d">\%</annotation></semantics></math>) on LFWÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>. â€œ<math id="S4.T3.17.m2.1" class="ltx_Math" alttext="N\_S" display="inline"><semantics id="S4.T3.17.m2.1b"><mrow id="S4.T3.17.m2.1.1" xref="S4.T3.17.m2.1.1.cmml"><mi id="S4.T3.17.m2.1.1.2" xref="S4.T3.17.m2.1.1.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S4.T3.17.m2.1.1.1" xref="S4.T3.17.m2.1.1.1.cmml">â€‹</mo><mi mathvariant="normal" id="S4.T3.17.m2.1.1.3" xref="S4.T3.17.m2.1.1.3.cmml">_</mi><mo lspace="0em" rspace="0em" id="S4.T3.17.m2.1.1.1b" xref="S4.T3.17.m2.1.1.1.cmml">â€‹</mo><mi id="S4.T3.17.m2.1.1.4" xref="S4.T3.17.m2.1.1.4.cmml">S</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.17.m2.1c"><apply id="S4.T3.17.m2.1.1.cmml" xref="S4.T3.17.m2.1.1"><times id="S4.T3.17.m2.1.1.1.cmml" xref="S4.T3.17.m2.1.1.1"></times><ci id="S4.T3.17.m2.1.1.2.cmml" xref="S4.T3.17.m2.1.1.2">ğ‘</ci><ci id="S4.T3.17.m2.1.1.3.cmml" xref="S4.T3.17.m2.1.1.3">_</ci><ci id="S4.T3.17.m2.1.1.4.cmml" xref="S4.T3.17.m2.1.1.4">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.17.m2.1d">N\_S</annotation></semantics></math>â€ implies that the corresponding dataset has <math id="S4.T3.18.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.T3.18.m3.1b"><mi id="S4.T3.18.m3.1.1" xref="S4.T3.18.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.T3.18.m3.1c"><ci id="S4.T3.18.m3.1.1.cmml" xref="S4.T3.18.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.18.m3.1d">N</annotation></semantics></math> identities with <math id="S4.T3.19.m4.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.T3.19.m4.1b"><mi id="S4.T3.19.m4.1.1" xref="S4.T3.19.m4.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.T3.19.m4.1c"><ci id="S4.T3.19.m4.1.1.cmml" xref="S4.T3.19.m4.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.19.m4.1d">S</annotation></semantics></math> samples per identity, <em id="S4.T3.24.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.T3.25.2" class="ltx_text"></span>, <math id="S4.T3.20.m5.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.T3.20.m5.1b"><mi id="S4.T3.20.m5.1.1" xref="S4.T3.20.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.T3.20.m5.1c"><ci id="S4.T3.20.m5.1.1.cmml" xref="S4.T3.20.m5.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.20.m5.1d">N</annotation></semantics></math> and <math id="S4.T3.21.m6.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.T3.21.m6.1b"><mi id="S4.T3.21.m6.1.1" xref="S4.T3.21.m6.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.T3.21.m6.1c"><ci id="S4.T3.21.m6.1.1.cmml" xref="S4.T3.21.m6.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.21.m6.1d">S</annotation></semantics></math> indicate the width and depth. LFW (w/ IM) means employing the identity mixup (IM) for training.</figcaption>
</figure>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Impacts of Different Facial Attributes</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.2" class="ltx_p"><span id="S4.SS5.p1.2.1" class="ltx_text ltx_font_bold">Experimental Setup.</span> We explore the impacts of different facial attributes for face recognition (<em id="S4.SS5.p1.2.2" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS5.p1.2.3" class="ltx_text"></span>, expression, pose and illumination) by controlling face generation process. We construct four synthetic datasets that have <math id="S4.SS5.p1.1.m1.1" class="ltx_Math" alttext="5K" display="inline"><semantics id="S4.SS5.p1.1.m1.1a"><mrow id="S4.SS5.p1.1.m1.1.1" xref="S4.SS5.p1.1.m1.1.1.cmml"><mn id="S4.SS5.p1.1.m1.1.1.2" xref="S4.SS5.p1.1.m1.1.1.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="S4.SS5.p1.1.m1.1.1.1" xref="S4.SS5.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS5.p1.1.m1.1.1.3" xref="S4.SS5.p1.1.m1.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.1.m1.1b"><apply id="S4.SS5.p1.1.m1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1"><times id="S4.SS5.p1.1.m1.1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1.1"></times><cn type="integer" id="S4.SS5.p1.1.m1.1.1.2.cmml" xref="S4.SS5.p1.1.m1.1.1.2">5</cn><ci id="S4.SS5.p1.1.m1.1.1.3.cmml" xref="S4.SS5.p1.1.m1.1.1.3">ğ¾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.1.m1.1c">5K</annotation></semantics></math> identities and <math id="S4.SS5.p1.2.m2.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S4.SS5.p1.2.m2.1a"><mn id="S4.SS5.p1.2.m2.1.1" xref="S4.SS5.p1.2.m2.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.2.m2.1b"><cn type="integer" id="S4.SS5.p1.2.m2.1.1.cmml" xref="S4.SS5.p1.2.m2.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.2.m2.1c">50</annotation></semantics></math> samples per identity. The difference between the four datasets is the distribution of different facial attributes. Specifically, the first dataset is referred to as â€œNonâ€, since it fixes all the facial attributes. The rest three datasets are referred to as â€œExpressionâ€, â€œPoseâ€, and â€œIlluminationâ€, respectively, which indicates the only changed attribute while keeping other attributes unchanged.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.2" class="ltx_p"><span id="S4.SS5.p2.2.1" class="ltx_text ltx_font_bold">Empirical Analysis.</span>
As shown in FigureÂ <a href="#S4.F7" title="Figure 7 â€£ 4.5 Impacts of Different Facial Attributes â€£ 4 Experiments â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, â€œNonâ€ and â€œExpressionâ€ achieve the worst two performances <math id="S4.SS5.p2.1.m1.1" class="ltx_Math" alttext="74.55\%" display="inline"><semantics id="S4.SS5.p2.1.m1.1a"><mrow id="S4.SS5.p2.1.m1.1.1" xref="S4.SS5.p2.1.m1.1.1.cmml"><mn id="S4.SS5.p2.1.m1.1.1.2" xref="S4.SS5.p2.1.m1.1.1.2.cmml">74.55</mn><mo id="S4.SS5.p2.1.m1.1.1.1" xref="S4.SS5.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.1.m1.1b"><apply id="S4.SS5.p2.1.m1.1.1.cmml" xref="S4.SS5.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS5.p2.1.m1.1.1.1.cmml" xref="S4.SS5.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS5.p2.1.m1.1.1.2.cmml" xref="S4.SS5.p2.1.m1.1.1.2">74.55</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.1.m1.1c">74.55\%</annotation></semantics></math> and <math id="S4.SS5.p2.2.m2.1" class="ltx_Math" alttext="73.72\%" display="inline"><semantics id="S4.SS5.p2.2.m2.1a"><mrow id="S4.SS5.p2.2.m2.1.1" xref="S4.SS5.p2.2.m2.1.1.cmml"><mn id="S4.SS5.p2.2.m2.1.1.2" xref="S4.SS5.p2.2.m2.1.1.2.cmml">73.72</mn><mo id="S4.SS5.p2.2.m2.1.1.1" xref="S4.SS5.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.2.m2.1b"><apply id="S4.SS5.p2.2.m2.1.1.cmml" xref="S4.SS5.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.SS5.p2.2.m2.1.1.1.cmml" xref="S4.SS5.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS5.p2.2.m2.1.1.2.cmml" xref="S4.SS5.p2.2.m2.1.1.2">73.72</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.2.m2.1c">73.72\%</annotation></semantics></math>. Specifically, we find that â€œExpressionâ€ is limited to poor diversity, <em id="S4.SS5.p2.2.2" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS5.p2.2.3" class="ltx_text"></span>, the generated face images mainly have the expression of â€œsmilingâ€ (see more demo images in the supplementary materials). Hence, there is basically only one valid sample per identity for â€Nonâ€ and â€Expressionâ€, causing the poor performances. Experimental results on â€œPoseâ€ and â€œIlluminationâ€ demonstrate significant improvements over â€œNonâ€, possibly due to their more diverse distributions and the testing dataset (<em id="S4.SS5.p2.2.4" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS5.p2.2.5" class="ltx_text"></span>, LFW) also has similar pose and illumination. Lastly, we find that all of four settings are significantly improved with the proposed identity mixup, especially for â€œNonâ€. A possible reason is that identity mixup can be regarded as a strong data augmentation method for face recognition, reducing the influences of different facial attributes on the final recognition accuracy.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2108.07960/assets/x7.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="243" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Face verification accuracies (<math id="S4.F7.2.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.F7.2.m1.1b"><mo id="S4.F7.2.m1.1.1" xref="S4.F7.2.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.F7.2.m1.1c"><csymbol cd="latexml" id="S4.F7.2.m1.1.1.cmml" xref="S4.F7.2.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.2.m1.1d">\%</annotation></semantics></math>) on LFW using the training datasets with variations in different facial attributes. Specifically, â€œExpressionâ€, â€œPoseâ€, and â€œIlluminationâ€ indicate that we separately introduce variations in expression, pose, and illumination while keeping the other attributes unchanged. w/ IM and w/o IM indicate whether identity mixup (IM) is used during training.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we explored the potentials of synthetic data for face recognition, <em id="S5.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S5.p1.1.2" class="ltx_text"></span>, SynFace. We performed a systematically empirical analysis and provided novel insights on how to efficiently utilize synthetic face images for face recognition: 1) enlarging the intra-class variations of synthetic data consistently improves the performance, which can be achieved by the proposed identity mixup; 2) both the depth and width of the training synthetic dataset have significant influences on the performance, while the saturation first appears on the depth dimension, <em id="S5.p1.1.3" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S5.p1.1.4" class="ltx_text"></span>, increasing the number of identities (width) is more important; 3) the impacts of different attributes vary from pose, illumination and expression, <em id="S5.p1.1.5" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S5.p1.1.6" class="ltx_text"></span>, changing pose and illumination brings significant improvements, while generated face images suffer from a poor diversity on expression; 4) a small subset of real-world face images can greatly boost the performance of SynFace via the proposed domain mixup.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgement</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">Dr. Baosheng Yu is supported by ARC project FL-170100117.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Martin Arjovsky, Soumith Chintala, and Leon Bottou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Wasserstein gan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1701.07875</span><span id="bib.bib1.4.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Jianmin Bao, Dong Chen, Fang Wen, Houqiang Li, and Gang Hua.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Towards open-set identity preserving face synthesis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:90%;">, pages 6713â€“6722, 2018.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Volker Blanz and Thomas Vetter.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">A morphable model for the synthesis of 3d faces.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 26th annual Conference on Computer
graphics and interactive techniques</span><span id="bib.bib3.5.3" class="ltx_text" style="font-size:90%;">, pages 187â€“194, 1999.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Ingwer Borg and PatrickÂ JF Groenen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Modern multidimensional scaling: Theory and applications</span><span id="bib.bib4.3.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.4.1" class="ltx_text" style="font-size:90%;">Springer Science &amp; Business Media, 2005.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Alexander Buslaev, VladimirÂ I. Iglovikov, Eugene Khvedchenya, Alex Parinov,
Mikhail Druzhinin, and AlexandrÂ A. Kalinin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Albumentations: Fast and flexible image augmentations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Information</span><span id="bib.bib5.4.2" class="ltx_text" style="font-size:90%;">, 11(2), 2020.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Kaidi Cao, Yu Rong, Cheng Li, Xiaoou Tang, and ChenÂ Change Loy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Pose-robust face recognition via deep residual equivariant mapping.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, pages 5187â€“5196, 2018.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Yuhua Chen, Wen Li, Xiaoran Chen, and LucÂ Van Gool.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Learning semantic segmentation from synthetic data: A geometrically
guided input-output adaptation approach.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, pages 1841â€“1850, 2019.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Zhuo Chen, Chaoyue Wang, Bo Yuan, and Dacheng Tao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Puppeteergan: Arbitrary portrait animation with semantic-aware
appearance transformation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib8.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib8.5.3" class="ltx_text" style="font-size:90%;">, June 2020.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Sumit Chopra, Raia Hadsell, and Yann LeCun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Learning a similarity metric discriminatively, with application to
face verification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:90%;">, volumeÂ 1, pages 539â€“546. IEEE, 2005.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Bin Dai and David Wipf.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Diagnosing and enhancing vae models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1903.05789</span><span id="bib.bib10.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos Zafeiriou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Arcface: Additive angular margin loss for deep face recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, pages 4690â€“4699, 2019.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Yu Deng, Jiaolong Yang, Dong Chen, Fang Wen, and Xin Tong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Disentangled and controllable face image generation via 3d
imitative-contrastive learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">, pages 5154â€“5163, 2020.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Yu Deng, Jiaolong Yang, Sicheng Xu, Dong Chen, Yunde Jia, and Xin Tong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Accurate 3d face reconstruction with weakly-supervised learning: From
single image to image set.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
Workshops (CVPRW)</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, pages 0â€“0, 2019.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Zhongying Deng, Xiaojiang Peng, Zhifeng Li, and Yu Qiao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Mutual component convolutional neural networks for heterogeneous face
recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Image Processing (TIP)</span><span id="bib.bib14.4.2" class="ltx_text" style="font-size:90%;">, 28(6):3102â€“3114,
2019.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Dihong Gong, Zhifeng Li, Weilin Huang, Xuelong Li, and Dacheng Tao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Heterogeneous face recognition: A common encoding feature
discriminant approach.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions Image Process (TIP)</span><span id="bib.bib15.4.2" class="ltx_text" style="font-size:90%;">, 26(5):2079â€“2089, 2017.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Dihong Gong, Zhifeng Li, Dahua Lin, Jianzhuang Liu, and Xiaoou Tang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Hidden factor analysis for age invariant face recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE International Conference on Computer Vision (ICCV)</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:90%;">,
pages 2872â€“2879, 2013.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Dihong Gong, Zhifeng Li, Jianzhuang Liu, and Yu Qiao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Multi-feature canonical correlation analysis for face photo-sketch
image retrieval.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 21th ACM International Conference on
Multimedia</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, pages 617â€“620, 2013.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Dihong Gong, Zhifeng Li, Dacheng Tao, Jianzhuang Liu, and Xuelong Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">A maximum entropy feature descriptor for age invariant face
recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, pages 5289â€“5297, 2015.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Generative adversarial nets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems (NeurIPS)</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">,
pages 2672â€“2680, 2014.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Hongyu Guo, Yongyi Mao, and Richong Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Mixup as locally linear out-of-manifold regularization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI Conference on Artificial Intelligence (AAAI)</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">,
volumeÂ 33, pages 3714â€“3722, 2019.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Yandong Guo, Lei Zhang, Yuxiao Hu, Xiaodong He, and Jianfeng Gao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Ms-celeb-1m: A dataset and benchmark for large-scale face
recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision (ECCV)</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, pages
87â€“102. Springer, 2016.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Raia Hadsell, Sumit Chopra, and Yann LeCun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Dimensionality reduction by learning an invariant mapping.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">, volumeÂ 2, pages 1735â€“1742. IEEE, 2006.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, pages 770â€“778, 2016.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Elad Hoffer and Nir Ailon.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Deep metric learning using triplet network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib24.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Workshop on Similarity-Based Pattern
Recognition</span><span id="bib.bib24.5.3" class="ltx_text" style="font-size:90%;">, pages 84â€“92. Springer, 2015.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
FuÂ Jie Huang, Zhihua Zhou, Hong-Jiang Zhang, and Tsuhan Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Pose invariant face recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of IEEE International Conference on Automatic
Face and Gesture Recognition</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, pages 245â€“250, 2000.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Gao Huang, Zhuang Liu, Laurens Van DerÂ Maaten, and KilianÂ Q Weinberger.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Densely connected convolutional networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, pages 4700â€“4708, 2017.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
GaryÂ B Huang, Marwan Mattar, Tamara Berg, and Eric Learned-Miller.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Labeled faces in the wild: A database forstudying face recognition in
unconstrained environments.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">2008.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Ira Kemelmacher-Shlizerman, StevenÂ M Seitz, Daniel Miller, and Evan Brossard.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">The megaface benchmark: 1 million faces for recognition at scale.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib28.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib28.5.3" class="ltx_text" style="font-size:90%;">, pages 4873â€“4882, 2016.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Adam Kortylewski, Bernhard Egger, Andreas Schneider, Thomas Gerig, Andreas
Morel-Forster, and Thomas Vetter.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Analyzing and reducing the damage of dataset bias to face recognition
with synthetic data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition Workshops (CVPRW)</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:90%;">, pages 0â€“0, 2019.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Alex Krizhevsky, Ilya Sutskever, and GeoffreyÂ E Hinton.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Imagenet classification with deep convolutional neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Communications of the ACM</span><span id="bib.bib30.4.2" class="ltx_text" style="font-size:90%;">, 60(6):84â€“90, 2017.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Zhifeng Li, Dihong Gong, Qiang Li, Dacheng Tao, and Xuelong Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Mutual component analysis for heterogeneous face recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Transactions on Intelligent Systems and Technology (TIST)</span><span id="bib.bib31.4.2" class="ltx_text" style="font-size:90%;">,
7(3):1â€“23, 2016.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Zhifeng Li, Dihong Gong, Yu Qiao, and Dacheng Tao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Common feature discriminant analysis for matching infrared face
images to optical face images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions Image Process (TIP)</span><span id="bib.bib32.4.2" class="ltx_text" style="font-size:90%;">, 23(6):2436â€“2445, 2014.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Weiyang Liu, Yandong Wen, Zhiding Yu, Ming Li, Bhiksha Raj, and Le Song.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Sphereface: Deep hypersphere embedding for face recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib33.5.3" class="ltx_text" style="font-size:90%;">, pages 212â€“220, 2017.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Weiyang Liu, Yandong Wen, Zhiding Yu, and Meng Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Large-margin softmax loss for convolutional neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning (ICML)</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">,
volumeÂ 2, pageÂ 7, 2016.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Ziwei Liu, Zhongqi Miao, Xiaohang Zhan, Jiayun Wang, Boqing Gong, and StellaÂ X
Yu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Large-scale long-tailed recognition in an open world.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib35.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib35.5.3" class="ltx_text" style="font-size:90%;">, pages 2537â€“2546, 2019.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Mehdi Mirza and Simon Osindero.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Conditional generative adversarial nets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1411.1784</span><span id="bib.bib36.4.2" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Youssef Mroueh, Tom Sercu, and Vaibhava Goel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Mcgan: Mean and covariance feature matching gan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1702.08398</span><span id="bib.bib37.4.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Wanli Ouyang, Xiaogang Wang, Cong Zhang, and Xiaokang Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Factors in finetuning deep model for object detection with long-tail
distribution.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib38.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib38.5.3" class="ltx_text" style="font-size:90%;">, pages 864â€“873, 2016.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith
Chintala.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Pytorch: An imperative style, high-performance deep learning library.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text" style="font-size:90%;">In H. Wallach, H. Larochelle, A. Beygelzimer, F. d AlchÃ©-Buc, E.
Fox, and R. Garnett, editors, </span><span id="bib.bib39.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing
Systems (NeurIPS)</span><span id="bib.bib39.5.3" class="ltx_text" style="font-size:90%;">, pages 8024â€“8035. Curran Associates, Inc., 2019.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
Guo-Jun Qi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Loss-sensitive generative adversarial networks on lipschitz
densities.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">International Journal of Computer Vision (IJCV)</span><span id="bib.bib40.4.2" class="ltx_text" style="font-size:90%;">,
128(5):1118â€“1140, 2020.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
Haibo Qiu, Dihong Gong, Zhifeng Li, Wei Liu, and Dacheng Tao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">End2end occluded face recognition by masking corrupted features.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence
(TPAMI)</span><span id="bib.bib41.4.2" class="ltx_text" style="font-size:90%;">, pages 1â€“1, 2021.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
Alec Radford, Luke Metz, and Soumith Chintala.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">Unsupervised representation learning with deep convolutional
generative adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1511.06434</span><span id="bib.bib42.4.2" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
Elad Richardson, Matan Sela, and Ron Kimmel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">3d face reconstruction by learning from synthetic data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib43.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2016 fourth International Conference on 3D vision (3DV)</span><span id="bib.bib43.5.3" class="ltx_text" style="font-size:90%;">,
pages 460â€“469, 2016.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
Christos Sakaridis, Dengxin Dai, Simon Hecker, and Luc VanÂ Gool.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:90%;">Model adaptation with synthetic and real data for semantic dense
foggy scene understanding.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib44.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision (ECCV)</span><span id="bib.bib44.5.3" class="ltx_text" style="font-size:90%;">, pages
687â€“704, 2018.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text" style="font-size:90%;">
Swami Sankaranarayanan, Yogesh Balaji, Arpit Jain, Ser NamÂ Lim, and Rama
Chellappa.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.2.1" class="ltx_text" style="font-size:90%;">Learning from synthetic data: Addressing domain shift for semantic
segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib45.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib45.5.3" class="ltx_text" style="font-size:90%;">, pages 3752â€“3761, 2018.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text" style="font-size:90%;">
Florian Schroff, Dmitry Kalenichenko, and James Philbin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.2.1" class="ltx_text" style="font-size:90%;">Facenet: A unified embedding for face recognition and clustering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib46.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib46.5.3" class="ltx_text" style="font-size:90%;">, pages 815â€“823, 2015.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text" style="font-size:90%;">
Yujun Shen, Ping Luo, Junjie Yan, Xiaogang Wang, and Xiaoou Tang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.2.1" class="ltx_text" style="font-size:90%;">Faceid-gan: Learning a symmetry three-player gan for
identity-preserving face synthesis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib47.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib47.5.3" class="ltx_text" style="font-size:90%;">, pages 821â€“830, 2018.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text" style="font-size:90%;">
Karen Simonyan and Andrew Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.2.1" class="ltx_text" style="font-size:90%;">Very deep convolutional networks for large-scale image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1409.1556</span><span id="bib.bib48.4.2" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text" style="font-size:90%;">
Lingxue Song, Dihong Gong, Zhifeng Li, Changsong Liu, and Wei Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.2.1" class="ltx_text" style="font-size:90%;">Occlusion robust face recognition based on mask learning with
pairwise differential siamese network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib49.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE International Conference on Computer Vision (ICCV)</span><span id="bib.bib49.5.3" class="ltx_text" style="font-size:90%;">,
pages 773â€“782, 2019.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text" style="font-size:90%;">
Cecilia Summers and MichaelÂ J Dinneen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.2.1" class="ltx_text" style="font-size:90%;">Improved mixed-example data augmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib50.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Winter Conference on Applications of Computer Vision
(WACV)</span><span id="bib.bib50.5.3" class="ltx_text" style="font-size:90%;">, pages 1262â€“1270. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text" style="font-size:90%;">
Ryo Takahashi, Takashi Matsubara, and Kuniaki Uehara.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.2.1" class="ltx_text" style="font-size:90%;">Ricap: Random image cropping and patching data augmentation for deep
cnns.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib51.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Asian Conference on Machine Learning (ACML)</span><span id="bib.bib51.5.3" class="ltx_text" style="font-size:90%;">, pages 786â€“798.
PMLR, 2018.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text" style="font-size:90%;">
Zheng Tang, Milind Naphade, Stan Birchfield, Jonathan Tremblay, William Hodge,
Ratnesh Kumar, Shuo Wang, and Xiaodong Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.2.1" class="ltx_text" style="font-size:90%;">Pamtri: Pose-aware multi-task learning for vehicle re-identification
using highly randomized synthetic data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib52.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE International Conference on Computer Vision (ICCV)</span><span id="bib.bib52.5.3" class="ltx_text" style="font-size:90%;">,
pages 211â€“220, 2019.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text" style="font-size:90%;">
DanielÂ SÃ¡ez Trigueros, Li Meng, and Margaret Hartnett.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.2.1" class="ltx_text" style="font-size:90%;">Generating photo-realistic training data to improve face recognition
accuracy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1811.00112</span><span id="bib.bib53.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text" style="font-size:90%;">
Vikas Verma, Alex Lamb, Christopher Beckham, Amir Najafi, Ioannis Mitliagkas,
David Lopez-Paz, and Yoshua Bengio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.2.1" class="ltx_text" style="font-size:90%;">Manifold mixup: Better representations by interpolating hidden
states.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib54.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning (ICML)</span><span id="bib.bib54.5.3" class="ltx_text" style="font-size:90%;">, pages
6438â€“6447. PMLR, 2019.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text" style="font-size:90%;">
Fei Wang, Liren Chen, Cheng Li, Shiyao Huang, Yanjie Chen, Chen Qian, and Chen
ChangeÂ Loy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.2.1" class="ltx_text" style="font-size:90%;">The devil of face recognition is in the noise.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib55.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision (ECCV)</span><span id="bib.bib55.5.3" class="ltx_text" style="font-size:90%;">, pages
765â€“780, 2018.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text" style="font-size:90%;">
Hao Wang, Dihong Gong, Zhifeng Li, and Wei Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.2.1" class="ltx_text" style="font-size:90%;">Decorrelated adversarial learning for age-invariant face recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib56.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib56.5.3" class="ltx_text" style="font-size:90%;">, pages 3527â€“3536, 2019.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text" style="font-size:90%;">
Hao Wang, Yitong Wang, Zheng Zhou, Xing Ji, Dihong Gong, Jingchao Zhou, Zhifeng
Li, and Wei Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.2.1" class="ltx_text" style="font-size:90%;">Cosface: Large margin cosine loss for deep face recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib57.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib57.5.3" class="ltx_text" style="font-size:90%;">, pages 5265â€“5274, 2018.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock"><span id="bib.bib58.1.1" class="ltx_text" style="font-size:90%;">
Qi Wang, Junyu Gao, Wei Lin, and Yuan Yuan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.2.1" class="ltx_text" style="font-size:90%;">Learning from synthetic data for crowd counting in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib58.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib58.5.3" class="ltx_text" style="font-size:90%;">, pages 8198â€“8207, 2019.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text" style="font-size:90%;">
Xiaobo Wang, Shuo Wang, Jun Wang, Hailin Shi, and Tao Mei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.2.1" class="ltx_text" style="font-size:90%;">Co-mining: Deep face recognition with noisy labels.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib59.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE International Conference on Computer Vision (ICCV)</span><span id="bib.bib59.5.3" class="ltx_text" style="font-size:90%;">,
pages 9358â€“9367, 2019.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text" style="font-size:90%;">
Yitong Wang, Dihong Gong, Zheng Zhou, Xing Ji, Hao Wang, Zhifeng Li, Wei Liu,
and Tong Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.2.1" class="ltx_text" style="font-size:90%;">Orthogonal deep features decomposition for age-invariant face
recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib60.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision (ECCV)</span><span id="bib.bib60.5.3" class="ltx_text" style="font-size:90%;">, pages
738â€“753, 2018.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock"><span id="bib.bib61.1.1" class="ltx_text" style="font-size:90%;">
Yandong Wen, Kaipeng Zhang, Zhifeng Li, and Yu Qiao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.2.1" class="ltx_text" style="font-size:90%;">A discriminative feature learning approach for deep face recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib61.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision (ECCV)</span><span id="bib.bib61.5.3" class="ltx_text" style="font-size:90%;">, pages
499â€“515. Springer, 2016.
</span>
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text" style="font-size:90%;">
Minghao Xu, Jian Zhang, Bingbing Ni, Teng Li, Chengjie Wang, Qi Tian, and
Wenjun Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.2.1" class="ltx_text" style="font-size:90%;">Adversarial domain adaptation with domain mixup.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib62.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI Conference on Artificial Intelligence (AAAI)</span><span id="bib.bib62.5.3" class="ltx_text" style="font-size:90%;">,
volumeÂ 34, pages 6502â€“6509, 2020.
</span>
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock"><span id="bib.bib63.1.1" class="ltx_text" style="font-size:90%;">
Xiaolong Yang, Xiaohong Jia, Dihong Gong, Dong-Ming Yan, Zhifeng Li, and Wei
Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.2.1" class="ltx_text" style="font-size:90%;">Larnet: Lie algebra residual network for face recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib63.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning (ICML)</span><span id="bib.bib63.5.3" class="ltx_text" style="font-size:90%;">, pages
11738â€“11750. PMLR, 2021.
</span>
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock"><span id="bib.bib64.1.1" class="ltx_text" style="font-size:90%;">
Dong Yi, Zhen Lei, Shengcai Liao, and StanÂ Z Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.2.1" class="ltx_text" style="font-size:90%;">Learning face representation from scratch.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1411.7923</span><span id="bib.bib64.4.2" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock"><span id="bib.bib65.1.1" class="ltx_text" style="font-size:90%;">
Xi Yin, Xiang Yu, Kihyuk Sohn, Xiaoming Liu, and Manmohan Chandraker.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.2.1" class="ltx_text" style="font-size:90%;">Towards large-pose face frontalization in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib65.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE International Conference on Computer Vision (ICCV)</span><span id="bib.bib65.5.3" class="ltx_text" style="font-size:90%;">,
pages 3990â€“3999, 2017.
</span>
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock"><span id="bib.bib66.1.1" class="ltx_text" style="font-size:90%;">
Baosheng Yu, Tongliang Liu, Mingming Gong, Changxing Ding, and Dacheng Tao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.2.1" class="ltx_text" style="font-size:90%;">Correcting the triplet selection bias for triplet loss.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib66.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision (ECCV), Munich,
Germany</span><span id="bib.bib66.5.3" class="ltx_text" style="font-size:90%;">, pages 71â€“87, September 08-14, 2018.
</span>
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock"><span id="bib.bib67.1.1" class="ltx_text" style="font-size:90%;">
Baosheng Yu and Dacheng Tao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib67.2.1" class="ltx_text" style="font-size:90%;">Deep metric learning with tuplet margin loss.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib67.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib67.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE International Conference on Computer Vision (ICCV),
Seoul, Korea</span><span id="bib.bib67.5.3" class="ltx_text" style="font-size:90%;">, pages 6490â€“6499, October 27-November 02, 2019.
</span>
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock"><span id="bib.bib68.1.1" class="ltx_text" style="font-size:90%;">
Hongyi Zhang, Moustapha Cisse, YannÂ N Dauphin, and David Lopez-Paz.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib68.2.1" class="ltx_text" style="font-size:90%;">mixup: Beyond empirical risk minimization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib68.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1710.09412</span><span id="bib.bib68.4.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock"><span id="bib.bib69.1.1" class="ltx_text" style="font-size:90%;">
Jiangning Zhang, Xianfang Zeng, Mengmeng Wang, Yusu Pan, Liang Liu, Yong Liu,
Yu Ding, and Changjie Fan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib69.2.1" class="ltx_text" style="font-size:90%;">Freenet: Multi-identity face reenactment.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib69.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib69.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib69.5.3" class="ltx_text" style="font-size:90%;">, pages 5326â€“5335, 2020.
</span>
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock"><span id="bib.bib70.1.1" class="ltx_text" style="font-size:90%;">
Kaipeng Zhang, Zhanpeng Zhang, Zhifeng Li, and Yu Qiao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib70.2.1" class="ltx_text" style="font-size:90%;">Joint face detection and alignment using multitask cascaded
convolutional networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib70.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Signal Processing Letters</span><span id="bib.bib70.4.2" class="ltx_text" style="font-size:90%;">, 23(10):1499â€“1503, 2016.
</span>
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock"><span id="bib.bib71.1.1" class="ltx_text" style="font-size:90%;">
Wenchao Zhang, Shiguang Shan, Xilin Chen, and Wen Gao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib71.2.1" class="ltx_text" style="font-size:90%;">Local Gabor binary patterns based on Kullback - Leibler
divergence for partially occluded face recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib71.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Signal Processing Letters</span><span id="bib.bib71.4.2" class="ltx_text" style="font-size:90%;">, 14(11):875â€“878, 2007.
</span>
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock"><span id="bib.bib72.1.1" class="ltx_text" style="font-size:90%;">
Xiangxin Zhu, Dragomir Anguelov, and Deva Ramanan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib72.2.1" class="ltx_text" style="font-size:90%;">Capturing long-tail distributions of object subcategories.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib72.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib72.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib72.5.3" class="ltx_text" style="font-size:90%;">, pages 915â€“922, 2014.
</span>
</span>
</li>
</ul>
</section>
<figure id="Sx1.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="Sx1.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2108.07960/assets/x8.png" id="Sx1.F8.sf1.g1" class="ltx_graphics ltx_img_landscape" width="221" height="172" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>CASIA-WebFace</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="Sx1.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2108.07960/assets/x9.png" id="Sx1.F8.sf2.g1" class="ltx_graphics ltx_img_landscape" width="221" height="172" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Syn_10K_50</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Comparison of real and synthetic face images. Each row indicates the same person with different face images. Obviously, comparing the real-world dataset, the synthetic dataset significantly lacks of the intra-class variations.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p">In this appendix, we illustrate plenty of face images (from both Syn_10K_50 and CASIA-WebFace) to further demonstrate our observations: 1) the synthetic dataset usually lacks of intra-class variations which significantly degrades the performance (Appendix.Â <a href="#A1" title="Appendix A Intra-class Variations â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>), and 2) the generated face images have limited diversity on facial expressions which are mainly â€œsmilingâ€ with slight differences (Appendix.Â <a href="#A2" title="Appendix B Expression Diversity â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>).</p>
</div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Intra-class Variations</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.2" class="ltx_p">Recalling that there is a clear performance gap (<math id="A1.p1.1.m1.1" class="ltx_Math" alttext="88.98\%" display="inline"><semantics id="A1.p1.1.m1.1a"><mrow id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml"><mn id="A1.p1.1.m1.1.1.2" xref="A1.p1.1.m1.1.1.2.cmml">88.98</mn><mo id="A1.p1.1.m1.1.1.1" xref="A1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.1b"><apply id="A1.p1.1.m1.1.1.cmml" xref="A1.p1.1.m1.1.1"><csymbol cd="latexml" id="A1.p1.1.m1.1.1.1.cmml" xref="A1.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="A1.p1.1.m1.1.1.2.cmml" xref="A1.p1.1.m1.1.1.2">88.98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.1c">88.98\%</annotation></semantics></math> <em id="A1.p1.2.1" class="ltx_emph ltx_font_italic">vs</em>.<span id="A1.p1.2.2" class="ltx_text"></span> <math id="A1.p1.2.m2.1" class="ltx_Math" alttext="99.18\%" display="inline"><semantics id="A1.p1.2.m2.1a"><mrow id="A1.p1.2.m2.1.1" xref="A1.p1.2.m2.1.1.cmml"><mn id="A1.p1.2.m2.1.1.2" xref="A1.p1.2.m2.1.1.2.cmml">99.18</mn><mo id="A1.p1.2.m2.1.1.1" xref="A1.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.2.m2.1b"><apply id="A1.p1.2.m2.1.1.cmml" xref="A1.p1.2.m2.1.1"><csymbol cd="latexml" id="A1.p1.2.m2.1.1.1.cmml" xref="A1.p1.2.m2.1.1.1">percent</csymbol><cn type="float" id="A1.p1.2.m2.1.1.2.cmml" xref="A1.p1.2.m2.1.1.2">99.18</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.2.m2.1c">99.18\%</annotation></semantics></math>) on LFWÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> between SynFace and RealFace. We notice that the fundamental purpose of face synthesis model (<em id="A1.p1.2.3" class="ltx_emph ltx_font_italic">e.g</em>.<span id="A1.p1.2.4" class="ltx_text"></span>, DiscoFaceGANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>) is to generate high-quality and clean face images, while the face recognition model is usually required to recognize those face images in the wild (<em id="A1.p1.2.5" class="ltx_emph ltx_font_italic">e.g</em>.<span id="A1.p1.2.6" class="ltx_text"></span>, LFWÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>) with complex conditions. Therefore, this kind of domain gap leads to the model trained on synthetic data intrinsically lacking well generalization ability.</p>
</div>
<div id="A1.p2" class="ltx_para">
<p id="A1.p2.2" class="ltx_p">Then we explore the potential factors which are responsible for the simplicity of Syn_10K_50. FigureÂ <a href="#Sx1.F8" title="Figure 8 â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> demonstrates multiple face images of different people from both CASIA-WebFace (FigureÂ <a href="#Sx1.F8.sf1" title="In Figure 8 â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8a</span></a>) and Syn_10K_50 (FigureÂ <a href="#Sx1.F8.sf2" title="In Figure 8 â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8b</span></a>), in which face images of one row belong to the same person. As we can observe, the variations of real face images are clearly larger than the synthetic images. For example, comparing to the synthetic face images, the real face images in the wild usually have the large motion blur and illumination variations. If we augment the synthetic face images with the ColorJitter transformation in PyTorch and MotionBlur from AlbumentationsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> for training, the face recognition performance is boosted from <math id="A1.p2.1.m1.1" class="ltx_Math" alttext="88.98\%" display="inline"><semantics id="A1.p2.1.m1.1a"><mrow id="A1.p2.1.m1.1.1" xref="A1.p2.1.m1.1.1.cmml"><mn id="A1.p2.1.m1.1.1.2" xref="A1.p2.1.m1.1.1.2.cmml">88.98</mn><mo id="A1.p2.1.m1.1.1.1" xref="A1.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.p2.1.m1.1b"><apply id="A1.p2.1.m1.1.1.cmml" xref="A1.p2.1.m1.1.1"><csymbol cd="latexml" id="A1.p2.1.m1.1.1.1.cmml" xref="A1.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="A1.p2.1.m1.1.1.2.cmml" xref="A1.p2.1.m1.1.1.2">88.98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.1.m1.1c">88.98\%</annotation></semantics></math> to <math id="A1.p2.2.m2.1" class="ltx_Math" alttext="91.23\%" display="inline"><semantics id="A1.p2.2.m2.1a"><mrow id="A1.p2.2.m2.1.1" xref="A1.p2.2.m2.1.1.cmml"><mn id="A1.p2.2.m2.1.1.2" xref="A1.p2.2.m2.1.1.2.cmml">91.23</mn><mo id="A1.p2.2.m2.1.1.1" xref="A1.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.p2.2.m2.1b"><apply id="A1.p2.2.m2.1.1.cmml" xref="A1.p2.2.m2.1.1"><csymbol cd="latexml" id="A1.p2.2.m2.1.1.1.cmml" xref="A1.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="A1.p2.2.m2.1.1.2.cmml" xref="A1.p2.2.m2.1.1.2">91.23</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.2.m2.1c">91.23\%</annotation></semantics></math>. Hence, we conclude that the lack of intra-class variations by synthetic dataset leads to its simplicity which significantly degrades the face recognition performance.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Expression Diversity</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">We randomly select three classes from the â€œExpressionâ€ dataset (which means only varying the facial expression of face images while fixing the other attributes) and visualize all the samples (<math id="A2.p1.1.m1.1" class="ltx_Math" alttext="50" display="inline"><semantics id="A2.p1.1.m1.1a"><mn id="A2.p1.1.m1.1.1" xref="A2.p1.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="A2.p1.1.m1.1b"><cn type="integer" id="A2.p1.1.m1.1.1.cmml" xref="A2.p1.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.1.m1.1c">50</annotation></semantics></math> images per identity) in FigureÂ <a href="#A2.F9" title="Figure 9 â€£ Appendix B Expression Diversity â€£ SynFace: Face Recognition with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. Apparently, the differences of images inside the same class are marginal and only reflected by the mouth variations, which reveal the limited expression diversity of â€œExpressionâ€ that is responsible for the worst performance. We conjecture that the 3D priors from 3DMMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> and the training images from web lack of the expression variations, which result in the limited expression diversity of synthetic face images generated by DiscoFaceFANÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<figure id="A2.F9" class="ltx_figure"><img src="/html/2108.07960/assets/x10.png" id="A2.F9.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="380" height="671" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Visualizations of all the samples from three different classes. The generated expressions of face images are mainly â€œsmilingâ€ despite of slight differences, which reveals the limited expression diversity of â€œExpressionâ€.</figcaption>
</figure>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2108.07959" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2108.07960" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2108.07960">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2108.07960" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2108.07961" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar 19 10:33:40 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
