<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2310.03178] Digital Ethics in Federated Learning</title><meta property="og:description" content="The Internet of Things (IoT) consistently generates vast amounts of data, sparking increasing concern over the protection of data privacy and the limitation of data misuse. Federated learning (FL) facilitates collabora…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Digital Ethics in Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Digital Ethics in Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2310.03178">

<!--Generated on Wed Feb 28 02:42:58 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Digital Ethics in Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Liangqi Yuan, ,
Ziran Wang, , and
Christopher G. Brinton
</span><span class="ltx_author_notes">Manuscript received August 31, 2023.L. Yuan, Z. Wang, and C. G. Brinton are with the College of Engineering, Purdue University, West Lafayette, IN 47907, USA (e-mails: liangqiy@purdue.edu; ryanwang11@hotmail.com, cgb@purdue.edu).</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">The Internet of Things (IoT) consistently generates vast amounts of data, sparking increasing concern over the protection of data privacy and the limitation of data misuse. Federated learning (FL) facilitates collaborative capabilities among multiple parties by sharing machine learning (ML) model parameters instead of raw user data, and it has recently gained significant attention for its potential in privacy preservation and learning efficiency enhancement. In this paper, we highlight the digital ethics concerns that arise when human-centric devices serve as clients in FL. More specifically, challenges of game dynamics, fairness, incentive, and continuity arise in FL due to differences in perspectives and objectives between clients and the server. We analyze these challenges and their solutions from the perspectives of both the client and the server, and through the viewpoints of centralized and decentralized FL. Finally, we explore the opportunities in FL for human-centric IoT as directions for future development.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The Internet of Things (IoT) encompasses a phenomenon where physical devices, embedded with sensors, interact with their surroundings and engage in data exchange with other devices and systems via the Internet. These devices cover a vast range, from compact thermostats to large-scale industrial machinery, all interconnected within the IoT infrastructure. The human-centric IoT applications focus on devices within the IoT ecosystem that are designed to focus on human interaction or significantly influenced by human factors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, such as smartphones, wearable devices, vehicles, and healthcare appliances. These devices, through their diverse sensors, incessantly produce a wealth of highly sensitive data. For example, images taken by smartphones can contain global positioning systems (GPS) location information, smartwatches can detect a user’s electrocardiogram (ECG), and vehicle navigation systems document a driver’s routes. Certain companies might require customers to disclose such rich personal data to improve their machine learning (ML) models. The growing demand for data invariably raises concerns over potential privacy breaches and misuse of associated data, introducing pressing digital ethics issues in our interconnected digital era, such as privacy, security, and fairness.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Federated learning (FL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> represents a decentralized learning paradigm, designed to facilitate multi-party collaboration while safeguarding user privacy. Its essence lies in sharing ML models rather than raw user data, achieving privacy preservation. Moreover, with the exponential growth of users and their data, the transmission and storage of vast amounts of raw data pose significant challenges for communication channels and server storage. FL can also be perceived as a form of knowledge distillation, distilling knowledge from raw data into model parameters to alleviate communication overhead. In line with the presence or absence of a server for coordination, management, and aggregation, FL can be categorized into two frameworks: centralized FL (CFL) and decentralized FL (DFL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Initially proposed by Google researchers and deployed in the Google keyboard for cooperative learning in keyboard input recommendation models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, FL has found extensive applications in numerous sectors, such as healthcare, mobile services, and intelligent transportation systems, facilitating collaboration amongst widely distributed edge devices or institutions.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2310.03178/assets/Figure/Ethics.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="417" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The human-centric Internet of Things (IoT) applications within the (a) centralized federated learning (CFL) and (b) decentralized federated learning (DFL) frameworks.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">FL presents a powerful approach for mitigating privacy concerns inherent in collaborative ML. However, digital ethical concerns extending beyond privacy are often overlooked <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, especially within the context of the human-centric IoT. Notably, most existing research inadequately addresses ethical considerations from the narrow perspective of the client side. For example, users of applications like Google Keyboard may remain oblivious to or unconcerned about the underlying FL algorithms. Their primary concern is that they are contributing their model but not receiving highly accurate personalized recommendations in return. This disparity in expectations can breed disappointment and potentially lead to a discontinuation of use. Consequently, human emotions may emerge as a vital factor in ensuring the continuity and longevity of FL frameworks in these contexts.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this paper, we present a discourse on the digital ethical issues arising within both CFL and DFL deployments in human-centric IoT applications, as depicted in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Digital Ethics in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. We illustrate the FL lifeline in Fig. <a href="#S1.F2" title="Figure 2 ‣ I Introduction ‣ Digital Ethics in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, encompassing two trajectories, namely human-centric IoT and the digital ethics of FL. Apart from user privacy, people are generally concerned about fairness, interpretability, accountability, transparency, and other aspects. Additionally, issues related to user management, incentives, penalties, continuity, and compatibility with new users are important considerations in FL systems. In addition to pursuing higher performance and convergence in ML and optimizing communication networks, there is also a growing interest in the social, psychological, and economic aspects of FL, among others.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The organization of this paper is as follows: First, we provide an in-depth examination of the definitions and perspectives of clients and the server, as well as the underlying reasons for the game dynamic relationship that arises between the CFL and DFL frameworks (Sec. <a href="#S2" title="II Variance of Perspectives ‣ Digital Ethics in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>). The discrepancies, limitations, and information asymmetry between clients and the server, especially the fundamental difference in their objectives, inevitably give rise to a game dynamic (Sec. <a href="#S3" title="III Game Dynamics ‣ Digital Ethics in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>). Subsequently, the resultant trust issues emerging from divergent objectives appear specifically as client skepticism towards the fairness of the FL framework (Sec. <a href="#S4" title="IV Fairness ‣ Digital Ethics in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>). Notably, the difference in perspective also leads to varied definitions of fairness between clients and the server. Adjacent to the issue of fairness is the problem of incentive mechanisms for clients (Sec. <a href="#S5" title="V Incentives ‣ Digital Ethics in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a>). Beyond the extensively researched server-led incentive mechanisms, we discuss the potential for a reputation system, established by the client community, to become one of the primary mechanisms in DFL. Alongside fairness and incentives, we also touch upon the continuity of FL’s development and updates (Sec. <a href="#S6" title="VI Continuity ‣ Digital Ethics in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>). Based on these four properties (i.e., game dynamics, fairness, incentives, and continuity), we proceed to discuss opportunities to foster the continuous, active, and positive development of FL (Sec. <a href="#S7" title="VII Opportunities ‣ Digital Ethics in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VII</span></a>). Finally, we draw conclusions from this paper (Sec. <a href="#S8" title="VIII Conclusion ‣ Digital Ethics in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VIII</span></a>).</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2310.03178/assets/Figure/Roadmap.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="233" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Lifeline of digital ethics and the human-centric Internet of Things (IoT) applications in federated learning (FL).</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Variance of Perspectives</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Within FL, different roles possess distinct perspectives and varied levels of knowledge. The core of the game dynamics in FL stems from the differences in clients’ contributions (e.g., the volume of raw data), the learning process, and the information asymmetry among participants.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">Omniscient (Authors’ and Readers’) Perspective</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Currently, a significant portion of research papers on FL tends to overlook the information asymmetry between clients and servers. They often adopt an idealized perspective, optimizing FL based on the assumption of complete and perfect knowledge. These design methods, founded on the notion of omniscient information, fail to address the practical challenges that arise from limited information exchange, client data heterogeneity, and potential trust issues. Recognizing and considering the scenarios of information asymmetry are crucial for developing effective FL systems.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">Server’s Perspective</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">In CFL, the role of the server is to receive model parameters from all clients, aggregate them, and then redistribute the aggregated model. The server, however, remains oblivious to how clients collect data, train models, and handle the post-processing of models. Some CFL frameworks make presumptions that the server is privy to more extensive metadata from clients. For example, in the case of FedAvg, each client not only sends their model parameters but also transmits the volume of their local raw data. This additional metadata allows the server to perform weighted averaging. Therefore, in CFL, the resources or perspectives available to the server can be summarized as previously aggregated models, current and past models from clients, and other metadata that clients are asked to send, such as volume of raw data, performance on local test sets, losses, training epochs, etc.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.4.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.5.2" class="ltx_text ltx_font_italic">Clients’ Perspective</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Considering the perspective of the clients, we discuss the contexts of both CFL and DFL frameworks, as illustrated in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Digital Ethics in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">In CFL, clients are oblivious to each other’s information, such as the number of clients, the volume of raw data each client holds, the learning process, and the model performance of each. In specific FL scenarios, for example, when healthcare institutions act as clients for FL, the components such as optimizers, loss functions, learning rates, and training epochs differ from client to client. Additionally, clients lack knowledge about the server-side details, like the aggregation method employed by the server. Hence, in a CFL framework, the only available information for each client is the aggregated model received from the server.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">In DFL, clients directly share models without the coordination of a server. For example, in a fully connected network topology, every client within the DFL framework needs to transmit their own model parameters to all other clients, and reciprocally receive models from them. As a result, a certain framework, such as network topology, communication direction, frequency, and so forth, needs to be agreed upon among clients. They also need to be cognizant of certain information about other clients, like their addresses and ports. Additionally, some extra metadata, such as the volume of raw data, number of clients, model versions, etc., might also be transmitted as per the requirement. Therefore, in DFL, for the system to function correctly, clients need to establish a communication protocol among themselves and are required to directly disclose their local information to other clients.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Definition of Digital Ethics for Client and Server in CFL and DFL</figcaption>
<table id="S2.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S2.T1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_tt"></td>
<td id="S2.T1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S2.T1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.2.1.1" class="ltx_p" style="width:70.0pt;"><span id="S2.T1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Perspective</span></span>
</span>
</td>
<td id="S2.T1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S2.T1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.3.1.1" class="ltx_p" style="width:65.0pt;"><span id="S2.T1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Game Dynamics (Objective)</span></span>
</span>
</td>
<td id="S2.T1.1.1.4" class="ltx_td ltx_align_justify ltx_border_r ltx_border_tt">
<span id="S2.T1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.4.1.1" class="ltx_p"><span id="S2.T1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Fairness</span></span>
</span>
</td>
<td id="S2.T1.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S2.T1.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.5.1.1" class="ltx_p" style="width:95.0pt;"><span id="S2.T1.1.1.5.1.1.1" class="ltx_text ltx_font_bold">Incentives</span></span>
</span>
</td>
<td id="S2.T1.1.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S2.T1.1.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.6.1.1" class="ltx_p" style="width:85.0pt;"><span id="S2.T1.1.1.6.1.1.1" class="ltx_text ltx_font_bold">Continuity</span></span>
</span>
</td>
</tr>
<tr id="S2.T1.1.2" class="ltx_tr">
<td id="S2.T1.1.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="6"><span id="S2.T1.1.2.1.1" class="ltx_text ltx_font_bold">Centralized Federated Learning</span></td>
</tr>
<tr id="S2.T1.1.3" class="ltx_tr">
<td id="S2.T1.1.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S2.T1.1.3.1.1" class="ltx_text ltx_font_bold">Omniscient</span></td>
<td id="S2.T1.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.3.2.1.1" class="ltx_p" style="width:70.0pt;">Everything</span>
</span>
</td>
<td id="S2.T1.1.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.3.3.1.1" class="ltx_p" style="width:65.0pt;">Generalized and personalized model</span>
</span>
</td>
<td id="S2.T1.1.3.4" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S2.T1.1.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.3.4.1.1" class="ltx_p">Fairness-aware strategy</span>
</span>
</td>
<td id="S2.T1.1.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.3.5.1.1" class="ltx_p" style="width:95.0pt;">Incentive mechanism design</span>
</span>
</td>
<td id="S2.T1.1.3.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.3.6.1.1" class="ltx_p" style="width:85.0pt;">Server Management Enhancement</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.4" class="ltx_tr">
<td id="S2.T1.1.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S2.T1.1.4.1.1" class="ltx_text ltx_font_bold">Server</span></td>
<td id="S2.T1.1.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.4.2.1.1" class="ltx_p" style="width:70.0pt;">Models and information from the clients</span>
</span>
</td>
<td id="S2.T1.1.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.4.3.1.1" class="ltx_p" style="width:65.0pt;">Generalized model</span>
</span>
</td>
<td id="S2.T1.1.4.4" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S2.T1.1.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.4.4.1.1" class="ltx_p">Overall accuracy is highest</span>
</span>
</td>
<td id="S2.T1.1.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.4.5.1.1" class="ltx_p" style="width:95.0pt;">Revenue, market share, available generalized models</span>
</span>
</td>
<td id="S2.T1.1.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.4.6.1.1" class="ltx_p" style="width:85.0pt;">Management of clients and models</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.5" class="ltx_tr">
<td id="S2.T1.1.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S2.T1.1.5.1.1" class="ltx_text ltx_font_bold">Client</span></td>
<td id="S2.T1.1.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.5.2.1.1" class="ltx_p" style="width:70.0pt;">Model from the server</span>
</span>
</td>
<td id="S2.T1.1.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.5.3.1.1" class="ltx_p" style="width:65.0pt;">Personalized model</span>
</span>
</td>
<td id="S2.T1.1.5.4" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S2.T1.1.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.5.4.1.1" class="ltx_p">Local accuracy is highest</span>
</span>
</td>
<td id="S2.T1.1.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.5.5.1.1" class="ltx_p" style="width:95.0pt;">Rewards, punishments, and model updates</span>
</span>
</td>
<td id="S2.T1.1.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.5.6.1.1" class="ltx_p" style="width:85.0pt;">Compliance with server management</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.6" class="ltx_tr">
<td id="S2.T1.1.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="6"><span id="S2.T1.1.6.1.1" class="ltx_text ltx_font_bold">Decentralized Federated Learning</span></td>
</tr>
<tr id="S2.T1.1.7" class="ltx_tr">
<td id="S2.T1.1.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S2.T1.1.7.1.1" class="ltx_text ltx_font_bold">Omniscient</span></td>
<td id="S2.T1.1.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.7.2.1.1" class="ltx_p" style="width:70.0pt;">Everything</span>
</span>
</td>
<td id="S2.T1.1.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.7.3.1.1" class="ltx_p" style="width:65.0pt;">Generalized and personalized model</span>
</span>
</td>
<td id="S2.T1.1.7.4" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S2.T1.1.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.7.4.1.1" class="ltx_p">Fairness-aware strategy</span>
</span>
</td>
<td id="S2.T1.1.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.7.5.1.1" class="ltx_p" style="width:95.0pt;">Incentive mechanism design</span>
</span>
</td>
<td id="S2.T1.1.7.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.7.6.1.1" class="ltx_p" style="width:85.0pt;">Encouraging spontaneous management by clients</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.8" class="ltx_tr">
<td id="S2.T1.1.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S2.T1.1.8.1.1" class="ltx_text ltx_font_bold">Server</span></td>
<td id="S2.T1.1.8.2" class="ltx_td ltx_align_center ltx_align_top ltx_border_r ltx_border_t" colspan="5">N/A</td>
</tr>
<tr id="S2.T1.1.9" class="ltx_tr">
<td id="S2.T1.1.9.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_l ltx_border_r ltx_border_t"><span id="S2.T1.1.9.1.1" class="ltx_text ltx_font_bold">Client</span></td>
<td id="S2.T1.1.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S2.T1.1.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.9.2.1.1" class="ltx_p" style="width:70.0pt;">Model from other clients</span>
</span>
</td>
<td id="S2.T1.1.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S2.T1.1.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.9.3.1.1" class="ltx_p" style="width:65.0pt;">Personalized model</span>
</span>
</td>
<td id="S2.T1.1.9.4" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t">
<span id="S2.T1.1.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.9.4.1.1" class="ltx_p">Local accuracy is highest</span>
</span>
</td>
<td id="S2.T1.1.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S2.T1.1.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.9.5.1.1" class="ltx_p" style="width:95.0pt;">Exposure, reputation, and model updates</span>
</span>
</td>
<td id="S2.T1.1.9.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S2.T1.1.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.9.6.1.1" class="ltx_p" style="width:85.0pt;">Identify, accuse, and report malicious clients</span>
</span>
</td>
</tr>
</table>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Game Dynamics</span>
</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Why Game Dynamic Emerge?</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Compared with distributed learning that assigns tasks to nodes or miners, FL inherently emphasizes more on the data-generating clients. Governed by these data-holding clients, and propelled by self-interest and greed, the inclination towards selfish behavior and a lack of trust in others could surface. This drives the dynamics of interaction among clients in a game dynamics context, where each seeks to maximize personal gains.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">This dynamic is primarily attributed to significant data heterogeneity among clients, where the server-aggregated model may not exhibit exceptional performance on all clients. Firstly, inter-group heterogeneity exists among clients. For example, professionals such as professors, doctors, and lawyers using Google Keyboard would require highly tailored recommendations due to their distinctive fields of expertise. Secondly, intra-group heterogeneity exists within each group of users, wherein each user’s academic discipline, level of knowledge, years of expertise, and other factors vary. Lastly, system heterogeneity among clients arises from variations in IoT devices, which includes disparities among sensor and instrument manufacturers, differences in software versions of devices, and varying user operations.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Game Dynamics between Client and Server</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">In CFL, clients and the server share similar yet fundamentally different objectives: clients aim to achieve the best-performing personalized model on their local dataset, while the server seeks to achieve the best average-performing general model across all clients. While this setup can be mutually beneficial, a game dynamics relationship emerges between the clients and the server due to the trade-off between personalized performance and generalization.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Personalized FL represents a potential solution to mitigating the game dynamics between clients and the server, as it seeks to satisfy the objectives of both parties <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. There are two main strategies in this context: client compromise and server compromise. In the case of client compromise, a simplistic implementation would involve the client performing additional gradient descent upon receiving the generalized global model (i.e., meta-learning), thus achieving personalized expansion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Conversely, in server compromise, a common practice is clustered FL. In this scenario, the server can create multiple aggregated global models based on the nature of the clients or clustering of client models, with even the potential for multiple servers to partition different regions for aggregation (i.e., hierarchical FL). Regardless of whether it is client compromise or server compromise, these strategies both entail additional overheads, such as computation, communication, and storage.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.4.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.5.2" class="ltx_text ltx_font_italic">Game Dynamics among Clients</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In DFL, despite the symmetric roles of clients in communication and knowledge propagation, competition can still emerge due to data heterogeneity and system heterogeneity. They all share the same but conflicting objective of striving for the best model performance on their respective local data sets. However, given the data heterogeneity among clients, it is more common that the models from other clients perform poorly on their local dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">Analogous to the two compromise strategies in CFL, DFL also incorporates similar personalized methods to enhance the performance of aggregated models on clients’ local data sets. Apart from model post-processing methods such as meta-learning, DFL can reduce data heterogeneity among clients within a cluster by establishing different topological structures, mimicking the clustered FL. In particular, in real-world DFL scenarios, clients might prefer freely forming their clusters and establishing DFL network topologies among similar and familiar populations, such as city clusters and suburb clusters determined by geographical locations. These more flexible and customizable network topologies, although more challenging to establish initially, also confer more personalized and trustworthy DFL with communication cost advantages.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span>State-of-the-art technologies, strategies, and mechanisms</figcaption>
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T2.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_tt">
<span id="S3.T2.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.1.1.1" class="ltx_p" style="width:60.0pt;"><span id="S3.T2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Issue</span></span>
</span>
</td>
<td id="S3.T2.1.1.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_tt">
<span id="S3.T2.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.2.1.1" class="ltx_p"><span id="S3.T2.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Definition</span></span>
</span>
</td>
<td id="S3.T2.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S3.T2.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.3.1.1" class="ltx_p" style="width:250.0pt;"><span id="S3.T2.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Technologies, strategies, and mechanisms</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.2" class="ltx_tr">
<td id="S3.T2.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.2.1.1.1" class="ltx_p" style="width:60.0pt;"><span id="S3.T2.1.2.1.1.1.1" class="ltx_text ltx_font_bold">Game Dynamics (Objective)</span></span>
</span>
</td>
<td id="S3.T2.1.2.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S3.T2.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.2.2.1.1" class="ltx_p">Divergent objectives amongst clients and server</span>
</span>
</td>
<td id="S3.T2.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.2.3.1.1" class="ltx_p" style="width:250.0pt;">
<span id="S3.T2.1.2.3.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_top" style="width:433.6pt;">
<span id="S3.I1" class="ltx_itemize">
<span id="S3.I1.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I1.i1.p1" class="ltx_para">
<span id="S3.I1.i1.p1.1" class="ltx_p">Personalized FL</span>
<span id="S3.I1.i1.I1" class="ltx_itemize">
<span id="S3.I1.i1.I1.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="S3.I1.i1.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<span id="S3.I1.i1.I1.i1.p1" class="ltx_para">
<span id="S3.I1.i1.I1.i1.p1.1" class="ltx_p">Server compromise (e.g., clustering, knowledge distillation)</span>
</span></span>
<span id="S3.I1.i1.I1.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="S3.I1.i1.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<span id="S3.I1.i1.I1.i2.p1" class="ltx_para">
<span id="S3.I1.i1.I1.i2.p1.1" class="ltx_p">Client compromise (e.g., meta-learning, data augmentation)</span>
</span></span>
</span>
</span></span>
</span>
</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.3" class="ltx_tr">
<td id="S3.T2.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.3.1.1.1" class="ltx_p" style="width:60.0pt;"><span id="S3.T2.1.3.1.1.1.1" class="ltx_text ltx_font_bold">Fairness</span></span>
</span>
</td>
<td id="S3.T2.1.3.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S3.T2.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.3.2.1.1" class="ltx_p">Contribution and performance distribution among clients</span>
</span>
</td>
<td id="S3.T2.1.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.3.3.1.1" class="ltx_p" style="width:250.0pt;">
<span id="S3.T2.1.3.3.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_top" style="width:433.6pt;">
<span id="S3.I2" class="ltx_itemize">
<span id="S3.I2.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I2.i1.p1" class="ltx_para">
<span id="S3.I2.i1.p1.1" class="ltx_p">Averaging (i.e., arithmetic mean)</span>
</span></span>
<span id="S3.I2.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I2.i2.p1" class="ltx_para">
<span id="S3.I2.i2.p1.1" class="ltx_p">Weighted averaging (e.g., FedAvg is based on sample volume)</span>
</span></span>
<span id="S3.I2.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I2.i3.p1" class="ltx_para">
<span id="S3.I2.i3.p1.1" class="ltx_p">Post-processing (e.g., personalized CFL)</span>
</span></span>
</span>
</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.4" class="ltx_tr">
<td id="S3.T2.1.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.4.1.1.1" class="ltx_p" style="width:60.0pt;"><span id="S3.T2.1.4.1.1.1.1" class="ltx_text ltx_font_bold">Incentives</span></span>
</span>
</td>
<td id="S3.T2.1.4.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S3.T2.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.4.2.1.1" class="ltx_p">Clients contribute honestly, actively, and positively</span>
</span>
</td>
<td id="S3.T2.1.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.4.3.1.1" class="ltx_p" style="width:250.0pt;">
<span id="S3.T2.1.4.3.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_top" style="width:433.6pt;">
<span id="S3.I3" class="ltx_itemize">
<span id="S3.I3.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I3.i1.p1" class="ltx_para">
<span id="S3.I3.i1.p1.1" class="ltx_p">Feedback (e.g., aggregated model)</span>
</span></span>
<span id="S3.I3.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I3.i2.p1" class="ltx_para">
<span id="S3.I3.i2.p1.1" class="ltx_p">Reward (e.g., sponsorship, subscription)</span>
</span></span>
<span id="S3.I3.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I3.i3.p1" class="ltx_para">
<span id="S3.I3.i3.p1.1" class="ltx_p">Reputation (e.g., like, follow, share)</span>
</span></span>
</span>
</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.5" class="ltx_tr">
<td id="S3.T2.1.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.5.1.1.1" class="ltx_p" style="width:60.0pt;"><span id="S3.T2.1.5.1.1.1.1" class="ltx_text ltx_font_bold">Continuity</span></span>
</span>
</td>
<td id="S3.T2.1.5.2" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t">
<span id="S3.T2.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.5.2.1.1" class="ltx_p">FL maintains its operations and efficiency to prolong its lifecycle</span>
</span>
</td>
<td id="S3.T2.1.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S3.T2.1.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.5.3.1.1" class="ltx_p" style="width:250.0pt;">
<span id="S3.T2.1.5.3.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_top" style="width:433.6pt;">
<span id="S3.I4" class="ltx_itemize">
<span id="S3.I4.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I4.i1.p1" class="ltx_para">
<span id="S3.I4.i1.p1.1" class="ltx_p">Enlistment of new clients</span>
</span></span>
<span id="S3.I4.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I4.i2.p1" class="ltx_para">
<span id="S3.I4.i2.p1.1" class="ltx_p">Rapid and efficient model iteration</span>
</span></span>
<span id="S3.I4.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I4.i3.p1" class="ltx_para">
<span id="S3.I4.i3.p1.1" class="ltx_p">Low computational, communication, and storage overheads</span>
</span></span>
</span>
</span></span>
</span>
</td>
</tr>
</table>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Fairness</span>
</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">How to Define Fairness?</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">A fairer system would enhance client trust, incentivize client contributions, reduce the potential for free-riding behaviors, attract more new client engagement, and bolster the long-term continuity of the system, among other benefits. Fairness has always been a central theme in human cooperation, and FL is no exception. Particularly in CFL, the method of aggregation has spurred discussions concerning fairness. The question of fairness in FL is indeed become a focal point of discourse. It involves considering whether the FL framework should prioritize the majority of users and clients with a larger number of samples, or whether it should also take into account clients with fewer samples that may have lower representativeness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. Furthermore, the perspectives of both clients and the server may also sway their interpretations of fairness. Clients may not have full visibility into the server’s aggregation algorithm, nor comprehend the performance of the aggregated model across different clients.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Fairness of Server</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">From the perspective of the server, its objective is to pursue a generalized model that maximizes the overall average performance of all clients. Driven by this objective and the pursuit of generalization in FL, the server’s concept of fairness often tends to favor clients with a greater influence or voice. In the classic FedAvg algorithm, the server conducts a weighted averaging aggregation based on the sample number of each client. This approach seems fair because the sample size can extent reflect the performance and credibility of the model to some extent, and can be seen as a reward for clients with more samples, as the aggregated model is more likely to bias towards them. However, for those underrepresented clients, the performance of the aggregated model might be unsatisfactory. Furthermore, the dominance of large sample clients could lead to low sample diversity and cause the aggregated model to lose its generalization capability. On the contrary, an FL framework involving non-weighted averaging during aggregation might demotivate clients with large sample sizes, subsequently diminishing system performance and continuity. Hence, from the server’s standpoint, the conception of fairness remains a topic open to debate.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Fairness of Client</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Conversely, from the client’s perspective, their interpretation of fairness tends to be simpler. This is primarily due to the likelihood that they are either unaware of or unconcerned with the server’s aggregation algorithm and the performance of the aggregated model on other clients. Hence, within the FL framework, clients would consider the system fair from a standpoint of individual fairness, provided the model maintains acceptable performance locally. A noteworthy example is Google Keyboard, where users contribute local model parameters in their usage, and in return, benefit from personalized recommendations. Interestingly, these recommendations from Google Keyboard are not necessarily completely accurate. As long as the output is within the user’s range of acceptability, the application can maintain its advantage relative to non-personalized keyboard applications. Of course, it is crucial to note that the level of acceptable performance may vary according to individual clients’ requirements and should not be generalized. When using Google Keyboard, users are often oblivious to or indifferent towards the server’s aggregation algorithm and have minimal or no knowledge of the model’s performance among other users. Users are likely to be self-interested, prioritizing their user experience without considering any factors related to others, i.e., a non-cooperative game scenario.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Incentives</span>
</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.4.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.5.2" class="ltx_text ltx_font_italic">Incentives Driven by Server</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">As the owner, leader, and manager of FL frameworks, the server typically aspires for its framework to undergo large-scale, active, positive, and continuable development. Thus, how the server employs incentive strategies to encourage clients to report their models, metadata, contributions, and even flaws in a rational, honest, and proactive manner remains an unresolved issue. The right to use the aggregated model itself serves as a form of reward (passive incentive), and current incentive strategies also contemplate offering additional rewards disseminated by the server to motivate clients (active incentives). The client contributions in these incentive strategies can follow economic principles, such as game theory, auction, contract, matching theory, and so forth <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. The Stackelberg game, in particular, has garnered considerable attention due to its alignment with the behaviors of the server and clients in a CFL setting. Besides these active incentives, punitive incentives may also serve as a potential strategy. For example, the right to use the aggregated model could be revoked if a client’s contribution does not meet expectations.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.4.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.5.2" class="ltx_text ltx_font_italic">Incentives Driven by Client Community</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Within the context of DFL, the absence of server coordination and the customizability of diverse network topologies render the incentive problem more variable and challenging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. On the one hand, there is no server to generate and distribute rewards, while on the other hand, calculating client contributions is especially difficult due to mutual distrust among clients. Therefore, certain passive incentive strategies may become more effective and prevalent than active incentives. On one side, clients can acquire the right to use the models by participating in the DFL community. Simultaneously, due to the factors of information asymmetry and mutual invisibility of information among clients, they are unaware of the size of each other’s contributions, such as the volume of raw data, training epochs, optimization results, etc. Consequently, they might be more inclined to share models imbued with local knowledge in exchange for other clients’ model updates. The motivation here is to garner as many resources as possible from the client community, albeit at the expense of disclosing local resources. We can draw inspiration from altruistic contribution behaviors observed in human societies, such as open-sourcing on Github, answering questions on Stack Overflow, voluntarily performing peer reviews, etc. While free-riding attacks (where some users garner knowledge from others without contributing themselves) are inevitable, the influence of reputation and prestige can nonetheless maintain a virtuous cycle within the community <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Continuity</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Continuity is a critical feature for the survival, revenue generation, and expansion of any application, system, or framework. In terms of FL, continuity signifies the pause, elimination, and reactivation of inactive clients, the continual, active, and voluntary updates from current clients, and the willingness, eligibility, and data diversity of a large number of prospective clients.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS1.4.1.1" class="ltx_text">VI-A</span> </span><span id="S6.SS1.5.2" class="ltx_text ltx_font_italic">Continuable Development of Server</span>
</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">From the server’s perspective, continuable development necessitates addressing and responding to the needs of these three classes of clients - inactive, current, and potential - while also considering the maintenance of different versions of the model to prevent catastrophic forgetting. More specifically, due to the continuous generation of new data by clients in the real world, particularly IoT devices, the local model updates of clients are typically based on the latest data. Although new models are evidently more compelling due to factors such as scenario updates, user utilization, and concept drift, old versions of the models do not entirely lose their contributions. A potential example could be an application using IoT devices, such as a smartwatch that monitors user’s ECG patterns. The ECG readings of users are likely to differ between weekdays and weekends, thus the models derived from weekend data might warrant individual storage. In practice for FL, while the server is aggregating the current versions of local models, it also incorporates previous versions with appropriate weighting. Furthermore, clients are granted the ability to trace back and retrieve prior versions of the model at any time. This feature serves as a safeguard against potential instability in client performance due to model updates.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS2.4.1.1" class="ltx_text">VI-B</span> </span><span id="S6.SS2.5.2" class="ltx_text ltx_font_italic">Continuable Update of Client</span>
</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">In the context of CFL, clients strive for long-term stability, rapid iterations, and efficient updates of the aggregated models from the server. Thus, they may work hard to deploy server-updated models at the earliest opportunity to achieve enhanced performance and user experience. Beyond their expectations from the server, under rational circumstances, clients might also attempt to report their model parameters to the server as rapidly, thoroughly, and accurately as possible, to ensure their models are significantly considered during the server’s aggregation process. This is because the server cannot indefinitely wait for all clients to upload their models. Therefore, in a rational state, the behavior of client updates is balanced between the long-term nature of data collection and the rapidity of model updates.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p">In the scenario of DFL, clients within the community may voluntarily identify, denounce, and report malicious clients performing adversarial attacks (e.g., model poisoning) in order to protect the community, given that this relates to their own interests. This is because the incorporation of models from these malicious clients into the FL process could potentially harm their interests. Clients might also proactively share their models with other clients, establishing a good reputation, so that other clients will be inclined to promptly share their model updates in return. One potential concern is that the DFL client population may exhibit exclusionary tendencies. Specifically, the mistrust towards new clients and the uncertainty brought about by their models, especially within smaller communities, can be quite pronounced. This may further hinder the continuity and growth of such small-scale communities.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Opportunities</span>
</h2>

<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS1.4.1.1" class="ltx_text">VII-A</span> </span><span id="S7.SS1.5.2" class="ltx_text ltx_font_italic">Interplay of Game Dynamics, Fairness, Incentives, and Continuity</span>
</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p">The issues of game dynamics, fairness, incentive mechanisms, and continuity in FL are interrelated and mutually impactful. For example, if an FL framework could perfectly achieve the objectives of all clients, such as Google Keyboard ideally meeting user expectations, users would naturally diminish their concerns about fairness. A fairness-aware strategy can also be considered as an incentive mechanism where clients contributing more are rewarded proportionally. Taking FedAvg as an example, clients might make great efforts to contribute as much local data as possible to the model training, to gain a more significant voice during the server’s model aggregation process. Therefore, fairness-aware strategies of weighted aggregation indirectly incentivize clients to make more contributions. Concurrently, this enhances the continuity of the FL framework, as each client will make an effort to collect data, train models, and participate in FL updates promptly to gain rewards. Under such continuable conditions, the game dynamics within the FL framework are also mitigated, as each client generates a steady stream of data resources, enabling the training of more robust models. Therefore, for the issues of game dynamics, fairness, incentive mechanisms, and continuity, both parallel multi-solution approaches and single-solution breakthroughs are viable options.</p>
</div>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS2.4.1.1" class="ltx_text">VII-B</span> </span><span id="S7.SS2.5.2" class="ltx_text ltx_font_italic">Integration with Sociology and Ethology</span>
</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">FL essentially represents a form of knowledge propagation, a method that is already widespread, diverse, and matured within both human societies and animal behaviors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. For example, the instructive paradigm between a teacher and students can offer insights to CFL, resonating with the architecture of a large model within the server and smaller models among clients utilized in federated knowledge distillation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Intriguingly, a similar hierarchical structure is observed in the field of ethology, particularly within ant colonies or bee hives. Here, directives (models) from the queen ant or queen bee (server) are disseminated to the worker ants or bees (clients), offering a clear instance of role distribution.</p>
</div>
<div id="S7.SS2.p2" class="ltx_para">
<p id="S7.SS2.p2.1" class="ltx_p">DFL is increasingly becoming a focus for researchers, due to its capacity to circumvent limitations imposed by server dependency, and also its reflection of more prevalent modes of knowledge dissemination among clients within human societies and ethology. For example, in the context of conferences, speakers (clients) present their research findings (models) to all attendees (other clients), which can be viewed as a manifestation of fully connected DFL. In group collaborations, each team member (client) contributes a part towards a common goal (model), mirroring the concept of split DFL. Interestingly, similar decentralized patterns of knowledge dissemination are observable in animal behavior. For example, within a school of fish, individual fish (clients) only communicate with their neighbors (gossip protocol), but when danger arises, the alert signal (model) spreads across the entire school (other clients), promoting swift collective evasion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.</p>
</div>
<div id="S7.SS2.p3" class="ltx_para">
<p id="S7.SS2.p3.1" class="ltx_p">Therefore, incorporating insights from sociology and ethology can effectively enhance FL organizational structures that are centered on IoT users, better aligning with the psychological expectations of users as clients.</p>
</div>
</section>
<section id="S7.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS3.4.1.1" class="ltx_text">VII-C</span> </span><span id="S7.SS3.5.2" class="ltx_text ltx_font_italic">Deployment Optimization in Federated Learning</span>
</h3>

<div id="S7.SS3.p1" class="ltx_para">
<p id="S7.SS3.p1.9" class="ltx_p">Current research mainly centers on the optimization of training and communication within FL, largely overlooking the strategy and timing for deploying the base model in FL on client devices. Specifically, in classical algorithms such as FedAvg, the fundamental operational cycle entails download <math id="S7.SS3.p1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S7.SS3.p1.1.m1.1a"><mo stretchy="false" id="S7.SS3.p1.1.m1.1.1" xref="S7.SS3.p1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.p1.1.m1.1b"><ci id="S7.SS3.p1.1.m1.1.1.cmml" xref="S7.SS3.p1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.p1.1.m1.1c">\rightarrow</annotation></semantics></math> train <math id="S7.SS3.p1.2.m2.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S7.SS3.p1.2.m2.1a"><mo stretchy="false" id="S7.SS3.p1.2.m2.1.1" xref="S7.SS3.p1.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.p1.2.m2.1b"><ci id="S7.SS3.p1.2.m2.1.1.cmml" xref="S7.SS3.p1.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.p1.2.m2.1c">\rightarrow</annotation></semantics></math> upload <math id="S7.SS3.p1.3.m3.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S7.SS3.p1.3.m3.1a"><mo stretchy="false" id="S7.SS3.p1.3.m3.1.1" xref="S7.SS3.p1.3.m3.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.p1.3.m3.1b"><ci id="S7.SS3.p1.3.m3.1.1.cmml" xref="S7.SS3.p1.3.m3.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.p1.3.m3.1c">\rightarrow</annotation></semantics></math> download <math id="S7.SS3.p1.4.m4.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S7.SS3.p1.4.m4.1a"><mo stretchy="false" id="S7.SS3.p1.4.m4.1.1" xref="S7.SS3.p1.4.m4.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.p1.4.m4.1b"><ci id="S7.SS3.p1.4.m4.1.1.cmml" xref="S7.SS3.p1.4.m4.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.p1.4.m4.1c">\rightarrow</annotation></semantics></math> deploy. In contrast, personalized algorithms, such as meta-learning, follow a cycle of download <math id="S7.SS3.p1.5.m5.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S7.SS3.p1.5.m5.1a"><mo stretchy="false" id="S7.SS3.p1.5.m5.1.1" xref="S7.SS3.p1.5.m5.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.p1.5.m5.1b"><ci id="S7.SS3.p1.5.m5.1.1.cmml" xref="S7.SS3.p1.5.m5.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.p1.5.m5.1c">\rightarrow</annotation></semantics></math> train <math id="S7.SS3.p1.6.m6.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S7.SS3.p1.6.m6.1a"><mo stretchy="false" id="S7.SS3.p1.6.m6.1.1" xref="S7.SS3.p1.6.m6.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.p1.6.m6.1b"><ci id="S7.SS3.p1.6.m6.1.1.cmml" xref="S7.SS3.p1.6.m6.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.p1.6.m6.1c">\rightarrow</annotation></semantics></math> upload <math id="S7.SS3.p1.7.m7.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S7.SS3.p1.7.m7.1a"><mo stretchy="false" id="S7.SS3.p1.7.m7.1.1" xref="S7.SS3.p1.7.m7.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.p1.7.m7.1b"><ci id="S7.SS3.p1.7.m7.1.1.cmml" xref="S7.SS3.p1.7.m7.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.p1.7.m7.1c">\rightarrow</annotation></semantics></math> download <math id="S7.SS3.p1.8.m8.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S7.SS3.p1.8.m8.1a"><mo stretchy="false" id="S7.SS3.p1.8.m8.1.1" xref="S7.SS3.p1.8.m8.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.p1.8.m8.1b"><ci id="S7.SS3.p1.8.m8.1.1.cmml" xref="S7.SS3.p1.8.m8.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.p1.8.m8.1c">\rightarrow</annotation></semantics></math> train <math id="S7.SS3.p1.9.m9.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S7.SS3.p1.9.m9.1a"><mo stretchy="false" id="S7.SS3.p1.9.m9.1.1" xref="S7.SS3.p1.9.m9.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.p1.9.m9.1b"><ci id="S7.SS3.p1.9.m9.1.1.cmml" xref="S7.SS3.p1.9.m9.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.p1.9.m9.1c">\rightarrow</annotation></semantics></math> deploy. Therefore, it’s evident that the deployment sequence within the communication and training processes significantly affects the performance of the model. With this in mind, we propose considering two distinct deployment sequences, facilitating the deployment of either generalized or personalized models, contingent on the specific use case:</p>
<ol id="S7.I1" class="ltx_enumerate">
<li id="S7.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(i)</span> 
<div id="S7.I1.i1.p1" class="ltx_para">
<p id="S7.I1.i1.p1.1" class="ltx_p">Deploy post-download for a generalized model: The model deployed is the aggregated one, offering wider generalization capabilities. However, it may not necessarily deliver optimal performance on local datasets.</p>
</div>
</li>
<li id="S7.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(ii)</span> 
<div id="S7.I1.i2.p1" class="ltx_para">
<p id="S7.I1.i2.p1.1" class="ltx_p">Deploy post-training for a personalized model: The model deployed is the one locally trained on the aggregated model, offering a higher degree of personalization and subsequently, enhancing confidence in the model’s performance.</p>
</div>
</li>
</ol>
<p id="S7.SS3.p1.10" class="ltx_p">Beyond the influence of the order of deployment on performance within the FL process, in the real world, due to the sequential and time-sensitive nature of data collection from IoT devices, excessive waiting for responses from the server or other clients may degrade model performance. Therefore, deployment optimization in FL, as an issue rooted in real-world applications, builds upon the foundational capacities of training and communication to further enhance FL’s performance, credibility, and operational efficiency.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VIII </span><span id="S8.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">In this paper, we explore and discuss FL in the context of human-centric IoT applications, with a particular emphasis on the advancements made by FL algorithms in addressing human privacy concerns, as well as other digital ethical dilemmas. We take into account perspectives from three distinct roles: the omniscient, clients, and the server, with a detailed analysis of both the CFL and DFL frameworks. Each of these roles, characterized by varying objectives and information asymmetries, raises game dynamics and trust crises, which in turn incite debates around fairness, incentive, and continuity. This paper aims to highlight the prevalent disregard for human digital ethics in the current FL paradigm and to inspire the future design of FL frameworks from sociological, psychological, and economic perspectives.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
K. F. Ystgaard, L. Atzori, D. Palma, P. E. Heegaard, L. E. Bertheussen, M. R. Jensen, and K. De Moor, “Review of the theory, principles, and design requirements of human-centric internet of things (iot),” </span><em id="bib.bib1.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">J. Ambient Intell. Humaniz. Comput.</em><span id="bib.bib1.3.3" class="ltx_text" style="font-size:90%;">, vol. 14, no. 3, pp. 2827–2859, Mar. 2023.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, “Communication-efficient learning of deep networks from decentralized data,” in </span><em id="bib.bib2.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Artificial intelligence and statistics</em><span id="bib.bib2.3.3" class="ltx_text" style="font-size:90%;">.   PMLR, 2017, pp. 1273–1282.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
L. Yuan, L. Sun, P. S. Yu, and Z. Wang, “Decentralized federated learning: A survey and perspective,” </span><em id="bib.bib3.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2306.01603</em><span id="bib.bib3.3.3" class="ltx_text" style="font-size:90%;">, Jun. 2023.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
A. Hard, K. Rao, R. Mathews, S. Ramaswamy, F. Beaufays, S. Augenstein, H. Eichner, C. Kiddon, and D. Ramage, “Federated learning for mobile keyboard prediction,” </span><em id="bib.bib4.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1811.03604</em><span id="bib.bib4.3.3" class="ltx_text" style="font-size:90%;">, Nov. 2018.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
V. P. Chellapandi, L. Yuan, C. G. Brinton, S. H. Zak, and Z. Wang, “Federated learning for connected and automated vehicles: A survey of existing approaches and challenges,” </span><em id="bib.bib5.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2308.10407</em><span id="bib.bib5.3.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
A. Z. Tan, H. Yu, L. Cui, and Q. Yang, “Towards personalized federated learning,” </span><em id="bib.bib6.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Trans. Neural Netw. Learn. Syst.</em><span id="bib.bib6.3.3" class="ltx_text" style="font-size:90%;">, Mar. 2022.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
L. Yuan, L. Su, and Z. Wang, “Federated transfer-ordered-personalized learning for driver monitoring application,” </span><em id="bib.bib7.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2301.04829</em><span id="bib.bib7.3.3" class="ltx_text" style="font-size:90%;">, Jan. 2023.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
L. Yuan, Y. Ma, L. Su, and Z. Wang, “Peer-to-peer federated continual learning for naturalistic driving action recognition,” in </span><em id="bib.bib8.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib8.3.3" class="ltx_text" style="font-size:90%;">, 2023, pp. 5249–5258.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
T. Li, M. Sanjabi, A. Beirami, and V. Smith, “Fair resource allocation in federated learning,” </span><em id="bib.bib9.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1905.10497</em><span id="bib.bib9.3.3" class="ltx_text" style="font-size:90%;">, May 2019.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
X. Tu, K. Zhu, N. C. Luong, D. Niyato, Y. Zhang, and J. Li, “Incentive mechanisms for federated learning: From economic and game theoretic perspective,” </span><em id="bib.bib10.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Trans. Cogn. Commun. Netw.</em><span id="bib.bib10.3.3" class="ltx_text" style="font-size:90%;">, May 2022.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
V. P. Chellapandi, L. Yuan, S. H. Zak, and Z. Wang, “A survey of federated learning for connected and automated vehicles,” </span><em id="bib.bib11.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2303.10677</em><span id="bib.bib11.3.3" class="ltx_text" style="font-size:90%;">, Mar. 2023.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
E. Fehr and K. M. Schmidt, “A theory of fairness, competition, and cooperation,” </span><em id="bib.bib12.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Q. J. Econ.</em><span id="bib.bib12.3.3" class="ltx_text" style="font-size:90%;">, vol. 114, no. 3, pp. 817–868, Aug. 1999.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
I. Eibl-Eibesfeldt, </span><em id="bib.bib13.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Human ethology</em><span id="bib.bib13.3.3" class="ltx_text" style="font-size:90%;">.   Routledge, 2017.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
C. Wu, F. Wu, L. Lyu, Y. Huang, and X. Xie, “Communication-efficient federated learning via knowledge distillation,” </span><em id="bib.bib14.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Nat. Commun.</em><span id="bib.bib14.3.3" class="ltx_text" style="font-size:90%;">, vol. 13, no. 1, p. 2032, Apr. 2022.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
A. H. Sayed, S.-Y. Tu, J. Chen, X. Zhao, and Z. J. Towfic, “Diffusion strategies for adaptation and learning over networks: an examination of distributed strategies and network behavior,” </span><em id="bib.bib15.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Signal Process. Mag.</em><span id="bib.bib15.3.3" class="ltx_text" style="font-size:90%;">, vol. 30, no. 3, pp. 155–171, Apr. 2013.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2310.03177" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2310.03178" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2310.03178">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2310.03178" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2310.03179" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 02:42:58 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
