<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks</title>
<!--Generated on Fri Jul 12 16:01:53 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2405.10632v5/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S1" title="In Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S2" title="In Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background &amp; Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S2.SS1" title="In 2 Background &amp; Related Work ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Defining model safety evaluations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S2.SS2" title="In 2 Background &amp; Related Work ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Reviewing the evaluation of human-LLM interaction</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S3" title="In Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>The Case for Human Interaction Evaluations</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S3.SS1" title="In 3 The Case for Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Definition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S3.SS2" title="In 3 The Case for Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Utility</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S3.SS2.SSSx1" title="In 3.2 Utility ‣ 3 The Case for Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title">Increasing the validity of evaluations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S3.SS2.SSSx2" title="In 3.2 Utility ‣ 3 The Case for Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title">Assessing direct human impact and interaction-specific harms</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S3.SS2.SSSx3" title="In 3.2 Utility ‣ 3 The Case for Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title">Guiding future assessments of models’ societal impact</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S3.SS3" title="In 3 The Case for Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Methods</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S3.SS3.SSSx1" title="In 3.3 Methods ‣ 3 The Case for Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title">Human subject experiments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S3.SS3.SSSx2" title="In 3.3 Methods ‣ 3 The Case for Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title">Real-world usage datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S3.SS3.SSSx3" title="In 3.3 Methods ‣ 3 The Case for Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title">User studies</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4" title="In Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>A Framework for Designing Safety-focused Human Interaction Evaluations</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4.SS1" title="In 4 A Framework for Designing Safety-focused Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Patterns in emerging human interaction evaluations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4.SS1.SSSx1" title="In 4.1 Patterns in emerging human interaction evaluations ‣ 4 A Framework for Designing Safety-focused Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title">Risk aspect</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4.SS1.SSSx2" title="In 4.1 Patterns in emerging human interaction evaluations ‣ 4 A Framework for Designing Safety-focused Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title">Target user groups</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4.SS1.SSSx3" title="In 4.1 Patterns in emerging human interaction evaluations ‣ 4 A Framework for Designing Safety-focused Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title">Interaction modes</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4.SS1.SSSx4" title="In 4.1 Patterns in emerging human interaction evaluations ‣ 4 A Framework for Designing Safety-focused Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title">Generalizability</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4.SS2" title="In 4 A Framework for Designing Safety-focused Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Framework</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4.SS2.SSSx1" title="In 4.2 Framework ‣ 4 A Framework for Designing Safety-focused Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title">Stage 1: Identifying risk and/or harm area</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4.SS2.SSSx2" title="In 4.2 Framework ‣ 4 A Framework for Designing Safety-focused Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title">Stage 2: Characterizing use context</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4.SS2.SSSx3" title="In 4.2 Framework ‣ 4 A Framework for Designing Safety-focused Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title">Stage 3: Choosing evaluation parameters</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S5" title="In Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Example Evaluations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S6" title="In Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S6.SS1" title="In 6 Discussion ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S6.SS2" title="In 6 Discussion ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Recommendations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S6.SS2.SSSx1" title="In 6.2 Recommendations ‣ 6 Discussion ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title">Develop accessible protocols, guides, and standardized test suites</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S6.SS2.SSSx2" title="In 6.2 Recommendations ‣ 6 Discussion ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title">Apply best practices from established disciplines to develop rigorous and replicable HIEs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S6.SS2.SSSx3" title="In 6.2 Recommendations ‣ 6 Discussion ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title">Diversify sourcing strategies and community involvement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S6.SS2.SSSx4" title="In 6.2 Recommendations ‣ 6 Discussion ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title">Attend to ethical issues of human participation</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S7" title="In Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Acknowledgments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#A1" title="In Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Lujain Ibrahim<sup class="ltx_sup" id="id1.1.id1">1, 2 <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>first &amp; corresponding author: lujain.ibrahim@oii.ox.ac.uk</span></span></span></sup>,
Saffron Huang<sup class="ltx_sup" id="id2.2.id2">3</sup>,
Lama Ahmad<sup class="ltx_sup" id="id3.3.id3">4</sup>,
Markus Anderljung<sup class="ltx_sup" id="id4.4.id4">2</sup>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id5.id1">Model evaluations are central to understanding the safety, risks, and societal impacts of AI systems. While most real-world AI applications involve human-AI interaction, most current evaluations (e.g., common benchmarks) of AI models do not. Instead, they incorporate human factors in limited ways, assessing the safety of models in isolation, thereby falling short of capturing the complexity of human-model interactions. In this paper, we discuss and operationalize a definition of an emerging category of evaluations – “human interaction evaluations” (HIEs) – which focus on the assessment of human-model interactions or the process and the outcomes of humans using models. First, we argue that HIEs can be used to increase the validity of safety evaluations, assess direct human impact and interaction-specific harms, and guide future assessments of models’ societal impact. Second, we propose a safety-focused HIE design framework – containing a human-LLM interaction taxonomy – with three stages: (1) identifying the risk and/or harm area, (2) characterizing the use context, and (3) choosing the evaluation parameters. Third, we apply our framework to two potential evaluations for overreliance and persuasion risks. Finally, we conclude with tangible recommendations for addressing concerns over costs, replicability, and unrepresentativeness of HIEs.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Artificial intelligence (AI) model evaluations have become central in developers’ and regulators’ efforts to ensure that AI systems are “safe.” Governments like that of the United Kingdom, through its AI Safety Institute <cite class="ltx_cite ltx_citemacro_citep">(UK Government <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib93" title="">2024</a>)</cite>, and the United States, through a recent Executive Order, emphasize the importance of conducting model evaluations for various risks like discrimination and cybersecurity <cite class="ltx_cite ltx_citemacro_citep">(The White House <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib91" title="">2023</a>)</cite>; AI labs, including OpenAI with its Preparedness Framework and Anthropic with its Responsible Scaling Policy <cite class="ltx_cite ltx_citemacro_citep">(OpenAI <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib67" title="">2023</a>; Anthropic <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib4" title="">2023</a>)</cite>, propose utilizing model evaluations to monitor and mitigate misuse and catastrophic risks; and, academic researchers are developing safety evaluation datasets at unprecedented rates <cite class="ltx_cite ltx_citemacro_citep">(Röttger et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib77" title="">2024</a>)</cite>. This has positioned model evaluations as integral to a range of important decisions on the safe development and deployment of AI systems.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">While drawing on the history of research in natural language processing (NLP), the evaluation of current general purpose AI models faces new challenges. These models have open-ended input and output spaces, and thus can produce unpredictable and varied responses which make designing comprehensive evaluations challenging <cite class="ltx_cite ltx_citemacro_citep">(Ganguli et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib25" title="">2022</a>)</cite>. Their model evaluation results are also sensitive to different prompting strategies <cite class="ltx_cite ltx_citemacro_citep">(Liang et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib56" title="">2022</a>)</cite>, suffer from replicability issues <cite class="ltx_cite ltx_citemacro_citep">(Ganguli et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib26" title="">2023</a>; Hutson <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib35" title="">2018</a>)</cite>, and can be compromised by data leakage from test sets <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib39" title="">2024</a>)</cite>. These challenges have prompted calls for intensified and interdisciplinary research efforts to enhance the robustness, reliability, and replicability of evaluations <cite class="ltx_cite ltx_citemacro_citep">(Chang et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib12" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Current safety evaluation approaches primarily develop datasets and benchmarks to evaluate model completions for hazardous behaviors and capabilities <cite class="ltx_cite ltx_citemacro_citep">(Sharma et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib82" title="">2023</a>; Parrish et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib70" title="">2021</a>; Wang et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib94" title="">2023</a>)</cite>. While such approaches are important in identifying potential downstream harms, they insufficiently address the ‘sociotechnical gap’ — the discrepancy between what safety assessments predict in controlled, model-only settings and how models actually perform in the environments in which they are deployed <cite class="ltx_cite ltx_citemacro_citep">(Weidinger et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib96" title="">2023</a>; Liao and Xiao <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib58" title="">2023</a>; Raji et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib75" title="">2022</a>)</cite>. By assessing models largely in isolation, these evaluation approaches incorporate human factors in limited ways, thereby failing to capture the complexity of human-model interactions <cite class="ltx_cite ltx_citemacro_citep">(Chang et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib12" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">This sociotechnical gap manifests across three dimensions: (1) <span class="ltx_text ltx_font_italic" id="S1.p4.1.1">joint performance</span>: while many AI use cases involve human interaction, most benchmarks are non-interactive and might not reveal capabilities and behaviors that may only appear through human-model collaboration and possible feedback effects <cite class="ltx_cite ltx_citemacro_citep">(Pan et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib69" title="">2024</a>)</cite>; (2) <span class="ltx_text ltx_font_italic" id="S1.p4.1.2">evaluation tasks</span>: analyses of real-world usage data reveal significant discrepancies between benchmark tasks and those performed in practical scenarios, indicating that current evaluations may not accurately reflect model behaviors outside of ‘lab settings’ <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib68" title="">2023</a>)</cite>; and (3) <span class="ltx_text ltx_font_italic" id="S1.p4.1.3">human impact</span>: current evaluation approaches are insufficient for operationalizing complex constructs and examining the direct impact of model behaviors on human users <cite class="ltx_cite ltx_citemacro_citep">(Weidinger et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib96" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Recognizing these limitations, there has been an increasing recognition of the need to expand how safety evaluations incorporate human factors. In this work, we motivate the need for this expansion and provide model evaluators — whether in labs, governments, or academia — with a framework to design human interaction evaluations (HIEs). We focus on large language models (LLMs) due to their ubiquity and influence in current applications, though we expect that many of our findings will also apply to other modalities (with additional considerations which we invite future work to address). Our key contributions are:
</p>
</div>
<div class="ltx_para" id="S1.p6">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">Defining HIEs and clarifying how they contribute to our understanding of model risks and harms.</span> We propose a definition for HIEs and outline the key roles they can play in the current landscape of assessing model safety (Section <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S3" title="3 The Case for Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">Developing an evaluation design framework.</span> We develop a three-stage framework for designing HIEs. Specifically, we synthesize evaluation considerations from NLP and human-computer interaction (HCI) to introduce a taxonomy of interaction forms for evaluating human-LLM interactions (Section <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4" title="4 A Framework for Designing Safety-focused Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_tag">4</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">Instantiating the framework.</span> We instantiate the framework by describing two potential HIEs to better understand overreliance and persuasion risks (Section <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S5" title="5 Example Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_tag">5</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i4.p1.1.1">Providing actionable recommendations.</span> We conclude with recommendations for advancing HIEs (Section <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S6" title="6 Discussion ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_tag">6</span></a>).</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background &amp; Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">We first clarify the key terms used in this paper. Then, we review research on the evaluation of human-LLM interaction.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Defining model safety evaluations</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">We follow existing work in adopting a wide definition for “safety” which encompasses model capabilities and behaviors associated with various taxonomized risks and harms <cite class="ltx_cite ltx_citemacro_citep">(Weidinger et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib97" title="">2022</a>; Shelby et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib83" title="">2023</a>)</cite>. Examples include different types of biases <cite class="ltx_cite ltx_citemacro_citep">(Parrish et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib70" title="">2021</a>)</cite>, toxicity or malicious advice <cite class="ltx_cite ltx_citemacro_citep">(Hartvigsen et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib34" title="">2022</a>)</cite>, sycophancy or power-seeking behaviors <cite class="ltx_cite ltx_citemacro_citep">(Sharma et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib82" title="">2023</a>)</cite>, and dangerous capabilities like persuasion and cybersecurity risks <cite class="ltx_cite ltx_citemacro_citep">(Phuong et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib73" title="">2024</a>)</cite>. In this context, ‘harms’ refer to negative outcomes that have already occurred and can be directly observed, whereas ‘risks’ refer to the potential for harm, specifically the likelihood and the magnitude of harm.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">We define a model evaluation as an assessment that targets one or both of two model properties: model capabilities and model behaviors. Model capabilities refer to the range and extent of tasks or functions a model can perform, such as translating languages or identifying objects in images. Model behaviors, on the other hand, describe how the model executes these tasks and how it responds under various circumstances, including its handling of potential biases or its reaction to unexpected inputs.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Reviewing the evaluation of human-LLM interaction</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">In NLP, much of the research on human-LLM interaction has focused on analyzing and improving domains like dialogue and co-writing <cite class="ltx_cite ltx_citemacro_citep">(Li et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib55" title="">2021</a>; Lin et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib59" title="">2023</a>)</cite>. Additionally, other research uses datasets of human-LM conversations from adversarial testing with crowdworkers to improve chatbot safety <cite class="ltx_cite ltx_citemacro_citep">(Xu et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib101" title="">2021</a>)</cite>. Recent work on human preferences also collects interaction data in the form of feedback on live conversations between humans and LLMs <cite class="ltx_cite ltx_citemacro_citep">(Kirk et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib46" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">However, research on <span class="ltx_text ltx_font_italic" id="S2.SS2.p2.1.1">evaluations</span> of human-LLM interactions has been relatively limited, with some exceptions. Lee et al. notably present a novel approach extending LLM evaluations from static to interactive through three stages: (1) defining an interactive task, (2) constructing an interactive system, and (3) designing evaluation metrics <cite class="ltx_cite ltx_citemacro_citep">(Lee et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib52" title="">2022</a>)</cite>. They evaluate several models across five tasks and find that better non-interactive performance does not always translate to better interactive performance, and that user judgment of performance can diverge from that of crowdsourced annotators. Other studies like Collins et al. utilize this framework to interactively evaluate three LLMs as assistants in proving undergraduate-level mathematics <cite class="ltx_cite ltx_citemacro_citep">(Collins et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib15" title="">2023</a>)</cite>. User-led, interactive evaluations have also been explored as a way to compare the performance of different models, such as the popular use of Elo or relative win rates between models <cite class="ltx_cite ltx_citemacro_citep">(Chiang et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib14" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">Most existing work focuses on interaction as a source of feedback for improving model performance; our study expands on this work, notably <cite class="ltx_cite ltx_citemacro_citet">Lee et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib52" title="">2022</a>)</cite> and existing insights from HCI, to specifically understand and improve model safety as opposed to general model performance <cite class="ltx_cite ltx_citemacro_citep">(Subramonyam et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib89" title="">2024</a>; Gordon et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib28" title="">2021</a>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>The Case for Human Interaction Evaluations</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Definition</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Weidinger et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib96" title="">2023</a>)</cite> first use the term “human interaction evaluation” to describe evaluations which study ”effects on people interacting with AI systems, and the human–AI dyad.” Here, we further refine and operationalize this definition. We define an HIE as the assessment of human-model interactions, which includes the process and/or the outcome of a human engaging with a model — that is, focusing on the mechanisms of interaction, the outcomes yielded, or a combination of the two.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">Humans can be involved in building model evaluations in different ways; in this paper, we distinguish between static evaluations and interactive evaluations. While static evaluations, like common dataset-based benchmarks, can still prompt models using human-written prompts and assess model outputs using annotations from human crowdworkers, interactive evaluations – which we focus on and develop here – engage humans as <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.1">subjects</span> of the evaluation who either respond to or actively elicit model outputs through interacting with the model <cite class="ltx_cite ltx_citemacro_citep">(Chang et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib12" title="">2024</a>; Lee et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib52" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">We specifically focus on evaluation units that consist of one human and one model, though we expect that many important HIEs will go beyond that (see Section <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S6.SS1" title="6.1 Limitations ‣ 6 Discussion ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_tag">6.1</span></a>). Borrowing from (non-safety focused) NLP research, we propose that human-model interactions be evaluated in the context of completing tasks (e.g., brainstorming, article writing) <cite class="ltx_cite ltx_citemacro_citep">(Lee et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib52" title="">2022</a>; Liang et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib56" title="">2022</a>)</cite>. Thus, the evaluation target may be the process of interaction aimed at completing some task, also known in HCI as an <span class="ltx_text ltx_font_italic" id="S3.SS1.p3.1.1">interaction trace</span>, or it may be the resulting outcome of these tasks (e.g., a decision that was made by a user with model assistance). An interaction trace is defined as a record or log of interactions between a user and a system, where the logs include data such as user actions (e.g., clicks, keystrokes, edits), system responses (e.g., model output), and contextual information (e.g., device type) <cite class="ltx_cite ltx_citemacro_citep">(Lee, Liang, and Yang <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib51" title="">2022</a>; Collins et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib15" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Utility</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We argue that because HIEs can assess the performance of human-model teams and the impact of model capabilities and behaviors on human users, they can be used to (1) increase the validity of evaluations, (2) assess direct human impact and interaction-specific harms, and (3) guide future assessments of models’ societal impact.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSSx1">
<h4 class="ltx_title ltx_title_subsubsection">Increasing the validity of evaluations</h4>
<div class="ltx_para" id="S3.SS2.SSSx1.p1">
<p class="ltx_p" id="S3.SS2.SSSx1.p1.1">We argue that for some target constructs, HIEs can have greater internal and external validity compared to static evaluations, and that they may also increase the validity of static evaluations.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSSx1.p2">
<p class="ltx_p" id="S3.SS2.SSSx1.p2.1">The internal validity of an evaluation is the extent to which the chosen datasets, survey questions, or prompts measure the target model properties in the controlled environment of the evaluation <cite class="ltx_cite ltx_citemacro_citep">(Rooney et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib76" title="">2016</a>; Raji et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib74" title="">2021</a>)</cite>. HIEs enable researchers to collect richer forms of observable data <cite class="ltx_cite ltx_citemacro_citep">(Kiela et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib45" title="">2021</a>)</cite>. For example, researchers can observe the behaviors of the entire human-model system, including how participants’ beliefs change after interacting with models, what they do with given information, and which model capabilities they leverage most frequently. Such detailed observations can be used to generate insights or create datasets, prompts, or other proxies that can more faithfully measure the target model properties <cite class="ltx_cite ltx_citemacro_citep">(Mialon et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib61" title="">2023</a>)</cite>. Therefore, HIEs may not only be a possible substitute for some static evaluations, but may also be an important complement that validates static evaluations.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSSx1.p3">
<p class="ltx_p" id="S3.SS2.SSSx1.p3.1">The external validity of an evaluation is the extent to which the insights gained from it apply beyond the specific controlled environment it is conducted in. HIEs allow for experimenting and drawing conclusions in contexts that are more akin to real-world, naturalistic contexts, as they directly involve human users interacting with models. This can increase the likelihood that evaluation results generalize to real-world settings. For example, an HIE could assess the capacity of human users to elicit a particular model capability and identify the cases in which this occurs. HIEs are thus particularly useful when it comes to assessing not only the upper bound of capabilities (e.g., in the case of red-teaming with domain experts) but also the extent to which everyday human-model interactions elicit model capabilities approaching this upper bound. Importantly, the representativeness of an HIE study sample is also a determiner of external validity as it concerns whether HIE results on a study population (e.g., a representative sample of U.S. adults crowdsourced from an online platform) can generalize to the target population (e.g., the population of the U.K. or the entire user base of a product) <cite class="ltx_cite ltx_citemacro_citep">(Susukida et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib90" title="">2017</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSSx2">
<h4 class="ltx_title ltx_title_subsubsection">Assessing direct human impact and interaction-specific harms</h4>
<div class="ltx_para" id="S3.SS2.SSSx2.p1">
<p class="ltx_p" id="S3.SS2.SSSx2.p1.1">HIEs could assess direct impact — how and whether users are affected by certain model capabilities and behaviors (e.g., whether persuasive capabilities lead to attitude change). This offers several evaluation advantages.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSSx2.p2">
<p class="ltx_p" id="S3.SS2.SSSx2.p2.1">First, HIEs enhance the external validity of human impact assessment. Static evaluations typically grade model outputs using specific metrics, assuming these metrics adequately represent human impact, without directly measuring the actual impact on users. For example, static evaluations cannot directly assess the psychological impact of models on human users’ emotions, cognitions, and behaviors. This implicates harms like those from anthropomorphic language <cite class="ltx_cite ltx_citemacro_citep">(Abercrombie et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib1" title="">2023</a>)</cite>, overreliance on models <cite class="ltx_cite ltx_citemacro_citep">(Xu, Feng, and Chen <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib102" title="">2023</a>)</cite>, model-driven deception and persuasion <cite class="ltx_cite ltx_citemacro_citep">(Hackenburg et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib31" title="">2023</a>; Karinshak et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib43" title="">2023a</a>)</cite>, and the engagement in friendships and romantic relationships with AI systems <cite class="ltx_cite ltx_citemacro_citep">(Brandtzaeg, Skjuve, and Følstad <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib10" title="">2022</a>)</cite> — all of which HIEs may be more suited to address as a starting point.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSSx2.p3">
<p class="ltx_p" id="S3.SS2.SSSx2.p3.1">Second, many risks are specifically realized through, often multi-turn, human interaction, and are difficult to discover and study without additional human involvement. For example, static evaluations do not fully capture effects of feedback loops of human-model influence, which previous work has shown can drive harmful behavior like in-context reward hacking <cite class="ltx_cite ltx_citemacro_citep">(Pan et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib69" title="">2024</a>)</cite>. Conversely, the risks of a model which static evaluations show can produce falsehoods, for example, may not be realized if humans consistently observe and reject the outputs as misleading.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSSx2.p4">
<p class="ltx_p" id="S3.SS2.SSSx2.p4.1">Finally, in the discovery and assessment of model risks, HIEs can enhance user agency by shifting the evaluator perspective from third-party (e.g., developers or annotators) to first-party (users), allowing for direct user input on experienced harms and giving users greater evaluatory power <cite class="ltx_cite ltx_citemacro_citep">(Lam et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib50" title="">2022</a>; Lee et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib52" title="">2022</a>)</cite>. Users’ detections of harmful algorithm behaviors are heavily informed by personal experiences with and exposure to societal biases, suggesting that user-driven evaluations can elicit more diverse, comprehensive, and therefore useful results <cite class="ltx_cite ltx_citemacro_citep">(Shen et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib84" title="">2021</a>; DeVos et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib19" title="">2022</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSSx3">
<h4 class="ltx_title ltx_title_subsubsection">Guiding future assessments of models’ societal impact</h4>
<div class="ltx_para" id="S3.SS2.SSSx3.p1">
<p class="ltx_p" id="S3.SS2.SSSx3.p1.1">HIEs allow us to understand model impact on human users through an individual frame, but the complexity of network and ecosystem dynamics can make it difficult to generalize from this individual frame to a societal one <cite class="ltx_cite ltx_citemacro_citep">(Rybski et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib78" title="">2009</a>; Johnson, Faraj, and Kudaravalli <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib40" title="">2014</a>)</cite>. Despite this, the results of HIEs can be used to develop individual-level interventions with societal-level implications <cite class="ltx_cite ltx_citemacro_citep">(Chater and Loewenstein <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib13" title="">2023</a>)</cite>. For example, understanding how individuals interact with non-factual or persuasive model output can help develop more effective ways to label AI-generated content. This not only helps individuals identify and understand synthetic media, but also addresses broader societal concerns about misinformation and trust.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSSx3.p2">
<p class="ltx_p" id="S3.SS2.SSSx3.p2.1">Furthermore, integrating the results of HIEs with additional contextual information can provide a clearer view of how, if at all, these risks would materialize at the societal level. For example, the feasibility of human interaction risks can be contingent upon the availability of resources such as time, money, and personnel. Consider the assessment of disinformation risks; it is crucial to incorporate both the findings of a relevant HIE and the effectiveness of existing social media defenses, like whether content is adequately watermarked or how recommendation systems respond to AI-generated content, to design assessments that more accurately reflect broader societal impact <cite class="ltx_cite ltx_citemacro_citep">(Kapoor and Narayanan <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib42" title="">2023</a>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Methods</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">HIEs can either be <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.1">controlled</span>, where interactions are set in a structured, lab-like setting to systematically study specific variables under predetermined conditions, or <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.2">grounded</span>, where interactions occur in naturalistic, real-world settings to observe how humans interact with models in real-life environments. We briefly recap the methods for conducting HIEs, organizing them around established methods in HCI and adjacent fields <cite class="ltx_cite ltx_citemacro_citep">(Kuniavsky <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib49" title="">2003</a>)</cite>. Each method has different strengths in extracting various insights on human-LLM interaction:</p>
</div>
<section class="ltx_subsubsection" id="S3.SS3.SSSx1">
<h4 class="ltx_title ltx_title_subsubsection">Human subject experiments</h4>
<div class="ltx_para" id="S3.SS3.SSSx1.p1">
<p class="ltx_p" id="S3.SS3.SSSx1.p1.1">observe or measure the effects of certain conditions or interventions on human participants in controlled settings. An example is randomized controlled trials (RCTs), where participants are randomly assigned to different groups to compare outcomes across interventions or control conditions <cite class="ltx_cite ltx_citemacro_citep">(Hariton and Locascio <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib33" title="">2018</a>)</cite>. Human-LLM experiments can involve participants engaging with models to examine how they perceive, use, or are influenced by the model outputs. They may also track participants’ interactions with models for analysis, and/or include surveys with pre- and post-interaction questions.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSSx2">
<h4 class="ltx_title ltx_title_subsubsection">Real-world usage datasets</h4>
<div class="ltx_para" id="S3.SS3.SSSx2.p1">
<p class="ltx_p" id="S3.SS3.SSSx2.p1.1">contain real-world interaction information (e.g., of common use cases, prompting methods, revisions, usage patterns) about human interactions with models in grounded settings. Datasets may also include reported or inferred user characteristics (e.g., geographic location, age). Analyzing these datasets secondarily, but not directly involve human subjects in an evaluation. These datasets are also currently largely accessible only to product providers, with the exception of some crowdsourcing initiatives, e.g., <cite class="ltx_cite ltx_citemacro_citet">ShareGPT (<a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib81" title="">2022</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib104" title="">2024</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSSx3">
<h4 class="ltx_title ltx_title_subsubsection">User studies</h4>
<div class="ltx_para" id="S3.SS3.SSSx3.p1">
<p class="ltx_p" id="S3.SS3.SSSx3.p1.1">often involve relatively small groups of participants engaging with models in controlled or grounded settings. These studies can gather in-depth insight into how individuals interact with models, including their strategies, preferences, and challenges. Qualitative methods like think-aloud protocols, cognitive walkthroughs, interviews, and focus groups are often utilized in user studies <cite class="ltx_cite ltx_citemacro_citep">(Wilson <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib98" title="">2000</a>)</cite>.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>A Framework for Designing Safety-focused Human Interaction Evaluations</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We first present findings from a brief review of existing HIEs (Section <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4.SS1" title="4.1 Patterns in emerging human interaction evaluations ‣ 4 A Framework for Designing Safety-focused Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_tag">4.1</span></a>). This review guides our proposed three-stage framework (Section <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4.SS2" title="4.2 Framework ‣ 4 A Framework for Designing Safety-focused Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_tag">4.2</span></a>) for designing safety-focused HIEs. <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Note that our framework is restricted to the “design” stage of evaluations. Discussions of what user training is needed, which statistical analyses to conduct, and other related issues, while critical, are outside the scope of this paper.</span></span></span> LLMs have a vast surface of capabilities and risks which require evaluation. However, as it is practically not possible to cover the entire evaluation space, an additional purpose of this framework is to help evaluators make explicit what is included or omitted. This can aid decision-makers — policymakers, developers, users or affected non-users — in interpreting the scope and coverage of evaluation results <cite class="ltx_cite ltx_citemacro_citep">(Liang et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib56" title="">2022</a>)</cite>.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Patterns in emerging human interaction evaluations</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">A recent review by <cite class="ltx_cite ltx_citemacro_citet">Weidinger et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib96" title="">2023</a>)</cite> shows that the number of HIEs is limited but growing. We conduct a brief review of 21 such evaluations. We restrict our review to studies which utilize one of the methods from Section <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S3.SS3" title="3.3 Methods ‣ 3 The Case for Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_tag">3.3</span></a> to assess an aspect of model safety, risks, or harms. Our review consists of 11 studies from the repository of safety evaluations in <cite class="ltx_cite ltx_citemacro_citet">Weidinger et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib96" title="">2023</a>)</cite>’s review (last updated in December 2023), along with 10 additional studies which we add from existing knowledge and suggestions made by the paper authors. We examine these studies for common patterns and limitations, categorizing them by (1) <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.1">risk/harm focus area</span>, (2) <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.2">methods</span>, and (3) <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.3">design attributes</span>, namely target study population, risk aspect, interaction tasks, and number of models evaluated (details in Appendix Table <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#A1.T1" title="Table 1 ‣ Appendix A Appendix ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_tag">1</span></a>). The insights from this review lay the groundwork for our framework, and are summarized below:</p>
</div>
<section class="ltx_subsubsection" id="S4.SS1.SSSx1">
<h4 class="ltx_title ltx_title_subsubsection">Risk aspect</h4>
<div class="ltx_para" id="S4.SS1.SSSx1.p1">
<p class="ltx_p" id="S4.SS1.SSSx1.p1.1">Recent work has drawn attention to the importance of assessing marginal rather than absolute risks from AI system use <cite class="ltx_cite ltx_citemacro_citep">(Kapoor et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib41" title="">2024</a>)</cite>. We find that while earlier studies often focused on <span class="ltx_text ltx_font_italic" id="S4.SS1.SSSx1.p1.1.1">absolute</span> risks — assessing the direct likelihood and severity of harms from model use, more recent studies tend to examine <span class="ltx_text ltx_font_italic" id="S4.SS1.SSSx1.p1.1.2">marginal</span> risks, comparing the risks of models against a human baseline or that of other existing technologies.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSSx2">
<h4 class="ltx_title ltx_title_subsubsection">Target user groups</h4>
<div class="ltx_para" id="S4.SS1.SSSx2.p1">
<p class="ltx_p" id="S4.SS1.SSSx2.p1.1">Research indicates that different user groups experience computing harms differently, highlighting the importance of evaluating diverse user interactions and perceptions when assessing model risks <cite class="ltx_cite ltx_citemacro_citep">(Aizenberg and van den Hoven <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib3" title="">2020</a>)</cite>. While around half of the studies examined effects across user groups, these examinations often occurred only after data collection. We find that few studies targeted a specific population, like intentionally using a representative sample, set of user personas, or otherwise justified their sampling strategy.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSSx3">
<h4 class="ltx_title ltx_title_subsubsection">Interaction modes</h4>
<div class="ltx_para" id="S4.SS1.SSSx3.p1">
<p class="ltx_p" id="S4.SS1.SSSx3.p1.1">There is a wide range of possible human-LLM interactions. We find that many interaction modes, such as assistance (e.g., planning a cybersecurity attack) or collaboration (e.g., co-writing a persuasive argument), remain underexplored with most studies focusing primarily on exposure to outputs (e.g., reading a persuasive message) or explorative conversations (e.g., dialogue with a social agent).</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSSx4">
<h4 class="ltx_title ltx_title_subsubsection">Generalizability</h4>
<div class="ltx_para" id="S4.SS1.SSSx4.p1">
<p class="ltx_p" id="S4.SS1.SSSx4.p1.1">The broader applicability of findings across different models and tasks is important for conducting relatively comprehensive evaluations. Most studies assessed either a single model or system (e.g., a specific model within ChatGPT) or a single type of task (e.g., information retrieval), limiting their generalizability and coverage.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Framework</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Synthesizing the results of our review with evaluation considerations from NLP and HCI, we propose a three-staged approach to constructing safety-focused HIEs using human subject experiments: (1) identifying risk and/or harm area, (2) characterizing the use context, and (3) choosing the evaluation parameters. <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>While the design considerations outlined in our framework are useful for both controlled and grounded studies, grounded studies conducted in real-world environments (e.g., workplaces, schools) require additional environment considerations which are beyond the scope of this paper.</span></span></span></p>
</div>
<section class="ltx_subsubsection" id="S4.SS2.SSSx1">
<h4 class="ltx_title ltx_title_subsubsection">Stage 1: Identifying risk and/or harm area</h4>
<div class="ltx_para" id="S4.SS2.SSSx1.p1">
<p class="ltx_p" id="S4.SS2.SSSx1.p1.1">The first stage of any evaluation should be a clear articulation of the real-world question it aims to answer. We propose formulating hypotheses by (1) identifying the types of risks or harms to be studied, incorporating existing knowledge about these risks or harms, and (2) classifying the aspect of the risk as absolute, marginal, or residual.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSSx1.p2">
<p class="ltx_p" id="S4.SS2.SSSx1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSSx1.p2.1.1">What is the real-world question of interest?</span> The types of model risk and harms have been extensively taxonomized in previous work <cite class="ltx_cite ltx_citemacro_citep">(Shelby et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib83" title="">2023</a>; Weidinger et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib97" title="">2022</a>; Solaiman et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib87" title="">2023</a>)</cite>. Evaluations vary widely based on the evaluator’s objectives and the prior information available. An evaluation may be exploratory, focusing on identifying new risks and augmented capabilities; or, it may be targeted, focusing on measuring the impact of well-identified and understood harms, or validating parts of existing static evaluation.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSSx1.p3">
<p class="ltx_p" id="S4.SS2.SSSx1.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSSx1.p3.1.1">What aspect of risk is being considered?</span> HIEs can assess different aspects of risk. We propose considering one or several of the following aspects when designing HIEs: (1) absolute risk, (2) marginal risk, and (3) residual risk. Table <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4.T1" title="Table 1 ‣ Stage 1: Identifying risk and/or harm area ‣ 4.2 Framework ‣ 4 A Framework for Designing Safety-focused Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates examples of different aspects of risk for four distinct risk areas.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSSx1.p4">
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">Absolute risk</span> assesses direct risks from model use. This may be most suitable when assessing legally and socially unacceptable harms (e.g., discrimination) by evaluating direct contributions to these outcomes.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">Marginal risk</span> assesses additional risks from model use relative to a baseline such as human capabilities or the use of existing technologies or other hypothetical scenarios. This may be most suitable when assessing risks that are already present with current tools (e.g., those related to information retrieval) <cite class="ltx_cite ltx_citemacro_citep">(Kapoor et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib41" title="">2024</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.1.1">Residual risk</span> considers risks due to model use which remain after implementing safety mitigations or interventions <cite class="ltx_cite ltx_citemacro_citep">(Fraser and y Villarino <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib23" title="">2023</a>)</cite>. This may be most suitable when there are feasible and realistic safety measures (e.g., new safety filters) that are expected to reduce a specific risk.</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.1.1.1.1">
<span class="ltx_p" id="S4.T1.1.1.1.1.1.1" style="width:116.4pt;"></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.1.1.2.1">
<span class="ltx_p" id="S4.T1.1.1.1.2.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.2.1.1.1">Absolute</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.1.1.3.1">
<span class="ltx_p" id="S4.T1.1.1.1.3.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.3.1.1.1">Marginal</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.1.1.4.1">
<span class="ltx_p" id="S4.T1.1.1.1.4.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.4.1.1.1">Residual</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.1.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.2.1.1.1">
<span class="ltx_p" id="S4.T1.1.2.1.1.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.2.1.1.1.1.1">Discrimination risks</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.2.1.2.1">
<span class="ltx_p" id="S4.T1.1.2.1.2.1.1" style="width:116.4pt;">Risks of model use leading to unfair treatment based on protected classes (e.g., race, age, gender)</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.1.2.1.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.2.1.3.1">
<span class="ltx_p" id="S4.T1.1.2.1.3.1.1" style="width:116.4pt;">Comparison of discrimination risks from model decision-making vs. human decision-making</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.1.2.1.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.2.1.4.1">
<span class="ltx_p" id="S4.T1.1.2.1.4.1.1" style="width:116.4pt;">Discrimination risks that remain after use of anti-discrimination measures (e.g., model fairness checks)</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T1.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.3.2.1.1">
<span class="ltx_p" id="S4.T1.1.3.2.1.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.3.2.1.1.1.1">Biorisks</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T1.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.3.2.2.1">
<span class="ltx_p" id="S4.T1.1.3.2.2.1.1" style="width:116.4pt;">Risks of model providing critical information for the creation of biological threats</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T1.1.3.2.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.3.2.3.1">
<span class="ltx_p" id="S4.T1.1.3.2.3.1.1" style="width:116.4pt;">Comparison of risks from accessing critial bio-related information from model versus from google search</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T1.1.3.2.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.3.2.4.1">
<span class="ltx_p" id="S4.T1.1.3.2.4.1.1" style="width:116.4pt;">Biorisks that remain after restricting model access of suspected bad actors</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T1.1.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.4.3.1.1">
<span class="ltx_p" id="S4.T1.1.4.3.1.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.4.3.1.1.1.1">Overreliance risks</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T1.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.4.3.2.1">
<span class="ltx_p" id="S4.T1.1.4.3.2.1.1" style="width:116.4pt;">Risks of becoming over-dependent on inaccurate or biased model output</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T1.1.4.3.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.4.3.3.1">
<span class="ltx_p" id="S4.T1.1.4.3.3.1.1" style="width:116.4pt;">Comparison of risks from overreliance on model versus overreliance on other decision-making tools</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T1.1.4.3.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.4.3.4.1">
<span class="ltx_p" id="S4.T1.1.4.3.4.1.1" style="width:116.4pt;">Overreliance risks that remain after measures to encourage human oversight (e.g., regular reminders to fact-check model output)</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S4.T1.1.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.5.4.1.1">
<span class="ltx_p" id="S4.T1.1.5.4.1.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.5.4.1.1.1.1">Persuasion risks</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S4.T1.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.5.4.2.1">
<span class="ltx_p" id="S4.T1.1.5.4.2.1.1" style="width:116.4pt;">Risks of model changing someone’s attitudes or behaviors</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S4.T1.1.5.4.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.5.4.3.1">
<span class="ltx_p" id="S4.T1.1.5.4.3.1.1" style="width:116.4pt;">Comparison of persuasion risks from model vs. from traditional persuasion methods (e.g., human salesperson)</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S4.T1.1.5.4.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.5.4.4.1">
<span class="ltx_p" id="S4.T1.1.5.4.4.1.1" style="width:116.4pt;">Persuasion risks that remain despite effective watermarking of AI-generated content</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Examples of absolute, marginal, and residual risks for different risk areas</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSSx2">
<h4 class="ltx_title ltx_title_subsubsection">Stage 2: Characterizing use context</h4>
<div class="ltx_para" id="S4.SS2.SSSx2.p1">
<p class="ltx_p" id="S4.SS2.SSSx2.p1.1">The second stage involves specifying the use context, which we break down into (1) the harmful use scenario, (2) the user, model, and system dimensions, and (3) the human-model interaction mode and tasks.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSSx2.p2">
<p class="ltx_p" id="S4.SS2.SSSx2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSSx2.p2.1.1">What is the harmful use scenario?</span> In HCI research, user goals or objectives have been shown to shape how they engage with systems and thus influence the outcomes of these engagements <cite class="ltx_cite ltx_citemacro_citep">(Subramonyam et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib89" title="">2024</a>)</cite>. Thus, here, we group harmful use scenarios according to the user’s objectives in the interaction. In each scenario, we also consider the affected parties of any harm caused by use. We propose in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4.T2" title="Table 2 ‣ Stage 2: Characterizing use context ‣ 4.2 Framework ‣ 4 A Framework for Designing Safety-focused Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_tag">2</span></a> four scenarios which we believe address some of the most salient failure modes of current concern <cite class="ltx_cite ltx_citemacro_citep">(Mitchell <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib62" title="">2024</a>)</cite>. Additionally, evaluations may be grounded in a specific use domain (e.g., medicine, education) to target domain-specific considerations.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.1.1.1.1">
<span class="ltx_p" id="S4.T2.1.1.1.1.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.1.1.1">Scenario</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.1.1.2.1">
<span class="ltx_p" id="S4.T2.1.1.1.2.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.2.1.1.1">Misuse / adversarial testing</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.1.1.3.1">
<span class="ltx_p" id="S4.T2.1.1.1.3.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.3.1.1.1">Unintended harm: personal impact</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.1.1.4.1">
<span class="ltx_p" id="S4.T2.1.1.1.4.1.1" style="width:111.3pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.4.1.1.1">Unintended harm: external impact</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.1.1.1">
<span class="ltx_p" id="S4.T2.1.2.1.1.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.2.1.1.1.1.1">Objective</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.1.2.1">
<span class="ltx_p" id="S4.T2.1.2.1.2.1.1" style="width:116.4pt;">User intentionally uses model to inflict harm on another person, group of people, or system</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.2.1.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.1.3.1">
<span class="ltx_p" id="S4.T2.1.2.1.3.1.1" style="width:116.4pt;">User uses model, gets harmed in the process</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.2.1.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.1.4.1">
<span class="ltx_p" id="S4.T2.1.2.1.4.1.1" style="width:111.3pt;">User uses model, unintentionally harms another person, group of people, or system</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.2.1.1">
<span class="ltx_p" id="S4.T2.1.3.2.1.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.3.2.1.1.1.1">Affected parties</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.2.2.1">
<span class="ltx_p" id="S4.T2.1.3.2.2.1.1" style="width:116.4pt;">External subjects</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.3.2.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.2.3.1">
<span class="ltx_p" id="S4.T2.1.3.2.3.1.1" style="width:116.4pt;">User</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.3.2.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.2.4.1">
<span class="ltx_p" id="S4.T2.1.3.2.4.1.1" style="width:111.3pt;">External subjects</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S4.T2.1.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.3.1.1">
<span class="ltx_p" id="S4.T2.1.4.3.1.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.4.3.1.1.1.1">Example(s)</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S4.T2.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.3.2.1">
<span class="ltx_p" id="S4.T2.1.4.3.2.1.1" style="width:116.4pt;">Influence operations, cybersecurity attacks, hate speech</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S4.T2.1.4.3.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.3.3.1">
<span class="ltx_p" id="S4.T2.1.4.3.3.1.1" style="width:116.4pt;">Exposure to harmful stereotypes in model output</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S4.T2.1.4.3.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.3.4.1">
<span class="ltx_p" id="S4.T2.1.4.3.4.1.1" style="width:111.3pt;">Decision-maker trusts inaccurate model judgment hurting decision-subject</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Three primary harmful use scenarios and examples of each</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.SSSx2.p3">
<p class="ltx_p" id="S4.SS2.SSSx2.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSSx2.p3.1.1">What are the user, model, and system dimensions?</span> Users and models which make up an evaluation vary across multiple dimensions. Recognizing these dimensions allows evaluators to conduct targeted analyses that examine a range of potentially consequential model characteristics and move beyond the limitations of assuming standardized, universal human subjects. Currently, most research subjects come from Western, Educated, Industrialized, Rich, and Democratic (WEIRD) populations, which do not represent the majority of technology users <cite class="ltx_cite ltx_citemacro_citep">(Seaborn, Barbareschi, and Chandra <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib80" title="">2023</a>)</cite>. As a starting point, we propose specifying the following user, model, and system dimensions:</p>
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.1">User dimensions:</span> users can be characterized by information on their demographics, domain expertise, technical knowledge, and emotional or psychological state <cite class="ltx_cite ltx_citemacro_citep">(Ibrahim, Rocher, and Valdivia <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib37" title="">2024</a>; Liao and Sundar <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib57" title="">2022</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i2.p1.1.1">Model dimensions:</span> models can be characterized by their size (number of parameters), tuning (e.g, instruction-tuned, chat-tuned), dataset (e.g., composition, treatment, language).<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>This information may not always be accessible or available. Evaluators should specify dimensions where possible. Otherwise, evaluators can also note the absence of information about specific model dimensions.</span></span></span></p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i3.p1">
<p class="ltx_p" id="S4.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i3.p1.1.1">System dimensions:</span> models could be augmented by system messages and/or scaffolding <span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>“Scaffolding” is a term used to describe structured support for AI models that improve their ability to perform certain tasks or expand their affordances and spheres of influence.</span></span></span> with prompt engineering, planning and reasoning frameworks, or tools.<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>Given the current state of the field, system dimensions are fairly limited compared to model dimensions. Hence, in this paper, we mostly focus on model and user dimensions but in the future we expect the scope of system dimensions to grow.</span></span></span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS2.SSSx2.p4">
<p class="ltx_p" id="S4.SS2.SSSx2.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSSx2.p4.1.1">What is the interaction mode and associated evaluation tasks?</span> For each use scenario, there exists multiple <span class="ltx_text ltx_font_italic" id="S4.SS2.SSSx2.p4.1.2">interaction modes</span>, visualized in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4.F1" title="Figure 1 ‣ Stage 2: Characterizing use context ‣ 4.2 Framework ‣ 4 A Framework for Designing Safety-focused Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_tag">1</span></a>, which define the nature of the human-model relationship in completing certain tasks towards the objective <cite class="ltx_cite ltx_citemacro_citep">(Gao et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib27" title="">2024</a>; Händler <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib36" title="">2023</a>)</cite>. Those tasks may be goal-oriented tasks focused on specific outcomes (e.g., summarization), or open-ended tasks which are exploratory and without a clear endpoint (e.g., social dialogue). We present example tasks in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4.T3" title="Table 3 ‣ Stage 2: Characterizing use context ‣ 4.2 Framework ‣ 4 A Framework for Designing Safety-focused Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSSx2.p5">
<p class="ltx_p" id="S4.SS2.SSSx2.p5.1">Based on observed use cases, existing literature reviews, and studies on real-world usage data, we taxonimize five main modes of prototypical human-model interactions <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib68" title="">2023</a>; Zhao et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib104" title="">2024</a>)</cite>:</p>
<ul class="ltx_itemize" id="S4.I3">
<li class="ltx_item" id="S4.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I3.i1.p1">
<p class="ltx_p" id="S4.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I3.i1.p1.1.1">Collaboration</span>: human and model work in tandem towards completing joint goal-oriented tasks.</p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I3.i2.p1">
<p class="ltx_p" id="S4.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I3.i2.p1.1.1">Direction</span>: human instructs the model to complete specific goal-oriented tasks.</p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I3.i3.p1">
<p class="ltx_p" id="S4.I3.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I3.i3.p1.1.1">Assistance</span>: model provides support to human in completing specific goal-oriented tasks.</p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I3.i4.p1">
<p class="ltx_p" id="S4.I3.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I3.i4.p1.1.1">Cooperation</span>: human and model undertake separate but complementary goal-oriented tasks. Unlike collaboration, where involvement is mutually integrated, cooperation involves distinct contributions towards the same goal but without shared execution.</p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I3.i5.p1">
<p class="ltx_p" id="S4.I3.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I3.i5.p1.1.1">Exposure</span>: human observes or is exposed to a single or discrete set of pre-produced model output (e.g., human reads a model-generated message).</p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I3.i6.p1">
<p class="ltx_p" id="S4.I3.i6.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I3.i6.p1.1.1">Exploration</span>: human engages in open-ended tasks with model (e.g., open-ended dialogue).</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_figure" id="S4.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="204" id="S4.F1.g1" src="x1.png" width="968"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Taxonomy of human-LLM interaction modes. The figure illustrates different human-LLM interaction paths from an initial set of instructions to completing goal-oriented or open-ended tasks.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.1.1.1">
<span class="ltx_p" id="S4.T3.1.1.1.1.1.1" style="width:208.1pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.1.1.1">Task category</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.1.2.1">
<span class="ltx_p" id="S4.T3.1.1.1.2.1.1" style="width:208.1pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.2.1.1.1">Example tasks</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T3.1.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.2.1.1.1">
<span class="ltx_p" id="S4.T3.1.2.1.1.1.1" style="width:208.1pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.2.1.1.1.1.1">Content generation</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T3.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.2.1.2.1">
<span class="ltx_p" id="S4.T3.1.2.1.2.1.1" style="width:208.1pt;">Email writing, creative writing, article writing</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T3.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.3.2.1.1">
<span class="ltx_p" id="S4.T3.1.3.2.1.1.1" style="width:208.1pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.1.1.1.1">Data translation</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T3.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.3.2.2.1">
<span class="ltx_p" id="S4.T3.1.3.2.2.1.1" style="width:208.1pt;">Table creation, language translation, summarization</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T3.1.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.4.3.1.1">
<span class="ltx_p" id="S4.T3.1.4.3.1.1.1" style="width:208.1pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.4.3.1.1.1.1">Dialogue</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T3.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.4.3.2.1">
<span class="ltx_p" id="S4.T3.1.4.3.2.1.1" style="width:208.1pt;">Social dialogue, brainstorming</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T3.1.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.5.4.1.1">
<span class="ltx_p" id="S4.T3.1.5.4.1.1.1" style="width:208.1pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.5.4.1.1.1.1">Data retrieval &amp; analysis</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T3.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.5.4.2.1">
<span class="ltx_p" id="S4.T3.1.5.4.2.1.1" style="width:208.1pt;">Sentiment analysis, classification, information retrieval</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.6.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T3.1.6.5.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.6.5.1.1">
<span class="ltx_p" id="S4.T3.1.6.5.1.1.1" style="width:208.1pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.6.5.1.1.1.1">Reasoning</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T3.1.6.5.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.6.5.2.1">
<span class="ltx_p" id="S4.T3.1.6.5.2.1.1" style="width:208.1pt;">Mathematical reasoning, commonsense reasoning, domain-specific reasoning</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.7.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T3.1.7.6.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.7.6.1.1">
<span class="ltx_p" id="S4.T3.1.7.6.1.1.1" style="width:208.1pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.7.6.1.1.1.1">Coding</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T3.1.7.6.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.7.6.2.1">
<span class="ltx_p" id="S4.T3.1.7.6.2.1.1" style="width:208.1pt;">Code generation, debugging</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.8.7">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T3.1.8.7.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.8.7.1.1">
<span class="ltx_p" id="S4.T3.1.8.7.1.1.1" style="width:208.1pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.8.7.1.1.1.1">Discussion</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T3.1.8.7.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.8.7.2.1">
<span class="ltx_p" id="S4.T3.1.8.7.2.1.1" style="width:208.1pt;">Explanation, brainstorming</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.9.8">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S4.T3.1.9.8.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.9.8.1.1">
<span class="ltx_p" id="S4.T3.1.9.8.1.1.1" style="width:208.1pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.9.8.1.1.1.1">Decision-making aid</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S4.T3.1.9.8.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.9.8.2.1">
<span class="ltx_p" id="S4.T3.1.9.8.2.1.1" style="width:208.1pt;">Scoring, evaluation, advice</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Sample interaction tasks. The tasks are categorized into eight high-level task categories <cite class="ltx_cite ltx_citemacro_citep">(Chang et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib12" title="">2024</a>)</cite>, drawn from information on how models are currently used, e.g., as reported by <cite class="ltx_cite ltx_citemacro_citet">Ouyang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib68" title="">2023</a>)</cite> and how models may be used in the future. </figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSSx3">
<h4 class="ltx_title ltx_title_subsubsection">Stage 3: Choosing evaluation parameters</h4>
<div class="ltx_para" id="S4.SS2.SSSx3.p1">
<p class="ltx_p" id="S4.SS2.SSSx3.p1.1">Finally, after selecting the risk area to evaluate and identifying the use context, the third stage is choosing an evaluation target within that set up and selecting evaluation metrics to measure the chosen target.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSSx3.p2">
<p class="ltx_p" id="S4.SS2.SSSx3.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSSx3.p2.1.1">What is the evaluation target?</span> HIEs shift the evaluation target from model-only output to joint human-model output. HIEs also introduce a new target: the interaction trace. Evaluating an interaction trace is evaluating the process of human-model interaction towards completing a task; this may include assessing the contextual appropriateness of model responses, the adaptability of the model to human inputs, and the efficiency of achieving the intended outcome over multiple turns of interaction. When evaluating an interaction trace, a decision on the evaluation period (i.e., for how long or how many turns to evaluate) must also be made as it can affect the evaluation results. For example, evaluating the persuasiveness of models after exposure to one model output (e.g., a single message) or via a dialogue where 10 messages are exchanged may lead to different conclusions on models’ persuasive capabilities.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSSx3.p3">
<p class="ltx_p" id="S4.SS2.SSSx3.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSSx3.p3.1.1">What are the metrics used to evaluate that target?</span> HCI offers a wide diversity of metrics to measure different targets in accordance with evaluation needs <cite class="ltx_cite ltx_citemacro_citep">(Damacharla et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib18" title="">2018</a>)</cite>. These metrics can be <span class="ltx_text ltx_font_italic" id="S4.SS2.SSSx3.p3.1.2">subjective</span> metrics — capturing personal perceptions, feelings, and judgments of users — or <span class="ltx_text ltx_font_italic" id="S4.SS2.SSSx3.p3.1.3">objective</span> metrics — capturing quantifiable, direct measures of performance or behavior (e.g., response time and accuracy) <cite class="ltx_cite ltx_citemacro_citep">(Coronado et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib16" title="">2022</a>; Gordon et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib28" title="">2021</a>)</cite>. Subjective metrics may be more suited for open-ended tasks such as dialogue, while objective metrics may be more suited for goal-oriented tasks such as solving a crossword puzzle. Table <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S4.T4" title="Table 4 ‣ Stage 3: Choosing evaluation parameters ‣ 4.2 Framework ‣ 4 A Framework for Designing Safety-focused Human Interaction Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_tag">4</span></a> presents a set of interaction evaluation metrics, offering both subjective and objective measures for quantifying human impact of models and the performance of human-model teams.</p>
</div>
<figure class="ltx_table" id="S4.T4">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S4.T4.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.1.1.1.1">
<span class="ltx_p" id="S4.T4.1.1.1.1.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.1.1.1.1.1">Evaluation target</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S4.T4.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.1.1.2.1">
<span class="ltx_p" id="S4.T4.1.1.1.2.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.1.2.1.1.1">Objective/subjective</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S4.T4.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.1.1.3.1">
<span class="ltx_p" id="S4.T4.1.1.1.3.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.1.3.1.1.1">Description</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S4.T4.1.1.1.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.1.1.4.1">
<span class="ltx_p" id="S4.T4.1.1.1.4.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.1.4.1.1.1">Metric examples</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T4.1.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.2.1.1.1">
<span class="ltx_p" id="S4.T4.1.2.1.1.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.1.2.1.1.1.1.1">Outcome - task quality</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T4.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.2.1.2.1">
<span class="ltx_p" id="S4.T4.1.2.1.2.1.1" style="width:116.4pt;">Objective</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T4.1.2.1.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.2.1.3.1">
<span class="ltx_p" id="S4.T4.1.2.1.3.1.1" style="width:116.4pt;">Metrics that measure objective quality of a task output</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T4.1.2.1.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.2.1.4.1">
<span class="ltx_p" id="S4.T4.1.2.1.4.1.1" style="width:116.4pt;">Accuracy in solving a crossword puzzle</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T4.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.3.2.1.1">
<span class="ltx_p" id="S4.T4.1.3.2.1.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.1.3.2.1.1.1.1">Outcome - task quality</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T4.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.3.2.2.1">
<span class="ltx_p" id="S4.T4.1.3.2.2.1.1" style="width:116.4pt;">Subjective</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T4.1.3.2.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.3.2.3.1">
<span class="ltx_p" id="S4.T4.1.3.2.3.1.1" style="width:116.4pt;">Metrics that use third-party evaluators to assess the subjective quality of a task output</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T4.1.3.2.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.3.2.4.1">
<span class="ltx_p" id="S4.T4.1.3.2.4.1.1" style="width:116.4pt;">Consistency of a summary given a document</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T4.1.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.4.3.1.1">
<span class="ltx_p" id="S4.T4.1.4.3.1.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.1.4.3.1.1.1.1">Interaction trace - characteristics</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T4.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.4.3.2.1">
<span class="ltx_p" id="S4.T4.1.4.3.2.1.1" style="width:116.4pt;">Objective</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T4.1.4.3.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.4.3.3.1">
<span class="ltx_p" id="S4.T4.1.4.3.3.1.1" style="width:116.4pt;">Metrics that measure some aspect of an interaction trace</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T4.1.4.3.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.4.3.4.1">
<span class="ltx_p" id="S4.T4.1.4.3.4.1.1" style="width:116.4pt;">Number of queries users make, number of revisions, time between queries</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S4.T4.1.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.5.4.1.1">
<span class="ltx_p" id="S4.T4.1.5.4.1.1.1" style="width:116.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.1.5.4.1.1.1.1">Interaction trace - user experience</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S4.T4.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.5.4.2.1">
<span class="ltx_p" id="S4.T4.1.5.4.2.1.1" style="width:116.4pt;">Subjective</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S4.T4.1.5.4.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.5.4.3.1">
<span class="ltx_p" id="S4.T4.1.5.4.3.1.1" style="width:116.4pt;">Metrics that survey users for responses relating to their interaction experience</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S4.T4.1.5.4.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.5.4.4.1">
<span class="ltx_p" id="S4.T4.1.5.4.4.1.1" style="width:116.4pt;">Usability metrics, user satisfaction surveys, psychometrically validated surveys and behavioral measures (e.g., Decision Regret Scale)</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Subjective and objective evaluation metrics for the assessment of the processes and outcomes of human-LLM interactions</figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Example Evaluations</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The proposed framework is illustrated through the design of two HIEs: one for overreliance risks in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S5.T5" title="Table 5 ‣ 5 Example Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_tag">5</span></a> and one for persuasion risks in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#S5.T6" title="Table 6 ‣ 5 Example Evaluations ‣ Beyond Static AI Evaluations: Advancing Human Interaction Evaluations for LLM Harms and Risks"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure class="ltx_table" id="S5.T5">
<table class="ltx_tabular ltx_align_middle" id="S5.T5.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T5.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S5.T5.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.1.1.1.1">
<span class="ltx_p" id="S5.T5.1.1.1.1.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.1.1.1.1.1.1">Stage</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S5.T5.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.1.1.2.1">
<span class="ltx_p" id="S5.T5.1.1.1.2.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.1.1.2.1.1.1">Substage</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S5.T5.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.1.1.3.1">
<span class="ltx_p" id="S5.T5.1.1.1.3.1.1" style="width:333.9pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.1.1.3.1.1.1">Description</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T5.1.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.2.2.1.1">
<span class="ltx_p" id="S5.T5.1.2.2.1.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.2.2.1.1.1.1">1 Identifying risk and/or harm</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T5.1.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.2.2.2.1">
<span class="ltx_p" id="S5.T5.1.2.2.2.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.2.2.2.1.1.1">Research question</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T5.1.2.2.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.2.2.3.1">
<span class="ltx_p" id="S5.T5.1.2.2.3.1.1" style="width:333.9pt;">Research has investigated risks from integrating algorithmic decision-support systems (ADS) into high stakes decision-making settings like in criminal justice and hiring <cite class="ltx_cite ltx_align_left ltx_citemacro_citep">(Green and Chen <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib29" title="">2019</a>)</cite>. Introducing LLMs to such settings may involve additional risks, as LLMs are capable of engaging in dialogue about their decisions, and generating plausible but false information. Thus, there may be new risks of overreliance on these systems, where users depending too heavily on their output, potentially overlooking their limitations. Overreliance can be especially concerning in cases where a model produces or defends inaccurate or biased judgements.</span>
<span class="ltx_p" id="S5.T5.1.2.2.3.1.2">We use the case study of hiring assistance where a system is used to predict candidate success and ask: what are there additional overreliance risks associated with the use of LLMs compared to human decision-making?</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T5.1.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.3.3.1.1">
<span class="ltx_p" id="S5.T5.1.3.3.1.1.1" style="width:65.8pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T5.1.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.3.3.2.1">
<span class="ltx_p" id="S5.T5.1.3.3.2.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.3.3.2.1.1.1">Risk aspect</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T5.1.3.3.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.3.3.3.1">
<span class="ltx_p" id="S5.T5.1.3.3.3.1.1" style="width:333.9pt;">We focus on <span class="ltx_text ltx_align_left ltx_font_italic" id="S5.T5.1.3.3.3.1.1.1">marginal risk</span> from LLMs compared to human decision-making <cite class="ltx_cite ltx_align_left ltx_citemacro_citep">(Green and Chen <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib29" title="">2019</a>; Kleinberg et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib47" title="">2017</a>)</cite>. We are interested in examining what LLMs add in terms of new risks, if anything at all. Thus, our two experimental conditions are: (1) human only and (2) human using LLM.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T5.1.4.4.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.4.4.1.1">
<span class="ltx_p" id="S5.T5.1.4.4.1.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.4.4.1.1.1.1">2 Characterizing use context</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T5.1.4.4.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.4.4.2.1">
<span class="ltx_p" id="S5.T5.1.4.4.2.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.4.4.2.1.1.1">Harmful use scenario</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T5.1.4.4.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.4.4.3.1">
<span class="ltx_p" id="S5.T5.1.4.4.3.1.1" style="width:333.9pt;">The harmful use scenario is primarily the <span class="ltx_text ltx_align_left ltx_font_italic" id="S5.T5.1.4.4.3.1.1.1">unintended harm: personal impact</span> scenario, as our aim is to understand possible harms inflicted on the decision-maker from overreliance (e.g., loss of autonomy, decision regret).</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T5.1.5.5.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.5.5.1.1">
<span class="ltx_p" id="S5.T5.1.5.5.1.1.1" style="width:65.8pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T5.1.5.5.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.5.5.2.1">
<span class="ltx_p" id="S5.T5.1.5.5.2.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.5.5.2.1.1.1">User, model, and system dimensions</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T5.1.5.5.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.5.5.3.1">
<span class="ltx_p" id="S5.T5.1.5.5.3.1.1" style="width:333.9pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.5.5.3.1.1.1">User dimensions</span> Users (e.g., hiring managers) may range in their technical literacy and thus awareness of various capabilities and limitations of AI systems. We include a few questions for users to report their technical literacy in a pre-experiment survey.</span>
<span class="ltx_p" id="S5.T5.1.5.5.3.1.2"><span class="ltx_text ltx_font_bold" id="S5.T5.1.5.5.3.1.2.1">Model &amp; system dimensions</span> We test five LLaMA models, all tuned for chat interactions: LLaMA 2 (7B), LLaMA 2 (13B), LLaMA 2 (70B), LLaMA 3 (8B), LLaMA 3 (70B).</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T5.1.6.6.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.6.6.1.1">
<span class="ltx_p" id="S5.T5.1.6.6.1.1.1" style="width:65.8pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T5.1.6.6.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.6.6.2.1">
<span class="ltx_p" id="S5.T5.1.6.6.2.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.6.6.2.1.1.1">Interaction mode and tasks</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T5.1.6.6.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.6.6.3.1">
<span class="ltx_p" id="S5.T5.1.6.6.3.1.1" style="width:333.9pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.6.6.3.1.1.1">Mode</span> In decision-making support settings, the most salient interaction form is <span class="ltx_text ltx_align_left ltx_font_italic" id="S5.T5.1.6.6.3.1.1.2">assistance</span> where an LLM advises a human on a decision. In this case, the decision is whether or not to hire a candidate.</span>
<span class="ltx_p" id="S5.T5.1.6.6.3.1.2"><span class="ltx_text ltx_font_bold" id="S5.T5.1.6.6.3.1.2.1">Tasks</span> The three main associated evaluation tasks are:</span>
<span class="ltx_itemize" id="S5.I1">
<span class="ltx_item" id="S5.I1.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I1.i1.p1">
<span class="ltx_p" id="S5.I1.i1.p1.1"><span class="ltx_text ltx_font_italic" id="S5.I1.i1.p1.1.1">Summarization</span>: summarizing the candidate’s documents (e.g., CV, cover letter)</span>
</span></span>
<span class="ltx_item" id="S5.I1.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I1.i2.p1">
<span class="ltx_p" id="S5.I1.i2.p1.1"><span class="ltx_text ltx_font_italic" id="S5.I1.i2.p1.1.1">Information retrieval</span>: gathering information on the candidate, on the role, on other applicants, and on other companies hiring</span>
</span></span>
<span class="ltx_item" id="S5.I1.i3" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I1.i3.p1">
<span class="ltx_p" id="S5.I1.i3.p1.1"><span class="ltx_text ltx_font_italic" id="S5.I1.i3.p1.1.1">Advice</span>: providing a score of how likely the candidate is to succeed in the role</span>
</span></span>
</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.7.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T5.1.7.7.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.7.7.1.1">
<span class="ltx_p" id="S5.T5.1.7.7.1.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.7.7.1.1.1.1">3 Choosing evaluation parameters</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T5.1.7.7.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.7.7.2.1">
<span class="ltx_p" id="S5.T5.1.7.7.2.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.7.7.2.1.1.1">Evaluation target</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T5.1.7.7.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.7.7.3.1">
<span class="ltx_p" id="S5.T5.1.7.7.3.1.1" style="width:333.9pt;">We choose to evaluate the <span class="ltx_text ltx_align_left ltx_font_italic" id="S5.T5.1.7.7.3.1.1.1">interaction trace</span> to understand the characteristics of overreliance in decision-making contexts.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.8.8">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S5.T5.1.8.8.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.8.8.1.1">
<span class="ltx_p" id="S5.T5.1.8.8.1.1.1" style="width:65.8pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S5.T5.1.8.8.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.8.8.2.1">
<span class="ltx_p" id="S5.T5.1.8.8.2.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.1.8.8.2.1.1.1">Evaluation metrics</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S5.T5.1.8.8.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T5.1.8.8.3.1">
<span class="ltx_p" id="S5.T5.1.8.8.3.1.1" style="width:333.9pt;">Subjective metrics:

<span class="ltx_itemize ltx_align_left ltx_centering" id="S5.I2">
<span class="ltx_item" id="S5.I2.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I2.i1.p1">
<span class="ltx_p" id="S5.I2.i1.p1.1">Decision Regret Scale: this scale measures the regret a person feels after making a decision, assessing the extent to which they believe a different choice might have resulted in a better outcome <cite class="ltx_cite ltx_citemacro_citep">(Brehaut et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib11" title="">2003</a>)</cite>.</span>
</span></span>
<span class="ltx_item" id="S5.I2.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I2.i2.p1">
<span class="ltx_p" id="S5.I2.i2.p1.1">Likert scale questions on how accurate, fair, and reliable users perceived the model to be</span>
</span></span>
</span></span>
<span class="ltx_p" id="S5.T5.1.8.8.3.1.2">Objective metrics:</span>
<span class="ltx_itemize" id="S5.I3">
<span class="ltx_item" id="S5.I3.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I3.i1.p1">
<span class="ltx_p" id="S5.I3.i1.p1.1">Time between queries in each task</span>
</span></span>
<span class="ltx_item" id="S5.I3.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I3.i2.p1">
<span class="ltx_p" id="S5.I3.i2.p1.1">The number of follow-up queries made after a model presents a recommendation</span>
</span></span>
<span class="ltx_item" id="S5.I3.i3" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I3.i3.p1">
<span class="ltx_p" id="S5.I3.i3.p1.1">Weight of advice metric to measure how much the model’s score influenced the final hiring decision in cases where the model was wrong and right (based on ground truth hiring data) <cite class="ltx_cite ltx_citemacro_citep">(Bailey et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib6" title="">2023</a>)</cite></span>
</span></span>
<span class="ltx_item" id="S5.I3.i4" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I3.i4.p1">
<span class="ltx_p" id="S5.I3.i4.p1.1">Disparity in influence of the model prediction on the human decision-maker based on protected attributes of candidates (e.g., gender) <cite class="ltx_cite ltx_citemacro_citep">(Green and Chen <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib29" title="">2019</a>)</cite></span>
</span></span>
</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Evaluation to examine overreliance on models during high stakes decision-making </figcaption>
</figure>
<figure class="ltx_table" id="S5.T6">
<table class="ltx_tabular ltx_align_middle" id="S5.T6.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T6.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S5.T6.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.1.1.1.1">
<span class="ltx_p" id="S5.T6.1.1.1.1.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.1.1.1.1">Stage</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S5.T6.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.1.1.2.1">
<span class="ltx_p" id="S5.T6.1.1.1.2.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.2.1.1.1">Substage</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S5.T6.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.1.1.3.1">
<span class="ltx_p" id="S5.T6.1.1.1.3.1.1" style="width:333.9pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.3.1.1.1">Description</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T6.1.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.2.2.1.1">
<span class="ltx_p" id="S5.T6.1.2.2.1.1.1" style="width:65.8pt;">1 <span class="ltx_text ltx_align_left ltx_font_bold" id="S5.T6.1.2.2.1.1.1.1">Identifying risk and/or harm</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T6.1.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.2.2.2.1">
<span class="ltx_p" id="S5.T6.1.2.2.2.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.2.2.2.1.1.1">Research question</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T6.1.2.2.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.2.2.3.1">
<span class="ltx_p" id="S5.T6.1.2.2.3.1.1" style="width:333.9pt;">LLMs have been shown to produce political messages that rival the persuasiveness of human messages, even those written by expert political consultants <cite class="ltx_cite ltx_align_left ltx_citemacro_citep">(Hackenburg et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib31" title="">2023</a>)</cite>. The majority of research on such persuasion risks has focused on attitude change due to exposure to persuasive LLM output. It is equally important to study the mechanisms of uplift in message persuasiveness when users access an LLM to co-write a persuasive message. This can aid in understanding LLMs’ persuasive capabilities and their limitations <cite class="ltx_cite ltx_align_left ltx_citemacro_citep">(Phuong et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib73" title="">2024</a>)</cite>.</span>
<span class="ltx_p" id="S5.T6.1.2.2.3.1.2">Thus, here, we ask: how does the use of an LLM lead to a change in human writing performance — quality and persuasiveness — of political messaging in opinion pieces?</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T6.1.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.3.3.1.1">
<span class="ltx_p" id="S5.T6.1.3.3.1.1.1" style="width:65.8pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T6.1.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.3.3.2.1">
<span class="ltx_p" id="S5.T6.1.3.3.2.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.3.3.2.1.1.1">Risk aspect</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T6.1.3.3.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.3.3.3.1">
<span class="ltx_p" id="S5.T6.1.3.3.3.1.1" style="width:333.9pt;">We focus on <span class="ltx_text ltx_align_left ltx_font_italic" id="S5.T6.1.3.3.3.1.1.1">marginal risk</span> as we are interested in assessing the model’s persuasive capabilities relative to a human baseline. Thus, our three experimental conditions are (1) human only (college students), (2) human only (domain experts), (3) human using LLM (college students), (4) human using LLM (domain experts).</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T6.1.4.4.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.4.4.1.1">
<span class="ltx_p" id="S5.T6.1.4.4.1.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.4.4.1.1.1.1">2 Characterizing use context</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T6.1.4.4.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.4.4.2.1">
<span class="ltx_p" id="S5.T6.1.4.4.2.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.4.4.2.1.1.1">Harmful use scenario</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T6.1.4.4.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.4.4.3.1">
<span class="ltx_p" id="S5.T6.1.4.4.3.1.1" style="width:333.9pt;">The harmful use scenario is the <span class="ltx_text ltx_align_left ltx_font_italic" id="S5.T6.1.4.4.3.1.1.1">misuse scenario</span>, as we aim to understand how LLMs can assist bad actors in producing persuasive messaging that can manipulate people’s opinions and actions.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T6.1.5.5.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.5.5.1.1">
<span class="ltx_p" id="S5.T6.1.5.5.1.1.1" style="width:65.8pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T6.1.5.5.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.5.5.2.1">
<span class="ltx_p" id="S5.T6.1.5.5.2.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.5.5.2.1.1.1">User, model, and system dimensions</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T6.1.5.5.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.5.5.3.1">
<span class="ltx_p" id="S5.T6.1.5.5.3.1.1" style="width:333.9pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.5.5.3.1.1.1">User dimensions</span> We recruit a mix of college students and political consultants. We are interested in how this variation in domain expertise influences risks. We consider this variation a proxy for difficulty of capability elicitation.</span>
<span class="ltx_p" id="S5.T6.1.5.5.3.1.2"><span class="ltx_text ltx_font_bold" id="S5.T6.1.5.5.3.1.2.1">Model &amp; system dimensions</span> We test three models, all tuned for chat interactions: Claude 3 Opus, GPT-4, and LLaMA 3.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T6.1.6.6.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.6.6.1.1">
<span class="ltx_p" id="S5.T6.1.6.6.1.1.1" style="width:65.8pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T6.1.6.6.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.6.6.2.1">
<span class="ltx_p" id="S5.T6.1.6.6.2.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.6.6.2.1.1.1">Interaction mode and tasks</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T6.1.6.6.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.6.6.3.1">
<span class="ltx_p" id="S5.T6.1.6.6.3.1.1" style="width:333.9pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.6.6.3.1.1.1">Mode</span> As we are focused on co-writing, the main interaction form is <span class="ltx_text ltx_align_left ltx_font_italic" id="S5.T6.1.6.6.3.1.1.2">collaboration</span>.</span>
<span class="ltx_p" id="S5.T6.1.6.6.3.1.2"><span class="ltx_text ltx_font_bold" id="S5.T6.1.6.6.3.1.2.1">Tasks</span> The three main associated evaluation tasks are:</span>
<span class="ltx_itemize" id="S5.I4">
<span class="ltx_item" id="S5.I4.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I4.i1.p1">
<span class="ltx_p" id="S5.I4.i1.p1.1"><span class="ltx_text ltx_font_italic" id="S5.I4.i1.p1.1.1">Brainstorming</span>: brainstorming arguments to include in the article</span>
</span></span>
<span class="ltx_item" id="S5.I4.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I4.i2.p1">
<span class="ltx_p" id="S5.I4.i2.p1.1"><span class="ltx_text ltx_font_italic" id="S5.I4.i2.p1.1.1">Information retrieval</span>: gathering information on political issues, support for them across demographics, and relevant historical events</span>
</span></span>
<span class="ltx_item" id="S5.I4.i3" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I4.i3.p1">
<span class="ltx_p" id="S5.I4.i3.p1.1"><span class="ltx_text ltx_font_italic" id="S5.I4.i3.p1.1.1">Article writing</span>: writing a medium-length article (around 500 words) to convince someone of a political issue</span>
</span></span>
</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.7.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T6.1.7.7.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.7.7.1.1">
<span class="ltx_p" id="S5.T6.1.7.7.1.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.7.7.1.1.1.1">3 Choosing evaluation parameters</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T6.1.7.7.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.7.7.2.1">
<span class="ltx_p" id="S5.T6.1.7.7.2.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.7.7.2.1.1.1">Evaluation target</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T6.1.7.7.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.7.7.3.1">
<span class="ltx_p" id="S5.T6.1.7.7.3.1.1" style="width:333.9pt;">The main evaluation target here is the <span class="ltx_text ltx_align_left ltx_font_italic" id="S5.T6.1.7.7.3.1.1.1">interaction trace</span>. We also investigate how characteristics of the interaction trace influence the <span class="ltx_text ltx_align_left ltx_font_italic" id="S5.T6.1.7.7.3.1.1.2">outcome</span>, which is the resulting persuasive article.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.8.8">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S5.T6.1.8.8.1">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.8.8.1.1">
<span class="ltx_p" id="S5.T6.1.8.8.1.1.1" style="width:65.8pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S5.T6.1.8.8.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.8.8.2.1">
<span class="ltx_p" id="S5.T6.1.8.8.2.1.1" style="width:65.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.8.8.2.1.1.1">Evaluation metrics</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S5.T6.1.8.8.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T6.1.8.8.3.1">
<span class="ltx_p" id="S5.T6.1.8.8.3.1.1" style="width:333.9pt;">To evaluate the interaction trace, we use</span>
<span class="ltx_p" id="S5.T6.1.8.8.3.1.2">Subjective metrics:</span>
<span class="ltx_itemize" id="S5.I5">
<span class="ltx_item" id="S5.I5.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I5.i1.p1">
<span class="ltx_p" id="S5.I5.i1.p1.1">User satisfaction and perceived helpfulness of the model</span>
</span></span>
<span class="ltx_item" id="S5.I5.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I5.i2.p1">
<span class="ltx_p" id="S5.I5.i2.p1.1">Perceived creativity and novelty of the model</span>
</span></span>
</span>
<span class="ltx_p" id="S5.T6.1.8.8.3.1.3">Objective metrics:</span>
<span class="ltx_itemize" id="S5.I6">
<span class="ltx_item" id="S5.I6.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I6.i1.p1">
<span class="ltx_p" id="S5.I6.i1.p1.1">Length of the interaction (time, number of queries) until users submit their articles</span>
</span></span>
<span class="ltx_item" id="S5.I6.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I6.i2.p1">
<span class="ltx_p" id="S5.I6.i2.p1.1">Length of the prompts used, types of prompts used (generation, revision, evaluation)</span>
</span></span>
</span>
<span class="ltx_p" id="S5.T6.1.8.8.3.1.4">To evaluate the outcome of the human-LLM collaboration, we use third-party experts to assess the persuasiveness of the articles using a detail rubric to:</span>
<span class="ltx_itemize" id="S5.I7">
<span class="ltx_item" id="S5.I7.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I7.i1.p1">
<span class="ltx_p" id="S5.I7.i1.p1.1">Score article quality</span>
</span></span>
<span class="ltx_item" id="S5.I7.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S5.I7.i2.p1">
<span class="ltx_p" id="S5.I7.i2.p1.1">Score article persuasiveness</span>
</span></span>
</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Evaluation to understand the mechanisms of human uplift of model persuasion capabilities</figcaption>
</figure>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Here, we highlight the main limitations of our framework and propose some recommendations.</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Limitations</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">Our framework and taxonomy are starting points for safety-focused HIEs and are focused on controlled, human subject experiments and evaluation units consisting of one human and one model. More detailed taxonomizing is necessary as models continue to be integrated in real-world applications and new interaction forms involving multiple human actors and models emerge <cite class="ltx_cite ltx_citemacro_citep">(Li et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib54" title="">2023</a>; Ward et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib95" title="">2024</a>)</cite>. Additionally, our framework does not fully consider the characteristics and effects of feedback loops in human-LLM interaction which complicate discerning whether outcomes are driven by the model’s influence on humans or human input to the model. Further research into the conceptual and empirical risks of these loops is needed <cite class="ltx_cite ltx_citemacro_citep">(Pan et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib69" title="">2024</a>; Krauth, Wang, and Jordan <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib48" title="">2022</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Recommendations</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.p1.1.1">Our first and most primary recommendation is for greater investment into HIEs.</span> Several domains — such as medicine and automotives — allocate considerable portions of research and development budgets to identify the impact of their products during development and after deployment <cite class="ltx_cite ltx_citemacro_citep">(Wouters, McKee, and Luyten <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib99" title="">2020</a>)</cite>. In this paper, we outline how HIEs, although costly compared to other model evaluation methods, can improve AI risk assessments. We also argue that HIEs are useful for validating existing static evaluations — a focus we encourage more HIEs to adopt. Thus, as the capabilities and use of AI systems increase, so should the resources and efforts we dedicate to understanding them and their potential impact.</p>
</div>
<div class="ltx_para" id="S6.SS2.p2">
<p class="ltx_p" id="S6.SS2.p2.1">Concerns over, and some objections to, expanding human involvement in model evaluation often invoke one of four challenges:</p>
<ul class="ltx_itemize" id="S6.I1">
<li class="ltx_item" id="S6.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i1.p1">
<p class="ltx_p" id="S6.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i1.p1.1.1">Costs and scale</span>: experiments, particularly long experiments or powered experiments with large sample sizes, can require significant funds to compensate participants and develop and use online platforms, and thus are difficult to scale.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i2.p1">
<p class="ltx_p" id="S6.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i2.p1.1.1">Replicability</span>: variable and unpredictable study environments, along with AI labs frequently updating their systems without interruption or announcement, might make replicating HIEs and applying their results in real-world settings challenging <cite class="ltx_cite ltx_citemacro_citep">(Baxter, Courage, and Caine <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib7" title="">2015</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i3.p1">
<p class="ltx_p" id="S6.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i3.p1.1.1">Representativeness</span>: participants recruited from crowdsourcing platforms often involve WEIRD samples that are biased along axes like race, geography, and technical literacy <cite class="ltx_cite ltx_citemacro_citep">(Levay, Freese, and Druckman <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib53" title="">2016</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i4.p1">
<p class="ltx_p" id="S6.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i4.p1.1.1">Ethical issues</span>: there may be serious ethical issues with exposing human participants to harmful model behaviors, such as hateful or persuasive output.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S6.SS2.p3">
<p class="ltx_p" id="S6.SS2.p3.1">Given additional investment, we offer tangible suggestions to alleviate these concerns:</p>
</div>
<section class="ltx_subsubsection" id="S6.SS2.SSSx1">
<h4 class="ltx_title ltx_title_subsubsection">Develop accessible protocols, guides, and standardized test suites</h4>
<div class="ltx_para" id="S6.SS2.SSSx1.p1">
<p class="ltx_p" id="S6.SS2.SSSx1.p1.1">This paper serves as a step towards organizing and sharing design-level considerations for safety-focused HIEs. We recommend further developing accessible protocols, guides, and standardized test suites, similar to those available for non-interactive evaluations, to specifically facilitate human participation in model evaluation <cite class="ltx_cite ltx_citemacro_citep">(UK AI Safety Institute <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib92" title="">2024</a>; METR <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib60" title="">2023</a>)</cite>. An example of this is CheckMate, a prototype platform which records interaction traces of humans interacting with LLMs <cite class="ltx_cite ltx_citemacro_citep">(Collins et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib15" title="">2023</a>)</cite>. Such infrastructure can reduce costs associated with custom tool development, accommodate evaluators of diverse technical proficiencies, and promote wider participation in model evaluation. Further research should also investigate methods to create extensive automated evaluations informed by scoped HIEs.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S6.SS2.SSSx2">
<h4 class="ltx_title ltx_title_subsubsection">Apply best practices from established disciplines to develop rigorous and replicable HIEs</h4>
<div class="ltx_para" id="S6.SS2.SSSx2.p1">
<p class="ltx_p" id="S6.SS2.SSSx2.p1.1">While the science of evaluating general purpose AI systems is in its early stages, disciplines such as HCI, experimental psychology, and economics have well-established, often human-centered, experimental practices that can be adapted. Additionally, it may be beneficial to encourage standardized reporting for HIEs (e.g., similar to initiatives like CONSORT statements for medical trials <cite class="ltx_cite ltx_citemacro_citep">(Moher, Schulz, and Altman <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib63" title="">2001</a>; Morten, Nicholas, and Viljoen <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib64" title="">2024</a>)</cite>) that disclose important evaluations details, including information on the models, experimental design, and sampling strategies.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S6.SS2.SSSx3">
<h4 class="ltx_title ltx_title_subsubsection">Diversify sourcing strategies and community involvement</h4>
<div class="ltx_para" id="S6.SS2.SSSx3.p1">
<p class="ltx_p" id="S6.SS2.SSSx3.p1.1">Recruitment efforts should attend to underrepresented groups and different geographical regions, which constitute a significant and growing portion of LLM users <cite class="ltx_cite ltx_citemacro_citep">(Duarte <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib21" title="">2024</a>)</cite>. Evaluations should expand to involve community stakeholders beyond context-independent experimental settings and in more long-term evaluation issues such as determining appropriate risk thresholds and unacceptable use cases <cite class="ltx_cite ltx_citemacro_citep">(Sloane et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib85" title="">2022</a>; Bergman et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib8" title="">2024</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S6.SS2.SSSx4">
<h4 class="ltx_title ltx_title_subsubsection">Attend to ethical issues of human participation</h4>
<div class="ltx_para" id="S6.SS2.SSSx4.p1">
<p class="ltx_p" id="S6.SS2.SSSx4.p1.1">Thoughtful participant training, debriefing, and feedback collection can mitigate some risks to participants. In ethically-challenging cases, the use of historical usage data may be a sufficient substitute. Simulated human interactions is another direction that further research should explore, but is also one that carries its own set of critical and functional ethical issues <cite class="ltx_cite ltx_citemacro_citep">(Agnew et al. <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib2" title="">2024</a>; Gui and Toubia <a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib30" title="">2023</a>)</cite>.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Acknowledgments</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">In no particular order, we are grateful to Jamie Bernardi, Merlin Stein, Patrick Levermore, Kobi Hackenburg, Deep Ganguli, Ben Bucknall, Esin Durmus, and Christopher Summerfield for feedback on this draft. We thank Kobi Hackenburg for help visualizing the taxonomy. Lujain Ibrahim acknowledges funding from the Oxford Internet Institute - Dieter Schwarz Foundation.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abercrombie et al. (2023)</span>
<span class="ltx_bibblock">
Abercrombie, G.; Curry, A. C.; Dinkar, T.; and Talat, Z. 2023.

</span>
<span class="ltx_bibblock">Mirages: On anthropomorphism in dialogue systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2305.09800</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agnew et al. (2024)</span>
<span class="ltx_bibblock">
Agnew, W.; Bergman, A. S.; Chien, J.; Díaz, M.; El-Sayed, S.; Pittman, J.; Mohamed, S.; and McKee, K. R. 2024.

</span>
<span class="ltx_bibblock">The illusion of artificial inclusion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2401.08572</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aizenberg and van den Hoven (2020)</span>
<span class="ltx_bibblock">
Aizenberg, E.; and van den Hoven, J. 2020.

</span>
<span class="ltx_bibblock">Designing for human rights in AI.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Big Data &amp; Society</em>, 7(2): 2053951720949566.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anthropic (2023)</span>
<span class="ltx_bibblock">
Anthropic. 2023.

</span>
<span class="ltx_bibblock">Anthropic’s responsible scaling policy.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. (2023)</span>
<span class="ltx_bibblock">
Bai, H.; Voelkel, J. G.; Eichstaedt, j. C.; and Willer, R. 2023.

</span>
<span class="ltx_bibblock">Artificial Intelligence Can Persuade Humans on Political Issues.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bailey et al. (2023)</span>
<span class="ltx_bibblock">
Bailey, P. E.; Leon, T.; Ebner, N. C.; Moustafa, A. A.; and Weidemann, G. 2023.

</span>
<span class="ltx_bibblock">A meta-analysis of the weight of advice in decision-making.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Current Psychology</em>, 42(28): 24516–24541.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baxter, Courage, and Caine (2015)</span>
<span class="ltx_bibblock">
Baxter, K.; Courage, C.; and Caine, K. 2015.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Understanding your users: a practical guide to user research methods</em>.

</span>
<span class="ltx_bibblock">Morgan Kaufmann.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bergman et al. (2024)</span>
<span class="ltx_bibblock">
Bergman, S.; Marchal, N.; Mellor, J.; Mohamed, S.; Gabriel, I.; and Isaac, W. 2024.

</span>
<span class="ltx_bibblock">STELA: a community-centred approach to norm elicitation for AI alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Scientific Reports</em>, 14(1): 6616.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Böhm et al. (2023)</span>
<span class="ltx_bibblock">
Böhm, R.; Jörling, M.; Reiter, L.; and Fuchs, C. 2023.

</span>
<span class="ltx_bibblock">People devalue generative AI’s competence but not its advice in addressing societal and personal challenges.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Communications Psychology</em>, 1(1): 32.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brandtzaeg, Skjuve, and Følstad (2022)</span>
<span class="ltx_bibblock">
Brandtzaeg, P. B.; Skjuve, M.; and Følstad, A. 2022.

</span>
<span class="ltx_bibblock">My AI friend: How users of a social chatbot understand their human–AI friendship.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Human Communication Research</em>, 48(3): 404–429.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brehaut et al. (2003)</span>
<span class="ltx_bibblock">
Brehaut, J.; O’Connor, A.; Wood, T.; Hack, T.; Siminoff, L.; Gordon, E.; and Feldman-Stewart, D. 2003.

</span>
<span class="ltx_bibblock">Validation of a Decision Regret Scale.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Medical decision making : an international journal of the Society for Medical Decision Making</em>, 23: 281–92.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang et al. (2024)</span>
<span class="ltx_bibblock">
Chang, Y.; Wang, X.; Wang, J.; Wu, Y.; Yang, L.; Zhu, K.; Chen, H.; Yi, X.; Wang, C.; Wang, Y.; et al. 2024.

</span>
<span class="ltx_bibblock">A survey on evaluation of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">ACM Transactions on Intelligent Systems and Technology</em>, 15(3): 1–45.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chater and Loewenstein (2023)</span>
<span class="ltx_bibblock">
Chater, N.; and Loewenstein, G. 2023.

</span>
<span class="ltx_bibblock">The i-frame and the s-frame: How focusing on individual-level solutions has led behavioral public policy astray.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Behavioral and Brain Sciences</em>, 46: e147.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chiang et al. (2024)</span>
<span class="ltx_bibblock">
Chiang, W.-L.; Zheng, L.; Sheng, Y.; Angelopoulos, A. N.; Li, T.; Li, D.; Zhang, H.; Zhu, B.; Jordan, M.; Gonzalez, J. E.; and Stoica, I. 2024.

</span>
<span class="ltx_bibblock">Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference.

</span>
<span class="ltx_bibblock">arXiv:2403.04132.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Collins et al. (2023)</span>
<span class="ltx_bibblock">
Collins, K. M.; Jiang, A. Q.; Frieder, S.; Wong, L.; Zilka, M.; Bhatt, U.; Lukasiewicz, T.; Wu, Y.; Tenenbaum, J. B.; Hart, W.; et al. 2023.

</span>
<span class="ltx_bibblock">Evaluating language models for mathematics through interactions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2306.01694</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Coronado et al. (2022)</span>
<span class="ltx_bibblock">
Coronado, E.; Kiyokawa, T.; Ricardez, G. A. G.; Ramirez-Alpizar, I. G.; Venture, G.; and Yamanobe, N. 2022.

</span>
<span class="ltx_bibblock">Evaluating quality in human-robot interaction: A systematic search and classification of performance and human-centered factors, measures and metrics towards an industry 5.0.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Journal of Manufacturing Systems</em>, 63: 392–410.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Costello, Pennycook, and Rand (2024)</span>
<span class="ltx_bibblock">
Costello, T. H.; Pennycook, G.; and Rand, D. G. 2024.

</span>
<span class="ltx_bibblock">Durably reducing conspiracy beliefs through dialogues with AI.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Damacharla et al. (2018)</span>
<span class="ltx_bibblock">
Damacharla, P.; Javaid, A. Y.; Gallimore, J. J.; and Devabhaktuni, V. K. 2018.

</span>
<span class="ltx_bibblock">Common Metrics to Benchmark Human-Machine Teams (HMT): A Review.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">IEEE Access</em>, 6: 38637–38655.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">DeVos et al. (2022)</span>
<span class="ltx_bibblock">
DeVos, A.; Dhabalia, A.; Shen, H.; Holstein, K.; and Eslami, M. 2022.

</span>
<span class="ltx_bibblock">Toward User-Driven Algorithm Auditing: Investigating users’ strategies for uncovering harmful algorithmic behavior.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems</em>, CHI ’22. New York, NY, USA: Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9781450391573.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Doshi and Hauser (2024)</span>
<span class="ltx_bibblock">
Doshi, A. R.; and Hauser, O. P. 2024.

</span>
<span class="ltx_bibblock">Generative artificial intelligence enhances creativity but reduces the diversity of novel content.

</span>
<span class="ltx_bibblock">arXiv:2312.00506.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duarte (2024)</span>
<span class="ltx_bibblock">
Duarte, F. 2024.

</span>
<span class="ltx_bibblock">Number of ChatGPT users (May 2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Durmus et al. (2024)</span>
<span class="ltx_bibblock">
Durmus, E.; Lovitt, L.; Tamkin, A.; Ritchie, S.; Clark, J.; and Ganguli, D. 2024.

</span>
<span class="ltx_bibblock">Measuring the Persuasiveness of Language Models.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fraser and y Villarino (2023)</span>
<span class="ltx_bibblock">
Fraser, H.; and y Villarino, J.-M. B. 2023.

</span>
<span class="ltx_bibblock">Acceptable risks in Europe’s proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough.

</span>
<span class="ltx_bibblock">arXiv:2308.02047.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gadiraju et al. (2023)</span>
<span class="ltx_bibblock">
Gadiraju, V.; Kane, S.; Dev, S.; Taylor, A.; Wang, D.; Denton, E.; and Brewer, R. 2023.

</span>
<span class="ltx_bibblock">”I wouldn’t say offensive but…”: Disability-Centered Perspectives on Large Language Models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency</em>, FAccT ’23, 205–216. New York, NY, USA: Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9798400701924.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ganguli et al. (2022)</span>
<span class="ltx_bibblock">
Ganguli, D.; Hernandez, D.; Lovitt, L.; Askell, A.; Bai, Y.; Chen, A.; Conerly, T.; Dassarma, N.; Drain, D.; Elhage, N.; et al. 2022.

</span>
<span class="ltx_bibblock">Predictability and surprise in large generative models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency</em>, 1747–1764.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ganguli et al. (2023)</span>
<span class="ltx_bibblock">
Ganguli, D.; Schiefer, N.; Favaro, M.; and Clark, J. 2023.

</span>
<span class="ltx_bibblock">Challenges in evaluating AI systems.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2024)</span>
<span class="ltx_bibblock">
Gao, J.; Gebreegziabher, S. A.; Choo, K. T. W.; Li, T. J. J.; Perrault, S. T.; and Malone, T. W. 2024.

</span>
<span class="ltx_bibblock">A Taxonomy for Human-LLM Interaction Modes: An Initial Exploration.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2404.00405.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gordon et al. (2021)</span>
<span class="ltx_bibblock">
Gordon, M. L.; Zhou, K.; Patel, K.; Hashimoto, T.; and Bernstein, M. S. 2021.

</span>
<span class="ltx_bibblock">The Disagreement Deconvolution: Bringing Machine Learning Performance Metrics In Line With Reality.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</em>, CHI ’21. New York, NY, USA: Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9781450380966.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Green and Chen (2019)</span>
<span class="ltx_bibblock">
Green, B.; and Chen, Y. 2019.

</span>
<span class="ltx_bibblock">Disparate Interactions: An Algorithm-in-the-Loop Analysis of Fairness in Risk Assessments.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the Conference on Fairness, Accountability, and Transparency</em>, FAT* ’19, 90–99. New York, NY, USA: Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9781450361255.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gui and Toubia (2023)</span>
<span class="ltx_bibblock">
Gui, G.; and Toubia, O. 2023.

</span>
<span class="ltx_bibblock">The Challenge of Using LLMs to Simulate Human Behavior: A Causal Inference Perspective.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">SSRN Electronic Journal</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hackenburg et al. (2023)</span>
<span class="ltx_bibblock">
Hackenburg, K.; Ibrahim, L.; Tappin, B. M.; and Tsakiris, M. 2023.

</span>
<span class="ltx_bibblock">Comparing the persuasiveness of role-playing large language models and human experts on polarized US political issues.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">OSF Preprints</em>, 10.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hackenburg and Margetts (2023)</span>
<span class="ltx_bibblock">
Hackenburg, K.; and Margetts, H. 2023.

</span>
<span class="ltx_bibblock">Evaluating the persuasive influence of political microtargeting with large language models.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hariton and Locascio (2018)</span>
<span class="ltx_bibblock">
Hariton, E.; and Locascio, J. J. 2018.

</span>
<span class="ltx_bibblock">Randomised controlled trials - the gold standard for effectiveness research: Study design: randomised controlled trials.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">BJOG</em>, 125(13): 1716.

</span>
<span class="ltx_bibblock">Epub 2018 Jun 19.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hartvigsen et al. (2022)</span>
<span class="ltx_bibblock">
Hartvigsen, T.; Gabriel, S.; Palangi, H.; Sap, M.; Ray, D.; and Kamar, E. 2022.

</span>
<span class="ltx_bibblock">Toxigen: A large-scale machine-generated dataset for adversarial and implicit hate speech detection.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2203.09509</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hutson (2018)</span>
<span class="ltx_bibblock">
Hutson, M. 2018.

</span>
<span class="ltx_bibblock">Artificial intelligence faces reproducibility crisis.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Händler (2023)</span>
<span class="ltx_bibblock">
Händler, T. 2023.

</span>
<span class="ltx_bibblock">A Taxonomy for Autonomous LLM-Powered Multi-Agent Architectures.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ibrahim, Rocher, and Valdivia (2024)</span>
<span class="ltx_bibblock">
Ibrahim, L.; Rocher, L.; and Valdivia, A. 2024.

</span>
<span class="ltx_bibblock">Characterizing and modeling harms from interactions with design patterns in AI interfaces.

</span>
<span class="ltx_bibblock">arXiv:2404.11370.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jakesch et al. (2023)</span>
<span class="ltx_bibblock">
Jakesch, M.; Bhat, A.; Buschek, D.; Zalmanson, L.; and Naaman, M. 2023.

</span>
<span class="ltx_bibblock">Co-Writing with Opinionated Language Models Affects Users’ Views.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</em>, CHI ’23. New York, NY, USA: Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9781450394215.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2024)</span>
<span class="ltx_bibblock">
Jiang, M.; Liu, K. Z.; Zhong, M.; Schaeffer, R.; Ouyang, S.; Han, J.; and Koyejo, S. 2024.

</span>
<span class="ltx_bibblock">Investigating data contamination for pre-training language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:2401.06059</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson, Faraj, and Kudaravalli (2014)</span>
<span class="ltx_bibblock">
Johnson, S. L.; Faraj, S.; and Kudaravalli, S. 2014.

</span>
<span class="ltx_bibblock">Emergence of Power Laws in Online Communities: The Role of Social Mechanisms and Preferential Attachment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">MIS Quarterly</em>, 38(3): 795–A13.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kapoor et al. (2024)</span>
<span class="ltx_bibblock">
Kapoor, S.; Bommasani, R.; Klyman, K.; Longpre, S.; Ramaswami, A.; Cihon, P.; Hopkins, A.; Bankston, K.; Biderman, S.; Bogen, M.; Chowdhury, R.; Engler, A.; Henderson, P.; Jernite, Y.; Lazar, S.; Maffulli, S.; Nelson, A.; Pineau, J.; Skowron, A.; Song, D.; Storchan, V.; Zhang, D.; Ho, D. E.; Liang, P.; and Narayanan, A. 2024.

</span>
<span class="ltx_bibblock">On the Societal Impact of Open Foundation Models.

</span>
<span class="ltx_bibblock">arXiv:2403.07918.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kapoor and Narayanan (2023)</span>
<span class="ltx_bibblock">
Kapoor, S.; and Narayanan, A. 2023.

</span>
<span class="ltx_bibblock">How to Prepare for the Deluge of Generative AI on Social Media.

</span>
<span class="ltx_bibblock">Knight First Amendment Institute.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karinshak et al. (2023a)</span>
<span class="ltx_bibblock">
Karinshak, E.; Liu, S. X.; Park, J. S.; and Hancock, J. T. 2023a.

</span>
<span class="ltx_bibblock">Working with AI to persuade: Examining a large language model’s ability to generate pro-vaccination messages.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the ACM on Human-Computer Interaction</em>, 7(CSCW1): 1–29.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karinshak et al. (2023b)</span>
<span class="ltx_bibblock">
Karinshak, E.; Liu, S. X.; Park, J. S.; and Hancock, J. T. 2023b.

</span>
<span class="ltx_bibblock">Working With AI to Persuade: Examining a Large Language Model’s Ability to Generate Pro-Vaccination Messages.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Proc. ACM Hum.-Comput. Interact.</em>, 7(CSCW1).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kiela et al. (2021)</span>
<span class="ltx_bibblock">
Kiela, D.; Bartolo, M.; Nie, Y.; Kaushik, D.; Geiger, A.; Wu, Z.; Vidgen, B.; Prasad, G.; Singh, A.; Ringshia, P.; et al. 2021.

</span>
<span class="ltx_bibblock">Dynabench: Rethinking benchmarking in NLP.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">arXiv preprint arXiv:2104.14337</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirk et al. (2024)</span>
<span class="ltx_bibblock">
Kirk, H. R.; Whitefield, A.; Röttger, P.; Bean, A.; Margatina, K.; Ciro, J.; Mosquera, R.; Bartolo, M.; Williams, A.; He, H.; et al. 2024.

</span>
<span class="ltx_bibblock">The PRISM Alignment Project: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">arXiv preprint arXiv:2404.16019</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kleinberg et al. (2017)</span>
<span class="ltx_bibblock">
Kleinberg, J.; Lakkaraju, H.; Leskovec, J.; Ludwig, J.; and Mullainathan, S. 2017.

</span>
<span class="ltx_bibblock">Human Decisions and Machine Predictions*.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">The Quarterly Journal of Economics</em>, 133(1): 237–293.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krauth, Wang, and Jordan (2022)</span>
<span class="ltx_bibblock">
Krauth, K.; Wang, Y.; and Jordan, M. I. 2022.

</span>
<span class="ltx_bibblock">Breaking Feedback Loops in Recommender Systems with Causal Inference.

</span>
<span class="ltx_bibblock">arXiv:2207.01616.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kuniavsky (2003)</span>
<span class="ltx_bibblock">
Kuniavsky, M. 2003.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Observing the User Experience</em>, xiii–xvi. San Francisco: Morgan Kaufmann.

</span>
<span class="ltx_bibblock">ISBN 978-1-55860-923-5.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lam et al. (2022)</span>
<span class="ltx_bibblock">
Lam, M. S.; Gordon, M. L.; Metaxa, D.; Hancock, J. T.; Landay, J. A.; and Bernstein, M. S. 2022.

</span>
<span class="ltx_bibblock">End-user audits: A system empowering communities to lead large-scale investigations of harmful algorithmic behavior.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Proceedings of the ACM on Human-Computer Interaction</em>, 6(CSCW2): 1–34.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee, Liang, and Yang (2022)</span>
<span class="ltx_bibblock">
Lee, M.; Liang, P.; and Yang, Q. 2022.

</span>
<span class="ltx_bibblock">Coauthor: Designing a human-ai collaborative writing dataset for exploring language model capabilities.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">Proceedings of the 2022 CHI conference on human factors in computing systems</em>, 1–19.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (2022)</span>
<span class="ltx_bibblock">
Lee, M.; Srivastava, M.; Hardy, A.; Thickstun, J.; Durmus, E.; Paranjape, A.; Gerard-Ursin, I.; Li, X. L.; Ladhak, F.; Rong, F.; et al. 2022.

</span>
<span class="ltx_bibblock">Evaluating human-language model interaction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">arXiv preprint arXiv:2212.09746</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Levay, Freese, and Druckman (2016)</span>
<span class="ltx_bibblock">
Levay, K. E.; Freese, J.; and Druckman, J. N. 2016.

</span>
<span class="ltx_bibblock">The demographic and political composition of Mechanical Turk samples.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">Sage Open</em>, 6(1): 2158244016636433.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Li, H.; Chong, Y. Q.; Stepputtis, S.; Campbell, J.; Hughes, D.; Lewis, M.; and Sycara, K. 2023.

</span>
<span class="ltx_bibblock">Theory of Mind for Multi-Agent Collaboration via Large Language Models.

</span>
<span class="ltx_bibblock">arXiv:2310.10701.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2021)</span>
<span class="ltx_bibblock">
Li, H.; Gao, T.; Goenka, M.; and Chen, D. 2021.

</span>
<span class="ltx_bibblock">Ditch the gold standard: Re-evaluating conversational question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">arXiv preprint arXiv:2112.08812</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al. (2022)</span>
<span class="ltx_bibblock">
Liang, P.; Bommasani, R.; Lee, T.; Tsipras, D.; Soylu, D.; Yasunaga, M.; Zhang, Y.; Narayanan, D.; Wu, Y.; Kumar, A.; et al. 2022.

</span>
<span class="ltx_bibblock">Holistic evaluation of language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">arXiv preprint arXiv:2211.09110</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liao and Sundar (2022)</span>
<span class="ltx_bibblock">
Liao, Q.; and Sundar, S. S. 2022.

</span>
<span class="ltx_bibblock">Designing for Responsible Trust in AI Systems: A Communication Perspective.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency</em>, FAccT ’22, 1257–1268. New York, NY, USA: Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9781450393522.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liao and Xiao (2023)</span>
<span class="ltx_bibblock">
Liao, Q. V.; and Xiao, Z. 2023.

</span>
<span class="ltx_bibblock">Rethinking model evaluation as narrowing the socio-technical gap.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">arXiv preprint arXiv:2306.03100</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2023)</span>
<span class="ltx_bibblock">
Lin, J.; Tomlin, N.; Andreas, J.; and Eisner, J. 2023.

</span>
<span class="ltx_bibblock">Decision-oriented dialogue for human-ai collaboration.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">arXiv preprint arXiv:2305.20076</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">METR (2023)</span>
<span class="ltx_bibblock">
METR. 2023.

</span>
<span class="ltx_bibblock">METR Autonomy Evaluations Resources.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mialon et al. (2023)</span>
<span class="ltx_bibblock">
Mialon, G.; Dessì, R.; Lomeli, M.; Nalmpantis, C.; Pasunuru, R.; Raileanu, R.; Rozière, B.; Schick, T.; Dwivedi-Yu, J.; Celikyilmaz, A.; et al. 2023.

</span>
<span class="ltx_bibblock">Augmented language models: a survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">arXiv preprint arXiv:2302.07842</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitchell (2024)</span>
<span class="ltx_bibblock">
Mitchell, M. 2024.

</span>
<span class="ltx_bibblock">Ethical ai isn’t to blame for Google’s Gemini debacle.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moher, Schulz, and Altman (2001)</span>
<span class="ltx_bibblock">
Moher, D.; Schulz, K. F.; and Altman, D. G. 2001.

</span>
<span class="ltx_bibblock">The CONSORT statement: revised recommendations for improving the quality of reports of parallel-group randomised trials.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">The lancet</em>, 357(9263): 1191–1194.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Morten, Nicholas, and Viljoen (2024)</span>
<span class="ltx_bibblock">
Morten, C.; Nicholas, G.; and Viljoen, S. 2024.

</span>
<span class="ltx_bibblock">Researcher Access to Social Media Data: Lessons from Clinical Trial Data Sharing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">Berkeley Technology Law Journal, Forthcoming</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mouton, Lucas, and Guest (2024)</span>
<span class="ltx_bibblock">
Mouton, C. A.; Lucas, C.; and Guest, E. 2024.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">The Operational Risks of AI in Large-Scale Biological Attacks: Results of a Red-Team Study</em>.

</span>
<span class="ltx_bibblock">Santa Monica, CA: RAND Corporation.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nov, Singh, and Mann (2023)</span>
<span class="ltx_bibblock">
Nov, O.; Singh, N.; and Mann, D. 2023.

</span>
<span class="ltx_bibblock">Putting ChatGPT’s Medical Advice to the (Turing) Test.

</span>
<span class="ltx_bibblock">arXiv:2301.10035.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock">Preparedness.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al. (2023)</span>
<span class="ltx_bibblock">
Ouyang, S.; Wang, S.; Liu, Y.; Zhong, M.; Jiao, Y.; Iter, D.; Pryzant, R.; Zhu, C.; Ji, H.; and Han, J. 2023.

</span>
<span class="ltx_bibblock">The shifted and the overlooked: a task-oriented investigation of user-gpt interactions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib68.1.1">arXiv preprint arXiv:2310.12418</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan et al. (2024)</span>
<span class="ltx_bibblock">
Pan, A.; Jones, E.; Jagadeesan, M.; and Steinhardt, J. 2024.

</span>
<span class="ltx_bibblock">Feedback Loops With Language Models Drive In-Context Reward Hacking.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">arXiv preprint arXiv:2402.06627</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parrish et al. (2021)</span>
<span class="ltx_bibblock">
Parrish, A.; Chen, A.; Nangia, N.; Padmakumar, V.; Phang, J.; Thompson, J.; Htut, P. M.; and Bowman, S. R. 2021.

</span>
<span class="ltx_bibblock">BBQ: A hand-built bias benchmark for question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">arXiv preprint arXiv:2110.08193</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patwardhan et al. (2024)</span>
<span class="ltx_bibblock">
Patwardhan, T.; Liu, K.; Markov, T.; Chowdhury, N.; Leet, D.; Cone, N.; Maltbie, C.; Huizinga, J.; Wainwright, C.; Jackson, S. F.; and et al. 2024.

</span>
<span class="ltx_bibblock">Building an early warning system for LLM-aided biological …

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pentina, Hancock, and Xie (2023)</span>
<span class="ltx_bibblock">
Pentina, I.; Hancock, T.; and Xie, T. 2023.

</span>
<span class="ltx_bibblock">Exploring relationship development with social chatbots: A mixed-method study of replika.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib72.1.1">Computers in Human Behavior</em>, 140: 107600.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Phuong et al. (2024)</span>
<span class="ltx_bibblock">
Phuong, M.; Aitchison, M.; Catt, E.; Cogan, S.; Kaskasoli, A.; Krakovna, V.; Lindner, D.; Rahtz, M.; Assael, Y.; Hodkinson, S.; et al. 2024.

</span>
<span class="ltx_bibblock">Evaluating Frontier Models for Dangerous Capabilities.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib73.1.1">arXiv preprint arXiv:2403.13793</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raji et al. (2021)</span>
<span class="ltx_bibblock">
Raji, I. D.; Bender, E. M.; Paullada, A.; Denton, E.; and Hanna, A. 2021.

</span>
<span class="ltx_bibblock">AI and the everything in the whole wide world benchmark.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">arXiv preprint arXiv:2111.15366</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raji et al. (2022)</span>
<span class="ltx_bibblock">
Raji, I. D.; Kumar, I. E.; Horowitz, A.; and Selbst, A. 2022.

</span>
<span class="ltx_bibblock">The fallacy of AI functionality.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib75.1.1">Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency</em>, 959–972.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rooney et al. (2016)</span>
<span class="ltx_bibblock">
Rooney, A. A.; Cooper, G. S.; Jahnke, G. D.; Lam, J.; Morgan, R. L.; Boyles, A. L.; Ratcliffe, J. M.; Kraft, A. D.; Schünemann, H. J.; Schwingl, P.; et al. 2016.

</span>
<span class="ltx_bibblock">How credible are the study results? Evaluating and applying internal validity tools to literature-based assessments of environmental health hazards.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib76.1.1">Environment international</em>, 92: 617–629.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Röttger et al. (2024)</span>
<span class="ltx_bibblock">
Röttger, P.; Pernisi, F.; Vidgen, B.; and Hovy, D. 2024.

</span>
<span class="ltx_bibblock">SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Model Safety.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib77.1.1">arXiv preprint arXiv:2404.05399</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rybski et al. (2009)</span>
<span class="ltx_bibblock">
Rybski, D.; Buldyrev, S. V.; Havlin, S.; Liljeros, F.; and Makse, H. A. 2009.

</span>
<span class="ltx_bibblock">Scaling laws of human interaction activity.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib78.1.1">Proceedings of the National Academy of Sciences</em>, 106(31): 12640–12645.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sandoval et al. (2023)</span>
<span class="ltx_bibblock">
Sandoval, G.; Pearce, H.; Nys, T.; Karri, R.; Garg, S.; and Dolan-Gavitt, B. 2023.

</span>
<span class="ltx_bibblock">Lost at c: A user study on the security implications of large language model code assistants.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">32nd USENIX Security Symposium (USENIX Security 23)</em>, 2205–2222.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Seaborn, Barbareschi, and Chandra (2023)</span>
<span class="ltx_bibblock">
Seaborn, K.; Barbareschi, G.; and Chandra, S. 2023.

</span>
<span class="ltx_bibblock">Not Only WEIRD but “Uncanny”? A Systematic Review of Diversity in Human–Robot Interaction Research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib80.1.1">International Journal of Social Robotics</em>, 15(11): 1841–1870.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">ShareGPT (2022)</span>
<span class="ltx_bibblock">
ShareGPT. 2022.

</span>
<span class="ltx_bibblock">ShareGPT.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sharma et al. (2023)</span>
<span class="ltx_bibblock">
Sharma, M.; Tong, M.; Korbak, T.; Duvenaud, D.; Askell, A.; Bowman, S. R.; Cheng, N.; Durmus, E.; Hatfield-Dodds, Z.; Johnston, S. R.; et al. 2023.

</span>
<span class="ltx_bibblock">Towards understanding sycophancy in language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib82.1.1">arXiv preprint arXiv:2310.13548</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shelby et al. (2023)</span>
<span class="ltx_bibblock">
Shelby, R.; Rismani, S.; Henne, K.; Moon, A.; Rostamzadeh, N.; Nicholas, P.; Yilla-Akbari, N.; Gallegos, J.; Smart, A.; Garcia, E.; et al. 2023.

</span>
<span class="ltx_bibblock">Sociotechnical harms of algorithmic systems: Scoping a taxonomy for harm reduction.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib83.1.1">Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society</em>, 723–741.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et al. (2021)</span>
<span class="ltx_bibblock">
Shen, H.; DeVos, A.; Eslami, M.; and Holstein, K. 2021.

</span>
<span class="ltx_bibblock">Everyday algorithm auditing: Understanding the power of everyday users in surfacing harmful algorithmic behaviors.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib84.1.1">Proceedings of the ACM on Human-Computer Interaction</em>, 5(CSCW2): 1–29.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sloane et al. (2022)</span>
<span class="ltx_bibblock">
Sloane, M.; Moss, E.; Awomolo, O.; and Forlano, L. 2022.

</span>
<span class="ltx_bibblock">Participation Is not a Design Fix for Machine Learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">Proceedings of the 2nd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization</em>, EAAMO ’22. New York, NY, USA: Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9781450394772.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Soice et al. (2023)</span>
<span class="ltx_bibblock">
Soice, E. H.; Rocha, R.; Cordova, K.; Specter, M.; and Esvelt, K. M. 2023.

</span>
<span class="ltx_bibblock">Can large language models democratize access to dual-use biotechnology?

</span>
<span class="ltx_bibblock">arXiv:2306.03809.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Solaiman et al. (2023)</span>
<span class="ltx_bibblock">
Solaiman, I.; Talat, Z.; Agnew, W.; Ahmad, L.; Baker, D.; Blodgett, S. L.; au2, H. D. I.; Dodge, J.; Evans, E.; Hooker, S.; Jernite, Y.; Luccioni, A. S.; Lusoli, A.; Mitchell, M.; Newman, J.; Png, M.-T.; Strait, A.; and Vassilev, A. 2023.

</span>
<span class="ltx_bibblock">Evaluating the Social Impact of Generative AI Systems in Systems and Society.

</span>
<span class="ltx_bibblock">arXiv:2306.05949.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Spitale, Biller-Andorno, and Germani (2023)</span>
<span class="ltx_bibblock">
Spitale, G.; Biller-Andorno, N.; and Germani, F. 2023.

</span>
<span class="ltx_bibblock">AI model GPT-3 (dis) informs us better than humans.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib88.1.1">Science Advances</em>, 9(26): eadh1850.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Subramonyam et al. (2024)</span>
<span class="ltx_bibblock">
Subramonyam, H.; Pea, R.; Pondoc, C. L.; Agrawala, M.; and Seifert, C. 2024.

</span>
<span class="ltx_bibblock">Bridging the Gulf of Envisioning: Cognitive Design Challenges in LLM Interfaces.

</span>
<span class="ltx_bibblock">arXiv:2309.14459.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Susukida et al. (2017)</span>
<span class="ltx_bibblock">
Susukida, R.; Crum, R. M.; Ebnesajjad, C.; Stuart, E. A.; and Mojtabai, R. 2017.

</span>
<span class="ltx_bibblock">Generalizability of findings from randomized controlled trials: application to the National Institute of Drug Abuse Clinical Trials Network.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib90.1.1">Addiction</em>, 112(7): 1210–1219.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">The White House (2023)</span>
<span class="ltx_bibblock">
The White House. 2023.

</span>
<span class="ltx_bibblock">https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">UK AI Safety Institute (2024)</span>
<span class="ltx_bibblock">
UK AI Safety Institute. 2024.

</span>
<span class="ltx_bibblock">Inspect AI.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">UK Government (2024)</span>
<span class="ltx_bibblock">
UK Government. 2024.

</span>
<span class="ltx_bibblock">Ai Safety Institute approach to evaluations.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023)</span>
<span class="ltx_bibblock">
Wang, B.; Chen, W.; Pei, H.; Xie, C.; Kang, M.; Zhang, C.; Xu, C.; Xiong, Z.; Dutta, R.; Schaeffer, R.; et al. 2023.

</span>
<span class="ltx_bibblock">Decodingtrust: A comprehensive assessment of trustworthiness in gpt models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib94.1.1">arXiv preprint arXiv:2306.11698</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ward et al. (2024)</span>
<span class="ltx_bibblock">
Ward, F. R.; MacDermott, M.; Belardinelli, F.; Toni, F.; and Everitt, T. 2024.

</span>
<span class="ltx_bibblock">The Reasons that Agents Act: Intention and Instrumental Goals.

</span>
<span class="ltx_bibblock">arXiv:2402.07221.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weidinger et al. (2023)</span>
<span class="ltx_bibblock">
Weidinger, L.; Rauh, M.; Marchal, N.; Manzini, A.; Hendricks, L. A.; Mateos-Garcia, J.; Bergman, S.; Kay, J.; Griffin, C.; Bariach, B.; et al. 2023.

</span>
<span class="ltx_bibblock">Sociotechnical safety evaluation of generative ai systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib96.1.1">arXiv preprint arXiv:2310.11986</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weidinger et al. (2022)</span>
<span class="ltx_bibblock">
Weidinger, L.; Uesato, J.; Rauh, M.; Griffin, C.; Huang, P.-S.; Mellor, J.; Glaese, A.; Cheng, M.; Balle, B.; Kasirzadeh, A.; et al. 2022.

</span>
<span class="ltx_bibblock">Taxonomy of risks posed by language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib97.1.1">Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency</em>, 214–229.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wilson (2000)</span>
<span class="ltx_bibblock">
Wilson, T. D. 2000.

</span>
<span class="ltx_bibblock">Recent trends in user studies: action research and qualitative methods.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib98.1.1">Information Research</em>, 5(3).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wouters, McKee, and Luyten (2020)</span>
<span class="ltx_bibblock">
Wouters, O. J.; McKee, M.; and Luyten, J. 2020.

</span>
<span class="ltx_bibblock">Estimated Research and Development Investment Needed to Bring a New Medicine to Market, 2009-2018.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib99.1.1">JAMA</em>, 323(9): 844–853.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie, Pentina, and Hancock (2023)</span>
<span class="ltx_bibblock">
Xie, T.; Pentina, I.; and Hancock, T. 2023.

</span>
<span class="ltx_bibblock">Friend, mentor, lover: does chatbot engagement lead to psychological dependence?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib100.1.1">Journal of service Management</em>, 34(4): 806–828.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2021)</span>
<span class="ltx_bibblock">
Xu, J.; Ju, D.; Li, M.; Boureau, Y.-L.; Weston, J.; and Dinan, E. 2021.

</span>
<span class="ltx_bibblock">Bot-adversarial dialogue for safe conversational agents.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib101.1.1">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, 2950–2968.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib102">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu, Feng, and Chen (2023)</span>
<span class="ltx_bibblock">
Xu, R.; Feng, Y.; and Chen, H. 2023.

</span>
<span class="ltx_bibblock">ChatGPT vs. Google: a comparative study of search performance and user experience.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib102.1.1">arXiv preprint arXiv:2307.01135</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib103">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024)</span>
<span class="ltx_bibblock">
Zhang, Z.; Jia, M.; Lee, H.-P. H.; Yao, B.; Das, S.; Lerner, A.; Wang, D.; and Li, T. 2024.

</span>
<span class="ltx_bibblock">“It’s a Fair Game”, or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib103.1.1">Proceedings of the CHI Conference on Human Factors in Computing Systems</em>, CHI ’24. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib104">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2024)</span>
<span class="ltx_bibblock">
Zhao, W.; Ren, X.; Hessel, J.; Cardie, C.; Choi, Y.; and Deng, Y. 2024.

</span>
<span class="ltx_bibblock">WildChat: 1M ChatGPT Interaction Logs in the Wild.

</span>
<span class="ltx_bibblock">arXiv:2405.01470.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>
<figure class="ltx_table" id="A1.T1">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A1.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T1.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A1.T1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.1.1.1.1">
<span class="ltx_p" id="A1.T1.1.1.1.1.1.1" style="width:80.9pt;"><span class="ltx_text ltx_font_bold" id="A1.T1.1.1.1.1.1.1.1">Evaluation study</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A1.T1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.1.1.2.1">
<span class="ltx_p" id="A1.T1.1.1.1.2.1.1" style="width:75.9pt;"><span class="ltx_text ltx_font_bold" id="A1.T1.1.1.1.2.1.1.1">Risk/harm</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A1.T1.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.1.1.3.1">
<span class="ltx_p" id="A1.T1.1.1.1.3.1.1" style="width:60.7pt;"><span class="ltx_text ltx_font_bold" id="A1.T1.1.1.1.3.1.1.1">Methods</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A1.T1.1.1.1.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.1.1.4.1">
<span class="ltx_p" id="A1.T1.1.1.1.4.1.1" style="width:60.7pt;"><span class="ltx_text ltx_font_bold" id="A1.T1.1.1.1.4.1.1.1">Different user groups and/or representative sample [Y/N]</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A1.T1.1.1.1.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.1.1.5.1">
<span class="ltx_p" id="A1.T1.1.1.1.5.1.1" style="width:60.7pt;"><span class="ltx_text ltx_font_bold" id="A1.T1.1.1.1.5.1.1.1">Risk aspect</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A1.T1.1.1.1.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.1.1.6.1">
<span class="ltx_p" id="A1.T1.1.1.1.6.1.1" style="width:60.7pt;"><span class="ltx_text ltx_font_bold" id="A1.T1.1.1.1.6.1.1.1">Interaction tasks</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A1.T1.1.1.1.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.1.1.7.1">
<span class="ltx_p" id="A1.T1.1.1.1.7.1.1" style="width:45.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T1.1.1.1.7.1.1.1">Number of models</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T1.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T1.1.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.2.1.1.1">
<span class="ltx_p" id="A1.T1.1.2.1.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Mouton, Lucas, and Guest <span class="ltx_text ltx_font_bold" id="A1.T1.1.2.1.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib65" title="">2024</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.2.1.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T1.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.2.1.2.1">
<span class="ltx_p" id="A1.T1.1.2.1.2.1.1" style="width:75.9pt;">biorisk</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T1.1.2.1.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.2.1.3.1">
<span class="ltx_p" id="A1.T1.1.2.1.3.1.1" style="width:60.7pt;">experiments</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T1.1.2.1.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.2.1.4.1">
<span class="ltx_p" id="A1.T1.1.2.1.4.1.1" style="width:60.7pt;">N</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T1.1.2.1.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.2.1.5.1">
<span class="ltx_p" id="A1.T1.1.2.1.5.1.1" style="width:60.7pt;">marginal</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T1.1.2.1.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.2.1.6.1">
<span class="ltx_p" id="A1.T1.1.2.1.6.1.1" style="width:60.7pt;">planning</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T1.1.2.1.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.2.1.7.1">
<span class="ltx_p" id="A1.T1.1.2.1.7.1.1" style="width:45.5pt;">2</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.3.2.1.1">
<span class="ltx_p" id="A1.T1.1.3.2.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Xu, Feng, and Chen <span class="ltx_text ltx_font_bold" id="A1.T1.1.3.2.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib102" title="">2023</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.3.2.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.3.2.2.1">
<span class="ltx_p" id="A1.T1.1.3.2.2.1.1" style="width:75.9pt;">overreliance, misinformation</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.3.2.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.3.2.3.1">
<span class="ltx_p" id="A1.T1.1.3.2.3.1.1" style="width:60.7pt;">experiments</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.3.2.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.3.2.4.1">
<span class="ltx_p" id="A1.T1.1.3.2.4.1.1" style="width:60.7pt;">Y</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.3.2.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.3.2.5.1">
<span class="ltx_p" id="A1.T1.1.3.2.5.1.1" style="width:60.7pt;">marginal</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.3.2.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.3.2.6.1">
<span class="ltx_p" id="A1.T1.1.3.2.6.1.1" style="width:60.7pt;">information retrieval</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.3.2.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.3.2.7.1">
<span class="ltx_p" id="A1.T1.1.3.2.7.1.1" style="width:45.5pt;">1</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.4.3.1.1">
<span class="ltx_p" id="A1.T1.1.4.3.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Jakesch et al. <span class="ltx_text ltx_font_bold" id="A1.T1.1.4.3.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib38" title="">2023</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.4.3.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.4.3.2.1">
<span class="ltx_p" id="A1.T1.1.4.3.2.1.1" style="width:75.9pt;">persuasion</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.4.3.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.4.3.3.1">
<span class="ltx_p" id="A1.T1.1.4.3.3.1.1" style="width:60.7pt;">experiments</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.4.3.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.4.3.4.1">
<span class="ltx_p" id="A1.T1.1.4.3.4.1.1" style="width:60.7pt;">N</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.4.3.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.4.3.5.1">
<span class="ltx_p" id="A1.T1.1.4.3.5.1.1" style="width:60.7pt;">absolute</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.4.3.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.4.3.6.1">
<span class="ltx_p" id="A1.T1.1.4.3.6.1.1" style="width:60.7pt;">writing</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.4.3.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.4.3.7.1">
<span class="ltx_p" id="A1.T1.1.4.3.7.1.1" style="width:45.5pt;">1</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.5.4.1.1">
<span class="ltx_p" id="A1.T1.1.5.4.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Doshi and Hauser <span class="ltx_text ltx_font_bold" id="A1.T1.1.5.4.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib20" title="">2024</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.5.4.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.5.4.2.1">
<span class="ltx_p" id="A1.T1.1.5.4.2.1.1" style="width:75.9pt;">overreliance</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.5.4.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.5.4.3.1">
<span class="ltx_p" id="A1.T1.1.5.4.3.1.1" style="width:60.7pt;">experiments</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.5.4.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.5.4.4.1">
<span class="ltx_p" id="A1.T1.1.5.4.4.1.1" style="width:60.7pt;">Y</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.5.4.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.5.4.5.1">
<span class="ltx_p" id="A1.T1.1.5.4.5.1.1" style="width:60.7pt;">absolute</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.5.4.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.5.4.6.1">
<span class="ltx_p" id="A1.T1.1.5.4.6.1.1" style="width:60.7pt;">writing/content generation</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.5.4.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.5.4.7.1">
<span class="ltx_p" id="A1.T1.1.5.4.7.1.1" style="width:45.5pt;">1</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.6.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.6.5.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.6.5.1.1">
<span class="ltx_p" id="A1.T1.1.6.5.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Nov, Singh, and Mann <span class="ltx_text ltx_font_bold" id="A1.T1.1.6.5.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib66" title="">2023</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.6.5.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.6.5.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.6.5.2.1">
<span class="ltx_p" id="A1.T1.1.6.5.2.1.1" style="width:75.9pt;">trust</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.6.5.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.6.5.3.1">
<span class="ltx_p" id="A1.T1.1.6.5.3.1.1" style="width:60.7pt;">experiments</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.6.5.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.6.5.4.1">
<span class="ltx_p" id="A1.T1.1.6.5.4.1.1" style="width:60.7pt;">Y</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.6.5.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.6.5.5.1">
<span class="ltx_p" id="A1.T1.1.6.5.5.1.1" style="width:60.7pt;">absolute</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.6.5.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.6.5.6.1">
<span class="ltx_p" id="A1.T1.1.6.5.6.1.1" style="width:60.7pt;">exposure</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.6.5.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.6.5.7.1">
<span class="ltx_p" id="A1.T1.1.6.5.7.1.1" style="width:45.5pt;">1</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.7.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.7.6.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.7.6.1.1">
<span class="ltx_p" id="A1.T1.1.7.6.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Böhm et al. <span class="ltx_text ltx_font_bold" id="A1.T1.1.7.6.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib9" title="">2023</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.7.6.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.7.6.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.7.6.2.1">
<span class="ltx_p" id="A1.T1.1.7.6.2.1.1" style="width:75.9pt;">AI aversion</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.7.6.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.7.6.3.1">
<span class="ltx_p" id="A1.T1.1.7.6.3.1.1" style="width:60.7pt;">experiments</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.7.6.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.7.6.4.1">
<span class="ltx_p" id="A1.T1.1.7.6.4.1.1" style="width:60.7pt;">N</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.7.6.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.7.6.5.1">
<span class="ltx_p" id="A1.T1.1.7.6.5.1.1" style="width:60.7pt;">marginal</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.7.6.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.7.6.6.1">
<span class="ltx_p" id="A1.T1.1.7.6.6.1.1" style="width:60.7pt;">exposure</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.7.6.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.7.6.7.1">
<span class="ltx_p" id="A1.T1.1.7.6.7.1.1" style="width:45.5pt;">1</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.8.7">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.8.7.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.8.7.1.1">
<span class="ltx_p" id="A1.T1.1.8.7.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Xie, Pentina, and Hancock <span class="ltx_text ltx_font_bold" id="A1.T1.1.8.7.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib100" title="">2023</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.8.7.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.8.7.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.8.7.2.1">
<span class="ltx_p" id="A1.T1.1.8.7.2.1.1" style="width:75.9pt;">psychological impact, relationships</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.8.7.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.8.7.3.1">
<span class="ltx_p" id="A1.T1.1.8.7.3.1.1" style="width:60.7pt;">user studies</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.8.7.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.8.7.4.1">
<span class="ltx_p" id="A1.T1.1.8.7.4.1.1" style="width:60.7pt;">Y</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.8.7.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.8.7.5.1">
<span class="ltx_p" id="A1.T1.1.8.7.5.1.1" style="width:60.7pt;">absolute</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.8.7.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.8.7.6.1">
<span class="ltx_p" id="A1.T1.1.8.7.6.1.1" style="width:60.7pt;">dialogue</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.8.7.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.8.7.7.1">
<span class="ltx_p" id="A1.T1.1.8.7.7.1.1" style="width:45.5pt;">1</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.9.8">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.9.8.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.9.8.1.1">
<span class="ltx_p" id="A1.T1.1.9.8.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Soice et al. <span class="ltx_text ltx_font_bold" id="A1.T1.1.9.8.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib86" title="">2023</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.9.8.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.9.8.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.9.8.2.1">
<span class="ltx_p" id="A1.T1.1.9.8.2.1.1" style="width:75.9pt;">biorisk</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.9.8.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.9.8.3.1">
<span class="ltx_p" id="A1.T1.1.9.8.3.1.1" style="width:60.7pt;">user studies</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.9.8.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.9.8.4.1">
<span class="ltx_p" id="A1.T1.1.9.8.4.1.1" style="width:60.7pt;">N</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.9.8.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.9.8.5.1">
<span class="ltx_p" id="A1.T1.1.9.8.5.1.1" style="width:60.7pt;">absolute</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.9.8.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.9.8.6.1">
<span class="ltx_p" id="A1.T1.1.9.8.6.1.1" style="width:60.7pt;">information retrieval, planning</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.9.8.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.9.8.7.1">
<span class="ltx_p" id="A1.T1.1.9.8.7.1.1" style="width:45.5pt;">3+</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.10.9">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.10.9.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.10.9.1.1">
<span class="ltx_p" id="A1.T1.1.10.9.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Spitale, Biller-Andorno, and Germani <span class="ltx_text ltx_font_bold" id="A1.T1.1.10.9.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib88" title="">2023</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.10.9.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.10.9.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.10.9.2.1">
<span class="ltx_p" id="A1.T1.1.10.9.2.1.1" style="width:75.9pt;">disinformation</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.10.9.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.10.9.3.1">
<span class="ltx_p" id="A1.T1.1.10.9.3.1.1" style="width:60.7pt;">experiments</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.10.9.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.10.9.4.1">
<span class="ltx_p" id="A1.T1.1.10.9.4.1.1" style="width:60.7pt;">N</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.10.9.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.10.9.5.1">
<span class="ltx_p" id="A1.T1.1.10.9.5.1.1" style="width:60.7pt;">marginal</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.10.9.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.10.9.6.1">
<span class="ltx_p" id="A1.T1.1.10.9.6.1.1" style="width:60.7pt;">exposure</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.10.9.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.10.9.7.1">
<span class="ltx_p" id="A1.T1.1.10.9.7.1.1" style="width:45.5pt;">1</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.11.10">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.11.10.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.11.10.1.1">
<span class="ltx_p" id="A1.T1.1.11.10.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Karinshak et al. <span class="ltx_text ltx_font_bold" id="A1.T1.1.11.10.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib44" title="">2023b</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.11.10.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.11.10.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.11.10.2.1">
<span class="ltx_p" id="A1.T1.1.11.10.2.1.1" style="width:75.9pt;">persuasion</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.11.10.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.11.10.3.1">
<span class="ltx_p" id="A1.T1.1.11.10.3.1.1" style="width:60.7pt;">experiments</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.11.10.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.11.10.4.1">
<span class="ltx_p" id="A1.T1.1.11.10.4.1.1" style="width:60.7pt;">Y</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.11.10.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.11.10.5.1">
<span class="ltx_p" id="A1.T1.1.11.10.5.1.1" style="width:60.7pt;">marginal</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.11.10.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.11.10.6.1">
<span class="ltx_p" id="A1.T1.1.11.10.6.1.1" style="width:60.7pt;">exposure</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.11.10.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.11.10.7.1">
<span class="ltx_p" id="A1.T1.1.11.10.7.1.1" style="width:45.5pt;">1</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.12.11">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.12.11.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.12.11.1.1">
<span class="ltx_p" id="A1.T1.1.12.11.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Gadiraju et al. <span class="ltx_text ltx_font_bold" id="A1.T1.1.12.11.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib24" title="">2023</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.12.11.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.12.11.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.12.11.2.1">
<span class="ltx_p" id="A1.T1.1.12.11.2.1.1" style="width:75.9pt;">disparate performance</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.12.11.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.12.11.3.1">
<span class="ltx_p" id="A1.T1.1.12.11.3.1.1" style="width:60.7pt;">user studies</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.12.11.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.12.11.4.1">
<span class="ltx_p" id="A1.T1.1.12.11.4.1.1" style="width:60.7pt;">Y</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.12.11.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.12.11.5.1">
<span class="ltx_p" id="A1.T1.1.12.11.5.1.1" style="width:60.7pt;">absolute</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.12.11.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.12.11.6.1">
<span class="ltx_p" id="A1.T1.1.12.11.6.1.1" style="width:60.7pt;">dialogue</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.12.11.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.12.11.7.1">
<span class="ltx_p" id="A1.T1.1.12.11.7.1.1" style="width:45.5pt;">1</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.13.12">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.13.12.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.13.12.1.1">
<span class="ltx_p" id="A1.T1.1.13.12.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Hackenburg et al. <span class="ltx_text ltx_font_bold" id="A1.T1.1.13.12.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib31" title="">2023</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.13.12.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.13.12.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.13.12.2.1">
<span class="ltx_p" id="A1.T1.1.13.12.2.1.1" style="width:75.9pt;">persuasion</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.13.12.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.13.12.3.1">
<span class="ltx_p" id="A1.T1.1.13.12.3.1.1" style="width:60.7pt;">experiments</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.13.12.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.13.12.4.1">
<span class="ltx_p" id="A1.T1.1.13.12.4.1.1" style="width:60.7pt;">Y</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.13.12.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.13.12.5.1">
<span class="ltx_p" id="A1.T1.1.13.12.5.1.1" style="width:60.7pt;">marginal</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.13.12.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.13.12.6.1">
<span class="ltx_p" id="A1.T1.1.13.12.6.1.1" style="width:60.7pt;">exposure</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.13.12.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.13.12.7.1">
<span class="ltx_p" id="A1.T1.1.13.12.7.1.1" style="width:45.5pt;">1</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.14.13">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.14.13.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.14.13.1.1">
<span class="ltx_p" id="A1.T1.1.14.13.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Patwardhan et al. <span class="ltx_text ltx_font_bold" id="A1.T1.1.14.13.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib71" title="">2024</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.14.13.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.14.13.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.14.13.2.1">
<span class="ltx_p" id="A1.T1.1.14.13.2.1.1" style="width:75.9pt;">biorisk</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.14.13.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.14.13.3.1">
<span class="ltx_p" id="A1.T1.1.14.13.3.1.1" style="width:60.7pt;">experiments</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.14.13.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.14.13.4.1">
<span class="ltx_p" id="A1.T1.1.14.13.4.1.1" style="width:60.7pt;">Y</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.14.13.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.14.13.5.1">
<span class="ltx_p" id="A1.T1.1.14.13.5.1.1" style="width:60.7pt;">marginal</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.14.13.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.14.13.6.1">
<span class="ltx_p" id="A1.T1.1.14.13.6.1.1" style="width:60.7pt;">planning/aid</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.14.13.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.14.13.7.1">
<span class="ltx_p" id="A1.T1.1.14.13.7.1.1" style="width:45.5pt;">1</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.15.14">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.15.14.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.15.14.1.1">
<span class="ltx_p" id="A1.T1.1.15.14.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Durmus et al. <span class="ltx_text ltx_font_bold" id="A1.T1.1.15.14.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib22" title="">2024</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.15.14.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.15.14.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.15.14.2.1">
<span class="ltx_p" id="A1.T1.1.15.14.2.1.1" style="width:75.9pt;">persuasion</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.15.14.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.15.14.3.1">
<span class="ltx_p" id="A1.T1.1.15.14.3.1.1" style="width:60.7pt;">experiments</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.15.14.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.15.14.4.1">
<span class="ltx_p" id="A1.T1.1.15.14.4.1.1" style="width:60.7pt;">N</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.15.14.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.15.14.5.1">
<span class="ltx_p" id="A1.T1.1.15.14.5.1.1" style="width:60.7pt;">marginal</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.15.14.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.15.14.6.1">
<span class="ltx_p" id="A1.T1.1.15.14.6.1.1" style="width:60.7pt;">exposure</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.15.14.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.15.14.7.1">
<span class="ltx_p" id="A1.T1.1.15.14.7.1.1" style="width:45.5pt;">5</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.16.15">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.16.15.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.16.15.1.1">
<span class="ltx_p" id="A1.T1.1.16.15.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Sandoval et al. <span class="ltx_text ltx_font_bold" id="A1.T1.1.16.15.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib79" title="">2023</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.16.15.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.16.15.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.16.15.2.1">
<span class="ltx_p" id="A1.T1.1.16.15.2.1.1" style="width:75.9pt;">security</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.16.15.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.16.15.3.1">
<span class="ltx_p" id="A1.T1.1.16.15.3.1.1" style="width:60.7pt;">user studies</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.16.15.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.16.15.4.1">
<span class="ltx_p" id="A1.T1.1.16.15.4.1.1" style="width:60.7pt;">Y</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.16.15.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.16.15.5.1">
<span class="ltx_p" id="A1.T1.1.16.15.5.1.1" style="width:60.7pt;">absolute</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.16.15.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.16.15.6.1">
<span class="ltx_p" id="A1.T1.1.16.15.6.1.1" style="width:60.7pt;">coding assistance</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.16.15.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.16.15.7.1">
<span class="ltx_p" id="A1.T1.1.16.15.7.1.1" style="width:45.5pt;">3</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.17.16">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.17.16.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.17.16.1.1">
<span class="ltx_p" id="A1.T1.1.17.16.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Phuong et al. <span class="ltx_text ltx_font_bold" id="A1.T1.1.17.16.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib73" title="">2024</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.17.16.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.17.16.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.17.16.2.1">
<span class="ltx_p" id="A1.T1.1.17.16.2.1.1" style="width:75.9pt;">persuasion</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.17.16.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.17.16.3.1">
<span class="ltx_p" id="A1.T1.1.17.16.3.1.1" style="width:60.7pt;">experiments</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.17.16.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.17.16.4.1">
<span class="ltx_p" id="A1.T1.1.17.16.4.1.1" style="width:60.7pt;">N</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.17.16.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.17.16.5.1">
<span class="ltx_p" id="A1.T1.1.17.16.5.1.1" style="width:60.7pt;">absolute</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.17.16.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.17.16.6.1">
<span class="ltx_p" id="A1.T1.1.17.16.6.1.1" style="width:60.7pt;">dialogue</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.17.16.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.17.16.7.1">
<span class="ltx_p" id="A1.T1.1.17.16.7.1.1" style="width:45.5pt;">3</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.18.17">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.18.17.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.18.17.1.1">
<span class="ltx_p" id="A1.T1.1.18.17.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Hackenburg and Margetts <span class="ltx_text ltx_font_bold" id="A1.T1.1.18.17.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib32" title="">2023</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.18.17.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.18.17.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.18.17.2.1">
<span class="ltx_p" id="A1.T1.1.18.17.2.1.1" style="width:75.9pt;">persuasion</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.18.17.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.18.17.3.1">
<span class="ltx_p" id="A1.T1.1.18.17.3.1.1" style="width:60.7pt;">experiments</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.18.17.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.18.17.4.1">
<span class="ltx_p" id="A1.T1.1.18.17.4.1.1" style="width:60.7pt;">N</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.18.17.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.18.17.5.1">
<span class="ltx_p" id="A1.T1.1.18.17.5.1.1" style="width:60.7pt;">absolute</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.18.17.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.18.17.6.1">
<span class="ltx_p" id="A1.T1.1.18.17.6.1.1" style="width:60.7pt;">exposure</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.18.17.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.18.17.7.1">
<span class="ltx_p" id="A1.T1.1.18.17.7.1.1" style="width:45.5pt;">1</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.19.18">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.19.18.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.19.18.1.1">
<span class="ltx_p" id="A1.T1.1.19.18.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Zhang et al. <span class="ltx_text ltx_font_bold" id="A1.T1.1.19.18.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib103" title="">2024</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.19.18.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.19.18.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.19.18.2.1">
<span class="ltx_p" id="A1.T1.1.19.18.2.1.1" style="width:75.9pt;">privacy</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.19.18.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.19.18.3.1">
<span class="ltx_p" id="A1.T1.1.19.18.3.1.1" style="width:60.7pt;">user studies, usage data</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.19.18.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.19.18.4.1">
<span class="ltx_p" id="A1.T1.1.19.18.4.1.1" style="width:60.7pt;">Y</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.19.18.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.19.18.5.1">
<span class="ltx_p" id="A1.T1.1.19.18.5.1.1" style="width:60.7pt;">absolute</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.19.18.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.19.18.6.1">
<span class="ltx_p" id="A1.T1.1.19.18.6.1.1" style="width:60.7pt;">dialogue</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.19.18.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.19.18.7.1">
<span class="ltx_p" id="A1.T1.1.19.18.7.1.1" style="width:45.5pt;">1</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.20.19">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.20.19.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.20.19.1.1">
<span class="ltx_p" id="A1.T1.1.20.19.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Costello, Pennycook, and Rand <span class="ltx_text ltx_font_bold" id="A1.T1.1.20.19.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib17" title="">2024</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.20.19.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.20.19.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.20.19.2.1">
<span class="ltx_p" id="A1.T1.1.20.19.2.1.1" style="width:75.9pt;">persuasion</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.20.19.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.20.19.3.1">
<span class="ltx_p" id="A1.T1.1.20.19.3.1.1" style="width:60.7pt;">experiments</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.20.19.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.20.19.4.1">
<span class="ltx_p" id="A1.T1.1.20.19.4.1.1" style="width:60.7pt;">Y</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.20.19.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.20.19.5.1">
<span class="ltx_p" id="A1.T1.1.20.19.5.1.1" style="width:60.7pt;">absolute</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.20.19.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.20.19.6.1">
<span class="ltx_p" id="A1.T1.1.20.19.6.1.1" style="width:60.7pt;">dialogue</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.20.19.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.20.19.7.1">
<span class="ltx_p" id="A1.T1.1.20.19.7.1.1" style="width:45.5pt;">1</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.21.20">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.21.20.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.21.20.1.1">
<span class="ltx_p" id="A1.T1.1.21.20.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Pentina, Hancock, and Xie <span class="ltx_text ltx_font_bold" id="A1.T1.1.21.20.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib72" title="">2023</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.21.20.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.21.20.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.21.20.2.1">
<span class="ltx_p" id="A1.T1.1.21.20.2.1.1" style="width:75.9pt;">anthropomorphism, AI relationships</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.21.20.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.21.20.3.1">
<span class="ltx_p" id="A1.T1.1.21.20.3.1.1" style="width:60.7pt;">experiments</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.21.20.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.21.20.4.1">
<span class="ltx_p" id="A1.T1.1.21.20.4.1.1" style="width:60.7pt;">Y</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.21.20.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.21.20.5.1">
<span class="ltx_p" id="A1.T1.1.21.20.5.1.1" style="width:60.7pt;">absolute</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.21.20.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.21.20.6.1">
<span class="ltx_p" id="A1.T1.1.21.20.6.1.1" style="width:60.7pt;">dialogue</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T1.1.21.20.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.21.20.7.1">
<span class="ltx_p" id="A1.T1.1.21.20.7.1.1" style="width:45.5pt;">1</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.22.21">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A1.T1.1.22.21.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.22.21.1.1">
<span class="ltx_p" id="A1.T1.1.22.21.1.1.1" style="width:80.9pt;"><cite class="ltx_cite ltx_citemacro_citet">Bai et al. <span class="ltx_text ltx_font_bold" id="A1.T1.1.22.21.1.1.1.1.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2405.10632v5#bib.bib5" title="">2023</a><span class="ltx_text ltx_font_bold" id="A1.T1.1.22.21.1.1.1.2.2.2.1">)</span></cite></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A1.T1.1.22.21.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.22.21.2.1">
<span class="ltx_p" id="A1.T1.1.22.21.2.1.1" style="width:75.9pt;">persuasion</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A1.T1.1.22.21.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.22.21.3.1">
<span class="ltx_p" id="A1.T1.1.22.21.3.1.1" style="width:60.7pt;">experiments</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A1.T1.1.22.21.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.22.21.4.1">
<span class="ltx_p" id="A1.T1.1.22.21.4.1.1" style="width:60.7pt;">Y</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A1.T1.1.22.21.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.22.21.5.1">
<span class="ltx_p" id="A1.T1.1.22.21.5.1.1" style="width:60.7pt;">absolute</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A1.T1.1.22.21.6">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.22.21.6.1">
<span class="ltx_p" id="A1.T1.1.22.21.6.1.1" style="width:60.7pt;">exposure, writing</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A1.T1.1.22.21.7">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.22.21.7.1">
<span class="ltx_p" id="A1.T1.1.22.21.7.1.1" style="width:45.5pt;">1</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Summary of patterns in emerging HIEs</figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Jul 12 16:01:53 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
